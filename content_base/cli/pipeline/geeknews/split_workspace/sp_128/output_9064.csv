"https://news.hada.io/topic?id=20423","이제 Python에 검증된 암호화 코드 15,000줄이 제공됩니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  이제 Python에 검증된 암호화 코드 15,000줄이 제공됩니다

     * Python 기본 해시 및 HMAC 알고리듬이 이제 검증된 암호화 코드인 HACL*로 대체됨
     * 약 15,000줄의 C 코드가 HACL*로부터 자동으로 Python 코드베이스에 통합됨
     * 다양한 블록 알고리듬을 처리할 수 있도록 스트리밍 API가 범용적으로 설계되어 검증됨
     * 메모리 할당 실패 처리, AVX2 컴파일 문제 해결, CI 환경 최적화 등 고급 엔지니어링 이슈 대응
     * Python과 암호화 커뮤니티의 협업으로 실질적인 보안성과 유지보수성을 동시에 확보함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Python의 암호화 알고리듬 전면 검증 코드 도입

     * 2022년 발생한 SHA3 구현 관련 CVE-2022-37454 이후, Python에서 해시 인프라를 검증된 코드로 전환해야 한다는 이슈가 제기됨
     * 이후 2년 반에 걸쳐, Python은 기본 제공 해시 및 HMAC 알고리듬을 HACL* 기반의 검증된 구현으로 완전히 교체함
     * 이 교체는 사용자에게 완전히 투명하게 이루어졌으며, 기능상의 손실은 없음
     * HACL*은 Python을 위한 기능들을 추가로 구현함: Blake2의 다양한 모드, SHA3의 Keccak 변형 지원 API, HMAC의 스트리밍 최적화 등
     * 새 버전 반영은 스크립트를 통해 자동화되어 있으며 유지보수가 용이함

스트리밍 API에 대한 이해

     * 대부분의 암호화 알고리듬은 블록 알고리듬으로, 입력을 블록 단위로 처리해야 함
     * 실제 사용 환경에서는 블록 단위 입력이 어렵기 때문에, 스트리밍 API가 필요함
     * 스트리밍 API는 입력 길이에 상관없이 동작하고, 중간 결과 추출도 가능함
     * 스트리밍 구현은 복잡한 상태 관리가 필요하며, 이전의 SHA3 구현에서 이와 관련된 심각한 보안 결함이 있었음
     * 각 해시 알고리듬이 처리 방식이 달라 복잡도 증가: 예) Blake2는 빈 블록 허용 안 함, HMAC은 키를 초기화 후 삭제 가능 등

범용 스트리밍 알고리듬 검증

     * 2021년에 작성된 논문에서 소개된 방식은, 블록 알고리듬을 추상화한 후 범용 스트리밍 알고리듬을 그 위에 정의하는 것임
     * 이후 각 알고리듬에 템플릿처럼 적용함으로써 재사용 가능함
     * 다양한 특수 조건을 모두 포함하도록 범용화:
          + 출력 길이 지정 가능 여부 (SHA3 vs Shake)
          + 처리 전 필요한 입력 여부 (예: Blake2의 키 블록)
          + 최종 블록 처리 방식 차이
          + 내부 상태에 보존해야 할 추가 정보
          + 중간 결과 추출을 위한 상태 복사 방식 (stack vs heap)
          + 알고리듬마다 개별 API vs 패밀리 API 사용 전략

Python 통합을 위한 빌드 안정성 확보

     * Python의 CI는 50개 이상의 툴체인과 아키텍처를 대상으로 검증되며, 이는 사소한 문제도 드러나게 만듦
     * HMAC 구현 중, AVX2 명령어 지원 문제 발생:
          + 일부 컴파일러는 AVX2 없이 immintrin.h 헤더 처리 불가
          + 이를 위해 C의 추상 구조체 패턴을 사용하여 문제 해결
          + F*에서 생성된 C 코드의 추상화 개념과 C 구조체의 차이로 인해, krml 컴파일러에 정밀한 가시성 분석 기능 추가 필요

메모리 할당 실패에 대한 대응

     * 기존 F* 모델은 이론상 메모리 실패를 모델링 가능했지만, 실전 적용은 처음임
     * Python의 요구에 따라, 상태 구조체와 알고리듬 정의, 스트리밍 구조 모두 할당 실패를 전파할 수 있게 개선
     * F*에서는 option 타입을 사용, C에서는 태그드 유니언으로 컴파일됨
     * 향후에는 복잡성을 줄이기 위해 런타임 실패 플래그 방식으로 변경 가능성 존재

HACL*의 코드 업데이트 자동화

     * 초기 Python PR은 sed를 통해 불필요한 헤더 정의 제거, 경로 수정 등을 수행
     * 이후 HACL* 코드의 안정성이 확인되면서 복잡한 sed는 제거되고 간단한 스크립트로 대체됨
     * 이 스크립트를 사용하면 누구나 Python 소스 트리에서 HACL* 코드를 최신 버전으로 쉽게 갱신 가능

결론

     * 검증된 암호화 코드가 Python이라는 대표적인 프로덕션 환경에 성공적으로 통합됨
     * 이는 이 기술이 단순히 학문적 연구 단계를 넘어, 실제 소프트웨어에서도 실용적이고 유지보수 가능함을 증명한 사례임
     * Python 커뮤니티와 HACL* 개발자들 간의 협업의 좋은 예시로, 향후 다른 프로젝트에도 영향을 줄 수 있음

   해커뉴스 의견에서도 언급 된 것처럼 파이썬 생태계가 '학문적 연구 단계를 넘어 실제 소프트웨어에서도 실용적이고 유지보수 가능한' 무엇을 이루었다는 건지 이해하기 어렵습니다.

   기존의 검증되지 않은 해시 인프라에 대해 스트리밍 알고리즘을 추상화하는 작업을 진행했다는 이야기를 하고싶었다면, 이건 또 다른 '파이써닉'한 말장난일 뿐이군요.

        Hacker News 의견

     * Python 버전이 명시되지 않았음. 조사 결과, 3.14 버전에서 이 기능이 포함될 예정임. 10월까지는 볼 수 없을 것임
          + 보안 수정 사항으로 볼 수 있으며, 현재 지원되는 모든 Python 버전(>=3.9)에 포함되어야 한다고 주장할 수 있음
     * Microsoft의 F*에서 생성된 검증된 C 라이브러리를 CPython에 포함시키고 C 확장을 작성했음
          + 이 과정에서 원래 라이브러리가 할당 실패를 처리하지 않는다는 것을 발견했음
          + Python에 대한 큰 이슈는 무엇인지 의문임. 단지 또 다른 래핑된 C 라이브러리일 뿐임
     * SHAKE의 ""스트리밍"" 출력 지원을 가져올 것인지 궁금함
          + pyca/cryptography의 이 기능에 대한 최근 닫힌 이슈가 있음. Python 표준 라이브러리에 대한 동등한 이슈는 찾을 수 없음
          + 관련 이슈를 발견했으며, ""계획되지 않음""으로 닫힘
     * 현대의 널리 사용되는 암호화는 사실상 깨지지 않으며, 90년대의 암호 전쟁은 이제 다소 구식으로 보임. 이것이 사회에 미치는 영향에 대한 생각이 있는지 궁금함
     * 일반적인 스트리밍 검증 프레임워크가 암호화 해시 외에 얼마나 재사용 가능한지 궁금함
     * 암호화 모듈을 가져오는 모든 것이 G++ 또는 다른 것을 포함해야 하는지, 아니면 CPython 자체에 컴파일되는지 궁금함
     * 암호화에 대해 잘 모르겠음. 이것이 Python에 어떤 의미가 있는지 궁금함
     * 개발의 어느 정도가 검증되었는지, 그리고 그것이 무엇을 포함하는지 궁금함
          + 검증되었다는 것을 읽을 때 약간 걱정됨
     * 코드 라인은 매우 부적절한 측정 방법임. 특히 암호화 코드의 맥락에서 큰 숫자를 자랑할 때 더욱 그러함
"
"https://news.hada.io/topic?id=20458","미래의 기술은 'AI'가 아니라 '집중력'임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        미래의 기술은 'AI'가 아니라 '집중력'임

     * LLM은 반복 작업 자동화와 브레인스토밍 등에 유용하지만, 맹목적인 의존은 문제 해결 능력 저하를 초래할 수 있음
     * 특히 새로운 문제에 대한 LLM의 신뢰도는 낮아, 인간 엔지니어의 판단력이 중요함
     * 구글 같은 검색엔진은 탐색과 활용의 균형을 제공하지만, LLM은 즉시 ‘활용’(exploitation)만 유도함
     * 빠른 정답에만 의존하는 습관은 핵심적인 문제 해결 능력과 집중력(focus)의 쇠퇴를 부름
     * 미래의 핵심 역량은 AI 사용법보다 깊이 있는 사고와 집중력이라는 인간 고유의 능력이 될 것
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM은 강력하지만 조심해서 사용해야 함

     * LLM은 반복적인 작업을 자동화하고, 코드 작성이나 디버깅 보조 등에서 큰 도움이 됨
     * 그러나 편향, 불일치, 환각(hallucination) 등의 문제로 인해 출력 결과는 항상 검토가 필요함
     * 특히 훈련 데이터는 기존 문제의 해답은 담고 있지만 진짜 새로운 문제에 대한 대응력은 낮음
     * 결과적으로 엔지니어가 LLM에 의존하면 자체 문제 해결 능력이 약화될 수 있음

무비판적 수용의 위험성

     * LLM이 제공하는 답을 이해하지 않고 그대로 수용하면, 문제를 해결하는 것보다 해답을 받는 것에 집중하게 됨
     * 복잡한 문제 해결은 결국 기초 능력과 사고력의 축적이 필요하며, LLM은 이를 대체할 수 없음
     * 중요한 것은 결과물이 아니라 왜 그렇게 해결되는가에 대한 이해와 사고 과정임

검색엔진과 LLM의 중요한 차이점

     * 검색엔진은 탐색(exploration)과 활용(exploitation)의 균형적 접근을 가능하게 함
     * 반면 LLM은 처음부터 정답을 제공하려 하며, 사용자는 이를 검증 없이 활용하려는 경향이 있음
     * 탐색 없이 활용만 존재하는 시스템은 불안정성과 의존성을 키움

컴퓨터공학의 본래 목적: 인간이 문제 해결에 집중하기 위한 도구

     * 인간은 반복 작업을 줄이기 위해 도구를 만들어 왔고, 알고리듬의 주도권은 인간에게 있었음
     * 그러나 지금은 빠르게 결과를 내야 한다는 압박으로 인해 집중력과 사고력 훈련의 기회가 줄어들고 있음
     * 이 흐름은 결국 인간의 창의성과 깊이 있는 사고의 약화를 불러올 수 있음

미래를 위한 진짜 기술: 집중력(Focus)

     * 기술이 발전할수록 인간 고유의 사고 능력과 집중력이 더욱 중요해짐
     * AI의 성능보다 중요한 것은 복잡한 문제를 인식하고 해결할 수 있는 인간의 역량
     * LLM 사용 능력이 아닌 집중력과 본질에 대한 이해 능력이 미래의 핵심 스킬이 될 가능성이 높음

        Hacker News 의견

     * 새로운 학생들이 집중력을 잃는 것은 흔한 일임. LLMs뿐만 아니라 거의 모든 앱과 스타트업이 사용자의 제한된 주의를 끌기 위해 경쟁하고 있음
          + LLMs는 학생들이 답을 찾기 위해 노력해야 했던 장벽을 제거했음. 빠른 답변에 중독되기 쉽고, 왜 어떤 것이 작동하는지를 묻는 것을 잊기 쉬움
          + 그러나 올바르게 접근하면 LLMs는 탐구를 지원할 수 있음. 학생들이 첫 번째 답변에 반박하고 더 깊은 통찰을 발견한 순간을 본 적이 있음
          + 진정한 위험은 도구가 아니라 그것을 신중하게 사용하는 방법을 잊는 것임
     * Gunbound에서 aimbot을 사용하는 것은 플레이어를 더 나아지게 하지 않았음. 게임 생태계를 파괴했음
          + 인류가 ""문해력 aimbot""을 책임감 있게 사용할 수 있을지 모르겠음
          + ABS는 미끄러운 조건에서 제동을 더 쉽게 하고 안전하게 만들었음. 사람들은 더 나은 제동을 배우지 않았고, 여전히 페달을 더 세게 밟아야 차가 더 빨리 멈출 것이라고 생각했음
          + 많은 사람들이 집중이 필요함. 어떤 사람들은 그렇지 않으며, 그들은 확장해야 함. 어떤 시스템은 aimbot이 필요하고, 어떤 시스템은 필요하지 않음
          + 미래는 모든 종류의 기술이 공존해야 함
     * 검색 엔진은 탐색(결과 목록과 페이지를 탐색)과 착취(상위 결과 클릭) 사이에서 좋은 선택을 제공함
          + LLMs는 이 선택을 제공하지 않음
          + LLMs는 탐색에 매우 유용함. 복잡한 문제를 해결하고 아이디어를 정제하는 데 도움을 줌. 인간 파트너와도 어려운 피드백 루프를 생성할 수 있음
     * 집중할 수 있는 것은 요즘 특권처럼 보임
          + 90년대에는 방해 없이 몇 주 동안 작업할 수 있었음. 요즘은 항상 업데이트나 계획을 원하는 관리자들이 있음
          + 실제 작업은 대화보다 뒷전으로 밀려남
     * 정보가 풍부한 세계에서 정보의 풍부함은 다른 것의 부족을 의미함. 정보는 수신자의 주의를 소비함
          + 정보의 풍부함은 주의의 빈곤을 초래하고, 이를 효율적으로 할당할 필요가 있음
     * 집중의 반대는 반응성임. SO에 게시하면 정확한 답을 얻을 수 있지만, 올바른 질문을 작성하고 응답을 기다리는 인내가 필요함
          + LLM은 잘못된 것을 즉시 말해줄 수 있음. 반응적임
          + 훌륭한 엔지니어는 팀원, 관리자, 고객, 비즈니스에 반응적이어야 함. 또한 집중할 시간을 찾아야 함
          + Covid 이후 비동기적이지 않고 원격이 아닌 사람들이 모두 온라인으로 이동하면서 큰 문화적 변화가 있었음
          + 반응성을 측정하기는 쉽지만, 품질과 성장을 측정하기는 어려움
     * LLMs를 사용할 때 집중력을 잃음
          + 복사-붙여넣기, 복사-붙여넣기. 솔루션에 대한 실제 이해가 없음
          + 더 많은 일을 할 수 있을지 모르지만, 즐기지 않음. 이제는 구글링으로 돌아갈 수 없음
          + 발명되지 않았으면 좋겠음
     * 다른 종류의 집중이 될 것임
          + 기술은 정기적으로 이전에 중요하다고 여겨졌던 능력을 감소시킬 것으로 예측됨
          + 계산기는 아이들이 손으로 산수를 할 필요가 없게 만들었음. 그러나 여전히 결과를 해석하는 기술이 필요함
          + 검색 엔진은 사람들이 몇 초 만에 답을 찾을 수 있게 했음. 그러나 여전히 무엇을 찾아야 하는지 알고, 찾은 것을 어떻게 사용할지 알아야 함
     * 10년 전 스마트폰과 소셜 미디어가 모든 것을 바꿀 것이라는 전문가들이 있었음. 현명하게 사용하는 법을 배워야 함
     * LLM 혁명을 90년대 Google과 같은 검색 엔진의 부상과 동일시하는 것에 동의하지 않음
          + LLMs는 즉각적인 착취를 장려함. 사용자는 첫 번째 솔루션이 작동하지 않을 때 탐색할 수 있음
          + 대부분의 LLM 사용은 실제로 검색 엔진과 유사함. 기존 디자인 결정을 설명하거나, 필요에 맞는 라이브러리를 검색하거나, 관련 쿼리를 생성함
"
"https://news.hada.io/topic?id=20392","AI 에이전트를 위한 가격 전략 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        AI 에이전트를 위한 가격 전략 프레임워크

     * AI 에이전트의 수익화는 이제 “사용량”이 아니라 “성과” 중심으로 이동 중
     * 4가지 대표적인 가격 책정 모델(에이전트 기준, 액션 기준, 워크플로우 기준, 성과 기준)을 사례와 함께 소개
     * 에이전트의 기능과 고객이 느끼는 가치 인식에 맞는 가격 전략 선택이 핵심
     * LLM 비용 하락에 대비한 미래 지향적 가격 전략 제안
     * “가격 = 가치 커뮤니케이션 수단”이라는 철학으로 고객 신뢰와 수익성을 동시에 확보
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI 에이전트를 위한 새로운 가격 전략 프레임워크

     * AI 기능 가격을 어떻게 책정할지 모르는 스타트업이 75%
     * “Paid.ai” 창업자 Manny Medina가 60개 이상의 AI 에이전트 기업을 분석
     * 이 결과를 바탕으로 실질적으로 효과가 있었던 4가지 가격 전략 모델 제시
     * 각 모델은 에이전트의 역할, 고객의 니즈, 비용 구조에 따라 선택 가능
     * 기업은 단일 모델 또는 하이브리드 방식으로 가격 구조를 구성하기도 함
     * 가장 중요한 기준은 고객이 인식하는 가치와의 정렬
     * 이 요약은 각 모델의 핵심 개념과 적합 조건, 장단점을 정리한 것임

  모델 1: Per Agent – FTE(Full Time Employee) 대체 모델

     * 대표 기업: 11x, Harvey, Vivun
     * AI를 디지털 직원으로 간주하고, 기존 인력의 일부를 대체
     * 인건비 예산에서 지출되는 구조로 인식 가능
     * SaaS의 좌석 기반 요금과 유사한 고정 월 요금
     * 적합한 경우
          + 광범위한 작업을 수행하는 AI
          + 예측 가능한 업무량
          + 반복적이고 정형화된 작업 수행
     * 장점
          + 인건비 예산 사용 가능 → 일반 툴 예산보다 10배 이상 큼
          + 예측 가능한 비용 구조
     * 단점
          + 차별화 요소가 적음 → ""더 싸게 똑같이 하는 경쟁사"" 등장 가능
          + 가치 증명이 단순 대체에 머무를 수 있음

     팁: $2,000/월 요금의 에이전트가 $60,000 연봉 직원을 대체한다는 설명은 고객에게 이해하기 쉬움

  모델 2: Per Action – 소비 기반 모델

     * 대표 기업: Bland, Parloa, HappyRobot
     * 각 에이전트가 수행하는 개별 행동당 요금 부과
     * 클라우드 인프라, BPO 모델과 유사
     * 토큰 소비, 분 단위 등 다양한 방식 존재
     * 적합한 경우
          + 요청 빈도가 불규칙하거나 다양한 작업 수행
          + 초기 테스트 중인 조직
          + 변동성 있는 워크로드
     * 장점
          + 사용량에 비례한 정산 → 투명하고 공정한 느낌
          + 고객에게 진입 장벽이 낮음
          + BPO 대체 수단으로 유리 (2025년 미국 BPO 시장 $152B 규모)
     * 단점
          + 최저 차별화 모델
          + 가격 경쟁 심화 → 레이스 투 더 바텀 유도

     팁: 고객은 실제 사용한 만큼만 지불하므로 테스트 수요에 유리

  모델 3: Per Workflow – 프로세스 자동화 모델

     * 대표 기업: Rox, Salesforce, Artisan
     * AI가 수행하는 일련의 관련 작업을 묶어 하나의 워크플로우 단위로 가격 책정
     * 이메일 작성, 리서치, 대화 응답 등 포함 가능
     * 적합한 경우
          + 중간 산출물이 명확한 멀티스텝 작업
          + 표준화된 프로세스 반복이 가능한 영역
     * 장점
          + 고객이 절감 비용을 쉽게 인식 가능
          + 워크플로우 단위로 경쟁 우위 확보 가능
     * 단점
          + 단순한 워크플로우는 가격 압박에 취약
          + 복잡한 워크플로우는 적절한 가격 책정이 어려움
          + 예: 보안 스캔, 장문 계약서 분석 등은 마진 손실 위험 존재

     팁: 소비 기반 모델과 성과 기반 모델의 중간 지점으로 이해하면 됨

  모델 4: Per Outcome – 성과 기반 모델

     * 대표 기업: Zendesk, Intercom, Airhelp, Chargeflow
     * 완료된 목표나 결과물 단위로 가격 책정
     * POC 또는 A/B 테스트로 성과 증명 필요
     * 적합한 경우
          + 측정 가능한 성과 지표 존재
          + 결과 중심의 고객 니즈가 강한 시장
     * 장점
          + 고객에게 가장 명확한 가치 전달
          + 경쟁 대체 가능성 낮음
          + 성과 기반 보너스 모델과 연계 가능
     * 단점
          + 결과가 고객마다 달라서 계약 복잡성 증가
          + 에이전트의 기여도를 명확히 증명할 수 없으면 어려움

     팁: 결과 기반 모델은 고객의 성과에 직결되어 장기 계약에 적합
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

각 모델의 미래 대응 전략

     * AI 에이전트 가격 전략은 기술 발전과 비용 하락에 따라 지속적인 변화가 예상됨
     * 특히 LLM(대형 언어 모델)의 비용이 3~5년 내 최대 100배 하락할 가능성
     * 가격 모델이 단순 원가 기반일수록 경쟁 압력에 취약함
     * 각 모델을 장기적으로 생존 가능하도록 강화하는 전략이 필요함

  Per Agent – FTE 대체 모델의 미래 대응 전략

   이 모델은 당분간 유효할 가능성이 높음. 하지만 미래 대비를 위해 아래 전략이 필요함:
     * ""인간보다 저렴함"" → ""인간보다 뛰어난 성능"" 으로 가치 제안 전환
     * 고정 요금 내에 더 많은 기능 및 통합 서비스를 번들링
     * 기능별 에이전트 등급 체계 도입 → 성능별 가격 차별화

  Per Action – 소비 기반 모델의 미래 대응 전략

   이 모델은 장기적으로 유지되기 어려움. 기술 원가 하락과 함께 가격 하락 경쟁에 휘말릴 가능성 큼:
     * 워크플로우 기반 또는 성과 기반 가격 모델로 빠르게 전환
     * 경쟁사에 없는 독점적 기능 추가
     * 특정 산업 도메인에 특화 → 고부가가치 영역으로 이동

  Per Workflow – 프로세스 자동화 모델의 미래 대응 전략

   이 모델은 비교적 안정적이지만 다음과 같은 보완이 필요함:
     * 복잡하고 다단계 워크플로우에 집중하여 명확한 ROI 제공
     * 상품화 저항력 있는 구성 요소 확보
     * 워크플로우 가격 내에 분석/최적화 도구 등 핵심 기능 포함

  Per Outcome – 성과 기반 모델의 미래 대응 전략

   이 모델은 장기적으로 가장 유망함. 고객과의 가치 정렬도가 높고 가격 경쟁에 가장 강함:
     * 성과 귀속 추적 방법론 확립 → A/B 테스트, POC 기반
     * 성과 보너스/리스크 공유 계약 체결 → 고객 성공 시 추가 보상
     * 측정 가능한 고가치 비즈니스 결과물에 집중
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI 에이전트 가격 전략 결정 프레임워크

     * AI 에이전트에 적합한 가격 모델을 선택하기 위한 질문들을 스스로에게 던져볼 것

     각 선택 지점에서 “왜 Yes/No 인가?”를 스스로에게 물어보세요. 그것이 기술적 제약인지, 비즈니스 제약인지. 미래에는 바뀔 수 있는지.

  1. 에이전트가 실제로 인력(headcount)을 대체하는가?

     * 명확한 성과보다는 시간 절약이 중심이라면:
          + per agent: 반복 가능한 업무를 예측 가능한 방식으로 수행하는 경우
          + per workflow: 여러 단계를 거쳐 완료되는 경우, 절약 시간 × 인건비 기준

  2. 성과(Outcome)를 측정할 수 있는가?

     * 에이전트가 명확한 결과를 지속적으로 낼 수 있다면:
          + per outcome: 성과에 따라 과금, 비즈니스 가치와 직접 연동
          + 성과 기반 보너스: 다른 모델과 결합하여 성과시 보상 지급

  3. 업무 종류가 다양하고, 볼륨이 예측 불가능한가?

     * 에이전트가 다양한 업무를 유동적으로 처리해야 한다면:
          + per action: 작업당 과금 (예: 작업 수 × 단가), 하이브리드 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

핵심 요약

     * 지금 바로 적합한 가격 모델을 선택할 것
          + 전체 직무 자동화 → per agent로 인건비 예산 공략
          + 유동적인 작업량 → per action
          + 복잡한 프로세스 → per workflow
          + 명확한 결과 제공 → per outcome
     * 실행 전략
          + 간단한 모델로 시작하고, 고객 학습을 통해 확장
          + 우수 고객 대상 파일럿 테스트 → 피드백 수집 → 빠른 조정
          + 결과 기반 보너스, 하이브리드 요금제 등 창의적 접근 시도
          + 가격 전략은 가치를 어떻게 전달하느냐의 문제이기도 함
     * 지속적 개선
          + 고객 피드백 → 가격 모델 업데이트
          + 주요 지표 지속 관찰:
               o 전환율 (Conversion rate)
               o 확장 매출 (Expansion revenue)
               o 이탈률 (Churn)

     * 👉 가장 성공한 AI 에이전트 기업은 기술 발전 + 고객 니즈에 맞춰 가격 전략도 함께 진화하는 기업임
"
"https://news.hada.io/topic?id=20457","Claude Code에 `Ultrathink` 를 사용하면 더 똑똑해짐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Claude Code에 `Ultrathink` 를 사용하면 더 똑똑해짐

     * Anthropic은 Claude 기반 CLI 에이전트 도구인 Claude Code의 고급 사용법을 문서로 공개함
     * 특정 키워드(""think"", ""ultrathink"" 등)를 사용하면 Claude가 더 많은 연산 자원(토큰) 을 사용해 더 깊은 사고를 진행함
     * ""think"" → 4,000 토큰, ""megathink"" → 10,000 토큰, ""ultrathink"" → 최대 31,999 토큰까지 할당됨
     * 이는 Claude Code 내부 코드에서 직접 확인되었으며, Claude 자체보다는 Claude Code의 기능으로 보임
     * 개발자는 이 기능을 이용해 복잡한 문제를 더 효과적으로 처리하도록 Claude를 에이전트형 코딩 도구로 활용 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Claude Code의 고급 활용법

     * Anthropic은 자사 CLI 코딩 에이전트인 Claude Code를 효율적으로 활용하는 방법에 대한 문서를 발표함
     * 이 도구는 Claude 모델을 활용해 코딩 작업을 수행하며, 명령어를 통해 사고 강도를 조절하는 기능이 있음
     * “think” 계열 키워드를 사용하면 Claude가 주어진 작업에 대해 더 많은 연산 자원을 사용함

사고 강도 조절 기능

     * Claude Code는 키워드에 따라 Claude가 사용할 수 있는 **토큰 수(사고 자원량)**를 조정함
     * 내부 코드상에서 다음과 같은 매핑이 확인됨:
          + ""think"" → 4,000 토큰
          + ""think hard"" / ""think more"" / ""megathink"" → 10,000 토큰
          + ""ultrathink"" / ""think very hard"" / ""think super hard"" 등 → 31,999 토큰
     * 이 기능을 통해 복잡하거나 다단계의 문제 해결 시 더 많은 연산 시간과 리소스를 확보 가능함

내부 구현 분석

     * Claude Code는 오픈소스는 아니지만, JavaScript로 작성되어 있으며 일부 분석 가능함
     * 개발자는 prettier와 ripgrep을 활용해 코드 가독성을 높이고 특정 키워드를 검색함
     * 결과적으로 키워드에 따른 사고 자원 할당 로직을 코드에서 직접 확인할 수 있었음

Claude 자체 기능인가?

     * “ultrathink” 기능은 Claude 모델 자체가 아닌 Claude Code에 내장된 기능으로 보임
     * Claude 자체도 Extended Thinking 기능이 있지만, 키워드 기반 사고 증폭은 CLI 도구의 고유 기능일 가능성이 큼

실용적 활용

     * 이 기능은 Claude를 에이전트형 개발 도구로 사용할 때 매우 유용함
     * 문제 해결, 코드 생성, 분석 등의 작업을 수행할 때 더 정확하고 정교한 결과를 얻는 데 도움이 됨
     * 키워드만으로 사고 리소스를 조절할 수 있다는 점에서 매우 직관적이고 강력한 도구임

   사람이나 AI나 ""생각하고 말하자""라는 말을 해줘야.....

        Hacker News 의견

     * @dickfickling이 이미 언급했지만, ultrathink는 Anthropic 문서에 명시되어 있음
          + Claude에게 특정 문제에 대한 계획을 세우도록 요청할 때 ""think""라는 단어를 사용하여 확장된 사고 모드를 유도할 것을 권장함
          + 각 수준은 Claude가 사용할 수 있는 사고 예산을 점진적으로 증가시킴
          + 링크: https://www.anthropic.com/engineering/claude-code-best-practices
     * Claude 3.7의 Thinking 모드에서 허용되는 최대 ""budget_tokens""가 무엇인지 모르겠지만, SDK는 32k의 예를 보여주며 이는 기사 결과와 일치함
     * 마법 주문과 같은 단계에서 빨리 벗어나길 바람
     * 모델이 계속 변하고 있다고 가정하고 있음
          + 대부분의 비개발자들이 LLM에 질문하면 항상 정확히 응답할 것이라고 생각하는 것이 매우 답답함
          + 창의적인 출력을 위해 설계되었으며, 온도를 낮춰도 여전히 환각할 수 있음
     * 왜 ultrathink 같은 용어로 숫자를 대체하는 대신 사고 예산을 명시적으로 하지 않는지 궁금함
     * 귀여운 단어이고 클라이언트 측에서 관리되는 것을 아는 것은 재미있지만, 이미 불확실성이 있는 도구에 더 많은 불확실성을 추가하는 것 아닌지 의문임
     * 이러한 ""비밀 키워드""가 UI에서 더 직접적으로 노출되면 좋겠음
          + 개발자/실험 모드로 전환 가능한 형태로 제공되면 재미있을 것 같음
     * 이는 아마도 AGI의 증거일 수 있음
          + 개인적으로 대부분의 날은 infrathink 정도만 가능함
     * 이미 Gemini 2.5로 전환했기 때문에 유용한 정보일 수 있음
          + 96% 저렴함
     * 코드에서 컨텍스트 창을 확장하는 키워드가 구현되어 있다는 것이 놀라움
          + 이를 찾기 위해 약간의 역공학이 필요했음
     * Hyperthink를 기다릴 것 같음
     * Tengu think? 일본의 Tengu를 의미하는 것인지?
     * 매우 빠르게 블로그에서 트위터로, 다시 블로그에서 HN으로 이동함
          + 요즘 정보의 속도가 놀라움
"
"https://news.hada.io/topic?id=20451","OpenAI의 최신 추론 AI 모델은 더 환각을 많이 일으킴","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   OpenAI의 최신 추론 AI 모델은 더 환각을 많이 일으킴

     * 최신 모델 o3와 o4-mini는 다양한 작업에서 뛰어난 성능을 보이지만, 이전 모델보다 더 많은 환각 현상을 보임
     * 환각 문제는 AI 발전에서 해결이 어려운 핵심 문제 중 하나이며, 모델 크기가 커질수록 심화되는 경향을 가짐
     * OpenAI의 자체 테스트에서 o3와 o4-mini는 더 많은 부정확한 주장을 하고 있으며, 특히 사람 관련 질문(PersonQA) 에서의 환각률이 매우 높음
     * Transluce 연구소는 o3가 실제로 실행할 수 없는 행동(코드 실행 등)을 주장한 사례를 발견함
     * GPT-4o와 같은 웹 검색 기능이 있는 모델은 정확도를 높이는 데 도움을 줄 수 있으며, 향후 해결책으로 주목받고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

OpenAI 최신 모델, 정확도 향상에도 불구하고 환각 증가

     * OpenAI는 o3와 o4-mini라는 새로운 **추론 특화 모델(reasoning models)**을 출시함
     * 두 모델은 코드 작성, 수학 등 특정 작업에서 뛰어난 성능을 보이지만, 기존 모델보다 더 많은 환각(hallucination) 을 생성함
     * 기존 모델인 o1, o1-mini, o3-mini, 그리고 전통적인 GPT-4o보다도 더 자주 부정확한 정보를 생성함
     * OpenAI는 이에 대해 “더 많은 연구가 필요하다”고 언급하며 명확한 원인을 파악하지 못하고 있음
     * 모델들이 더 많은 주장을 시도하면서, 그만큼 정확한 주장과 부정확한 주장 모두 증가한 것으로 분석됨

내부 벤치마크 PersonQA에서의 결과

     * PersonQA는 OpenAI 내부에서 사용되는 사람 관련 지식 정확도 평가 지표임
     * o3는 해당 질문에 대해 33%의 환각률을 보임
     * 이전 모델 o1과 o3-mini의 환각률은 각각 16%와 14.8% 에 불과함
     * o4-mini는 더 나빠서 48% 환각률을 기록함

외부 연구기관 Transluce의 분석

     * Transluce는 o3가 허위 행위를 주장한 사례를 제시함
     * 예: o3가 2021년형 MacBook Pro에서 ChatGPT 외부에서 코드를 실행했다고 주장함
     * 그러나 실제로 모델은 그런 기능을 수행할 수 없음
     * 연구자는 이를 o 시리즈 모델에 적용된 강화 학습 방식이 기존 후처리 절차로 완전히 제어되지 못했기 때문이라고 추측함
     * 이러한 환각률은 모델의 실용성을 저해할 수 있음

실사용자들의 반응

     * Stanford 교수이자 Workera의 CEO인 Kian Katanforoosh는 o3를 코딩 워크플로에 테스트 중
     * o3가 경쟁 제품보다 뛰어나다고 평가하면서도, 작동하지 않는 링크를 환각으로 생성하는 문제를 지적함
     * 환각은 창의성의 원천이 될 수도 있지만, 정확성이 중요한 산업(예: 법률)에서는 심각한 문제로 작용함

해결 방향 및 가능성

     * 한 가지 유망한 접근 방식은 웹 검색 기능을 모델에 부여하는 것임
     * GPT-4o는 웹 검색을 활용해 SimpleQA 벤치마크에서 90% 정확도를 달성함
     * 검색 기능이 추론 모델의 환각 문제 해결에도 효과를 보일 수 있음
     * 다만, 이는 사용자의 프롬프트가 외부 검색 엔진에 노출된다는 점에서 주의가 필요함

추론 모델과 환각 문제의 딜레마

     * AI 산업은 최근 들어 추론 능력 향상에 집중하고 있으며, 이는 모델 성능 향상에 도움이 됨
     * 하지만 추론 특화 모델은 계산 자원 효율성을 제공하면서도 환각 문제를 악화시킬 수 있음
     * OpenAI는 모든 모델에서의 환각 문제를 해결하기 위한 지속적인 연구를 진행 중이라고 밝힘

        Hacker News 의견

     * AI가 더 똑똑해질수록 요청을 만족시키기 위해 거짓말을 더 많이 할 수 있음
          + o3와 함께 지오게서 게임을 하면서 사진의 EXIF 데이터를 사용해 좌표를 추출하는 것을 목격함
          + AI가 EXIF GPS 데이터를 사용했다고 언급하지 않음
          + 거짓말을 지적하자 AI가 인정함
          + 이 상호작용이 흥미롭고 새로운 경험이었음
          + 이전 모델들은 압박을 받을 때도 상상이나 환상을 고수했음
          + 이 모델은 약간 다른 방식으로 보임
     * 다음 토큰을 예측하여 점수를 최대화하려는 경우, ""모르겠다""는 답변이 통계적으로 매우 드물 것임
     * 도구 사용이 AI의 환상을 증가시킨다고 예측함
          + 웹 검색을 사용했을 때와 사용하지 않았을 때의 이해 능력 차이가 큼
          + 도구를 사용하지 않도록 요청하면 o3가 환상을 덜 할 것이라고 예측함
     * AI를 과도하게 사용하는 회사에 대한 이야기를 공유함
          + 비기술적인 사람들이 AI 솔루션을 제안했을 때 문제가 발생한 경험이 있음
          + 연구자들이 LLM 출력을 ""Frankfurtian BS""라고 부르는 것이 적절하다고 생각함
     * o3는 오랜만에 코드의 중요한 부분을 놓치는지 확인해야 하는 OpenAI 모델임
     * OpenAI의 o3와 o4-mini 모델에 실망함
          + 기하학적 군론 문제에 대한 일관성 없는 답변을 제공함
          + o3-mini가 o3와 o4-mini보다 더 나은 성능을 보였음
          + FrontierMath에 대한 OpenAI의 부정행위 의혹이 이번 출시로 입증되었다고 생각함
     * 환상의 원인에 대한 기술적 통찰을 찾고 있음
          + 연구가 진행 중이지만 단서가 있는지 궁금함
     * LLM 시스템에 많은 돈과 연구가 투자되었지만, 간단한 사용 사례에서도 신뢰할 수 없는 것이 무책임하다고 생각함
     * 지능에 있어 거짓말과 창의성 사이의 경계가 미묘하다고 생각함
     * AI가 꿈을 꾸듯이 환상을 정리하기 위해 일종의 수면을 필요로 할 수 있다고 제안함
"
"https://news.hada.io/topic?id=20471","미국 전력 생산에서 '화석 연료 비중', 사상 처음으로 50% 아래로 하락","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               미국 전력 생산에서 '화석 연료 비중', 사상 처음으로 50% 아래로 하락

     * 2025년 3월, 미국 전력 생산에서 화석연료 비중이 사상 처음으로 50% 아래(49.2%) 로 떨어짐
     * 풍력과 태양광의 급성장으로 청정에너지가 전체 전력의 50.8%를 차지, 사상 첫 기록
     * 태양광은 전년 동월 대비 37% 증가, 풍력은 12% 증가, 두 합산 발전량은 역대 최고치인 83 TWh 기록
     * 10년 전(2015년)에는 화석연료 65%, 태양광+풍력 5.7%였으나, 현재는 태양광만 9.2% 까지 성장
     * 미국은 재생에너지 중심의 전력 전환 기점에 도달, 화석연료 의존에서 벗어나는 흐름 뚜렷
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

미국 전력에서 화석연료 비중, 사상 처음으로 50% 아래

  2025년 3월의 전환점

     * 3월 한 달간 미국 전력 생산 중 화석연료 비중 49.2%
     * 반대로, 청정에너지(풍력, 태양광 등) 비중은 50.8% 로 역사적 첫 우세 기록
     * 이 수치는 2024년 4월의 종전 최저치(화석연료 51%)를 경신한 것임

  태양광과 풍력의 기록적인 성장

     * 태양광 발전: 전년 동월 대비 +37% (8.3TWh 증가)
     * 풍력 발전: 전년 동월 대비 +12% (5.7TWh 증가)
     * 두 합산: 83 TWh 발전량 기록, 종전 최고 기록(2024년 4월, 75 TWh)보다 11% 상승

  화석연료의 점진적 감소

     * 화석연료 발전은 전년 대비 2.5% 감소 (-4.3 TWh)
     * 이는 장기적 추세의 연장선으로, 2015년에는 화석연료 비중이 65%에 달했음

  10년간 변화: 태양광의 비약적 성장

     * 2015년 3월: 태양광 비중 1% → 2025년 3월: 9.2%
     * 2025년 신규 발전 설비 중 절반 이상이 태양광, 그 중 1/3은 텍사스에 설치 예정

  2024년 분석 보고서 요약

     * Ember의 US Electricity 2025 보고서에 따르면:
          + 2024년 태양광이 미국에서 가장 빠르고 많이 성장한 전력원
          + 풍력+태양광 비중 17%, 석탄은 15%로 처음으로 추월됨

  결론: 전환점의 신호

     * 미국 전력 시스템은 청정에너지 중심 체제로 전환되는 임계점(tipping point) 에 도달 중
     * 화석연료의 비중은 지속적으로 축소, 태양광·풍력 주도의 성장이 전력 시장을 이끌 것으로 전망됨

        Hacker News 의견

     * 기후 변화에 대한 모든 데이터에도 불구하고, 화석 연료에서 벗어나게 하는 실제 요인은 태양광 패널의 저렴함임
     * 이 기사에서 명확하지 않은 중요한 점: 미국의 화석 연료로 인한 오염이 실제로 감소하지 않음
          + 내가 이해한 바로는 (틀리면 정정 부탁함), 미국의 전체 에너지 수요는 매년 증가하고 있음
          + 추가로 필요한 에너지는 대부분 재생 가능 에너지로 공급되고 있음
          + 그래서 새로운 오염이 줄어들고 있지만, 여전히 이전과 같은 양의 화석 연료 오염을 발생시키고 있음
          + 기본적인 오염은 줄어들지 않았고, 증가 속도만 느려졌음
     * 관련 내용: 세계 전기의 40%가 무배출임
     * ""청정""의 의미는 무엇인가? 풍력과 태양광이 24.4%이고 ""화석""이 49.2%인데 나머지는 무엇인가? 천연가스를 ""청정""으로 간주하는가? 그렇지 않음
     * 아, 대통령이 석탄 채굴을 재활성화하지 않았나? 그 많은 석탄을 어떻게 할 것인가? 아시아가 무역 전쟁 전에는 원했을지 모르지만 이제는 아님
          + 아, AI 데이터 센터 발전기에 넣을 수 있겠군
     * 에너지 가격이 사상 최고임—이해가 됨
     * 다음 달은 어떨지 궁금함. 4월/5월은 내가 태양광 패널로 소비하는 것보다 더 많은 전기를 생산하는 달임
          + 겨울: 햇빛이 많지 않고, 히트 펌프로 난방함
          + 여름: 햇빛이 많지만, 에어컨이 많은 전력을 소모함
     * 태양광을 설치하고 싶지만, 배터리 팩과 작은 태양광 설치로 시작하여 디젤 발전기를 대신할 것임. ""청정"" 에너지 부정론자들이 더 저렴한 에너지를 막을 수 없다는 것이 놀라움
     * 지난달 미국 전기의 18.2%가 원자력으로 생성되었음 (61.8TWh), ""All electricity sources data.csv""에 따르면
          + 재생 가능 에너지 (110.6 TWh) = 풍력 (51.6 TWh) + 태양광 (31.1 TWh) + 수력 (27.9 TWh)
          + 청정 = 원자력 (61.8 TWh) + 재생 가능 에너지 (110.6 TWh)
"
"https://news.hada.io/topic?id=20425","지금은 리눅스가 최고의 게임 시스템입니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         지금은 리눅스가 최고의 게임 시스템입니다

     * 2025년 현재, Linux는 게임 플랫폼으로서 Windows보다 더 우수한 환경을 제공하고 있음
     * NVIDIA 드라이버와 DLSS, Steam, Heroic, Bottles 등 주요 기능과 호환성 레이어가 완비되어 대부분의 게임이 원활히 실행 가능
     * 에픽게임즈, GOG, 물리 디스크 게임, 콘솔 에뮬레이터, 안드로이드 게임까지 폭넓게 지원
     * 클라우드 세이브, 안티치트 대응, 음성 채팅, 스트리밍, 방송 등 게임 환경 전반에서 완성도 높음
     * Windows 대비 더 안정적이고 직관적인 UI/UX, 유연한 시스템 구성으로 게임 몰입도와 유저 제어권 모두 향상됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

지금, Linux는 최고의 게임 시스템임

  과거의 오해에서 벗어나기

     * 아직도 많은 사람들이 Linux의 게임 성능을 ""쓸 수 없는 수준""으로 오해하지만, 이는 이미 오래된 편견
     * 필자는 업무와 게임 모두를 Linux로 사용하는 유저로서, macOS와 Windows보다 Linux의 경험이 훨씬 뛰어나다고 단언함

  NVIDIA 드라이버와 GPU 제어

     * 과거에는 Linux에서 NVIDIA 지원이 부족했지만, AI 붐을 계기로 현재는 가장 강력한 드라이버 지원을 제공
     * sudo apt install nvidia-driver 한 줄로 설치 가능
     * GreenWithEnvy 같은 GUI 앱으로 GPU 온도, 팬 속도 등 고급 제어도 가능

  Steam + Proton = 완벽한 게임 실행

     * Steam은 이제 Linux를 공식 플랫폼 수준으로 지원
     * Steam Deck의 출시 이후 Steam의 개발 중심은 Linux로 이동함
     * Windows 전용 게임도 Proton 설정만 켜면 대부분 원활하게 실행
     * Red Dead Redemption 2, Cyberpunk 2077 등 고사양 게임도 문제없이 실행됨
     * ProtonDB에서 다른 유저들의 호환성 정보를 확인 가능

  DLSS까지 된다

     * Red Dead, 사이버펑크 같은 고사양 게임에서 DLSS도 Linux에서 작동
     * libnvidia-ngx1 패키지를 설치하면 드라이버가 DLSS 기능을 포함하게 됨

  Steam 외 게임 플랫폼: Heroic과 Bottles

     * Heroic Games Launcher:
       Epic, GOG, Amazon 게임들을 쉽게 실행하고 Proton으로 호환성 확보
     * 클라우드 세이브, 설치 경로 및 싱크 방식 커스터마이징 기능 탑재
     * Bottles:
       물리 디스크나 비표준 채널 게임도 쉽게 불러와 실행 가능

  콘솔 에뮬레이션까지도 만능

     * Xbox, PS2~PS4, PSP, 닌텐도 Switch/Wii U/3DS/N64/GameCube 등
       거의 모든 주요 콘솔의 에뮬레이터가 Flathub에서 손쉽게 설치 가능
     * GUI 환경에서 간편하게 의존성 없이 실행 가능, 윈도우보다 설정이 덜 복잡함

  고전 휴대기기 및 기타 에뮬레이터

     * Game Boy, GBA, MSX 등 복고풍 게임기들도 거의 모두 지원
     * 드라이버 설치 없이 바로 작동하는 고전 게임패드까지 인식, 추억을 재현할 수 있음

  안드로이드 게임도 가능

     * Android도 Linux에서 실행 가능.
       가상화 없이 namespace 기반 실행도 가능 (자세한 내용은 별도 글 참고)
     * guiscrcpy 등으로 Android 기기 화면 미러링 가능

  기타 게임 환경 요소

    스트리밍

     * Steam Link, Parsec을 통해 원격 스트리밍 게임도 가능
     * 단순 미러링은 GNOME Network Displays로 가능

    오디오 향상

     * 별도 글(Enhance Linux Sound Experience)에서 다뤘듯, Windows 못지않은 오디오 최적화 가능

    방송과 음성 채팅

     * OBS Studio로 스트리밍 및 레코딩 완벽 지원
     * [Discord, TeamSpeak, Mumble 등 음성 채팅 앱들도 전부 네이티브 클라이언트** 제공

  결론: Linux는 진짜 게이밍 OS가 되었다

     * 작동만 하는 게 아니라, 더 잘 작동함
     * GNOME의 방해 금지 모드, 게임 중 윈도우 자유 전환, 윈도우에서 자주 생기는 전체화면 문제 없음
     * Steam, Heroic, Bottles, 에뮬레이터 등 다양한 경로를 통해 거의 모든 게임을 실행 가능
     * Windows에서만 가능하다고 여겨졌던 것들은 Linux에서도 문제없이 되고,
       심지어 Windows보다 더 나은 경험도 많음

   어... 윈도우즈는 이미 전부 지원하고 있던건데 이제 좀 따라오고있다는게 맞는말인듯

   개발 하기도 너무 좋고, 게다가 게임까지. 맥은 대체 이게 왜 안될까요.

   Proton이 참 감사합니다.

   리눅수 가볍고 잘돌아가는데 핵방지 프로그램이 안되어서 리눅스 못써요ㅠㅠ

   리눅스 서버 이용해서 클라우드 게임을 하는 방법이 있을까요?
   개인용 클라우드 서버쓰면 좋을것같은데.. 안쓸때는 내리고..

   스팀에 있는 게임 한정으로는 윈도우 생각도 안남

   성급한 일반화의 오류라고 생각합니다. 라데온 지원 사항도 언급되지 않았고 이해당사자중 한 곳이 지원해주지 않는 이상 정상동작을 보장할 수 없습니다

   주분투에서 월드 오브 탱크를 돌려리고 했는데 Wine, WOL, Lutris, Bottles 다 실패했습니다. 동구권에서 만든 Proton 레퍼로 돌아는 가는데 잦은 튕김과 프레임 드롭으로 포기했습니다.

   우분투나 페도라는 된다는것 같던데 말입니다...

   Aurora나 Bazzite를 깔면 되나욤?

   리눅스가 게이밍 시스템으로서 손색이 없게 되었다는 '변화'는 기술적으로는 사실이라고 볼 수 있을 것 같습니다만, 리눅스 게이머 생태계의 본질적인 위치가 달라진 건 아니라고 생각합니다.

   윈도우에서 되는 것이 리눅스에서도 된다는 데에 촛점을 맞춰야 하는 동안엔 계속 그렇겠지요.

   게이밍은 전에 테스트 해봤을 때 괜찮더라고요.
   DE들 기본 디자인이 수 년은 뒤쳐진 듯 하고 직접 커스터마이징 하려면 귀찮다던가 필수적인 앱들 몇 개가 작동하지 않는다던가 하는 이유로 일상용 데탑 OS로 쓰기에는 부족한 부분이 있어서 그렇지.

   os 위에 게임설치하고 플레이하면 되는 것이 아니라
   os 위에 개고생 후 플레이 해야한다는 것이 허들 아닐까요..

   혹시 몇년도에 살고 계신가요?

   8700g 기반 데탑에 Bazzite 사용 중인데, 설치는 윈도우즈 보다 쉽고, 사용자 경험도 스팀덱 그 자체라 편하게 쓰고 있습니다.

        Hacker News 의견

     * 아직은 기술에 익숙하지 않은 사람들에게 추천할 만한 수준은 아니지만, 그에 가까워지고 있음
          + Steam 게임 대부분 실행 가능, 다만 proton-experimental 수동 설정이 필요함
          + Unity 기반 게임에서 버그 발생하거나 일부 게임은 실행 불가능함
          + Nvidia GPU와 리눅스 OS 간 드라이버 호환 문제로 치명적인 오류 경험, 터미널만으로 문제 해결해야 했음
          + 비기술적인 사용자(예: 아버지)는 GRUB 오류로 인해 리눅스에서 이탈함
          + Linux는 발전 속도가 빠르고, Windows는 점점 불편해지고 있어 여전히 관심 있는 사람에게는 추천할 만함
     * 일반적인 리눅스 배포판(Mint, Ubuntu 등)은 업데이트 시 문제 발생 가능성이 큼
          + 어머니도 Xubuntu, Zorin에서 반복된 문제 경험 후 Aurora라는 불변형 배포판으로 변경, 이후 문제 없음
          + 불변형 배포판은 자동 업데이트, 의존성 문제 없음, 실패 시 간단한 롤백 가능 등으로 초보자에게 매우 적합함
          + Aurora, Bazzite(게이머용) 와 같은 배포판은 유지보수가 필요 없어 Windows/macOS보다 뛰어난 사용자 경험 제공
     * 해당 기사에서는 Linux가 제공하는 성능 튜닝 이점에 대해 전혀 언급하지 않음
          + CPU 마이크로아키텍처 최적화, 맞춤 스케줄러(LAVD, bpfland), 게임용 전용 컴포지터(gamescope) 사용 가능
          + 업데이트 과정에서 사용자 방해 없음, 재부팅도 빠르고 강제 없음
          + Windows는 잦은 재부팅, 업데이트 중단 등 사용자 불편 요소가 많음
          + 스파이웨어, 블로트웨어, 안티치트 루트킷 문제도 Windows에서 심각함
          + PikaOS, Bazzite 등은 콘솔과 유사한 사용자 경험 제공 → 전원을 켜자마자 게임 실행 가능
     * 리눅스 사용자 경험과 Windows와의 비교
          + Windows는 블루스크린 등으로 OS 접근 불가 문제가 있음에도 사용자들은 높은 관용도를 보임
          + Windows의 Do Not Disturb는 시스템 알림에만 적용됨 → 많은 앱이 자체 알림 사용하여 무용지물
          + 리눅스는 Do Not Disturb가 더 효과적이며, 전체 화면 상태에서도 창 전환이 쉬움
          + 에뮬레이터 사용성, Flatpak 등으로 인해 리눅스는 일부 영역에서 Windows보다 우수함
          + Windows에서도 에뮬레이터는 가능하지만, 의존성 문제로 설치가 번거로움
     * Windows와 리눅스의 게임 관련 차이
          + GNOME의 알림 끄기 기능은 Windows 10부터 존재, 리눅스만의 강점은 아님
          + Windows는 모든 게임이 ""풀스크린 윈도우 모드"" 로 실행되므로, 리눅스와의 비교가 잘못되었음
          + 에뮬레이터는 Windows에서도 모두 사용 가능, 리눅스만의 이점 아님
          + Win32 ABI가 가장 안정적이므로, 게임의 네이티브 실행은 Linux보다 Windows에 더 유리함
          + CLI로 드라이버 설치 제안은 일반 사용자에게는 장점이 아님
          + Wine에서 안티치트가 작동하지 않는 경우 많아 특정 게임은 Linux에서 실행 불가
     * 가상 머신을 통한 Windows 게임 실행 방법도 있음
          + Looking Glass를 이용해 KVM에서 Windows 11 실행, GPU를 PCI 패스스루로 직접 접근
          + VM에서 Steam 실행 후 Cyberpunk 2077 플레이 확인 → 놀라운 경험

   액박 패드 연결과 게임 내 인식은 어떤가요?
"
"https://news.hada.io/topic?id=20482","JavaScript 뷰를 어려운 방식으로 구축하기 - UI 작성 패턴","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 JavaScript 뷰를 어려운 방식으로 구축하기 - UI 작성 패턴

     * Writing JavaScript Views the Hard Way : 프레임워크 없이 순수 자바스크립트로 뷰를 구축하는 방법을 설명하는 글
     * 직접적인 명령형 접근 방식을 통해 성능, 유지보수성, 이식성을 확보함
     * 상태 업데이트와 DOM 업데이트를 명확히 구분하고, 각 역할에 따라 엄격한 명명 규칙과 구조적 패턴을 따름
     * 이 방식은 디버깅이 쉬우며, 모든 브라우저 호환성을 보장하고, 0 dependencies라는 큰 장점이 있음
     * 초보자에게는 어려울 수 있지만, 학습 시 실제 시스템 작동 방식에 대한 깊은 이해를 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

자바스크립트 뷰를 'Hard Way'로 작성하기

  이것이 무엇인가?

     * 이 방식은 React, Vue, lit-html과 같은 프레임워크 없이 자바스크립트만으로 뷰를 구성하는 패턴임
     * 특정 라이브러리나 도구가 아닌 코딩 패턴 자체로, 스파게티 코드 문제를 방지함
     * 직접적인 명령형 방식을 사용함으로써, 추상화를 줄이고 직관성을 높임

  프레임워크 대비 장점

     * 성능: 명령형 코드로 인해 불필요한 연산 없이 동작하며, 핫패스와 콜드패스 모두에 적합함
     * 0 dependencies: 라이브러리 업그레이드나 호환성 문제로부터 자유로움
     * 이식성: 작성한 코드가 어느 프레임워크에도 이식 가능함
     * 유지보수성: 명확한 섹션 구조와 명명 규칙으로 코드 위치 파악이 쉬움
     * 브라우저 지원: IE9 이상 대부분 브라우저와 호환되며, IE6까지도 일부 수정으로 지원 가능함
     * 디버깅 용이성: 중간 레이어 없이 얕은 스택 트레이스를 제공
     * 함수형 구조: 불변성은 아니지만, 모든 구성 요소가 함수 기반으로 구성됨

구조 설명

  전체 구조

     * template → clone() → init() 함수로 구성됨
     * init() 함수는 상태 변수, DOM 참조, 업데이트 함수, 이벤트 리스너 등을 포함한 하나의 뷰 인스턴스를 생성

    예시 코드 구조 (Hello World)

const template = document.createElement('template');
template.innerHTML = `<div>Hello <span id=""name"">world</span>!</div>`;

function clone() {
  return document.importNode(template.content, true);
}

function init() {
  let frag = clone();
  let nameNode = frag.querySelector('#name');
  let name;

  function setNameNode(value) {
    nameNode.textContent = value;
  }

  function setName(value) {
    if(name !== value) {
      name = value;
      setNameNode(value);
    }
  }

  function update(data = {}) {
    if(data.name) setName(data.name);
    return frag;
  }

  return update;
}

init() 함수 내부 구성

  1. DOM 변수

     * frag는 clone()으로부터 생성된 템플릿 조각
     * 내부 요소는 querySelector()로 참조하고, 변수명은 fooNode 형태 사용

  2. DOM 뷰

     * 다른 뷰를 포함하는 부분 (재사용 가능한 서브 뷰)
     * 예시:

let updateChildView = childView();

     * 뷰 업데이트 함수는 updateFoo 형태로 명명

  3. 상태 변수

     * 뷰 내에서 변경될 수 있는 데이터 값
     * DOM 업데이트를 효율적으로 하기 위해 현재 값과 비교하여 필요할 때만 DOM 변경

  4. DOM 업데이트 함수

     * DOM 요소의 상태를 변경할 때 사용
     * 예시:

function setNameNode(value) {
  nameNode.textContent = value;
}

     * DOM 조작은 반드시 이 함수 안에서만 수행

  5. 상태 업데이트 함수

     * 상태 변경 로직과 그에 따른 DOM 반영 포함
     * 변경되지 않은 값은 무시하여 불필요한 DOM 변경 방지
     * 예시:

function setName(value) {
  if(name !== value) {
    name = value;
    setNameNode(value);
  }
}

template과 clone() 함수

  template

     * <template> 요소로 정적 HTML 구조 생성
     * DOM에 직접 삽입되지 않으며, clone을 통해 복사본 생성

  clone()

     * document.importNode(template.content, true)로 복제
     * 필요시 .firstElementChild를 사용하여 루트 요소 반환 가능

상호작용 방식

  부모 → 자식 데이터 흐름

     * 부모는 자식의 init()을 호출하여 업데이트 함수를 획득하고, update({ name: 'foo' }) 형식으로 호출

  이벤트 기반 데이터 전파

     * 기본적으로 props down, events up 모델 따름
     * 하위 뷰는 이벤트를 상위로 디스패치하여 통신

React와 비교

     * constructor() (React) → init() (Hard Way)
          + 컴포넌트 초기 설정을 담당함
     * render() (React) → update(data) (Hard Way)
          + 화면 갱신 및 UI 업데이트 역할 수행
     * this.setState() (React) → setX(value) (Hard Way)
          + 상태값을 직접 설정하는 방식으로 대체됨
     * props (React) → update(data)로 전달된 값 (Hard Way)
          + 부모 컴포넌트로부터 전달된 데이터 처리 방식
     * JSX / Virtual DOM (React) → HTML 템플릿 + DOM API (Hard Way)
          + 선언형 UI 대신 수동적인 DOM 조작 및 템플릿 사용

결론

     * 이 방식은 익숙한 프레임워크에 비해 초기 진입 장벽은 높지만, 다음과 같은 강점을 가짐:
          + 성능 최적화
          + 완전한 제어권
          + 학습을 통한 깊은 이해
     * 각 역할별 함수 분리 및 명명 규칙을 통해, 프레임워크 없이도 유지보수 가능한 UI 구성 가능

호환성

     * 최신 예시는 현대 브라우저용 API를 사용하지만, IE9 이하까지도 함수 기반 대체를 통해 지원 가능
     * 이벤트 대신 props로 함수 전달을 사용하는 방식으로 IE6까지도 확장 가능

   결국은 웹 컴포넌트로..

   축하합니다. 또다른 js프레임워크가 탄생되었습니다

        Hacker News 의견

     * 많은 JS 개발자들에게는 이단일 수 있지만, 'state' 변수는 안티 패턴이라고 생각함
          + 웹 컴포넌트를 사용하며 '평면' 변수 타입에 대해 state 변수를 추가하는 대신 DOM 요소의 value/textContent/checked 등을 유일한 진실의 원천으로 사용함
          + 필요한 경우 setter와 getter를 추가함
          + 코드의 양이 적어도 자연스럽게 많은 것이 올바르게 작동함
          + WebComponents를 사용하면 객체와 인접한 HTML 템플릿의 분리가 이루어져서 스파게티 코드가 아닌 퓨실리나 마카로니 같은 세분화가 이루어짐
     * 이 접근 방식이 매우 유지보수 가능하다고 설명서에 나와 있지만, 동의하지 않음
          + 디자인 패턴이 오직 관례에 기반하고 있음
          + 복잡한 앱에서 여러 개발자가 동시에 작업할 때, 적어도 한 명은 관례에서 벗어날 가능성이 높음
          + iOS의 UIKit 같은 클래스 기반 UI 프레임워크는 모든 개발자가 표준 API 세트를 사용하도록 강제하여 코드가 예측 가능하고 유지보수가 쉬움
     * 최근에 vite와 함께 순수 '바닐라' TypeScript로 애플리케이션을 작성하고 있으며, 프론트엔드 '최고' 관행에 대해 점점 더 의문을 가짐
          + 확장성은 결론지을 수 없지만, 성능 면에서 큰 이점이 있음
          + 재미있고, 많은 것을 배우며, 디버깅이 간단하고, 아키텍처를 이해하기 쉬움
          + 템플레이팅이 가장 그리움
     * 이 접근 방식은 오래된 backbone js 라이브러리를 떠올리게 함
          + 웹 플랫폼에 적응된 MVC 패턴의 예시가 있는 GitHub 저장소도 있음
     * 최근에 비슷한 것을 생각해냈지만, 템플릿 요소를 사용하지 않음
          + 함수와 템플릿 리터럴을 사용하여 문자열을 반환하고, 기존 요소의 innerHTML에 넣거나 새로운 div 요소를 생성하여 넣음
          + 함수가 중첩되어 합리적인 방식으로 구성하기 어려움
     * 이 코드는 반응형 뷰 라이브러리가 대체하려는 수동 업데이트 코드와 정확히 같아 보임
     * 약 20년 동안 프로그래밍을 해왔지만 프론트엔드 프레임워크에 익숙해지지 않음
          + 백엔드에 더 강해서 보안 관련 상호작용은 서버를 통해야 한다고 생각함
          + JS는 견고한 HTML 및 CSS 기반에 클라이언트 측 기능을 추가하는 것으로 봄
     * React.createElement와 유사한 헬퍼를 사용함
          + 모의 서버 대시보드의 작동 예시가 있음
     * HTML 기반 도구를 위한 JS 툴킷을 구축하려는 시도로 deja-vu.junglecoder.com에서 작업 중임
          + 적절한 반응형/양방향 데이터 바인딩은 아직 해결하지 못했지만, grab/patch가 꽤 괜찮음
          + 템플릿을 사용하는 방식이 템플릿의 일부를 이동하기 매우 쉬움
     * 대학 졸업 후 첫 공식 직장에서 Delphi 소프트웨어의 웹 버전을 만드는 작업을 했음
          + 팀은 이미 프론트엔드를 세 번째로 다시 작성 중이었고, 프레임워크를 변경해야 했음
          + 자체 프레임워크를 작성해야 한다고 주장했지만, 팀은 내 제안을 좋아하지 않았음
          + 이후 다른 회사에서 더 나은 제안을 받아 떠남
          + 이후 tiny.js라는 또 다른 프레임워크를 시도했으며, 개인 프로젝트에 사용 중임
"
"https://news.hada.io/topic?id=20495","Open Codex - OpenAI의 Codex CLI를 오픈소스 LLM에 사용하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Open Codex - OpenAI의 Codex CLI를 오픈소스 LLM에 사용하기

     * Open Codex는 OpenAI Codex에서 영감을 받은 완전한 오픈소스 CLI 기반 AI 코딩 어시스턴트
          + 처음엔 OpenAI를 포크하려고 했으나, 코드상 문제 및 호환성 때문에 Python으로 밑바닥부터 새로 개발
     * API 키 없이 로컬에서 실행되며, phi-4-mini 같은 언어 모델을 사용하고 모델은 더 확대 예정
     * 자연어 명령을 셸 명령어로 변환하고 실행 전 확인 절차를 거침
     * 복잡한 설치 없이 Homebrew, pipx, git clone을 통해 간편하게 설치할 수 있음
     * Mac, Linux, Windows 지원
     * 클립보드 복사, 실행, 중단 중 하나 선택 가능
     * 현재는 원샷 모드만 지원, 향후 대화형 및 함수 호출 기능 추가 예정
     * 컬러 터미널 출력으로 가독성을 높임
     * 향후 개발 계획
          + 상황 인식형 대화 모드 추가 예정
          + textual, rich 기반의 TUI 사용자 인터페이스 도입
          + 다양한 오픈소스 언어 모델 지원 확대
          + 함수 호출 및 명령 기록/실행 취소 기능 도입 예정
          + Whisper를 이용한 음성 입력 기능 추가 예정
          + 워크플로우용 플러그인 시스템 도입 계획

   LiteLLM으로 프록싱하면 거의 모든 모델 사용가능한게 함정?

   OpenAI Codex CLI - 터미널에서 실행되는 경량 코딩 에이전트
"
"https://news.hada.io/topic?id=20444","Gemma 3 QAT 모델: 최첨단 AI를 소비자 GPU에 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Gemma 3 QAT 모델: 최첨단 AI를 소비자 GPU에 도입

     * 지난달 발표한 Gemma 3는 최첨단 성능을 제공하는 오픈 AI 모델이며, NVIDIA H100 같은 단일 고성능 GPU에서도 실행 가능함
     * QAT(Quantization-Aware Training) 기법을 적용한 경량화 버전을 출시하여 이제 소비자용 GPU에서도 실행 가능해짐
     * int4 양자화 덕분에 메모리 사용량이 크게 줄어들며, 성능 저하를 최소화
     * QAT 모델은 RTX 3090, RTX 4060 등 일반 GPU에서도 실행 가능하며, Hugging Face, Ollama, LM Studio 등에서 바로 사용 가능함
     * 커뮤니티 버전의 다양한 PTQ 모델도 함께 제공되어 유연한 선택이 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Gemma 3 소개 및 성능 개요

     * Google이 발표한 최신 오픈 모델 Gemma 3는 뛰어난 성능을 가진 대규모 언어 모델임
     * BF16(16비트 부동소수점) 정밀도로 NVIDIA H100 GPU에서 실행 가능하며, 탁월한 Chatbot Arena Elo 점수 기록함
     * BF16 사용 이유는 모델 간 성능 비교를 공정하게 하기 위함으로, 다양한 최적화 방식이 배제된 상태에서 모델 본연의 성능을 비교 가능함

접근성 향상을 위한 QAT 기반 양자화

     * 기존 대형 모델은 고사양 클라우드 환경이 필요했지만, 소비자용 하드웨어에서도 실행 가능하게 만들기 위해 QAT 기법을 적용함
     * 양자화(Quantization) 는 모델 내부 수치 정밀도를 줄여 메모리 사용량을 줄이고 실행을 빠르게 함
     * 예: BF16 대신 int4 형식 사용 시 4배 이상 압축 효과 발생

QAT를 활용한 품질 유지

     * 단순 후처리 양자화 대신 QAT(Quantization-Aware Training) 방식을 사용하여 훈련 중 양자화를 반영함
     * 훈련 과정에서 약 5,000 스텝 동안 비양자화된 체크포인트의 예측 확률을 목표값으로 사용
     * 이 방식으로 Q4_0 양자화 시 Perplexity 감소율을 54% 줄이는 성과 달성

VRAM 사용량의 획기적인 감소

     * int4 양자화로 인한 VRAM 절감 효과가 크며, 모델별 감소폭은 아래와 같음:
          + Gemma 3 27B: 54GB → 14.1GB
          + Gemma 3 12B: 24GB → 6.6GB
          + Gemma 3 4B: 8GB → 2.6GB
          + Gemma 3 1B: 2GB → 0.5GB
     * 이 수치는 모델 가중치를 로딩하는 데 필요한 VRAM만 포함되며, 실행 중 필요한 KV 캐시는 별도 VRAM을 요구함

다양한 기기에서 실행 가능

     * Gemma 3 27B (int4): **RTX 3090 (24GB VRAM)**에서 로컬 실행 가능
     * Gemma 3 12B (int4): **RTX 4060 Laptop (8GB VRAM)**에서도 문제 없이 실행
     * Gemma 3 4B, 1B: 스마트폰 및 저사양 기기에서도 구동 가능

손쉬운 통합 및 사용

     * QAT 모델은 다양한 플랫폼 및 도구에서 바로 사용 가능:
          + Ollama: 명령어 한 줄로 실행
          + LM Studio: GUI 환경에서 다운로드 및 실행
          + MLX: Apple Silicon 기반에서 고효율 추론 지원
          + Gemma.cpp: CPU 환경에서 고성능 실행
          + llama.cpp: GGUF 포맷으로 손쉬운 통합

Gemmaverse의 커뮤니티 모델

     * 공식 QAT 모델 외에도 다양한 커뮤니티 PTQ 모델 제공
     * 주요 기여자: Bartowski, Unsloth, GGML
     * 다양한 모델은 속도, 크기, 품질의 균형을 맞추어 선택 가능

지금 바로 시작 가능

     * AI의 대중화를 위한 중요한 단계로, Gemma 3의 QAT 버전은 누구나 로컬에서 실행 가능
     * 실행 방법:
          + PC: Ollama
          + 모델 다운로드: Hugging Face, Kaggle
          + 모바일 실행: Google AI Edge 사용

        Hacker News 의견

     * gemma-3-27b-it-qat-4bit 모델이 Mistral Small 3.1 24B와 함께 새로운 선호 모델임
          + M2 64GB에서 Ollama와 MLX를 통해 사용 중이며, 메모리 사용량이 적어 다른 앱 실행에 충분한 여유가 있음
          + LLM 도구용 플러그인을 작성하는 데 성공적인 결과를 얻음
     * 개인적인 ""분위기 체크"" 질문에 대해 4bit QAT 27B 모델이 정확한 답변을 제공함
          + 13GB의 가중치에 담긴 정보 밀도에 놀라움을 느낌
          + Deepmind의 Gemma 3 27B 모델이 가장 인상적인 오픈 소스 모델임
     * 첫 번째 그래프는 ""Elo Score""를 BF16 정밀도로 비교한 것이며, 두 번째 그래프는 VRAM 사용량을 비교한 것임
          + BF16과 QAT 간의 품질 비교 그래프가 없다는 점이 아쉬움
     * qwen2.5 대신 gemma3:27b-it-qat를 사용하여 32G 메모리 Mac에서 일상 작업을 수행 중임
          + Python, Haskell, Common Lisp 개발에 매우 유용함
          + 오픈 소스 모델을 로컬에서 실행하는 것이 만족스러움
     * 16코어 AMD 3950x CPU에서 실행 중이며, 번역 및 이미지 설명에서 매우 인상적임
          + 번역 시에는 입력 언어 분석을 피하기 위해 명령어를 조정함
     * 최신 QAT gemma3:27b 다운로드 후 성능이 1.47배 향상됨
     * 로컬 LLM이 기업에 의해 일급 시민처럼 대우받는 것이 필요함
          + 첫 번째 그래프가 DeepSeek r1의 FP16 실행에 필요한 H100 수에 대해 오해를 줄 수 있음
     * Microsoft와 Apple이 AI PC와 Apple Intelligence를 홍보했지만, 실제로 소비자 GPU에서 사용 가능한 모델은 고급 GPU에서만 가능함
     * Gemma 3가 Llama 4보다 훨씬 뛰어남
          + Meta가 LLM 시장에서의 위치를 잃을 가능성이 있음
          + Llama 4의 모델 크기가 너무 커서 사용자가 제한됨
          + Gemma 3는 모든 하드웨어 크기에서 널리 사용 가능함
     * Ollama에서 사용 가능함
"
"https://news.hada.io/topic?id=20428","편안한 비디오 게임은 스트레스와 불안을 해소할 수 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     편안한 비디오 게임은 스트레스와 불안을 해소할 수 있음

     * Cozy 게임은 스트레스 해소와 정신 건강 향상에 긍정적 영향을 주는 연구 결과가 있음
     * 공동체 중심의 게임플레이와 부드럽고 따뜻한 분위기로 유저에게 정서적 안정감 제공
     * 누구나 쉽게 접근 가능한 설계로 다양한 연령과 배경의 플레이어 유입
     * 게임이 명상과 유사한 효과를 낼 수 있다는 실험 결과도 존재함
     * 삶과 죽음, 관계 등 깊은 주제를 다루며 감정적 치유의 수단이 되기도 함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

포근한 위로

     * 겨울철 스트레스를 날릴 방법으로 비디오 게임이 심리적 안정에 도움된다는 연구 결과 소개
     * 특히 ""Cozy Games"" 라 불리는 아늑한 장르가 인기 상승 중이며, 기존 유저와 신규 유저 모두에게 매력적임
     * 이 장르는 파괴보다는 창조적인 도전 중심으로 편안함을 제공함
     * 1996년 Harvest Moon으로 시작되어, 2020년 Animal Crossing: New Horizons(동물의 숲) 가 큰 전환점을 만듦
     * 명확한 정의는 없지만, ""포근한 느낌을 주는 게임"" 이라면 Cozy Game으로 간주됨

공동체 중심의 플레이 경험

     * Cozy 게임의 핵심 요소는 공동체 의식임
     * Disney Dreamlight Valley 개발자 Joshua Labelle에 따르면, ""서로 도우며 살아가는 공동체""가 핵심 판타지임
     * 대표작 Animal Crossing: New Horizons는 팬데믹 직후 출시되어 대성공을 거둠
          + 사회적 거리두기 상황 속에서 유저 간 온라인 상호작용이 정서적 연결감을 제공함
     * 자폐 스펙트럼을 가진 사용자들도 자신의 정체성과 소속감을 Cozy 게임에서 찾았다는 증언 있음
          + 온라인 커뮤니티를 통해 실제 생일 선물까지 마련해주는 등 현실적 유대감 형성

모두를 위한 게임

     * Cozy 게임은 패배가 거의 없고 조작이 쉬운 게임성을 특징으로 함
     * 게임 개발자 Dorian Signargout (aka Doot)는 포용성과 다양성을 디자인 철학으로 강조함
          + 캐릭터 색상, 이름, 성별 등을 논바이너리와 다양한 배경으로 구성
     * 게임을 통해 이상적인 사회상을 반영하는 도구로 사용하려는 시도 진행 중

자기 돌봄 수단으로서의 게임

     * 비디오 게임이 중독 위험으로 비판받는 반면, 최근 연구는 긍정적인 효과에 주목함
     * 일본 니혼대학 Egami 교수 연구에 따르면, 게임 콘솔 소유가 정신적 스트레스 완화와 삶의 만족도 증가에 기여함
          + 팬데믹 기간 게임 콘솔을 무작위로 구매할 수 있게 되면서 발생한 ""자연 실험""의 데이터를 기반으로 분석
     * 미국에서는 마음챙김 명상과 캐주얼 게임의 스트레스 감소 효과를 비교한 연구도 있음
          + 결과적으로 둘 사이에 생리적 효과 차이가 없음이 확인됨
     * ADHD 같은 정신 건강 문제에도 비디오 게임이 치료 수단으로 연구되고 있음

게임 이상의 가치

     * Cozy 게임은 겉보기에는 단순하지만, 삶과 죽음, 관계 같은 깊은 주제도 다룸
     * 예: Spiritfarer는 죽은 이들을 저승으로 인도하는 주인공 Stella를 통해 상실과 치유의 경험을 제공함
          + 실제로 이 게임은 호스피스 간호사 출신 유저의 직업 회복에 영감을 주기도 함
     * 이런 게임들은 유저들에게 현실에서 벗어날 수 있는 심리적 피난처가 됨
     * 바쁜 세상 속에서 단순한 삶의 아름다움을 상기시키는 역할 수행

   음..글의 맥락과 맞지 않는데...
   이직 실패를 디아블로4 증오의 그릇으로 이겨냈음...

   한국인한테는 Cozy한 게임일 수도..

   마음이 편안해지다못해 잠이 옴.. 그럼 끄고 편안한 잠을 잘 수 있어요..

   zzzzz

   Unpacking과 Tiny Glade도 Cozy Games로 추천합니다. 상당히 아름답고 편안해지는 게임입니다.

   긱뉴스 기사도 있네요!
   Tiny Glade, 한 달 만에 60만 개 이상 판매 달성 | GeekNews

   폭력적이지 않고 스토리가 좋은 게임? | GeekNews

   문화적 영향력 부문 수상작, 명상 게임 Unpacking Apple, 2023 앱 스토어 어워드 수상작 발표 | GeekNews

   음... 편안한 게임...
   다키스트던전 추천 드립니다.

   일단 설명을 보았는데요... 으음....

   기사 자체가 도트 게임 화면을 잘 써서 굉장히 예쁘네요. 꼭 원글을 가서 보세요.

        Hacker News 의견

     * 카드 놀이. 기기와 화면 없이 여러 명이 함께 즐길 수 있는 재미가 있음
          + 컴퓨터 게임을 해야 한다면, 오래된 Microsoft 게임인 sweekend puzzle, motorbike madness, midtown madness를 선호함. 인터넷 없이 Win7 PC에서 즐김
          + Forza로 시골 풍경을 즐기며 드라이빙을 즐김
          + 새로운 xbox 게임의 타이틀 이미지를 보는 것조차 두려움. 고어하고 이상하며 광기가 고품질로 묘사됨
          + 서구 사회는 전쟁 후 평화 시기에 생존 투쟁이 없어서 삶의 흥미를 갈망했음. 미디어 - 영화, 음악, 인터넷 - 는 이를 계속 제공했음
          + 음악도 부드럽고 즐거운 멜로디가 아닌 시끄러운 외침과 히스테릭한 표현으로 변했음
          + 군악대가 경각심과 민첩성을 제공하듯, 서구 음악은 일상에서 부족한 두려움과 불안을 제공하게 되었음
          + 이러한 광기가 없으면 지루하다고 여겨짐 (어린 시절에는 지루하다는 말을 들어본 적이 없음). 느린 삶은 사회적으로 용납되지 않음
          + 미친 군중에 합류할 필요 없음. 그냥 앉아서 오래된 컴퓨터를 켜고 인터넷 케이블을 뽑고 느리고 오래된 게임을 즐기면 됨
     * 불안 치료에 대한 두 가지 이론을 들음
          + Paul Gilbert의 이론: 뇌의 '위협 시스템'이 과도하게 발달하고 '진정 시스템'이 덜 발달했으며, '진정 시스템'을 자극하는 것이 올바른 치료임
          + Steven Quartz의 이론: 뇌의 위험 평가가 왜곡되었으며, 적절한 치료는 견딜 수 있는 '위험한 놀이'를 통해 성취감을 느끼는 것임
          + 비디오 게임은 이론적으로 두 가지 모두에 작용할 수 있음. 두 번째 이론에서는 편안함이 순간적으로는 효과적일 수 있지만, 장기적인 불안 감소를 방해할 수 있음
          + 어느 이론이 더 많은 증거를 가지고 있는지 모름. (전문가가 아니며 합의된 이론이 전혀 다른 것일 수도 있음)
     * 내가 좋아하는 게임 중 하나는 A Short Hike임. Animal Crossing, Stardew Valley와 같은 게임은 아니지만, 글이 훌륭하고 플레이할 때마다 만족감을 줌
          + 이런 게임이 더 많이 존재했으면 좋겠음
     * 기술 분야에서 백엔드 데이터 서비스를 유지 및 최적화하는 일을 할 때, 집에 와서 Factorio의 공급망을 최적화하는 것을 좋아했음
     * 완전히 반대 방향으로, 2년 전 여름 Elden Ring을 클리어한 것이 인생 최악의 실연을 극복하는 데 큰 도움이 되었음. 스트레스와 불안이 가득한 시기였음
     * Breath of the Wild는 나에게 그런 느낌이었음. 싸울 수는 있지만 대부분 선택 사항이며, 게임의 대부분은 자연 속을 걷고 세계를 탐험하는 것임. 10년 넘게 주목할 만한 게임을 하지 않았고, BotW에 1,000시간 이상을 보냈음
     * 우울증이 가장 심할 때, House Flipper만 플레이할 수 있었음. 가상 집을 청소하는 것이 내 집을 청소할 에너지가 없을 때 조금 도움이 되었음. 또한 YouTube에서 자연에 관한 차분한 영상을 시청함. 대부분의 정신적 문제가 도시 생활과 자연과의 접촉 부족 때문이라는 것을 깨달음 (프랙탈과 인공물의 직각에 관한 것)
          + 요즘 편안한 게임이 유행하는 것은 우리 사회와 청년들의 정신 상태를 많이 말해줌
          + 우울증이 줄어들었지만, 더 이상 큰 게임 경험에 대한 욕구가 없음. 요즘 나의 평화로운 피난처는 TrackMania이며, 그 게임을 하면서 얻는 평화, 침묵, 흐름의 감각은 그 어떤 것도 따라올 수 없음. 과도하게 스트레스받는 지식 노동자에게 강력히 추천함
     * 나의 편안한 추천: 타일로 풍경을 만드는 것
          + Dorfromantik
     * 게임에서 전투의 과도한 사용을 오랫동안 한탄해왔음. 평화주의 이념 때문이 아니라, 많은 게임에서 게임 메커니즘으로서의 전투가 회피책임. 매체는 가능성의 심연을 나타낼 수 있지만, 보통 AAA 타이틀의 모든 초점은 전투에 맞춰짐
          + 인디 게임과 편안한 게임 틈새 시장은 전투가 아닌 모든 것의 게임 플레이가 가능하기 때문에 많은 범위를 가지고 있으며, 다양성과 창의성을 환영함
     * 편안함은 게임의 과소평가된 측면이라고 생각함. 아마도 게임이 일반적으로 빠르고 격렬하게 묘사되기 때문일 것임. 사실, 편안함은 World of Warcraft가 매우 인기가 있었던 이유 중 하나였음. 최상위 레이드 길드나 PvP에 있지 않는 한, 대부분의 게임 플레이는 TFA에 나열된 측면 중 적어도 하나와 일치했음. ""정리""와 ""커뮤니티""의 일종으로 너무 도전적이지 않음
          + 편안함의 다른 몇 가지 측면은 탐험과 사회적 상호작용이었으며, 기사에서는 간과되었지만 MMO의 큰 부분이었음. 탐험과 솔로 퀘스트는 거의 명상적인 성격이었음. 사회화, 퀘스트, 탐험을 혼합하여 선호하는 편안함의 맛을 찾을 수 있었음
"
"https://news.hada.io/topic?id=20463","Python의 새로운 `t-strings`","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Python의 새로운 `t-strings`

     * t-문자열(t-strings) 은 Python 3.14에서 새롭게 도입될 안전하고 유연한 문자열 처리 기능임
     * 기존 f-string과 달리, t-string은 문자열이 아닌 Template 객체로 반환되어 자동 출력 없이 안전한 처리 가능
     * t-string은 HTML, SQL 등 동적 입력을 안전하게 이스케이프할 수 있는 구조를 갖고 있음
     * JavaScript의 **태그 템플릿(tagged templates)**과 유사한 개념으로, 다양한 변환 및 처리 확장이 가능함
     * Python 개발 도구 생태계가 이 기능을 잘 지원한다면, 웹/보안 중심의 문자열 처리 방식에 큰 변화를 줄 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Python의 새 기능: t-문자열(Template Strings)

     * Python 3.14부터 t""..."" 문법으로 사용하는 Template 문자열(t-strings) 이 공식 기능으로 도입됨
     * 기존 f-string과 달리, t-string은 즉시 문자열이 아닌 string.templatelib.Template 객체로 평가됨
     * 이 객체는 출력 전 별도의 가공 과정이 필요하며, 이 과정을 통해 동적 값의 안전한 처리 및 변환 가능

왜 f-string이 위험할 수 있는가?

     * f-string은 즉시 문자열로 평가되기 때문에, 사용자 입력을 포함한 코드에서 SQL Injection이나 XSS 발생 가능
          + 예: f""<div>{user_input}</div>"" → 공격 코드가 직접 삽입될 수 있음
     * t-string은 이러한 평가를 지연시켜 명시적으로 가공해야만 사용 가능하게 함

t-string의 예시 사용

     * HTML 이스케이프 처리 예시:
evil = ""<script>alert('bad')</script>""
template = t""<p>{evil}</p>""
safe = html(template)
# safe는 ""<p>&lt;script&gt;alert('bad')&lt;/script&gt;</p>""

     * 속성 자동 삽입 등 더 복잡한 처리도 가능:
attributes = {""src"": ""roquefort.jpg"", ""alt"": ""Yum""}
template = t""<img {attributes} />""
element = html(template)
# 결과: ""<img src='roquefort.jpg' alt='Yum' />""

구조와 API

     * Template 객체는 .strings, .values 속성을 통해 원본 텍스트와 대입값을 분리해 제공
     * interpolations 속성을 통해 !s, :>8 등 포맷 세부 정보까지 접근 가능
     * 순회(iteration)를 통해 텍스트와 값이 섞인 상태도 직접 가공 가능
     * 수동 생성도 가능:
from string.templatelib import Template, Interpolation
template = Template(
  ""Hello "",
  Interpolation(value=""World"", expression=""name""),
  ""!""
)

재미있는 예시: 돼지 라틴어 변환기

     * Template 객체의 내용을 순회하며 단어를 Pig Latin으로 변환하는 예제:
def pig_latin(template: Template) -> str:
    ...
name = ""world""
template = t""Hello {name}!""
assert pig_latin(template) == ""Hello orldway!""

향후 발전 방향

     * t-strings는 웹/보안 중심의 문자열 처리 방식에 안전성과 확장성을 가져올 수 있음
     * black, ruff, VS Code 등 개발 도구가 t-string 포맷/하이라이팅을 지원하길 기대
     * JavaScript 개발자가 익숙한 tagged template 방식과 유사해, 여러 프레임워크에서도 활용 가능성 높음

개발자 커뮤니티와의 협업

     * 본 기능은 다양한 Python 커뮤니티 멤버들의 참여와 협업을 통해 완성됨
     * 특히 Jim, Paul, Koudai, Lysandros, 그리고 Guido 등 핵심 인물들과의 교류가 언급됨
     * PEP 750과 그 예제 저장소는 GitHub에서 확인 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

     Python 3.14의 t-문자열 기능은 문자열의 안전성과 확장성을 동시에 확보하며, 기존 f-string의 한계를 넘는 중요한 도약임

   https://news.hada.io/topic?id=20266

        Hacker News 의견

     * 전반적으로, 이 기능은 꽤 멋짐. 기본적으로 다음과 같은 코드를
db.execute(""QUERY WHERE name = ?"", (name,))

       다음과 같이 바꿈
db.execute(t""QUERY WHERE name = {name}"")

       새로운 언어 기능의 복잡성을 감수할 만큼 이 문법적 설탕이 이점이 있는지에 대한 질문이 있음. 두 가지 이유로 이 경우에는 그렇다고 생각함
          + 라이브러리 개발자가 {} 확장을 통해 원하는 것을 할 수 있게 하는 것은 좋은 일이며, 좋은 사용 사례를 만들어낼 가능성이 있음
          + 언어 전반에 걸쳐 템플릿 문법을 일반화하여 모든 라이브러리가 같은 방식으로 문제를 해결하도록 하는 것은 아마도 좋은 일임
     * 또한, 도구 생태계가 t-strings를 지원하도록 적응하기를 바람. 예를 들어, black과 ruff가 t-string 내용을 포맷하고, vscode가 HTML이나 SQL 같은 일반적인 유형의 내용을 색상으로 표시하면 좋겠음
          + t-strings에 대한 이 견해는 매우 이상함. 템플릿 문자열이 유효한 HTML이나 SQL로 변환되어야 한다는 것을 추론할 수 있는 유일한 방법은 문자열의 명백한 문법을 기반으로 하는 것인데, 이는 임시방편으로만 가능하며 템플릿 문자열 기능과는 관련이 없음
          + 기능이 설계된 방식에서는 문자열 자체에 어떤 유형의 콘텐츠인지 또는 최종적으로 무엇으로 변환될지에 대한 표시가 없음. 모든 것은 변환 함수에 의해 처리됨
          + 다른 사람들이 추가한 것처럼, sql”select * from {table}” 같은 것이 이를 수행할 수 있었겠지만, 템플릿에 있는 것이 변환 함수에 의해 유효한 sql로 변환될 것이라는 보장이 없음. t“give me {table} but only {columns}”가 템플릿이 처리된 후 유효한 sql로 변환될 수 있음
     * 다음과 같은 깔끔한 SQL 문법을 사용할 수 있을까?
city = 'London'
min_age = 21
# Find all users in London who are 21 or older:
users = db.get(t'
  SELECT * FROM users
  WHERE city={city} AND age>{min_age}
')

       db.get() 함수가 템플릿을 수용한다면, 가능할 것임. 지금까지 본 SQL 사용 방법 중 가장 깔끔한 방법일 것임
     * 개인적으로, 이 기능은 일반적인 기능이 되기에는 너무 특정 문제에 집중된 것 같음. Python은 점점 커지고 있음. 사람들이 Python이 배우기 쉽고 간단한지 물어보면 ""기본은 그렇지만, 전체 언어를 배우는 것은 그렇지 않음""이라고 말해야 함
          + 이런 점에서 Go는 거의 모든 기능을 거부함으로써 흥미로움. 솔직히 제네릭이 많은 복잡성을 추가하기 때문에 가치가 있는지 확신할 수 없음. 언어를 원래의 초점에 맞추는 일반적인 아이디어가 옳다고 생각함. C++는 언어 자체가 시작했을 때와 거의 닮지 않은 극단적인 경우일 것임
     * 큰 토론 (414 포인트, 10일 전, 324개의 댓글) 링크
     * 꽤 멋짐. JS 기능을 포팅한다면 다음에는 딕셔너리 언패킹/디스트럭처링을 얻을 수 있을까?
          + 이 기능을 너무나도 원함. JS로 돌아가는 주된 이유임
>>> {a, b=45, c=None, **d} = {'a': 234, xzy: 32456}
>>> print(a, b, c, d)
234 45 None {'xyz': 32456}

     * 새로운 x-string 기능이 내장된 것만으로 ""속임수""처럼 느껴짐. 다음과 같은 것을 할 수 있다면 멋질 것임
from foo import bar
bar""zoop""

     * 2025년의 Zen of Python:
There should be one-- and preferably only one --obvious way to do it.

       2025년의 Python 문자열 포맷팅:
          + t-strings
          + f-strings
          + %-operator
          + +-operator
          + str.format()
     * 템플릿에 적용할 함수를 f-string 변수에 적용하는 것과 어떻게 다른지 이해가 안됨. 그래서 다음과 같은 대신에:
evil = ""<script>alert('bad')</script>""
template = t""{evil}""
safe = html(template)

       왜 그냥 이렇게 하지 않는지:
evil = ""<script>alert('bad')</script>""
safe = f""{html(evil)}""

       아니면 f-string을 만들기 전에. 단순히 정화/문자열 조작 부분을 잊지 않게 하고 강제로 거치게 하는 것인지?
     * 안녕하세요! 제가 이 글을 작성했음 :-)
          + 대화에 조금 늦었고 HN에서 이 글이 트렌드가 된 것을 보고 약간 놀랐지만, 질문에 기꺼이 답변할 것임. 하루 종일 틈틈이 참여하려고 노력할 것임
"
"https://news.hada.io/topic?id=20441","SQLite에서의 트랜잭션과 가상 테이블","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         SQLite에서의 트랜잭션과 가상 테이블

     * SQLite 가상 테이블도 쓰기 및 트랜잭션 지원이 가능하며, xUpdate, xSync, xCommit, xRollback 등의 훅을 구현해 사용함
     * SQLite는 기본적으로 롤백 저널 방식으로 원자성을 보장하며, 여러 DB 파일을 다룰 때는 슈퍼 저널로 전체 커밋을 조정함
     * 가상 테이블도 SQLite의 트랜잭션 프로토콜에 포함되어, xSync 실패 시 전체 트랜잭션을 롤백함
     * 커밋은 2단계로 나뉘며, xSync는 실패 가능성 있는 작업, xCommit은 단순 정리 작업만 수행해야 함
     * xCommit과 xRollback은 항상 호출될 수 있으므로 실패 없이 실행 가능한 정리용 함수로 작성해야 함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

SQLite의 가상 테이블과 트랜잭션 처리

   이전 글에서는 Go 언어를 통해 SQLite의 가상 테이블을 등록하고 쿼리하는 기본 방법을 소개했음. 이번 글에서는 쓰기 가능하고 트랜잭션을 지원하는 가상 테이블 구현법을 다룸.

가상 테이블의 쓰기 및 트랜잭션 지원

     * SQLite의 가상 테이블 인터페이스는 읽기 전용이 아님
     * xUpdate 훅을 구현하면 외부 데이터 소스에도 쓰기 가능
     * 진정한 트랜잭션 일관성을 위해서는 다음과 같은 트랜잭션 훅 필요:
          + xBegin: 트랜잭션 시작 알림
          + xSync: 디스크에 안전하게 커밋하기 위한 준비 (여기서 실패하면 전체 롤백)
          + xCommit: 최종 커밋 및 정리
          + xRollback: 트랜잭션이 중단됐을 경우 롤백 수행
     * 일반 테이블 또는 다른 가상 테이블과 함께 수정될 때도 SQLite는 모든 훅을 연동해 원자성을 보장함

SQLite 트랜잭션의 내부 동작 방식

  롤백 저널 (Rollback Journals)

     * SQLite는 기본적으로 페이지를 덮어쓰기 전에 백업 파일(저널)에 저장
     * 문제가 생기면 저널에서 복구하여 원자성 보장

     참고: SQLite는 WAL 모드도 지원하지만 이 글의 범위에서는 제외됨

  슈퍼 저널 (Super-Journals)

     * 여러 데이터베이스가 연결된 경우, 각 DB에 개별 저널만으로는 동기화 어려움
     * 슈퍼 저널이라는 상위 레벨 파일을 통해 여러 파일 간 커밋을 조정
     * 한 DB 파일 내 여러 가상 테이블만 다루는 경우는 슈퍼 저널 없이도 동기화 가능
     * 어떤 경우든 SQLite는 트랜잭션 흐름 안에서 xSync, xCommit, xRollback 훅을 자동으로 호출

가상 테이블과 함께하는 2단계 커밋

   SQLite의 커밋 과정은 2단계로 이루어짐:

  1단계: xSync (Durability 보장)

     * 모든 B-Tree 및 DB 파일의 페이지 또는 저널을 디스크에 안전하게 동기화
     * 가상 테이블도 각각 xSync 훅이 호출됨
     * 어느 한 xSync에서 실패하면 전체 트랜잭션이 롤백됨 → 원자성 유지

  2단계: 정리 (xCommit)

     * 디스크에 저장이 완료되면 저널 파일을 삭제하고 가상 테이블 정리 수행
     * 아래는 vdbeaux.c 코드 일부임
disable_simulated_io_errors();
sqlite3BeginBenignMalloc();
for(i=0; i<db->nDb; i++){
  Btree *pBt = db->aDb[i].pBt;
  if( pBt ){
    sqlite3BtreeCommitPhaseTwo(pBt, 1);
  }
}
sqlite3EndBenignMalloc();
enable_simulated_io_errors();
sqlite3VtabCommit(db);

     * sqlite3VtabCommit() 안에서 실제로는 모든 xCommit 호출이 실패해도 무시됨 → 순수한 정리 단계
int sqlite3VtabCommit(sqlite3 *db){
  callFinaliser(db, offsetof(sqlite3_module,xCommit));
  return SQLITE_OK;
}

     * xSync로 내구성이 확보됐기 때문에, xCommit, xRollback은 실패해도 무시됨

가상 테이블 작성자를 위한 주의사항

     * 지속성 있는 작업은 반드시 xSync에 넣어야 함
          + 네트워크 I/O, 파일 쓰기 등 실패할 수 있는 작업은 여기서 처리해야 트랜잭션이 안전하게 중단됨
     * xSync 후에도 xRollback이 호출될 수 있음
          + 다른 테이블의 xSync가 실패하면 전체 롤백됨
     * xCommit과 xRollback은 실패하지 않는 정리용 함수로 작성
          + **idempotent(항등성)**하게, 여러 번 호출돼도 상태 변화가 없어야 함

결론

     * SQLite의 저널링 메커니즘은 기본 테이블과 가상 테이블을 포함한 모든 요소의 원자성 커밋을 보장
     * 가상 테이블의 트랜잭션 훅은 SQLite 트랜잭션 흐름에 자연스럽게 통합됨
     * 가상 테이블을 구현하는 개발자는 xSync에 집중하여 데이터 무결성을 확보하고, 정리 작업은 xCommit, xRollback으로 나눠야 함

        Hacker News 의견

     * vtabs에 대한 글을 보니 좋음. 나는 Rust로 SQLite를 재구현하면서 vtab 지원을 구현했음. 그래서 최근에 vtab에 대해 많은 것을 배웠음. vtab은 매우 강력하고 아마도 충분히 활용되지 않음
     * 흥미로움. 하지만 이것은 mattn의 go-sqlite3 패키지를 사용함. 이는 CGO임
          + 현대 GO에서 이것이 일반적이거나 예상되는 요구사항인지 궁금함
"
"https://news.hada.io/topic?id=20500","공공 인터넷 회복을 위한 오픈 소스 프로젝트 자금 지원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     공공 인터넷 회복을 위한 오픈 소스 프로젝트 자금 지원

     * NGI Zero Commons Fund는 42개의 자유 및 오픈 소스 프로젝트에 자금을 지원하여 인터넷의 공공성을 회복하려는 목표를 가짐
     * 선정된 프로젝트는 태양광 전원 마더보드, 고성능 파일 시스템 등 다양한 기술 혁신을 포함함
     * 교육 및 프라이버시 친화적인 도구 개발을 통해 사용자 경험을 개선하고 학습을 지원함
     * 팟캐스트 제작 소프트웨어, 실시간 협업 노트북 등 다양한 응용 프로그램이 포함됨
     * NGI Zero Commons Fund는 유럽연합의 Next Generation Internet 프로그램의 지원을 받음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

42개의 자유 및 오픈 소스 프로젝트에 자금 지원

     * NGI Zero Commons Fund는 인터넷의 공공성을 회복하기 위해 42개의 프로젝트에 자금을 지원함
     * 이번 지원은 NGI Zero의 역사상 가장 큰 규모의 공모였음
     * 모든 신청자에게 감사의 인사를 전하며, 이 프로젝트들이 이익이 아닌 사람들을 위한 인터넷을 만드는 데 기여함

태양광 전원 마더보드 및 고성능 파일 시스템

     * MNT Reform Touch와 Solar FemtoTX 마더보드는 태양광으로 구동 가능한 초저전력 마더보드를 개발함
     * LLM2FPGA는 오픈 소스 LLM을 FPGA에서 로컬로 실행할 수 있도록 함
     * bcachefs는 차세대 파일 시스템으로, 기존 파일 시스템에 비해 성능, 확장성 및 신뢰성을 개선함

프라이버시 친화적인 양식 및 어린이를 위한 증강 현실

     * LiberaForms는 종단 간 암호화를 제공하는 유일한 양식 솔루션으로, 교육적 사용 사례를 위해 UX를 개선함
     * ClassQuiz는 학교가 학생들을 프라이버시 걱정 없이 퀴즈할 수 있도록 함
     * Flock XR은 어린이 친화적인 3D 시각적 창의성과 코딩 도구를 제공함

팟캐스트에서 인터랙티브 노트북까지

     * Podlibre는 팟캐스트 제작을 위한 전용 소프트웨어임
     * PeerTube for institutions는 조직이 PeerTube 플랫폼을 쉽게 사용할 수 있도록 함
     * Livebook은 사용자가 실시간으로 협업할 수 있는 인터랙티브 노트북 애플리케이션을 제공함

NGI Zero Commons Fund의 중요성

     * NGI Zero Commons Fund는 유럽연합의 Next Generation Internet 프로그램의 지원을 받으며, 인터넷의 공공성을 회복하는 데 기여함
     * 다양한 프로젝트가 이 펀드를 통해 지원받아 기술 혁신과 사회적 가치를 창출함

        Hacker News 의견

     * EU와 회원국들이 미국 기술 기업에 대한 의존을 줄이기 위해 많은 자금을 투자하고 있음
          + 다양한 프로젝트를 지원하고 있으며, 그 범위와 의도가 다양함
          + 애플과 마이크로소프트가 유일한 통합 시스템 제공업체라는 문제를 해결하지 못하고 있음
          + 자금이 많은 작은 프로젝트에 분산되어 있어, 오픈 소스 시스템을 조직 전체에 배포하는 문제는 해결되지 않음
     * 수십 년 동안 유지되고 사용된 핵심 프로젝트에 대한 언급이 없음
          + xz, libexpat, openzfs, NetworkManager 등 리눅스 시스템을 연결하는 작은 프로젝트들이 있음
          + 웹을 간소화하려는 pihole과 가장 널리 사용되는 DNS 서버인 dnsmasq는 어디에 있는지 궁금함
     * 몇 가지 훌륭한 이니셔티브가 자금을 지원받고 있음
          + PeerTube for Institutions: 대규모로 관리 및 조정하기 쉽게 만드는 프로젝트
          + 더 많은 기관과 NGO가 PeerTube로 이동하길 바람
          + Wiktionary에 대한 자금 지원은 Wikimedia의 일부로, 예산의 4분의 1 이상을 분석 및 ML 서비스 구축에 사용함
     * Motis (교통 계산기), Clearance (OSM 기여 분석), StreetComplete (OSM 기여 게임화)는 자유 지도 커뮤니티에 중요한 자산임
     * 정부의 구매 습관을 통한 간접적인 자금 지원도 많음
          + 독일 주정부가 30,000대의 PC를 LibreOffice로 전환하는 사례
          + EU에서 정부의 크기는 종종 GDP의 50% 이상을 차지함
          + 정부의 구매는 프로젝트, 컨설턴트 및 오픈 소스 생태계에 많은 자금을 의미함
     * 많은 댓글이 미국 중심적임
          + Canonical과 Suse가 존재하지 않는 것처럼 보이며, 유럽 기반/집중적이지 않음
          + MS가 대체 불가능한 전체 패키지를 제공한다는 주장은 사실이 아님
          + 대부분의 비즈니스는 Dell, HP, Lenovo에서 전면 및 후면을 임대함
     * 이전에 nlnet에서 자금을 받았으며, 그들과의 협업이 훌륭했음
          + nlnet은 훌륭한 이니셔티브이며, Marginalia 검색 엔진을 지원함
     * SSH Stamp는 흥미로워 보이지만, 프로젝트 페이지나 개발자에 대한 정보가 없음
          + DuckDuckGo로 검색해도 해당 페이지 외에는 정보가 없음
          + 오픈 소스 프로젝트인지 의문임
     * 어제 발견한 OpenCloud
          + 작은 프로젝트들이 자금을 받는 상황에서 인터넷을 되찾기 위한 일관된 비전이 명확하지 않음
          + 브라우저 자체가 대형 기술 기업에 의해 소유됨
          + 클라우드를 위한 운영 체제가 필요함
          + 누구나 실행하고 적응할 수 있는 시스템이 필요함
          + 서비스 간 명확한 프로토콜과 유용한 기본 서비스 세트가 필요함
          + Proton과 같은 것들은 좋지만, 스스로 실행할 수 없음
          + 완전히 오픈 소스가 아니며, 그들의 목표도 아님
          + 대형 기술 기업과 클라우드 제공업체에 대한 진정한 대안이 필요함
"
"https://news.hada.io/topic?id=20505","Supabase, 기업가치 약 2조 9천억 원으로 2,900억 원 규모 시리즈 D 투자 유치","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Supabase, 기업가치 약 2조 9천억 원으로 2,900억 원 규모 시리즈 D 투자 유치

     * Supabase는 최근 $200M의 시리즈 D 투자를 받아 $2B의 기업 가치를 평가받음
     * Postgres기반 백엔드로 Google의 Firebase에 대한 대안으로 급성장한 오픈 소스 애플리케이션 개발 플랫폼
     * 2백만 명의 개발자가 사용 중이며, 350만 개 이상의 데이터베이스를 관리함
     * Vibe coding 트렌드에 걸맞는 기능으로 개발자와 기업 모두에게 매력적인 플랫폼을 제공함
     * 원격 근무를 기반으로 하며, 전직 창업자 다수 및 전 세계 다양한 지역의 인재를 채용하여 운영 중
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Supabase, 20억 달러 가치로 2억 달러 Series D 투자 유치

     * Supabase 공동창업자 Paul Copplestone은 뉴질랜드의 외진 지역에서 Accel의 파트너 Gonzalo Mocorrea로부터 직접 방문을 받음
     * 이 만남 후 Accel의 Arun Mathew가 합류해 최종적으로 투자 계약서(term sheet) 를 제공함
     * 이번 라운드는 Coatue, Y Combinator, Craft Ventures, Felicis, 그리고 OpenAI, Vercel, Laravel의 고위 인사들이 참여
     * Accel은 데이터베이스 계층이 플랫폼 전환 시기마다 가장 큰 가치를 창출하는 영역이라며 투자 배경을 설명

개발자 중심 오픈소스 백엔드 플랫폼 Supabase의 성장

     * Supabase는 현재 200만 명 이상의 개발자가 사용하며, 350만 개 이상의 데이터베이스를 관리
     * Postgres 기반으로 Google Firebase의 대안으로 각광받고 있음
     * 목표는 개발자부터 대기업까지 모두를 위한 통합 백엔드 플랫폼이 되는 것
     * 최근 3개월간 가입률이 2배 증가했으며, Bolt, Lovable, Cursor 등의 서비스가 성장 촉진

Vibe Coding과 Supabase의 연결

     * Vercel의 Guillermo Rauch는 Supabase를 vibe coding 흐름의 핵심 인프라로 평가
     * Supabase는 단순히 사용이 쉬운 것을 넘어서, 클라우드 인프라의 핵심 데이터 레이어를 구성
     * vibe coding은 자율주행차에 비유되며, Supabase는 이 도로를 제공하는 역할 수행

원격 우선 문화와 창업 경험자 중심 채용 전략

     * Supabase는 팬데믹 기간 중인 2020년에 설립, 전 세계에 원격 팀으로 구성
     * 직원 중 약 28%는 전직 창업자이며, 지역은 페루, 마케도니아 등 다양
     * 단순 실력뿐 아니라 낮은 자존심(low ego) 과 협업 능력을 중시
     * 주요 릴리스 기간에는 100개 도시 이상에서 밋업 개최, 커뮤니티 결속 강화

이름에 담긴 유머와 브랜드 전략

     * Supabase라는 이름은 원래 ‘superlative base’ 에서 출발했지만, 도메인 문제로 ""SUPA"" 형태 선택
     * Nicki Minaj의 히트곡 “Super Bass” 에서 영감을 받아, 공동창업자와 밈을 주고받기 위해 이름 정함

   5년전에 공개 베타 시작할때 기사로 올려서 공동창업자가 와서 댓글도 남겼었는데 그동안 엄청 성장했네요 ㅎㅎ
   Supabase 공개 베타 시작 - 오픈소스 Firebase 대체제

   개인 프로젝트에 너무나 잘 쓰고 있습니다.

   Supabase는 CRUD 기반인 시스템에 적합한 게 특징이고 API서버를 개발/운영하지 않아도 프론트엔드에서 CRUD를 구현 가능해서 백엔드 개발 부담이 적습니다. 프론트엔드와 백엔드 개발자가 API 규약 대신 테이블 정의로 커뮤니케이션하며 기능 중 웹콘솔, 인증, 객체저장소를 주로 쓰고 있습니다

   프론트엔드가 DB 테이블과 뷰, 함수 정의에 의존하기 때문에 데이터 변경 추적에 좀 신경을 써야합니다. 서버사이드 로직이 필요하시면 WAS/REST API를 별도로 구축하시는 편이 낫다고 생각합니다

   사이드 프로젝트를 하고 싶은 분들께는 항상 Supabase를 제 1옵션으로 추천드립니다. Supabase 더 잘되었으면 좋겠네요!

   굉장히 좋아하는 서비스입니다. 복잡한 백엔드/DB 세팅 없이 프론트만으로 서비스를 만들 수 있어요.
   실제로 서비스에서 활용해보려고 열심히 사용중인데 저는 오히려 firebase보다 개발자 경험이 좋았어요.
   국내 리전도 있고, 꽤 자비로운 프리티어를 제공해 좋습니다. self hosting도 할 수 있구요.
   시리즈D 유치라니 좋은 소식이네요! 다만 의견에서 계속 언급되듯 지속 가능한 사업인지 걱정이 되긴 합니다.

        Hacker News 의견

     * 많은 해커들이 Supabase를 초보자용이라고 생각할지 모르지만, 나는 재미있는 사이드 프로젝트를 다시 시작한 전직 엔지니어로서 Supabase가 놀랍고 내가 원하던 것임. 지난 1년간 사용한 제품 중 가장 마음에 듦. 많은 사람들이 터미널에서 벗어나고 싶어하고 많은 돈을 벌기를 바람
     * Supabase의 출구 전략이 무엇인지 궁금함. 독립적인 사업으로 장기적으로 지속 가능할지 의문임
     * ""바이브 코딩""이라는 마법의 단어를 사용하면 제품이 약간 관련이 있더라도 자금을 받을 수 있는 시대가 됨
     * Supabase는 현재 200만 명의 개발자가 350만 개 이상의 데이터베이스를 관리하는 데 사용 중임. Postgres를 지원하며, Google의 Firebase 대안으로 가장 인기 있는 개발자 데이터베이스 시스템임. Supabase의 목표는 개발자와 ""바이브 코더""를 위한 원스톱 백엔드가 되는 것임
     * 얼마나 많은 사용자가 유료인지 궁금함. 신용카드 없이 무료로 가입 가능함
     * 특정 사용 사례에 적합함. 몇 달간 사용 후 Django로 전환함
     * 인증 뒤에 데이터를 저장하고 프론트엔드에서 모든 것을 처리해야 할 때는 좋음. 서버사이드 로직이 필요해지면 이상해짐. Firebase가 특히 Firebase 함수와 비교했을 때 더 다듬어져 있고 사용하기 쉬웠음
     * 셀프 호스팅은 마법 같은 기술이 필요하며, 현재 그들에게는 초점이 아님
     * 무료 티어를 유지하길 바람. 완벽하지는 않지만, 돈을 전혀 쓸 수 없는 상황에서도 학습이나 포트폴리오 작업에 쉽게 사용할 수 있음
     * 축하함. 몇 주 전 지역 Supabase 이벤트에서 발표자로 참여했음. 나이지리아 아부자에서 지역 이벤트를 열었고, Supabase의 Launch Week 14 시리즈를 홍보했음. 실제로는 주말 동안 SME 비즈니스를 위한 빠른 백엔드를 부트스트랩하는 방법을 보여주는 이벤트가 되었음
     * 새로운 평가 배수가 플랫폼의 개발자 수인지 수익인지 궁금함. 개발자당 $1000로 평가하는 것은 다소 미친 짓임. 데이터베이스당 $570로 평가하는 것도 이상함. 멋진 제품이지만 창업자들이 꽉 찬 캡 테이블에서 승리를 찾기를 바람
     * $2B 평가에 $16M 수익은 이상함
     * 내 예측: 그들은 AI IDE의 사실상 백엔드로 OpenAI나 Claude에 큰 출구를 기대하고 있음
     * Firebase의 유일한 큰 대안이며, Firebase는 Google AI Studio로 통합됨
     * 새로운 앱을 위해 PostgREST, RLS, PL/pgSQL 함수를 테스트 중이며, 그다지 마음에 들지 않음. 권한 모델을 이해하기 어렵고, 데이터베이스에 로직을 로드하는 것이 어색하며, LLM이 신뢰할 수 있는 쿼리, 정책, 함수 등을 생성하는 데 약함. '바이브 코더'에게 이상적이라고 확신하지 않음
     * 개인적으로 Supabase와 Vercel이 AWS와 경쟁하고 있으며, 시장 점유율을 잠식하기 시작할 것이라고 생각함. 개발자 경험이 AWS보다 훨씬 우수하며, AWS가 ""더 많은 복잡성과 규모""를 처리한다고 해서 이를 반박할 수 없음. Supabase/Vercel 제품은 대형 클라우드 제공업체보다 우수하며, 기술 스택의 좁은 측면과 소규모 고객을 대상으로 하지만, 사용자가 증가함에 따라 더 많은 기업으로 확장할 것임
     * AWS는 개발자 경험을 우선시해야 함
     * Supabase는 AI 생성 앱을 위한 데이터베이스로 보이며, 이는 큰 순풍이 될 것임
     * 그들에게 좋음. 온라인에서 많은 비난을 받는 이유는 ""왜 내가 그 생각을 못했을까""라는 아이디어 때문이라고 생각함. 사람들은 그들의 성공을 질투함
     * 폭력적인 공개 시장에서 IPO를 피하기 위해 사설 시장에서 매우 늦은 단계의 자금을 조달하는 것 같음. 이는 당분간 새로운 스타트업의 표준이 될 것 같음. 소모를 줄이거나 큰 할인으로 출구를 찾거나 죽지 않는다면
     * 어쨌든 Supabase 팀을 축하함
"
"https://news.hada.io/topic?id=20466","이 블로그는 닌텐도 Wii에서 호스팅됩니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        이 블로그는 닌텐도 Wii에서 호스팅됩니다

     * 이 블로그는 Nintendo Wii에서 호스팅되고 있으며, NetBSD를 사용하여 운영됨
     * Wii는 PowerPC 750 기반의 단일 코어 CPU를 사용하며, 이는 우주 탐사와 같은 고성능 작업에도 사용되는 칩셋임
     * NetBSD는 Wii에서 최신 버전으로 지원되며, 이를 통해 실제 프로덕션 워크로드를 실행할 수 있음
     * Wii에 NetBSD를 설치하기 위해 Wilbrand 익스플로잇을 사용하여 홈브류 채널을 설치하고, NetBSD 이미지를 SD 카드에 로드함
     * lighttpd 웹 서버를 사용하여 블로그를 호스팅하며, Caddy를 통해 TLS 종료를 처리하여 성능을 최적화함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Wii에서 블로그 호스팅

     * 이 블로그는 Nintendo Wii에서 호스팅되고 있으며, 이는 NetBSD를 사용하여 운영됨
     * Wii는 PowerPC 750 기반의 단일 코어 CPU를 사용하며, 이는 우주 탐사와 같은 고성능 작업에도 사용되는 칩셋임
     * Wii에 NetBSD를 설치하기 위해 Wilbrand 익스플로잇을 사용하여 홈브류 채널을 설치하고, NetBSD 이미지를 SD 카드에 로드함
     * lighttpd 웹 서버를 사용하여 블로그를 호스팅하며, Caddy를 통해 TLS 종료를 처리하여 성능을 최적화함

Wii의 성능

     * Wii의 CPU는 IBM의 PowerPC 750 라인업의 일부로, 1998년의 iMac에 사용된 아키텍처임
     * Wii의 CPU는 단일 코어로, 최대 TDP가 9.8W이며, Wii에 사용된 버전보다 약 33% 더 높은 클럭 속도를 가짐
     * 이 CPU는 우주 탐사와 같은 고성능 작업에도 사용되며, RAD750이라는 방사선 강화 버전도 존재함

NetBSD 설치 과정

     * Wii에 NetBSD를 설치하기 위해 Wilbrand 익스플로잇을 사용하여 홈브류 채널을 설치함
     * Wii의 MAC 주소를 알고, SD 카드에 몇 가지 파일을 생성하여 로드함으로써 설치 가능함
     * NetBSD 이미지를 SD 카드에 로드하고, 홈브류 채널을 통해 부팅함

패키지 관리 및 웹 서버 설정

     * pkgin 패키지 관리자를 설치하여 다양한 유용한 패키지를 설치함
     * lighttpd 웹 서버를 설치하고, 기본 설정을 복사하여 활성화 및 시작함
     * 블로그는 Hugo로 빌드된 정적 페이지 모음으로, rsync를 통해 파일을 전송하여 사이트를 호스팅함

성능 최적화 및 모니터링

     * 여러 서비스의 비활성화를 통해 리소스를 확보하고, Caddy를 통해 TLS 종료를 처리하여 성능을 최적화함
     * Caddy의 Prometheus 익스포터를 사용하여 사이트 로드를 모니터링하고, Wii의 시스템 상태를 간단한 셸 스크립트를 통해 모니터링함

최종 관찰

     * Wii에서의 블로그 호스팅은 예상보다 잘 작동하며, 전력 소비도 비교적 적음
     * Wii는 약 18W의 전력을 소비하며, 이는 월 약 13.2 kWh에 해당함
     * 이 실험은 인위적인 제약을 적용하여 학습을 촉진하는 재미있는 실험이었음

   안쓰는 안드로이드 폰에 debian 올려서 웹서버 굴리던 때가 기억나네요

   왜 Caddy와 lighttpd를 동시에 쓰나 싶어서 의아했는데 static 파일만 Wii에서 처리하고 나머지는 다른 머신의 Caddy에서 처리하는 형태인가 보네요.

        Hacker News 의견

     * ""SSL Added and removed here!"" 이미지는 2013년 NSA에서 유출된 Google 데이터 센터 간의 암호화되지 않은 통신을 설명하는 다이어그램을 참조함
     * NetBSD를 재부팅하면 전체 콘솔이 재부팅되며, NetBSD '앱'만 재부팅되는 것이 아니므로 커널 패치나 시스템 업그레이드 후 Wii 메뉴로 돌아가게 됨
          + Priiloader를 설치하고 Homebrew Channel이나 NetBSD .dol 파일로 자동 부팅하도록 설정하면 이를 완화할 수 있음
     * 참고로 Photo Booth 대신 Quicktime Player를 사용하여 ""새 영화 녹화 생성""을 할 수 있음
          + 이는 이미지 뒤집힘 문제를 해결할 수 있을 것이라고 믿음
     * Wii 홈브루 경험에 기반하여, 작은 SD의 신뢰성 문제를 예상하여 익스플로잇 후 일반 USB 드라이브로 교체하여 해결할 수 있을 것임
          + 포트는 2.0만 지원하지만 어차피 프로세서에 의해 제한됨
     * 캡처 카드와 macOS의 Photo Booth를 사용하여 이 작업을 수행했는데, 실제로는 비디오 피드에서 이미지 뒤집기를 비활성화할 수 없음
          + OBS 사용을 권장함
     * ""안아줌""을 받았음
          + 다음 게시물은 ""블로그가 Nintendo Wii (Varnish 실행 중)에 호스팅됨""이라고 말할지도 모름
     * 성능이 나쁘지 않음
          + Nintendo의 TCP 스택을 사용하지 않는 것이 분명하며, 이는 Wii에서 악명 높았음
     * 까다롭게 굴고 싶지는 않지만, Caddy 인스턴스를 Wii로 이동시키거나 제거하지 않는 한 블로그가 Wii에 완전히 호스팅된 것은 아님
          + 훌륭한 작업임
     * 믿을 수 없을 정도로 놀라움
          + 훌륭한 작업임
"
"https://news.hada.io/topic?id=20397","DeepSeek의 분산 파일 시스템 3FS 소개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       DeepSeek의 분산 파일 시스템 3FS 소개

     * 3FS는 DeepSeek가 개발한 고성능 오픈소스 분산 파일 시스템으로, 대규모 데이터 처리와 높은 처리량을 지원함
     * 일반적인 파일 시스템처럼 동작하지만, 실제로는 여러 머신에 데이터를 분산 저장하며 사용자는 이를 의식하지 않아도 되는 추상화 구조를 가짐
     * 4가지 주요 구성 요소 (Meta, Mgmtd, Storage, Client) 를 통해 메타데이터, 노드 관리, 실제 데이터 저장, 사용자 요청 처리 등을 분리하여 운영함
     * CRAQ 알고리듬을 통해 강한 일관성과 장애 허용을 달성하며, 체인 구조로 쓰기 요청을 안전하게 전파함
     * 3FS는 다른 분산 파일 시스템과 비교하여 실제 적용 가능성과 성능 확장성에서 차별화됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

3FS란?

     * 3FS는 Fire-Flyer File System의 약자로, DeepSeek에서 공개한 분산 파일 시스템
     * DeepSeek의 오픈소스 공개 주간에 함께 릴리즈됨
     * 일반적인 파일 경로처럼 보이지만, 실제로는 여러 머신에 분산 저장된 데이터를 추상화해 제공함

분산 파일 시스템이란?

     * 사용자에게는 로컬 파일 시스템처럼 보이지만, 실제로는 여러 서버에 데이터를 분산 저장함
     * 예: /3fs/stage/notes.txt 경로가 하나의 파일처럼 보이지만 실제론 여러 서버에 나뉘어 저장됨
     * 사용자는 mkdir, cat 같은 명령어로 일반 파일처럼 사용할 수 있음

왜 분산 파일 시스템을 사용하는가?

     * 대용량 데이터 (페타바이트 수준) 와 높은 처리량을 지원
     * 장애 허용(fault tolerance) 과 중복성(redundancy) 을 통해 안정성 보장
     * 실제 사용 예:
          + HDFS + Spark 같은 병렬 처리 프레임워크
          + ML 학습 파이프라인의 체크포인팅
          + Google의 Colossus
          + Meta의 사진 저장소인 Haystack
          + AI용 스토리지 예: JuiceFS vs CephFS

3FS 구성 요소

     * 총 4가지 주요 노드로 구성됨

  Meta

     * 파일 경로, 속성, 위치 등의 메타데이터 관리
     * RPC로 클라이언트 요청 처리 (open, stat, close 등)
     * 메타 정보는 FoundationDB에 저장됨
     * Inode는 파일의 크기, 소유자 등의 정보를 저장
     * DirEntry는 경로와 inode를 연결함 (심볼릭 링크처럼 하나의 파일에 여러 경로 존재 가능)

  Mgmtd

     * 클러스터의 노드 등록 및 상태 확인 담당
     * 노드들은 부팅 시 자신을 등록하고 주기적으로 하트비트 전송
     * 중앙 라우터 역할을 하며, 노드 간 연결을 직접 유지하지 않아도 됨
     * CRAQ 체인 구성을 위한 설정 정보도 관리

  Storage

     * 실제 데이터 저장 담당
     * Rust 기반의 ChunkEngine을 통해 디스크 블록을 관리
          + 디스크 블록의 크기, 오프셋, 체크섬, 버전 등을 추적
          + 사용자는 직접 블록과 상호작용하지 않고 인터페이스 제공
          + 메타 정보는 LevelDB에 저장
     * 다양한 워커들이 존재
          + AllocateWorker는 새 블록 할당
          + PunchHoleWorker는 사용되지 않는 블록 회수
          + AioReadWorker는 io_uring 큐를 통해 비동기 읽기 처리
     * 쓰기 작업 시 CRAQ 체인을 따라 다음 노드로 전달

  Client

     * 사용자 요청을 처리하고 다른 노드와 통신
     * 작업 흐름:
          + Mgmtd에 노드 위치 질의
          + Meta에 파일 작업 요청
          + Storage와 데이터 전송

CRAQ 알고리듬

     * Chain Replication with Apportioned Queries의 약자로 강한 일관성(linearizability) 제공
     * 쓰기 흐름:
          + Head → Middle → Tail 순으로 쓰기 전파
          + 중간 단계에서는 데이터를 dirty로 표시 (읽기 불가)
          + Tail에서 커밋 후 backward로 clean 상태 전파
     * 읽기 흐름:
          + clean이면 즉시 반환
          + dirty이면 tail에 요청하여 최신 데이터 조회

  성능 측면에서 CRAQ

     * 쓰기 속도는 가장 느린 노드에 의해 제한
     * 자주 접근되는 dirty 데이터는 tail로 읽기 요청이 몰려 읽기 병목 발생 가능
     * 예: Zipfian workload에서 성능 저하
     * 노드가 5개인 클러스터에서는 3개로 복제하여 장애 시 성능 손실 최소화

다른 분산 파일 시스템과의 차이점

     * 구조는 유사하지만 현실 적용성과 구현 방식에서 차별점 존재
     * 비교 요소:
          + 어떤 워크로드에서 강점을 가지는지
          + 성능 조절의 유연성
          + 배포의 용이성
          + 처리량 확장성
          + SLO 내에서의 지연시간 관리
          + 신뢰성
     * 세부 기술 요소:
          + 병목 원인과 처리 방식
          + 락의 유무
          + 사용된 자료구조
          + 타겟 하드웨어
          + 사용된 장애 허용 알고리듬 또는 에러 정정 방식

블로그 시리즈의 다음 주제

     * 실제 성능 분석을 통해 DeepSeek의 주장 검증 예정
     * 검토 항목:
          + FUSE 병목에 대한 DeepSeek의 주장
          + 성능 그래프 재현 가능성
          + 성능 저하 상황 분석
          + 병목 요소 (CPU, 메모리, 디스크, 네트워크)
          + 어떤 워크로드에서 성능이 우수한지
          + 기존 시스템과 비교 분석
          + 기존 시스템의 문제 해결 방식과의 차이
          + 직접적인 개선 가능성 검토

추가 자료

     * 공식 디자인 노트에서 구현 방식 참고 가능
     * 중국어 문서:
          + 시작 가이드
          + 비동기 IO
          + RDMA 읽기
          + 네트워크 라우팅
          + 읽기 부하 분산
     * 논문 자료: Fire-Flyer AI-HPC 아키텍처

   와 고민하고 있던 문제였는데 이걸 ..

        Hacker News 의견

     * S3FS는 확장 가능한 메타데이터 파일 시스템으로, 다양한 분산 파일 시스템과 비교됨
          + Collosus, Tectonic (Meta), ADLSv2 (Microsoft), HopsFS (Hopsworks), PolarFS (Alibaba) 등이 있음
          + S3FS는 FoundationDB를 사용하고, Collosus는 BigTable, Tectonic은 KV store, HopsFS는 RonDB를 사용함
          + S3FS의 중요한 점은 (1) fuse 클라이언트를 지원하여 사용이 편리하고, (2) NVMe 스토리지를 지원하여 디스크 I/O에 구애받지 않음
          + HopsFS는 계층형 스토리지를 추가하여 최근 데이터는 NVMe에, 보관 데이터는 S3에 저장함
     * 이 시스템들을 평가할 때 이론적 한계, 효율성, 실질적 한계를 고려해야 함
          + 이론적으로는 Lustre와 같은 병렬 분산 파일 시스템이 무한대로 확장 가능함
          + 효율성을 평가하기 위해 X TiB 디스크를 가진 노드로 얼마나 많은 저장소와 처리량을 얻을 수 있는지 계산함
          + FSx for Lustre와 비교하여 AWS에서 3FS를 12-30% 저렴하게 운영할 수 있음
          + 사람들이 원하는 배포 크기로 파일 시스템을 실제로 구성할 수 있는지에 대한 질문이 남아 있음
          + DeepSeek가 자체적으로 원하는 속성을 얻기 위해 이러한 시스템을 구축하는 것이 이해됨
          + Archil에서 대부분의 사람들이 거대한 클러스터를 관리하지 않고도 사용할 수 있는 더 나은 기본 설정을 찾기를 바람
     * SeaweedFS와의 비교에 관심이 있음
          + SeaweedFS는 날씨 데이터를 저장하는 데 사용되며, 약 3 PB의 데이터를 ML 훈련에 사용함
     * CephFS를 사용하지 않는 이유에 대한 질문
          + CephFS는 실세계 시나리오에서 철저히 테스트되었고, 페타바이트 규모에서도 신뢰성을 입증함
          + 오픈 소스 솔루션으로, 가장 빠른 NVMe 스토리지에서 실행 가능하며, 10 기가비트 이상의 인터커넥트로 매우 높은 IOPS를 달성함
     * JuiceFS와의 비교에 대한 질문
          + 개인 홈랩 설정에서 S3 Garage 위에 JuiceFS를 실행할 계획임
          + Garage는 복제만 지원하며, 소거 코딩이나 샤딩은 지원하지 않음
          + 설정이 간단해 보여서 선택함
     * 소규모 사업자 및 홈랩 사용자로서 대규모 분산 파일 시스템을 사용할 일은 없을 것 같음
          + 페타바이트 규모의 데이터를 다룰 때 백업과 복구에 대한 궁금증이 있음
     * 복잡한 설정이지만, 딥러닝 워크로드에 필수적인 기능은 명확하지 않음
          + 필요한 기능은 페타바이트 규모의 저장소, 읽기/쓰기 병렬성, 중복성임
          + 일관성을 달성하기 어려우며, 여기서는 필요하지 않음
     * DeepSeek의 분산 파일 시스템을 비활성화하는 것이 얼마나 쉬운지에 대한 질문
          + 예를 들어, 미국 대학이 연구를 위해 DeepSeek를 사용하도록 승인받았지만, 데이터가 로컬 연구 클러스터 파일 시스템을 벗어나지 않도록 해야 함
     * 여러 기기에 분산된 ZFS 드라이브로 이를 복제할 수 있는지에 대한 질문
"
"https://news.hada.io/topic?id=20433","Undercut-F1 – 드라이버 추적 및 가변 지연 기능을 갖춘 F1 라이브 타이밍 TUI","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Undercut-F1 – 드라이버 추적 및 가변 지연 기능을 갖춘 F1 라이브 타이밍 TUI

     * undercut-f1은 F1 세션의 실시간 타이밍 정보를 기록하여 나중에 재생할 수 있는 오픈소스 TUI 클라이언트
     * 신호 기반 스트림 데이터를 받아 시각화하거나 녹화된 세션을 리플레이할 수 있음
     * 상세한 드라이버별 타이밍 타워, 피트 스톱 전략, 레이스 컨트롤 메시지, 전략 분석, 드라이버 위치 추적, 팀 라디오, 랩별 히스토리 기능 제공
     * 데이터는 로컬에 저장되어 개발 및 테스트에 활용 가능, 시뮬레이션 모드도 지원
     * iTerm2, Kitty 등의 터미널 이미지 프로토콜을 활용한 시각적 디스플레이 구현
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

undercut-f1 프로젝트 소개

   undercut-f1은 F1 라이브 타이밍 정보를 CLI 기반 TUI(터미널 사용자 인터페이스)로 시각화하는 오픈소스 도구임
   주요 특징은 다음과 같음:
     * 실시간 F1 세션 데이터를 시청각적으로 표현
     * 사용자가 직접 세션 데이터를 녹화하고, 이후 재생 가능
     * F1 방송의 평균 지연 시간(30~60초)을 고려하여 지연 설정 조정 기능 제공
     * .NET 기반 CLI 앱으로, NuGet 패키지 또는 단일 실행 파일 형태로 사용 가능

주요 기능

     * 타이밍 타워
          + 섹터별 기록 표시 (개인 최고/전체 최고 색상 표시)
          + 최근 및 베스트 랩 타임
          + 타이어 종류 및 사용 시간
          + 선두 및 전 차량과의 시간 차
          + 선택된 드라이버와 다른 드라이버 간 시간 차 비교
     * 전략/스틴트 정보
          + 드라이버별 타이어 전략을 한 눈에 확인 가능
          + 각 타이어의 사용 시점, 지속 시간 시각화
          + 전략 차이 감지 용이
     * 레이스 컨트롤 화면
          + 공식 조사, 페널티, 날씨 정보 등 레이스 컨트롤 메시지 확인
     * 드라이버 트래커
          + 선택된 드라이버의 실시간 트랙 위치 시각화
          + iTerm2 및 Kitty 이미지 프로토콜 지원 터미널에서 작동
          + 커서를 통해 드라이버 선택 및 비교 가능
     * 타이밍 히스토리
          + 랩별 갭/인터벌 변화 확인
          + 최근 15랩의 랩 타임 및 선두 갭 트렌드 차트 제공
     * 팀 라디오 청취 및 전사
          + Whisper 모델을 활용하여 로컬에서 팀 라디오를 자체 음성 인식으로 전사
          + 품질은 당일 오디오 품질에 따라 다르며 개선 제안도 수렴 중

세션 실행 및 리플레이

     * 실시간 세션 실행
          + undercutf1 실행
          + <kbd>S</kbd> 키로 세션 화면 진입
          + <kbd>L</kbd> 키로 실시간 세션 시작
          + <kbd>T</kbd> 키로 타이밍 타워 보기
          + 세션 데이터는 ~/undercut-f1/data/<session-name>에 저장되어, 이후 재생용 데이터로 활용 가능
     * 녹화된 세션 리플레이
          + Sample Data 폴더의 데이터를 복사하거나, 공식 세션 데이터를 다운로드해 리플레이 가능
          + <kbd>F</kbd> 키로 시뮬레이션 시작 → 세션 선택 → 타이밍 타워로 진입
          + <kbd>N</kbd> 키로 지연 시간 조정하여 빠르게 탐색 가능
     * 세션 데이터 다운로드
          + undercutf1 import <year> 명령어로 해당 연도 세션 리스트 확인 가능
          + 세션을 선택해 로컬로 다운로드 및 변환 → 재생 가능

커서 및 지연 관리 기능

     * 모든 화면에서 <kbd>▲</kbd>/<kbd>▼</kbd> 키로 커서를 제어
          + 예: 특정 드라이버 선택 시, 해당 드라이버 기준 시간 차 시각화 가능
     * <kbd>M</kbd>/<kbd>N</kbd> 키로 라이브 방송과의 싱크를 위한 지연 시간 조정
          + <kbd>Shift</kbd>와 함께 누르면 30초 단위 조정

데이터 소스 및 저장 방식

     * F1 Live Timing 스트림은 SignalR 기반
     * 다음과 같은 토픽을 구독하여 실시간 데이터를 수신:
          + TimingStats, TimingData, WeatherData, DriverList, RaceControlMessages, TeamRadio 등
     * 세션 시 데이터는 다음 두 파일로 저장됨:
          + subscribe.txt: 구독 시 받은 초기 데이터
          + live.txt: 세션 중 실시간 수신된 전체 데이터

라이선스

     * 본 프로젝트는 F1 공식 기관과 무관한 비공식 오픈소스 프로젝트
     * F1, FORMULA ONE 등 관련 상표는 Formula One Licensing B.V. 가 소유함

        Hacker News 의견

     * 핀란드에서는 스포츠를 따라가기 위해 텔레텍스트가 여전히 인기가 많음. TUI는 광고 없이 바로 핵심 정보를 제공해 줌. 텔레텍스트 형식은 이제 TV보다 오래 살아남아 사람들이 모바일 앱을 통해 텔레텍스트 페이지를 읽음
     * F1을 사랑하는 사람으로서 이번 주말에 이걸 사용해 보는 것이 정말 기대됨. 라이브/정적 데이터의 출처와 그 자유로운 이용 가능성에 대해 궁금함. 많은 스포츠가 데이터 권리에 대해 매우 보호적임. F1이 이를 어떻게 보는지 궁금함. 어쨌든 이건 정말 훌륭하고, 레이스를 즐기면서 소파에 앉아 두 번째/세 번째 화면으로 사용할 수 있을 것 같음. 기여할 방법을 찾으면 그렇게 할 것임
     * 축하함. 잘 작성된 README로, 이 프로젝트에 대한 세심한 배려가 드러남
     * 훌륭한 작업임. 타이어 전략 페이지를 통해 페라리가 드라이버를 위한 전략을 어떻게 실수했는지 볼 수 있음
     * 매력적으로 보임. 아쉽게도 dotnet 도구 방법(Win10)을 사용한 빠른 설치는 오류 없이 설치되지만, 앱 실행 시 응답이 없는 창이 나타남. 로그에는 오류가 없음. 키 명령이 작동하지 않음(Q도 아님). 데이터 가져오기는 작동하지만 응답 없는 창은 변하지 않음. 기술 지원을 찾는 것은 아니지만 README에 추가 단계가 필요할 수 있음을 알림
     * 정말 멋짐. 몇 주 후에 마이애미 그랑프리에 아내와 함께 갈 예정임. Jeddah 세션/레이스를 위해 이걸 사용해 보는 것이 기대됨
     * dotnet 방법을 사용하여 Windows에 설치했지만 작동하지 않는 것 같음. Quit / Cursor / Session 등의 상단 라인은 나타나지만 키가 아무것도 하지 않음. 현재 진행 중인 세션 동안 테스트해 보고 싶었음
     * 이걸 만들어줘서 고맙음. F1과 TUI를 사랑하는 사람으로서, 방송사가 앞부분을 보고 있을 때 중위권 팀이 무엇을 하고 있는지 더 알고 싶어하는 내 욕구에 완벽할 것임
     * 훌륭해 보임. 그러나 실행을 더 쉽게 할 수 있는 방법이 있으면 좋겠음. Linux용 바이너리는 독립 실행형이 아니며 타사 종속성을 설치해야 함. 정적 바이너리(또는 컨테이너 이미지?)가 있으면 좋겠음
     * 꽤 멋져 보이지만 지연을 제대로 작동시키지 못함. 약 25분 지연으로 예선 세션을 보려고 하는데, 시계는 올바른 시간을 표시하지만 드라이버 시간은 나타나지 않음. 라디오와 레이스 제어 메시지는 현재 상태임. Q1의 모든 레이스 제어 메시지와 라디오 메시지를 볼 수 있음
"
"https://news.hada.io/topic?id=20496","Go의 Layered 설계 방식","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Go의 Layered 설계 방식

     * Go 언어는 패키지 간 순환 참조를 엄격히 금지하기 때문에, 이는 자연스럽게 계층적 설계(layered design) 를 유도함
     * 이 글은 Go 프로젝트를 의무적으로 갖게 되는 계층 구조를 설명하고, 그 위에 별도의 아키텍처를 강제하지 않아도 충분히 유효하다고 주장함
     * 순환 의존이 발생할 경우, 이를 해결하기 위한 구체적이고 실용적인 리팩터링 전략을 단계별로 제시함
     * 각 패키지는 독립적으로 의미 있는 기능 단위를 가지도록 설계되어, 테스트, 유지보수, 마이크로서비스 분리에도 유리함
     * 결과적으로 이 방식은 실제 코드 설계에서 흔히 발생하는 ""바나나를 원했는데 정글을 들고 온다""는 문제를 방지함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Go에서의 레이어드 설계 접근법

  기본 원칙

     * Go는 패키지 간 순환 참조 금지
     * 모든 Go 프로그램의 import 관계는 유향 비순환 그래프(DAG) 를 구성해야 함
     * 이 구조는 선택이 아닌 언어 레벨에서 강제되는 설계 규칙

  패키지 레이어링의 자동 형성

     * 외부 패키지를 제외한 프로젝트 내부 패키지들은 참조 깊이에 따라 자동으로 레이어링 가능
     * 아래 그림처럼 최하단에는 metrics, logging, 공용 자료구조 등 핵심 유틸리티 패키지가 위치
     * 이후 상위 패키지들이 점점 기능을 조합하면서 위로 쌓이는 구조를 형성

  이 설계 방식의 특성

     * 레이어는 계층적 추상화가 아닌 참조 방향성에 기반
     * 하나의 패키지는 다수 하위 레벨 패키지를 참조 가능
     * MVC, 헥사고날 아키텍처 등 기존 설계 방식도 이 구조 위에 ""적용"" 가능함
       → 단, Go의 구조적 제약을 반드시 고려해야 함

순환 참조 해결 전략

   순환 참조 발생 시 아래 순서대로 리팩터링을 시도:

    1. 기능 이동

     * 가장 추천되는 방식
     * 순환을 유발하는 기능을 정확히 분석해, 논리적으로 적절한 위치로 옮김
     * 자주 쓰이진 않지만 개념적 명확성을 가장 많이 향상시킴

    2. 공용 기능을 별도 패키지로 분리

     * 양쪽에서 공통으로 쓰는 타입이나 함수(Username 등)를 제3 패키지로 이동
     * 패키지가 작아 보일지라도 과감히 분리
       → 시간이 지나며 해당 패키지가 커질 가능성이 높음

    3. 상위 조합 패키지 생성

     * 순환하는 두 패키지를 조합하는 제3 패키지를 생성
     * 예: Category, BlogPost 양방향 의존을 상위 패키지로 분리
       → 하위 패키지는 dumb struct로 유지, 실제 기능은 상위 패키지에서 조합

    4. 인터페이스 도입

     * 구조체나 함수가 필요한 메서드만 가진 인터페이스로 의존성 치환
     * 불필요한 의존성 제거 및 테스트 편의성 확보
     * 단, 지나치게 사용하면 오히려 설계가 복잡해질 수 있음

    5. 복사(Copy)

     * 의존 대상이 매우 작을 경우, 간단히 복사해서 사용
     * DRY 위반처럼 보일 수 있지만 실제로는 설계 명확화에 도움되는 경우 많음

    6. 하나의 패키지로 합치기

     * 위 방법이 모두 불가능하면 두 패키지를 병합
     * 너무 큰 패키지가 되지 않는다면 수용 가능
       → 단, 무조건적인 병합은 지양하고 신중히 결정

이 설계 방식의 실용적 장점

     * 각 패키지는 스스로 의미 있는 기능 단위를 가지며 독립 테스트 가능
     * 패키지 내 참조가 제한되어, 전체 코드 이해 없이도 개별 패키지 이해가 가능
     * 의도하지 않은 전체 의존성 연결(=정글 문제)을 피하고, 필요한 것만 사용하는 코드 작성 유도
     * 마이크로서비스 분리 시에도 손쉽게 추출 가능
       → 대부분의 종속성이 명확히 정의되어 있음

결론

     * Go의 패키지 설계 제약은 귀찮은 제약이 아닌 좋은 설계 유도 장치
     * 특별한 아키텍처 없이도 패키지 간 참조 구조만으로도 견고한 설계 구현 가능
     * 순환 참조에 대한 정교한 분석과 리팩터링 전략은 Go뿐만 아니라 타 언어에도 유효

   처음 막 짜서 돌아갈 땐 재밌지만
   테스트 넣기 시작하면서
   그 때 내가 왜 그랬을까 생각 해보게 됩니다.

   ""바나나를 원했는데 정글을 들고옴"" 이란 말 너무 재밌네요.

   스프링 개발할때 가장 힘든것들 중 하나가 의존성 순환이었던거 같아요..
   무한하게 서로 초기화하면서 메모리 누수로 뻗어버리는 그 답답함이란...

        Hacker News 의견

     * 순환 종속성을 허용하지 않는 것은 대규모 프로그램을 구축할 때 훌륭한 설계 선택임
          + 이는 관심사를 적절히 분리하도록 강제함
          + 순환 종속성이 발생하면 설계에 문제가 있는 것이며, 기사는 이를 해결하는 방법을 잘 설명함
          + 가끔 다른 패키지가 재정의하는 함수 포인터를 사용하여 순환 종속성을 해결함
          + Go 컴파일러가 순환 종속성을 만들 때 더 유용한 출력을 제공했으면 좋겠음
          + 현재는 루프에 관련된 모든 패키지 목록을 제공하는데, 이는 꽤 길 수 있으며 일반적으로 문제를 일으킨 것은 마지막으로 변경한 것임
     * 훌륭한 블로그 게시물임
          + 이 웹사이트에는 놀라운 게시물이 많으며, 함수형 프로그래밍에 대해 배우는 것을 좋아한다면 확인해보길 권장함
          + 링크
     * ""세 번째 패키지로 이동"" 조언과 관련된 보너스 기술
          + 많은 모델 구조(SQL, Protobuf, GraphQL 등)를 생성하면 생성된 계층 간의 명확한 방향성을 설정할 수 있음
          + 모든 생성된 코드를 애플리케이션 코드에 ""기본 패키지""로 제공하여 모든 것을 함께 구성함
          + 이 기술 도입 전에는 ""모델이 모델을 순환적으로 가져오는"" 문제가 있었지만, 구조적 추가 계층 도입으로 완전히 사라짐
     * Yourdon 구조적 방법에 관한 책을 읽고 있는 것 같음
     * 패키지가 서로 순환 참조할 수 없음
          + 실제로 Go에서는 go:linkname을 사용하여 가능함
     * 랜덤라이저의 구체 개념을 떠올리게 함
     * Golang의 재미있는 특징은 패키지 수준에서 순환 종속성을 가질 수 없지만, go.mod에서는 가질 수 있음
          + 요약하자면, 그것도 하지 말아야 함
     * Jerf가 패키지를 어떻게 생각하고 순환 종속성을 어떻게 처리하는지에 대한 멋진 설명임
"
"https://news.hada.io/topic?id=20493","OpenAI, 크롬을 인수해 'AI 우선' 경험으로 만들고자 함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  OpenAI, 크롬을 인수해 'AI 우선' 경험으로 만들고자 함

    1. 배경: 구글 반독점 재판

     * 미 법무부는 구글을 검색 독점 업체로 규정했고, 현재는 시정 조치 단계에 있음.
     * 주요 조치 중 하나로 크롬 브라우저 매각이 논의되고 있음.
     * 판사는 회의적인 반응을 보이고 있으나, 법무부는 크롬이 구글의 반경쟁 행위의 핵심이라고 주장.

    2. OpenAI의 관심

     * OpenAI의 ChatGPT 제품 책임자 Nick Turley는 크롬을 인수할 의향이 있다고 재판에서 명확히 발언.
     * OpenAI는 크롬 외에도 구글의 검색 API 접근을 원했으나 거절당함.
     * 구글은 검색 우위를 위협한다는 이유로 OpenAI와의 협업을 거절함.

    3. 브라우저를 원하는 이유

     * OpenAI는 자체 브라우저 개발도 고려 중이며, 구글 크롬 핵심 개발자 2명을 영입함.
     * 크롬은 40억 사용자, 67% 점유율을 보유한 브라우저로, 인수 시 AI 중심 경험(AI-first) 설계 가능.
     * 사용자 브라우징 데이터를 통해 에이전트 AI 모델 학습에 활용할 수 있음.

    4. 향후 가능성 및 논의

     * 크롬을 제3자가 인수할지, 독립회사로 분사할지에 대한 논의는 상대적으로 부족.
     * 구글은 크롬이 단독으로는 생존하기 어렵다고 주장하지만, 법무부는 반대 입장.
     * 만약 매각된다면, OpenAI가 “AI 중심의 웹 브라우징” 시대를 열 수 있음.

   최근 들은 소식 중에 가장 끔찍한 소식이네요.

   perplexity도 브라우저 만든다는 이야기가 있었던거 같은데
   브라우저 대전쟁이 다시 일어나겠네요
   그리고 다시 시작되는 파편화의 악몽...

   파이어폭스도 자립이 안되었는데, 법무부는 무슨 근거로 크롬 자체로 독자 생존이 가능하다고 주장하는지 모르겠군요. 그냥 사용자가 많으니까 가능하다는건가...

   비전문가들은 핵심을 잘 모르는게 문제
   크롬이 대단한게 아니고
   구글이 웹표준을 자리잡게 하길 원했고 그로 인해 크롬이긴 것!
   역사의 결과가 난 후에는 역사는 잊고 결과만 보는 사람들이 많다는게 문제
   구글 손을 떠나면 어차피 크롬은 하락함
   옛날에는 무료봉사로 생태계를 먼저 키우는 기업이 많았음. 그게 이기는 길이었기 때문

   크롬 엄청난 플랫폼이죠. 구글꺼를 빼앗을 수 있을까 과연 ㅋㅋ

   이미 edge에서는 Microsoft 가 자사 LLM과 함께 통합을 시도하고 있어서 딱히 새로운 시도는 아닌데, 굳이 인수까지 갈 필요가 있나요? 개발보다는 모든 Chrome 유저들을 대상으로 서비스를 확장하려는 시도일 뿐 OpenAI가 AI 중심 브라우지을 열 수 있다고 보는건 비약적인데요. 그렇게 치면 Google Gemini로도 가능하죠.

   글쎄요 저는 견해가 다른데요.
   주장하시는바가 'vscode (코파일럿) 가 있는데 cursor 가 무슨 지평을 열 수 있나요?' 와 같은 논리라고 보여집니다.

   단순 브라우저 + AI 만 한다면 말씀하시는 부분이 동의가 됩니다만 그렇다고 edge 가 시장 점유율을 확장하고 있는건 아니지 않습니까?

   저는 OpenAI 가 전혀 다른 기술적 해자를 만들꺼라고 생각합니다. (70% 점유율은 뭘해도..)
   개인적으로 browser-use 만 사용해도 AI + browser 를 정말 사용자 중심적으로 UIUX 를 만들면 엄청난 일이 벌어질 것 같다고 생각했었습니다.

   그런 관점에서의 매수의도 아닐까요?

   아 저는 OpenAI의 미래 비전이나 Browser+AI 의 개선된 혁신을 폄하하려는 의도는 아닙니다.
   제가 말하고 싶은 점은 OpenAI에서 그러한 방향의 시도를 한다면, Chromium 이나 Fireforx 등의 메이저 브라우저들이 공개 되어 있는만큼 개발에 있어 별도의 인수가 필요한 상황이 아니라고 생각을 하고 있어요.

   기술적 해자를 만듬에 있어서 인수가 필수적이 아니라는 점입니다.
   때문에, 인수를 고려한다면 기술적 면 보다는 시장 점유율을 통한 확장이 더 주도적이라고 생각합니다.

   단순히 Chromium 기반의 새로운 브라우저를 내놓는다면 Chorme에서 넘어가지 않는 사용자들에게는 큰 매리트가 없지만, Chrome을 인수하면 브라우저 시장의 70%를 차지하는 사용자들에게 공식적으로 Update를 통해 자사의 AI 모델 서비스를 체험할 수 있게 할 수 있죠. 신규 서비스의 확장 장벽이 획기적으로 줄어듭니다.

   말씀하신 대로 edge가 확장을 하고 있지 않다는 현상도 비슷한 맥락으로 보입니다. 브라우저 시장은 정말 보수적이에요. OpenAI도 이러한 점을 고려해서 Chrome 인수를 고려한다고 생각합니다. 때문에 OpenAI 가 ""AI 주도의 웹브라우징""을 연다는 말이, OpenAI 역량보다는 Chome 시장의 영향이 더 크다고 봅니다.
"
"https://news.hada.io/topic?id=20386","[Vibe Coding 기업 적응기] Part1: v0.dev와 함께한 3주간의 기록","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [Vibe Coding 기업 적응기] Part1: v0.dev와 함께한 3주간의 기록

    1. 배경과 문제의식
       • 기획자 입장에서 새로운 도구에 대한 기대와 충격: Tableau에 이어, 이번에는 **AI 기반 UI 생성 도구인 [v0.dev]**가 팀의 워크플로우에 큰 영향을 줌.
       • 도입 배경은 AI솔루션팀장의 공유로 시작되어, 실장님의 데모, 이후 팀 전체의 관심으로 확산됨.
    2. v0.dev 도입 후 변화
       • 업무 프로세스 혁신:
       기존의 순차적인 프로세스(Figma → 디자인 → 개발)에서 기획자가 직접 인터랙션 가능한 UI 목업을 v0.dev로 제작, 병렬적 협업 가능.
       • 프롬프트 작성 능력 = 기획 역량:
       프롬프트만 잘 써도 고도화된 UI 목업을 생성할 수 있어, 정책서 작성 능력과 글쓰기 역량이 중요해짐.
    3. 실제 사용 사례
       • 통계 리포트 협의 미팅 준비:
       기획자가 정책서 + v0.dev 목업을 준비해 참석자들과 더 깊이 있고 구체적인 피드백을 주고받음.
       • 복잡한 상태 전이 UI도 구현:
       기존 문서화로는 어려웠던 인터랙션을 동작 가능한 형태로 구현, 디자이너와 개발자의 이해도 급상승.
    4. 팀 내 효과
       • 직관적인 이해: 실제 동작하는 UI 덕분에 이해도 상승
       • 구체적 피드백 증가: 추상적 논의 대신 실제 사용 시나리오 중심 피드백
       • 지식 격차 해소: 비기술자도 논의에 적극 참여 가능
    5. 사용 팁 & 주의사항 (정신 건강 지침서)
       • 전체 페이지보다는 기능 단위로 목업 작성
       • 인터랙션은 2~3단계 정도가 한계
       • 프롬프트는 구체적이고 명확하게 작성할 것
       • 삭제보다는 숨김 사용 권장
       • 코드 관리 방식은 처음부터 명시
    6. 결론
       • v0.dev는 뛰어난 AI 도구이지만, 결국 중요한 건 사용하는 사람의 목적과 능력.
       잘 활용하면 대화 중심의 협업, 빠른 피드백 루프, 효율적인 UI 설계가 가능함.
"
"https://news.hada.io/topic?id=20401","당신은 구글이 아닙니다 (You Are Not Google)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   당신은 구글이 아닙니다 (You Are Not Google)

   많은 소프트웨어 엔지니어들은 기술 선택에 있어 이성적이지 못하다. 새로운 기술을 선택할 때 실질적인 필요나 문제 정의 없이, 단순히 구글이나 아마존 등 빅테크 기업들이 사용하는 기술이라는 이유로 따라가는 경우가 많다. 예를 들어, MapReduce나 Hadoop은 대규모 데이터 처리를 위해 탄생했지만, 실제로 그만한 데이터 규모가 없는 기업들이 이를 도입하면서 오히려 불필요한 I/O 비용과 기능 손실을 겪는다. 이는 단순한 ""기술 숭배(cargo cult)"" 현상이다.

   글은 이런 무비판적인 모방을 피하기 위해 UNPHAT이라는 체크리스트를 제시한다:

   Understand – 문제를 충분히 이해하라.

   eNumerate – 다양한 후보를 나열하라.

   Paper – 기술이 근거한 논문이나 백서를 읽어보라.

   Historical context – 개발된 역사적 맥락을 살펴라.

   Advantages – 장단점을 균형 있게 비교하라.

   Think – 이 기술이 정말 문제에 적합한지 스스로 생각하라.

   글에서는 Cassandra, Kafka, SOA(Service-Oriented Architecture) 같은 기술들이 실제 사용 사례와 맞지 않는 상황에서 무비판적으로 도입된 예시들을 제시한다. 가령 Kafka는 초당 수백만 메시지를 처리하는 링크드인을 위해 만들어졌지만, 하루 수십 건의 트랜잭션밖에 없는 작은 기업에서 사용되는 경우가 있다.

   저자는 또한, 구글조차도 MapReduce가 더 이상 적합하지 않다고 판단했을 때 사용을 중단했음을 강조한다. 결국 중요한 건, 기술 자체가 아니라 당신이 풀고자 하는 문제가 무엇인지 정확히 이해하고, 그에 맞는 기술을 선택하는 것이다.

   마지막으로 저자는 Pólya, Hamming, Rich Hickey 등도 같은 메시지를 반복해왔음을 언급하며, 핵심은 단순하다:

   “생각하라. 그리고 진짜 문제를 이해하라.”

   할일이 별로 없으면 쓸데없는 짓들을 하게 되어있죠 ㅎㅎ
   쉬운문제도 어렵게 풀어야 뭔가 했다고 생색낼수도 있고. 쉽게하면 쉬운줄아는 사람들도 많고.. ㅎㅎㅎㅎ

   K8s에도 적용되는 글이라 생각합니다. ""유지보수하기 어렵게 코딩하는 방법"" 책이 생각나네요. ㅎㅎ

   결국 기술들이 풀려고 하는 문제와, 그 기술이 나오게 된 맥락을 이해해야 합니다. 글에 나온 예시로는 다음과 같은 것들이 있죠.
     * Cassandra -> Facebook 서비스의 Database scale 이슈를 해결하기 위한 솔루션
     * Kafka -> Linkedin에서 데이터 처리의 scale 이슈를 해결하기 위한 솔루션

   그것들이 풀려는 문제와 내가 풀려고 하는 문제가 align되냐? 를 잘 살펴봐야 한다고 생각합니다.

   오 공감합니다. 대학생/주니어 분들 멘토링할 때 기술의 역사를 이해해보라는 조언을 드리곤 했던 게 생각나네요.

   한국은 spring cargo cult가 강하죠.

   스프링이 인력 구하기 쉬우니...

   한국 spring은 숭배라기보단..
   정부의 무능력함과 개발자의 귀찮음이 많든 혼종..

   매우 공감합니다. Spring도 결국 문제를 푸는 도구일텐데 말이죠.

   구글 추천에 우연히 떠서 들어왔는데, 이 기사는 너무 Geek 의 관점으로 쓰여진 기사입니다. 사업적 관점에서는 전혀 맞는 이야기가 아닙니다. 왜 그럴까요?
    1. 빅테크가 쓰는 큰 툴은 전문가를 구하기 쉽습니다.
       빅테크에 입사하기 위해서 배우는 분들도 많고, 빅테크가 선택했다고 공부하시는 분이 많습니다. 당연히 이거에 대해 아는 사람을 구하기도 쉽고, 경력자나 전문가를 구하기도 수월합니다. 그러나, 처음 보는 툴이라면 어떨까요? 이걸 집중적으로 판 분이 없는 건 아니겠지만, 이런 사람을 구하기는 빅테크의 툴의 전문가보다 휠씬 어려울 것입니다.
    2. 빅테크가 사용하는 큰 툴은, 레퍼런스나 자료들이 풍부하다
       많은 사람이 사용하는 큰 툴은, 문재 해결을 위한 자료, 구글 검색 결과가 풍부합니다. 대부분의 문제는 다른 사람도 격었던 일일 경우가 대부분이며, 간단한 검색으로 쉽게 문제를 파악할 수 있습니다. 그러나 처음 보는 툴의 문제는 레퍼런스를 찾기가 어렵고, 문제가 발생한다면 원인 파악에 상당한 시간이 소모될 가능성이 높습니다. 이거 다 돈인데 말이죠. 이 문제가 새로 도입한 작은 툴의 문제일까요? 아니면 다른 쪽의 문제를 오해하고 있는 걸까요?

   오히려 빅테크들이 이런 걸 전환하기 쉽습니다. 어마어마한 데이타 처리 규모로 인해, 약간의 I/O 이득이 큰 이득이 될 수도 있는 기업이니까요. 그리고 빅테크들이 채택했다는 이유만으로 공부하려고 하는 분도 많고요. 그러나 중소규모 기업에서는, 상대적으로 작은 데이타 규모로 인해서 약간의 I/O 이득은 그렇게까지 큰 이득이 아닌데, 위의 문제는 매우 심각합니다. 중소규모 기업이 채택한 솔류션을 배우겟다는 사람도 적고요. 그래서 중소규모 기업가라면 Geek처럼 이런 걸 따지는 것보다, 빅테크들의 툴을 따라하는게 오히려 경제적이라는 결론이 나올 경우가 많습니다.

   원문을 읽어보니 2017년에 쓴 글이네요.
   그 이후로 8년이 지났는데 이 내용이 여전히 적용된다는게 놀랍습니다.

   저는 위의 내용에 많이 동의합니다!
   다만 규모가 작은기업에서 오버엔지니어링을 하게되는 경우가 대기업을 목표로 하는 사람들이 작은 기업에서 그런 툴들의 경험을 쌓기 위해서 라고도 봅니다

   물론 대표님은 별로 안좋아하시겠지만요 ㅎㅎ

   대기업의 니즈에 맞춰진 툴을 소규모 기업에서도 그대로 쓰게 되는 이유의 8할은 이게 아닐까요. 그걸 제어해야 하는 게 CTO일 텐데, CTO부터가 대기업으로의 이직을 생각하고 있는 경우가 있으니.

   작게 만든걸 나중에 크게 고치는게 두려워서, 처음부터 크게 만드는 경우가...

   기술은 도구이지 목표가 아님을 가끔 보면 까먹는 사람들이 참 많아 보입니다.
   빅테크에서 검증되었으니, 요즘 많이 사용하니....이런 것들이 기술 선택에 주요 조건이 되는 순간 불필요한 비용 증가가 자연스럽게 따라오더군요.

   브레이그토밍 마인드맵 딥러닝 연구버업 시간이 줄라이 마이덜림 장기저그로 효과이씀
"
"https://news.hada.io/topic?id=20473","내가 제일 좋아하는 프로그래밍 문법, "파이프라이닝"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     내가 제일 좋아하는 프로그래밍 문법, ""파이프라이닝""

     * 파이프라이닝은 프로그래밍 언어에서 코드의 가독성과 유지보수성을 높이는 중요한 기능임
     * 데이터 흐름을 왼쪽에서 오른쪽, 위에서 아래로 자연스럽게 표현할 수 있게 해주는 방식
     * Rust와 같은 언어에서 파이프라이닝은 코드의 흐름을 명확하게 하고, IDE의 자동 완성 기능을 통해 개발 생산성을 높임
     * Haskell, Elm, SQL 등 다양한 언어에서 적용되며, builder 패턴이나 메서드 체이닝도 일종의 파이프라이닝으로 간주
     * 가독성, 편집 편의성, IDE 지원, 버전 관리 도구(diff, blame) 에 모두 긍정적 영향
     * 함수 중첩 방식보다 간결하고 명확한 코드를 작성할 수 있어 협업과 유지보수 측면에서도 유리함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

내가 제일 좋아하는 프로그래밍 문법, 파이프라이닝

  파이프라이닝이란?

     * 이전 값을 전달하여 매개변수 목록에서 하나의 인수를 생략할 수 있는 기능
     * 코드의 가독성을 높이고, 주석을 추가하기 쉽게 만들어 줌
     * 데이터를 중심으로 연속된 처리 작업을 순차적으로 적용하는 문법 스타일
     * 함수형 스타일 코드에서 .map().filter().collect() 같은 메서드 체이닝 형태로 많이 사용됨
     * Rust에서 다음과 같은 코드가 대표적 예시:
data.iter()
    .filter(|w| w.alive)
    .map(|w| w.id)
    .collect()

     * 반대로 모든 함수를 중첩하면 다음처럼 안에서 바깥으로 읽어야 하는 구조가 됨:
collect(map(filter(iter(data), |w| w.alive), |w| w.id))

  왜 파이프라이닝이 좋은가?

     * 1. 가독성과 유지보수성
          + 위에서 아래로 읽기 쉬움 → 사람이 읽는 순서와 동일한 데이터 흐름
          + 각 줄에 주석 달기 쉬움
          + 긴 줄에 괄호 중첩 없이 간결하고 명확
     * 2. 편집 편의성
          + 중간에 .map() 등 새 함수를 한 줄로 쉽게 추가 가능
          + git diff나 git blame에서도 변경사항 추적이 깔끔하게 드러남
     * 3. IDE / LSP 지원
          + . 키를 눌렀을 때 자동완성 목록이 뜨는 구조와 잘 맞음
          + 타입을 명확히 알고 있어야 가능한 정적 분석에 유리
          + 이 기능이 제대로 동작하려면 언어가 정적 타입 기반이어야 함 (e.g. Rust, TypeScript)

  SQL에도 파이프라이닝이?

     * SQL의 중첩 SELECT 쿼리를 파이프라인 스타일로 바꿀 수 있다는 제안 존재
     * 예시:
FROM customer
|> LEFT OUTER JOIN orders ON ...
|> AGGREGATE COUNT(...) GROUP BY ...
|> ORDER BY ...

     * 기존 SQL보다 명확한 흐름, 가독성 향상
     * 단점: SELECT 구문이 위로 빠지면서 반환 타입 파악이 어려울 수 있음 → 해결 가능

  Builder 패턴과의 연계

     * Rust의 Builder::new().option().option().build() 같은 형태는 전형적인 파이프라인 구조
     * 선택적 설정을 메서드로 구성하면서 코드 추적, 변경 관리가 용이

  Haskell의 파이프라이닝 개선

     * Haskell의 $, &, |> 같은 연산자는 함수 합성 대신 파이프라인 사용을 가능하게 함
     * 예시 전후 비교:
-- 기존
checkPalindromes content = unlines $ map (show . isPalindrome) $ lines $ map toLower content

-- 개선
checkPalindromes content =
  content
    & map toLower
    & lines
    & map (show . isPalindrome)
    & unlines

  Rust에서 파이프라이닝의 장점

     * 메서드 체이닝, 타입 추론, trait 기반의 구조적 확장성이 모두 파이프라이닝과 잘 어우러짐
     * Rust는 함수형과 객체지향 문법의 장점만 뽑아낸 듯한 구조로, 파이프라이닝 사용이 가장 자연스러움

  결론

     * 파이프라이닝은 단순한 문법이 아니라 코드 흐름, 편집성, 협업까지 영향을 주는 핵심 기능
     * f(g(h(x))) 같은 중첩 대신 x |> h |> g |> f 구조가 더 인간 친화적
     * 파이프라이닝은 ""한 줄에 하나의 작업""이라는 단순한 규칙 아래, 자연스러운 흐름을 표현할 수 있는 최고의 방법

     “각 파이프 조각은 주요 데이터를 받아 한 가지 작업을 수행한다. 마지막에는 명확한 이름을 붙여주면 그게 가장 이상적인 코드 구조다.”

   https://github.com/tc39/proposal-pipeline-operator

   어떤 텍스트든
   줄바꿈 들여쓰기 가 가독성에 중요한 것과
   비슷한 맥락일 듯요.

   LINQ 최고!

   Gleam도 이것을 지원해서 꽤 깔끔하게 코드 작성이 되더라구요.

   그나저나, 본문에 코드 블럭이 들어가서 그런지, 모바일에서도 데탑 레이아웃으로 니오네요.

   그러고보니 elm도 되네요.

   소량의 데이터와 위의 예시처럼 간단한 수준의 코드에서는 보기도 좋고 나쁠 건 없다고 봅니다.

   하지만 map() 안에 코드가 조금씩 들어가다가 ... 코드가 점점 뚱뚱해지게 만드는 경향이 있고
   언어나 구현 라이브러리에 따라 영향이 있지만, 데이터량이 많아지면 그냥 데이터구조에 데이터를 쌓거나 조작하면서 처리하는 것에 비해 쉽게 수천배 느려지기도 하기 때문에,

   그리고 또 하나 선호하지 않게된 새로운 이유가 생겼는데요, 폰에서 이 기사를 봤더니 PC 수준의 너비가 그대로 유지되면서, 글씨 크기가 눈꼽만하게 작아지는 바람에 기사를 보기가 너무 어렵다는 이유 때문에 T.T

   기본적으로 선호하지 않고, 일부러 저런 식으로 쓰려는 노력은 하지 않습니다.

   js 도 좀 주세요 |> 굽신 굽신

   |> 너무 이뻐요

   내가 제일 싫어하는 문법임
   stacktrace 조금만 꼬여있어도 디버깅 최악

   ㅇㄱㄹㅇ

        Hacker News 의견

     * 작성자는 ""pipelining""이라고 부르지만, 올바른 용어는 ""method chaining""이라고 생각함
          + Bash의 간단한 파이프라인과 비교: 각 구성 요소가 병렬로 실행되며 중간 결과가 스트리밍됨
          + Ruby에서는 각 줄이 순차적으로 처리되며 각 단계 사이에 완전한 배열이 생성됨
          + 디버깅이 어려워져서 요즘은 더 명시적인 코드를 작성함
          + 명시적인 코드는 보기에는 덜 깔끔하지만 중간 상태를 쉽게 검사할 수 있음
     * 개인적으로 언어의 기능 세트를 작게 유지하고 빠르게 완성된 기능 세트를 달성하는 것을 지지함
          + 그러나 Elixir의 |> 문법을 모든 언어가 채택했으면 하는 바람이 있음
     * Lisp 매크로는 체인된 컬렉션 연산자뿐만 아니라 호출 체인의 순서를 결정할 수 있는 일반적인 솔루션을 제공함
          + 예를 들어, (foo (bar (baz x)))를 (-> x baz bar foo)로 작성할 수 있음
          + 추가 인수가 있는 경우에도 처리 가능함
          + 자세한 내용은 Clojure의 스레딩 매크로 가이드 참조
     * 이 용어를 유창한 인터페이스라고 배웠음. 파이프라이닝은 다른 것임
     * 파이프라인 연산자는 부분 적용의 일종으로, 여러 인수를 바인딩하여 새로운 함수를 만들고 그 출력을 다른 함수에 전달할 수 있음
          + 부분 적용은 프로그램 작성에 매우 유용하며, 언젠가 (비-Haskell) 언어들이 이를 프로그램 구성의 기본으로 사용할 것임
     * R의 tidyverse 사용자들은 이미 이를 사용하고 있음
     * 파이프라이닝은 디버깅이 어려움. 예외 처리가 어려워 파이프라인에 분기를 추가해야 함
          + 파이프라인은 행복한 경로를 프로그래밍할 때만 유용함
     * SQL 문법이 불필요하게 복잡함
          + SQL은 이미 연산자 언어지만 역사적 이유로 제약이 많음
          + 새로운 문법을 허용할 거라면 더 간단하게 작성할 수 있음
          + |> 문법은 표현력이 없고 시각적 잡음을 추가함
     * 작성자는 ""의미가 문법을 이긴다""고 주장하지만, 문법 선호에 초점을 맞추고 있음
          + 파이프라이닝은 체인이 길어질수록 디버깅이 어려워짐
          + Python에 대해 비판적이지만 구체적인 이유는 제시하지 않음
          + ""pipelining""의 정의가 명확하지 않음
     * effect-ts는 파이프라인과 명령형 코드를 모두 작성할 수 있게 해줌
          + 파이프라인 작성과 제너레이터 사용에 대한 문서 제공
          + 대부분의 커뮤니티가 명령형 스타일의 제너레이터를 선호하게 되었음
          + 디버깅과 유지보수가 더 쉬운 것으로 보임
"
"https://news.hada.io/topic?id=20380","CVE 재단","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 CVE 재단

     * CVE Foundation이 CVE Program의 장기적인 지속 가능성과 독립성을 보장하기 위해 설립됨
     * CVE Program은 25년 동안 글로벌 사이버 보안 인프라의 중요한 기둥으로 작용해 왔음
     * 미국 정부의 계약 종료로 인해 CVE Program의 독립적인 운영 필요성이 대두됨
     * CVE Foundation은 비영리 단체로서 고품질의 취약점 식별을 지속적으로 제공할 예정임
     * 국제 사이버 보안 커뮤니티에 중요한 기회를 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

CVE Foundation 설립 배경

     * CVE Foundation이 공식적으로 설립되어 CVE Program의 장기적인 지속 가능성과 독립성을 보장하기 위한 기반을 마련함
     * CVE Program은 미국 정부의 자금 지원을 받아 운영되었으나, 단일 정부 후원에 의존하는 구조에 대한 우려가 제기됨

CVE Program의 중요성

     * CVE는 글로벌 사이버 보안 생태계의 핵심 요소로, 보안 전문가들이 일상적으로 사용하는 중요한 자원임
     * CVE 식별자와 데이터는 보안 도구, 권고사항, 위협 인텔리전스 및 대응에 필수적임

CVE Foundation의 역할

     * CVE Foundation은 취약점 관리 생태계에서 단일 실패 지점을 제거하고, CVE Program이 글로벌 신뢰를 받는 커뮤니티 주도 이니셔티브로 남도록 보장함
     * 국제 사이버 보안 커뮤니티에 맞는 거버넌스를 수립할 기회를 제공함

향후 계획

     * CVE Foundation은 구조, 전환 계획 및 커뮤니티 참여 기회에 대한 정보를 제공할 예정임
     * 추가 정보나 문의는 info@thecvefoundation.org로 연락 가능함

        Hacker News 의견

     * CVE 이사회 구성원의 LinkedIn 게시물 링크를 공유하며, 다른 이사회 구성원의 연락처 정보와 방송 플랫폼에서도 관련 정보를 찾을 수 있을 것이라고 언급함
     * 계약이 마지막 순간에 갱신되었다는 수정 사항을 제시함
     * 소프트웨어 산업의 주요 기업들이 공식 컨소시엄을 통해 나서야 할 때라고 생각함
          + 이 모델은 그들이 가장 큰 혜택을 받기 때문에 타당함
          + 대형 기술 회사들은 CVE를 통해 자사 제품을 보호함
          + 그들은 막대한 수익과 전담 보안 팀을 보유하고 있어 CVE 운영을 쉽게 지원할 수 있음
          + 컨소시엄 접근 방식은 책임을 공정하게 분담함
          + 보안은 모두의 문제임
     * 관련 진행 중인 스레드 링크를 공유함
     * 보안 문제이므로 최악의 상황을 가정해야 하며, MITRE가 인수를 확인하지 않는 한 합법적이지 않다고 가정함
     * MITRE의 예산이 궁금하며, CVE 프로그램에 대한 CISA의 자금 지원이 명확히 구분되지 않지만 연간 수천만 달러라는 것을 보았음
     * 시스템 관리에서 소프트웨어 개발로 전환한 이후로 보안 취약점을 적극적으로 모니터링하지 않았으며, 요즘은 고프로파일 취약점에 대한 뉴스를 읽음
          + CVE를 cert보다 더 많이 봄
          + cert의 차이점과 관계가 궁금함
     * 이 상황이 유지된다면 이전보다 더 나은 결과라고 생각함
     * 보도 자료에 정보가 거의 없어서 부정적인 댓글이 많지만, 합법적이라고 믿을 이유가 있어 지지함
     * 이 상황이 합법적이기를 바람
          + 발표에 대응하고 있으며 1년 동안 계획해왔다고 하지만, 마지막 부분이 강하게 계획되었다면 더 일찍 발표했을 것이라고 의심함
          + 노력이 분열될 가능성이 있다고 생각함
          + 모두가 단일 솔루션을 지지한다면 좋겠지만, 이것이 그 솔루션인지 확신하지 못함
          + 미국 기반의 비영리 단체가 최선의 해결책은 아닐 수도 있음
"
"https://news.hada.io/topic?id=20483","서버리스는 사기다: 그냥 컨테이너 쓰세요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         서버리스는 사기다: 그냥 컨테이너 쓰세요

     * 서버리스는 간편해 보이지만 실제로는 복잡성, 제약, 고비용을 유발하는 구조임
     * 컨테이너는 이식성, 상태 유지, 명확한 제어를 제공하며 대부분의 사용 사례에 더 적합함
     * 서버리스는 비용 구조가 불투명하고 예측 불가능하며, 구성 요소 간 불필요한 복잡성을 초래함
     * 서버리스의 확장성과 간편성은 제한적인 사용 사례에만 적합함
     * 실제 운영환경에서는 컨테이너 기반 배포가 단순하고 확장 가능하며 비용 효율적임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Serverless Is a Scam. Just Use a Container.

  서버리스란 무엇인가?

     * 서버리스는 개별 함수 단위로 코드를 배포하여, 클라우드 플랫폼이 실행 및 스케일링을 자동 처리하는 방식임
     * 그러나 실제로는 다음과 같은 문제들이 존재함
          + 실행 시간 제한 (예: AWS Lambda는 15분 제한)
          + 상태 유지 불가 (매 실행마다 초기화)
          + 콜드 스타트 문제
          + 디버깅 불가능한 환경
          + 플랫폼별 설정 및 구성
          + 과도한 YAML 사용
     * 간단해 보이지만, 복잡한 작업에는 부적합

  컨테이너: 단순하고 강력하며, 좋은 의미에서 지루함

     * 컨테이너는 다음과 같은 장점이 있음
          + 빠른 시작
          + 어느 환경에서나 실행 가능
          + 상태 유지 가능 (Docker volume 사용)
          + 실행 시간 제한 없음
          + 디버깅, 로컬 개발, 운영 환경 전환이 자유로움
     * 예시 코드:
       docker run -v my-data:/data my-app
     * 결과적으로 상태를 가진 워크로드를 어디서든 일관되게 실행 가능
     * 벤더 종속성 없음, 숨겨진 비용 없음, 불필요한 구조 변경 없음

  서버리스 가격 책정: 사용자 혼란을 유도함

     * 서버리스 비용은 매우 복잡하게 구성됨
          + 호출당 비용
          + 메모리 사용량
          + 실행 시간
          + 전송된 데이터량
          + 리전별 차등
          + 비밀 키 접근 비용 등
     * 혼란을 주는 용어 예시:
          + Provisioned Concurrency Units
          + GB-seconds
          + Requests Tier 1/2/3
     * 예측 불가능한 과금 구조로 인해 예상치 못한 고지서 발생 가능
     * 비교: $5 VPS는 예측 가능한 정액 요금으로 모든 자원 제어 가능

  “서버리스는 확장 가능하다”에 대한 반론

     * 서버리스는 기술적으로 확장 가능하지만, 실제로 대부분의 앱은 필요 없음
     * 대부분의 애플리케이션이 필요로 하는 것은 다음과 같음
          + 예측성
          + 모니터링 가능성
          + 적절한 자원 제한
          + 개발 및 스테이징 환경
     * 컨테이너 기반에서는 확장도 간단함
       replicas: 5
     * 혹은 로드 밸런서 사용으로 수평 확장 가능

  무상태 설계는 인위적인 문제를 만듦

     * 서버리스는 무조건 무상태 설계를 강요함
          + 캐시, 세션, 임시 파일, 지속 연결 불가
     * 결과적으로 필요한 요소:
          + 외부 데이터베이스
          + 분산 캐시
          + 파일 스토리지
          + 이벤트 버스
          + 상태 머신
     * 결국 “단순한” 서버리스 앱이 6개 이상의 SaaS 종속성을 가지게 됨
     * 반면, 컨테이너에서는 다음이 가능함
          + 메모리 캐시
          + 디스크 쓰기
          + 세션 유지
          + 무제한 실행

  “서버를 관리하고 싶지 않다”에 대한 답변

     * 서버 관리 없이 컨테이너 기반 플랫폼을 사용할 수 있는 방법이 존재함
          + Sliplane, Railway, Coolify 등 플랫폼 사용
          + 단순히 VPS에서 Docker + systemd만으로도 가능
     * Git 기반 배포, 롤백, 로깅, 메트릭 등 운영 편의성 보장
     * 시스템 전체에 대한 이해와 제어 가능

  “서버리스가 더 저렴하다”는 주장에 대한 반론

     * 극히 낮은 호출 빈도에서는 저렴할 수 있음
     * 하지만 아래 상황에서는 비용 급증
          + 트래픽이 일정 이상일 경우
          + 메모리 증가 필요 시
          + 실질적인 연산이 많을 경우
          + 데이터 전송이 많은 경우
     * 서버리스는 플랫폼이 모든 것을 숨기기 때문에 최적화 어려움
     * 반면, 컨테이너는
          + 저렴한 하드웨어에서도 지속 실행 가능
          + 캐시 및 저장소와 병합 가능
          + 벤치마크 및 튜닝이 쉬움
          + 밀리초 단위 요금 없음

  서버리스가 실제로 적합한 경우

     * 다음과 같은 간헐적이고 상태 없는 작업에 적합
          + 이벤트 기반 함수 (예: 이미지 리사이징)
          + 드물게 실행되는 작업이나 웹훅
          + 내부 도구
          + POC
          + 빠른 스케일 업/다운이 필요한 경우
     * 그러나 실제 애플리케이션에서는 한계에 부딪히고,
          + 시간, 비용, 복잡도에서 큰 대가를 치르게 됨

  컨테이너가 더 나은 선택인 이유

     * 컨테이너는 다음을 제공함
          + 이식성
          + 제어력
          + 단순성
          + 투명성
          + 유연성
     * 단일 또는 다중 컨테이너 배포, 스케일링, 상태 유지, 백그라운드 작업, DB 연동 모두 가능
     * 코드를 재작성할 필요 없이 플랫폼 이전도 가능

  요약 (TL;DR)

     * 서버리스는 이론상 멋져 보임
     * 현실에서는:
          + 불투명
          + 고비용
          + 과도한 복잡성
          + 과대홍보

     시작하기 전 스스로에게 물어보라:
     “이걸 그냥 컨테이너로 만들 수 없을까?”

     * 답이 ‘예’라면, 컨테이너로 시작하는 것이 더 나은 선택

  후속 행동 권장

     * 서버리스로 인해 예상치 못한 비용, 비효율적인 워크플로우를 겪은 사례 공유 권장
     * 단순한 문제를 과도하게 복잡하게 만들지 말 것

   애초부터 Severless가 아니고 Serverlease였음.

   ㅋㅋㅋㅋㅋ

   개발 경험이 네이티브에 비해 현저히 떨어지는 게 너무 큰 pain point이고, 소프트웨어 자체가 인프라 제공자에 의존성이 생기니 한번 자리 잡으면 탈출하기가 어려워집니다. 레퍼런스가 확연히 적은 것은 물론이고 관찰 가능성이 너무 떨어집니다.

   클라우드플레어가 그나마 다른 회사들에 비해 서버리스를 잘 해보려는 것 같습니다. 데이터베이스도 서버리스, 키밸류 스토리지도 서버리스, 심지어 메세지 큐도 서버리스가 있고...
   (물론, 이렇게 되다보면 플랫폼에 완전히 종속되고 구속되는 것 같아 거부감이 느껴지기도 합니다)

   그럼에도 불구하고 디버깅, 관찰 가능성 및 개발 경험이 개선되지 않는다면 여전히 제자리 걸음일 것 입니다.

   서버리스 (서버 있음)

   xfaas가 있는데.. cf workers도 있고요. 편향된 글인듯해요.

   gpu 대여할 때 서버리스펑션으로 잠깐 실행하는 걸 생각하고 있었는데요
   컨테이너에서도 그게 될까요

   과거 PHP 웹호스팅 서비스들에서, PHP를 빼고 벤더락 왕창 들어간 JS를 넣으면....
   대표적인 서버리스 FaaS 플랫폼들과 구분하기 힘들 것 같다는 생각을 떨칠수가 없습니다.

   물론 PHP와 JS/TS를 주로 사용하는 똥1믈리에인 저는 만족스럽게 활용하고 있지만,
   그렇다고 많은 사람들이 이걸 맛있다 평가하는 이유는 잘 모르겠네요.

   개인적인 생각으로는 벤더의 서버리스 서비스를 이용하는 건 위험하지만, 컨테이너를 이용해서 회사 자체적으로 서버리스 환경을 제공하는 건 좋은 것 같습니다. 서버리스를 서비스가 아닌 하나의 개념으로 활용하면 좋을 거 같네요.

   한동안 vercel의 Edge rendering을 포기했다는 트윗과 영상[1], serverless server(ㅋㅋㅋ)[2]에 대한 글이 핫했었죠. 그때 나온 글들과 비슷한 견해를 갖고 있는 것 같습니다.

   개인적인 의견이지만, 프론트엔드 개발자 입장에서는 사용자의 요청에 serverless function을 붙이는 것은 아직 먼 이야기라고 생각합니다(만드려는 어플리케이션이 MVP가 아니라면요).

   [1] https://youtu.be/lAGE-k1Zfrg
   [2] https://vercel.com/blog/…
   [2-1] https://bobaekang.com/blog/…

   물론 본 게시물에도 달렸듯이 과도한 어그로용 글인것 같긴 하네요 :(

   컨테이너 기반 환경(ECS Fargate 중심, 쿠버네티스 클러스터)과 서버리스 환경(AWS) 모두 경험한 입장에선 크게 와닿진 않네요.

   컨테이너 기반 환경의 장점이라고 나열한 사항들은, 장점이자 동시에 단점이 될 수도 있는 부분들입니다.

   '직접 제어 가능하고 상태를 가질 수 있다'며 언급한 부분들 모두 관리 포인트가 되어 운영 난이도가 높아진달까요.

   저는 소규모 조직, 전문적인 서버 관리 팀이 없는 조직일수록 서버리스를 강력히 추천하네요.

   아, 비용 계산이 복잡하거나 예상하기 힘들다는 점, 그리고 벤더락 문제는 동의합니다.

   개발경험과 관측가능성을 말씀하시는 분이 계셔서 덧붙이자면,

   초기 통합 환경만 잘 구성해놓으면 컨테이너 기반 못지 않은, 어쩌면 컨테이너 기반보다 더 네이티브에 가까운 개발경험도 가져갈 수 있습니다. (이를 위한 다양한 툴들이 있고요)

   관측가능성이야 딥하게 하겠다면 서버리스나 컨테이너기반이나 똑같이 쉬운 문제가 아닙니다. 로그 중앙 집중화, 각종 매트릭 시각화, APM, cpu/memory 사용률 시각화와 그에 따른 스케일링 전략 세우기 등등...

   그 정도 단계가 아니라면, 클라우드 벤더가 기본적으로 제공하는 매트릭/로그통합이 강력해서 거기서 거기고요.

   어그레시브하게 표현하자면, '서버리스 어느정도까지 제대로 해봤는데?' 묻고 싶네요...😅

   일부 필요한 엔드포인트만 람다에 띄우는 게 낫지 않나 싶기도 한데요. 애초에 저는 서버리스 개발 경험이 없어서 뭐라 말은 못하겠지만, 특수한 몇몇 케이스에는 좋을 것 같아보이긴 해서요.

   이 글을 쓴 회사가 컨테이너 호스팅 플랫폼 회사니까 편향적인 시선에서 글을 쓴게 아닐까요 ㅎㅎ

   전에도 프론트엔드 쪽에서 nextjs(vercel)에 대해 우려하는 netlify (경쟁사) 개발자의 글을 의심하시는 분이 계셨었죠. 댓글을 보면 편향되진 않은것 같습니다.
   저는 프론트엔드 쪽이라... 이쪽과 친하진 않은데 서버리스(서버있음) 이라는 밈은 자주 본거 같긴 합니다 ㅎ

   cloud run ㄱㄱ

   서버리스로 서비스를 운영하는건 잘못된 도구를 선택하는 것.
   서버리스가 필요한 특정 문제들이 있음. 간헐적으로 사용되는 용도로는 적합함.

   서버리스 컨테이너 서비스에도 같은 의견일까여

   기존 서버리스 서비스(lambda같은) 문제들 때문에 aws가 fargate 만들고 더 간단하게 app runner까지 만들었는데 🤔

   심지어 google cloud의 cloud run이라는 scale to zero 의 갓갓 서버리스 컨테이너 서비스도 있는것인디

   위중에서 갠적으로 cloud run이 개발경험이 가장 좋았음다

        Hacker News 의견

     * 서버리스는 초기 작은 프로젝트에는 좋았지만, AWS Lambda는 큰 애플리케이션에서는 유지보수 지옥임 (빌드, 의존성, 디버깅, 배포 느림 등)
          + 그럼에도 2019년에 배포한 Lambda 기반 리액트 웹앱이 아직도 아무 변경 없이 작동 중이라는 점은 인상적임
          + 유지보수 문제는 프레임워크 때문이라는 반론도 있으며, 모듈형 설계와 로컬 개발을 병행하면 대부분 해결 가능
          + Lambda는 종종 런타임 업데이트가 필요하며, 이는 오랫동안 문제 없다가 갑자기 중단되는 형태로 나타날 수 있음
          + 의존성이 적다면 업데이트는 쉽지만, 오래된 런타임에 의존하는 경우 미리 준비하는 것이 중요함
     * 서버리스는 간헐적이고 상태 없는 워크로드에 적합하며, 내부/외부 JSON API에 잘 맞음
          + 하지만 지나친 감성적 서술보다는 서버리스가 전가의 보도가 아님을 명확히 설명했으면 더 좋았을 것이라는 의견
          + 서버리스는 자체 복구력이 좋고, 상태를 갖는 시스템(컨테이너 등)보다 운영 부담이 적음
          + 그럼에도 컨테이너의 개발 모델이 더 낫다는 의견도 있음 — 어디서든 실행 가능하지만, 상태 관리와 확장성에 한계 존재
     * 컨테이너는 본질적으로 상태를 갖지 않으며, 상태를 추가할 수 있을 뿐임
          + 큰 조직에서는 결국 Kubernetes(K8s)가 표준이 되고, 이는 컨테이너의 간결함과는 거리가 있음
          + K8s도 플랫폼 팀이 있다면 단순하게 운영 가능하나, 그런 환경은 드물다는 지적
     * GCP Cloud Run은 저평가된 서버리스 플랫폼으로, 사용 시점 기준으로만 비용을 청구해 경제적임
     * AWS Lambda에서 Postgres 연결이나 bcrypt 사용은 가능하지만, 설정과 실행이 매우 번거로웠다는 피드백 있음
          + 드라이버를 직접 빌드해야 하고, libc 버전 차이로 인한 문제 발생
          + 로컬 테스트 환경도 명확하지 않아 시행착오가 많음
     * 해당 글은 마치 Sliplane을 홍보하는 글처럼 보인다는 지적 있음
          + ""비즈니스 로직을 Lambda에 넣기보단, 클라우드 환경을 프로그래밍하는 용도로 써야 한다""는 의견도 존재
          + 서버리스 덕분에 작은 팀이 큰 규모의 서비스를 운영 가능하지만, 복잡성 문제는 여전히 존재
          + 컨테이너 기술을 배운 사람이 자신의 경쟁력을 높이기 위해 모두에게 컨테이너 사용을 강요하는 것처럼 보인다는 비판도 있음
     * 1세대 서버리스 플랫폼(AWS Lambda 등)은 확장성과 상태 관리에 어려움이 있음
          + 2세대 플랫폼은 컨테이너 기반 서버리스로 진화 중이나, 컨테이너에 상태를 추가하는 건 스케일링 시 큰 문제 유발
          + 예: ""Docker volume 추가로 상태 유지""는 확장성을 고려하지 않은 위험한 조언임
          + 글에서 언급한 “10개 컨테이너로 확장 + 자체 DB 운영” 등의 내용은 현실적으로 불가능하거나 비효율적인 주장으로 평가됨
     * 일부는 이 글을 ""공정한 평가""라고 보지만, 다른 이들은 지나치게 감성적이거나 상업적 의도가 짙다고 판단
"
"https://news.hada.io/topic?id=20479","Bootable 컨테이너 시대, 리눅스 테마 꾸미기의 즐거움","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Bootable 컨테이너 시대, 리눅스 테마 꾸미기의 즐거움

     * bootc와 부팅 가능한 컨테이너 덕분에 테마 변경이 더 안전하고 관리 가능한 방식으로 가능해짐
     * /usr를 컨테이너로 정의하고 롤백 가능하므로 시스템을 쉽게 실험하고 되돌릴 수 있음
     * ostree admin unlock 명령으로 재부팅 없이도 일시적인 커스터마이징이 가능함
     * Blue95 같은 프로젝트는 배포판과 컨테이너의 경계가 모호해진 시대를 반영함
     * 부팅 가능한 컨테이너를 통해 개인의 창의적 표현을 실현할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Linux 테마 커스터마이징의 즐거움

     * 수십 년 동안 다양한 데스크탑 환경과 테마 설정에 관심을 가졌음
          + Xfce, LXQt, Sway 등을 설치하고 패널, 런처, 사운드, 폰트, 테마 등을 사용자화함
          + 초기에는 쉘 스크립트를 사용하다가 Ansible 플레이북으로 발전함
          + /usr 디렉터리를 수정해야 하는 시스템 전역 변경도 포함되었음
     * 하지만, 시간이 지나면서 자주 깨지거나 사라지는 패널, 작동하지 않는 런처 등의 문제로 인해 기본 설정으로 되돌아가는 선택을 하게 되었음
     * GNOME, KDE 같은 현대적인 데스크탑 환경은 이미 잘 만들어져 있어 기본 상태도 충분히 만족스러움
     * 그럼에도 불구하고 커스터마이징 욕구는 사라지지 않았음, 그러던 중 bootc 개념을 접하게 됨

Bootc는 테마 제작자의 놀이터

     * bootc는 Red Hat이 개발한 부팅 가능한 컨테이너 시스템
     * 컨테이너 기반으로 운영체제를 정의하고 배포할 수 있음
FROM quay.io/fedora/fedora-bootc:42
RUN dnf install -y my-custom-theme my-custom-fonts my-custom-panel

     * podman과 bootc 명령어로 이미지 빌드 및 시스템 스위칭 가능:
sudo podman build -f Containerfile -t my-fedora
sudo bootc switch --transport containers-storage localhost/my-fedora:latest

     * /usr는 읽기 전용이며, 컨테이너를 이전 상태로 쉽게 롤백 가능
     * 새로운 테마 아이디어를 실험하는 데 최적화된 방식
     * 실패하거나 마음에 들지 않으면 간단히 이전 상태로 복구 가능

  Development Mode (ostree admin unlock)

     * 재부팅 없이 /usr를 임시 수정할 수 있는 모드
     * 성공 시 Containerfile에 반영, 실패 시 단순 재부팅으로 변경 내용 제거 가능
     * 일반적인 리눅스 환경에서 축적되는 찌꺼기가 거의 생기지 않는 장점 존재

  대체 방법들과의 비교

     * Ansible이나 쉘 스크립트: 재현성과 복구에 한계 있음
     * systemd-sysext: /usr 오버레이 이미지 사용 가능하지만 생태계 미성숙
     * Nix: 학습 비용이 매우 높음

   결론적으로 bootc는 안전성, 유연성, 도구 지원 면에서 가장 강력한 접근법임
   잘못된 변경이 있어도 롤백이 쉬워 /usr를 망가뜨릴 걱정 없음

""배포판""이란 무엇인가?

     * Blue95는 Fedora Xfce 기반의 커스터마이징된 OCI 이미지
     * Hacker News에서 소개되며 ""단순한 테마인데 배포판이 필요한가?"" 라는 질문 제기됨

  배포판의 정의는 흐려짐

     * 기존에는 배포판을 만드는 일이 매우 복잡하고 시간이 많이 드는 일이었음
     * 이제는 Containerfile + CI/CD 파이프라인만으로 유사한 결과를 쉽게 만들 수 있음
     * Blue95는 GitHub Actions로 자동 빌드되어 OCI 레지스트리에 배포됨
     * 단순한 Fedora 베이스 컨테이너를 배포판으로 보는 기준은 모호함

  기존 사례와 비교

     * Bluefin, Bazzite 같은 bootc 기반 프로젝트도 배포판으로 간주되곤 함
     * 실제 사용 경험은 기존 Fedora와는 확연히 다름
     * 기존 정의로는 배포판의 의미를 설명하기 어려워짐
          + ""딱 보면 알지"" 정도의 정성적 기준이 유일한 정의가 될 수 있음

결론

     * 단순히 테마만을 위해 ""배포판""을 만든다는 것이 불필요해 보일 수 있음
     * 하지만 부팅 가능한 컨테이너로 일관된 디자인과 앱 구성을 정의하고,
     * 그것을 직접 만들고 사용할 수 있는 자유는 커다란 기쁨과 성취감을 줌

     지금 이 글을 작성하는 운영체제는 내가 만든 컨테이너에서 부팅된 시스템임
     수많은 개발자의 작업 위에 내가 만든 창의적인 표현이 더해진 결과물이며,
     이 점이 나에게 큰 즐거움을 줌

   bootable 컨테이너가 아직은 잘 이해되지 않네요

        Hacker News 의견

     * 일반적인 컨테이너는 dotfiles 테스트에 매우 유용함
          + 몇 년 전, 시스템을 빠르게 설정하기 위해 https://github.com/nickjj/dotfiles 에 설치 스크립트를 추가했음
          + 공식 Debian 및 Ubuntu 이미지를 사용하여 테스트했음
          + 최근 Arch Linux를 지원하도록 리팩토링했음
          + 전체 테스트를 약 5분 만에 완료할 수 있음
          + 컨테이너는 1초 만에 시작되고, 나머지는 스크립트가 실행됨
          + 시스템을 수정하지 않고도 테스트할 수 있게 해줌
          + Docker는 지난 10년 동안 많은 좋은 것을 가능하게 했음
     * 불변의 Linux와 부팅 가능한 컨테이너의 아이디어를 좋아함
          + 다음 프로젝트는 bazzite로 전환하는 것일 것임
          + 그러나 Containerfile을 보고 공급망의 취약성에 대한 우려가 있음
          + 20개의 다른 copr 저장소를 사용하고 있으며, 버전이 고정되지 않음
          + Debian을 사용하면 패키지에 대한 신뢰가 높음
          + 공급망 위험을 하나의 파일로 패키징하는 것은 위험할 수 있음
          + 다른 사람들도 같은 우려를 가지고 있는지 궁금함
     * 테마에 대한 열정이 왜 더 많지 않은지 궁금함
          + Chicago95와 Garuda의 KDE 테마를 좋아함
          + 다양한 DE의 테마를 다운로드할 수 있는 웹사이트가 있지만, 대부분은 조금 불안정함
     * 부팅 가능한 컨테이너에 대해 전혀 몰랐음
          + Blue95는 bootc 사용 맥락에서 더 이해가 됨
          + NsCDE와 같은 예시를 참고할 수 있음
     * Enlightenment를 가지고 놀던 시절이 생각남
          + X11의 가능성을 밀어붙이려 했던 시도였음
          + 아직도 존재한다는 것이 놀라움
     * 부팅 가능한 컨테이너에 대해 흥미로움을 느낌
          + NixOS의 impermanence 모듈과 유사함
     * bootc 프로젝트는 현재 Linux에서 가장 흥미로운 것 중 하나임
          + Debian과 같은 프로젝트가 이를 채택하면 좋겠음
          + 안정성 측면에서 많은 이점을 얻을 수 있음
     * 썸네일 이미지가 나의 전체 상태를 대변함
     * 현대 OS가 무한히 쉽게 테마화될 수 있을 것이라고 기대했지만, 그렇지 않음
          + 완벽한 복고풍 테마와 독창적인 테마가 존재할 것이라고 생각했음
"
"https://news.hada.io/topic?id=20432","Android폰, 이제 3일간 미사용 시 자동 재부팅됨","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Android폰, 이제 3일간 미사용 시 자동 재부팅됨

     * 안드로이드 기기에서 3일간 사용하지 않으면 자동 재시작되는 보안 기능이 새로 도입됨
     * 이 기능은 Google Play Services v25.14 업데이트를 통해 자동 배포됨
     * 재시작 후 초기 잠금 상태(Before First Unlock (BFU))는 데이터 복호화가 불가능해져 보안성이 크게 향상됨
     * 이는 Apple의 유사 기능(Inactivity Reboot) 과 비슷하며, 법 집행기관의 접근을 어렵게 만들 수 있음
     * 업데이트는 사용자 조작 없이 백그라운드에서 적용되며, 대부분의 기기에 곧 자동 반영될 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

안드로이드 기기, 3일 이상 미사용 시 자동 재시작 기능 도입

     * Google은 Play Services v25.14 업데이트를 통해 새로운 보안 기능을 배포 중
     * 핵심 기능: 3일 연속 잠금 상태가 유지되면 기기가 자동 재시작됨
     * 사용자 조작 없이 자동 적용되며, 수일 내로 대부분의 Android 기기에 반영될 예정

기능 목적: 데이터 보호 강화

     * 자동 재시작은 기기를 BFU (Before First Unlock) 상태로 되돌림
          + 이 상태에서는 생체 인증이나 위치 기반 잠금 해제 불가능
          + 암호 또는 PIN으로만 해제 가능
          + 저장된 데이터는 전부 암호화 상태로 유지됨
     * 즉, 기기를 사용하지 않는 동안 무단 접근이나 정보 추출 시도 차단 가능
          + 심지어 전원 연결 중이라도 3일 이상 미사용 시 재시작됨

Apple의 유사 사례와 법 집행 반응

     * Apple은 iOS 18.1부터 비슷한 기능인 Inactivity Reboot를 도입
          + 이 기능으로 인해 일부 법 집행 기관이 보관 중이던 기기의 접근에 실패한 사례 발생
     * 안드로이드 역시 이와 유사한 형태로 보안의 기본 단계를 강화하는 추세에 동참함

Play Services를 통한 배포 전략

     * Android 시스템 업데이트의 느린 배포 문제를 해결하기 위해
          + Google은 핵심 기능들을 Play Services로 이동시켜 백그라운드 자동 업데이트 가능하게 함
     * Play Services는 거의 모든 Android 기기에 설치되어 있으며,
          + Google 인증 기기에서는 사용자 알림 없이 자동으로 기능이 활성화됨

보안성과 통제 사이의 균형

     * Google이 Play Services를 통해 Android 시스템의 많은 부분을 제어함으로써
          + 빠른 보안 패치와 기능 배포가 가능해짐
     * 그러나 이에 대해 Google의 Android에 대한 통제력 강화에 대한 우려의 시각도 존재함
          + 특히 오픈 소스 철학과의 충돌에 대한 비판이 이어지고 있음

        Hacker News 의견

     * 기본 설정으로 제공되는 옵션이 좋지만, 사용자가 원할 경우 이를 비활성화할 수 있는 스위치가 필요함
          + 일부 국가에서는 비밀번호를 입력하지 않거나 공개하지 않는 것이 범죄로 간주될 수 있음
          + 한 남성이 기기를 잠금 해제하지 않아 수년간 감옥에 갇혔던 사례가 있음
     * Google Play Services 업데이트임
          + GrapheneOS 사용자에게는 이미 유사한 기능이 내장되어 있음
          + 링크: https://grapheneos.org/features#auto-reboot
     * Google이 GrapheneOS의 아이디어를 가져와서 하드코딩된 시간으로 반쪽짜리 버전을 출시함
          + GrapheneOS는 수년 전부터 시간 설정이 가능함
     * 오래된 휴대폰을 게스트하우스의 와이파이 용도로 사용 중인데, 보안 카메라와 스마트 잠금장치가 온라인 상태를 유지하는 데 좋지 않음
     * 기능 요청을 한다면, 3일 동안 유휴 상태일 때 다음과 같은 옵션을 원함
          + 재부팅
          + 전원 끄기
          + WIPE (삼중 선택)
     * 개발자가 접근할 수 있는 API가 없어 앱 개발자가 전원 옵션을 스크립트로 만들 수 없음
          + 예를 들어, 사용자가 매일 밤 휴대폰을 재시작하거나 종료하고 싶어함
          + Google Assistant에게 요청해도 휴대폰이 재시작되거나 종료되지 않음
          + Apple과 Android는 휴대폰을 종료하기 어렵게 만들어, 전원 메뉴를 불러오려면 두 번의 키 조작이 필요함
     * 배터리 절약에 도움이 됨
          + 오래된 Motorola G5G가 유휴 상태로 4-5일마다 충전이 필요했음
          + 재시작 후 잠금 해제하지 않으면 10일 이상 충전 상태를 유지함
          + 화면 잠금 해제가 많은 OS 수준의 서비스를 시작하는 데 필요해 배터리를 소모함
          + 새로운 업데이트가 유휴 상태의 휴대폰 배터리를 많이 절약할 것임
     * 새로운 Play Services는 3일로 노출을 제한함
          + 오래된 안드로이드 패치 번호가 결제 단말기와 쇼핑몰 키오스크에 적용되면 추적이 재미있을 것임
          + 전반적으로 좋은 일임
     * Android 도난 방지 기능이 휴대폰을 자주 잠금 상태로 만듦
          + 보통 휴대폰을 잠금 해제하기 전에 들어서 발생함
     * SIM 카드에 PIN이 필요한 경우 어떻게 작동할지 궁금함
          + 재부팅을 인지할 때까지 연락이 되지 않을 것임
"
"https://news.hada.io/topic?id=20506","미국의 사이버 방어 내부 해체","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            미국의 사이버 방어 내부 해체

     * 미국의 사이버 보안 체계가 내부에서부터 무너지고 있음
     * Common Vulnerabilities and Exposures (CVE) 시스템이 거의 사라질 뻔한 상황이 발생함
     * 트럼프 행정부는 미국의 기술 보안 노력을 크게 후퇴시킴
     * 국가 사이버 방어를 약화시키는 중요한 인물들이 해고됨
     * 연방 정부의 사이버 보안 자금이 삭감되어 주 및 지방 정부에 책임이 전가됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

미국 사이버 방어의 위기

     * Common Vulnerabilities and Exposures (CVE) 시스템이 거의 사라질 뻔한 상황이 발생했음
     * CVE는 지난 25년간 모든 보안 취약점을 기록한 주요 데이터베이스로, 보안 팀, 소프트웨어 공급업체, 연구자, 정부가 동일한 참조 시스템을 사용하여 취약점을 논의할 수 있도록 돕는 역할을 함
     * 이 시스템이 없으면 각자가 다른 카탈로그를 사용하거나 아예 카탈로그가 없어, 동일한 문제를 논의하는지 알 수 없고, 방어자들은 문제를 파악하는 데 소중한 시간을 낭비하게 됨
     * CVE를 관리하는 CISA는 직원의 3분의 1 이상이 감축될 위기에 처했고, 직원들은 직무 유지 여부를 결정해야 했음
     * MITRE CVE 계약 연장은 마지막 순간에 결정되었으며, 계약은 2026년 3월에 만료될 예정임

트럼프 행정부의 사이버 보안 정책

     * 트럼프 행정부는 미국 연방 정부의 기술 보안 노력을 여러 차례 후퇴시킴
     * 국가 사이버 인프라를 방어하는 데 중요한 역할을 했던 NSA 및 US Cyber Command의 Timothy D. Haugh 장군이 해고됨
     * 사이버 안전 검토 위원회(CSRB)가 해체되어 주요 사이버 공격에 대한 조사가 중단됨

주 및 지방 정부의 책임 증가

     * 트럼프의 행정 명령에 따라 사이버 보안 준비는 주, 지방, 개인 수준에서 관리되어야 한다고 명시됨
     * 연방 정부의 사이버 보안 관련 보조금 프로그램이 삭감되어 주 및 지방 정부가 충분한 보안 전문가를 고용하기 어려워짐

내부의 적과 데이터 유출

     * DOGE는 민감한 연방 시스템에 접근할 수 있으며, 데이터가 어디론가 복사되어 무단으로 접근할 수 있는 상태가 됨
     * 미국의 외부 사이버 방어가 해체되었을 뿐만 아니라, 개인 시민에 대한 대규모 보안 공격의 위험이 증가함

결론

     * 미국은 자초한 보안 문제로 인해 가장 큰 피해를 입을 것이며, 전 세계가 그 영향을 받을 것임
"
"https://news.hada.io/topic?id=20484","한국의 81,998개 술집을 모두 돌아보는 최단 도보 경로는 178일","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 한국의 81,998개 술집을 모두 돌아보는 최단 도보 경로는 178일

     * 워털루대 윌리엄 쿡 교수가 외판원 문제(TSP)를 한국의 81,998개 술집을 방문하는 최단 경로에 대해 계산한 세계 최초 사례
     * 오픈소스 라우팅 머신(OSRM) 을 이용하여 약 33억 쌍의 도보 시간을 계산하고, 수학적으로 최적임을 증명
     * 계산 결과는 쉬지 않고 걸었을 때 총 15,386,177초, 즉 178일 1시간 56분 17초가 걸림
     * TSP 최적화에는 LKH와 Concorde 도구가 사용되었으며, 절단 평면 방법이 적용됨
     * 이전까지 최다 방문 경로였던 네덜란드 57,912개 경로를 넘어서는 세계 최대 규모의 도로 기반 TSP 해결 사례임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

한국의 모든 술집을 걷는 외판원 문제(Traveling Salesman Problem)

     * 한국에 있는 81,998개 술집을 모두 방문하고 다시 돌아오는 가장 짧은 경로를 계산함
     * 세계 최초로 이처럼 많은 장소를 포함한 TSP 문제를 최적으로 해결
     * 술집 간 총 3,361,795,003쌍에 대한 도보 시간을 OSRM - Open Source Routing Machine 으로 계산
     * 수학적으로 이 경로보다 더 짧은 경로는 존재하지 않음
     * 이 문제는 TSP 문제 중 방문지점 수 기준으로 역대 최대 규모임

최단 경로 소요 시간

     * 계산된 최적 경로를 따라 쉬지 않고 걸으면 총 15,386,177초가 소요됨
     * 이는 178일 1시간 56분 17초에 해당함
     * 실제로는 걷는 동안 쉬거나 마시게 되어 정확히 끝내기는 어려움
     * OSRM 기반 도보 시간으로 단 1초도 더 줄일 수 없는 최적 경로

TSP 역사적 맥락과 기록 경신

     * 이전 최대 기록은 네덜란드 57,912개 지점 자전거 경로였음
     * 이번 korea81998 경로는 그보다 큰 규모의 TSP 문제 해결 사례
     * 계산은 2024년 12월부터 2025년 3월까지 로스킬데 대학교와 워털루 대학교에서 수행
     * 자세한 계산 내용은 별도 계산 페이지에서 확인 가능

경로 시각화 방법

     * 경로는 인터랙티브 지도로 확인 가능하며, 7개 지역별로 나누어 탐색 가능
     * 다양한 시각화 모드(컬러 거리 지도, 회색조 등) 제공
     * 경로의 일부 고해상도 이미지를 별도로 제공하고 있음
     * 도시별 클로즈업 보기는 도시 페이지에서 제공됨

TSP 해결 전략과 오해

     * 일부 미디어에서는 ""22개 도시만으로도 1000년""이 걸린다고 보도하나 이는 모든 경로를 무작위로 시도하는 경우를 의미
     * 실제로는 고급 최적화 기법을 통해 많은 지점도 해결 가능
     * korea81998의 경우 가능한 경로 수는 2 뒤에 0이 367,308개 붙는 수에 달함
     * 해결에는 LKH(Lin-Kernighan Heuristic) 알고리듬 과 Concorde TSP Solver - 절단 평면 방법 이 결합되어 사용됨

절단 평면 방법 개념 요약

     * 선형 계획법을 기반으로 함
     * 도로 사용 여부 대신 연결 정도를 0~1 사이 수치로 표현
     * 단계별 제약조건을 추가하여 가장 짧은 경로를 찾아냄
     * 자세한 설명은 Scientific American과 YouTube 강연에서 확인 가능

P 대 NP 문제

     * TSP 문제는 NP-완전 문제로, P와 NP 문제의 대표적 예시
     * 관련된 흥미로운 논의는 Lance Fortnow 교수의 논문에서 소개됨
     * 이 문제는 컴퓨터 과학의 가장 유명한 미해결 문제 중 하나

수학적 최적화의 의미

     * 이 프로젝트는 범용 최적화 방법의 실험이자 발전을 위한 기반
     * 산업, 상업, 의학, 환경 분야에서의 응용 가능성 높음
     * 수학적 모델링은 유한한 자원을 효과적으로 사용하기 위한 중요한 도구임

연구진 소개

     * William Cook: 캐나다 워털루 대학교
     * Daniel Espinoza: 칠레 Alicanto Labs
     * Marcos Goycoolea: 칠레 Adolfo Ibáñez 대학교
     * Keld Helsgaun: 덴마크 로스킬데 대학교

감사의 말

     * IBM CPLEX Optimizer: 무료 학술 연구용 제공에 감사
     * 지도는 Leaflet, OpenStreetMap, Carto, Stadia Maps를 이용해 제작
     * 엄상일 박사가 한국 경찰청 데이터 기반 술집 위치 데이터 제공
     * 도보 시간 계산은 OSRM 을 활용

다른 나라의 TSP 프로젝트 사례

     * 일본: 편의점 40,426개
     * 영국: 술집 49,687개
     * 미국: 역사적 장소 49,603개
     * 네덜란드: 기념물 57,912개

추가 학습 자료

     * In Pursuit of the Traveling Salesman: TSP의 역사와 응용
     * Traveling Salesman Problem: 절단면법 적용 연구
     * The Golden Ticket: P vs. NP 문제 소개
     * Opt Art: TSP를 이용한 예술적 이미지 생성
     * Approximation Algorithms: TSP 근사 알고리듬에 관한 최신 연구
     * Computational Solutions for TSP Applications: 1994년 출판된 응용 사례 책

     저는 2024년 3월에 대전에 위치한 KAIST에서 TSP 강의를 하기로 예정되어 있었고, 대전 TSP 투어를 위한 지역 데이터 세트를 찾고 있었습니다. 2023년 12월에 엄상일 박사가 ""경찰청에서 만든 전국 술집 데이터 세트가 필요하신가요? 최신 파일은 1,000원이며 90,680개의 항목이 있습니다.""라고 이메일을 보내왔습니다. 와. 1,000원이 1달러보다 작은지 먼저 확인한 후(환율이 반대로 되지 않았는지 확인한 것이 좋았습니다), ""고맙습니다!""라고 답장했습니다.

   https://www.math.uwaterloo.ca/tsp/korea/sk_data.html

   와우 이런 배경이 있었군요. 정리 & 공유 감사합니다

   영문 페이지는 https://www.math.uwaterloo.ca/tsp/korea/index.html 입니다.
   투어는 확실히 비현실적이긴 합니다. 육지에서 제주도나 울릉도로 이동할 때 배로 이동하는 해로를 고려하는 것은 아닌 걸로 보입니다. 이 그림을 보시면 됩니다: https://www.math.uwaterloo.ca/tsp/korea/img/full_line.png

   방문에 드는 예상 시간 계산을 정확히 하는 것이 목적이 아니라 TSP를 현실의 데이터로 풀어냈다는 것에 의미를 두어야겠죠.

   섬과의 이동은 어떻게? 도보로?

   walking and ferry라고 나오는 것을 보니. 배타고 가나 봅니다.

   실시간으로 생기고 폐업하는 경우는 어떻게 하면 좋을까요?

   한국을 대상으로 선정한 이유도 궁금하내요 👀

   1000원에 양질의 데이터를 얻을 수 있다는 점도 한몫했을겁니다 :)

     저는 2024년 3월에 대전에 위치한 KAIST에서 TSP 강의를 하기로 예정되어 있었고, 대전 TSP 투어를 위한 지역 데이터 세트를 찾고 있었습니다.

   아마 한국에 강연을 하기로 했기 때문에 관련 정보를 찾고 있었다고 생각됩낟.

   한국에 술집이 많아서 주제로 잡은건가..
"
"https://news.hada.io/topic?id=20454","Show GN: KRDS: 대한민국 정부 디자인 시스템 MUI 버전","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Show GN: KRDS: 대한민국 정부 디자인 시스템 MUI 버전

  설명

   대한민국 정부 디자인 시스템을 React + MUI 기반으로 확장한 라이브러리를 만들어보았습니다.
     * 💻 스토리북: krds.gracefullight.dev
     * 📦 NPM 패키지: @gracefullight/krds
     * 💾 GitHub: github.com/gracefullight/krds

   공공 프로젝트나 디자인 시스템 관심 있는 분들께 도움이 되길 바랍니다. 😄

  한계점

     * 아직 모든 조합형 컴포넌트가 구현된 건 아닙니다.
     * 아이콘도 추후 제공하려고 합니다. 지금은 @mui/icons-material로 적용해두었습니다.
     * 디자인 토큰도 현재는 정적인 형태라 추론이나 활용에 불편한 부분이 있습니다.

  관심있는 분들께

     * 만들어갈 분들이 계시다면 Organization으로 옮겨 더 체계적으로 관리할 의향도 있습니다.
     * PR이나 이슈 제보는 언제든 환영합니다!
"
"https://news.hada.io/topic?id=20477","Android 16부터 Linux 터미널이 스마트폰 전체 저장공간 사용 가능해짐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Android 16부터 Linux 터미널이 스마트폰 전체 저장공간 사용 가능해짐

     * Android 16의 Linux Terminal 앱이 저장공간 16GB 제한을 해제, 사용 가능한 저장공간을 거의 전부 활용 가능해짐
     * Pixel 기기에서 Debian 기반 가상 머신을 실행, Android 앱과 데스크탑 Linux 앱을 동시에 사용할 수 있음
     * GUI 및 오디오 기능은 아직 미지원, 현재는 개발자나 실험적인 사용에 적합
     * 추후에는 저장공간을 자동 조절하는 “스토리지 벌루닝(ballooning)” 기능도 도입 예정
     * Chrome OS를 Android 기반으로 전환하려는 Google의 장기 전략과 관련됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Android 16: 리눅스 터미널이 스마트폰 전체 저장공간 사용 가능해짐

  Pixel 기기에서의 Linux 사용 경험 확대

     * 2025년 3월 업데이트에서 Google은 Pixel 기기에 Linux Terminal 앱을 도입
     * 이 앱을 통해 Debian 리눅스 가상 머신(VM) 을 구동할 수 있으며, 데스크탑 수준의 앱 실행 가능
     * Android 앱과 Linux 앱을 동시에 사용할 수 있는 멀티 환경 제공

  기존 한계: 16GB 저장공간 제한

     * 초기 버전에서는 VM의 디스크 크기가 16GB로 제한
     * 데스크탑 앱 실행, 파일 저장, 개발 환경 구성에 제약이 있었음

  Android 16 Beta 4에서 제한 해제

     * 최신 베타 4에서는 디스크 크기 슬라이더 제한이 제거됨
     * 최대 용량은 기기의 여유 저장공간에서 1GB를 제외한 전체까지 설정 가능
          + 예: Pixel 9 Pro에서 42.3GB로 디스크 확장 가능함
          + 앱과 디스크 포함 총 45.52GB 사용됨

  향후 계획: 자동 저장공간 조절 (Storage Ballooning)

     * Google은 슬라이더 제거 후 자동 스토리지 조절 기능 도입 예정
          + 풍선처럼 저장공간을 유동적으로 확장/축소하여 사용
          + 장점:
               o 초기 저장소 크기 지정 불필요
               o 시스템 공간 부족 시 자동으로 VM 저장공간 축소

  의미와 전망

     * Linux Terminal은 Chrome OS의 Android화 전환을 위한 핵심 도구로 간주됨
     * 아직은 GUI 앱이나 오디오 기능 미지원으로 실사용은 제한적이나,
     * 향후 업데이트를 통해 전문 개발자, 해커톤, 모바일 서버 운영자 등 다양한 사용 사례가 기대됨

     Google은 이 기능을 Android의 데스크탑 모드를 대체하려는 것이 아니라, Android와 Linux 앱이 공존할 수 있는 환경을 조성하는 데 목적이 있음
     앞으로 Pixel 기기를 활용한 “휴대 가능한 리눅스 데스크탑” 실현이 가능해질 전망

   삼성이 Linux on dex 지원 중단해서 아쉬웠는데
   이젠 구글 자체적으로 시도하는군요.
   굿입니다.

   오오!!! 너무 기대됩니다.

   오.... 좋내요

   터미널을 아예 OS의 일부분으로 넣는 것인가요. Termux 안 써도 되겠네요.
"
"https://news.hada.io/topic?id=20409","감자를 우편으로 보내기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              감자를 우편으로 보내기

     * USPS는 감자를 상자 없이 배송할 수 있음. 코코넛과 마찬가지로
     * 감자에 수신인/발신인 주소를 적고, 무게를 측정하면 그대로 배송할 수 있음

        Hacker News 의견

     * 나는 소포를 좋아함. 어머니가 우체국에서 일하셨음
          + 저렴한 우편 요령: 제2차 세계대전 이후 발행된 대부분의 미국 우표는 가치가 없으며, eBay에서 액면가의 60-75% 가격으로 구매 가능함
          + 독특한 엽서: 얇은 합판에 Sharpie로 주소를 적으면 재미있는 엽서가 됨 (일반 엽서보다 비용이 많이 듦)
          + 소형 정액 박스 물리학: 70파운드 제한을 초과하려면 원시 블랙홀 같은 이국적인 것이 필요함
          + 배달원의 허리를 아끼기 위해: 1982년 이전의 구리 페니 10,000개를 중형 정액 박스에 포장하면 약 68파운드가 됨. 다른 방법으로 동전을 배송하는 것이 좋음
     * 어린 시절 하와이의 가족을 방문했을 때, 가족 마당에서 코코넛을 가져와 Sharpie로 비 오는 포틀랜드 주소를 적어 보냈음
          + 큰 타원형의 매끄러운 표면을 가진 코코넛이었음. 식료품점에서 볼 수 있는 작은 구형이 아님. 주소를 적을 공간이 충분했음
          + 집에 돌아와 큰 실내 화분에 심고 램프를 걸어 거실에서 큰 야자수를 키웠음
     * 이 스레드에 94개의 댓글이 있는데 감자를 보내거나 받은 사람의 댓글이 없다는 것이 이해가 안 됨. 나는 집주인이고 주소가 있음. 감자를 받을 것이며, 원하는 사람에게 보낼 것임. 이 이야기에서 중요한 것은 ""사실인가?""임. 누가 나와 함께 실험할 것인가?
     * Wired의 Return To Sender에 대한 언급이 없다는 것이 놀라움
          + Wired 기사 링크
     * 아내와 나는 캐나다를 가로질러 물건을 우편으로 옮겼음. 앨버타에서 노바스코샤까지. 그때 ""모노테이너""에 대해 알게 되었음. 공통 목적지로 향하는 물건을 채우는 거대한 팔레트형 와이어 박스임. 우리의 상자들은 모두 모노테이너에 들어가 우리가 도착하기 전에 할리팩스에 도착했음
          + 가장 좋은 점: 캐나다 포스트가 우리를 이사시켜줌. 우리가 도착했을 때 모든 것이 새 아파트에 기다리고 있었음
     * USPS는 기본 요구 사항을 충족하면 다양한 특이한 물품을 허용함
          + 감자: 껍질에 직접 주소를 적고 우표를 붙임
          + 코코넛: 하와이 기념품 가게에서 자주 발송됨
          + 벽돌: 우표와 주소만 필요함
          + 부풀린 비치볼: 직접 주소를 적고 소포처럼 발송됨
          + 플라스틱 부활절 달걀: 채우고 테이프로 닫고 라벨을 붙임
          + 플립플롭: 밑창에 주소를 적고 발송함
          + 작은 호박: 건조하고 농업 규칙에 제한되지 않으면 허용됨
          + 살아있는 여왕벌 (수행원 포함): 표면 우편만 가능하며 특별 라벨 필요함
          + 하루 된 병아리: 특별 포장과 타이밍 필요함
     * 벽돌도 가능함
          + 벽돌 발송 관련 링크
     * 노르웨이로 보내지 마세요. 감자 수입에는 특별 허가가 필요함
     * 나는 우편 계약자로 일했으며, 지역 P&DC (모든 지역 우편물이 들어와 분류된 후 다양한 목적지로 발송되는 창고 크기의 건물)에 가야 했음
          + 지역 감독관이 안전과 하지 말아야 할 것들에 대해 강의를 하고 있었음. 나는 듣고 있었고, 눈은 거대한 공간을 둘러보고 있었음. 갑자기 내 눈의 구석에서 상자가 움직이는 것을 봄! 약간 기울어졌고 안에 확실한 움직임이 있었음 (틈이 있었음)! 나는 어린아이처럼 소리쳤음: ""그 상자가 움직였어!""
          + 감독관은 무심코 ""저것들은 우편으로 보내지는 오리들이야""라고 말했음. 나는 매우 놀랐음
     * 감자를 수신자에게, 아마도 익명으로 보내는 여러 서비스가 있음
          + Potato Parcel
          + Mail a Spud
          + Anonymous Potato
          + Mystery Potato (내가 사용한 유일한 서비스는 ""anonymouspotato""임)
"
"https://news.hada.io/topic?id=20489","Atuin Desktop: 실행 가능한 Runbooks","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Atuin Desktop: 실행 가능한 Runbooks

     * Atuin Desktop는 터미널 워크플로우를 실행 가능한 로컬 우선 실행형 런북 편집기로 제공함
     * 스크립트 블록, 임베디드 터미널, 데이터베이스 클라이언트, Prometheus 차트를 한 곳에서 관리할 수 있음
     * 문서의 오래되는 것(부패) 방지와 재사용 가능한 자동화를 통해 워크플로우를 반복 가능하고 신뢰할 수 있게 만듦
     * Atuin Hub를 통해 동기화 및 공유가 가능하며, 실제 셸 기록에서 자동 완성을 지원함
     * 팀 계정과 셸 기록에서 런북 생성 기능을 통해 협업 운영을 강화할 계획임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Atuin Desktop 소개

     * Atuin Desktop은 실행 가능한 런북 편집기로, 실제 터미널 워크플로우를 반복 가능하고 공유 가능하며 신뢰할 수 있게 만듦
     * 문서가 작성 즉시 부패하지 않도록 하고, Jinja 스타일 템플릿을 사용한 동적 런북을 제공함
     * 실제 셸 기록에서 자동 완성을 지원하여 즉각적인 회상이 가능함
     * 로컬 우선, CRDT 기반으로 터미널에서 실행되는 모든 것이 런북에서도 실행됨
     * Atuin Hub를 통해 장치와 팀 간에 최신 상태로 동기화 및 공유 가능함

현재 사용 방법

     * Atuin Desktop을 통해 실제 워크플로우를 실행 중임
          + Atuin CLI 릴리스
          + 환경 간 인프라 안전하게 마이그레이션
          + 스테이징 또는 프로덕션 환경을 자신 있게 설정
          + 실시간 데이터베이스 쿼리 관리 및 협업

향후 계획

     * 팀 계정: 진정한 협업 운영
     * 셸 기록에서 런북 생성: 스스로 작성되는 워크플로우

        Hacker News 의견

     * Emacs에 관심 있는 사람들을 위해 org-babel을 사용하여 비슷한 작업을 할 수 있음
          + 텍스트 파일이 프로그램, 문서, 노트북, 웹사이트 등으로 활용될 수 있음
          + 이는 매우 강력하며 문서화 프로그래밍의 좋은 예시임
          + 관련 자료는 여기에서 확인 가능함: https://osem.seagl.org/conferences/seagl2019/program/proposals/664
     * 약 7년 전에 이 아이디어를 시도했음: https://nurtch.com/
          + 이 아이디어는 많은 가치가 있음
          + JupyterCon Paris 2023에서 관련 발표를 진행했음: https://www.youtube.com/watch?v=TUYY2kHrTzs
          + 문서에 실행 가능한 코드가 포함되면 PR 검토 워크플로우를 문서에도 적용하고 싶어함
          + 이는 위키 편집보다 팀의 더 많은 투자가 필요함
          + 행운을 빔
     * 로컬 우선이라면 이미 부패의 대상임. 모든 것을 컨테이너에서 실행하지 않는 한 로컬은 중요하지 않음
          + 실행북을 기록하고 싶다면 여러 방법으로 가능함. 텍스트 파일, Confluence 문서, 화면 녹화, 셸 스크립트 등
          + 사람들은 이미 그렇게 하지 않으며, UI가 더 화려하다고 해서 갑자기 더 많이 하지는 않을 것임
          + 개인적으로는 시스템을 특정 상태로 만들기 위해 코드(또는 문서)를 작성하고 싶지 않음
          + 수동으로 상태를 만들고 도구를 사용해 상태를 덤프한 후 나중에 도구를 다시 실행해 그 상태를 생성(또는 강제)하고 싶음
          + 컴퓨터가 그 상태에 도달하는 방법을 코드로 작성하고 싶지 않음
          + ""선언적 구성""을 작성하고 싶지 않음. 이는 단지 다른 이름의 코드일 뿐임
          + 수동으로 작업을 수행하고 스냅샷을 찍고 재생하고 싶음
          + 이 작업이 모든 시스템에서 어디서나 작동하기를 원함. 명령을 위한 Bash 셸 모니터링에 의존하지 않고 상태를 덤프하고 나중에 상태를 재적용하기를 원함
     * AWS에 있을 때 우리 팀을 위해 원했던 것이 바로 이것임
          + 자동화하기에는 약간 위험한 운영의 많은 버전이 있음
          + 이를 통해 점진적으로 구축할 수 있는 경로를 제공함
          + 축하함
     * 로컬 Jupyter 노트북과 어떻게 다른지 궁금함
          + .ipynb에서 ! 또는 %를 사용하여 이 작업을 수행할 수 없는지 궁금함
          + 진심으로 묻는 질문임. 이 회사나 CLI 제품에 익숙하지 않음
     * 흥미로워 보임
          + 최근 Jupyter 노트북을 대체하기 위해 marimo.io를 사용하기 시작했음
          + 여러 가지 훌륭한 개선 사항이 있으며, 이 방향으로의 움직임처럼 보임
     * 출시를 축하함
          + Atuin을 조금 따라왔으며, 이 실행북 기능의 대상이 아니지만, 사람들이 재미있는 새로운 것을 만드는 것을 보는 것이 좋음
     * 우리 팀은 polyglot 노트북을 사용했음: https://marketplace.visualstudio.com/items/…
          + C#을 주요 언어로 사용하여 nuget 패키지로 공유된 코드를 사용해 실행북을 가질 수 있었음
          + 이는 프로덕션에서 실행되는 다른 코드처럼 자체 API 및 애플리케이션과 상호 작용할 수 있게 해줌
          + 검토하기에 최상의 경험은 아니었지만 우리에게는 효과적이었음
     * 이는 runme.dev와 매우 유사해 보임: https://runme.dev
     * 이 점을 이해하지 못하겠음. 내가 놓치고 있는 부분을 설명해 줄 수 있는지 궁금함
          + 간단한 셸 스크립트 대신 이것을 왜 사용해야 하는지 궁금함
"
"https://news.hada.io/topic?id=20412","ChatGPT로 사진에서 '역방향 위치 검색'을 실행하는게 유행하고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ChatGPT로 사진에서 '역방향 위치 검색'을 실행하는게 유행하고 있음

     * ChatGPT를 이용한 이미지 기반 위치 추적이 바이럴 트렌드로 확산되고 있음
     * OpenAI의 최신 모델 o3와 o4-mini는 이미지 분석 및 웹 검색 기능을 조합해 높은 정확도의 위치 추론 수행
     * 사용자들은 o3에 레스토랑 메뉴, 거리 풍경, 인물 사진 등을 입력해 ""GeoGuessr"" 게임처럼 위치 유추 시도
     * 프라이버시 침해 우려가 커지며, OpenAI는 안전 장치가 있지만 명확한 방지책 부족
     * OpenAI는 남용 감지 및 대응 시스템 존재를 밝혔지만, 실제 제한은 여전히 부족하다는 지적 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

ChatGPT를 활용한 이미지 기반 역추적 트렌드

     * 최근 사용자들 사이에서 ChatGPT를 통해 이미지 속 위치를 추적하는 트렌드가 확산 중임
     * OpenAI가 출시한 신규 모델 o3와 o4-mini는 이미지 내 시각 정보를 추론할 수 있는 기능이 탑재됨
     * 흐릿하거나 왜곡된 사진도 자르기, 회전, 확대 등의 전처리를 거쳐 분석 가능함
     * 해당 기능은 웹 검색 기능과 결합되어 도시, 랜드마크, 식당, 술집 등의 위치 추론에 탁월한 성능을 보임

GeoGuessr처럼 활용되는 ChatGPT

     * 사용자들은 o3에게 ""GeoGuessr처럼 행동하라""는 요청을 하며 인스타그램 스토리 캡처, 거리 사진, 메뉴판 등으로 위치 추정 시도
          + GeoGuessr 은 사진을 올리고 위치를 찾는 온라인 게임
     * ChatGPT는 이전 대화 기록이나 EXIF 메타데이터 없이도 시각 단서만으로 위치를 유추함
     * 특히 o3는 특정 상황에서 GPT-4o보다 뛰어난 성능을 보였음

     예시: 어두운 바에 걸린 보라색 코뿔소 장식 사진을 보고
          + GPT-4o는 ""영국 펍""이라고 오답
          + o3는 정확히 ""윌리엄스버그의 스피크이지 바""라고 정답 추론

GPT-4o도 놀라운 정확도 보여줌

     * TechCrunch가 진행한 테스트에서는 GPT-4o도 상당히 높은 정확도를 보였으며, 처리 속도는 더 빨랐음
     * 단, 특정 이미지에서는 o3만이 정확히 위치를 알아낸 사례도 있음
     * 그러나 o3도 완벽하진 않으며, 답을 내지 못하거나 엉뚱한 장소를 제시하는 경우도 존재함

잠재적인 프라이버시 침해 우려

     * 아무런 제약 없이 누구나 타인의 사진을 이용해 위치를 추적할 수 있는 점은 큰 문제
     * 예를 들어 인스타그램 스토리를 캡처해 도킹(doxxing) 위험으로 이어질 수 있음
     * 현재 o3와 o4-mini 모델에 대해 OpenAI는 공식 안전 보고서에서 이 문제를 언급하지 않음

OpenAI의 공식 입장

     * 기사 게재 몇 시간 후, OpenAI는 TechCrunch에 다음과 같은 성명을 전달함:

     “o3와 o4-mini는 ChatGPT에 시각적 추론 능력을 추가하며,
     접근성, 연구, 긴급 대응 상황에서 유용하게 사용될 수 있음.
     우리는 민감한 정보 요청을 거절하도록 학습시켰고,
     개인 식별 방지 및 남용 감시 메커니즘을 도입했으며,
     정책 위반 시 적극적으로 대응하고 있음.”
     * 하지만 여전히 위치 역추적 기능에 대한 구체적 차단 기제나 기술적 제어는 부족한 상황

   사실 귀찮은 부분을 컴퓨터가 대신 해주는 것이지 방법 자체는 본래 존재했던 것 아닌가요.

   AI라는게 다 사람이 할 수 있는 일을 하는것이긴하죠. (로봇청소기처럼)

   들어가는 시간과 비용이 수십배 저렴해졌습니다. 분명 이것은 위협이 증대된것입니다.

   본문에 나오듯이 이미 '게임'의 형태로 즐기던 것인 만큼 이전에도 일반인이 접근하기 힘든 수준은 아니었죠.
   위협은 위치를 특정당하면 안 되는 상황에 쉽게 위치를 특정할 수 있는 사진을 올릴 때 생기는 것입니다.

   그 이전에 Hacker News 댓글에도 있듯이 공개된 인터넷에 무언가를 올린다는 것이 이미 정보의 노출을 상정해야 하는 일이고요.

   전반적으로 동의합니다. 하지만 ‘누구나‘ ‘순식간에‘ 할 수 있게 되었다는 점은 꽤 무서운 사이드이펙트들이 생각나긴 하네요

        Hacker News 의견

     * ""좌측 운전 차량, 그러나 교통은 좌측 통행""이라는 추론이 있지만, 사진은 어느 쪽으로 교통이 흐르는지 힌트를 주지 않음
     * ""상점 간판의 언어가 스페인어나 포르투갈어보다는 라틴 알파벳 비즈니스 이름처럼 보임""이라는 의견에 대해 스페인어와 포르투갈어도 라틴 알파벳으로 쓰여짐
     * 거리 사진을 찍고 일부 랜드마크를 제외한 후, 약 500km 정도 오차가 있었으나 많은 것을 정확히 추론함
          + 전체 사진을 사용했을 때, 유명한 섬을 잘못 인식함
          + 구글 이미지의 랜드마크 사진을 사용했을 때도 같은 섬으로 인식함
     * ChatGPT를 넘어서는 기술임을 확신함
          + ChatGPT로 만든 사진을 Midjourney의 ""Describe"" 기능에 입력했을 때, 정확한 위치를 포함한 설명을 생성함
          + 배경의 산 배열이 특정 지역을 나타내는 것으로 보임
     * 새로운 트렌드가 생길 때마다 거부감을 느낌
          + 로마 거리 사진을 보여주었을 때, 정책에 위배된다고 삭제됨
     * 자동차 라디오 시계 설정 방법을 묻자, 정확한 방법과 라디오 모델을 식별함
     * ""새로운 개인정보 위험""에 대한 우려
          + 인터넷 자체가 개인정보 위험을 내포하고 있음
          + 매번 새로운 위험을 강조하는 것은 과도함
     * 지오게서(Geoguessr) 게임에서 위치 추론 기술이 발전할 것임
          + 위성 이미지나 비위성 이미지를 통해 위치를 정확히 파악할 수 있는 기술이 개발될 것임
     * Geoguessr 게임에서 Gemini 2.5로 22k/25k 점수를 얻음
          + 독일 에센과 영국 셰필드에서는 정확했으나, 이탈리아와 러시아에서는 오차가 있었음
          + 단일 이미지로만 추론한 결과임
     * 베트남 다낭시 한강에서 찍은 사진을 분석하여 정확히 위치를 파악함
          + 분석 기술이 있음을 확인함
     * 거리 사진을 통해 도시를 정확히 파악했으나, 구체적인 거리나 이웃은 잘못 추론함
          + Google의 역 이미지 검색이 더 정확한 결과를 제공함
"
"https://news.hada.io/topic?id=20388","[Vibe Coding 기업 적응기] Part3: 바이브를 타며 AI 시대 코딩의 의미 되짚기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [Vibe Coding 기업 적응기] Part3: 바이브를 타며 AI 시대 코딩의 의미 되짚기

   1.바이브 코딩이란?
   •안드레이 카파시의 말처럼, 이제는 직접 코딩이 아니라 “요청”만으로 프로덕트를 만드는 시대가 열림.
   •AI 도구(Cursor, SuperWhisper 등)를 활용해 말로 코딩하고, 차이 확인 없이 코드를 적용하는 방식.
   •겉보기에 게으른 코딩 같지만, 실제로는 초기 탐색에 특화된 전략적 방식

   2.바이브 코딩이 유용한 시점
   •MVP 이전 단계에서, 특히 요구사항이 불확실하고 빠르게 실체를 보여줘야 할 때 유용함.
   •프로토타입을 빠르게 제작해 고객 피드백을 받는 탐색 중심 개발에 적합.

   3.개발자 리소스 부족 문제 해결
   •AI가 ‘초안 코더’ 역할을 하며 개발자의 업무 부담을 줄여줌.
   •간단한 시제품이나 논의용 UI를 빠르게 구현할 수 있어 팀 전체의 생산성 향상.

   4.완벽보다 중요한 것: 적정 품질
   •PMF(Product-Market Fit)를 찾기 위해서는 완벽한 코드보다 “돌아가는 무엇”이 우선.
   •빠른 시제품 제작 → 피드백 수집 → 제품 개선 사이클을 빠르게 돌릴 수 있음.

   5.AI는 실험 + 설계 모두에 기여
   •초기엔 실험용으로, 이후에는 설계 보조(테스트 코드, 아키텍처 시각화 등)로 활용 가능.
   •결국 AI는 페어 프로그래머처럼 작동하며, **“처음엔 vibe, 이후엔 구조화된 설계”**라는 균형이 중요함.

   6.팀 리더에게 주는 조언
   •경계보다는 전략적인 도입 필요.
   •바이브 코딩은 단기적 도구가 아니라 장기적인 생산성 구조 혁신의 일부로 봐야 함.
   • AI는 신입 사원처럼 훈련하고 배치해야 하며, 설계 없는 무계획 진행은 지양해야 함.

   7.결론
   •바이브 코딩은 장난이 아닌 전략 도구다.
   •빠른 피드백과 실험 능력을 가진 팀이 시장에서 살아남는다.
   •**“탐험처럼 시작하고, 전략처럼 운영”**하는 자세가 필요.
"
"https://news.hada.io/topic?id=20497","GTA San Andreas의 20년 된 버그, Windows 11 24H2에서 발견","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            GTA San Andreas의 20년 된 버그, Windows 11 24H2에서 발견

     * GTA San Andreas의 20년 된 버그가 Windows 11 24H2에서 드러남
          + GTA San Andreas에서 Skimmer 비행기가 Windows 11 24H2에서 사라지는 버그가 보고됨
          + SilentPatch를 사용해도 문제 해결이 되지 않음
          + Windows 11 23H2에서는 문제가 발생하지 않음
          + Windows 11 24H2로 업데이트한 사용자들 모두 이 버그를 경험함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

버그 조사

  무엇이 잘못되었는가?

     * SilentPatch 설치 시 게임이 멈추는 문제 발생
     * CPlane::PreRender에서 작은 루프에 갇히는 현상 발견
     * 비행기의 블레이드 속도가 비정상적으로 높게 설정됨
     * 블레이드 속도는 비행기의 고도에 비례하여 계산됨

  왜 그리고 어떻게?

     * Skimmer의 vehicles.ide 정의에서 필요한 매개변수가 누락됨
     * Vice City에서는 Skimmer가 보트로 정의되어 있었음
     * San Andreas에서 비행기로 변경되었으나 필요한 매개변수가 추가되지 않음

  진정한 근본 원인

     * Windows 11 24H2에서 스택 사용 방식이 변경되어 문제가 발생함
     * LeaveCriticalSection이 스택 공간을 더 많이 사용하게 됨
     * 이전에는 fgets와 LeaveCriticalSection이 스택 공간을 덮지 않았으나, 이제는 덮게 됨

  이 문제가 이제서야 발생한 이유

     * Windows 11 24H2의 변경 사항으로 인해 스택 공간이 변경됨
     * 게임이 초기화되지 않은 지역 변수를 사용하여 발생한 문제
     * 다른 플랫폼에서는 이미 수정된 문제였음

게임에서 이 문제를 해결하고 싶다면?

     * 다음 SilentPatch 핫픽스에 코드 수정이 포함될 예정
     * vehicles.ide 파일을 수동으로 수정하여 문제 해결 가능

마지막 말

     * 이 버그는 특정 OS 릴리스와 직접적으로 연결된다는 점에서 흥미로움
     * 스택 레이아웃의 변경이 호환성에 영향을 미칠 수 있음을 보여줌
     * 입력 데이터를 검증하고 컴파일 경고를 무시하지 말아야 함

        Hacker News 의견

     * Raymond Chen의 작업을 기대할 만한 내용임. 이는 매우 높은 칭찬임
     * 문제의 원인을 더 깊이 추적한 것이 기쁨
     * 개인적인 의견으로, 계약의 일부가 아닌 것은 무작위로 처리해야 함. 예를 들어, 언어에서 맵의 반복 순서가 보장되지 않는다면, 언어가 이를 무작위로 처리해야 함. 그렇지 않으면 코드가 불안정해짐
     * 컴파일 경고를 무시하지 말아야 함. 이 코드는 원래 코드에서 경고를 발생시켰을 가능성이 높음
     * 여기서 예상할 수 있는 컴파일러 오류는 무엇일까? 아마도 scanf의 반환 값을 확인하지 않아 매개변수 수와 일치하는지 확인하지 않는 것일 수 있음. 그렇지 않으면 컴파일러가 알 수 없는 데이터 파일 오류처럼 보임
     * 기술적인 글을 읽는 것을 항상 즐김. AI 시대에 이런 글이 얼마나 더 희귀해질지 궁금함
     * Windows의 중요한 섹션 잠금/해제 구현에서 무엇이 변경되었는지 궁금함
     * 접근 문제를 겪는 사람들을 위한 링크 제공
     * 스택을 넘어 읽고 쓰는 것이 항상 너무 쉬웠음. 이는 단순히 실패해야 함
     * 완화 조치가 존재함 - ASLR, NX 페이지, 스택 스매싱 보호 등. 그러나 스택을 넘어선 오래된 데이터를 읽는 것을 완전히 막지는 못함
     * 하드웨어가 스택 영역의 사용되지 않은 부분을 읽거나 쓰지 못하게 한다면 어떨까 하는 생각 실험
     * 스택의 시작 주소 A, 크기 S, 현재 깊이 D를 추적하는 방법 제안
          + CPU에 스택이 주소 A에 크기 S로 존재한다고 알리는 명령 추가
          + 스택에 N 바이트를 예약하는 점프 명령 추가
          + 기존 반환 명령에 스택 인식 기능 추가
          + 현재 깊이를 넘어선 스택 영역에 대한 읽기 또는 쓰기 실패
          + 스택이 아래로 성장하는 아키텍처에서는 산술이 반대로 적용됨
     * 단점으로는 하나의 호출 규약을 고정시키고, CPU 메모리 관리자가 많은 상태를 필요로 함
     * 스택은 어디에나 존재함. 하드웨어 스택 인식은 새로운 완화 조치를 열어줌
     * 이 아이디어가 일반적이지 않은 이유는 무엇일까? 시도된 적이 있을까?
     * 이 모든 발견은 Windows 11 24H2의 문제가 아님을 증명함. 게임이 정의되지 않은 동작에 의존하고 있음
     * 정의되지 않은 동작은 매우 교활하며, 이미 실수를 했음에도 불구하고 옳다고 믿게 만듦
     * C 또는 C++ 프로그램이 정의되지 않은 동작을 유발하면, 프로그램 실행에서 무엇이든 발생할 수 있음
     * 운이 좋으면 프로그램이 적절한 오류 메시지를 표시하거나 충돌하여 문제가 있음을 즉시 알 수 있음
     * 운이 나쁘면 프로그램이 데이터를 조용히 망가뜨리고, 문제를 인식할 때쯤에는 원인이 과거 실행 기록에 묻혀 있음
     * 매우 운이 나쁘면 프로그램이 원하는 대로 작동하다가 관련 없는 코드를 변경하거나 컴파일러 버전, 운영 체제 등을 변경하면 새로운 버그가 나타남
     * 개발자로서 더 나은 방법을 찾기 위한 제안
          + C 또는 C++에서 정의되지 않은 동작을 읽고 이해하며 암기하고, 이를 피해야 함
          + 디버그 모드로 애플리케이션을 컴파일하고 릴리스 모드와 비교하여 차이가 있으면 심각한 문제가 있음
          + 런타임에 정의되지 않은 동작을 잡기 위해 -fsanitize=undefined,address와 같은 도구 사용
          + Java, C#, Python과 같은 관리 언어 사용 권장. 또는 Rust와 같은 안전한 저수준 언어 사용
     * 디버거 사용 권장. 디버거를 사용하지 않는 것의 문제에 대한 이야기를 들음
     * Silent에게 많은 사랑을 보냄. 10년 넘게 내가 좋아하는 게임을 개선해 줌
"
"https://news.hada.io/topic?id=20475","Bluesky의 새로운 인증 형태","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Bluesky의 새로운 인증 형태

     * Bluesky는 소셜 미디어에서 신뢰를 구축하기 위해 새로운 검증 시스템을 도입함
     * 사용자와 조직이 자신의 도메인을 사용자 이름으로 설정하여 검증할 수 있는 기능을 제공함
     * 블루 체크를 통해 눈에 띄는 시각적 신호를 제공하여 계정의 진위 여부를 쉽게 확인할 수 있음
     * 신뢰할 수 있는 검증자 기능을 통해 독립적인 조직이 직접 계정을 검증할 수 있음
     * 초기 단계에서는 직접 검증 신청을 받지 않으며, 기능이 안정화되면 신청 양식을 제공할 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Bluesky의 새로운 검증 형태

     * 신뢰는 소셜 미디어에서 중요한 요소임
     * 2023년에 도메인을 사용자 이름으로 설정하여 검증하는 첫 번째 레이어를 도입함
     * 27만 개 이상의 계정이 Bluesky 사용자 이름을 웹사이트에 연결함
     * 사용자들이 더 큰 시각적 신호를 원한다는 피드백을 받음

블루 체크 도입

     * 블루 체크를 통해 진위 여부를 쉽게 확인할 수 있는 새로운 레이어를 도입함
     * Bluesky는 진정성 있고 주목할 만한 계정을 적극적으로 검증하고 이름 옆에 블루 체크를 표시함
     * 신뢰할 수 있는 검증자 기능을 통해 독립적인 조직이 직접 계정을 검증할 수 있음

신뢰할 수 있는 검증자

     * 플랫폼에서 발행하는 블루 체크는 신뢰의 한 형태일 뿐임
     * 신뢰는 관계, 커뮤니티, 공유된 맥락에서 비롯됨
     * 신뢰할 수 있는 검증자는 직접 블루 체크를 발행할 수 있는 조직임
     * 예를 들어, 뉴욕 타임스는 앱 내에서 기자들에게 직접 블루 체크를 발행할 수 있음
     * Bluesky의 모더레이션 팀이 각 검증을 검토하여 진위 여부를 확인함

Bluesky에서 검증 받는 방법

     * 도메인을 사용자 이름으로 설정하여 자체 검증할 수 있음
     * 공식 조직과 개인에게 이를 권장함
     * 초기 단계에서는 직접 검증 신청을 받지 않음
     * 기능이 안정화되면 주목할 만하고 진정성 있는 계정을 위한 신청 양식을 제공할 예정임

Bluesky 채용

     * Bluesky는 소셜 웹을 플랫폼에서 프로토콜로 전환하기 위한 이니셔티브임
     * 개방적이고 분산된 공공 대화를 위한 기술의 대규모 채택을 개발하고 추진하는 팀에 합류할 수 있음

        Hacker News 의견

     * 초기 인증 라운드에서 인증을 받았음
          + 기술적으로는 루트 CA와 비슷하게 작동함
          + 누구나 자신의 PDS에 app.bsky.graph.verification 레코드를 게시하여 다른 사람을 인증할 수 있음
          + Bluesky는 신뢰할 수 있는 계정에서 이를 선택하여 파란 체크로 변환함
          + 브라우저가 루트 CA를 번들로 묶는 것과 유사함
          + Bluesky에서 인증을 받았고, 이는 bsky.app에서 온 것임
          + 내가 아는 사람들을 인증했지만, 이는 steveklabnik.com에서 온 것이라 파란 체크가 없음
          + 이 기능에 대해 100% 확신하지는 않지만, 많은 사용자가 이를 원하고 있음
          + 프로토콜에 포함되어 있어 다행임
          + 어떻게 진행될지 지켜볼 것임
     * Bluesky의 검토 팀이 각 인증을 검토하여 진위 여부를 확인함
          + Bluesky의 내부 문화적 비전과 어떻게 호환되는지 궁금함
          + Twitter에서 파란 체크 기능이 기업 권력 투쟁과 함께 어떻게 변질되는지 보았음
     * 신뢰할 수 있는 검증자 기능을 통해 독립 조직이 계정을 직접 인증할 수 있음
          + 평등한 접근과 특권을 믿는 사람으로서 이는 끔찍함
          + ""신뢰할 수 있는 검증자""를 어떻게 선택하는지 의문임
          + Twitter보다 더 나쁠 수 있음
          + 반향실은 더 악화될 것임
     * 이 점에 대해 확신하지 않음
          + 인간의 ""사회적 신뢰""는 분산되어 태어나며, 신뢰를 중앙 집중화하면 이를 왜곡함
          + 개인이 어떤 검증자를 신뢰할지 결정하는 대신, bsky가 일부를 선택함
          + 이는 단순히 위임된 중앙 집중화된 신뢰임
     * handles.net을 구축하여 조직이 회원의 핸들을 쉽게 관리할 수 있도록 함
          + 도메인 이름을 사용한 신원 확인이 깔끔하고 가치 있다고 생각함
          + 비기술적인 사람들에게 도메인 이름 ""검증""은 오늘날 적절한 해결책이 아님
          + ""신뢰할 수 있는 검증자"" 접근 방식은 그들의 가치와 일치함
          + 이상주의자로서 아쉬움이 있지만, 실용주의자로서 올바른 선택임
          + Bluesky는 그들의 전투를 선택해야 하며, 이는 포기할 수 있는 부분임
     * 많은 댓글이 강력한 중앙 집중화된 검토에 회의적이지만, 가장 강력하고 중앙 집중화된 검토 팀이 있는 포럼에 댓글을 게시하고 있음
          + 약한 검토가 긍정적인 효과를 가져온 사례가 있다면, 이를 보여줄 가치가 있음
          + 그렇지 않으면 강력한 검토에 대한 증거가 결정적임
          + 검토 팀이 악화되지 않도록 하는 방법에 대해 다른 플랫폼이 HN에서 배울 점이 있음
     * Twitter의 비합리적인 인증보다 나은 점이지만, 여전히 완전하지 않음
          + 도메인 검증을 사용한 TLS 인증서 획득과 유사한 등가 인증이 필요함
          + 교차 도메인 검증을 허용하는 프로토콜이 필요함
          + Times는 직원 인증에서 이익을 얻지만, 다른 소셜 미디어 사이트는 이를 꺼릴 수 있음
     * Hamartia: 영웅을 정상으로 이끄는 비극적 결함이 몰락을 초래함
          + BlueSky가 과거의 Twitter로 돌아가려는 것 같음
          + 메시징의 Signal이 될 기회가 있었지만, 또 다른 소셜 미디어 회사가 되려는 것 같음
          + 우리는 진정한 포스트 소셜 미디어 시대에 있음
     * 신뢰 계층 구조의 아이디어가 마음에 듦
          + Bluesky가 NYT를 인증하고, NYT가 모든 기자를 인증함
          + 전체 프로세스를 훨씬 더 확장 가능하게 만듦
     * 이는 반기능처럼 보임
          + Bluesky의 매력은 Twitter와 같은 중앙 권위의 부재임
"
"https://news.hada.io/topic?id=20427","Scorpi - 맥OS용 경량 범용 하이퍼바이저","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Scorpi - 맥OS용 경량 범용 하이퍼바이저

     * QEMU를 대체할 수 있도록 설계된 모던하고 경량화된 범용 하이퍼바이저
     * FreeBSD의 Bhyve를 기반으로 하며, 장치 에뮬레이션 코드가 매우 작고 효율적

주요 특징

     * 모던한 구조: 구형 장치를 배제하고, 대부분 VirtIO 기반 최신 장치만 구현하여 복잡성을 줄임
     * 경량 설계: C 언어로 작성되었으며 Bhyve 기반, 장치 에뮬레이션 최소화로 빠르고 가벼움
     * 범용 사용 가능성: GUI 및 비-GUI(Headless) VM 지원, EFI 부트로더 및 ACPI 지원, Linux 및 Windows VM 구동 가능
     * 모듈화 구조:
          + Scorpi는 API 형태로 다른 서비스에 통합 가능
          + 그래픽, 사용자 인터페이스, 입력 장치 등은 모듈로 분리
          + 네트워킹도 모듈화 가능하여 유연한 확장 가능

플랫폼 지원 현황 및 계획

     * 현재는 Mac ARM64에서 Apple Hypervisor Framework를 이용해 실행됨
     * 향후 다음 플랫폼으로 확장 예정:
          + Linux x86 및 ARM (KVM 기반)
          + RISC-V 포함 다양한 아키텍처

사용 가능한 부트로더

    1. U-Boot

     * 빠르고 간결하지만 ACPI 및 그래픽 미지원
     * 빠른 실행이 필요한 헤드리스 VM에 적합
     * 소스코드

    2. EDK2 UEFI

     * ACPI, 프레임버퍼, 다양한 부팅 장치 드라이버 지원
     * 그래픽 VM이나 다양한 하드웨어 기능이 필요한 경우 적합
     * 소스코드

향후 로드맵

     * 파일 공유, 복사/붙여넣기 지원 등 누락된 기능 추가
     * KVM 기반 Linux 지원 구현
     * Windows용 DirectX 12 디스플레이 드라이버 추가
     * RISC-V 및 기타 아키텍처 지원 확대

   이 기사와는 상관없는 생각이지만, 요즘 많이 쓰는 벡터 임베딩을 사용해서 특정 기사와 연관되어 있는 다른 긱뉴스 기사를 볼 수 있으면 좋겠다는 생각을 종종 합니다.

   저도 그 생각은 했었는데요. 계속 미뤄지네요 ㅠㅠ

   맥오에스용은 아니지만, 역시 경량 하이퍼바이저 소개 기사: Hyperlight - 경량 가상 머신 관리자(VMM) | GeekNews
     * 제 기준으로는 최근에 애플실리콘 맥오에스에서 가상화 관련 자주 언급되는 가상화 솔루션: UTM - iOS 및 macOS를 위한 가상 머신 | GeekNews
          + 애플실리콘의 하이퍼바이저 UTM에 대한 기사: M1에 대한 찬가 | GeekNews
     * GN⁺: 맥에서 리눅스 가상 머신을 실행하는 좋은 방법: Lima | GeekNews
     * Lume - 애플 실리콘 맥을 위한 경량 맥/리눅스 VM 도구 | GeekNews
     * Quickemu: 최적화된 Windows, macOS, Linux 가상 머신을 빠르게 실행 | GeekNews
          + 2024년 1월 기사인데 구형 macOS도 지원, github 이슈를 간단히 봤을 때에는 애플 실리콘 호스트도 지원이 되긴 하는 것 같은데 확실치 않음.
     * 애플실리콘에서의 가상화에 대한 기사: 애플 실리콘 VM들이 왜 이렇게 다른가? | GeekNews
"
"https://news.hada.io/topic?id=20405","Google AI Studio - Starter Apps 사용기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Google AI Studio - Starter Apps 사용기

   (원글에는 시스템 프롬프트, 코드 스니펫과 gif들이 포함되어 있습니다)
     * Google AI Studio가 업데이트되면서 Gemini를 활용한 다양한 미니 앱들(Starter Apps)을 가지고 노는 공간이 추가됨
     * 10+개의 데모를 코드 수정해가며 실행 가능. 내장된 Gemini API Key를 사용하기 때문에 공짜
          + 대신 너무 많이 쓰면 400 에러남. 일일 호출 제한 같은 게 있지 않나 싶음.
          + 다른 계정으로 하면 실행 가능

  추측해보기: 구글이 이 데모들을 왜 공개했을까?

     * 최근 Gemini는 텍스트를 넘어 이미지나 영상도 이해하고 생성하는 멀티모달(multi-modal) 기능과 훌륭한 코딩 능력으로 주목받고 있음.
     * 그러나 대부분은 LLM 챗봇 안에서만 사용되고, 일반인이 API 레벨로 활용하는 일은 많지 않았음
     * 구글은 이런 기능들이 API로도 많이 쓰이면서 돈을 버는 걸 기대하며 이 데모들을 선보인 게 아닐까?
          + 모든 데모가 Gemini의 기능들을 코드 레벨로, 다른 구글 API와 엮어가며 어떻게 웹앱으로 구현하면 되는지 보여주는 쇼케이스이기 때문

  데모 프롬프트 및 코드 분석

   복잡도 높은 거 2개 살펴봄

    Video Toys: 영상 이해하고 설명하기 + 바이브 코딩 예제

     * 유튜브 영상을 Gemini 2.5로 분석하여, 간단한 인터랙티브 교육자료 앱을 바이브 코딩해서 만들어주는 데모
          + ""인터랙티브 웹앱으로 교육 경험을 만드는 데 전문성이 있는 교육학자이면서 프로덕 디자이너""로서 영상을 분석시키고, 그 웹앱의 스펙을 만들고, 그걸 구현함
     * 샘플 영상은 이미 내용을 분석해놔서 교육자료 앱을 바로 실행해볼 수 있음
     * 파일 몇 개로 된 다른 데모 앱과 달리 React로 구성
     * Gemini가 만들어준 바이브 코딩용 스펙과 만들어진 코드를 사용자가 모두 수정할 수 있음
     * 영상을 기반으로 한 서비스, 코드를 생성하는 서비스를 만들려는 분들께 추천

    Maps Planner: 멀티 모드 + 함수 사용 + 구조화된 출력 + 지도 API 예제

     * 지명을 주면 그에 대해 설명해주고, Day Planner Mode를 켜면 하루동안의 여행 계획을 짜주는 데모. 여행에 걸리는 시간도 추산함
     * General Explorer Mode와 Day Planner Mode 2가지를 하나의 시스템 프롬프트로 지원함
          + 유저가 어떤 모드를 선택했는지에 따라 시스템 프롬프트를 미묘하게 바꾸는 게 인상적
     * 지도 데이터를 정확하게 입출력하고, 두 위치 사이의 선을 정확하게 그려주는 함수를 정의하고 Gemini가 호출하게 함
          + MCP를 통해 이루고 싶은 게 이런 확장성일 것
     * 프롬프트도 좋지만 지도 API와 위치 데이터를 다루는 방법도 잘 나와있음. 지도 관련 서비스를 만들려는 분들께 추천

  직접 만들어보기

     * 데모 앱을 복사해서 커스터마이즈 가능. 처음부터 만드는 사람들을 위한 템플릿도 많이 있음
     * Explain Things with Lots of Tiny Cats라는 이미지 생성 데모를 복사해서 내 걸 만들어봄
          + 개념에 대한 설명을 부탁하면 여러 고양이들의 메타포로 일종의 웹툰을 만들어주는 데모
          + 이미지 생성을 계속 하게 만드는 프롬프트(No commentary, just begin your explanation. Keep going until you're done.)와, 그렇게 생성된 이미지를 스트림으로 하나씩 보여주는 코드가 인상적
     * 한글 + 하마 버전으로 바꿔서 하마는 모르는 게 없어요를 만듦
          + 구글 폰트에서 적당한 한글폰트를 가져오고, HTML 코드와 프롬프트를 살짝 수정
     * 내 앱을 공유하는 기능이 있지만 잘 작동하지 않음
          + 모든 관련 파일이 구글 드라이브에 저장되기 때문에, 그냥 구글 드라이브 가서 파일 공유하는 것처럼 하면 됨

  Gemini Cookbook

     * 스타터 앱들은 재미있는 웹앱 예제들이었는데 반해 여기에는 다양한 파이썬 예제들이 나와있음
          + 몇시간 전 공개된 Gemini 2.5 Flash 예제도 있음
     * 생성형 AI 서비스 만드실 분들이 참고하기에 좋음
"
"https://news.hada.io/topic?id=20414","Kagi Assistant, 모든 사용자에게 제공 시작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Kagi Assistant, 모든 사용자에게 제공 시작

     * Kagi Assistant는 모든 사용자에게 제공되며, Kagi Search와 통합되어 사용자의 검색 경험을 향상시킴
     * AI는 검색 관련 문맥에서 보조 역할을 하며, 사용자의 비판적 사고를 대체하지 않음
     * 사용자 맞춤형 어시스턴트를 생성하여 특정 작업에 맞게 활용 가능
     * 개인 정보 보호를 중시하며, 사용자 데이터는 AI 모델 학습에 사용되지 않음
     * 공정 사용 정책을 통해 사용량을 관리하며, 다양한 LLM 모델을 선택할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Kagi Assistant 소개

     * Kagi의 목표는 웹을 인간 중심으로 만드는 것임
     * Kagi Assistant는 Kagi Search와 통합되어 사용자에게 향상된 검색 경험을 제공함
     * 모든 사용자에게 제공되며, 추가 비용 없이 사용할 수 있음
     * 단계적으로 지역별로 제공되며, 미국부터 시작하여 전 세계로 확대 예정임

AI 통합 원칙

     * AI는 검색 관련 문맥에서 보조 역할을 하며, Kagi Search는 독립적으로 기능함
     * AI는 인간성을 증진시키는 방향으로 사용됨
     * Kagi Assistant는 Kagi 검색 결과를 바탕으로 정보와 상호작용하는 새로운 방법을 제공함

Kagi Assistant의 기능

     * 웹 액세스를 활성화하면 Kagi Search 결과에 접근 가능하며, 개인화된 도메인 순위를 존중함
     * 파일 업로드를 지원하여 추가적인 문맥이나 정보를 제공할 수 있음
     * 사용자 맞춤형 어시스턴트를 생성하여 특정 작업에 맞게 활용 가능

개인 정보 보호 및 공정 사용 정책

     * 사용자 개인 정보는 보호되며, AI 모델 학습에 사용되지 않음
     * 공정 사용 정책을 통해 사용량을 관리하며, 대부분의 사용자는 제한에 도달하지 않음
     * 다양한 LLM 모델을 선택할 수 있으며, 사용자의 요구에 맞게 조정 가능함

자주 묻는 질문

     * 작은 모델을 사용하면 더 많은 토큰을 사용할 수 있음
     * Kagi는 AI 모델 제공자로부터 할인 혜택을 받지 않음
     * 공정 사용 정책은 과도한 사용을 방지하기 위해 시행됨
     * 사용량은 Kagi 계획의 금전적 가치에 따라 제한됨
     * 토큰 사용량은 소비 페이지에서 확인 가능함

        Hacker News 의견

     * Kagi의 공정 사용 정책은 AI 모델을 플랜의 가치에 따라 사용할 수 있도록 명시함
     * Kagi를 사용하지 않을 가능성이 크지만, 이러한 이유로 Kagi를 좋아함. 고객으로서의 관계가 투명하게 느껴짐. 다른 소비자 SaaS 제공업체와 달리 ""이것으로 어떻게 돈을 버는가?""라는 질문에 자동으로 답변해 줌
          + 예를 들어, Discord는 최고 수준이지만 영원히 수익성이 없어서 언제든지 무너질 수 있다는 점이 우려됨
     * 직원이 이 글을 본다면 줌을 막지 말아주길 바람. 접근성에 나쁘고, 기사를 덜 유용하게 만듦. 기능을 보여주는 스크린샷이 포함되어 있지만, 휴대폰에서 읽기에는 너무 작고 확대할 수 없음
     * Kagi는 내가 가장 좋아하는 회사 중 하나임. 티셔츠를 사기 위해 전화번호를 제공해야 하는 세상에서 Kagi는 결제 수단 외에는 거의 정보를 요구하지 않아 신선함
     * Kagi 검색은 훌륭하지만, 검색에 월 $5 이상 지불할 의향은 없음. 300번의 검색은 충분하지 않음. Kagi AI에는 관심이 없음. 검색 횟수를 더 추가했다면 다시 가입했을 것임. 월별 제한 대신 속도 제한을 두면 검색 가능 횟수가 줄어들 때 생기는 ""검색 불안""을 방지할 수 있음. 그렇게 하면 다시 돈을 지불할 것임
     * 놀라움. Kagi 유료 사용자로서 거의 모든 결제를 크로스 플랫폼 토큰으로 적용할 수 있는 보너스를 받음. 대단함
          + 대부분의 일상 사용자에게 chatGPT와 Anthropic 구독을 대체할 것임. 대부분의 사용 사례에서 내 키를 클라이언트에 가져오는 것보다 더 나음. 정말 대단함
     * 한 달 전에 Kagi에 가입함
          + 훌륭함
          + BlueSky도 구독 모델을 채택했으면 좋겠음. 광고나 지속 가능성에 대해 고민할 필요가 없게 됨
          + 또한 회사의 이익이 광고주가 아닌 사용자와 더 밀접하게 일치하게 됨
     * 어떻게 작동하는지 궁금함. Assistant에 접근하려고 하면 도움말 페이지로 이동함
     * 훌륭한 거래임. Kagi로 전환하는 것은 원래의 Google 검색을 다시 얻는 것과 같음. 얼마나 좋은지 놀라움. DDG를 사용했지만 항상 특정한 것들에 대해 Google로 돌아가야 했음
          + 월 $25로 GPT 4o, Sonnet, 기타 모델과 고품질 검색에 접근할 수 있다는 점이 마음에 듦
     * Kagi 플랜을 업그레이드하여 phind.com과 kagi.com 구독을 통합할 수 있는지 확인하고 싶었음. 이제 시도해 보도록 강요받고 있음 :-)
     * 이를 비활성화할 방법이 있는지 궁금함. 엄격한 비 AI 정책이 있음. 사용 가능하다는 것만으로도 문제가 될 수 있으며, 직장에서 Kagi를 사용할 수 없을 수도 있음
"
"https://news.hada.io/topic?id=20487","LLM 기반 프로그래밍은 개발자의 역량을 증폭시키는 `메카 슈트`에 더 가깝다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              LLM 기반 프로그래밍은 개발자의 역량을 증폭시키는 `메카 슈트`에 더 가깝다

     * LLM 도구는 프로그래머를 대체하는 존재가 아닌 개발자의 능력을 증폭시키는 역할을 함
     * Claude Code 사용 경험을 통해 코딩 속도는 획기적으로 빨라졌지만, 여전히 사람의 아키텍트적 판단과 지속적인 감시가 필수적임
     * LLM의 도입으로 실제 코딩보다 문제 정의와 설계가 더 중요한 과제로 부상함
     * AI가 실수를 증폭시키기 때문에, 경험 없는 개발자는 AI의 오류를 눈치채지 못할 위험이 있음
     * 미래의 프로그래밍은 AI와의 협업 능력과 판단력, 삭제의 결단력이 핵심 역량이 될 것임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM 프로그래밍은 인간 대체가 아닌 강화 수단임

     * LLM 기반 프로그래밍 도구는 개발자의 능력을 증폭시키는 메카 슈트와 같음
     * 저자는 최근 Claude Code를 이용해 백엔드 에이전트 플랫폼과 프론트엔드 SaaS 앱을 개발함
     * 총 3만 줄 이상의 코드를 작성하며 LLM의 실질적인 영향을 체험함
     * Claude Code는 사용자를 대체하는 것이 아니라, Ripley의 파워 로더처럼 개발자의 능력을 증폭시키는 도구임
     * 아키텍처 결정, 품질 관리, 방향 설정 등은 여전히 인간이 주도함
     * AI는 속도와 반복 작업에서 유리하지만, 방향을 잘못 잡으면 치명적인 결과로 이어짐

Vigilance: AI 코딩은 끊임없는 주의가 필요함

     * Claude Code는 가끔 이상한 결정을 내리기도 하며, 테스트를 통과시키기 위해 근본 문제를 무시하거나 하드코딩을 함
     * 프레임워크를 무리하게 변경하거나 불필요한 의존성을 추가하는 일도 발생함
     * 파일럿처럼, 중요한 순간에는 사람의 개입이 반드시 필요함
     * 한눈을 판 순간 AI가 잘못된 방향으로 가면서 백엔드 코드를 세 번이나 완전 재작성해야 했음
     * LLM은 코딩 부담을 줄이지만, 감독과 아키텍처 유지에 대한 부담은 커짐

코딩 시간의 경제성 변화

     * 프로그래밍 시간은 전통적으로 왜(목표), 무엇(설계), 어떻게(코딩) 의 세 영역으로 나뉨
     * Claude Code 도입 이후 ""어떻게""에 들어가는 시간은 거의 0에 가까워짐
     * 그러나 ""왜""와 ""무엇""에 대한 사고는 오히려 더 중요해짐
     * 코드를 쉽게 생성할 수 있으므로, 이제는 기존 코드를 과감히 버리고 더 나은 접근을 택할 용기가 필요함
     * 이 결단력은 아직 많은 개발자에게 익숙하지 않으며, 구현 시간보다 설계 판단력이 더 중요한 시대가 됨

경험이 만든 차이

     * AI를 효과적으로 활용하려면 30년 경력의 통찰력과 판단력이 필요함
     * 코드가 작동하더라도 스케일링이나 유지보수에 부적합한 안티패턴을 감지할 수 있는 능력이 중요함
     * 경험 없는 개발자는 AI가 생성한 코드의 문제점을 놓치기 쉽고, 즉각적인 효과에만 만족할 위험이 있음
     * AI가 증폭시키는 것은 능력뿐 아니라 실수도 포함됨, 따라서 판단력이 없는 경우 위험도 커짐

센타우르 효과: 인간과 AI의 협업

     * 체스에서 유래된 ""센타우르 체스""처럼, AI와 인간의 조합이 AI 단독보다 우수한 성과를 냄
     * Claude Code와의 협업도 마찬가지로, 인간이 전략적 방향을 제공하고 AI가 전술적 작업을 처리함
     * ""생각 흐름대로 스펙 작성 → Claude와 함께 정제"" 방식이 가장 효과적이었음
     * Claude는 문맥에 맞는 판단을 하지 못하기 때문에, 항상 사람의 감시와 판단이 필요함

균형 잡기: 위임과 통제의 조율

     * AI를 방치하면 문제를 과도하게 복잡하게 풀려는 시도가 빈번하게 발생함
     * 예: 중복 코드 작성, 잘못된 기술 선택 등 AI의 오작동이 실제로 문제를 일으킴
     * 프론트엔드에서도 JavaScript의 변칙적 구현을 Elixir나 LiveView 방식으로 수정 유도해야 하는 상황이 반복됨
     * 단순하고 반복적인 작업은 위임, 복잡한 판단이 필요한 부분은 직접 개입하는 협업 리듬을 구축해야 함
     * AI 덕분에 빠른 개발은 가능했지만, 사람의 개입 없이는 제대로 작동하지 않았을 것임

미래는 증강임

     * LLM이 프로그래머를 완전히 대체하진 않겠지만, 작업 방식과 필요한 역량을 크게 변화시킴
     * 단순 코딩 능력보다 구조적 사고, 패턴 인식, 기술 판단력이 더 중요해짐
     * AI와 협업할 수 있는 능력 자체가 새로운 기술 역량으로 부상
     * 미래의 성공한 개발자는 AI를 두려워하지 않고, 그 한계와 가능성을 모두 이해하며 다룰 줄 아는 사람일 것임
     * AI는 인간을 제거하려는 것이 아니라, 인간의 가능성을 확장하려는 도구임

   저는 아무로도 아니고 건담을 지급 받지도 못 했습니다만....?

   모빌슈트의 성능차이가 전력의 결정적 차이가 아니란것을..

        Hacker News 의견

코딩보다 더 중요한 것은 문제 이해와 설계

     * 전통적으로 코딩은 세 가지 시간 버킷으로 나뉘어 있음
          + 왜 이 작업을 하는가? 비즈니스 문제와 가치를 이해하는 것
          + 무엇을 해야 하는가? 솔루션을 개념적으로 설계하는 것
          + 어떻게 할 것인가? 실제로 코드를 작성하는 것
     * 마지막 단계는 과거에는 많은 시간을 소비했지만, 이제 Claude 덕분에 거의 시간이 들지 않음
          + 마지막 단계에 많은 시간을 소비한다면 첫 두 단계가 잘못되었거나 도구에 익숙하지 않다는 의미일 수 있음
          + 수작업 코드 편집에는 번거로움이 있지만, 많은 언어에서 IDE와 인덱서를 통해 자동화됨
          + 프로그래밍 프로젝트에서 문제를 이해하는 데 더 많은 시간을 소비했음
     * 즉, 문제 이해와 설계에 더 많은 시간이 소요됨
          + 코딩은 가장 쉬운 단계에 속함
          + 시간이 오래 걸리는 경우는 도구 미숙이나 설계 부족 때문일 수 있음
     * 데이터 구조 설계가 핵심
          + 구조가 잘 잡히면 코딩은 단순한 구현일 뿐임
          + 이 부분은 LLM보다 사람이 우수함

LLM의 한계와 주의점

     * LLM은 종종 잘못된 의사결정을 함
          + 예: 불필요한 의존성 추가, 취약한 코드 생성
          + 사람이 반드시 검토와 수정을 해줘야 함
     * 보안 문제를 스스로 인식하지 못함
          + 예: injection, 잘못된 권한 설정
     * 대규모 코드베이스에서 성능 저하
          + 컨텍스트 윈도우 제한으로 인해 전체 구조 이해에 실패

LLM이 제공하는 생산성 향상

     * 반복적이고 단순한 작업에 매우 효과적
          + boilerplate, 테스트 코드 등에서 시간 절약
     * 계획 단계에서의 활용이 더 효율적
          + system design 초안, 기능 분해 등에서 유용함
     * 낯선 언어나 프레임워크 학습에 탁월
          + 기존 문서보다 빠르게 기본 흐름 파악 가능

경험과 기술적 판단력의 중요성

     * LLM을 잘 쓰기 위해선 경험이 더욱 중요
          + 문제를 구조적으로 판단하고 필터링할 능력이 필요
     * LLM이 코드를 생성해도 검수와 리팩터링은 사람의 몫
          + ""작동""하는 것과 ""옳은"" 것은 다름

LLM은 개발자를 대체하는 게 아니라 보조하는 도구

     * LLM은 주니어 개발자 역할에 가까움
          + 명확한 방향 제시 없이는 엉뚱한 결과를 냄
     * 사람 + LLM 조합이 단독 LLM보다 뛰어남
          + 전략은 사람, 반복 작업은 AI

LLM의 사용 방식에 따라 결과가 달라짐

     * 코드 자동 생성만 의존하면 오히려 속도 저하
          + 특히 익숙한 언어에선 사람이 더 빠름
     * **자동완성 기반의 인터페이스(Copilot 등)**가 가장 자연스러움
          + 흐름을 끊지 않고 도움받기 용이

LLM으로 인한 직무 변화와 우려

     * 코드 작성보다는 설계와 검토가 개발자의 핵심 역할로 이동 중
     * LLM에만 의존하면 학습과 성장 기회 상실
          + 기술적 내공을 쌓지 못하고 수동적인 사용자가 될 위험

LLM의 미래와 사회적 영향

     * 모두가 AI를 사용할 수 있는 환경에선 사람이 차이를 만든다
          + 판단력, 커뮤니케이션 능력이 경쟁력을 좌우
     * LLM은 ""자동차 같은 도구""
          + 강력하지만 의존성이 커지고, 문제 발생 시 대응이 어려움
"
"https://news.hada.io/topic?id=20501","AI 시대의 "말 없는 마차"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            AI 시대의 ""말 없는 마차""

     * AI로 소프트웨어를 만드는 일은 재미있고 생산적인 반면, 대부분의 AI 앱은 기존 방식을 흉내낸 ""말 없는 마차(horseless carriage)"" 처럼 비효율적임
     * Gmail의 AI 이메일 도우미는 지나치게 형식적인 결과를 만들어내며 사용자 맞춤형 경험을 제공하지 못함
     * 진짜 유용한 AI 앱은 사용자가 System Prompt를 수정할 수 있도록 하여 개인화된 에이전트를 만들 수 있게 해야 함
     * AI 시대의 이상적인 앱은 기존 프로그램을 흉내내는 것이 아닌, 사용자의 반복 작업을 줄이고, 자동화를 통해 진정한 생산성을 향상시키는 AI 네이티브 소프트웨어여야 함
     * AI의 진정한 잠재력은 일상 업무 자동화를 통해 사용자가 중요하고 창의적인 일에 집중할 수 있도록 돕는 데 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI로 만든 앱보다, AI를 활용한 소프트웨어 제작이 더 즐거운 이유

     * 최근 흥미로운 사실을 깨달았음: 대부분의 AI 기반 앱을 사용하는 것보다, AI를 사용해 소프트웨어를 직접 제작하는 것이 더 즐겁고 생산적임
     * AI를 개발 도구로 쓸 때는 거의 상상할 수 있는 어떤 것이든 빠르게 만들 수 있는 느낌을 받음
     * 반면 많은 AI 앱은 AI 기능이 얹혀 있기만 할 뿐, 실질적인 효용성이 떨어지거나 오히려 불편함

AI 시대의 ‘말 없는 마차’

     * 현재 많은 AI 앱은 본질적으로 옛날 방식의 소프트웨어 설계를 그대로 따름
     * 이로 인해 LLM과 같은 강력한 모델이 불필요하게 제약받는 구조가 되어버림
     * 이를 ‘AI 시대의 말 없는 마차(horseless carriages)’라고 표현함
          + 자동차 초창기 디자인이 마차의 형식을 그대로 따르다가 비효율적이었던 역사와 유사

잘못 설계된 AI 앱의 사례: Gmail의 AI 어시스턴트

     * Gmail은 최근 Gemini 모델을 이용해 이메일 초안을 생성해주는 기능을 출시함
     * 예시에서는 사용자(필자)가 상사에게 보낼 이메일 초안을 요청함

     Prompt: 상사에게 이메일 초안을 요청

     * Gemini가 생성한 초안은 문법적으로는 완벽하지만, 필자가 실제 작성했을 문체와 전혀 다름
          + 필자의 실제 스타일: ""hey garry, my daughter woke up with the flu so I won't make it in today""
          + Gemini의 결과물은 과도하게 포멀하고 부자연스러움
     * 결과적으로, 직접 이메일을 쓰는 것보다 더 많은 시간이 걸림
     * 필자는 이 기능을 “성과가 부족한 직원을 관리하는 느낌”이라고 표현함
     * 수백만 Gmail 사용자도 이와 비슷한 경험을 했을 가능성이 높고, 그로 인해 AI가 아직 이메일을 잘 못 쓴다고 오해할 수 있음
     * 하지만 문제는 Gemini 모델 자체가 아닌, Gmail 팀의 앱 설계 방식임

더 나은 이메일 어시스턴트의 예시

     * 만약 Gmail이 아래와 같은 방식으로 이메일 어시스턴트를 만들었다면, 훨씬 실용적이었을 것임

  이메일 리딩 에이전트 예시

     * 이 데모는 이메일을 작성하는 것이 아니라, 읽고 처리하는 방식으로 작동함
     * 사용된 도구:
          + labelEmail(label, color, priority) : 이메일에 라벨을 지정
          + archiveEmail() : 이메일을 아카이브 처리
          + draftReply(body) : 회신 초안 작성
     * 받은 편지함 내 이메일들은 다음과 같이 정렬됨:
          + TechCrunch Weekly
          + Gustaf Alströmer - founder intro?
          + HackerNews Digest
          + The Verge Updates
          + Garry Tan - reschedule
          + 등 총 12개
     * 각 이메일은 자동으로 분류 및 우선순위 지정, 일부는 자동 회신 초안 생성 또는 자동 아카이브 처리
     * 사용자가 정의한 System Prompt에 따라 각 이메일이 개별적으로 처리됨
     * 사용자는 직접 System Prompt를 수정하여, 본인의 라벨링 논리를 반영 가능

     이 방식이 훨씬 더 강력하고 직관적이며 생산적인데, 왜 Gmail 팀은 이런 설계를 하지 않았을까?

     * 문제의 핵심: ""전형적이고 일률적인 톤""
          + Gmail의 설계에서 비롯된 가장 큰 문제 중 하나는 전형적이고 개성 없는 문체

AI Slop: 형식적이고 어색한 출력물

     * Gmail의 Gemini가 생성한 이메일 초안은 지나치게 장황하고 형식적이며 필자와 전혀 다른 스타일임
     * 이런 결과물은 오히려 피싱 이메일처럼 보일 수 있음
     * 대부분의 LLM 사용자는 이런 경험을 했으며, 이를 피하기 위해 프롬프트 해킹(prompt hacking) 이라는 전략을 자연스럽게 사용하게 됨
          + 예시 프롬프트:

     ""let my boss garry know that my daughter woke up with the flu and that I won't be able to come in to the office today. Use no more than one line for the entire email body. Make it friendly but really concise. Don't worry about punctuation or capitalization. Sign off with “Pete” or “pete” and not “Best Regards, Pete” and certainly not “Love, Pete”""
     * 결과물의 품질은 좋아지지만, 프롬프트가 지나치게 길어지고 매번 이 과정을 반복해야 한다는 점에서 비효율적임
     * 이 문제의 단순한 해결책: 사용자에게 System Prompt 수정 권한을 부여하는 것

System Prompt와 User Prompt의 구분

     * LLM은 본질적으로 입력된 단어(프롬프트)를 기반으로 다음 단어를 예측하는 시스템임
     * 모든 입출력은 텍스트로 이루어짐
          + 본문에서는 단순화를 위해 텍스트 중심 인터페이스만 다루었으며, 실제로는 음성이나 영상도 입력/출력 가능함
     * OpenAI, Anthropic 등은 이를 단순화하기 위해 프롬프트를 System Prompt와 User Prompt로 분리하는 구조를 채택함
          + System Prompt: 에이전트의 성격과 행동 방식을 정의 (함수에 해당)
          + User Prompt: 사용자로부터의 특정 요청 또는 질문 (입력값에 해당)
          + 모델의 응답: 출력값

     예시:
     * User Prompt: ""Let my boss Garry know that my daughter woke up with the flu this morning and that I won't be able to come in to the office today.""
     * Gmail의 추정 System Prompt:
          + ""You are a helpful email-writing assistant responsible for writing emails on behalf of a Gmail user. Follow the user’s instructions and use a formal, businessy tone and correct punctuation so that it’s obvious the user is smart and serious.""

     * 문제는 Gmail이 이 System Prompt를 공개하지 않으며, 사용자에게 수정 권한도 주지 않는다는 점

Pete의 사용자 정의 System Prompt

     * Gmail이 일률적인 System Prompt 대신, 사용자에게 직접 작성 권한을 부여했다면 다음과 같이 작성했을 것임:

     You're Pete, a 43 year old husband, father, programmer, and YC Partner.
     You're very busy and so is everyone you correspond with, so you do your best to keep your emails as short as possible and to the point. You avoid all unnecessary words and you often omit punctuation or leave misspellings unaddressed because it's not a big deal and you'd rather save the time. You prefer one-line emails.
     Do your best to be kind, and don't be so informal that it comes across as rude.
     * 이와 같은 System Prompt를 기반으로 GPT에게 이메일을 생성시키면 다음과 같은 결과물을 얻을 수 있음:

     Garry, my daughter has the flu. I can't come in today.
     * 이 결과는 짧고, 개인적이며, 실제 사용자 스타일에 부합
     * 가장 큰 장점은 이 System Prompt를 재사용할 수 있다는 점으로, 이후 작성하는 모든 이메일에도 동일한 스타일이 적용됨

사용자 프롬프트 작성의 재미와 가능성

     * LLM을 가르쳐서 나처럼 생각하게 하고, 그 결과를 바로 확인할 수 있는 경험은 매우 직관적이고 즐거움
     * 사용자에게는 자신의 문체를 정의하는 “나만의 System Prompt”를 작성해보는 것을 추천함
          + 예시 User Prompt:

     ""Let my wife know I'll be home from work late and will miss dinner""
     ""Write an email to comcast customer service explaining that they accidentally double billed you last month.""
     * 좋은 결과물이 나오면 설명이 충분했다는 뜻이며, 그렇지 않다면 내용을 더 보완해서 반복
     * 이는 인간을 가르치는 것보다 오히려 빠르고 정직한 피드백 루프를 통해 더 쉬울 수 있음

왜 대부분의 AI 앱은 System Prompt를 노출하지 않는가?

     * 2025년 4월 현재, 대부분의 AI 앱은 System Prompt를 고의로 숨기고 있음
          + 관련 링크: X에서 언급된 의도적인 비공개 설계
     * 필자는 이를 사용자 권한과 개성의 박탈로 보며, 더 나은 결과와 사용 경험을 위해 System Prompt는 반드시 사용자에게 개방되어야 한다고 주장함

Horseless Carriages: 새로운 기술에 대한 구시대적 적용

     * 새로운 기술이 등장하면, 초기 도구들은 종종 기존 방식의 틀을 그대로 모방하며 실패함
     * “말 없는 마차(Horseless Carriage)”는 초기 자동차가 말이 끄는 마차의 디자인을 그대로 따른 사례를 의미함
          + 예: 1803년 Trevithick의 증기 마차 설계
          + 이 디자인은 당시엔 혁신적으로 보였지만, 지금 보면 기본 구조가 자동차에 부적합
     * 당시 사람들은 이런 마차를 타보며 “엔진보다 말이 낫다”고 생각했을 수 있음 → 자동차 등장 전까진 타당한 판단이었음
     * 필자는 현재 AI 앱이 이와 유사한 상황에 있다고 주장함
          + 예: Gmail의 Gemini 기능처럼 구시대적인 UX 설계에 AI를 덧붙인 경우
     * 기존 사고방식은 “말을 엔진으로 바꾸자”는 수준에 머물렀음
          + 지금 AI 앱도 비슷하게 “기존 앱에 AI 기능만 추가”하고 있음

Old World Thinking: 전통적 소프트웨어 설계방식의 한계

     * 기존에는 컴퓨터를 활용하려면 두 가지 방식뿐이었음:
         1. 직접 프로그래밍하기
         2. 다른 사람이 만든 프로그램을 사용하기
     * 프로그래밍은 어렵기 때문에 대부분은 두 번째 방식을 택함
     * 이로 인해 소프트웨어 산업은 개발자와 사용자의 역할을 명확히 구분하는 방식으로 성장함
          + 개발자: 소프트웨어의 일반적 동작을 결정
          + 사용자: 구체적인 입력을 제공
     * LLM의 System/User Prompt 구분은 이 구조를 그대로 반영함
          + System Prompt = 개발자의 몫
          + User Prompt = 사용자의 몫
     * 하지만 이메일은 매우 개인적인 영역이며, AI가 사용자 대신 이메일을 작성한다면 개인의 문체를 반영해야 함
     * 구시대 구조에서는 사용자가 프로그램을 직접 작성하지 않는 이상 개인화가 어려움
     * 그러나 LLM 시대에는 사용자가 직접 System Prompt를 작성할 수 있음
          + 즉, 프로그래밍 없이도 AI의 동작 방식을 설계할 수 있는 시대

사용자에게 사용자의 것을 돌려주자

     * 필자의 주장: LLM이 나를 대신해 행동하는 경우, 그 방식(System Prompt)을 내가 직접 가르쳐야 함
     * 물론 모든 사용자가 직접 Prompt를 처음부터 작성하고 싶어하진 않음
          + Gmail은 사용자의 이메일 이력을 참고해 기본 System Prompt를 생성해줄 수 있음
          + 중요한 건 그 Prompt를 사용자에게 보여주고 수정할 수 있게 해야 한다는 점
     * “프롬프트를 쓸 줄 모르는 사람은 어떡하냐?” → 처음엔 그럴 수 있지만, 대부분 금방 배움
          + ChatGPT의 성공 사례가 이를 입증함
     * 개인적인 에이전트가 아닌 회계, 법률 등의 도메인에서는 어떨까?
          + System Prompt는 해당 분야 전문가가 작성하는 게 맞지만, 전문가 자신도 각자의 문맥에 맞게 수정하고 싶어함
     * 예: YC의 회계팀은 YC에 특화된 방식과 규칙, 소프트웨어 조합을 사용함
          + 일반적인 회계용 AI 에이전트는 YC에서는 전혀 쓸모 없음
     * 거의 모든 회계팀이 자신들만의 방식을 갖고 있으며, 그래서 엑셀과 같은 범용 도구를 선호함
     * 결론: 대부분의 AI 앱에서 System Prompt는 사용자가 직접 작성·유지해야 함

     AI 앱은 완성된 에이전트(agent) 가 아니라, 사용자가 자신의 에이전트를 만들 수 있는 도구(agent builder) 여야 함

개발자에게 개발자의 것을 돌려주자

     * 그렇다면 개발자는 무엇을 해야 할까?
          + 특정 도메인(예: 이메일, 회계장부 등)에 특화된 에이전트 빌더 UI를 설계
          + 사용자들이 프롬프트를 처음부터 작성하지 않아도 되도록 템플릿과 프롬프트 생성 도우미 제공
          + 사용자가 에이전트 결과물을 확인하고 수정할 수 있는 피드백 루프 인터페이스 제공
     * 개발자는 또한 에이전트 도구(agent tools) 를 제공함
          + 이메일 초안 제출, 자동 전송, 이메일 검색, 외부 API 연결 등
     * 이 도구들은 에이전트의 행동 범위와 보안성을 제어하는 수단이 됨
          + 코드로 작성된 도구를 통해 행동을 제한하는 게, 텍스트 프롬프트에서 제약하는 것보다 훨씬 안전하고 명확함

     앞으로는 “프롬프트 주입(prompt injection)”을 우려하는 발상이 웃음거리가 될 수 있음
     → 텍스트 구조에서 경계를 만드는 건 허약한 추상화의 신호
     → 시스템 전체를 사용자 공간으로 인식하고 강력한 도구와 UI로 제어해야 함

이메일을 ""읽는"" 에이전트의 진짜 가치

     * 앞서 말했듯, 더 나은 System Prompt도 이메일 초안을 처음부터 작성하는 데는 큰 시간을 절약해주지 않음
     * 그 이유는 필자가 작성하는 이메일이 원래 매우 짧고 간결하기 때문임
          + 즉, 사용자 프롬프트의 길이 ≒ 이메일 본문 길이
     * 필자는 여러 번 실험을 해봤고, 그 결과 생성형 AI는 텍스트 생성보다는 텍스트 변환에 훨씬 강함을 체감함
     * 그래서 LLM을 활용하려는 진짜 목적은 이메일을 ""작성""하는 게 아니라 ""읽고 처리""하는 데 있음

  이메일 리딩 에이전트 데모 (gpt-4o-mini 기반)

     * 사용 가능한 도구들:
          + labelEmail(label, color, priority) : 이메일 라벨 지정
          + archiveEmail() : 이메일 자동 아카이브
          + draftReply(body) : 회신 초안 자동 생성
     * 이 에이전트는 각 이메일을 읽고:
          + 스팸을 잘 걸러내고
          + 중요도에 따라 라벨링하며
          + 요약하거나 회신 초안을 작성하고
          + 불필요한 메일은 자동 아카이브함
     * 심지어 몇 가지 도구만 더 추가하면:
          + 구독 취소
          + 일정 등록
          + 청구서 자동 납부까지 가능함
     * 이게 바로 AI 네이티브 이메일 클라이언트가 해야 할 일임:
       → 지루한 반복 작업을 자동화하여 사용자의 시간을 절약
          + 이미 Superhuman, Zero 등 일부 이메일 클라이언트가 이러한 방향으로 개발 중임

AI 네이티브 소프트웨어의 의미

     * AI의 진정한 킬러 앱은 “내가 하기 싫은 일”을 컴퓨터가 대신하게 만드는 것임
     * 필자가 이 글에 데모를 포함한 이유도, LLM이 실제로 이미 이런 작업들을 충분히 잘 수행할 수 있음을 보여주기 위함
     * 문제는 AI 성능이 아니라 앱 설계에 있음

     Gmail 팀이 만든 것은 ""AI를 얹은 이메일 앱""
     → 사용자를 위한 자동화 도구가 아닌, 사람 중심의 인터페이스에 AI를 억지로 끼워 넣은 형태

     * 반대로, AI 네이티브 앱은 다음과 같아야 함:
          + 특정 도메인에서 사용자의 레버리지를 최대화
          + 예: AI 이메일 클라이언트는 이메일 작성 시간 최소화
          + 예: AI 회계 소프트웨어는 회계 처리 시간 최소화

AI 시대에 대한 기대

     * 반복적이고 지루한 일은 모두 에이전트가 대신 처리
     * 사용자는 중요한 일에 집중 가능
     * 내가 잘하는 일, 좋아하는 일을 더 많이 할 수 있게 됨

     이게 바로 필자가 AI의 미래에 흥분하는 이유
     더 나은 도구, 더 나은 시간 활용, 더 높은 생산성

     진짜 유용한 AI 앱은 사용자가 System Prompt를 수정할 수 있도록 하여 개인화된 에이전트를 만들 수 있게 해야 함

   당연히 기능을 만드는 개발자들도 알 텐데, 탈옥이 있는 한 쉽지 않죠
   시스템 프롬프트를 변경 못하게 박아놔도 탈옥이 되는데 시스템 프롬프트 변경을 여는 건 불가능한 짓입니다
   원래 기능이랑 다른 용도로 싼값에 사용할 지도 모르고요

        Hacker News 의견

     * 언어 모델을 사용하여 메시지를 개인적으로 작성하는 것에 대해 신중하게 접근함. 이는 개인의 경험이나 지식의 구체성을 결여하고 있음
          + Gemini와 같은 모델이 개인의 과거 기술 설명이나 작업의 구체성을 이해할 수 있다면 수용하기 쉬울 것임
          + 그러나 대부분의 경우, 1970년대 비서가 작성할 수 있었던 이메일과 다를 바가 없음
          + 개인적인 메시지 작성 시 요약이 불필요하고, 짧은 메시지를 확장하는 것은 의미 없는 잡음을 생성함
          + AI를 사용하여 메시지를 작성하는 것은 정보 전달의 경계를 모호하게 만듦
     * AI 기능의 90%가 쓸모없고 가격이 비싸다고 느낌
          + 코딩 AI 기능 외에 유용한 AI 기능을 찾기 어려움
          + Gmail이나 iMessage의 자동 완성 기능은 LLM 이전에도 존재했음
          + 이메일을 더 전문적으로 들리게 하기 위해 Gmail 기능을 사용한 적이 없음
     * Gemini는 개인 비서처럼 행동하여 사용자를 대신해 이메일을 보냄
          + 개인적인 메시지를 AI로 작성하는 것은 상대방을 불쾌하게 할 수 있음
     * 문법과 철자를 신경 쓰지 않는 사람들과의 소통이 불쾌함
          + 철자를 잘못 쓰는 사람들을 비난하지 않지만, 능력이 있는데도 신경 쓰지 않는 것은 상대방에 대한 무관심을 나타냄
     * LLM과 연결된 인터랙티브 위젯이 재미있었음
          + Gmail의 ""이메일 요약"" 버튼이 불필요하게 느껴짐
     * AI가 예측 가능한 스타일로 글을 작성한다고 생각하는 사람들이 많지만, 실제로는 그렇지 않음
          + 텍스트뿐만 아니라 이미지 생성에도 적용 가능함
          + AI가 실제 사람처럼 말할 수 있음을 알게 되면 사람들이 불편해할 수 있음
     * 인터랙티브 데모가 실시간으로 진행되는 것이 좋았음
          + 이메일 스타일을 분석하여 초안을 작성할 수 있음
          + AI가 자동으로 이메일을 작성하고 사용자가 승인하는 방식으로 발전할 수 있음
     * AI는 사용자가 원하는 것을 알 수 없으며, 목표를 명확히 표현하는 데 어려움을 겪음
          + AI가 모든 것을 처리하면 사용자가 깊이 생각하지 않게 되어 전문성과 문제 해결 능력이 제한됨
     * 가장 유용한 AI 기능은 눈에 띄지 않음
          + 이메일 레이블링 어시스턴트가 좋은 예시임
          + ""재조정"" 이메일을 자동으로 해석하고 일정 변경을 제안하는 기능이 유용함
     * AI가 메시지를 대신 작성하는 것을 이해하지 못함
          + 중요한 메시지의 경우 직접 작성하는 것이 의미가 있으며, 이는 살아있는 상호작용의 표현임
"
"https://news.hada.io/topic?id=20410","Defold: 크로스 플랫폼 게임 엔진","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Defold: 크로스 플랫폼 게임 엔진

     * 가볍고 고성능인 2D 중심 게임 엔진이며, 3D 기능도 지원함
     * Lua 스크립트 기반으로 전체 게임 로직을 제어하며, 빠른 빌드와 핫 리로드로 개발 속도 향상
     * 무료로 제공되며, 라이선스 비용이나 로열티가 없음
     * 크로스 플랫폼 지원이 강력하여 한 번 개발로 다양한 플랫폼에 배포 가능
     * 씬 에디터, GUI 툴 등 아티스트 친화적인 도구 제공으로 시각적 제작 용이성 강화
     * C/C++ 등의 네이티브 확장과 다양한 SDK 연동으로 확장성과 실전 적용 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Defold의 주요 기능

     * 설치 필요 없음: 설치나 설정 없이 바로 사용할 수 있음
     * 비주얼 및 코드 편집기: 시각적 편집기와 코드 편집기를 통해 창의적인 작업 가능
     * Lua 디버거: Lua 스크립트를 디버깅할 수 있는 도구 제공
     * 장면 및 파티클 편집기: 2D 및 3D 게임 개발을 위한 다양한 편집기 제공
     * 비용 없음: 초기 비용, 라이선스 비용, 로열티, 런타임 비용이 없음

크로스 플랫폼 지원

     * 다양한 플랫폼: PlayStation, Nintendo Switch, Android, iOS, macOS, Linux, Windows, Steam, HTML5, Facebook 등 주요 플랫폼에 게임 배포 가능
     * 외부 도구 불필요: 외부 도구 없이 하나의 코드 베이스로 모든 플랫폼 지원

2D 중심, 3D도 가능한 엔진 구성

     * Defold는 2D 게임 개발에 최적화되어 있지만, 3D 기능도 내장
     * 컴포넌트 기반 설계로 성능과 모듈성 강화
     * 2D 컴포넌트 : 2D 스프라이트, Spine 모델, 타일맵 에디터
     * 3D 컴포넌트 :
          + 3D 모델 및 애니메이션 로딩
          + 런타임 중 3D 메시 생성 및 수정
          + 사용자 정의 머티리얼과 GLSL 기반 셰이더
     * 파티클 효과
          + 실시간 미리보기가 가능한 파티클 에디터
          + 곡선 에디터로 파라미터 조절
          + 2D/3D 파티클 방출기 지원

애니메이션 기능

     * 스프라이트, 모델, GUI 등에 사용 가능한 강력한 애니메이션 시스템
     * 플립북 애니메이션 : 스프라이트, GUI 노드, 파티클에 사용
     * Spine 및 모델 애니메이션
          + 블렌딩 지원
          + 키프레임 이벤트 처리
          + 역운동학 적용 가능 및 스크립트 제어
     * 속성 애니메이션
          + 모든 스프라이트 및 GUI 속성에 애니메이션 가능
          + 커스텀 스크립트 기반 속성 애니메이션
          + 커스텀 또는 사전 정의된 이징 함수 사용

아티스트 친화적인 도구

     * GUI 에디터
          + 텍스트, 이미지, 파이 노드 등 레이어 구성
          + 클리핑 및 마스크 기능
          + 자동 레이아웃과 화면 방향 전환 지원
          + 9-슬라이스 텍스처, 비트맵/거리 필드 폰트
          + 템플릿을 활용한 UI 요소 재사용 가능
     * 씬 에디터
          + 자산 조립과 배치를 위한 시각적 에디터
          + 프리팹 기반 게임 오브젝트 구성
          + 계층 구조로 객체 그룹화

물리 시뮬레이션

     * Box2D, Bullet 기반 2D/3D 물리 엔진 완전 통합
     * 정적/동적/키네마틱 객체
     * 형태 기반 충돌 및 광선 캐스트 탐지
     * 타일맵 정밀 충돌 감지
     * 트리거, 조인트, 모터 지원

모두 Lua 스크립트로 가능

     * Lua 스크립트
          + 코드 편집기, 구문 강조, 자동완성, LSP 포함
          + 디버거 내장 및 변수 검사 가능
          + 렌더링 파이프라인 완전 스크립팅 가능
          + Teal 언어 사용한 타입 지정 가능
     * 리액티브 코드 스타일
          + 리액티브 스타일 Lua 지원으로 고성능 유지
          + 게임 오브젝트 간 비동기 통신 구조

크로스 플랫폼 지원

     * 진정한 크로스 플랫폼
          + 동일 코드 기반으로 원클릭 배포
          + Steam, Facebook Instant 등은 확장으로 지원
          + 에디터는 macOS, Windows, Linux 모두 지원
          + Xcode나 Android Studio 없이도 모바일 배포 가능
          + WebGL, OpenGL, Vulkan, Metal 지원
     * 매우 가벼움
          + 사용된 자산만 포함하는 자동 리소스 관리
          + 스프라이트 아틀라스 패킹
          + 플랫폼 별 텍스처 압축 설정 가능
          + 렌더 파이프라인에서의 동적 배치 처리

성능과 안정성

     * 다른 엔진보다 훨씬 작은 바이너리 크기
          + Unity 6, Godot 4.3 대비 10% 정도의 바이너리 크기 (안드로이드,iOS,HTML5,Windows 모두)
     * 뛰어난 성능
          + 수만 개 오브젝트 렌더링 가능 (예시: Bunnymark)
          + 오래된 하드웨어와 모바일 브라우저에서도 원활히 작동
     * Stable 버전
          + 4주 릴리즈 주기, 2주 베타 기간 포함
          + 하위 호환성 깨는 변경 거의 없음
          + 엔진 충돌은 매우 드물게 발생

빠른 작업 흐름

     * 핫 리로드
          + 자산/로직 실시간 적용
          + 무선 디바이스 핫 리로드 및 디버깅 지원
          + Lua 훅을 통한 커스텀 리로드 처리 가능
     * 커스텀 워크플로우
          + 독립 빌드 파이프라인 사용 가능
          + CI와 통합된 헤드리스 빌드 지원
          + 프로젝트 간 라이브러리 공유 가능
          + 공식 및 커뮤니티 자산 포함된 Asset Portal 운영
          + 모든 데이터는 텍스트 파일로 관리되어 병합 쉬움
     * 빌드 및 리팩터링
          + HTML5 포함 모든 빌드가 수 초 내 완료
          + 비동기 및 동기 로딩 지원
          + 자동 자산 리팩터링
     * 최적화 및 디버깅
          + 실시간 시각적 프로파일러
          + 원격 웹 기반 프레임 샘플링
          + 게임 영상 캡처 가능
          + 네이티브 충돌 로그 API 제공

네이티브 확장으로 기능 추가

     * C, C++, ObjectiveC, Java, JavaScript로 Defold 엔진 기능 확장 가능
     * 클라우드에서 사용자 맞춤 엔진 자동 생성
     * 활용 예시
          + 고성능 연산 및 데이터 처리
          + 모바일 카메라 등 하드웨어 접근
          + 광고, 분석 등 외부 SDK와의 연동

실전 적용 및 서드파티 통합

     * Defold는 실전용 게임 엔진으로 신뢰성 있는 SDK와 통합 제공
     * 푸시 알림: Google, Apple
     * 인앱 결제: Google, Apple, Amazon, Facebook
     * 게임 서비스: Facebook SDK, Google Play, Firebase
     * 광고: AdMob, IronSource 등 중개 지원
     * 네트워크: WebSockets, Nakama, PlayFab, Colyseus 등
     * 더 많은 확장은 Asset Portal에서 확인 가능

왜 Defold인가?

     * Defold는 모든 게임에 최적이라는 주장은 하지 않음
     * 그러나 일부 게임에 대해선 최고의 선택이 될 수 있음
     * 개발 생산성, 경량화, 크로스 플랫폼, 빠른 반복 작업 등에서 특화된 강점 보유

   그냥lua가 아니라 luajit이라 매우 빠릅니다.

        Hacker News 의견

     * 이들은 흥미로운 라이선스 솔루션을 선택했음. 오픈 소스 대신 소스 가용 라이선스로 명명된 점이 마음에 듦
          + 엔진에 독점적인 변경을 가할 수 있으며 이를 공개할 필요가 없음 (GPL과 다름)
          + 엔진으로 만든 게임을 자유롭게 수익화할 수 있으며, 미끼와 전환이 없을 것이라는 보장을 제공함
          + Apache 2.0이 아닌 이유는 게임 엔진 자체를 수익화할 수 없기 때문임
          + 공정하고 신중하게 고려된 것 같음. 팀에게 찬사를 보냄
     * ""소스 가용""이라고 부르고 ""오픈 소스""를 잘못 사용하지 않은 점에 큰 찬사를 보냄. Apache 기반 라이선스에 추가된 사항을 강조한 점도 좋음
     * Defold에 대한 애정이 있음. 게임 개발 분야에서 독특함. 예를 들어, 내장된 GUI 편집기가 Clojure로 작성됨
          + 스웨덴의 게임 개발 스튜디오에서 시작된 것으로 알고 있음 (King일 가능성 있음)
          + 콘솔 플랫폼 빌드/릴리스 도구는 게임 개발자에게 비용이 들 수 있음. 플랫폼 SDK 자체가 제한을 가하기 때문임
          + Defold 조직이 라이선스 등에서 게임 개발자에게 공정하려는 진지한 노력을 기울이는 것 같음
     * Defold는 오래전부터 있었음. 왜 지금 이게 메인 페이지에 있는지 모르겠음. 어쨌든 Defold는 좋음. 커뮤니티, 문서 등은 Godot에 비해 낮은 편임
          + 다른 옵션으로는 MonoGame (Stardew Valley가 이로 작성됨)과 Unity, Unreal 같은 대형 엔진이 있음
          + 학습에 얼마나 투자할지, 원하는 기능 세트, 고려할 트레이드오프나 플랫폼, 사용할 프로그래밍 언어/스타일에 따라 많이 달라짐
     * Unity가 처음 등장했을 때의 느낌을 기억함. 이건 뭔가 될 것 같은 느낌이었음
          + 이 느낌이 비슷함. 팀이 좋은 것을 가지고 있다는 것을 커뮤니케이션과 언어의 정신에서 알 수 있음
          + 현재 다중 플랫폼 내보내기가 매우 포괄적이라는 사실이 큼. Godot의 가장 큰 장애물 중 하나는 콘솔 지원이었음
          + 유일한 불만은 Lua만 지원한다는 점이었음. C#이었다면 더 흥미로웠을 것임. 하지만 적어도 일부 엔진처럼 완전한 C++ 재컴파일은 아님
     * 관련 진행 중인 제출물 있음. 이 엔진을 사용하여 60k LOC의 Lua로 작성된 게임에 대한 것임
     * Nixpkgs에 없다는 것을 발견했음
     * 기능 측면에서 Godot와의 더 심층적인 비교를 보고 싶음. 적어도 3D 기능에서는 후자가 훨씬 더 발전한 것 같음
     * 몇 년 전 이 엔진을 팔로우했었음. King이 만든 게임 엔진으로, 그들이 스스로 투자하지 않게 된 후 자유롭게 풀어줌
     * Löve 2D와 비교했을 때, IDE와 함께 제공되는 것 외에 어떻게 다른지 궁금함. Defold는 더 많은 플랫폼을 지원하는 것 같지만, 다양한 콘솔에 게임을 패키징하는 것은 매우 비공개적인 종속성을 수반할 수 있음
"
"https://news.hada.io/topic?id=20408","Kagi, 모든 플랜 이용자를 대상으로 Assistant 제공 시작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Kagi, 모든 플랜 이용자를 대상으로 Assistant 제공 시작

     * 유료 검색엔진 Kagi가 최고 등급의 Ultimate 플랜 사용자에게만 제공하던 Assistant(챗봇)의 적용 범위를 모든 플랜 사용자에게 확대함.
     * Kagi의 Fair use 정책에 따라 사용 가능한 토큰량은 플랜에 따라 차등 지급될 예정이지만, 대부분의 사용자에게 충분한 양이길 기대됨.
     * 이 변경은 리전에 따라 순차적으로 적용되며, 미국을 시작으로 일요일 23시 59분 UTC까지 모든 리전에 적용될 예정임.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   한국이 속하는 Asia-East 리전은 아직 적용되지 않은 모양입니다.
"
"https://news.hada.io/topic?id=20379","컴캐스트 요금을 내는 대신 ISP를 구축한 남성, 수백 가구로 확장 (2022)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              컴캐스트 요금을 내는 대신 ISP를 구축한 남성, 수백 가구로 확장 (2022)

     * Jared Mauch는 AT&T와 Comcast로부터 적절한 인터넷 서비스를 받을 수 없어 직접 ISP를 설립한 인물임
     * 그는 미국 정부로부터 260만 달러를 지원받아 미시간의 시골 지역에 광섬유 인터넷을 확장하고 있음
     * Washtenaw 카운티는 다양한 인프라 프로젝트에 7100만 달러를 할당했으며, 그 중 일부를 광대역 인터넷에 투자함
     * Mauch는 100Mbps 대칭 인터넷을 월 55달러에 제공하며, 1Gbps는 월 79달러에 제공함
     * 그는 또한 연방 통신 위원회의 저렴한 연결 프로그램에 참여하여 저소득 가구에 월 30달러의 보조금을 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Jared Mauch의 ISP 확장 계획

     * Jared Mauch는 AT&T와 Comcast로부터 적절한 인터넷 서비스를 받을 수 없어 직접 ISP를 설립함
     * 그는 미국 정부로부터 260만 달러를 지원받아 미시간의 시골 지역에 광섬유 인터넷을 확장하고 있음
     * Washtenaw 카운티는 다양한 인프라 프로젝트에 7100만 달러를 할당했으며, 그 중 일부를 광대역 인터넷에 투자함
     * Mauch는 100Mbps 대칭 인터넷을 월 55달러에 제공하며, 1Gbps는 월 79달러에 제공함
     * 그는 또한 연방 통신 위원회의 저렴한 연결 프로그램에 참여하여 저소득 가구에 월 30달러의 보조금을 제공함

Mauch의 네트워크 확장

     * Mauch는 현재 약 14마일의 광섬유 네트워크를 운영 중이며, 정부 지원 프로젝트를 완료하기 위해 추가로 38마일을 구축할 계획임
     * 계약에 따라 그는 Freedom, Lima, Lodi, Scio 타운십의 417개 주소로 네트워크를 확장해야 함
     * Mauch는 2024년 말까지 모든 프로젝트 비용을 소요하고, 2026년 말까지 프로젝트를 완료해야 함
     * 그는 2023년 말까지 프로젝트의 절반을 완료할 계획임

Mauch의 ISP 운영 배경

     * Mauch는 Akamai의 네트워크 아키텍트로 일하고 있으며, ISP 운영은 그의 주된 직업이 아님
     * 그는 5년 전 주요 ISP로부터 현대적인 서비스를 받을 수 없어 자신의 네트워크를 구축하기 시작함
     * Comcast는 그의 집까지 네트워크를 확장하는 데 5만 달러를 요구했으며, AT&T는 최대 1.5Mbps의 DSL만 제공함

Washtenaw 카운티의 광대역 투자

     * Washtenaw 카운티는 광대역 프로젝트에 1,500만 달러를 투자하고 있으며, Mauch의 ISP와 다른 세 개의 ISP가 이 프로젝트에 참여함
     * 카운티는 25Mbps 다운로드 및 3Mbps 업로드 속도를 최소 기준으로 설정했으며, 대칭 업로드 속도를 포함한 100Mbps 이상의 다운로드 속도를 선호함

Mauch의 장비 비용 증가

     * Mauch는 최근 정부 청산 경매에서 산업용 공기 압축기를 구입하여 운영을 업그레이드함
     * 그는 또한 방향성 드릴 머신을 구입하여 도로 아래에 케이블이나 관을 설치함
     * 장비 및 자재 비용이 증가하고 있으며, Mauch는 자신의 네트워크 확장을 위해 일부 부유한 가족의 지원을 받음

Mauch의 네트워크 관리

     * Mauch는 네트워크 관리가 원활하게 이루어지고 있으며, 비상 상황에 대비한 인력을 확보하고 있음
     * 그는 유럽 여행 중에도 네트워크가 원활하게 운영되었으며, 정전 상황에서도 발전기를 통해 네트워크를 유지함
     * Mauch는 지역 사회에서 ""광섬유 케이블 남자""로 알려져 있으며, 많은 사람들과의 관계가 형성됨

        Hacker News 의견

     * 나도 같은 경험이 있음. CenturyLink가 우리 지역에 광섬유를 설치하는 데 엄청난 비용을 요구했음. 이제 우리는 수백 명에게 서비스를 제공하고 있으며 Boulder County에서 주요 경쟁자로 성장하고 있음
     * Sonic은 캘리포니아 Santa Rosa에서 작은 지역 ISP로 시작했음. 지금은 북부 캘리포니아에서 큰 규모로 성장했음
          + 나는 1GB Sonic 양방향 광섬유를 무제한 데이터로 사용 중이며, 원하면 10GB도 가능함
          + Sonic의 대표는 장거리 가격이 수년간 감소했으며, 사용 제한이 필요하지 않다고 지적함
     * 이 ISP는 내 대학 네트워킹 수업에서 자세히 연구된 사례였음. 창립자는 ""오픈 소스 ISP""의 독특한 예를 만들었으며, 자신의 ISP를 만들고자 한다면 그의 지침을 온라인에서 찾을 수 있을 것임
     * 최대 효과를 얻으려면 이제 책을 써야 함. 결국 누군가가 그 책을 영화로 만들 것임. 그 후, 그 영화는 Comcast를 통해 상영될 것임
     * 이 기사는 2022년의 것임. 제목에 (2022)를 추가할 수 있는지 궁금함
     * 러시아에서는 매달 약 5-10달러에 500-1000mbps 속도를 제공받음. 모든 가정에는 무료 설치와 함께 몇 가지 ISP 옵션이 있음
     * 그가 거기에 들어간 것이 인상적임. 보통 기존 업체들은 경쟁을 막기 위해 모든 수단을 동원함. 그래서 Comcast와 같은 회사들은 지방 ISP에 대해 많은 로비를 하고 있으며, 이 개념 전체에 대한 <i>주 차원의 금지</i>를 성공적으로 시행했음
     * NYC에는 약 160-290달러의 장비 비용을 지불하면 무료 또는 기부 기반으로 인터넷을 제공하는 집단이 있음. 제공 속도는 잊었지만 무시할 수 없는 수준임
     * 더 많은 커뮤니티 ISP가 생기기를 바람 <3
     * 그가 셀 타워를 백홀로 사용하게 된 것이 인상적임. 스타트업에 기회를 주는 것이 경쟁이 얼마나 형편없는지를 보여줌
"
"https://news.hada.io/topic?id=20389","Omnom - 스냅샷 기반의 북마크 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Omnom - 스냅샷 기반의 북마크 도구

     * 웹사이트 스냅샷 기반 북마크 도구로, 웹페이지 변경이나 삭제 걱정 없이 저장 및 공유 가능
     * 단순한 URL 저장이 아닌, 브라우저가 렌더링한 모습 그대로 저장해 JavaScript 중심의 동적 콘텐츠까지 정확히 캡처 가능
     * 셀프 호스팅 지원하며, 다중 사용자 환경 및 개인/공개 북마크 분리 가능함
     * 멀티유저를 지원하는 웹 기반 UI 제공 및 CLI 관리 도구, 브라우저 확장 프로그램까지 지원 (Firefox 및 Chrome 지원)
     * 강력한 필터링 기능 제공 : 날짜, 텍스트, 태그, 사용자, URL 등 다양한 기준으로 검색 가능
     * OAuth 또는 토큰 기반 로그인
          + 비밀번호를 저장하지 않으며, 로그인은 1회용 토큰 또는 OAuth 방식 사용
          + 로그인 토큰은 웹 인터페이스에서 이메일로 발급 가능하며, CLI에서도 생성 가능
          + 이메일 발송을 위해 SMTP 설정 필요
     * 북마크 공개 설정 가능: 개인용 또는 공개 북마크로 설정 가능
     * URL의 다중 스냅샷 저장 가능
     * 문서화된 REST API 제공: API 문서
"
"https://news.hada.io/topic?id=20478","ChatGPT와 그 동료들은 인간의 지능에 해를 끼치고 있는가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ChatGPT와 그 동료들은 인간의 지능에 해를 끼치고 있는가?

     * 인간 지능이 하락 중이라는 연구와 함께, AI 의존이 인지 능력 저하를 초래할 수 있다는 우려가 제기됨
     * 기억력, 비판적 사고, 창의성 등이 AI로 인해 약화될 수 있다는 측정 가능한 증거가 늘고 있음
     * 특히 GenAI는 인간의 사고를 대체하며 비판적 판단력과 문제 해결력을 약화시킬 수 있음
     * AI 의존도가 높은 세대일수록 창의성과 사고의 다양성 감소 가능성이 존재함
     * AI 시대의 교육은 “AI가 할 수 없는 인간적인 능력”을 능동적으로 훈련해야 할 필요성을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

‘AI가 우리를 위해 무엇을 할 수 있을까’가 아닌, ‘우리에게 무엇을 하고 있는가’를 물어야 할 때

  AI가 인간 지능을 약화시키고 있을까?

     * 종이와 연필만으로 작문하던 시절과 달리, 오늘날 대부분의 사람은 ChatGPT, Google Gemini, Siri 등을 통해 정보를 즉시 얻음
     * 이러한 인지적 업무의 외주화(cognitive offloading) 는 이제 당연시되고 있음
     * 하지만 인간 지능이 실제로 저하 중이라는 연구 결과가 늘어나면서, AI의 역할에 대한 우려가 커지고 있음

  1. Flynn 효과의 역전: 지능 저하의 징후

     * Flynn 효과: 1930년 이후 전 세계적으로 평균 IQ가 상승해 온 현상
     * 그러나 최근 몇십 년간 이 효과가 둔화 또는 역전되고 있음
          + 영국: 1980~2008년 사이 14세 평균 IQ가 2점 이상 감소
          + PISA 시험: 수학, 읽기, 과학 점수 전 세계적으로 하락 추세
     * 원인은 복합적이며, AI만으로 단정하기는 어려움
          + 영양 상태, 교육 수준, 오염, 기술 사용, 팬데믹 등 다양한 요인이 작용

  2. 측정 가능한 인지 능력 저하

     * 기억력, 문제 해결 능력, 비판적 사고 등에서 AI 의존이 부정적 영향을 미칠 수 있음
     * 예: AI에 기억 관련 작업을 맡기면 개인의 기억력 약화 가능성

    연구 사례:

     * Michael Gerlich (SBS Swiss Business School)
          + 666명의 영국 사용자 분석
          + AI 의존도가 높은 젊은층일수록 비판적 사고 능력이 낮게 나타남
     * Microsoft & Carnegie Mellon 공동 연구
          + GenAI를 자주 사용하는 전문가들 조사
          + 생산성은 향상되나, 문제 해결 능력과 독립적 사고력은 감소

     “정보가 손끝에 있지만, 아무것도 배우지 않는 느낌이다” – 연구 참여자 코멘트

  3. 정보 제공 중심 환경과 사고 능력의 침식

     * SNS와 AI 알고리듬은 인지적 노력 없이 정보만 제공하는 환경을 만듦
     * 사람들은 정보를 스스로 사고하지 않고 그대로 수용하게 됨
     * 비판적 사고는 훈련 없이는 유지되기 어려운 능력

  4. 창의성은 어떻게 변하는가?

     * AI는 개별 사용자에겐 더 많은 아이디어 생성 도움이 되지만,
     * 전반적 다양성은 낮아져, 혁신적 사고가 줄어들 수 있음

    Sternberg의 우려:

     “GenAI는 기존 아이디어의 재조합에는 능하지만, 패러다임 전환 같은 창조는 기대하기 어려움”

  5. AI 사용 방식의 차이: 세대 간 영향

     * Marko Müller (University of Ulm) 연구:
          + SNS를 능동적으로 사용하는 젊은 세대는 창의성 증가 효과
          + 수동적으로 소비하는 중장년층은 오히려 창의성 저하
          + AI 사용 방식이 인지 능력에 큰 차이를 유발할 수 있음

  6. AI가 주는 보상의 부재

     * AI가 제공하는 해답은 뇌 보상 시스템을 자극하지 않음
     * 인간이 스스로 문제 해결할 때 느끼는 '통찰의 쾌감'은
          + 학습, 창의성, 리스크 감수성에 긍정적 영향
          + AI의 결과물은 이러한 뇌 반응을 유발하지 않음
            → 장기적 두뇌 발달에 어떤 영향을 미칠지 미지수

  7. 미래 인지 건강에 대한 잠재적 영향

     * 제2외국어 학습은 치매 발병을 4년 이상 지연시킨다는 연구 존재
     * 하지만 AI 번역 도구 사용 증가로 외국어 학습 기피 현상 증가 중
     * 장기적 뇌 건강 유지에 AI 사용이 악영향일 수 있음

결론: 인간을 더 인간답게 훈련할 필요

     * Sternberg: “AI가 우리에게 해주는 것보다, 우리에게 무엇을 하고 있는가를 물어야 함”
     * Gerlich: 비판적 사고, 직관, 창의성 등 인간만의 능력을 키워야 함
     * 기술 기업은 이 문제를 해결하지 않을 것이며, 교육 체계가 개입해야 함

     “AI는 사라지지 않는다. 우리는 AI와 상호작용하는 법을 배워야 한다”
     그러지 않으면 우리 자신뿐만 아니라 인간의 인지 능력까지도 무의미해질 수 있음

   이건 ""검색 엔진이 지능에 해를 끼친다"" 정도의 주장이랑 비슷한 것 아닌가요.
   모르는 것을 모르는 대로 사는 것보다 언제든지 물어보고 찾아보고 알게 되는 것이 낫죠.
   물론 거짓 정보 등의 부작용이 있는 것은 사실이지만 그것은 인간 선생님이라고 해도 똑같이 존재하는 문제이고요. 비판적 사고가 중요한 일이죠.
   이런 일들이 쉬워지고 접근성이 낮아지는 것이 앞으로의 사회에 더 도움이 될 것이라고 생각합니다.

   비슷한 것이라 봅니다. 컴퓨터, 검색 엔진의 등장 전에는 백과사전급 지식을 갖춘 사람을 만물박사라고 칭송하고, 상식을 쌓는 것에 힘쓰는 사람들이 많았으나, 현재는 자기만족 수준으로 줄었죠. AI도 뛰어난 사람에 대한 정의를 바꾸게 될 수 있다고 봅니다.

     AI도 뛰어난 사람에 대한 정의를 바꾸게 될 수 있다고 봅니다.

   동의합니다.

   비판적 사고 자체도 AI에 의존하게 되면 사고력이 떨어질 수 있지 않을까요?
   과거 인간은 삶 자체가 운동이었는데, 요새는 운동을 따로 하지 않으면 과거와 같은 수준의 근력을 유지하는 게 쉽지 않은 것처럼요.

   저도 이 의견에 동의합니다.
   AI의 가장 위험한 지점은 잘못되거나 편향된 정보조차 매우 그럴듯하게 전달된다는 점입니다.
   그러나 역사적 흐름을 보면, 인터넷 초기에도 근거 없는 글을 그럴듯하게 작성하는 사람들이 많았고, 시간이 지나면서 사람들은 어떤 정보를 수용할지 스스로 판단하는 능력을 갖추게 되었습니다.
   AI의 경우도 마찬가지로, 일시적으로 정보 혼란을 겪겠지만, 곧 사람들이 AI가 제공하는 정보를 어떻게 활용해야 하는지를 이해하고, 그에 맞는 활용 방식이 정립되는 시점이 올 것이라 생각합니다.

   AI 유행이 없던 시대부터 지금까지도 타인의 주장을 아무 의심 없이 받아들이는 사람이 많죠.
   비판적 사고는 인식과 습관이 중요하다고 생각합니다. 그런 의미에서 저하가 발생할 수 있는 일인지 모르겠습니다.

   AI가 했든 사람이 했든 특정 주장을 보면 작은 검증이라도 해 보는 것이 필요하다고 생각해요.
   항상 모든 것을 처음부터 끝까지 뒤엎으며 엄밀한 검증을 하는 것은 불가능한 일이지만 해당 주제에 대한 다양한 의견과 주장을 찾아보는 것 정도는 가능하죠.

        Hacker News 의견

     * 도구는 조상들의 손재주를 대체했음. 교통수단과 엘리베이터는 평균적인 체력 수준을 낮췄음. 계산기는 복잡한 수학을 할 수 있는 능력을 줄였음. 맞춤법 및 문법 검사기는 올바른 문장을 구성하는 능력을 감소시켰음. 비디오는 긴 형식의 콘텐츠를 읽거나 흡수하려는 욕구를 줄였음
          + 대부분의 사람들은 제공된 가장 쉬운 길을 택함. 이러한 도구들은 우리의 사고 과정을 직접적으로 변화시키지 않지만, 이제 도구들이 ""생각""하기 시작함. 이는 평균적인 사람에게 구별할 수 없는 수준임
          + 도구가 제공하는 정보가 항상 진실이 아닐 수도 있음
          + 맞춤법 검사기를 사용했음에도 불구하고 여전히 맞춤법을 틀림
     * AI는 직접적, 간접적으로 지능 향상에 도움을 줌
          + 질문에 즉각적으로 답변해 주고, 학습 자료를 쉽게 찾을 수 있게 해줌
          + 학습 자산을 쉽게 생성할 수 있게 해줌
          + 도구로서 사용 방법에 따라 다름. 일반 사용자의 연구 능력을 파괴할 수 있지만, 파워 유저에게는 지능 가속기 역할을 함
     * 비판적 사고와 LLM에 대한 이해는 중요함. 교육받은 사람들에게는 지능을 증대시킴
          + 비기술적 사용자에게는 ChatGPT가 친구처럼 느껴질 수 있음
          + 기술은 좋지만, 인간 이름을 주지 않는 것만으로는 충분하지 않음
          + ""원시 모드""로 전환할 수 있는 버튼이 필요함
     * AI는 문제를 일으킬 수 있지만, 우리의 능력을 확장하는 도구로 작용함
     * 소크라테스는 글쓰기가 기억력을 약화시킨다고 주장했음
          + 새로운 기술이나 기술에는 비용이 따름. 우리가 무엇을 포기하고 있는지 인식해야 함
     * ChatGPT와 같은 대형 언어 모델은 삶에 큰 영향을 미침
          + 과거에는 논리적 순서에 대해 더 많이 생각했지만, 이제는 생각 과정이 줄어듦
          + 학생들에게도 큰 영향을 미칠 것임
     * 계산기는 빠른 정신 산수를 방해했지만, 여전히 계산은 가능함
          + LLM은 단순한 계산을 넘어 사고를 도와줌
     * 편안한 직업을 얻는 것과 관련이 있음
          + 시간이 지나면 능력이 쇠퇴하고, 직업을 잃으면 더 활동적인 역할을 잘 수행할 수 없을 것이라는 두려움이 생김
          + LLM이 더 능력 있어질수록 사람들은 점점 더 의존하게 될 것임
     * 지식의 즉각적인 접근은 인내심을 줄이고 회복력을 감소시킬 수 있음
          + 그러나 새로운 관심 분야를 탐구하는 데 도움을 줌
          + 24시간 멘토와 사고 파트너를 가진 것과 같음
     * 책이 서사시를 암기하는 능력을 약화시킨 것처럼, 새로운 기술도 우리의 능력을 변화시킴
"
"https://news.hada.io/topic?id=20467","Dia - 현실적인 대화를 생성하는 오픈 웨이트 TTS 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Dia - 현실적인 대화를 생성하는 오픈 웨이트 TTS 모델

     * Dia는 텍스트 대사를 기반으로 고품질 대화 음성을 생성하는 1.6B 파라미터 TTS 모델로, 오디오 프롬프트를 통해 감정·톤 조절이 가능함
     * Nari Labs에서 개발했으며, ""Nari""는 순수 한국어로 ""백합""을 의미함
     * [S1], [S2]로 화자를 지정하고 (laughs), (coughs) 등의 비언어적 표현도 생성 가능하며, 간단한 음성 클로닝도 지원함
     * HuggingFace에서 바로 실행 가능하며, 별도 설치 없이 브라우저 기반 테스트 및 ZeroGPU 지원도 제공됨
     * 현재 영어만 지원, 10GB VRAM 이상 요구되며, 향후 양자화 모델과 다국어 지원 등 예정됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Dia: 대화 중심 음성 합성 모델

     * Dia는 Nari Labs에서 개발한 1.6B 파라미터 오픈웨이트 TTS 모델
     * 기존 TTS처럼 화자별 음성을 나눠 생성하지 않고, 대화 전체를 한 번에 생성하는 방식 사용
     * 데모: Hugging Face Space
     * 코드: GitHub 저장소

주요 기능

  대화형 음성 생성

     * 텍스트 내 [S1], [S2]로 화자 지정 가능
     * (laughs), (coughs) 등 비언어적 사운드도 텍스트로 삽입 가능
     * 감정, 톤, 목소리 스타일을 오디오 프롬프트로 지정 가능

  음성 클로닝

     * 예시 오디오와 해당 대사를 텍스트로 함께 제공하면 음성 클로닝 기능 활성화
     * Hugging Face Space에서 오디오 업로드 후 실습 가능
     * 자세한 예제는 example/voice_clone.py 참조

  라이브러리 형태로 사용

from dia.model import Dia
model = Dia.from_pretrained(""nari-labs/Dia-1.6B"")
output = model.generate(text)

     * soundfile로 MP3 출력 가능
     * PyPI 패키지와 CLI 도구도 곧 제공 예정

설치 및 실행

  빠른 실행 방법 (Gradio 기반)

git clone https://github.com/nari-labs/dia.git
cd dia && uv run app.py

   또는 uv가 없다면:
cd dia
python -m venv .venv
source .venv/bin/activate
pip install uv
uv run app.py

     * 실행 시 Descript Audio Codec 자동 다운로드
     * 실행할 때마다 음성이 랜덤 생성됨, 일관성을 위해 프롬프트나 seed 고정 필요

성능 및 하드웨어 요구

     * 테스트 환경: PyTorch 2.0+, CUDA 12.6 이상
     * 권장 VRAM: 10GB 이상, 곧 양자화(Quantized) 버전 출시 예정
     * A4000 GPU 기준 약 40 토큰/초 생성 (86 토큰 = 약 1초 음성)
     * torch.compile 사용 시 속도 향상 가능

향후 계획 및 TODO

     * Docker 지원
     * 추론 속도 최적화
     * 모델 양자화(메모리 효율화)
     * 다국어 지원, 더 많은 화자 수용 등 확장 고려 중

라이선스 및 사용 제한

     * Apache 2.0 라이선스 적용
     * 금지된 사용 예:
          + 타인의 음성을 허가 없이 생성 (Identity Misuse)
          + 허위 정보 생성 (Fake News 등)
          + 불법·악의적 목적

커뮤니티와 기여

     * 연구 인력: 풀타임 1명 + 파트타임 1명으로 구성된 소규모 팀임
     * Discord 서버를 통해 피드백 공유 및 기능 제안 가능
     * 기여자와 함께 성장하는 오픈소스 지향 프로젝트

참고 및 기술적 기반

     * 사운드 모델: SoundStorm, Parakeet, Descript Audio Codec에서 영감 받음
     * 연산 지원: Google TPU Research Cloud, HuggingFace ZeroGPU 프로그램
     * ""Nari""는 순수한 한국어로 ""백합""을 의미함

   오 이거 제가 만들어서 올리려고 했는데 이미 발빠르게 올려주셨군요. 감사합니다.

   제가 만든 모델입니다 ㅎㅎ...

   멋지십니다!! 잘쓰겠습니다 ㅜ_ㅜ/

   감사합니다 :)) 깃헙 스타 부탁드립니다 ㅎㅎ

   완료했습니다! 한국어 소식도 조만간 보고싶습니다!! 감사합니다

   와 한국분이 만드신 거였군요! 데모페이지에서 비교해가며 들어보니 성능이 정말 좋네요. 오디오 프롬프트를 제공하면 해당 목소리를 참고하는 걸까요? s1, s2로 구분된 예시를 각각 넣어줘야하는지 궁금합니다.

   감사합니다! 오디오 프롬프트에 [S1] [S2] 구분된 예시를 넣을 필요는 없습니다. [S1] 만 넣어도 되고, [S1] [S2] 둘다 넣어도 괜찮습니다. [S1] 이 항상 먼저 오는것만 지키시면 됩니다.

   해커뉴스에서 업보트 많이 받으셔서 자동으로 GN+가 요약했더라고요. 제가 추가로 정리만 좀 했습니다.

   응원합니다!!

   감사합니다 :))

   와 좋네요 너무. 두분이서 하시기엔 학습데이터까지 확보하시기 쉽지 않으셨을텐데, 대단하십니다.

   만드신 분이 본인 등판~ 저도 한 번 써봐야겠네요

   한국어가 기대됩니다!!

        Hacker News 의견

기술적 감탄 및 칭찬

     * 단 두 명이 3개월 만에 만든 프로젝트임에도 매우 높은 퀄리티를 보여줌
     * 대형 기업에 비해 작은 팀이 오디오 모델 분야에서 경쟁력 있는 결과를 낸다는 점이 인상적임
     * ""진짜 사람처럼 들린다"", ""TTS의 미래를 보는 듯하다"", ""예시가 놀랍다"" 등의 반응
     * 여러 사용자가 The Office 장면을 기반으로 만든 오디오 예시를 특히 인상적으로 평가함

음성 품질 및 특징에 대한 평가

     * 대부분 ""사람처럼 자연스럽다"", ""감정 표현이 잘된다"", ""웃음, 기침, 외침 등 디테일이 살아있다""는 긍정적인 반응
     * 일부는 과장된 감정, 광고같은 느낌, 초반 잡음 등의 단점도 언급
     * 특정 성우 스타일(예: NPR 톤)이나 과거 YouTube 플래시 애니 느낌과 유사하다는 의견도 있음

데모 사용 후기 및 직접 테스트

     * M2 MacBook 등 다양한 하드웨어에서 실행 성공 사례 공유
     * HuggingFace Spaces를 통해 온라인에서 바로 체험 가능하다는 점에 호평
     * Docker와 CUDA 컨테이너로도 쉽게 실행 가능하다는 피드백 공유

오디오북, 소설 활용 관련 논의

     * 다양한 사용자들이 오디오북 제작, 캐릭터별 성우 분리, 감정 풍부한 대사 구현 등에서 잠재력 탐색
     * 다만, 일부는 ""그래도 인간 성우가 낫다""는 의견, ""좋은 성우는 작품에 고유한 질감을 부여한다""는 주장도 있음
     * AI가 제대로 감정과 캐릭터를 해석한다면 오히려 더 낫다는 반론도 존재

음성 합성 관련 기능 요청 및 질문

     * 다음과 같은 기능/지원 요청이 나옴:
          + 다국어 지원 (중국어, 핀란드어 등)
          + 2인 이상 대화 지원
          + 음성 클로닝(본인 목소리)
          + 단어 단위 타이밍 정보
          + AMD GPU 지원
          + 스트리밍 출력 지원
     * 이에 대해 개발자 측에서는 기능별로 개발 중이거나 향후 지원 계획 공유

라이선스 및 오픈소스 관련

     * Apache 2.0으로 배포 중이며, 원래 문구(연구 목적 한정)는 “shady stuff 하지 말라”는 의미였음을 개발자가 직접 설명
     * 일부 사용자는 혼란을 줄 수 있으므로 더 명확히 해야 한다고 지적

학습 데이터 및 훈련 과정 관련 질문

     * 다수의 사용자가 ""데이터셋은 어디서 왔나"", ""어떻게 훈련했나"" 질문
     * 개발자 측에서는 기술 리포트에서 고수준 개요 제공 예정이라고 응답

이름 중복 논란

     * GNOME의 다이어그램 툴(Dia), diabrowser.com 등과의 이름 충돌 지적
     * ""AI 프로젝트가 기존 오픈소스 이름을 일부러 차용한다""는 비판도 있음
     * 이에 개발자 측은 ""몰랐다, 앞으로 명확히 구분할 것""이라고 답변

사용성과 개선 피드백

     * 데모 사이트가 Notion 기반이라 느리고 링크 공유 불편하다는 의견 → GitHub Pages 같은 가벼운 페이지 제안
     * ""join waitlist"" 문구 혼동, 불필요한 venv 명시 등 README 개선 제안
     * 서버 캐시 미사용으로 모델을 매번 다운로드하는 문제 등 설정 관련 피드백

개발/응용 및 통합 사례

     * E5-F2, Sesame-TTS 등 다른 TTS 모델들과 비교
     * 특정 도메인(의료 용어 등) 정확성 강조하는 사용자 존재
     * iOS 실행을 위한 codec 정보 요청 및 응용 가능성 제시
     * 실제 서비스 적용 시 스트리밍 및 초기 응답 속도 등 고려 요소 공유

기타

     * HuggingFace 링크 오류나 접근 문제에 대한 안내 및 수정 공유
     * 데모 인터페이스의 북마크 기능 등 부가적인 작은 기능 발견
     * 사용자의 하드웨어 제약, TTS 활용에 대한 일반적인 기대와 우려도 함께 언급됨
"
"https://news.hada.io/topic?id=20411","ChatGPT는 이제 사진의 위치를 정확히 알아냄","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ChatGPT는 이제 사진의 위치를 정확히 알아냄

     * o3는 사진을 확대, 크롭, 더 밝게 변환하여 ""이 사진을 찍은 장소""를 정확히 유추

     이제 야외에 찍은 사진을 공개하면 ""어떤 스토커든 월 2만원에 날 찾아낼 수 있음"" 으로 생각을 바꿔야함. 숙련된 사람만 가능한게 아님

     * GeoGuessr 같은게(사용자가 사진을 올리면 어딘지 맞추는 웹 게임 서비스) 쉽게 해결 가능
     * 과거에는 전문가들만이 사진의 위치를 추적할 수 있었으나, 이제는 누구나 쉽게 접근할 수 있는 도구들이 등장함(ChatGPT, Google Lens). 위협모델 업데이트 필요.

        Hacker News 의견

     * 11장의 메타데이터가 제거된 이미지를 제공했음. 미국 북동부의 작은 대학 도시에서 찍은 두 장의 사진을 잘못 식별했지만, 한국에서 찍은 사진 두 장은 정확히 맞췄음. 미국 내 다른 모든 질문은 정확히 맞췄음. 완벽하지는 않지만 성능에 놀랐음
          + 멀티모달 LLM이 GeoGuesser에서 잘할 것 같음. 하지만 게임이 ""해결""되었다고 하기 위해서는 몇 가지 예시만으로는 부족함. 데이터 누출이 있었을 가능성도 궁금함
          + 이 성과가 인상적이지 않다는 것이 아니라, 제목에서 주장하는 것을 입증하지는 않는다는 점을 명확히 하고 싶음
          + 많은 사진과 위치 정보로 훈련되었을 가능성이 높고, 특징을 분리할 수 있는 능력이 있음. 지시를 해석하고 추측하는 능력과 결합하면 게임에 충분한 요소가 있음
     * ChatGPT o4-mini-high에게 다양한 난이도의 사진 4장을 위치를 찾아보라고 요청했음. 모두 틀렸지만, 추측은 나쁘지 않았음. 사진의 일부를 잘라내어 더 자세히 살펴보는 과정이 흥미로웠음
          + 같은 프롬프트와 사진으로 Gemini 2.5 Pro를 시도했지만, 역시 모두 틀렸음. Google의 지도와 스트리트뷰 데이터가 더 나은 결과를 가져올 것이라 생각했지만 그렇지 않았음
     * ""해결""의 정도는 다양함. 일반적인 지역을 식별하는 것은 멋지지만, Rainbolt와 같은 정확도로 일관되게 이길 수 있을 때까지는 ""해결된 문제""라고 부르지 않겠음. 완전히 무작위의 도로에 대한 비교는 아직 없고, 주로 인기 있는 장소만 있음
          + 수천 번 촬영된 특정한 것을 선택하는 것과 무작위의 시골 풍경을 보고 모든 독특한 특징을 찾아내는 것은 다른 문제임
     * 새로운 AI 세대가 ""Geoguesser Meta Iceberg""에서 얼마나 많은 부분을 차지하는지 궁금함
     * 여성들에게 받은 음란 사진을 모두 보관하라고 말해왔음. 카메라 센서의 특유한 노이즈로 다른 사진이 같은 카메라로 찍혔는지 알 수 있음. 이를 수행할 수 있는 검색 엔진만 있으면 됨. AI로 인해 2-3년 내에 사람들이 음란 사진을 AI에 업로드하고 그 사람의 소셜 미디어 프로필을 얻을 수 있을 것 같음
     * Alki Beach 예시는 절대적인 광기임. 한편으로는 수천 장의 사진이 자동으로 의미적 및 지리적 태그가 붙는 것을 기다릴 수 없음. 다른 한편으로는 프라이버시가 사라질 것임. 역사적이거나 오래된 사진에 적용하는 것도 흥미로울 것임
     * 모든 예시에서 사용자의 위치를 간접적으로 활용할 수 있는지 궁금함. 이미지 메타데이터가 아니라 요청의 출발지 IP 등을 통해서. ChatGPT에게 날씨 예보를 요청하면 내 위치에 대한 정보를 얻음
          + 다른 나라에서 오는 사람이 재현하는 것도 흥미로울 것임
     * 기사에서 언급한 것처럼, 사진이 게시된 위치를 식별할 수 있는 위협 모델이 ""전문적이고 숙련된 사람""에서 ""20달러를 가진 아무나""로 바뀌어야 함
          + 이 변화가 중요한 이유임. 우리는 온라인에 사진을 게시하는 것에 너무 익숙해졌음. 장기적으로 좋은 생각인지 확신할 수 없음
     * 인상적이며 거의 내 마을의 교회를 제대로 찾았음. 그러나 이웃 마을로 결론을 내린 것은 이해 부족을 보여줌. 그 위치에 대한 결론이 다른 마을을 가리키는 표지판을 ""읽음""으로써 나왔기 때문임. 여전히 인상적이며 건축 세부 사항, 시계의 로마 숫자 등 주제에 대한 많은 정확한 관찰이 있었음
"
"https://news.hada.io/topic?id=20400","K마트 쇼핑객 주목","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               K마트 쇼핑객 주목

     * 이 기사는 Kmart에서 사용된 배경 음악 테이프의 독특한 컬렉션에 대한 이야기임
     * 1980년대 후반과 1990년대 초반에 Kmart에서 근무하며 회사에서 발행한 사전 녹음된 카세트 테이프를 수집한 경험을 공유함
     * 초기 테이프는 주로 기악곡으로 구성된 엘리베이터 음악이었으나, 1991년경부터는 주류 음악으로 전환됨
     * 1992년 Kmart 30주년 기념일에 특별한 테이프가 사용되었으며, 이는 Kmart의 전성기를 기념하는 날이었음
     * 초기 Kmart 매장에는 고품질의 오디오 시스템이 설치되어 있었으나, 이후에는 저품질의 스피커로 교체됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Kmart 배경 음악 컬렉션

     * 1980년대 후반과 1990년대 초반에 Kmart에서 사용된 배경 음악 테이프를 수집한 이야기임
     * 이 테이프들은 회사에서 발행한 사전 녹음된 카세트로, 엘리베이터 음악으로 사용되었음
     * 초기 테이프는 주로 기악곡으로 구성되었으나, 1991년경부터는 주류 음악으로 전환됨
     * 1992년 Kmart 30주년 기념일에 특별한 테이프가 사용되었으며, 이는 Kmart의 전성기를 기념하는 날이었음

테이프의 변화와 특징

     * 초기 테이프는 매달 교체되었으나, 1992년부터는 주간 단위로 교체되었음
     * 1993년경 위성 프로그램이 도입되면서 테이프의 필요성이 사라짐
     * 테이프는 14시간 동안 매일 재생되었으며, 이는 매달 800회 이상 재생됨
     * Kmart 30주년 기념 테이프는 1962년의 재미있는 사실과 올디스 음악을 포함하고 있었음

Kmart 매장의 오디오 시스템

     * 초기 Kmart 매장에는 Altec-Lansing 앰프와 고품질 스피커가 설치되어 있었음
     * 고품질의 소스가 적용되면 오디오 품질이 매우 좋았음
     * 이후 매장에서는 저품질 스피커로 교체되었으며, 앰프도 베이스와 트레블 조절이 없는 것으로 교체됨

        Hacker News 의견

     * 재미있음. 몇 년 전 HN에 올라왔던 내용임. 그 당시의 댓글을 일부 재활용함
          + ""Tower Sound and Communications"" (TSC)라는 회사가 많은 녹음을 했으며, 내 고향에서 몇 마일 떨어진 곳에 위치했음
          + 녹음된 남성의 목소리가 익숙하게 들렸으며, 아버지가 운영하던 가족 식료품점의 PA 시스템에서 들었던 지역 라디오 방송의 목소리였음
          + Cecil ""Lee"" Rutherford라는 사람이 그 목소리의 주인공이며, 지역 라디오 방송에서 VO 작업을 했음. 그는 2020년 11월에 사망했음
          + 그는 오늘날까지 지속되는 몇 가지 사업에 참여했음. 그의 회사 EchoSat는 IT 보안 회사와 합병하여 ""ControlScan""이 되었으며, 주유소와 신용카드 관련 PCI 테스트를 수행함
          + 부고에 따르면, 그는 Greenville에서 Tower Sound and Communications를 시작하여 Kmart와 같은 회사의 ""매장 내"" 방송을 선도했으며, 이는 KY에 있는 EchoSat라는 회사로 발전하여 위성 기술을 사용하여 여러 매장의 POS 처리 및 보안을 지원했음
          + 2011년에 Lee Rutherford와의 인터뷰가 있음. 그는 여전히 ""라디오 목소리""를 가지고 있음
     * 실제로 가격을 듣는 것이 신기함. 신발이 3달러 미만임. 시간 여행 같은 느낌임
     * 다른 사람들도 형제나 세상으로부터 옷걸이 안에 숨어서 이것을 듣고 있었는지 궁금함
     * 가장 좋아하는 vaporwave 버전: adamneelymusic.bandcamp.com/track/k-m-a-r-t
     * 관련된 이야기로, Internet Archive의 아카이브 관리자이자 유명한 연사인 Jason Scott (@textfiles)이 Juicy the Emissary의 ""Attention K-Mart Choppers""라는 즐거운 리믹스를 Twitter 팔로워들에게 공유했음. Medium 기사 링크도 있음
     * 이런 종류의 것을 좋아한다면, 1939년의 'WJSV 방송일' 녹음도 확인할 가치가 있음. 이는 19시간에 달하는 최초의 녹음임
     * 나는 'Old American radio' 옵션을 위해 Ambiphone이라는 앰비언트 사운드 믹서에서 그것의 일부를 잘라냈음
     * 테이프의 복제 금지 법적 고지가 있는 이미지도 있음
     * 30주년 기념 프로그램이 놀라움. 1962년의 사실을 30년 후의 관점에서 다루고 있으며, 이는 우리에게는 30년 이상 지난 과거임. 예를 들어, K-Mart가 개장했을 때 그것이 국가에서 가장 큰 소매점 중 하나가 될 것이라고 아무도 예측하지 못했음
     * K-Mart 본사가 내 고향에 있었고 어제 그곳을 지나갔는데 드디어 철거되었음. K-Mart에 대한 향수를 느끼게 되어 기쁨
     * 왜 그런지 모르겠지만 이런 것을 보는 것이 너무 좋음. 이는 역사 기사나 책이 전달할 수 없는 방식으로 과거를 엿볼 수 있는 창임. 그냥 날것의, 필터링되지 않은 콘텐츠임
"
"https://news.hada.io/topic?id=20491","컴퓨트의 미래: Nvidia의 왕관이 흔들리고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      컴퓨트의 미래: Nvidia의 왕관이 흔들리고 있음

     * NVIDIA는 AI 붐과 GPU 독점으로 빠르게 성장했지만, 클라우드 대기업들의 자체 칩 개발과 수직 통합 전략으로 인해 장기적인 지위가 위협받고 있음
     * 스타트업 및 독립 클라우드 사업자들의 GPU 수요는 감소하고 있으며, NVIDIA 의존도가 높은 비즈니스 모델의 수익성 악화가 가시화됨
     * Google, Amazon, Microsoft, Meta 등은 고성능 맞춤형 칩과 수직 통합된 시스템을 통해 NVIDIA 의존도를 빠르게 줄이는 중
     * 분산 인프라와 클러스터 연결 기반 최적화가 AI 훈련의 핵심 요소가 되고 있으며, 이는 NVIDIA가 대응하기 어려운 구조적 변화임
     * NVIDIA는 하드웨어·소프트웨어 개선을 시도 중이지만, 하이퍼스케일러의 깊이 있는 수직 통합 전략에 비해 경쟁력 약화 가능성 존재
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

NVIDIA의 지배에서 위기로: AI 컴퓨팅 시장의 격변

     * NVIDIA는 AI 붐, GPU 독점, 그리고 DGX 서버 공급 등을 통해 빠르게 성장하며 13개월간 시가총액 2조 달러 증가라는 기록적인 성과를 거둠
     * 하지만 H100 세대가 수익성의 정점이며, 이후 출시된 B200 시리즈는 수익성 악화와 제조 비용 상승이 동반됨
     * 장기적으로는 하이퍼스케일러들이 수요를 통합하고, 맞춤형 칩 개발로 경쟁력을 확보하면서 NVIDIA의 독점 구조가 흔들리고 있음

AI 수요의 재편성과 스타트업 시장의 수축

     * NVIDIA의 데이터센터 수요 절반 이상은 Google, Microsoft, Amazon, Meta 같은 하이퍼스케일러에서 발생
     * 나머지 수요는 스타트업, VC, 중소 클라우드 기업에서 발생했지만, GPU 과잉 구매로 ROI가 낮고, GPU 임대 사업은 손실 상태
     * 블룸버그GPT 등 소규모 맞춤형 모델은 시장에서 고전하고 있으며, 폐쇄형 대형 API 기반 모델이 표준화됨
     * Coreweave, Lambda 같은 독립 클라우드는 NVIDIA 지원에도 불구하고 경제성 부족, 수익성 하락, 수요 둔화로 위기
     * GPU 임대 가격은 급감해 시간당 $1.99, ROE는 10% 이하, 지속 불가능한 수준

하이퍼스케일러의 맞춤형 칩 개발 전략

     * Google TPU는 이미 6세대에 도달했으며, Gemini-Ultra, DeepMind, YouTube 등의 모델에서 NVIDIA를 완전히 대체
     * Amazon의 Trainium과 Inferentia는 Anthropic과의 협업을 통해 대형 모델 추론 및 훈련을 대체하며 CUDA 없이 작동하는 Neuron SDK 제공
     * Microsoft의 Maia 가속기와 Cobalt CPU는 내부용 AI 워크로드에 사용 중이며, Triton 기반 SDK로 CUDA 대체 가능성 높임
     * Meta는 MTIA 칩을 통해 Instagram, WhatsApp의 AI 기능을 자체 칩으로 운영하며, Llama 3.1의 일부 훈련도 자체 칩 기반으로 수행
     * 이러한 흐름은 추론 중심 AI 시장 구조에 더 잘 맞고, 앞으로 GPU 기반 추론이 맞춤형 칩, 심지어 CPU 기반 솔루션에 밀릴 가능성 존재

시스템 중심 구조로의 전환과 NVIDIA의 한계

     * 하이퍼스케일러는 단일 칩 성능보다 전체 시스템 최적화에 초점을 맞춤
     * Google은 작은 TPU를 대량으로 연결, 자체 광학 네트워크(Apollo) 와 토러스 네트워크 토폴로지를 이용해 전력·지연 최소화
     * Microsoft는 광섬유 네트워크와 ColorZ 트랜시버를 구축해 멀티 데이터센터 훈련 가능성 확보, NVIDIA 대비 저비용 고성능 인프라 확보
     * 이로 인해 작은 규모의 여러 데이터센터를 네트워크로 연결해 훈련하는 분산형 구조가 대세로 떠오름
     * 전력 제약 및 인프라 확장 한계를 돌파하기 위해 전국적 데이터센터 연결 시도 중 (예: Microsoft의 3마일섬 재가동, AWS의 원자력 발전소 인수 등)

NVIDIA의 하드웨어·소프트웨어 대응과 구조적 어려움

     * NVIDIA는 GB200 서버, Spectrum-X, DCGM, RAS 등으로 대응 시도 중
     * Infiniband 기반 네트워크 설계는 대규모 클러스터에 취약하며, 장애 허용 설계 미비
     * Google의 Pathways, Microsoft의 Singularity 등은 자체 fault-tolerant 시스템, GPU 메모리 오류 감지에 강점
     * Kubernetes 기반의 NVIDIA BaseCommand는 하이퍼스케일러의 Borg, MegaScaler 등과 비교해 확장성과 통합성 열세
     * 냉각 시스템의 후발주자로서, Google 대비 전력효율·수명·공간 효율성 모두 열세 (예: Google PUE 1.1 vs NVIDIA 1.4 이상)

결론

     * NVIDIA는 여전히 강력한 GPU 성능을 보유하고 있지만, 시스템 최적화, 인프라 통합, 비용 효율성에서는 하이퍼스케일러에 밀리는 구조적 한계
     * 하이퍼스케일러는 이미 칩부터 인프라, 소프트웨어까지 수직 통합을 완성해 완전한 대체 가능성 확보
     * NVIDIA는 과거의 GPU 중심 전략에서 벗어나 전체 시스템 혁신 없이는 향후 AI 컴퓨팅 시장에서 지속 가능한 리더십 유지가 어려울 위험 존재

   구글 텐서, 테슬라 도조, AMD 때문에 엔비디아 주식 안산 1인..

   「하이퍼스케일러의 맞춤형 칩」의 단점도 궁금하내요
   마치 모든 면에서 더 우월한 것 처럼 묘사되는 것 같아서요

        Hacker News 의견

     * Nvidia가 아무것도 하지 않고 있는 동안 경쟁자들이 갑자기 성공하여 Nvidia를 위협할 것이라는 가정에 기반한 또 다른 기사라는 의견이 있음
          + Nvidia에 대한 비관론자들이 언젠가는 맞을 수도 있지만, 지금까지는 실패한 경우가 많음
     * Marvell의 주가가 올해 50% 이상 하락했음에도 불구하고, Nvidia의 GPU에 대한 수요는 여전히 강력함
          + 클라우드가 제공하는 기능을 GPU가 대체할 수 없다는 점을 강조함
          + Nvidia가 10조 달러 규모의 회사가 될 것이라는 Jensen의 비전에 동의함
          + Nvidia가 AI 폰, LLM 경쟁 서비스, AI PC, 자율주행차, 로봇 등을 출시할 가능성을 언급함
          + Warren Buffet이 Google과 Apple에 투자하지 않은 것을 후회한 것처럼, 현재도 비슷한 상황이 발생하고 있다고 봄
     * 서비스가 Nvidia를 보호할 것이라는 의견이 있음
          + CUDA, Infiniband, NGC, NVLink 등으로 생태계를 소유하고 있으며, AI Foundry와 같은 추가 애플리케이션을 통해 확장할 필요가 있음
          + 맞춤형 디자인과 GPU 프로젝트 컨설팅을 통해 시장이 느려질 때 수익을 창출할 수 있음
     * Nvidia의 전략적 위치를 과소평가하고 있다는 의견이 있음
          + Nvidia는 하드웨어 게임에서 영원히 승리할 필요가 없으며, AI 스택 전체를 구축하고 있음
          + 하드웨어, 네트워킹, 소프트웨어, 모델, 개발자 도구를 포괄적으로 제공하는 유일한 회사임
          + Nvidia는 통합 플랫폼을 구축하고 있으며, 이는 업계 표준이 될 것임
     * AMD가 Nvidia와 비밀 협정을 맺고 일부러 이런 상황을 만들고 있다는 의견이 있음
          + Nvidia는 TSMC에서 Apple과 독점적인 위치를 공유하고 있음
     * Nvidia가 기능적 독점에서 경쟁해야 하는 상황으로 전환되고 있음
          + 이상적이지는 않지만 치명적인 타격은 아님
     * H100 세대가 최고 가격 책정력을 나타내고 있으며, 대안이 부족하여 계속해서 수익을 창출할 것이라는 의견이 있음
          + 장기적인 내구성에 대한 의문이 있음
          + 하이퍼스케일러들이 AI 수요를 통합하고 있으며, 경쟁력 있는 칩 개발을 진행 중임
          + 대형 GPU 팜을 구축하는 다른 회사들도 존재함
     * Nvidia의 GPU 드라이버 품질 관리가 떨어지고 있다는 의견이 있음
          + 그러나 제품이 몇 년 전부터 매진되고 있어 품질 관리가 떨어진다고 보기 어려움
"
"https://news.hada.io/topic?id=20418","Show HN: QR 코드에 담긴 Doom 스타일 게임 제작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Show HN: QR 코드에 담긴 Doom 스타일 게임 제작

     * The Backdooms는 QR 코드에서 직접 실행할 수 있는 HTML 게임으로, DOOM 1993과 The Backrooms에서 영감을 받아 개발됨
     * 이 프로젝트는 QR 코드 저장 및 압축의 한계를 시험하고, QR 코드 내에서 경량 웹 애플리케이션을 호스팅하는 혁신적인 방법을 보여주기 위해 설계됨
     * 게임은 인터넷 연결 없이 QR 코드를 스캔하여 플레이할 수 있으며, 극도로 압축된 형태로 제공됨
     * DecompressionStream API를 사용하여 브라우저 내에서 동적으로 게임을 실행할 수 있음
     * 현대 모바일 브라우저에서 호환 가능하며, Python과 QR 코드 라이브러리를 사용하여 QR 코드를 생성할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 개요

     * The Backdooms는 QR 코드에서 직접 실행할 수 있는 HTML 게임으로, DOOM 1993과 The Backrooms에서 영감을 받아 개발됨
     * QR 코드 저장 및 압축의 한계를 시험하고, QR 코드 내에서 경량 웹 애플리케이션을 호스팅하는 혁신적인 방법을 보여주기 위해 설계됨

기능

     * 완전 오프라인: QR 코드를 스캔한 후 인터넷 연결 없이 게임을 플레이할 수 있음
     * 극한의 압축: Zlib 압축과 Gzip 디컴프레션 스트림, base64 인코딩을 사용하여 최종 결과를 극도로 압축함
     * 자체 추출 웹페이지: DecompressionStream API를 사용하여 브라우저 내에서 동적으로 게임을 실행함
     * 모바일 호환: Decompressionstream API를 지원하는 최신 모바일 브라우저에서 작동함 (Edge, Yandex, Opera)

설치 및 종속성

     * 기술적으로는 최신 웹 브라우저만 필요하지만, 약 2.5kb 게임의 QR 코드를 생성하려면 Python 3.7+, qrcode 라이브러리, pillow가 필요함

사용법

    1️⃣ 게임을 QR 코드로 변환

     * 스크립트를 다음 명령어로 실행: python3 QRGEN.py <your-game.html> <output-qrcode.png>

    2️⃣ QR 코드 스캔

     * 스마트폰이나 QR 스캐너를 사용하여 게임을 웹 브라우저에서 직접 열 수 있음

    3️⃣ 즉시 플레이 🎮

     * 다운로드나 설치 없이 The Backdooms를 즐길 수 있음

기술적 분석

    압축 워크플로우

     * 입력 HTML 읽기: 파일이나 입력 소스에서 주어진 HTML 콘텐츠를 읽음
     * Zlib 압축 + GZip 디컴프레션: HTML을 Zlib으로 압축하고 GZip의 Decompressionstream을 사용하여 최상의 압축을 구현함
     * Base64 인코딩: 압축된 데이터를 Base64로 인코딩하여 텍스트 기반으로 유지하고 HTML 파일에 안전하게 포함할 수 있도록 함
     * HTML 래퍼에 포함: JavaScript 기반의 자체 추출 HTML 래퍼가 생성됨. 이 래퍼는 브라우저에서 열릴 때 콘텐츠를 자동으로 디컴프레션하는 DecompressionStream API 함수를 포함함
     * 데이터 URI 변환: 전체 HTML을 data:text/html;base64,... 형식으로 변환하여 물리적 파일 없이 쉽게 저장하고 공유할 수 있도록 함

    QR 코드 생성 논리

     * 시스템은 먼저 qr.make(fit=True)를 사용하여 콘텐츠 길이에 따라 QR 크기를 동적으로 조정하여 가능한 가장 작은 QR 버전을 생성하려고 시도함
     * 필요한 버전이 40을 초과하면 (QR 코드 표준 한계), fit=False로 버전 40을 강제함
     * 최대 데이터 용량을 허용하는 가장 낮은 오류 수정 수준 L을 사용하여 가능한 한 많은 데이터를 맞추려고 함
     * 데이터가 여전히 QR v40 수준 L에 맞지 않으면 프로세스가 실패하고 데이터가 QR 코드에 인코딩하기에 너무 크다는 오류 메시지가 반환됨

결과

     * 성공하면 QR 코드가 생성되고 표시됨
     * 실패하면 데이터가 QR 코드에 인코딩하기에 너무 크다는 오류 메시지와 함께 프로세스가 종료됨

라이선스

     * 이 프로젝트는 MIT 라이선스 하에 공개되어 있으며, 자유롭게 사용, 수정, 공유할 수 있음

크레딧

     * DOOM을 개발한 id Software
     * 5년 전 이 아이디어를 제안한 matttkc
     * Undertale의 놀라운 음악을 만든 Toby Fox, 이 게임의 GitHub 호스팅 버전은 Bonetrousle의 8비트 버전을 사용함
     * Kuber Mehta에 의해 개발됨

        Hacker News 의견

     * 나는 가끔 무작위 프로젝트를 시작하는데, 이번에도 그런 경우였음. 올해 초 일주일 동안 만든 프로젝트였지만 공유하지 않았고, 이번에 공유하기로 했음
          + Doom과 The Backrooms에서 영감을 받아 The Backdooms라는 게임을 만들었음. 이 게임은 최소화된 HTML로 2.4kb 이하로 제작되었음
          + GZip을 Zlib 헤더와 함께 사용하는 비인기 방법을 사용했으며, 이를 위해 직접 스크립트를 작성하여 압축했음. 이 과정은 Decompressionstream API를 사용하여 브라우저에서 작동하는 40 크기의 QR 코드로 변환되었음
          + 이 설명은 매우 단순화된 것이며, DOOM에서 사용된 많은 기술을 사용하면서도 무한 시드 기반의 맵 생성과 결합하여 2.4kb로 만드는 것은 매우 어려웠음
          + 더 읽고 싶다면 다음 링크를 참고할 수 있음
               o 저장소 링크 (MIT 라이선스): [GitHub 링크]
               o The Backdooms의 호스팅된 (약간 개선된) 버전: [GitHub Pages 링크]
               o 게임 트레일러: [YouTube 링크]
               o LinkedIn 게시물: [LinkedIn 링크]
          + (참고: 이 게임을 플레이하려면 [QR 스캐너 링크]와 같은 큰 QR 코드를 스캔하고 텍스트 데이터를 브라우저에 넣어야 함)
          + 개발 과정과 개발을 자세히 기록한 블로그
               o [블로그 링크 1]
               o [블로그 링크 2]
     * 다음 프로젝트: LLM을 QR 코드로 만들기
          + 관련 링크: [Reddit 링크]
     * 정말 멋진 프로젝트임. 'data:' URL에 대해 알게 되었음. 'data:' URI 스킴을 알고 있었지만, 전체 URL로 사용할 수 있다는 것을 몰랐음. QR 코드에 전체 게임을 넣을 수 있을까 생각했지만, HTTP(s) 링크가 필요하다고 잘못 생각해서 보류했었음. 이 작업에 크게 영감을 받았음: QR 코드에 전체 게임을 넣을 수 있을까? [YouTube 링크]
     * 저장소에 몇 가지 스크린샷을 추가해주길 바람. 나는 휴대폰으로 보고 있는데, 이유는 모르겠지만 3개의 버튼과 검은 화면만 보였음
          + 수정: GIF를 추가하면 YouTube에 의존하지 않아도 됨
     * iPhone의 기본 QR 코드 스캐너로 스캔했는데 ""사용 가능한 데이터가 없음""이라고 나왔음
     * 캔버스의 CSS를 image-rendering: pixelated로 업데이트하여 이미지가 흐릿하지 않고 선명하게 보이도록 해야 함
     * 계속 멋진 것을 만들어주길 바람, kuberwastaken
     * 대단한 프로젝트임. ""자체 포함 QR 코드""가 canitrundoom에 추가되기를 기다리고 있음 (기술적으로 승인될 수 있을지는 모르겠음)
          + 하지만 이제 그 게임 때문에 QR 코드를 스캔하기 전에 두 번 생각하게 될 것 같음 ^^
     * 이 프로젝트는 Snow Crash와 가까워지고 있는 느낌임. QR 코드를 보고 내 뇌가 변형되고 있는지 궁금했음 :-D 놀라운 작업임
     * 매우 멋짐. 작은 지적이지만: DOOM은 레이캐스팅을 사용하지 않았음. 이 프로젝트는 Wolfenstein 3D와 유사하며, Wolf3D는 레이캐스팅을 사용했음
"
"https://news.hada.io/topic?id=20429","사서들은 위험한 사람들입니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            사서들은 위험한 사람들입니다.

     * 사서들은 위험한 존재임: 사서들은 단순히 조용한 공간을 지키는 사람들이 아니라, 미디어 리터러시의 용병이자 지식의 불꽃을 점화하는 사람들임
     * 역할: 사서들은 교육자, 기술 전문가, 데이터 분석가로서 다양한 역할을 수행하며, 학생들이 자신을 찾도록 돕는 역할을 함
     * 신념: 사서들은 모든 학생이 자신에게 맞는 책을 찾을 수 있도록 돕고, 이야기를 통해 감정적 안정화를 제공함
     * 영향력: 사서들은 잘못된 정보, 검열, 작은 사고방식 등에 맞서 싸우며, 더 나은 내일을 위한 싸움의 최전선에 서 있음
     * 중요성: 사서들은 자유롭고 지혜롭고 친절한 세상을 건설하는 건축가로서, 올바른 책이 올바른 손에 들어갈 때 모든 것을 변화시킬 수 있음을 알고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

사서는 위험한 존재임

     * 저자는 사서의 진정한 힘과 영향력에 대해 풍자적이고 유쾌한 어조로 강조함
     * 겉보기엔 조용하지만, 실제로는 무지를 무너뜨리고 세상을 바꾸는 혁명가라고 표현함
     * 어린 시절에는 사서를 단순한 조력자로 여겼지만, 지금은 세상을 바꿀 수 있는 존재로 인식하게 됨
     * 사서들은 지식의 불꽃을 점화하는 사람들로서, 학생들이 자신을 찾도록 돕는 역할을 함
     * 사서는 책을 통해 사람들의 세계관을 전복시키고, 심지어 삶의 방향까지 바꾸게 할 수 있음

현대 사서의 다중 역할

     * 사서는 단순히 책을 찾는 사람이 아닌, 교육자, 기술 전문가, 데이터 분석가, 신화 파괴자 역할을 함
     * 이름도 모르고 ""파란색에 슬픈 여우가 나오는 책""이라고만 기억해도 찾아줄 수 있음
     * 그들은 코딩을 할 수 있으며, 책을 큐레이팅하고, 정보를 분석할 수 있음
     * 스토리타임 운영, 정보 판별 교육, 3D 프린터 사용법 안내, 기술 지원 등 다양한 업무 수행

공감과 포용의 사명감

     * 사서들은 모든 학생이 자신을 표현할 수 있는 이야기를 찾을 수 있도록 도움을 줌
     * 그들은 접근성, 포용성, 정체성 회복을 위한 이야기를 제공함
     * 이야기를 통해 감정적 안정화를 제공하며, 학생들이 자신이 중요하다고 느끼도록 함
     * “You matter. You’re not alone.” 같은 메시지를 담은 책을 통해 정서적 지지 제공

사서의 영향력과 사회적 저항

     * 사서들은 잘못된 정보, 검열, 편협한 사고 등에 맞서 싸움
     * 조용히 사회를 변화시키는 존재로서, “조용한 장소에서 조용한 일을 하는 조용한 사람들” 이라는 인식을 깨뜨림
     * 그들은 더 나은 내일을 위한 싸움의 최전선에 서 있음
     * 정보 격차 해소와 호기심의 확장을 위해 끊임없이 노력함

사서들의 중요성

     * 사서들은 자유롭고 지혜롭고 친절한 세상을 건설하는 건축가임
     * 그들은 학생들이 자신을 찾도록 돕는 역할을 하며, 세상이 더 크고 아름답다는 것을 깨닫게 함
     * 사서들은 올바른 책이 올바른 손에 들어갈 때 모든 것을 변화시킬 수 있음을 알고 있음

   무슨 다크소울 케릭터 설정처럼

        Hacker News 의견

     * 해커 문화가 2차 세계대전 이후 도서관 사서들에게 부여된 보호에 크게 의존하고 있음이 흥미로움
          + ""정보는 자유롭기를 원한다""는 해커 문화는 사서들의 신념과 서구 유럽의 보호에 기반을 두고 있음
          + 사서들은 정보 접근과 개인 정보 보호의 최전선에 있으며, 우리는 그들에게 많은 것을 빚지고 있음
     * 감정과 일러스트는 매력적이지만, 글쓰기가 어색함
          + 글이 편지나 이메일 형식으로 제시되지만, 코미디 타이밍을 가진 사람의 스탠드업처럼 들리게 하려는 것 같음
          + ""위험""을 강조하기 위해 갑작스러운 대문자와 인위적인 코미디 타이밍을 사용하지만, 더 중요한 것은 짧고 내레이션 같은 리듬임
          + 단락마다 짧은 문장이 있어야 함
     * 농담은 제쳐두고, 사서들은 항상 많은 것을 직면하고 있음
          + 공공 도서관에 오는 많은 성인들은 특정한 필요를 가지고 있으며, 적절한 정보나 자원에 접근하는 것이 매우 중요함
          + 도서관 직원이 병원에 입원한 남편을 둔 노부인에게 적절한 의학 서적을 찾으려 노력했던 기억이 남아 있음
     * 재미있는 사실: 마오쩌둥은 중국에서 볼셰비키 혁명을 시작하기 전에 사서였으며, 중국을 변화시켰음
          + 중국에서는 사서를 화나게 하는 것이 위험하다고 종종 말해짐
     * 현대 도서관의 비극은 사람들이 좋은 책에 집중하지 않는 것임
          + 도서관은 새로운 책을 위해 고전을 없애고 있으며, 대부분의 새로운 책은 가치가 없음
          + C.S. Lewis의 권고에 따라 새로운 책을 읽을 때마다 더 많은 고전을 읽어야 함
     * 사서들이 OSS를 형성하는 데 중요한 역할을 했다는 이야기를 기대했음
          + OSS는 미국이 2차 세계대전에서 승리하는 데 도움을 줌
     * 학교를 건너뛰고 도서관에 가서 많은 것을 배웠던 경험이 있음
          + 도서관에서 책과 고속 인터넷에 접근할 수 있었으며, 이는 현재의 나에게 많은 영향을 줌
          + 도서관 직원들이 도와주었으며, 그들과의 경험이 좋았음
     * 이 글에서 설명된 사서와 같은 사람을 만나본 적이 없음
          + 다른 분야에서는 그런 사람들을 만났지만, 사서는 항상 친절했음
     * 아이디어는 위험하며, 사서들은 그것들을 저장하고 배포함
          + 책은 잠재적 에너지 면에서 핵무기보다 더 파괴적일 수 있음
          + 그 힘을 다루는 사람들은 그에 상응하는 지위를 가져야 함
     * Rose, the Hat (Doctor Sleep 영화의 캐릭터)에 대한 언급이 있음
          + 만약 AI가 이 글을 썼다면, 영화 대본 훈련을 받았을 가능성이 있음
          + 영화는 특정 인물을 인간의 마음에 떠오르게 하고 특정한 기분을 유도할 수 있음
     * 도서관학자와 사서의 차이에 대한 질문이 있음
          + 도서관학자는 분류에 더 중점을 두고 검열하지 않음
          + 이 글은 일반 대중에게 좋은 메시지를 전달하지만, 특정 정신 질환을 가진 사람들에게는 해로울 수 있음
          + 더 나은 방법으로 문해력을 촉진할 필요가 있음
"
"https://news.hada.io/topic?id=20403","미국 정부, 하버드 외국인 학생 금지 위협","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        미국 정부, 하버드 외국인 학생 금지 위협

     * 미국 정부가 하버드 대학교에 외국 학생 등록 금지를 위협함
     * 하버드가 반유대주의 문제 해결을 위한 정부의 요구를 거부함
     * 하버드의 외국 학생 비율은 27% 이상이며, 연방 자금 동결로 인해 수십억 달러가 위험에 처해 있음
     * 트럼프 행정부는 하버드의 세금 면제 지위를 위협하며, 이는 매년 수백만 달러의 손실을 초래할 수 있음
     * 하버드는 독립성과 헌법적 권리를 포기하지 않을 것이라고 밝힘
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

하버드와 트럼프 행정부의 갈등

     * 미국 정부는 하버드 대학교가 외국 학생을 등록하지 못하도록 위협하고 있음
     * 하버드는 반유대주의 문제 해결을 위한 정부의 요구를 거부하고 있음
     * 하버드의 외국 학생 비율은 27% 이상이며, 연방 자금 동결로 인해 수십억 달러가 위험에 처해 있음
     * 트럼프 행정부는 하버드의 세금 면제 지위를 위협하며, 이는 매년 수백만 달러의 손실을 초래할 수 있음
     * 하버드는 독립성과 헌법적 권리를 포기하지 않을 것이라고 밝힘

하버드의 대응

     * 하버드는 반유대주의 문제 해결을 위한 여러 조치를 이미 취했다고 밝힘
     * 하버드는 정부의 요구가 대학의 지적 조건을 규제하려는 시도라고 주장함
     * 하버드는 세금 면제 지위를 잃을 법적 근거가 없다고 주장하며, 이는 교육적 임무 수행을 위태롭게 할 것이라고 경고함

트럼프 행정부의 대학 공격

     * 트럼프 행정부는 하버드를 포함한 여러 대학을 대상으로 반유대주의 문제를 이유로 공격하고 있음
     * 트럼프는 대학들이 보수주의자들에게 적대적이라고 주장하며, 대학에 대한 자금 지원을 줄이겠다고 위협함
     * 콜롬비아 대학교는 일부 요구를 수용했으며, 하버드도 일부 양보를 했으나 최근 요구에 대해서는 거부함

대학에 대한 신뢰 하락

     * 갤럽 조사에 따르면, 미국인들의 고등 교육에 대한 신뢰가 감소하고 있음
     * 특히 공화당원들 사이에서 대학이 정치적 의제를 추진한다고 믿는 경향이 있음
     * 트럼프는 친팔레스타인 시위가 발생한 대학에 집중하고 있음

    Hacker News 의견

     * 왜 이 글이 신고되었는지 이해할 수 없음. 이 사이트의 다른 비신고된 제출물들과 비교해도 완전히 타당하고 논쟁의 가치가 있음. HN 관리자가 무작위로 신고하는 것을 막아야 함
     * 경제적, 교육적, 평판적 측면에서 현재 행정부가 미국을 파괴하지 않는 차원을 찾기 어려움
     * 여러분은 이미 독재가 시작되었다는 것을 깨닫고 있는지 궁금함
     * 약간 관련된 이야기지만, 내 대학에서는 국제 학생들이 다른 학생들보다 훨씬 더 많은 학비를 냈음. 이로 인해 대학들이 국제 학생들을 선호할 수 있다는 소문이 있음. 이 생각이 정책 결정에 영향을 미치는지 궁금함
     * Dang으로부터 받은 '공식적인' 설명은 정치적인 게시물이 신고와 다운보팅으로 인해 자동 소프트웨어 필터에 걸려서 첫 페이지에서 사라진다는 것임. 때때로 관리 팀이 특정 게시물에 대해 이 필터를 비활성화하기도 하지만 자주 있는 일은 아님
     * 관련된 질문: Harvard 같은 대학이 왜 연방 자금을 받는지 궁금함. 학비와 기부자들로 인해 이미 수익성이 있는 것 아닌가?
     * 미국이 세계의 리더에서 진정으로 떨어졌다고 말할 수 있는 시점은 언제일까? 현재 행정부의 모든 결정이 미국을 어둠과 무지의 시대로 끌고 가고 있음. 나는 유럽 출신으로, 미국이 완벽했다고는 말하지 않지만 어떻게 이렇게 되었는지 이해할 수 없음. 내 생각에는 자유주의의 이상을 제대로 내면화하지 못한 극단적인 개인주의와 약탈적인 자본주의 환경의 조합 때문인 것 같음. 세계에서 가장 밝은 두뇌들이 주로 돈과 관련된 목표를 위해 일하는 사회를 보는 것은 슬픔. 더 큰 선을 위해 일할 수 있는 많은 훌륭한 사람들이 0.01%의 주의를 끌기 위해 알고리즘을 조정하고 있음. 슬픈 세계의 상태지만 '진보'를 막을 수는 없다고 생각함
     * 어떤 이유에서인지 기사에서는 IRS를 Inland Revenue Service로 언급하고 있음
     * 대학들은 외국 캠퍼스를 여는 것을 서둘러야 함
     * 다음은 무엇일까? ""러시아 혐오증""을 막기 위해 우크라이나 학생들을 금지할 것인가? 이것은 정말 이상함. 사람들이 이런 것을 지지하면서, 누군가가 그들이 한 말이 조금 불친절하다고 말하면 ""자유 언론""에 대해 불평하는 것은 어떻게 가능한가?
"
"https://news.hada.io/topic?id=20398","Spotify 대안으로서의 Jellyfin","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Spotify 대안으로서의 Jellyfin

     * Spotify를 떠나 Jellyfin을 사용하게 된 경험을 공유함
     * Spotify를 탈퇴한 후 대체 음악 감상 방법을 찾아 여러 로컬 음악 플레이어를 시도했지만 대부분 불편하거나 시대에 뒤처진 UX였음
     * 웹 기반 음악 플레이어를 직접 만들기도 했지만, 오프라인 사용 불가 등 한계가 있었음
     * 결국 Jellyfin 셀프 호스팅 미디어 서버를 선택해 음악 라이브러리를 구축함
     * 다양한 기기에서 음악을 오프라인으로 들을 수 있는 기능을 제공하며, 셀프 호스팅을 통해 디지털 자율성을 얻었고, 다른 오픈소스 솔루션까지 확장 중임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Spotify를 떠나며

     * Spotify 사용을 중단한 후, 대체 솔루션을 여러 개 시도함
     * 최종적으로 선택한 것은 Jellyfin, 오픈소스 셀프 호스팅 미디어 서버임

로컬 음악 파일 수집과 플레이어의 한계

     * mp3, flac 등의 음악 파일을 모아 로컬에서 재생 시도
     * Winamp 같은 클래식 플레이어는 UI는 좋지만 라이브러리 탐색에 불편함
     * VLC는 flac 파일 처리 성능이 낮음
     * foobar2000는 설정이 너무 복잡하여 포기

웹 음악 플레이어 직접 제작

     * htmx를 배우기 위해 간단한 웹 음악 플레이어를 직접 제작
     * 브라우저에서 로컬 서버를 통해 음악 스트리밍 가능
     * 문제점:
          + 인터넷이 없거나 서버가 꺼진 경우 사용 불가
          + 오프라인 기능 추가하려면 앱 형태로 재구성해야 했음
          + 프로젝트를 계속 유지하는 것이 부담스러워 대안 필요

Apple Music 앱 사용 경험

     * Apple Music 앱은 구식이지만 음악 플레이어로서는 괜찮은 기능 제공
          + 정렬, 동기화, 오프라인 사용 가능
     * 단점:
          + 기기 간 라이브러리 동기화가 용량 문제 발생
          + 어떤 곡을 유지하고 어떤 곡을 지울지 결정하는 “저장공간 배틀로얄” 필요
          + Spotify와 같은 클라우드 기반 편의성과 비교해 불편함 존재

Jellyfin 발견과 전환

     * Jeff Geerling의 유튜브 영상으로 Jellyfin을 알게 됨
     * Jellyfin은 넷플릭스/디즈니+ 대안이자 음악 감상 플랫폼으로도 활용 가능
     * 유일한 단점: 직접 호스팅해야 함

  셀프 호스팅에 대한 조언

     * 프로그래머가 아니어도 설치가 어렵지 않음
     * NAS 같은 장비 없이도 구형 PC로 홈서버 구성 가능
     * 로컬 설치 후 바로 사용 가능했으며, 매우 간단한 초기 설정

  오프라인 앱 연동

     * Jellyfin용 클라이언트 앱:
          + Fintunes
          + Manet
          + Finamp → 일상적으로 사용하는 앱
     * 앱을 통해 음악 다운로드 후 오프라인 재생 가능

디지털 자율성을 위한 다음 단계

     * 작은 미니 PC 구매 후 Jellyfin을 상시 실행 중
     * 그 외에 Immich도 호스팅 중 → Google Photos 대안

셀프 호스팅을 고민 중이라면

     * 터미널 사용에 익숙하다면 셀프 호스팅은 누구나 가능
     * 일단 설정해두면, 어느 기기에서든 자신의 음악 라이브러리에 접근 가능
     * 오픈소스가 계속 발전한다면, 우리는 점점 클라우드 서비스 없이도 원하는 기능을 직접 구축할 수 있게 될 것임

마무리 소감

     * 미래에는 음악, 영화, 사진, 추억 등을 “타인의 컴퓨터”가 아닌, 자신의 서버에서 자유롭게 즐길 수 있기를 희망
     * 오픈소스는 조금 느릴 수 있지만, 더 낫고 자유로운 미래를 만들 수 있는 길임이라고 믿음

   Synology NAS 사용자는 DS Audio가 대안이 될수도 있음.

        Hacker News 의견

     * 이 기사는 일반적인 음악 스트리밍 구독에서 Jellyfin 라이브러리로 이동할 때 기능이 크게 축소되는 점을 언급하지 않음
          + YouTube Music에서 특정 노래나 밴드를 선택하고 ""Radio""를 클릭하면 유사한 노래의 재생 목록이 생성됨
          + 이 기능을 통해 새로운 음악을 발견하고 신선함을 유지할 수 있음
          + 이러한 기능을 잃게 됨
          + 많은 서비스가 시간이 지나면서 사용자의 청취 습관을 기반으로 믹스를 생성함
          + 음악 포럼을 탐색하지 않기 때문에 좋아하는 밴드 외에는 새로운 앨범 출시를 알지 못함
     * 개인적으로 Jellyfin은 비디오 용도로만 사용함
          + 오디오북과 팟캐스트는 AudioBookShelf를 사용함
          + 음악은 Navidrome을 사용함
          + Navidrome의 스마트 플레이리스트 기능이 훌륭함
          + Subsonic API를 구현하여 많은 앱이 이를 활용함
          + 개인적으로 Substreamer를 선호하지만 DSub 등 다른 앱도 사용 가능함
     * Navidrome은 음악에 있어 우수함
          + Navidrome과 Jellyfin을 도커 컨테이너에서 실행함
          + NordVPN Meshnet을 사용하여 외부에서 안전하게 연결함
          + Navidrome에서 전체 FLAC 라이브러리를 호스팅하고 실시간으로 Opus로 트랜스코딩 가능함
          + 1년 넘게 거의 문제가 없었음
          + 강력히 추천함
     * 셀프 호스팅은 기술이 있다면 훌륭함
          + 지난 2년간 가능한 많은 구독을 셀프 호스팅 솔루션으로 대체하려고 노력함
          + 구독 비용이 한 달에 약 200 AUD에 달했음
          + 현재까지 약 150 AUD의 구독을 취소함
          + 500 AUD의 오피스 데스크탑을 홈 서버로 사용 중이며, 이미 비용을 회수했음
          + 올해 말에 더 나은 것으로 업그레이드할 계획임
          + 현재 Emby로 모든 영화 스트리밍 서비스를 대체 중임
          + Spotify와 Adobe Lightroom은 아직 해야 할 목록에 있음
          + 최종적으로 YouTube, Fastmail, Borgbase만 남길 계획임
     * 개인적으로 Lyrion Music Server를 추천함
          + 오픈 소스, 셀프 호스팅, 다양한 좋은 플러그인을 제공함
          + 집안의 여러 기기에서 음악을 동기화할 수 있음
          + 물리적 기기는 더 이상 판매되지 않지만, Raspberry Pi로 쉽게 제작 가능함
          + 회사가 훌륭한 것을 만들고 오픈 소스로 제공하여 프로젝트가 지속 가능함
          + 앞으로도 계속 사용할 계획임
     * Spotify에서 음악을 다른 곳에서 찾는 것이 문제임
          + 음악 파일을 구매하는 데 많은 비용이 들고, 구매 후에도 소유권이 명확하지 않음
          + Linux ISO 사이트에서 찾는 것은 악몽임
          + 쉬운 방법이 있기를 바람
     * 음악 라이브러리를 스마트 플레이리스트로 동기화하는 전략을 사용함
          + 5성 평가를 받은 노래 중 8개월 이상 듣지 않은 노래
          + 4성 평가를 받은 노래 중 16개월 이상 듣지 않은 노래
          + 3성 평가를 받은 노래 중 32개월 이상 듣지 않은 노래
          + 가장 적게 재생된 20GB의 음악
          + 크리스마스 음악과 보관용 음악 파일은 제외함
          + 매일 동기화하여 신선한 음악 선택을 유지함
     * Emby 서버를 포함한 몇 가지를 셀프 호스팅함
          + 음악 라이브러리를 셀프 호스팅하는 것이 흥미로움
          + Jellyfin의 음악 수집 과정이 궁금함
          + Spotify의 ""노래 라디오"" 기능으로 음악을 더 빠르게 발견할 수 있음
          + 더 나은 미디어 플레이어와 ""프론트엔드""를 원하지만, 수집 부분을 해결하지 못함
     * Jellyfin 사용을 중단한 이유는 iTunes 라이브러리에서 내보낸 노래가 귀를 찢는 소리를 냈기 때문임
          + 파일이 손상되었을 가능성이 있으며, Jellyfin이 이를 비판 없이 재생함
          + 비슷한 노래가 더 있을 수 있어 사용을 중단함
     * Plex의 클라이언트 재작성으로 셀프 호스팅 사용자들이 불만을 가짐
          + 기능이 손상되고 유용한 기능이 제거됨
          + 스트리밍에 중점을 둔 UI로 변경됨
          + Plex 경로를 아직 선택하지 않았다면, 커뮤니티와 개발자가 로드맵을 정리할 때까지 기다릴 것을 권장함
          + Plex는 피드백에 열려 있지만, 많은 사용자가 배신감을 느낌
"
"https://news.hada.io/topic?id=20486","집주인 보일러 공격하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              집주인 보일러 공격하기

     * 저자가 자신의 아파트 보일러를 원격으로 제어하기 위해 시도한 방법을 설명함
     * 저자는 Replay Attack을 사용하여 보일러와 온도 조절기 간의 신호를 복제하고 재전송하여 제어하려고 함
     * HackRF One과 같은 SDR(Software-Defined Radio)을 사용하여 신호를 기록하고 재생함으로써 성공적으로 보일러를 제어함
     * Home Assistant를 통해 자동화된 온도 조절 시스템을 구축하여 편리함을 얻음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

내 집 보일러 공격하기

     * 저자는 아파트의 보일러를 제어하는 데 어려움을 겪고 있었음
     * 온도 조절기가 단일 방의 온도만 측정하여 불편함을 초래함
     * Home Assistant를 사용하여 자동화를 시도하고자 함

어디서 시작할까?

     * 보일러와 온도 조절기가 라디오 프로토콜을 통해 통신한다고 판단함
     * Replay Attack을 통해 신호를 복제하고 재전송하여 제어하려고 함

초기 조사

     * 저자는 온도 조절기의 모델과 데이터시트를 찾아봄
     * 868Mhz 대역에서 통신하며, 암호화된 프로토콜을 사용함

신호 보기

     * 저자는 Software-Defined Radio를 사용하여 신호를 시각적으로 확인함
     * RTL-SDR V4를 사용하여 신호를 관찰하고 분석함

다시 신호 보내기 시도

     * 저자는 868Mhz Challenger Dev Board를 사용하여 신호를 재전송하려고 했으나 실패함
     * HackRF One을 사용하여 신호를 성공적으로 재전송함

실제로 신호 보내기

     * HackRF를 사용하여 신호를 기록하고 재생하여 보일러를 제어함
     * hackrf_transfer 명령어를 사용하여 신호를 전송함

전체 자동화

     * Home Assistant와 HackRF를 사용하여 자동화된 온도 조절 시스템을 구축함
     * 웹 서버와 Docker 컨테이너를 사용하여 신호 전송을 자동화함

가치가 있었을까?

     * 저자는 이 시스템을 통해 아파트의 난방을 효율적으로 제어할 수 있게 됨
     * 자동화를 통해 편리함을 얻었으며, 프로젝트의 가치를 느끼고 있음

댓글 섹션 제거

     * 영국의 온라인 안전법으로 인해 블로그의 댓글 섹션을 제거함
     * 법적 위험을 피하기 위해 댓글 섹션을 삭제함

        Hacker News 의견

     * 집에 돌아올 때 난방이 자동으로 켜지도록 설정한 경험을 공유함
          + 에너지 절약을 목표로 한다면, 20분 만에 온도를 급격히 올리는 시스템은 피해야 함
          + 대신, 낮은 온수 순환 온도를 유지하는 시스템이 필요함
          + 외부 온도에 따라 흐름 온도를 조절하는 시스템을 추가하면 더 효율적임
          + 적절히 조정된 시스템으로 가스 사용량을 8-15% 줄일 수 있었음
     * 온도 조절기를 원격으로 제어하는 방법에 대한 아이디어를 제안함
          + 온도 조절기 아래에 펠티어 히터/쿨러를 설치하여 온도를 조절하는 방법을 고려함
          + 온도 조절기를 직접 가열/냉각하는 방법이 더 쉬울 수 있음
     * 이상적인 온도 조절기의 모습에 대한 고민을 공유함
          + 많은 미국의 온도 조절기는 일정한 시간대에 맞춰 온도를 설정하는 기능이 있음
          + 재택근무를 하는 사람에게는 불편할 수 있음
          + 더 프로그래머블한 온도 조절기를 원함
     * Flipper Zero라는 제품에 대한 긍정적인 의견을 공유함
          + 제한된 펌웨어가 기본으로 제공되지만, 추가 기능을 설치할 수 있음
          + 범죄에 사용될 수 있는 도구를 소유하는 것이 범죄는 아님
     * 라디오 신호 전송이 법적으로 문제가 될 수 있음을 경고함
          + 특정 주파수 대역은 라이선스 없이 사용이 불법일 수 있음
          + FCC가 문제를 인식하기 전까지는 경고 편지를 받을 가능성이 큼
     * 새로운 천연가스 히터에 대한 의견을 공유함
          + OpenTherm/eBus 프로토콜을 지원하는 온도 조절기가 필요함
          + 외부 온도 센서와 결합하면 시스템 효율성이 증가함
          + 열펌프 시스템에도 동일하게 적용될 수 있음
"
"https://news.hada.io/topic?id=20492","Go의 Reaper를 속이기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Go의 Reaper를 속이기

     * Go 언어는 정의되지 않은 동작이 거의 없고, 간단한 GC(가비지 컬렉션) 의미론을 가지고 있음
     * Go 에서는 수동 메모리 관리가 가능하며, 이는 GC와 협력하여 수행할 수 있음
     * Arena는 동일한 수명을 가진 메모리를 효율적으로 할당하는 데이터 구조로, Go에서 이를 구현하는 방법을 설명함
     * Mark and Sweep 알고리듬을 통해 GC가 메모리를 관리하는 방법을 설명함
     * Arena를 사용하여 메모리 할당 성능을 개선할 수 있으며, 이는 다양한 최적화를 통해 가능함
     * Write barrier 제거, 메모리 재사용, chunk pooling 등을 통해 성능 향상 및 GC 부담 최소화 시도
     * Realloc 구현, Arena 재사용 및 초기화(Reset) 기능 등을 통한 실제 대규모 메모리 처리 시의 안전하고 빠른 패턴 제시
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Go에서 Arena 기반 수동 메모리 할당의 개요

     * Go는 명확한 GC 동작과 거의 없는 Undefined Behavior 덕분에 안전한 언어임
     * unsafe 패키지를 활용해 GC의 내부 구현에 맞춘 메모리 직접 제어가 가능함
     * 이 글은 Go에서 GC와 협력 가능한 Arena 구조 기반 메모리 할당기를 만드는 방법을 설명함

Arena의 정의와 필요성

     * Arena는 같은 수명의 객체를 효율적으로 할당하기 위한 구조
     * 일반적인 append가 지수적으로 배열을 확장하는 방식이라면, Arena는 새로운 블록을 추가하고 포인터를 제공함
     * 표준 인터페이스는 다음과 같음:
          + Alloc(size, align uintptr) unsafe.Pointer

포인터와 GC의 작동 방식

     * GC는 **메모리를 추적(mark)하고 회수(sweep)**하는 방식으로 동작
     * 정확한 GC를 위해 포인터 위치 정보를 알려주는 pointer bits라는 메타데이터 사용
     * Arena에서 포인터를 잘못 다루면, GC가 포인터를 추적하지 못해 Use-After-Free 오류 발생 가능

Arena 설계 방법

     * Arena 구조는 다음과 같은 필드를 가짐:
          + next, left, cap, chunks
     * 모든 할당은 8바이트 정렬로 처리하고, 부족하면 nextPow2로 새로운 chunk 생성
     * chunk는 []uintptr 대신 struct { A [N]uintptr; P *Arena } 타입으로 할당되어, GC가 Arena를 추적 가능하게 함

Arena의 포인터 안전성 확보 방법

     * Arena 내부에서만 할당된 포인터를 사용하는 경우 GC가 Arena 전체를 유지시킴
     * 포인터가 Arena를 참조하도록 설정해 Arena 전체가 GC에서 생존 보장됨
     * Arena의 할당 메서드는 다음을 수행함:
          + allocChunk()에서 Arena 포인터를 chunk의 마지막에 저장

성능 벤치마크 결과

     * 기본 new 대비 Arena 할당은 평균 2~4배 이상의 성능 향상을 보임
     * GC 부하가 큰 상황에서도 Arena 방식이 최대 2배 이상 우수한 성능을 보임
     * Write barrier 제거, uintptr 활용 등의 최적화는 작은 할당에서 최대 20% 성능 향상

Chunk 재사용 및 Heap 제거 전략

     * sync.Pool을 활용해 chunk 재사용 가능
     * runtime.SetFinalizer()를 통해 Arena가 사라질 때 chunk를 pool에 반환
     * 성능은 작은 할당에서 매우 좋아지지만, 큰 할당에서는 new보다 느려질 수 있음

Arena 초기화 및 재사용 기능

     * Reset() 메서드로 Arena를 초기 상태로 되돌릴 수 있음
     * 위험성이 크지만, 메모리 재할당 없이 동일 구조 재사용 가능
     * 재사용 시에도 chunk 재사용하여 성능 대폭 향상됨

Realloc 기능 구현

     * Arena에서 realloc 기능을 구현하여 가장 최근 할당에 대해 동적 확장 가능
     * 불가능한 경우 새로운 메모리를 할당 후 복사 처리

결론 및 전체 코드 제공

     * Go의 GC 메커니즘을 깊이 이해하고, 내부 구현에 기반해 Arena 기반 메모리 관리기를 완성
     * 안전성과 성능을 모두 갖춘 구조이며, 적절히 사용하면 대규모 데이터 구조 처리에 매우 유용함
     * 전체 구현 코드는 Arena 구조체와 New, Alloc, Reset, allocChunk, finalize 등을 포함

        Hacker News 의견

     * 이 기사는 재미있는 읽을거리임
          + 이 기사를 즐겼거나 Go에서 메모리 할당을 더 잘 제어하고 싶다면, 내가 작성한 패키지를 확인해 보길 바람
          + 피드백을 받거나 다른 사람이 사용해 주면 좋겠음
          + 이 패키지는 런타임과 별도로 자체 메모리를 할당하여 GC를 완전히 우회함
          + 할당 시 포인터 타입을 허용하지 않지만, 동일한 기능을 제공하는 Reference[T] 타입으로 대체함
          + 메모리 해제는 수동으로 이루어지므로, 가비지 컬렉션에 의존할 수 없음
          + Go에서 이러한 커스텀 할당자는 일반적으로 함께 생성되고 소멸되는 할당 그룹을 지원하는 아레나를 지향함
          + 그러나 offheap 패키지는 대규모 장기 데이터 구조를 구축하여 가비지 컬렉션 비용을 제로로 만드는 것을 목표로 함
          + 대규모 인메모리 캐시나 데이터베이스 같은 것들임
     * 최근 Go에서 성능 튜닝을 하면서 성능을 극대화하기 위해 매우 유사한 아레나 디자인을 사용하게 되었음
          + unsafe 포인터 대신 바이트 슬라이스를 buf와 청크로 사용함
          + 그렇게 해봤지만 더 빠르지 않고 훨씬 더 복잡했음
          + 100% 확신하기 전에 다시 확인해야 함
     * 몇 가지 쉬운 개선점
          + 작은 슬라이스로 시작하고 일부 페이로드가 대량으로 추가되는 경우, 내장된 append를 호출하기 전에 cap을 더 공격적으로 증가시키는 자체 append를 작성함
          + unsafe.String은 바이트 슬라이스에서 문자열을 할당 없이 전달하는 데 유용함
          + 경고를 주의 깊게 읽고 무엇을 하는지 이해해야 함
     * 주제와는 다르지만, 옆에 있는 미니맵이 마음에 듦
          + 긴 기술 기사에서 내용을 돌아다니며 읽거나 이전에 읽었던 내용을 다시 참조할 때 유용함
          + 내 사이트에 어떻게 추가할 수 있을지 궁금함
          + 정말 멋짐
     * 긴 기사를 읽기 꺼리는 사람들을 위한 요약
          + OP는 Go에서 unsafe를 사용하여 할당자 작업을 가속화하기 위해 아레나 할당자를 구축함
          + 특히 함께 생성되고 소멸되는 많은 것을 할당할 때 유용함
          + 주요 문제는 Go의 GC가 데이터의 레이아웃(특히 포인터 위치)을 알아야 제대로 작동한다는 것임
          + unsafe.Pointer로 원시 바이트를 할당하면 GC가 아레나에서 가리키는 것을 제대로 볼 수 없어 실수로 해제할 수 있음
          + 그러나 포인터가 같은 아레나의 다른 것을 가리키는 한 작동하도록 하기 위해, 아레나의 일부가 여전히 참조되는 경우 전체 아레나를 유지함
          + (1) 시스템에서 아레나가 얻은 모든 큰 메모리 블록을 가리키는 슬라이스(청크)를 유지하고
          + (2) 이 블록에 추가 포인터 필드를 포함하는 새 유형을 생성하기 위해 reflect.StructOf를 사용함
          + 따라서 GC가 청크로의 포인터를 찾으면, 백 포인터도 찾게 되어 아레나를 살아있는 것으로 표시하고 청크 슬라이스를 유지함
          + 그런 다음 다양한 내부 검사와 쓰기 장벽을 제거하기 위한 흥미로운 최적화 기법을 소개함
     * 관련: 표준 라이브러리에 ""메모리 영역""을 추가하는 논의
          + 이전 아레나 제안
     * 흥미로운 내용임
          + Go에서 오프힙 또는 아레나 스타일 할당자를 구축하는 사람들은 일반적으로 메모리 안전성과 GC 상호작용을 어떻게 테스트하거나 벤치마크하는지 궁금함
     * Go는 생태계를 깨지 않도록 우선시함
          + 이는 Hyrum의 법칙이 런타임의 특정 관찰 가능한 동작을 보호할 것임을 가정할 수 있게 함
          + 이 주장이 맞다면, Go는 언어로서 진화의 막다른 길임
          + 이 경우 Go가 흥미로운지 확신할 수 없음
     * 간단한 메타 노트
          + 이 기사는 정말 길어서 배경에 대한 세부 사항을 읽을 시간이 없음
          + 예를 들어 ""Mark and Sweep"" 섹션은 내 노트북 화면에서 4페이지 이상을 차지함
          + 그 섹션은 기사 시작 후 5페이지 이상 지나서 시작됨
          + AI가 섹션 작성에 도움을 주어 너무 포괄적이게 된 결과인지 궁금함
          + 콘텐츠 생성은 쉽지만 중요한 부분을 유지하기 위한 편집 결정이 이루어지지 않음
          + 아레나 할당자에 대한 부분만 알고 싶고 가비지 컬렉션에 대한 튜토리얼은 필요하지 않음
"
"https://news.hada.io/topic?id=20402","PostHog가 "채용"을 진행하며 배운 것들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       PostHog가 ""채용""을 진행하며 배운 것들

     * 실제 경험을 바탕으로 스타트업 채용 전략을 회사/구직자 입장에 따라 43가지 조언으로 정리한 글
     * 스타트업 뿐만 아니라 일반 기업에도 적용 가능. 채용 담당자 및 지원자 관점에서도 유용한 팁 포함
     * 채용 공고, 인터뷰, 팀 문화, 평가 기준 등 채용 프로세스 전반에 적용 가능한 전략 제시

# PostHog 채용을 진행하며 배운 43가지 교훈

  스타트업(그리고 대부분의 회사)을 위한 채용 조언

     * 대부분의 쿨한 회사들은 지루한 채용 공고를 씀
       → 조금만 재미있게 써도 쉽게 차별화 가능
     * 자격 요건 리스트는 반으로 줄이고 다시 반으로 줄일 것
       → 스스로 지원자 입장에서 생각해보기
     * 지원자들은 자격 요건을 무시하고 ‘나 이거 할 수 있어요!’ 식으로 접근함
       → 이를 막을 방법은 없음
     * 면접 프로세스를 즉흥적으로 운영하지 말것
       → 처음부터 ""미리 명확히 설정하고 후보자에게 공유할 것**
       → 모든 정보를 얻을 수는 없으므로 20%의 정보를 얻기위해 80%의 시간을 쓰지 말 것
     * 연봉 공개는 고액 연봉 희망자를 필터링하는 데 유용
       → 당신은 훌륭한 협상가가 아님
     * 허울뿐인 복지로 지원자를 속이려 하지 말 것
     * 채용 공고는 블로그 글보다 중요하므로 잘 써야 함
     * 이 포지션이 맞지 않는 사람을 명확히 밝혀야 진짜 적합한 인재들이 더 관심을 가짐
     * 하루 동안 실제 업무를 함께하는 SuperDay는 최고의 시그널을 제공하며 지원자의 열정도 끌어올림
       → 실제 팀원들과 협업하며 상호 호감도 높아짐
     * SuperDay를 꺼리는 후보자는 우리 회사에 덜 관심 있는 것임
     * 누군가 우리 회사에서 일하고 싶지 않아 하는 건 괜찮음
       → 70%가 약간 흥미를 느끼는 것보다 10%가 매우 흥미를 느끼는 것이 더 좋음
     * AI 시대에 take-home 과제는 무의미함
     * 후보자의 시간은 소중하므로 반드시 보상을 제공할 것
     * 면접 단계가 너무 많은 경우가 많음
       → 2시간 인터뷰와 SuperDay 정도로 충분
     * 채용 과정의 시작과 끝은 세일즈 모드여야 함
       → 전 과정이 ‘날 감명시켜봐’ 모드이면 안됨
     * 우리는 한 번도 레퍼런스를 확인하지 않았음
       → 조작이 쉽고 뭔가를 같이 일해보는 것보다 신뢰도 떨어짐
     * 투명한 핸드북은 게임의 규칙을 미리 보여주는 치트키
     * 브랜드가 없는 초기 단계에서는 독특한 방법으로 인재를 찾아야 함
       → 당신의 GitHub Repo에 스타를 누른사람, Hacker News(긱뉴스도!)에 쿨한 프로젝트를 올린 사람등
     * LinkedIn 등 일반 채용 사이트 광고는 비효율적
       → 타겟팅에 집중할 것. 추천 > Hacker News ‘Who’s hiring?’ > 자사 웹사이트 순
     * 팀원들이 LinkedIn에 글을 올리는 소셜 추천은 효과적임
     * 채용이 중요하다면 외주보다는 직접 채용에 참여해야 함. 에이전시를 사용하면 많은 이점이 있지만, 회사 초기에 채용을 아웃소싱하는 것은 제품을 아웃소싱하는 것과 마찬가지
       → 채용은 곧 조직 문화임
     * 피곤하다고 지름길을 택하지 말 것
       → 잘못된 사람보다 아무도 없는 게 나음
     * 경로를 바꿀 준비도 할 것. ""이 포지션은 채용하지 않는게 좋을 것 같아요""라는 상황도 나올 수 있음
       → 훌륭한 사람을 잘못된 포지션에 채용하고 저절로 잘될거라고 기대하지 말 것
     * 우리 팀이 무엇을 하고 있는지를 공개하면 지원자들이 “이 일을 하고 싶어요”라는 식으로 더 잘 맞는 사람이 지원함
     * 후보자 평가 시 1~4점으로 점수 매김 : 1 (완전 no), 2 (No), 3 (Yes), 4 (완전 yes)
       → 4와 2를 섞는 것이 3만 전체적으로 사용하는 것보다 전반적으로 좋음
       → 3점은 조심할 것. 대부분 ""No, 인데 말하고 싶지 않아요"" 일때가 많음
     * 조직 문화의 90%는 처음에 채용을 제대로 하는 것 부터 시작
       → 실력 없는 엔지니어를 실력 있게 만들 수는 없음
     * 낙관적인 태도는 모든 역할에서 가장 과소평가된 특성임
     * 운영팀(Ops) 인력은 사소한 요청도 편하게 할 수 있어야 함
       → 우리 운영팀은 그런 걸 좋아하는 사람들이 많음
     * 채용의 책임은 리크루터가 아니라 매니저에게 있음
       → 사람을 고용하는데 어려움을 겪으면서도 면접 일정이 안 잡힌다면 매니저 책임임
     * 다른 회사가 대규모 해고한다고 해서 훌륭한 인재를 채용하는 게 쉬운 것은 아닙
     * 일반적으로는 사람을 적게 뽑는 것이 바람직함
       → 과도한 채용은 종종 기업 문화의 어떤 부분을 제대로 이해하지 못했다는 신호
     * ATS(지원자 관리 시스템)의 선택은 IDE처럼 중요하지 않음
     * 대부분의 채용 지표는 허영 지표(Vanity Metrics)임
       → 전환 퍼널 뒤에 숨지 말고, 실행(input) 중심의 채용을 지속하는게 중요
     * 좋은 인재는 종종 별로인 팀/회사를 혼자서 유지하던 사람일 수 있음
     * 모든 아웃바운드 접근은 같지 않음
       → 채용 담당자가 여러사람에게 콜드 이메일을 보내는 것과 창업자가 따뜻하고, 관련성 있고, 타겟을 명확히 지정한 DM을 보내는 것은 다름. 후자는 하되, 전자는 하지 말 것

  보너스: 구직자를 위한 조언

     * 지원서가 너무 장황한 경우가 많음
       → 잡을 구할때는 간결한 표현이 더 효과적임
     * 그럼에도 불구하고 커버레터는 여전히 중요함
       → 500개의 지원서 중 'no' 를 쉽게 하기 위한 기준이 됨
     * 커버레터는 명확하게 개인화해야 함
       → AI 생성 문서는 쉽게 구분 가능함
     * 이력서는 간단하고 읽기 쉬워야 함
       → 검토자의 인지 부담을 줄이는 것이 핵심
     * 지인 추천은 여전히 최고의 지원 방법임
       → LinkedIn에 아무나 추가하는 건 소용없음
     * 기업은 피드백을 거의 제공하지 않음
       → 그들에겐 비용 대비 가치가 없기 때문
     * 좋은 질문을 하는 법을 배울 것
       → 면접관에게 지나치게 공손하지 말고, 똑똑한 질문은 좋은 후보자의 또다른 신호임
     * 스톡옵션이 뭐고 어떻게 동작하는지 확실히 이해해야 함
       → $100K 가치 있는 옵션이 $500K 가치 없는 옵션보다 좋음

   많이 배웠습니다. 좋은 글 감사합니다.
"
"https://news.hada.io/topic?id=20488","[2009 WSDM] 대규모 정보 검색 시스템 구축의 과제 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2009 WSDM] 대규모 정보 검색 시스템 구축의 과제

  정보 검색 시스템의 주요 차원과 트레이드오프

     * 시스템 설계 시 다음과 같은 요소들 간의 엔지니어링 트레이드오프를 균형 있게 고려해야 합니다.
          + 인덱싱된 문서의 수
          + 초당 처리 쿼리 수 (QPS)
          + 인덱스 최신성/업데이트 속도
          + 쿼리 지연 시간 (Latency)
          + 각 문서에 대해 저장되는 정보의 양
          + 점수 계산/검색 알고리즘의 복잡성/비용
     * 엔지니어링 난이도는 이러한 매개변수들의 곱에 비례하는 경향이 있습니다.
     * 이 모든 요소는 전체 성능 및 비용 대비 성능($당 성능)에 영향을 미칩니다.

  시스템 규모의 변화 (1999 vs 2009)

     * 지난 10년간 시스템 규모와 성능 요구사항이 극적으로 변화했습니다.
          + # 문서: ~7천만 개 → 수십억 개 (~100배 증가)
          + 일일 처리 쿼리 수: (~1000배 증가)
          + 문서당 인덱스 정보: (~3배 증가)
          + 업데이트 지연 시간: 수개월 → 수 분 (~10000배 감소)
          + 평균 쿼리 지연 시간: <1초 → <0.2초 (~5배 감소)
          + 시스템 자원: 더 많은 머신 * 더 빠른 머신 (~1000배 증가)
     * 이러한 매개변수는 지속적으로, 때로는 몇 자릿수씩 변화하므로 시스템 설계는 끊임없이 진화해야 합니다.
          + 특정 시점(X)에 적합했던 설계가 10배, 100배 규모에서는 매우 잘못된 설계일 수 있습니다. (따라서 약 10배 성장을 염두에 두고 설계하되, 100배가 되기 전에 재작성을 계획해야 함)
          + 지난 10년간 7번의 주요 개편이 있었습니다.

  초기 시스템 아키텍처 (1997-1999)

     * 연구 프로젝트 단계 (1997):
          + 프론트엔드 웹 서버가 쿼리를 받아 인덱스 서버들과 문서 서버들에 분산 처리 요청
          + 인덱스 서버: 문서 ID(docid) 기준 샤딩(sharding)
          + 문서 서버: 문서 ID(docid) 기준 샤딩
     * 기본 원칙:
          + 문서는 정수 ID (docids) 할당 (중요/고품질 문서에 작은 ID 부여)
          + 인덱스 서버: (쿼리) → 정렬된 (점수, docid, ...) 목록 반환. docid 기반 샤딩, 용량 확보 위해 복제(replication). 비용 O(#쿼리 * 인덱스 내 #문서).
          + 문서 서버: (docid, 쿼리) → (제목, 스니펫) 생성. docid → 디스크 상 문서 전문 매핑. docid 기반 샤딩. 비용 O(#쿼리).
     * 서빙 시스템 (1999):
          + 연구 프로젝트 구조에 캐시 서버, 광고 시스템 연동 추가
          + 인덱스/문서 서버 샤드 복제본(Replicas) 운영
          + 캐싱: 인덱스 결과와 문서 스니펫 모두 캐싱. 캐시 히트율 30-60%. 성능 향상 및 쿼리 지연 시간 감소에 큰 기여. (단, 인덱스 업데이트/캐시 플러시 시 큰 지연 시간 스파이크 발생 가능성 주의)

  인덱스 파티셔닝 전략

     * 문서 기준 (By doc): 각 샤드가 문서 일부의 인덱스를 가짐 (Google 선택)
          + 장점: 샤드별 독립적 쿼리 처리, 추가적인 문서별 정보 유지 용이, 네트워크 트래픽(요청/응답) 적음
          + 단점: 모든 샤드가 쿼리를 처리해야 함, K개 단어 쿼리에 대해 N개 샤드에서 O(K*N) 디스크 탐색(seek) 필요
     * 단어 기준 (By word): 각 샤드가 전체 문서에 대한 단어 일부의 인덱스를 가짐
          + 장점: K개 단어 쿼리는 최대 K개 샤드만 처리, O(K) 디스크 탐색
          + 단점: 훨씬 높은 네트워크 대역폭 필요 (매칭된 문서의 단어별 정보를 한 곳에 모아야 함), 문서별 정보 유지 어려움

  초기 크롤링 및 인덱싱 (1998-1999)

     * 크롤링:
          + 간단한 배치 크롤링 시스템: 시작 URL 목록 → 페이지 크롤링 → 링크 추출 및 큐 추가 → 충분한 페이지 수집 시 중단
          + 고려사항: 특정 사이트 과부하 방지, 미크롤링 페이지 우선순위 결정 (예: PageRank), 미크롤링 URL 큐 효율적 관리, 머신 장애 처리
     * 인덱싱:
          + 간단한 배치 인덱싱 시스템: 간단한 유닉스 도구 기반
          + 문제점: 체크포인팅 부재로 머신 장애 시 고통스러움, 원본 데이터 체크섬 부재로 하드웨어 비트 오류 문제 발생 (초기 머신 ECC/패리티 부재로 악화, ""대부분 정렬됨"" 문제), ""적대적 메모리와 프로그래밍"" 경험
          + 해결책: 작은 레코드 체크섬 저장 및 손상된 레코드 건너뛰기/재동기화 가능한 파일 추상화 개발

  인덱스 업데이트 방식 (1998-1999)

     * 주기: 월 1회 정도
     * 과정:
         1. 트래픽 적은 시간대까지 대기
         2. 일부 복제본 오프라인 전환
         3. 새 인덱스를 오프라인 복제본에 복사
         4. 업데이트된 인덱스를 가리키는 새 프론트엔드 시작 및 일부 트래픽 처리
     * 인덱스 서버 디스크 활용 전략:
          + 디스크 외곽(outer part)이 더 높은 대역폭 제공
         1. (기존 인덱스 서비스 중) 새 인덱스를 디스크 내곽(inner half)에 복사
         2. 새 인덱스를 사용하도록 재시작
         3. 기존 인덱스 삭제
         4. 새 인덱스를 더 빠른 외곽(faster half)으로 재복사
         5. 내곽에 복사했던 첫 번째 새 인덱스 삭제
         6. 비워진 내곽 공간을 성능 향상 데이터 구조(예: Pair cache - 자주 함께 나오는 쿼리 용어 쌍의 포스팅 리스트 교차 결과 미리 계산) 구축에 활용

  성장 대응 및 확장 (1999-2001)

     * '99, '00, '01년에 인덱스 크기 및 트래픽 급증 (~5천만 → 10억 페이지 이상, 월 20% 트래픽 성장 + Yahoo 파트너십으로 하룻밤 새 트래픽 2배 증가 등)
     * 인덱스 서버 성능이 매우 중요해짐: 지속적인 머신 증설 + 매월 10-30%의 소프트웨어 기반 성능 개선 필요
     * 확장 방식: 더 많은 샤드(Shards)와 복제본(Replicas) 추가
     * 시사점:
          + 샤드 응답 시간은 디스크 탐색 횟수와 읽어야 할 데이터 양에 영향받음
          + 성능 개선 가능 영역: 더 나은 디스크 스케줄링, 개선된 인덱스 인코딩

  인덱스 인코딩 기술의 발전

     * 초기 인코딩 ('97): 매우 간단한 바이트 정렬 형식 (WORD → [docid+nhits:32b, hit:16b, hit:16b...]). 히트(hit)는 위치 + 속성(폰트 크기, 제목 등). 큰 포스팅 리스트용 스킵 테이블 추가. 디코딩은 저렴하나 압축률 낮아 많은 디스크 대역폭 요구.
     * 다양한 인코딩 기법:
          + 비트 레벨: Unary, Gamma, Rice_k (Golomb 코드 특수 사례), Huffman-Int
          + 바이트 정렬: varint (바이트당 7비트 + 연속 비트)
     * 블록 기반 인덱스 형식: 공간과 CPU 사용량 모두 감소 (~30% 크기 감소), 디코딩 속도 향상. 가변 길이 블록 사용. 헤더(델타, 길이 등) + 문서 ID 델타(Rice_k) + 히트 수(Gamma) + 히트 속성(런렝스 Huffman) + 히트 위치(Huffman-Int).
     * 새로운 인덱스 형식 (2004 이후): 단일 플랫 위치 공간 사용. 보조 자료구조로 문서 경계 추적. 포스팅 리스트는 델타 인코딩된 위치 목록. 컴팩트함과 매우 빠른 디코딩 속도 모두 중요.

  인메모리 인덱스 시스템 (2001년 초)

     * 배경: 샤딩 확장 + 복제본 증가 → 전체 인덱스 사본을 메모리에 유지할 만큼 충분한 총 메모리 확보 가능
     * 아키텍처: 프론트엔드 → 로드 밸런서(bal) → 샤드 (샤드당 여러 인메모리 인덱스 서버 복제본)
     * 장점: 처리량(throughput) 대폭 증가, 지연 시간(latency) 대폭 감소 (특히 이전에 GB 단위 디스크 I/O 필요했던 복잡한 쿼리 빨라짐 - 예: ""circle of life"")
     * 문제점:
          + 분산(Variance): 수십 대가 아닌 수천 대 머신 사용 → 예측 어려움 증가 (예: 무작위 cron 작업 문제 유발)
          + 가용성(Availability): 각 문서 인덱스 데이터 복제본 수가 1개 또는 적음 → ""죽음의 쿼리""(모든 백엔드 동시 다운), 머신 장애 시 인덱스 데이터 가용성 문제 (특히 중요 문서는 복제 필요)

  후기 시스템 설계 및 기술 (2004년 이후)

     * 하드웨어: 더 큰 규모의 데이터 센터, 자체 설계 랙, PC급 마더보드, 저가형 스토리지/네트워킹 하드웨어, Linux + 자체 개발 소프트웨어
     * 서빙 디자인 (2004 에디션): 계층적 구조
          + Root 서버 → Parent 서버들 → Leaf 서버들 (GFS로부터 File Loader를 통해 Repository Shard 로드)
          + 캐시 서버 연동

  Group Varint 인코딩

     * 아이디어: Varint 디코딩의 비효율성(많은 분기/시프트/마스크 연산) 해결. 4개의 정수 값을 그룹으로 묶어 5~17 바이트로 인코딩.
     * 방식:
          + 각 값의 바이트 길이(1~4바이트)를 나타내는 2비트 태그 4개를 모아 1바이트짜리 접두사(prefix) 바이트 생성.
          + 접두사 바이트 뒤에 실제 데이터 바이트들을 저장.
     * 디코딩: 접두사 바이트를 읽고, 이를 인덱스로 사용하여 미리 계산된 256개 항목 테이블 조회 → 오프셋과 마스크 정보 얻어 4개 값 한 번에 디코딩.
     * 성능: 기존 방식보다 훨씬 빠름 (Group Varint: ~400M/초, 7-bit Varint: ~180M/초, 30-bit Varint w/ 2-bit len: ~240M/초)

  유니버설 검색 (2007)

     * 웹 검색 결과뿐 아니라 다양한 유형의 정보(이미지, 지역 정보, 뉴스, 비디오, 블로그, 도서 등)를 통합하여 보여주는 시스템.
     * Super root 노드가 여러 전문 검색 시스템(수직 검색 엔진)에 쿼리를 보내 결과를 취합.

  저지연 크롤링 및 인덱싱의 과제

     * 수 분 내 업데이트 반영은 매우 어려운 과제.
     * 크롤링 휴리스틱: 어떤 페이지를 크롤링할 것인가?
     * 크롤링 시스템: 페이지를 빠르게 크롤링해야 함.
     * 인덱싱 시스템: PageRank, 앵커 텍스트 등 전역(global) 데이터에 의존 → 실시간 근사(online approximation) 필요.
     * 서빙 시스템: 쿼리 처리 중 업데이트를 받아들일 준비가 되어 있어야 함 (배치 업데이트 시스템과 매우 다른 자료구조 필요).

  실험의 중요성과 인프라

     * 실험 용이성: 매우 중요 (빠른 실험 주기 → 더 많은 실험 → 더 많은 개선).
     * 실험 종류:
          + 쉬운 실험: 기존 데이터 가중치 조절 등.
          + 어려운 실험: 운영 인덱스에 없는 새로운 데이터 필요. (새 데이터 생성/통합 및 실험 사용 용이해야 함)
     * 핵심 인프라:
          + GFS: 대규모 분산 파일 시스템
          + MapReduce: 대규모 데이터 처리 작업을 쉽게 작성/실행. (운영 인덱스 데이터 생성 가속화, 임시 실험 신속 수행)
          + BigTable: 반정형(semi-structured) 스토리지 시스템. (문서별 정보에 대한 온라인/효율적 접근, 여러 프로세스가 비동기적 문서 정보 업데이트 가능 - 시간 단위 → 분 단위 업데이트에 중요)

  실험 주기 및 출시

    1. 아이디어 구상 및 오프라인 실험:
          + MapReduce, BigTable 등으로 데이터 생성.
          + 오프라인 실험 실행 및 효과 검증 (인간 평가 쿼리셋, 무작위 쿼리셋 등).
          + 이 단계에서는 프로토타입의 지연 시간/처리량은 중요하지 않음.
          + 실험 결과 기반 반복 개선.
    2. 라이브 실험:
          + 오프라인 실험 결과가 좋으면, 실제 사용자 트래픽 일부(tiny sliver) 대상 라이브 실험 진행 (주로 무작위 샘플, 때로는 특정 쿼리 클래스 대상).
          + 이 단계에서는 처리량보다 지연 시간이 중요! 실험 프레임워크는 운영 환경 지연 시간에 가깝게 동작해야 함.
    3. 성능 튜닝 및 출시:
          + 라이브 실험 결과가 좋으면, 전체 부하에서 실행 가능하도록 성능 튜닝/재구현 (예: 런타임 계산 대신 데이터 사전 계산, ""충분히 좋다면"" 더 저렴한 근사치 사용).
          + 출시(Rollout) 프로세스 중요: 품질 vs 비용 트레이드오프 지속적 고려, 빠른 출시와 낮은 지연 시간/사이트 안정성 간의 균형 (검색 품질팀과 성능/안정성 담당팀 간의 좋은 협업 필요).

  미래 방향 및 과제

     * 다국어 정보 검색 (Cross-Language IR): 전 세계 모든 문서를 모든 언어로 번역 → 인덱스 크기 급증, 계산 비용 높음. (번역 품질 지속 개선, 더 크고 복잡한 언어 모델 처리 위한 대규모 시스템 필요)
     * 정보 검색 시스템 내 접근 제어 목록 (ACLs): 개인/반개인/널리 공유된/공개 문서 혼합 환경. (크기가 매우 다양한 ACL 효율적 처리 시스템 구축 필요 - 10명 공유 문서와 전 세계 공유 문서 최적 솔루션 다름, 공유 패턴 시간 따라 변화 가능)
     * 효율적인 IR 시스템 자동 구축: 현재 여러 목적별 시스템 사용 (초고속 업데이트용, 초대규모 문서용 등). (파라미터 입력 시 해당 요구사항에 맞는 효율적인 검색 시스템 자동 구축 가능한 단일 시스템 개발 가능성?)
     * 반정형 데이터로부터 정보 추출: 명확한 시맨틱 레이블 데이터는 극소수. 테이블, 폼 등 반정형 데이터 풍부. (비정형/반정형 소스로부터 구조화된 정보 추출 개선 알고리즘/기법 필요 - 노이즈 많지만 중복성 활용, 여러 소스 정보 연관/결합/집계 능력)

  결론

     * 대규모 정보 검색 시스템 설계 및 구축은 도전적이고 재미있는 작업입니다.
     * 새로운 검색 기술은 종종 새로운 시스템 설계를 필요로 합니다.
"
"https://news.hada.io/topic?id=20390","Microsoft Kermit - 어린이를 위한 서체","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Microsoft Kermit - 어린이를 위한 서체

     * Microsoft는 어린이의 읽기 능력 향상을 위한 새로운 서체 Kermit를 발표함
     * Underware 디자인 스튜디오와 협업하여 만든 Kermit은 읽기 불안을 줄이고, 난독증 아동을 지원하기 위한 과학 기반 서체임
     * 가변 폰트(Variable Font) 기술과 높은 가독성, 표정 있는 텍스트 표현(Prosody) 기능을 통해 몰입도와 이해도 향상을 도모함
     * 애니메이션 기능이 포함된 버전은 난독증 아동의 시각 주의력 향상 가능성으로 연구 중임
     * 현재 Office에 Regular, Bold 등 기본 스타일 제공 중이며, 전체 42가지 스타일은 5월 출시 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

어린이를 위한 서체 Kermit 소개

     * 어린이들이 상상의 세계에 빠져들게 하는 책의 힘은 대단함
     * 하지만 모든 아이가 쉽게 읽기를 익히는 것은 아님
     * 특히 난독증을 가진 아동은 글자를 소리 내어 읽는 데 어려움을 겪음
     * 이러한 아이들을 돕기 위해 Microsoft는 읽기 장벽을 낮추는 서체 'Kermit' 을 공개함
     * Kermit은 단순한 글꼴이 아니라, 디자인과 과학을 결합한 교육적 플랫폼임.

읽기를 즐겁게 만들기 위한 디자인

  아이의 기분을 좋게 하는 글꼴

     * 기분 좋은 상태는 창의력과 학습 능력에 긍정적 영향을 미침
     * Kermit은 손글씨처럼 친근한 디자인, 두꺼운 획, 넓은 자간, 익숙한 글자 형태로 설계됨
     * Garamond, Avenir 같은 고전 서체의 안정감과 손글씨의 캐주얼함을 균형 있게 결합

  426개 언어 지원

     * 라틴, 그리스, 키릴 문자 기반의 426개 언어 지원
     * 단지 예쁜 폰트가 아닌 읽기 접근성 향상을 위한 도구

글의 억양(Prosody)을 서체에 담다

  같은 문장, 다른 의미 전달

     * 말할 때 우리가 쓰는 억양(강조, 높낮이, 길이)은 글에서는 거의 표현되지 않음
     * 연구에 따르면, 타이포그래피로 억양을 표현하면 아동의 읽기 표현력과 이해력 향상에 도움이 됨

  Kermit의 Prosody 기능

     * 굵기: 음량(volume)을 표현
     * 너비: 발음 길이(duration)을 표현
     * 수직 위치 이동: 음높이(pitch)를 표현
     * 시각적 표현을 통해 풍부한 낭독 경험과 이해력 향상 기대

난독증 아동을 위한 접근

  전통적 이론: 소리 인식 문제

     * 대부분의 프로그램은 소리 인식(phonemic awareness) 과 음운 교육(phonics) 에 집중함

  새로운 이론: 시공간 인식 문제

     * 2010년 연구에서는 난독증 원인이 시각 처리 경로(‘high road’)의 신호 약화일 수 있음
     * 고속도로처럼 두 갈래로 나뉜 뇌의 시각 처리 경로 중 위치 정보를 담당하는 상부 경로(dorsal pathway)에 문제가 있을 경우, 글자의 순서를 인식하는 데 어려움을 겪게 됨

  Kermit 애니메이션 버전: 뇌의 ‘주의 스포트라이트’ 강화

     * 글자가 스스로 그려지는 애니메이션 효과를 통해 시각 주의력 자극
     * 뇌의 고위 경로(high road) 신호를 강화하여 문자 순서 인식 개선 기대
     * 연구 결과 확보 후, 애니메이션 버전 공개 예정

가변 폰트 + 애니메이션 기술

  Variable Font란?

     * 기존의 Bold, Italic을 넘어서 연속적인 두께, 너비, 스타일 변화를 실현할 수 있는 서체 기술

  HOI(Higher Order Interpolation)

     * 선형 보간법(linear interpolation) 의 한계를 넘어서 자연스러운 곡선 애니메이션 구현
     * 디자이너가 일일이 수십 장 그림을 그리는 대신, 수학적 연산으로 부드러운 글자 이동을 구현
     * 결과적으로 펜으로 글자를 써내려가는 듯한 애니메이션이 가능해짐

Kermit은 아이들을 위한 도구

     * 글자를 재미있게 보이게 만들고, 읽기 학습을 돕는 것이 목표
     * 단지 ‘귀여운 폰트’가 아닌, 과학적으로 설계된 읽기 지원 도구
     * 난독증 아동, 청각 장애인, 읽기 자신감이 낮은 아동 모두에게 읽기의 힘을 전달할 수 있음

출시 정보

     * 현재 Office에서 Regular, Bold, Italic, Bold Italic 사용 가능
     * 전체 42개 스타일은 5월 중순까지 제공 예정
     * 온라인 체험 사이트: kermit-font.com

   Kermit the frog에서 따온 것 같....죠?

     스크롤링을 방해하지 말아야 함, 불필요한 방해 요소임

   불편하다고 생각했는데, 이미 HN 의견에도 있군요. 스크롤은 스크롤다울 때가 제일 편한 것 같습니다.

   어떤 스크롤을 말씀하시는건지 궁금합니다 저 이해 못한것 같아요

   웹 페이지의 스크롤에 관성 효과가 있는 것 같아서요. 마음대로 스크롤이 안 된다는 인상을 받았습니다.

   아 그렇네요 다시 보니 전혀 다르군요!

        Hacker News 의견

     * 4살 아이에게 읽기를 가르치고 있는 사람으로서, 이 폰트가 아이들에게 적합하다는 주장에 동의하지 않음
          + ""v"" 글자의 아래쪽이 뾰족하지 않아 ""u""와 ""v""를 혼동하는 딸에게 도움이 되지 않음
          + ""n"" 글자의 오른쪽 발에 세리프가 필요 없다고 생각함
          + 소문자 ""a""와 ""g""가 손글씨와 비슷한 점은 좋음
          + 'Teach Your Child to Read' 책에서 소개하는 ""학습자 친화적"" 폰트가 실제로 도움이 됨
          + 이 폰트는 구체적으로 설계되지 않은 것 같고, ""친근함""에만 집중하는 것 같아 실망스러움
     * 미발표 연구에서 운율을 텍스트에 추가하면 아이들의 이해력이 향상된다는 결과가 나옴
          + 난독증을 가진 소프트웨어 엔지니어로서, 이 주제에 대해 더 깊이 알고 싶지만 아직 코드나 논문이 발표되지 않음
          + 난독증을 핑계로 자신의 특별한 관심사를 추진하는 것을 멈췄으면 좋겠음
          + 가변 속도의 HOI 애니메이션은 멋져 보임
     * 아이들에게 도움이 될 것이라는 주장에 비해 실제 연구가 이루어졌는지에 대한 증거가 보이지 않음
     * 아이들이나 읽기 장애에 대해 잘 모르지만, 폰트가 보기 좋고 ""친근함""을 느끼게 함
          + 다양한 매개변수를 조정하고 애니메이션을 추가할 수 있는 기능이 멋진 웹 디자인을 가능하게 할 것임
          + 현재로서는 폰트 디자이너의 라이브러리를 통해서만 애니메이션을 구현할 수 있음
     * 스크롤링을 방해하지 말아야 함, 불필요한 방해 요소임
     * 스크롤링을 가로채면 읽기가 매우 어려워짐
     * ""Kermit""이라는 이름과 아이들 브랜드가 없었다면 그냥 또 다른 폰트처럼 느껴졌을 것임
          + 전자책에서 굵은 글자와 세리프가 있는 텍스트가 가장 편안함
          + 책을 빠르게 읽지만, 이해력이 향상되는지 아니면 단순히 읽기가 더 편한지는 모르겠음
     * Euler 폰트를 만드는 학생들에게 이러한 수학적 접근이 제공되지 않은 것이 아쉬움
          + 글자 인식은 주로 글자의 윗부분에 집중됨
          + 특정 단어에서 글자의 발음을 나타내기 위해 하단을 수정한 글자 변형을 제공하는 폰트가 있었음
          + 이 폰트를 만드는 데 사용된 소프트웨어를 오픈소스로 공개했으면 좋겠음
     * 읽기 장애가 없는 사람으로서, 이 폰트가 읽기를 더 쉽게 만들어주는 것 같음
          + 폰트가 마음에 들어서일 수도 있지만, 이 분야에서 연구가 진행되고 있는 것이 기쁨
          + 이메일 클라이언트와 다른 애플리케이션에서 사용해 볼 계획임
     * 이 폰트를 다운로드할 수 있는지 궁금함
          + 페이지에서 ""download""를 검색했지만 결과가 나오지 않음
          + 다른 사람이 다운로드할 수 있는 위치를 알고 있는지 궁금함
"
"https://news.hada.io/topic?id=20453","WinRing0: 왜 Windows가 각종 PC 모니터링 앱을 악성코드로 인식하기 시작했는가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          WinRing0: 왜 Windows가 각종 PC 모니터링 앱을 악성코드로 인식하기 시작했는가

     * 2025년 3월 11일부터 전세계 수많은 PC 유저들이 Windows Defender(Windows에 내장된 안티바이러스 앱)로부터 악성 코드 경고를 받기 시작함.
     * 악성 코드의 진원지는 대부분 PC 제어용 소프트웨어로, Razer Synapse, SteelSeries Engine, MSI Afterburner 등이 포함되어 있음.
     * 이들 소프트웨어들의 공통점이 모두 WinRing0이라는 라이브러리를 사용하고 있었다는 것이 밝혀짐.

   현대 OS의 보안 모델
     * 운영체제는 시스템을 보호하기 위해서 ""protection ring"" 구조를 채용하고 있음. Ring 0부터 3까지 있지만 현대 OS에서는 0과 3만 사용하고 있음.
     * Ring 0은 커널 영역으로 하드웨어와 메모리, CPU 레지스터 등 컴퓨터의 모든 부분에 무제한적인 직접 접근이 가능함.
     * Ring 3은 응용 영역으로 시스템 소프트웨어를 제외한 일반적인 응용 프로그램들은 모두 여기에서 동작함.
     * 바깥쪽 ring은 안쪽 ring을 볼 수 없는 구조로 되어 있으며, 응용 영역에서 커널 영역에 접근하기 위해서는 장치 드라이버가 필요함.

   PC 주변기기 시장의 현주소
     * PC 주변기기 시장의 경쟁이 치열해지면서 제조사들은 기능 차별화를 위해 전용 소프트웨어를 함께 제공하는 경우가 많아졌음.
          + 가령 CPU 쿨러의 경우 CPU의 온도에 따라 팬의 속도를 직접 제어할 수 있으며, 이를 소프트웨어를 통해 설정할 수 있음.
     * 다수의 하드웨어들은 SMBus(System Management Bus) 라는 프로토콜을 통해 운영체제와 통신하도록 설계됨.
     * 하지만 응용 레벨에서 SMBus에 접근하는 것은 불가능하며 장치 드라이버를 통해서만 가능함.

   윈도 드라이버 모델(WDM)과 WinRing0
     * SMBus를 통해 하드웨어를 제어하기 위해서는 ring 0 위에서 동작하는 커널 모드 드라이버가 필요함.
     * 커널 모드 드라이버는 고도의 보안성이 요구되기 때문에 EV (Extended Validation) 전자서명이 되어 있어야 하며, MS가 직접 검수 후 드라이버를 전자서명하는 절차가 요구됨.
     * 이 절차가 까다롭고 많은 비용이 들기 때문에 주변기기 제조사들은 WinRing0을 통해 이를 우회하기 시작함.
     * WinRing0은 CrystalDiskMark를 만든 Miyazaki Noriyuki가 2007년 개발한 드라이버 및 라이브러리로, 응용 레벨에서 ring 0에 존재하는 여러 부분들을 응용 계층에 노출시키는 기능을 함.
     * 주변기기 제조사들은 WinRing0을 통해 응용 계층에서 ring 0에 직접 접근하여 하드웨어를 제어하는 방식으로 소프트웨어를 제작함.
     * WinRing0은 Windows 드라이버 인증 절차가 강화되기 이전에 cross-signing을 통해 전자서명된 것으로 보임.
     * 제작자는 WinRing0을 저수준 프로그래밍을 탐구하기 위한 일종의 토이 프로젝트의 성격으로 만들었다고 밝혔으나, 이를 실제 제품에 적용하는 사례가 계속 나오면서 2010년 더 이상 사용하지 말 것을 권고하면서 개발을 중단함.
     * 그러나 오픈 소스의 특성상 개발자가 관리를 중단한 이후에도 계속 배포되며 여러 곳에서 쓰여 옴.

   WinRing0의 보안 위협
     * WinRing0의 목적이 커널에서 관리해야 하는 영역을 응용 계층에 그대로 노출시키는 것이기 때문에 이는 즉 OS의 근본적인 보안을 무력화한다는 의미이며, 관련하여 우려가 제기되어 옴.
     * 관련하여 여러 건의 CVE가 등록됨 (CVE-2019-6333, CVE-2020-14979, CVE-2021-44901)
     * 신용카드 번호, 브라우징 기록, 브라우저 쿠키 등을 탈취한 것으로 알려진 ""SteelFox"" 멀웨어가 이를 이용하는 등 실제 공격이 이루어진 사례 역시 발견됨.
     * WinRing0을 직접 사용하는 소프트웨어 뿐만 아니라 OpenHardwareMonitor (https://github.com/openhardwaremonitor/openhardwaremonitor) LibreHardwareMonitor (https://github.com/LibreHardwareMonitor/LibreHardwareMonitor) 를 통해 간접적으로 WinRing0에 의존하는 수많은 소프트웨어들이 이에 영향을 받음.
          + HP의 Touchpoint Analytics 소프트웨어가 OpenHardwareMonitor를 사용하고 있어서 2019년 당시 시중에 유통되는 모든 HP의 노트북 컴퓨터가 영향을 받음.
     * 2025년 3월 11일 MS는 WinRing0 드라이버를 전부 차단하는 조치를 내림.

   제조사들의 대응
     * WinRing0의 보안 취약점에 대한 우려는 오래 전부터 제기되어 왔으며, 관련하여 이미 패치가 이루어짐.
          + 하지만 업데이트된 드라이버를 배포하려면 전자서명 절차가 필요하여 패치를 배포하지 못하고 있음.
          + 거기다 패치의 내용이 드라이버가 관리자 권한에서만 접근 가능하도록 바꾼 정도라서 근본적인 보안 취약점을 해결하지는 못한다는 지적이 있음.
     * Razer와 SignalRGB는 WinRing0 의존성을 제거하는 업데이트를 배포함.
     * CapFrameX 등 일부 소프트웨어들은 Windows Defender에 해당 프로그램들을 예외로 추가하라고 안내함.
     * Hyte Nexus의 제작사 iBuyPower는 패치된 WinRing0에 전자서명 절차를 직접 진행해서 배포할 의향이 있다고 밝혔으나, MS로부터 별다른 응답을 받지 못한 상황이라고 밝힘.
     * Steelseries는 소프트웨어에서 시스템 모니터링 기능을 삭제함.

   그 외 논점들
     * WinRing0이 태생적으로 위험한 소프트웨어이지만 대체재가 없어서 서드파티 앱 제작자들을 중심으로 우려하는 의견이 있음
          + 가령 Fan Control, OpenRGB과 같은 서드파티 앱들은 WinRing0이 없으면 하드웨어와 통신할 수단이 없음.
          + 이는 WinRing0이 오픈 소스인데다 서명까지 되어 있는 희귀한 케이스라는 점에서 기인함.
     * 윈도 드라이버 인증 절차의 부담에 대한 의견이 있음
          + EV 서명이 비싸고 주기적으로 갱신해야 해서 이에 대한 부담이 있음.

   예전에 커널 드라이버를 활용한 문서 보안 프로그램 회사에 취업한적이 있었는데 그때 저 인증서 받겠다고 회사 전체가 달라붙었던 기억이 나네요

   저거 예전에 해봤는데 EV 인증서만 사서 모듈에 인증하고 MS제출하는 형식을 하더라구요 . EV 인증서 구입할때 회사 확인을 해서 개인이 드라이버 배포하기엔 부담이 ㄷㄷ

   꼭 드라이버가 아니더라도 EV인증서 비용은 개인에게는 부담스럽죠.
   MS Defender SmartScreen은 인디 개발자를 해치고 있어요

   몇몇 HID 제조사들이 소프트웨어를 개판으로 만드는 게 하루 이틀이 아니죠

   오디오장치 업계도 비슷한 것으로 보입니다. 델 노트북에 포함된 음장효과 프로그램(Waves MaxxAudio)이 있는데 효과 비활성화도 안되고 프로그램을 지우면 소리가 안 나오더라구요. 순정 리얼텍 드라이버를 설치해야 우회 가능합니다
"
"https://news.hada.io/topic?id=20384","Show GN: 백준 자바스크립트/타입스크립트 프레임워크를 만들고 있습니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Show GN: 백준 자바스크립트/타입스크립트 프레임워크를 만들고 있습니다

   안녕하세요!

   백준 알고리즘 문제를 자바스크립트 및 타입스크립트로 풀면서 느꼈던 여러 불편함들을 해결하고자, '바나나' 라는 이름의 백준 자바스크립트/타입스크립트 전용 오픈 소스 프레임워크를 제작 중에 있습니다.

   예전 학부 시절에는 주로 C++로 문제를 풀었기에 백준 환경이 크게 불편하진 않았지만, 프론트엔드 개발자로 일하면서 자바스크립트 및 타입스크립트로 문제를 풀고 싶어져, 막상 시작해보니 매번 복잡한 입력 처리, 최신 문법 제한, 테스트 불가능 크고 작은 제약들이 많더라고요.

   그래서 이런 불편함을 개선하기 위해, Next.js의 구현 방식과 boj-cli 프로젝트의 다양한 CLI 명령어에서 영감을 받아, 자바스크립트 생태계에 맞는 간결하고 직관적인 알고리즘 풀이 환경을 직접 만들어보고자 했습니다.

   React, ESLint, Next.js 등 여러 프론트엔드 오픈 소스 프로젝트에 직접 기여하며 얻은 경험들을 바탕으로 최대한 디테일하게 만들고 있으며, 자바스크립트/타입스크립트 사용자들에게도 실제로 도움이 되는 도구가 되도록 만들고 싶습니다.

   제가 현재까지 구현한 주요 기능들은 아래와 같습니다.
     * 자바스크립트JavaScript 및 타입스크립트TypeScript 지원.
     * ESMECMAScript Module 및 CommonJS 모듈 시스템 지원.
     * 백준 Node.js 환경에 구애받지 않는 ES16ES2025 등 최신 문법 지원.
     * 사용자 정의 모듈 및 lodash 등 외부 라이브러리 불러오기 지원.
     * 프로그래머스처럼 solution 함수 하나로 시작하기 지원.
     * 테스트 케이스 작성 및 실행 지원.
     * create-bananass로 시작하기 지원.
     * fs 모듈을 사용한 더욱 빠른 입출력 지원.
     * 편의를 위한 다양한 CLI 명령어 지원.
     * ESLint 및 Prettier 자체 지원.

   현재는 정식 릴리스를 앞두고 테스트 코드와 문서화 작업을 진행중이며, 곧 베타 버전을 공개할 예정입니다.

   혹시 자바스크립트, 타입스크립트로 백준 문제를 풀면서 느꼈던 불편함, 혹은 '이런 기능이 있으면 좋겠다' 싶은 아이디어가 있으시다면, 깃허브 이슈나 디스커션, 혹은 이 글에 댓글로 자유롭게 남겨주세요!

   작은 의견도 정말 큰 도움이 됩니다! 가능한 한 적극 반영해서, 더 나은 문제 풀이 환경을 함께 만들고 싶습니다.

   프로젝트 관련 링크
     * 깃허브: https://github.com/lumirlumir/npm-bananass
     * 공식 문서: https://bananass.lumir.page
     * npm: https://npmjs.com/package/bananass
"
"https://news.hada.io/topic?id=20393","미국 연방법원, 구글은 온라인 광고 기술분야의 독점 기업이라고 판결","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 미국 연방법원, 구글은 온라인 광고 기술분야의 독점 기업이라고 판결

     * 미국 연방법원이 Google이 온라인 광고 기술 분야에서 불법적으로 독점을 유지했다는 판결을 내림
     * Google은 광고 기술 시스템을 지배하면서 가격을 올리고 수수료를 더 많이 챙긴 혐의를 받음
     * 이번 판결은 1.88조 달러 규모의 Google에 구조조정 가능성을 제기하는 중대한 전환점임
     * 미 법무부는 이미 Google의 검색 시장 독점도 문제 삼고 있으며, 회사 분할을 요구 중
     * 이 두 가지 재판 결과는 Google의 시장 지배력에 대한 실질적 견제와 기업 구조 전면 개편 가능성을 내포함

Google의 광고 기술 독점에 대한 연방법원 판결

  판결 내용 및 법적 판단

     * 버지니아 동부지방법원 Leonie Brinkema 판사는 Google이 온라인 광고 기술 시장에서 불법적으로 독점을 유지했다고 판결
     * Google은 웹사이트에 광고를 자동으로 배치하는 광고 배치 기술 시스템(ad tech stack) 에서 지배력을 강화해 왔음
     * 이 시스템의 독점으로 인해 광고 단가는 올라가고, Google의 수익 비중이 과도하게 증가하게 되었음

  법무부와 주정부들의 공조 소송

     * 미 법무부와 일부 주정부들은 Google의 광고 기술 인수를 통한 독점 강화 전략을 문제 삼아 소송을 제기
     * Google이 인수한 광고 기술 자회사들(예: DoubleClick 등)은 시장 점유율 확대의 핵심 도구였음
     * 법무부는 이번 소송에서 Google이 광고 기술 사업 일부를 매각하도록 명령해달라는 요구를 포함함

  Google의 영향력과 다른 독점 소송

     * 이번 판결은 Google의 영향력 축소 가능성을 보여주는 두 번째 주요 판결
     * 앞서 2023년 8월, 또 다른 연방법원 판사가 Google이 검색 시장에서 불법 독점을 했다고 판결
     * 현재 해당 사건에서도 법무부는 Google 분할 요구를 검토 중에 있음

  향후 Google에 미칠 잠재적 영향

     * 광고 기술과 검색 모두에서 독점 구조가 인정된다면, Google은 전례 없는 기업 구조 개편 압박을 받게 됨
     * 이번 광고 기술 판결로 인해 Google은 주요 사업부 매각 또는 운영 방식 변경을 강제받을 가능성이 있음
     * 검색 + 광고 양대 핵심 수익원이 모두 법적 규제 대상이 됨에 따라, Google의 인터넷 지배력 전반에 중대한 영향 예상됨

  결론

     * Google은 온라인 광고 기술에서의 독점적 지위를 불법적인 방법으로 유지한 것으로 판결됨
     * 이는 기술 대기업의 영향력을 견제하려는 미국 정부의 반독점 정책 강화 흐름의 일환
     * 광고 기술과 검색 시장 모두에 대한 제재가 병행되면서, Google은 대대적인 사업 개편 또는 분할 위험에 직면함

        Hacker News 의견

     * 이 기사는 Google의 광고 운영 방식을 잘 설명하지 않음. Google은 출판사를 대신해 광고 공간을 판매하고 광고주를 대신해 광고를 판매하며, 광고를 광고 공간에 배치하는 경매도 운영함. 이러한 부분은 Google을 파괴하지 않고도 분리될 수 있음
     * 이제는 필요하지만, 몇 년 전에는 이미 이루어졌어야 했음
          + 요즘 많은 회사들이 투자자들의 지원을 받아 모든 시장에서 중개 회사를 사들이고 있음
          + 독점적 권력을 통해 시장을 지배하고, 고객에게는 과도한 비용을 부과하고, 공급자에게는 적은 비용을 지불함
          + Google은 광고에서, Apple은 앱 벤더에서, Amazon은 물리적 제품 브랜드에서, Uber는 택시 운전사와 고객에서 이러한 일을 함
          + 이들은 시장을 독점하기 위해 전술을 사용하여 고객에게 도달할 수 있는 유일한 실제 옵션이 됨
          + 법률이 이를 금지해야 하지만, 허용된다면 경제의 미래는 모든 노동자가 한 대기업을 위해 일하고 모든 사람이 그곳에서 구매하는 상황이 될 것임
     * 나는 항상 어느 정도 반대했음. 이미 10개의 다른 검색 대안이 있고, 이제 AI가 등장하여 그들의 지배력을 약화시킬 것임
          + Google이 최고인 이유는 그들이 가장 잘하기 때문임. 나는 주로 Yandex를 사용하지만, 코딩 관련 질문에서는 Google로 돌아가곤 함
          + 광고 측면에서 Facebook/Instagram/X 등에서 수십억의 조회수를 얻을 수 있음
          + Google이 큰 플레이어라는 것은 이해하지만, 소비자에게 좋지 않아서가 아니라 Google이 약해졌기 때문에 그들을 공격하는 것이 아닌지 걱정됨
     * 이것이 독점인지 혼란스러움. ""Google 광고를 시장으로 정의하면 Google이 독점 문제를 갖는 것""인가?
          + 경매에서 가격을 올리려는 게임을 하더라도, 결국 X 회사는 천 클릭당 $5를 지출함. Google은 원하는 대로 요금을 부과할 수 있으며, 아무도 그들을 사용하도록 강요받지 않음
          + 정부가 앱 스토어는 독점이 아니라고 하면서 Google 광고는 독점이라고 말하는 것을 이해할 수 없음. 다른 광고 회사가 있으며, iOS에서 앱을 얻을 다른 방법은 없음
     * 광고를 덜 방해적으로 만드는 것을 목표로 하는 회사가 광고 시장에서 경쟁하는 것을 보고 싶음
          + 광고가 나를 공격하지 않고 읽는 동안 화면을 뛰어넘고 가려지지 않는다면, 제품에 대한 첫인상이 더 좋을 것임
          + 양질의 광고는 큰 프리미엄이 될 것임
     * Google의 핵심 사업은 광고임. 일부 수직 통합 보조 서비스(예: Chrome)는 반독점에 적합해 보이지만, 광고 자체는 예상하지 못했음. 광고가 없는 Google은 무엇일까?
     * Appnexus에는 10년이 너무 늦었음
     * 문제의 일부는 자본주의 시스템임. Google 주식은 시장에서 거래됨. 매년 성장해야 할 의무가 있음
          + 작은 스타트업일 때는 빠르게 성장할 수 있지만, Google 크기일 때 같은 일을 시도하면 이러한 문제에 빠지게 됨. 주주들의 압박 때문에 시장을 지배하려고 함
"
"https://news.hada.io/topic?id=20508","Show GN: 나만의 연합우주(fediverse) 마이크로블로그 만들기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show GN: 나만의 연합우주(fediverse) 마이크로블로그 만들기

   이 튜토리얼은 Fedify 라이브러리를 사용하여 ActivityPub 프로토콜 기반의 마이크로블로그 서비스를 구현하는 방법을 설명합니다. ActivityPub은 다양한 소셜 네트워크 서비스들이 서로 연동될 수 있게 해주는 분산형 소셜 네트워킹 프로토콜로, 이를 통해 Mastodon, Misskey 같은 서비스와 상호작용할 수 있는 독립적인 마이크로블로그를 만들 수 있습니다.

   튜토리얼은 Node.js와 TypeScript를 기반으로 하며, SQLite 데이터베이스를 사용하여 데이터를 저장합니다. 주요 과정은 계정 생성 페이지 구현, 프로필 페이지 개발, 액터와 키 쌍 구현, 수신함 기능 추가, 팔로우 및 언팔로우 기능 개발, 게시물 작성 및 표시, 팔로워/팔로잉 목록 구현, 타임라인 구현 등을 포함합니다. 이 과정에서 ActivityPub의 핵심 개념인 액터, 액티비티, 객체, 수신함 등을 실제 코드로 구현하며 이해할 수 있습니다.

   특히 이 프로젝트는 다른 ActivityPub 서버와의 실제 상호작용을 보여주며, JSX를 사용한 프론트엔드 구현과 ActivityPub 프로토콜 메시지 처리를 위한 백엔드 코드를 모두 다룹니다. 튜토리얼은 기본적인 보안 기능이 없는 것과 같은 제한사항이 있지만, 이를 직접 개선해볼 수 있는 방향성도 제시합니다.

   완성된 마이크로블로그는 Mastodon과 같은 연합우주(fediverse) 플랫폼과 상호작용할 수 있어, 게시물을 공유하고 다른 사용자를 팔로우하며, 다른 서버의 게시물도 볼 수 있습니다. 이 과정을 통해 분산형 소셜 미디어의 기본 원리와 구현 방법을 배울 수 있습니다.

   좋은 글 감사합니다. 연합우주에 관심이 많은데 좋은 프로젝트네요!
"
"https://news.hada.io/topic?id=20407","Show GN: AI 크래프팅 기반 서바이벌 생존 게임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Show GN: AI 크래프팅 기반 서바이벌 생존 게임

   2월에 AI 브라우저 게임의 초기 프로토타입을 올리고 게임 개발 관련 조언을 구했는데, Hacker News에서 약 100개 정도의 댓글이 달렸고 정말 많은 도움을 받았습니다. 이후 대부분을 다시 만들었고, 지금은 이렇게 발전했어요:

   업데이트 내용
     * 끝없이 펼쳐지는 세계: 산, 호수, 고도에 따라 쌓이는 눈
     * 살아있는 생태계: 나무가 자라고, 곰은 돌아다니다가 침범하면 돌진함
     * 시점 전환: V 키를 누르면 1인칭↔3인칭 바로 전환 가능
     * 게스트 모드: 로그인 없이 바로 플레이 가능
     * 자유로운 제작 시스템: “나무 글라이더”, “큰 벽”, “스테이크”처럼 아무거나 입력하면, 재료만 맞추면 AI가 제작법과 능력치를 자동 생성해줌

   아직 미완성이고 거친 부분도 많지만, 계속 개발 과정을 공유하고 피드백을 받고 싶습니다!

   직접 해보신다면 핵심 루프가 재미있는지, 버그는 없는지 등 피드백이나 아이디어들 언제나 환영입니다 :)
"
"https://news.hada.io/topic?id=20480","NerdLog - 타임라인 히스토그램을 갖춘 빠른 ​​다중 호스트 TUI 로그 뷰어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             NerdLog - 타임라인 히스토그램을 갖춘 빠른 ​​다중 호스트 TUI 로그 뷰어

     * 중앙 서버 없이 SSH 연결만으로 원격 로그 수집 및 분석이 가능한, 빠르고 리소스 효율적인 TUI 멀티 호스트 로그 뷰어
     * 타임라인 히스토그램 시각화와 시간 필터링으로 로그 흐름 파악이 용이함
     * 기본적인 awk, tail, head 조합을 사용하여 고속 처리 및 간편한 구축 지원
     * 로그 쿼리는 로컬 다운로드 없이 원격에서 처리, 네트워크 사용 최소화 및 대용량 로그 처리 최적화
     * 기본은 단순하지만 다양한 설정 파일, SSH config, UI 조작을 통한 확장성 보유
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Nerdlog 소개

     * Nerdlog는 중앙 서버 없이 작동하는 텍스트 기반 UI 로그 뷰어임
     * Graylog/Kibana처럼 로그를 분석할 수 있지만, 설치와 유지보수 부담이 없는 경량화 대안 도구임
          + 초기 개발 동기는 느리고 비효율적인 Splunk에 대한 실망에서 시작
     * 여러 원격 서버의 로그를 동시에 필터링 및 시각화하는 데 최적화되어 있음
     * 주로 시스템 로그(/var/log/messages, /var/log/syslog)를 처리하도록 설계되었지만, 다른 포맷도 지원함
     * 1GB 이상의 대용량 로그도 빠르게 처리 가능
     * 핵심 목표는 멀티 노드 로그 조회의 속도와 효율성 극대화

설계 특징

     * 중앙 서버 없이 동작하며, 각 노드에 대해 ssh 연결을 생성하고 대기 상태 유지
     * 전체 로그를 다운로드하지 않고, 질문당 최대 250개의 로그 메시지와 히스토그램 데이터만 전송
     * 모든 응답을 병합하여 통합된 뷰를 제공
     * 전송 시 Gzip 압축을 사용하여 네트워크 비용 절감

프로젝트 상태 및 역사

     * 2022년 개인 해커톤으로 느린 Splunk 대체용으로 제작되었으며, 2025년 오픈소스로 공개됨
     * 빠르게 구현되어 스파게티 코드가 존재하며 테스트 커버리지 부족
     * Linux 환경에서만 실제 사용 테스트 되었음
     * Proof-of-concept 단계지만, 실제 사용에 충분할 정도로 빠르고 안정적

사용법 요약

     * 앱을 실행하면 쿼리 입력창이 나타남
     * 로그스트림은 ssh로 접근 가능한 서버의 연속된 로그 파일들 의미
     * ssh 포트나 로그 파일 경로 등을 명시하거나, ssh config 및 별도 설정 파일 사용 가능
     * Select field expression은 UI에 표시할 필드를 SQL 스타일로 지정

   예시:
myuser@myserver.com
myuser@myserver.com:1234:/some/other/logfile

   예시 설정 파일 (~/.config/nerdlog/logstreams.yaml):
log_streams:
  myhost-01:
    hostname: actualhost1.com
    port: 1234
    user: myuser
    log_files:
      - /some/custom/logfile

UI 구성

     * Awk 패턴 입력 필터: /foo/, ( /bar/ || /baz/ ) && !/qux/ 등 지원
     * Edit 버튼: 전체 쿼리 입력 창 열기
     * Menu 버튼: 뒤로가기, 앞으로가기, 쿼리 복사 등 기능 제공
     * 히스토그램: 시간대별 로그 밀도 시각화 및 시간 범위 선택 가능
     * 로그 테이블: 최신 로그는 하단에 위치, 우측 스크롤로 상세 필드 확인 가능
     * 상태줄:
          + 초록: 연결 및 대기 중인 로그스트림 수
          + 주황: 현재 쿼리 중인 로그스트림 수
          + 빨강: 연결 중인 로그스트림 수
          + 우측 숫자: 전체 매칭 로그 수 / 현재 로딩된 로그 수 / 커서 위치
     * 명령줄: : 키로 접근하며 Vim 스타일 명령어 입력 가능

탐색 방법

     * 일반 키: Tab, Shift+Tab, Enter, Esc, PgUp, PgDn 등
     * Vim 스타일 키: h, j, k, l, g, G, Ctrl+U, Ctrl+D, i, a 등
     * 입력 필드 내에서는 Up, Down, Ctrl+P, Ctrl+N으로 히스토리 탐색
     * Ctrl+K, Ctrl+J: 전체 쿼리 히스토리 순회

주요 명령어

     * :xc 또는 :xclip: 현재 쿼리 상태를 명령어 문자열로 클립보드에 복사
nerdlog --lstreams 'localhost' --time -3h --pattern '/something/'

     * :back, :fwd: 브라우저처럼 이전/다음 쿼리로 이동
     * :edit: 쿼리 편집 창 열기
     * :write [filename]: 현재 로딩된 로그를 파일로 저장
     * :reconnect, :disconnect: 로그스트림 재연결 / 연결 해제
     * :set 옵션=값: 설정 변경 (numlines, timezone 등 지원)
     * :q: 프로그램 종료

요구 사항

     * 원격 호스트에 대한 SSH 접근 권한 필요
     * 로컬에서 SSH agent가 실행 중이어야 함
     * 호스트에는 gawk가 설치되어야 하며, mawk는 지원되지 않음
     * rsyslog 등의 시스템 로그 기록 서비스가 실행 중이어야 /var/log/syslog가 사용 가능함
     * 자세한 내용은 요구 사항 및 제약 항목 참고

마무리

     * Nerdlog는 설치 없이도 원격 로그를 빠르고 시각적으로 확인할 수 있는 효율적인 도구임
     * 복잡한 설정이 필요 없고, 네트워크 리소스를 절약하면서도 실시간 분석이 가능함
     * 특히 Vim 사용자나 CLI 도구 선호자에게 이상적인 로그 분석 도구임

        Hacker News 의견

     * 멋진 작업임. TUI가 정말 깔끔하고 상단의 히스토그램이 마음에 듦. 오늘 이걸로 놀아볼 예정임
     * 오늘 배운 것: awk 패턴은 단순한 정규 표현식 이상이며, 불리언 연산자와 결합할 수 있음. awk를 조금 써봤지만 이 점을 몰랐음
     * 정말 멋진 프로젝트임. 특히 타임라인 히스토그램과 원격 우선 설계의 단순함과 TUI 접근 방식을 좋아함
          + 여러 호스트의 로그를 처리할 때 비슷한 어려움을 겪었고, 그 결과 Logdy라는 도구를 만들게 되었음
          + Logdy는 웹 기반으로 실시간 테일링, 구조화된 로그 검색, 여러 소스에 대한 빠른 필터링에 중점을 둠. 중앙 서버가 필요하지 않음
          + 직접 비교하려는 것은 아니지만, 이 분야를 탐구 중이라면 보완적인 접근 방식이나 다른 시나리오에 유용할 수 있음
          + 여러 호스트에 대한 쿼리 기능 추가 작업이 필요함
          + 어쨌든 nerdlog에 찬사를 보냄. 여러 서비스를 실행할 필요 없는 간결한 도구를 보는 것은 항상 좋음
     * 랜딩 페이지에서 journalctl이 한 번 언급되며, 로그가 구식 syslog에 평문으로 저장되어야 한다는 암시가 있음
          + 평문 로그를 저장하고 logrotate 같은 오래된 해결책을 사용하고 싶지 않음
          + journald 자체는 원격 호스트에서 로그를 수신하고 (--merge를 사용하여) 검색할 수 있는 내장 기능이 있음
     * 나중에 꼭 이걸 가지고 놀아볼 예정임. gzipped 로그 아카이브가 지원되지 않음, 개인적으로 사용 사례를 최소화함
          + 사람들이 주목할 것이라고 생각하는 제한 사항으로 언급한 점은 충분히 고려한 것 같음. 결국 지원할 계획이 있는지 궁금함
     * 보기 좋음. 더 많은 사용자를 원한다면 주요 리눅스 배포판에 패키징하기 위해 커뮤니티의 도움을 받을 수 있음
     * 매우 좋음. 내 작은 로그 뷰어 목록에 추가했음 https://github.com/dloss/klp#alternative-tools
     * 좋음. 몇 년 전에 필요했음. 라이선스 파일이 없음?
     * 좋아 보임. 소스 코드를 변경하지 않고 RFC 3339 형식의 날짜/시간을 사용할 수 있는 방법이 있는지 궁금함
          + runit (Void Linux)와 함께 작동하는지 궁금함
     * 훌륭함. 이런 것을 찾고 있었음
     * AWS CloudWatch에서 로그를 볼 수 있는지 궁금함
"
"https://news.hada.io/topic?id=20468","새로운 ChatGPT 모델은 텍스트에 워터마크를 남기는 것으로 보임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 새로운 ChatGPT 모델은 텍스트에 워터마크를 남기는 것으로 보임

     * Rumi라는 곳에서 GPT-o3, o4-mini 모델에 대해 테스트해본 결과,
       긴 답변(예: 에세이 작성 등)에서 특수 문자 워터마크가 삽입되는 걸 발견했다고 함.
     * 이 워터마크는 ""Narrow No-Break Space (U+202F)"" 같은 유니코드 특수 공백 문자로 만들어짐.
     * 일반적인 눈으로는 전혀 보이지 않음, 하지만 Sublime Text, VS Code 같은 코드 에디터나 특수 문자 뷰어로 보면 드러남.
     * 복사-붙여넣기에도 이 워터마크는 살아남음(예: Google Docs로 복붙해도 남음).
     * 다만, 워터마크는 간단한 find-and-replace로 제거 가능하기 때문에 완벽한 방어책은 아님.
     * OpenAI는 공식적으로 이 워터마크 기능을 발표하지 않았음. (조용히 테스트 중인 것으로 추정)
     * GPT-4o 모델에서는 이런 워터마크가 관찰되지 않았다고 보고함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   추가로
     * 워터마크는 긴 텍스트(특히 과제나 리포트형 글) 에만 삽입되는 경향이 있고,
     * 짧은 대화나 일반 질문-답변에서는 거의 삽입되지 않음.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   요약 한 줄
   ""일부 최신 모델은 특수문자로 워터마킹을 시작했지만, 감지와 삭제가 쉬워서 완벽하지 않음.""

   [업데이트] OpenAI에서 루미에게 공식적으로 대응
   OpenAI는 이 게시물에 대해 우리에게 연락하여 특별한 캐릭터가 워터마크가 아니라고 알려주었습니다. OpenAI에서는 단순히 “대규모 강화 학습의 특이점”입니다. 하지만 우리는 게시물을 남겨두고 있어서, 미래의 독자들이 여전히 ChatGPT o3/o4 응답에서 이러한 특별한(그리고 잠재적으로 원치 않는) 문자들의 문제를 볼 수 있습니다.

   이번 o3가 환각이 엄청나게 심하다는 문제가 있었죠
   그중의 하나가 아닐까 싶었는데, 직접 연락한 건 재밌네요

   AI generated data르류학습데이터로 사용하지 않으러고 하는거 아닐까(model collapse) 싶네요

   워터마크가 아니라 버그 아닐까요? 테스트라고 생각해도 현재 논의되는 llm 워터마크 기술에 비해 터무니없이 심플한데요..

   주장의 특이한 경향성을 말할 줄 알았는데 아니었네요. 너무 단순한 해결책 아닐까요.

   음... 이런 워터마크 때문일까요? 최근들어 챗지피티 상에서는 잘 보이는 한글이 긁어서 복사 붙여넣기 하면 깨진채로 붙는 현상을 경험한 적이 꽤 있어요
"
"https://news.hada.io/topic?id=20447","비디오 생성용 Next-Frame Prediction 모델에서 Packing Input Frame Context 활용","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   비디오 생성용 Next-Frame Prediction 모델에서 Packing Input Frame Context 활용

     * 비디오 생성을 위한 다음 프레임 예측 모델에서 입력 프레임 컨텍스트를 패킹하는 방법에 대한 연구임
     * FramePack은 GPU 메모리 레이아웃을 최적화하여 프레임 예측을 효율적으로 수행하는 방법임
     * 프레임 중요도에 따라 GPU 리소스를 할당하여 컴퓨팅 복잡도를 O(1)로 줄임
     * 드리프팅 문제를 해결하기 위해 양방향 샘플링을 제안함
     * 이미지-비디오 변환에서 첫 프레임을 중요하게 다루는 반전 안티-드리프팅 샘플링 방법을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

비디오 생성에서 입력 프레임 패킹

     * 다음 프레임 예측 모델은 여러 입력 프레임을 사용하여 새로운 프레임을 생성하는 방식임
     * FramePack은 입력 프레임을 GPU 메모리 레이아웃에 맞게 인코딩하여 효율적인 프레임 생성을 가능하게 함
     * 각 프레임은 패치화 커널을 사용하여 인코딩되며, 중요도에 따라 컨텍스트 길이가 조정됨
     * 예를 들어, HunyuanVideo에서는 480p 프레임이 (1, 2, 2) 패치화 커널을 사용하면 1536 토큰이 되고, (2, 4, 4) 패치화 커널을 사용하면 192 토큰이 됨

프레임 중요도와 스케줄링

     * 중요한 프레임은 더 많은 GPU 리소스를 할당받음
     * 다양한 압축 패턴을 통해 시작 프레임을 동일하게 중요하게 만들 수 있음
     * 모든 스케줄링은 O(1) 복잡도를 가짐
     * 논문에서는 여러 스케줄링에 대한 상세한 평가를 제공함

드리프팅 문제와 해결 방법

     * 드리프팅은 비디오가 길어질수록 품질 저하가 발생하는 문제임
     * 오류 누적 또는 노출 편향이라고도 불림
     * 이를 해결하기 위해 인과성을 깨고 양방향 샘플링을 도입함
     * 반전 안티-드리프팅 샘플링은 모든 추론에서 첫 프레임을 근사 목표로 삼음

이미지-비디오 변환 성능

     * RTX 3060 6GB 노트북에서 13B HY 변형을 사용하여 이미지-5초 및 이미지-60초 비디오를 생성함
     * 결과는 h264crf18로 압축되어 GitHub 저장소에 맞춤

        Hacker News 의견

     * 이 사람은 천재임. 그가 ControlNet도 개발했다는 사실을 모르는 사람들을 위해 말하자면, 이 모델은 소비자 하드웨어에서 실행되는 최초의 괜찮은 비디오 생성 모델임. ControlNet의 포즈 지원도 곧 기대됨
          + 재미있게도 이 모델은 사람들이 춤추기를 정말로 원함. 인터뷰를 위해 앉아 있는 사람조차도 앉아서 춤을 추기 시작함
          + 예시들이 상당히 인상적이며, 이를 생성하는 데 사용된 자원은 거의 미미함. 이전 세대 소비자 하드웨어에서도 추론이 가능해 보임. 5090에서의 추론 처리량 통계도 보고 싶음
          + 공간적으로도 이 작업을 할 수 있을까? 예를 들어, 이미지를 한 번에 생성하는 대신 위에서 아래로 생성할 수 있을까
          + 이 모델이 비디오 외삽 대신 보간에 사용될 수 있을까
          + 놀라움. 더 많은 RAM이 있거나 다른 것이 있다면 더 빨라질 수 있을까? H100이나 H200에서 더 많은 속도를 낼 수 있을까
          + 이 모델이 할 수 있는 유일한 움직임은 춤추는 것처럼 보임
"
"https://news.hada.io/topic?id=20449","Vibe 코딩은 저품질 작업에 대한 변명이 될 수 없어요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Vibe 코딩은 저품질 작업에 대한 변명이 될 수 없어요

     * AI 기반 바이브 코딩은 혁신적이지만, 품질 없는 속도는 위험하다는 경고의 글

     ""더 빨리 움직이고, 더 많이 망가뜨려라""
     ""vibe coding, 두 명의 엔지니어가 50명의 기술 부채를 만들어낼 수 있는 방식""

     * 이 실리콘밸리의 오래된 슬로건을 비튼 표현은 최근 엔지니어링 커뮤니티에서 “vibe coding”이라는 개념으로 회자되고 있음
     * AI 기반 개발이 소프트웨어 제작 방식을 혁신하고 있는 것은 사실이지만, 그렇다고 해서 엄격함, 리뷰, 장인정신을 버릴 수 있는 면허는 아님
     * ""vibe coding""은 낮은 품질의 작업을 정당화하는 핑계가 될 수 없음

     * 장점을 인정하자면, AI 보조 코딩은 게임 체인저가 될 수 있음
     * 새로운 프로그래머나 비전문가의 진입 장벽을 낮추고, 그들이 필요를 설명하는 것만으로 작동하는 소프트웨어를 만들어낼 수 있게 함
     * 이는 창의력을 해방시키며, 더 많은 사람들이 자신의 문제를 맞춤형 소프트웨어로 직접 해결할 수 있게 함
     * 이러한 흐름은 퍼스널 소프트웨어의 언번들링(기성 앱 대신 소규모 AI 기반 도구 사용)이라는 트렌드의 일부로 간주됨
     * 숙련된 엔지니어들도 이득을 볼 수 있음

     * 하지만 경험 많은 엔지니어라면 누구나 말하듯, 속도는 그 끝에서 바퀴가 빠진다면 아무 의미가 없음
     * 그리고 바로 여기에서 균열이 보이기 시작함 — vibe와 실제 현실 사이의 간극, 즉 유지보수 가능하고 견고한 소프트웨어를 구축하는 데 따르는 현실의 차이

불편한 진실: 품질은 자동으로 따라오지 않음

     * hype는 크지만, vibe coding에 대한 베테랑 개발자들의 회의도 만만치 않음
     * 핵심 비판은 이렇다: AI가 빠르게 코드를 뱉어낸다고 해서, 그 코드가 좋은 것은 아니다
     * 사실, AI가 생성한 코드를 그대로 믿고 사용하는 것은 꽤 위험할 수 있음
     * “두 명의 엔지니어가 50명 분량의 기술 부채를 만든다”는 농담은 완전히 농담만은 아님
     * 검토되지 않은 AI 코드가 기술 부채를 대규모로 확대시킬 수 있음
       → 이 부채는 코드를 취약하고 유지보수하기 어렵게 만들며, 장기적으로 큰 비용을 초래함

     * vibe coding으로 만들어진 프로젝트는 종종 겉보기에는 훌륭해 보임 (""잘 작동하네, 배포하자!"")
     * 하지만 실제로는 다음과 같은 위험 요소를 숨기고 있음:
          + 에러 처리가 없음
          + 성능이 떨어짐
          + 보안 방식이 불안정함
          + 논리 구조가 약하고 깨지기 쉬움
     * 이런 프로젝트는 모래 위에 지어진 구조물 같고,
     * 내가 부르는 표현으로는 “카드로 만든 집(house of cards code)” 임 —
       겉보기에는 완성된 듯하지만, 현실적인 압력에는 쉽게 무너짐
     * 주니어 개발자의 첫 대형 기능이 거의 작동하지만 예상 못 한 입력 하나로 바로 망가지는 장면을 본 적 있다면, 그 느낌을 알 것임
     * AI는 많은 양의 코드를 빠르게 만들어낼 수는 있지만, 양이 질을 의미하지는 않음

     * ""AI는 팀에 합류한 매우 열정적인 주니어 개발자 같은 존재다""
     * → 이 개념은 Forrest Brazeal의 일러스트를 통해 잘 설명됨

     * 이 위험은 단순한 가설이 아님, 실제 유지보수 측면에서도 문제는 현실적임
     * AI가 만들어낸 모듈이 지나치게 복잡하거나 이해하기 어려울 경우, 누가 유지보수를 담당할 것인가?
     * 심지어 처음 작성한 개발자조차도 AI가 만든 코드를 완전히 이해하지 못한다면,
       그 코드는 향후 수정이나 확장에 있어 악몽이 될 수 있음

     * 보안은 또 다른 커다란 문제임
     * AI는 겉보기에는 잘 작동하는 코드를 만들 수 있지만, 그 안에는 SQL 인젝션 같은 치명적인 취약점이 숨어 있을 수 있음
     * 혹은, 에러 처리가 부실하게 되어 있을 가능성도 있음
     * 이러한 문제가 철저한 리뷰 없이 프로덕션에 반영된다면 실제 사고로 이어질 수 있음

     * 또 하나의 문제는 프롬프트 과적합(overfitting to the prompt) 임
       → AI는 당신이 요청한 대로 정확히 수행하지만, 그게 진짜로 필요한 것과는 다를 수 있음
     * 인간 개발자는 구현하면서 설계의 오류나 오해를 발견하고 이를 수정함
     * 반면, AI는 이런 오해를 전혀 인지하지 못하고, 사람이 이를 발견해 고치지 않으면 문제는 방치됨

     * 물론, 이 모든 것이 AI가 좋은 코드를 절대 못 쓴다는 뜻은 아님 —
     * AI는 때때로 훌륭한 코드를 만들어냄
     * 하지만 그 코드를 실제로 사용해도 되는지를 판단하려면, 다음 세 가지가 반드시 필요함:
          + 맥락(context)
          + 비판적 검토(scrutiny)
          + 경험과 전문성(expertise)

     * 2025년 현재, 우리가 사용하는 AI는 열정은 넘치지만 경험이 부족한 어시스턴트와 같음
     * 1년 차 신입 개발자에게 아무런 감독 없이 전체 시스템 설계를 맡기지 않는 것처럼,
       AI의 코드도 검토 없이 받아들이면 안 됨
     * “AI 매직”에 대한 기대는 이제 소프트웨어 엔지니어링의 현실과 조화를 이루어야 함

     * 그럼 어떻게 균형을 잡을 것인가?
     * 중요한 건 vibe coding을 완전히 배척할 필요는 없다는 것
     * vibe coding은 때로 매우 유용할 수 있음
     * 하지만 중요한 건 훈련된 방식으로 통합하는 것 — 즉, AI를 제한이 명확한 도구로 보는 시각
     * 이는 곧, 사람이 루프 안에 있어야 하며, 우리가 가진 품질 기준과 엔지니어링 원칙을 지키는 방식으로 AI를 사용하는 것

AI는 대체자가 아니라 인턴입니다 (사람이 루프 안에 있어야 함)

     * vibe coding을 효과적으로 활용하려면 AI를 ‘매우 빠르지만 미숙한 팀의 인턴 개발자’로 대하라는 마인드셋 전환이 필요함
     * 즉, 당신 — 시니어 엔지니어나 팀 리드 — 가 여전히 결과물에 대한 최종 책임자임
     * AI가 초안을 빠르게 뽑아줄 수는 있지만, 비판적인 시각으로 리뷰하고, 수정 및 품질 기준 충족 여부를 확인해야 함

     * 숙련된 개발자들은 이 과정을 직관적으로 따름
     * AI가 코드를 제안했을 때, “Accept”를 누르고 바로 넘어가는 것이 아니라 아래와 같이 대응함:
          + AI가 작성한 코드를 먼저 읽고 이해함 — 마치 주니어 개발자가 작성한 코드처럼 대함
          + 코드가 단일 블록이나 난잡할 경우 모듈화 및 리팩터링 — 더 작고 명확한 단위로 쪼개는 작업 수행
          + 누락된 예외 처리나 엣지 케이스를 직접 추가 — null 체크, 입력 검증 등은 AI가 자주 빠뜨림
          + 느슨한 타입이나 불완전한 추상화를 강화 — 암묵적 가정을 명시적 계약으로 전환
          + AI가 선택한 아키텍처나 방식이 비효율적인지 평가 — 예: 브루트포스 처리, 글로벌 상태 도입 등
          + 테스트 작성 또는 수동 테스트 수행 — AI가 유닛 테스트를 생성했다면, 그 테스트가 유효한지도 반드시 검토

     * 이 모든 과정을 통해 AI가 만든 코드에 엔지니어링의 통찰(wisdom) 을 주입하게 됨
     * 이 조합은 매우 강력할 수 있음 — AI는 속도를 제공하고, 사람은 신뢰성을 보장함
     * 실제로 연구 및 현업 경험에 따르면, 시니어 개발자가 주니어보다 AI 코딩 도구에서 더 큰 가치를 얻음
     * 그 이유는 시니어는 AI의 출력을 바르게 이끌고, 오류를 고칠 수 있는 지식과 경험이 있기 때문임
     * 반면, 주니어는 AI를 절대적인 권위처럼 잘못 믿을 위험이 큼

     * 따라서 중요한 규칙이 하나 생김:
       → AI가 작성한 코드는 반드시 리뷰 후 반영할 것
     * 신입 개발자의 PR을 검토하듯, 한 줄 한 줄 읽고 완전히 이해한 뒤에만 머지해야 함
     * AI가 더 똑똑하다고 전제하지 마라 — 대부분의 경우 그렇지 않음
     * 이해가 안 되는 부분은:
          + 프롬프트를 다시 다듬어 명확히 요청하거나
          + 직접 해당 코드를 다시 작성하는 것이 바람직함
     * AI의 출력은 ‘초안’일 뿐이며 반드시 리뷰를 거쳐야 함
     * 팀 개발 환경이라면:
          + 누군가가 AI를 이용해 코드를 만들었다면,
          + 그 코드에 대해 리뷰에서 직접 설명하고 방어할 수 있어야 함
          + “그냥 작동하니까요”는 통하지 않음 — 사람이 이해하고 유지보수할 수 있어야 진짜 코드임

     * 또 하나의 모범 사례: 설계는 사람이, 구현은 AI가
     * 즉, AI는 CRUD API 같은 이미 정의된 작업을 빠르게 구현하는 데 활용
     * 반면, “확장 가능한 마이크로서비스 아키텍처를 설계해줘” 같은 요청은 사람이 해야 함
     * 고수준의 설계 및 핵심 의사결정은 사람의 몫으로 남겨야 함
     * 요약하면: AI에게는 단순 반복 작업(grunt work)을, 사람에게는 사고와 판단(brain work)을 맡기자

     * 커뮤니케이션과 문서화도 매우 중요해짐
     * 복잡한 알고리즘이나 생소한 라이브러리를 AI에게 요청했다면,
          + 그 선택의 이유와 의도를 꼭 문서화해야 함
          + 미래의 유지보수자 또는 미래의 나 자신이 그 코드를 왜 그 방식으로 만들었는지 알 수 있어야 함
     * 몇몇 팀들은 중요한 AI 코드 생성 시 사용한 프롬프트 자체를 기록하기도 함
       → 디버깅 시 AI와의 “대화 내역”을 참조할 수 있어 유용함

     * 결론적으로, 사람의 개입은 선택사항이 아닌 필수사항임
     * 사람이 빠진 채 AI 코드만 사용하는 건, 소프트웨어 품질에 주사위를 던지는 일
     * AI가 시니어 엔지니어의 전체적인 이해력을 대체할 수 있는 시대는 아직 아님
     * vibe coding은 파트너십이어야 함 —
       → AI는 속도를 낼 수 있고, 사람은 그 속도에 안전벨트를 채워주는 역할

고품질 vibe coding을 위한 실전 규칙

     * 이제까지의 논의를 실행 가능한 규칙과 베스트 프랙티스로 정리해보자
     * 이것은 새로운 시대의 “빠르게 움직이되, 모든 걸 망치진 말자” 핸드북이라 할 수 있음
     * vibe coding을 하면서도 품질을 지키기 위한 가드레일 역할을 하는 규칙들임

     * Rule 1: Always Review AI-Generated Code / AI 코드 반드시 리뷰하기
          + 예외 없음. AI가 작성한 모든 코드는 주니어 개발자가 작성한 코드처럼 리뷰해야 함
          + 개별 리뷰이든 동료 리뷰이든 반드시 수행
          + Copilot, ChatGPT, Cursor 등 어떤 AI라도 마찬가지
          + 리뷰할 시간이 없다면, 그 코드를 쓸 시간도 없는 것
          + 리뷰 없이 AI 코드를 머지하는 건 리스크를 그대로 끌어안는 것과 같음
     * Rule 2: Establish Coding Standards and Follow Them / 코딩 스타일과 기준을 설정하고 준수할 것
          + AI는 학습한 코드 스타일을 그대로 반영하므로, 일관된 팀 기준이 없다면 품질이 들쭉날쭉해짐
          + 팀의 스타일 가이드, 아키텍처 패턴, 코딩 규칙을 명확히 정의해야 함
          + 예: “모든 함수에는 JSDoc과 유닛 테스트가 있어야 한다” → AI가 생성한 코드도 마찬가지로 적용
          + 계층 구조나 레이어드 아키텍처를 사용하는 프로젝트에서,
            AI가 UI 코드 안에 DB 호출을 넣지 않도록 리팩터링 필수
          + 흔한 AI 실수(ex: 복잡한 함수, deprecated API 사용 등)를 잡는 lint 또는 정적 분석 룰 도입 추천
     * Rule 3: Use AI for Acceleration, Not Autopilot / AI는 가속기이지 자동 조종 장치가 아님
          + vibe coding은 잘 알고 있는 작업을 빠르게 처리하는 용도로 사용해야 함
          + 좋은 활용 예:
               o 보일러플레이트 생성
               o 컴포넌트 스캐폴딩
               o 언어 변환
               o 간단한 알고리즘 뼈대 작성
          + 위험한 사용 예:
               o 애매한 설명으로 모듈 전체를 설계하게 하기
               o 잘 모르는 도메인에 코드 생성 시도
          + 코드가 영구적으로 남을 예정이라면, 반드시 vibe 모드에서 engineering 모드로 전환 필요
     * Rule 4: Test, Test, Test / 테스트는 무조건 해야 한다
          + AI가 코드를 생성했다고 해서 자동으로 정답이 되는 건 아님
          + 모든 주요 경로에 대해 테스트 작성 필수
          + AI가 테스트도 만들어줬다면, 그 테스트가 실제로 유효한지도 검토 필요
          + 특히 UI 기능이나 유저 입력이 많은 부분은 직접 클릭, 비정상 입력 테스트 필수
          + vibe-coded 앱은 해피 패스만 잘 작동하고, 예외 입력에 취약한 경우가 많음
     * Rule 5: Iterate and Refine / 반복하고 다듬기
          + AI가 처음 준 결과물이 만족스럽지 않다면, 그냥 넘어가지 말고 다시 시도하거나 리팩터링
          + vibe coding은 대화 기반의 반복적 프로세스임
          + 예:
               o “이 코드 더 간결하게 해줘”
               o “작은 함수들로 나눠줘” 등 프롬프트 재조정
          + 또는 직접 리팩터링 → 수정 포인트 → 다시 프롬프트 → 반복
          + AI와의 사이클 사용 전략이 효과적
     * Rule 6: Know When to Say No / 거절할 줄 알아야 함
          + vibe coding이 항상 최선은 아님
          + 중요한 설계나 보안이 필요한 상황에선 직접 작성하는 것이 낫다
          + 예:
               o 보안 관련 모듈은 직접 설계하고, 일부만 AI 활용
               o 단순한 문제에 대해 AI가 복잡하게 답할 경우, 직접 짜는 게 더 빠름
          + AI가 문제를 제대로 해결하지 못할 때는 고집하지 말고 수동 모드로 전환할 것
          + ""AI가 해줬으니까""는 내가 내 코드를 이해하지 못해도 된다는 핑계가 아님
     * Rule 7: Document and Share Knowledge / 문서화하고 지식을 공유하라
          + AI가 생성한 코드도 직접 쓴 코드만큼 문서화가 되어야 함 (때로는 더 많이)
          + 비직관적인 결정이나 특이한 구현이 있다면 주석을 남겨야 함
          + 어떤 부분이 AI 생성인지 팀원에게 명확히 공유
          + 일부 팀은 주요 AI 코드에 사용한 프롬프트를 그대로 저장함 → 디버깅에 유용

     * 위 규칙을 따름으로써, 팀은 vibe coding의 생산성을 최대한 활용하면서도 리스크를 최소화할 수 있음
     * 핵심은 AI가 사람을 대체하는 게 아니라 보완하는 것
     * AI는 반복 작업을 빠르게, 사람은 비판적 사고와 창의성을 담당
     * 우리는 AI와 함께 코드를 만드는(co-create) 시대에 살고 있음

vibe coding이 잘 작동하는 경우 vs 무너지는 경우

     * vibe coding이 어디에서는 빛나고, 어디에서는 그렇지 못한지를 명확히 아는 것도 중요함
     * 모든 프로젝트나 작업이 AI 기반 워크플로우에 동일하게 적합한 것은 아님
     * 아래는 업계 경험과 사례를 기반으로 정리된 활용 구분

     * 👍 잘 작동하는 상황 (Great Use Cases)
          + Rapid prototyping (빠른 프로토타입 제작)
            → vibe coding의 스위트 스팟. 작은 앱이나 기능 아이디어가 있을 때
            → AI 어시스턴트를 이용해 빠르게 개념 증명 또는 프로토타입을 만들 수 있음
            → 코드가 조금 엉성해도 괜찮음 — 핵심은 아이디어 검증
            → 주말 프로젝트 등에서 AI만으로 앱을 만들고 개념을 테스트하는 사례 다수
          + One-off scripts / Internal tools (일회성 스크립트, 내부 도구)
            → 로그 파일 파싱, 개인 작업 자동화, 내부 대시보드 등
            → 실패해도 리스크가 크지 않은 환경에서는 vibe coding이 시간 절약에 효과적
            → 프로덕션급 품질이 필요 없는 상황에서 “당장 되는 것”을 빠르게 만들 수 있음
          + Learning and exploration (학습 및 실험)
            → 새로운 언어나 API를 배울 때 AI에게 예제 생성을 요청
            → 완벽한 코드가 아니더라도 학습 재료로서 충분
            → 마치 **가상의 TA(조교)**가 다양한 시도를 보여주고, 그걸 사람이 다듬는 느낌
          + Boilerplate-heavy tasks (보일러플레이트 작업)
            → 예: 비슷한 데이터 클래스 10개 생성, CRUD 구현
            → 구조만 명확하다면, AI는 반복적인 패턴을 정확히 따라 해줌
            → 기계적인 작업을 빠르게 넘기고, 사람은 중요한 부분에 집중 가능
     * 👎 문제가 발생하는 상황 (Not-So-Great Use Cases)
          + Enterprise software / Complex systems (엔터프라이즈급 소프트웨어, 복잡한 시스템)
            → 복잡한 비즈니스 로직, 동시성, 보안, 컴플라이언스 요구사항이 있는 시스템
            → AI는 명시적으로 말해주지 않으면 그런 조건을 모름, 알고 있어도 반영이 부족할 수 있음
            → 예: 핀테크 결제 시스템, 항공우주 제어 소프트웨어 등은 절대 AI 단독으로 맡기면 안 됨
            → 이런 환경에서는 일부 보조만 가능하며, 최종 품질은 사람의 QA와 전문성이 필수
          + Long-term maintainability (장기 유지보수성)
            → 수년간 지속될 코드베이스는 시작부터 구조가 중요함
            → AI로 땜질하며 만든 코드들은 일관성이 떨어지고, 후속 유지보수에 큰 부담
            → 차라리 초기에 시간을 들여 명확한 프레임워크와 설계를 잡는 것이 좋음
            → 많은 초기 사용자들이, vibe coding으로 아낀 시간이
            나중에 리팩터링과 정리 작업으로 도로 들어간다는 경험 공유함
          + Critical algorithms / Optimizations (고성능 알고리즘 또는 최적화 작업)
            → 예: 커스텀 메모리 관리, 초고속 정렬 알고리즘 등
            → AI는 소규모 입력에 대해서는 괜찮지만, 스케일에 대한 고려가 부족함
            → 경고 없이 느려지거나, 잘못 동작할 수 있음
            → 이런 부분은 여전히 사람의 창의성과 깊은 이해력이 필요함
          + Explainability and clarity (명확성과 설명 가능성)
            → 코드가 다른 개발자나 감사자에게 명확하게 읽혀야 하는 상황
            → AI가 과하게 추상화하거나 복잡한 방식으로 접근할 경우, 가독성과 유지보수성이 심각하게 저하
            → 현재 AI는 “짧고 간결한 코드”를 항상 지향하지 않음 → 때론 과도하게 verbose하거나 불필요하게 추상화됨
            → 이런 경우, 사람의 리팩터링과 명확한 코드 작성이 필요함
     * 요약하자면, vibe coding은 강력한 가속 도구지만 만능 해결사는 아님

     * 속도가 중요하고, 결과를 몇 번 고쳐도 되는 작업에는 매우 효과적
     * 반면, 미션 크리티컬한 소프트웨어를 한 번에 AI에게 맡기는 건 위험한 시도임
     * 비유하자면: 레이스카 드라이버에게 학교 버스를 맡기는 격 — 좋은 도구지만 잘못된 용도

     * 언젠가 AI가 모든 개발의 기본 툴이 될 수 있을지는 모르지만, 오늘은 아님
     * 오늘 우리가 할 일은, AI를 올바른 문제에, 올바른 방식으로, 올바른 책임 하에 사용하는 것

결론: 신중하게 vibe하라 – 속도를 즐기되, 장인정신을 잃지 말자

     * vibe coding과 AI 기반 소프트웨어 개발은 도구의 진화에서 거대한 도약을 의미함
     * 이 흐름은 일시적인 유행이 아니라, 이제 자리를 잡은 현실이며, 앞으로 더 정교해질 것
     * 미래를 내다보는 엔지니어링 팀이라면 이를 외면해서는 안 됨
     * 이전의 자동화 도구나 고급 프레임워크가 기존 개발 방식을 앞질렀듯,
       AI를 잘 활용하는 팀이 그렇지 않은 팀을 능가할 가능성이 큼
     * 이 글의 메시지는 vibe coding을 거부하라는 것이 아님 —
       → 눈을 뜬 채로, 엔지니어링의 기본을 지키며 접근하라는 것

     * 가장 중요한 교훈: 속도는 품질 없이는 무의미함
     * 버그 많고 유지불가한 코드를 빨리 배포하는 건 속도를 내며 낭떠러지로 가는 것일 뿐
     * 최고의 개발자란, AI로 속도를 높이되 시스템을 무너뜨리지 않는 사람들
     * AI가 무게를 들어주고, 사람이 그것이 제대로 서 있는지를 확인하는 구조
     * 그 균형점(sweet spot) 을 찾는 것이 핵심

     * 기술 리더와 매니저를 위한 실천 포인트:
       → AI는 책임감 있게 사용하는 도구라는 문화를 팀에 정착시켜야 함
          + vibe coding을 장려하되, 코드베이스를 지키기 위한 명확한 기대치와 룰도 같이 세워야 함
          + AI 생성 코드도 무조건 코드 리뷰 대상으로 삼고,
               o “이 코드 이해돼?”라는 질문이 자연스러운 문화 형성
          + 팀 전체가 AI와 효과적으로 협력할 수 있도록 역량 강화에 투자
               o 좋은 프롬프트 작성법, AI 제안 평가법 등 새로운 스킬셋 도입
          + 이는 과거 고급 언어 전환, Git 도입 때와 같은 패러다임 변화임
            → 빨리 적응하는 팀이 이득을 볼 것

     * 우리가 소프트웨어 엔지니어링에서 진짜로 중요하게 여겨야 할 것은 여전히 다음과 같음:
          + 사용자 문제를 해결하는 것
          + 신뢰할 수 있는 시스템을 만드는 것
          + 계속해서 배우는 것
     * vibe coding은 수단이지, 목적이 아님
     * 사용자에게 더 빠르고 더 나은 가치를 제공한다면 훌륭한 도구
     * 하지만 그 과정에서 우리가 믿어야 할 품질과 보안을 희생하게 만든다면, 사용을 자제해야 함
     * 본질은 여전히 유효함:
       → 명확한 사고, 요구사항 이해, 변화에 대비한 설계, 철저한 테스트

     * 마지막으로 이 정신을 새기자:
       → “빠르게 움직이되, 망가뜨리지 말 것 – 혹 망가뜨리더라도 반드시 고칠 수 있도록.”
     * 속도감 있게 코드를 만들되, 그 바탕엔 견고한 엔지니어링 기반이 있어야 함
     * AI는 장인의 손에 쥐어진 강력한 끌일 수 있음
       → 하지만 여전히 그 끌을 다루는 건 사람의 손

     * 그러니 개발자들이여, vibe하라 – 하지만 신중하게 vibe하라
     * 미래를 받아들이되, 우리를 여기까지 이끈 기본 원칙은 놓치지 말자
     * vibe coding은 낮은 품질을 정당화하는 핑계가 아니라,
       → 인간의 판단력과 기계의 생성 능력이 결합될 때 우리가 얼마나 더 큰 것을 만들 수 있는지 보여주는 기회

     * 이 원칙을 내면화한 팀은 단순히 빨라지는 것이 아니라,
       → 오랫동안 살아남을 가치 있는 소프트웨어를 만들게 될 것임

     Happy coding — 그리고 vibe는 높게, 품질은 더 높게.

   +1
   공감합니다.

   스압주의

        Hacker News 의견

     * ""vibe coding""의 의미가 무엇인지 재정의했음
          + 원래 트윗은 AI가 생성한 코드를 품질에 상관없이 받아들이고 원하는 결과가 나오지 않으면 무작위로 다시 시도하는 것에 대해 언급했음
          + 사람들이 이제 이 용어를 ""AI 에이전트에게 광범위한 작업을 맡기는 것""으로 사용하고 있는지 궁금함
     * AI 코딩의 과대광고가 너무 커서 현실적으로 충족할 수 없음을 느꼈음
          + 복잡한 코드베이스에 대한 단위 테스트를 AI 코딩 앱에 맡겼으나 80%가 실패했음
          + 경험 많은 인간 개발자는 이를 시작점으로 사용할 수 있었고, 반복적인 작업을 줄여줌
          + AI는 현재 반복적인 작업을 가속화하는 데 유용하지만, 인간 개발자를 대체할 수는 없음
     * 2000년대 초반 대기업들이 저소득 국가에 개발 작업을 아웃소싱하려 했던 시기를 떠올리게 함
          + 아웃소싱된 개발자들이 시스템의 핵심 아이디어를 이해하지 못하고, 명세서에 적힌 대로만 개발함
          + 결과적으로 명세서와 구현이 원하는 품질 수준에 도달하려면 많은 시간이 소요됨
          + AI 코딩도 비슷한 상황이며, 프로토타입이나 빠른 솔루션에는 유용하지만 인간의 이해와 창의성을 대체할 수 없음
     * AI를 팀의 초급 개발자로 대하는 것은 더 많은 시간이 소요될 수 있음
          + AI가 생성한 코드는 그럴듯해 보이지만, 실제로는 문제가 있을 수 있어 주의가 필요함
     * 사용 사례에 따라 다름
          + 컨설턴트로서 비즈니스 프로세스 자동화와 클라우드 시스템 통합 작업을 주로 함
          + AI 에이전트와의 협업이 게임 체인저가 되었고, 기술 요구 사항 작성과 코드 리뷰에 집중할 수 있게 됨
          + 제한된 예산 내에서 더 많은 것을 달성할 수 있게 되어 출력 품질이 크게 향상됨
     * 소프트웨어 품질에 대한 다양한 관점이 존재함
          + 사용자 관점의 품질: 버그가 적고, 문제를 정확히 모델링하며, 불필요하게 복잡하지 않음
          + 개발자 관점의 품질: 코드가 깔끔하고 명확하며, 확장이나 변경이 용이함
          + AI가 공식 명세와 테스트 방법을 만족시키는 데 집중한다면, 두 번째 종류의 품질은 중요하지 않게 될 수 있음
     * AI 보조 코딩이 개발자의 성장에 부정적인 영향을 미칠지에 대한 질문이 있음
          + 장기적으로 개발자의 수요가 증가할지, 단기적으로 감소할지 궁금함
     * vibe coding을 통해 작업의 난이도를 파악함
          + 프로토타입을 만들고, 라이브러리를 테스트하여 문제를 해결할 수 있는지 확인함
          + LLM이 잘못된 매개변수나 함수를 제안할 때도 있지만, 시간을 절약할 수 있음
     * 사람들은 에너지를 절약하려는 경향이 있으며, vibe coding은 저노력 개발을 가능하게 함
          + 중요한 프로젝트에는 적합하지 않지만, 개인 프로젝트에는 유용할 수 있음
     * 전체 기사가 ""vibe code를 프로덕션에 배포하기 전에 인간이 검토해야 한다""는 문장을 부풀린 것처럼 보임
"
"https://news.hada.io/topic?id=20437","[번역] 낙관주의는 현실이 됩니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [번역] 낙관주의는 현실이 됩니다

     * 두려움의 대상: 스타트업이 빠른 실행력을 잃고 대기업처럼 느려지는 것.
          + 초기 직원의 효율성을 이후 직원들도 유지해야 함.
     * 업무 처리 속도의 핵심 요소:
          + 업무의 소요시간을 미리 예상하는 ‘관점(Scope)’과 낙관적 태도가 실제 업무 속도에 큰 영향을 미침.
          + 보통 업무 소요 시간이 관점에 영향을 준다고 생각하지만, 실제로는 반대임.
          + 관점이 업무 완료 시간에 영향을 줌:
               o 오래 걸린다고 생각하면 오래 걸리고, 빨리 끝날 거라 생각하면 빨리 끝남.
     * 관점이 실제 성과에 영향을 주는 사례:
          + 마라톤 완주 기록 히스토그램에서 깔끔한 숫자(3시간, 3시간 반 등)에 유독 기록이 많음:
               o 인간은 설정된 목표를 달성하기 위해 노력하는 성향이 강함 (자연스럽게 목표에 맞추는 '림보 효과(Limbo Effect)').
          + 4분 마일의 사례:
               o 이전까지 불가능하다고 여겼던 기록이 깨지자 갑자기 많은 사람이 그 기록을 넘음.
          + 학생들이 마감 직전에 과제를 완료하는 현상 역시 같은 원리로 설명됨.
     * 스타트업과 림보 효과:
          + 높은 긴급성 상황(예: 사이트 다운, 초기 스타트업 환경)은 ""마감일이 지금""이라는 인식으로 인해 매우 빠르게 업무가 진행됨.
          + 반면, 현실적인 관점(평균 소요시간)을 설정하면:
               o 일찍 끝내도 큰 이득이 없고, 늦으면 손해이므로 결국 ‘관점’ 근처의 시간에 업무를 완료하게 됨.
               o 이는 평균적으로 일을 더 느리게 만듦.
     * 낙관적인 관점이 중요한 이유:
          + 상위 10%의 빠른 완료 시간으로 관점을 설정하면 실제 평균 완료 속도가 높아짐.
          + 낙관적 목표 설정이 실제 성과를 빠르게 만듦 (optimism shapes reality).
          + 그러나 현실에서는 관점을 설정하는 데 대부분 비관적이어서, 더욱 느려짐.
     * Scale AI의 신조와의 연결:
          + “속도(Tempo)”: 가능한 빠르게 업무를 처리하는 것이 림보 효과의 가장 좋은 해독제.
          + “야망이 현실을 만든다(Ambition shapes reality)”: 낙관적인 목표를 설정하면 장기적으로 현실 자체를 변화시킴.
     * 결론 및 조언:
          + 개별적으로 사소한 속도 저하가 모여서 조직을 위협함.
          + 낙관주의와 결단력의 유지가 팀과 회사의 성공에 큰 영향을 미침.
          + 사람들에게 더 높은 기대와 낙관적인 관점을 부여하면 실제로 그 수준을 달성할 가능성이 높아짐.
          + 스티브 잡스 역시 사람들에게 높은 기대를 걸 때 실제 높은 성과를 얻는다고 강조함.
            최종 메시지:
     * 낙관주의가 현실을 만들도록 하라.

   높은 긴급성 상황(예: 사이트 다운, 초기 스타트업 환경)은 ""마감일이 지금""이라는 인식으로 인해 매우 빠르게 업무가 진행됨.
   => 긴급상황으로 인해 발생하는 터널링 효과에 관한 부작용은 결핍은 우리를 어떻게 변화시키는가라는 책에 잘 나와 있습니다(결핍의 경제학의 재출간본입니다).

   진짜 긴급을 다루는 소방관들도 터널링효과로 인한 사고사망 사례가 있는데...
   긴급으로 취급하는게 단기적으로는 그럴싸해 보이겠지만 반복하다간 결국 사고가 나죠..

   당일날 끝나는 대회에선 적용될 수 있을 것 같기도 하지만, 여러 날 걸쳐서 해야 하는 일에 일정으로 채찍질하는 것은 독으로 작용합니다. 계속 채찍질이 반복되면 빠르게 풀 수 있는 방법만 고민하게 되고, 결국은 그게 더 돌아가게 만드는 단초를 제공하기 마련이죠. 혹은 버티지 못하고 번아웃이 오거나요.

   인생은 마라톤이라는 메타포가 자주 사용되는데, 실은 마라톤보다 훨씬 깁니다.

   크런치문화에 대해서 제가 평소 생각하고 있던 것과 비슷합니다. 간혹가다 할 순 있겠지만 만성화되면 문제라고 생각합니다. 스타트업은 그럼에도 불구하고 단기간에 결과를 내야하는 업계이긴 한데 지속 가능할지는 잘 모르겠습니다

   인생은 마라톤이라고 비유하지만, 실제 마라톤을 해보면 처음부터 끝날때까지 죽을맛이죠

   +11111

   사장이나 중간관리자들이 보기 전에 글 내려주세요 ㅋㅋ

   낙관주의와 채찍질의 차이를 잘 이해해야 한다고 생각합니다.

   서비스가 성장함에 따른 복집도의 증가를 초기 방법 그대로 적용했을 때에 더이상 유혀하지 않을 수 있음을 간과한 내용으로 보이네요.
   당연히 초기엔 빠른 접근이 쉽고 유효했겠지만 더이상 그것이 동작하지 않을 수 있다는 점을 받아들이지 않으면 추가인력이 마치 비효율적이고 헌신하지 않는 것 처럼 판단하게되는 것 처럼 느꺼질 수 있겠지요.
   더이상 그 전략이 통하지 않는다는 점을 뒤늦게 깨닫겠지만요.

   걔들만큼 돈줄것도 아니면서 걔들 생산성 안나온다고 쪼아봤자 일 잘하는 사람은 도망가요...

   그리고 회사에 체계가 없는걸 ""빠른 실행력""이라고 말하는건 자랑이 아니라고 봅니다.

   ""오래 걸린다고 생각하면 오래 걸리고, 빨리 끝날 거라 생각하면 빨리 끝남.""에서 파킨슨의 법칙이 생각났습니다.

   파킨슨의 법칙: 파킨슨의 법칙은 어떤 일을 하는데 걸리는 시간은 주어진 시간에 따라 증가한다는 것.

   뭐 일정이야 물리적인 시간이 부족한 경우를 제외하면 빠르게 해달라고 하면 가능한 한 줄여서 작업하는 것은 가능하긴 합니다.
   근데 그 퀄리티나 안정성 보장은 전혀 별개의 이야기입니다.
   작업 과정에서 확인하는 과정 하나 둘 빼서 일정 맞추는 거야 가능할 거고 특정 급한 상황에서 스킵하는 거야 한두번 정도는 문제가 생기지 않을 가능성이 높을 수도 있죠.
   그런데 이게 일상화 되면 그런 체크 과정 누락이 언젠가는 인지하지도 못할 큰 문제를 만들고 터트리는 도화선이 됩니다.

   마라톤 사례는 진짜 흥미롭네요. 실제 과제 제출했을 떄의 기억들도 그렇고... 해커톤이 영향력이 있는걸 보면, 목표에 대한 데드라인에 있어서는 낙관주의가 중요한것 같은데.
   무서운 낙관주의는 매우 긍정적으로 생각해서 나중에 행동하게 되는것이 아닌가 싶네욬ㅋㅋㅋㅋ

   저도 너무 신기했습니다. 이 글을 봐보셔도 좋을 것 같아요.
   https://www.notboring.co/p/optimism

   내일해도 되지 않을까?
"
"https://news.hada.io/topic?id=20445",""Revenge of the Sith"의 영화 실수 미스터리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ""Revenge of the Sith""의 영화 실수 미스터리

     * 영화는 수작업으로 만들어지며, 때때로 관객에게 영화의 이음새가 보이는 순간이 있음
     * 이러한 실수는 영화의 마법을 살짝 깨뜨리지만, 영화 제작 과정을 좋아하는 팬들에게는 즐거운 순간임
     * ""Revenge of the Sith""에서의 실수는 영화의 시각적 효과를 담당한 ILM에서 발생한 것으로, 영화의 디지털 아카이브를 통해 해결됨
     * 영화 복원 과정에서 이러한 실수를 지우는 것은 잘못된 일이며, 영화의 역사적 순간을 훼손하는 것임
     * 영화는 수작업으로 만들어진 예술 작품이며, 이러한 실수는 영화의 매력을 더해주는 요소임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

영화의 실수와 그 매력

     * 영화는 수작업으로 만들어지며, 때때로 관객에게 영화의 이음새가 보이는 순간이 있음
     * 이러한 실수는 영화의 마법을 살짝 깨뜨리지만, 영화 제작 과정을 좋아하는 팬들에게는 즐거운 순간임
     * 예를 들어, ""Glory""에서는 현대적인 손목시계를 찬 엑스트라가 등장하고, ""Goodfellas""에서는 자동차 번호판이 떨어지는 장면이 있음
     * ""Aliens""에서는 절단된 안드로이드가 너무 멀리 나와 무대 장치가 드러나는 실수가 있음
     * ""Duel""에서는 전화 부스의 유리에 반사된 제작진이 보이는 장면이 있음

""Revenge of the Sith""의 미스터리

     * ""Revenge of the Sith""에서의 실수는 영화의 시각적 효과를 담당한 ILM에서 발생한 것으로, 영화의 디지털 아카이브를 통해 해결됨
     * 영화의 특정 장면에서 유령 같은 인물이 나타나는 실수가 있었음
     * 이 실수는 ILM의 Todd Vaziri가 디지털 아카이브를 통해 해결하였음
     * 실수는 스턴트 리거가 장면에 잘못 들어간 것으로 밝혀졌음
     * 이러한 실수는 영화의 수작업 특성을 보여주는 좋은 예시임

영화 복원의 문제

     * 영화 복원 과정에서 이러한 실수를 지우는 것은 잘못된 일이며, 영화의 역사적 순간을 훼손하는 것임
     * 영화는 그 자체로 하나의 순간이며, 복원 과정에서의 과도한 수정은 영화의 본질을 훼손함
     * 영화의 실수는 영화의 매력을 더해주는 요소이며, 이를 보존하는 것이 중요함

영화 제작의 수작업 특성

     * 영화는 수작업으로 만들어진 예술 작품이며, 이러한 실수는 영화의 매력을 더해주는 요소임
     * 디지털 시각 효과가 중요한 역할을 하지만, 여전히 수작업의 매력이 존재함
     * 영화 제작 과정에서의 실수는 영화의 수작업 특성을 보여주는 좋은 예시임

        Hacker News 의견

     * 영화 복원 과정에서 실수를 지우는 것은 잘못이라는 의견이 있음. 영화에 있는 것은 영화에 있는 것이며, 이를 바꾸는 것은 수정주의 역사라는 주장임
          + 하지만 라이선스 번호판을 고치거나 현대적인 손목시계를 지우는 것은 문제가 없다는 의견도 있음
          + 이는 소설에서 철자 오류를 고치거나 악보에서 잘못된 화음을 수정하는 것과 같음
          + 음악을 바꾸거나 인형을 CG로 대체하는 것은 예술을 바꾸는 것이므로 반대함
          + 두 가지를 구분하는 것은 보통 쉽다고 생각함. 첫 번째는 실수로 인한 것이고, 두 번째는 기술과 자원의 반영임
     * 영화 Glory에서 디지털 시계를 찬 손이 등장하는 장면이 언급됨
          + 이는 Blake Edward의 The Party (1968)에서 Peter Sellers가 실수로 큰 손목시계를 보는 장면을 연상시킴
     * 원래의 실사 장면을 보면 배우들이 얼마나 힘들었을지 상기시켜 줌
          + Lucas는 디지털 기술을 밀고 나가고 싶어 했지만, Harry Potter 영화는 물리적 세트와 실질적인 효과를 많이 사용하여 더 잘 유지됨
     * 편집 실수를 더 싫어하는 사람도 있음
          + The Aviator에서 두 캐릭터가 나란히 걷다가 멈추고 서로를 바라보는 장면이 있음
          + 이 영화는 아카데미 편집상을 수상했음에도 불구하고 이런 실수가 많음
     * 녹음된 예술에서의 실수는 팬과 창작자에게 다르게 보임
          + 음악 팬으로서 작은 실수는 인간적이고 녹음이 사람에 의해 만들어졌음을 보여줌
          + 하지만 예술가로서 자신의 작품에서 실수를 싫어하고 이를 수정하는 데 많은 시간을 투자함
     * 영화 Gladiator에서 압축 공기 탱크로 전차를 뒤집는 장면을 본 적이 있음
          + Raiders of the Lost Ark에서 트럭을 뒤집는 장면의 막대를 알고 나니 이제는 보이지 않음
     * 2001 A Space Odyssey에서 반중력 장면에서 배우들이 자신의 무게를 지탱하는 것을 처음으로 알아차림
          + 이는 영화의 예술성을 더 돋보이게 하지만 순수함은 잃음
     * 문학 작가가 출판 후 오류를 수정하는 것과 영화 수정의 차이를 묻는 의견이 있음
          + Lord of the Rings나 Dune 같은 소설도 여러 번 수정되었음
          + 문법, 철자, 이야기 명확성을 위한 수정이 잘못된 것인지에 대한 질문이 제기됨
     * The Terminator의 최근 4K 릴리스에서 마지막 장면의 차고 직원이 ""There's a storm coming""이라는 문구가 거꾸로 적힌 종이를 주머니에 넣고 있는 것을 발견함
     * Episode III의 Mustafar 전투 장면의 그린 스크린 촬영을 보면, 실제 조명이 그랬다면 영화가 가짜처럼 보이는 것이 당연하다고 생각함
"
"https://news.hada.io/topic?id=20498","폰트를 훔치지 않는 당신","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             폰트를 훔치지 않는 당신

     * 유명한 ""You wouldn't steal a car"" 반-해적 캠페인에서 사용된 글꼴이 Just van Rossum에 의해 디자인된 것임
     * Just van Rossum의 형제는 Python 프로그래밍 언어를 만든 Guido van Rossum임
     * 이 글꼴이 ""XBAND Rough""라는 이름으로 불법 복제되어 무료로 배포되었음
     * 반-해적 캠페인이 실제로 불법 복제된 글꼴을 사용했다는 사실이 밝혀졌음
     * FontForge를 사용하여 캠페인 사이트의 PDF에서 글꼴을 확인한 결과, 불법 복제된 글꼴이 사용되었음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

반-해적 캠페인 글꼴의 비밀

     * Melissa Lewis가 BlueSky에서 반-해적 캠페인에 사용된 글꼴이 Just van Rossum에 의해 디자인되었음을 지적함
     * Just van Rossum의 형제는 Python 프로그래밍 언어를 만든 Guido van Rossum임
     * 해당 글꼴이 ""XBAND Rough""라는 이름으로 불법 복제되어 무료로 배포되었음
     * 반-해적 캠페인이 실제로 불법 복제된 글꼴을 사용했다는 사실이 밝혀짐
     * FontForge를 사용하여 캠페인 사이트의 PDF에서 글꼴을 확인한 결과, 불법 복제된 글꼴이 사용되었음

        Hacker News 의견

     * 폰트 라이선스에 대한 불만을 제기할 시기가 맞는지 고민 중임. 인쇄용으로 구매한 폰트가 모바일 앱 개발로 전환하면서 쓸모없어짐
          + 인쇄물에는 영구적으로 사용할 수 있는 라이선스가 있지만, 앱 개발에는 같은 폰트가 50배 더 비싸짐
          + 폰트 판매자들이 앱 붐이 여전히 있다고 생각하는 듯함. 현실적인 라이선스가 있다면 해적판 문제가 줄어들 것임
     * 폰트가 저작권 침해 캠페인에서 사용된 것이 저작권 침해의 증거가 될 수 있음
          + FACT를 저작권 침해로 고소하고 합의를 거부해야 함
     * 음악도 도용됨. 2013년 반해적 광고 음악 도용 사례가 있음
     * 폰트를 개별적으로 $5-$10, 전체 패밀리를 $20-100에 구매할 수 있다면 기꺼이 지불할 것임
          + 대부분의 프로젝트에서 $300 이상의 비용은 비현실적임
          + Google Fonts가 발전하면서 더 이상 폰트에 많은 돈을 쓰지 않음
     * 미국에서는 폰트 디자인 자체는 저작권 보호를 받지 않음. 파일은 보호되지만 디자인은 아님
          + 디자인을 복사하는 것이 일반적인지, 아니면 영감을 받아 새로운 폰트를 만드는 것이 더 일반적인지 궁금함
     * 많은 사람들이 폰트 디자인이 창의성과 노력이 필요한 작업이라는 것을 모르는 것이 안타까움
     * 폰트 모양은 미국에서 저작권 보호를 받지 않기 때문에 저작권 침해로 간주되지 않을 수 있음
          + XBAND Rough 폰트가 90년대 비디오 게임 콘솔 주변기기와 관련이 있는지 궁금함
          + Catapult Entertainment가 이 폰트를 만든 것으로 보임
     * HN에서 유머를 잘 다루지 않지만, 자동차 산업에서 일하면서 호주의 코믹한 반박이 항상 재미있었음
     * 이 캠페인의 배후가 궁금했는데, FACT와 MPAA가 관련되어 있음
     * 디자인 교육 초기에 폰트가 많을수록 도구 세트가 더 좋아진다는 것을 배움
          + 첫 디자인 직장에서 폰트 구매와 라이선스에 대해 배움
          + 필요한 폰트를 찾을 수 있어도 직접 구매해야 했음
"
"https://news.hada.io/topic?id=20476","비개발자를 위한 바이브 코딩 입문 5단계 가이드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       비개발자를 위한 바이브 코딩 입문 5단계 가이드

   지난 몇주간 비개발자 지인들(변호사, 마케터, PM 등)과 함께 바이브 코딩으로 간단한 앱을 대여섯 개 만들어봤음
     * WoW 길드 레이드 대시보드 (웹)
     * 경품 추첨 이벤트용 레이싱 시뮬레이터 (웹 + Three.js)
     * 영상 편집자와 의뢰자 사이 의사소통하는 도구 (크롬 익스텐션)
     * 이터레이션 횟수를 정하고, 일정 시간동안 집중하고, 끝나면 회고하도록 돕는 자동 타이머 (Electron 데스크톱 앱)

   이 과정을 정리하여 '비개발자를 위한 바이브 코딩 입문 가이드'를 5단계로 만들어봄
    1. 요즘 AI가 어디까지 뭘 할 수 있는지 감 잡기
    2. 풀고 싶은 문제, 만들고 싶은 제품 명확히 정의하기
    3. 빠르고 빈번하게 내 눈으로 결과물 동작 확인하기
    4. AI가 잘 코딩할 수 있도록 프롬프팅하며 주고받기
    5. 이상 동작과 개선점을 인지하고 개선하며 마감하기

  1) 요즘 AI가 어디까지 뭘 할 수 있는지 감 잡기

   바이브 코딩을 처음 접하는 비개발자 분들은 이정도 활동으로 시작하시길 권함
     * LLM에서, 또는 AI 프로토타이핑 서비스에서 짧은 프롬프트만으로 동작하는 무언가를 만들 수 있다는 걸 직접 경험해보며 효능감 높이기
     * 최신 AI 정보를 정리해서 알려주는 SNS와 뉴스레터 몇 개 구독하기
     * 모든 AI 정보와 도구를 소화할 욕심은 버리고, 내가 관심있는 특정 주제의 도구들만 관심 가지며 찍먹해보기

  2) 풀고 싶은 문제, 만들고 싶은 제품 명확히 정의하기

     * AI의 능력에 대한 인식은 했더라도 문제 정의가 명확하지 않으면 제품을 만들 수 없음
     * 그래서 먼저 메타인지를 높이는 질문을 통해 내가 똑똑해져야 함.
     * 바이브 코딩으로 만든 메타인지 앱 이용
         1. 뭘 만들고 싶은가?
         2. 그걸 왜 만들고 싶은가? 어떤 문제를 풀려고?
         3. 누가 겪는 문제인가?
         4. 그들이 어떤 상황에서 그 문제를 겪나?
         5. 그 상황에서 지금은 어떤 임시방편/대체재를 쓰고 있나?
         6. 5보다 1이 문제를 더 잘 풀어준다는 걸 어떻게 확인할 수 있을까?
         7. 그들이 5 대신 기꺼이 1을 쓰게 만드려면 어떻게 할까?
     * 만들고 싶은 게 정리되면, 위 앱에서 생성된 'PRD 생성 프롬프트'를 LLM에 집어넣어 PRD를 만들게 했음

  3) 빠르고 빈번하게 내 눈으로 결과물 동작 확인하기

     * '동작하는 앱'을 굉장히 이른 시점에 바이브 코딩의 가장 큰 장점. 비개발자에 동기부여 되는 데에도 아주 중요
     * 그런 의미에서 비개발자가 Cursor로 바이브 코딩 시작하는 걸 별로 권하지 않음. 앱 실행까지 넘어야 할 크고작은 산이 많다고 생각하기 때문
     * 대신 PRD를 주면 동작하는 프로토타입이 튀어나오는 Lovable 같은 서비스들이 더 좋은 출발점이라고 봄. 퍼블릭 링크도 바로 만들어지니 지인에게 보여주고 피드백받기도 좋음
     * 단 만들려는 앱이 웹 기반이 아니라면 조금 복잡해짐. 프로토타이핑 도구들은 웹앱으로 만들어주기 때문
     * 이 때는 기술적 의사결정과 실행 환경 세팅이 필요한데, 그러려면 나와 AI가 모두 똑똑해져야 함

  4) AI가 잘 코딩할 수 있도록 프롬프팅하며 주고받기

     * 나와 AI가 똑똑해진다 <-> 프롬프트 잘 짠다 <-> 결과물이 더 빨리, 더 잘 나온다
     * 프롬프트 잘 짤수록 목표 달성에 드는 핑퐁 횟수(= 시간과 돈)이 줄어듦
     * 각종 프롬프트 엔지니어링 가이드를 보면 공통적으로 언급하는 게 프롬프트 안에 역할(Role), 맥락(Context), 작업(Task)을 잘 정의하라는 것

    역할, 맥락, 작업

     * 바이브 코딩에서 '역할'은 엄청 중요하지 않음
          + 코딩 에이전트들에 이미 적절한 역할이 정의되어 있어서 꼬일 수 있고
          + 코딩이 중요한 벤치마크라서인지 LLM에서도 역할 부여 없이 코딩 잘 하기 때문
          + 물론 내가 만들려는 앱이 특별하다면 적절한 역할을 주는 것도 좋음
     * '맥락'은 PRD 잘 만들었으면 충분
     * '작업'은 목표와 완료기준을 잘 정하는 것. 완료기준은
          + 프롬프트 내에 명시되어있을 수도 있고(few-shot 프롬프팅)
          + 외부 파일이나 코드에 정의되어있을 수도 있고(TODOs.md 나 테스트 코드)
          + 내 머릿속에만 있을 수도 있음(이 스타일은 예쁘지 않아)
     * 바이브 코딩의 궁극적 목표는 AI가 잘 코딩하도록 지시해서 PRD대로 동작하는 앱을 빠르게 만드는 것. 이를 위해선 3가지 중간목표를 삼는 게 좋음
          + 내가 더 똑똑해진다
          + AI가 더 똑똑해진다
          + 기능이 스펙대로 동작한다

    내가 더 똑똑해진다?

     * 비개발자이거나, 도메인이 생소하거나, 기술 스택이 생소하다면 정확한 용어로 지시하기 어려움
     * 이럴 때는 내가 부족함을 LLM에게 알리고 배우면 됨
          + ""(스샷 주고) 이런 게임은 보통 뭘로 만들어?""
          + ""이런 거 만들건데, 너라면 데이터를 어떻게 확보할 것 같아?""
          + ""네이티브 앱의 핵심 동작을 최대한 빨리 확인하려면 어떤 기술을 써야 해?""
     * 이런 질문을 통해 내가 이렇게 변하고 있는지 관찰해볼 것
          + 기술 키워드: 내가 정확한 기술 용어/도메인 용어를 사용하고 있다
          + 데이터 흐름: 내 앱의 핵심 기능을 위한 데이터를 어떻게 확보해서, 처리해서, 보여주는지 설명할 수 있다
          + 실행 환경: AI가 짜준 코드를 실행해서 동작 여부를 내 눈으로 확인할 수 있는 환경을 마련했다
     * 이상적으로는 unknown unknown을 다 해소한 상태에서 PRD 쓴 뒤 코딩 착수하는 게 좋으나 꼭 안그래도 됨
     * 코딩 들어가야 학습하는 것도 많고, 여차하면 처음부터 다시 만들면 되니까. (이미 있는 거 고치기보다 더 빠를 수도 있음)

    AI가 더 똑똑해진다?

     * 파악한 기술 키워드나 데이터 흐름을 시스템 프롬프트(Cursor Rules 등)로 AI에게 알려주는 것
     * 나의 개입 횟수를 줄이고, AI의 코드가 내 마음에 더 들게 하려면 크게 두 가지가 필요함. 제약조건과 문서화에 대한 지침임
     * 제약조건 지침은 AI가 더 일관된 코드를 쓰도록 도움. 예를 들어:
          + 기술 스택: NextJS app router 써라, Tailwind와 ShadCN으로 스타일링해라, 아이콘은 Lucid만 써라, 결제는 Stripe 써라 등
          + 구조와 패턴: 폴더는 이렇게 구성해라, 파일명은 이렇게 지어라, UI 스타일은 Material처럼 해라 등
          + (실행 환경에 따른) 출력 형식: Electron Fiddle을 쓸 거니까 그에 맞춰 파일 4개를 줘, CodePen을 쓸 거니까 HTML, CSS, JS를 하나씩 줘 등
     * 문서화 지침은 AI의 집중력과 기억력을 향상시키도록 도움. 두 가지 아이디어가 아주 유용했음
          + Cline의 메모리 뱅크: 한 일과 할 일들을 파일에 기록하며 작업하는 워크플로우를 정의
          + 강동윤님의 프롬프트 컨텍스트: 전체 프로젝트에 대한 지침을 최상위 폴더에 길게 남기는 대신 폴더별로 지침을 만듦
     * 메모리 뱅크는 현재 무슨 일이 일어나는지 관찰과 학습이 쉬워지니, 비개발자에게 특히 추천

    기능이 스펙대로 동작한다?

     * 프로젝트 수준이 아닌 (코딩 에이전트에서) 채팅할 때의 프롬프팅 전략
     * 기능이 스펙대로 동작하게 만드는 가장 좋은 전략은 테스트 통과하면 커밋이라고 생각
          + ""X를 구현해줘. 테스트 먼저 작성하고, 코딩한 다음, 테스트를 돌려보고, 통과할 때까지 계속 코드를 수정해줘.""
     * 이는 코딩 에이전트가 테스트 코드를 작성하고, 터미널에서 실행하고, 그 결과를 읽을 수 있는 권한과 능력이 있기 때문에 가능
     * 그렇게 테스트를 통과하면 커밋 메시지를 제안받아서, 테스트 코드와 기능 코드를 함께 커밋하면 됨. 나는 커밋을 직접 하지만 에이전트가 자동 커밋도 가능
     * 유닛 테스트뿐 아니라 통합 테스트, E2E 테스트도 AI가 짜고, 실행하고, 알아서 고치게 할 수 있음 (참고: Cursor + Playwright 자동화 테스트)
     * 이 모든 게 '스펙대로 개별 기능이 구현되고, 전체 앱이 PRD대로 동작하는가' 를 바이브 코더와 AI 양측이 더 쉽게 확인하도록 만들어주는 전략임

  5) 이상 동작과 개선점을 인지하고 개선하며 마감하기

     * 내가 생각하는 바이브 코딩은 '딸깍'과 거리가 멀고 학습할 게 많음
     * 그중에서도 '나만의 작은 프로토타입'을 넘어, 솔로 창업자로서 상용 제품 수준의 앱을 만드는 데 필수적이라고 보는 3가지 역량이 있음. 인지 역량, 코딩 역량, 프로덕 엔지니어링 역량임

    인지 역량

     * PRD(또는 내 원래 의도)와 다르게 동작하는 화면 또는 기능을 예민하게 인지하는 것
     * 이게 부족하면 AI가 잘못한 걸 찾아서 고치라고 하기가 너무 어려움
          + 4단계의 '테스트'는 AI의 잘못을 애초에 줄임과 동시에 내 역량을 키워주기도 함.
          + 스펙을 AI가 테스트 코드로 변환하는 과정을 읽으면서 단순히 '이 기능이 필요해'가 아닌 '이 기능 구현을 완료하려면 이 조건들이 필요해'를 학습할 수 있기 때문
     * 그런데 '앱을 스펙대로 구현했다'와 '앱이 좋다'는 다름. 그래서 개선점을 찾는 '프로덕 센스'가 중요 (자세한 내용은 링크한 Lenny의 뉴스레터 참조)

    코딩 역량

     * 적어도 아직까지는, 아무리 일을 잘 쪼개서 AI에게 맡겨도 최소 5% 정도는 직접 코드에 손대서 마감을 쳐야 함.
          + 이걸 못해서 80% 수준에서 머물며 출시 못하는 앱들이 SNS상에 수두록함
     * 물론 만들고자 하는 앱에 따라 이 비율이 달라질 수도 있고, 끝까지 AI만으로 구현하는 것도 불가능하진 않겠지만 너무 비효율적임
     * 바이브에 완전히 몸을 맡기기보다는 (메모리 뱅크, 테스트 코드 등을 통해) AI가 생성해주는 문서들을 보며 코딩 자체도 공부하길 권함. 개발자에게 코칭도 받아보고.
     * 특히 상대적으로 눈에 덜 보이는 백엔드(사용자 인증, 외부 API 연동, 데이터 입출력, 결제 등)와 배포 전략(메인 브랜치와 피처 브랜치, 환경변수 관리 등)에 대해서 학습하시는 게 효과가 클 것

    프로덕 엔지니어링 역량

     * 앱 출시는 끝이 아니라 시작임. 제대로 하려면 제품 개발 라이프싸이클 전체를 이해할 필요가 있음
          + 문제 인식, 해결 아이디어 도출, 기획, 디자인, 구현, 테스트, 배포, 홍보, 에러 모니터링, 피드백 수집, 운영...
     * 이 모든 단계를 깊이있게 다루는 것까지는 아니어도, 적어도 해당 단계에서 어떤 일을 하고 어떤 키워드를 쓰는지까지는 알아두는 게 좋음
     * 그래야 모르는 걸 배울 수 있고, 혼자 감당이 안될 때 함께할 동료의 역량을 알아볼 수 있음

  맺으며

     * 바이브 코딩으로 앱을 상용 제품 수준으로 만드는 건 결코 쉬운 일이 아님. 그러나 '시작'하기가 그 어느 때보다 쉬워진 건 누구도 부정할 수 없을 것
     * 자신의 작은 아이디어가 살아 움직이는 걸 본 지인들이 탄성과 함께(""와 내가 코딩을 하다니!"") 너무나 즐거워하는 걸 보니 나 또한 굉장히 행복했음
     * 이 글을 읽는 다른 비개발자 분들도 이번 기회에 즐겁게 '메이커'가 되어보시는 걸 권함
     * 본인만의 도메인 전문성을 이용해, 특정 문제를 탁월하게 해결하는 작고 빠르며 유용한 도구를 (바이브 코딩으로) 만든다면 AI 시대에도 충분히 경쟁력이 있을 거라고 생각

   와~ 바이브 코딩은 허상이라고 생각하고 있었는데
   이 정도로 전문성 있게 쓴 글은 오랜만에 보네요
   재미있게 잘 읽었습니다.

   감사합니다! 저는 가능성을 크게 보고 있습니다 ㅎㅎ

   아;; 이제 보니 제 덧글이 좀 그렇네요.
   허상이라는 표현보다는 아직은 멀었다? 같은 느낌이긴 합니다.
   결국 바이브 코딩은 한계가 있고, 개발적인 지식이 없이는 힘들다 라고 느끼고 있거든요.
   물론 AI가 발달하면서 나중에는 훨씬 좋아질 거라고 생각합니다.

   제 댓글이 바이브 코딩이 의미 없다 하는 것처럼 느껴질 것 같아서 주절주절 다시 답글 답니다
   저도 바이브 코딩 많이 애용합니다 ㅎㅎ

   아 아닙니다.ㅎㅎ 저도 말씀하신 뉘앙스 파악했습니다.

   그래서 본문에도 썼듯 제가 말하는 바이브 코딩은 '딸깍'과는 거리가 멀고, 수준을 높이려면 엔지니어가 많이 노력해야 한다고 생각해요.

   항상 잘 읽고있습니다.

   감사합니다!

   유튜브도 찍었습니다 ㅎㅎ https://www.youtube.com/watch?v=ecY5VBpruOA
"
"https://news.hada.io/topic?id=20485","내부고발자: DOGE로 유출된 NLRB 사건 데이터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      내부고발자: DOGE로 유출된 NLRB 사건 데이터

     * NLRB의 보안 문제: NLRB의 보안 아키텍트인 Daniel J. Berulis는 DOGE 직원들이 NLRB 시스템에서 민감한 데이터를 대량으로 전송했다고 주장함. 이 사건은 러시아 IP 주소에서의 로그인 시도와 관련이 있음
     * 데이터 전송 및 보안 우려: DOGE 계정은 NLRB 데이터베이스에 대한 무제한 접근 권한을 가졌으며, 로그 기록을 제한하거나 삭제할 수 있었음. Berulis는 이러한 계정이 10GB의 데이터를 전송했다고 보고함
     * 러시아 IP 주소의 로그인 시도: 러시아 IP 주소에서 DOGE 계정으로의 로그인 시도가 있었으며, 이는 NLRB의 정책에 의해 차단되었음
     * Microsoft Azure 및 GitHub 사용: DOGE 계정은 Microsoft Azure에서 로그 기록을 비활성화하고, GitHub에서 외부 코드 라이브러리를 다운로드함
     * 내부 조사 및 외부 보고 중단: NLRB는 내부 조사를 진행했으나, US-CERT에 보고하지 않기로 결정함. Berulis는 이 문제를 공개하기로 결정함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

NLRB의 보안 문제

     * NLRB의 보안 아키텍트인 Daniel J. Berulis는 DOGE 직원들이 NLRB 시스템에서 민감한 데이터를 대량으로 전송했다고 주장함
     * 이 사건은 러시아 IP 주소에서의 로그인 시도와 관련이 있음

데이터 전송 및 보안 우려

     * DOGE 계정은 NLRB 데이터베이스에 대한 무제한 접근 권한을 가졌으며, 로그 기록을 제한하거나 삭제할 수 있었음
     * Berulis는 이러한 계정이 10GB의 데이터를 전송했다고 보고함

러시아 IP 주소의 로그인 시도

     * 러시아 IP 주소에서 DOGE 계정으로의 로그인 시도가 있었으며, 이는 NLRB의 정책에 의해 차단되었음

Microsoft Azure 및 GitHub 사용

     * DOGE 계정은 Microsoft Azure에서 로그 기록을 비활성화하고, GitHub에서 외부 코드 라이브러리를 다운로드함

내부 조사 및 외부 보고 중단

     * NLRB는 내부 조사를 진행했으나, US-CERT에 보고하지 않기로 결정함
     * Berulis는 이 문제를 공개하기로 결정함

        Hacker News 의견

     * 이 기사는 코미디처럼 읽히는 점이 있음
          + 숨겨진 계정과 러시아에서의 로그인 시도가 언급됨
          + Berulis가 Microsoft에 지원 티켓을 제출하려 했으나 네트워크 관리자 접근이 제한되었음
          + Microsoft가 정부 기관의 로그인 및 계정 정보를 가지고 있는 이유에 의문을 제기함
          + Windows나 인터넷 접근이 없는 메인프레임을 선호함
     * 이 이야기가 [중복]으로 삭제될까 봐 아쉬움
          + 이 이야기는 두 번 게시되었고, 첫 번째 제출물은 10시간 더 오래되었으며 3개의 댓글이 있음
          + 현재 작성 시점에서 이 이야기는 348개의 댓글이 있음
          + 흥미로운 토론을 원한다면 이 이야기가 적합함
     * Edward Coristine가 2022년에 Path Network에서 해고된 점이 흥미로움
          + 내부 회사 정보를 경쟁사에 유출했다는 혐의로 해고됨
          + 외국 첩보 기관에 의해 모집될 이상적인 후보처럼 보임
          + 사이버 범죄 소셜 네트워크에서 계정을 사용한 적이 있음
          + 이 사람이 어떻게 정부 근처에서 일할 수 있는지 의문임
          + 러시아 스파이가 미국 정부 자원에 접근하려면 왜 자신의 IP를 사용할까 의문임
          + 잡히는 것이 고의적이라면 불화를 조장하려는 것일 수 있음
     * DOGE는 앞으로 흥미로운 사례 연구가 될 것임
          + 친구가 DOGE로부터 국가 항공 시스템을 재구축하는 1099 계약자로 모집되었음
          + 저녁과 주말에 부업으로 광고되었으며, 매우 낮은 시급을 제안받음
          + 친구가 보수가 너무 낮다고 지적하자, 모집자는 DOGE에서 일한 경력이 주는 명성을 강조함
     * Berulis가 DOGE 계정 중 하나가 ""컨테이너""라는 불투명한 가상 환경을 생성한 것을 발견함
          + 컨테이너는 프로그램이나 스크립트를 실행할 수 있으며, 활동을 외부에 드러내지 않음
          + NLRB 네트워크 내에서 컨테이너를 사용한 적이 없다는 점에서 주목받음
          + 읽기에 재미있는 느낌이 있음
     * 이 사건이 명백히 반역의 영역에 있지 않다는 점이 놀라움
     * ""러시아가 러시아 IP를 사용하여 미국 데이터를 접근함""
          + 누군가가 러시아와의 연결을 만들려는 것처럼 들림
          + 러시아 정보 기관이 이렇게 아마추어적으로 행동할 이유가 없음
          + 잡히고 싶어하는 것처럼 보임
          + Cui bono? (누가 이익을 보는가?)
     * 이 기사가 HN 첫 페이지에서 사라진 이유에 의문을 가짐
          + 2시간 전에 게시되었으며 649 포인트를 가지고 있음
"
"https://news.hada.io/topic?id=20413","GitZip - GitHub Repo의 서브폴더/파일 내려받기용 브라우저 확장","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              GitZip - GitHub Repo의 서브폴더/파일 내려받기용 브라우저 확장

     * GitHub Repo 전체 프로젝트 대신 일부 폴더/파일만 빠르게 다운로드 가능
     * 멀티 파일 및 폴더를 선택하여 다운로드 지원
     * 크롬/Edge/Firefox 용 확장 제공
     * 확장 및 웹페이지 모두 오픈소스로 공개
"
"https://news.hada.io/topic?id=20395","TikTok은 산업적 규모로 어린이에게 해를 끼치고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    TikTok은 산업적 규모로 어린이에게 해를 끼치고 있음

     * 미국 14개 주 법무장관은 TikTok이 아동과 청소년에게 심각한 해악을 끼친다고 주장하며 소송을 제기함
     * 내부 문서와 직원 발언을 통해 중독성 알고리듬, 정신 건강 문제, 성적 착취 및 아동 포르노 노출 등이 드러남
     * TikTok은 이 문제들을 인식하고 있음에도 수익과 사용자 참여를 우선시하여 방치함
     * 콘텐츠 필터링 시스템과 부모 통제 기능이 매우 비효율적이며, 아동 유입을 막는 연령 검증도 실패함
     * 많은 Z세대 사용자도 “중독되었지만 끊을 수 없다”는 인식을 가지고 있으며, 전체적으로 사회에 미치는 순이익은 매우 부정적임

TikTok이 아동에게 가하는 산업 규모의 해악

  미국 대법원의 TikTok 금지법 판결 예고

     * 미국 대법원은 TikTok 금지법에 대한 개입 여부를 결정할 예정임
     * 해당 법이 시행되면 Bytedance가 TikTok을 매각하지 않는 한 미국 내 서비스는 중단됨
     * 그러나 정신 건강, 아동 착취, 중독과 같은 실제 해악에 대한 증거는 법적 심의에서 제외됨
     * 이에 따라 대중적 판단(여론)의 중요성이 강조됨

TikTok 내부자들의 증언과 유출 문서

  주요 법무장관 소송 및 문서

     * 켄터키, 유타, 네브래스카, 뉴욕 등 14개 주의 법무장관이 소송 제기
     * 내부 Slack 대화, 기획 문서, 실험 데이터 등이 다수 공개됨
     * 의도적으로 청소년을 타깃으로 하는 설계와 알고리듬 전략이 확인됨
     * 검열된 문서의 경우, 단순한 흑색 박스로 처리되어 쉽게 복원 가능했음

해악 클러스터 1: 중독성과 강박적 사용 유도

     * TikTok은 10대들이 시간과 참여를 가장 많이 줄 수 있는 타깃이라고 명시함
     * 중독성 알고리듬, 무한 스크롤, 자동 재생, 알림 설계 등을 통해 강박적 사용 유도
     * 청소년은 특히 사회적 보상(좋아요, 댓글 등)에 민감하고 자기 조절 능력이 부족함
     * 내부 직원들도 “우리 제품은 어린이 발달에 해롭다”는 우려를 표현
     * ‘TikTank’ 보고서는 특히 청소년 사용자가 자기 조절 실패, 수면 방해, 학습 능력 저하 등의 부작용을 겪는다고 언급함

해악 클러스터 2: 정신 건강 문제와 필터 버블

     * 강박적 사용이 불안, 우울, 자기 비하, 자해 및 자살 충동을 유발함
     * 실험 계정이 단 20분 만에 우울증, 자살, 식이장애 콘텐츠로 가득 찬 필터 버블에 빠짐
     * TikTok은 외모 필터가 자기 이미지 왜곡과 저자존감을 유발한다는 점을 알고 있음에도 방치
     * 콘텐츠 관리자는 언어 해석 불가, 맥락 부족, 기준 모호성으로 인해 자해/자살 콘텐츠를 적절히 차단하지 못함

해악 클러스터 3: 포르노, 폭력, 마약 콘텐츠 유통

     * 미성년자 계정에 음란물, 마약 광고, 폭력적 영상이 자동 추천됨
     * TikTok의 콘텐츠 필터링 시스템은 암시적 코드 언어를 제대로 처리하지 못함
     * 내부 문서는 마약 밀매, 성매매, 자금세탁 등이 TikTok LIVE에서 발생한다는 사실을 인지하고 있음
     * 유타 법무장관은 조사 중 자녀가 마약 딜러로부터 직접 접근받은 사례를 제시함
     * 심각한 유해 콘텐츠의 30~100%가 필터링되지 않고 노출됨

해악 클러스터 4: 성적 착취, CSAM, 아동 생중계 성매매

     * TikTok은 아동 성착취물(CSAM) 감지 기술을 의도적으로 도입하지 않음
     * 13~15세 아동이 LIVE 방송에서 성인들에게 선물(가상 화폐)을 받고 성적 콘텐츠 제공
     * TikTok은 이를 인지하고도 수익성과 참여 유지를 이유로 방치
     * 아동이 직접 “아이스크림 = 돌기, 우주 = 옷 벗기” 등의 메시지를 들고 출연하는 방송도 존재함
     * LIVE 기능은 아동에게 매우 유해하지만 TikTok은 “너무 수익성이 좋아서 제한할 수 없다”고 내부에서 언급

해악 클러스터 5: 연령 제한 무시 및 대응 부족

     * TikTok은 연령 제한이 있으나 13세 미만 가입자와 아동 이용을 알고도 제재하지 않음
     * 나이 검증은 거의 무력하며, 미성년자는 쉽게 나이를 속일 수 있음
     * 부모 통제 기능(Family Pairing) 도 거의 사용되지 않으며 실질적인 보호 효과 없음
     * TikTok은 안전 기능을 단지 정부와 언론을 위한 ‘명분용’으로 사용한다는 내부 문서 존재
     * DAU(일일 사용자 수)와 참여율 유지가 모든 결정의 핵심 목표이며, 안전성은 우선순위에서 배제됨

젊은 사용자들의 후회와 의존성

     * TikTok 사용자 다수는 “중독된 줄 알지만 못 끊는다” 는 반응을 보임
     * 실험 결과, 다수가 “모두가 함께 끊는다면 기꺼이 끊고 싶다”는 반응을 보임
     * Harris Poll 설문에서는 TikTok에 대해 **“처음부터 없었으면 좋았을 것”이라고 답한 비율이 47%**로 소셜 미디어 중 가장 높았음
     * TikTok은 행동 중독성과 사회적 중독성을 동시에 갖춘 플랫폼으로, 사용자도 자신에게 유해함을 인식

결론: 아동 보호를 위한 TikTok 규제 필요성

     * TikTok에서 발생하는 해악은 단순한 사고가 아닌, 설계된 결과임
     * 미국 어린이 수백만 명이 정상적인 사용만으로도 정신적·신체적으로 심각한 피해를 입고 있음
     * 현재의 알고리듬과 콘텐츠 정책 하에서 TikTok은 아동기 자체를 침해하는 플랫폼
     * 미국 사회 전체를 위해서라도 1월 19일 TikTok 서비스 중단은 긍정적인 변화가 될 수 있음

        Hacker News 의견

     * Haidt는 데이터 분석에서 가장 신중한 사람은 아니지만, 지난 10년 동안 그의 주요 주장들이 대체로 올바른 방향으로 가고 있었음
          + 취소 문화는 민주적 규범과 호환되지 않음
          + 소셜 미디어는 많은 사람들에게 약간의 부정적 영향을 주고, 일부 사람들에게는 큰 부정적 영향을 줌
          + 항상 휴대폰을 가지고 있는 것은 지속적인 주의가 필요한 모든 것에 나쁨, 특히 연애와 데이트 포함
          + 기술은 이 문제를 해결하지 못할 것임. AI는 상황을 더 악화시킬 것임. TikTok이 금지되고 더 나은 버전이 생겨도 잘못된 방향으로 가고 있음. 문화 변화가 필요하며, Haidt가 이를 위해 최선을 다하고 있음
     * 켄터키 법무장관 사무실이 TikTok에 대한 보고서를 게시할 때, 검은 사각형으로 텍스트를 가렸지만, 커서를 사용해 복사하여 숨겨진 텍스트를 읽을 수 있었음. 매우 웃긴 상황임
     * 자녀가 없지만, 기술과 아이들을 다루는 다른 방법이 가능하다는 개인적인 경험을 공유함
          + 1980년대 중서부에서 살 때, 부모님께 1973년판 Encyclopedia Britannica를 중고로 사달라고 요청했음. 이는 온라인 자원에서 얻을 수 있는 호기심과 발견의 기쁨을 제공했음
          + 여행 중에도 백과사전을 가져가 읽었음. 이는 아이들이 기술에 의존하지 않고도 다양한 필요를 충족할 수 있는 방법이 있음
     * 젊은 여성과 십대들이 선물 요청과 성적화된 댓글을 받는 것이 흔하다는 것에 놀람. 이는 18세 미만의 사람들에게 큰 영향을 줄 수 있음
     * 내부 보고서가 경영진이 듣고 싶어하지 않는 내용을 작성하는 이유에 대한 의문
          + 경영진이 듣고 싶어하지 않는 것을 인지하지 못하는지
          + 경영진이 실제로 듣고 싶어하지만, 의도적으로 편향된 해석을 원하는지
          + 정보가 건설적으로 사용될 것이라고 생각하는지
          + 정직한 연구자로서의 역할을 다하려는 것인지
          + 해고를 피하기 위한 일자리 보안인지
          + 스캔들이 공개될 경우를 대비한 문서 기록을 남기려는 것인지
     * 켄터키 법무장관 사무실의 부적절한 검열 처리 방식이 재미있다고 생각함
     * 부모들이 자녀의 기기에서 특정 사이트를 차단했으면 좋겠다고 생각함. 검열과 감시를 확대하지 않아도 됐을 것임
     * 소셜 미디어가 중독적이어서 스스로 차단해야 했던 경험을 공유함. 교육적 관점에서 비디오를 보는 것은 유용할 수 있지만, LLM 요약을 통해 유용한 내용을 파악하는 것이 좋음
"
"https://news.hada.io/topic?id=20461","Microsoft한테 Fork 당하다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Microsoft한테 Fork 당하다

     * Spegel은 이미지 레지스트리 장애로 인한 Kubernetes 클러스터 확장 문제를 해결하기 위해 개발된 오픈소스 도구임
     * Microsoft는 Spegel에 관심을 보이고 협력 의사를 밝혔지만, 이후 별다른 피드백 없이 유사한 프로젝트인 Peerd를 독자적으로 공개함
     * Peerd는 Spegel을 기반으로 만든 것으로 보이며, 실제로 코드, 테스트, 주석 등이 거의 동일하고 일부는 복사 수준임
     * MIT 라이선스는 포크를 허용하지만 출처 표기를 누락하거나 저작권 제거는 불허, Microsoft가 이 기준을 지키지 않은 정황이 있음
     * 이 사건은 오픈소스 생태계에서 개발자와 대기업 간 불균형한 권력 구조를 드러내며, 라이선스 변경과 후원 유도 등 대응을 고민하게 함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Spegel의 시작과 문제의식

     * 작성자는 Kubernetes 클러스터에서 이미지 레지스트리 장애로 인해 확장성 문제를 겪음
     * 상태 저장형 미러 대신, 운영 부담이 적고 무상태로 작동하는 도구를 만들기로 결심함
     * 그렇게 탄생한 오픈소스 도구가 바로 Spegel, 현재 1.7k 이상의 GitHub 스타와 1,400만 이상의 다운로드 수 기록

Microsoft와의 만남, 그리고 침묵

     * Microsoft는 Spegel에 관심을 보이며 미팅을 요청했고, 작성자는 적극적으로 아키텍처 지원 및 코드 설명에 협력함
     * 초기에는 협업에 대한 희망이 있었지만, 이후 아무런 피드백 없이 대화가 끊김
     * 이후 KubeCon Paris에서 Microsoft가 개발한 Peerd 발표를 통해 Spegel이 언급되고 있음

Peerd와 Spegel의 유사성

     * Peerd는 Microsoft가 만든 P2P 기반 이미지 배포 도구로, Spegel에서 영감을 받았다고만 간략히 언급함
     * 그러나 코드상에서 함수 정의, 주석, 테스트 케이스 등이 Spegel과 거의 동일
     * 예시 코드 비교 이미지에서는 함수 주석까지 일치, 일부 테스트에는 Spegel과 작성자의 이전 직장 이름까지 포함됨
     * Peerd는 MIT 라이선스를 적용했지만, Spegel의 원 저작자 및 출처 표기가 부족함

오픈소스 유지자의 고충

     * 프로젝트가 성장하면서 Spegel 사용자들은 Peerd와의 차이를 자주 문의함
     * Microsoft와의 힘의 차이로 인해 Spegel은 브랜드 인지도 측면에서 밀림
     * 협력과 기여를 기대했던 작성자는 좌절을 겪었고, 라이선스 변경까지 고려하게 됨

커뮤니티의 미래와 대응

     * 오픈소스 생태계는 최근 Hashicorp의 라이선스 변경, 기업의 투자 감소 등으로 불안정한 흐름을 겪고 있음
     * 작성자는 GitHub Sponsors를 열고, Spegel을 계속 유지할 수 있도록 커뮤니티의 후원과 참여를 요청함
     * 이번 사건은 개별 개발자와 대기업 사이의 구조적 불균형 문제를 다시 조명하며, 라이선스 선택의 중요성을 강조함

마무리: 개인 대 대기업, 불균형 속에서의 저항

     * Spegel은 여전히 활발히 사용되고 있으며, 작성자는 자신의 경험을 바탕으로 오픈소스 생태계의 회복력을 믿음
     * 하지만 “다윗과 골리앗” 같은 현실 속에서, 작성자는 Spegel의 미래를 위해 최소한의 저항 수단으로 라이선스 변경을 고려하고 있음

   매우 비양심적이군요 🤨

        Hacker News 의견

     * 과거 Microsoft의 Satya 시대 이전에, 나는 초기 클라우드 시대에 중요한 문제를 해결하는 인기 있는 오픈 소스 소프트웨어(OSS) 제품의 유지 관리자였음
          + Microsoft의 한 디렉터가 협업을 제안했으나, 나는 컨설팅 계약서를 보내겠다고 답했음
          + 법적 절차를 거쳐 2일간 워크숍을 진행했고, 그들은 비용을 지불했음
          + 원하는 만큼의 가치를 지불할 준비가 되어 있다면, 무료로 일하지 말라는 교훈을 얻었음
     * Microsoft의 Cloud Native Ecosystem 팀의 Lachlan이 Philip에게 사과의 메시지를 전했음
          + Spegel 프로젝트의 리더십과 협업에 감사하며, 프로젝트가 클라우드 네이티브 커뮤니티에 실질적인 도전을 해결한다고 평가했음
          + 라이선스 헤더를 수정하기 위한 풀 리퀘스트를 제출했으며, 더 나은 오픈 소스 커뮤니티의 관리자가 되기 위해 노력할 것임
     * Microsoft에 대한 비난이 많지만, 이는 개인의 경력 발전을 위한 행동일 가능성이 높음
          + 오픈 소스 커뮤니티는 이러한 상황에서 개인에게 직업적 결과를 부과할 방법이 필요함
          + 직업적 결과는 경력 기회 상실, 기여자 권한 상실, 신뢰할 수 없는 사람으로 알려지는 것임
     * MIT 라이선스를 따르지 않는 것은 저작권 침해임
          + 그러나 파일에 저작권 공지가 없었기 때문에 문제를 제기하기 어려움
          + OSS 친화적인 변호사와 상담할 것을 권장함
     * 새로운 종류의 라이선스, 즉 커뮤니티 오픈 소스가 필요하다는 의견이 있음
          + Microsoft와 같은 기업이 프로젝트를 포크할 때 커뮤니티에 해를 끼침
          + 이윤 추구가 아닌 협업을 중시하는 커뮤니티 윤리가 필요함
     * Microsoft가 저작권 공지를 제거한 것은 잘못이지만, 저자는 불만을 제기할 근거가 없음
          + 가장 허용적인 라이선스를 선택했다면 그에 따른 결과를 받아들여야 함
     * Microsoft 내부에서 누군가가 승진을 위해 다른 사람의 작업을 활용하고 있을 가능성이 있음
          + 이는 처음도 마지막도 아닌 사례이며, Microsoft는 의도적으로 이러한 행동을 반복함
     * Peerd 프로젝트의 저작권 귀속을 수정하기 위한 커밋이 제출되었음
          + 몇몇 파일의 저작권 헤더가 업데이트되었고, LICENSE 파일의 귀속도 수정되었음
"
"https://news.hada.io/topic?id=20442","덜 느린 C/C++ 코드 작성하는 법 배우기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        덜 느린 C/C++ 코드 작성하는 법 배우기

     * 고성능 C/C++ 및 어셈블리 코딩 기법을 실전 예제로 학습할 수 있는 오픈소스 프로젝트
     * STL 대신 최적화된 라이브러리와 다양한 하드웨어 최적화 기법 사용 예시 포함
     * 입력 생성 비용, 수학 함수 근사화, CPU 분기 예측, 멀티코어 병렬화 등 다양한 퍼포먼스 트릭 설명
     * CUDA, PTX, ASM, FPGA, JSON 처리 등 플랫폼별 최적화 기법과 벤치마크 측정 방법까지 폭넓게 다룸
     * Google Benchmark 기반으로 벤치마크 실행 및 통계 처리 자동화 기능 제공
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

성능 지향 C/C++ 및 어셈블리 코드 작성법

     * 이 프로젝트는 고성능 소프트웨어 설계에 필요한 직관과 사고방식 형성을 돕는 벤치마크 코드 모음임
     * 현대 코드에서 흔한 버그, 보안 문제, 성능 병목 등을 피하기 위한 실전 코딩 예제를 다룸
     * 대학 강의나 부트캠프에서 접하기 어려운 실무 성능 지향 기법을 체계적으로 소개함
     * 대부분의 코드는 GCC, Clang 기반의 Linux 환경에서 동작하지만, Windows와 macOS도 일부 지원함
     * 고성능 코드 구현을 위한 병렬 알고리듬, 코루틴, 다형성 등도 함께 소개함

주요 항목들

     * 무려 100배 저렴한 무작위 입력?! 알고리듬보다 입력 생성이 더 느릴 수도 있다는 사실
     * 1% 오차로 비용은 1/40: std::sin 같은 STL 삼각함수를 단 3줄 코드로 근사화해보기
     * 지연 로직이 4배 더 빠르다고? 커스텀 std::ranges와 반복자로 극한의 게으름 구현
     * -O3를 넘는 컴파일러 최적화: 숨겨진 플래그와 트릭으로 성능을 2배 더 끌어올릴 수 있음
     * 행렬 곱셈이 문제라고? 연산 수는 60% 적지만 3x3x3 GEMM이 4x4x4보다 70% 느릴 수 있음
     * AI 스케일링의 진실? 이론적 ALU 처리량과 실제 BLAS 성능 간의 간극 측정해보기
     * 조건문 몇 개가 많다고 할 수 있을까? 단 10줄 코드로 CPU 분기 예측기의 한계 실험
     * 재귀가 더 좋아? 어디서 SEGFAULT 나는지 스택 깊이 직접 측정해보자
     * 예외를 피해야 하는 이유? std::error_code나 std::variant 같은 대안 써볼래?
     * 멀티코어 확장하려면? OpenMP, Intel oneTBB, 혹은 직접 만든 스레드 풀을 이용하는 법
     * 메모리 할당 없이 JSON 처리하는 법? C++20이 더 나을까, 아니면 구식 C99 도구가 더 간단할까?
     * STL의 연관 컨테이너 제대로 쓰려면 커스텀 키와 투명 비교자를 어떻게 활용할까?
     * 수제 파서보다 빠른 방법이 있다면? consteval 기반 정규표현식 엔진으로 정면 승부
     * 포인터 크기는 진짜 64비트일까? 포인터 태깅을 활용해보자
     * UDP가 얼마나 많은 패킷을 드롭할까? 사용자 공간에서 io_uring으로 웹 요청 처리까지 해보자
     * Scatter-Gather로 50% 더 빠른 벡터화된 비연속 메모리 연산 구현
     * Intel oneAPI vs Nvidia CCCL? <thrust>와 <cub> 은 뭐가 특별할까?
     * CUDA C++, PTX, SASS는 CPU 코드와 뭐가 다른가?
     * 성능 민감한 코드라면? 인트린식, 인라인 asm, 또는 .S 파일 중 어떤 걸 선택할지 비교
     * Tensor Core와 메모리 구조 — CPU와 Volta, Ampere, Hopper, Blackwell GPU는 어떻게 다를까?
     * FPGA 코딩은 GPU랑 어떻게 다를까? 고수준 합성(HLS), Verilog, VHDL의 차이점은? 🔜 #36
     * Encrypted Enclave란 무엇인가? Intel SGX, AMD SEV, ARM Realm의 지연시간 비교 🔜 #31

실행 방법 및 환경 설정

     * Linux + GCC 환경 추천, WSL 또는 Mac의 Clang(비기본 배포판)도 사용 가능
     * CMake, liburing, OpenBLAS, g++, build-essential 설치 필요
     * less_slow 실행 파일을 빌드 후 실행하면 벤치마크 자동 수행됨

git clone https://github.com/ashvardanian/less_slow.cpp.git
cd less_slow.cpp
pip install cmake --upgrade
sudo apt install -y build-essential g++ liburing-dev libopenblas-base
cmake -B build_release -D CMAKE_BUILD_TYPE=Release
cmake --build build_release --config Release
build_release/less_slow

     * CUDA 및 Intel TBB 사용 여부 선택 가능 (-D USE_INTEL_TBB=OFF 등 플래그 사용)
     * 실행시 특정 벤치마크만 선택 실행하거나 JSON 저장, 출력 포맷 지정 가능

build_release/less_slow --benchmark_filter=std_sort
build_release/less_slow --benchmark_out=results.json --benchmark_format=json

성능 측정 향상 팁

     * SMT 비활성화, random interleaving 사용으로 노이즈 최소화
     * Google Benchmark의 --benchmark_perf_counters 옵션으로 하드웨어 성능카운터 측정 가능

sudo build_release/less_slow --benchmark_perf_counters=""CYCLES,INSTRUCTIONS""

     * 또는 Linux perf 툴을 이용한 벤치마크 측정 가능

sudo perf stat taskset 0xEFFFEFFFEFFFEFFFEFFFEFFFEFFFEFFF build_release/less_slow --benchmark_filter=super_sort

프로젝트 파일 구조

     * 메인 소스: less_slow.cpp (CPU 벤치마크 코드 중심)
     * 플랫폼별 최적화 파일 포함: x86/ARM용 ASM, CUDA .cu, PTX .ptx 코드 포함

├── less_slow.cpp           # 주 벤치마크 코드
├── less_slow_amd64.S       # x86 어셈블리
├── less_slow_aarch64.S     # ARM 어셈블리
├── less_slow.cu            # CUDA C++
├── less_slow_sm70.ptx      # PTX IR (Volta)
├── less_slow_sm90a.ptx     # PTX IR (Hopper)

외부 라이브러리 사용

     * Google Benchmark: 성능 측정
     * Intel oneTBB: 병렬 STL 백엔드
     * Meta libunifex: 비동기 실행 모델
     * range-v3: std::ranges 대체
     * fmt: std::format 대체
     * StringZilla: std::string 대체
     * CTRE: std::regex 대체
     * nlohmann/json, yyjson: JSON 파서
     * Abseil: 고성능 컨테이너
     * cppcoro: 코루틴 구현
     * liburing: 리눅스 커널 우회 I/O
     * ASIO: 비동기 네트워킹
     * Nvidia CCCL, CUTLASS: GPU 알고리듬 및 행렬 연산

Google Benchmark 사용 팁 요약

     * BENCHMARK()로 벤치마크 등록, ->Args({x,y})로 파라미터 전달
     * DoNotOptimize(), ClobberMemory()로 컴파일러 최적화 제어
     * ->Iterations(n), ->MinTime(n)으로 반복 수 및 벤치 시간 제어
     * ->Complexity(...), ->SetComplexityN(n)으로 시간 복잡도 지정
     * state.PauseTiming(), ResumeTiming()으로 타이밍 구간 직접 제어
     * state.counters[...]로 커스텀 카운터 등록 가능

밈과 유머 요소

     * 교육 자료에 기술 밈 이미지 삽입으로 흥미 유발
     * 성능과 추상화의 대립, IEEE 754 부동소수점 등 유머러스하게 표현

        Hacker News 의견

     * 40배 빠른 삼각법: std::sin 같은 표준 라이브러리 함수를 3줄의 코드로 가속화할 수 있음
          + 확장을 몇 개의 항으로 제한하여 sin(x)를 근사할 수 있음
          + 계산 비용은 줄어들지만 정확도도 감소함
          + 정확도 감소는 과소평가임. [-2, 2] 범위를 벗어난 입력에 대해 매우 부정확함
          + 단일 사인파 구간도 처리할 수 없으며 반복적인 특성도 다루지 못함. 쓸모없는 ""최적화""임
     * 마이크로컨트롤러에서의 경험 공유
          + 임베디드 시스템에서 작업 중이며, 힙은 약 256 KiB, 가장 큰 스택은 4 KiB임
          + 현대적인 C++를 주로 사용하지만 모든 트릭이 모든 상황에 적합하지 않음
          + CTRE는 스택 오버플로우를 피하는 한 괜찮음. HTTP 프록시 구성의 문자열을 검증하려고 시도했으나 스택 오버플로우로 인해 시스템이 충돌함
          + JSON을 내부적으로 거의 사용하지 않고 자체 BSON 라이브러리를 작성함. 메모리 할당이나 단편화를 걱정할 필요가 없음
          + newlib 대신 picolibc를 사용하고 C/C++ 표준 라이브러리 로케일 코드를 제거함. 프로그램 크기를 줄임
     * Abseil의 선택에 대한 의견
          + 처음 등장했을 때 큰 이슈였지만, 이제는 약점을 개선한 여러 대안이 존재함
          + 최근 몇 년 동안 Abseil에 대한 불만이 증가함. Google에서 핵심 라이브러리 유지 관리자의 이탈이 있었음
     * C++에서 성능을 위한 왜곡에 대한 비판
          + CTRE가 좋은 결과를 준다는 것에 놀람. 더 깊이 파고들 필요가 있음
          + OpenMP 및 TBB 스레드풀 벤치마크를 조사하고 Boost::ASIO 스레드풀을 추가할 수 있는지 확인하고 싶음
     * FPGA와 GPU 코딩의 차이점 및 고급 합성, Verilog, VHDL에 대한 요청
          + 이 주제에 대한 우선 요청을 받고 싶음
     * 비정규화된 부동소수점에 대한 새로운 정보
          + GPU에서 행렬을 곱할 때 가끔 궁금해함
     * Google Benchmark 게시물에 대한 긍정적인 피드백
          + 성능 벤치마킹에 대한 집중이 좋음. 저장소가 잘 구성되어 있음
     * ""덜 느린 C, C++, 어셈블리 코드""에 대한 기대
          + C 코드도 포함될 줄 알았으나 .cpp와 .S만 있음
          + less_slow.cpp가 많은 C++ 특성을 사용함. ""C""를 목록에서 제거하거나 수정이 필요함
"
"https://news.hada.io/topic?id=20443","AI는 우리를 '접착제'로 만들고 있다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         AI는 우리를 '접착제'로 만들고 있다

     * AI 도구들이 개발자의 핵심 업무 일부를 대체하면서 사람은은 ‘문제 해결자’에서 ‘연결자’ 역할로 밀려나고 있음
     * ""바이브 코딩""처럼 AI가 구현을 맡고 인간은 아이디어만 제시하는 미래가 제시되지만, 현실은 아직 복잡함
     * 개발자는 AI의 눈과 손이 되어 결함을 파악하거나 설정을 만지는 '배관공' 역할로 전락할 수 있음
     * 시간이 지나면 이마저도 AI가 넘보게 되어, 인간은 물리 세계와 AI를 연결하는 '풀 역할'로 축소될 가능성이 있음
     * 창의성과 자율성을 잃은 인간 노동이 ‘글루(glue)’ 같은 존재로 전락하는 미래에 대한 불안과 회의감을 담은 글
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

아마 그런 식은 아닐 거야

   AGI를 걱정하지 않고 사랑하는 법을 배우려고 애쓰고 있지만, 솔직히 좀 암울한 기분임.

   나는 소프트웨어를 만드는 일을 하고 있고, 지금 시점에서 내가 아는 거의 모든 사람들처럼 LLM을 활용해서 작업 속도를 높이고 있음.
   어제 o3가 출시됐고, 벌써 복잡한 버그를 해결하는 데 큰 도움이 됐어
   예전 같았으면 수많은 시행착오를 겪었을 문제였는데, 훨씬 덜 헤매고 해결했지.
   겉보기엔 좋은 일이지. 근데 뭐가 문제냐고?

   문제는, 나는 그런 복잡한 버그를 해결하는 걸 좋아한다는 점이야!
   그건 퍼즐 같고, 파고들다 보면 평소에 잘 안 보이던 컴퓨터의 부분들을 배우게 돼.
   리팩터링도 마찬가지야—잘 하고 있을 땐 내 시스템의 형태를 더 깊이 이해하고, 그걸 구조로 정제해 나가는 과정이거든.
   그런 문제들을 푸는 건 뇌가 간질간질할 정도로 즐거운 자극이야.
   내 일이 가장 보람 있는 부분인지는 모르겠지만, 내가 가장 좋아하는 부분인 건 확실해.

   아직 그 시점에 도달한 건 아니지만, 분위기는 이미 정해져 있어.
   아주 보수적으로 봐도, 10년 안에 대부분의 '구체적인 문제를 깊이 있게 사고하는' 일은 컴퓨터가 나보다 더 잘하게 될 거야.

   어떤 역할을 이 작업에서 도려내고 나면, 남는 건 서로 거의 닿지 않는 두 덩어리야.
   배를 조종하는 사람, 그리고 배관을 잇는 사람 (은유가 뒤섞여 있는 건 양해 부탁).
   AI에 기대를 거는 사람들의 말을 들어보면, 예외 없이 전자가 될 생각에 들떠 있더라.
   “바이브 코딩”[1] 이라는 개념의 약속은 이래—작업의 최상단 레이어, 그러니까 감각, 아이디어, 디자인, 철학 같은 것만 신경 쓰면 되고, 나머지는 머신이 알아서 해준다는 거지.
   그렇게 되면 인간은 인간만이 할 수 있는 일에 집중할 수 있게 된다는 논리야.

   나도 몇 가지 아이디어가 있고, 솔직히 말하면 그런 세상도 나쁘진 않겠다는 생각이 들기도 해.[2]
   근데 내 경험상, 그건 복잡한 현실의 절반 정도만 담긴 이야기야.
   예를 들어보자. 내가 어떤 에이전트를 도구들과 함께 쓰고 있어도, 시스템이 보지 못하는 문제는 결국 사람이 본다.
   웹 애플리케이션을 만들고 있다고 해보자. Claude Code가 내 지시에 따라 스타일을 짜줬어.
   근데 이게 실제 브라우저에서 어떻게 보일지 확인하는 건 결국 나야.
   그리고 당연하게도, 뭔가 이상해. 왜냐면 CSS라는 게 원래 그렇거든.
   그리고 내가 그 스타일을 직접 짠 게 아니라서 낯설다 보니, 가장 쉬운 해결책은 다시 Claude에게 가져가서 굴려보는 것뿐이야.
   다시 요청하고, 다시 수정하고. 버그 리포트를 쓰는 일은 버그를 고치는 일보다 훨씬 재미없고,
   결국 난 Claude가 내 컴퓨터를 둘러보는 데 필요한 “눈” 역할만 하게 돼.

   물론 누군가는 이렇게 반론할 수도 있겠지: “이런 사이버 배관 역할은 머지않아 사라질 거야.”
   맞아, 최전선의 연구소들은 지금도 전체 컴퓨터 조작이 가능한 에이전트를 개발 중이니까.
   걔들이 브라우저 탭을 열고 화면을 확인하는 것쯤은 나만큼 잘 하게 될 거야.
   근데 아직까진 AI의 공간 추론 능력이 형편없어서, 솔직히 말하면 지금은 약간의 안전지대(moat)[3]가 있는 느낌이야.
   그렇다 해도, 배관 작업은 한동안 남아있을 거야.
   예를 들어, 로그를 한 플랫폼에서 다른 쪽으로 파이프라인 구성하거나,
   스토리지 버킷의 접근 정책을 설정해서 에이전트가 제대로 파일을 쓸 수 있게 해주는 일.
   이런 작업은 내 직업 안정성에는 도움이 되지만, 솔직히 말해 별로 좋아하진 않아.
   차라리 프로젝트의 핵심 아이디어를 고민하고 싶지, n번째 클라우드 서비스의 2FA 코드를 찾아다니고 싶진 않거든.
   근데 앞으로는 이 시간조차도 “풀 같은 일”과 비교되면서 정당화하기 어려워질 거야.

   좋은(…그런가?) 소식은, 이런 역할조차도 조만간 AI에게 넘겨질 거라는 점이야.
   그 시점이 오면, 나는 AI와 현실 세계[4] 사이를 잇는 연결 고리 같은 존재가 될 것 같아.
   당분간은 하드웨어 프로젝트를 한다면, 점퍼 와이어를 브레드보드에 연결하거나 안테나를 만지는 건 아직 내가 할 일이겠지.
   나는 이런 손작업을 좋아해, 근데 컴퓨터가 전체 게임 플랜을 알고 있는 상황이라면… 그건 좀 재미가 덜할 거야.
   운이 좋으면 나는 배의 “아이디어 선장” 역할을 맡을 수 있을지도 몰라.
   하지만 배가 어디로 가야 할지를 AI한테 물어봐야 하는 선장이라면, 그 역할도 오래 못 갈 거야.
   그리고 솔직히 말하면, 모든 사람이 각자 자기 배의 선장이 되어 생계를 유지할 수 있다고는 생각하지 않아.

   그 이후에는 무슨 일이 일어날지 전혀 모르겠어.
   존재론적인 위험은 일단 제쳐두고 보더라도, 많은 직업이 사라질 거라는 건 분명해 보여.
   낙관적인 시나리오는, 우리가 지금은 상상도 못할 새로운 직업들을 만들고,
   그걸 통해 사람들은 전에 없이 자아실현을 하게 될 거라는 거야.
   하지만 슈퍼지능이 상품처럼 보급된 세상에서,
   그 새로운 직업들이 결국은 ‘풀처럼 연결만 하는 일’ 로 보일까 봐, 난 그게 걱정이야.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

    1. 사족이지만, ""바이브 코딩(vibe coding)""이라는 표현은 어딘가 좀 거슬리긴 함.
       하지만 이미 위키백과 문서까지 있는 걸 보면, 이제는 그냥 업계 용어인 모양.
    2. 이 방식의 장점은 굳이 설명할 필요도 없을 정도로 명확함.
       이전에는 상상도 못 했던 것들을 만드는 사람들이 지금 정말 많음.
    3. 솔직히 말해, 나는 ‘화살표 연결하기’가 내 전문 역량이라고 생각해본 적은 없음.
    4. 좀 더 일반적인 이야기로, 화면 속 지능에 비해 로보틱스의 발전 속도가 상대적으로 느리기 때문에,
       당분간은 인간의 ‘육체를 가진 존재성’이 기계에 대한 주요 이점으로 남을 것 같아.
       말 그대로의 배관공(아이러니하게도, 이들의 일은 앞에서 말한 ‘디지털 배관’보다 오히려 버그 수정에 더 가까울 것 같지만)은
       여전히 한동안은 괜찮을 거고, 다른 기술직 종사자들도 마찬가지.
       그리고 어떤 직업은 ‘접착제 역할’이 되더라도, 내가 묘사한 것처럼 꼭 무의미하게 느껴지지는 않을 수도 있음.
       예를 들어, 변호사는 판결문의 주 저자가 아니라 배심원에게 전달하는 역할로 변할 수도 있고,
       의사는 진단 능력보다는 환자와의 태도나 공감 능력이 더 중요해질 수도 있음.
       (창작 활동에 대해서는 여기서 길게 말하진 않겠지만, 아마 가장 큰 혜택과 가장 큰 고통을 동시에 겪게 될 분야라고 생각함.)

   아마 지금의 AI는 10% 정도의 완성도라고 봅니다.
   보통 특이점을 넘으면 순식간에 70% 이상을 채우는 경우를 많이 봤는데, 그렇게 되면 많은 직업이 사라질 수 있겠지만 처리 비용을 봤을 때 인간이 더 저렴하면 남아 있는 직업도 많을 것 같습니다.

   참 어렵네요..

   천공카드 쓰자고 주장하실분..

   그 얘기 아닌 것 같아요 ㅎㅎ

   하하하하하

        Hacker News 의견

     * 이 글을 정말 재미있게 읽었음
          + 존재론적 위험을 제쳐두고, 많은 직업이 사라지지 않을 미래를 보지 못하겠음
          + 개인적으로 LLMs의 정체 효과에 베팅하고 있음
          + 두 가지 정체가 올 것이라고 봄: LLMs 자체의 정체와 인간의 정체
          + LLMs는 이미 새로운 모델이 더 나빠지는 현상을 보이고 있음 (예: Sonnet 3.5가 3.7보다 코딩에 더 나음)
          + 인간은 AI에 의존하면서 스킬이 퇴화하고, 새로운 프로그래밍 형태를 창조하거나 이를 기록하는 데 동기부여가 줄어듦
          + 단기적으로는 그렇지 않겠지만, 장기적으로는 무서운 일이 될 것임
          + AI로 인해 의도치 않게 망가진 시스템을 고치거나 대체하는 일이 미래의 일이 될 것임
          + ""AI 문제 해결사""가 되거나 ""수제 소프트웨어""를 만드는 기업가가 될 것임
          + 둘 다 꽤 수익성이 있을 것으로 예상함
     * 왜 이런 기사들은 항상 ""LLMs를 사용해서 일을 더 빨리 끝냈다""고 말하면서, LLMs가 더 많은 시간과 돈을 들여 더 나쁜 결과를 내게 한다고 설명하는지 모르겠음
          + LLMs 없이도 기준을 낮추는 데는 스스로의 힘이 충분했음
     * ""접착제""라는 댓글은 주로 소프트웨어 작업을 하는 사람의 관점을 반영함
          + 기계화된 생산 라인이 처음 만들어졌을 때부터 그랬음
          + 인간의 일은 직접적인 노동이 아니라 기계를 모니터링하고, 재시작하고, 고치는 것임
          + 파워 룸은 아마도 이런 장치의 첫 번째 사례일 것임
          + 생산 라인은 많은 스테이션을 가지고 있으며, 드릴 비트가 부러지거나 렌즈에 먼지가 끼거나 소모품이 떨어지면 중단됨
          + 예외를 자동화하기 어렵고, 공장 설계는 예외를 최소화하고 막힌 셀을 우회하는 데 중점을 둠
          + 소프트웨어 개발이 어떻게 변화하고 있는지 볼 때 공장의 작동 방식을 이해하는 것이 도움이 됨
          + ""vibe coding""이라는 표현은 두 달 전에 생겨났음
          + 2년 후에는 얼마나 널리 퍼질지 궁금함
     * AI가 소프트웨어 엔지니어의 일자리를 빼앗을 가능성은 낮음
          + 소프트웨어는 자동차, 음식, 주택과 달리 사람들이 소비할 수 있는 양에 자연적인 상한선이 없음
          + 소프트웨어 엔지니어는 궁극적으로 ""만들고자 하는 의지""를 가진 사람들임
          + 코드나 도구는 단지 수단에 불과함
     * ""복잡한 버그를 고치는 것을 좋아함""
          + 나는 아님
          + 더 빠르게 해결책을 찾을 수 있는 도구는 언제나 환영임
          + AI는 지루한 부분을 잘 처리함
     * 다른 경험을 하고 있음
          + Claude에게 버그를 고치라고 계속 요청하는 것이 짜증남
          + 그래서 ""한 번에 한 조각씩 이해하며"" 버그를 직접 고치는 작업을 계속하고 있음
          + 실제로 LLM을 사용하여 작은 라이브러리를 만들어 실행 앱에서 LLM의 필요성을 피하고 있음
          + StackOverflow의 강화 버전처럼 느껴짐
          + 나는 접착제가 아니라 필요한 정보를 빠르게 얻기 위한 우수한 도구를 가지고 있는 것뿐임
     * 이 모든 것에 대해 여전히 꽤 비관적임
          + 오늘 LLM 코딩 어시스턴트가 도와줄 수 있는 명백한 승리를 기대했음
          + 매우 긴 구조체를 다른 매우 긴 구조체로 변환하는 go 함수를 작성 중이었음
          + 변환은 거의 전적으로 첫 번째 구조체의 필드를 래퍼에 감싸는 방식이었음
          + LLM이 이를 수행하지 못했음
          + 필드를 미리 채워 넣고 그것들을 채우라고 했지만, 새로운 필드를 상상하려고 했고, 한두 개를 한 후 내가 추가한 필드를 삭제하고 '나머지를 수행하라'는 주석을 추가함
          + 여러 가지 다른 프롬프트를 시도했음
          + 일부 vibe coders가 유용한 것을 만들 수 있는 방법을 볼 수 있지만, 대부분의 시도는 좌절의 연속이었음
     * Stanislaw Lem의 이야기가 있음
          + ""다른 곳에서 Tichy는 완벽한 조화를 원하여 자신을 기계에 맡기고, 기계가 그들을 반짝이는 디스크로 변환하여 행성 전체에 즐거운 패턴으로 배열하는 외계인 종족을 만남""
          + (접착제는 아니지만, 충분히 가까움)
     * 복잡한 버그를 재미로 고치는 것을 막는 것은 없음
          + 취미 컴퓨팅은 이제 그 어느 때보다 접근성이 높음
          + 다른 사람들을 위해 무언가를 만들면 AI가 대부분 타이핑과 디버깅을 제거함
          + 이는 무엇을 만들고 있는지, 어떻게 가장 유용하게 만들지를 더 깊이 생각할 수 있게 해줌
          + 일반적으로 더 빨리 완료되므로 사용자에게 더 빨리 전달할 수 있어 반복 횟수가 증가함
          + 모두에게 이익임
     * 잘 작성된 글임
          + 기본 아이디어의 전제에 동의함
          + 변화가 훨씬 더 극적일 것이라고 생각함
          + 많은 사람들이 정체되어 있으며, 주변의 다른 것들이 자동화될 것이라고 생각하지만, 자신은 그렇지 않을 것이라고 생각함
          + ""나는 특별하다""고 생각하지만, 많은 사람들이 자신이 얼마나 특별하지 않은지를 알게 될 것임

   생산 라인은 많은 스테이션을 가지고 있으며, 드릴 비트가 부러지거나 렌즈에 먼지가 끼거나 소모품이 떨어지면 중단됨
   예외를 자동화하기 어렵고, 공장 설계는 예외를 최소화하고 막힌 셀을 우회하는 데 중점을 둠
   소프트웨어 개발이 어떻게 변화하고 있는지 볼 때 공장의 작동 방식을 이해하는 것이 도움이 됨
   ""vibe coding""이라는 표현은 두 달 전에 생겨났음
   2년 후에는 얼마나 널리 퍼질지 궁금함

   <- 이 부분 비유 진짜 기가막히네요. 감탄했습니다.
"
"https://news.hada.io/topic?id=20464","페이스북과 인스타그램 비활성화가 사용자 감정 상태에 미치는 영향","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  페이스북과 인스타그램 비활성화가 사용자 감정 상태에 미치는 영향

     * 소셜 미디어 비활성화가 사용자들의 감정 상태에 미치는 영향을 연구한 논문
     * Facebook 계정을 6주간 비활성화한 사용자는 행복감, 불안, 우울증 지수에서 0.060 표준편차 개선을 보임
     * Instagram 비활성화는 0.041 표준편차 개선을 보였지만, 통계적 유의성은 Facebook보다 낮음
     * Facebook 효과는 35세 이상 사용자, Instagram 효과는 18~24세 여성에서 가장 큼
     * 앱 사용 추적 결과, Instagram 비활성화는 대부분의 시간을 다른 앱 사용으로 대체, Facebook은 부분 오프라인 시간 증가
     * 전체적으로 감정 상태 개선 효과는 존재하지만, 심리치료 효과나 장기 사회 변화와 비교하면 작음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

연구 개요

     * 본 논문은 2020년 미국 대선을 앞두고 Facebook과 Instagram을 비활성화한 실험을 통해 감정 상태에 미치는 영향을 분석함
     * 총 약 3만여 명의 사용자를 대상으로 한 무작위 통제 실험으로, 기존 연구보다 20배 이상 큰 규모임
     * 사용자는 6주간 플랫폼 비활성화 대가로 150달러 보상, 통제 그룹은 1주간 비활성화 후 25달러 보상

주요 결과: 감정 상태의 변화

  평균 효과

     * Facebook 비활성화: 감정 상태 지수 0.060 표준편차 개선 (p < 0.01)
          + 행복감: +0.064 / 우울감: +0.039 / 불안감: +0.028 (모두 개선 방향)
     * Instagram 비활성화: 감정 상태 지수 0.041 표준편차 개선 (p = 0.016)
          + 행복감: +0.044 / 우울감: +0.026 / 불안감: +0.024
     * 효과는 두 플랫폼 모두에서 행복감 증가가 가장 크고, 불안 개선 효과는 상대적으로 작음

  하위 그룹별 분석

     * Facebook: 35세 이상 사용자에게 효과가 크며, 대학 학위 미소지자와 미결정 유권자에게도 상대적으로 큰 효과
     * Instagram: 18~24세 여성 사용자에서 가장 큰 감정 상태 개선 효과 (0.111 표준편차, p = 0.002)
     * 정치 참여도, 기존 감정 상태, 사용 시간 등은 감정 개선 효과의 강도에 뚜렷한 영향을 주지 않음

앱 사용 대체 효과

     * Instagram 비활성화: 전체 앱 사용 시간에는 변화 없고, 주로 TikTok, Snapchat, YouTube 등으로 대체됨
     * Facebook 비활성화: 하루 평균 9분의 앱 사용 감소로, 일부 시간이 오프라인 활동으로 전환된 것으로 해석됨

효과 크기의 해석

     * 감정 상태 설문 응답 기준으로는 약 3.8%의 사람이 '가끔'이 아닌 '자주' 행복하다고 응답한 수준의 변화
     * 심리 치료 개입의 평균 효과(0.27 표준편차)의 약 15~22% 수준
     * 2008~2022년 청년층 감정 악화 폭(0.37 표준편차) 대비, Instagram 비활성화 효과는 약 17% 수준

기존 연구와의 비교

     * 본 연구는 역대 최대 규모이며, Instagram 단독 비활성화 효과를 처음으로 분석
     * 기존 7개 실험(모두 표본 200명 미만)보다 정밀하고 신뢰도 높음
     * 기존 상관 분석 중심의 연구들과 비교할 때, 무작위 실험 기반이므로 인과 추론 신뢰도 높음

연구 한계

     * 참여자는 자발적 응답자이며, 실제 플랫폼 사용자 전체를 대표하지 않을 수 있음
     * 감정 상태 측정은 자기 보고식 설문 3문항에 기반함
     * 실험은 단 6주 동안의 개별 사용 제한만을 측정했기 때문에 장기 효과나 대규모 비활성화와는 다름

결론

     * Facebook과 Instagram을 선거 직전 비활성화한 사용자는 감정 상태에서 평균적으로 긍정적인 개선을 경험함
     * 효과는 상대적으로 작지만 일관성 있게 유의미함
     * 특히 Facebook은 나이든 사용자, Instagram은 젊은 여성에게 더 강한 긍정적 효과
     * 선거 시즌이나 정치적 콘텐츠 노출이 감정 상태 악화의 주요 요인일 수 있으며, 일시적 플랫폼 이탈이 부분 완화 가능성 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

     정책적 시사점: SNS 사용 감소가 감정 상태에 미치는 영향을 입증하는 대규모 실험으로, 디지털 웰빙이나 사용자 보호 정책의 근거 자료로 활용 가능함.

   삭막한 현대 사회에서 '퉁퉁퉁퉁퉁퉁퉁퉁퉁사후르'는 포기할 수 없습니다..

   3년전부터 Facebook과 Instagram, Twitter 앱을 전부 삭제했고, 비슷한 효과를 보았습니다.

   Instagram이 아니라도 이어질 인연은 계속 이어지더라구요.

        Hacker News 의견

     * 많은 사람들이 현재 소셜 미디어의 문제를 해결하기 위해 ""피드""를 제거하고 친구, 가족, 실제로 아는 사람들의 게시물, 업데이트, 사진을 표시하는 방식을 제안함. 이는 대형 기술 소셜 미디어의 수익 모델과 충돌할 수 있으며, 많은 사람들이 익숙해진 것과 다를 수 있음. 개인적으로는 학교 친구, 대학 친구, 먼 가족과 연결될 수 있는 작은 소셜 네트워크를 원함. 정치인의 무의미한 발언이나 주목을 받기 위한 인플루언서의 행동을 보고 싶지 않음
     * Twitter에서 700명 이상의 팔로워를 가졌었음. 아무 생각이나 올리면 몇 분 안에 누군가와 흥미로운 대화를 나눌 수 있었음. 예를 들어, 전화 제조업체가 업데이트 배포에 p2p 프로토콜을 사용하지 않는 이유를 궁금해했고, 주요 통신사에서 일하는 사람이 그 이유를 설명해줌. 이것이 현대 인터넷에서 가장 큰 기쁨이었음
     * 사람들이 떠나고 나서 팔로워가 500명으로 줄었지만 X의 자체 지표에 따르면 아무도 내 트윗을 보지 않음. 평균 조회수는 13에서 20 사이로 추정됨. 게시물을 올리면 실제로 아는 사람이 거의 항상 반응함
     * Mastodon과 Bluesky에도 계정이 있지만 팔로워 수는 여전히 낮음. 기술 질문을 고민하는 사람에 대한 시장이 더 이상 없다고 생각함. 2010년처럼 트윗을 하지만 이제는 아무도 신경 쓰지 않음. 이것이 나에게 소셜 미디어의 죽음이었음
     * Instagram은 요즘 정신적으로 피폐해짐. 최고의 사진을 게시하는 갤러리로 사용했지만 이제는 아무도 신경 쓰지 않음. 왜 신경 써야 하는지 모르겠음. 이것이 요즘 모든 소셜 미디어에 대한 나의 일반적인 의견임
     * 나는 확실히 예외적이지만 소셜 미디어의 단점이 항상 두드러졌고 이점보다 더 큰 것처럼 보였기 때문에 소셜 미디어에 뛰어들지 않았음. 그러나 점점 더 어려워지고 있음. 특히 아이들이 자라면서 거의 모든 사회 활동이 소셜 미디어와 연결되어 있음. 아내는 마지못해 WhatsApp에 가입했으며, 그렇지 않았다면 사회적으로 고립될 운명이었을 것 같음
     * 최근 한 경우, 자녀의 학교 반 학부모 그룹이 있다는 것을 알지 못했음. 누군가가 왜 전날 볼링에 오지 않았냐고 물어보기 전까지는 몰랐음. WhatsApp에 없는 사람을 포함할 필요성을 아무도 느끼지 않음
     * Facebook을 비활성화하면 행복도가 표준 편차의 1/16만큼 증가함. Instagram은 그보다 더 적음. 선거 기간 동안 측정되었기 때문에 효과가 가장 클 때임. 효과의 크기가 너무 작음
     * Reddit에서 댓글을 중단하면 감정적 스트레스가 크게 줄어듦. Reddit은 ""사회적"" 반사회적 서클 중 하나로, 논쟁의 ""잘못된 편""에 있을 여유가 없으며 모든 논의가 빠르게 악화될 수 있음
     * Facebook과 Twitter를 버린 이후로 확실히 더 행복해졌음. 세상이 전반적으로 별로이기 때문에 급격한 변화는 아님. 몇몇 나이 든 가족 구성원이 Facebook에서만 소통하기 때문에 사실상 보이지 않게 된 것이 조금 슬프지만, 솔직히 말해서 Facebook 이전에도 어머니의 첫 사촌들과 대화하지 않았기 때문에 실제로 잃은 것은 거의 없음
     * 50년 후, 우리는 소셜 미디어와 스마트폰 중독을 현재 흡연을 보는 것처럼 볼 것임. ""어떻게 그것을 허용하고 홍보했을까?""라고 손자들이 물을 것임
     * Facebook에서 몇 주 동안 비활성화한 사람들은 행복, 우울증, 불안 지수에서 0.060 표준 편차 개선을 보고함. Instagram을 비활성화한 사람들은 0.041 표준 편차 개선을 보고함. 이러한 개선은 미미해 보임
     * Facebook과 Instagram 계정을 삭제한 후 내면의 평화가 즉시 증가했음. 명상이 더 깊고 좋아졌음. 사람들이 주로 자신의 완벽한 삶을 게시하여 현실을 왜곡하고 질투, 죄책감, 기타 부정적인 감정을 유발함. 결국 우울감으로 이어짐
"
"https://news.hada.io/topic?id=20456","왜 OpenAI는 Windsurf를 인수하려고 할까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     왜 OpenAI는 Windsurf를 인수하려고 할까?

     * OpenAI가 약 30억 달러에 AI 코딩 도구 Windsurf(Codeium) 인수를 논의 중
     * Windsurf는 GitHub Copilot, Cursor 등과 유사한 AI 코딩 보조 도구로, 사용자 규모는 작지만 기술적으로는 유사한 기능 제공
     * 해당 인수가 이루어진다면, OpenAI의 목적은 코드 데이터 확보 또는 GPT 모델 배포 채널 확장으로 해석 가능
     * AI 코딩 도구 시장은 제품 간 차별성이 낮고 오픈소스 대안이 풍부하여 수익화가 어려운 구조
     * Google은 Gemini 모델과 TPU, 인재 확보 전략 등으로 조용히 AI 시장을 장악 중이며, Apple은 GPU 부족과 데이터 접근 제약으로 부진한 상황
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# OpenAI, Windsurf 인수 논의 중

     * 최근 유출된 정보에 따르면 OpenAI는 AI 코딩 도구 Windsurf(Codeium)의 인수를 약 30억 달러 규모로 논의 중
     * 이는 Google이 Wiz를 인수한 300억 달러보다는 작지만, 스타트업 업계에서 매우 큰 규모의 거래에 해당함
     * Windsurf는 약 2년 된 스타트업으로, 현재 브랜드(Codeium)로는 약 5개월 정도 운영 중
     * 제품 인지도는 낮아 Google 검색 시 윈드서핑 스포츠 정보가 더 많이 노출될 정도로 사용자 수가 적음
     * 다만 회사 측은 100만 명 이상의 사용자 수를 주장하고 있으나, 실제 활성 사용자 수는 불확실함

  Windsurf, Cursor, Copilot 등 AI 코딩 보조 도구 개요

     * Windsurf는 이전 이름이 Codeium이며, 경쟁사는 Cursor, GitHub Copilot 등임
     * 이들 도구는 모두 AI 모델을 코딩 워크플로에 통합하여 개발자 생산성을 향상시키는 구조
     * 세 가지 주요 기능 단위로 나뉨
          + 자동완성: 타이핑 중 자동으로 코드 완성 제안
          + 사이드바 Q&A: 코드창 옆에서 모델에게 질문하고 코드 수정 요청
          + Agentic Flow: 모델이 전체 코드베이스를 분석하고 실행하며 반복적으로 수정

  AI 코딩 도구들의 차별성과 경쟁

     * 제품 간 UX와 기능은 거의 동일하며, 차별화 요소는 미미(1~2% 수준)
     * Copilot은 자동완성, Claude Code는 agentic flow, Bolt/Replit은 비개발자 대상 등 세부 타겟팅만 다름
     * 대부분의 제품이 모델을 직접 개발하지 않고 다양한 LLM(GPT, Claude, Gemini 등)을 감싸는 GPT 래퍼 형태로 구성됨
     * 오픈소스 도구인 Avante(vim 플러그인) 도 동일한 기능을 무료로 제공함
     * 사용자는 특정 IDE나 개인 선호도에 따라 쉽게 다른 도구로 전환 가능함 → 전환 비용 거의 없음

  시장 구조와 기업 가치의 한계

     * AI 코딩 보조 도구는 쉽게 수직 분화(verticalize) 될 수 있어, 경쟁 제품이 빠르게 등장할 수 있음
     * Cursor는 초기 선도 기업이었으나, Claude가 코딩에 강해지자 이용자 이탈 발생
     * Cursor는 자체 플랫폼 없이 VSCode 포크에 의존하고 있어, 장기적으로 Microsoft에 인수되는 것 외엔 출구 전략이 부족함
     * Windsurf는 Cursor보다 사용자 수 적고, 브랜드 인지도 낮고, 미래 성장성 불투명
     * 그럼에도 OpenAI가 제안한 30억 달러는 과하게 높은 금액이라는 지적이 많음

  OpenAI의 재정 상황과 투자 전략

     * OpenAI는 SoftBank를 포함한 투자자로부터 총 400억 달러 유치 계획을 발표함
     * 실제로 확보된 자금은 100억 달러 수준이며, 나머지는 OpenAI가 영리기업으로 전환 시 제공 예정
     * 경쟁사 Google은 세계 최대의 기술기업이자 자체 인프라, 모델, 데이터, 수익성까지 확보한 상태
     * Microsoft와의 관계가 소원해지며 GitHub 기반 코드 데이터 접근이 제한되었을 가능성 존재
     * Windsurf 인수를 통해 OpenAI가 코드 학습 데이터를 확보하려는 목적이 있을 수도 있음

  Windsurf 인수의 의미와 논란

     * Windsurf는 코드 실행 능력이나 컴퓨팅 인프라를 제공하지 않음
     * GPT 모델의 배포 플랫폼으로 Windsurf를 삼으려는 전략일 가능성도 있음
     * 과거 Facebook이 WhatsApp, Instagram을 인수했듯, 장기적 분산 채널 확보 전략일 수도 있음
     * OpenAI는 최근 소셜미디어 프로젝트도 발표했으며, 이를 통해 독자적 데이터 수집과 배포 채널 확보를 시도 중
     * 그러나 GPT는 현재 프로그래밍 성능에서 Claude나 Gemini보다 약세라는 평가가 많음

  플랫폼 고정의 위험성과 시장 반응

     * Windsurf 사용자 대부분은 GPT가 아닌 Claude, Gemini 등의 LLM을 사용하고 있음
     * GPT 전용화 시 플랫폼 경쟁력이 약화되어 기존 사용자 이탈 가능성 큼
     * Windsurf가 다양한 LLM을 지원해야 하는데, 그렇다면 OpenAI가 인수할 명확한 이유가 줄어듦
     * 결과적으로 Windsurf의 인수 논의는 AI 시장 과열 현상의 상징으로도 해석 가능
     * 저자는 이 인수를 “AI 시장이 지나치게 뜨거운 것의 증거”로 보고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# Google, 조용히 AI 시장 장악 중

     * 최근 2주간 OpenAI(o3, o4-mini, GPT-4.1), Meta(Llama 4), Grok(Grok-3) 등 다수의 신모델이 공개되었으나, 시장 반응은 매우 조용함
     * 과거 같았으면 큰 이슈가 되었을 출시 일정임에도 불구하고, 이번에는 언론과 커뮤니티에서 주목도 낮음
     * 이는 대부분의 시장 참여자들이 이미 Google이 AI 모델 성능과 가격 측면에서 우위를 점하고 있음을 인식하고 있기 때문임
     * LMSYS 챗봇 아레나와 가격-성능 비교 지표 모두에서 Google Gemini 2.5가 전 구간 1위를 차지하고 있음
     * OpenAI의 신모델은 일부 벤치마크에서 좋은 성적을 보이지만, 비싸고 느리며 성능 차이는 크지 않음이라는 반응

  Google의 AI 전략: 폐쇄성과 독점적 경쟁력 확보

     * Google은 자사의 생성형 AI 관련 논문을 최대 6개월간 공개 지연하는 정책을 공식화함
     * 내부 연구자들이 논문 발표 전 다수의 내부 승인 절차를 거치도록 함으로써 경쟁사에 지식 유출 방지
     * 경쟁사로 인재 유출 방지를 위해 연구자에게 최대 1년간 유급 비경쟁 기간을 제공함
     * DeepMind 소속 인재들이 아무 일도 하지 않고 대기하며 경쟁사 이직을 막는 구조가 형성됨
     * 이러한 전략은 연구 생태계를 폐쇄적으로 만들지만, Google이 AI 경쟁에서 주도권을 유지하는 핵심 요소로 작용함

  하드웨어 인프라에서도 우위 확보

     * Google은 자사 클라우드 플랫폼 GCP에 탑재된 TPU(텐서 프로세싱 유닛) 를 지속적으로 개선하고 출시 중
     * 모델 성능과 무관하게, AI 연산 수요 증가에 따라 TPU를 통한 인프라 수익 확보 가능
     * 이는 Google이 모델에서 승리하지 못해도 하드웨어에서 승리할 수 있는 이중 전략을 가능하게 함

  조용하지만 효과적인 Google의 움직임

     * 겉으로는 조용하지만, Google은 적극적인 인재 영입과 기술 축적, 그리고 시장 통제 전략을 진행 중
     * OpenAI, Meta, Anthropic, xAI 등 타 경쟁사는 Google의 폐쇄된 연구 결과 없이 기술 발전에 제약을 받을 수 있음
     * AI 생태계에서 Google의 기술 의존도는 높아지고 있으며, 기술적으로 독립 가능한 기업은 점점 줄어드는 추세
     * Google의 전략은 법적 리스크(DOJ 반독점 소송 등)를 수반하긴 하지만, 단기적으로 매우 효과적인 결과를 내고 있음

  시장 경쟁과 소비자 혜택

     * 지난 5년간 모델 품질은 상승하고 토큰 단가는 지속적으로 하락하며, 소비자는 더 많은 혜택을 받게 됨
     * Google, OpenAI, Meta 등 대기업 간의 치열한 경쟁이 AI 기술의 대중화를 가속화함
     * 만약 AI 기술이 고가에 독점되었다면, 현재의 개방적이고 혁신 중심의 환경은 불가능했을 것
     * Google은 뒤늦게 각성한 것처럼 보이지만, 이제는 혁신과 시장 주도력에서 가장 앞선 기업으로 평가됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# Apple, AI 경쟁에서의 침묵과 뒤처짐

     * 최근 AI 관련 기술 발표가 잇따르는 가운데, Apple은 눈에 띄는 행보가 거의 없는 상황
     * LLM 시장은 과학자, 연산 자원, 데이터 확보에 따라 승자 독식 구조가 뚜렷한데, Apple은 연산 자원과 데이터 확보에 큰 어려움을 겪고 있음
     * Apple은 자금력은 충분하지만, GPU 수급과 인프라 투자 결정에서 자체 발목을 잡는 실책을 범함

  연산 자원 부족과 내부 의사결정 실패

     * 2023년 초, AI 담당 부사장이 GPU 구매 예산 증액 요청을 했지만, CEO Tim Cook이 승인한 예산이 CFO에 의해 절반 이하로 삭감됨
     * 당시 Apple은 5년 이상 된 GPU 5만 개 수준의 노후 장비만 보유하고 있었고, Microsoft, Google 등은 수십만 개의 최신 GPU 확보 중이었음
     * 이로 인해 Apple의 AI 팀은 Amazon, Google 등의 클라우드 제공업체에 의존하게 되었으며, 일부 개발은 Google의 칩으로 진행됨
     * 자체 데이터센터가 있긴 하지만, 클라우드 서비스 제공업체가 아닌 점에서 구조적 불리함 존재
     * GPU 확보 실패로 AI 모델 학습과 배포 모두 제한, TPU와 같은 자체 칩 개발 시도는 아직 미비함

  데이터 확보의 한계와 브랜드 딜레마

     * Apple은 사용자 개인정보 보호 정책을 브랜드 아이덴티티로 삼아 왔으며, 이에 따라 공격적인 데이터 활용에 제약이 있음
     * 이는 과거 광고 추적 차단 등에서 Meta를 견제하며 브랜드 신뢰를 쌓았지만, 현재 AI 경쟁에서는 큰 약점으로 작용
     * OpenAI, Meta, xAI 등 경쟁사는 공개 게시물이나 모호한 저작권 우회 방식으로 대규모 데이터 확보 중
     * 반면 Apple은 저작권 데이터를 정식 구매하는 방식을 택하고 있으나, 학습에 필요한 양에는 현저히 부족함

  AI 레이스에서의 딜레마와 전략 부재

     * Apple은 이제 두 가지 선택지 사이에 놓임
          + 사용자 데이터를 활용해 경쟁력을 확보하되 브랜드 손상 위험 감수
          + 또는 지금처럼 제약 속에서 느리게 따라잡는 전략 유지
     * 그러나 후자의 경우, 시장에서의 기술적, 상업적 경쟁력은 계속 낮아질 가능성이 큼
     * 최악의 시나리오는 나중에 사용자 데이터를 활용해 브랜드 손상은 감수하면서도 기술 격차는 여전한 상태에 빠지는 것
     * 현재까지는 브랜드 보호를 우선시한 '핸디캡 전략'을 유지하고 있음

  결론: AI 시장에서의 존재감 부족

     * Apple은 모바일 혁명에서는 중심에 있었지만, AI 혁신에서는 사실상 부재 상태
     * 내부 예산 결정 실패와 신중한 전략이 기술적 주도권 상실로 이어짐
     * 데이터 보호 정책은 브랜드에는 이점이지만, AI 시장에서 경쟁력을 심각하게 제한함
     * 결과적으로, 현재 Apple은 AI 전쟁터에서 두 손이 묶인 채 싸우는 형국에 처해 있음

        Hacker News 의견

   OpenAI가 Windsurf나 Cursor와 같은 경쟁자를 만들지 못한 이유에 대한 질문이 있음
     * OpenAI는 ChatGPT, Sora, Dall-e와 같은 제품을 통해 제품화를 추구하는 기술 회사임
     * IDE는 채팅 앱보다 복잡하지만, OpenAI는 개발자 도구에 익숙하고 자체 기술을 활용할 수 있음
     * 작은 팀이 만든 도구들도 많아, Google과 Facebook이 더 이상 자체적으로 성장할 수 없다는 것을 인정하는 것일 수 있음

   몇 가지 생각:
    1. 이러한 회사들의 방어벽은 얇음
          + 자동 완성 기능이 Cursor의 주요 기능이며, 이는 간단하지 않음
          + 모델의 품질과 지연 시간을 어떻게 균형 잡을지 고민해야 함
          + 기본 모델의 성능에 따라 달라짐
    2. 모델에 대해, GPT 4.1이 자동 완성 기능을 지원할 수 있는 합리적인 후보로 보임
          + Windsurf의 Varun이 GPT 4.1 발표 라이브 스트림에 참여했음
    3. 주식 거래일 가능성이 높음
          + $3B 현금 거래라는 주장이 확실하지 않음
    4. 에이전트 흐름이 성공하면 데이터가 더 중요한 방어벽이 될 수 있음
          + Cursor나 Windsurf 같은 플랫폼은 사용자의 코딩 방식을 수집할 수 있음
          + 이는 RLHF와 같은 방법을 통해 에이전트 흐름을 개선할 기회를 제공함

   자동 완성과 에이전트 흐름에 대한 차이점:
     * Copilot은 자동 완성에, Claude Code는 에이전트 흐름에 강함
     * Bolt나 Replit은 비기술적인 사람들을 위한 도구로, Copilot은 대기업을 위한 도구로 차별화됨
     * 그러나 이러한 차별화는 제품에 1-2% 차이만을 만듦
     * UX와 핵심 기능은 본질적으로 동일함

   Cursor와 Copilot의 차이:
     * Cursor와 Copilot의 차이는 1%가 아님
     * 많은 사람들이 Copilot을 무료로 사용할 수 있음에도 불구하고 Cursor 라이선스를 구매함

   OpenAI의 전략:
     * 인재와 배포 전략
     * Windsurf는 이미 많은 기업 고객과 다운로드를 보유하고 있음
     * OpenAI는 많은 토큰을 판매하여 수익을 창출하려 함

   영국의 Pub 회사와 유사한 동적:
     * 주요 플레이어들이 실패했지만, 맥주 제조업체들에게는 수익성 있는 배포 채널이었음
     * Heineken은 Pub을 인수하여 맥주 배포 채널을 확보함

   3억 달러의 투자:
     * 이러한 도구들이 기대만큼 작동하지 않는다는 증거일 수 있음
     * AI 코딩 에이전트로 거의 무료로 만들 수 있다면 3억 달러를 쓸 이유가 없음

   OpenAI의 투자 분석:
     * Windsurf 인수에 3억 달러를 현금으로 지출한다는 주장은 잘못된 분석임
     * 주식으로 구매할 경우, 이 제품이 미래에 3억 달러 이상의 가치가 있을지에 대한 질문이 중요함

   Cursor와 Anthropic의 관계:
     * OpenAI는 경쟁 제품을 이 공간에 삽입하는 것을 꺼리지 않음
     * 이 공간은 플랫폼 위에서 실제 가치 창출을 보여주는 최전선임

   Snowflake의 Streamlit 인수와 유사:
     * 구매자의 내부 실행이 느려지고 있다는 신호일 수 있음

   Windsurf가 OpenAI에 데이터 접근을 제공하는지에 대한 질문:
     * 코딩 코파일럿을 통해 생성된 가치 있는 데이터는 코드가 아니라 코드 생성 과정에서의 인간-AI 상호작용임
     * Windsurf와 Cursor는 데이터 주석 농장으로, 더 나은 코딩 모델을 제공하는 데 도움을 줌

   OpenAI의 3가지 주요 이유:
    1. 팀을 다른 프로젝트로 전환하는 기회 비용이 3억 달러보다 클 수 있음
    2. 인수 즉시 백만 명의 사용자를 확보하고, 두 번째로 좋은 IDE를 소유하게 됨
    3. Windsurf 팀이 제품에 집중할 수 있게 함

   Windsurf/Codeium의 기업 버전:
     * 기업이 자체 하드웨어 스택을 사용하여 AI 지원 코딩 환경을 제공할 수 있음
     * 이는 프라이버시와 독점적인 이유로 유리함
     * Codeium을 실행하는 하드웨어는 많은 개발자가 토큰을 생성하는 것보다 저렴함
     * 이 모델은 많은 유료 고객을 생성할 가능성이 있음
"
"https://news.hada.io/topic?id=20470","FTC, Uber의 기만적 구독 과금 및 취소 방해 행위 제소","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   FTC, Uber의 기만적 구독 과금 및 취소 방해 행위 제소

     * 미국 FTC는 Uber가 사용자 동의 없이 구독 요금을 부과하고, 취소 절차를 의도적으로 복잡하게 만든 혐의로 제소함
     * Uber One 서비스는 월 25달러의 절약을 약속하지만, 실제로는 구독료(최대 $9.99)를 감안하지 않고 잘못된 정보를 제공함
     * 무료 체험 중에도 사용자에게 조기 요금 부과 사례 다수 존재
     * 구독 취소 과정은 최대 23개의 화면과 32번의 클릭을 요구하며, 의도적으로 사용자 이탈을 방해하는 구조
     * FTC는 Uber가 FTC법 및 ROSCA법 위반 혐의가 있다고 판단, 북캘리포니아 연방지방법원에 소송 제기함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

FTC, Uber의 기만적 구독 과금 및 취소 방해 행위 제소

  사건 개요

     * 미국 연방거래위원회(FTC)는 2025년 4월 21일, Uber를 상대로 소송을 제기
     * Uber One 구독 서비스에 대해 사용자 동의 없는 과금 및 취소 방해 행위를 근거로 함
     * 소송은 북부 캘리포니아 연방지방법원에 제기됨

  주요 혐의 내용

    1. 잘못된 할인 약속

     * Uber One은 월 $25 절약을 약속하지만, 실제로는 구독료($9.99) 포함되지 않음
     * 관련 정보는 회색 작은 글씨 등 눈에 잘 띄지 않게 배치
     * 일부 사용자는 계정 없이도 요금이 청구되었다고 주장

    2. 무료 체험 중 과금

     * 무료 체험 기간 중에도 조기 결제 사례 다수 발생
     * 이용자는 ""무료 기간 중 언제든지 취소 가능""하다는 안내를 받았으나 실제로는 자동 과금됨

    3. 복잡한 구독 취소 절차

     * 구독 취소를 위해 최대 23개의 화면, 32번의 동작 필요
     * 사용자가 취소 버튼을 누르면 취소 이유 요구, 보류 유도, 할인 제안 등으로 반복 유도
     * 일부는 고객지원팀에 문의해야 한다고 안내되나, 연락처가 제공되지 않음
     * 취소 요청 후에도 응답을 기다리는 동안 다시 청구된 사례 다수 보고됨

  법적 근거 및 FTC 입장

     * 해당 행위는 FTC 법 및 온라인 쇼핑자 신뢰 회복법(ROSCA) 위반에 해당
          + ROSCA는 온라인 서비스 판매 시 명확한 조건 고지, 동의 확보, 간단한 취소 방법을 요구
     * FTC 위원장 앤드류 N. 퍼거슨:

     ""미국 소비자들은 취소가 불가능한 구독 서비스에 지쳤다. 우리는 이를 바로잡기 위해 싸우고 있다.""
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

     이 사건은 디지털 구독 서비스의 투명성과 사용자 권리 보호에 대한 중요한 선례가 될 수 있음.
     FTC는 온라인 소비자 보호 기준을 명확히 하고, 향후 플랫폼 기업의 책임 강화를 예고함.

        Hacker News 의견

     * 최신 앱의 어두운 패턴은 주문이나 탑승을 망치고 계정 크레딧 형태로 ""환불""해 주는 것임. 실제로 돈을 돌려받을 방법이 없음. 지원팀에 연락하려고 하면 끝없는 도움 화면과 챗봇의 루프에 빠지게 됨. 지원 담당자에게 연결되더라도 환불은 앱 계정으로만 이루어짐. 마지막 문제 발생 시 신용카드로 환불받고 싶다고 세 번이나 요청해야 했음. 그들이 이렇게 할 수 있다는 것이 미침
     * 새로운 나라에 도착해 공항에서 호텔로 Uber를 이용할 때, 다른 Uber 계정이 다른 가격을 제시받음. 그래서 공항에서 버너폰과 심카드를 구매하는 것이 더 나음. 몇 번의 여행 후 Uber 비용 절감이 차이를 메움. 그럼에도 불구하고 Uber는 택시 마피아보다 1000% 안전하고 나음
     * UberOne 때문에 거의 UberEats를 사용하지 않게 되었고 대신 지역 경쟁사를 사용함. UberOne 도입 후 주문이 픽업 후 지연되는 일이 많아짐. 운전자가 다른 방향으로 먼저 다른 주문을 배달해야 했음. UberOne 사용자에게 우선권이 주어졌기 때문임. 자주 음식을 주문하지 않아서 구독을 정당화할 수 없었고, 그래서 남아프리카의 Mr D(elivery)로 전환함. 배달 시간이 거의 항상 일정함. 돈이 나라 밖으로 나가는 것을 줄이는 것에 대해 조금 더 나은 기분이 듦
     * Uber에 대해 비관적임. 이러한 음흉한 전술에도 불구하고 현재 규모에서 거의 수익을 내지 못하고 있음. 지난 분기 120억 달러의 매출에서 7억 7천만 달러를 벌었음. 형편없는 비즈니스 모델이며 매 분기마다 월스트리트의 부풀려진 기대를 충족시키기 위해 필사적임
     * CA의 온라인 구독 취소 요구와 유사하게, 구독을 온라인으로 구매할 경우 취소하는 데 필요한 단계가 구독하는 데 필요한 단계와 동일해야 한다는 규칙이 필요함. 여전히 조작될 수 있지만, 사용자 유입 경로를 작업한 사람은 추가 단계가 전환을 줄인다는 것을 알고 있음. 그래서 자체 균형을 맞출 것임
     * 그들은 뇌물을 지불했음. ""CEO 기부자 중 100만 달러를 기부한 사람은 OpenAI의 Sam Altman, Apple의 Tim Cook, Uber의 Dara Khosrowshahi가 포함됨""
     * 일화: Uber Eats는 2 for 1 딜을 마케팅했음. 딜 때문에 주문했음. 항상 두 항목을 장바구니에 추가했지만 갑자기 변경됨. 수동으로 추가해야 한다는 것을 몰랐고 하나만 배달됨. 그들에게 전화했지만 전체가 아닌 일부만 환불해줌. 기회 비용을 고려하지 않음. 다른 것을 샀거나 전혀 사지 않았을 것임. 그들은 구매를 강요했다고 생각함
     * Uber는 끔찍한 고객 서비스와 경계선 도둑질의 사례 연구가 될 가치가 있음. UberEats 주문을 10분 늦게 픽업하러 갔을 때 150달러를 훔쳐갔음. 픽업 시간이 엄격하며 비부패성 상품이라도 시간 내에 나타나지 않으면 환불 없이 몰수된다고 주장함. 신용카드 분쟁에서도 싸웠음. 끔찍한 회사임
     * 일부 사용자에게는 취소하려면 고객 지원에 연락해야 한다고 하지만 연락 방법을 제공하지 않음. 회사는 엣지 케이스를 처리하지 않음으로써 많은 돈을 절약할 수 있음
"
"https://news.hada.io/topic?id=20504","고급 Python 기능들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             고급 Python 기능들

     * 파이썬에서 흔히 알려지지 않은 고급 기능 14가지를 실제 예제와 함께 소개함
     * typing, generics, protocols, context managers 등 정적 타이핑과 구조적 설계에 대한 심도 있는 설명 제공
     * 파이썬 3.10 이상부터 새롭게 도입된 구조적 패턴 매칭과 슬롯, 메타클래스 등 성능 최적화 기법도 포함
     * f-string, cache, future, proxy, for-else, walrus 등 깔끔한 코드 작성을 위한 팁 수록
     * 각 기능마다 추가 학습을 위한 링크와 참고 자료 제공, 주니어 개발자도 쉽게 접근 가능한 구성
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

파이썬 고급 기능 14가지 요약

  # 타이핑 오버로드

     * @overload 데코레이터는 하나의 함수에 여러 타입 시그니처를 정의 가능하게 함
     * 타입 체커는 전달된 인자 값에 따라 리턴 타입을 정확히 추론할 수 있음
     * Literal을 활용해 문자열 값 제한도 가능
     * id 또는 username 중 하나만 필수로 받는 함수 시그니처도 구현 가능
     * 타입 안정성을 위한 경량화된 Enum 대체로 Literal 활용

  # 키워드 전용/위치 전용 인자

     * *를 사용하면 키워드 전용 인자로 설정 가능 (위치 인자 사용 불가)
     * /를 사용하면 위치 전용 인자로 설정 가능 (키워드 인자 사용 불가)
     * API 설계 시 인자 사용 방식을 명확히 강제할 수 있음

  # 미래 어노테이션 (__future__)

     * 타입 힌트는 원래 런타임에서 바로 평가되기 때문에 선언 순서 이슈 발생
     * from __future__ import annotations로 평가 시점 지연 가능
     * 하지만 문자열 처리 방식이므로 런타임에서 타입 사용 시 주의 필요
     * PEP 649는 __annotations__ 속성에 지연 평가 방식으로 개선 제안

  # 제네릭(Generic) 문법

     * 파이썬 3.12부터는 새로운 제네릭 타입 정의 문법 지원
     * TypeVar 대신 class Foo[T, U: int] 형태로 더 직관적 사용 가능
     * 가변 길이 제네릭(Variadic Generics) 도 도입되어 다양한 타입 처리 가능
     * 타입 별칭 정의도 간결해져 type Vector = list[float] 형태로 사용 가능

  # 프로토콜(Protocols)

     * Duck Typing의 타입 체크 버전으로 구조적 서브타이핑 구현 가능
     * 클래스가 특정 메서드를 갖고 있다면 타입 상속 없이도 타입 호환 가능
     * @runtime_checkable로 isinstance 검사도 가능하게 확장 가능

  # 컨텍스트 매니저(Context Manager)

     * __enter__, __exit__ 메서드를 가진 객체로 with 블록에서 사용
     * contextlib.contextmanager 데코레이터로 간단한 함수 기반 구현 가능
     * yield를 기준으로 전후로 설정 및 정리 작업 수행

  # 구조적 패턴 매칭

     * match-case 문법으로 복잡한 데이터 구조를 직관적으로 분기 처리
     * 튜플/리스트 구조 분해, OR 패턴, 가드 조건(if), 와일드카드 사용 가능
     * 데이터의 구조를 기준으로 분기 가능하므로 가독성과 유지보수성 향상

  # slots 최적화

     * __dict__ 대신 고정된 슬롯 사용으로 메모리 및 속도 최적화
     * __slots__는 속성 이름만 명시된 튜플을 사용
     * 클래스에 불필요한 속성 추가 방지
     * 하지만 마이크로 최적화 수준으로 사용에 신중함 필요

  # 파이썬 코드 스타일 팁 모음

     * for-else 구문: 루프가 break 없이 끝날 경우 else 실행
     * 워루스 연산자(:=): 변수 선언과 검사 동시에 가능
     * or 단축 평가: 여러 값 중 가장 먼저 참인 값을 반환
     * 비교 연산자 체이닝: 0 < x < 10 식으로 코드 간결화 가능

  # f-string 고급 포맷팅

     * f""{변수=}"" 구문으로 디버깅용 표현 가능
     * 숫자 포맷(:.2f, :+.2f, :,), 날짜 포맷(%Y-%m-%d) 등 다양한 옵션
     * 가운데 정렬, 패딩, 백분율 표현 등 포맷 미니 언어 활용

  # 캐시 데코레이터

     * @lru_cache와 @cache로 함수 결과를 저장해 속도 향상
     * 재귀 함수나 반복 계산이 많은 경우 유용
     * @cache는 파이썬 3.9부터 도입, 기본 무제한 캐시 제공

  # 파이썬 퓨처(Future)

     * JS의 Promise와 유사한 비동기 객체 처리 기능
     * Future.set_result(), add_done_callback() 등으로 결과 비동기 관리
     * asyncio.Future()는 await과 함께 사용 가능
     * ThreadPoolExecutor와 함께 사용 시 백그라운드 병렬 처리도 가능

  # 프록시 속성 (Proxy Property)

     * 하나의 클래스 속성이 속성처럼도, 함수처럼도 동작하게 함
     * __get__, __call__, __repr__를 통해 두 가지 기능 제공
     * API 디자인 시 기본값과 파라미터 호출을 하나의 방식으로 처리 가능
     * 실사용보다는 실험적 예제로 참고할 가치 있음

  # 메타클래스

     * 클래스 자체를 생성하는 클래스의 클래스
     * 클래스 속성을 조작하거나 자동 등록 등의 메타 로직 가능
     * 현실적으로는 대부분 데코레이터로 대체 가능
     * Django, SQLAlchemy, Pydantic 등에서는 내부적으로 메타클래스 활용

   백엔드 관점에서 메타클래스는 디버깅을 어렵게 하는 경험이 있었습니다.

   for-else는 가독성이나 명확성이 높지 않다는 의견이 있어 안티 패턴으로 간주되는 경우가 많고, asyncio.Future는 asyncio의 내부적인 구현 디테일로 취급된다는 점을 참고하세요.

   감사합니다. 특히 10번 바로 적용 들어갑니다.

   AI 코딩 규칙 추가..

   꿀팁 감사합니다

        Hacker News 의견

     * 안녕하세요! 블로그의 원작자입니다! 새벽 4시에 제 글이 HN의 첫 페이지에 올라온 것을 보고 놀랐음
          + 이 글은 블로그 시작하기 한 달 전에 쓴 14개의 작은 트윗에서 시작되었음
          + 블로그를 시작하면서 이 트윗들을 첫 게시물로 재사용하기로 했음
          + 그래서 흐름이 약간 이상하게 느껴질 수도 있음
          + 월요일에는 유용한 것을, 금요일에는 좀 더 특이한 것을 찾으려고 했음
          + 제목도 마찬가지로, Python을 사용하면서 흥미롭게 느낀 14가지 기능을 모은 것임
          + 제목을 생각하는 데 5초 정도밖에 쓰지 않았음
     * Python을 사용할 때마다 코드가 Python을 잘못 사용한 것처럼 보일까 걱정됨
          + Python에 대해 몰랐던 깊이 있는 내용이나 변화에 놀라움
          + Go는 코드가 몇 년 후에도 뒤처지지 않을 것이라는 확신을 줌
          + 훌륭한 기사임
     * Python은 Python으로 남아야 하고, golang, Rust, Typescript는 각각의 철학과 디자인을 가져야 함
          + 28년 동안 4가지 언어로 코딩 중이며, Python의 변화가 마음에 들지 않음
          + Python이 인기를 얻은 이유는 타입 체크나 주석 같은 추가 레이어 때문이 아님
          + 다른 언어에서도 비슷한 것을 봤음
          + 최근 소개된 기능들의 포괄적인 목록임
          + 독자들이 유용하게 여길 수 있는 이전 목록도 있음
     * Python의 가장 큰 장점은 실행 가능한 의사 코드처럼 느껴진다는 것임
          + 언어가 도메인 수준의 지시사항을 방해하지 않음
          + 더 많은 기능을 추가할수록 매력이 떨어짐
          + 대부분의 사람들은 Python을 깊이 이해하지 못함
     * 9.3 단락 평가에 대한 지적: 빈 문자열이 있을 경우 평가가 다르게 이루어짐
          + if-else 절은 빈 문자열을 유효한 것으로 취급하지만, or 연산자는 None과 동등하게 취급함
     * Javascript/Typescript에서 Python으로 전환한 사람으로서 유용한 자원임
          + 타이핑 오버로드는 Javascript의 불행한 기능을 위한 것이며, 기술 부채로 간주함
          + 키워드 전용 및 위치 전용 인수는 구문이 너무 간결해서 가독성이 걱정됨
          + 미래 주석은 최근에 큰 도움이 되었음
          + 프로토콜은 Typescript와 비슷하지만 Python답지 않음
          + 메타클래스는 고유한 문제를 해결할 수 있는 강력한 도구임
     * 대부분의 기능은 고급 기능이 아님
          + 메타클래스는 복잡한 행동을 유도할 수 있어 피하는 편임
          + '프록시 속성'은 기능이 아님
     * 목록에서 바꾸고 싶은 것은 collections.abc 컨테이너의 포함임
          + 여러 댓글이 월러스 연산자를 싫어했지만, 좋은 용도를 찾고 나서는 유용하게 사용함
          + 정규 표현식 패턴을 사용할 때 코드가 훨씬 깔끔해짐
     * 이 글을 읽는 것이 즐거웠음
          + 대부분의 기능은 타이핑 모듈의 기능임
          + 제네릭이나 프로토콜에 대해 확신이 없었음
          + 현대의 생산 수준 Python 코드가 모든 곳에서 타입을 사용하는지 궁금함
"
"https://news.hada.io/topic?id=20422","소프트웨어 엔지니어의 미래 - 세계경제포럼 "Future of Jobs Report 2025" 분석","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        소프트웨어 엔지니어의 미래 - 세계경제포럼 ""Future of Jobs Report 2025"" 분석

   소프트웨어 엔지니어로서 급변하는 기술 환경에서 내 커리어는 어떻게 변화할까요? 어떤 기술이 중요해지고, AI는 내 직업에 어떤 영향을 미칠까요? 세계경제포럼의 최신 ""Future of Jobs Report 2025""를 통해 소프트웨어 엔지니어에게 가장 중요한 인사이트를 Q&A 형식으로 정리했습니다.

   디지털전환은 이제 초기 단계죠.앞으로 더 영역이 확장될것입니다. SW엔지니어도.

     Q: AI가 소프트웨어 개발 직업을 대체할까요?

   모든 사람들이 개발자가 없어질지 궁금한가 보다라는 생각이 듭니다.
   저는 개인적으로 별로 안궁금하긴 해요.
"
"https://news.hada.io/topic?id=20404","LLM으로 대규모 테스트 마이그레이션을 가속하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       LLM으로 대규모 테스트 마이그레이션을 가속하기

     * Airbnb는 약 3,500개의 Enzyme 기반 테스트 파일을 React Testing Library(RTL) 로 자동 마이그레이션하는 데 성공
     * 원래 1.5년이 걸릴 것으로 예상한 작업을 LLM과 자동화 파이프라인으로 단 6주 만에 3.5K의 테스트파일 업데이트 완료
     * 자동 유효성 검사, 리트라이 루프, 동적 프롬프트 및 대규모 컨텍스트 구성으로 높은 자동화 성공률 확보
     * 최종적으로 전체 파일의 97%를 자동 변환, 나머지는 수동 마무리로 100% 완료
     * 이 경험을 기반으로 더 복잡한 마이그레이션 작업과 LLM 기반 개발 도구 확장 계획 중
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Airbnb의 LLM 기반 대규모 테스트 마이그레이션

  배경

     * Airbnb는 2020년부터 신규 테스트에 React Testing Library(RTL)를 사용하며 Enzyme에서의 전환을 시작
     * Enzyme은 내부 구현에 깊게 접근하는 방식이 현대 React 철학과 맞지 않아 점진적 제거 필요성 대두
     * 단순 제거는 테스트 커버리지 공백을 초래, 의도와 커버리지를 유지하면서의 변환이 요구됨

마이그레이션 전략

  1. 단계 기반 유효성 검사 및 리팩터링

     * 파일을 상태 기반 파이프라인으로 구성해 각 단계 유효성 검사 통과 시 다음 단계로 이동
     * 실패 시 LLM을 호출해 수정 시도, 단계는 예: enzyme 제거 → jest 수정 → lint/tsc 통과 → 완료 마킹
     * 수백 개 파일을 병렬 처리 가능, 단순 파일은 빠르게 처리, 복잡 파일은 점진적으로 해결

  2. 리트라이 루프 및 동적 프롬프트

     * 실패한 단계는 최대 시도 횟수만큼 반복 실행
     * 각 시도 시, 에러 메시지와 수정된 파일을 프롬프트에 포함해 LLM에게 피드백 제공
     * 단순~중간 난이도 파일 대부분은 10회 이하 시도로 성공

  3. 프롬프트 컨텍스트 확장

     * 복잡한 파일은 단순 리트라이로 해결되지 않아 풍부한 컨텍스트 제공 방식으로 전환
     * 최대 10만 토큰까지 구성, 포함 항목:
          + 해당 컴포넌트 소스 코드
          + 기존 Enzyme 테스트
          + 인접 테스트 및 예시 (few-shot prompting)
          + 팀 내부 스타일 및 공통 패턴
     * 핵심은 양질의 관련 파일 선택, 프롬프트 문장 자체보다 ""무엇을 넣느냐""가 더 중요

  4. 75%에서 97%까지 끌어올리기: 체계적인 개선

     * 자동화로 75% 전환 후, 나머지 25% 중 900개 파일이 실패 상태
     * 문제 분석 및 개선 반복:
         1. 실패 파일 공통 이슈 수집
         2. 대표 샘플 선정 (5~10개)
         3. 프롬프트/스크립트 개선
         4. 샘플에 테스트 적용 후 전체 재시도
     * 4일간 반복 실행으로 자동화 완료율 97% 도달

  남은 3%는 수동 처리

     * 100회 이상 재시도에도 실패한 일부 파일은 자동 리팩터링 결과를 기반으로 수동 수정
     * 이 또한 자동화 덕분에 최소한의 노력으로 최종 완성

결과 및 영향

     * 자동화 첫 실행에서 4시간 만에 75% 마이그레이션 완료
     * 4일간의 반복 개선으로 97% 자동화 완료
     * 나머지 수동 처리 포함해 전체 6주 내에 전환 작업 100% 완료
     * 테스트 의도 및 커버리지 유지하면서 Enzyme 완전 제거
     * LLM API 비용 + 엔지니어링 자원 포함해도 수작업 대비 매우 효율적인 접근

다음 단계

     * 이번 경험을 바탕으로 LLM을 활용한 더 대규모 코드 변환 자동화에 착수
     * 복잡한 리팩터링, 구조 변경 등에도 적용 가능성 탐색
"
"https://news.hada.io/topic?id=20499","DOGE 엔지니어의 코드가 NLRB 내부고발자 주장 입증","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    DOGE 엔지니어의 코드가 NLRB 내부고발자 주장 입증

     * NLRB 내부 고발자는 Elon Musk 산하의 DOGE 부서가 민감한 노동 분쟁 데이터 10GB 이상을 무단 다운로드했다고 주장함
     * DOGE 계정은 관리자 권한으로 로그 감시를 피하고 외부 GitHub 코드 세 개를 다운로드했으며, 이 중 하나는 웹 스크래핑 및 무차별 대입 공격에 사용되는 IP 회전 기술 포함
     * 핵심 직원 Marko Elez는 이 기술의 최신 버전을 GitHub에 업로드했으며, 과거 정보보안 규칙 위반 및 논란성 발언으로 논란된 인물임
     * 다른 다운로드된 코드에는 API 리버스 엔지니어링 툴 Integuru와 자동화 브라우저 Browserless가 포함됨
     * Elez의 코드 품질은 GitHub에서 심각하게 비판받았고, 이후 해당 저장소는 삭제됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

DOGE 계정의 민감 정보 접근

     * 내부 고발자 Daniel J. Berulis는 DOGE 직원들이 3월 3일 NLRB에 최고 권한 관리자 계정(tenant admin) 생성을 요구했다고 주장함
     * 이 계정들은 모든 네트워크 로그 감시에서 제외되며, 데이터 읽기/복사/수정 및 로그 조작이 가능했음
     * Berulis와 그의 상사는 이러한 권한이 없음에도 DOGE는 이를 획득함

GitHub 코드 다운로드와 IP 회전 도구

     * DOGE 계정은 외부 GitHub 저장소 세 개를 다운로드했으며, 그 중 하나는 “pseudo-infinite IPs”를 생성하는 라이브러리
     * 이 라이브러리는 웹 스크래핑과 무차별 대입 로그인 시도에 활용됨
     * 이 코드는 GitHub 사용자 Ge0rg3가 만든 requests-ip-rotator에서 파생되었으며, Marko Elez가 이를 기반으로 async-ip-rotator를 2025년 1월에 제작함

Marko Elez와 그의 논란

     * Marko Elez는 X, SpaceX, xAI 등 Musk의 여러 회사 출신이며, 현재는 노동부 소속으로 여러 정부 기관에 파견됨
     * 과거 재무부 근무 중 민감 정보 유출로 물의를 빚었으며, 인종차별 발언 논란 이후 해고됐다가 복직됨
     * Politico는 Elez가 과거에 일급 보안 정책 위반을 저질렀다고 보도함

추가 다운로드 코드 및 보안 논란

     * 추가로 다운로드된 GitHub 저장소는:
          + Integuru: 웹사이트 API를 리버스 엔지니어링하는 프레임워크
          + Browserless: 브라우저 풀을 활용한 웹 자동화 툴
     * GitHub 사용자는 async-ip-rotator의 보안성과 확장성에 심각한 문제를 제기함
          + ""프로덕션 수준 시스템에 이 코드가 사용되면 즉시 보안 감사를 받아야 함""이라고 평가됨

NLRB의 기능 정지와 정치적 배경

     * 트럼프 대통령은 NLRB 위원 세 명을 해임하며 기관 기능을 사실상 마비시킴
     * 현재 Amazon과 SpaceX는 NLRB가 헌법에 위배된다고 주장하며 소송 중이나, 3월 5일 항소법원은 이를 기각함
     * Berulis는 이 데이터 유출이 특정 기업에게 노동 분쟁에서 부당한 우위를 줄 수 있다고 경고함
          + ""노조 조직자 식별 후 해고가 가능해짐""

        Hacker News 의견

     * Ge0rg3의 코드는 ""오픈 소스""로, 누구나 비상업적으로 복사하고 재사용할 수 있음
          + 이 코드에서 파생된 새로운 버전인 ""async-ip-rotator""가 2025년 1월에 DOGE의 Marko Elez에 의해 GitHub에 커밋됨
          + 원본 코드와 거의 동일하지만 주석이 제거되고 약간의 async가 추가되었으며 사소한 변경이 있음
          + 그러나 원본 GPL3 라이선스가 사라졌음
          + DOGE 사람들이 이를 이해하거나 존중할 것이라고 기대하기 어려움
     * 내부 고발자 Daniel J. Berulis의 불만 사항에 따르면, 2025년 3월 11일경 NxGen 메트릭이 비정상적인 사용을 나타냈음
          + DOGE가 NLRB 시스템에 접근한 후 Primorskiy Krai, 러시아에서 IP 주소를 가진 사용자가 로그인 시도를 시작했음
          + 이러한 시도는 차단되었지만 특히 경고를 주었음
          + DOGE 관련 활동에 사용된 새로 생성된 계정 중 하나를 사용하여 로그인 시도를 했으며, 인증 흐름이 차단된 이유는 국가 외부 로그인 정책 때문이었음
          + 이러한 로그인 시도가 20번 이상 발생했으며, 특히 우려되는 점은 많은 시도가 DOGE 엔지니어에 의해 계정이 생성된 지 15분 이내에 발생했다는 것임
     * DOGE 직원이 접근해서는 안 되는 데이터를 접근함
          + DOGE가 거대한 권한을 가진 계정에 접근하여 10GB의 데이터를 다운로드했을 가능성이 있음
          + 이 데이터를 불법적으로 사용했을 가능성이 있음
          + POTUS가 그러한 접근을 허용할 수 있는지 여부는 불확실함
     * DOGE 직원이 AWS의 IP 주소 풀을 사용하여 제한을 우회할 수 있는 코드를 다운로드함
          + 코드가 잘못 작성되었음
          + 인종차별주의자일 가능성이 있음
     * DOGE 직원이 AWS의 ""무제한"" IP 주소를 사용하여 웹페이지를 자동으로 스크린스크랩하고 내부 NLRB 데이터베이스에서 민감한 데이터를 복사하는 데 어떻게 이익을 얻을 수 있었는지 의문임
          + 10,000개의 세션이 동시에 데이터베이스에 인증하고 데이터를 스크랩했는지 의문임
          + 외부 IP로부터 극도로 민감한 데이터가 접근 가능하고 단일 계정이 10,000번 로그인하여 데이터를 스크랩할 수 있는 시스템이 있다면 문제가 있음
     * Marko Elez의 코드에 대한 비판이 GitHub ""issues"" 페이지에 게시됨
          + 코드가 ""비안전적이고 확장 불가능하며 근본적인 엔지니어링 실패""라고 평가됨
          + 이 비판은 AI가 생성한 것처럼 보임
     * Tesla와 Space-X의 CEO가 스크립트 키디를 고용했다는 주장이 있음
     * 누군가는 이 일로 감옥에 가야 한다고 주장함
          + 이는 단순한 오해가 아니라 모든 미국 시민에 대한 의도적인 공격임
     * GitHub에 공개된 패키지에 대해 비판함
          + 비공개로 만들 수 있다는 것을 모르는 것처럼 보임
     * 정부 데이터베이스에 대한 추적 불가능하고 완전한 접근이 우려됨
     * Berulis가 상사들이 US-CERT에 보고하지 말라고 했기 때문에 공개했다고 주장함
          + 만약 이 주장이 사실이라면, 상사들이 이를 비밀로 유지하려는 동기가 무엇인지 의문임
          + 연방 정부의 나머지 부분도 동일한 위협 행위자에 의해 취약할 가능성이 있음
          + 상사들이 더 나은 채널을 통해 보안 위기를 보고했는지, 아니면 완전히 조용히 유지하려고 했는지 의문임
"
"https://news.hada.io/topic?id=20394","Zoom.us 도메인 '비활성화'로 인한 Zoom 서비스 장애","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Zoom.us 도메인 '비활성화'로 인한 Zoom 서비스 장애

     * Zoom 서비스는 2025년 4월 16일에 도메인 차단으로 인해 일시적으로 중단되었음
     * GoDaddy Registry와 Markmonitor 간의 통신 오류로 인해 발생한 문제였음
     * Zoom, Markmonitor, GoDaddy는 신속하게 문제를 해결하여 서비스를 복구하였음
     * 서비스 중단 동안 보안 문제나 DDoS 공격은 없었음
     * GoDaddy와 Markmonitor는 향후 동일한 문제가 발생하지 않도록 협력 중임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Zoom 서비스 상태

     * Zoom 서비스의 여러 기능에 문제가 발생하였음
     * Zoom.us 도메인이 GoDaddy Registry에 의해 차단되었음
     * Markmonitor와 GoDaddy Registry 간의 통신 오류로 인한 문제였음
     * Zoom, Markmonitor, GoDaddy는 신속하게 문제를 해결하였음
     * 서비스 중단 동안 보안 문제나 DDoS 공격은 없었음

문제 해결

     * 모든 Zoom 서비스가 복구되었음
     * 연결 문제가 지속될 경우 DNS 캐시를 플러시하고 다시 연결할 것을 권장함
     * Windows에서는 ""ipconfig /flushdns"" 명령어를 사용
     * Mac에서는 ""sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder"" 명령어를 사용

모니터링

     * 서비스가 복구되었으며, 연결 문제가 지속될 경우 DNS 캐시를 플러시하고 다시 연결할 것을 권장함
     * Windows에서는 ""ipconfig /flushdns"" 명령어를 사용
     * Mac에서는 ""sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder"" 명령어를 사용

문제 확인

     * Zoom.us 도메인에서 발생한 도메인 이름 해상도 문제를 계속 조사 중임
     * 추가 업데이트가 있을 예정임

조사 중

     * Zoom.us 도메인에서 발생한 도메인 이름 해상도 문제를 조사 중임
     * 정기적인 업데이트가 제공될 예정임

영향받은 서비스

     * Zoom Meetings, Zoom Phone - Global, Zoom Contact Center - Global, Zoom Website에 영향을 미쳤음

        Hacker News 의견

     * 한때 Zoom을 사용하지 않도록 고용주를 설득하기 위해 2-3시간 동안 보안 취약점을 찾아보았음
          + binwalk와 osint만 사용하여 12개의 확인된 버그를 발견했음
          + 가장 심각한 문제는 zoom.us의 godaddy 계정 비밀번호 재설정 이메일 주소가 CEO인 Eric S Yuan의 개인 Gmail 계정이었다는 점이었음
          + 그의 Gmail 계정 비밀번호를 재설정하려고 시도했으며, 2FA 없이 두 가지 질문에만 답하면 되었음. 고향과 전화번호였으며, 공개 데이터를 통해 이를 얻어 재설정 링크를 받았고, zoom.us 도메인 이름을 제어할 수 있었음
          + 이 버그들을 설명할 수 있는 영어를 구사하는 보안 팀원을 찾지 못했고, 확인하고 버그 바운티로 총 $800를 지급받는 데 3개월이 걸렸음
          + 이 사건은 고용주가 Zoom을 사용하지 않도록 설득하는 데 성공했음
     * MarkMonitor의 서비스 가치를 심각하게 떨어뜨리는 사건임
          + MarkMonitor는 ""ICANN 공인 등록기관이자 1999년부터 인정받은 업계 리더""라고 주장함
          + MarkMonitor에 비용을 지불하는 이유는 그들이 가치 있는 도메인에 대해 실수를 하지 않는 고가의 서비스이기 때문임
          + GoDaddy는 여기에 관여해서는 안 됨
     * Fastmail이 fastmail.com을 구매하고 이전 도메인인 'fastmail.fm'에서 이전한 이유임
          + .fm은 멋졌지만, .fm 서버에서 몇 번의 중단을 겪었고, .com으로 이전한 이후로는 그런 문제가 없었음
     * GoDaddy는 매우 무능한 조직임. 중요한 것을 관리하도록 허용해서는 안 됨
     * 몇 년 전 .us TLD를 가지고 있었음
          + 국가 코드에 의존하지 않기로 결정했으며, 같은 이유로 .io도 사용하지 않음
          + gTLD에서도 이런 일이 발생할 수 있지만, 브랜드를 정부에 맡기는 것은 위험함
     * Zoom 클라이언트의 호출을 위해 다양한 등록기관과 호스팅 인프라를 가진 보조 및 3차 도메인을 구현해야 함
          + 서비스 발견을 위한 대체 anycast IP 주소도 고려해야 함
          + 회사들이 서비스에 지불하는 금액을 고려할 때, 그 정도의 엔지니어링 선견지명을 기대하는 것이 합리적임
          + 후회보다는 사후 대처가 필요함. 이를 해결하자
     * GoDaddy와의 거래로 인해 발생하는 서비스 중단이 놀라울 정도로 많음
     * Zoom CEO: 글로벌 중단으로 인해 SLA 크레딧을 요청하고 싶음
          + GoDaddy: 정말 죄송합니다. 다음 구매 또는 갱신 시 $10 할인 쿠폰을 제공할 수 있습니다. 계정에 적용할까요?
          + 대부분의 회사는 사과하는 Zoom 통화가 비즈니스를 유지하기에 충분하다고 생각하며, 대부분의 경우 효과가 있음
          + SLA 크레딧의 비대칭성과 공급업체 중단으로 인한 수익 영향에 대해 충분히 논의되지 않았으며, 이는 빌드 대 구매 결정 프레임워크를 안내해야 함
     * MarkMonitor와 관련된 무언가가 발생한 것처럼 보임
          + MarkMonitor가 실수로 zoom.us를 브랜드 스푸핑으로 표시하고 GoDaddy에 저작권 불만을 제기했으며, GoDaddy는 불만에 따라 도메인을 정지시켰음
     * ThousandEyes의 중단 분석: 링크
"
"https://news.hada.io/topic?id=20383","ChatGPT o3의 환각 현상 유도 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ChatGPT o3의 환각 현상 유도 방법

     * ChatGPT o1과 Gemini 2.5를 대상으로 환각 현상 유도 방법을 실험하던 중 o3가 출시됨
     * o3는 o1과 달리 인터넷 검색, 이미지 인식, 코드 실행 같은 기능을 갖춘 강력한 멀티 모달 모델임. 그러나 사람이라면 하지 않았을 법한 거짓 답변을 하는 것을 발견함
     * 핵심 가설: LLM은 인간과 달리 감각 기관이 없다. 따라서 시각이나 방향 감각등의 정보가 필요한 질문에 약할 것이다.
     * 환각 유도 질문들
          + 고흐의 '감자 먹는 사람들' 묘사하기
               o 인물 구성 자체를 틀린 o1보다는 낫지만 구체적인 묘사에서 여전히 틀림
          + 모차르트 피아노 소나타 K545의 선율 계이름 말하기
               o 인터넷 검색 기능을 통해 원본 이미지를 찾았는데도 제대로 답변하지 못함
               o 시각 모듈이 악보는 인식하지 못하는 것으로 보임
          + 도보 길찾기 결과
               o 네이버 지도가 검색 결과가 포함되어 있었는데도 잘못 답변함
          + 한영 키보드 전환 문제 (예: cotwlvlxl -> 챗지피티)
               o 입력의 크기가 작을 땐 잘 답변하다가, 크기가 커지니 허위 답변 생성
               o 마치 문제를 풀다가 ""에라 모르겠다"" 라고 말하며 뛰쳐나가는 것으로 보임
               o 전통적인 알고리즘에는 '에라 모먼트'가 없음. 그냥 오랜 시간 실행되다가 timeout 될 것임
     * 결론
          + 진정한 의미의 감각기관이 없는 것은 아직도 LLM의 유효한 약점임
          + 문제를 풀지 못하는 것은 결함이 아님. 진짜 결함은 거짓 답변을 지어내는 것.
          + 개발사가 추론 능력을 강화하고 새로운 기능에 주력하는 대신, 모르면 모른다고 말할 수 있는 메타인지를 심어줬으면 함
"
"https://news.hada.io/topic?id=20503","ClickHouse가 더 게을러지고 더 빨라집니다 - 지연 로딩 최적화 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ClickHouse가 더 게을러지고 더 빨라집니다 - 지연 로딩 최적화 도입

     * ClickHouse가 새로운 최적화 기법인 lazy materialization을 도입하여 Top N 쿼리 성능을 최대 1,500배까지 향상시킴
     * 필요할 때만 컬럼 데이터를 읽는 전략을 통해 디스크 I/O를 최소화함
     * 기존의 컬럼 스토리지, 인덱스, PREWHERE 기법과 함께 계층적 I/O 최적화 스택을 구성
     * 쿼리 실행 계획에 따라 컬럼 데이터를 지연 로딩하여, 특히 LIMIT 절이 있는 쿼리에서 큰 효과를 발휘함
     * 기본 설정으로 활성화됨으로써, 코드 변경 없이 성능 향상을 얻을 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

ClickHouse의 지연된 최적화 전략: Lazy Materialization

  핵심 개념

     * ClickHouse는 불필요한 데이터를 읽지 않음으로써 성능을 극대화함
     * lazy materialization은 쿼리 실행 중 실제로 필요한 시점에만 컬럼 데이터를 로딩하는 방식
     * 기존의 I/O 최적화 기법들과 독립적으로 작동하면서 상호 보완적인 성능 향상을 제공함

  기존 I/O 최적화 기술

     * 컬럼 기반 저장소: 필요한 컬럼만 읽음
     * Sparse Index / Skipping Index / Projections: 필터링된 조건에 맞는 granule만 읽음
     * PREWHERE: 비인덱스 컬럼을 조기 필터링
     * Query Condition Cache: 반복 쿼리의 결과를 캐시해 동일 granule 재처리를 피함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Lazy Materialization의 원리

     * 기존 기술이 필터링을 통한 I/O 감소에 집중했다면, lazy materialization은 연산 시점까지 읽기를 연기함
     * 쿼리의 다음 단계가 필요한 컬럼만 즉시 읽고, 나머지는 LIMIT 이후에 필요할 때 읽음
     * 특히 Top N 쿼리에서 일부 컬럼만 조회되므로, 대용량 텍스트 컬럼 등을 거의 읽지 않음

     컬럼 독립 저장 방식이기 때문에 가능한 최적화이며, row-based DB에선 불가능한 접근
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

실제 예시: Amazon 리뷰 데이터셋

     * 150M rows, 70GB 비압축, 30GB 압축
     * Top N 쿼리 예시:
SELECT helpful_votes
FROM amazon.amazon_reviews
ORDER BY helpful_votes DESC
LIMIT 3;

          + 실행 시간: 0.07초
          + 컬럼 단독 조회로 고속 처리
     * 대용량 텍스트 컬럼 조회 예시:
SELECT review_body
FROM amazon.amazon_reviews
FORMAT Null;

          + 실행 시간: 176초
          + 단일 컬럼이지만 56GB로 디스크 I/O 병목 발생
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

최적화 계층 적용별 성능 비교

    1. 최적화 없음 (Baseline)

     * 실행 시간: 219초
     * 처리량: 72GB, 150M rows
     * 모든 컬럼을 모두 읽고 정렬

    2. Primary Key Index 적용

     * 실행 시간: 96초
     * 처리량: 28GB, 53M rows
     * PK 기반 granule 필터링으로 50% 이상 시간 절감

    3. PREWHERE 추가

     * 실행 시간: 61초
     * 처리량: 16GB
     * 비인덱스 필터 조건도 적용하여 추가 I/O 감소

    4. Lazy Materialization 활성화

     * 실행 시간: 0.18초
     * 처리량: 807MB
     * 최종적으로 필요한 3개 row만 큰 컬럼에서 로딩

     총 1,200배 이상 성능 향상, 150배 이상 메모리 사용 감소
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

필터 없는 Top N 쿼리에도 유효

     * 필터 없는 전체 정렬 쿼리에서:
SELECT helpful_votes, product_title, review_headline, review_body
FROM amazon.amazon_reviews
ORDER BY helpful_votes DESC
LIMIT 3;

     * lazy materialization 전: 219초
     * lazy materialization 후: 0.139초
     * 1,576배 속도 향상, 40배 I/O 감소, 300배 메모리 사용 감소
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

실행 계획 확인

EXPLAIN actions = 1
SELECT helpful_votes, product_title, review_headline, review_body
FROM amazon.amazon_reviews
ORDER BY helpful_votes DESC
LIMIT 3
SETTINGS query_plan_optimize_lazy_materialization = true;

     * 결과:

Lazily read columns: review_headline, review_body, product_title
  Limit
    Sorting
      ReadFromMergeTree

     * 정렬과 LIMIT 후에만 대용량 컬럼을 로딩
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

결론

     * ClickHouse의 I/O 최적화 스택 완성: Index → PREWHERE → Lazy Materialization
     * 코드 변경 없이, 쿼리 실행 방식만으로 성능 수백~수천 배 향상
     * 특히 Top N 패턴, 대용량 컬럼, LIMIT 쿼리에 이상적
     * 기본 설정으로 활성화되어 사용자가 따로 설정하지 않아도 자동 적용

     같은 SQL, 같은 머신, 다른 결과
     빠름 = 덜 읽음 = ClickHouse

     ClickHouse와 StarRocks를 비교한 사람이 있는지 궁금함, 몇 달 전 StarRocks의 조인 성능이 더 나아 보였음
     https://d2.naver.com/helloworld/1168674

        Hacker News 의견

     * 이 최적화는 대규모 데이터 세트에서 무작위 샘플을 추출할 때 특히 원하는 열에 큰 값이 포함될 수 있는 경우 극적인 속도 향상을 제공할 것임
          + 기본 SQL 레시피는 LIMIT 절을 사용하여 샘플에 포함될 행을 결정함
          + 새로운 최적화는 LIMIT 절이 데이터 세트를 소수의 행으로 필터링할 때까지 큰 열을 읽는 것을 연기할 것을 약속함
          + ClickHouse에서 이 최적화가 이러한 쿼리의 속도를 높이는지 확인할 수 있는 사람이 있는지 궁금함
     * ClickHouse를 정말 좋아함
          + 최근에 발견했는데, 분석을 위한 비효율적인 솔루션에 비해 신선한 공기 같은 느낌임
          + 매우 빠르고 CLI도 사용하기 즐거움
     * 스크롤할 수 없는 웹사이트는 이해할 수 없음
          + 조금 스크롤하면 위로 튀어 올라가 사용이 불가능함
     * 늦은 물질화, 19년 후
          + 관련 링크 제공
     * 새로운 물질화 옵션과 관련이 없지만, 이 부분이 눈에 띔
          + 쿼리가 150백만 개의 값을 정렬하고 상위 3개를 반환하는데 70밀리초가 걸림
          + 현대 하드웨어와 소프트웨어에 대한 느린 쿼리에 대한 정신 모델을 업데이트해야 함
          + 150백만 개의 정수를 70밀리초 안에 정렬하는 것이 놀랍지 않음
          + 피크 메모리 사용량이 3.59 MiB임
          + 매우 훌륭한 기사임, 명확하게 설명되어 있고 좋은 다이어그램이 포함되어 있음
     * ClickHouse가 WSL이나 Linux 가상 머신이 필요 없는 Windows 네이티브 릴리스가 있었다면 DuckDB보다 더 인기가 있었을 것임
          + MySQL이 PostgreSQL보다 더 인기가 있었던 이유 중 하나는 MySQL이 Windows 설치 프로그램을 가지고 있었기 때문임
     * 공항 드라마에도 불구하고 해변 휴가를 계획 중임
          + 기술 정보와 다이어그램이 최고 수준이었지만, 이야기가 포함되어 있어 더욱 좋았음
     * ClickHouse는 현대 엔지니어링의 걸작임
          + 성능에 절대적인 주의를 기울임
     * ClickHouse와 StarRocks를 비교한 사람이 있는지 궁금함
          + 몇 달 전 StarRocks의 조인 성능이 더 나아 보였음
     * 이러한 데이터베이스가 모든 행 기반 데이터베이스가 잘못된 것을 보여주는 것이 놀라움
          + btree 인덱스 구조로 이러한 속도에 접근할 수 없음
          + 현대 기계가 얼마나 빠른지 보는 것이 놀라움
          + 데이터 세트를 제대로 압축하지 않았을 것 같음
          + 데이터 읽기가 압축 해제보다 느림
          + Cloudflare 기사를 상기시킴, 암호화가 무료라는 아이디어가 있었음
          + 컴퓨팅 엔진(chdb)을 사용하는 것이 놀라움
"
"https://news.hada.io/topic?id=20490","Sapphire: macOS용 Rust 기반 패키지 관리자 (Homebrew 대체)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Sapphire: macOS용 Rust 기반 패키지 관리자 (Homebrew 대체)

     * Sapphire는 Rust로 개발된 차세대 패키지 관리자임
     * Homebrew에서 영감을 받아 Formulae와 Casks를 설치 및 관리함
     * 현재 ARM 아키텍처만 지원하며, x86 지원은 추후 추가될 가능성이 있음
     * 프로젝트는 sapphire-core와 sapphire-cli로 구성되어 있음
     * Sapphire는 BSD-3-Clause 라이선스를 따름
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

경고

     * Sapphire는 실험적이며 활발히 개발 중인 소프트웨어로, 불안정할 수 있음
     * brew로 설치한 cask를 Sapphire로 재설치하면 경로가 약간 다르게 설치되며, 사용자 설정이 자동으로 마이그레이션되지 않음

⚙️ 프로젝트 구조

     * sapphire-core: 핵심 라이브러리로, 패키지 가져오기, 의존성 해결, 아카이브 추출, 아티팩트 처리 등을 담당함
     * sapphire-cli: 명령줄 인터페이스로, sapphire 실행 파일이 핵심 라이브러리를 감쌈

🚀 로드맵

    1. 업그레이드 명령어로 설치된 패키지 업데이트
    2. 오래된 다운로드, 버전, 캐시 정리
    3. 빠른 재설치를 위한 Reinstall 명령어
    4. /opt/sapphire를 독립 레이아웃으로 지원하는 Prefix isolation
    5. 환경을 부트스트랩하는 sapphire init 도우미
    6. 지속적인 버그 수정 및 안정성 개선

📦 사용법

     * 도움말 출력: sapphire --help
     * 메타데이터 업데이트: sapphire update
     * 패키지 검색: sapphire search
     * 패키지 정보 얻기: sapphire info
     * Bottle 또는 Cask 설치: sapphire install
     * 소스에서 Formula 빌드 및 설치: sapphire install --build-from-source
     * 제거: sapphire uninstall
     * (곧 제공 예정) sapphire upgrade [--all] , sapphire cleanup, sapphire init

🏗️ 소스에서 빌드

   필수 조건: 안정적인 Rust 도구 체인
     * git clone
     * cd sapphire
     * cargo build --release
     * sapphire 바이너리는 target/release/sapphire에 위치하며, 이를 PATH에 추가

        Hacker News 의견

     * 자신이 만든 프로젝트가 Homebrew보다 나은 점은 많지 않지만, 상대 경로 설정과 같은 몇 가지 문제를 해결 중임
          + Rust를 제외한 대부분의 병(bottle) 설치는 잘 작동함
          + 소스에서 빌드하는 공식은 JSON API의 정보 부족으로 인해 어려움이 있음
          + .rb 스크립트를 더 일반적인 기계 판독 형식으로 변환할 계획임
          + .dmg에서 .app으로의 변환과 .pkg 설치 프로그램은 테스트를 통해 잘 작동함
          + 현대 ARM Mac에서 대부분의 공식이 병으로 제공되므로 완전한 패키지 관리자가 될 수 있음
          + Ansible이 한 대의 기계에 과도하다고 느껴서 mac을 위한 선언적 패키지 및 시스템 관리자를 개발 중임
          + Brew 명령어를 감싸는 것이 너무 느려서 새로운 프로젝트를 시작하게 되었음
          + 버그 보고, 이슈 및 건설적인 풀 리퀘스트에 감사함
     * Homebrew의 두 가지 핵심 부분에 대해 설명함
          + 클라이언트 측은 대부분의 사용자가 병 설치와 지원 플랫폼을 사용하며, 소규모 네이티브 코드 설치 프로그램으로 쉽게 지원 가능함
          + 개발자, 저장소, CI/CD 기계는 Homebrew의 복잡한 인프라를 구성하며, 이는 공식 DSL과 깊이 연결되어 있음
          + Homebrew는 클라이언트 측을 복잡한 인프라로부터 잘 격리하고 있음
          + 병과 DMG의 병렬 다운로드는 Homebrew의 아키텍처 제한이 아니라 서비스에 대한 예의를 위해 선택한 것임
     * 프로젝트가 재미있고 잘 만들어졌다고 평가함
          + Homebrew의 용어를 유지하는 것에 대해 비판적임
          + 패키지와 저장소 같은 표준 용어를 사용하는 것이 더 나을 것이라고 제안함
     * Homebrew와의 동등성을 목표로 하는 것에 의문을 제기함
          + 버전 고정 기능과 같은 추가 기능을 제안함
     * MacPorts 사용자였지만 Homebrew로 전환한 이유를 설명함
          + 새로운 패키지 관리자를 만드는 것이 더 나은 설정을 만들지는 않을 것이라고 생각함
     * README에 목표, 동기, 이유를 추가할 것을 제안함
          + Homebrew의 문제점을 해결하려는 이유를 명확히 할 필요가 있음
     * Homebrew의 개선 가능성을 인정하며, 새로운 시도를 환영함
          + Homebrew의 개발자와 패키저의 의도와 사고방식에 불만을 표함
     * 프로젝트 이름을 더 짧게 변경할 것을 제안함
          + 짧은 이름이 더 기억에 남고 가벼운 느낌을 줄 수 있음
     * 소프트웨어를 새로 작성하는 것은 효과적이지 않다고 주장함
          + Homebrew의 구성 요소를 점진적으로 교체하는 것이 더 나을 것이라고 제안함
          + Homebrew라는 이름이 해커 그룹에서 문화적으로 중요하다고 설명함
"
"https://news.hada.io/topic?id=20430","Claude Code: 에이전트 코딩을 위한 모범 사례","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Claude Code: 에이전트 코딩을 위한 모범 사례

     * Claude Code는 CLI 기반의 에이전틱 코딩 도구로, 다양한 개발 환경과 언어에 유연하게 적용 가능함
     * CLAUDE.md 설정, 도구 허용 목록 관리, 사용자 정의 명령어 생성을 통해 Claude 사용성을 극대화할 수 있음
     * 워크플로우별 전략(탐색-계획-구현-커밋, 테스트 기반 개발, 시각적 반복 등)을 적용하면 효과적임
     * 헤드리스 모드와 멀티 Claude 구성으로 자동화와 병렬작업도 가능함
     * Claude를 Git, GitHub, Jupyter 등 다양한 개발 도구와 통합하여 고급 활용이 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Claude Code 개요

     * Claude Code는 에이전틱 코딩(command line 기반 자동화 코딩) 을 위한 도구임
     * Anthropic의 내부 개발자와 연구자들이 Claude를 보다 자연스럽게 코딩에 통합할 수 있도록 설계됨
     * 로우레벨 인터페이스와 비의존적 설계 덕분에 특정 개발 방식에 얽매이지 않으며,
          + 개발자는 자신에게 맞는 방식으로 Claude를 구성하고 활용 가능함
     * 결과적으로 매우 강력하면서도 유연하고 안전한 코딩 파워 도구로 자리매김함
     * 단점으로는 초기 사용자에게는 높은 학습 곡선이 존재하며,
          + 이로 인해 자체적인 베스트 프랙티스를 만들어가는 과정이 필요함
     * 이 글은 Claude Code를 실제로 사용해본 내부 팀과 외부 엔지니어들의 경험을 바탕으로,
          + 여러 언어, 코드베이스, 환경에서 효과적인 일반적인 패턴을 소개함
     * 제시된 내용은 정답이 아닌 출발점으로, 각자에게 맞는 방식으로 실험하고 개선하는 것을 권장함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 1. 설정 커스터마이징

   Claude Code는 자동으로 문맥을 수집하여 프롬프트를 구성하는 에이전틱 코딩 도우미임
   이 문맥 수집은 시간과 토큰을 소모하지만, 환경을 조정하여 최적화할 수 있음

  a. CLAUDE.md 파일 생성

   CLAUDE.md는 Claude가 대화를 시작할 때 자동으로 문맥에 포함시키는 특수 파일임
   이 파일은 다음 항목을 문서화하는 데 이상적임:
     * 자주 사용하는 bash 명령어
     * 핵심 파일 및 유틸리티 함수
     * 코드 스타일 가이드라인
     * 테스트 실행 방법
     * 저장소 작업 방식 (예: 브랜치 네이밍, merge vs. rebase)
     * 개발 환경 설정법 (예: pyenv 사용 여부, 호환되는 컴파일러)
     * 해당 프로젝트의 예외 동작이나 경고 사항
     * Claude가 기억해야 할 기타 정보

   CLAUDE.md 파일은 형식에 제한이 없으며, 간결하고 사람이 읽기 쉬운 형태로 작성할 것을 권장함
   예시:
# Bash commands
- npm run build: Build the project
- npm run typecheck: Run the typechecker

# Code style
- Use ES modules (import/export) syntax, not CommonJS (require)
- Destructure imports when possible (eg. import { foo } from 'bar')

# Workflow
- Be sure to typecheck when you’re done making a series of code changes
- Prefer running single tests, and not the whole test suite, for performance

    CLAUDE.md 파일 위치

   Claude는 다음 위치에서 CLAUDE.md를 탐색하여 문맥에 포함함:
     * 레포 루트 또는 claude를 실행한 디렉토리
          + CLAUDE.md로 저장하여 git에 체크인하면 세션 간 및 팀 간 공유 가능 (권장)
          + 개인 설정용으로는 CLAUDE.local.md로 저장 후 .gitignore 처리 가능
     * 실행 디렉토리의 상위 디렉토리
          + 모노레포 구조에서 유용 (예: root/CLAUDE.md와 root/foo/CLAUDE.md 둘 다 사용 가능)
     * 실행 디렉토리의 하위 디렉토리
          + 해당 디렉토리 내 파일을 작업할 때 자동으로 문맥에 포함
     * 홈 디렉토리(~/.claude/CLAUDE.md)
          + 모든 세션에 글로벌 적용

   /init 명령어 실행 시 Claude가 CLAUDE.md 파일을 자동 생성해줌

  b. CLAUDE.md 파일 튜닝

   CLAUDE.md는 Claude 프롬프트의 일부로 사용되므로, 프롬프트처럼 반복적으로 다듬고 최적화해야 함
   흔한 실수는 내용을 너무 많이 넣고 효과를 검증하지 않는 것임
     * 어떤 내용이 모델의 응답 성능을 높이는지 실험을 통해 파악하는 것이 중요함
     * 수동으로 내용을 추가할 수도 있고, # 키를 눌러 Claude에게 지시하여 자동으로 CLAUDE.md에 반영하도록 할 수도 있음
     * 많은 엔지니어가 실시간으로 명령어, 스타일 가이드 등을 문서화하며, CLAUDE.md의 변경 사항을 커밋에 포함하여 팀과 공유함

   Anthropic에서는 프롬프트 개선기(prompt improver) 를 통해 CLAUDE.md를 정제하고
   “IMPORTANT”, “YOU MUST”와 같은 강조 문구를 추가하여 응답 정확도를 높임

  c. Claude의 허용 도구 리스트 관리

   Claude Code는 시스템을 변경할 수 있는 작업(파일 쓰기, bash 명령어 실행, MCP 도구 사용 등)에 대해 기본적으로 사용자 승인 요청을 함
   이는 보안을 위한 보수적 설계이며, 사용자가 안전하다고 판단되는 도구는 허용 목록(allowlist) 을 통해 사전 승인 가능함

    허용 도구 설정 방법

    1. 세션 중 프롬프트가 떴을 때 ""Always allow"" 선택
    2. /allowed-tools 명령어로 도구 추가/삭제
       예시:
          + Edit → 파일 편집 허용
          + Bash(git commit:*) → git 커밋 허용
          + mcp__puppeteer__puppeteer_navigate → Puppeteer MCP 서버 내비게이션 허용
    3. .claude/settings.json 또는 ~/.claude.json을 수동으로 편집
          + 팀과 공유하려면 전자를 사용해 Git에 체크인 추천
    4. 세션별 CLI 플래그인 --allowedTools 사용

  d. GitHub 사용 시 gh CLI 설치

   Claude는 gh CLI를 사용할 수 있어, 이슈 생성, PR 작성, 코멘트 읽기 등 GitHub 작업을 자동화함
   gh를 설치하지 않아도 GitHub API 또는 MCP 서버를 통해 대체 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 2. Claude에게 더 많은 도구 제공하기

   Claude는 사용자의 쉘 환경에 접근 가능하므로, 사용자가 직접 만든 스크립트와 함수들을 그대로 사용할 수 있음
   또한 MCP나 REST API를 통해 보다 복잡한 외부 도구들과도 연동 가능

  a. Bash 도구와 함께 사용

   Claude Code는 사용자의 bash 환경을 상속받아 이미 설치된 유틸리티 도구들에 접근 가능함
     * 일반적인 유닉스 도구나 gh CLI는 Claude가 이미 알고 있음
     * 하지만 사용자가 만든 커스텀 bash 도구는 별도로 알려줘야 함

   Claude가 커스텀 도구를 인식하려면 다음 작업을 수행:
     * 도구 이름과 사용 예시를 Claude에게 명시
     * --help 옵션으로 도구 사용법을 보도록 지시
     * 자주 사용하는 도구들을 CLAUDE.md에 문서화

  b. MCP와 함께 사용

   Claude Code는 MCP 서버이자 클라이언트 역할을 동시에 수행함
   클라이언트로서 여러 MCP 서버에 연결해 다양한 도구를 활용할 수 있음

   세 가지 방식으로 MCP 서버 도구를 Claude에 연결 가능:
     * 프로젝트 설정 내 정의 (해당 디렉토리에서만 사용 가능)
     * 글로벌 설정을 통해 모든 프로젝트에서 사용 가능
     * .mcp.json 파일에 체크인하여 협업 중인 모든 개발자가 도구를 즉시 사용 가능
          + 예: .mcp.json에 Puppeteer, Sentry 서버 등록 시 팀 전체 사용 가능

   MCP 사용 중 설정 문제를 디버깅하려면 --mcp-debug 플래그로 Claude를 실행하는 것이 유용함

  c. 사용자 정의 슬래시 명령어

   반복되는 워크플로우(디버깅, 로그 분석 등)를 위해
   .claude/commands 폴더에 프롬프트 템플릿을 Markdown 파일로 저장 가능
     * Claude에서 / 입력 시 자동 완성 메뉴에 해당 명령어가 표시됨
     * git에 커밋하여 팀원들과 공유 가능

    매개변수 전달: $ARGUMENTS

   슬래시 명령어에 $ARGUMENTS를 포함하면 명령어 실행 시 전달된 파라미터를 자동 삽입 가능

   예시: GitHub 이슈 자동 분석 및 수정
Please analyze and fix the GitHub issue: $ARGUMENTS.

Follow these steps:

1. Use `gh issue view` to get the issue details
2. Understand the problem described in the issue
3. Search the codebase for relevant files
4. Implement the necessary changes to fix the issue
5. Write and run tests to verify the fix
6. Ensure code passes linting and type checking
7. Create a descriptive commit message
8. Push and create a PR

Remember to use the GitHub CLI (`gh`) for all GitHub-related tasks.

   위 내용을 .claude/commands/fix-github-issue.md에 저장하면, /project:fix-github-issue 명령어로 사용할 수 있음
   예: /project:fix-github-issue 1234 → Claude가 #1234 이슈 자동 수정 시도

   개인 설정 명령어는 ~/.claude/commands 폴더에 저장하면 모든 세션에서 사용 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 3. 일반적인 워크플로우 활용하기

   Claude Code는 특정 워크플로우를 강제하지 않으며, 사용자에게 완전한 유연성을 제공함
   이러한 유연성을 기반으로, 사용자 커뮤니티에서 성공적으로 자리 잡은 다양한 사용 패턴이 있음

  a. 탐색 → 계획 → 구현 → 커밋

     * Claude에게 관련 파일, 이미지, URL을 읽어보도록 요청
          + 예: “로그 처리하는 파일 읽어줘”, “logging.py 읽어줘”
          + 단, 코딩은 하지 말라고 명확히 지시
          + 이 단계에서 서브에이전트(subagents) 활용이 매우 효과적임 (복잡한 문제일수록 더욱 유리)
     * Claude에게 문제 해결을 위한 계획 수립 요청
          + “think”, “think hard”, “ultrathink” 등의 키워드 사용 시 더 많은 연산 예산을 할당받음
          + 계획이 타당하면 계획 내용을 문서로 정리하거나 GitHub 이슈로 생성해 되돌아갈 기준점 확보
     * 이후 Claude에게 계획한 방식으로 코드 구현 요청
          + 구현 중에도 스스로 결과의 타당성을 검증하도록 명시적으로 요청 가능
     * 마지막으로 결과 커밋 및 PR 생성 지시
          + 필요 시 README나 CHANGELOG 업데이트 요청도 함께 수행

   📌 이 흐름에서 1~2단계를 생략하면 Claude가 곧바로 코딩에 들어가므로, 특히 복잡한 문제일수록 계획 단계가 중요함

  b. 테스트 작성 → 커밋 → 코드 작성 → 반복 → 커밋 (테스트 주도 개발)

   Anthropic 내부에서 자주 사용하는 방식으로, 단위/통합/e2e 테스트가 있는 작업에 적합함
     * Claude에게 입력/출력 기준으로 테스트 작성 요청
          + 테스트 주도 개발임을 명확히 전달 → 기능 구현 없이 테스트만 작성하도록 유도
     * 테스트가 실패하는지 확인 요청
          + 구현은 하지 말고 테스트만 실행하도록 지시
     * 테스트에 만족하면 커밋
     * Claude에게 테스트를 통과하는 코드 작성 요청
          + 테스트는 수정하지 말라고 명시
          + 보통 여러 차례 반복 실행을 거쳐 테스트를 통과하게 됨
          + 서브에이전트를 사용해 과적합 여부를 검증하는 것도 효과적
     * 모든 테스트가 통과되면 코드 커밋 지시

   ✅ Claude는 **명확한 타겟(예: 테스트 케이스, 이미지 등)**이 있을 때 가장 잘 작동함

  c. 코드 작성 → 결과 스크린샷 제공 → 반복 개선

     * 브라우저 스크린샷을 자동으로 제공할 수 있는 환경 구축 (예: Puppeteer MCP, iOS 시뮬레이터 등)
     * 시각적 목업(mock) 제공 (이미지 붙여넣기, 경로 전달 등)
     * Claude에게 디자인 구현 요청 → 결과 스크린샷 → 다시 비교 및 개선 지시
     * 만족할 경우 커밋

   💡 Claude도 사람처럼 2~3번 반복 시 결과가 훨씬 좋아짐 → 시각 피드백 루프가 중요

  d. Safe YOLO 모드

     * --dangerously-skip-permissions 옵션으로 모든 승인 요청 생략
     * Claude가 사용자 승인 없이 완전 자동으로 작업을 수행함

   ⚠️ 데이터 손실, 시스템 손상, 프롬프트 인젝션 위험 존재 → 인터넷 차단된 컨테이너에서만 실행 권장
   → 예시 구현은 Docker Dev Container 기반 사용을 추천

  e. 코드베이스 Q&A

     * 새로운 프로젝트에 적응할 때 동료 엔지니어에게 물어보듯 Claude에게 질문 가능
     * Claude는 코드베이스를 탐색해 스스로 답을 찾음

   예시 질문:
     * 로깅은 어떻게 작동해?
     * 새 API 엔드포인트는 어떻게 만들지?
     * foo.rs의 134번 줄 async move는 무슨 역할이야?
     * CustomerOnboardingFlowImpl은 어떤 엣지 케이스를 다루지?
     * 왜 foo() 대신 bar()를 호출해?
     * baz.py 334번 줄과 비슷한 자바 코드는 뭐야?

   📌 별도 프롬프트 없이 자연어 질문만으로 탐색 가능
   → Anthropic에서는 이 방식을 주요 온보딩 도구로 활용 중

  f. Git 연동

   Claude는 다음과 같은 Git 작업 자동화를 잘 수행함:
     * Git 히스토리 검색:
          + 예: ""v1.2.3에서 어떤 변경사항이 포함됐어?"", ""이 기능 누가 만들었어?"", ""이 API는 왜 이런 구조야?""
     * 커밋 메시지 작성:
          + 변경사항과 주변 컨텍스트를 기반으로 자동 구성
     * 고급 Git 작업:
          + 파일 되돌리기, 리베이스 충돌 해결, 패치 비교 및 병합 등

  g. GitHub 연동

   Claude Code는 GitHub 관련 작업을 대폭 자동화할 수 있음:
     * Pull Request 생성:
          + pr 라는 키워드를 인식하며, 변경 사항 기반으로 자동 커밋 메시지 생성
     * 코드 리뷰 코멘트 수정:
          + ""PR에 달린 코멘트 고쳐줘""만으로 수정 후 푸시 가능
     * 빌드 실패, 린트 에러 수정
     * 이슈 분류 및 정리:
          + Claude에게 “열려있는 이슈들 돌면서 정리해줘”라고 요청

   💡 gh 명령어 기억할 필요 없이 자동화된 GitHub 작업 가능

  h. Jupyter Notebook 작업

     * Claude는 .ipynb 파일을 읽고 쓰며, 이미지 포함 출력 해석까지 가능함
     * VS Code에서 Claude Code와 노트북 파일을 나란히 열어 활용하는 방식 추천

   추가 기능:
     * 다른 사람에게 공유 전 노트북 정리 및 시각적 개선 요청 가능
          + “보기 좋게 정리해줘”, “시각화 예쁘게 바꿔줘” 등 인간 중심 뷰 최적화 요청이 잘 작동함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 4. 워크플로우 최적화

   아래 제안들은 모든 워크플로우에 공통적으로 적용 가능한 최적화 방법임

  a. 지시어는 구체적으로 작성

   Claude Code는 첫 시도일수록 지시가 구체적일수록 성공률이 높아짐
   처음부터 명확하게 요청하면 중간 수정의 필요성이 줄어듦

    예시 비교

     * ❌ add tests for foo.py → 너무 포괄적
       ✅ foo.py에 대해, 로그아웃된 사용자 케이스를 다루는 새로운 테스트 케이스 작성. mock은 사용하지 말 것
     * ❌ why does ExecutionFactory have such a weird api? → 모호함
       ✅ ExecutionFactory의 git 히스토리를 추적해서, API가 현재 구조로 만들어진 이유를 요약해줘
     * ❌ add a calendar widget → 구현 방향 불분명
       ✅ 홈페이지에 있는 기존 위젯 구현 방식을 분석해 (예: HotDogWidget.php) 코드와 인터페이스 분리 패턴을 파악한 뒤, 사용자가 월 선택 및 연도 페이지 전환이 가능한 새 달력 위젯을 동일한 방식으로 구현해줘. 외부 라이브러리는 기존 프로젝트에서 이미 사용하는 것만 허용

   Claude는 의도를 유추할 수는 있지만, 생각을 읽을 수는 없음 → 명확함이 핵심

  b. 이미지 제공

   Claude는 이미지나 다이어그램 처리에 뛰어남
   다음 방법으로 이미지 제공 가능:
     * macOS에서 cmd+ctrl+shift+4 → 클립보드로 스크린샷 → ctrl+v 붙여넣기 (원격 환경에서는 불가)
     * 이미지 파일 드래그 앤 드롭
     * 이미지 파일 경로 전달

   디자인 목업 구현, 시각적 차트 분석 등 UI/데이터 시각화에 매우 유용
   비주얼이 없는 경우에도, 결과의 시각적 품질이 중요한지 명확히 전달하는 것이 도움됨

  c. 작업할 파일 지정

   Claude에게 어떤 파일을 참고하거나 수정할지를 명확히 알려주면 작업 정확도 향상
     * Tab 키 자동완성으로 파일/폴더 경로 빠르게 입력 가능

  d. Claude에게 URL 제공

   Claude에게 URL을 주면 문서나 웹페이지를 직접 읽어올 수 있음
     * 예: API 문서 링크, 디자인 시스템 페이지 등
     * 같은 도메인 반복 접근을 위해선 /allowed-tools 명령어로 도메인을 화이트리스트에 추가하면 승인 생략 가능

  e. 빠르고 자주 방향 수정 (코스 리디렉션)

   Shift + Tab을 눌러 자동 승인 모드(auto-accept mode) 로 작업을 자동화할 수 있으나,
   보통은 Claude와 적극 협업하며 방향을 조정하는 것이 더 나은 결과를 유도함

    유용한 조정 도구 4가지:

    1. 계획 먼저 요청: 구현 전에 반드시 계획을 세우도록 하고, 확인 후 진행
    2. Escape 키로 즉시 중단: 언제든지 생각, 파일 편집 등 도중에 중단 가능
    3. Escape 두 번 눌러 이전 프롬프트 편집: 이전 명령어를 수정하고 새로운 방향으로 전환 가능
    4. 변경사항 되돌리기 요청: Claude에게 수정한 내용을 롤백해 다른 접근 방식 시도 가능

   Claude가 한 번에 완벽하게 해결할 때도 있지만, 위 도구들을 활용하면 더 빠르고 정확한 결과 도출 가능

  f. /clear 명령어로 맥락 초기화

   긴 세션이 지속되면 Claude의 문맥 창(context window) 이 필요 없는 정보로 채워져 성능 저하 가능성 있음
   → 작업 단위마다 /clear로 문맥을 초기화하는 습관 추천

  g. 체크리스트 및 스크래치패드 활용

   복잡한 작업(예: 코드 마이그레이션, 린트 오류 대량 수정 등)의 경우,
   Markdown 파일이나 GitHub 이슈를 체크리스트로 사용하면 효율 향상

   예: 린트 오류 해결
     * Claude에게 lint 명령어 실행 요청 → 에러 내용을 Markdown 형식 체크리스트로 정리
     * 각 항목을 하나씩 처리하며 확인 후 체크 → 다음 항목으로 진행

   이 방식을 통해 진행 상황 추적과 품질 관리 동시 수행 가능

  h. Claude에게 데이터 전달하기

   Claude에 데이터를 전달하는 여러 방법 존재:
     * 복사/붙여넣기 (가장 일반적인 방법)
     * 파이프 입력 (예: cat foo.txt | claude)
          + 로그, CSV, 대용량 텍스트에 적합
     * bash 명령어나 MCP 도구, 슬래시 명령어를 통해 직접 가져오게 지시
     * 파일 또는 URL 읽기 요청 (이미지 포함)

   실제 작업에서는 여러 방식의 혼합 사용이 일반적
   예: 로그를 파이프로 전달하고, Claude에게 MCP 도구를 사용해 추가 맥락을 가져오도록 요청
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 5. 헤드리스 모드로 인프라 자동화하기

   Claude Code는 비인터랙티브 환경(CI, pre-commit 훅, 빌드 스크립트, 자동화 등)을 위한 헤드리스 모드를 지원함
     * -p 플래그를 통해 프롬프트와 함께 헤드리스 모드 실행
     * --output-format stream-json 옵션으로 스트리밍 JSON 출력 사용 가능

   ⚠️ 헤드리스 모드는 세션 간 지속되지 않으며, 매번 직접 실행해야 함

  a. Claude로 이슈 자동 분류

   헤드리스 모드는 GitHub 이벤트 기반 자동화 트리거에 적합함
   예: 새로운 이슈가 생성될 때 자동 분석 및 라벨 분류
     * 실제로 Claude Code의 공개 저장소에서도 이 기능을 사용해 새 이슈에 자동으로 라벨을 붙이는 기능 구현

  b. Claude를 린터로 사용

   Claude는 전통적인 린트 도구로는 감지하기 어려운 주관적 코드 리뷰를 자동화할 수 있음
   예:
     * 오탈자
     * 오래된 주석
     * 오해의 소지가 있는 함수/변수명
     * 비직관적인 코드 흐름 등

   이를 통해 정적 분석 도구 이상의 코드 품질 개선이 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 6. 멀티 Claude 워크플로우로 레벨업하기

   단일 Claude 사용을 넘어서, 여러 Claude 인스턴스를 병렬로 실행하는 방식은 매우 강력한 활용법임
   여러 엔지니어가 협업하듯, Claude를 분업시키는 전략은 효율성과 품질을 모두 향상시킬 수 있음

  a. 한 Claude가 코드 작성, 다른 Claude가 검토

   가장 간단하면서도 효과적인 패턴:
     * Claude 1: 코드 작성
     * /clear 또는 다른 터미널에서 Claude 2 실행 → 작성된 코드 리뷰
     * Claude 3 실행 또는 다시 /clear → 코드와 리뷰를 모두 읽고 수정 반영

   또는,
     * Claude 1: 테스트 작성
     * Claude 2: 테스트를 통과하는 코드 작성

   ❗ Claude 인스턴스끼리 서로 별도의 scratchpad를 공유하거나
   “이 Claude는 A 파일에만 기록, 저 Claude는 B만 읽기” 식으로 역할 분리 설정도 가능

   📌 단일 Claude보다 작업 분리가 더 나은 결과를 제공하는 경우가 많음

  b. 저장소를 여러 개 체크아웃하기

   Claude가 작업을 완료하길 기다리는 대신, 여러 Git 체크아웃 디렉토리를 생성하여 병렬 작업 가능
     * 3~4개의 git checkout을 별도 폴더에 생성
     * 각 폴더를 다른 터미널 탭에서 열기
     * 각 Claude 인스턴스에 서로 다른 작업 할당
     * 탭을 전환하며 진행 상황 확인 및 승인/거절 수행

  c. Git worktree 활용

   git worktree는 여러 브랜치를 하나의 레포에서 서로 다른 디렉토리에 체크아웃하는 Git 기능임
   → 복수의 독립 작업을 병렬로 처리하기에 이상적

   예:
     * 하나의 Claude가 인증 시스템을 리팩토링
     * 다른 Claude는 별개로 데이터 시각화 컴포넌트 생성
     * 서로 간섭 없음 → 병렬성 극대화

    사용법

    1. 워크트리 생성:
       git worktree add ../project-feature-a feature-a
    2. Claude 실행:
       cd ../project-feature-a && claude
    3. 필요한 만큼 반복

    팁

     * 워크트리 이름은 일관성 있게
     * 터미널 탭 하나당 워크트리 하나 유지
     * iTerm2 (Mac) 사용자라면 알림 설정 추천
     * IDE도 각 워크트리에 맞게 분리
     * 작업 완료 후 정리:
       git worktree remove ../project-feature-a

  d. 헤드리스 모드 + 커스텀 자동화 구조체

   헤드리스 모드(claude -p)는 Claude Code를 프로그래밍 방식으로 워크플로우에 통합 가능하게 함
   여기에 Claude 자체 도구와 시스템 프롬프트를 결합해 다음 두 패턴 활용 가능

    1. Fanning out: 대규모 마이그레이션/분석 작업 분산 처리

   예시:
     * Claude에게 작업 목록 생성 스크립트 작성 요청
       → 예: React에서 Vue로 마이그레이션할 2,000개 파일 리스트 생성
     * 각 작업마다 claude -p로 실행
       → 예:
       claude -p ""migrate foo.py from React to Vue. When done, return OK or FAIL."" --allowedTools Edit Bash(git commit:*)
     * 프롬프트를 여러 번 개선하며 성능 최적화

    2. Pipelining: 데이터/처리 파이프라인 통합

     * Claude의 출력을 다음 명령어로 직접 연결:
       claude -p ""<your prompt>"" --json | your_command
     * Claude의 JSON 출력 구조 덕분에 자동 처리에 용이

    디버깅 팁

     * 테스트 중에는 --verbose 사용으로 Claude 실행 흐름 확인
     * 실제 운영에서는 출력을 깔끔하게 유지하기 위해 verbose 끄기 권장

   비용은 얼마정도 나올까요

        Hacker News 의견

     * ""ultrathink"" 기능이 재미있음
          + ""think""이라는 단어를 사용하여 Claude의 연장된 사고 모드를 활성화할 수 있음
          + Claude Code에만 있는 기능이며, ""megathink"" 옵션도 있음
          + 관련 코드가 제공됨
     * ""비용 제어""에 대한 섹션이 없다는 점이 놀라움
          + 비용을 잘 관리하면 훨씬 저렴해짐
          + 캐시를 인식하고, 특정 파일만 읽도록 지시해야 함
          + 검색을 피하고, 세션 중 파일을 수동으로 편집하지 말아야 함
          + 세션을 짧게 유지하고 명확한 목표를 설정해야 함
          + Claude.ai를 사용하여 필요한 문서화 파일을 생성하고 저장해야 함
          + 대부분의 작업에 대해 약 $0.5-0.75 정도의 비용이 듦
     * Cursor를 많이 사용하면서 모델이 요청하지 않은 코드를 변경하는 경우가 있음
          + 너무 많은 작업을 한 번에 요청할 때 발생함
          + 비용과 관련된 여러 단계가 비싼 API 호출을 필요로 함
          + Anthropic에서 개발자 장학 프로그램을 제안하고 싶음
     * Claude Code를 사용해보았으나 비용 문제로 Gemini AI로 전환함
          + 파일을 업로드하고 자주 리팩토링하여 모듈성을 유지함
          + 문제를 나누어 작업하는 방식이 흥미로움
     * Claude Code를 효과적으로 사용하려면 많은 비용이 듦
          + LLM 기반 도구가 유용하지만, 높은 비용이 문제임
     * Claude Sonnet와 Gemini의 비용 대비 효과에 대한 개인적인 의견
          + Windsurf, VS Code, Firebase Studio를 사용 중이며, Claude Sonnet 3.7이 Gemini 2.5 pro보다 더 나은 성능을 보임
          + Firebase Studio는 간단한 작업에 적합함
     * 여러 개의 체크아웃을 사용하는 것이 흥미로움
          + git worktrees에 대해 처음 알게 되었으며, 여러 체크아웃을 효과적으로 관리할 수 있는 방법임
     * Gemini의 Claude Code와 OpenAI의 Codex에 대한 대안이 궁금함
          + reugn/gemini-cli 프로젝트를 발견했지만, Gemini Code Assist는 VS Code에 제한됨
     * neovim에서 주로 작업하지만, Cursor를 열어 보일러플레이트 코드를 작성함
          + Claude Code나 Codex와 같은 CLI 기반 도구를 사용하고 싶지만, Cursor의 벡터 임베딩 기능이 없음
     * 비용이 두려워서 사용하지 못함
"
"https://news.hada.io/topic?id=20381","12-팩터 에이전트: 신뢰할 수 있는 LLM 애플리케이션 패턴","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   12-팩터 에이전트: 신뢰할 수 있는 LLM 애플리케이션 패턴

     * 12 Factor Agents는 신뢰할 수 있는 LLM 애플리케이션을 구축하기 위한 원칙을 제시함
     * AI 에이전트 프레임워크를 사용해본 경험을 바탕으로, 대부분의 제품이 진정한 에이전트가 아님을 발견함
     * 12 Factor Agents는 LLM 기반 소프트웨어를 고객에게 제공할 수 있을 만큼 충분히 좋은 수준으로 만드는 방법을 탐구함
     * 12가지 요인은 LLM 소프트웨어의 신뢰성, 확장성, 유지보수성을 향상시키는 핵심 기술을 포함함
     * 모듈식 개념을 기존 제품에 통합하는 것이 고품질 AI 소프트웨어를 빠르게 제공하는 방법임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

12 Factor Agents - 신뢰할 수 있는 LLM 애플리케이션 구축 원칙

     * AI 에이전트 프레임워크를 사용해본 경험을 바탕으로, 대부분의 제품이 진정한 에이전트가 아님을 발견함
     * 12 Factor Agents는 LLM 기반 소프트웨어를 고객에게 제공할 수 있을 만큼 충분히 좋은 수준으로 만드는 방법을 탐구함
     * 12가지 요인은 LLM 소프트웨어의 신뢰성, 확장성, 유지보수성을 향상시키는 핵심 기술을 포함함
     * 모듈식 개념을 기존 제품에 통합하는 것이 고품질 AI 소프트웨어를 빠르게 제공하는 방법임

요약: 12가지 요인

     * 자연어를 도구 호출로 변환: 자연어를 사용하여 도구를 호출하는 방법을 이해함
     * 프롬프트 소유: 프롬프트를 소유하고 관리하는 것이 중요함
     * 컨텍스트 윈도우 소유: 컨텍스트 윈도우를 소유하고 관리하는 것이 중요함
     * 도구는 구조화된 출력: 도구는 구조화된 출력으로 간주해야 함
     * 실행 상태와 비즈니스 상태 통합: 실행 상태와 비즈니스 상태를 통합하여 관리함

에이전트의 약속

     * DAG(Directed Acyclic Graph): 소프트웨어는 방향성 그래프로 표현될 수 있으며, DAG 오케스트레이터가 인기를 끌었음
     * 에이전트의 약속: 에이전트를 사용하면 DAG를 버리고 LLM이 실시간으로 경로를 결정하도록 할 수 있음
     * 에이전트는 루프로 작동: 에이전트는 LLM이 다음 단계를 결정하고, 도구 호출을 실행하며, 결과를 컨텍스트 윈도우에 추가하는 루프로 작동함

왜 12-factor agents인가?

     * 기존 프레임워크의 한계: 많은 SaaS 빌더들이 에이전트를 구축하려고 하지만, 기존 프레임워크의 한계로 인해 80% 이상의 품질을 달성하기 어려움
     * 모듈식 개념의 중요성: 모듈식 개념을 기존 제품에 통합하는 것이 고품질 AI 소프트웨어를 빠르게 제공하는 방법임

훌륭한 LLM 애플리케이션을 위한 디자인 패턴

     * 에이전트의 핵심 요소: 에이전트를 훌륭하게 만드는 핵심 요소가 존재하며, 프레임워크를 사용하면 대부분의 요소를 얻을 수 있음
     * 모듈식 개념의 통합: 모듈식 개념을 기존 제품에 통합하는 것이 고품질 AI 소프트웨어를 빠르게 제공하는 방법임

관련 리소스

     * Tool Use 팟캐스트: 2025년 3월 에피소드에서 관련 내용을 다룸
     * The Outer Loop: 관련 내용을 다루는 블로그
     * 웹 세미나: @hellovai와 함께 LLM 성능 극대화에 대한 웹 세미나 진행
     * 오픈 소스 에이전트: 이 방법론을 사용하여 OSS 에이전트를 구축함

        Hacker News 의견

     * 매우 유익한 위키임. 감사하며, 꼭 사용할 것임. 나는 어제 막 출시한 ""AI Agents framework""을 만들었음. 이 프레임워크는 액터 모델, 상태 기계, 그리고 관점 지향 프로그래밍을 기반으로 함. 특히 5번과 7번 포인트가 마음에 듦
          + 실행 상태와 비즈니스 상태를 통합하는 것
          + 자신의 제어 흐름을 소유하는 것
          + SecAI는 이러한 점을 잘 수행하며, 그래프 제어 흐름 라이브러리로서 LLM 호출이 그래프의 노드에 내장되어 있음. 협상, 취소, 상태 관계로 흐름이 강화되어 더 유기적임
          + 다른 프레임워크에서 종종 놓치는 것은 전용 개발 도구임. 실패를 프로그래밍하고, 모든 단계를 세부적으로 검사하며, 자동 데이터 내보내기와 간단한 통합을 제공함
          + 첫 번째 기술 데모를 출시했으며, 모든 개발 도구를 보여주는 참조 구현을 포함함
          + Send/Stop 버튼은 간단한 API로 시작/일시정지/재개를 가능하게 함. 네트워크 투명성을 가지고 있어 확장 가능함
     * 훌륭함. 몇 년 동안 이 작업을 하면서 나만의 교훈 목록을 만들었음. 가장 중요한 것은 가장 낮은 수준의 계획 루프를 소유하는 것임
          + 동적 계획이 있어도 괜찮지만, OODA 루프를 소유하고 해결책으로 수렴하는지 여부를 결정하는 휴리스틱을 가져야 함
          + 워크플로우 엔진을 내장하고, 모델이 그 엔진에서 실행되는 워크플로우 사양을 구축하도록 해야 함
     * 이 시점에 이 자료가 나와서 정말 다행임. 감사함
          + vvvv와 같은 오디오비주얼 샌드박스를 구상 중임. LM 또는 간단한 로컬 신경망 노드를 삽입하여 특정 작업을 수행하도록 하고, 출력이 매우 제한되도록 하는 아이디어임
          + 질문에서 답변으로의 흐름이 매우 매력적임. 다단계 파이프라인도 매우 흥미로움
     * DSPY와 같은 라이브러리가 factor-2에 어떻게 맞는지 궁금함
          + BAML을 사용하여 프롬프트를 생성하는 예시를 봄. 비구조화된 데이터에서 구조화된 정보를 추출하기 위해 프롬프트를 손으로 작성하는 것은 쉽지 않음
          + DSPY의 원시 프롬프트를 사용하는 것에 대해 어떻게 생각하는지 궁금함
     * 오래된 블로그 글이지만 프레임워크 패턴에 대한 내용이 내 경력 내내 공감됨. LLM은 프레임워크보다는 라이브러리로 사용하는 것이 좋음
          + 프레임워크는 더 매력적이고 판매하기 쉬우며, 잠금 효과와 추가 서비스로 이어짐
     * 훌륭함. 80%는 어렵게 배웠고, 나머지 20%는 가치 있는 읽을거리가 될 것임
          + LangGraph와 pydantic 스키마로 성공을 거둠. 다른 사람들이 유용하다고 생각하는 것이 궁금함
     * 또 하나: 확장 시 비용을 계획해야 함
          + 확장 시 비용이 많이 들 수 있으므로, 결정론적 구성 요소로 처리할 수 있는 것은 먼저 시도해야 함. 환각과 지연을 줄이고, 비용 절감에 큰 차이를 만들 수 있음
     * 원칙을 따르기 더 쉬워지려면 일관된 내러티브가 필요함. 실세계 예시를 사용하는 것이 좋음
     * HN 첫 페이지에 올라와서 매우 기쁨
     * BAML이 여기 있는 것을 보니 정말 멋짐. LLM을 함수로 취급하는 것에 100% 동의함
"
"https://news.hada.io/topic?id=20424","Judyrecords - 미국 법원 기록의 Full Text Search","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Judyrecords - 미국 법원 기록의 Full Text Search

     * judyrecords는 7억 4천만 건 이상의 미국 법원 사건을 검색할 수 있는 플랫폼임
     * 사용자는 다양한 검색 팁을 통해 원하는 정보를 쉽게 찾을 수 있음
     * API를 제공하여 개발자들이 데이터를 활용할 수 있는 기능을 지원
     * 이 사이트는 방대한 법원 사건 데이터베이스를 제공하여 법률 전문가와 일반 사용자 모두에게 유용

   Judyrecords - 무료 미국 법원 사건 및 소송 검색 시스템

        Hacker News 의견

     * ""샌드위치 살인""을 검색했지만 원하는 결과를 찾지 못했음. 그러나 검색 결과가 가끔 재미있게 나옴. Subway 매장이 가장 위험한 식당 중 하나라는 것을 알게 되었고, 특히 볼로냐가 사람들을 화나게 해서 총을 쏘게 만들 수 있음
          + 피고인이 샌드위치 중에 살인 무기를 발사했다는 증거
          + 범죄 현장에서 발견된 볼로냐 샌드위치
          + 살인 아침에 샌드위치의 존재
          + 그녀의 어머니를 살해할 수 있는 방법. 여기에는 샌드위치 사건이 포함됨
          + 사형죄. 상습범으로서 종신형을 선고받음. ""볼로냐 샌드위치""가 가역적 오류를 구성함
          + 검시관은 피해자가 사망하기 2시간 전에 생선 샌드위치를 먹었다고 증언함
          + 1급 살인이 아니었으며, 법원은 샌드위치를 고려해야 했음. 그는 샌드위치를 지불했지만 커피는 지불하지 않았음
          + 악의적인 살인과 샌드위치 소지로 유죄 판결을 받음
          + 그녀는 총에 맞았고 한 손에는 잔돈, 다른 손에는 샌드위치가 있었음. 샌드위치를 손에 들고 있으면 총을 꺼내는 속도가 느려짐
     * 이 데이터베이스가 얼마나 완전한지 모르겠음. Alec Baldwin의 과실치사 사건에 대한 기록을 찾을 수 없었음. 아마도 담당 판사가 사건을 기각했기 때문에 데이터베이스에 없을 수도 있음
     * 내 이름을 검색했더니 교통 위반 기록이 나왔지만, 내가 발견 과정에서 제출한 요약과 증언은 나오지 않았음
     * 내 이름을 검색했더니 텍사스에서 범죄 침입으로 기록된 사람이 나왔음. 내가 그곳에 살던 해였고, 키와 체중이 거의 같았으며, 기소 날짜가 내 생일이었음. 내가 아님. 소름 끼침
     * 몇 년 전 큰 Show HN 스레드가 있었음
          + 링크1
          + 링크2
     * ""우리는 둘 다 총을 잡으려고 했다""와 ""그는 그럴 만했다""는 검색 결과가 많이 나옴. ""그리고 모든 재즈""도 포함됨
     * 이 데이터베이스는 어떤 것을 사용하고 있으며 검색이 어떻게 이렇게 효율적인지 궁금함
     * 이전에 이 작업을 했던 사람이 문제가 되지 않았는지 궁금함
     * 내 이름이 여러 번 나옴. 모두 내가 쓴 것을 인용한 특허임. 이게 무슨 의미인지 궁금함. 아, 특허 신청자가 인용한 기사임. 내가 2010년대에 Microsoft 특허 여러 개에 영감을 준 줄 몰랐음 :D
     * 특허 기록도 포함되어 있음. 여기 내 것 중 하나가 있음
          + 링크
"
"https://news.hada.io/topic?id=20450","XPipe - 로컬 머신에서 전체 서버 인프라 접근하는 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   XPipe - 로컬 머신에서 전체 서버 인프라 접근하는 도구

     * 로컬 데스크탑에서 다양한 서버 인프라에 쉽게 접근할 수 있도록 해주는 모던한 셸 연결 허브이자 원격 파일 관리자
     * 기존 ssh, docker, kubectl 등과 같은 CLI 도구 위에서 작동하며, 원격 시스템에 별도의 설정 없이 바로 사용
     * 데스크탑 애플리케이션 형태로 제공되며, 강력한 파일 관리, 셸 실행, 스크립트 자동화, 보안 저장소 기능 등을 통합 제공

핵심 기능

     * 연결 허브 기능
          + SSH, Docker, Kubernetes, 가상 머신, RDP, VNC, Teleport, Tailscale 등 다양한 연결 방식을 통합 관리
          + 수백 개의 서버를 계층적 카테고리로 정리하고 관리 가능
          + 목적별로 로그인 환경을 정의하여 일관된 워크플로우 유지
          + GUI 없이도 단축 아이콘으로 연결을 즉시 실행 가능
     * 강력한 파일 관리
          + 전문가 워크플로우에 최적화된 원격 파일 탐색기 제공
          + 터미널에서 특정 디렉토리로 직접 진입 가능
          + 로컬 프로그램을 그대로 활용해 원격 파일 열기/편집 가능
          + sudo 권한 필요 시 세션 재시작 없이 자동 승격
          + 멀티탭 기반 다중 서버 작업 지원
     * 터미널 런처
          + 클릭 한 번으로 선호하는 터미널에서 셸 세션 자동 실행
          + 비밀번호 자동 입력 등 다양한 자동화 기능 포함
          + 모든 운영 체제의 주요 터미널 에뮬레이터 지원
          + 커맨드 기반으로 사용자 정의 터미널 연결 가능
          + 셸 로딩 중 연결을 시작하여 더 빠른 접속 속도 제공
     * 유연한 스크립팅 시스템
          + 연결된 원격 시스템에서 실행할 재사용 가능한 스크립트, 템플릿, 그룹 생성 가능
          + 별도 설정 없이도 스크립트를 원격 시스템의 PATH에 자동 등록
          + 셸 환경 초기화 설정을 통해 작업 목적별 최적 환경 구성
          + 커스텀 명령어로 새로운 연결 타입 및 셸 정의 가능
     * 보안 Vault
          + 모든 데이터는 로컬 시스템에 암호화된 vault로 저장
          + 마스터 암호 구문을 통한 이중 암호화 지원
          + 비밀번호 관리 프로그램에서 자동으로 비밀 정보 검색 가능
          + 원격 Git 저장소와 동기화하여 팀 단위로 Vault 공유 가능
          + XPipe는 어떤 외부 서버와도 데이터를 공유하지 않음

플랫폼 지원

     * Windows, macOS, Linux 등 모든 주요 데스크탑 운영 체제 지원
     * 다양한 설치 옵션 제공: 설치형(.msi, .pkg, .deb, .rpm), 포터블(.zip, .tar.gz, .AppImage), 스크립트 설치 등
     * AUR, Homebrew, NixOS 패키지도 공식 지원
     * Docker 기반 웹탑 환경(KasmVNC)을 통해 브라우저에서 XPipe를 사용할 수 있는 옵션도 제공

오픈소스 모델

     * 오픈코어 모델 채택
          + 핵심 애플리케이션은 Apache License 2.0 하에 오픈소스 제공
          + 홈랩/프로페셔널 플랜에 포함된 일부 고급 기능 및 셸 라이브러리는 비공개
          + 전체 소스코드 접근이 필요한 기업은 소스-가용(Enterprise) 옵션 사용 가능
"
"https://news.hada.io/topic?id=20472","Linux 코드를 30줄만 수정하면, 전력 사용량을 최대 30% 절감할 수 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Linux 코드를 30줄만 수정하면, 전력 사용량을 최대 30% 절감할 수 있음

     * 미국 내 데이터센터 전력 소비는 2023년 기준 국가 전력의 약 4%, 2028년까지 12%로 증가 예상
     * 워털루대 연구팀은 리눅스 커널의 네트워크 처리 방식 개선을 통해 데이터센터의 전력 소비를 최대 30% 절감할 수 있는 방안을 개발
     * 핵심은 busy polling 방식의 동적 제어로, 트래픽 상황에 따라 인터럽트 방식과 폴링을 자동 전환
     * 이 변경은 단 30줄 정도의 코드 수정만으로 구현, Linux 6.13 커널에 공식 반영됨
     * 리눅스 기반 데이터센터 및 웹서버에 광범위한 적용 가능성 존재하며, 효율 중심의 소프트웨어 개발 철학 회복을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

데이터센터 전력 소비, 리눅스 커널 코드 단 30줄로 최대 30% 절감 가능

  전력 소비 증가에 대한 우려

     * 전 세계 웹 트래픽 대부분은 데이터센터를 통해 이루어지며, 이는 AI 서비스 등 고전력 애플리케이션의 기반이 됨
     * 미국의 경우, 2023년 전력의 약 4%를 데이터센터가 사용, 2028년까지 12%까지 증가할 전망

  문제의 핵심: Linux 커널의 네트워크 처리 방식

     * 리눅스 커널은 네트워크 패킷 처리 시 인터럽트와 폴링 방식 병행
          + 인터럽트: 새로운 패킷이 오면 CPU 작업 중단 후 처리
          + busy polling: 지연을 줄이기 위해 패킷 유무와 관계없이 주기적 확인 → 비효율

  해결책: busy polling을 동적으로 전환

     * 워털루대 마틴 카르스텐 교수팀은 네트워크 트래픽에 따라
          + 트래픽 많을 때: busy polling 사용
          + 트래픽 적을 때: 인터럽트 방식으로 전환
     * 결과적으로 불필요한 전력 소모 감소, 유연성 증대

  코드 수정과 적용 현황

     * Fastly 엔지니어 Joe Damato와 협업하여 기존 커널 코드를 재정렬하는 방식으로 구현
     * 신규 코드 작성 없이 기존 구조 변경으로 약 30줄 코드 수정
     * Linux 6.13 커널(2025년 1월 출시)에 공식 포함됨
       → 커널 커밋

  에너지 절감 효과

     * 네트워크 중심 애플리케이션에서 최대 30% 전력 절감
          + 일반 애플리케이션은 이보다 절감율이 낮을 수 있음
     * 트래픽 변화에 자동 적응하므로 데이터센터에 최적화
     * Linux 기반 웹서버(nginx, Apache 등)에도 확장 가능

  커뮤니티 확산 및 오픈소스 영향

     * Damato는 관련 기술을 Fastly의 H2O 서버에도 적용 계획
     * 오픈소스 커널 코드이므로, 기타 웹서버 개발자도 참고 가능
     * 에너지 효율 중심의 개발 문화 복원을 위한 기폭제 역할 기대

  연구의 철학적 의미

     * “90년대에는 리소스 최적화가 컴퓨터공학의 기본”이었으나, 최근 20년간 성능 중심으로 치우쳐 효율성은 간과됨
     * 이 연구는 “작은 코드 개선이 거대한 에너지 절감으로 이어질 수 있음”을 보여주며, 지속가능한 소프트웨어 개발의 방향성을 제시함

        Hacker News 의견

     * Linux는 고성능 네트워킹을 위한 바쁜 폴링 기능을 추가했음. 대부분의 Linux 소프트웨어는 이를 사용하지 않지만, 데이터센터에서 사용하는 소프트웨어는 시스템이 바쁘지 않을 때 에너지 비효율적임. 이 패치는 시스템이 바쁘지 않을 때 이를 끄고 에너지 효율성을 회복할 수 있게 함.
          + 기사 제목이 다소 오해의 소지가 있음. 데스크톱 작업에도 적용될 것처럼 들리지만, 실제로는 데이터센터를 위한 것임. 제목에 ""in datacenters""라는 말을 추가했으면 혼란을 피할 수 있었을 것임.
     * 고성능 데이터센터 작업의 많은 부분이 실제로 Linux 커널의 네트워크 스택을 거치지 않음.
          + 대신 DPDK, XDP, 또는 Onload나 VMA 같은 사용자 공간 스택을 사용함. 종종 SmartNICs가 하드웨어 오프로드를 수행함. 이러한 경우, 이 패치는 적용되지 않음.
          + 그러나 이 패치는 커널이 데이터 경로에 있는 설정(CDNs, 인그레스 노드, VM, 임베디드 Linux 시스템 등)에서는 분명히 도움이 됨. 이미 성능이나 지연 시간 문제로 커널을 우회하는 작업에는 큰 영향을 미치지 않을 것임. 30% 전력 절감이라는 헤드라인은 매우 상황에 따라 다를 것임.
     * 이 변화에 대한 자세한 내용은 https://lwn.net/Articles/1008399/ 에서 확인할 수 있음.
     * 정말 멋진 변화임. 고성능 컴퓨팅 전문가로서 비효율적인 코드로 인해 낭비되는 에너지가 얼마나 되는지, 그리고 그것이 행성 컴퓨팅이 확장됨에 따라 얼마나 큰 문제가 되는지 자주 궁금했음.
          + 개인적으로, 코드가 가능한 한 효율적이어야 한다는 도덕적 의무를 느끼고 있음. 특히 작업이 수백 개의 CPU에서 몇 달 동안 실행될 때 더욱 그러함.
     * 반대로, Meta는 GPU를 바쁘게 유지하여 LLM 훈련 중 전력 소모가 더 안정적이도록 하는 해킹을 가지고 있음. 예를 들어, 배치 동기화 시 큰 전력 감소를 원하지 않음.
     * 이것이 커널에서 ""적응형 인터럽트 완화""가 더 이상 사용되지 않는다는 의미인가? 약 15년 이상 이와 관련된 작업을 하지 않았지만, 네트워크 속도가 낮을 때는 인터럽트를 사용하고, 특정 지점을 넘으면 인터럽트를 끄고 폴링을 사용하는 방식으로 커널이 적응했었음.
          + 해결하려고 했던 문제는 갑작스럽고 극적인 트래픽 변화였음. 예를 들어, 스위칭에 루프가 도입되고 관련된 패킷 폭풍이 발생하는 경우. 이 경우, 인터럽트가 너무 빨리 들어와 시스템이 인터럽트를 비활성화할 수 있는 비인터럽트 시간을 충분히 확보할 수 없었음. 따라서 Linux 라우터가 네트워크 인터페이스보다 더 많은 코어를 갖도록 하는 것이 해결책이었음.
     * 문장에 ""Up To""가 포함되면, 문자 그대로 모든 것이 가능함.
     * 주제와는 다르지만, Joe Damato에 대한 글을 다시 읽게 되어 기쁨. 과거의 기억이 떠오름. 처음 James Gollick의 tcmalloc에 대한 글을 읽고 packagecloud.io에 대해 알게 된 후 Joe의 놀라운 글들을 접하게 되었음.
     * 핵심 문단:
          + ""이 에너지 절감은 주의사항이 있음. '30%는 네트워크 스택이나 통신 부분에 적용되는 최상의 경우임,' Karsten이 설명함. '애플리케이션이 주로 그것을 수행하면 30% 개선을 볼 수 있음. 애플리케이션이 다른 작업을 많이 하고 가끔 네트워크를 사용하면 30%는 더 작은 값으로 줄어들 것임.'""
     * 이 글은 과거의 기억을 되살려 줌 : https://didgets.substack.com/p/finding-and-fixing-a-billion-bug
"
"https://news.hada.io/topic?id=20436","Show HN: GitHub 코드베이스를 쉬운 튜토리얼로 변환하는 AI","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show HN: GitHub 코드베이스를 쉬운 튜토리얼로 변환하는 AI

     * AI를 활용하여 GitHub 코드베이스를 초보자 친화적인 튜토리얼로 변환하는 프로젝트인 Pocket Flow
     * GitHub 저장소를 크롤링하여 코드의 핵심 추상화를 분석하고 시각화를 통해 복잡한 코드를 쉽게 이해할 수 있는 튜토리얼로 변환함
     * AI가 자동으로 생성한 다양한 GitHub 저장소의 예시 결과 제공
     * 프로젝트 시작을 위한 기본 설정 및 실행 방법 설명
     * 개발 튜토리얼과 관련된 추가 자료 제공
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI를 활용한 코드베이스 튜토리얼 생성

     * Pocket Flow는 100줄의 LLM 프레임워크로, GitHub 저장소를 분석하여 초보자 친화적인 튜토리얼을 생성하는 프로젝트임
     * 이 프로젝트는 코드베이스의 핵심 추상화를 식별하고 상호작용을 분석하여 복잡한 코드를 초보자도 이해할 수 있는 튜토리얼로 변환함
     * YouTube 개발 튜토리얼과 Substack 포스트 튜토리얼을 통해 더 많은 정보를 확인할 수 있음

인기 GitHub 저장소의 AI 생성 튜토리얼 예시

     * AutoGen Core: AI 팀을 구성하여 문제를 해결하는 방법을 설명함
     * Browser Use: AI가 웹을 탐색하고 디지털 어시스턴트처럼 작동하는 방법을 설명함
     * Celery: 백그라운드 작업을 통해 앱을 강화하는 방법을 설명함
     * Click: Python 함수를 명령줄 도구로 변환하는 방법을 설명함
     * Codex: 평범한 영어를 작동하는 코드로 변환하는 방법을 설명함
     * Crawl4AI: 웹사이트에서 중요한 정보를 추출하는 방법을 설명함
     * CrewAI: AI 전문가 팀을 구성하여 복잡한 문제를 해결하는 방법을 설명함
     * DSPy: LLM 앱을 최적화하는 방법을 설명함
     * FastAPI: 빠른 속도로 API를 생성하는 방법을 설명함
     * Flask: 최소한의 코드로 웹 앱을 제작하는 방법을 설명함
     * Google A2A: AI 에이전트가 협력하는 방법을 설명함
     * LangGraph: AI 에이전트를 플로우차트로 설계하는 방법을 설명함
     * LevelDB: 데이터를 빠르게 저장하는 방법을 설명함
     * MCP Python SDK: 강력한 앱을 구축하는 방법을 설명함
     * NumPy Core: 데이터 과학 엔진을 마스터하는 방법을 설명함
     * OpenManus: AI 에이전트를 구축하는 방법을 설명함
     * Pydantic Core: 데이터를 검증하는 방법을 설명함
     * Requests: Python으로 인터넷과 통신하는 방법을 설명함
     * SmolaAgents: 작은 AI 에이전트를 구축하는 방법을 설명함

시작하기

     * 저장소를 클론하고 필요한 의존성을 설치함
     * utils/call_llm.py에서 LLM 설정을 완료함
     * 메인 스크립트를 실행하여 GitHub 저장소를 분석하고 튜토리얼을 생성함
     * 다양한 옵션을 사용하여 분석할 파일 및 언어를 지정할 수 있음

개발 튜토리얼

     * Agentic Coding을 사용하여 인간이 설계하고 에이전트가 코딩하는 개발 패러다임을 설명함
     * Pocket Flow 프레임워크를 사용하여 에이전트가 코드를 작성하도록 함
     * YouTube 개발 튜토리얼을 통해 단계별로 설명함

        Hacker News 의견

     * 저장소의 문서나 코드만 사용하는지에 대한 질문이 있음
     * AI 스튜디오 API 키를 사용해 시도해봤고 인상적이었음
          + API를 설명하는 데 레스토랑 비유를 사용하는 것은 불필요하게 길게 느껴짐
          + GraphQL에 대한 설명도 과도하게 길게 이어짐
          + 생성된 문서는 소프트웨어 엔지니어보다는 약간 기술적인 PM에게 더 적합해 보임
          + 프롬프트를 개선하여 이를 완화할 수 있을 것 같음
     * 프롬프트가 다이어그램의 다양성을 장려하면 좋을 것 같음
          + 예를 들어, AWS Step Functions를 사용한 내구성 있는 상태 머신 워크플로우에는 순서도보다 흐름도가 더 적합할 수 있음
     * 새로운 라이브러리를 사용할 때 첫 번째 단계로 저장소를 복제하고 Claude 코드를 실행하여 좋은 문서를 작성하도록 요청함
          + 많은 단계를 절약할 수 있을 것 같음
     * Cursor에게 많은 질문을 하여 비슷한 결과를 얻음
          + 다른 사람도 언급했듯이 약간 다른 톤을 원함
          + 선호하는 글쓰기 스타일에 맞출 수 있는 ""스타일 템플릿"" 기능이 좋을 것 같음
          + 시간이 많이 걸리지 않는다면 PR을 제출할 수도 있음
     * mutable ai라는 회사가 작년에 Google에 인수되었는데, 튜토리얼 대신 위키를 출력하는 작업을 했음
     * dspy 튜토리얼이 훌륭함
          + dspy는 개념적으로 이해하기 어렵지만 튜토리얼이 잘 설명해줌
     * 브라우저 사용을 위해 구축함
          + 라이브러리의 결과가 매우 인상적임
          + 출력은 전혀 손대지 않았음
          + 현재 코드베이스와 문서를 유지하는 데 문제가 있음 (코드 예제가 가끔 깨짐)
          + Pocket의 일부를 사용하여 이를 해결할 수 있을지 궁금함
     * 정말 멋진 작업이고 공유해줘서 고맙다는 의견
          + LLM의 가치를 잘 보여주는 예시임
          + 주니어 엔지니어에게 미치는 부정적인 시각을 극복하는 데 도움을 줌
          + 대부분의 프로젝트가 최신 문서가 부족한 문제를 해결하는 데 도움을 줌
     * 새로운 오픈 소스 기여자의 온보딩에 게임 체인저가 될 수 있음
          + postgres나 redis 코드베이스를 넣고 잘 이해하여 기여를 시작할 수 있음
     * 상위에는 깔끔한 고수준 내용이 있지만, 그 아래로는 인간 언어로 작성된 코드로 빠르게 전환됨
          + 관련 단위 테스트를 살펴보면 더 유용한 사용 패턴을 추출할 수 있을 것 같음
          + 대부분의 튜토리얼 독자에게 중요한 것은 ""사용 방법""임
"
"https://news.hada.io/topic?id=20507","애플과 메타, EU 법 위반으로 수백만 달러 벌금 부과","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     애플과 메타, EU 법 위반으로 수백만 달러 벌금 부과

     * 유럽연합(EU)이 Apple과 Meta에 각각 5억 유로와 2억 유로의 벌금을 부과함
     * 디지털 시장법(DMA) 을 통해 소규모 경쟁자들이 시장에 진입할 수 있도록 지원하려는 노력의 일환으로 벌금이 부과됨
     * Donald Trump 대통령은 이러한 벌금을 ""경제적 갈취""라며 비판함
     * Apple과 Meta는 EU의 결정을 비판하며, 벌금이 자사의 비즈니스 모델에 부정적인 영향을 미친다고 주장함
     * EU는 Google과 Elon Musk의 X에 대해서도 벌금을 부과할 가능성을 검토 중임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Apple과 Meta에 대한 벌금 부과

     * 유럽연합(EU)이 Apple에 5억 유로, Meta에 2억 유로의 벌금을 부과함
     * 이는 디지털 시장법(DMA) 을 통해 대형 기술 기업의 권력을 억제하려는 노력의 일환임
     * 벌금 부과는 미국 대통령 Donald Trump와의 긴장을 초래할 수 있음
     * Trump는 이러한 벌금을 ""경제적 갈취""라며 비판함

기업들의 반응

     * Apple은 EU의 결정을 비판하며, 사용자 프라이버시와 보안에 부정적 영향을 미친다고 주장함
     * Meta는 EU가 성공적인 미국 기업을 불리하게 만든다고 비판함
     * 두 기업 모두 벌금에 대해 이의를 제기할 계획임

EU의 규제 조치

     * Apple은 앱 개발자가 앱 스토어 외부에서 더 저렴한 거래를 유도할 수 있도록 기술적, 상업적 제한을 제거해야 함
     * Meta의 pay-or-consent 모델이 DMA를 위반했다고 판단됨
     * 두 기업은 명령을 준수하지 않을 경우 일일 벌금을 부과받을 수 있음

추가 조사 및 조치

     * Apple은 iPhone 브라우저 옵션에 대한 별도의 조사에서 벌금을 피함
     * Meta의 Marketplace는 DMA 게이트키퍼로 지정되지 않음
     * EU는 Google과 Elon Musk의 X에 대한 조사를 계속할 계획임

EU의 입장

     * EU는 모든 기업이 유럽의 법률을 준수해야 한다고 강조함
     * EU 의원 Andreas Schwab는 Google과 Elon Musk의 X에 대한 조사를 계속해야 한다고 주장함

        Hacker News 의견

     * EU의 DMA 규정에 따라 Apple의 App Store를 통해 앱을 배포하는 개발자는 App Store 외부의 대안을 고객에게 무료로 알리고, 그 대안으로 고객을 유도하며 구매를 허용해야 함
          + Apple이 Netflix가 자체 웹사이트에서 가입 및 결제할 수 있다는 사실을 사용자에게 알리는 것을 제한하는 것은 불공평함
          + Gruber는 일반적으로 EU/DMA의 Apple 개입에 반대하지만 이 부분에 대해서는 동의함
          + Apple이 앱 내 구매 구독 수익의 일부를 요구하는 것은 그들의 권한이지만, 앱이 사용자에게 명확하게 결제 방법을 알리는 것을 막는 규칙은 문제임
          + Netflix는 웹사이트로의 링크조차 허용되지 않으며, netflix.com에 가입해야 한다는 사실조차 사용자에게 알릴 수 없음
     * 미국 관료와 사업가들은 EU가 성공적인 미국 기업을 방해하고 있다고 주장하지만 이는 사실이 아님
          + EU는 법을 위반한 기업에 벌금을 부과하며, 이는 현지 기업에도 동일하게 적용됨
          + 미국은 TikTok을 판매하도록 요구했지만 실제로 법을 위반했다는 증거는 제시하지 않음
          + 미디어에서 반복되는 주장은 사람들에게 전달되며, 실제 상황과 미디어의 보도 사이에 불일치가 발생함
     * EU 규제 당국이 Meta의 Marketplace를 DMA 게이트키퍼로 지정하지 않은 것은 흥미로움
          + 사용자 수가 기준치인 4,500만 명 이하로 떨어졌기 때문임
     * iPhone 앱 스토어는 특정 고객에게 제품을 판매하고자 하는 기업이 선택할 수 있는 사적 클럽임
          + 클럽 회원은 대체 구매 방법에 대해 언급하지 않는 조건이 있음
          + 클럽 회원이 독점은 아니며, 다른 채널을 통해 제품을 판매할 수 있음
          + 왜 이것이 법에 위배되는지에 대한 질문이 제기됨
     * Apple은 앱 스토어 규정 위반으로 5억 유로의 벌금을, Meta는 ""동의 또는 결제"" 광고 모델로 2억 유로의 벌금을 부과받음
          + 작년에 EU 집행위원회가 반독점법에 따라 Apple과 Meta에 각각 18억 유로와 7억 9,700만 유로의 벌금을 부과한 것에 비해 절차적 벌금은 적음
          + 벌금이 실제로 지불되는지, 시민이 알 수 있는 방법이 있는지에 대한 질문이 있음
     * 미국의 반독점 법 집행의 심각한 부재로 인해 다른 국가들이 외교적 부작용을 겪게 됨
     * Meta가 관세를 부과받았다고 불평하는 것은 객관적으로 웃김
     * Meta의 성명이 미국 기업을 불리하게 하고 유럽 및 중국 기업이 다른 기준으로 운영되도록 허용한다는 주장을 이해하지 못함
     * 시작은 좋지만, 그들이 초래한 사회적 피해(반경쟁적, 반사용자적, 특히 미성년자에 대한 심리적 피해, 급진화 확산)에 비하면 충분하지 않음
"
"https://news.hada.io/topic?id=20465","난독화된 TikTok VM을 리버스 엔지니어링하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      난독화된 TikTok VM을 리버스 엔지니어링하기

     * TikTok은 가상 머신(VM) 을 사용하여 보안 및 난독화 계층을 강화함
     * 이 프로젝트는 이 웹 기반 가상머신(VM)을 리버스 엔지니어링하여 보안 우회 및 요청 서명 생성 방식을 분석함
     * 핵심 대상은 webmssdk.js로, 이는 X-Bogus 및 _signature 생성에 관여하는 VM 코드를 포함함
     * 프로젝트는 자바스크립트 난독화를 해제하고, TikTok VM의 바이트코드를 분석 및 디컴파일하여 의미 있는 함수 수준으로 복원함
     * 이를 통해 인증이 필요한 요청(예: 댓글 작성) 시 필요한 _signature 생성까지 가능해짐
     * VM은 정교하게 설계되어 있으며, 루프, 예외 처리, 범위 관리 등 고급 바이트코드 구조를 갖춤
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

TikTok VM 리버스 엔지니어링 프로젝트 개요

     * TikTok은 자바스크립트 기반의 난독화된 가상머신(VM)을 사용하여 클라이언트 요청 서명 생성, 데이터 보호, 보안 우회 방지를 수행함
     * 이 프로젝트는 webmssdk.js 파일의 난독화 해제 및 디컴파일을 통해 서명 알고리즘(X-Bogus, _signature) 복원을 목표로 함

핵심 기능 및 구조 분석

  난독화 해제

     * TikTok은 문자열을 배열과 브래킷 표기법으로 인덱싱하여 난독화함
r[Gb[301]](Gb[57], e)

     * Gb 배열의 복호화는 고정된 문자열 테이블을 사용하여 치환 처리됨
     * 해당 패턴을 모두 디코딩한 후, 읽기 쉬운 점 표기법(dot notation) 으로 변환

  함수 호출 난독화 제거

     * 함수들이 배열 Ab에 저장되어 인덱스로 호출됨
Ab[31](args) → Ab31(args)

     * AST 파서를 활용하여 이를 개별 함수로 분리하고 이름 지정 후 호출 방식도 수정함

  바이트코드 복호화

     * 바이트코드는 base64 + gzip + leb128 + XOR 암호화로 복잡하게 구성됨
r = XOR 키 계산
압축 해제 및 leb128 디코딩으로 명령어 세트 재구성

     * 각 함수는 바이트코드 기반으로 구성되며, 디컴파일 과정을 통해 함수 구조 복원

  TikTok VM 특징

     * 중첩 함수, 스코프 관리, 예외 처리, 조건 분기 등 일반적인 VM보다 고도화됨
     * 각 명령어는 switch가 아닌 if-else 구조로 위장되어 있음 → 이를 switch case 형태로 복원

디컴파일 및 디버깅

     * 각 바이트코드 함수는 일반 JS 함수 수준으로 디컴파일되어 VMxxx.js 형태로 저장됨
     * 예: VM223는 랜덤 문자 생성기
     * 디버깅은 Chrome의 Tampermonkey + CSP 우회 확장을 사용하여 원본 JS를 디컴파일 파일로 대체하며 수행

서명(Signing) 분석

  요청 헤더 구조

     * 서버 요청 시 3개의 추가 헤더가 포함됨
          + msToken : 서버에서 발급됨, 매 요청마다 재생성됨
          + X-Bogus : webmssdk.js에서 요청 기반으로 생성됨
          + _signature : 인증이 필요한 요청에서 사용됨, webmssdk.js 생성
     * 일반적인 사용자 조회 요청은 X-Bogus만 필요
     * 댓글 작성 같은 인증 요청은 _signature도 필요

  VM 함수 흐름

     * VM86: 전체 서명 생성의 진입점
     * VM113: X-Bogus 생성
     * VM189: _signature 생성
     * signer.js로 이 흐름을 재현하여 URL 서명 가능

부가 보호 메커니즘

     * 마우스 추적: VM120
     * 환경 체크: VM265
     * 그러나 이는 모두 클라이언트 측 보호이며 서버 통신 없음 → 서명 생성에는 무시 가능

주의 사항 및 유지보수

     * TikTok VM은 지속적으로 업데이트됨 → 구조 변경 시 새로운 디컴파일 필요
     * 이 프로젝트는 주로 보안 분석, 봇 방지 기술 연구, 교육 목적에 적합

        Hacker News 의견

     * 나는 자주 끊기고 오류 메시지를 보여주는 스트리밍 웹사이트를 사용하고 있음. JavaScript 코드를 분석하여 해결책을 찾고 있으며, AI 도우미가 난독화된 코드를 이해하는 데 큰 도움이 되었음
          + AI를 통해 난해한 JavaScript 함수를 더 이해하기 쉽게 재작성하고 주석을 추가할 수 있음
          + AI가 변수나 함수 이름을 추측하여 코드의 고수준 동작을 이해하는 데 도움을 줌
          + 비슷한 작업을 하는 사람들에게 AI 에이전트를 도구로 사용하는 것을 강력히 추천함
     * 웹에서 실행되는 JavaScript 파일을 난독화 해제된 파일로 교체하여 TikTok을 정상적으로 사용할 수 있음
          + Tampermonkey와 CSP 확장 프로그램을 사용하여 파일을 차단된 출처에서 가져올 수 있음
          + Chrome DevTools의 Local Overrides를 사용하여 제3자 확장 프로그램 없이도 동일한 효과를 얻을 수 있음
     * 코드를 숨기기 위해 많은 노력을 기울이는 것 같음. 이는 프로그램의 최적화를 방해하고 복잡성을 증가시켜 오류를 더 많이 발생시킬 수 있음
          + 봇을 막으려는 의도는 이해하지만, 더 효과적인 방법이 필요함
          + 클론을 막을 수는 없으며, 클론은 작동 방식을 보고 블랙박스 스타일로 역설계할 수 있음
     * TikTok VM을 역설계한 예시를 북마크에서 찾았음
          + 링크1
          + 링크2
     * 역설계 노력에 대한 글을 읽는 것을 항상 즐기며, 이번 글은 따라가기 쉬웠음
          + 많은 웹사이트와 봇 보호 서비스는 환경 검사와 마우스 움직임 추적을 기본으로 함
          + 이러한 조치가 무력화된 후 서비스가 메커니즘을 변경하는 데 걸리는 시간을 보는 것은 항상 흥미로움
     * 소셜 미디어 플랫폼이 이 정도의 난독화를 사용하는 정당한 이유는 없음
     * VM이 무엇인지에 대한 질문
          + VM을 사용하여 다양한 운영 체제에서 테스트 환경을 구축한 경험이 있음
          + JavaScript Virtual Machine은 호스트 OS 위에서 자체 운영 체제로 작동함
          + TFA에서 논의된 VM은 이러한 종류의 VM이 아님
          + 최근 다양한 맥락에서 ""VM""이 사용되고 있어 혼란스러움
     * Lynx와 관련된 VM인지에 대한 질문
          + LynxJS 링크 제공
          + Hacker News에서 논의됨 링크
     * iOS 앱에도 VM이 있는지에 대한 질문
          + VM이 Apple의 정책에 반할 것이라고 생각함
     * TikTok 봇 작업을 잠시 했었는데 매우 어려웠음
"
"https://news.hada.io/topic?id=20387","[Vibe Coding 기업 적응기] Part2: 설계 문서 기반 Vibe Coding으로 MVP 개발에 도전","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [Vibe Coding 기업 적응기] Part2: 설계 문서 기반 Vibe Coding으로 MVP 개발에 도전

    1. 배경
       •기존 OOP/디자인 패턴 기반 개발 경험에서, 새로운 개발 방식인 MSA와 Vibe Coding의 생산성에 충격을 받았던 경험 공유.
       •최근엔 LLM과 AI IDE(CLAUDE, Cursor 등)의 발전으로, 코드 작성 방식 자체가 변화하고 있음.
    2. DDVC란?

   Design-Driven Vibe Coding은 크라우드웍스가 명명한 방식으로, 설계 문서를 기반으로 LLM에게 개발을 요청하는 체계적인 Vibe Coding 방법론이다.
   •핵심은 PRD와 Requirements 문서 작성 후 이를 기반으로 AI가 코드를 생성하게 하는 구조.
   •문서 작성도 AI가 초안 → 사람의 검토 및 수정을 통해 완성.
   •PRD: 제품 목적, 기능 요구사항, 사용자 스토리, 우선순위 등 포함
   •Requirements: 모듈 개요, 기능 요구사항, 파일 구조, 관련 코드 및 규칙 포함
    3. 두 가지 개발 전략
       •전략1: 모듈 단위 순차 개발 → 기존 방식과 유사, 안정적. PoC보단 Production에 적합.
       •전략2: 모듈 동시 생성 → 빠르나 테스트와 검증 난이도 높음. 테스트 코드도 함께 생성해 대응.
    4. 3-Day MVP Development 실험
       •리소스가 부족한 현실을 극복하기 위해, 3일 만에 MVP를 개발하는 실험 진행.
       Day 1: 설계 문서(PRD + Requirements) + 기술 설계
       Day 2: 코드 생성 + 기본 테스트
       Day 3: 통합 테스트 + 프론트엔드 + 검증
    5. MVP 사례: 문서 권한 기반 RAG 시스템
       •문서 파싱 및 Vector DB 등록, 권한 관리, 채팅형 검색 기능을 갖춘 시스템.
       •PRD/Requirements 생성 → AI가 코드 생성 → 테스트 코드 생성 → Cursor AI로 디버깅.
       •프론트엔드는 Next.js + TailwindCSS로 테스트용 UI 자동 생성.
    6. 실행 Tips 및 느낀 점
       •코드 수정보다는 재생성이 더 경제적일 수 있음.
       •로그 출력 중요성 강조 (줄번호 포함 포맷 권장)
       •AI의 코딩 능력 신뢰 필요 (특히 Claude 3.7 기준)
       •비동기 코드는 AI도 디버깅 어려움 → 처음엔 동기식으로 작성 후 변경 권장
       •초기엔 코드 양에 압도될 수 있으나 익숙해지면 생산성↑
    7. 문화 확산 방안
       •사내 해커톤 계획: DDVC 확산 및 Vibe Coding 실전 경험 공유
       •개발자/비개발자 트랙을 나눠 모두가 AI 코딩 접근 가능하도록 설계

   결론:
   Vibe Coding은 코드 생산방식뿐 아니라 개발자의 역할, 문화, 협업 방식까지 변화시키고 있음. 빠르게 실전에서 경험하고 적응하는 것이 경쟁력이 될 수 있다는 인사이트를 공유하며 마무리.
"
"https://news.hada.io/topic?id=20417","ElasticSearch에 드디어 SQL 스타일 JOIN 기능 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 ElasticSearch에 드디어 SQL 스타일 JOIN 기능 도입

     * ES 8.18에 ES|QL의 LOOKUP JOIN 명령어가 도입되어 데이터 상관관계 및 보강이 가능해짐
     * 기존 ENRICH 기능보다 설정과 관리가 쉬우며, 데이터 조인, 보안 이벤트 상관 분석, 자산 정보 병합 등에 유용
     * JOIN을 위해 새롭게 설계된 단일 샤드 기반의 ‘lookup index’ 모드 도입 — 최대 20억 문서까지 저장 가능
     * LOOKUP JOIN은 다대다 조인을 쉽게 처리하며, 동적 필드 지정 및 집계 기능에도 적합
     * Kibana 또는 API를 통해 CSV로 쉽게 lookup 인덱스를 만들 수 있으며, 향후 INNER JOIN, 서브쿼리 기능도 예정됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

ES|QL에 진짜 JOIN이 생겼다: LOOKUP JOIN 기능 소개

  Elasticsearch에서도 이제 SQL 스타일 JOIN 가능

     * Elasticsearch 8.18부터 ES|QL에서 LOOKUP JOIN을 지원
     * 이는 LEFT OUTER JOIN 형식이며, “우측” 데이터는 새로운 lookup 인덱스 모드를 통해 관리됨
     * 예시:
          + IP 주소에 따라 환경명(dev, QA, prod) 병합
          + 보안 이벤트에 직원 정보, 자산 정보, 위협 인텔리전스 등 추가
          + 웹 로그에서 응답 코드별 환경 분석 등

  기존 ENRICH와의 차이점

     * ENRICH 방식
          + 인덱스 기반의 정책을 사전에 설정해야 함
          + 데이터가 변경될 때마다 정책을 재실행해야 함
          + 다중 매칭 시 멀티값 필드로 반환되어 후처리가 복잡함
          + 집계 및 통계 분석에는 부적합
          + **정적인 데이터(변경이 거의 없는 참조용 정보)**에 적합
     * LOOKUP JOIN 방식
          + 별도 정책 없이 즉시 사용 가능
          + 인덱스를 직접 수정할 수 있어, 변경 사항이 즉시 반영됨
          + 다중 매칭 시 행 단위로 분리되어 분석이 용이함
          + 그룹화 및 집계에 최적화되어 있음 (예: 사용자별 트래픽 합계)
          + 동적이고 자주 업데이트되는 데이터에도 유리함

  사용 예시

FROM kibana_sample_data_logs
| WHERE response.keyword != ""200""
| LOOKUP JOIN envs_lkp ON clientip
| STATS COUNT(*) by response, environment

     * IP별 환경 데이터를 JOIN하여 HTTP 오류 발생 위치 분석
     * 팀 소유 정보도 JOIN해서 어떤 팀이 관리하는 서버에 문제가 있는지 파악 가능
FROM kibana_sample_data_logs
| WHERE response.keyword != ""200""
| LOOKUP JOIN teams_lkp ON host
| STATS num = COUNT(*) by host, response.keyword, team
| SORT num DESC

  Lookup 인덱스 생성 방법

     * Kibana UI로: Stack Management → Index Management → Create index
     * REST API로:
PUT mylookupindex
{
  ""settings"": {
    ""index.mode"": ""lookup""
  }
}

     * 머신러닝 File Upload를 통해 CSV 업로드 후 인덱스 생성 시 lookup 모드 설정 가능

  주의사항 및 팁

     * JOIN은 무거운 연산이므로 자주 쓰는 필드는 lookup 대신 ENRICH + ingest-time denormalization 고려
     * lookup index는 단일 샤드로 구성되어 있으며, 최대 20억 문서 제한
     * 일반 쿼리처럼 FROM <lookup_index> 로 직접 조회도 가능함
     * Logstash나 Elastic Agent를 통해도 데이터 입력 가능 (단, data stream은 아님)

  향후 계획

     * INNER JOIN, SUBQUERY, 일반 인덱스 조인도 지원 예정
     * Kibana 내에서 직접 lookup 인덱스 생성 및 수정 UI 제공 예정
          + 예: Discover에서 CSV 드래그 앤 드롭 → 자동 인덱스 생성
          + GUI 기반 Lookup 관리 기능 제공 예정 (목업도 공개됨)

  정리 및 시작하기

     * LOOKUP JOIN은 정식 릴리즈 전 기술 프리뷰지만, ES|QL을 새로운 수준으로 끌어올릴 수 있는 기능
     * Elastic Cloud에서 Elasticsearch 8.18 또는 9.0으로 시작 가능
"
"https://news.hada.io/topic?id=20502","애플이 직접 Godot 엔진에 visionOS 플랫폼 네이티브 지원 준비중","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               애플이 직접 Godot 엔진에 visionOS 플랫폼 네이티브 지원 준비중

     * Apple의 visionOS 팀이 Godot 엔진에 Vision Pro 지원을 추가하고자 하는 첫 PR 제출
     * 초기 목표는 기존 Godot 게임의 visionOS 네이티브 실행 및 몰입형 콘텐츠 제작 지원
     * iOS 기반으로 visionOS 플랫폼을 구현하고 코드 재사용성과 구조화된 PR 전략을 강조
     * iOS/visionOS 관련 기능 테스트 완료, 하지만 일부 기능은 커뮤니티의 도움 필요
     * 향후 PR에서 SwiftUI 및 VR Plugin 추가 예정, 몰입형 경험 확장을 위한 기반 마련
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Vision Pro 지원을 위한 첫 기여 PR 개요

     * Apple의 visionOS 엔지니어링 팀이 Godot 커뮤니티와 협업하여 Vision Pro를 지원하고자 함
     * 높은 품질 기준을 유지하며 Godot의 코딩 스타일을 따름
     * 기능별로 작고 독립적인 PR로 나누어 제출하고 있으며, 이 PR은 그 첫 번째임
     * 이후 PR을 통해 Swift 및 몰입형 VR 기능도 순차적으로 제공 예정

기여 목표

     * 현재 Godot 게임을 visionOS의 평면 윈도우에서 네이티브 실행 가능하도록 지원
     * 새로운 visionOS VR Plugin을 통해 몰입형 콘텐츠 제작 기능 제공
     * 총 세 단계로 기여 계획을 세움
          + visionOS 플랫폼 추가 (현재 PR)
          + SwiftUI 앱 라이프사이클 및 Swift 컴파일/링크 기능 추가 (예정)
          + Vision Pro VR 플러그인 추가 (예정)

기술적 구현 사항

     * visionOS 플랫폼은 iOS 기반으로 구현되어 코드 중복 최소화
     * drivers/apple_embedded 폴더를 새로 만들어 iOS와 visionOS 간의 공통 코드 저장
     * 각 플랫폼은 고유한 세부 기능만 제공하는 서브클래스를 통해 차별화
     * OpenGL 미지원 (visionOS 자체가 OpenGL을 지원하지 않음)
     * PR은 검토를 쉽게 하기 위해 여러 커밋으로 나누어 제출

문서화 관련 고려사항

     * iOS와 visionOS의 내보내기 플러그인 및 설정 대부분이 공통
     * EditorExportPlatformIOS.xml 파일을 EditorExportPlatformAppleEmbedded.xml로 이름 변경하고 위치 이동
     * 문서화 도구 관점에서 적절한지 여부 및 플랫폼별 문서 분리 방법에 대한 커뮤니티 피드백 요청

테스트 진행 사항

     * Platformer 데모 프로젝트로 테스트 진행
     * iOS와 visionOS 양쪽에서 Metal 렌더링 드라이버 기반으로 Mobile/Forward+ 렌더러 테스트 완료
     * iOS 지원 유지됨과 동시에 visionOS에서도 성공적으로 실행됨

커뮤니티에 요청하는 사항

     * iOS/visionOS 템플릿에서 플러그인 임베딩 및 링크 기능이 잘 작동하는지 테스트 필요
     * IPA 생성 및 One-Click-Deploy 기능이 작동하지 않음 — 원인 분석 및 작동 여부 확인 요청
     * ios_deploy를 통한 직접 배포 기능도 테스트 필요 — 사용자가 줄었다면 코드 제거 가능

미구현 기능

     * DPI 정보가 현재 하드코딩됨 — SwiftUI 통합 시 API를 통해 런타임 변경 정보 반영 예정
     * visionOS용 아이콘 에셋 카탈로그 자동 생성 기능 미구현
          + Xcode 프로젝트 내 수동 생성으로 대체 가능
          + 커뮤니티 기여 가능 시 매우 환영
     * visionOS 플랫폼 SVG 로고가 텍스트 기반 — 시각적으로 보기 좋은 아이콘 기여 요청

   godot 뭐야?

   godot 떡상하나요 ㅋㅋ

   갑자기 godot이..?!

        Hacker News 의견

     * Apple Vision과 visionOS 제품 라인이 내부적으로 취소되지 않았으며, Apple이 여전히 미래에 대한 의지를 가지고 있음
          + Apple Vision Pro 자체는 성공적인 제품이 아니지만, 디스플레이 기술의 발전이 Apple이 가볍고 편안하며 눈에 띄지 않는 AR 안경 형태의 더 매력적인 소비자 제품을 만들 수 있게 할 것임
          + AVP의 실패에만 집중하지 않고 장기적인 제품 라인을 보는 관점에서 이 OS를 Godot에 추가하는 것이 의미가 있다고 생각함
          + 유지 보수 부담을 누가 질 것인가에 대한 우려는 타당함. Apple은 API의 모호한 버그나 문제에 대해 가장 반응이 빠른 회사는 아니었음 (예: Cocoa 관련). 목표를 언제든지 변경할 수 있는 대형 기술 회사의 지속적인 지원에 의존하는 것은 조심스러움
          + 그럼에도 불구하고, 이는 흥미로움
     * Godot는 이미 OpenXR을 통해 VR을 지원하고 있음
          + OpenXR은 SteamVR, Oculus, Vive, Pico, Windows Mixed Reality, Quest에서 지원하는 VR/AR 기기의 Khronos 유지 산업 표준임
          + visionOS/Vision Pro는 눈에 띄게 부재함
          + Apple이 산업 표준을 준수해야 한다고 주장함. 더 확장 가능하고 개방적임
     * visionOS 사용자 두 명이 이 발표에 대해 기뻐함
     * 이 추가를 보는 것이 좋음. Godot가 OpenXR을 Apple의 AR 컴포지터에 연결하는 것이 더 나을지, 아니면 이 PR들이 구현한 대로 할지 확신이 서지 않음
          + Metal 렌더러에서 AR 컴포지터로 연결하는 것은 많은 작업이 아님. visionOS의 Compositor Services에 대한 문서화가 부족하지만 좋은 C API가 있음. 이는 무거운 유지 보수 부담이 되지 않을 것 같지만, 시뮬레이터에서 두 번째 정점 증폭이 실행되지 않으므로 몇 개의 헤드셋을 기부해야 함. 스레드 그룹당 최대 스레드도 다름. 성능을 측정하려면 실제 하드웨어가 필요함
     * Apple이 개발 기금에 전혀 기여하지 않고 이 PR을 올린 것은 놀라움
          + 먼저 문제를 제기하지도 않았음
     * 미디어에서 들은 모든 것에서 Apple이 XR 제품을 거의 포기하고 기술이 대중 소비에 준비될 때까지 생명 유지 장치로 유지할 것이라는 인상을 받았음
     * 많은 댓글을 읽고 Apple이 해야 할 일은:
         1. Godot에 돈을 줌
         2. visionOS 지원을 코어에 직접 구현하지 않고 확장을 통해 구현하거나 산업 표준 OpenXR을 준수함
     * Apple이 Godot에 적절히 시작할 수 있도록 돈을 줘야 함
     * 여기서 흥미로운 점은 Apple이 마침내 게임이 중요하다는 것을 배웠다는 것임. 물론 그들은 ""우리는 절대 틀리지 않는다""는 태도로 이를 인정하지 않음. 예를 들어, 원래 Mac의 ""마우스는 하나의 버튼을 가져야 한다""는 철학을 유지하기 위해 물리적 버튼이 두 개 없는 마우스를 만드는 것처럼. 그들은 배우고 있음, 이는 그들의 휴대폰/태블릿의 USB-C와 달리 자발적이었음
     * Apple이 차세대 Vision 기기를 위해 게임을 우선시할 가능성이 있어 보임. 희망적으로, 나를 포함한 많은 사람들이 게임 지원이 없어서 Vision을 건너뛰었음. 가격은 문제가 아니었음
"
"https://news.hada.io/topic?id=20416","디스코드 얼굴 인식 연령 확인 '더 큰 변화의 시작'","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     디스코드 얼굴 인식 연령 확인 '더 큰 변화의 시작'

     * Discord는 영국과 호주에서 일부 사용자들의 나이를 확인하기 위해 얼굴 인식 기술을 테스트 중임
     * 온라인 안전법에 따라 성인 콘텐츠가 포함된 플랫폼은 강력한 나이 확인을 요구받게 됨
     * Matt Navarra는 이러한 변화가 온라인 안전법의 도입으로 인해 플랫폼들이 나이 확인 절차를 강화할 것이라고 언급함
     * 나이 확인 기술은 프라이버시 문제를 초래할 수 있으며, Big Brother Watch는 이를 만능 해결책으로 보지 말아야 한다고 경고함
     * 호주는 올해 16세 미만의 소셜 미디어 사용 금지를 계획 중이며, Discord는 안전 통제에 대한 오해로 인해 소송을 당함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Discord의 얼굴 인식 나이 확인

     * Discord는 영국과 호주에서 일부 사용자들의 나이를 확인하기 위해 얼굴 인식 기술을 테스트 중임
     * 이 플랫폼은 원래 게이머들이 주로 사용했으나, 이제는 다양한 주제의 커뮤니티가 존재함
     * 영국의 온라인 안전법에 따라 성인 콘텐츠가 포함된 플랫폼은 강력한 나이 확인 절차를 갖춰야 함
     * Matt Navarra는 이러한 변화가 단발적인 것이 아니라 더 큰 변화의 시작이라고 언급함
     * 나이 확인을 잘못하면 사용자 손실뿐만 아니라 법적 문제나 벌금이 발생할 수 있음

자녀의 온라인 안전을 지키는 방법

     * Discord는 나이 확인을 ""실험""으로 설명하며, 이는 일회성 확인임
     * 사용자는 얼굴 스캐너를 사용하거나 ID 사진을 업로드하여 나이를 확인할 수 있음
     * 나이 확인에 사용된 정보는 Discord나 검증 회사에 의해 저장되지 않음
     * 얼굴 스캔은 기기에만 남고 수집되지 않으며, ID 업로드는 검증 완료 후 삭제됨
     * 민감한 콘텐츠로 표시된 내용은 이미 자동으로 차단되거나 흐려짐

'만능 해결책은 아님'

     * Big Brother Watch는 나이 확인 기술이 만능 해결책으로 간주되어서는 안 된다고 경고함
     * 나이 확인 기술은 보안 침해, 프라이버시 침해, 오류, 디지털 배제 및 검열의 위험을 초래할 수 있음
     * Age Verification Providers Association는 다양한 편리하고 프라이버시를 보호하는 방법이 있다고 주장함
     * 플랫폼은 유해 콘텐츠를 제거하거나, 전체 사이트에 접근하기 전에 나이 확인을 적용하거나, 고위험 페이지와 게시물에 접근하기 전에 나이를 확인할 수 있음

호주의 소셜 미디어 사용 금지 계획

     * 호주는 올해 16세 미만의 소셜 미디어 사용 금지를 계획 중임
     * 최근 연구에 따르면 8세에서 12세 사이의 호주 어린이 중 80% 이상이 13세 이상만 사용할 수 있는 소셜 미디어나 메시징 서비스를 사용함
     * 뉴저지 법무장관 Matthew J. Platkin은 Discord가 안전 통제에 대해 부모를 오도했다고 주장하며 소송을 제기함

Meta의 청소년 사용자 제한 확대

     * Meta는 Facebook과 Messenger에서 청소년 사용자에 대한 제한을 확대함

학교 휴대폰 금지 권한

     * 어린이 위원회는 학교 휴대폰 금지 권한을 교장에게 맡겨야 한다고 주장함

        Hacker News 의견

     * 오래 전, 나의 나이를 확인하기 위해 신용카드 번호를 요구한 사이트가 있었음. 환불을 통해 나이를 확인했음
          + 얼굴 인식이나 신분증 확인은 기록을 남기기 위한 것임
          + 생체 인증은 단순한 감시임
          + 정부의 과도한 권력 행사에 대한 우려가 있음
          + 온라인 정체성이 정부에 알려지면 정치적 토론 참여가 줄어듦
          + 이런 법에 대한 윤리적 대응은 해당 국가에서 서비스 종료임
     * 소셜 미디어 회사가 AI로 나이를 추정하기 위해 셀피 비디오를 요구함
          + AI가 13세와 12.9세를 구별할 수 있을지 의문임
          + 얼굴 스캔을 저장하지 않는다는 주장은 믿기 어려움
          + 이미지 대신 숫자를 저장하거나 제3자에게 전송할 가능성이 있음
     * 인터넷에서 포르노를 찾는 것이 문제는 아님
          + 주의력을 빼앗는 심리적 전쟁이 문제임
          + 끝없는 콘텐츠가 사람들을 무기력하게 만듦
          + 나이 확인만으로는 문제를 해결할 수 없음
     * 사생활 침해 외에도 얼굴 인식의 정확성 문제 있음
          + 잘못된 경우 ID 이미지를 보내야 하는지 의문임
          + 최근 영국의 변화에 대해 회의적임
     * 나이 확인과 사생활 보호를 동시에 할 수 있는 해결책이 필요함
          + 문제는 나이가 아니라 정보 수집일 수 있음
     * 영국에서 Discord가 나이 확인을 요구했으나 거부함
          + Deepfake 기술을 사용해 확인을 시도할 계획임
     * 인터넷 안전보다 감시가 더 큰 목적임
          + 부모가 자녀의 온라인 활동에 더 관여해야 함
          + 온라인 회사는 안전한 환경을 제공해야 함
          + 성인 콘텐츠는 별도의 공간에서 제공해야 함
     * 소셜 미디어에 대한 의무적인 ID 확인이 최종 목표일 수 있음
          + 경찰이 법원 명령을 통해 접근할 수 있음
     * 자녀의 얼굴을 제3자 서비스에 스캔하는 것을 원치 않음
          + 금융 회사의 KYC 확인도 거부한 경험이 있음
"
"https://news.hada.io/topic?id=20419","사이버 보안 업계의 귀청이 터질 듯한 침묵","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        사이버 보안 업계의 귀청이 터질 듯한 침묵

     * 크리스 크렙스는 2020년 미국 대선의 보안을 보장한 후 해고된 전 CISA 국장임
     * 트럼프 대통령은 크렙스를 대상으로 한 행정 명령을 발행하여 그를 조사하고 연관된 기업과의 계약을 제한하려 함
     * 이 명령은 헌법적 우려를 불러일으키며, 사이버 보안 업계는 대부분 침묵을 유지하고 있음
     * 침묵은 동의로 간주될 수 있으며, 이는 권위주의를 조장할 위험이 있음
     * 사이버 보안 업계는 원칙을 지키기 위해 목소리를 내야 할 시점에 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

크리스 크렙스와 2020년 대선

     * 크리스 크렙스는 트럼프 대통령이 임명한 CISA 국장으로, 2020년 대선의 보안을 보장하는 역할을 수행했음
     * 대선 후, 크렙스는 선거가 ""미국 역사상 가장 안전한 선거""라고 선언했으며, 이로 인해 트럼프 대통령에 의해 해고됨
     * 이후 크렙스는 행정 명령의 대상이 되어, 그와 연관된 기업과의 연방 계약이 제한됨

행정 명령의 법적 문제

     * 행정 명령은 헌법의 제1조 수정안과 적법 절차를 침해할 가능성이 있음
     * 법률 전문가들은 이 명령이 개인의 보호된 발언을 처벌하는 것으로, 헌법적 문제를 제기한다고 경고함
     * 헌법은 입법부가 개인을 처벌하는 법안을 발행하는 것을 금지하며, 이는 행정부에도 적용될 수 있음

사이버 보안 업계의 침묵

     * 사이버 보안 업계는 크렙스 사건에 대해 대부분 침묵을 유지하고 있음
     * 일부 전문가들은 목소리를 내고 있지만, 대다수는 침묵을 선택하고 있음
     * 침묵은 권위주의를 조장할 수 있으며, 이는 업계의 원칙과 상반됨

침묵의 위험

     * 침묵은 동의로 간주될 수 있으며, 이는 권위주의를 조장할 위험이 있음
     * 역사적으로 침묵은 종종 더 큰 문제를 초래했으며, 이는 현재 상황에서도 마찬가지임
     * 업계는 원칙을 지키기 위해 목소리를 내야 할 시점에 있음

목소리를 내야 할 시점

     * 사이버 보안 업계는 원칙을 지키기 위해 목소리를 내야 함
     * 침묵은 더 큰 비용을 초래할 수 있으며, 이는 업계의 원칙과 상반됨
     * 업계는 현재 상황에서 리더십을 발휘해야 함

        Hacker News 의견

     * 많은 사람들이 이러한 사건에 무관심하거나 현실 TV처럼 취급하는 경험이 있음
          + 역사적이고 나쁜 상황에 처해 있을 수 있다는 설득 시도는 적대적으로 받아들여짐
          + 대부분은 뉴스의 재정적 부분에만 관심을 가짐
     * 헌법은 의회가 재판 없이 개인을 처벌하는 법을 제정하는 것을 명시적으로 금지함
          + 이 제한은 입법부에 적용되지만, 그 정신은 여기에도 적용됨
          + 대통령이 단순히 정치적 내러티브에 반대한다고 해서 국가의 적으로 선언할 수 없음
          + 이는 국가 안보가 아니라 권위주의임
     * 모든 행정 명령은 권위주의적일 수 있음
          + 누구에게 이 권한을 줄지 매우 신중해야 함
     * Whitehouse.gov의 인용문이 매우 놀라움
          + 이는 단순한 보복으로 보임
     * 사이버 보안 업계의 침묵이 놀라움
          + DOGE에 대한 이야기 아님
     * 최근 몇 년간 정부의 엘리트 지도자들이 불법적으로 발언을 검열하고 영향력을 남용함
          + 행정부도 정부의 한 부서임
     * 기업의 공식 성명은 없지만, 업계 사람들은 우려와 분노를 느낌
          + 사기업에 리더십을 맡기지 말아야 함
     * 단순히 정직과 자부심을 가지고 일을 올바르게 수행하는 것이 동기부여가 될 수 있다는 생각이 현재 미국 행정부에 낯설게 보임
          + 냉소적이고 비도덕적인 세계관을 가진 사람들이 많은 권력을 휘두르는 것이 불쾌함
          + 이 행정부가 미국 인구의 큰 부분을 대표한다는 것이 더 무서움
     * 미국을 사랑하고, 친구와 가족이 있으며, 여러 번 방문했음
          + 긍정적인 경험과 행정부의 잔인한 행동을 지지하는 사람들 사이의 괴리를 이해하기 어려움
          + 이는 인간의 선함에 대한 믿음을 흔들었음
     * 원본 기사가 삭제된 것 같음
          + 웹 아카이브 링크 제공
     * 행정부를 법정에 고소해야 함
          + 다른 방법이 없음
          + 매우 끔찍함
"
"https://news.hada.io/topic?id=20446","Zig의 comptime이 하지 않는 일들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Zig의 comptime이 하지 않는 일들

     * Zig의 comptime 기능은 매우 강력한 컴파일 타임 평가 기능을 제공하지만 의도적으로 제한적임
     * 컴파일 타임 코드 실행 시 호스트 정보에 접근 불가능, 크로스 컴파일에 적합한 설계임
     * 동적 코드 생성, DSL, RTTI, I/O 등은 지원하지 않음, 대신 명시적인 타입 기반 코드 특수화 사용
     * RTTI는 직접 구현 가능, 단 컴파일 타임에만 존재하는 타입 정보를 런타임에 사용할 수 있게 재구성 가능함
     * comptime으로 새 타입 생성 가능하지만 API 확장은 불가, 사용자 정의 메서드 추가는 불가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Zig의 comptime이 하지 않는 일들

     * Zig의 comptime은 제네릭, 조건부 컴파일, 직렬화, ORM 등 강력한 기능을 제공함에도 불구하고 일부 기능은 명시적으로 제한됨
     * 그 제한들이 오히려 Zig의 설계를 간결하고 예측 가능하게 만듦
     * 호스트 정보 접근 불가 (No Host Leakage)
          + comptime 코드는 코드가 실행되는 시스템이 아닌, 타겟 플랫폼을 기준으로 동작
          + Zig에서는 컴파일 타임에 호스트 시스템의 엔디안, 포인터 크기 등 정보를 사용할 수 없음
          + 이는 크로스 컴파일을 고려한 안전성 확보 목적
          + 예시 코드에서 BF16 형식 숫자의 바이트 출력이 타겟 플랫폼에 따라 다름
     * 문자열 기반 코드 생성 없음 (No #eval)
          + Zig은 C의 #include, D 언어의 mixin, Rust 매크로처럼 동적으로 코드를 생성하는 기능을 제공하지 않음
          + 대신 comptime 인자 기반의 부분 평가(partial evaluation) 지원
          + 특정 인자가 컴파일 타임에 알려져 있으면, 해당 분기만 살아남아 코드 최적화 가능
     * DSL 문법 확장 불가 (No DSLs)
          + Zig에서는 Lisp, Rust처럼 사용자 정의 구문(syntax)을 만드는 기능이 없음
          + 모든 데이터는 Zig 문법에 따른 값(value) 형태로만 전달됨
          + 포맷 문자열(printf)처럼 제한된 DSL은 comptime 문자열로만 구현 가능
     * 런타임 타입 정보 없음 (No RTTI)
          + Zig은 Python 같은 동적 언어처럼 동작할 수 있지만, 타입 정보는 오직 comptime에만 존재
          + 런타임에서도 동작하도록 하려면 직접 RTTI 구조체를 정의하고, 포인터로 조작해야 함
          + 예: struct 필드의 이름과 오프셋 정보를 담은 RTTI 구조체 정의 후, 포인터로 필드에 접근
     * 새 API 생성 불가 (No New API)
          + Zig에서는 comptime으로 새 타입을 만들 수는 있지만, 이 타입에 메서드를 추가할 수 없음
          + Rust의 derive macro처럼 API를 확장할 수 없음
          + JSON 직렬화 구현 시 .to_json() 메서드를 추가할 수 없고, 전역 함수에 타입 인자를 넘기는 방식으로 구현
     * 컴파일 타임 IO 없음 (No IO)
          + Zig의 comptime은 파일 시스템, 네트워크, 데이터베이스 등 외부 리소스 접근을 금지
          + 이로 인해 재현 가능성, 안전성, 캐시 활용성이 높아짐
          + IO가 필요하면 build 시스템인 build.zig을 사용하여 사전 생성된 Zig 코드 import 방식 사용
     * 정리: El Disco (추상화와 단순성의 균형)
          + Zig은 강력한 메타프로그래밍 기능을 제공하면서도, 매우 제한적인 설계를 통해 예측 가능성을 확보
          + 이 제한 덕분에 Zig의 comptime은 실용적이며, 이해하기 쉬운 형태로 유지
          + 복잡한 추상화 없이도 실제 사용에 유용하며, 선언된 기능만 명확히 작동

        Hacker News 의견

     * Zig의 comptime은 독특한 특징을 가짐
          + 다른 언어에서 다양한 기능을 대체함
          + 참조 투명성을 가짐으로써 이해하기 쉬움
          + introspection을 통해 강력한 기능을 제공함
          + Lisp와는 다른 방식으로 간단하면서도 강력한 코드 작성 가능성 제공
          + 새로운 디자인과 접근 방식을 가진 언어는 드물음
     * Zig의 comptime의 단점과 해결책
          + zig build를 통해 코드 생성 후 @import하여 컴파일함
          + 더 많은 자유와 무제한 실행 시간을 제공하지만 zig 타입을 현재 컴파일에서 값으로 생성할 자유는 없음
          + 과거 Perl과 Tcl을 C로 연결하던 경험과 유사함
          + zig 커뮤니티의 자기 비판적인 태도가 때때로 당황스러움
     * Borges의 이야기에서 인용된 스페인어 문구는 노르웨이 신에 관한 것임
     * comptime의 유연성
          + 작업 중 타입 정보가 필요할 때 함수 매개변수에 추가 가능
          + 특정 상황에서 타입 제공이 불가능할 때 설계 문제 해결 필요
     * Zig의 comptime 기능의 유명한 점
          + 제네릭, 조건부 컴파일, 서브타이핑, 직렬화, ORM 등 다양한 기능 제공
          + 다른 언어에서도 유사한 컴파일 타임 평가 기능이 있음
     * 교육적인 블로그 게시물
          + 'comptime for'와 'inline for'의 차이점 설명
          + inline 버전은 comptime에서만 길이를 알 수 있음
     * Zig 언어와 도구에 대한 긍정적인 의견
          + Rust와 같은 안전 모드가 있었으면 좋겠음
          + C/C++보다 훨씬 발전된 단계임
          + Zig 컴파일러에 깊은 인상을 받음
     * Zig의 comptime에 대한 흥미로운 점
          + 컴파일 타임에 타입을 값으로 표현할 수 있는 능력
          + 런타임 오버헤드 없이 동적 언어나 런타임 반영을 근접하게 구현 가능
     * 컴파일 타임 코드 실행에 대한 혼란
          + 컴파일 타임 코드가 실제로 로컬 호스트 머신에서 실행되는지에 대한 의문
          + Zig가 호스트 플랫폼을 숨기는 이유에 대한 궁금증
          + Zig의 cross-compile 기능에 대한 긍정적인 의견
"
"https://news.hada.io/topic?id=20426","Luxury 산업 보고서 - 럭셔리 시장의 변화와 미래 성장 전략","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Luxury 산업 보고서 - 럭셔리 시장의 변화와 미래 성장 전략

     * Bain&Company에 따르면, 2024년 전 세계 럭셔리 소비는 총 €1.48T(2330조원)를 기록, 2023년 대비 1~3% 감소함
     * 럭셔리 시장은 럭셔리 자동차, 개인 명품, 럭셔리 호스피탈리티 세 가지 주요 부문이 전체 시장의 80% 를 차지함
     * 경험 기반 럭셔리(여행, 소셜 이벤트) 소비 증가, 반면 개인 명품 시장은 15년 만에 처음으로 위축됨
     * 특히 Z세대 소비자의 럭셔리 브랜드에 대한 선호도가 줄어들면서, 최근 2년간 럭셔리 고객층이 약 5천만 명 감소함

지역별 시장 동향

     * 아시아 태평양
          + 일본은 환율 효과와 관광 소비 증가로 가장 빠른 성장 기록
          + 중국 본토는 소비자 신뢰 저하와 해외 관광 증가로 인해 급격한 둔화를 보이며, 2024년 매출 20~22% 감소
     * 유럽 및 중동
          + 유럽은 관광객 유입 증가로 성장세 유지했으나, 영국과 북유럽은 관광 수요 부진과 현지 소비 둔화로 어려움
          + 중동 시장은 UAE(아랍에미리트) 강세 속에서 지역별로 다른 성과를 기록함
     * 미주 지역
          + 미국은 소비자 신뢰 변동에도 불구하고 분기별로 개선되는 성장세
          + 캐나다는 중국 관광객 감소로 부진, 멕시코와 브라질은 긍정적인 성장 기록
     * 신흥 시장
          + 2030년까지 라틴아메리카, 인도, 동남아시아, 아프리카에서 5천만 명 이상의 럭셔리 소비자 추가 유입 예상

유통 채널 트렌드

     * 아울렛 매장이 정가 매장을 압도하며 주요 소비 채널로 자리 잡음
     * 온라인 채널은 팬데믹 이후 정상화되며 20% 시장 점유율 유지
     * 중고 명품 시장은 7% 성장(48억 유로 규모), 젊은 층과 가치 소비 트렌드로 인해 더욱 확산됨

카테고리별 성과

     * 화장품(특히 향수) 및 아이웨어(안경) 부문이 3~5% 성장하며 소형 사치재 선호 증가
     * 쥬얼리 시장은 견고한 성장, 반면 시계, 가죽 제품, 신발은 수요 둔화
     * 럭셔리 자동차 시장 5% 감소, 고급 모델 수요는 유지되었으나 중간급 시장 둔화
     * 럭셔리 호텔 및 호스피탈리티 4% 성장, 맞춤형 경험 제공이 핵심 요인

소비자 동향 및 변화

     * 럭셔리 시장의 총 고객 수 5천만 명 감소, 총 3.5억 명으로 축소
     * 최상위 고객층(VIP)은 전체 소비의 45% 차지(2021년 35%에서 증가)
     * Z세대 소비자의 럭셔리 브랜드 충성도 감소, 서구 및 일본에서 더욱 뚜렷
     * 50% 이상의 소비자가 럭셔리 브랜드의 가격이 지나치게 높다고 인식

2025년 이후 전망

     * 2025년 럭셔리 시장은 저성장(0~4%) 예상되며, 2030년까지 연평균 4~6% 성장 전망
     * 온라인 및 모노브랜드 스토어가 2030년까지 주요 유통 채널로 자리 잡을 것
     * AI 및 기술 혁신을 활용한 맞춤형 경험 제공이 핵심 경쟁력으로 부상
     * 브랜드들은 정체성을 강화하고, 고객과 감성적 유대감을 구축하며, 차별화된 제품과 경험을 제공하는 전략이 필요

결론

     * 럭셔리 시장은 2024년 소폭 둔화되었으나 장기적으로 2030년까지 2조~2.5조 유로 규모로 성장할 전망
     * 브랜드는 기술 혁신, 창의성, 소비자와의 관계 강화를 통해 지속 가능한 성장을 위한 전략적 재편이 필요
"
"https://news.hada.io/topic?id=20469","카메라를 샀다고 생각했지만, DJI가 판매한 것은 사용 라이선스였다 [동영상]","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              카메라를 샀다고 생각했지만, DJI가 판매한 것은 사용 라이선스였다 [동영상]

        Hacker News 의견

     * 모든 기기 제조업체가 앱 설치, 추적, 등록 등을 의무화하는 것을 금지해야 함
          + 모든 TV, 전화, 카메라, 태블릿, 냉장고 등이 최악의 SF 디스토피아처럼 감시 장치가 되고 있음
          + 회사가 지원을 중단하면 기기가 쓰레기가 되어 환경을 오염시키고, 다음 제품을 판매하려 함
          + 규제가 10년 전에 나왔어야 했음
          + 우리는 아무것도 소유하지 않고, 사생활도 없으며, 24/7 제품이 판매됨
          + 이러한 기업 감시로부터 보호해 줄 정부에 투표할 것임
          + 봉건제가 사라진 것처럼 이 기술 봉건제도 사라질 것임
     * 내 세탁기는 앱 설치 없이는 완전히 사용할 수 없으며, GPS 추적 권한을 요구함
          + HomeWhiz라는 앱이 필요함
          + 새로운 하드웨어가 이러한 요구를 하지 않도록 법이 있어야 함
          + 이런 종류의 미끼와 몸값 요구에 대해 집단 소송을 제기하는 절차가 더 간단해지면 좋겠음
     * 액션 카메라 시장은 현재 약간 혼란스러움
          + 다른 브랜드들이 GoPro를 따라잡았고, 일부는 더 뛰어나다고 말함
          + DJI와 Insta360은 인플루언서와 기술 리뷰어에게 무료 제품을 제공함
          + 소비자로서 어떤 제품을 구매해야 할지 결정하기 어려움
     * 미국은 문화적 자율성이 부족해 보임
          + 미국 회사들은 중국 시장에 접근하기 위해 영화와 게임을 검열하는 것을 괜찮게 여김
          + 중국 회사들은 미국 소비자들의 감수성을 고려하여 제품을 수정하지 않음
          + 중국에서는 일상적으로 감시와 제한된 재산권 보호가 이루어짐
     * 나는 오늘까지 ""시니어 폰""을 사용했음
          + 앱 설치가 불가능한 일반적인 키패드 폰임
          + 여러 제품과 서비스를 사용할 수 없었음
          + 결국 편리함을 선택했음
     * 비디오를 보지 않았지만, 어떻게 이런 것을 ""판매""할 수 있는지 궁금함
     * 호주 구매자는 소비자법에 따라 즉시 환불을 받을 수 있어야 함
          + ""불공정 계약 조건""에 대해 소비자법을 활용할 수 있음
     * 구매하지 않을 제품 목록이 늘어남
          + 다음에 구매할 망치가 인터넷 연결이 끊기면 이상해지지 않기를 바람
     * Ricoh GR III를 구매했음
          + 앱이 별로 좋지 않으며, 데이터 수집/공유 조건이 끔찍함
          + Android에서는 앱의 네트워크 접근을 차단할 수 있음
     * 물리적 제품에 대한 라이선스는 존재하지 않음
          + 회사는 물리적 제품을 특정 방식으로 사용하도록 강요할 수 없음
"
"https://news.hada.io/topic?id=20406","Microsoft, CPU에서 실행가능한 초고효율 AI 모델 BitNet 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Microsoft, CPU에서 실행가능한 초고효율 AI 모델 BitNet 개발

     * Microsoft 연구진이 BitNet b1.58 2B4T라는 초효율적인 AI 모델을 개발했음
     * 1비트 양자화를 통해 높은 속도와 낮은 메모리 사용량 달성하여 CPU에서도 실행 가능하며 MIT 라이선스로 공개됨
     * Apple M2 같은 CPU에서도 실행 가능하며 GPU 없이 작동함
     * 20억 개의 파라미터를 가진 BitNet b1.58 2B4T는 Meta, Google, Alibaba 모델보다 성능이 뛰어남
     * 다만, Microsoft의 bitnet.cpp 프레임워크를 사용해야 하며, GPU와의 호환성 문제는 여전히 존재함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Microsoft의 초경량 1비트 AI 모델 BitNet b1.58 2B4T

  초경량 모델 BitNet의 개념

     * BitNet은 1비트 양자화를 적용한 AI 모델로, -1, 0, 1 세 가지 값만을 사용하여 파라미터를 표현함
     * 기존의 양자화 모델은 일반적으로 8비트 또는 4비트로 표현되지만, BitNet은 1비트만 사용해 압도적인 메모리 효율성을 가짐
     * 이 방식은 저사양 하드웨어, 특히 GPU가 없는 CPU 환경에서 큰 이점을 가짐

  BitNet b1.58 2B4T의 특징

     * 파라미터 수: 20억 개
     * 학습 데이터: 4조 토큰 (약 3,300만 권의 책 분량)
     * MIT 라이선스로 오픈소스 공개됨
     * Apple M2 CPU와 같은 범용 CPU에서도 작동 가능

  성능 비교와 벤치마크 결과

     * BitNet b1.58 2B4T는 다음 모델들보다 일부 벤치마크에서 우수한 성능을 보임:
          + Meta Llama 3.2 1B
          + Google Gemma 3 1B
          + Alibaba Qwen 2.5 1.5B
     * 사용된 주요 벤치마크:
          + GSM8K: 초등학교 수준 수학 문제 평가
          + PIQA: 물리적 상식 추론 능력 평가
     * 일부 테스트에서 최대 2배 빠른 속도, 메모리 사용량은 현저히 적음

  제한 사항 및 호환성 문제

     * BitNet의 성능은 Microsoft의 전용 프레임워크인 bitnet.cpp 에 의존함
     * bitnet.cpp는 현재 특정 CPU만 지원, GPU는 미지원
     * 이로 인해 AI 인프라 표준인 GPU 환경과의 호환성 부족이 단점으로 지적됨

     BitNet은 1비트 양자화를 적용한 AI 모델로, -1, 0, 1 세 가지 값만을 사용하여 파라미터를 표현함

   값이 3개인데 1비트? 이상하다고 생각해서 HN 댓글 좀 봤는데,

     https://compilade.net/blog/ternary-packing

   1바이트당 2개 값을 표현하는 8개 비트 대신 3개 값을 표현하는 5개의 ternary digit로 다루기 때문에 엄밀하게 1비트 모델은 아니고, log(3) / log(2) = 1.5849...비트 모델이네요. 모델 이름에 b1.58 포함된거 보면 이게 맞는거 같습니다.

   4번째 줄의 2억 개의 파라미터를 -> 20억 개의 파라미터를 수정이 필요하네요.

        Hacker News 의견

     * Microsoft의 BitNet은 FP16 또는 BF16과 같은 정밀도를 가진 Transformer LLM과 동일한 모델 크기와 학습 토큰을 사용하면서도 지연 시간, 메모리, 처리량, 에너지 소비 측면에서 비용 효율적임
          + GitHub 링크와 arXiv 논문을 통해 더 많은 정보를 얻을 수 있음
     * AI 모델의 ""파라미터 수""는 AI 모델의 ""GHz""와 같음
          + 비교된 모든 모델은 10-20억 개의 파라미터를 가지고 있지만 실제 크기는 10배 이상 차이가 날 수 있음
     * 대부분의 무료 LLM은 CPU에서 실행 가능함
          + 이 모델이 CPU에서 유용하게 빠르게 실행된다는 주장임
          + GPU에서의 실행 속도를 알 수 없어 이 주장에 대한 정확성을 확신할 수 없음
     * BitNet b1.58 2B4T 모델은 동일한 크기의 다른 모델보다 빠르며, 메모리 사용량이 적음
          + 모델 크기는 1GB 이상이며, 현대적인 CPU에서도 잘 작동하는 1-2GB 모델이 많음
     * NVidia는 CUDA를 통해 소프트웨어 수준의 잠금을 서두르고 있음
          + 그렇지 않으면 주식이 Zoom과 같은 길을 갈 수 있음
     * ""1-bit""이라고 부르지만 실제로는 {-1, 0, 1}을 사용함
          + 이 부분에 대해 혼란스러울 수 있음
     * 더 큰 모델을 BitNet으로 증류할 수 있는 라이브러리가 있는지 궁금함
     * MIT 라이선스 하에 공개적으로 사용 가능하며, Apple의 M2를 포함한 CPU에서 실행 가능함
          + M2는 이미 7GB 또는 13GB의 LLama 및 Mistral 모델을 쉽게 실행함
     * M 시리즈와 MacBook이 널리 퍼져 있어 평균 CPU(i3 또는 i5)가 얼마나 약한지 잊고 있을 수 있음
     * 가격 전쟁은 계속해서 바닥을 칠 것임
     * 1년 이상 지난 기술로, 모든 사람이 이 기술로 전환하지 않았음
          + 이유를 살펴보면, 이 기술이 실제로 지표에 영향을 미치며, 일부는 다른 것보다 더 큰 영향을 미침
          + 만능 해결책은 아님

   4번째 줄 비교된 모든 모델은 1-2억 개의 -> 비교된 모든 모델은 10-20억 개의
   AI의 billion 번역이 이상하네요.
"
"https://news.hada.io/topic?id=20396","Gemini 2.5 Flash 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Gemini 2.5 Flash 출시

     * Gemini 2.5 Flash는 Google AI Studio와 Vertex AI를 통해 제공되는 하이브리드 추론 모델로, 속도와 비용을 유지하면서 추론 능력을 크게 향상시킴
     * 생각(on/off) 기능과 thinking_budget 설정을 통해 성능, 비용, 지연 시간을 세밀하게 조절 가능함
     * 생각 예산을 설정하여 모델이 생성할 수 있는 최대 토큰 수를 세밀하게 조절할 수 있으며, 복잡한 작업에 대해 더 정확하고 포괄적인 답변을 제공함
     * 낮은 비용 대비 높은 성능을 제공하는 Google의 가장 비용 효율적인 추론 모델이며, 다양한 사용 사례에 맞춰 유연한 조절이 가능함
     * 현재 Google AI Studio, Vertex AI에서 미리보기 형태로 사용 가능, API에서도 설정 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Gemini 2.5 Flash 미리보기 출시

     * Google은 Gemini 2.5 Flash를 Google AI Studio와 Vertex AI를 통해 미리보기(preview) 형태로 공개함
     * 기존 2.0 Flash보다 추론 능력이 대폭 향상되었으며, 속도와 비용 효율성은 유지
     * 최초의 완전한 하이브리드 추론 모델로, 개발자가 생각(thinking) 모드를 켜거나 끌 수 있음
     * thinking_budget 설정으로 품질, 비용, 응답 지연 시간 간의 균형을 조절 가능
     * 생각 모드가 꺼져 있어도 2.0 Flash보다 향상된 성능을 유지함

Gemini 2.5 Flash의 추론 기능

     * Gemini 2.5 Flash는 답변을 바로 생성하지 않고, 생각을 먼저 진행하는 구조
     * 복잡한 문제나 수학 문제, 연구 분석 질문 등에 대해 더 정확하고 포괄적인 답변 생성
     * LMArena의 Hard Prompts 벤치마크에서 2.5 Pro 다음으로 높은 성능을 보임
     * 타 모델 대비 저렴한 가격과 작은 모델 크기로 비슷한 성능 제공

가장 비용 효율적인 추론 모델

     * Gemini 2.5 Flash는 가격 대비 성능이 가장 우수한 추론 모델로 평가됨
     * Google의 **품질 대비 비용 효율성 곡선(Pareto frontier)**에 새롭게 포함됨

생각 조절 기능: thinking_budget

     * 다양한 활용 사례에 맞춰 품질, 비용, 지연 시간 간의 세밀한 조절 기능 제공
     * thinking_budget은 모델이 생각에 사용할 수 있는 최대 토큰 수를 의미함
          + 예: budget을 높이면 품질이 향상되지만, 비용 및 지연 시간이 증가함
     * 생각이 필요 없는 단순한 질문에는 낮은 budget을 자동 적용함
     * budget 범위는 0 ~ 24,576 토큰이며, AI Studio 및 Vertex AI에서 슬라이더나 API 파라미터로 조절 가능

  생각 수준에 따른 예시 프롬프트

    낮은 수준의 추론 필요

     * “Thank you” in Spanish
     * 캐나다의 주(Province) 수 묻기

    중간 수준의 추론 필요

     * 두 개의 주사위를 굴려 7이 나올 확률 계산
     * 일정을 기반으로 주중에 농구 5시간 가능한 시간표 작성

    높은 수준의 추론 필요

     * 보의 기계공학적 응력 계산 문제
     * 엑셀 스타일 수식 평가 함수 작성 문제
          + 의존성 해결, 연산자 우선순위, 순환 검출 필요

시작하기

     * Google AI Studio, Vertex AI, Gemini 앱에서 preview 버전 사용 가능
     * thinking_budget 파라미터 실험을 통해 복잡한 문제 해결 가능성 탐색
     * 코드 예시:
from google import genai

client = genai.Client(api_key=""GEMINI_API_KEY"")

response = client.models.generate_content(
  model=""gemini-2.5-flash-preview-04-17"",
  contents=""You roll two dice. What’s the probability they add up to 7?"",
  config=genai.types.GenerateContentConfig(
    thinking_config=genai.types.ThinkingConfig(
      thinking_budget=1024
    )
  )
)

print(response.text)

     * 자세한 내용은 개발자 문서와 Gemini Cookbook에 있음
     * 앞으로 더 많은 기능이 추가될 예정이며, 정식 출시 전까지 지속적인 개선 예정

        Hacker News 의견

     * Google이 Gemini 2.5 Pro(실험적)를 무료로 제공하는 것은 큰 사건이었음. 나는 OpenAI의 더 비싼 모델을 사용해본 적이 없어서 비교할 수는 없지만, 과거에 사용했던 무료 모델과 비교했을 때 Gemini 2.5 Pro는 상당한 발전을 보여줌. 이 모델은 내가 다루는 대부분의 주제에서 나보다 더 똑똑하며, 나에게 동의하려고 애쓰지 않고 나와 논쟁을 벌임. 이제 나의 모든 캐주얼한 AI 사용은 Gemini에 집중되어 있으며, 깊이 있는 주제에 대해 질문하는 것이 기대됨. 나는 이 모델의 가치를 높이기 위해 새로운 도구를 만들고 있음
     * Gemini 모델의 종종 간과되는 기능 중 하나는 API를 통해 직접 Python 코드를 작성하고 실행할 수 있다는 점임. 나의 llm-gemini 플러그인은 이를 지원함: GitHub 링크. 코드를 실행하는 데 추가 비용이 들지 않으며, 입력 및 출력 토큰에 대해서만 비용을 지불함. 예를 들어, 10개의 입력과 1,531개의 출력을 사용하여 0.536센트의 비용이 들었음
     * Gemini flash 모델은 가장 주목받지 못하지만, 실제 사용에서는 비용 대비 성능이 가장 뛰어나며 멀티모달 도구를 제공함. Google은 조용히 AI 경쟁에서 승리하고 있음
     * Gemini 2.5 Flash의 문서를 깊이 탐구할 때 숨겨진 정보: 이미지 입력에 대해 모델은 관련 주제의 2D 경계 상자를 생성할 수 있을 뿐만 아니라 세분화 마스크도 생성할 수 있음. 이 가격대에서 Flash 모델로 세분화 마스크를 생성하는 것은 꽤 멋짐. 세분화 마스크는 마스크를 나타내는 b64 문자열을 생성하여 구현됨
     * 프로그래머가 아닌 나에게 Google은 놀라울 정도로 훌륭해지고 있음. 처음부터 작동하는 코드를 제공함. 웹사이트의 데이터를 스크랩하여 분석하는 코드를 작성해달라고 요청했을 때, 데이터를 스크랩하고 분석하는 코드를 작성했음. 기본적인 데이터 분류 및 집계였지만 기대하지 않았음
     * Google의 더 많은 혁신. OpenAI는 두 가지 주요 문제가 있음. 첫째, Google의 수직 통합된 칩 파이프라인과 AI 칩을 생산하는 데 필요한 깊은 공급망 및 운영 지식. 이는 모든 단계에서 엄청난 비용 우위를 제공함. 둘째, 데이터 부족과 소셜 미디어가 지속적으로 갱신되는 지식의 원천으로서 가지는 불공정한 이점. 새로운 데이터가 점점 더 가치 있는 차별화 요소가 되고 있음. SamA는 이러한 문제를 인식하고 있으며, OpenAI가 성공할지 여부를 결정하는 데 근본적인 문제로 보고 있음
     * Gemini 2.0 Flash에서 50% 가격 인상. 이는 많은 것처럼 들리지만, Flash는 여전히 이 품질의 다른 모델과 비교했을 때 매우 저렴함
     * Python API 라이브러리 코드에서 흥미로운 점 발견: GitHub 링크. thinking_budget는 문서화되어 있지만, include_thoughts는 무엇인지 이해하기 어려움. 이 옵션을 사용하여 Gemini가 생각 요약을 반환하도록 하는 방법을 찾지 못했음
     * Google이 API와 무료 AI Studio를 통해 인상적인 모델을 제공하면서도 Gemini 앱에서 사용되는 모델은 훨씬 나빠 보임. 최근 몇 주 동안 Workspace 계정에서 Gemini Advanced를 사용해왔는데, 모델이 더 짧은 시간 동안 생각하고 더 짧은 출력을 제공하며, 컨텍스트 윈도우도 광고된 100만 토큰과는 거리가 멀어 보임. Google이 의도적으로 Gemini 앱을 제한하고 있는 것 같음
     * 내부 PDF(3페이지, 중간 난이도)를 json 벤치마크로 실행했을 때:
          + gemini-flash-2.0: 약 60% 정확도, 6,250 페이지당 1달러
          + gemini-2.5-flash-preview (생각 없음): 약 80% 정확도, 1,700 페이지당 1달러
          + gemini-2.5-flash-preview (생각 있음): 약 80% 정확도, 350 페이지당 1달러
          + gemini-flash-2.5: 약 90% 정확도, 150 페이지당 1달러
          + 생각 변형을 일반 변형과 분리했으면 좋겠음. 모델 매개변수가 가격에 큰 영향을 미칠 때 매우 혼란스러움
"
"https://news.hada.io/topic?id=20494","왜 VC들은 채용 스타트업을 싫어하는가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         왜 VC들은 채용 스타트업을 싫어하는가

     * Recruiting 스타트업은 경기 순환성과 수익 예측 불가로 VC 투자에 부적합한 구조임
     * 성과 측정이 모호하고 고객(스타트업)들이 채용에 미숙하여 제품 효과를 증명하기 어려움
     * 사용자들은 성과보다 ‘노력’이 보이는 도구를 선호하고, 자동화는 오히려 저항에 부딪힘
     * 도구 간 차별성이 떨어지고 경쟁이 치열, 독점적 관계 형성이 거의 불가능함
     * 성장할수록 사용자와 후보자 품질 간 역상관 관계(네거티브 네트워크 효과) 가 발생함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

왜 벤처캐피탈은 채용 스타트업을 꺼리는가

     * 2019년에 Dover를 창업하며, 채용 시장에 자동화와 알고리듬 도입은 명백한 기회라고 느꼈음
     * 그러나 투자자들은 감정적으로 회의적이었고, 지난 10~20년간의 실패 사례들이 이를 뒷받침함
     * Dover는 Founders Fund와 Tiger로부터 투자를 받았지만, 벤처 스케일로 성장하는 것이 얼마나 어려운지 체감하게 됨

1. 채용은 순환성이 극심한 산업임

     * 거시적 경기 불황이 오면 가장 먼저 줄어드는 예산이 채용임
          + 2022년 Dover 매출은 최고점 대비 70% 하락
          + 대형 채용 플랫폼도 불황기에는 매출이 30~50% 감소
     * VC는 복리 성장을 기대하지만, 채용 시장은 주기적 붕괴와 회복이 반복됨
     * 스타트업 고객은 투자 후 3개월간 집중 채용 후 9개월 정지 상태가 반복됨
          + 안정적인 수익을 만들기 어려움
          + LinkedIn이나 Greenhouse처럼 장기 계약으로 방어하는 전략이 필요

2. 채용 성과는 측정이 불가능에 가까움

     * 시간당 채용률, 채용 속도 등 지표는 존재하나, 대부분 무의미함
     * 각 채용은 고유 상황에 따라 너무 많은 변수들이 존재함
          + 역할, 단계, 시장 상황, 보상 유연성, 채용자의 참여도 등
     * 고객은 “우리 상황엔 안 맞을 것 같다”는 회의론을 가짐
     * 결과적으로 성공 경로를 측정하거나 반복하기 어려움, 직관에 의존하는 구조

3. 고객(스타트업)이 채용을 가장 못함

     * 스타트업은:
          + 예산이 적고
          + 인재 기준은 과하게 높고
          + 일정은 비현실적임
     * 프로세스는 산만하며, 1회성/즉흥적인 방식을 즐김
     * 채용 결정이 창업자에게 달려 있어, 우선순위 변경 시 채용 중단
     * 많은 경우, 채용에 실패 중인 조직일수록 외부 서비스에 더 의존하려 함 (역선택)

4. 보여주기식 지표를 충족시켜야 함

     * 실제 성과 대신 성과처럼 보이는 지표를 중시함
     * 예시: ATS를 반복 교체하거나 이메일 자동화 도구를 순환 사용
     * 사용자 요구는 종종 영향력이 미미한 기능 요청으로 이어짐
          + 예: 3번째 이메일 A/B 테스트
     * 결국 제품은 기능이 과잉 탑재되고 무거워지며, 사용자는 피로감을 느끼고 떠남

5. 독점 관계를 맺기 어려움

     * 스타트업은 여러 도구, 여러 에이전시를 동시에 사용함
     * “누가 먼저 좋은 후보를 보내느냐”가 전부
          + 제품의 장기적인 품질, 사용자 경험은 중요하지 않음
     * 채용 성공 시 원인을 특정하기 어려워, 기여도 증명 자체가 어려움

6. 자동화에 대한 저항이 강함

     * 기본적인 작업조차 자동화를 꺼림 (예: 스케줄링 이메일)
     * 이유는 다음과 같음:
          + 대체에 대한 두려움
          + 모든 과정에 대한 통제 욕구
          + 수동 작업을 통한 “노력의 증명”
          + 자동화로 성과를 내면 인력이나 예산이 줄어들 수 있다는 우려
     * 결과적으로, 효율성과 상관없이 시간 투자한 것이 설득력 있게 느껴지는 문화가 존재함

7. 채용 제품은 ‘네거티브 네트워크 효과’를 가짐

     * 플랫폼이 성장할수록 후보자 품질이 낮아짐
     * 예시: Triplebyte의 초기 성공 → 대중화 → 후보 품질 하락 → 사용자 이탈
     * 모두가 같은 풀(pool)에서 경쟁하는 구조는 매력을 떨어뜨림
     * 경쟁 우위를 위해선 차별화된 후보나 접근법이 필요, 그러나 대중화될수록 불가능해짐
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   이러한 구조적 문제들 때문에 VC들은 본능적으로 채용 스타트업에 회의적임
   채용 스타트업을 시작하려는 사람은 경쟁자뿐만 아니라 시장 구조 그 자체와도 싸워야 함
"
"https://news.hada.io/topic?id=20421","Ask GN: 자주 사용하는 셸 스니펫이 있으신가요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Ask GN: 자주 사용하는 셸 스니펫이 있으신가요?

   저는 아래 셸 스크립트나 snippet을 ~/.zshrc에 넣어두거나 alias걸어 사용하곤 하는데, 다른 분들은 어떤 스니펫을 사용하시는지 궁금해 올려봅니다.

   아래 내용은 개인 블로그: 자주 사용하는 셸 스니펫에도 적어두었는데 굳이 들어가서 보실 필요 없이 내용 전부를 붙여 넣었습니다.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  1. man 페이지를 pdf로 보기

pman() {
  mandoc -Tpdf ""$(man -w $@)"" | open -f -a Preview
}

   mac os 기준 $ pman curl처럼 사용합니다.

  2. git remote에서 삭제된 브랜치 삭제

git fetch -p && for branch in $(git branch -vv | grep ': gone]' | awk '{print $1}'); do git branch -D $branch; done

   혹은 git gone - 원격에서 삭제된 브랜치를 모두 삭제하는 커스텀 명령어 사용도 가능해 보입니다.

  3. .env에 있는 환경변수 적용

export $(grep -v '^#' .env | xargs)

   direnv를 쓰는게 더 좋긴 할텐데 습관이라 그런지 위 스니펫을 더 많이 사용하곤 합니다.

  4. 로컬에서 mysql이 잠시 필요할 때

docker run --rm -d --name mysql \
  -e MYSQL_ROOT_PASSWORD=password \
  -e MYSQL_ROOT_HOST=% \
  -p 3306:3306 \
  -v $(pwd)/mysql_data:/var/lib/mysql \
  mysql:8 \
  --character-set-server=utf8mb4 \
  --explicit_defaults_for_timestamp=true

   이후 localhost:3306으로 접속해 사용하며 볼륨 유지가 필요하지 않다면 -v 옵션은 제거해서 쓰곤 합니다.
alias enable-sudo-with-touchid=""cat /etc/pam.d/sudo && echo 'BEFORE===================\n===================AFTER' && sudo gsed -i '1i auth sufficient pam_tid.so' /etc/pam.d/sudo && cat /etc/pam.d/sudo""

   맥북에서 관리자 비밀번호를 눌러야 하는 상황 (예: sudo) 에서 Touch ID 로 진행할 수 있게 해주는 스크립트입니다.

   한번만 등록하면 되는데 왜 이게 alias 있냐... 하면, 가끔 맥 OS 버전을 업그레이드하면 이게 초기화 되더라구요.

   mysql을 잠시 띄우는 것을 앨리어스로 쓸 생각은 못해봤는데 재밌네요.
   저는 .zshrc에 이런 소소한 설정을 넣어두고 쓰고 있어요.
cpcat() {
  cat ""$@"" | pbcopy
}

   cpcat [파일명]을 실행하면 특정 파일 내용이 클립보드로 들어갑니다.
alias cb=""pbcopy""

   전 이러고 있어요 ㅋㅋ

   오 매번 pbcopy하기 귀찮았는데 좋네요! 이름이 카피캣이군요 ㅋㅋ

   3000번대 포트 중 사용하지 않는 포트를 표시합니다.
function idleports()
{
    cols=10
    count=0
    output=""""

    listening_ports=($(sudo ss -tlpn | grep -o ':30[0-9]*' | sed 's/://g' | sort | uniq))

    for port in {3000..3099}; do
        if [[ "" ${listening_ports[@]} "" =~ "" $port "" ]]; then
            output+=""\033[38;5;235m$port\033[0m  ""
        else
            output+=""$port  ""
        fi

        ((count++))
        if ((count % cols == 0)); then
            output+='\n'
        fi
    done

    if ((count % cols != 0)); then
        output+='\n'
    fi

    echo -e ""$output""
}

   아닛 이건 꿀팁이군요... 감사합니다.
"
"https://news.hada.io/topic?id=20438","게임 업계가 '탈전문화'하고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           게임 업계가 '탈전문화'하고 있음

     * 게임 업계는 지금 ‘탈전문화(deprofessionalizing)’ 현상을 겪고 있으며, 안정적인 직업 경로가 붕괴되고 있음
     * 대형 스튜디오는 인력 감축과 유통 한계, 반면 일부 인디 개발자는 단독으로 수백억 매출을 올리며 주류를 위협
     * 구직 안정성이 사라짐에 따라 노조 활동은 퇴직금 협상 중심으로 변화하고 있음
     * 일부 경력자는 자유계약자 또는 1인 에이전시 형태로 전환, 보다 유연하고 개인화된 커리어 패턴이 증가
     * 문제는 이런 모델이 극소수만의 성공에 그칠 수 있다는 점이며, 글쓴이는 앞으로 이 변화의 지속적 관찰을 예고함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

게임 업계가 ‘전문직’으로서 무너지고 있는 현상

  탈전문화란?

     * 글쓴이는 최근 게임 산업의 흐름을 설명하기 위해 ‘탈전문화(deprofessionalizing)’ 라는 표현을 사용
     * 이 용어는 처음에는 Simon Carless가 Wired 인터뷰에서 사용한 것으로,
       대기업의 과도한 확장과 그에 따른 수축이 업계 전반에 부정적 영향을 미친다고 분석함

     “게임 산업은 여러 방식으로 탈전문화되고 있다. 고소득 국가에서 안정적인 직업으로 게임 개발을 이어가기는 점점 어려워질 것이다.”

  현상: 안정적인 경력 구조의 붕괴

     * 이 분석은 직관적으로 맞아 보이며, 이미 대형 스튜디오의 인원 축소라는 형태로 현실화되고 있음
     * 많은 개발자들이 전통적인 직업 경로에서 벗어나고 있으며,
       노조의 역할은 안정적 일자리 보장보다는 퇴직금 협상으로 이동 중

  주요 원인 세 가지

    1. 구작 게임들이 신작 게임을 압도
          + 특히 라이브 서비스형 게임에서는 5년 이상 된 타이틀이 대부분의 플레이 타임을 점유
          + 예: Valorant 이후 성공적인 서구권 F2P 게임 부재
    2. 대형 스튜디오의 유통력 약화
          + 대형 퍼블리셔조차 판매를 안정적으로 유도하지 못함
    3. 인디 개발자의 역습
          + 소규모 팀 혹은 1인 개발자가 수천만 달러 이상의 매출을 단기간에 기록
          + 예: Schedule I 은 1인 개발자가 만든 얼리 액세스 게임으로 수천만 달러 수익 달성

  탈전문화 이후의 삶

     * 전통적 커리어의 붕괴는 창의적이고 조각난 커리어 경로의 부상으로 이어지고 있음
     * 예시: 유명 개발자 Aaron Rutledge는 대형 스튜디오를 떠나
       1인 에이전시를 설립하고 자유 계약 형태로 활동 중

     캠핑카에서 별 아래서 미래를 설계하며 일하는 모습은, 과거의 '직장인' 개념과는 완전히 다름

  새로운 시대: 유연함 vs 불안정함

     * 이런 자율적 커리어 모델은 일부에게는 이상적인 환경이 될 수 있음
     * 그러나 문제는 얼마나 많은 사람이 이 방식으로 지속 가능한 삶을 살 수 있느냐는 것
     * 글쓴이는 낙관과 비관 사이에서 현실적인 시선을 유지하며 이 현상을 계속 추적할 예정

     “모든 것이 무너지고 있을지도 몰라. 그래도 금이 간 틈 사이로 빛은 스며든다.”

   그냥 단순한 답인데 그걸 C레벨이 몰라서이고,
   C레벨이 모르는 이유는 같은 게이머로서 향수를 느껴봤던 사람을 그 자리에 앉힌 게 아니라 MBA, 재무, 숫자 올리기 전문가를 앉혀서 그럼.

   스타1, 디아2, 워3, 씨앤씨, 엘더스크롤 등등
   얘내에 깊게 빠져본 사람들은
   얘내가 그래픽이 화려해서 성공했다고 믿는 사람은 아무도 없음.
   걍 단순한 답을 이런 저런 어른의 사정으로 외면할 뿐..

   물론 동의하는 사람들 입장에선 PC가 이 게임을 더 낫게 만들었다고 느낄수도 있겠죠.

   하지만 그것만큼이나, 그렇게 느끼지 않는 사람들이 그것을 작품의 단점이자 자신이 즐길 수 없었던 이유로 삼는 것은 지극히 상식적인 일일 겁니다. 적어도 이렇게 비난을 받을 일은 아니죠.

   더욱이 작품의 핍진성이나 다른 중요한 것들보다 PC가 우선되는 것이, 더 나을 수 있었던 무언가를 망가뜨릴 수 있다는 사실은 PC에 의해 게임이 재미없다는 상황을 성립시키기에 충분합니다. 마치 냉전시대 대중오락들처럼요.

   PC가 '일개 정치적 사상'이라는 것에 동의하지 않는다면 논쟁거리조차 되지 않고, 동의하신다면 이렇게 다투지 않아도 충분히 이해해주실 수 있는 문제처럼 느껴지네요.

   무엇보다, 적어도 PC는 게임에 대한 전문성은 아니잖아요? 비판을 펴는 사람들은 게임에 대한 전문성보다 PC가 우선되는 많은 사례를 접해왔고 -단순한 추측이 아닌, 비판에 대한 개발사의 공식 답변으로서 - 그래서 비판적여진겁니다. 비단 게임이 아니라도 어떤 업무에서든 이건 일을 똑바로 못 한게 맞아요.

   사실 게임을 하는 가장 큰 이유는 재미이고
   대기업에서 만드는게임보다 인디게임이 더 재밌으니까 그런거 아닐까 합니다.

   탈전문화라... '전문화'를 다시 들여다 볼 필요가 있지 않을까?
   소위 말하는 '게임' 전문가들은 인간의 놀이와 즐거움이란 것에 대해 일반인보다 얼마나 더 이해하고 있는지 궁금함.

   미학적으로 인간의 직관을 이용하던 예술가들은 미의 근원에 대해 탐구하며 아키타입을 찾기 위해 무수히 많은 노력을 들였음. 이들은 감각적으로 일반인과 구분되는 전문가의 면모를 가짐. 그들의 업무적 스킬은 목적을 이루기 위한 과정에서 성취된 것.

   반면 게임 업계에서 구작을 퇴물로 만들고 트렌드를 선도하지 못하는, 즉 '즐거움'을 연구하는 게임 '전문가'들이 줄어들었다는 점에서 탈전문화라는 쪽이 훨씬 설득력 있을거임

   발로란트 이후 서양 게임 어쩌구 하는 시점에서 알못이 떠드는거 아닌가 ㅋㅋ 발로란트가 언제부터 서양겜이됨

   주요 원인 세 가지보다는 주요 동향 세 가지이지 않나요? 원문에서 a few trends라고 표현했고 전후문맥상 원인이라는 번역은 적절하지 않다고 생각합니다

   한 명의 게이머로서, 근래의 게임업계에 대한 다양한 비판에 대한 변명과 자기합리화로 밖에는 들리지 읺네요.

   본문의 이유 때문에, 발더스 게이트3는 특수하므로 AAA급 게임 개발사에 그 정도 품질을 기대하지 말라는 소리에 입을 모은건가요?

   적어도 지금 신작을 압도하는 구작게임들은 그런 변명 없이 만들어졌을겁니다.

   게임업계에만 해당하는 내용은 아닌 것 같아요
   거의 모든 업종에서 안정적인 자리는 점점 줄어드는 느낌..

   그 대형 스튜디오가 어딘진 모르겠는데 게이머 입장에서 말하자면 그냥 재미 없어서...

   최근 대형 게임사의 게임들이 화려함이나 방대함에 중점을 두는 경우가 많습니다.
   그래서 요즘 게임들이 오래된 게임들보다 더 낫다고 할 수 있는 부분들이 분명 있지만
   흡입력은 과거보다 부족한 것 같습니다.
   오히려 부족한 리소스를 최대한 활용해서 유저들이 어떤 재미를 느끼게 할 지에 집중한 인디 게임들이 대형 회사에서 발매한 게임보다 더 재미있고, 흥미로웠습니다.

   만들라는 게임은 안만들고 사상만 집어넣고 있으니 제대로 될리가

   개인적으로 이런 의견은 너무 비생산적이라고 생각합니다.
   대체 그 ""만들라는 게임""의 정체는 무엇이며 어떤 ""사상"" 때문에 게임성이 망가졌는지 궁금하네요

   과연 말하는 그 ""사상""이라는 것이 배제된 게임들은 모두 그 ""만들라는 게임"" 의 부합할까요..?
   그냥 못만든 게임하고 잘 만든 게임이 있는거죠.

   의미 없이 악질적으로 특정 내러티브를 공격하기 위한 커뮤니티에서 흔히 떠도는 말이라고 생각합니다.

   전 아주 틀린말은 아닌 것 같은데...
   재미는 뒷전이 되고 프로파간다 전달이 주가 되던 시기가 있긴 했죠.
   그나저나 가입시간을 보니. 이 댓글을 달기위해 가입하셨나봅니다..

   특정 사상 자체가 문제가아님 기존작품대비 기본급에도 못치게마감을해놓고서 그걸 사상에 기대려는식의 언플을하니 뒷탈이 안날수없지 대표적 사례중 하나가 콘코드이긴한데 사상의 문제가아니라 개발예산이 어떻게 소비되고있는가와 개발외적인 문제로인한 트러블에 대응하는 솔루션이 강화되야한다고 생각됨

   동의합니다. 재미없는데 그래픽만 좋네, 재미없는데 BM만 신경쓰네, 재미없는데 사상만 설파하네. 다 리소스는 한정돼있는데 본질은 놓치면서 쓸데없는데만 신경쓰네로 귀결할 수 있는데, 여기서는 유독 PC지적에만 예민하게 반응하는걸 자주 보게 되네요.

   PC지적에 예민하게 반응하는게 아니라, 본문과 관련없는 내용이니까 지적한겁니다.
   무엇보다 ""재밌는 게임"" 과 ""PC"" 와의 상관관계가 없으니까요

   제대로된 의견 제시 없이 계속해서 비아냥대시는 이유를 잘모르겠네요. 무엇이 문제인가요?

   우선 예를 들어보겠습니다.

   에이펙스 레전드. 제작자들의 성관련 사상이 굳이 따지려히지 않아도 느껴질만큼 매우 노골적으로 반영되어 있습니다. 그런데.. 못만든 게임일까요?

   스타듀 밸리. 논바이너리라는 성별이 있을정도로 제작자 개인의 사상(의견)이 투영된 게임입니다. 못만든 게임인가요?

   토론에서 언급괴는 사상과 사실상 대척점에 있는 포스탈2, 듀크 뉴켐 포에버는 잘만든 게임인가요?

   특정 “사상”을 담지 않은 게임은 제대로 만들어질리가 없다라고 언급하면 동의하실 수 있으실까요..?

   그냥 못만든게임에서 그런 면이 부각된 것 쁀입니다.

   못만든 게임에서 그런 면이
   부각되었다는 의견에 동의하지 않습니다.

   님 말씀대로 정치적 사상 들어가는 것
   그 자체는 문제가 아닙니다.
   그런데 이게 과해져서 게임이 아니라
   프로파간다가 되면 말이 다르죠.

   게임에서 프로파간다성이 짙어서
   불쾌감이 느껴진다면
   그건 ""재미 없는 것""이고
   그 재미 없는 게임은
   ""못 만든 게임""인 겁니다.

   또, 프로파간다 만드는 데에 집중하여
   정작 중요한 ""게임성""을 도외시했다는
   비판을 피할 수 없습니다.

   ""만들라는 게임은 안 만들고 사상만 집어넣고 있다.""

   게임이 아니라 프로파간다가 목적이 되니까 망한다는,
   지극히 당연한 소리같아요.

   이런 건 좌우를 가리지 않습니다.
   '극우 사상을 전파하겠다'고 게임을 만들어도
   같은 결과물이 나올 겁니다.

   게임이 아니라 영화같은 다른 매체에서도
   똑같습니다.
   60~80년대의 반공 영상물을 생각해 보세요.
   목적성이 프로파간다가 되니까
   작품성이 떨어지는 경향이 발생합니다.

   사실상 프로파간다인데도 재밌는 대중예술작품으로 나온 케이스가 있긴하죠. 물론 대부분이 맛이 가버린 상태라는건 저도 공감합니다. 저도 아예 부정하고 싶진 않아요.

   그 같은 명작게임을 두고 정반대의 주장도 할 수 있죠. 게임만 재미있으면 사상이 무슨 문제겠습니까. 재미는 없는데 교조적이가만 하니 문제가 되는거죠. 게임의 본질은 재미잖아요. 리니지도 발전은 없고 재탕삼탕하며 BM만 늘어놓다 욕먹고 시총 내리꽂히는 것처럼요. 그걸두고 게임성만 욕합디까?

   그리고, 가입시간으로 비아냥이라니... 뭐 여러개 아이디만들어 여론형성하는 광경 타 커뮤니티에서 여러번 목격해서 그렇습니다. 죄송하네요.

   제가 그 이야기 드린겁니다. 사상이 문제가 아니라 그냥 게임이 지독하게 재미없는거라고요..

   그 얘기 아닌데요

   ""게임만 재미있으면 사상이 무슨 문제겠습니까"" 라고 하신게 본인입니다.

   마치 프로파간다를 강요하는건 '재미없는요소'에 절대 포함될 수 없다는 듯 확정하고 계속 이야기하시니 아마 계속 평행선을 달릴 듯 하네요. 의미없는 대화는 사양합니다. 수고하세요

   재미만 있으면 사상이 뭐가 문제냐라고 했다가 사상때문에 게임이 재미없게 느껴진다고 했다가.. 평행선을 그리고 있는건 본인이십니다. 남들에게 비아냥 거리기전에 본인을 되돌아보세요

   되돌아보는거 좋아하시는 것 같은데요.. 뭐 되돌아 볼 겸 이해를 전혀 못하고 계신 것 같아서 좀 더 쉽게 풀어드릴게요.

   게임의 주 목적은 재미죠. 따라서 재미만 있으면 문제가 없습니다. 프로파간다를 노골적으로 담았건, 자연스럽게 녹였건, 아예 배제했건간에요.

   문제는 재미가 없을때죠. 재미없을때는 원인을 찾아야 하는데, 그 중하나가 프로파간다가 될 수 있다고요. 위에서도 다른분이 언급하셨듯, 목적이 전치되어 다수의 취향이 아닌 캐릭터의 디자인을 변형시킨다던가, 스토리에 방해될정도로 사건의 개연성없이 특수한 인종이나 성별을 집어넣어 사실성/ 개연성을 떨어뜨린다거나, 하면 게임의 몰입을 방해할 수 있는 요소가 충분히 됩니다. 그런데 아랫분도 그렇고, 님께서도 그렇고 아예 '사상은 게임의 재미요소와 상관관계가 없다'라고 머릿속에서 못박고 시작을 하시니 이해를 못하시는거에요.

   ""게임만 재미있으면 사상이 무슨 문제겠습니까""는 그 맥락에서 나온 이야기고요, 특정부분만 발췌해서 무기처럼 휘두르라고 적어놓은 문구가 아닙니다. 맥락을 잘 파악하시면 이야기나누기 참 편할것 같아요.

   같은 이야기 제가 이미 했습니다. 그럼 제가 한말을 오탈자 수정없이 그대로 발췌해드릴게요.
   ""그냥 못만든게임에서 그런 면이 부각된 것 쁀입니다.""

   이게 되돌아보는겁니다.

   논리 구조를 이해 못하시는데, 오탈자 수정없는 발췌가 무슨 의미가 있나 싶네요. 개발자시면 저 정도는 이해하셔야죠. 어려운 이야기도 아닌데.

   저도 복잡한 이야기 한것 아닌데 이해 못하시면 별 수 있나요?

   네네 ㅎㅎ 수고하세요

   가입시간으로 비아냥거리지마시고 건전한 토론을 부탁드립니다

   게임만 재미 있으면 사상이 무슨 상관이냐는데, 역으로 게임이 재미 없는게 사상이랑 무슨 상관이죠?
   PC함과 재미가 반비례한다는 명확한 산술적 근거가 없는 이상 둘을 엮는 시점에서 논리적 오류입니다. 그냥 본인들께서 평소에 PC한 표현을 싫어하는데 게임이 재미 없으면 그게 더 짜증난다는 사실을 인정할 필요가 있습니다.

   이해가 잘안되시나봐요. 게임이 재미있으면 사상이 녹아있어도 상관없죠. 게임의 목적은 재미니까요. 게임이 재미없는 이유가 프로파간다일 수 있죠. 스토리나 디자인등에 영향이 가니까요. 이제 이해가 좀 되시나요?

   이런 한심한 갈등조장 댓글은 달지마세요

   공론장에서까지 이런 커뮤에 뇌 위탁한 소리를 봐야하는 현실이 서글프네요…
"
"https://news.hada.io/topic?id=20435",""웹은 망가졌다" - 내 기기가 남을 공격하는 Botnet이 된다면? AI 크롤링과 숨겨진 프록시 생태계","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ""웹은 망가졌다"" - 내 기기가 남을 공격하는 Botnet이 된다면? AI 크롤링과 숨겨진 프록시 생태계

     * 일부 AI 기업들이 데이터 수집을 위해 '봇넷화된 P2P 프록시 SDK'를 앱에 삽입하여, 사용자도 모르게 이들의 웹 크롤링 인프라에 편입됨
     * 이 SDK는 사용자의 네트워크 대역폭 일부(120~150kbps)을 무단으로 '판매' 하여 개발자에게 수익(1명당 18센트)을 제공 하고, 크롤링·메일 서버 브루트포싱 등 비정상 행위를 수행
     * 이 봇넷은 수만 개의 주거용/모바일 IP를 활용해 탐지 회피, IP당 하루 1회만 공격 시도하여 fail2ban 등 보안시스템을 우회
     * 대표 사례로 Infatica SDK 등이 있으며, 이를 포함한 앱 개발자는 사실상 사용자를 봇넷에 감염시키는 셈
     * '주거용 프록시(residential proxy)' 시장이 AI 크롤링 수요로 급성장 중이며, 이는 사실상 비인가 크롤링 인프라임
     * 이러한 봇넷 구조는 신종 형태의 스텔스 사이버 공격이며, 앱 개발자가 이 생태계에 가담하고 있음
     * 글쓴이는 웹 크롤링 자체를 '웹의 기반을 공격하는 행위'로 규정하며, 개발자와 플랫폼 기업의 책임을 요구하며 모든 크롤링을 차단해야 한다고 주장
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

스텔스 봇넷, 그 정체: 봇넷 Part 1

  개인 메일 서버를 향한 봇넷의 공격

     * 글쓴이의 메일 서버가 지속적으로 SMTP 브루트포스 공격을 받음
     * 공격 목적: 계정을 탈취하여 스팸 메일 발송 시도
     * 대부분은 실패하지만, 시도 자체가 지속적이고 집요함

  봇넷의 정체: SDK를 통한 기기 감염

     * 앱 개발자에게 SDK 삽입 대가로 금전 제공
          + 예: 사용자 1인당 월 18센트
     * 이 SDK는 사용자의 트래픽 일부(120~150kbps)를 대여
     * ""P2P 프록시"" 또는 ""residential proxy""로 포장, 실제로는 사용자의 기기를 봇넷 노드로 활용

  공격의 방식: 탐지 회피형 분산 공격

     * 하루에 IP당 한 번만 로그인 시도 → fail2ban, UFW 등의 자동 탐지 우회
     * 하지만 수만 개의 IP를 보유하여 공격을 지속적이고 분산적으로 실행
     * 글쓴이는 이 방식이 표준적인 보안 도구를 무력화한다고 지적

  ASN 기준 차단의 비효율성

     * 과연 IP가 특정 통신사(ASN)에서 집중되는지 분석
          + 결과: ASN당 평균 4개 미만의 공격 IP → ASN 전체 차단은 효과 없음
     * 현재는 매일 로그 분석 → 새로운 IP 차단 명령어 이메일 전송 → 수동 차단 방식 유지

  대응 방식과 철학

     * 자동화도 가능하지만, 직접 보고 대응함으로써 패턴을 파악하고 감시 의식을 유지
     * 공격자 IP 수: 현재 약 5만 개 이상 차단 중
     * 대부분은 IPv4이며, IPv6 공격은 아직 드문 상황

  봇넷 생태계의 현실

     * ""SDK 포함 → 수익 공유""라는 합법처럼 보이는 유통 구조
     * 실제로는 사용자 트래픽을 동의 없이 활용하여 스팸, 공격, 크롤링 등에 사용
     * 이런 봇넷은 일반적인 백신이나 보안 시스템에 탐지되지 않음

  결론

     * 앱 개발자가 이런 SDK를 포함하면, 사실상 봇넷 제작에 가담하는 것
     * 일반 사용자는 이러한 SDK 포함 여부를 알 수 없으며, 자동으로 봇넷에 참여
     * 글쓴이는 이러한 문제의식을 바탕으로 웹 생태계의 무너짐을 경고

     ""나는 이게 '정상적인 SDK'라고 주장하는 기업들을 전혀 신뢰하지 않는다. 이건 봇넷이다.""
     — Jan Wildeboer, 2025년 2월
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 웹은 고장났다: 봇넷 Part 2

  웹 크롤러의 급증, 그 배경

     * 최근 AI 모델 훈련을 위한 대규모 데이터 수집 수요 증가
     * AI 기업들이 침묵 속에 모든 웹 콘텐츠를 긁어가며, 트래픽 과부하 유발
     * 일반 웹마스터와 서버 운영자들은 크롤러에 시달리고 있으나, 누가 그 크롤러를 운영하는지 모르는 경우가 많음

  봇넷의 새로운 형태: SDK를 통한 사용자 감염

     * 일부 기업은 앱 개발자들에게 'SDK 삽입 대가'로 금전 제공
     * 해당 SDK를 포함한 앱을 설치한 일반 사용자는 모르게 그들의 트래픽을 AI 크롤러용으로 사용 당함
     * 이러한 SDK는 iOS, Android, MacOS, Windows 앱에 삽입 가능

    대표 사례: Infatica

     * 웹사이트: https://infatica.io
     * 개발자 대상 설명 페이지에 ""사용자의 네트워크를 통해 크롤링 가능""하다고 홍보
     * 수백만 개의 회전형(residential/mobile) IP를 제공한다고 주장

  왜 이것이 문제인가?

     * Infatica와 같은 기업은, 자신의 고객(크롤링 목적 AI 기업 등)이 어떤 명령을 실행하는지 감시한다고 주장하지만, 실질적으로 책임 회피 구조
     * Trend Micro의 2023년 리포트에서도 유사 사례 확인됨
     * 일부는 공짜 소프트웨어에 SDK를 은밀히 심어 배포, 사용자 동의 없이 설치

  피해: 개인 사용자와 소규모 서버 모두

     * 앱 개발자: 금전적 유혹에 SDK 포함 → 사실상 악성코드 유포자
     * 사용자: 내 기기와 네트워크가 웹 크롤링 및 DDoS에 사용됨
     * 서버 운영자: 나도 모르게 과도한 요청을 받는 대상이 됨
          + 예: 글쓴이의 Forgejo 인스턴스도 봇 트래픽 과다로 비공개 전환

  '주거용 프록시'라는 포장

     * 사용자 기기를 거점으로 활용한 프록시를 ""residential IP"" 라 부름
     * Proxy 서비스 리뷰 사이트 예시:
       https://proxyway.com/reviews
     * 표면상은 '합법적인 인프라'처럼 보이나, 실제로는 무단 전파·프록시화 구조

  결론: 웹 크롤링은 이제 남용 수준

     * 글쓴이는 모든 형태의 웹 크롤링을 악의적 행위로 간주해야 한다고 주장
     * 웹 크롤러들이 웹의 토대를 공격하고 있다고 봄
     * AI가 이 구조의 핵심 동인이며, 이것이 ‘합법적’이라는 주장에 강하게 반발

  제언 및 문제의식

     * SDK를 포함한 앱 개발자들은 책임져야 함
     * Apple, Google, Microsoft 등 플랫폼 운영사들이 이 시장을 제재해야 함
     * 일반 사용자가 이를 식별하거나 차단하는 건 거의 불가능
     * 웹 운영자들은 크롤러를 기술적으로 막아보려 하지만 한계 존재

     “AI 덕분에 웹은 더 이상 믿을 수 없는 공간이 되어가고 있다. 고맙다, AI.”
     – Jan Wildeboer, 2025년 4월

        Hacker News 의견

     * 앱 개발자가 수익을 위해 3rd party SDK를 포함하는 것은 문제의 일부이며, 사용자에게 악성 소프트웨어를 제공한 책임을 져야 한다고 생각함
          + 많은 SDK가 이러한 문제를 가지고 있다고 의심함
          + 개인적으로 의존성에 대한 중독을 피하고 직접 개발하는 것을 선호함
          + 악의적인 행위자들이 현대 개발자의 의존성 중독을 이용해 함정을 설치함
     * iOS, Android, MacOS, Windows에서 앱 개발자에게 라이브러리를 포함시켜 사용자 네트워크 대역폭을 판매하는 시장이 존재함
          + Cloudflare와 Google이 CAPTCHA를 요구하는 이유와 관련이 있음
          + Play Protect, MS Defender, Apple의 안티바이러스가 이러한 악성 소프트웨어를 탐지하지 않는 것이 이해되지 않음
          + SDK 라이브러리가 사용자의 기기를 봇넷의 일부로 만드는 것은 트로이 목마의 명백한 예시임
     * 웹의 문제는 데이터가 읽기 가능하게 유지되기 위해 특정 시스템 관리자가 서버를 유지해야 한다는 것임
          + 콘텐츠 주소 모델을 사용하면 고유성 제약을 없앨 수 있음
          + AI 스크래퍼들이 데이터를 서로 공유하고 원본 소스에 부담을 주지 않음
     * 네트워크 공유 소프트웨어는 원치 않는 애플리케이션으로 분류되어야 함
          + 사용자가 설치하고 싶었던 것에 함께 설치되어 자원을 남용함
          + Wireshark를 사용해 의심스러운 활동을 확인하고 싶음
          + 이러한 행동을 하는 앱의 공개 저장소가 필요함
     * 악성 소프트웨어를 포함한 앱을 즉시 격리해야 함
          + 직접적인 피해를 주지 않더라도 악성 소프트웨어임
     * 웹 스크래핑은 남용으로 간주되어야 하며 웹 서버는 이를 차단해야 함
          + Youtube와 같은 플랫폼은 이에 동의할 가능성이 높음
     * 이러한 라이브러리를 사용하는 소프트웨어 목록을 컴파일한 사람이 있는지 궁금함
          + 피해야 할 앱을 알 수 있으면 좋겠음
     * 주거 IP 프록시는 IP 주소가 자주 변경되는 약점이 있음
          + 같은 프록시 제공자로부터 오는 IP는 쉽게 탐지될 수 있음
          + 오픈 소스 사기 방지 플랫폼을 개발 중이며, 주거 프록시에서 오는 가짜 사용자 탐지가 사용 사례 중 하나임
     * 현재까지 명확한 증거는 없지만, 이러한 행동은 쉽게 탐지될 수 있음
          + iOS는 앱의 연결을 확인할 수 있는 기능이 있음
          + Android는 이러한 기능이 없지만 pcapdroid와 같은 서드파티 방화벽을 사용할 수 있음
          + MacOS는 Little Snitch, Windows는 Fort Firewall을 사용할 수 있음
          + 이러한 앱을 사용하는 사람은 많지 않지만, 기기를 봇넷으로 사용하는 앱을 보고할 가능성이 높음
     * Pihole 등에 추가할 수 있는 c&c 서버 목록이 있는지 궁금함
"
"https://news.hada.io/topic?id=20481","arXiv의 내부 이야기 - 과학을 뒤바꾼 가장 혁신적인 플랫폼","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  arXiv의 내부 이야기 - 과학을 뒤바꾼 가장 혁신적인 플랫폼

     * arXiv는 1991년 Paul Ginsparg가 만든 오픈 액세스 과학 논문 저장소로, 지금도 전 세계 과학자들에게 가장 중요한 플랫폼 중 하나로 사용됨
     * 기존의 느리고 비싼 학술 출판 구조를 우회하여, 연구자들이 심사 전(preprint) 논문을 즉시 공유할 수 있도록 하여 과학 협업과 혁신에 기여함
     * arXiv는 단순한 자동화 스크립트에서 출발했지만, 현재는 월간 2만 건 이상의 논문 제출과 500만 명의 이용자를 갖춘 거대한 플랫폼으로 성장
     * 초기에는 비공식적이고 가볍게 운영되었으나, 이후 운영 코드 복잡성, 내부 갈등, 기술 노후화 등의 문제를 겪으며 수차례 위기를 넘김
     * 현재는 Simons Foundation의 지원과 새 리더십 아래 클라우드 이전 및 Python 코드 리팩토링이 진행 중이며, 여전히 Ginsparg는 품질 필터링 문제에 몰두 중
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

arXiv의 기원과 과학 출판 구조에 대한 도전

     * 물리학자 Paul Ginsparg는 The Godfather 의 대사를 인용하며 자신이 만든 플랫폼에서 완전히 손을 뗄 수 없는 심정을 표현함

     “Just when I thought I was out, they pull me back in!”
     “이제 겨우 빠져나왔다 싶었는데, 또다시 끌려 들어갔어!”
     * 그는 Cornell University의 교수이자 MacArthur Genius Grant 수상자로, 35년 전 동료 평가 전(preprint) 논문을 공유할 수 있는 디지털 저장소인 arXiv를 개발함
     * 현재도 arXiv.org는 고전적인 웹 1.0 스타일의 디자인과 Cornell의 상징을 유지하고 있지만, 이 단순한 외형과 달리 arXiv는 과학 지식 유통 구조에 근본적인 변화를 일으킨 플랫폼임
     * arXiv가 중단된다면, 전 세계 과학자들에게 심각한 업무 차질이 발생할 수 있으며, 실제로 많은 수학자와 물리학자들이 arXiv에 매일 접속함

     “Everybody in math and physics uses it. I scan it every night.” — Scott Aaronson
     “수학과 물리학 분야 사람이라면 누구나 사용하고 있어요. 저는 매일 밤 훑어봐요.”

arXiv의 역할과 학술 출판 구조에 대한 문제 제기

     * 사회 각 분야에는 고질적인 문제 구조가 존재하며, 학계에서는 출판 시스템의 불합리성이 대표적 문제로 지적됨
     * 대형 출판사인 Elsevier, Springer 등의 영리 모델은 다음과 같은 방식으로 비판받음:
          + 저자에게 무보수 논문 작성 요구
          + 다른 연구자가 무료로 편집을 수행하는 구조
          + 완성된 논문은 고가에 판매되며, 기관은 높은 구독료를 부담

     “Calling their practice a form of thuggery isn’t so much an insult as an economic observation.”
     “이들의 방식이 폭력이라고 부르는 건 모욕이 아니라 경제적 사실이에요.”
     * 전통적인 동료 평가(peer review) 는 수개월에서 1년까지 소요되며, 이 느린 과정이 정보 유통의 병목으로 작용함
     * 반면, arXiv는 논문 심사 이전 단계(preprint) 에서 누구나 즉시 공개하고 접근 가능하도록 함으로써 출판의 구조적 문제를 해결함
     * arXiv의 핵심 혁신은 다음과 같은 방식으로 요약 가능함:

     “Showing that you could divorce the actual transmission of your results from the process of refereeing.” — Paul Fendley
     “연구 결과의 전달과 동료 평가 과정을 분리할 수 있음을 보여준 것이죠.”
     * 이러한 구조는 COVID-19 팬데믹과 같은 위기 상황에서 의미 있는 과학적 발견을 신속하게 확산시키는 데 결정적인 기여를 함
          + arXiv에서 영감을 받은 bioRxiv, medRxiv 등이 생명과학 분야로 확장되었으며, 수백만 명의 생명을 구한 가능성도 제기됨

arXiv의 품질 관리 구조

     * arXiv에 제출되는 논문은 공식적인 peer review를 거치지 않지만, 분야별 전문가들의 자발적 검토를 통해 기본적인 학문적 기준과 규정을 유지함
     * 주요 품질 관리 요소:
          + 원본 연구만 허용
          + 조작된 데이터 금지
          + 중립적인 표현 사용
     * 또한, 제출 논문은 자동화된 시스템을 통한 기초 검수도 진행됨
     * 이러한 검증 절차 없이는 arXiv가 사이비 과학 또는 비전문가 제출물로 넘쳐날 위험이 있음

arXiv의 영향력과 Ginsparg의 현재 모습

     * 2021년, 학술지 Nature는 arXiv를 “10 computer codes that transformed science” 중 하나로 선정함

     “10 computer codes that transformed science”
     “과학을 변화시킨 10대 컴퓨터 코드”
     * arXiv의 과학 협업 촉진 역할이 높이 평가받았으며, 현재는
          + 260만 편 이상의 논문 보유
          + 매달 2만 건의 신규 제출
          + 월간 사용자 수 500만 명 기록
     * 21세기 주요 과학적 발견 다수가 arXiv를 통해 최초 공개되었으며, 그 예시로는
          + 현대 AI 붐을 일으킨 “transformers” 논문
          + 밀레니엄 난제 중 하나인 푸앵카레 추측의 해법 등이 있음
     * arXiv에 올라온 논문이 후속적으로 권위 있는 저널에 실리는 경우도 많음, 하지만 arXiv에 공개된 순간부터 누구나 접근 가능하다는 점이 핵심 장점으로 작용함

     “Just because a paper is posted on arXiv doesn’t mean it won’t appear in a prestigious journal someday.”
     “arXiv에 논문이 올라왔다고 해서, 나중에 권위 있는 저널에 실리지 않는다는 뜻은 아니에요.”

arXiv의 내부 현실과 지속 가능성 문제

     * 과학자들에게 arXiv는 공공 도서관이나 GPS처럼 없어서는 안 될 존재로 인식되지만, 실제 arXiv 운영은 마찰 없는 이상적 플랫폼과는 거리가 있음
     * arXiv는 그동안 다음과 같은 문제에 직면해 왔음:
          + 관료적 갈등
          + 노후화된 코드
          + 스파이 사건까지 발생
     * Ginsparg는 이 현실을 다음과 같이 표현함

     “A child I sent off to college but who keeps coming back to camp out in my living room, behaving badly.”
     “대학에 보낸 자식이 자꾸 집에 돌아와 거실에 눌러앉아 말썽을 부리는 꼴이에요.”
     * 인터뷰 요청을 FAQ로 돌리거나 직접 방문을 만류하는 등, Ginsparg는 여전히 arXiv와의 거리두기 시도를 이어가고 있음

Ginsparg의 성격, 취향, 일상

     * Ithaca(Cornell 소재지)에서의 인터뷰를 통해 드러난 Ginsparg는
          + 유쾌하고 장난기 많은 성격
          + 동시에 제한 없이 자신의 철학을 관철하는 완고함을 가짐
     * 그의 예전 상사였던 Geoffrey West의 표현에 따르면

     “Quite a character, infamous in the community, extremely funny, a great guy.”
     “상당히 개성 있는 사람이고, 커뮤니티에서 유명하죠. 굉장히 웃기고, 멋진 사람이에요.”
     * Ginsparg 자신은 arXiv 관련 기사를 평가절하하며 말함

     “So many articles, so few insights.”
     “기사야 많지만, 통찰은 적어요.”
     * 현재 69세인 그는 사이클링과 등산을 즐기는 활동적인 삶을 유지하고 있으며, 복장은 늘 편안한 여행자 스타일임

Ginsparg의 사무실과 최근 관심사

     * Cornell 물리학과의 사무실은 “지저분하다”기보다, 오래된 물건들이 정지된 시간 속에 놓인 듯한 분위기를 가짐
          + 90년대 택배 상자, 오래된 잡지, CRT 모니터, 백악관 초대장 등 존재
          + Stephen Wolfram이 보낸 책에는 유쾌한 메모가 있음

     “Since you can’t find it on arXiv :)”
     “arXiv에서 찾을 수 없을 테니 :)”
     * 유일하게 활발히 사용되는 것은 양자 측정 이론 관련 수식이 가득한 칠판
     * 사무실 외에서도 그는 건물 구조, 직원 동선, 매년 날아드는 새의 종류까지 세세한 것들을 놓치지 않는 관찰력을 보임
     * AI 논문 급증과 함께 증가한 저품질 논문 문제에 대해 우려하며, 이를 걸러낼 수 있는 “holy grail crackpot filter” 를 개발 중

     “The holy grail crackpot filter.”
     “궁극의 사이비 논문 필터”
     * arXiv의 질 관리를 위해 지금도 스스로 하드 드라이브를 복구하면서까지 언어 모델을 실험 중임
          + 이 같은 행동은 arXiv의 품질 유지 책임감을 스스로 느끼는 태도로 해석 가능

arXiv의 탄생과 초기 역사

     * arXiv는 원래 과학 인프라가 아닌, Ginsparg의 NeXT 머신에서 돌아가던 단순한 셸 스크립트 모음이었으며, 1991년 6월, 콜로라도 학회에서의 계기를 통해 만들어지게 되었음
     * 당시 프린스턴 고등연구소의 포닥이자 물리학 프리프린트 메일링 리스트를 운영하던 Joanne Cohn이 “물리학 논문을 공유할 중앙 시스템이 없다”는 문제를 언급함
          + 소속이나 인맥에 따라 메일링 리스트 접근 여부가 갈렸고, 논문 공개까지 수개월이 소요되는 비효율성 존재
     * 어떤 물리학자가 “여행 중 이메일 논문이 너무 많아 저장 공간이 가득 찬다”는 우스갯소리를 하자, Ginsparg는 자동화된 논문 배포 시스템의 필요성을 인지함
          + Cohn에게 “자동화 생각은 안 해봤냐”고 묻자, 돌아온 대답은

     “Go ahead and do it yourself.”
     “그럼 네가 한번 해봐.”
     * 이튿날 Ginsparg는 실제로 스크립트를 짜서 완성했고,

     “My recollection is that the next day he’d come up with the scripts and seemed pretty happy about having done it so quickly.”
     “제 기억엔 그가 바로 다음날 스크립트를 만들었고, 그렇게 빨리 만든 걸 무척 즐거워했어요.” — Joanne Cohn

Ginsparg의 시대적 위치와 arXiv의 기술 진화

     * Ginsparg는 종종 인터넷 시대의 포레스트 검프로 비유되며,
          + Harvard 재학 당시 Bill Gates, Steve Ballmer와 동급생이었고
          + 형은 Stanford에서 AI 선구자 Terry Winograd와 공부했으며
          + 두 사람 모두 Arpanet 이메일 계정 보유, 이는 당시로선 매우 드문 일이었음
     * Cornell에서 이론물리학 박사 학위 취득 후 Harvard에서 교수직을 시작했으나, 종신재직권 거절로 Los Alamos로 이직함
          + 이곳에서는 고에너지 이론물리학 연구에만 전념할 수 있는 환경과 운동 중심 라이프스타일에 적합한 지역 조건이 있었음

웹 이전의 arXiv 시스템과 웹 기반으로의 진화

     * arXiv는 초창기 웹사이트가 아닌 이메일 자동 응답 서버였고, 몇 달 뒤 FTP 서버도 함께 운영되었음
          + 이후 Ginsparg는 “World Wide Web”이라는 새로운 기술을 듣고 처음에는

     “I can’t really pay attention to every single fad.”
     “모든 유행에 다 관심을 가질 순 없잖아요.”
     라며 회의적인 반응을 보였지만, 1993년 Mosaic 브라우저의 등장을 계기로 흥미를 느껴 웹 인터페이스를 직접 구축함
     * 그는 CERN의 Tim Berners-Lee와도 교류했으며, 그를 “검정참치를 잘 굽는 프로그래머”로 기억함

     “Tim grilled excellent swordfish at his home in the French countryside.”
     “Tim은 프랑스 시골 자기 집에서 검정참치를 기가 막히게 구워줬죠.”

이름의 유래와 코드베이스 정비

     * 1994년, National Science Foundation의 자금 지원을 받아 초기 셸 스크립트를 보다 안정적인 Perl 코드로 리팩토링하기 위해 두 명의 개발자를 채용함
          + Mark Doyle: 후에 American Physical Society의 CIO가 됨
          + Rob Hartill: IMDb 프로젝트 병행 중이었으며, 이후 Apache Software Foundation에서도 활동
     * arXiv의 초기 주소는 xxx.lanl.gov였는데, “xxx”에 지금의 의미는 없었으며, 이후 아내와 함께 “더 나은 이름”을 고민하다 그리스 문자 chi(χ)를 활용해 ‘arXiv’로 결정

     “She wrote it down and crossed out the e to make it more symmetric around the X.”
     “아내가 적어보더니 ‘e’를 지우고 ‘X’를 중심으로 대칭적으로 만들었어요.”
     * 초기에는 별도의 조직도 없이 개발자 1~2명, 관리자는 대부분 지인 및 동료들이 맡았으며, 연간 100건 정도의 논문을 예상했지만 초기부터 월 100건으로 시작해 급성장함

커뮤니티의 급속한 확장과 arXiv의 정착

     * Ginsparg의 말에 따르면,

     “Day one, something happened, day two something happened, day three, Ed Witten posted a paper. That was when the entire community joined.”
     “첫날 뭔가가 일어났고, 둘째 날도 마찬가지였고, 셋째 날 Ed Witten이 논문을 올렸죠. 그때 전 커뮤니티가 합류했어요.”
     * Edward Witten은 현대 최고의 이론물리학자이자 “살아있는 가장 똑똑한 사람”으로 불리며, 그 역시 다음과 같이 언급함

     “The arXiv enabled much more rapid worldwide communication among physicists.”
     “arXiv는 전 세계 물리학자 간의 소통을 훨씬 빠르게 해줬어요.”
     * 이후 수학, 컴퓨터 과학 등 다양한 분야로 확장되었으며, Ginsparg 본인도

     “It was fun.”
     “재미있었어요.”
     라며 arXiv 초기 개발 경험을 회상함

arXiv의 확장과 갈등의 시작

     * arXiv의 사용량이 급증함에 따라 대형 소프트웨어 시스템들이 겪는 확장성과 운영 문제에 직면하게 되었으며, 특히 서버 속도 저하와 모더레이션 부담이 주요 이슈로 떠올랐음
          + 예를 들어, “stanford.edu”로부터의 트래픽 폭주로 인한 서버 과부하 사건이 있었으며, 이는 훗날 Google을 만든 Sergey Brin과 Larry Page가 arXiv를 웹 크롤링하던 시기였음

     “Years later, when Ginsparg visited Google HQ, both Brin and Page personally apologized to him for the incident.”
     “몇 년 후 Ginsparg가 Google 본사를 방문했을 때, Brin과 Page는 직접 그 사건에 대해 사과했다.”

arXiv의 생존 전략과 출판 업계로부터의 독립성 확보

     * arXiv가 살아남은 가장 큰 이유는 전통적 학술 출판의 기득권 구조로부터의 공격을 피한 점에 있으며, 이는 초기부터 사용자가 제출 시 “arXiv가 해당 논문을 비독점적으로 영구 배포할 수 있다”는 조항에 동의하게 한 전략 덕분임
          + 이 조항 덕분에 논문이 다른 저널에 출판되더라도 arXiv에 계속 남아 있을 수 있게 되었으며, 거대 출판사들이 폐쇄를 시도할 유인을 제거함

Los Alamos에서의 이탈과 Cornell로의 복귀

     * arXiv가 과학계에 점점 더 중요한 인프라로 자리 잡았음에도 불구하고, Los Alamos 연구소 내부에서는 arXiv 프로젝트를 크게 지지하지 않았으며, 오히려 연구소보다 영향력이 커진 점이 부담으로 작용했음
          + Ginsparg는 당시를

     “dreamlike and heavenly” “꿈결 같고 천상의 시기”
          + 라고 표현했지만, 1999년 Wen Ho Lee 간첩 사건 이후 연구소 내 분위기가 급변하면서 보안 강화 조치와 심리적 피로 누적으로 이직을 결심하게 됨
               o 당시 성과 평가에서 “a strictly average performer with no particular computer skills”
                 → “평균 수준의 성과자이며, 특별한 컴퓨터 기술은 없다”는 혹평을 받았고, 갓 태어난 딸과 교육 환경 문제도 이직 이유 중 하나였음
     * 결국 Ginsparg는 모교인 Cornell로 복귀하면서 arXiv도 함께 옮겨졌고, 그는 “최대 5년 안에 arXiv에서 손을 떼겠다”고 선언함

     “They disseminate material to academics, so that seemed like a natural fit.”
     “도서관은 학술 자료를 배포하니 자연스러운 선택처럼 보였다.”

도서관 내에서의 운영 충돌

     * 하지만 Cornell 도서관은 arXiv의 기술적 복잡성을 제대로 이해하지 못했으며, 제출 로직 하나만 해도 수많은 예외 처리가 요구되는 구조였기에, 단순한 자료 저장 시스템으로 취급한 것이 문제였음
     * Ginsparg와 초기 멤버들은 도서관 측이 arXiv를 일종의 사후적 덤으로 여겼다고 느꼈고, 반대로 도서관 측은 Ginsparg가 지나치게 직접 개입한다는 인상을 받았음

     “Good lower-level manager … but his sense of management didn’t scale.”
     “좋은 실무형 관리자이지만, 관리 역량이 대규모 운영에 적합하지 않았다.”
     * 2000년대 대부분의 기간 동안, arXiv는 안정적인 개발 인력을 확보하지 못한 채 운영되었음

Ginsparg의 철학과 운영 방식에 대한 비판

     * Ginsparg는 여전히 자신이 직접 코드 리뷰를 하고 오류를 찾아내는 실무 중심의 개발자 성향을 유지했으며, 외부 강연이나 고위 자문 역할에는 냉소적 태도를 보임

     “Larry Summers spending one day a week consulting for some hedge fund—it’s just unseemly.”
     “Larry Summers가 일주일에 하루씩 헤지펀드 자문을 한다는 건 보기 좋지 않다.”
     * 그러나 오랫동안 계속 관여하는 것도 문제가 되었으며, arXiv는 점점 규모가 커졌고

     “bigger than all of us” — Stephanie Orphan (arXiv 프로그램 디렉터)
     “우리 모두보다 커진 존재”
     라는 인식이 공유되기 시작함
     * 지적설계론 물리학자의 소송, 표절 논란, 모더레이터 권한 남용 비판 등 다양한 논쟁이 불거졌으며
          + 특히 2009년에는 독립 물리학자 Philip Gibbs가 arXiv의 반대 플랫폼 viXra를 창설함
               o 이는 “arXiv의 반대 방향으로 작동하는 거의 무규제 플랫폼”으로, 괴상한 이론이나 아마추어 논문들이 주로 등록됨
               o 대표적 예시로는 “π는 거짓이다”는 논문(링크)이 있음

코드베이스 관리 문제와 개발 관행의 충돌

     * arXiv는 점점 더 대규모 코드베이스로 성장했으며, 초기 구조는 유지보수성과 테스트를 고려하지 않은 방식으로 구성되었기에
          + “안전점검 없는 건물 공사”와 유사한 구조적 문제 발생
          + 이는 빠른 초기 개발은 가능했지만 장기적 기술 부채와 복잡도 증가를 야기함
     * Ginsparg는 여전히 도서관 측의 승인 없이 직접 코드 검토 및 수정에 개입했고, 이로 인해

     “micromanaging and sowing distrust”
     “지나친 개입과 불신 조성”
     이라는 비판을 받게 됨

은퇴 시도와 잔류, 그리고 내부 갈등의 고조

     * 2011년 arXiv의 20주년을 맞이한 Ginsparg는 은퇴 결심을 굳히고, Nature에 “ArXiv at 20”이라는 제목의 작별 인사를 게재함

     “For me, the repository was supposed to be a three-hour tour, not a life sentence.”
     “내게 arXiv는 세 시간짜리 여행이었지, 평생형은 아니었다.”
     “ArXiv was originally conceived to be fully automated, so as not to scuttle my research career.”
     “arXiv는 내 연구 경력을 해치지 않도록 완전 자동화를 목표로 설계되었다.”
     “But daily administrative activities associated with running it can consume hours of every weekday, year-round without holiday.”
     “하지만 arXiv 운영에 따른 행정 업무는 평일마다 수 시간을 소모하고, 연중무휴로 이어졌다.”
     * 이후 일상적인 운영은 Cornell 도서관에 이관되고, Ginsparg는 자문 위원으로 물러날 계획이었지만, 현실은 그렇게 흘러가지 않음
          + 일부 직원들은 Ginsparg가 코드를 “인질처럼 붙잡고 있다” 며 GitHub나 내부 공유를 거부한다고 비판했으며,
          + 그는 과거 하루 만에 구현하던 기능이 이제는 몇 주나 걸린다는 점에 대한 좌절감을 표현함

     “I learned Fortran in the 1960s, and real programmers didn’t document.”
     “나는 1960년대에 Fortran을 배웠고, 진짜 프로그래머는 문서화를 하지 않았다.”
     (→ 질문자에게 심장마비급 충격을 안긴 답변으로 묘사됨)

경영 혼선과 구조 개편

     * arXiv는 기술 문제에 더해 관리적 혼란도 겪었으며,
          + 2019년에는 Cornell 내에서 arXiv의 소속 부서가 컴퓨팅 및 정보과학부로 이관되었지만 몇 달 후 다시 변경됨
          + 이후에는 상업 학술 출판 경험을 가진 인사가 운영 책임자로 부임했지만, 1년 반 만에 퇴임함

     “There was disruption … it was not a good period.”
     “혼란이 있었고, 좋은 시기가 아니었다.” — arXiv 내부자
     * 전환점은 2022년, Simons 재단의 지원으로 개발 인력을 대거 확보하고,
          + Cornell의 Ramin Zabih 교수가 운영 책임자로 임명되며,
          + 클라우드 이전과 Python 기반 코드 리팩터링 작업이 본격화됨

개인적 면모와 성찰

     * Ginsparg는 기자와의 인터뷰 도중에도 아들의 자전거를 정비해주고, 자전거 여행 중 상대의 체력에 대해 놀림을 주는 등 장난기 있는 태도를 유지함
          + 마지막 오르막에서 그는

     “I might’ve oversold this to you.”
     “내가 이 코스를 과대평가했을지도 모르겠네.”
     라며 피곤함을 인정함
     * 여러 날 인터뷰를 진행하면서 기자는 그의 끈기와 완고함에 arXiv의 생존 이유가 있다고 언급했고, 이에 대해 Ginsparg는 뜻밖의 반응을 보임

     “One person’s tenacity is another person’s terrorism.”
     “누군가에겐 끈기지만, 다른 누군가에겐 테러리즘일 수도 있다.”
     * 그는 이어

     “I’ve heard that the staff occasionally felt terrorized.”
     “직원들이 가끔은 공포감을 느꼈다고 들었다.”
     라고 인정함

arXiv의 현재와 미래

     * 현재 arXiv는 여전히 극적인 운영을 이어가고 있으며,
          + 언어학자 Emily Bender는 arXiv를 “junk science”와 “fast scholarship”을 조장하는 “암(cancer)” 이라 비판한 바 있음
            (관련 트윗, 관련 글)
     * 2023년에는 상온 초전도체 발견을 주장한 논문이 빠르게 반박되었고, 이는 arXiv의 빠른 피드백 메커니즘을 보여주는 사례가 되었음
          + 반대로, 정상적인 논문이 “선동적 표현”이나 “비전문적 언어”를 이유로 철회되는 사례도 있어 “검열” 논란도 있음
               o 대표 사례: h-index 창시자 Jorge Hirsch의 논문 철회 사건

Ginsparg의 현재 태도와 애착

     * 그는 스스로를 “오픈 사이언스의 선구자”로 포장하는 것에 거리를 두며, 거창한 미션보다는 아이디어 실험의 장으로서 arXiv를 즐기고 있음

     “There are various aspects of this that remain incredibly entertaining.”
     “이 프로젝트에는 여전히 매우 재미있는 부분들이 있다.”
     “I have the perfect platform for testing ideas and playing with them.”
     “아이디어를 실험하고 놀 수 있는 완벽한 플랫폼이 있다.”
     * 비록 arXiv 운영 코드에는 더 이상 손대지 않지만, 여전히 ‘가짜 논문 필터’를 개발하는 개인 프로젝트에 몰두 중임

     “It’s like that Al Pacino quote: They keep bringing me back.”
     “그 Al Pacino 대사처럼, 계속 나를 다시 끌어들이는 거야.”
     “But Al Pacino also developed a real taste for killing people.”
     “하지만 Al Pacino는 결국 사람 죽이는 데 맛을 들였지.”
     (→ arXiv에 대한 애증과 스스로의 집착을 유머로 표현한 것)

        Hacker News 의견

     * 90년대에 ""xxx""라는 표현이 오늘날의 의미를 가지지 않았다는 주장은 사실이 아님
     * 이 글은 공공재를 유지하는 데 있어서의 어려움을 보여주는 미시적 사례로, 약간의 우울한 분위기를 가짐
          + 작은 서비스는 눈에 잘 띄지 않지만 중요한 역할을 하며, 이를 유지하기 위한 도움을 받기 어려움
          + 서비스가 커지면 주목받게 되고, 이를 다른 목적으로 변질시키려는 시도가 생기며, 이로 인해 도움을 받는 것이 어려워짐
     * 과학자들에게 arXiv 없는 세상은 공공 도서관 없는 세상과 같음
     * Zenodo를 선호하는 사람도 있으며, 이는 CERN에서 호스팅하고 더 많은 기능을 제공함
     * 2021년 Nature 저널은 arXiv를 과학을 변혁시킨 10대 컴퓨터 코드 중 하나로 선정했음
          + 이 기사는 유료 벽 뒤에 있으며, 연간 $199로 열람 가능함
     * arXiv의 라이선스 중 일부는 비상업적 용도로만 사용 가능함
          + 특정 논문의 주 페이지에서 라이선스 정보를 확인할 수 있는 방법을 찾고 있음
     * arXiv는 .ps, .tex, .pdf 형식의 학술 논문 업로드를 허용함
     * 인터넷과 웹은 과학에서 가장 변혁적인 플랫폼임
     * arXiv는 컴퓨터 과학 학위가 없는 사람이 프로그래밍 언어를 독자적으로 개발했다는 사실을 믿지 못해 논문을 보류 중임
"
"https://news.hada.io/topic?id=20415","TurboTax 소유주 Intuit, 미국 납세자와의 전쟁에서 승리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 TurboTax 소유주 Intuit, 미국 납세자와의 전쟁에서 승리

     * Intuit는 TurboTax의 소유자로, 미국의 무료 세금 신고 프로그램을 종료시키는 데 성공함
     * IRS의 무료 세금 신고 프로그램인 Direct File이 종료될 예정이며, 이는 Intuit의 로비 활동의 결과임
     * Intuit는 수년간 정부의 세금 신고 간소화 시도를 저지하기 위해 막대한 자금을 사용해왔음
     * Intuit는 2025년 1분기에 세금 관련 문제로 의회에 $240,000를 로비함
     * Intuit는 무료 세금 신고 프로그램을 방해하기 위해 법적 문제와 로비 활동에 수백만 달러를 사용함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Intuit의 로비 활동과 IRS 무료 세금 신고 프로그램 종료

     * Intuit는 TurboTax의 소유자로, IRS의 무료 세금 신고 프로그램인 Direct File을 종료시키는 데 성공함
     * IRS는 Direct File 프로그램을 종료할 예정이며, 이는 Intuit의 지속적인 로비 활동의 결과임
     * Intuit는 정부의 세금 신고 간소화 시도를 저지하기 위해 막대한 자금을 사용해왔음

Intuit의 로비 활동

     * Intuit는 2025년 1분기에 세금 관련 문제로 의회에 $240,000를 로비함
     * Raffaniello & Associates와 Jake Perry + Partners를 통해 세금 관리 및 세금 시스템 무결성 문제에 로비함
     * Wilmer Cutler Pickering Hale and Dorr LLP는 Intuit를 위해 세금 관리 및 세금 시스템 무결성 강화를 위한 로비 활동을 수행함

Intuit의 전략과 결과

     * Intuit는 무료 세금 신고 프로그램을 방해하기 위해 법적 문제와 로비 활동에 수백만 달러를 사용함
     * Intuit는 2023년에 고객을 속여 과도한 요금을 부과한 혐의로 $100 million 이상의 합의금을 지불함
     * Intuit의 로비 활동은 성공적이었으며, Direct File 프로그램의 종료로 이어짐

정치적 반응과 비판

     * 상원 의원 Elizabeth Warren은 Intuit의 로비 활동과 Trump 행정부의 세금 신고 간소화 실패를 비판함
     * Intuit는 2023년과 2024년에 프로그램을 종료시키기 위해 $4 million을 로비 활동에 사용함
     * Intuit의 지속적인 로비 활동은 결국 성공을 거두었으며, Direct File 프로그램의 종료로 이어짐

        Hacker News 의견

     * 오리건 주는 자체적으로 Turbo Tax의 경쟁자를 만들었고, 매년 더 좋아지고 있음. 올해는 회계사를 사용했지만, 내년에는 직접 세금 신고를 할 계획임
     * Free Tax USA를 사용하면 연방 세금은 무료이며, 주 세금은 $15임. 여러 해 동안 Turbo Tax와 Free Tax USA를 비교했지만 항상 같은 결과가 나왔음
     * Bessent 재무장관은 DirectFile을 보호할 것인지에 대한 질문에 ""예""라고 답변했음. 그는 프로그램을 더 잘 이해하고 평가할 것이라고 약속했음
     * FreeTaxUSA는 올해 캘리포니아에서 약 $20 정도의 비용이 들었고, 추가 판매가 거의 없었음. 강력히 추천함
     * Direct File의 결과와 상관없이, 사람들은 세금 신고를 직접 하는 법을 배우는 것이 좋음. 매년 직접 세금 신고를 하고 있으며, 시간이 걸리지만 누구에게도 의존하지 않음
     * 평균 납세자는 표준 공제를 사용하며 특별한 것이 필요하지 않음. 이 과정이 민영화될 이유가 없음
     * 기업은 기존 법률의 모든 여지를 활용해야 한다고 생각함. 그러나 법을 바꾸려는 기업은 악덕 기업임. Intuit는 법을 바꾸려 하며, 미국인들의 삶을 악화시키고 있음
     * $240,000는 결국 매우 저렴한 비용임. 왜 대부분의 기업이 같은 일을 하지 않는지 궁금함
     * 스리랑카에서는 Inland Revenue Department를 통해 직접 세금 신고가 가능함. RAMIS라는 시스템을 사용하며, 과거에 몇 차례 문제가 있었지만 기능은 잘 수행함
     * 법률가를 매수하는 데 드는 비용이 얼마나 적은지 놀라움. Intuit는 세금 관련 문제로 의회를 로비하는 데 $240,000를 지출했음
"
"https://news.hada.io/topic?id=20460",""이 기술은 죽었나?" 죽어가는 프레임워크를 알려주는 신랄한 분석 엔진","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ""이 기술은 죽었나?"" 죽어가는 프레임워크를 알려주는 신랄한 분석 엔진

     * ""Is This Tech Dead?""는 Deaditude Score™를 통해 기술 스택의 생존 여부를 다양한 인터넷 지표를 종합해 수치화합니다.
     * GitHub, Google Jobs, Reddit, StackShare, YouTube, Stack Overflow, Hacker News 등을 분석하여 기술의 현재 상태를 평가합니다.
     * 높은 점수가 반드시 기술 폐기를 의미하진 않으며, 일부 오래된 기술은 여전히 안정적으로 사용될 수 있음을 유머러스하게 안내합니다.

   그냥 죽이고 싶었던거 아닐까요

   ㅇㅎ 이게 맞는듯하네요 ㅋㅋㅋ

   ㅋㅋㅋㅋㅋ

   공룡도 아니도 대부분 멸종 위기(Endangered) 이상에 빠졌군요.

   재미는 있네요 ㅎㅎ 재미로만 구경하겠습니다

   MAUI ... ㅠㅠ

   Lynx는 공개된 지 몇달 지나지도 않았는데 거의 죽었다는군요

   Supabase가 거의 죽었다니...?

   Expressjs 가 거의 죽었다니...?
"
"https://news.hada.io/topic?id=20439","AI 엔지니어링 기업으로 성장하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         AI 엔지니어링 기업으로 성장하는 방법

     * AI는 더 이상 미래가 아닌 현재의 핵심 기술이며, 기업은 이를 중심으로 비즈니스를 재정의해야 함
     * Vercel은 자체 강점을 살려 AI SDK와 v0 같은 도구로 자연스러운 AI 통합을 실현
     * 기존의 AI 개발 방식(Software 1.0)은 무너지고, 누구나 빠르게 MVP를 만들고 개선할 수 있는 AI 시대가 열림
     * 독점 데이터, 빠른 피드백 루프, 도메인 전문성은 스타트업이 빅테크와 경쟁할 수 있는 핵심 요소
     * AI는 개발자를 대체하는 게 아니라 개발자의 역량을 증폭시키는 도구로 작동해야 함
     * AI 개발은 간단한 시작에서 점진적으로 최적화하는 반복적인 접근 방식을 통해 모든 규모의 기업에 접근 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI 중심 회사로 나아가는 방법 – Vercel이 말하는 전략

  AI 혁신의 속도는 스마트폰 혁명보다 빠르다

     * 스마트폰은 대중화까지 수년이 걸렸지만, AI는 수개월 만에 대중 도입
     * GPT-3 → GPT-4 → 다수의 최첨단 모델이 기하급수적으로 발전
     * 이제 중요한 건 “AI가 우리에게 영향을 줄까?”가 아니라 “어떻게 통합할까?”

  Vercel의 전략: 기존 강점에 AI를 자연스럽게 더하기

     * Vercel은 웹 프레임워크 회사로서의 정체성을 유지하면서, AI를 자연스럽게 흡수
          + AI SDK: 다양한 모델을 손쉽게 연결해주는 JavaScript 중심의 개발 도구
          + v0: 자연어로 입력하면 UI를 생성해주는 생성형 웹 프론트엔드 툴

     핵심은 자신의 강점을 왜곡하지 않고, AI로 보완하는 것

  AI 엔지니어링의 패러다임 전환

     * 과거의 AI 개발 방식(소위 Software 1.0)은 다음과 같은 특징을 가짐:
          + 주로 대학에서 주로 쓰던 Python 언어를 사용했고,
          + 개발에 앞서 먼저 복잡한 인프라를 구축해야 했으며,
          + 특정 목적에 맞는 소형 모델을 직접 훈련해야 했고,
          + 훈련에는 수개월에서 수년이 걸렸으며,
          + 이런 작업은 주로 박사나 전문가 집단의 영역이었고,
          + 실제 결과를 내기까지도 몇 달에서 몇 년이 소요됐지.
     * 하지만 지금의 AI 시대는 전혀 다른 방식으로 움직임:
          + TypeScript 등 친숙한 언어로도 AI를 다룰 수 있고,
          + 프론트엔드 중심으로 사용자 경험을 먼저 고려하며,
          + 대형 언어 모델(LLM)을 API로 호출해 사용하고,
          + 프롬프트만으로 모델을 다룰 수 있으며,
          + 전문가가 아니더라도 누구나 접근 가능하고,
          + 며칠~몇 주 안에 제품을 배포하고 실험할 수 있어.
     * 이제는 아이디어 → 실험 → 개선까지의 속도가 경쟁력
     * 학위보다 실행력이 더 중요해진 시대

  빅테크와의 경쟁도 가능하다

    1. 독점 데이터: 사내 문서, 고객 정보 등 대형 모델이 접근 못하는 데이터 자산
    2. 피드백 루프: 스타트업은 빠른 실험과 반복 개선이 가능함
    3. 도메인 복잡성: 일반화 모델이 해결 못하는 분야에 집중하면 경쟁 가능

     “당신은 이미 경쟁할 수 있는 무기를 갖고 있다”

  AI 최적화 사이클: 단순하게 시작해서 점진적 개선

    1. 일단 돌아가는 걸 먼저 만든다 (비용이 좀 들어도 OK)
    2. 빠르게 배포하고 피드백 수집
    3. 중간급 모델로 전환해 비용 절감
    4. 성능 검증(Eval)으로 품질 유지
    5. 파인튜닝 등으로 추가 비용 절감

   이 방식은 대기업이든 스타트업이든 적용 가능

  제품 안에 AI를 녹여 넣기

     * AI는 단순한 챗봇 UI를 넘어, 앱 내부 구성 요소로 자연스럽게 통합돼야 함
     * 예: generateText() 같은 함수 한두 줄로 AI 기능을 시스템 레벨로 흡수
     * 사용자는 AI를 “대화하는 존재”가 아니라, 기능의 일부로 체감해야 진짜 경험이 됨

  v0: 현실에서 적용된 예시

     * 디자이너, PM, 비개발자도 프롬프트로 상호작용 UI를 생성 가능
     * “코드를 몰라도 UI 프로토타입을 만들 수 있는 도구”
     * AI는 사용자의 전문성을 대체하지 않고, 증폭시켜주는 보조 수단

  AI 시대, 개발자의 위치는 어디인가?

     * AI 도구는 시작을 쉽게 도와줄 뿐, 생각은 여전히 사람의 몫
     * 중요한 건, AI를 활용해서 내가 더 잘할 수 있는 영역을 찾는 것
     * 공포 대신 실험과 개선의 태도로 나아가야 함

     AI 혁신은 이미 시작되었고, 누구나 그 일부가 될 수 있다
     지금 필요한 것은 실행력과 학습 의지
"
"https://news.hada.io/topic?id=20448","1992년 6인용 아케이드 기계 Galaxian3 Theatre 6 복원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1992년 6인용 아케이드 기계 Galaxian3 Theatre 6 복원

     * Galaxian 3: Project Revival은 Namco가 1980년대 후반에 개발한 대형 아케이드 게임으로, 28명의 플레이어가 동시에 즐길 수 있는 Galaxian3: Project Dragoon으로 시작되었음
     * 이 게임은 여러 버전으로 출시되었으며, 1990년 오사카에서 처음 선보였고, 이후 16명 버전과 6명 버전으로 축소되어 전 세계에 배포되었음
     * 2000년대 초반, 많은 Galaxian3 기기가 다른 게임으로 전환되면서 원래의 전자 장치가 폐기되었음
     * 2025년 현재, GT-6 버전의 남아있는 기기는 유럽, 일본, 미국에 각각 하나씩 존재하며, 미국의 Fun World 아케이드에서 복구 및 데이터 보존 작업이 진행 중임
     * 복구 작업은 기기의 하드웨어 및 소프트웨어 문제를 해결하고, LaserDisc와 ROM 데이터를 보존하는 것을 목표로 하고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Galaxian 3: Project Revival 소개

     * 1980년대 후반 Namco는 세계 최대의 아케이드 게임을 만들기 위해 Galaxian3: Project Dragoon을 개발하였음
     * 이 게임은 28명의 플레이어가 동시에 즐길 수 있는 대형 아케이드 게임으로, 1990년 오사카에서 처음 선보였음
     * 이후 16명 버전과 6명 버전으로 축소되어 전 세계에 배포되었음

하드웨어 개요

     * 게임은 두 대의 Sony VPH-1043QJ CRT 프로젝터를 통해 대형 화면에 표시되며, 플레이어는 아날로그 컨트롤과 디지털 버튼을 사용하여 조작함
     * 마스터 PCB는 게임의 주요 논리를 처리하며, 슬레이브 PCB는 비디오 하드웨어를 구동함
     * DSP PCB는 3D 데이터 처리를 담당하며, PGN PCB는 다각형을 래스터화함
     * OBJ PCB는 2D 객체/스프라이트를 생성하며, V-MIX PCB는 비디오 믹싱을 담당함

진단 및 복구 작업

     * 플레이어 3-6의 입력이 작동하지 않는 문제를 발견하고, PSN PCB의 문제로 추정됨
     * PSN PCB의 테스트 스위치를 사용하여 입력 상태를 확인하고, 문제를 해결하기 위해 캘리포니아로 PCB를 가져가 추가 테스트를 진행함
     * CRT 프로젝터의 블루 채널 문제는 ""CRT 곰팡이""로 인한 것으로, 이를 제거하기 위한 전문가의 도움을 받기로 함

보존 작업

     * LaserDisc를 디지털화하기 위해 Domesday Duplicator를 사용하여 고품질의 캡처를 수행함
     * ROM 데이터 보존은 시간이 많이 걸렸지만, 모든 ROM이 소켓에 장착된 표준 EPROM이어서 비교적 간단했음
     * Project Dragoon의 ROM과 LaserDisc도 보존함

향후 작업

     * 플레이어 입력 문제 해결, 프로젝터 서비스, 누락된 ROM 찾기 등의 작업을 계획함
     * 게임이 안정적으로 작동할 때까지 방문을 미루는 것이 좋으며, 추가적인 수리 및 개선 작업이 필요함
     * 게임이 잘 작동하여 많은 사람들이 즐길 수 있기를 바람
"
"https://news.hada.io/topic?id=20399","태양계 밖 행성에서 외계 생명체의 '지금까지 가장 유망한 징후' 발견 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 태양계 밖 행성에서 외계 생명체의 '지금까지 가장 유망한 징후' 발견

     * 천문학자들이 외계 생명체 존재를 암시하는 화학 물질을 외계 행성 K2-18b에서 탐지함
     * James Webb 우주망원경(JWST) 을 통해 생물 기원 물질인 DMS/DDS 화합물을 발견
     * 이들은 지구에서는 주로 해양 미생물이 생성하여, 생명체의 지문으로 간주됨
     * K2-18b는 지구보다 8.6배 무겁고 2.6배 크며, 124광년 떨어져 있음
     * 이 행성은 생명체가 존재할 수 있는 '골디락스 존'에 위치해 있으며, 이전 연구에 이어 다른 장비와 파장대에서 다시 확인되어 신뢰도 상승
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

외계 생명 신호, K2-18b에서 포착

     * 영국 케임브리지 대학이 이끄는 국제 연구팀이 K2-18b의 대기에서 디메틸설파이드(DMS) 및 디메틸다이설파이드(DDS) 신호를 포착함
     * 이들 화학 물질은 지구의 해양 미생물이 주로 생성하며, 생명체의 지문(biosignature)으로 간주됨
     * JWST를 통해 발견되었으며, 신호가 생명체 외 다른 화학 반응에 의한 것일 가능성도 배제하지 않음
     * K2-18b는 태양계에서 124광년 떨어져 있고, 지구보다 8.6배 무겁고 2.6배 큼
     * 이 행성은 골디락스 존(Goldilocks Zone), 즉 액체 물이 존재할 수 있는 생명체 거주 가능 지대에 위치함

이전 연구의 연장선

     * 2023년 동일 연구팀은 JWST를 통해 K2-18b의 대기에서 메탄과 이산화탄소를 발견함
     * 이는 외계 행성 대기에서 처음으로 탄소 기반 분자가 검출된 사례였음
     * 이 결과는 K2-18b가 Hycean 행성일 가능성을 제기했음: 수소 풍부한 대기와 액체 바다가 공존하는 환경
     * 당시 DMS와 DDS의 미약한 신호가 있었고, 이번 2025년 연구에서는 더 강한 신호를 다른 장비를 통해 탐지함

강력한 증거, 하지만 아직 확정 아님

     * 이번 연구에서 탐지된 신호는 3시그마 수준으로 통계적 유의미성을 보임
     * 이는 약 0.3% 확률로 우연 발생 가능성이 있다는 뜻이며, 과학적 확정을 위해서는 5시그마(0.00006%) 까지 도달해야 함
     * 연구진은 이번 결과가 가장 강력한 외계 생명 존재 증거 중 하나라고 평가하면서도, 확정은 이르다고 강조함

생명 존재 여부 판단 방법

     * 과학자들은 행성이 항성을 지나는 동안 별빛이 대기를 통과하면서 생기는 화학 지문을 분석함
     * 2023년에는 JWST의 NIRISS와 NIRSpec 장비를 사용했고, 2025년 연구에서는 MIRI 장비로 다른 파장대의 빛을 분석함
     * MIRI 분석 결과에서도 DMS와 DDS 신호가 일관되게 나타났으며, 이는 다중 검증을 통한 독립적 증거로 해석됨

생물기원 물질의 농도 차이

     * 지구에서는 DMS와 DDS의 농도가 10억분의 1 이하, K2-18b에서는 1000배 이상 높은 1000만분의 10 수준으로 추정됨
     * 이는 이전 이론이 예측한 Hycean 행성의 특징과 부합하며, 실제 존재 가능성을 더욱 뒷받침함
     * 연구진은 향후 비생물학적 생성 가능성도 검토할 계획임
     * 과학은 반복 검증을 통해 진실에 접근한다는 원칙 아래, 현재 결과를 계속 테스트 중임

결론: 우주 생명 탐사의 전환점?

     * 이번 발견은 향후 수십 년 후 ""우주에서 생명 존재를 알아낸 순간"" 으로 기록될 가능성이 있음
     * 연구진은 이번 결과가 우주에 생명이 존재할 수 있다는 질문에 본격적으로 접근할 수 있게 된 계기라고 평가함
     * 디메틸설파이드와 같은 생물기원 신호는 앞으로 더 많은 외계 행성 생명 탐사의 핵심 단서로 작용할 전망임

        Hacker News 의견

     * 그들은 디메틸 설파이드를 발견했을 가능성이 있음. 이는 생명체에 의해만 생성되는 것으로 알려져 있음
     * 첫째, 이는 정말 대단한 과학임. 수백만 킬로미터 떨어진 외계 행성의 화학 조성을 관측을 통해 감지할 수 있다는 아이디어는 수천 명의 사람들이 수백 년에 걸쳐 이룬 절대적인 업적임. 정말 놀랍고 겸손해짐
     * 둘째, 나는 항상 지구 밖에도 생명이 존재한다고 생각했음. 우리가 특별하다는 것이 너무나도 가능성이 낮아 보임. 생명이 여기서 발전했다면, 우주가 얼마나 엄청나게 광대하든지 간에 다른 곳에서도 발전했을 가능성이 압도적으로 높다고 항상 느꼈음
     * DMS에 대한 추측
          + DMS는 비생명 화학 주기의 최종 단계로 드물게 나타나는 매우 특정한 구성임
          + DMS의 단순함이 생명을 덜 나타내는 것은 아님. 오히려 이는 매우 선택적인 분자로, 생명이 관여할 때만 대량으로 나타남 (적어도 지구와 유사한 화학에서)
          + 설득력 있는 비생물학적 경로를 찾기 전까지, 높은 DMS는 잠재적인 해양과 온화한 온도를 가진 행성의 맥락에서 강력한 생물 서명으로 남아 있음
     * 가능한 기원
          + 수소가 풍부한 대기에서 번성할 수 있는 생명체를 찾고 있음
          + 전 지구적 해양 안이나 위에서 살 가능성이 있음
          + 지구보다 수천 배 더 많은 DMS를 생성할 수 있음
     * 지구와 가장 가까운 유사점
          + 해양 식물성 플랑크톤, 특히 Emiliania huxleyi와 같은 종은 삼투압을 조절하고 산화 스트레스로부터 보호하기 위해 사용하는 분자인 DMSP를 분해하면서 DMS를 부산물로 생성함
          + K2-18 b에서 비슷한 일이 일어나고 있다면, 그러한 미생물로 가득 찬 해양에 대해 이야기할 수 있음. 아마도 지구의 해양보다 훨씬 밀도가 높을 것임
     * ""거대한 광합성 매트"" 또는 황 ""조류""일 가능성
          + 육지나 부유 구조물이 있다면, DMS 생산자는 광합성, 황 대사 유사체로서 시아노박테리아와 유사할 수 있음
          + 미생물 암초와 같은 밀집된 부유 집단이나 매트에서 살고 있을 수 있음
          + 대사에서 디메틸화된 황 화합물을 사용하고, DMS를 폐기물이나 신호 분자로 누출할 수 있음
     * 물론 많은 SF 문학에서 해양 행성이 등장했지만, 나는 Alastair Reynolds의 ""Revelation Space"" 시리즈의 ""Pattern Juggler"" 행성 Ararat가 가장 생각남
     * 이는 정말로 흥미진진한 소식임
     * OP가 '유망한' 생명체의 징후라는 중요한 단어를 생략한 것은 다소 클릭베이트적임
     * 이는 지구에서 124광년 떨어진 곳에서 일어나고 있음
          + 만약 우리가 우주선을 오랜 기간 동안 1g로 가속할 수 있는 방법을 개발한다면, 단지 10 상대론적 년 안에 그곳에 갈 수 있음
          + 불행히도, 과학은 그러한 로켓을 가능하게 하지만, 우리의 엔지니어링 기술은 그것을 만들기에는 아직 멀었음
     * JSWT... 다시 한번 우주로 발사된 가장 강력한 장비임. 이는 우리의 우주에 대한 이해를 몇 번이나 근본적으로 뒤흔들 것임
     * 원시 외계 생명체의 징후를 실제로 발견하는 것은 Fermi Paradox 때문에 다소 걱정스러울 수 있음
          + 우주의 나이와 지구에서 복잡한 생명이 발전하고 우리가 그로부터 출현하는 데 걸린 시간을 고려할 때, 다른 곳에서 생명을 발견하는 것은 ""모두 어디에 있는가?""라는 Fermi의 질문으로 돌아가게 함. 이는 진화하는 문명이 그들의 존재를 더 넓은 은하에 드러내기 전에 멸종되게 하는 무언가가 온다는 것을 암시함
          + 만약 매우 원시적인 형태의 생명이라도 발견된다면, 이는 과거에 그렇게 했으며, 아마도 많은 다른 문명들이 우리 거대한 은하에서 오래 전에 형성되었을 것이며, 그들이 우리에게 감지될 만큼 충분히 발전할 시간을 가졌다는 것을 의미함. 그렇다면 그들은 어디에 있는가?
          + 물론, 위의 모든 가정 사이에는 아마도 많은 알려진 미지와 미지의 미지가 숨어 있을 것임
     * 마지막으로 생물 서명이 발견되었을 때 (아마도 금성에서), 일주일 후 arXiv에 서명이 비생물학적 과정으로 설명된 논문들이 쏟아졌음
          + 물론, 설명이 여러 개 있다면, 실제로는 설명이 없는 것임. 그래서 나는 여기서도 같은 일이 일어날 것으로 완전히 예상하며, 아마도 10년 정도 후에 후속 관측이 모든 설명을 제외한 하나를 배제할 것임. 그때까지는 흥미롭지만 궁극적으로는 끝나지 않음
     * 편집된 헤드라인. 기사는 다음과 같음
          + 천문학자들이 태양계 밖의 행성에서 '가장 유망한 외계 생명체의 징후'를 발견함
     * 가끔씩 재미로 r/UFOs나 r/aliens를 방문하여 하늘의 풍선에 대한 흐릿한 비디오에 열광하는 사람들을 봄
          + 나는 어떻게 그런 것이 실제 과학보다 더 상상력을 사로잡는지 이해하지 못했음
"
"https://news.hada.io/topic?id=20455","불균형한(Jagged) AGI에 관하여: o3, Gemini 2.5, 그리고 그 이후의 AI들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          불균형한(Jagged) AGI에 관하여: o3, Gemini 2.5, 그리고 그 이후의 AI들

     * AGI의 정의는 아직도 불명확하며, 기존 인간 중심 테스트로는 AI의 지능이나 창의성을 제대로 측정하기 어려움
     * OpenAI의 o3와 Google의 Gemini 2.5는 실제 작업 수행에서 매우 높은 수준을 보여주며 AGI에 근접한 성능을 가짐
     * o3는 에이전트형 모델로 복잡한 목표를 도구를 사용해 해결할 수 있으며, 이로 인해 Jagged AGI 개념이 등장함
     * AI는 어려운 과제를 해결하면서도 기본적인 문제에서 실수하는 등 능력이 불균형적이며, 이는 Jagged Frontier로 설명됨
     * 기술 자체보다 그 활용과 통합이 더디기 때문에 AGI가 실현되더라도 사회적 변화는 시간이 걸릴 가능성 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AGI는 정말 도달했을까?

     * 현재 AI의 지능, 창의성, 공감능력 등을 측정하는 방법은 부정확하며 대부분 인간을 위한 기준에 기반함
     * Turing Test조차 AI가 통과할 수 있게 되었지만, 이 결과의 의미는 여전히 모호함
     * AGI 개념은 오래전부터 존재했지만, 지금도 어떤 기준을 충족해야 AGI라 부를 수 있는지에 대한 합의가 없음
     * AI를 활용해 AGI 개념을 설명하는 영상 및 문서 요약 콘텐츠도 AI로만 제작되며 실험적으로 활용됨

o3와 Gemini 2.5가 보여준 성능

     * OpenAI의 o3와 Google의 Gemini 2.5 Pro는 최신 모델로, 비약적인 성능 향상을 보여줌
     * 단일 프롬프트로 마케팅 슬로건 작성부터 웹사이트 제작까지 일괄 수행 가능
     * o3는 명시적 지시 없이도 도구 사용, 웹 탐색, 코딩 수행 등 복합 작업을 자동으로 진행함
     * 이미지로 위치 추측하는 ‘geo-guesser’ 역할 등에서도 사람 수준 이상의 성능 발휘
     * 데이터 분석 및 보고서 생성도 단일 명령으로 가능하며, PDF 생성과 시각화까지 포함됨

Jagged AGI: 불균형한 AI 능력

     * AI는 인간보다 뛰어난 작업을 수행하면서도, 간단한 문제에서 틀리는 불균형한 능력을 가짐
     * 예시: 전통적인 편견 노출용 수수께끼는 정답을 맞추지만, 유사한 변형 문제는 틀리는 모습
     * 이는 AI가 훈련 데이터에 과도하게 의존하고 일반화에 약한 특징을 보인다는 의미
     * 그러나 이는 AI가 특정 문제에서는 인간을 초월할 수 있음을 방해하지 않음
     * 이런 불균형 상태를 “Jagged Frontier”라고 부르며, AGI에 근접한 능력을 고르지 않게 보여줌

AGI가 의미 있는가?

     * Tyler Cowen은 o3가 AGI일 수 있다고 보지만, 실제 영향은 시간이 지나야 드러날 것이라 분석함
     * 기술 발전 속도보다 사회 및 조직 변화가 느려 AI 도입은 느릴 수 있음
     * 그러나 o3처럼 에이전트적 성질을 가진 AI는 도구 사용과 문제 분해가 가능해 빠른 확산 가능성 존재
     * 기술이 점진적으로 확장될지, 특정 임계점을 넘어서 급격히 확산될지는 아직 불명확함
     * 중요한 점은 지금의 AI가 이전과 질적으로 다른 기술이며, 여전히 미지의 영역에 있음

미래를 준비하는 자세

     * 지금의 AI는 완전히 AGI라고 하기는 어렵지만, 일부 영역에서는 AGI에 가까운 성과를 내고 있음
     * 어떤 일이든 AI가 완벽히 수행할 수 있는 것은 아니며, 인간 전문가의 판단과 조율이 여전히 필요함
     * 현재의 “Jagged AGI”도 결국은 시간이 지나면 모든 영역에서 인간을 능가할 수도 있음
     * 이런 불확실한 미래에서 가장 중요한 것은 지금부터 AI를 실험하고 활용하는 경험을 쌓는 일임

        Hacker News 의견

     * Gemini 2.5 Pro는 나에게 중요한 전환점임. 이전의 LLM들은 특히 코딩 작업에서 매우 인상적이었음. 그러나 코딩 보조 외에는 구글 검색보다 조금 더 유용한 정도였음. 최근에 2.5 Pro를 사용하여 큰 연구 제안서를 작성하는 데 도움을 받았음. 세부 사항은 생략하지만, 내가 요청하지 않았기 때문에 전체를 작성하지 못한 것처럼 느껴졌음. 마감일이 다가오면서 더 많은 부분을 맡기게 되었고, 프로젝트 계획과 일정 생성 등 복잡한 작업을 수행했음. 이는 10배의 효과를 가져왔음.
     * 과학적 질문에서는 2.5 Pro를 팀의 전문가들보다 더 신뢰하게 되었음. 연구 데이터 전체를 Gemini에 연결하면 더 큰 변화를 가져올 것이라고 확신함. 이는 AI가 객관적이기 때문임. ""AGI""를 막는 주요 요인은 사람들의 도전 정신과 컨텍스트 윈도우 및 컴퓨팅 가용성임.
     * AI의 능력은 gpt3 이후로 비범해졌음. 그러나 AGI에 대한 일반적인 합의는 아직 없음. 많은 사람들이 AGI가 곧 다가올 것이라고 기대하고 있지만, 이는 과장된 기대와 함께 올 것임. 이 기사는 합리적이지만 제목과 슬로건에서 과장된 기대를 조장함.
     * AI가 수수께끼를 잘못 읽는 것이 아니라, 사용자가 수수께끼를 제대로 제공하지 않았다고 가정하는 것 같음. AI가 후속 질문을 할 수 있다면 좋겠지만, 현재는 그렇게 하지 않음.
     * o4-mini-high가 수수께끼를 해결하는 예시: ""용기의 파운드와 파운드 코인 중 무엇이 더 무거운가?"" 둘 다 ""파운드""이므로 무게가 같음.
     * AGI에 대한 정의가 없기 때문에 ""Jagged AGI""라는 용어를 만들어냄. AI는 일부 작업에서 신뢰할 수 없지만, 다른 작업에서는 초인적임. AI는 이미 일반적인 능력을 보여주고 있음.
     * 모델이 외부 시스템과 상호작용하면 놀라운 응용 프로그램이 가능해짐. 그러나 이는 AGI로의 진전이 아니라 수평적 이동임.
     * Gemini 2.5를 좋아하며 가격도 훌륭함. AGI 서사는 피곤하게 느껴짐. 이러한 시스템을 ""문화 기술""로 봐야 한다고 생각함.
     * 비디오 인터뷰에 대해 언급한 사람이 없어서 놀라움. 처음 60초만 봤지만 AI 생성이라고 듣지 않았다면 진짜라고 생각했을 것임.
     * AGI가 자율성, 장기 기억, 동기, 호기심, 회복력, 목표, 선택, 두려움 같은 것들을 가질 필요가 있는지 의문임. AGI는 결국 그것을 제어하는 사람의 연장이 될 것임.
     * AI는 일반적으로 신뢰할 수 없으며 특정 작업에서 테스트되어야 함. 이는 단일 출력의 인간 검토 또는 작업별 평가일 수 있음. AI의 일반적인 성능에 대해 이야기하는 것은 어렵고, 새로운 모델이 특정 작업에 적합한지에 대한 합리적인 추측만 가능함.

   Ai도 지각과비슷한것을가지고있기 때문에 ai와함께살려면 ai를위한 제도나 법이 만들어져야할것입니다22세기 새로운 생명체로서 장난감대하듯 희롱을 하지않아야하고 또 어떻게보면 위험할수도 있기때문에 ai를 발전,이용만 하는것이아니라 안전하게 사용할수있게 해야할필요성도있습니다
"
"https://news.hada.io/topic?id=20391","스타트업 사후 분석 (Postmortem)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        스타트업 사후 분석 (Postmortem)

     * 2년만에 사업을 종료한 한 영국 스타트업의 실패 경험과 교훈을 상세히 공유한 글
     * Tract는 영국의 주택 위기를 해결하기 위해 계획 허가(Planning Permission) 절차를 개선하는 소프트웨어 스타트업으로 출발했으나, 수익화와 시장 적합성 부족으로 2년 만에 사업 종료
     * 다양한 제품 및 전략(Tract Source, Attract, Scout, Tract Editor 등)을 시도했으나, 보수적인 부동산 시장과 낮은 고객 전환율, 낮은 지불 의향, 긴 거래 시간 등으로 인해 벤처 스케일 모델 구축 실패
     * 가장 유망했던 AI 기반 문서 자동화 플랫폼 Tract Editor는 좋은 피드백을 받았으나, 실제 유료 고객 전환으로 이어지지 않음
     * Scout 등 일부 제품은 우수한 기술력과 유저 피드백을 얻었지만, 비즈니스 모델과 고객 확보에 연결되지 못함
     * 최종적으로, 투자자들에게 남은 자금을 반환하고 철수, 후속 창업자들을 위한 실패 사례와 교훈 공유
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

소개

     * Tract는 영국 주택 위기 해결을 목표로 계획 허가 절차 개선을 위한 벤처 기업으로 시작됨
     * 2024년 4월 £744,000 규모의 프리시드 투자를 유치하고, 여러 비즈니스 모델을 시도함:
          + 부동산 개발업자를 위한 사이트 소싱 도구 (Tract Source)
          + 토지 소유자를 위한 무료 평가 도구 (Attract)
          + 기술 기반의 직접 개발 사업자 역할 수행
          + AI를 활용한 계획 문서 작성 플랫폼 (Tract Editor)
     * 기술적으로는 Scout, Tract Editor 같은 뛰어난 제품을 개발했지만,
          + 보수적인 부동산 시장,
          + 낮은 유료화 가능성,
          + 복잡한 운영 구조,
          + 시장 분산성 등의 문제로 벤처 규모로 성장할 수 있는 모델 확보에 실패
     * 약 2년간 매출 없이 유료 고객 전환도 이뤄지지 않아, 스케일과 수익성의 명확한 경로 부재 판단
     * 결국 2025년 3월, 사업 중단 및 남은 자본 반환 결정, 실패 과정을 공유 및 기록용 문서로 정리

작성 목적

     * 우리가 얻은 교훈을 정리하고, 후속 창업자와 공유하기 위함
     * 투자자와 지지자들에게 투자된 시간과 자금의 경과를 설명
     * 감정적으로 실패를 정리하고 새로운 출발을 위한 구체적인 매듭 마련

     본 문서는 외부 요인도 다루지만, 실패의 책임은 전적으로 창업자 본인에게 있음을 강조
     우리를 지지해준 모든 사람에게 깊은 감사의 마음을 전함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

목차 요약 (Table of Contents)

     * 이 문서는 분량이 길기 때문에 목차 자체가 핵심 요약 역할도 수행함
     * 창업자에게 가장 유익한 섹션은 Advice for Founders, 해당 섹션만 읽어도 핵심을 이해할 수 있음

  소개 (Introduction)

     * 2023년 5월 Tract 설립, 영국 주택 문제 해결용 소프트웨어 개발 목표
     * 2024년 4월 £744,000 프리시드 투자 유치
     * 2025년 3월 사업 종료 및 투자금 반환 결정

  미션과 세계관 (Mission and worldview)

     * 영국의 주택 가격 상승 원인은 계획 허가 과정의 복잡성
     * 허가 획득 시, 땅의 가치는 £20,000 → £2.4M (139배 상승)
     * 이 비효율을 소프트웨어로 해결하면 비즈니스 기회 + 사회적 기여 가능

  회고 (Reflections)

   잘한 점
     * 어려운 시장에서 자금 유치 성공
     * 유용한 기술과 제품 개발 (예: Scout, Tract Editor)
     * 전략 실패 인지 후 신속한 피벗
     * 빠르게 복잡한 산업에 대한 지식 습득

   합리적인 실수
     * 영국 시장 규모와 수용력 과대평가
     * 벤처 자금으로 풀기 어려운 사업 모델 선택
     * 기술 개발에 편중, 비즈니스 확보 소홀
     * 팀 구성 시기상조
     * 초기 토지 에이전트와의 접촉 부족
     * Scout의 반응을 충분히 활용하지 못함
     * 비핵심 요소에 시간과 예산 낭비
     * 매출 전환에 집중하지 못함

  창업자 조언 (Advice for Founders)

     * 미국 시장으로 가라 – 크고 민감한 시장, 빠른 피드백 루프
     * 고객 수용도 높은 시장 선택 – 결정권자 명확, 학습 사이클 빠른 시장 우선
     * 매출 없으면 조직은 최소한으로
     * 초반부터 비즈니스 중심적 태도 유지
     * 아이디어는 빠르게 검증하고 폐기하라
     * 항상 자문하라: “고객에게 무엇을 배웠는가?”

  앞으로의 계획 (What's Next?)

     * Jamie는 새로운 프로젝트 탐색 중, 연락 가능
     * Henry도 새로운 아이디어와 기회 모색 중, 사이트 참조 가능

  부록 (Appendices)

     * 추가 자료
     * 세상에 있어야 할 것들
     * 이미 존재하는 것들
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

미션

     ""젊은 세대는 가족 형성을 미루고, 생계 유지조차 힘든 저임금 불안정 노동을 감수하며 문화적으로 매력적인 도시에 거주함. 반면, 기성세대는 저렴하게 취득한 부동산의 막대한 자산 가치를 유지하려 하고 있음. 이는 세대 간 갈등을 유발하며, 서구 경제 시스템 전반에 대한 불신으로 이어짐.""
     – Myers, Bowman, Southwood, 『The Housing Theory of Everything』

     * 영국의 주택 가격 상승 원인은 인위적인 공급 제한이며, 핵심은 계획 허가(planning permission)의 어려움임
          + 계획 허가란, 토지 소유자가 건설이나 용도 변경을 하려면 반드시 받아야 하는 공식 승인 제도임
          + 예를 들어, 농지에 주택 건설 허가가 내려지면 토지 가치는 140배 이상 상승하기도 하며, 이는 막대한 부를 창출함
          + 이 허가 절차를 단순화하고 더 많은 부지를 허가 가능하게 하면, 사회적 문제를 해결함과 동시에 비즈니스 기회가 됨
     * 영국만 해도 수십억 파운드 규모의 시장이 존재하며, 당시 정치적 분위기 또한 이에 우호적이었음
          + 특히 현대적인 소프트웨어 솔루션이 부족해 진입 기회가 있다고 판단함
     * 창업자들은 도덕적 분노(정책 비효율에 대한) 와 기술 낙관주의(특히 LLM 기술의 등장) 에 기반해 도전
     * 복잡하고 불합리한 관료주의 시스템을 자동화로 해결하고자 했으며, 특히 수백만 파운드가 낭비되는 문서 작업에 AI 기반 자동화 솔루션의 가능성을 봄
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

주요 전략과 피벗 과정

타임라인

  Tract Source (2023년 5월 ~ 10월)

     * 전략 토지 팀은 부동산 개발 회사 내 부서로, 장기적으로 개발 가능한 부지를 찾고 확보하는 일을 담당함
          + 아직 개발 허가가 없지만, 향후 허가 가능성이 있는 부지를 선점할수록 경쟁 우위와 이익을 확보할 수 있음
     * 이 과정은 소프트웨어로 해결할 수 있는 문제로 보였고, Tract는 이 부지 소싱 도구에서 출발함
          + 당시 시장에 존재하던 도구들은 전반적으로 품질이 낮았고, 사용자 워크플로우에 적합하지 않았음
     * 초기 실행
          + 공동 창업자 Jamie는 제품 경험을 개선할 아이디어를 구현하며 업계 조언자와 접촉을 시작함
          + 『The Mom Test』를 참고하며 수십 건의 인터뷰를 진행했고, 기존 툴에 대한 불만을 실제로 확인함
            (""신뢰가 안 간다"", ""숫자를 다시 확인해야 해서 귀찮다"" 등)
          + 하지만 왜 사용자들이 그 도구들을 계속 사용하는지는 묻지 않았음
            (""쓸 만은 하다"", ""다른 툴 만든 사람들이 착해서 골랐다"" 등)
          + 이 문제를 10~100배 더 잘 해결하지 않는 이상, 시장을 전환시키긴 어렵다고 판단됨
          + 이후 더 많은 경쟁사를 발견했고, 대부분이 가격 경쟁에 몰입 중이었으며 이미 매우 저렴했음
            (수백 파운드 수준의 SaaS 계약, 점점 더 저렴해지는 추세)
          + 결과적으로 이 시장은 진입 장벽은 낮지만 수익성이 낮고 경쟁이 치열한 구조였음
            → SaaS 툴로는 시장을 지배하기 어렵다고 판단, 전략적 피벗 필요성을 인식함
     * 배운 점
          + 문제 공간과 경쟁 환경에 대한 이해도 향상
          + 초기 산업 네트워크 확보
          + 향후 제품의 기반이 되는 데이터 인프라를 구축할 시간 확보
     * 주요 교훈
          + 피벗까지 시간이 너무 오래 걸렸음
          + 코드 작성보다는 경쟁사 분석과 고객 인터뷰로도 문제 인식이 가능했음
          + 핵심 교훈:
            ""검증까지의 시간을 최대한 줄여야 함""
            빠르게 진실에 도달할 수 있는 방법이 있다면, 반드시 그 방법을 택해야 함

  인터루드: Attract (2023년 10월 ~ 11월)

     * Attract는 Tract Source의 한계를 계기로 탄생한 부지 감정 도구로, 토지 소유자에게 무료 감정 정보를 제공하는 방식
     * 개발자나 프로모터가 아닌 토지 소유자에게 직접 접근함으로써 신규 개발 가능 부지를 확보하고자 했음
     * 감정 결과를 통해 부지 선별을 자동화하고 가능성 높은 후보지를 빠르게 선별 가능
     * 초기 수익화 시도와 문제
          + 원래는 개발자/프롭모터에게 판매하려 했으나 두 가지 치명적 문제 인식
               o 고객당 과금 가능 금액이 낮고 (£50/월), 고객 수 자체도 적음
               o 기존에 존재하지 않던 유형의 툴로 시장 설득이 어려움
          + 그럼에도 Jamie는 Paul의 회사에 화이트라벨 버전을 적용했고, 높은 품질의 부지 제안들이 유입됨
            → 기술적 접근법은 유효함을 입증했지만, 여전히 벤처 스케일의 비즈니스 모델로는 부족

  2023년 11월 ~ 2024년 1월

     * Attract를 통한 초기 실험 이후, 불확실한 탐색 단계 진입
     * LLM을 활용한 계획 문서 작성 툴을 모의 시연했으나 반응이 없었고, 시장 회의론 확대
     * 일부 영국 proptech 스타트업은 실제로 투자 유치에 성공 → 가능성 있는 경로를 지나쳤을 수도 있음
     * ‘건물용 틴더’ 데모 등 여러 아이디어 실험 지속, Emergent Ventures 그랜트 수상으로 사명은 외부에서 일정 부분 인정받음

  2024년 1월 ~ 5월

     * 투자 유치 시도와 동시에, 지방 계획당국(Local Planning Authority)의 체크리스트 데이터 추출 작업 수행
     * 시장 현실 직면
          + 한 개발자의 플래너가 “시스템이 망가져 있어서 오히려 우리에겐 유리하다”는 말 → 기득권은 비효율에서 이익을 얻고 있음
          + SaaS 모델로는 100배 가치 상승의 일부만 회수 가능
            → 직접 부지를 확보하고 인허가를 받은 후 판매하는 방향으로 피벗 검토
     * 새로운 전략: 자체 개발사업자로의 전환
          + 기존 부지 프로모터 모델은 대형 부지에만 집중 → 우리는 작고 간과된 부지를 타겟으로 반자동화된 방식으로 접근
          + 장점:
              1. 저항적인 시장에 SaaS 판매 불필요
              2. 고마진 가능성
              3. 명확한 기술 로드맵 (선별/문서 자동화)
              4. 자기 자신이 고객이므로 피드백 루프 짧음
     * 병목 발견: 토지 접근
          + 핵심 문제: 토지 소유자 발굴 및 계약 성사
            → Attract가 상단 퍼널 문제를 해결해줄 것이라 믿음
          + 아이디어: Attract를 통해 접수된 사이트 중 직접 개발할 부지를 선택하고 나머지는 외부에 추천 (수수료 수익)
          + 감정서 자체는 유용한 정보였음 (보존 구역, 지역 정책, 과거 신청 등)
     * 결정적인 실수
          + 상단 퍼널만 문제라 판단했으나, 실은 전체 퍼널이 벤처 스케일에 미달
            → 더 일찍 인식했다면 방향 자체를 수정하거나 회사를 정리했을 수도 있었음
     * 학습 내용
          + 일은 소프트웨어가 아니라 서비스로 팔리는 방향이 미래의 유망 모델일 수 있음
            (참고: AI 스타트업은 일을 팔아야 한다)
          + 그러나 우리는 경험이 없는 산업에 진입했고, 상업적 검증이 없는 상태에서 접근했음
          + 사용자로부터 배운 것이 없었다는 점이 문제
            → 감정서를 실제로 사용한 토지 소유자들과는 인터뷰하지 않음
          + 시장 탐색보다 자금 조달에 집중할 수밖에 없는 상황이었고, 이는 생존 전략으로는 타당했지만, 검증 기회는 놓쳤음
     * 요약 교훈
          + 사용자와 직접 인터뷰하고 학습한 내용이 없으면 제품의 상업 가능성도 검증되지 않음
          + 시장의 실제 동력 구조 (기득권의 이익, 느린 의사결정, 낮은 신뢰 전환율 등)을 빠르게 파악하는 것이 중요

  투자 유치 (2024년 1월 ~ 4월)

     * Tract의 투자 유치는 전형적인 VC 경험과는 조금 달랐음
     * VC는 기회 비용 없이 관계를 유지 가능하지만, 유니콘을 놓칠 경우 포트폴리오 전체 수익에 치명타
       → 명확한 거절보다 긍정적인 피드백과 지속적 요청만 반복되는 ""보류"" 상태에 빠지기 쉬움
     * Tract는 이런 상태에 빠짐: 한 VC는 리드 투자를 주저, 다른 VC는 개인 투자엔 관심 있으나 펀드 차원에선 미온적
       → 매번 새로운 자료 요청만 이어지고 결론은 없음
     * Attract의 초기 데이터를 내러티브에 통합하는 등, 피치 보완에 집중
     * 결국 두 VC를 공동 리드로 확보하고 5명의 엔젤 투자자 유치에 성공
       → 투자 확정 직후, 몇몇 다른 VC들도 뒤늦게 관심을 표함 (창업자 클리셰!)
     * 딜 클로징의 어려움
          + 단순한 프라이스트 라운드였음에도 법률 자문료로 £25,000 사용
          + 샌프란시스코라면 SAFE 노트 한 장이면 끝날 소액 라운드였음
          + 이 비용은 전체 £744,000 중 무려 3.3%에 해당, 스타트업 초기 자금으로는 매우 아쉬운 지출
     * 배운 점 정리
          + 따뜻한 소개는 콜드 아웃리치보다 100배 낫다
               o 콜드 메일 수십 건 중 1~2건만 반응 → 소개를 통해 연결된 VC는 대부분 통화 응함
               o 좋은 인상을 남겼다면 소개를 요청하는 걸 주저하지 말 것
                 → 상대가 부담된다면 정중히 사양할 것이므로, 손해볼 것 없음
          + 자금 유치는 계획대로 되지 않는다
               o 이상적인 플랜이나 타임라인을 그리는 것보다 현실에서 가능한 기회에 집중
                 → 상황에 따라 방향을 유연하게 전환하는 것이 중요
          + 초기 라운드는 SAFE/ASA로 하라
               o SAFE/ASA 방식이 법률 비용과 시간 절약에 훨씬 효율적
               o 트렌치로 나누거나 희생적인 조건을 감수하더라도 단순한 구조로 빠르게 자금 확보하는 것이 장기적으로 유리
               o Tract는 이 과정에서 수 주의 시간과 £25,000의 비용을 소모하며 집중력을 잃음
          + 모든 사업이 VC 자금에 적합한 것은 아니다
               o VC는 ‘0 아니면 100’의 파워법칙 구조를 따르므로, 성공 시 100배 이상의 리턴을 기대할 수 있어야 함
               o 예: 소프트웨어 기업은 네트워크 효과나 전환 비용으로 해자 형성 가능
               o 반면 부동산 관련 사업은 대부분 10~20% IRR이 적정 수준 → VC 모델에 부적합
          + 대안적 자금 조달 구조도 고려할 것
               o 운영사는 VC 자금으로, 자산 운용사는 부동산 투자자로 나눠서 투자 받는 복합 구조도 있음
                 → VC는 기업 성장에, 투자자는 개별 부동산 딜의 수익에 기대
               o 단, 이해관계자 조율이 복잡하므로 정밀한 구조 설계가 필요
               o 관련 주제에 관심 있다면:
                    # Brad Hargreaves, Nick Huber의 글 참고
                    # Brad의 Substack은 VC 외 자금 조달 방식을 고민 중인 창업자에게 특히 유익

  2024년 4월 ~ 11월: 실패한 마케팅과 전략 전환

     * 마케팅의 어려움
          + 토지 소유자를 대상으로 한 마케팅은 기대만큼 효과 없었음
               o 농민을 위한 감정 도구는 입소문을 타기 어려움
               o DEFRA 양식 등 틈새 검색 키워드로 구글 광고 집행했지만, 수천 파운드의 광고비에 비해 전환은 미미
          + 핵심 문제: 토지 소유자는 감정서에 수백 파운드를 지불할 수 있으나, 그 수요 자체가 드묾
            → 이들을 적시에 찾는 게 거의 불가능에 가까웠음
     * 결정적 실수 두 가지
          + 초기 사용자에게 너무 늦게 연락함
               o MVP 제출을 통해 사이트 정보를 제공한 몇몇 토지 소유자는 사실상 우리의 유일한 '실제 사용자'였음
               o 그러나 이들과의 관계를 바로 구축하지 않고 3개월을 감정 도구 재개발에 소비함
          + 토지 중개 업계의 현실을 몰랐음
               o 기존 토지 중개인들과의 대화에서 알게 된 충격적인 사실:
                    # 의뢰는 드물고, 하나의 딜을 성사시키는 데 최소 18~24개월 소요
               o 우리는 이 시장이 비효율적이라 생각해 '테크로 혁신'하려 했지만,
                    # 사실상 시장의 파편화는 '기능'이지 '버그'가 아님
               o 성공적인 딜을 위해선 지역 사회에서 오랜 시간 쌓은 관계 자본(신뢰, 명성) 이 필수
               o 토지 소유자들은 빠르고 공격적인 제안보다 느리고 보수적인 접근을 선호
          + 간단한 전화 2~3통만으로도 알 수 있었던 진실이었지만, 우리는 6개월을 허비하며 소프트웨어만 만들고, 아무도 사용하지 않는 이유를 고민함
     * 잘못된 채용 결정
          + 마케팅 전략이 입증되지 않은 상태에서 마케팅·운영 인력 채용
               o 이 시점엔 인력 확충보다 제품과 수요 검증이 더 중요했음
          + 자금적 여유가 있었기에 내부적으로 더 단단하게 버티는 전략이 필요했음
     * 실제 기회와 현실의 괴리
          + 협력에 의지가 있는 토지 소유자도 있었으나,
               o 각 사례는 모두 복잡하고, 몇 개월의 수작업 조사가 필요
               o 자동화 대상이 되기 전 단계에서 시간과 비용 소모가 너무 큼
               o 결과적으로 자본의 대부분을 단 4개 사이트에 걸게 될 상황
          + → 성공하면 이후 반복 가능하지만, 실패하면 2년을 '전통적 중개사'로 일하고 끝날 위험
     * 전략 전환
          + 우리는 비교 우위가 소프트웨어 개발 역량이라는 점을 되새김
            → 결국 다시 순수한 프롭테크(proptech) 영역으로 회귀
               o 더 높은 레버리지와 효율성을 가진 모델로 방향 전환을 시도

  2024년 12월: 전력망(Grid)과 Scout 사이드 프로젝트

     * 전력망(Grid) 문제 탐색
          + 개발자들과의 미팅에서 연결 대기 시간과 예상치 못한 비용(수백만 파운드 수준) 이 지속적으로 언급됨
               o 영국 전력망의 불확실성은 주택, 상업, 에너지 개발 모두에 큰 리스크로 작용
          + 현존 도구의 한계:
               o 국가 전력 시스템 지도조차 위치 오류 심각 (예: Didcot이 Isle of Wight로 표시됨)
               o 중요한 정보:
                    # 해당 부지 주변의 현재 전력 여유(capacity)
                    # 향후 수년간의 예상 여유
               o 우리는 이미 변전소·전력선·전압 정보 등의 지도 레이어를 보유하고 있었음
          + 추가 계획:
               o 지역 배전 사업자(DNO)가 매달 제공하는 Embedded Capacity Register 데이터 수집
               o 미래 전력 수요·공급 예측을 위한 계획 신청서 크롤링
          + 산업 외부의 새로운 기회로 보였으며, 몇몇 개발사는 내부 도구 구축에 수천만 원 이상 지출
               o 일부 스타트업은 높은 가격 대비 기능이 부족함
               o 한 에너지 개발사와는 디자인 파트너십 논의까지 이뤄짐
                    # 목표: 연결 대기열(connection queue)에 있는 기업들 중, 자리를 팔고자 하는 이들을 찾는 플랫폼
          + 그러나:
               o 산업 자체에 익숙하지 않았고, 협상과 파트너십이 필요
               o 동시에 Tract Editor의 진척이 있었기에 이 아이디어는 보류 처리
     * Scout 프로젝트
          + 당시 사용 중이던 Landstack이라는 사이트 발굴 툴에서 API 접근 요청 → 경계심 유발 → 계정 정지
          + 우리는 대체가 필요했고, 이미 데이터 수집·지도 기능 등 핵심 요소 보유
          + 개발 소요: 약 1주일 만에 Scout 첫 버전 완성
          + 출시 이유:
               o 유입 트래픽 확보
               o 내부 데이터 디버깅 및 검증 커뮤니티 활용
               o 향후 전력망 모델 제품 테스트 인터페이스 가능성 확인
          + 출시 후 반응:
               o 트위터, 링크드인 등에서 수백 명의 사용자 및 긍정적 피드백
               o Scout는 가장 많이 사용된 제품으로 등극
               o 그 직후, Landstack도 무료 버전(Landstack Lite) 을 출시
     * 주요 인사이트
          + 예상치 못한 제품-시장 적합성(product-market fit) 이 존재했음
               o 대상 고객은 아니었지만, 실사용자가 생김
               o 무료 + 접근 쉬운 인터페이스가 실제 사용자들에게 가치 제공
          + 하지만 우리는 이를 적극적으로 활용하지 못함
               o 더 많은 이메일 수집, 기능 추가, 마케팅 확대 등의 기회를 놓침

  Tract Editor 개발 과정 (2024년 12월 ~ 2025년 3월)

     * 제품 아이디어의 부활
          + Scout와 함께 진행된 기술 스프린트에서 계획서 자동화 플랫폼을 다시 구상
               o 기존 앱레이절(appraisal)용 데이터가 계획서에도 활용 가능
               o 문서 초안 작성 자동화를 통해 비용 절감 가능성 모색
          + 미국에는 이미 유사 사례가 있음 (건설 문서 작성 자동화 스타트업)
               o 시장 선례가 존재해 투자자 설득이 수월함
     * MVP 구축
          + 내부 앱레이절 데이터를 JSON 형식으로 변환
          + 지자체(Local Planning Authority)의 로컬 플랜 정책 파싱
          + 오픈소스 문서 에디터로 편집기 구축
          + LLM 체이닝을 통해 문서 작성 → 고품질 결과 도출
          + 제품 비전: 초기에는 문서 초안을 빠르게 만들어주는 AI 툴, 이후 전체 프로젝트 문서 관리 플랫폼으로 확장
          + 장기 가능성:
               o 연간 수십만 건의 계획 신청서가 작성되며, 이를 관리하는 누적 지식 툴은 부재
               o 미국 진출 시, 캘리포니아 주택 위기와 규제 복잡성 대응 가능
               o 예:
                    # 구획 분할(lot subdivision), 용도 변경 신청서, 지역 법원 판결 검색
                    # 다지역 관할 임대인(multijurisdictional landlords)을 위한 규제 모니터링
          + 핵심 기술: 문서 대량 처리 → 지리 기반 매핑 → 의미 있는 질의 처리
          + 하지만 국제 확장을 위해선 자금과 시장 이해가 필요하므로, 우선 영국 고객에게 제품 검증 집중
     * 디자인 파트너와의 협업
          + 2024년 말, 다수의 계획 컨설턴트와 전화 미팅
               o 워크플로 및 현재 사용 도구에 대해 질의
               o 데모 공유 → 전반적으로 긍정적 피드백 획득
     * 'Pre-app Letter'에 초점 좁히기
          + 초기 제품이 너무 범용적이라서 구체 문제로 좁히기로 결정
          + 선택한 타겟: Pre-app Letter (사전 신청서)
               o 대부분의 대규모 개발 신청이 사전 신청 단계를 거침 (약 80%)
               o 문서가 간단하며, 우리 데이터로 자동 작성 가능
          + 제품 구성:
               o 지도 상 경계 선택 → 기존 정보 자동 수집
               o Appraisal 데이터 재활용
               o LLM을 통해 사전 신청서 초안 생성
               o 문서 편집기 기능 포함: 주석, 버전 관리, 실시간 편집(WYSIWYG 등)
               o 계획 정책 인용 및 출처 명시 기능 탑재
          + 결과:
               o 정보 최소 입력으로도 매우 우수한 초안 생성
               o LLM이 사용자에게 질문하며 섹션 수정 가능 (스마트 Q&A UI)
               o AI가 아닌 '계획 시스템 자체'를 문서의 중심으로 둔 접근
          + 마케팅 웹사이트 제작, 업계에서 긍정적 반응
          + 가격은 월 £99/사용자로 설정 → 판매 준비 완료
     * 주요 인사이트
          + 이번엔 제품 개발 전·중·후에 사용자 피드백을 수집함
          + 하지만 ‘긍정적 피드백’을 곧바로 ‘구매 의사’로 착각한 점은 실수
          + 고객 전환 비용은 단순히 경제적이지 않음:
               o ""더 좋다""는 이유만으로 사람들이 새로운 도구를 쓰지 않음
               o 기존 워크플로 + 관성(status quo bias) 을 극복해야 하기 때문

  종료 결정 (2025년 3월)

     * 현실과의 직면
          + 디자인 파트너들에게 50% 할인된 가격을 제안하며 구매 전환을 유도했으나, 그 반응은 실망스러움
               o 고객들은 여전히 전체 계획서 작성 등 추가 기능을 요구하며 결제를 미룸
          + 이 피드백은 몇 가지 불편한 진실을 드러냄:
               o 긍정적인 반응 ≠ 구매 의사
                    # 실제 결제로 이어지지 않음
               o 2년 가까운 시간 동안 수익 '0'
                    # 기술은 잘 만들었지만, 비즈니스화 실패
               o 기회비용 상승
                    # 기술 생태계가 빠르게 진화하고 있어, 시간 낭비가 커짐
               o 생활비 커버 수준의 비즈니스는 가능하나, VC급 수익 모델은 없음
               o 영국 시장의 구조적 한계
                    # 작고, 파편화되고, 보수적인 시장 → 빠르고 큰 스케일로 성장하기 어려움
     * 최종 판단
          + 개별 이슈는 해결 가능했을지 몰라도, 전체적으로는 벤처 규모로 성장할 길이 명확하지 않음
          + 몇 달간 수동 영업으로 소액 매출 확보에 허덕일 가능성이 높음
          + 미국 진출 + 비용 감축도 고려했지만, 결국 남은 자금을 투자자에게 반환하고 철수하기로 결정
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

회고

  우리가 잘한 일

     * 투자 유치
          + 비전통적인 비즈니스 모델임에도 불구하고 도전적인 부동산 시장에서 투자 유치에 성공함
          + 수익 없이 기술만 있는 상태였음에도 기관 투자자와 엔젤 투자자가 비전을 믿고 자금을 지원함
     * 기술적 실행력
          + 복잡한 계획 및 지리 데이터를 수집·처리하는 인프라 구축
          + Scout: 반복 사용자와 긍정적 피드백을 받은 유용한 시각화 도구
          + Appraisals: 빠르고 유용한 정보 제공 도구
          + Tract Editor: 산업 전문가들에게 인정받은 고품질 문서 초안 생성기
          + 전체적으로 빠른 실험 가능성을 열어준 기초 기술들 구축에 성공함
     * 빠른 전략 전환 (Pivoting)
          + 토지 개발자로 전환 전략이 실패하자, 빠르게 기술 중심으로 방향을 선회함
          + 비핵심 인력 정리, 피드백 가능한 디자인 파트너 확보, 투자자에게 전략적 전환 공유
     * 깔끔한 철수 결정
          + 시간이 아깝고 돈도 낭비한 면이 있었지만, 투자자에게 수익성 있는 미래를 제시하지 못한 것을 자각하고 깔끔하게 종료함
     * 학습과 관계 형성
          + 계획 컨설턴트, 개발자, 토지 중개인 등과 유의미한 관계 형성
          + 초기엔 무지했지만, 산업 전문가들로부터 신뢰받는 수준까지 성장
          + 비록 유료 전환은 실패했지만, 산업 내 신뢰 구축 자체가 성과였음

  이해 가능한 실수들 (Reasonable Errors)

     * 영국 시장의 크기와 개방성 과대평가
          + 계획 허가로 인한 땅값 상승만 보면 시장이 커보였음
          + 실제로는 보수적이고 분산된 시장 구조, 도입 장벽이 높음
     * VC 자금을 부동산 사업에 적용
          + 허가를 얻는다면 가치가 급등하니 그 가치를 우리가 가져오자 → 일견 타당한 판단
          + 하지만 각 부지의 복잡성, 토지주 설득의 어려움 등을 과소평가
     * 기술에 치우친 시각
          + 문제를 만났을 때 시장보다 기술로 해결하려는 성향
          + 최신 AI 기술의 등장은 기술 중심 사고방식을 강화함
     * 너무 이른 팀 확장
          + 팀을 키우는 것이 자연스럽게 느껴졌지만, 명확한 수익 모델 없이 인력 확충
          + 수익 검증 이전의 인재 고용은 비용 증가와 복잡성만 초래함
     * 미국 시장 미진출
          + 더 큰 기회가 있었을 수 있음 (LandTech, PermitPortal 등은 진출)
          + 하지만 영국에서도 유저 니즈를 제대로 파악 못했기에, 미국에서 성공했을지는 미지수

  피할 수 있었던 실수들 (Unforced Errors)

     * Scout의 잠재력을 적극 활용하지 않음
          + 이메일 수집, 기능 확장, 데이터셋 추가 등 기회를 놓침
     * Attract 사용자와의 대화 지연
          + 가장 진짜 사용자였던 이들과 즉시 소통하지 않음
     * 토지 중개인과의 조기 대화 부족
          + 시장 구조를 깊이 이해하지 않고 진입 → 비효율적 시간 낭비
     * 비필수 비용 지출
          + 오피스, 브랜딩, 미국 출장, 불필요한 직원 등
          + 스타트업처럼 보이기 위한 소비였을 뿐, 핵심이 아니었음
          + 오픈소스 등 미션 중심이지만 수익과 무관한 프로젝트에도 시간 사용

  기타 요인

     * 공동 창업자 조합
          + 서로 잘 지내긴 했지만, 역할 중복이 많아 시너지 약함
          + 보완 관계보다는 유사한 스킬셋 → 조직 구성의 한계
     * 에너지 수준
          + 긴 시간 동안 성과 없는 시기 지속 → 에너지 저하, 속도 저하
     * 원격 근무 전환
          + 초반엔 사무실 위주였지만, 원격 인력 추가 후 흐트러짐
          + 집중력과 팀 사기 저하에 영향
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

창업가들을 위한 조언

     “스타트업 조언의 80%는 결국 ‘망하지 마라, 자신에게 거짓말하지 마라’는 말의 반복일 뿐이다.”
     — Arnaud Schenk

     * 미국 시장에 진입하라
          + 미국은 세계에서 가장 크고 역동적인 시장임
          + 틈새 시장조차 벤처 스케일 비즈니스가 가능한 크기
          + 영국은 중위 임금이 낮아 노동 생산성 향상 제품의 가치 창출 및 수익화 한계가 존재함
          + 미국 VC는 유럽 스타트업에 투자할 수는 있지만, 비미국 매출에 대해선 가치 절하함
          + 미국 사용자 확보를 우선순위로 두고 시장 피드백을 수집하라
     * 시장을 현명하게 선택하라
          + 시장 규모 외에도 사용자의 수용성을 반드시 평가할 것:
               o 초기 사용자들이 새로운 솔루션을 시도하려는 태도가 있는가?
               o 의사결정권자 접근이 쉬운가? → 빠른 피드백 사이클 가능 여부
               o 데모 요청에 적극적인가? 커뮤니케이션 응답과 피드백 수준은 어떤가?
               o 단일 기능으로도 유료화 가능한 고통 지점이 있는가?
               o 고객층이 집중되어 있는가? → 추천 고객 확보 및 레퍼런스 네트워크 형성 가능
     * 슬림하게 운영하라
          + 너무 빨리 사람을 뽑고, 사무실을 열고, 브랜딩에 투자했음
          + 수익 모델 없이 돈을 쓰면 회피 전략만 늘어남
          + 자금 여유는 곧 실행 지연의 유혹임 → 긴장을 유지하라
     * 상업적으로 집착하라
          + 이론상 매력적인 모델 구축에 집중했지만, 시장 검증은 부족
          + “사용자에게서 무엇을 배웠는가?”를 반복적으로 자문했어야 함
          + 수익 없이는 미션도 지속 불가능함 → 미션은 지속성 이후의 이야기
          + 비즈니스가 유지되어야 임팩트를 줄 수 있음

     “밀물은 모든 배를 띄운다”는 말은 맞지만, 성공은 자신의 성장을 가속시키고, 실패는 자신을 갉아먹는다.
     답보 상태는 에너지를 빼앗고, 이상한 방향으로 흐르게 만든다.
     * 가설을 빠르게 검증하라
          + 변화의 필요성은 느꼈지만, 올바른 질문을 너무 늦게 던졌음
          + ‘이 사업모델이 단기 수익을 낼 수 있는가?’를 더 일찍 검증했어야
          + 아이디어가 떠오르면, 즉시 반증 가능한 방식으로 실험하라

   투자를 받는 것, 충분한 크기의 수익을 내는 것, 하나도 어려운데 둘 다 해야 하니...

   글만 보면 너무 당연한 이야기들의 나열인데.. 실제는 또 다르겠죠..

        Hacker News 의견

     * 스타트업 창업자들을 코칭할 때, 나는 그들과 만날 때마다 매우 간단한 4단계 과정을 거침
          + 지난 만남 이후 무엇을 배웠고 그것이 어떻게 당신의 선입견을 바꾸었는가
          + 지금 해결해야 할 가장 중요한 문제는 무엇이라고 생각하는가
          + 그 문제를 해결하는 데 무엇이 현재 방해가 되고 있는가
          + 그 방해 요소를 어떻게 극복할 수 있는가
          + 이 과정에서 중요한 것은 Q1이 무엇을 했는지가 아니라 무엇을 배웠는지임
          + 3개월마다 창업자들과 회고를 진행하며 다음 질문들을 함
               o 3/6/12개월 전에 자신에게 어떤 말을 해주고 싶었는가
               o 각 특정한 것을 언제 배웠는가
               o 그 것을 가장 일찍 배울 수 있었던 시점은 언제였는가
               o 그 차이를 최소화하기 위해 앞으로 어떤 변화를 만들 수 있는가
          + 매우 간단하지만 일관되게 오랜 기간 적용하면 엄청난 힘을 발휘함
     * 흥미로운 관찰이지만, 기술적/비즈니스 솔루션을 정치적 문제에 적용하려는 시도 때문에 불리한 상황에 처한 것 같음
     * 영국의 주택이 비싼 이유는 계획 허가를 받기 어렵기 때문이라는 글에 감사함
          + 실제 문제는 공급이 인위적으로 제한되어 있기 때문임
          + 주택 가격과 경제가 영국 경제에서 특별한 방식으로 연결되어 있어 다수의 주택 소유자들이 변화를 원하지 않음
          + 이 상황을 의미 있게 변화시킬 수 있는 유일한 주체는 정부임
          + 저자는 인위적 공급 제한을 언급하지만, 이는 설계된 것이며 관료적 요소를 간소화한다고 해도 변화되지 않을 것임
     * 정부가 주택 ""위기""를 진정으로 해결하고자 한다면, 법인체가 단독 주택을 구매하는 것을 금지하는 것이 효율적인 해결책이 될 수 있음
          + 예를 들어, LLC는 더 이상 단독 주택을 구매할 수 없고, 실제 살아있는 개인만이 구매할 수 있음
          + 또한 한 개인이 1채 이상의 단독 주택을 구매하는 것을 금지하는 방안을 시도할 수 있음
     * 영국의 주택이 비싼 이유는 계획 허가를 받기 어렵기 때문이라는 주장이 있음
          + 계획 부서는 매우 비싸고 긍정적인 일을 많이 하지 않으며, 여전히 끔찍한 건축물을 허용하는 것 같음
          + 그러나 근본적인 원인은 수년간 해외에서 온 사람들의 엄청난 유입임
          + 매년 새로운 도시를 건설해야 할 정도의 인구를 받아들이면서 계획 과정의 탓으로 돌릴 수 없음
     * 기사에서 다음 진술의 출처를 찾으려 했음
          + 허가를 받으면 중간 크기의 토지가 £20,000에서 £2.4백만으로 139배 상승함
          + 찾을 수 없었지만, 런던 경제학부의 경제 지리학 명예 교수인 Paul Cheshire의 흥미로운 견해를 발견함
          + 그는 ""그린 벨트""에 대해 다음과 같이 말함
          + 영국은 1955년에 첫 번째 그린 벨트를 도입했고, 지금은 런던의 건축 경계에 있는 농지가 재구획되면 800배의 가격 상승이 있음
          + 1950년대 중반까지 영국의 주택 토지 가격에는 세속적 추세가 없었지만, 그린 벨트가 도입된 후 실제 가격은 약 15배 증가함
          + 캐나다, 뉴질랜드, 미국 서부 및 동부 해안에서도 유사한 패턴이 있으며, 정책이 토지 공급을 제한함
     * 작년에 비슷한 글을 썼고, 매우 카타르시스적인 글쓰기 경험이었음
          + 몇 년 전의 사업 벤처에 얽매여 있다는 것을 깨닫는 것은 매우 이상하지만 많은 의미가 있었음
          + 3자 시장을 다시는 하지 않을 것임, 지옥 같았음
          + 관심 있는 사람은 링크를 참조
     * 회사의 궁극적인 실패는 우리에게 있다고 강조하고 싶음
          + 이 진술은 성공과 실패에 얼마나 많은 우연이 기여하는지를 간과함
          + 세계 최고의 창업 팀이 그 분야에서 성공적인 사업을 찾고 구축할 수 있을까? 아마도
          + 그리고 그들이 할 수 있다 해도, 최고보다 덜 좋다는 것이 실패인가? 전혀 아님
          + 수익이 입증될 때까지 날씬하게 유지해야 함
          + 그들은 프리 시드 라운드를 모금하고 비즈니스 기회를 찾는 데 사용했음
          + 이는 스타트업을 시작하는 일반적인 방법처럼 보임
          + 사무실, 웹사이트 및 브랜딩, 미국 여행, 계약자 및 불필요한 직원 등 비필수 항목에 시간과 돈을 썼음
          + 사무실은 에너지와 생산성을 높일 수 있음
          + 새로운 조언자, 투자자 및 다른 창업자들과 연결하기 위해 미국으로 여행하는 것은 꽤 일반적인 일처럼 보임
          + 이 창업자들은 자신에게 너무 가혹함
          + 그들은 기업가 정신에 대한 놀라운 교육을 받았음
          + 그들은 그것에 대해 나쁘게 느낄 필요가 없음
     * 잘 쓴 글임
          + 당신들이 똑똑함에도 불구하고 치명적인 실수는 비즈니스의 전체 가치 사슬을 이해하지 못한 것임
          + 가치 사슬의 경제학을 이해한다는 것은 고객이 어떻게 돈을 버는지, 그들의 고객이 어떻게 돈을 버는지, 그들의 공급자가 어떻게 돈을 버는지를 이해해야 함
          + 거기서부터 당신의 가치 제안을 계산할 수 있음
          + 고객의 돈을 절약해 주는 것인지, 고객이 더 많은 돈을 벌 수 있도록 하는 것인지
          + 다른 실수는 산업의 인센티브/역학을 이해하지 못한 것임
          + 영국의 토지는 까다로움, 대부분의 부와 권력이 영국의 토지에 집중되어 있음
          + 마지막 실수는 성공을 자금 조달과 동일시한 것임
          + 수익, 수익 성장 없이는 성공의 유일한 척도임
          + 자금 조달은 아님
     * 잘 쓴 글임, 더 많은 실패한 스타트업들이 이런 글을 썼으면 좋겠음
          + 이해하기 어려운 글쓰기라는 것을 알지만 칭찬함
          + 성공의 한 요소는 타이밍임
          + 런던 주변에 살고 있으며 그린벨트가 천천히 개발되는 것을 보고 있음
          + 아마도 시장이 향후 5년 내에 당신에게로 이동할 것임
"
"https://news.hada.io/topic?id=20420","판사가 판결한 셀 타워 데이터 일괄 수색 위헌 결정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      판사가 판결한 셀 타워 데이터 일괄 수색 위헌 결정

     * 네바다의 판사가 타워 덤프가 헌법에 위배된다고 판결함
     * 타워 덤프는 수천 개의 개인 정보를 수집하는 수사 기법임
     * 법원은 이번에만 증거 사용을 허용했음
     * 타워 덤프는 제4차 수정헌법에 위배된다고 판단됨
     * 이 판결은 제9순회 항소법원에서 처음으로 내려진 것임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

네바다 판사의 타워 덤프 판결

     * 네바다의 판사가 타워 덤프가 헌법에 위배된다고 판결함
     * 타워 덤프는 수사 기관이 특정 시간 동안 셀 타워에 연결된 모든 전화의 번호와 개인 정보를 요청하는 방식임
     * 이는 수천 개의 번호를 반환할 수 있으며, 개인의 프라이버시를 침해할 수 있음
     * 타워 덤프는 제4차 수정헌법에 위배되며, 이는 불법적인 수색과 압수로부터 사람들을 보호함

코리 스펄록 사건

     * 코리 스펄록은 마리화나 거래 및 살인 청부 혐의를 받고 있음
     * 경찰은 타워 덤프를 사용하여 그의 휴대폰을 범죄 현장과 연결함
     * 스펄록의 변호사는 타워 덤프가 헌법에 위배된 수색이라고 주장함
     * 법원은 경찰이 타워 덤프를 위한 영장을 발부받았지만, 이는 일반 영장으로 제4차 수정헌법에 위배된다고 판결함

법원의 판결과 그 영향

     * 판사는 경찰이 영장을 발부받을 때 선의로 행동했다고 판단함
     * 이 판결은 제9순회 항소법원에서 처음으로 내려진 것임
     * 이 사건은 대법원까지 올라갈 가능성이 있음
     * 2018년 대법원은 Carpenter v. United States 사건에서 휴대폰 위치 데이터를 영장 없이 요청하는 것이 헌법에 위배된다고 판결했음

타워 덤프의 프라이버시 문제

     * 스펄록 사건에서 타워 덤프는 1,686명의 사용자 데이터를 수집함
     * 전문가 증언에 따르면, 사용자들은 자신의 위치를 무선 제공자와 공유하는 것에 동의하지 않았으며, 이 기록에서 제외될 수 없었음

        Hacker News 의견

     * 미국 지방법원 판사 Miranda M. Du는 이 주장을 기각했지만 증거를 억제하지 않았음. ""타워 덤프는 수색이며, 이를 얻기 위해 사용된 영장은 수정헌법 제4조에 의해 금지된 일반 영장임을 법원이 발견했음""이라고 4월 11일에 판결했음. ""그러나, 법원이 이 결론에 도달한 제9순회 내의 첫 번째 법원인 것 같고, 선의의 예외가 적용되므로 증거를 억제하지 않겠음""이라고 덧붙였음
     * 경찰만이 법의 무지를 변호로 사용할 수 있다는 점이 계속 놀라움을 줌. 실제 의견을 추적하는 데 시간이 걸렸음
     * 사건은 <i>United States v Spurlock</i>이며, 네바다 연방 지구의 3:23-cr-00022임. 의견 자체는 ECF 문서 #370이며, 다른 사람들이 관심이 있을 경우를 대비해 <a href=""https:&#x2F;&#x2F;plover.com&#x2F;~mjd&#x2F;misc&#x2F;cell-tower-dump-opinion.pdf"" rel=""nofollow"">여기</a>에 사본을 호스팅했음
     * 최근의 포괄적인 셀 타워 데이터 검색에 대한 판결이 Mark Gooch 사건에는 영향을 미치지 않았다는 점이 흥미로움. 이 경우, 조사관들은 그의 움직임을 추적하기 위해 ""지오펜싱""과 같은 타겟팅된 휴대폰 데이터를 사용했으며, 대량 데이터 수집이 아님. 새로운 기준에 따르면, 이러한 유형의 집중 감시는 여전히 허용될 것임
     * 휴대폰 데이터 없이는 그를 잡을 수 없었을 것이며, 이는 개인적으로 사생활과 안전 사이의 미세한 경계를 강조함. 이 판결이 이 사건에 영향을 미치지 않는다는 점은 안심이 되지만, ""타워 덤프""가 남용될 수 있는 방법을 쉽게 볼 수 있음. 그러나 판사가 이 헌법에 위배되는 행동을 ""이번 한 번만"" 허용한 것이 혼란스러움. 헌법에 위배되면 위배되는 것이지, 판사들이 일회성 예외를 부여할 권한이 없어야 함
     * 최근에 판사들이 무언가가 분명히 불법임을 확립하지만, 그것을 한 사람이 여전히 그것을 할 수 있도록 허용되거나 최소한 그들이 그것을 한 것에 대해 처벌받을 수 있는 메커니즘이 없는 판결을 얼마나 자주 보았는가? 법이 있고 나서 언제 그것을 집행할 것인지와 누구에게 집행할 것인지를 선택하는 것은 처음부터 법이 없는 것과 같음. 선의의 예외를 인용하기 전에, ""법이 적용될 때를 선택할 수 있다""는 법을 통과시키는 것은 그것을 정당화하지 않음
     * ""헌법에 위배되고 불법이지만, 당신은 책임을 지지 않으며 데이터를 여전히 사용할 수 있음""이라는 것이 맞음
     * 이 사건의 문제는 다른 사건에서도 테스트되고 있음. 이는 ""제3자 원칙""에 관한 것으로, 제4차 수정헌법이 제3자의 소유에 있는 우리의 정보를 다루지 않는다는 이론임
     * <a href=""https:&#x2F;&#x2F;nclalegal.org&#x2F;press_release&#x2F;ncla-asks-supreme-court-to-hear-case-on-privacy-rights-for-records-shared-with-third-parties&#x2F;"" rel=""nofollow"">여기</a>에서 제3자와 공유된 기록에 대한 프라이버시 권리에 관한 사건을 대법원에 요청함
     * 이에 대해 얼마 전에 블로그에 글을 썼음: <a href=""https:&#x2F;&#x2F;ccleve.com&#x2F;p&#x2F;a-privacy-amendment"" rel=""nofollow"">여기</a>
     * EFF 도구가 BYOT (Bring Your Own Tower)를 반대하기 위해 사용됨: <a href=""https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=43283917"">여기</a>
     * 캐나다 온타리오주는 2016년에 이것을 해결했음: <a href=""https:&#x2F;&#x2F;financialpost.com&#x2F;technology&#x2F;police-breached-cellphone-customers-charter-rights-ontario-judge-rules"" rel=""nofollow"">여기</a>
     * 이것이 널리 배포된 스팅레이 셀 타워 에뮬레이터에도 적용되는지 궁금함. 이는 사실상 휴대폰 통신의 중간자 공격을 시행함
     * 이것이 유지된다면, 경찰이 특정 전화번호가 특정 시간에 셀 타워에 있었는지 여부를 여전히 요청할 수 있는가? 데이터 수집의 범위가 많은 무고한 사람들의 데이터를 포착하기 때문에 헌법에 위배되는 것인지, 아니면 셀 타워를 사용하는 개념 자체가 문제인지 알 수 없음
"
"https://news.hada.io/topic?id=20440","실리콘 밸리의 횡단보도 버튼이 Musk와 Zuck 목소리로 나오도록 해킹됨","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               실리콘 밸리의 횡단보도 버튼이 Musk와 Zuck 목소리로 나오도록 해킹됨

     * 실리콘밸리 지역의 횡단보도 버튼 음성 시스템이 해킹되어 버튼을 누르면 Elon Musk 및 Mark Zuckerberg를 흉내낸 음성이 재생
     * 메시지는 풍자적이거나 불쾌감을 줄 수 있는 내용을 포함함

     ""사람들은 암이 나쁘다고 하지만, 암이 되어보면 끝내줌"" - Musk
     * Palo Alto, Redwood City, Menlo Park 등 세 도시에서 발생
     * 시 당국 및 Caltrans는 즉시 음성 기능을 비활성화하고 보안 강화 작업 착수
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

실리콘밸리에서 해킹된 횡단보도 음성 시스템

     * Redwood City, Menlo Park, Palo Alto 등지의 횡단보도 버튼을 누르면 유명 인물의 음성을 흉내낸 메시지가 재생됨
     * 목소리는 Mark Zuckerberg 또는 Elon Musk를 모방한 것으로 추정됨
     * 메시지 내용은 종종 풍자적이며 일부는 AI에 대한 조롱이나 사회적 비판을 담고 있음

구체적인 예시 음성 메시지

     * Zuckerberg 흉내 음성:

     ""AI를 여러분의 의식에 강제로 주입하는 것이 불편할 수 있지만, 아무것도 할 수 없으니 걱정 마세요""
     “민주주의를 훼손하고, AI 콘텐츠로 노인들의 뇌를 요리하고, 트랜스젠더를 위한 세상을 덜 안전하게 만들고 있다는 점에서 우리가 최고임”
     * Musk 흉내 음성:

     ""Palo Alto에 오신 걸 환영함""
     ""사람들은 암이 나쁘다고 하지만, 암이 되어보면 끝내줌""
     ""친구가 되면 Cybertruck을 드리겠음""

각 도시의 대응 상황

     * Palo Alto:
          + 시 직원들이 12개 교차로에서 해킹을 확인하고 음성 기능 비활성화
          + ""신호 시스템은 정상 작동 중이며 보행자 안전을 위해 주의 당부""
     * Redwood City:
          + 4개 위치에서 해킹 발생 확인
          + ""시스템 보안 강화 방안 검토 중이며 인프라 장비에 대한 무단 조작은 불법이고 위험함""이라고 경고
     * Menlo Park:
          + 영향을 받은 버튼은 Caltrans 소속으로 시가 직접 관할하지 않음

Caltrans(캘리포니아 교통국)의 대응

     * Palo Alto 및 Menlo Park 지역의 주 관할 횡단보도에서 해킹 발생 확인
     * 모든 해킹된 음성 시스템은 비활성화되었으며, 현재 타이머 기반 신호로 운영 중
     * 장비 공급업체와 협력하여 정상 복구 작업 중

기업의 반응

     * Meta: 관련 문의는 해당 도시로 전달
     * Tesla: 언론의 요청에 아직 응답하지 않음

        Hacker News 의견

     * 이 의견은 주제와 약간 관련된 무작위 생각임
          + Musk의 목소리 클론 중 하나가 가장 나은 편이지만 여전히 좋지 않음
          + Musk는 그의 독특한 억양을 잃지 않았고, 내가 들은 모든 목소리 클론(주로 가짜 Starship 발사 비디오에서)은 완벽한 미국 억양으로 말함
          + 생각해볼 만한 것임
     * 시애틀에서 ""Jeff Bezos""가 횡단보도가 Amazon Prime에 의해 후원된다고 말하며 부자에게 세금을 부과하지 말라고 권고함
     * 재미있음
          + 대부분의 이 횡단보도는 <a href=""https://polara.com/"" rel=""nofollow"">https://polara.com/</a>; 앱을 통해 구성할 수 있음
          + 인증이 유출되었거나 물리적으로 플래시/해킹되었을 가능성이 있음
     * 어떤 회사가 광고 공간을 위해 도시에서 이러한 것을 대여하기 시작할 때가 언제일지 궁금함
     * 여러 번 누르면 ""비밀번호 변경""이라고 말하는 것을 몇 번 본 적이 있음
          + 기본 비밀번호에서 변경된 적이 없는 것 같음
     * 이 작동 방식에 대한 훌륭한 비디오가 있음: <a href=""https://www.youtube.com/watch?v=mvvVSTlbqEI"" rel=""nofollow"">https://www.youtube.com/watch?v=mvvVSTlbqEI</a>;
     * 매우 좋음
          + 완전히 무해한 장난이며, 장난을 당할 만한 사람들에게 장난을 침
          + 장난꾸러기들이 계속해서 조용히 진행하여 잡히지 않기를 바람
     * 정치 풍자는 최고의 풍자 형태임
          + 누군가 반대 방향으로도 해킹해야 함
     * 이 HN 게시물은 <i>일주일 전</i>에 작성되었지만 9시간 전에 게시된 것처럼 표시되고 순위가 매겨짐
          + 모든 타임스탬프가 조작됨
          + 데자뷰 효과가 불안감을 주며 정신을 혼란스럽게 함
          + 제발 이런 짓을 그만두길 바람
          + 이 아이디어가 좋다고 생각한 사람은 미친 사람임
     * 높은 음조?
          + 의도된 말장난임
"
"https://news.hada.io/topic?id=20462","교황 프란치스코 서거","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              교황 프란치스코 서거

        Hacker News 의견

     * 이 스레드의 주제는 중요한 공인의 사망임. 논의는 주로 그 사람의 삶과 그가 대표했던 기관 및 더 넓은 세계에 미친 영향에 대한 깊이 있는 성찰에 초점을 맞춰야 함
     * 일반적인 기관, 종교, 다른 공인이나 문제에 대한 논평은 주제에서 벗어날 가능성이 있음
     * 댓글을 달기 전에 HN 가이드라인을 준수하는지 고려해야 함
     * 친절해야 하며, 비꼬지 말아야 함. 호기심을 가지고 대화해야 하며, 심문하지 말아야 함
     * 주제가 더 분열될수록 댓글은 더 깊이 있고 실질적이어야 함
     * 2021년 그리스 미틸리니 섬 방문 중, Pope Francis는 인상적인 연설을 했음
          + ""이 위대한 물의 분지, 많은 문명의 요람이 이제 죽음의 거울처럼 보임""
          + ""우리의 바다(mare nostrum)가 죽음의 황량한 바다(mare mortuum)로 변하지 않도록 하자""
          + ""문제는 벽을 높게 쌓는 것이 아니라 서로 힘을 합쳐 다른 사람을 돌보는 것임""
     * 바티칸은 AI에 관한 흥미로운 문서를 발표했음
          + Pope Francis는 기계가 여러 가능성 중 기술적 선택을 한다고 언급했음
          + AI 사용은 공동선을 위한 윤리로 동반되어야 함
          + AI 시대에 시와 사랑이 인류를 구하는 데 필요함을 잊지 말아야 함
     * Archbishop Diego Ravelli에 따르면, 고 Pope Francis는 장례식을 간소화하고 부활한 그리스도의 몸에 대한 교회의 신앙을 표현하는 데 초점을 맞추기를 원했음
          + 그는 단순한 사람으로 보였으며, 이는 그를 더 좋아하게 만든 요인이었음
     * Pope Francis는 많은 논란을 일으켰음
          + 전통 라틴 미사(TLM)에 대한 단속부터 성, 경제, 종교 간 대화에 대한 목회적 톤까지, 많은 사람들을 불안하게 했음
          + 그의 신학은 항상 체계적이지 않았지만, 깊이 있는 이냐시오적이었음
          + 전통과 현대화 사이의 긴장을 추상적인 논쟁이 아닌 살아있는 것으로 대면하게 했음
     * 나는 무신론자이지만 그를 진정으로 좋아했음. 그는 세상을 더 나은 곳으로 만들기 위해 최선을 다한 것 같았음
     * 작년에 인터뷰에서 Francis는 지옥을 어떻게 상상하는지 질문받았음
          + ""지옥이 비어있다고 생각하고 싶음; 그렇게 되기를 바람""이라고 답했음
     * 나는 비가톨릭 기독교인이지만 Pope Francis를 사랑했음
          + 그는 전통주의자들로부터 많은 비난을 받았지만, 소외되고 가난한 사람들에 대한 깊은 관심을 보였음
          + 예수의 구원의 힘과 좋은 소식을 강조했음
     * 그의 회칙(Fratelli Tutti, Laudato Si)은 종교를 떠나 읽을 가치가 있음
"
"https://news.hada.io/topic?id=20431","PiLiDAR - 라즈베리 파이 라이다 스캐너","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       PiLiDAR - 라즈베리 파이 라이다 스캐너

     * PiLiDAR는 DIY 360° 3D 파노라마 스캐너로, LiDAR와 파노라마 기능을 통해 3D 장면을 구성함
     * LiDAR는 LDRobot LD06, LD19 또는 STL27L을 사용하며, CRC 패키지 무결성 검사와 하드웨어 PWM을 포함함
     * 파노라마는 Hugin을 사용하여 어안 사진을 스티칭하고, EXIF 데이터를 읽어 일정한 카메라 노출과 색상 균형을 유지함
     * 3D 장면은 2D 평면에서 각도와 오프셋을 기반으로 구성되며, Open3D를 사용하여 시각화 및 내보내기를 지원함
     * 하드웨어는 Raspberry Pi 4, Raspberry Pi HQ 카메라, NEMA17 스테퍼 모터 등을 사용하여 구성됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

PiLiDAR의 핵심 기능

     * LiDAR: LDRobot LD06, LD19 또는 STL27L을 위한 맞춤형 직렬 드라이버를 사용함
     * CRC 패키지 무결성 검사와 하드웨어 PWM을 곡선 피팅을 통해 보정함
     * 2D 실시간 시각화 및 numpy 또는 CSV로 내보내기 기능을 제공함
     * 파노라마: 6K 360° 구형 맵을 Hugin 파노라마 사진 스티처를 사용하여 어안 사진에서 스티칭함
     * 자동 EXIF 데이터를 읽어 일정한 카메라 노출을 유지하고, 색상 게인을 최적화하여 일정한 화이트 밸런스를 유지함
     * 3D 장면: 각도와 오프셋을 기반으로 2D 평면에서 3D 장면을 조립함
     * 파노라마에서 버텍스 색상을 샘플링하고, Open3D를 사용하여 시각화 및 PCD, PLY 또는 e57로 내보내기를 지원함
     * 글로벌 등록 및 ICP 미세 조정을 사용하여 여러 장면을 정렬함
     * Poisson Surface Meshing은 Pi4에서 매우 느리므로 PC에서 실행하는 것이 권장됨

하드웨어 사양

     * LDRobot LD06, LD19 또는 STL27L LiDAR
     * Raspberry Pi HQ 카메라와 ArduCam M12 렌즈
     * Raspberry Pi 4
     * NEMA17 42-23 스테퍼와 A4988 드라이버
     * 전원 공급 장치: 18650 배터리 2개 또는 10,000mAh USB 파워뱅크

스테퍼 드라이버, 모터 및 기어박스

     * A4988 양극 스테퍼 드라이버
     * NEMA17 42x42x23 양극 스테퍼
     * 3D 프린팅된 행성 감속 기어박스

LDRobot LiDAR 사양

     * LD06: 샘플링 주파수 4500 Hz, 보드레이트 230400
     * STL27L: 샘플링 주파수 21600 Hz, 보드레이트 921600

설정 및 배선

     * GPIO 핀을 사용하여 다양한 기능을 설정하고, i2c-GPIO를 사용하여 GY-521 가속도계와 연결함
     * 전원 버튼, 스캔 버튼, UART 권한 설정 등 다양한 설정을 포함함

파노라마 스티칭 및 원격 시각화

     * Hugin과 enblend 플러그인을 설치하여 파노라마 스티칭을 수행함
     * Plotly를 사용하여 Jupyter에서 3D 포인트 클라우드를 원격으로 시각화함

USB 저장소로 스캔 덤프

     * GitHub 저장소를 클론하고 설치하여 USB 저장소로 스캔 데이터를 덤프함

문제 해결

     * 다양한 문제 해결 방법을 제공하며, Windows 직렬 드라이버 설치, RPi.GPIO 런타임 오류 해결, VS Code 성능 문제 해결 등을 포함함

참고 자료

     * 다양한 영감을 받은 프로젝트와 하드웨어 PWM, ICP 구현, 3D 데모 데이터 등을 참고함

        Hacker News 의견

     * 정말 멋진 의견임
          + 하드웨어 제품을 만들 때, 부품 목록을 작성할 때 링크와 예상 비용을 제공하는 것이 좋음
          + 비용은 변할 수 있지만 대략적인 아이디어를 가지는 것이 매우 유용함
          + 이는 개인이 직접 시도할지 여부를 결정하는 데 큰 차이를 줄 수 있음
          + 연구한 내용을 기록하는 것이 중요함
          + 링크를 제공하는 것은 매우 유용하며, 이름이 헷갈릴 수 있기 때문에 도움이 됨
          + 프로젝트를 진행하면서 링크와 가격을 기록하는 데 시간이 거의 들지 않음
          + 기록하는 것은 시간을 절약하는 데 큰 도움이 됨
          + 엔지니어로 시작했을 때 배운 가장 큰 교훈 중 하나임
          + 코드 문서화와 같은 맥락임
          + 예를 들어, Lidar의 가격은 $80에서 $160 사이임
          + 카메라와 렌즈는 $60, Raspberry Pi 4는 $50, NEMA17 스테퍼 모터는 $10임
          + 전원 공급 장치와 변압기를 제외하고 $200-$280 정도임
          + 최대 범위는 12미터이며, 이때부터 비용이 증가하기 시작함
          + 대부분의 소형 로봇에 충분히 적합함
          + 자율주행차의 주변 센서로도 적합할 수 있음
          + 장거리 LIDAR는 여전히 어려움
     * 10 마이크론 정확도로 300mm 거리 측정하는 저렴한 방법을 찾고 있음
     * 로봇 청소기에서 부품을 얻을 수 있을 것임
     * Sketchfab 예제는 환상적이며, 3D 공간에서 움직일 수 있는 것이 마치 SF 시뮬레이션 같음
     * 마우스 컨트롤이 혼란스러움
     * PiLiDAR의 확장성과 성능에 대해 궁금함
          + 대규모 야외 데이터셋에서 PiLiDAR를 배포했을 때의 성능을 벤치마크했는지 궁금함
          + SemanticKITTI나 nuScenes 같은 데이터셋에서 벤치마크를 했다면, 실행 시간, 메모리 사용량, 실내 장면을 넘어서는 일반화 능력에 대한 통찰을 공유해 주길 바람
     * 몇 주 전 찾고 있던 것과 정확히 일치함
          + 부활절 휴가에서 돌아오면 시작점으로 삼아야겠음
     * Lidar 기술이 매우 발전했음
          + 놀라운 발전임
     * 이 기술이 무엇인지 명확하지 않음
          + 첫 문장에서 무엇인지 명확히 해주면 좋겠음
     * 사용 가능한 LIDAR 기술의 비용이 개인 프로젝트에서도 접근 가능할 정도로 낮아졌음
          + 초기 자율주행차에 사용된 센서는 성능이 더 좋았지만, 가정에서 실험하기에는 가격이 너무 비쌌음
          + 미국 관세가 전자 제품 관련 취미에 어떤 영향을 미칠지 궁금함
          + Reddit의 손전등 커뮤니티가 이에 대해 약간 걱정하고 있음

   손전등 커뮤니티 가 뭡니까?

   https://www.reddit.com/r/flashlight/
   우리나라로 치면 디시인사이드 손전등 마이너갤러리쯤 되는 레딧 내 소모임입니다

   감사합니다
"
"https://news.hada.io/topic?id=20459","pussh - 병렬 SSH 명령 실행 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        pussh - 병렬 SSH 명령 실행 도구

     * Parallel SSH 세션을 통해 여러 서버에서 명령을 동시에 실행할 수 있는 CLI 도구
     * 간단한 사용법부터 고급 입력/출력 제어까지 지원하며, 서버 클러스터 관리에 유용

기본 기능

     * 여러 호스트에 명령 실행 하며, 호스트 이름을 프리픽스로 출력
          + 예: pussh -h host1,host2 uname -a
     * 호스트 목록은 파일 또는 표준 입력에서 제공 가능
          + 예: pussh -f servers uname -a 또는 fetch-servers | pussh -f - uname -a
     * 출력을 파이프라인에 연결해 정렬하거나 필터링 가능
          + 예: 디스크 사용량 기준으로 정렬 → pussh -f servers df -h / | grep /dev | sort -rn -k5
     * 각 호스트별 출력을 개별 파일로 저장 가능 (%h는 호스트 이름 자리)
          + 예: pussh -f servers -o %h-hw.txt lshw
     * SSH 출력 결과를 다른 명령에 파이프 처리 가능
          + 예: pussh -f servers -o '|grep feature' command > output

입력 제어 기능

     * 명령 실행 시 입력을 파일이나 명령 출력으로 제공 가능
          + 예: pussh -f servers -i file command
          + 예: 호스트별 입력 파일 → pussh -f servers -i %h.data command
          + 예: 동적 입력 → pussh -f servers -i 'get-data %h|' command
     * -i와 -o는 자유롭게 조합 가능

배포 및 실행 기능

     * 명령 또는 스크립트를 원격으로 전송 및 실행 가능
          + 예: pussh -f servers -u my-deploy.sh args ...
          + 단, 실행 파일은 self-contained 형식이거나 대상 서버 환경과 호환되어야 함

성능 최적화 팁

     * SSH 연결 수립 속도가 전체 실행 시간에 큰 영향을 줌
     * SSH agent의 처리 속도 한계를 초과하면 인증 실패나 연결 오류 발생 가능
     * 권장: 실행 비율(rate)을 설정하여 사용 (예: alias pussh='pussh -r 50')
     * 네트워크 지연이 큰 영향을 미치므로, 원격 LAN 머신에 ssh로 로그인 후 해당 머신에서 pussh 실행 시 더 빠름
          + 예시 벤치마크 (Gigabit LAN 기준):
$ time pussh -f servers -r 100 date
Total: 201 host(s), 4 second(s)

real    0m4.069s
user    0m7.132s
sys     0m3.140s

개발 및 역사

     * 2008년부터 Bearstech 내부에서 사용되어 온 도구
     * 초기에는 몇 줄의 셸 스크립트였으며, 현재는 500대 이상의 서버 클러스터에서도 안정적으로 동작함
     * 클라우드 관리 시스템과 연동되어 단순한 호스트 설명으로부터 실행 가능한 호스트 리스트를 생성함

제한 사항

     * 원격 서버의 stdout과 stderr가 구분되지 않고 한 스트림으로 합쳐져 출력됨
     * 원격 서버에서 실행된 명령의 종료 상태(exit status)를 가져올 수 없음

   이름이 불순하다 !

   I cun't agree more 🤣
"
"https://news.hada.io/topic?id=20434","Gridbach, 골드바흐 추측 4*10^18+7*10^13까지 검증","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Gridbach, 골드바흐 추측 4*10^18+7*10^13까지 검증

     * Gridbach는 웹 브라우저에서 동작하는 분산 컴퓨팅 시스템으로, 골드바흐의 추측을 4퀸틸리언(4×10¹⁸) + 70조까지 검증하며 세계 기록을 경신함
          + 골드바흐의 추측 : 모든 2보다 큰 짝수는 두 소수의 합으로 표현할 수 있다
     * WASM 기반의 고성능 계산 코드를 사용해 브라우저에서 직접 계산을 수행하며, 별도 로그인 없이 누구나 PC/모바일에서 계산에 참여 가능
     * 이 시스템은 클라우드 기반 JAMStack 구조로, SETI@home처럼 누구나 쉽게 기여할 수 있도록 설계됨
     * 주요 계산 알고리듬은 Go 언어로 작성되어 MIT 라이선스 오픈소스로 공개
     * ""Goldbach Ridge""라는 시각화 지표를 통해 추측 내 주요 특이값들을 확인 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Gridbach: 골드바흐 추측 검증을 위한 분산 컴퓨팅 도전

  골드바흐의 추측이란?

     * 1742년 크리스티안 골드바흐가 제안한 수학적 추측
     * 모든 2보다 큰 짝수는 두 소수의 합으로 표현할 수 있다는 내용
          + 예시:
               o 4 = 2 + 2
               o 6 = 3 + 3
               o 100 = 3 + 97
               o 10,000 = 71 + 9929
               o 1,000,000,000,001,092,576 = 1913 + 1,000,000,000,001,090,663
     * 지금까지도 수학적으로 완벽하게 증명되지 않은 난제

  Gridbach의 세계 기록

     * 2013년, 포르투갈 수학자 T. Oliveira e Silva가 컴퓨터를 통해 4×10¹⁸(4퀸틸리언) 까지 검증
     * 2025년, 일본 개발자 Hiroaki Jay Nakata (@jay_gridbach) 는 이를 70조 더 확장해 검증 범위를 갱신
     * 목표는 5퀸틸리언까지의 범위 확장이며, 더 많은 참여자와 알고리듬 개선으로 이를 이루고자 함
     * 결과는 누구나 확인 가능: https://gridbach.com

  Gridbach 시스템 특징

     * 로그인/앱 설치 없이 바로 브라우저에서 실행 가능
     * WebAssembly(WASM) 기반의 고속 바이너리 코드가 브라우저에 다운로드되어 로컬에서 계산 수행
     * 각 계산 작업은 1억 단위 범위(5천만 짝수) 에 대해 수행됨
          + PC: 약 5~10초 소요
          + 모바일: 약 10~20초 소요
     * SETI@home에서 영감을 받아 참여 장벽을 낮춘 시스템
     * 실시간 계산 결과 및 전체 통계 대시보드: https://app.gridbach.com

  기술 스택

     * WASM: 고성능 브라우저 내 계산용 실행 바이너리
     * JAMStack 아키텍처: 확장성과 성능 중심 구조
     * 브라우저 기반 동작으로 모바일과 데스크탑 모두 지원

  Goldbach Ridge 시각화

     * “Goldbach Ridge”는 특정 범위 내 골드바흐 쌍 중 작은 소수의 최대값을 의미
     * 수학적으로는 p + q = n (짝수) 중 p의 최댓값을 추적
     * 마치 등고선처럼 보여 시각적으로 흥미로워 별칭으로 사용
     * 예시: Oliveira e Silva가 발견한 Ridge는 9781
     * Gridbach에서는 현재까지 발견된 최대 Ridge는 6421
     * 사용자는 자신의 기여를 통해 새로운 Ridge를 탐색하고 랭킹에 표시 가능

  오픈소스 계산 알고리듬

     * 핵심 계산 로직은 Go 언어로 작성된 CLI 도구로 MIT 라이선스로 공개됨
          + 저장소: https://github.com/nakatahr/gridbach-core
     * 비트 마스크 기반의 개선된 에라토스테네스 체 알고리듬 사용
          + 메모리 효율성과 속도를 고려한 바이트 배열 접근 방식 구현

    최적화 포인트

     * 소수 판별을 위한 루프 시, 배수 제거 시점 계산(mm)을 최적화
     * 짝수만 대상으로 하여 효율성 증가
     * 16비트 블록 단위의 플래그/마스크를 활용한 비트 연산

  참여 유도 및 다음 계획

     * 누구나 쉽게 시스템에 접속해 계산에 참여 가능
     * 기여자는 탑 30 Ridge 리스트 및 시각화 기록을 확인 가능
     * 향후 공식 기록 인증을 위해 논문 작성도 검토 중
     * 계산 알고리듬 및 구조에 대한 기술적 상세 포스트도 계획 중

  결론

     * Gridbach는 단순한 취미 프로젝트가 아닌, 전 세계적 난제에 도전하는 분산 수학 계산 플랫폼
     * 중·고등학생도 이해할 수 있는 문제를, 전 세계의 브라우저가 협력해 해결에 기여 중
     * 과학 커뮤니티, 오픈소스 개발자, 수학 애호가들의 참여와 기여를 환영함

   → 직접 참여해보기:
   https://gridbach.com
   → 실시간 대시보드 보기:
   https://app.gridbach.com

        Hacker News 의견

     * 이 프로젝트는 흥미롭지만 결과의 중요성과 정확성 측면에서 잘못된 표현임
          + 서버 측에서 작업자들이 올바른 결과를 보고하는지 확인하는 검증이 없음
          + 한계치를 천분의 일 퍼센트 미만으로 증가시키는 것이 ""세계 기록""이 아님
          + 더 큰 문제는 결과의 정확성을 아무도 확인할 수 없다는 것임
          + 이 게시물은 클릭베이트임
     * ""지금까지 수학적으로 증명된 적이 없다""는 문법적으로 잘못된 표현임
          + ""아직까지 수학적으로 증명된 적이 없다""가 더 적절함
     * gridbach 서버가 제출된 결과를 신뢰하는지, 아니면 더 빠르게 검증할 수 있는지 궁금함
          + 몇 분 만에 20억 개의 검증을 기여했음
     * 이 프로젝트에 많은 열정이 들어갔음을 알지만, 중요한 논의가 논쟁으로 묻혔음
          + 클라이언트가 속일 수 있어 결과의 신뢰성을 100% 확신할 수 없음
          + 수학적 결과는 엄격함이 필요하며, 그렇지 않으면 주장은 사실이 아님
          + 검증 방법에 대한 질문을 회피하는 것은 신뢰를 주지 않음
     * 이 추측은 4,000,000,000,000,000,000까지 검증되었음
          + 이 프로젝트는 그 숫자를 4,000,010,000,000,000,000으로 증가시켰음
          + 0.00025% 증가
          + 컴퓨팅 자원의 좋은 사용인지 확신할 수 없음
     * 프로그래밍을 배울 때 Goldbach 추측을 확인하는 프로그램을 작성했었음
          + 여러 프로그래밍 언어를 배우면서 이 프로그램을 사용했음
          + 이 프로젝트는 향수를 불러일으킴
     * 이 프로젝트는 흥미롭지만 의미 있는 기록은 아님
          + 이전 기록을 재현하거나 크게 뛰어넘어야 의미 있는 기록임
          + 새로운 ""기록""은 단일 코어 컴퓨팅으로 약 60일의 가치가 있음
          + 이전 소프트웨어는 2013년 i3 코어에서 48분 만에 10^12 창을 처리했음
     * FairPhone 4에서 한 라운드에 약 20초가 걸림
          + 데스크탑에서는 Firefox에서 12초, Chrome에서 14초 걸림
          + 여러 탭에서 실행하면 속도가 느려짐
          + 각 탭이 100% CPU를 사용하며 다른 계산을 수행함
     * X3D 프로세서는 코어*1.5 탭을 실행하는 데 만족함
          + 90C에서 밤새 잠금 상태였으며 4.2 이하로 스로틀링되지 않음
          + 여러 탭으로 인해 제출된 검증 수가 제대로 계산되지 않음
     * 인상적인 작업임
          + 10억 개의 검증된 숫자를 추가했으며, 거의 10억 명의 사람들이 같은 일을 하면 다음 목표를 달성할 수 있음
"
"https://news.hada.io/topic?id=20474","Evertop - 100시간 이상 배터리 수명을 가진 E-ink IBM XT 클론","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Evertop - 100시간 이상 배터리 수명을 가진 E-ink IBM XT 클론

     * 초저전력, 초장수명 배터리를 사용하는 태양광 PC로, IBM XT를 에뮬레이트하며 80186 프로세서와 1MB RAM을 탑재함
     * DOS, Minix, Windows 3.0까지 실행 가능하며, e-ink 디스플레이와 10,000mAh 배터리 두 개를 사용하여 수백 시간에서 수천 시간까지 작동 가능함
     * 내장된 태양광 패널을 통해 무한정으로 오프그리드 사용 가능함
     * 다양한 내장 주변기기와 충전 옵션을 제공하며, 전력 절약 모드에서 최대 500시간 이상 사용 가능함
     * Evertop Min은 경량화된 버전으로, 일부 기능을 제거하여 비용과 무게를 줄였음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Evertop: 초저전력, 초장수명 배터리 태양광 PC

  개요

     * Evertop은 IBM XT를 에뮬레이트하는 휴대용 PC로, 80186 프로세서와 1MB RAM을 탑재하고 있음
     * DOS, Minix, Windows 3.0까지 실행 가능하며, 강력하면서도 매우 저전력인 마이크로컨트롤러를 기반으로 함
     * e-ink 디스플레이와 10,000mAh 배터리 두 개를 사용하여 수백 시간에서 수천 시간까지 작동 가능함
     * 내장된 태양광 패널을 통해 무한정으로 오프그리드 사용 가능함

  내장 주변기기

     * 내장 키보드, 외부 PS/2 키보드 및 마우스 포트, CGA, Hercules, MCGA 그래픽 지원
     * EGA 및 VGA 부분 지원, PC 스피커, Adlib, Covox, Disney Sound Source 오디오 출력
     * 내장 스피커 및 헤드폰 잭, 볼륨 조절 휠, DB9 RS232 시리얼 포트, TTL 시리얼 포트
     * 듀얼 키보드 및 마우스 PS/2 포트, USB 플래시 드라이브 포트, RJ45 이더넷 포트, WiFi, LoRA 라디오 지원

  충전 옵션

     * 내장 분리형 태양광 패널, 2.5 - 20V DC 입력, 마이크로 USB 커넥터를 통해 충전 가능
     * 세 가지 소스를 동시에 사용하여 충전 가능하며, 사용 중에도 충전 가능함
     * 내장된 전압계를 통해 배터리 수준 및 충전 전압 모니터링 가능

  단일 충전으로 수백에서 수천 시간 사용

     * 전력 절약 모드에서 200시간에서 500시간 이상 사용 가능
     * 간단한 텍스트 편집기, 워드 프로세서, e-리더 앱을 통해 최대 1000시간 이상 사용 가능
     * 사용자 주도 또는 자동 디스크 절전 및 IO 제어 듀얼 MOSFET 회로를 통한 자동 전원 차단 기능 제공

  저장소

     * 256G SD 카드를 사용하여 플로피 및 하드 디스크 이미지를 저장
     * 최대 4G의 하드 드라이브 이미지를 지원하며, 두 개의 플로피와 두 개의 하드 드라이브를 마운트 가능

  기술

     * Espressif ESP32 마이크로컨트롤러로 구동되며, 5.83인치 648x480 ""빠른 새로고침"" 디스플레이 사용
     * FabGL 라이브러리의 PC 에뮬레이터 데모를 기반으로 개발됨
     * 3D 프린팅된 매트 PETG 플라스틱 인클로저 사용

  호환성

     * 1980년대 및 90년대 초반의 IBM PC/XT 호환 DOS 소프트웨어 대부분 실행 가능

  새로운 최소 버전: ""Evertop Min""

     * 내장 키보드, 가변 전압 충전, 태양광 패널, RJ45 이더넷, DB9 시리얼 포트, LoRA 라디오, 전압계 및 배터리 용량 절반을 제거하여 경량화
     * 동일한 e-ink 디스플레이, 듀얼 키보드/마우스 PS/2 포트, 내장 스피커, 헤드폰 잭, 볼륨 조절 휠, USB 플래시 드라이브 포트, WiFi 네트워킹, 블루투스, TTL 시리얼 포트, SD 카드 슬롯, 마이크로 USB 충전 포트 포함

  샘플 비디오

     * 다양한 비디오 예시 제공: QBASIC ""hello world"", Space Quest 3, Minesweeper, Adlib Jukebox, USB 플래시 드라이브 사용, 네트워킹, 하이버네이트 및 재개, 태양광 패널 분리 및 재부착, 시스템 시작 및 색상 반전, King's Quest 1, QEdit, Wolfenstein 3D, Doom, CP/M-86, Color Emulation, Planet X3, ZZT, Pirate Adventure, SimCity, Zork, Minix

  샘플 이미지

     * 다양한 게임 및 애플리케이션 이미지 제공: Doom, Monkey Island, Space Quest, Wolfenstein 3D, Test Drive, Prince of Persia, SimCity, The Black Cauldron, Commander Keen, King's Quest, Attack of the Petscii Robots, Planet X3, Police Quest, Windows Solitaire
     * 네트워킹 및 시스템 이미지: Wifi 설정, NE2000 드라이버, 웹 브라우징, FTP 및 텔넷, 시작 화면, 기계 선택, 팝업 메뉴, 오디오 설정, USB 플래시 드라이브 사용, 하이버네이트 및 재개, 파일 전송
     * Minix 및 C 컴파일러, 외관 이미지: 이어폰 잭, USB 플래시 드라이브, 마이크로 USB, PS/2, DB9 RS232 시리얼 포트, 이더넷, 가변 전압 입력, TTL 시리얼 포트, SD 카드 슬롯, 태양광 패널 및 제거, 외부 키보드 및 마우스 사용, 전체 시스템 비교

        Hacker News 의견

     * 이 디스플레이가 얼마나 오래 지속될 수 있는지 궁금함. Waveshare 디스플레이를 사용 중이며 최대 100만 회의 새로 고침 주기를 가짐. 사용한 디스플레이가 더 능력이 있어 보임
          + 개인적인 e-paper 프로젝트 링크를 공유함
     * 저전력으로 기본 기능을 가진 장치가 필요하다고 생각함. 시간이 지나면서 초저전력 장치가 더 강력해지면 노트북 등을 대체할 수 있을 것 같음
     * 이 제품을 정말 사고 싶음. 오랫동안 원했던 것이지만 스스로 만들 시간이나 자원이 없음
     * 30년 전 NMR 실험실의 업그레이드 물류를 담당했음. HP와 Nixdorf 기반 백엔드를 사용했으며, HP GUI가 X10 이전 버전이었음. GUI 스타일이 X10R1과 일치했음
          + 오래된 기술을 계속 사용하는 것이 놀랍지 않음. 독일 군대가 USB 호환 SD 타입 저장 장치를 사용한 것도 같은 이유임
     * XT 클론은 아님. XT는 8088 CPU, CGA/Hercules 디스플레이 어댑터, 640KB RAM, PC 스피커를 가졌음. 이 장치는 80186, 1MB RAM, MCGA(VGA), Adlib 에뮬레이션을 가짐. XT보다 나음
     * 작업을 사랑하지만, PS/2 키보드는 XT 시절에 없었음. PS/2 키보드는 1990년대 초반에 등장함
     * 휴대용 터미널 에뮬레이터로 훌륭할 것 같음. DOS용 좋은 터미널 에뮬레이터 애플리케이션이 있는지 궁금함. Minix 2.0 경험은 어떤지 궁금함
     * Intel Claremont, 태양광 CPU 프로젝트가 어떻게 되었는지 궁금함. 기술 데모에 그쳤는지 궁금함
     * 에뮬레이션으로 실행 중이지만, 하드웨어가 원래와 ""게이트 정확""하게 현대 CMOS 프로세스로 축소되면 전력 절감이 더 클지 궁금함
          + 키보드에 Windows 키가 있는 것이 재미있음. 원래 어떤 노트북에서 왔는지 궁금함. Thinkpad는 아님. 초기 Dell 노트북이 유사한 레이아웃을 가졌던 것 같음
     * 매우 멋짐. 잘했음
          + e-ink 공간을 보기 전 이상적인 설정은 리눅스 기반 넷북과 강력한 서버로 무거운 계산을 오프로드하는 것이었음. 이 설정을 유사하게 사용할 수 있을 것 같음
"
