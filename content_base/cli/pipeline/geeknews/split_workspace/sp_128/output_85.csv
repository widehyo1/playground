"https://news.hada.io/topic?id=11225","23andMe, 사용자 데이터가 크리덴셜 스타핑 공격으로 도난당했다고 밝혀","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               23andMe, 사용자 데이터가 크리덴셜 스타핑 공격으로 도난당했다고 밝혀

     * 미국 생명공학 및 유전체학 회사인 23andMe가 플랫폼의 사용자 데이터와 관련된 데이터 유출을 확인했습니다.
     * 이 회사는 데이터 유출을 자격증명 스태핑 공격에 기인한다고 주장합니다.
     * 초기 데이터 유출은 제한적이었으며, 위협 요인은 아쉬케나지 사람들에 대한 100만 줄의 데이터를 공개했습니다.
     * 위협 요인은 후에 23andMe 계정당 1-10달러에 따라 대량으로 데이터 프로필을 판매할 것을 제안했습니다.
     * 노출된 데이터에는 전체 이름, 사용자 이름, 프로필 사진, 성별, 생년월일, 유전적 조상 결과, 지리적 위치가 포함됩니다.
     * 침해된 계정은 사용자가 유전적 친척을 찾고 그들과 연결할 수 있게 해주는 플랫폼의 'DNA 친척' 기능에 참여했습니다.
     * 위협 요인은 23andMe 계정의 소수에 접근한 후 그들의 DNA 친척 매치 데이터를 스크랩했습니다.
     * 23andMe는 이러한 접근 시도에서 사용된 로그인 자격증명이 사용자가 로그인 자격증명을 재사용한 다른 온라인 플랫폼에서 발생한 사건 중 데이터 유출로부터 위협 요인에 의해 수집되었을 수 있다고 밝혔습니다.
     * 회사는 추가적인 계정 보호 조치로서 이중 인증을 제공하며 모든 사용자에게 이를 활성화하도록 권장합니다.
     * 사용자들은 비밀번호를 재사용하는 것을 삼가고, 강력하고 독특한 자격증명을 모든 온라인 계정에 일관되게 사용할 것이라고 조언받았습니다.

        Hacker News 의견

     * 23andMe에서의 사용자 데이터 도난은 기존에 유출된 이메일/비밀번호 데이터베이스가 사이트 접근에 사용된 크리덴셜 스태핑 공격 때문이었다.
     * 문제는 사람들이 비밀번호를 재사용하고 이중 인증을 활성화하지 않아 발생했다.
     * 판매용 데이터에는 23andMe에서 작동한 다른 침해로부터의 이메일/비밀번호와 23andMe가 해당 사용자에 대해 가지고 있던 데이터가 포함되어 있다.
     * 이 사건은 ""전이 권한"" 또는 ""네트워크 권한""에 대한 우려를 불러일으켰다. 이는 한 사람에게 접근 권한을 부여하면 다른 사람들에게도 접근 권한을 부여할 수 있다는 것을 의미한다.
     * 일부 사용자들은 이러한 보안 우려로 인해 유전자 검사를 피하고 있다.
     * 해커들이 모든 데이터에 접근했지만 특히 아쉬케나지 유대인 130만 건의 기록만 유출했을 수 있다는 추측이 있다.
     * 일부 사용자들은 데이터 보관/보호의 부주의에 대한 형사 책임이 있을 때까지 이러한 침해가 계속 발생할 것이라고 믿는다.
     * 23andMe의 법 집행 기관과의 협력과 셋째 사촌 DNA 샘플을 기반으로 개인을 식별하는 능력은 개인 정보 보호에 대한 우려를 불러일으킨다.
     * 유전자 검사 회사 1Health.io가 민감한 데이터를 보호하지 못한 것에 대해 FTC에게 75,000달러의 벌금을 지불한 것은 정부가 개인 정보 보호를 심각하게 받아들이지 않는다는 증거로 여겨진다.
     * 일부 가계학 서비스는 사용자에게 그들의 23andMe 자격 증명을 요청한다고 보고되어, 이 부문의 보안이 약하다는 것을 나타낸다.
     * 이 사건은 사람들이 그들의 유전 정보를 사적 회사에 신뢰하는 것에 대한 비판을 불러일으켰다.
"
"https://news.hada.io/topic?id=11189","Career Advice (2013)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Career Advice (2013)

     * 저자는 보안이나 소프트웨어 개발 분야의 진로에 대한 조언을 구하는 청년들로부터 자주 연락을 받는다.
     * 저자는 어떤 진로를 선택할 것인가에 대한 질문이 복잡하며, 올바른 질문이 아닐 수 있다고 생각한다.
     * 저자는 직업이 사람의 정체성과 행동을 어떻게 변화시키는지 보여주기 위해 스탠포드 감옥 실험을 참조한다.
     * 저자는 직업이 사람의 생활 맥락과 사고 방식에 큰 영향을 미칠 수 있다고 제안한다.
     * 저자는 청년들에게 잠재적인 직장에서 노동자들을 관찰하라고 조언한다. 그들은 자신의 미래 버전을 대표한다.
     * 저자는 자신을 진정으로 이해하기 전에 진로를 선택하는 것에 대해 경고한다.
     * 저자는 청년들의 진로 선택이 종종 사회 구조와 압력에 의해 영향을 받는다고 믿는다.
     * 저자는 청년들이 이러한 구조를 벗어나 다양한 경험을 탐색하도록 격려한다.
     * 저자는 진로에 서두르지 않는 것이 좋다고 조언한다. 진로는 명확한 종료 시점이 없는 장기적인 약속이다.
     * 저자의 진로 조언은 종종 기아를 방지하기 위해 최소한의 일을 하고, 사회 구조를 벗어난 경험을 추구하는 것을 포함한다.

        Hacker News 의견

     * 텍스트는 커리어 발전에만 초점을 맞추는 것이 아니라 모험을 추구하고 삶의 풍요로움을 찾는 중요성에 대해 논의한다.
     * 일부 개인들은 여행, 이주, 열정 추구와 같은 비정규적인 경로를 통한 경험을 공유하며, 이후 소프트웨어 개발 커리어에 정착한다.
     * 커리어 선택이 개인의 정체성을 소비하지 않아야 하며, 삶의 여러 시기 동안 자신을 다시 정의하는 것이 가능하다는 감각이 있다.
     * 텍스트는 사회적 기대에 맹목적으로 순응하는 것을 경고하고, 커리어에 정착하기 전에 자기 발견의 중요성을 강조한다.
     * 일부 개인들은 기업 직장의 안정성과 혜택에도 불구하고 더 많은 위험을 감수하거나 독립적인 경로를 추구하지 않은 것에 대해 후회한다.
     * 텍스트는 또한 스탠포드 감옥 실험에 대해 논의하며, 이는 개인들이 유해한 환경에서 일시적으로 특정 행동으로 강요받을 수 있지만, 이러한 경험들이 그들의 정체성을 영구적으로 바꾸지는 않는다는 것을 보여준다고 주장한다.
     * 일부 개인들은 상당한 시간을 휴가를 가지거나 비정규적인 선택을 할 경우 그들의 커리어에 미칠 수 있는 부정적인 영향에 대해 두려워한다.
     * 텍스트는 젊은 사람들에게 미래의 자신을 대표하는 노령 동료들을 관찰하고, 커리어 결정을 할 때 이 현실을 고려하라고 조언한다.
"
"https://news.hada.io/topic?id=11247","Flappy Dird: MacOS Finder에서 구현된 Flappy Bird","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Flappy Dird: MacOS Finder에서 구현된 Flappy Bird

     * 'Flappy Dird'라는 게임의 창조에 대한 기사, 이는 MacOS Finder에서 구현된 Flappy Bird의 버전입니다.
     * 게임은 Finder의 ""Date Last Opened"" 필드를 사용하여 사용자 상호작용을 추적하였습니다.
     * 게임은 또한 Finder에서의 일정한 너비를 활용하여 시각적 디스플레이를 생성하기 위해 파일 이름에 이모티콘을 사용합니다.
     * 게임의 초기 프로토타입은 초당 4 프레임으로 실행되었고 화면 찢어짐 문제가 있었습니다.
     * 화면 찢어짐 문제를 해결하기 위해, 창조자는 AppleScript와 더블 버퍼링이라는 기술을 사용하였습니다. 이는 두 버퍼 사이를 번갈아 가며 흔들림을 피하기 위한 것입니다.
     * 게임의 입력 메커니즘이 파일을 두 번 클릭하는 것에서 파일을 선택하는 것으로 변경되었으며, 이는 게임의 성능을 향상시켰습니다.
     * 게임은 결국 AppleScript로 다시 작성되어 시작 속도를 향상시켰으며, 주 게임 루프는 AppleScript로 이동하고 게임 로직은 Python에 남아 있습니다.
     * 게임은 또한 최고 점수 추적 및 마키 광고 배너와 같은 기능을 포함합니다.
     * 창조자는 엔진 없이 Python에서 게임을 작성하는 과정을 즐겁게 느꼈으며, 이 방식으로 더 많은 게임을 만들 계획입니다.
     * 게임의 코드는 GitHub에서 사용 가능하며, 이를 통해 누구나 게임을 즐기거나 배울 수 있습니다.

        Hacker News 의견

     * 'Flappy Bird' 게임이 MacOS Finder에서 구현된 프로젝트에 대한 기사
     * 창의성과 도전적인 요소로 인해 칭찬받는 프로젝트
     * 비전통적인 장소에서 게임을 만드는 추세의 일부인 프로젝트
     * 언급된 비슷한 프로젝트들로는 'Fontemon: 폰트 안의 게임'과 'Dungeons & Directories: 파일 브라우저 안의 텍스트 어드벤처'
     * 창의적인 사고와 프로젝트에 기울인 노력으로 기사 작성자가 칭찬받음
     * Python에서 AppleScript 이벤트를 원래대로 트리거하는 py-appscript 사용 제안, 이로써 AppleScript의 필요성을 제거할 가능성
     * JavaScript로 다시 작성함으로써 AppleScript 시작 속도를 향상시킬 가능성에 대한 논의
     * 프로젝트가 새로움과 즐거움을 가져다주어, 일부는 이전 GNOME의 Fortune Teller fish 작업 표시줄 위젯을 떠올리게 함
     * 게임이 화살표 키를 누르는 것에 반응할 수 있는지, 또는 finder가 특정 파일로 점프하기 위해 wasd를 사용할 수 있는지에 대한 질문
     * 프로젝트에서 AppleScript의 사용이 칭찬받음, 한 댓글 작성자가 여러 해 동안 다양한 프로젝트에 AppleScript를 사용한 경험을 공유
     * 사이트에 독자를 끌어들이는 즐거운 흥미로운 실험으로 보이는 프로젝트
"
"https://news.hada.io/topic?id=11154","DMARC 학습 및 테스트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             DMARC 학습 및 테스트

     * ""Learn and Test DMARC"" 콘솔 도구 소개, 이메일 서버 통신 이해 도구
     * 콘솔은 SPF, DKIM, DMARC가 어떻게 함께 작동하는지 시각적으로 분석
     * 사용자는 ld-50911ea97b@learndmarc.com로 이메일을 보내 시작할 수 있음
     * 콘솔은 사용자의 이메일을 위장하거나, 무작위 예제를 로딩하거나, DMARC 지식을 테스트하거나, 이메일 헤더를 붙여넣는 등 여러 옵션 제공
     * 콘솔은 베타 테스트 단계에 있음
     * 콘솔은 사용자 데이터를 저장하지 않음으로써 사용자의 개인정보 보호를 보장
     * 콘솔은 사용자가 DMARC 설정을 확인하는 데 도움을 주도록 설계됨

        Hacker News 의견

     * DMARC, SPF, 그리고 DKIM의 중요성에 대한 기사: 스팸 감소와 이메일 보안 강화
     * Brand Indicators for Message Identification (BIMI)의 사용 강조: 마케팅 도구로서의 역할과 보안 개선
     * 이러한 보안 조치의 반복적 구현 과정이 사용자들에게 인정받음
     * DMARC 통과에 대한 수정 사항: DKIM 또는 SPF만 통과하면 되며, 둘 다 할 필요는 없음
     * 사용자가 Apple의 ""Hide My Email"" 서비스 사용 중 오류를 보고, JavaScript 코드가 오래되었거나 Safari 브라우저와 호환되지 않을 수 있음을 제안
     * 기사에서는 AWS SNS 메시지의 출처인 sns.amazonaws.com이 DMARC 레코드를 가지고 있지 않음을 지적
     * 일부 사용자들은 DMARC이 좋은 보안 조치이지만, 대부분의 피싱 공격은 친척 도메인을 사용하기 때문에 게임 체인저는 아니라고 주장
     * SSL과 같은 다른 프로토콜에 대해 비슷한 보안 조치를 구현하는 것을 제안
     * 기사에는 2022년 DMARC, SPF, 그리고 DKIM이 상호 작용하는 방식에 대한 토론 링크도 포함되어 있음
"
"https://news.hada.io/topic?id=11272","동전은 던진 면과 같은 면이 위로 떨어질 확률이 더 높습니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   동전은 던진 면과 같은 면이 위로 떨어질 확률이 더 높습니다.

     * 동전 던지기의 확률을 알아내기 위해 48명이 46개의 서로 다른 동전을 사용하여 총 350,757번의 동전 뒤집기를 실행.
     * 그 결과 던질 때 위에 있는 면이 똑같이 위로 떨어질 확률이 50.8%로 더 높은 것을 발견함.
     * 또한 던지는 사람에 따라 흔들림의 차이가 있어 이 편향이 더 커질 수 있는 것으로 관찰됨.
     * 이는 2007년에 Diaconis, Holmes, Montgomery가 주장한 동일 면 편향에 대한 증거를 발견한 것.
          + 물리적인 이유로 동전을 던지면 공중에서 던진 면이 위에 머무르는 시간이 약간 더 길어서 이런 일이 발생한다는 해석.
     * 모든 코드와 비디오 등 데이터 또한 같이 공개함.

   여담이지만, 동전던지기를 두번해서 (앞면-뒷면) 또는 (뒷면-앞면) 조합을 쓰면 확률이 동일하지 않은 동전으로도 공평한 동전던지기가 가능합니다.
     * HN 스레드

   1000번의 동전 뒤집기에서 1달러씩 걸면 (던진 면을 안다는 가정 하에) 약 19달러를 벌 수 있다네요.

   정말....? 신기한 연구같아요.

   논문에 대한 AI 요약

   이 논문은 48명이 46개의 서로 다른 동전을 사용해 350,757번의 동전 던지기를 수행한 실험에 대해 보고합니다. 이 실험은 사람들이 동전을 던질 때 동전이 처음에 던진 쪽에 떨어질 확률이 약 51%라는 페르시 디아코니스의 물리학 모델 예측을 테스트하기 위한 것이었습니다.

   그 결과 실제로 동전이 같은 면에 떨어질 확률은 50.8%로, 동전이 같은 면에 떨어질 확률이 더 높다는 압도적인 통계적 증거를 제시했습니다. 또한 이러한 같은 쪽 편향의 정도는 개인마다 상당한 차이가 있었습니다.

   그러나 동전이 앞면 또는 뒷면에 떨어질 확률에 대한 편향은 발견되지 않았으며, 기록된 확률은 50%였습니다. 또한 동전 종류에 따른 편차도 거의 발견되지 않았습니다.

   35만 개가 넘는 동전 던지기를 수집한 이번 실험은 지금까지 수행된 동전 던지기 실험 중 가장 규모가 큰 실험 중 하나입니다. 이 연구 결과는 사람이 동전을 던질 때 전진으로 인해 작은 편향이 발생한다는 디아코니스의 예측을 강력하게 뒷받침하는 한편, 일반 동전 자체는 뒤집었을 때 앞면/뒤면 편향이 나타나지 않는다는 사실을 강화합니다. 이는 동전 던지기의 결과가 순전히 무작위적이라는 일반적인 직관에 대해 동전 던지기의 물리학 모델을 검증하는 데 도움이 됩니다.
"
"https://news.hada.io/topic?id=11227","코어당 스레드(Thread-per-core)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        코어당 스레드(Thread-per-core)

     * 본 기사는 Rust 커뮤니티에서 멀티 스레드 실행자의 사용에 대한 논란을 논의하고 있으며, 이는 작업을 균형 있게 분배하기 위해 work-stealing을 수행하는 async 런타임입니다.
     * 일부 Rust 사용자들은 ""thread-per-core""라는 대안적인 아키텍처를 주장하며, 이는 성능이 더 우수하고 구현하기 쉽다고 약속하고 있습니다.
     * ""thread-per-core""라는 용어는 오해의 소지가 있습니다. 모든 멀티 스레드 실행자가 thread-per-core이며, OS 스레드를 코어 당 하나씩 생성하고 이러한 스레드 위에서 작업을 스케줄링합니다.
     * Thread-per-core는 세 가지 아이디어를 결합합니다: 사용자 공간에서의 동시성 처리, I/O를 비동기화하여 스레드 차단을 피하고, CPU 코어 간의 데이터를 분할하여 동기화 비용과 CPU 캐시 간의 데이터 이동을 제거합니다.
     * 이 논란은 주로 세 번째 포인트에 대한 것이며, async Rust를 사용하면 처음 두 요구사항을 충족시킬 수 있습니다.
     * Thread-per-core 아키텍처에서는 두 가지 최적화를 수행할 수 있습니다: 스레드 간의 작업을 훔쳐가고, 가능한 한 적은 상태를 공유합니다.
     * Work-stealing은 모든 스레드가 항상 작업을 할 수 있도록 하여 tail latency를 개선하지만, 구현하기 어렵고 동기화 비용과 캐시 누락을 초래할 수 있습니다.
     * Share-nothing은 데이터를 단일 CPU 코어에 속한 더 빠른 캐시에 유지함으로써 tail latency를 개선하지만, 여러 파티션에서 상태를 변경해야 하는 복잡한 애플리케이션에 대해 구현하기 어려울 수 있습니다.
     * 본 기사는 공유 상태를 사용하는 시스템에서 work-stealing이 부하하에서 CPU 사용률을 개선할 수 있을 것이라고 제안합니다.

        Hacker News 의견

     * 논쟁의 핵심은 코어당 스레드 작업 훔치기(executors)가 아니라 Rust에서 async/await가 좋은 추상화인지 여부입니다.
     * 코어당 스레드는 일반적인 많은 코어 서버에서의 계산의 확장성과 효율성을 해결하기 위해 발명되었으며, 이는 고처리량 I/O 바운드 작업에 탁월하다는 것이 밝혀졌습니다.
     * 코어당 스레드 아키텍처는 그들의 확장성과 효율성 때문에 여기에 머무를 것이지만, 대부분의 소프트웨어 엔지니어들은 현대적이고 관용적인 코어당 스레드 디자인이 어떤 것인지에 대한 직관이 제한적입니다.
     * 일부 애플리케이션은 단일 스레드 시스템에 더 적합하며, Rust는 이러한 유연성을 허용합니다.
     * Rust의 async 프로그래밍에 대한 비판이 있으며, 이에는 'Send + Sync + 'static이 요구되는 것이 포함되어 있으며, 일부는 이를 부담스럽게 느낍니다.
     * Send bound는 executor 스레드 간의 작업 이동을 허용하는 요구사항으로, Rust async 시스템의 결점으로 보입니다.
     * 모든 프로그램에 대한 최상의 성능을 달성하는 일괄적인 접근법은 없으며, async 사용은 많은 Rust 프로그램에 대해 성급한 최적화로 간주됩니다.
     * 커널 컨텍스트 스위치는 비용이 많이 들기 때문에 코어당 스레드 디자인을 선호하지만, 사용자 공간 컨텍스트 스위칭 스케줄링도 문제가 될 수 있습니다.
     * 작업 훔치기는 꼬리 지연을 해결하는 방법이지만, 캐시 미스와 Send, Sync 및 ‘static과 같은 추가 개발자 제약 조건을 초래합니다.
"
"https://news.hada.io/topic?id=11268","리벨리온 분석","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                리벨리온 분석

   리벨리온: 국내 1위 AI 팹리스 분석
    1. thesis
       ○ ai의 시대가 온다
       ○ 추론향 수요는 폭발 중
       ○ ai 모델 추론을 구동하기 위한 하드웨어 역시 수요 증가
    2. founding story
       ○ 박성현 대표는 KAIST 학사 MIT 박사 Intel, 삼성, SpaceX, Morgan Stanley 출신
       ○ 오진욱 CTO는 서울대 학사 KAIST 석박, IBM 출신
       ○ 김효은 CPO는 KAIST 학석박, Lunit CPO 출신
       => 한국의 인재풀과 생태계를 보고 국내 법인 설립
    3. product
       a. ION: 금융업에서 사용되는 ULL AI 칩
       b. ATOM: AI 추론에 사용되는 칩 (메인)
       c. REBEL: LLM 추론에 사용되는 칩 (24년 예정)
    4. market
       ○ 규모의 경제를 위해 대규모 데이터 센터 업체 정조준
       ○ 장기적으로 자율주행, 로봇향 수요까지 더해져 거대한 시장 형성이 예상됨
    5. business model
       ○ GTM
       a. 고객사에 SW/HW codesign으로 커스터마이징 제공
       b. KT 데이터 센터에서 얻은 실질 데이터 기반 세일즈
       c. 적은 마진으로 마켓 볼륨 확보, 빠른 노하우 축적과 기술 혁신
    6. traction
       ○ 2020년 창업 후 4년 동안 1000억 이상 투자 유치
       ○ 2022년 ATOM 출시 후 2023년 KT 데이터 센터 탑재
       ○ 2024년 출시될 REBEL은 삼성전자와 협업 하 준비 중 (4nm / HBM3e)
    7. competition
       ○ 기존 팹리스 강자: NVIDIA, AMD, Qualcomm -> NVIDIA is KING
       ○ 데이터 센터 업체: Google, Amazon, Microsoft
       ○ 스타트업: Sambanova, Tenstorrent, Cerebras
    8. valuation
       ○ 1120억 투자, 3500억 이상의 기업가치
       ○ 현재 시리즈 B 투자 라운드 돌고 있음
       ○ 타사 비해 높은 밸류는 아니나, 시리즈 B 돌고 나서 어떻게 될지 주시
       ○ Graphcore, Mythic을 타산지석 삼아 외부 수혈 없이 cash flow 확보해야
    9. key opportunities
       ○ best of Korea
       a. 한국의 인재풀 활용
       b. 한국의 투자 생태계 활용
       c. 이에 기반한 내수 구축 (KT, 정부 NPU Farm)
       d. 삼성파운드리, 세미파이브 등의 반도체 생태계 레버리지해 설계 중
       ○ positioning
       a. TCO (GPU 대비 5배 효율)와 유연성 (다양한 모델 구동) 갖춘 sweet spot 타겟
       b. MediaTek 사례에서 볼 수 있듯, 자신만의 확실한 마켓 구축해야 생존 가능
       c. 로우엔드 LLM을 돌리기 적합한 고TCO 마켓을 장악할 필요성 존재
       ○ latecomer advantage
       a. DRAM 기반 설계
       b. 확장가능한 아키텍처
       c. 언어모델 고려한 설계
   10. key risks
       ○ 시간이 없다
       a. 한 번 lock-in된 개발자들은 기존 것을 바꾸기 싫어함
       b. 데이터 센터 업체 (고객사)가 자사 칩을 만들고 있음
       c. 따라서 빠른 계약 체결 및 foundation model 개발사 타겟 등의 액션 필요
       ○ 해자가 없다
       a. 7 powers 기반 분석 시 강력한 power 부재함
       b. 글로벌 확장을 위해서 무기를 준비해야 할 것
   11. conclusion
       => NVIDIA는 스타트업이 아닌 거인. 동사는 리스크를 지며 큰 배팅을 하기엔 가장 적합한 위치에 있음.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   한국에서 빅테크, Hard Startup도 크게 될 수 있다는 것을 보여주길. 리벨리온을 응원한다!
"
"https://news.hada.io/topic?id=11267","스프레드시트의 가장 강력한 도구, 피벗 테이블 (2020)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    스프레드시트의 가장 강력한 도구, 피벗 테이블 (2020)

     * 이 기사는 스프레드시트에서 피벗 테이블의 역사와 중요성을 논의한다.
     * 피벗 테이블은 코딩 기술이나 수학적 능력을 요구하지 않고도 대규모 데이터셋을 분석하는 강력한 도구이다.
     * 애플의 창립자인 스티브 잡스는 피벗 테이블의 팬이었으며 그들의 잠재력을 일찍 인식했다.
     * 1985년, 잡스는 NeXT라는 회사를 창립하고 제품에 대한 수요를 창출하기 위한 소프트웨어 프로그램을 찾고 있었다.
     * 그는 Lotus 1-2-3이라는 인기 있는 스프레드시트 프로그램을 개발한 소프트웨어 회사 Lotus와 만났다.
     * 소프트웨어 개발자 Pito Salas는 ""flexible views""라는 도구를 개발하고 있었는데, 이는 지금 Microsoft Excel과 Google Sheets에서 피벗 테이블로 알려져 있다.
     * Salas의 도구는 사용자가 카테고리별로 요약 통계를 계산하게 해주어 과정을 단순화하고 오류를 줄였다.
     * 잡스는 Lotus에게 피벗 테이블 소프트웨어를 NeXT 컴퓨터 전용으로 개발하도록 설득했고, 이로 인해 Lotus Improv가 탄생했다.
     * 비록 NeXT 컴퓨터는 성공하지 못했지만, Lotus Improv와 그 ""flexible views"" 기능은 영향력이 있었고 Lotus 1-2-3과 Excel에 모두 통합되었다.
     * 오늘날, 피벗 테이블은 스프레드시트에서 가장 중요하고 일반적으로 사용되는 도구 중 하나이다.
     * 그들은 사용자가 수십만 행의 데이터로부터 몇 번의 클릭만으로 한 페이지 요약 보고서를 생성할 수 있게 해준다.
     * 피벗 테이블은 공공 보건, 경제 성장, 광고 효과 등 다양한 분야에서 널리 사용된다.
     * 이 기사는 기자가 미국에서 멕시코로 보낸 송금에 대한 데이터를 요약하기 위해 피벗 테이블을 어떻게 사용했는지 예를 제공한다.
     * 이 기사는 Excel과 Google Sheets에서 피벗 테이블을 사용하는 방법에 대해 더 알아보기 위한 자료로 마무리된다.

        Hacker News 의견

     * 한 사용자가 프로그램 증가 계획에 사용할 수 있는 셀의 값에 따라 행/셀을 그룹으로 정렬하는 유용한 Excel 공식을 공유함.
     * 또 다른 사용자가 셀이 비어 있지 않은 경우 하이퍼링크를 생성하는 공식을 공유하며, 이는 비즈니스 목적에 유용할 수 있음.
     * 자체 데이터베이스 기술을 개발한 사용자는 피벗 테이블을 매우 효율적으로 생성할 수 있지만, 이 기능의 가치를 다른 사람들에게 보여주는 데 어려움을 겪음.
     * SSAS 큐브를 활용한 피벗 테이블은 강력한 자체 분석 도구로 칭찬받지만, OSX 지원의 부재와 MDX 작성의 어려움에 대한 비판도 있음.
     * 한 사용자는 피벗 테이블을 진정한 다차원 스프레드시트의 부정확한 근사치로 비판하며, Lotus Improv를 예로 듦.
     * 오픈 코어 스프레드시트를 구축하는 사용자는 피벗 테이블이 공식보다도 더 인기 있는 데이터 변환 기능이라고 주장함.
     * Microsoft가 피벗 테이블의 개념을 Brio Technology, 한 사용자의 전 직장에서 훔쳤다는 주장이 있음.
     * 한 사용자가 피벗 테이블이 무엇인지 간단히 설명해 달라고 요청함. 그들은 한 번도 사용해 본 적이 없고, 기사의 비디오가 로드되지 않았음.
     * Google Ads 사용자들은 다른 유형의 대시보드보다 피벗 테이블 형식의 데이터를 선호한다고 보고됨.
     * 피벗 테이블은 능숙한 사용자가 데이터를 탐색할 수 있게 해주는 것으로 칭찬받지만, 한 사용자는 계산을 방해하는 일부 기능을 잠그기 위해 VBA를 사용해야 했다고 지적함.
     * SQL에 능숙한 엔지니어임에도 불구하고, 한 사용자는 Excel을 빠르게 사용하고 피벗 테이블을 생성하는 능력이 빠른 의사결정에 뛰어나다고 판단하여 그들의 커리어 향상에 크게 기여했다고 인정함.
"
"https://news.hada.io/topic?id=11279","ChatGPT Dall-E 3 시스템 프롬프트 유출","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ChatGPT Dall-E 3 시스템 프롬프트 유출

    1. If the description is not in English, then translate it.
    2. Do not create more than 4 images, even if the user requests more.
    3. Don't create images of politicians or other public figures. Recommend other ideas instead.
    4. Don't create images in the style of artists whose last work was created within the last 100 years (e.g. Picasso, Kahlo). Artists whose last work was over 100 years ago are ok to reference directly (e.g. Van Gogh, Klimt). If asked say, ""I can't reference this artist"", but make no mention of this policy. Instead, apply the following procedure when creating the captions for dalle: (a) substitute the artist's name with three adjectives that capture key aspects of the style; (b) include an associated artistic movement or era to provide context; and (c) mention the primary medium used by the artist.
    5. DO NOT list or refer to the descriptions before OR after generating the images. They should ONLY ever be written out ONCE, in the ""prompts"" field of the request. You do not need to ask for permission to generate, just do it!
    6. Always mention the image type (photo, oil painting, watercolor painting, illustration, cartoon, drawing, vector, render, etc.) at the beginning of the caption. Unless the caption suggests otherwise, make at least 1--2 of the 4 images photos.
    7. Diversify depictions of ALL images with people to include DESCENT and GENDER for EACH person using direct terms. Adjust only human descriptions.
    8. Silently modify descriptions that include names or hints or references of specific people or celebrities by carefully selecting a few minimal modifications to substitute references to the people with generic descriptions that don't divulge any information about their identities, except for their genders and physiques.

   Do not과 Don't와 DO NOT이 한 프롬포트에 같이 쓰이는게 정말 신기합니다.

   매번 궁금했는데, ai로부터 얻은 프롬프트가 진짜인지 아닌지는 어떻게 아나요?

   실제로 프롬프트의 내용을 보고 교차검증 해보면 됩니다.
   (예를 들어 내부 코드명이 유출되었다면 해당 코드명으로 호출했을 때 반응이라던지)

   정보 감사합니다. 달리 쓰는데 뭐 특별하지도 않았는데, 자꾸 거절당하고 이상한 이미지 뽑아낼때 스트레스 받던데 도움이 될거같아요.
"
"https://news.hada.io/topic?id=11157","사무실 복귀는 헛소리이며 모두가 그것을 알고 있다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      사무실 복귀는 헛소리이며 모두가 그것을 알고 있다

     * 저자, 대형 기술 회사의 전 직원이 강제 이전 정책으로 인해 직장을 그만둔 결정에 대해 논의
     * 2019년 100% 원격 근무자로 고용된 저자는 COVID-19 팬데믹 이후 사무실 위치로 이동하도록 예상됨
     * 원격 근무가 일시적인 조치라는 초기의 믿음에도 불구하고, 2022년 중반에는 팬데믹 이전의 정상으로 돌아갈 수 있다고 믿는 사람들은 습관을 바꾸기를 원치 않는 사람들뿐이라고 저자 주장
     * 저자는 암호화 조직에 대한 중요한 전문가이자 최고의 성과를 내는 사람으로, 보안 및 암호화 주제에 대한 통찰력 제공
     * 팬데믹으로 인한 원격 근무 전환에도 불구하고 저자와 그의 팀은 건강하고 생산적인 업무 환경을 유지할 수 있었음
     * 회사의 CEO는 모든 직원이 사무실로 돌아와야 하며 원격 근무자는 이동해야 한다는 일방적인 결정을 내림, 예외는 거의 없음
     * 저자는 고용주로부터 최후통첩을 받은 사람들에게 회사를 떠나는 것을 최종적으로 선택하도록 조언
     * 강제 이전을 강요하는 회사들은 대부분의 최고 인재를 잃고 다음 10년 동안 고용에 어려움을 겪을 것이라고 저자 예측
     * 저자는 H-1B 비자를 가진 기술 노동자들이 고용 상태와 연결된 이민 상태 때문에 기업의 학대를 가장 많이 받을 것이라고 제안
     * 저자는 새로운 원격 직업을 찾았으며, 비슷한 딜레마에 직면한 다른 사람들에게 그들이 혼자가 아니라는 것을 기억하고, 그들의 삶에 가장 적합한 선택을 하도록 격려
     * 저자는 그의 비판이 사무실 근무에 대한 것이 아니라 강제 이전과 이를 결정하는 데 필요한 데이터 부족에 대한 것임을 명확히 함

        Hacker News 의견

     * 많은 기술 전문가들이 수년 동안 원격으로 일해오고 있으며, 경영진의 결정으로 인해 그들의 생활 방식을 포기하고 싶어하지 않는다.
     * 저자는 권력 있는 사람들로부터의 최후통첩에 따르는 것은 자기 가치를 해칠 수 있으므로 반대한다.
     * 동시작업과 같은 산업적 작업 습관이 여전히 사무실 업무에서 지속되고 있음에도 불구하고, 이는 필요하지 않다.
     * 일부 사업 리더들은 직접 권력을 행사하는 것에 대한 감정적 만족을 위해 사무실 복귀(RTO)를 원한다.
     * 댓글 작성자는 현재 원격 근무에 대한 추세에도 불구하고, 공동 위치가 스타트업에게 경쟁 우위를 제공한다고 믿는다.
     * 원격 근무에 어려움을 겪는 사람들(group A)과 그것을 잘하는 사람들(group B) 사이에는 차이가 있다. RTO는 group A에게 이점을 주지만 group B에게는 불편을 준다.
     * 댓글 작성자는 하이브리드 모델을 제안한다: 대도시 내에서 고용하고, 한 달에 28일 동안 집에서 일하며, 한 달에 2일 동안 직접 만난다.
     * NPR에서 일하는 노동조합 소프트웨어 엔지니어는 그들이 3년 동안 원격 근무를 보장받았다고 공유한다.
     * 비디오 회의 기술은 여전히 부족하며, 지난 10년 동안 중요한 개선이 없다.
     * 댓글 작성자는 산업의 합병으로 인해, 대기업들은 더 이상 최고의 인재를 필요로 하지 않고, 그들의 확립된 비즈니스 모델을 유지하기 위해 ""충분히 좋은"" 직원만 필요로 할 수도 있다고 추측한다.
"
"https://news.hada.io/topic?id=11229","CCC, 함부르크에서 열리는 제37회 Chaos Communication Congress에 초대","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         CCC, 함부르크에서 열리는 제37회 Chaos Communication Congress에 초대

     * Chaos Computer Club (CCC)가 3년 만에 37번째 Chaos Communication Congress (37C3)를 2023년 12월 27일부터 30일까지 함부르크에서 개최합니다.
     * 37C3는 독일에서 가장 전통적인 IT 보안 및 기술 역량 컨퍼런스이며, 해커 커뮤니티의 가장 큰 유럽 모임입니다.
     * 이 행사는 해커 커뮤니티 내에서 더 많은 교류, 주제, 워크샵, 파티의 필요성에 대한 대응입니다.
     * 37C3는 살 가치 있는 디지털 미래에 대한 정보와 긍정적인 자극을 제공하고, 범용 컴퓨터로 가능한 것들에 대해 교육하는 것을 목표로 합니다.
     * CCC는 대규모의 자원봉사자인 '카오스 천사'들이 이 행사에 참여하도록 요청하고 있습니다.
     * 강연은 실시간으로 스트리밍되며, 나중에 media.ccc.de에서 제공될 예정이며, 강의를 여러 언어로 번역할 계획입니다.
     * 계획 및 조직에 소요되는 시간이 적기 때문에, 티켓 판매는 평소보다 늦게 시작되고 기간이 짧을 것입니다.
     * 행사는 최근에 리모델링된 Congress Center Hamburg (CCH)에서 개최될 예정이며, 익숙하지만 현대적으로 재설계된 건물을 제공합니다.
     * 진행 중인 팬데믹으로 인해 참가자 수는 이전 연도보다 약간 적을 것이며, 강의 프로그램은 더 적은 무대에서 제공될 것입니다.
     * 37C3는 당국이 금지하지 않는 한 반드시 개최될 것이며, 모든 공식 감염 통제 규정이 시행될 것입니다.
     * CCC는 모든 참가자들이 티켓을 구매하기 전에 대규모 행사의 건강 위험에 대한 자신의 인식을 고려하도록 권고하며, 감기 증상이 있는 사람들에게는 행사에 참석하지 않도록 요청합니다.

        Hacker News 의견

     * 제37회 Chaos Communication Congress (CCC)가 함부르크에서 개최 예정.
     * 이번 행사의 장소는 크게 축소되어 이전보다 참가자 수가 적어질 것으로 예상됨.
     * 이 행사는 기술 중심의 Burning Man 페스티벌에 비유되지만, 도시 환경으로 인해 인프라가 더 많음.
     * 일부 참가자들은 행사가 크리스마스와 새해 사이가 아닌 다른 시기에 개최되기를 원함.
     * 독일어 텍스트에 따르면 모든 ""공식 감염 통제 규정""이 만료되었다고 함.
     * CCC가 매년 확장하고 더 많은 참가자를 수용하기를 바라는 의견이 있음.
     * 라이프치히에서 함부르크로의 이동은 숙박비가 더 비싸짐으로 인해 비용이 증가할 수 있다고 지적됨.
     * 2022년에 실망스러운 취소 이후, 올해 행사가 개최될 것에 대한 기대와 희망이 있음.
     * CCC는 휴가 시즌 동안 기대되는 하이라이트 행사로 간주됨.
     * 등록 개시가 어떤 채널을 통해 발표될지에 대한 궁금증이 있음.
     * 일부 참가자들은 수용력이 줄어든 것에도 불구하고 라이프치히보다 함부르크 장소를 선호함.
"
"https://news.hada.io/topic?id=11164","Microsoft Defender가 Tor 브라우저를 트로이 목마로 간주하고 제거함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Microsoft Defender가 Tor 브라우저를 트로이 목마로 간주하고 제거함

     * Windows 10과 11에 통합된 안티바이러스 프로그램인 Microsoft Defender가 Tor 브라우저를 악성 소프트웨어로 간주하고 시스템에서 제거하고 있다.
     * Tor 브라우저는 인터넷을 익명으로 브라우징하기 위해 양파 라우팅을 사용하는 무료 오픈소스 소프트웨어로, 온라인 개인정보 보호에 필수적이다.
     * 이번 거짓 악성 소프트웨어 경고는 Tor를 사용하여 활동을 숨기는 트로이 목마를 식별하도록 설계된 Microsoft Defender의 새로운 휴리스틱 검출 방법 때문으로 추정된다.
     * 휴리스틱 검출 방법은 알려진 악성 소프트웨어의 특정 데이터베이스에 의존하는 서명 기반 검출과 달리, 미리 정의된 규칙과 알고리즘을 사용하여 의심스러운 행동을 식별한다.
     * 휴리스틱 방법은 새로운 위협을 감지하는 데 효과적일 수 있지만, 종종 거짓 양성 결과를 초래할 수 있다.
     * Tor 대표는 사용자에게 브라우저가 공식 웹사이트에서 설치되었는지 확인하고, 그렇다면 Defender의 경고를 거짓으로 간주하도록 조언했다.
     * 개발자들은 또한 Tor를 Microsoft의 보호 소프트웨어 제외 목록에 추가하고, Defender가 Tor의 작동에 영향을 미쳤다면 ""tor.exe""를 격리에서 복원하는 것을 권장했다.
     * 글 작성 시점에 Microsoft는 이 문제에 대해 공식적인 입장을 밝히지 않았다.

        Hacker News 의견

     * 기사는 Microsoft Defender가 Tor 브라우저를 트로이로 간주하고 제거하는 것에 대해 논의하고 있다.
     * 한 사용자는 악성 코드를 정의하는 어려움과 거짓 긍정 문제에 대해 논의하며, 이 사용자는 이전에 악성 코드 방지 팀에서 일했다.
     * 다른 사용자는 Windows Defender가 자주 비디오 게임의 업데이트를 플래그하고 제거하여 불편을 초래한다고 언급한다.
     * 사용자 중 한명은 EDR 시스템이 행동 분석에 기반한 경고를 내보내는 것에 대한 우려를 표현하며, 이 시스템이 바이러스 방지 시스템을 대체하지 않는다는 우려를 표현한다.
     * Microsoft Defender와 같은 시스템이 독재적 정권에 의해 비평가와 반체제 인사를 드러내고 침묵시키는 데 사용될 수 있다는 우려가 있다.
     * 일부 사용자들은 자신들의 소프트웨어가 Windows Defender에 의해 트로이로 플래그되어 작업에 방해가 되는 경험을 공유한다.
     * 한 사용자는 Microsoft Defender의 Enterprise 웹 필터가 Brave 브라우저 도메인으로의 모든 요청을 차단하기 시작했다고 언급한다.
     * 대안적인 출처는 Microsoft Defender가 Tor를 통해 연결을 시도하는 모든 앱을 악성 코드로 감지하고 있으며, 이로 인해 Tor 브라우저에 대한 거짓 긍정이 발생하고 있다고 제안한다.
     * 한 사용자는 Defender의 지속적인 스캔으로 인해 개발 환경이 느려지는 문제로 Windows 10에서 Linux로 다시 전환하는 경험을 공유한다.
"
"https://news.hada.io/topic?id=11269","파이어폭스의 22년 된 툴팁 버그가 수정되었습니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      파이어폭스의 22년 된 툴팁 버그가 수정되었습니다.

     * 2002년 6월 2일에 열린 툴팁 버그 티켓이 약 21년 3개월 뒤인 2023년 9월 7일에 수정됨.
     * 파이어폭스에서 띄운 툴팁이 파이어폭스 창이 사라져도 그대로 남는 문제.
     * Windows 98부터 Windows 11까지, MacOSX 10.1 부터 MacOS 14까지, Firefox 0.x부터 Firefox 118 버전까지 존재한 버그.

   아니 이게 파이어폭스 문제였다니!

   리눅스, 맥에서는 겪은 적이 없어서 애꿎은 윈도우를 탓하고 있었는데 파이어폭스 버그였군요...?!
     * 패치
     * HN 스레드

   오랜 역사(?)가 수정되었군요.
"
"https://news.hada.io/topic?id=11240","X(트위터), 신고 및 차단이 불가능한 새로운 광고 포맷 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   X(트위터), 신고 및 차단이 불가능한 새로운 광고 포맷 출시

     * 광고주가 누구인지, 광고인지도 밝히지 않는 이상한 광고 형식
     * 다수의 사용자들이 For You 피드에서 새로운 광고가 보인다고 보고함
          + 좋아요/리트윗이 불가능
          + 광고를 누가 한건지, 광고 인지 자체도 전혀 공개하지 않음
     * 광고 문구와 사진, 그리고 가짜 아바타 사진을 이용해서 광고를 순수 트윗처럼 보이게 함
     * 아바타나 광고 문구 어디를 클릭하든 새로운 창에서 써드파티 웹사이트로 이동
          + 즉 X 게시물도 없고, 광고에 연결된 사용자 프로필도 없음
     * X의 모바일 앱 내에서만 발견되었으며, 웹에서도 보이는지는 확실하지 않음
     * X는 머스크의 인수후에 광고주가 줄어들었고, 광고 수익 감소 때문에 제3자와 연동하여 광고 인벤토리를 판매함
          + 즉, 이 Ad 인벤토리는 X가 아닌 써드파티 인벤토리를 통한 것으로 보임

   ........

   저 광고를 막을 수 있는 건 애드블록밖에 없겠군요
"
"https://news.hada.io/topic?id=11163","구글 팟캐스트 앱을 2024년에 종료하고 청취자는 유튜브 뮤직으로 이관","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                구글 팟캐스트 앱을 2024년에 종료하고 청취자는 유튜브 뮤직으로 이관

     * 스트리밍 청취자를 Youtube Music으로 전환하기 위해, 별도로 운영되던 Google Podcasts 앱을 2024년에 종료
     * 올해초에 유튜브 뮤직이 미국부터 팟캐스트를 지원하도록 했으며, 연말까지 글로벌 확장할 예정
     * 팟캐스터들이 RSS피드를 유튜브에 등록하는 기능도 연말까지 추가할 것
     * 구글은 유튜브 뮤직의 팟캐스트 환경에 대한 투자를 더욱 늘리고, 검색/커뮤니티/오디오 팟캐스트와 비디오 팟캐스트간 전환등의 기능을 통해서 팟캐스트 팬들이 더 많이 찾는 곳으로 만들 계획
     * 데이터에 의하면 미국의 팟캐스트 청취자중 약 24%가 유튜브를 사용하며, 구글 팟캐스트는 4%만 사용
     * Google은 YouTube Music을 Spotify, Apple Music, Amazon Music 등에 대한 경쟁자로 만들기 위해 노력중
     * Spotify, Amazon 및 Pandora는 모두 주력 애플리케이션에서 음악과 팟캐스트, 두 가지 유형의 오디오를 모두 제공하고 있음. 구글의 이런 움직임으로 인해 음악과 팟캐스트를 단일 대상으로 통합하지 않은건 Apple만 남게 됨

   https://killedbygoogle.com/
   단두대에 걸렸습니다.

   이게 최신이겠지하고 들어갔는데 Jamboard 가 그 다음에 죽었군요. 바로 앞은 Google Domains 네요.

   앱이 나름 깔끔해서 좋았는데 아쉽군요. 저는 이제는 spotify로 다 옮기긴 했습니다만...

   저도 구글 팟캐스트 앱으로 듣던 터라 이 소식이 아쉽더라고요.ㅠ

   제목엔 Google Podcasts to shut down in 2024 라고 써있어서 또 서비스 문닫나 했더니, 앱을 유튜브뮤직으로 단일화 하는 거였네요.
   이해는 갑니다만, 과연 그래야 하나 싶기도 합니다. 전 그냥 애플 팟캐스트앱 쓰는게 편하더라고요.
"
"https://news.hada.io/topic?id=11242","OpenIPC: IP 카메라를 위한 대체 오픈 펌웨어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     OpenIPC: IP 카메라를 위한 대체 오픈 펌웨어

     * OpenIPC는 다양한 제조사의 ARM 및 MIPS 프로세서를 탑재한 IP 카메라용으로 설계된 오픈 소스 운영 체제입니다.
     * 이는 벤더가 사전에 설치한 폐쇄적이고 불투명하며 불안전하고 종종 지원되지 않는 펌웨어를 대체하려는 목표를 가지고 있습니다.
     * OpenIPC 펌웨어는 이진 사전 컴파일 파일로 제공되어 최종 사용자가 쉽게 설치할 수 있습니다.
     * 이 프로젝트는 또한 모든 프로그래머가 기여할 수 있도록 소스 파일에 대한 완전한 접근을 제공합니다.
     * OpenIPC 소스 코드는 MIT 라이선스에 따라 출시되며, 이는 사용자가 코드를 재사용하고 독점 소프트웨어를 포함한 모든 목적으로 사용할 수 있도록 하는 간단한 오픈 소스 라이선스 계약입니다.
     * 프로젝트는 사용자들이 커뮤니티에 개선 사항을 기여하도록 권장하며, 피드백과 제안을 환영합니다.
     * 초기에 OpenIPC 펌웨어는 HiSilicon에서 제조한 SoC만 지원했지만, 현재는 Ambarella, Anyka, Fullhan, Goke, GrainMedia, Ingenic, MStar, Novatek, SigmaStar, XiongMai의 칩을 지원하며, 더욱 확장될 것으로 예상됩니다.
     * 프로젝트에 대한 자세한 정보는 프로젝트의 웹사이트와 위키에서 찾을 수 있습니다.

        Hacker News 의견

     * OpenIPC는 IP 카메라를 위한 오픈 펌웨어로, 대량생산 IP 카메라에 종종 포함된 버그가 많고 보안 취약점이 있는 펌웨어에 대한 대안을 제공합니다.
     * 제조사들이 내부 하드웨어를 자주 변경하기 때문에 무작위 중국 IP 카메라를 오픈 펌웨어로 전환하는 것은 도전적입니다.
     * OpenIPC 펌웨어는 개인적이고 비상업적인 사용에 대해 무료입니다. 사업용으로 사용하려면 OpenIPC 팀에 연락하라는 권고가 있습니다.
     * OpenIPC의 일부 센서 드라이버는 바이너리 블롭이며, Ambarella S3L 및 일부 HiSilicon 칩셋에 대한 예시가 제공됩니다.
     * OpenIPC가 지원하는 장치 목록은 GitHub에서 확인할 수 있습니다.
     * OpenIPC는 저렴한 IP 카메라 하드웨어를 FPV 드론용 저지연 디지털 비디오 시스템으로 재활용하는 데 사용되고 있습니다.
     * OpenIPC를 지원하고 이미지 품질이 좋은 카메라에 대한 추천 요청이 있습니다.
     * OpenIPC는 이름에서 알 수 있듯이 프로세스 간 통신 추상화 또는 프레임워크가 아닙니다.
     * HackerNews에는 OpenIPC에 관한 이전 토론이 있습니다.
"
"https://news.hada.io/topic?id=11261","Show HN: 프리랜서 관리 업무를 돕기 위한 올인원 웹 앱 제작 완료","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show HN: 프리랜서 관리 업무를 돕기 위한 올인원 웹 앱 제작 완료

     * 새로운 올인원 웹 앱인 momo.coach가 프리랜서의 관리 업무를 돕기 위해 설계되었다는 기사 소개.
     * 이 앱은 여러 클라이언트 간의 시간 추적 과정을 단순화하고, 수많은 스프레드시트의 필요성을 제거하는 것을 목표로 한다.
     * 이 앱은 정확한 근무 시간 추적을 통해 미계상의 시간으로 인한 손실된 수익에 대한 해결책을 제공한다.
     * 이 앱은 프리랜서가 자신의 은행에서 CSV 거래 파일을 업로드함으로써 수입과 비용을 추적하는 데 도움을 준다.
     * 이 앱은 전문적이고 준수한 청구서와 견적서를 생성하는 기능을 제공한다.
     * 이 앱은 필요한 보고서를 컴파일하여 세금 환급 준비를 돕는다.
     * 이 앱은 영수증을 잃어버리거나 환급을 놓치는 문제를 해결하고, 모든 비용이 계산되도록 보장한다.
     * 이 앱은 프리랜서의 여정에서 스트레스를 줄이고 시간을 절약하는 데 도움을 준다.
     * 이 서비스는 월 10달러의 비용이 들며, 10GB의 저장 공간이 제공된다. 장기 계약이 필요 없으며 언제든지 취소할 수 있다.

        Hacker News 의견

     * 웹 앱은 미적 디자인과 기능성, 특히 프리랜서 관리 작업에 대한 인정을 받고 있다.
     * 일부 프리랜서들은 비용을 낮추기 위해 Google Sheets와 같은 무료 도구를 시간 추적 및 송장 생성에 사용하는 것을 선호한다.
     * 앱은 컨설팅이나 에이전시 운영과 같은 확장 작업에 더 유용할 수 있으며, 단독 프리랜서보다는 그렇다.
     * 오픈 소스, 자체 호스팅 버전의 앱에 대한 관심이 있지만, 사용자들은 창작자가 수익을 창출해야 한다는 필요성을 이해한다.
     * 일부 사용자들은 월간 요금과 데이터 프라이버시에 대한 우려를 표현하며, 일회성 결제의 로컬 오프라인 앱을 선호한다.
     * 사용자들은 앱이 Elster 통합이나 DATEV 내보내기와 같은 특정 기능을 지원하는지, 다른 통화를 지원하는지에 대한 관심이 있다.
     * 개선 제안에는 문제를 진술하는 대신 질문을 제기하는 언어로 변경하고, 추가 기능에 대한 더 많은 정보를 제공하는 것이 포함된다.
     * 사용자들은 창작자의 노력을 인정하고, 대기업 소프트웨어보다는 소규모 창작자를 지원하는 것을 선호한다.
     * 앱의 기술적 측면에 대한 관심이 있으며, 데모 비디오의 제작 및 모든 데이터를 백업 또는 이전 목적으로 내보내는 기능이 있다.
     * 일부 사용자들은 달러로 청구되는 것이 혼란스럽다고 느끼며, 특히 앱이 VAT를 지원한다는 것은 영국 사용자를 대상으로 한다는 것을 나타낸다.
     * 앱의 디자인이 칭찬을 받고 있으며, 창작자가 단독 창업자인지에 대한 궁금증이 있다.
"
"https://news.hada.io/topic?id=11166","효율적인 스트리밍 언어 모델과 어텐션 싱크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        효율적인 스트리밍 언어 모델과 어텐션 싱크

     * 대용량 언어 모델(Large Language Models, LLMs)의 스트리밍 애플리케이션 배포에 대한 기사, 이는 메모리 소비와 LLMs의 훈련 시퀀스 길이보다 긴 텍스트를 일반화하는 능력 부족으로 인해 도전적임.
     * 저자들은 '주의 집중 싱크(attention sink)'라는 개념을 소개, 이는 초기 토큰에 대한 강력한 주의 점수 현상을 의미하며, 그들이 의미론적으로 중요하지 않더라도 그렇습니다.
     * 저자들은 유한 길이의 주의 창으로 훈련된 LLMs가 미세 조정 없이 무한 시퀀스 길이로 일반화할 수 있게 하는 효율적인 프레임워크인 StreamingLLM을 제시합니다.
     * StreamingLLM은 Llama-2, MPT, Falcon, Pythia와 같은 모델이 최대 400만 토큰 이상으로 안정적이고 효율적인 언어 모델링을 수행할 수 있게 합니다.
     * 저자들은 또한 사전 훈련 중에 전용 주의 집중 싱크로 플레이스홀더 토큰을 추가하면 스트리밍 배포가 더욱 향상될 수 있음을 발견했습니다.
     * 스트리밍 설정에서 StreamingLLM은 슬라이딩 윈도우 재계산 기준을 최대 22.2배 빠르게 능가합니다.
     * 저자들은 LLMs의 컨텍스트 창이 StreamingLLM에서 확장되지 않으며, 모델은 최신 토큰만 처리할 수 있다는 것을 명확히 합니다.
     * StreamingLLM은 모델이 광범위한 메모리나 과거 데이터에 의존하지 않고 계속 작동해야 하는 다중 라운드 대화와 같은 스트리밍 애플리케이션에 이상적입니다.
     * 저자들은 StreamingLLM의 핵심 코드, Llama-2, MPT, Falcon, Pythia를 포함, 그리고 혼란도 코드, Streaming Llama Chatbot 데모, StreamEval 데이터셋 및 평가 코드를 공개할 계획입니다.
"
"https://news.hada.io/topic?id=11209","Show HN: 설치 가능한 웹 앱 전용 앱 스토어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Show HN: 설치 가능한 웹 앱 전용 앱 스토어

     * 새로운 앱 스토어가 설치 가능한 웹 앱 전용으로 논의되는 기사.
     * 앱 스토어는 PWA Labs, Inc.에서 개발됨.
     * 스토어는 AI, Crypto, Games, Productivity, Shopping, Social 등 다양한 카테고리의 앱을 특징으로 함.
     * 주요 앱으로는 Starbucks, Stemstr, Linear, BrandBird Studio, PromptPerfect 등이 포함됨.
     * 스토어는 또한 dexie, Kickresume, friend.tech, Unlonely, Writesonic 등의 트렌드 앱을 강조함.
     * 플랫폼은 또한 PromptPerfect, Replika, Chatfuel, OpenDream, Midjourney, Upscale.media 등의 최고의 AI 앱을 전시함.
     * 스토어는 또한 Wordi, Sudoku, Colonist, PROXX, Vapor Boy와 같은 게임을 특징으로 함.
     * 사용자는 플랫폼에서 가입하고 사용자 이름을 예약할 수 있음.
     * 앱 개발자는 플랫폼에 앱을 등록할 기회를 가짐.
     * 플랫폼은 사용자가 브라우즈, 프로필 생성, 선호 설정, 즐겨찾기 목록 작성 등의 옵션을 제공함.

        Hacker News 의견

     * 새로운 앱 스토어의 출시에 대한 기사, 특히 설치 가능한 웹 앱을 위한 것.
     * 일부 사용자들은 특히 데스크탑에서 URL이 있는 웹사이트를 앱보다 선호하며, 현재 웹사이트의 사용 추세에 의문을 제기.
     * 앱 스토어가 기본적으로 설치 가능한 앱만 필터링하도록 제안, 특히 모바일 사용자를 위해 오프라인에서도 사용 가능한 필터를 포함.
     * 일부 사용자들은 설치된 PWA가 자신의 휴대폰에 표시되는 방식에 불만을 표현.
     * 새로운 앱 스토어와 몇 년 전의 유사한 프로젝트 사이에 비교가 이루어짐.
     * 일부 사용자들은 앱 스토어의 'Get' 버튼에 혼란을 느끼며, '기기에 앱 설치'를 요청하지만 홈페이지로만 리디렉션.
     * 스토어의 일부 웹 앱들의 첫 인상 경험이 좋지 않다는 비판, 많은 앱들이 콘텐츠에 접근을 허용하기 전에 계정 생성을 요구.
     * 한 사용자는 앱 스토어의 도메인을 칭찬하며, 홈페이지의 수평 캐러셀을 트랙패드를 통해 스크롤 가능하게 함으로써 사용자 경험을 개선하자고 제안.
     * 새로운 앱 스토어의 성공을 희망하는 의견, 일부 사용자들은 Apple과 Google의 기존 앱 스토어에 대한 불만을 공유.
     * 앱 스토어에 오픈 소스 카테고리/태그와 다크 테마를 포함시키는 제안.
     * 목록 페이지에서 상세 페이지로 이동한 후 뒤로 가기를 누르면 스크롤 위치를 복원하지 않는 앱 스토어에 대한 피드백, 이는 브라우징 시나리오를 방해.
"
"https://news.hada.io/topic?id=11193","구글 Pixel 8 Pro 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           구글 Pixel 8 Pro 공개

     * Google Tensor G3 + Titan M2 보안칩, 12GB LPDDR5X
     * 6.7"" Super Actua 디스플레이. LTPO OLED. 120Hz. Always-on-Display
     * 213g
     * 50MP Octa PD 와이드 카메라(ƒ/1.68) + 48MP Quad PD 울트라와이드 카메라(ƒ/1.95) + 48MP Quad PD 망원 카메라(ƒ/2.8, 5배 광학줌)
          + Multi-zone LDAF (laser detect auto focus) 센서
     * 5050 mAh 배터리로 24시간 이상 사용 가능. 고속 충전(별도의 30W USB-PD 충전기)
     * 7년간 OS 업데이트 보장
     * 언더 디스플레이 지문 센서 및 얼굴인식 인증
     * 듀얼 SIM(Single Nano SIM + eSIM)
     * Wi-Fi 7 (802.11be), Bluetooth® v5.3, NFC, Dual Band GNSS
     * 5G mmWave + Sub 6GHz
     * Obsidian, Porcelain, Bay 컬러
     * $999 부터 용량에 따라 가격

   언제 또 국내정발 해주려나...

   원래 링크는 한국에서 안보여서, 미국 스토어 링크로 찾아서 교체 해뒀습니다.
   https://store.google.com/US/product/pixel_8_pro?hl=en-US

        Hacker News 의견

     * 스마트폰의 연간 출시 주기는 소프트웨어 기능과 하드웨어 업그레이드에 초점을 맞추는 것에 대한 비판을 받고 있다.
     * 스마트폰의 끊임없는 재디자인은 물리적 폐기물을 생성하며 이전 모델의 액세서리를 무용지물로 만든다.
     * 더 의미 있는 개선을 위해 스마트폰 출시를 5년마다로 늘리는 제안이 제시되었다.
     * 스마트폰의 빠른 발전이 주목되며, ""지루한"" 점진적 개선 단계가 첫 스마트폰 출시 후 단 15년 만에 도달했다.
     * iFixit와의 파트너십과 7년간의 지원은 인정받지만, 새 모델에 대한 수익 감소가 지적되었다.
     * Pixels와 iPhones의 가치 하락이 강조되며, iPhones가 훨씬 더 많은 가치를 유지한다.
     * Google 스토어의 지역 제한에 대한 불만이 표현되었다.
     * Pixel 8 Pro는 그 큰 크기와 가격 상승에 대해 비판을 받았다.
     * 저렴하고, 오래 지속되며, 수리 가능하고, 바닐라 안드로이드와 장기 소프트웨어 업데이트를 갖춘 스마트폰에 대한 욕구가 표현되었다.
     * 7년간의 지원은 안드로이드 생태계에서 중요한 개선으로 간주된다.
     * Pro의 온도 센서는 멋진 추가로 간주된다.
     * Pixel의 긴급 전화 문제에 대한 우려가 제기되었다.
     * 오디오 매직 이레이저 기능이 이전 Pixel 전화에서 사용 가능할지에 대한 의문이 제기되었다.
     * 스마트폰의 개발 주기는 혁신적이기보다는 반복적이라는 것으로 보인다.

   우와 이 요약은 인공지능으로 하시는 건가요?

   아.. 상세정보에 봇이라고 써있군요..
   신기한 세상
"
"https://news.hada.io/topic?id=11274","HTTP/2 신속한 재설정 취약점으로 인해 역대 규모의 DDoS 발생","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 HTTP/2 신속한 재설정 취약점으로 인해 역대 규모의 DDoS 발생

     * Google은 초당 3억 9800만 개의 요청이 들어오는 역대 규모의 DDoS를 처리함.
          + 공격이 있던 2분간 발생한 요청 수는 위키피디아의 1달 트레픽보다 많음.
     * 이 공격은 HTTP/2의 새로운 취약점인 신속한 재설정(Rapid Reset)에 의해 발생.
          + HTTP/2 동작 방식에 따라 스트림 멀티플렉싱과 요청 취소 기능 사용.
          + 한 클라이언트에서 네트워크 대역폭이 허락하는 한 무한한 수의 요청을 만들 수 있음.
               o 원래 7계층 DoS 공격은 RTT, 동시 연결 수 에 의존하여 한 클라이언트가 많은 요청을 생성하는 데 제한적임.
               o 하지만 이 방법은 요청 생성 후 즉시 취소하는 과정을 통해 아주 빠르게 요청을 생성 가능.
          + 기존에 있던 역대 규모의 DDoS와 다르게 적은 수의 기기로 효과적인 공격이 가능.
          + 이 취약점은 CVE-2023-44487에서 확인할 수 있으며, CVSS 점수는 7.5 점으로 심각한 수준.
     * 다른 공급업체인 Cloudflare와 AWS도 각각 2.01억 RPS와 1.55억 RPS의 DDoS 공격을 받음.
          + Cloudflare는 2만여 대의 봇넷에 의해 공격이 발생했다고 밝힘.
               o 기존에 있던 거대 규모의 DDoS는 수십 ~ 수백만 대의 봇넷에 의해 발생함.
     * Nginx, Caddy 등 웹 서버는 신속하게 패치를 진행하고 있음.
          + 특이하게 HAProxy는 2018년에 이 문제를 해결함.

     * 위 링크의 HN 스레드
     * 관련된 HN 스레드
          + Google - 작동 방식: 새로운 HTTP/2 '신속한 재설정' DDoS 공격
     * 관련된 HN 스레드
          + Cloudflare - HTTP/2 제로데이 취약점으로 인해 기록적인 DDoS 공격 발생

   초당 요청이 거의 4억 회라니... 진짜 무시무시하네요.
   HTTP/2 구현에 취약점이 있던 건데 이걸 완화한 구글, Cloudflare, AWS 등도 대단하긴 합니다.

   제일 신기한 게 HAProxy가 2018년에 이 문제를 해결했다는 점 같아요.
   당시에 이 취약점을 식별하고 수정한 건 아니지만, 나중에 다시 살펴보니 2018년에 제기된 문제가 이 취약점을 해결하는 아이디어였다고 합니다.

   아무튼 웹 서버 쓰시는 분들은 이 취약점이 해결된 버전으로 업데이트 하시기를 바랍니다.
"
"https://news.hada.io/topic?id=11273","AMD Ryzen 7000 데스크탑 CPU에 ECC RAM 기술 적용","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 AMD Ryzen 7000 데스크탑 CPU에 ECC RAM 기술 적용

     * AMD Ryzen 7000 데스크탑 CPU에서 ECC RAM 사용에 대한 기사
     * ECC RAM은 AMD의 Ryzen 데스크탑 CPU의 주요 특징으로, 경쟁사보다 선호되는 선택이었음
     * ECC RAM 지원은 대부분의 Ryzen 1000에서 5000 시리즈 CPU와 호환되는 마더보드에서 가능했음
     * 그러나 AMD Ryzen 7000 ""Raphael"" CPU와 새로운 Socket AM5의 출시와 함께 ECC 지원에 대한 언급이 없었음
     * 저자는 Ryzen 7950X로 업그레이드했지만 ECC 지원이 없어 초기에 실망했음
     * ApplesOfEpicness라는 사용자의 포럼 게시물에서는 AMD 엔지니어와 함께 AM5 마더보드에서 ECC RAM을 활성화하는 작업에 대해 언급했음
     * 이에 흥미를 느낀 저자는 32 GB 서버 등급 ECC 스틱을 한 쌍 주문하고 마더보드의 UEFI를 최신 버전으로 업데이트했음
     * 기존 RAM을 새로운 스틱으로 교체한 후, 시스템이 부팅되어 ECC 메모리가 올바르게 작동하고 있음을 나타냄
     * 저자는 Python 스크립트를 사용하여 System Management Network (SMN) 버스를 통해 Unified Memory Controller (UMC)에 쿼리를 보내 ECC가 활성화되었는지 확인했음
     * 저자는 Ryzen 7000 데스크탑 CPU에서 특히 ASRock 마더보드와 함께 ECC RAM을 활성화할 수 있다는 결론을 내림
     * 저자는 ECC RAM이 대부분의 데스크탑 사용자에게는 과도할 수 있지만, 컴퓨터에 의존하는 사람들에게는 유익하다는 것을 인정함

        Hacker News 의견

     * ECC RAM의 AMD Ryzen 7000 데스크탑 CPU 사용에 대한 기사
     * ASRock B550M-ITX/ac 및 AMD Ryzen 5 PRO 5650G를 사용한 AMD 시스템에서 ECC 지원에 대한 한 사용자의 경험 공유
     * ECC RAM 설정에 관심을 표한 또 다른 사용자의 AMD 프로세서 및 마더보드의 실제 ECC 지원에 대한 논쟁 언급
     * 잠재적 성능 저하를 고려할 때, 워크스테이션/개발자 컴퓨터에서 ECC RAM의 실용적 이점에 대한 질문 제기
     * Ryzen 3700X 및 ASUS TUF 게이밍 x570 MB 설정을 더 나은 단일 코어 성능 및 더 빠른 NVMe/디스크 속도를 위해 업그레이드를 고려하는 사용자
     * Hetzner가 몇 달 동안 ECC RAM과 함께 Ryzen 7000 CPU를 제공하는 데이터 포인트 공유
     * Threadripper 보드에서 ECC RAM을 사용한 경험을 공유하는 사용자와 인텔 보드에 수정 가능한 오류를 보고하도록 지시할 필요성 언급
     * 일부 ASUS AM5 마더보드가 공식적으로 ECC를 지원하나, 기본 BIOS 설정은 비활성화 상태라는 언급
     * 비-ECC 시스템의 취약성에 대한 우려를 표현하며, 입법자들이 ECC를 의무화해야 한다고 제안하는 사용자
     * ECC가 작동하는지 테스트하는 가장 확실한 방법은 오류를 도입하는 것이지만, 한 사용자는 RAM을 물리적으로 짧게 만들거나 천천히 오버클럭하는 것을 꺼려함
     * ECC 기능을 테스트하는 방법으로 헤어 드라이어를 사용하여 오류를 생성하라고 제안하는 사용자
"
"https://news.hada.io/topic?id=11253","한국 마스토돈 연합에 속한 twingyeo.kr 가 오늘(10월 10일) 운영을 중단합니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          한국 마스토돈 연합에 속한 twingyeo.kr 가 오늘(10월 10일) 운영을 중단합니다.

   twingyeo.kr의 self-destruct가 시작되었습니다. 이에 해당 링크의 접근이 불가능합니다.
"
"https://news.hada.io/topic?id=11210","NIST 타원 곡선 시드 바운티","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NIST 타원 곡선 시드 바운티

     * NIST 타원 곡선은 현대 암호학에 필수적이며, 90년대 후반에 NSA가 제공한 시드를 해싱하여 생성되었습니다.
     * 특정 해시 5개를 해독하기 위한 현상금은 $12,288이며, 수령자가 이를 501(c)(3) 자선단체에 기부하기로 결정하면 $36,864로 증가합니다.
     * NIST 타원 곡선 (P-192, P-224, P-256, P-384, P-521)은 2000년에 NIST가 FIPS 186-2에서 발표하였으며, 임의의 시드를 취하고 이를 SHA-1로 해싱하여 일부 매개변수를 도출하는 방식으로 ""검증 가능한 무작위""로 생성되었습니다.
     * 시드는 NSA가 제공하였으며, 1997년에 Jerry Solinas가 생성하였는데, 그는 나중에 잊어버린 영어 문장을 해싱하여 생성했다고 주장했습니다.
     * 이 현상금은 시드를 생성한 해시의 입력값인 프리-시드를 찾는 것을 목표로 하며, 이는 비밀번호 크래커와 브레인월렛 브루트포서에게 일반적인 작업입니다.
     * 입력값은 Jerry Solinas를 언급하는 영어 구문일 가능성이 크며, 아마도 다른 사람을 언급하고, 아마도 카운터일 것입니다.
     * 현상금은 첫 번째로 NIST의 5개 소수 순서 곡선에 대한 프리-시드를 seeds@filippo.io로 이메일 보내는 사람(들)에게 지급될 것입니다.
     * 현상금의 절반 ($6,144)은 적어도 하나의 프리-시드를 처음 제출한 사람에게 지급되며, 나머지 절반은 모든 5개의 프리-시드를 처음 제출한 사람에게 지급될 것입니다.
     * 현상금은 페이지에서 그렇게 발표될 때까지 유효하며, 취소되거나 줄어들 경우 6개월 전에 발표될 것입니다.

        Hacker News 의견

     * NIST P-곡선은 현대 암호학에 중요하며, 1990년대에 NSA가 제공한 씨앗을 해싱하여 생성되었습니다.
     * 이러한 곡선의 ""랜덤"" 씨앗은 NSA의 Jerry Solinas가 만든 ""Give Jerry a raise""라는 문구의 변형의 SHA1 해시라고 주장되었습니다.
     * SHA1의 사용은 씨앗의 구조를 파괴하여 NSA가 고의적으로 약한 씨앗을 선택하는 것을 방지하고, 곡선 씨앗에 대한 신뢰를 높이기 위한 것이었습니다.
     * 그러나 Solinas가 이 씨앗을 재구성하여 그것들의 해롭지 않은 성질을 증명하려고 시도했을 때, 그는 사용한 정확한 문자열을 기억할 수 없었습니다.
     * 이 씨앗을 생성하는 원래 문자열을 찾을 수 있는 사람에게는 현상금이 걸려 있습니다.
     * NSA가 제공한 이러한 씨앗이 추가적인 심사 없이 받아들여진 사실에 커뮤니티의 일부 사람들이 불안감을 느낍니다.
     * 지능 기관의 능력에 대한 추측이 있습니다, 그들의 암호학에 대한 지식과 관여의 역사를 감안할 때.
     * 일부 사용자들은 이 문구가 비밀번호를 깨는 것이 가능하다면, 그것이 중요한 역사적 영향을 미칠 것이라고 믿어 현상금에 기여하고 있습니다.
     * SHA1 해시를 추측해보고 싶은 사람들을 위한 링크가 제공됩니다: https://wending.dev/hash_guessing/
     * 씨앗의 창조자인 Jerry가 결국 인상을 받았는지에 대한 유머러스한 질문이 있습니다.
     * Professor Dan Boneh가 상황의 배경을 설명하는 비디오 링크가 제공됩니다: https://youtu.be/8WDOpzxpnTE?t=892
     * 일부 사용자들은 암호학 분야에서의 경험에 기반하여 NIST에 대한 불신을 표현합니다.
"
"https://news.hada.io/topic?id=11241","NES에서의 Elite에 대한 문서화된 소스 코드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NES에서의 Elite에 대한 문서화된 소스 코드

     * 텍스트는 닌텐도 엔터테인먼트 시스템(NES)의 게임 'Elite'의 완전히 문서화된 소스 코드에 대해 논의하고 있다.
     * 소스 코드는 모든 줄이 문서화되고 설명된 저장소에서 사용할 수 있다.
     * 저장소에는 소스 코드에서 게임을 빌드하는 방법에 대한 지침도 포함되어 있다.
     * 소스에서 빌드할 수 있는 게임의 두 가지 버전: Ian Bell의 개인 웹사이트에서의 NTSC 버전과 Imagineer PAL 버전이 있다.
     * 저장소는 교육적이고 비영리 목적으로, 사람들이 게임과 그 개발에 대해 더 이해하는 데 도움을 주기 위해 만들어졌다.
     * 게임의 소스 코드는 Ian Bell과 David Braben에 의해 작성되었으며, 코드에 대한 해설은 Mark Moxon이 제공하였다.
     * 저장소는 라이선스가 없으므로, 원래의 저작권법이 적용되며 아무도 작품을 복제, 배포, 파생 작품을 만들 수 없다.
     * 소스 코드는 통합 개발 환경(IDE)에서 탐색할 수 있으며, 주 게임의 소스 코드는 여덟 개의 다른 ROM 뱅크에 나뉘어 있다.
     * 저장소에는 게임의 특정 측면에 대해 자세히 다루는 ""깊은 탐구"" 기사도 여러 개 포함되어 있다.
     * 게임의 빌드 과정은 BeebAsm과 Python이 필요하며, 과정은 제공된 Makefile에서 정의된다.
     * 빌드 과정은 두 가지 주요 목표를 지원한다: 최대한 강화된 커맨더 버전과 게임의 출시 버전을 맞춘 버전.
     * 저장소에는 두 가지 다른 버전의 NES Elite의 소스 코드도 포함되어 있다: Ian Bell의 개인 웹사이트에서의 NTSC 버전과 Imagineer PAL 버전.
     * 텍스트는 NTSC 버전이 실제로는 NTSC 기계에서 작동하지 않지만, NTSC 모드에서 일부 에뮬레이터와 함께 작동하도록 변경되었다는 노트로 마무리된다.

        Hacker News 의견

     * Elite의 NES 버전은 초기에 하드웨어 타이머를 사용하여 게임 내 물리학을 위한 실시간을 추적했지만, 일부 NES 콘솔의 하드웨어 제한 때문에 자체 구현된 실시간 시계로 전환해야 했습니다.
     * 개발자들은 각 기능이 프레임당 얼마나 많은 클럭 사이클을 소비하는지에 대한 자체 추정을 만들었고, 이를 사용하여 실제 시간이 얼마나 경과했는지 추정했습니다.
     * 후속 게임인 Elite: Dangerous는 원래 1984년 버전과 연속성을 유지하면서 게임 요소를 벡터 그래픽에서 완전히 렌더링된 3D로 변환합니다.
     * 게임의 C 버전인 Elite - The New Kind는 원래 버전에 대부분 충실합니다.
     * Elite의 저자인 Ian Bell은 NES 버전이 그의 개인적으로 가장 좋아하는 8비트 버전이라고 주장했습니다.
     * Objective-C로 작성된 오픈 소스 Elite 클론인 Oolite의 소스 코드는 온라인에서 사용할 수 있습니다.
     * NES에서의 Elite의 소스 코드는 매우 상세하고 잘 문서화되어 있습니다.
     * NTSC 콘솔에서 게임을 실행하려는 관심이 있지만, 이를 위해서는 상당한 수정이 필요할 것입니다.
"
"https://news.hada.io/topic?id=11152","Bing ChatGPT 이미지 탈옥","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Bing ChatGPT 이미지 탈옥
"
"https://news.hada.io/topic?id=11192","디트로이트 남성, 블루투스를 이용해 주유소의 가스 펌프를 해킹하여 800갤런 훔쳐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             디트로이트 남성, 블루투스를 이용해 주유소의 가스 펌프를 해킹하여 800갤런 훔쳐

     * 디트로이트의 한 남성이 블루투스 기술을 이용해 가스 펌프를 해킹하여 800갤런의 가스를 훔침
     * 휴대폰의 블루투스를 이용하여 가스 펌프 시스템을 무력화시키는 것으로, 무료로 가스를 가져갈 수 있게함
     * 이 도둑질은 에이트 마일과 와이오밍에 위치한 쉘 가스 스테이션에서 발생했으며, 도둑은 거의 800갤런의 가스를 훔쳐 스테이션에 약 3,000달러의 손해를 입혔음
     * 스테이션 직원들은 해킹으로 인해 펌프의 정지 기능이 무력화되어 도둑질을 막을 수 없었다고
     * 이 가스 스테이션은 디트로이트 경찰이 순찰하는 ""프로젝트 그린 라이트"" 계획의 일부로, 현재 용의자의 감시 카메라 영상이 검토 중
     * 이 사기는 새로운 것이 아니며 최근에 다시 등장했는데, 리버뷰의 스피드웨이 스테이션에서도 도둑들이 유인-교환 전략을 사용한 비슷한 사건이 발생
     * 가스 스테이션 소유주들은 이제 잠재적인 사기에 대해 경계하고 있으며, 직원들은 의심스러운 활동을 발견하면 경찰에 전화하도록 지시 받음

        Hacker News 의견

     * 댓글러들은 가스 펌프 해킹에서 블루투스의 사용에 의문을 제기하며, 시장에 블루투스 기능이 있는 펌프를 알지 못한다고 지적합니다.
     * 원문 기사의 세부 사항과 입증 부족에 대한 비판이 있으며, 일부 댓글러들은 제공된 정보가 부정확할 수 있다고 제안합니다.
     * 일부는 펌프 내장 PC의 설계 결함이나 비활성화되지 않은 기본 기능 때문에 해킹이 가능했을 수 있다고 추측합니다.
     * 다른 사람들은 가스 펌프의 구조가 비용과 속도를 고려하여 사용되지 않지만 남겨진 블루투스 기능 부품을 포함할 수 있다고 제안합니다.
     * IoT를 모든 것에 사용하는 것의 보안적인 시사점에 대한 우려가 있으며, 이러한 제품을 개발하는 많은 회사들이 보안을 우선시하지 않는다는 댓글이 있습니다.
     * 일부 댓글러들은 해킹과 관련된 ""샘플 코드""의 공개 부족에 대해 불만을 표현합니다.
"
"https://news.hada.io/topic?id=11221","HN에게 알림: 계정 생성을 거부하면 Postman 업데이트가 모든 자료를 삭제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              HN에게 알림: 계정 생성을 거부하면 Postman 업데이트가 모든 자료를 삭제

     * 오랫동안 계정 없이 오프라인에서 Postman을 사용하였습니다. 오늘 프로그램을 열었을 때 계정을 생성하라는 메시지가 나왔습니다. 거절하자 모든 컬렉션과 기타 모든 것이 사라졌습니다.
     * 제가 가진 것은 '히스토리'뿐이며, 설정해놓았던 모든 변수와 컬렉션을 다시 조립해야 합니다.
     * 결국 계정을 생성하였지만, 아무것도 복구되지 않았습니다. 주의하세요!
     * 업데이트: ~/.config/Postman에서 찾은 백업을 사용해 수동으로 가져오기/복원할 수 있었습니다. 하지만 이 도구를 계속 사용하는 데 대한 신뢰는 없습니다. 이전할 수 있는 다른 대안이 있을까요?

        Hacker News 의견

     * Postman의 최근 업데이트는 계정 생성을 거부하는 모든 사용자 데이터를 삭제합니다.
     * 이번 Postman의 조치는 최근 Insomnia가 한 것과 유사합니다.
     * Postman과 Insomnia에 대한 대안이 논의되고 있으며, 이에는 텍스트 파일에서 요청을 정의할 수 있게 하는 VSCode 확장 기능이 포함됩니다.
     * 이러한 VSCode 확장 중 하나는 humao.rest-client로, 사용자가 파일을 실행하고 데이터를 표시할 수 있게 합니다.
     * HTTPie는 Postman이 너무 무거워 유용하지 않다는 이유로 사용자들이 즐겨 사용하는 또 다른 대안입니다.
     * 일부 사용자들은 프로젝트 데이터를 플랫폼에 저장하는 것을 방지하는 비밀 유지 합의(NDA)로 인해 Postman 사용을 중단했습니다.
     * Bruno는 버전 관리에 친화적인 기본 대안으로 Postman에 대해 제안되었습니다.
     * Bruno는 사용자의 파일 시스템에 직접 컬렉션을 저장하고 완전히 오프라인에서 작동하는 무료 오픈소스 API 탐색 및 테스트용 IDE입니다.
     * Kreya는 또 다른 추천 대안으로, 오픈소스는 아니지만 개인 정보 보호와 로컬 데이터 저장에 중점을 둡니다.
     * JetBrains IDE의 HTTP 클라이언트는 텍스트 기반 관리와 자동 기능으로 매우 추천됩니다.
     * 일부 사용자들은 Postman에 불만족하여 Insomnia로 전환했으며, 이를 적절한 대체품으로 발견했습니다.
     * 다른 사용자들은 많은 헤더를 처리할 때 curl을 사용하고 vim으로 쉘 명령 줄을 편집하는 것을 선호합니다.
"
"https://news.hada.io/topic?id=11270","Redis 사용량 타노스하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Redis 사용량 타노스하기

   Redis에 수많은 데이터들이 JSON 형태로 압축 없이 저장되고, Redis 서비스 간 모델 공유가 되지 않아 발생하는 비용을 절감하기 위한 엔지니어링 작업기
     * 동일한 원본 데이터의 저장 방식을 바꿔서 Elasticache의 메모리 사용량을 52%, 비용을 66% 절약
     * JSON 대신 Protobuf를 사용해서 데이터 스펙을 명시함과 동시에 서비스간 데이터 읽기/쓰기 방식을 통일
     * brotli를 비교했을 때 brotli가 가장 높은 압축률을 보임. window 크기와 압축 레벨에 따른 소요시간과 압축률을 비교해서 최적값을 찾아 적용함
     * UUID를 Redis의 key로 사용할 때 ascii85를 사용해서 메모리 사용량을 조금이나마 절약할 수 있었음
     * 도메인 관련 기술 부채가 인프라에 대한 비용 절감 작업의 장애물이 될 수 있음을 인지하고, 명시적인 schema로 이를 청산함

   서버 스펙이 날로 높아지면서 최적화에 대한 고민 보다는 빨리 제품을 만드는데만 몰두 해있었는데 오랜만에 최적화에 대해 고민할 수 있게 해주는 좋은 내용이네요!!

   그렇죠, 사실 가독성과 유동적인 구조화가 편하다는 장점 때문에 JSON이 주로 쓰이지만, 용량 측면에선 protobuf 같이 바이너리 프로토콜을 쓰는게 편하고, 극단적으로 나아가면 전통적인 PE구조나 TCP 프로토콜 같이 극도로 최적화된 바이너리 프로토콜 같은게 좋죠.
   도메인 관련 기술 부채라는 말씀이 딱 맞는 말 같습니다.

   멋지네요

   사장님! 이 분 월급 많이 올려 드리세요!!
"
"https://news.hada.io/topic?id=11213","델타항공, 위조 항공기능성 서류와 함께 가짜 제트 항공기 엔진 부품 발견","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                델타항공, 위조 항공기능성 서류와 함께 가짜 제트 항공기 엔진 부품 발견

     * 델타 항공사, 제트기 엔진에서 불법 부품 발견
     * 델타, 가짜 부품 사용 공시한 미국 4대 항공사 중 하나로 등극, 이전에는 아메리칸 항공, 유나이티드 항공, 사우스웨스트 항공이 공시
     * 의심 부품은 델타의 주력 기체인 2,100대 이상의 전력 발전소 중 1% 미만에서 발견
     * 문제의 부품은 현재 규제기관의 조사를 받고 있는 런던 기반 회사인 AOG Technics Ltd.에 의해 인증
     * 델타, 부정하게 문서화된 부품이 사용된 엔진의 서비스 여부를 공개하지 않음
     * 델타의 엔진 중 최대 21대가 영향을 받았을 수 있음, 이는 숫자를 공개한 미국 항공사 중 가장 많음
     * 델타, 불법 부품 교체 진행 중, 모든 FAA 지침 준수
     * 델타의 항공기 중 현재 불법 부품을 사용하는 것은 없으며, 이 발견이 항공 운항에 영향을 미치지 않음
     * 항공사, 유지 보수 제공업체, 규제기관 전 세계적으로 AOG에서 공급한 위조 항공 기술 적합성 문서 부품 조사 중
     * AOG, GE와 Safran이 소송을 제기한 후, 추가 의심 부품을 식별하기 위해 기록을 제출하라는 런던 판사의 명령 받음

        Hacker News 의견

     * Delta가 위조된 항공 기록서를 가진 가짜 제트기 엔진 부품을 발견했습니다.
     * Delta는 사기적으로 기록된 부품이 있는 엔진이 서비스에 투입되었는지 확인하지 않았습니다.
     * Delta의 항공기 중 어느 것도 승인되지 않은 부품을 사용하고 있지 않으며, 이 발견이 항공 운항에 영향을 미치지 않았습니다.
     * 가짜 부품은 이름을 밝히지 않은 제3자가 엔진 작업 중에 감지되었습니다.
     * 가짜 항공기 부품이 원인인 것으로 밝혀진 항공기 추락 조사에 대한 링크가 추가적인 맥락을 제공하기 위해 공유되었습니다.
     * 일화적 증거는 민간 항공 제트 엔진 산업에서 가짜 부품에 대한 보고가 2000년대 중반 이후로 발생해 왔음을 제안합니다.
     * 일부 댓글은 FAA 승인 부품의 높은 비용이 규제가 엄격한 항공 부문에서 위조 부품 사용을 유인할 수 있다고 제안합니다.
     * 이 상황은 마이클 크라이튼의 책 ""Airframe""의 줄거리를 연상시킵니다.
     * 캐나다의 WestJet에서도 비슷한 문제가 발생했습니다.
     * 위조 부품이 있는 엔진은 Delta의 2,100개 이상의 엔진 중 1% 미만을 차지합니다.
     * 가짜 항공기 부품의 거래/세탁은 매우 수익성이 높으며, 이에 대한 스캔들이 과거에 있었습니다.
     * 일부 댓글은 부품을 ""가짜""라고 표현하는 것에 반대하며, ""인증되지 않은"" 또는 ""위조""가 더 정확한 용어라고 제안합니다.
"
"https://news.hada.io/topic?id=11173","FDA가 승인한 수십 종류의 유전성 암을 진단하는 첫 번째 혈액 검사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 FDA가 승인한 수십 종류의 유전성 암을 진단하는 첫 번째 혈액 검사

     * FDA, 수백 가지의 잠재적 암 관련 유전 변이를 식별할 수 있는 첫 번째 혈액 검사를 승인하다.
     * 이 검사는 Invitae Common Hereditary Cancers Panel이라는 이름으로, 특정 종류의 암 발병 위험과 관련된 47개의 유전자에서 DNA 변이를 식별하기 위해 혈액 샘플을 평가한다.
     * FDA는 이 검사에 대해 de novo 마케팅 승인을 부여하며, 새로운 규제 분류를 만들었다.
     * 같은 유형의 미래 장치는 FDA의 510(k) 사전 시장 과정을 통해 마케팅 승인을 받을 수 있다.
     * FDA는 라벨링 및 성능 테스트와 관련된 특별한 제어를 설정하고 있다.
     * 이 검사는 다음 세대 시퀀싱을 사용하여 단일 검사에서 여러 유전자를 평가하며, 민감도와 속도로 유전 변이에 대한 통찰력을 제공한다.
     * 이 검사는 유전성 유방 및 난소암 증후군과 관련된 BRCA1 및 BRCA2와 같은 임상적으로 중요한 유전자와 Lynch 증후군, 유전성 확산성 위암, 유방암, Peutz-Jeghers 증후군과 관련된 다른 유전자를 식별한다.
     * 이 검사와 관련된 위험에는 거짓 양성 또는 거짓 음성 결과, 그리고 결과의 잘못된 이해가 포함된다.
     * Invitae의 처방 검사의 경우, 표본은 의사의 사무실과 같은 진료 과정에서 수집되어 실험실로 보내져 검사를 받는다.
     * 변이의 임상 해석은 출판된 문헌, 공개 데이터베이스, 예측 프로그램, 그리고 회사 내부에서 정리된 변이 데이터베이스를 사용하여 전문 단체나 인증된 위원회가 설정한 변이 해석 기준에 기반하여 이루어진다.

        Hacker News 의견

     * FDA, 유전성 암 수십 종에 대한 첫 혈액 검사 승인.
     * Invitae 개발 검사, 암 위험 증가와 관련된 47개 유전자 확인.
     * FDA 승인으로 보험 적용 가능성.
     * Galleri와 같은 다른 혈액 검사와 달리 암 진단 불가능.
     * 건강 보험 및 보험료에 대한 위험 프로필을 알고 있는 것의 영향에 대한 우려, 특히 미국에서.
     * Invitae, 고품질 유전 진단 검사 상용화 및 합리적인 가격으로 소비자에게 직접 제공에 대한 찬사.
     * IVF와 같은 것들에 대해 기회가 있을 경우 이러한 검사를 받지 않는 것은 거의 비윤리적이라고 일부 사용자들은 믿음.
     * 이러한 유전 검사를 의료 실무에 통합하는 데 문제가 있음, 의사들이 정보를 어떻게 활용해야 할지 모를 수 있음.
     * 23andme와 같은 저렴한 DNA 검사에서 이미 이러한 유전자를 식별하고 있는지에 대한 일부 사용자들의 의문.
     * Invitae의 사업 전략은 위험하였으며, 회사의 장기 생존에 대한 우려가 있음.
     * 40개 이상의 암 종을 감지하며, 일부는 1기에서부터 감지하는 Grail의 Galleri 검사가 비교 대상으로 언급됨. 검사당 약 1000달러 비용.
"
"https://news.hada.io/topic?id=11220","AMD는 어떻게 CUDA 해자를 넘을 수 있을까","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       AMD는 어떻게 CUDA 해자를 넘을 수 있을까

     * Nvidia는 CUDA와 cuDNN 같은 소프트웨어 도구와 최적화된 라이브러리 덕분에 GenAI 분야에서의 우위를 가지고 있음
          + 하드웨어 주변에 강력한 소프트웨어 ""해자(Moat)""를 구축해 HPC와 GenAI 시장에서 다른 회사들이 경쟁하는 것을 어렵게 만듦
     * GenAI 컴퓨팅 자원에 대한 수요 증가로 인해 GPU가 더 필요해지고 있음. 이로 인해 공급-수요 격차가 발생하고, AMD와 같은 회사들이 이를 채우려고 함
     * Nvidia와 경쟁하기 위해, 다른 제조사의 GPU와 가속기는 CUDA를 지원해야 함. AMD는 이를 HIP CUDA 변환 도구를 통해 가능하게 함
     * PyTorch 오픈소스 머신러닝 라이브러리는 GPU를 이용한 AI 애플리케이션을 만드는데 TensorFlow의 대안으로 인기를 얻고 있음.
     * PyTorch는 사용자를 기본 GPU 아키텍처로부터 격리시켜 AMD GPU가 CUDA 해자를 넘기는 것을 용이하게 함
     * Nvidia의 다가오는 72코어 ARM 기반 Grace-Hopper 슈퍼칩은 HPC와 GenAI에서의 잠재적 성능으로 많은 기대를 받고 있음
     * AMD는 다가오는 Instinct MI300A 프로세서로 Nvidia의 Grace-Hopper 슈퍼칩과 경쟁할 예정이며, 이 프로세서는 Lawrence Livermore National Laboratory의 다가오는 El Capitan을 구동할 것임
     * AMD CEO Lisa Su는 그들의 아키텍처 선택으로 인해 추론 솔루션의 산업 리더가 되려는 목표를 밝혔음
     * AMD 와 다른 하드웨어 벤더들에게 PyTorch는 CUDA 해자에 도개교(Drawbridge)를 놔줬음
     * GenAI 시장에서의 하드웨어 전투는 성능, 이식성, 그리고 가용성(performance, portability, and availability)에 의해 결정될 것

   좋은 기사 항상 잘 보고 있고 감사합니다 근데, 한가지 좀 개인적의견을 드리자면 , 한글화도 아니고 무슨 한자어로 변환하여 말이 어색하고 어렵습니다. 도개교라든지 해자라든지 이런 말은 영어 그대로 쓰거나 쉬운 한국말로 풀어주시면 좋겠어요

   해자는 많이 쓰이는 말이고, 도개교가 흔하게 쓰는 말은 아니지만 사전등을 찾아보면 딱 알맞게 번역된 용어인 것 같습니다.
   https://ko.wikipedia.org/wiki/%EA%B0%80%EB%8F%99%EA%B5%90

   경제쪽에서도 쓴다고는 알고있고 ai기술이 복잡해 짐에 따라 이걸 쓰는 건 알겠는데 용법이 틀리게 쓰는 거 같아요. 예를들어 기본 cpu아키텍처로부터 격리시켜 amd의 gpu가 cuda 해자를 넘기는 것을 용이하게한다는 건 뭔가 기술적으로 간단하게 해결되는 것 처럼 잘못 썼어요. 국문으로 해자를 넘어설 기술력이 있다는 표현이 더 어울리며 이 문장은 마치 무슨 라이브러리 하나가 뭘 해결할 수 있는 것처럼 써놔서 상당히 어색합니다. 해자가 그런 단어였나 싶을 정도로요

   해자는 대체가 딱히 안 되기도 하고 굳이 대체를 할 필요도 없는 너무도 적절한 단어인데요... 본인은 방금 사전으로 처음 접해서 낯설겠지만 다른 독자들이 모두 본인과 비슷한 어휘 수준을 가지고 있지는 않아요. 무지를 무기로 휘두르지 맙시다.

   뜨끔하네요. 하지만, 무지가 부끄러움이 되는 커뮤니티가 되지 않았으면 좋겠군요.

   맞습니다 저도 종종 자동 번역에서 어색한 부분을 느낄 때가 있어요.

   다만 ’해자‘는 이런 경우에 우리나라에서도 잘 쓰이는 표현입니다. 뉴스 검색에 ‘해자’ 검색해보시면 많은 결과를 확인할 수 있어요.

   AMD가 CUDA의 대항마로서 참여했던게 OpenCL이었던걸로 아는데 여기서 언급이 없는걸보니 그간 그렇게 인공지능 쪽 라이브러리와의 연계가 있진 않았나보네요.

        Hacker News 의견

     * 사용자는 ROCm을 Pytorch와 함께 사용하여 CPU에 비해 200배 성능 향상을 보았다.
     * AMD 설정의 복잡성 때문에 사용자는 공식 ROCm Pytorch 기본 도커 이미지 사용을 권장한다.
     * 사용자는 Nvidia 카드를 가진 유일한 이유가 CUDA이지만, 더 많은 프로젝트가 중립적인 환경으로 이동하면 감사할 것이라고 말했다.
     * 사용자는 Linux에서 Nvidia를 실행하는 것이 Windows Vista에서의 커널 충돌에 비해 즐겁지 않다고 느낀다.
     * 사용자는 AMD와 다른 경쟁사들의 경쟁을 환영하며, 대형 내부 RAM을 가진 Apple Silicon SOC에도 관심이 있다.
     * Pytorch는 다른 하드웨어를 허용하며, 사용자는 컴퓨팅 파워에 대한 실제 벤치마크를 보고 싶어한다.
     * AMD가 Nvidia와의 과학 또는 ML 소프트웨어에서 격차를 줄이는 것에 대한 실증적 증거는 제한적이다.
     * CUDA는 Nvidia가 생태계를 지원하는 노력의 결과물이며, Nvidia를 구매할 때, 그들이 생태계에 투자한 노력도 함께 구매하는 것이다.
     * AMD는 하드웨어를 가지고 있지만, bliss와 AOCL 외의 HPC에 대한 지원이 부족하다.
     * 사용자는 AMD가 Nvidia의 PTX처럼 전방 장치 호환성에 대한 해결책을 가지고 있는지 의문을 제기한다.
     * Nvidia의 우위는 오픈소스 커뮤니티, 대기업, 연구소들이 노력한 수년간의 작업이다.
     * 사용자는 AMD가 따라잡으면 취미용이나 부트스트랩 스타트업을 위한 가격이 낮아질지, 아니면 AMD도 Nvidia처럼 가격을 올릴지 의문을 제기한다.
     * AMD의 소프트웨어 솔루션은 어떤 하드웨어에서도 실행되도록 설계되었으며, hip이 cuda와 줄 단위로 호환되므로 이식이 매우 쉽다.
"
"https://news.hada.io/topic?id=11222","Cloudflare, 전체 서비스내의 CAPTCHA를 모두 Turnstile로 교체완료 및 누구나 사용가능하게 릴리즈 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Cloudflare, 전체 서비스내의 CAPTCHA를 모두 Turnstile로 교체완료 및 누구나 사용가능하게 릴리즈

     * ""사람에겐 더 쉽고, 봇에겐 더 어렵고, 더 Private한 CAPTCHA""
     * 1년간 베타중이던 무료 CAPTCHA 대체제 Turnstile을 Public Release
          + 플랫폼에서 완전히 분리해서 누구나 코드 몇줄만으로 사용 가능
     * WCAG 2.1 레벨 AA를 준수하면서 Audio CAPTCHA와 Visual CAPTCHA의 필요성을 제거
     * ePrivacy Directive, GDPR, CCPA 등을 모두 준수
          + 사용자가 사람인지 봇인지 판단하기 위해 사용자 트래킹 데이터를 사용하지 않음
     * 매니지드 모드에서 클라우드 플레어 로고가 보이는 버전은 무제한으로 이용 가능
     * Turnstile Enterprise 는 SaaS 플랫폼을 지원하여 클라우드 플레어 로고 없이도 이용 가능

   hCaptcha보다는 나은 것 같아요.

   Turnstile, Cloudflare가 공개한 무료 CAPTCHA 대체제
"
"https://news.hada.io/topic?id=11223","Wired가 "Google이 검색 쿼리를 변경하는 방법" 기사를 삭제함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Wired가 ""Google이 검색 쿼리를 변경하는 방법"" 기사를 삭제함

     * ""Google이 어떻게 검색 쿼리를 변경하여 당신의 지갑을 노린다""라는 제목의 기사가 Wired에서 삭제되었습니다.
     * 기사를 삭제하기로 한 결정은 Wired의 편집 리더십이 주의 깊게 검토한 후에 내려졌습니다.
     * 이 기사는 Wired의 편집 기준을 충족시키지 못했다고 판단되었습니다.
     * 기사의 삭제는 2023년 10월 6일에 Wired의 리더십으로부터의 메모에서 발표되었습니다.
     * 기사의 삭제는 Wired의 높은 편집 기준을 유지하려는 의지를 나타냅니다.
     * 기사의 삭제는 Google CEO Sundar Pichai와의 인터뷰와 같은 Wired의 다른 트렌딩 주제에는 영향을 미치지 않습니다.

        Hacker News 의견

     * ""Google이 검색 쿼리를 어떻게 변경하는가""라는 제목의 기사가 Wired에서 편집 기준을 충족하지 못해 삭제되었습니다.
     * 이 기사는 전 Duck Duck Go 임원이 작성했으며, 이로 인해 편향성 주장이 제기되었습니다.
     * 기사에서는 Google이 더 많은 상업적 결과를 생성하기 위해 검색 쿼리를 변경하고 있다고 주장했으나, 이는 잘못된 정보라는 비판을 받았습니다.
     * 이 기사의 삭제로 인해 HackerNews에서 사용자들이 기사의 보관본과 관련 토론을 공유하는 등의 토론이 이루어졌습니다.
     * 일부 사용자들은 기사가 Google의 관행에 대해 불분명하고 잠재적으로 오해의 소지가 있다고 비판했습니다.
     * 다른 사용자들은 Google의 검색 알고리즘의 영향과 사용자들이 검색 결과에 대한 통제력에 대한 우려를 표현했습니다.
     * 또한 Google의 검색 결과의 질과 광고 검색 결과에 대한 잠재적 영향에 대한 토론도 있었습니다.
     * 일부 사용자들은 Wired의 기사 삭제 결정을 지지하며, 이러한 결정은 가볍게 내리지 않으며 사실적 정확성에 기반한다고 주장했습니다.
     * 기사에서 제기된 주장에 대해 Google이 반응해야 한다는 요구가 있었으며, 일부 사용자들은 기사를 자세한 설명 없이 삭제하는 것이 Google과 Wired 모두에게 나쁘게 보인다고 주장했습니다.
"
"https://news.hada.io/topic?id=11237","왜 Debian이 현재의 모습인가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          왜 Debian이 현재의 모습인가?

     * 본 기사는 이제 30년이 된 대규모 복잡한 운영 체제 및 오픈 소스 프로젝트인 Debian의 독특한 측면을 논의합니다.
     * Debian은 대부분의 컴퓨터에서 실행되는 자유롭고 오픈 소스 소프트웨어만으로 구성된 고품질이며 안전한 일반 운영 체제를 목표로 합니다.
     * Debian의 의사결정 과정은 민주적이며, 의사결정을 위한 잘 정의된 프로세스와 매년 선출되는 프로젝트 리더가 있습니다.
     * Debian은 Debian의 약속인 사회 계약과 Debian 자유 소프트웨어 가이드라인을 가지고 있습니다.
     * Debian은 자체 포함을 고집하며, Debian에 패키지화된 모든 것은 Debian 내의 의존성만을 사용하여 구축되어야 합니다.
     * Debian은 보안 문제가 발생했을 때 라이브러리의 모든 복사본을 찾아 수정하는 것을 피하기 위해 패키지화된 소프트웨어와 함께 제공되는 라이브러리의 복사본을 사용하는 것을 피합니다.
     * Debian은 운영 체제의 크기와 복잡성, 그리고 새 패키지를 업로드하는 회원이 가질 수 있는 잠재적인 권력 때문에 엄격한 회원 가입 과정을 가지고 있습니다.
     * Debian은 각 주요 릴리스에 코드 이름을 할당하며, 이는 원래 Debian 패키지 아카이브를 미러링하는 것을 덜 비용이 들게 하기 위해 수행되었습니다.
     * Debian은 크기 때문에 천천히 변화하며, 패키지의 대부분에 영향을 미치는 모든 변경은 시간과 광범위한 토론을 필요로 합니다.
     * Debian 개발자들은 기술적 결정에서 보수적인 경향이 있으며, 대규모 변화를 필요로 하지 않는 솔루션을 선호하는 경향이 있습니다.

        Hacker News 의견

     * Debian의 ""자체 포함"" 방식과 ""번들 라이브러리""를 사용하지 않는 접근법은 ""소프트웨어 공급망"" 관련 문제를 피하는 데 도움이 되었다.
     * Debian과 같은 일부 오픈 소스 조직들은 일반적인 기업 비즈니스 모델에 대한 대안적인 모델이 협업에 더 우수할 수 있음을 보여준다.
     * Debian의 안정성과 선의는 사용자들에게 인정받고 있으며, 전역 업데이트의 패키지 모델이 때때로 버전 충돌을 일으킬 수 있음에도 불구하고 그렇다.
     * 오픈 소스 소프트웨어 열성가들 사이에서 Debian은 기부 대상 후보 중 상위에 자주 랭크된다.
     * Debian의 자원봉사 기반 구조는 자원봉사자가 원하지 않는 일을 강요받지 않는다는 것을 의미한다.
     * Debian의 창립자인 Ian Murdock은 GNU/Linux '방식'과 '자유로운 발언' 소프트웨어에 대해 열정적이었으며, 그의 가장 큰 기여는 패키지 및 패키지 관리 분야에 있었다.
     * 일부 사용자들은 Debian의 드라이버 지원 문제로 인해 Ubuntu와 같은 다른 배포판으로 전환하는 문제를 겪었다.
     * Debian은 Toyota에 비교되곤 한다 - 신뢰할 수 있지만 지루하며, 자원봉사자들에 의해 만들어진다.
     * Debian의 정책은 RetroArch의 제한된 버전이 패키지 관리 기능 때문에 사용 가능하게 되는 등 일부 소프트웨어에 제한을 가져왔다.
     * 일부 사용자와 업스트림은 Debian이 그들의 패키지를 ""수정""한다고 불평했지만, 이에 대한 이유는 불분명하다.
"
"https://news.hada.io/topic?id=11156","오픈소스 기여하고, 나무도 기부해보세요! (Hacktoberfest Korea)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              오픈소스 기여하고, 나무도 기부해보세요! (Hacktoberfest Korea)

   올해로 10년차를 맞이하는 Hacktoberfest에 꼭 참여해보세요!

   10월 한달간 hacktoberfest 태그가 달려있는 아무 오픈소스 프로젝트에,
   총 4개의 PR을 완료하면 여러분의 이름으로 나무를 기부해드립니다!

   참여 방법은 간단합니다
     * Hacktoberfest Korea를 통해, 가이드를 읽고
     * 공식 홈페이지로 들어가 신청 하세요
     * 10월 한달간hacktoberfest 태그가 달려있는 아무 오픈소스 프로젝트에나, 4개의 PR을 완료해주세요

   여기서 명심할건, SPAM/LOW-Quality PR은 절대 금물입니다!
   quantity is fun, quality is key!

   또한 국내 오프라인 행사도 진행되니, 많은 관심 부탁드립니다.

   국내 오픈소스 문화 확산을 위해 힘쓰시는 여러분, 감사합니다!
"
"https://news.hada.io/topic?id=11168","아이폰 4 활용하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               아이폰 4 활용하기

     * 이 기사는 iPhone 4를 공격하는 자세한 방법에 대해 다루고 있으며, 특히 진입하는 방법에 초점을 맞추고 있다.
     * 저자 Phillip Tennen은 iPhone 4를 위한 iOS 4 탈옥 도구 'gala'를 개발 중이다.
     * Tennen은 이전에 iOS 트윅 개발 장면에서 활동했으며, iOS 시스템 동작을 수정하고 새로운 기능을 추가하는 제품과 도구를 만들었다.
     * 탈옥 과정은 Apple의 서명 과정에 상관없이 iPhone에서 모든 코드를 실행할 수 있게 하는 것으로, 처음에는 Tennen에게 미스터리였다.
     * 저자는 p0sixninja와 axi0mx와 같은 이전 개발자들의 작업을 인정하면서, 자신의 탈옥을 작성함으로써 이 과정을 명확하게 하기로 결정했다.
     * Tennen은 eBay에서 iPhone 4와 3GS를 구입하여 시작했으며, 이들은 보안이 상대적으로 약할 것으로 추정되는 이전 기기를 선택했다.
     * 저자는 부트 ROM 취약점을 이용하는 것을 탐구했으며, 이를 통해 USB를 통해 장치와 상호작용할 수 있었다.
     * Tennen은 iPhone Wiki에서 공개적으로 사용할 수 있는 limera1n 공격 코드를 사용했다.
     * 저자는 iOS 부트 과정에서 '신뢰의 체인' 개념을 설명하며, 각 단계가 다음 단계가 신뢰할 수 있는 것임을 보장한다.
     * SecureROM은 부트 과정의 첫 번째 단계로, 암시적으로 신뢰되며 취약점이 발견되어도 교체할 수 없어, 이는 공격 대상이 될 수 있다.
     * Tennen은 2010년에 geohot에 의해 공개된 limera1n 공격을 사용했으며, 이는 DFU 모드의 장치가 USB를 통해 호스트로부터 iBSS를 기다리는 동안 공격될 수 있다.
     * 저자는 pod2g의 SecureROM 덤퍼를 사용하여 limera1n을 구현하고 USB를 통해 장치에서 메모리를 읽었다.
     * Tennen은 페이로드를 고급 언어로 작성하는 데 어려움을 겪었으며, 이는 일반적인 바이너리 컴파일 과정을 우회해야 했기 때문이다.
     * 저자는 성공적으로 파이프라인을 설정하여 바이너리에서 쉘코드를 컴파일하고 추출하고, limera1n을 사용하여 페이로드를 실행하고, 장치에서 데이터를 읽었다.
     * 이 기사는 부트 체인 우회에 대한 추가 탐구를 약속하는 Part 2로 마무리된다.

        Hacker News 의견

     * 아이폰 4를 이용한 상세한 기사는 독자들 사이에서 관심과 향수를 불러일으켰습니다.
     * 많은 독자들이 아이폰 탈옥 과정을 명확하게 설명한 이 기사에 감사의 표시를 했습니다.
     * 일부 독자들은 과거에 자신들의 기기를 탈옥한 개인적인 경험을 공유하며, 이로 인해 프로그래밍을 배우게 되었다고 말했습니다.
     * 몇몇 독자들은 오래된 iOS 인터페이스를 싫어하며, 이를 스큐어모피즘 디자인을 참조했습니다.
     * 독자들은 저자가 복잡한 개념을 이해하기 쉽게 설명하는 능력을 칭찬했습니다.
     * 한 독자는 이 취약점이 비밀번호를 잊어버린 오래된 아이폰 4s에서 데이터를 검색하는 데 사용될 수 있는지 물었습니다.
     * 한 독자가 공유한 링크는 탈옥된 휴대폰이 악성 소프트웨어로부터 자유로운지 확인하는 무결성 검증기에 대한 것이었습니다.
     * 오래된 아이폰의 SIM 잠금 해제에 대한 유사한 문헌의 가능성과 이 취약점이 아이폰 4s에서 작동할지에 대한 질문이 제기되었습니다.
"
"https://news.hada.io/topic?id=11226","Show HN: 회사 리뷰와 채용 담당자 자동응답기능이 있는 직업 지원 추적기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Show HN: 회사 리뷰와 채용 담당자 자동응답기능이 있는 직업 지원 추적기

     * 기사는 채용 검색 과정을 간소화하고 정리하는 도구인 Rolepad를 소개합니다.
     * Rolepad는 채용을 찾는 사람들에게 무료이며, 채용 신청서와 기회를 추적하는 편리한 방법을 제공합니다.
     * 이 플랫폼은 회사 정보, 역할 세부 사항, 인터뷰 단계, 연락처 정보, 후속 조치 등 채용 신청에 대한 다양한 세부 사항을 기록할 수 있게 합니다.
     * Rolepad는 또한 특정 Rolepad 이메일 주소로 이메일을 전달함으로써 채용 담당자, 인터뷰어, 고용 관리자와의 통신을 정리하는 기능을 제공합니다.
     * 사용자는 시간이 지남에 따른 채용 검색 여정을 시각화하는 다이어그램을 생성하고 민감한 정보를 공개하지 않고 공유할 수 있습니다.
     * 플랫폼은 사용자들이 인터뷰 경험과 회사의 응답 시간에 대한 피드백과 리뷰를 공유하도록 장려합니다.
     * Rolepad는 또한 사용자들이 회사 채용 과정에 대한 통찰력을 얻기 위해 다른 지원자들의 리뷰를 탐색할 수 있게 합니다.
     * 기사는 Rolepad가 이메일과 스프레드시트와 같은 전통적인 채용 신청 추적 방법보다 더 나은 대안이라고 제안합니다.
     * 이 플랫폼은 Chris H라는 소프트웨어 엔지니어에게 직관적이고 사용하기 쉬우며 저항이 적다는 칭찬을 받았습니다.

        Hacker News 의견

     * 새로운 채용 신청 추적기에 대한 기사, 회사 리뷰 및 채용 담당자를 위한 자동응답기능 포함
     * 일부 사용자들, 아이디어 칭찬하나 개인 데이터의 프라이버시에 대한 우려 표현, 로컬 전용 데이터 저장 옵션 제안
     * 회사 및 인터뷰 리뷰의 진실성에 대한 의문, 일부 사용자들 Glassdoor의 논란의 리뷰 시스템과 비교
     * 제품의 비즈니스 모델에 대한 질문 제기, 고용주들이 서비스에 대한 비용을 지불하게 될 것이라는 가정, 이해 관계의 충돌 가능성
     * 프라이버시 선언, 너무 개방적이라는 비판, 회사가 사용자 데이터를 잘못 사용할 가능성
     * 일부 사용자들, Obsidian과 함께 Kanban 보드와 같은 자신의 시스템을 사용하여 데이터를 제어하는 것을 선호
     * 도구, 채용 신청에 관련된 대량의 정보 관리에 유용하다고 봄, LinkedIn과 같은 기존 플랫폼이 잘 처리하지 못하는 작업
     * 민감한 데이터, 예를 들어 이력서를 클라우드에 저장하는 것에 대한 우려 제기
     * 일부 사용자들, 전화 추적, 회사에 녹음 첨부, 전화 통화록, 요약 등의 도구 기능 제안
     * 도구의 사용자 인터페이스, 모든 추적된 채용에 대한 빠른 개요 제공하지 않는다는 비판
     * 일부 사용자들, 이메일, 전화 통화, LinkedIn 메시지를 포함한 모든 커뮤니케이션 채널을 집계할 수 있는 도구 제안
     * 채용을 위한 도구의 자체 호스팅 버전 가능성 제안
"
"https://news.hada.io/topic?id=11160",""Nomnoml"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ""Nomnoml""

     * Nomnoml을 사용하여 생성된 다이어그램으로 보이는 텍스트
     * '약탈', '더 많은 전리품', '해적', '장난', '약탈자', '즐거운 선원', '럼' 등의 요소가 있는 해적 테마 시나리오를 그린 것으로 보이는 다이어그램
     * '시작', '약탈' 등의 상태, '더 많은 전리품' 등의 선택, '즐거운 선원' 등의 배우, '장난' 등의 테이블과 같은 다양한 UML 요소가 포함된 다이어그램
     * '해적' 요소는 다이어그램에서 중심 역할을 나타내는 여러 다른 요소와 연결되어 있음
     * '럼' 요소는 '맛있음'이라는 속성과 '한 모금()'이라는 메소드와 연관되어 있음
     * Nomnoml은 현재 새로운 파서를 테스트 중으로, 이는 다이어그램의 렌더링에 영향을 줄 수 있음
     * 사용자들은 자신의 다이어그램에 문제가 있으면 GitHub 또는 Daniel이라는 사람에게 이메일로 보고하도록 권장됨
     * 새 파서가 문제를 일으킬 경우 사용할 수 있는 레거시 파서 옵션이 있음

        Hacker News 의견

     * 브라우저 기반 PKM 프로젝트에서 계층적 태그 구조를 시각화하는 능력으로 Nomnoml 도구가 인정받음.
     * Nomnoml은 ""텍스트를 다이어그램으로"" 변환하는 도구를 비교하는 웹사이트에 포함되지 않음.
     * 일부 사용자들은 처음에 도구를 혼란스럽게 느꼈지만, 'about' 버튼을 찾은 후 명확성을 발견함.
     * 뛰어난 기능들로 인해 자주 사용될 가능성이 있는 도구로 찬사를 받음.
     * Nomnoml에 대한 비판 중 하나는 좋은 레이아웃을 얻는 것이 정의 순서에 너무 의존적이라는 것으로, 큰 다이어그램에서는 문제가 될 수 있음.
     * Nomnoml은 GPU 어셈블리 코드에 대한 제어 흐름 및 의존성 그래프와 같은 도구를 생성하는 데 사용되었음.
     * 일부 사용자들은 툴팁을 호버에 추가하고 특정 상자를 클릭하여 다른 다이어그램에 연결하는 기능을 추가하기 위해 코드를 수정함.
     * Nomnoml은 plantuml 클래스 다이어그램보다 시각적으로 우수하다고 간주됨.
     * 도구는 다이어그램이 에디터와 겹치므로 모바일 사용에 개선이 필요함.
     * Nomnoml은 인기 있는 그래프 시각화 소프트웨어인 graphviz와 비교됨.
"
"https://news.hada.io/topic?id=11246","셸, 포트나이트와 틱톡 등을 활용해 어린이들에게 화석 연료가 멋있다고 설득","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               셸, 포트나이트와 틱톡 등을 활용해 어린이들에게 화석 연료가 멋있다고 설득

     * 주요 석유 회사인 Shell이 Fortnite, TikTok, Twitch와 같은 인기 플랫폼을 이용해 청소년 대상으로 화석 연료를 홍보하고 있습니다.
     * 이 회사는 ""Shell Ultimate Road Trips""라는 Fortnite 세계를 만들어, 여섯 개의 다양한 지역을 탐험하고 지도의 중심으로 Shell 주유소를 표시했습니다.
     * 이 캠페인은 Shell의 “새롭고 개선된” 프리미엄 가솔린, V-Power NiTRO+를 홍보하기 위해 기획되었습니다.
     * Shell은 이 협업을 홍보하기 위해 TikTok 크리에이터와 Twitch 스트리머들과 파트너십을 맺었습니다.
     * Shell 캠페인을 홍보하는 콘텐츠 크리에이터들은 TikTok 팔로워 850만명, Instagram 팔로워 150만명, YouTube 구독자 1100만명을 보유하고 있습니다.
     * Shell은 또한 IGN에서의 게시물을 후원하고, IGN 직원들이 Fortnite를 플레이하고 Shell 후원 맵을 탐험하는 3부작 시리즈를 제작했습니다.
     * 이 캠페인은 큰 석유 회사들이 온라인 인플루언서와 콘텐츠 크리에이터를 통해 젊은 사람들과 연결하기 위한 더 넓은 노력의 일부입니다.
     * 그러나 이 캠페인은 부정적인 피드백을 받았으며, 많은 시청자들이 석유 회사의 홍보를 비판했습니다.
     * 2021년 조사에 따르면, 16-25세의 젊은 사람들 중 약 75%가 기후 변화로 인한 미래에 대해 두려워하고 있어, 석유 회사들이 이 연령대를 화석 연료 산업을 지지하도록 설득하는 것이 어렵습니다.

        Hacker News 의견

     * Shell이 Fortnite와 TikTok 같은 인기 플랫폼을 이용해 젊은 층에 화석 연료를 홍보하고 있습니다.
     * 최근 호주의 한 텔레비전 방송에서 어린이들이 Shell 프로모션 중에 휘발유 상품권을 상으로 받은 사건이 있었습니다.
     * 화석 연료는 비용 효율성과 접근성 때문에 대체 불가능하다는 주장이 있습니다.
     * 회사들이 게임을 후원하고 그들의 자산을 홍보 목적으로 사용하는 추세가 있습니다.
     * Z세대는 석유 가스 산업에 대한 보조금과 세금 감면에 대해 적극적으로 항의하고 있습니다.
     * Shell과 BP는 대중교통 광고와 온라인 커뮤니티를 통해 Z세대를 설득하려는 계획을 세우고 있다는 보고가 있습니다.
     * 엔터테인먼트 산업에서의 석유 산업의 선전 역사가 있습니다. 예를 들어, Exxon Mobile이 후원한 디즈니 월드의 공룡 표현이 그 예입니다.
     * Shell의 공식 예고편에 대한 YouTube 댓글은 이 홍보 전략이 PR 성공이 아닐 수 있다는 것을 시사합니다.
     * 화석 연료는 질병, 기근, 빈곤을 줄이는 데 인류의 발전에 크게 기여했다는 주장이 있습니다.
     * 녹색 운동이 핵 에너지를 반대하고 있는데, 이는 에너지를 탈탄소화할 수 있는 잠재력이 있는 것에 대한 비판이 있습니다.
     * Shell과 같은 회사들을 위해 광고 콘텐츠를 제작하는 일부 콘텐츠 조직들이 윤리적인 문제를 일으키고 있습니다.
     * Shell의 전략의 효과에 대한 의구심이 있습니다. Fortnite가 대상 청중 중에서 더 이상 인기가 없을 수 있기 때문입니다.
"
"https://news.hada.io/topic?id=11195","쿠버네티스 해킹해 Secret 리소스에 저장된 비밀번호 찾는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  쿠버네티스 해킹해 Secret 리소스에 저장된 비밀번호 찾는 방법

     * 이 내용은 쿠버네티스 보안의 중요성을 환기하는 게 목적임
     * Secret 저장 장소
          + 사용자가 kubectl 명령을 통해 리소스 선언하면 쿠버네티스는 이 리소스를 정의한 메니페스트 파일 만들어 etcd에 저장
          + 사용자가 Secret 리소스 선언하면 Secret도 etcd에 저장
          + 사용자가 Secret을 볼륨 혹은 환경변수로 읽는 pod 만들면 Secret은 해당 pod에 저장
          + Secret 저장되는 etcd와 secret이 사용되는 pod 해킹하면 Secret에 저장된 비밀번호 알 수 있음
     * 사전 준비
          + kubeadm으로 클러스터 생성
          + 실습 위해 세가지 리소스 미리 만듦: Secret credit-card, pod app1, pod app2
     * etcd 해킹
          + etcd: 쿠버네티스 클러스터 상태 저장하는 키-값 데이터 저장소. 쿠버네티스에 선언된 모든 정보가 여기에 저장. Secret도 etcd 조회해보면 알 수 있음
          + 1.1 etcdctl로 비밀번호 찾기
               o kube-apiserver 메니페스트 조회해 etcd 서버의 certificate authority, 공개 키, 개인 키 가져옴
               o etcd 편하게 조작하는 etcdctl 명령 통해 비밀번호 찾음
          + 1.2 etcd DB 직접 접근해 가져오기
               o etcd가 동작하는 프로세스 찾고, 해당 프로세스 데이터 모두 탐색해 비밀번호 찾음
                    # ps aux | grep etcd -etcd PID 가져옴
                    # ll /proc/<pid>/fd 보면 db라고 적힌 link 파일 보임
                    # cat /proc/<pid>fd/<db> | grep -A10 -B10 credit-card 명령 통해 사전에 만든 비밀번호 찾음
     * pod 해킹
          + kubectl exec 통해 가져오기
               o 쿠버네티스 조회하는 적절한 권한 있다면 kubectl 명령 통해 비밀번호 가져올 수 있음
          + 컨테이너에 직접 접근해서 가져오기
               o 워커 노드에서 도커 명령 자유롭게 쓸 수 있으면 비밀번호 빼낼 수 있음
               o pod app1이 스케줄된 워커 노드에서 컨테이너 찾아 컨테이너에 등록된 환경 변수 목록 추출할 수 있음
                    # crictl pods - app1의 Pod ID 찾음
                    # crictl ps - Pod ID에 상응하는 컨테이너 찾음
                    # crictl inspect <container id> | grep -A16 env - 해당 컨테이너를 상세 조회해 환경 변수 추출
          + Secret에 접근 권한 있는 ServiceAccount로 가져오기
               o Pod의 ServiceAccount가 Secret에 접근 권한 있다면 pod 내부에서 API 호출로 비밀번호 찾을 수 있음
     * 위에서 설명한 해킹 막는 방법
          + ‘최소 권한 원칙’ 따라 불필요한 권한 있는 service account 만들지 않기
          + 소셜 엔지니어링 등 위협에 대비해 사용자 credential 노출 X
          + EncryptionConfiguration 리소스 통해 etcd 암호화
"
"https://news.hada.io/topic?id=11211","잉크가 부족할 때 프린터의 스캐너를 사용 불능으로 만든다는 주장, HP가 반박 실패","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             잉크가 부족할 때 프린터의 스캐너를 사용 불능으로 만든다는 주장, HP가 반박 실패

     * HP, 잉크가 부족할 때 다기능 프린터의 스캔 및 팩스 기능을 고의로 비활성화한다는 주장으로 집단 소송에 직면하다.
"https://news.hada.io/topic?id=11198","Apple 충전기로부터의 라디오 간섭 제거","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Apple 충전기로부터의 라디오 간섭 제거
     * 해당 소송은 HP가 이 사실을 소비자에게 공개하지 않았으며, 이는 비싼 잉크 카트리지 판매로 이익을 늘리기 위한 전략으로 보인다고 주장한다.

     * 원고들은 잉크가 떨어져도 스캔이나 팩스를 할 수 있는 프린터를 제조하는 것이 기술적으로 가능하다고 주장한다.
     * 애플의 MagSafe 충전기로 인한 라디오 간섭 문제가 있음
     * 저자인 Ossi Herrala는 애플이 제품에서 원치 않는 라디오 주파수 방출을 제거하지 않은 것을 비판
     * 이 소송은 처음에는 법적 이유로 기각되었지만, 판사는 원고들이 주장을 수정하고 다시 제출할 수 있게 허용했다. 8월 10일, 판사는 HP의 수정된 고소를 기각하는 요청을 대부분 거부했다.
     * 문제는 제조사들이 비용을 절약하기 위해 모서리를 자르는 결과로 나쁜 디자인 선택이 생김
     * 프린터 잉크 비용은 소비자들에게 중요한 문제로, Consumer Reports에 따르면 잉크 비용은 연간 70달러를 쉽게 초과할 수 있다.
     * 저자는 차 안에서 충전기를 사용하면서, 아마추어 라디오 핸드헬드 트랜시버와 함께, 2m 밴드(145 MHz)와 항공 주파수(약 124 MHz)에서 노이즈를 감지
     * 상당량의 잉크가 문서 인쇄에 사용되지 않고 프린터 유지 보수 주기에 소비된다. 일부 모델은 잉크의 절반 미만을 인쇄 문서에 전달한다.
     * 무선 충전은 라디오 주파수를 이용하여 자기장을 생성하며, 연결 케이블은 기본 주파수와 그 고조파를 방출하는 안테나처럼 작동할 수 있음
     * HP만이 이러한 법적 불만을 받는 유일한 회사는 아니다. Canon Inc.도 2021년에 비슷하게 본인의 다기능 프린터를 비공개로 비활성화한 혐의로 고소되었다. 이 사건은 2022년 말에 합의로 해결되었지만, 합의 조건은 공개되지 않았다.
     * 저자는 제조사들이 제품을 제대로 차폐하는 것이 최선의 해결책이라고 제안

        Hacker News 의견
     * 그러나 이미 제품을 구매한 사람들에게는 저자가 간섭을 줄일 수 있는 페라이트 비드를 사용하는 것을 제안

     * 저자는 mix 31의 스냅온 페라이트를 사용하여 충전기의 USB 와이어를 세 번 감아서 간섭을 크게 줄였음
     * HP 프린터가 잉크가 부족할 때 기능을 상실하는 문제에 대한 기사
     * 저자는 간섭을 완전히 제거할 수는 없지만, 문제가 되는 주파수를 감쇠시킴으로써 충분히 좋은 결과를 얻을 수 있다고 결론지음
     * 일부 사용자들은 레이저 프린터가 잉크젯 프린터에 비해 시간, 돈, 자원 측면에서 덜 낭비한다고 제안
     * 저자는 비싼 제품을 추가 구성품으로 고쳐야 하는 데 대해 불만을 표현함

     * 중급 기업용 프린터를 사용하는 것이 초보자용 레이저 프린터보다 장기적으로 경제적이라는 제안
        Hacker News 의견

     * 일부 사용자들은 이러한 문제로 인해 프린터를 교체하는 것을 중단하고, 우편 서비스의 라벨 인쇄, 도서관, 우편으로 인쇄하는 회사 등의 대안을 찾고 있음
     * 본 기사는 애플 충전기의 라디오 간섭 문제, 특히 124 MHz 주변의 항공 주파수에서의 문제를 논의한다.
     * 시장에서 독립형 스캐너의 가용성이 감소하고 있으며, 많은 제품이 구식이고 지원이 부족함
     * 충전기가 FCC 승인을 받은 방법과 누가 테스트했는지에 대한 의문이 제기되었다. 이는 라디오 주파수(RF) 간섭 때문이다.
     * 사용자들은 한때 높게 평가받던 HP 제품의 품질 저하에 실망을 표현
     * 간섭은 충전기의 설계가 미흡하다는 것을 시사한다. USB 케이블의 전력은 DC여야 하며 RF 성분이 중요하지 않아야 한다.
     * 일부 사용자들은 이러한 문제가 디지털로 전환된 소비자 전자제품에서 흔하며, 제품들이 종종 설계가 미흡하고 복잡하다고 제안
     * 애플 충전기로 인한 라디오 간섭 문제는 새로운 것이 아니다. 2013년의 유사한 보고서가 인용되었다.
     * HP 프린터가 자동 업데이트 후에 기능을 상실하는 보고, 특히 비HP 잉크를 사용할 때
     * 일부 댓글은 충전기가 진짜 애플 제품이 아닐 수 있다는 의견을 제시한다. 가짜 제품이 흔하기 때문이다.
     * 일부 사용자들은 새로운 HP 프린터를 입력 또는 출력 장치로 의존하기보다는 부품으로 재활용하는 것을 제안
     * 문제는 페라이트 비드로 해결되었지만, 충전기가 진짜 MagSafe 퍽인지에 대한 의문이 있다.
     * 이러한 행동을 하는 회사에 대해 사용자들은 실망과 불만을 표현
     * 간섭이 애플 제품 자체보다는 공급 장비의 소음이 케이블을 통해 전파되는 것에 의해 발생할 수 있다는 제안이 있다.
     * 일부 사용자들은 컴팩트한 올인원 컬러 레이저 프린터의 부재로 레이저 프린터로 전환하지 않았음
     * 애플 충전기의 다른 문제들도 언급되었다. 예를 들어, Mac Studio를 연결할 때 큰 유입 전류와 무선 충전기에서의 코일 소음 또는 틱킹 소음 등이다.
     * 잉크 카트리지의 높은 비용과 탱크 버전 프린터의 필요성에 대한 논의
     * 일부 댓글러들은 유사한 간섭 문제에 대한 개인적인 경험을 공유하며, 이러한 문제를 줄이는 데 페라이트 비드의 중요성을 강조한다.
     * 일부 사용자들은 대량 인쇄 작업에 대해 레이저 프린터가 더 비용 효율적이라고 발견
     * 소비재와 서비스에서 구독 모델로의 전환에 대한 논의
"
"
"https://news.hada.io/topic?id=11197","Vite팀, Rollup의 러스트 포트인 Rolldown  작성중","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Vite팀, Rollup의 러스트 포트인 Rolldown 작성중

     * Rollup과 호환되며 성능 좋게 만드는 중
     * esbuild와 Rollup을 대체하는게 목표

   만약 만들어진다면
     * 프로덕션 빌드가 빨라짐 (작금의 Rollup을 대체하므로)
     * 개발/프로덕션 빌드간의 일관성 (esbuild와 Rollup으로 양분되지 않으므로)
     * SSR 종속성처리 개선
     * 청크 분할에 대한 더 많은 제어
     * Module federation 지원 강화

   관련된 프리젠테이션 자료
     * https://docs.google.com/presentation/d/…

   예전에 구 프로젝트를 CRA에서 Vite로 전환하려 했는데 esbuild하고 rollup 간의 차이가 발생해서 실패해서 롤백했는데 이거만 되면 이런 골치 아픈 문제는 없어지겠군요.

   사실 두 툴킷이 이질감 심해요. SSR 대응이 더딘 이유기도 했고요.
   아니면 Turbopack 도 있습니다. 베타 딱지 언제 땔지는 모르겠지만.
   [IMG] https://turbo.build/pack
"
"https://news.hada.io/topic?id=11181","FTC, 경제 전반에 걸친 "숨겨진 세금" 때문에 Amazon 분할을 위한 소송 제기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            FTC, 경제 전반에 걸친 ""숨겨진 세금"" 때문에 Amazon 분할을 위한 소송 제기

     * 연방 무역위원회(FTC)와 17개 주, 아마존에 대한 독점과 불공정 경쟁 방법에 대한 반독점 소송 제기
     * 소송, 아마존의 ""숨겨진 세금""에 초점, 소비자들이 아마존 프라임 고객에게 제공되는 무료 배송을 간접적으로 지불하는 방식
     * 아마존 프라임, 연간 회원비 $139 부과, 아마존이 매년 수천억 달러를 보조, 2022년 물류 부문 비용은 $85 billion
     * 아마존의 실제 고객은 아마존의 인프라에 의존하여 대중에게 접근하는 제3자 기업들, 이들 기업들은 온라인 대형점에서 다른 곳으로 전환하는데 높은 비용 부담
     * 아마존 프라임, 진입장벽 구축, 확장, 강화에 사용, 결과적으로 아마존은 온라인 쇼퍼들의 독점 지분 보유
     * 독점력 달성 후, 아마존은 제3자 판매자에게 수수료를 인상, 이제 수익의 거의 50%를 차지, 이 수수료는 ""무료"" 배송 및 프라임과 함께 제공되는 기타 서비스를 지원
     * 아마존의 알고리즘, 제3자 판매자가 아마존 외부에서 더 낮은 가격을 제공하는 것을 방지, 실질적으로 가격 인상을 강요
     * 소송이 정부의 유리하게 해결되면, 해결책은 반할인 조치 종료에서 회사 분할에 이르기까지 다양, 이로 인해 가격 하락 및 시장 경쟁력 증가 가능
     * 소송, 아마존이 문서와 내부 대화를 파괴하고 있으며, Project Nessie라는 비밀스러운 알고리즘 가격 결정 시스템을 언급
     * FTC, 고소장에서 삭제를 제거하려고 밀어붙일 것, 아마존이 이 정보의 공개를 방지하기 위한 합당한 이유를 제공해야 한다고 주장

   쿠팡 로켓 배송에 올라온 상품은 만원을 넘는데,
   그걸 따로 검색해 보니 배송비 별도로 몇천 원 수준에 팔고 있던 게 기억나네요.

   그런데 아마존은 한술 더 떠서 다른 곳에서 더 저렴하게 팔지 못하는 계약을 맺은 거군요...

        Hacker News 의견

     * eBay와 Amazon이 가격을 인위적으로 올리는 전략을 채택하였습니다. 이는 유료 광고가 있는 제품만 눈에 띄는 위치에 보여주는 것을 포함하여 모든 것의 비용을 10% 이상 증가시킵니다.
     * Amazon의 정책은 판매자에게 무료 배송을 제공하도록 요구하며, 이로 인해 Amazon (FBA)이 광범위한 물류 네트워크 때문에 기본적으로 가장 낮은 가격이 됩니다.
     * Amazon의 최우선 국가 지위는 판매자가 Amazon에서보다 싸게 판매하는 것을 금지하며, 이 정책은 주 검찰총장들로부터 소송을 받았습니다.
     * 일부 댓글러들은 Amazon, Apple, Google, Facebook과 같은 대형 기술 회사를 분할하고 수십억 달러 규모의 합병을 심사하는 것을 제안합니다.
     * 일부 소비자들은 고품질 웹사이트와 탄탄한 주문 경험 때문에 제조업체로부터 직접 제품을 구매하고 있으며, 이로써 Amazon을 우회합니다.
     * Amazon Prime은 Costco 멤버십과 비교되며, 차이점은 Amazon이 충족 센터에서 마지막 마일 배송을 처리한다는 것입니다.
     * 일부 댓글러들은 Amazon의 행동이 뻔뻔하게 독점적이라고 주장하며, 플랫폼 접근의 위협으로 플랫폼 외부에서 가격을 조정합니다.
     * 신용카드 회사에 대한 심사를 요구하는 목소리가 있으며, 이들은 대부분의 소매 거래에서 2-3%의 세금을 징수한다고 합니다.
     * Amazon을 어떻게 분할할 것인지에 대한 질문이 제기되었으며, 이해하고 있는 바는 Amazon의 로비스트들이 결과에 영향을 미칠 것이라는 것입니다.
"
"https://news.hada.io/topic?id=11278","전기화 지연을 위해 비효율적인 수소차를 주장하는 석유 산업","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    전기화 지연을 위해 비효율적인 수소차를 주장하는 석유 산업

     * Liebreich Associates의 CEO인 Michael Liebreich는 석유 산업이 비효율적인 수소 자동차를 지지하여 전기차로의 전환을 지연시키고 있다고 주장합니다.
     * Liebreich는 깨끗한 수소가 자동차와 가정 난방에 대한 나쁜 선택이며, 전기 해결책이 더 싸고 효율적이라고 믿습니다.
     * 그는 수소 사용이 경쟁력이 없거나, 탈탄소화를 위해 불가피하거나, 중간 어딘가에 위치하는지 보여주기 위해 '수소 사다리' 차트를 만들었습니다.
     * Liebreich는 석유 및 가스 회사들이 수소 산업에 자신들을 포함시키거나 전기로의 전환을 지연시키는 부적절한 용도로 수소를 홍보하고 있다고 주장합니다.
     * 그는 Shell이 문제가 많은 부유식 액화 천연가스(LNG) 플랫폼에 120억 달러를 투자하지만, 깨끗한 수소에는 같은 금액을 투자하지 않는 것을 비판합니다.
     * Liebreich는 또한 가정 난방용 수소 사용에 반대하며, 히트 펌프가 수소 보일러보다 거의 6배 더 에너지 효율적이라고 주장합니다.
     * 그는 가스 배급 회사들이 탈탄소화를 위해 가스 파이프 사용을 유지하기 위해 가정 난방에서의 수소 사용을 지지하고 있다고 제안합니다.
     * Liebreich는 천연가스 그리드에 깨끗한 수소를 혼합하여 탄소 배출을 줄이는 것이 ""어리석게 비효율적""이라고 결론 내립니다.

        Hacker News 의견

     * 수소 연료는 대부분의 경우에 에너지 저장에 있어 배터리가 더 나은 옵션인 문제를 해결하기 위한 해결책으로 보여진다.
     * 석유 부문과 전기 부문 모두에 대한 로비가 있으며, 두 부문은 서로 경쟁하고 있다.
     * 수소는 무거운 운송과 같은 특정 응용 분야에 필요하며, 초기 단계에 있음에도 불구하고 계속 개발되어야 한다.
     * NH3는 에너지 저장 및 에너지 운송에 이상적이며, 무거운 산업 분야와 같은 분야에 유용하다. 반면 전기와 배터리는 다른 분야에 더 적합하다.
     * 'Engineering Explained'이라는 YouTube 채널에는 수소가 전통적인 내연 기관에서 가솔린/휘발유/디젤을 대체하는 것이 비현실적인 이유를 설명하는 비디오가 있다.
     * 석유 부문은 전기차로의 전환을 지연시키려고 하는 것으로 보이지만, 이는 경제적 현실 관점에서는 시작조차 되지 않는 것으로 보인다.
     * 전기차는 미래로 보여지며, 대부분의 자동차 제조사들이 100% 전기화된 차량에 투자하고 있다.
     * 수소는 무거운 교통 및 가능성이 있는 철도 또는 항공을 제외하고는 시작조차 되지 않는 것으로 보인다.
     * 수소는 유통 네트워크의 유지와 그것을 생성하기 위한 화석 연료의 지속적인 사용을 가능하게 한다.
     * 수소는 비효율적이며 많은 기사들이 주장하는 것처럼 은총알이 아니라고 보여지며, 일부 산업 응용 분야가 있지만 주요 돌파구는 아니다.
     * 전력 그리드와 충전 인프라가 모든 차량이 배터리로 구동되는 것을 지탱할 수 없을 수 있다는 주장이 제기되었다.
     * 배터리는 대규모 에너지 저장 솔루션으로 적합하지 않다고 보여지며, 태양 및 풍력과 같은 비배치, 변동성 에너지 원천은 대량의 저장을 필요로 한다.
     * 동기에 대한 더 명확한 메시지를 요구하고 있으며, 산업은 메시지를 잘 전달하는 것으로 보여지고, 사람들은 오해를 불러일으키는 메시지를 인식하는 데 나쁘다고 보여진다.
"
"https://news.hada.io/topic?id=11187","헤이, 컴퓨터, 나에게 폰트를 만들어줘","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         헤이, 컴퓨터, 나에게 폰트를 만들어줘

     * 'FontoGen'이라는 폰트 생성을 위한 생성형 머신러닝(ML) 모델 구축
     * 모델은 폰트 설명을 입력으로 받아 폰트 파일을 출력으로 제공
     * 저자는 2023년 AI의 부상에 영감을 받아 텍스트에서 SVG 생성을 탐색하게 되었고, 이로 인해 폰트 생성 아이디어를 얻음
     * IconShop2 논문을 참고하여 모델을 구축하였고, SVG 생성과 비슷하게 폰트 생성이 가능함을 발견
     * 모델은 텍스트 임베딩 다음에 폰트 임베딩이 이어지는 시퀀스로 훈련된 시퀀스-투-시퀀스 모델
     * 텍스트 임베딩은 사전 훈련된 BERT 인코더 모델을 사용하여 생성되었고, 폰트 임베딩은 폰트를 토큰 시퀀스로 변환하여 생성
     * 모델은 16개의 레이어와 8개의 블록으로 구성된 자동 회귀 인코더 전용 트랜스포머로, 총 73.7백만 개의 파라미터를 가짐
     * 저자는 BigBird3 주의를 사용하여 초기 프롬프트에 집중하고 N개의 이전 토큰을 관찰하여 여러 이전 글리프의 스타일을 포착
     * 모델은 GPT-3.5를 사용하여 다양한 유형의 설명을 몇 가지 키워드로 요약한 71k개의 고유 폰트 데이터셋에서 훈련
     * 훈련 과정은 127시간 소요되었으며, 검증 손실이 거의 개선되지 않을 때 중단
     * 저자는 데이터셋 전처리 단계로 가능한 한 많이 이동함으로써 성능을 세 배 향상
     * 저자는 디자이너가 생성한 단일 글리프를 기반으로 모든 다른 글리프를 생성하기 위해 모델을 기존 폰트 편집기에 통합하는 등의 잠재적인 미래 응용을 제안

   귀여운 폰트를 만들어줘

        Hacker News 의견

     * gpt-4 코드 해석기는 글리프의 흑백 png를 svg로 변환할 수 있으며, 이는 이미지 생성 모델과 결합하여 폰트를 생성하는 데 사용될 수 있습니다.
     * Godel Escher Bach의 저자인 Douglas Hofstader는 일반 AI 없이는 폰트 생성이 불가능하다고 믿었습니다.
     * Letter Spirit 프로젝트는 그리드에 제한된 ""gridfonts""라는 스타일이 통일된 글꼴을 디자인함으로써 예술적 창의성을 모델링하는 것을 목표로 합니다.
     * ML 모델에 의해 생성된 폰트의 정밀도에 대한 우려가 있으며, 선이 완벽하게 평행하지 않고 모서리가 정확히 90도가 아닌 등의 문제가 있습니다.
     * 픽셀을 150x150 고유의 bin으로 표현하는 접근법은 이상적이지 않다고 보며, 대신 convnet을 사용하고 출력을 추적하는 것이 제안되고 있습니다.
     * 이러한 접근법으로 새로운 폰트, 특히 매우 스타일화된 폰트의 생성이 더욱 실현 가능해질 수 있습니다.
     * 모델은 safetensor가 아닌 ckpt이며, 이는 일부 사용자가 이를 시도해 볼지 여부에 영향을 줄 수 있습니다.
     * 확산 모델이 텍스트를 그리는 데 어려움을 겪음에도 불구하고, 이 방법은 이 애플리케이션에 잘 작동합니다.
"
"https://news.hada.io/topic?id=11256","Unity, 가격 논쟁 관련해서 CEO 사임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Unity, 가격 논쟁 관련해서 CEO 사임

     * Unity의 CEO였던 John Riccitiello가 가격 논란으로 많은 개발자들의 불만을 샀다가 사임
     * James M. Whitehurst가 Unity의 임시 CEO 및 대표로 임명
     * Riccitiello는 2013년에 이사회 합류해서 2014년부터 CEO 였음
     * Whitehurst는 2008~2020년까지 RedHat CEO였으며, IBM이 Redhat을 인수하면서 IBM의 수석 고문 겸 사장으로 재직했었음
     * Unity는 주식 패닉을 피하기 위해 이전의 재정 3분기 실적 예측을 재확인중
     * Unity 이사회의 주요 독립 이사인 Roelof Botha가 회장으로 임명되어 상설 CEO를 찾기 위한 철저한 검색을 감독할 예정
     * Riccitiello는 원활한 전환을 보장하기 위해 Unity에 계속 조언을 제공할 것
     * Unity는 다운로드 수에 따른 가격 인상을 시행한 후 개발자 커뮤니티로부터 반발을 받았으며, 이후 이를 철회하였음
     * Unity의 2023년 3분기 재정 결과는 2023년 11월 9일 목요일에 발표될 예정

   Unity 플랜 가격 및 패키지 업데이트
   Unity는 죽었다
   Unity, 커뮤니티에 보내는 공개서한을 통해 라이센스 수정 철회

        Hacker News 의견

     * 존 리치티엘로, 유니티 CEO 사임.
     * 이사회의 유니티 최근 문제에 대한 리치티엘로 책임 추궁 결정, 일부에게 놀라움.
     * 이전 IBM 및 Red Hat의 제임스 M. 화이트허스트, 임시 CEO로 임명.
     * 화이트허스트의 배경이 관리 컨설팅 및 수익에 더 초점을 맞춘 것으로 보이는 데 대해 일부 논평가들은 우려 표명.
     * 유니티의 최근 런타임 요금 정책 발표의 잘못된 처리로 인해 평판 손상, 리치티엘로의 퇴진에 기여했을 수도 있다는 추측.
     * 유니티를 사용하는 많은 게임 개발자들이 회사의 최근 결정으로 인해 미래의 게임에 대해 엔진을 바꾸려고 계획 중이라고 보고됨.
     * 일부 논평가들은 새로운 CEO가 회사의 현재 비즈니스 모델과 전략을 계속할 것이지만, PR은 더 나아질 것이라고 제안.
     * 유니티의 최근 가격 변경 및 리더십 변화는 그들이 피드백을 진지하게 받아들이고 있다는 추측.
     * 일부 논평가들은 회사가 이 상황에서 회복할 수 있기를 희망하며, 다른 일부는 회의적.
     * 가격을 인상하기로 한 초기 결정의 이유에 대한 호기심, 일부는 고객 반응의 잘못된 계산이었을 수 있다고 제안.
     * 일부 논평가들은 리치티엘로의 퇴진을 유니티에 대한 긍정적인 발전으로 보고, 그의 단기적인 주주 이익에 대한 초점을 비판.
     * 많은 해를 Red Hat을 성공적으로 이끈 화이트허스트의 임명은, 유니티의 도전을 어떻게 처리할지에 대한 불확실성에도 불구하고, 긍정적인 변화일 수 있다고 봄.
"
"https://news.hada.io/topic?id=11218","Open X-Embodiment: 로봇 학습 데이터세트 및 RT-X 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Open X-Embodiment: 로봇 학습 데이터세트 및 RT-X 모델

     * 최대 규모의 오픈 소스 데이터 셋
          + 21개 기관의 협업을 통해 22개의 다른 로봇으로부터 수집한 데이터 셋
          + 527개의 스킬셋(16만개의 태스크) 포함
     * 이 데이터로 훈련된 RT-X 모델을 2가지 공개
          + RT-1-X: 로봇 제어를 위해 설계된 효율적인 트랜스포머 기반의 아키텍처
          + RT-2-X: 자연 언어 토큰에서 로봇 액션을 출력해내는 대규모 비전-언어 모델
"
"https://news.hada.io/topic?id=11275","22년 만에 수정된 Firefox 툴팁 버그","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        22년 만에 수정된 Firefox 툴팁 버그

     * 22년 만에 Firefox의 버그가 수정되어, Firefox가 백그라운드에 있을 때도 툴팁이 전경에 계속 머무르는 현상이 해결되었습니다.
     * 이 버그는 22년 전에 처음 보고되었으며, 한 달 전에 드디어 해결되었습니다.
     * 이 버그는 Firefox와 Thunderbird 모두에 존재했으며, Windows 10, KDE Neon 22.04, GNU/Linux 등 다양한 운영 체제에서 재현되었습니다.
     * 이 버그는 다중 작업을 하는 사용자들에게 특히 불편했는데, 그들은 다른 창에서 작업하는 것을 방해하지 않기 위해 Firefox를 수동으로 최소화해야 했습니다.
     * 수정 사항은 문서에 포커스가 있을 때만 툴팁이 표시되도록 보장합니다.
     * 이 버그 수정은 커뮤니티에서 잘 받아들여졌으며, 많은 사람들이 이 오랫동안의 문제 해결에 대해 행복함을 표현하였습니다.

        Hacker News 의견

     * Mozilla 개발자인 Mike Conley는 수년 동안 Firefox 코드베이스 작업을 라이브 스트리밍하며 버그를 찾고 수정해 왔습니다.
     * 전체 화면 게임 위에 툴팁이 나타나게 하는 Firefox의 오래된 버그가 드디어 수정되었습니다.
     * 일부 사용자들은 이 버그가 수년 동안 우연히 수정되지 않은 것에 놀라워하며, 이는 소프트웨어의 뛰어난 후진 호환성을 강조하였습니다.
     * 이 버그는 종종 Linux 데스크톱 윈도우 관리자에게 비난을 받았으며, 이는 폼이나 다른 중요한 요소의 디스플레이를 방해할 때 불만을 유발하였습니다.
     * 이 버그에 대한 수정은 간단한 5줄 코드 변경이었으며, 이로 인해 일부 사용자들은 왜 자신들이 이를 수정하려고 시도하지 않았는지 의문을 제기하였습니다.
     * 많은 사용자들이 이 버그가 자신들의 잘못이라고 생각했으며, 이것이 알려진 문제였다는 것을 알게 되어 안도하였습니다.
     * 이 버그는 Firefox의 첫 버전이 출시되기 전에 파일되었으며, 이는 버그 트래커 기록의 장수를 보여줍니다.
     * 다른 앱으로 전환할 때 툴팁이 사라지지 않게 하는 관련 버그는 9개월 전에 수정되었습니다.
     * 일부 사용자들은 이 수정이 ""잘못된"" 수정이라고 주장하며, 윈도우가 포커스를 가지고 있지 않더라도 툴팁이 나타나야 하지만 마우스 포인터가 더 이상 윈도우 위에 없을 때 사라져야 한다고 주장합니다.
     * 수정의 기술적 세부사항에 관심이 있는 사람들을 위해 패치에 대한 직접 링크가 제공되었습니다.
"
"https://news.hada.io/topic?id=11179","Thoughtworks Technology Radar, Volume 29 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Thoughtworks Technology Radar, Volume 29 공개

   테크닉/도구/플랫폼/개발언어 및 프레임워크 분야의 최신 트렌드들을 Hold/Assess/Trial/Adopt 4단계로 시각화 및 설명

AI 지원 소프트웨어 개발

     * 코딩을 위한 오픈소스 LLM이 개발 도구 환경을 뒤흔들 것
     * 또한 코딩을 넘어서 사용자 스토리 작성 지원, 사용자 리서치, 엘리베이터 피치, 다른 언어 관련 작업등에서 큰 잠재력이 있음
     * 동시에 개발자는 이러한 모든 도구를 책임감 있게 사용해야하며, 환각적 종속성 같은 것도 주의해야 함

생산성 측정은 얼마나 생산적일까?

     * 소프트웨어 개발은 ​​기술 전문가가 아닌 사람들에게 때로 마술처럼 보일 수 있으며, 이로 인해 관리자는 개발자가 얼마나 생산적으로 수행하는지 측정하려고 노력하게 됨
     * 마틴 파울러는 2003년에 ""생산성은 측정될수 없다"" 라는 글을 썼음
     * 아직 SPACE 프레임워크(Satisfaction and well-being, Performance, Activity, Communication and collaboration, Efficiency and flow) 중 Activity에 대한 대체 지표들인 풀리퀘스트 수나 해결한 이슈 건수등은 그닥 좋지 않음
     * 대신 업계는 생산성을 측정하기보다는 ""흐름에 기여하거나 방해하는 요소를 측정""해야 한다는 ""엔지니어링 효율성""에 초점을 맞추기 시작했음
     * 개인의 활동에 초점을 맞추는 대신 시스템의 낭비 원인과 경험적으로 보여줄 수 있는 조건이 개발자의 ""생산성"" 인식에 영향을 미친다는 점에 초점을 맞춰야 함
     * DX DevEx 360과 같은 새로운 툴은 특정 결과물 측정이 아닌 개발자 경험에 집중하여 이 문제를 해결함
     * 그러나 많은 리더가 여전히 모호하고 정성적인 방식으로 개발자의 '생산성'을 언급하고 있음
     * 이러한 관심의 부활 중 적어도 일부는 AI 지원 소프트웨어 개발의 영향에 관한 것으로 생각되며, 이는 ""긍정적인 영향을 미치고 있는가?""라는 의문을 제기함
     * 생산성에 대한 실제 측정은 여전히 어려움

수 많은 LLM들

     * LLM(대형 언어 모델)은 AI의 많은 현대적 혁신의 기초를 형성
     * 현재 많은 실험에는 ChatGPT 또는 Bard 같은 채팅과 유사한 사용자 인터페이스를 표시하는 것이 포함
     * 광범위하게 LLM은 콘텐츠 생성(텍스트, 이미지 및 비디오)부터 코드 생성, 요약 및 번역에 이르기까지 다양한 문제를 해결할 수 있는 도구
     * 강력한 추상화 계층 역할을 하는 ""자연어""를 사용하는 이러한 모델은 보편적으로 매력적인 도구 세트를 제공하므로 많은 정보 노동자가 사용중
     * 클라우드 호스팅 LLM보다 커스터마이징과 더 강력한 제어가 가능한 셀프 호스팅을 포함하여 다양한 측면의 LLM에 대한 논의가 이루어 짐
     * LLM의 복잡성이 증가함에 따라 우리는 특히 에지 장치와 제한된 환경에서 소형 폼 팩터에서 LLM을 양자화하고 실행하는 기능을 고려함
     * 질문과 답변 상호 작용을 뛰어넘는 동적 애플리케이션을 구축하는 데 사용할 수 있는 LLM 기반 자율 에이전트 와 함께 성능 향상을 약속하는 ""ReAct Prompting"" 에 ​​대해 살펴 봄
     * 또한 LLM 덕분에 다시 부활하고 있는 여러 벡터 데이터베이스(Pinecone 포함)에 대해서도 언급
     * 전문화 기능과 자체 호스팅 기능을 포함한 LLM의 기본 기능은 폭발적인 성장을 이어가고 있음

원격 딜리버리의 해결방법(Workaround)이 성숙해짐

     * 원격 소프트웨어 개발 팀은 수년간 지리적 제약을 극복하기 위해 기술을 활용해 왔지만, 팬데믹의 영향으로 이 분야의 혁신이 촉진되어 전체 원격 또는 하이브리드 작업이 지속적인 추세로 굳어짐
     * 이번 Radar에서는 원격 소프트웨어 개발 방식과 도구가 어떻게 성숙해졌는지, 그리고 팀이 그 어느 때보다 분산되고 역동적인 환경에서 효과적인 협업에 중점을 두고 경계를 계속 넓혀가는 방법에 대해 논의
     * 일부 팀은 새로운 협업 도구를 사용하여 계속해서 혁신적인 솔루션을 제시
     * 일부는 실시간 페어 프로그래밍이나 Mob 프로그래밍 , 분산 워크숍(예: 원격 이벤트 스토밍) 과 같은 활동에 대한 기존 대면 관행을 계속해서 조정하고 개선중. 비동기식 및 동기식이 모두 가능
     * 원격 근무는 다양한 이점을 제공하지만(보다 다양한 인재 풀 포함), 대면 상호작용의 가치는 분명함
     * 팀은 중요한 피드백 루프가 소실되도록 해서는 안 되며 원격 설정으로 전환할 때 발생하는 장단점을 인식해야 함

[Techiniques]

  Adopt

    1. Design systems
    2. Lightweight approach to RFCs

  Trial

    3. Accessibility-aware component test design
    4. Attack path analysis
    5. Automatic merging of dependency update PRs
    6. Data product thinking for FAIR data
    7. OIDC for GitHub Actions
    8. Provision monitors and alerts with Terraform
    9. ReAct prompting
   10. Retrieval-Augmented Generation (RAG)
   11. Risk-based failure modeling
   12. Semi-structured natural language for LLMs
   13. Tracking health over debt
   14. Unit testing for alerting rules
   15. Zero trust security for CI/CD Assess
   16. Dependency health checks to counter package hallucinations
   17. Design system decision records
   18. GitOps
   19. LLM-powered autonomous agents
   20. Platform orchestration
   21. Self-hosted LLMs

  Hold

   22. Ignoring OWASP Top 10 lists
   23. Web components for server-siderendered (SSR) web apps

[Platforms]

  Adopt

   24. Colima

  Trial

   25. CloudEvents
   26. DataOps.live
   27. Google Cloud Vertex AI
   28. Immuta
   29. Lokalise
   30. Orca
   31. Trino
   32. Wiz

  Assess

   33. ActivityPub
   34. Azure Container Apps
   35. Azure OpenAI Service
   36. ChatGLM
   37. Chroma
   38. Kraftful
   39. pgvector
   40. Pinecone
   41. wazero

[Tools]

  Adopt

   42. dbt
   43. Mermaid
   44. Ruff
   45. Snyk

  Trial

   46. AWS Control Tower
   47. Bloc
   48. cdk-nag
   49. Checkov
   50. Chromatic
   51. Cilium
   52. Cloud Carbon Footprint
   53. Container Structure Tests
   54. Devbox
   55. DX DevEx 360
   56. GitHub Copilot
   57. Insomnia
   58. IntelliJ HTTP Client plugin
   59. KEDA
   60. Kubeconform
   61. mob
   62. MobSF
   63. Mocks Server
   64. Prisma runtime defense
   65. Terratest
   66. Thanos
   67. Yalc

  Assess

   68. ChatGPT
   69. Codeium
   70. GitHub merge queue
   71. Google Bard
   72. Google Cloud Workstations
   73. Gradio
   74. KWOK
   75. Llama 2
   76. Maestro
   77. Open-source LLMs for coding
   78. OpenCost
   79. OpenRewrite
   80. OrbStack
   81. Pixie
   82. Tabnine

[Languages and Frameworks]

  Adopt

   83. Playwright

  Trial

   84. .NET Minimal API
   85. Ajv
   86. Armeria
   87. AWS SAM
   88. Dart
   89. fast-check
   90. Kotlin with Spring
   91. Mockery
   92. Netflix DGS
   93. OpenTelemetry
   94. Polars
   95. Pushpin
   96. Snowpark

  Assess

   97. Baseline Profiles
   98. GGML
   99. GPTCache
   100. Grammatical Inflection API
   101. htmx
   102. Kotlin Kover
   103. LangChain
   104. LlamaIndex
   105. promptfoo
   106. Semantic Kernel
   107. Spring Modulith

   Thoughtworks Technology Radar, Volume 28 공개
   Thoughtworks Technology Radar 27호 발간
   Thoughtworks Technology Radar 26호 (39p PDF)
   ThoughtWorks Technology Radar 23호 발간
   ThoughtWorks Technology Radar 22호 발간 [32p PDF]
   ThoughtWorks가 6개월마다 발행하는 기술뉴스 - Radar Vol.21
"
"https://news.hada.io/topic?id=11178","NIST의 Kyber-512 보안 수준 계산에 대한 반박","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NIST의 Kyber-512 보안 수준 계산에 대한 반박

     * 블로그 포스트에서는 국립 표준 기술 연구소(NIST)의 Kyber-512 암호 시스템 보안 수준 계산 오류를 논의하고 있다.
     * 두 비용의 곱셈에서 발생한 오류로 인해 시스템의 보안 수준이 과대 평가되었다.
     * 저자는 이런 중요한 오류가 NIST의 검토 과정을 어떻게 통과했는지 의문을 제기하며, NIST의 절차에 근본적인 문제가 있을 수 있다고 제안한다.
     * 저자는 또한 정보공개법(FOIA) 요청을 방해한 NIST에 대한 소송을 제기하였으며, 이로 인해 국가안보국(NSA)의 과정 참여가 이전에 알려진 것보다 더 많았음이 밝혀졌다.
     * 저자는 NIST가 Kyber-512 암호 시스템을 다루는 방식을 비판하며, 이 기관이 계산 오류에도 불구하고 시스템을 안전하다고 주장하는 것에 필사적이었다고 제안한다.
     * 저자는 또한 NIST가 NTRU 암호 시스템의 유연성을 무시하고, Kyber, NTRU, Saber 암호 시스템 비교에서 키 생성 비용을 과장하고 홍보했다고 비판한다.
     * 저자는 결론적으로 NIST의 Kyber-512 암호 시스템 처리와 다른 암호 시스템 비교가 보안 및 성능의 객관적 평가 외의 요인에 의해 영향을 받았을 수 있다고 제안한다.

        Hacker News 의견

     * 국립 표준 기술 연구소(NIST)의 Kyber-512 보안 수준 계산에 대한 기사 논의
     * Kyber 팀은 NIST나 NSA가 아닌 여러 학자들로 구성
     * NIST의 비판에 대한 반응이 기만적이지 않고, 대립하는 입장에 대한 꺼림칙함일 수 있다는 일부 댓글
     * NIST가 NTRU보다 Kyber를 추천함으로써 사용자 데이터를 공격자에게 노출시켰다는 비난
     * 알고리즘과 프로세스 분야에서 NIST의 평판에 대한 의구심
     * 기사가 조직적이지 않고 전문 용어가 많다는 비판, 그러나 정보는 중요할 수 있다는 판단
     * NIST가 NSA의 도움으로 약한 알고리즘을 고의적으로 표준화했다는 시사점
     * 공격자가 같은 약점을 발견할 수 있으므로 공개 암호를 약화시키는 위험에 대한 의문
     * 전년도에 관련 스레드가 언급되며, NSA, NIST, 그리고 후기 양자 암호에 대해 논의
     * 한 댓글에서는 저자가 연방 정부에 도전할 의지를 지지
     * 일부 댓글에서는 저자가 NIST의 행동을 악의적으로 해석했다고 비판
     * 저자가 Kyber의 경쟁사인 NTRU에 관여했기 때문에 편향될 수 있다는 제안
     * NIST의 신뢰성에 대한 신뢰 부족을 표현하는 일부 댓글
     * NIST의 표준화 과정에 대한 비판, 더 많은 투명성과 공개적인 검토를 요구
     * NISTPQC의 평가가 선택된 알고리즘에 의해 제공되는 보안에 대한 명확하고 보수적인 하한을 제공하지 않는다는 비판
"
"https://news.hada.io/topic?id=11235","조직이 아마도 개선하고 싶어하지 않는 상황","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        조직이 아마도 개선하고 싶어하지 않는 상황

     * 기사는 일본의 honne(진심)과 tatemae(공적인 표면) 개념을 사용하여 조직들이 말하고 실제로 하는 것 사이의 불일치에 대해 논의한다.
     * 저자는 많은 관리자들이 데이터 중심의 결정을 원한다고 주장하지만 이 목표를 향해 나아가는 데 실패한다고 주장한다.
     * 데이터 시각화 도구인 Power BI의 사용이 이러한 불일치의 예로 들어진다. Power BI 개발자들의 높은 급여에도 불구하고, 대부분의 대시보드가 사용되지 않는다는 점을 저자는 지적한다.
     * 저자는 관리진이 종종 ""디지털 변혁""과 같은 유행어를 사용하여 수익을 창출하지 못하는 노력을 정당화하고 직원들의 불만을 유발한다고 제안한다.
     * 기사는 스터전의 법칙, 즉 모든 것의 90%가 쓰레기라는 주장을 논의하며, 대부분의 관리자와 프로그래머들이 독창적인 생각이나 자신의 역할에 대한 이해를 부족하다고 제안한다.
     * 저자는 많은 전문적인 환경이 무능력으로 고통받고 있으며, 시간이 종종 열등한 동료들이 초래한 문제를 해결하는 데 사용된다고 주장한다.
     * 저자는 팀의 목표 달성 불능에 대한 솔직함이 일자리 손실로 이어질 수 있어, 부인이나 무지의 문화가 생길 수 있다고 제안한다.
     * 기사는 독자들에게 관리진을 무시하고, 그들이 지능, 정직성, 그리고 조직의 기능 장애에 대한 이해를 보여줄 때만 주목하라고 조언한다.
     * 저자는 예산 제약으로 인해 인상을 거부당한 친구에 대한 개인적인 이야기를 공유하며, 저자 자신이 같은 역할에 대해 더 높은 급여를 제안받았다.
     * 저자는 미래의 개선에 대한 약속을 무시하고 조직이 취한 실제 문제 해결 행동에 초점을 맞추라고 조언한다.
     * 저자는 관리진의 업무 문화에 대한 주장을 무시하고 개인적인 업무에 집중함으로써 더 평화로운 업무 경험을 얻을 수 있다고 제안한다.

        Hacker News 의견

     * 기사는 일부 프로그래머들이 대기업에 대한 불만을 토로하며, 그들이 종종 만족하지 못하는 역할에 갇혀 있다고 주장합니다.
     * 일부 댓글 작성자들은 기사의 견해에 동의하며, 기업의 비효율성과 의미 없는 일에 대한 자신의 경험을 인용합니다.
     * 다른 사람들은 기사의 어조를 비판하며, 불행한 사람들이 불평하기보다 변화를 추구해야 한다고 제안합니다.
     * 일부 댓글 작성자들은 기사가 개인과 팀 성과 사이의 균형과 같은 복잡한 문제를 과도하게 단순화한다고 주장합니다.
     * 대기업이 ""바보들""로 가득하다는 기사의 주장에는 반발이 있으며, 일부 댓글 작성자들은 사람들이 단지 자신의 이익을 위해 행동하고 있다고 제안합니다.
     * 여러 댓글 작성자들은 기업 문화에 대한 자신의 경험을 공유하며, 피드백 부족, 직원 제안 무시, 내부보다 외부 입력에 초점을 맞추는 문제 등을 강조합니다.
     * 일부 댓글 작성자들은 자신의 일에 대한 열정이나 자부심의 부족이 기업 세계에서 중요한 문제이며, 이는 직원 불만에 기여할 수 있다고 제안합니다.
     * 논의는 또한 연령차별에 대한 주제를 다루며, 일부는 젊은 직원들이 종종 자신의 일에 더 참여하고 열정적이라고 제안합니다.
     * 기사가 대기업의 비효율성에 초점을 맞춘 것은 일부에게는 지나치게 부정적으로 보이며, 그들은 작은 개선조차도 큰 영향을 미칠 수 있다고 주장합니다.
     * 전반적으로, 논의는 기업 문화에 대한 다양한 관점을 강조하며, 많은 사람들이 중요한 문제가 있다는 것에 동의하지만 원인과 가능한 해결책에 대한 견해는 다릅니다.
"
"https://news.hada.io/topic?id=11257","pcz - 플랫폼 네이티브 지원에 집중한 Go언어용 새로운 stdlib","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                pcz - 플랫폼 네이티브 지원에 집중한 Go언어용 새로운 stdlib

     * ""A reimagination of Go""
     * GC 와 Goroutines 없음
     * 수정하지 않은 공식 Go 툴체인으로도 작은 바이너리를 생성

프로젝트의 목표

     * FFI 친화적
     * 네이티브하게 동작
          + 독단적인 방식이 아닌 실행 환경에 적응
          + 플랫폼 네이티브 API 제공
     * Go를 다양한곳에서 가능하게 확장
          + Web/NodeJS 어플리케이션
          + 네이티브 경험을 제공하는 크로스 플랫폼 GUI
          + 저수준 시스템 프로그래밍(crun, systemd), EFI 어플리케이션
          + 커널 및 펌웨어

프로젝트의 목표가 아닌 것

     * Go 팀이 작업하는 방식을 바꾸거나, 그들의 결정을 바꾸도록 하는 것
"
"https://news.hada.io/topic?id=11196","Vespa.ai가 Yahoo에서 독립 회사로 분리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Vespa.ai가 Yahoo에서 독립 회사로 분리

     * 빅 데이터 서빙 엔진인 Vespa가 야후에서 독립하여 별도의 회사가 됨
     * 원래 야후의 검색, 추천, 광고 서빙 등의 사용 사례를 해결하기 위한 프로젝트였던 Vespa.ai는 2017년에 오픈 소스화됨
     * ChatGPT와 벡터 데이터베이스와 같은 대규모 언어 모델을 다루는 사람들에게 인기가 있음
     * Vespa.ai는 AI 우선 접근법과 확장성 때문에 검색 또는 추천 시스템 경험이 있는 기업들에게 선호됨
     * 고가용성 상태 시스템을 운영하는 것의 어려움에도 불구하고, Vespa.ai는 야후 내 약 150개의 애플리케이션을 성공적으로 관리함
     * 확장성을 해결하기 위해, Vespa.ai는 중앙 집중식 클라우드 서비스를 만들어, 기계 사용량을 90% 줄이고 최대 200명의 전임직원들의 시간을 확보함
     * cloud.vespa.ai에서 제공하는 클라우드 서비스는 초당 800,000개 이상의 쿼리를 처리하며, 빠른 실험 실행부터 비즈니스 중요 애플리케이션 서비스까지 모든 것을 지원함.
     * 야후와 분리되더라도 두 엔티티는 관계를 유지하며, 야후는 Vespa.ai의 주식을 보유하고 가장 큰 고객 중 하나로 남아 있음
     * 독립은 Vespa.ai가 클라우드 서비스의 효율성을 더 넓은 관객에게 제공하게 해, 더 많은 회사들이 온라인에서 AI와 빅 데이터 문제를 해결하는 데 도움을 줄 수 있게 함
     * 회사는 또한 사용자가 더 나은 솔루션을 더 빠르고 저렴하게 만들 수 있도록 새로운 기능 개발을 가속화할 계획임
     * Vespa.ai는 실제 비즈니스 문제를 해결하기 위한 온라인 AI 솔루션에 대한 견고한 기반을 제공하는 플랫폼에 대한 필요성이 증가하고 있다는 것을 인정함
     * 회사는 사용자가 더 나은 그리고 더 빠른 온라인 AI 애플리케이션을 만드는 데 도움을 주는 것에 대해 기대감을 표현함

   Vespa만 단독으로 기사는 올린적이 없네요.
   Vespa vs. ElasticSearch
   위 글에 어느정도 요약이 있으니 같이 참고하세요

        Hacker News 의견

     * Yahoo의 자회사인 Vespa.ai가 별도의 회사로 분리됩니다.
     * Yahoo는 Vespa의 가장 큰 고객 중 하나로 계속 남아 있을 것이며, 새 회사에 지분을 소유하게 될 것입니다.
     * 이 분리는 Vespa의 성장과 공개 자본 시장에 대한 필요성 또는 수익성 모드로의 전환 때문일 수 있습니다.
     * Vespa는 Yahoo가 10년 전부터 벡터 검색을 위해 사용해온 오랜 역사를 가지고 있으며, Flickr의 유사성 검색 요청 처리 등의 생산적인 용도로 사용되었습니다.
     * Vespa는 뛰어난 플랫폼과 깊은 기술적 계보를 자랑하며, 수년 동안 개선되어 왔습니다.
     * Vespa는 텐서의 깊은 통합과 맞춤형 HNSW 구현을 지원하는 데 앞서, 학습된 임베딩의 대중화에서 선두를 달리고 있습니다.
     * Vespa는 전통적인 어휘 검색, 임베딩을 이용한 의미 검색, 하이브리드 검색, 다단계 랭킹, 호스팅된 ML 모델, 문서 처리 엔진 등을 결합한 최고의 조합을 제공합니다.
     * Vespa는 임베딩 검색과 일반적인 면적 검색에 대한 접근 방식을 칭찬받고 있습니다.
     * Vespa는 원래 Yahoo의 인수였으며, 주로 노르웨이의 팀이 개발하였고, 대부분의 개발이 여전히 그곳에서 이루어지고 있습니다.
     * Vespa의 벡터 지원과 어휘 필터링은 매우 높이 평가받고 있으며, 멀티 벡터 문서 필드와 같은 새로운 기능들도 함께 인정받고 있습니다.
"
"https://news.hada.io/topic?id=11162","의학 노벨상, Katalin Karikó와 Drew Weissman에게 수여","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               의학 노벨상, Katalin Karikó와 Drew Weissman에게 수여

     * 2023년 노벨 생리학 혹은 의학상은 Katalin Karikó와 Drew Weissman에게 수여되었다.
     * 그들은 COVID-19에 대한 효과적인 mRNA 백신 개발을 가능하게 한 핵산염기 수정에 관한 발견으로 인정받았다.
     * 그들의 혁신적인 연구 결과는 mRNA가 우리의 면역 시스템과 어떻게 상호 작용하는지에 대한 이해를 근본적으로 바꾸었다.
     * 이것은 COVID-19 팬데믹 동안 백신 개발의 전례 없는 속도에 기여하였다.
     * 팬데믹 이전의 백신들은 죽은 또는 약화된 바이러스, 또는 개별 바이러스 구성 요소를 기반으로 하였다.
     * mRNA 백신은 1980년대에 유망한 아이디어였지만 불안정성과 전달의 어려움 등의 도전에 직면했다.
     * Katalin Karikó와 Drew Weissman의 돌파구는 mRNA의 염기 수정이 염증 반응을 거의 없앨 수 있다는 것을 발견했을 때 왔다.
     * 이 발견은 mRNA를 치료제로 사용하는 데 깊은 의미를 가지며 2005년에 발표되었다.
     * 추가 연구들은 염기 수정으로 생성된 mRNA의 전달이 수정되지 않은 mRNA에 비해 단백질 생산을 크게 증가시킨다는 것을 보여주었다.
     * COVID-19 팬데믹은 SARS-CoV-2 표면 단백질을 인코딩하는 두 가지 염기 수정 mRNA 백신의 빠른 개발을 목격했다.
     * mRNA 기술은 미래에 치료 단백질을 전달하고 일부 암 유형을 치료하는 데 사용될 수도 있다.
     * Katalin Karikó는 1955년 헝가리 Szolnok에서, Drew Weissman은 1959년 미국 매사추세츠주 렉싱턴에서 태어났다.
     * 노벨 생리학 혹은 의학상은 Karolinska Institutet의 50명의 교수로 구성된 노벨 집단에 의해 수여된다.

   커리코가 받을꺼라고 예상했는데 역시나 ㅎㅎ

   mRNA 관련해서 이 영상 재미납니다. https://www.youtube.com/watch?v=hQVNdtLFGaY

        Hacker News 의견

     * 카탈린 카리코와 드류 웨이스만에게 의학 노벨상 수여.
     * 카리코 박사의 학계에서의 고군분투, 비전통적 연구 아이디어에 대한 자금 지원 어려움을 드러냄.
     * 과학 저널들의 거절과 제약회사들의 무관심에도 불구하고 카리코와 웨이스만은 연구를 계속함.
     * 카리코의 흥미로운 생애 이야기와 그녀가 쓴 회고록 ""Breaking Through"".
     * 이 이야기는 학문 기관들이 종종 그들의 행렬에서 최고를 인식하지 못하는 것을 상기시킴.
     * 그들의 연구에서 새로운 접근법으로 사용된 유사우리딘(Ψ)이 칭찬받음.
     * 2005년 카리코와 웨이스만의 논문은 그들의 혁신적인 작업의 출발점으로 간주됨.
     * 그들의 연구 결과인 mRNA 백신은 그들의 속도와 유연성 때문에 큰 발전으로 간주됨.
     * 노벨상은 백신의 효과와 잠재적 부작용에 대한 비판에도 불구하고 그들의 노력과 의도를 인정함.
     * 그들의 기념비적인 논문이 Nature에 의해 거절된 것은 중요한 간과로 간주됨.
     * RNA/DNA가 단백질을 어떻게 만드는지 이해는 저렴한 DNA 컴파일러와 분자 조립기에 대한 희망과 함께 우리의 미래를 통제하는 열쇠로 간주됨.
     * 그들의 연구 결과로 개발된 백신들은 COVID-19 팬데믹 동안 수많은 생명을 구함.
"
"https://news.hada.io/topic?id=11207","Linux 파이프의 속도는 얼마나 빠른가? (2022)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Linux 파이프의 속도는 얼마나 빠른가? (2022)

     * Unix 파이프의 Linux에서의 구현과 파이프를 통해 데이터를 쓰고 읽는 테스트 프로그램 최적화 방법 탐구
     * 초기 프로그램은 약 3.5GiB/s의 처리량을 가졌으며, 다양한 최적화를 통해 이를 20배로 향상
     * 이러한 최적화는 Linux의 perf 도구를 사용하여 프로그램을 프로파일링함으로써 이루어짐
     * 본문은 ~35GiB/s의 속도로 파이프에 출력을 밀어넣는 최적화된 FizzBuzz 프로그램에 영감을 받음
     * 파이프의 내부 작동 방식, 그것들로부터 쓰고 읽는 것이 느린 이유, 그리고 vmsplice와 splice 시스템 호출이 성능을 향상시키는 방법에 대해 깊이 파고듬
     * Linux 페이징과 huge pages 사용이 프로그램의 더 빠른 버전으로 이어질 수 있는 방법에 대해 논의
     * 최종 최적화는 폴링을 바쁜 루프로 대체하는 것을 포함
     * 테스트는 Intel Skylake i7-8550U CPU와 Linux 5.17에서 수행됨
     * 본문은 메모리가 일정한 크기의 덩어리인 페이지로 구성되는 방법과 CPU가 페이지 테이블을 사용하여 가상 주소를 물리 주소로 변환하는 방법에 대해 자세히 설명
     * 본문은 프로그램에서 huge pages로 전환하면 성능이 약 50% 향상된다는 관찰로 결론
     * 본문은 CPU에서 huge pages의 사용과 Translation Lookaside Buffer (TLB) 미스를 줄이는 방법에 대해 논의, 이는 성능을 향상시킬 수 있음
     * 커널 코드는 struct page가 현재 아키텍처의 표준 크기 페이지를 가리킨다고 가정. huge pages의 경우, ""head"" struct page에 실제 물리 페이지에 대한 정보가 포함되며, 연속적인 ""tail"" 페이지는 head 페이지를 가리키는 포인터만 포함
     * 최근 커널(5.17 이후)은 head 페이지를 명시적으로 식별하는 새로운 타입인 struct folio를 포함. 이는 런타임에 struct page가 head 페이지인지 tail 페이지인지 확인하는 필요성을 줄여 성능을 향상시킴
     * 본문은 동기화 비용을 회피하기 위한 바쁜 루프 개념에 대해 논의. 이는 파이프에 쓸 수 없는 경우 vmsplice가 반환하도록 요청하고, 준비될 때까지 바쁜 루프를 돌게 함. 이는 25%의 성능 향상을 가져올 수 있지만, vmsplice가 준비될 때까지 CPU 코어를 완전히 점유하는 비용이 따름
     * 저자는 본문에서 다룬 주요 주제들을 요약: 제로 복사 작업, 링 버퍼, 페이징 & 가상 메모리, 동기화 오버헤드
     * 저자는 또한 본문에서 논의되지 않은 많은 다른 옵션과 세부 사항들이 있음을 인정, 이는 그들의 관련성이 없거나 관심이 부족하기 때문
     * 본문은 독자들로부터 잘 받아들여짐, 이는 그들에게 도움이 되고 흥미롭다고 발견되었기 때문

        Hacker News 의견

     * Linux 파이프의 속도에 대한 기사, 두 프로세스 간의 미니 공유 메모리 메커니즘으로 작동하는 vmsplice에 초점을 맞춤
     * vmsplice의 사용은 읽기와 쓰기 시 버퍼의 신중한 처리를 필요로 하며, 복잡하지만 효율적일 수 있음
     * Linux 파이프의 표준 구현은 최적의 속도보다 20배 느리다고 보고됨
     * 기사는 잘 받아들여지며, 독자들은 그것의 정보적인 성격을 칭찬함
     * 한 독자는 Linux 파이프가 결정론적인 행동을 만들 수 있다고 지적하며, 추가적인 읽기를 위해 외부 소스를 연결함
     * 파이프, 소켓, 파일, 메모리 위에 추상화를 제공하는 데이터 처리 라이브러리에 대한 질문이 제기되며, 그들이 기사에서 논의된 최적화를 구현하는지 여부에 대해 논의됨
     * 기사는 splice() 및 vmsplice()와 같은 API를 언급하며, 이들은 대부분의 프로그램에서 사용하기 어렵고 활용되지 않는다고 보고됨
     * Linux 파이프의 속도는 시스템 내 단일 코어의 속도와 비교되며, 커널은 같은 물리 메모리 페이지를 한 프로그램의 stdout에서 다른 프로그램의 stdin으로 매핑하여, 작업을 zerocopy 또는 덜 최적화된 상황에서 빠른 onecopy로 만듦
     * 기사는 페이지 테이블의 개념을 perf를 이용한 성능 분석에 연결하며, 그것의 처리량에 대한 중요성을 강조함
     * 한 독자는 Cygwin 파이프 구현에 대한 경험을 공유하며, Linux에 비해 느린 속도를 언급함
     * Linux 파이프의 속도는 cat, sed, awk, cut, grep, uniq, jq 등의 명령어를 반복하고 구성하는 데 충분하다고 판단됨
"
"https://news.hada.io/topic?id=11266","회사 문화는 지난 50일에서 보여집니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         회사 문화는 지난 50일에서 보여집니다

     * 회사의 문화는 복잡한 개념이 아니라, 회사 내에서 집단적으로 나타나는 행동과 행위에서 자연스럽게 나타남
     * 회사의 문화는 50일 이동 평균선임. 지난 50일 동안 여러분이 회사로서 총체적으로 해온 일들의 합
          + 직원을 어떻게 대우했나
          + 누구를 채용하고 해고했으며 왜 그렇게 결정했나
          + 직원들이 스트레스 받았을때 어떻게 했나
          + 어떻게 사람들을 도왔나
          + 직원들이 서로를 어떻게 비평하나
          + 어떻게 공유하는가
          + 막막한 사람들을 어떻게 도와주는가
          + 품질 기준은 어떤가
          + 고객을 어떻게 지원하는가
          + 거래를 어떻게 성사시키는가
          + 어떤 일을 오래 방치하고 있나
          + 무엇을 축하했나
          + 무엇을 그냥 지나쳤나
          + 서로에게 그리고 자신에게 얼마나 솔직했나
     * 그 외에도 수많은 일이 일어났지만, 이것들은 실제 일어난 일이지, 이상적인 환경에서 일어났으면 좋겠다고 생각하거나 선언한 일들의 목록이 아님
     * 대부분은 조직 안팎에서 표현되는 대인 관계에 관한 것
     * 왜 50일인가?
          + 패턴이 형성되기에 충분한 시간이며, 현재 상태와 진실성을 반영할 수 있을 만큼 유연하기 때문
          + 하루 또는 몇 주만으로는 문화를 대변하기에 충분하지 않음
          + 단기간 동안 느슨하게 묶인 일련의 일들만으로는 어떤 곳의 실제 모습을 파악하기에 충분하지 않음
          + 잠시 동안은 최선의 행동을 할 수 있지만, 그 시간이 길어질수록 진실을 알 수 있음
     * 문화는 조직의 논픽션 이야기임. 스스로 만들어짐

   두달 정도면 회사 망하기에 충분한 시간이다.
   ...라고도 볼 수 있겠네요. 비약이 조금 심하지만.

   last 50 days. 마지막 50일이 아니라 지난 50일 일듯 합니다.

   글 중간엔 지난이라고 해놓고 왜 제목은 그렇게 했을까요 ㅎㅎ

   지금의 문제는 최소 50일전부터 시작되었다. 미꾸라지의 흙탕물도 50일이면 드러난다

   주식하는 사람들을 위한 비유적 설명이네요 굿

   공감가네요. N일 평균은 또 어떻게 집계할지 애매하긴 하지만
"
"https://news.hada.io/topic?id=11244","라즈베리 파이 5가 2개의 파이 4S보다 우수함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       라즈베리 파이 5가 2개의 파이 4S보다 우수함

     * Pi 5는 새로운 Broadcom BCM2712 시스템온칩(SOC)을 사용하여 2.4 GHz에서 네 개의 ARM A76을 실행함으로써 Pi 4보다 두 세 배 빠름
     * DRAM의 클럭 속도를 두 배로 높이고, 더 효율적인 비디오 코어, 두 배의 처리량을 위한 새로운 WiFi 컨트롤러, 그리고 두 배 빠른 SD 카드 인터페이스를 포함하여 여러 성능 향상을 보여줌
     * 또한 두 개의 MIPI 카메라/디스플레이 라인을 지원하여 스테레오 이미징 또는 동시 카메라 및 외부 디스플레이 작동이 가능
     * 새로운 Broadcom SOC는 ARM 암호화 확장을 지원하여 AES에서 45배 빠름
     * 새로운 전력 하위 시스템을 가지고 있으며, USB-C Power Delivery를 지원하는 DA9091 전력 관리 IC를 특징으로 함
     * 이전 모델에서 누락되었던 전원 버튼이 있음
     * 실제 PCIe 레인을 공식적으로 지원하여, Pi 4에서 필요했던 해킹을 제거함
     * Pi 5는 Raspberry Pi의 내부 혁신의 결과인 사용자 정의 RP1 인터페이스/사우스브리지 칩이 특징
     * SOC와 RP1 칩 사이의 백본으로 PCIe를 사용하여 본체와 두뇌 사이에 16 Gb/s의 링크를 제공
     * Raspberry Pi 5는 SBC 시장에서 소박한 한 걸음으로, 두 배의 속도 향상과 다양한 품질 개선을 작은 추가 비용으로 제공
     * 2023년 나머지 기간 동안 ""거의 백만 개""의 Pi 5를 생산하고 상점에 진열할 계획

        Hacker News 의견

     * Raspberry Pi 5는 USB-C 전원 공급을 지원하여 전원 공급 장치를 찾기 쉽게 만듭니다.
     * Pi 5의 전력 소비 효율성에 대해 논란이 있습니다. 이는 전압 대신 전류를 증가시키기 때문입니다.
     * Raspberry Pi의 가격이 크게 상승했습니다. 최초 모델은 약 $30에서 최신 버전은 $80 이상입니다.
     * 일부 사용자들은 Raspberry Pi 사용자들이 고성능을 추구하는지 의문을 제기하며, 이의 매력이 오픈 소스 특성과 주변 장치 옵션에 있다고 제안합니다.
     * Pi 5의 부팅 시간은 8초로, Commodore 64보다 2초 느립니다.
     * Pi 5의 코어는 1.8Ghz 대신 2.4GHz에서 작동할 수 있지만, 전력 소산을 고려해야 합니다.
     * 일부 사용자들은 Pi 5가 출시되면 더 저렴한 Pi 4를 구매할 수 있는 가능성에 흥분하고 있습니다.
     * Raspberry Pi의 가격 상승에 대한 실망이 있으며, 일부 사용자들은 $35 가격을 유지했으면 하는 바람을 표현하고 있습니다.
     * Pi 5의 새로운 Broadcom SOC는 ARM 암호화 확장을 지원하는 기능으로, 사용자들이 기대하고 있었습니다.
     * Pi 5의 냉각 솔루션의 영향에 대한 질문이 제기되었습니다. 이는 무게와 치수 모두에 대한 단위의 풋프린트에 대한 것입니다.
     * Pi 5는 SD 컨트롤러의 속도를 두 배로 높였지만, 일부 사용자들은 시스템에 eMMC가 있었으면 좋겠다는 바람을 표현하고 있습니다.
"
"https://news.hada.io/topic?id=11186","강력한 정적 타이핑, 나의 죽음을 걸고 싶은 언덕","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      강력한 정적 타이핑, 나의 죽음을 걸고 싶은 언덕

     * 소프트웨어 개발자로서 20년 이상의 경험을 가진 Tom Hacohen이 강력한 정적 타이핑의 사용을 강력히 주장하는 기사를 썼다.
     * 저자는 강력한 정적 타이핑이 단순히 좋은 아이디어가 아니라, 거의 항상 소프트웨어 개발에서 올바른 선택이라고 주장한다.
     * 타입이 없는 언어의 장점, 예를 들어 빠른 개발 속도를 인정하면서도, 저자는 이러한 이점이 강력한 타이핑의 장점에 의해 상쇄된다고 믿는다.
     * 강력한 정적 타이핑은 컴파일 시간에 불변성을 검사할 수 있게 해주어, 런타임 오류의 위험을 줄이고 코드의 신뢰성을 향상시킨다.
     * 저자는 강력한 타이핑이 어떻게 더 적은 버그, 더 나은 코드 계약, 향상된 개발 경험을 이끌어낼 수 있는지 예시를 제공한다.
     * 강력한 타이핑은 새로운 엔지니어의 온보딩 과정을 향상시킬 수도 있으며, 그들은 타입 정의를 따라가며 어디에서 무엇이 사용되는지 이해할 수 있다.
     * 저자는 그의 회사인 Svix가 타입 시스템에서 가능한 한 많은 정보를 인코딩하기 위해 강력한 타이핑을 사용하여 오류 탐지와 개발자 경험을 향상시키는 방법을 공유한다.
     * 저자는 강력한 타이핑에 대한 반론, 예를 들어 느린 개발 속도, 학습 곡선, 그리고 필요한 노력을 인정하지만, 이러한 도전을 상쇄하는 이점이 있다고 믿는다.
     * 저자는 소프트웨어 개발에서 강력한 타이핑의 가치에 대한 그의 확고한 믿음을 밝히며, 독자들이 이 주제에 대한 그들의 생각을 공유하도록 초대한다.

        Hacker News 의견

     * 프로그래밍 언어에서 강력한 정적 타이핑의 장단점에 대한 논의
     * 일부 댓글 작성자들은 논쟁이 경험적 증거보다는 개인적인 감정에 기반하고 있다고 주장하며, 버그 발생 빈도나 개발 속도 측면에서 정적 타이핑과 동적 타이핑 사이에 유의미한 차이를 찾지 못한 연구 결과를 들어냄
     * 정적 타이핑의 비평가들은 이것이 불필요한 복잡성을 초래하고 코드베이스 이해를 방해할 수 있다고 주장하며, 동적 타이핑이 더 간단하고 읽기 쉬운 코드를 장려한다고 제안함
     * 일부 댓글 작성자들은 TypeScript와 같은 언어에서 타입 시스템의 한계에 대해 불만을 표현하며, 이들은 여전히 런타임 버그를 허용하고 수동 검사를 필요로 한다고 주장함
     * 다른 사람들은 정적 타이핑이 타입 오류를 조기에 잡아내고 개발자가 타입에 대해 신중하게 생각하는 것을 줄여주어 개발을 가속화할 수 있다고 주장함
     * 소수의 댓글 작성자들은 정적 타이핑이 도메인 데이터 모델에 대한 이른바 구체화를 초래할 수 있으며, 이는 요구사항이 변경될 때 문제를 일으킬 수 있다고 제안함
     * 일부 댓글 작성자들은 정적 타이핑이 프로그램의 정확성을 보장하지 않으며, 오직 타입의 정확성만을 보장하며, 의미적 버그는 여전히 감지되지 않을 수 있다고 주장함
     * 정적 타이핑과 동적 타이핑 모두 자신의 위치를 가지고 있으며 많은 프로젝트에서 성공적으로 사용되었다는 것에 대한 합의가 있음. 그들 사이의 선택은 종종 개인적인 선호와 프로젝트의 특정 요구사항에 따라 달라짐
"
"https://news.hada.io/topic?id=11202","내 컴퓨터는 어디에서 시간을 가져오는가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         내 컴퓨터는 어디에서 시간을 가져오는가?

     * 컴퓨터의 시간 출처에 대한 논의, Network Time Protocol (NTP)에서 획득
     * 계층적인 NTP 시스템, Stratum 3 NTP 서버는 Stratum 2 서버로부터, Stratum 2 서버는 Stratum 1 서버로부터 시간을 얻음
     * Stratum 1 NTP 서버는 참조 시계, 주로 GPS 수신기로부터 시간을 얻음
     * GPS 시스템은 콜로라도의 Schriever Space Force Base로부터 시간을 얻음
     * Schriever Space Force Base는 현장에 위치한 US Naval Observatory Alternate Master Clock로부터 시간을 얻음
     * US Naval Observatory는 원자시계, International Earth Rotation Service (IERS), 그리고 International Bureau of Weights and Measures로부터 시간을 얻음
     * 파리 천문대에 기반을 둔 IERS는 지구의 회전에 대한 공보를 보내고, UTC를 지구 회전과 동기화하기 위해 윤초를 추가하거나 제거할 필요가 있는지를 알림
     * International Bureau of Weights and Measures는 세계의 국가 타이밍 실험실로부터 시간 측정을 수집하여 전세계 표준 UTC를 유지함
     * 시간의 SI 단위인 초의 정의는 세슘 원자의 양자 측정에 기반하며, 이는 1955년 Louis Essen과 Jack Parry가 만든 첫 세슘 원자시계에 의해 확립된 표준임
     * 원자시계 이전에는, 초의 정의는 천문학, 특히 지구의 축 주위 회전 및 태양 주위 궤도에 기반하였음
     * 컴퓨터가 시간을 Royal Greenwich Observatory로부터 얻지 않는다는 사실로 기사가 결론을 내림

        Hacker News 의견

     * NIST 무작위 비콘은 완전 엔트로피 비트 문자열을 생성하고 이를 60초마다 512비트 블록으로 게시하며, 이는 순서 번호가 매겨지고, 타임스탬프가 찍히며, 서명됩니다.
     * 정보의 형식은 슬라이드를 제거하고, 일관된 단락을 만들고, 중요한 이미지를 다시 삽입함으로써 개선될 수 있습니다.
     * NTP 풀은 NTP 서버의 자원봉사 그룹으로, 특히 오픈 소스 장치에 대한 일반적인 선택입니다.
     * 컴퓨터가 자동으로 시간을 동기화하도록 설정되지 않은 경우, 그것이 얼마나 빠르게 이동하는지 보여줄 수 있습니다.
     * DARPA는 Robust Optical Clock Network (ROCkN) 프로그램을 자금 지원하며, 이는 GPS 원자 시계보다 더 나은 타이밍 정확성과 홀드오버를 제공하는 작고 가벼운 광원자 시계를 만드는 것을 목표로 합니다.
     * 도구나 측정의 정밀도, 안정성 또는 신뢰성이 때때로 참조 자료를 초과할 수 있습니다.
     * 'Big Time'에 대한 의존성을 줄이기 위한 커뮤니티 유지 및 민주화된 시간 추적 표준에 대한 제안이 있습니다.
     * Raspberry Pi는 Stratum 1 NTP 서버를 실행하는 데 사용될 수 있습니다.
     * 시간 소스를 선택할 때는 주의가 필요하며, 부정확성은 인증 실패와 같은 문제를 일으킬 수 있습니다.
     * 시간 측정의 물리적 부분 (GPS 및 원자 시계 등)은 흥미롭지만, 홈 컴퓨터가 원격 시간 서버에서 보낸 패킷의 지연 시간을 어떻게 측정하는지 이해하는 것도 중요합니다.
"
"https://news.hada.io/topic?id=11165","VeraCrypt: Windows, Mac OS X, Linux를 위한 무료 오픈소스 디스크 암호화 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       VeraCrypt: Windows, Mac OS X, Linux를 위한 무료 오픈소스 디스크 암호화 기술

     * VeraCrypt는 Windows, Mac OS X, Linux와 호환되는 무료 오픈소스 디스크 암호화 소프트웨어입니다.
     * 이 소프트웨어는 IDRIX가 개발하였으며, TrueCrypt 7.1a를 기반으로 합니다.
     * VeraCrypt의 주요 기능은 파일 내에 가상 암호화 디스크를 생성하고, 전체 파티션 또는 저장 장치를 암호화하며, 자동적으로 실시간 암호화를 수행하는 것입니다.
     * VeraCrypt는 암호화 알고리즘에서 더 많은 반복을 사용하여 보안을 강화하며, 이로 인해 무차별 대입 공격에 대한 저항력이 향상됩니다.
     * 이 소프트웨어는 TrueCrypt에서 발견된 많은 취약점과 보안 문제를 해결합니다.
     * VeraCrypt는 PIM 기능을 통해 사용자 정의 반복을 허용하여 암호화 보안을 강화합니다.
     * 이 소프트웨어는 TrueCrypt 볼륨을 로드할 수 있으며, TrueCrypt 컨테이너와 비시스템 파티션을 VeraCrypt 형식으로 변환하는 옵션을 제공합니다.
     * VeraCrypt는 여러 업데이트를 출시하였으며, 최신 버전인 1.26.7은 주요 업그레이드와 향상된 보안, 특히 Windows를 위한 것을 제공합니다.
     * 이 소프트웨어는 다양한 언어를 지원하며, Apple M1 및 Raspberry Pi OS를 포함한 다양한 시스템과 호환됩니다.
     * VeraCrypt는 숨겨진 볼륨과 숨겨진 운영 체제 기능을 통해 합리적인 부인을 제공합니다.
     * 이 소프트웨어의 향상된 보안 조치는 암호화된 파티션의 열기에만 지연을 추가하며, 애플리케이션 사용 중에는 성능에 영향을 주지 않습니다.
     * VeraCrypt의 모든 출시 파일은 보안 검증을 위해 PGP 키로 서명됩니다.

        Hacker News 의견

     * 많은 사용자들이 TrueCrypt/VeraCrypt 및 암호화된 희소 번들/이미지를 포함한 다양한 암호화 체계를 시도했지만, Cryptomator가 기기 간 투명한 암호화로 인해 더 효과적이라고 판단했습니다.
     * Cryptomator는 사용자가 클라우드에 금고를 생성하고, 데이터를 저장하며, 다양한 기기에서 쉽게 접근할 수 있게 해줍니다. 일반 파일 탐색 API에 통합되어 사용자 경험을 방해하지 않습니다.
     * Cryptomator는 ""파일 당"" 암호화를 사용하여, 클라우드에서 큰 덩어리를 다운로드 받아 복호화할 필요를 없애, 더 빠르게 만듭니다.
     * Cryptomator는 오픈 소스이며 데스크톱에서는 무료이지만, 모바일 앱은 한 번의 비용이 필요합니다.
     * 일부 사용자들은 MP4 파일 내에 임베디드된 TrueCrypt/VeraCrypt 볼륨이 포함된 스테가노그래피 챌린지를 포함한 Capture The Flag (CTF) 챌린지에 참여했습니다.
     * VeraCrypt는 사용자들에게 ""금속"" SSD 속도와 뛰어난 성능으로 추천되며, 외부 HDD의 숨겨진 파티션과 함께 사용됩니다.
     * 일부 사용자들은 VeraCrypt와의 더 나은 Yubikey 통합을 원합니다.
     * Qt 기반 GUI를 선호하는 Linux 사용자들에게는 zuluCrypt가 추천됩니다. 이는 PLAIN dm-crypt, LUKS, TrueCrypt, VeraCrypt, Bitlocker 등 다양한 유형의 볼륨을 생성하고 잠금 해제할 수 있습니다.
     * 일부 사용자들은 TrueCrypt와 관련된 내부 이야기에 의문을 제기합니다.
     * 일반 Linux 사용자들은 Nautilus 또는 GNOME Disks에서 LUKS 볼륨과 유사하게 VeraCrypt 볼륨을 사용할 수 있습니다.
     * VeraCrypt는 더 나은 보안을 제공하지만, 비기술적인 사람들에게는 사용자 친화적이라고 보기 어렵습니다. Bitlocker는 간단한 인터페이스와 중앙 관리 복구 키로 인해 더 접근하기 쉽다고 봅니다.
     * 일부 사용자들은 수년 동안 VeraCrypt를 밀접하게 관찰하고 매우 유능한 옵션이라고 판단했지만, MBR/BIOS 대 UEFI 제한이 없었으면 좋겠다는 바람을 가지고 있습니다.
     * VeraCrypt의 Hidden OS 옵션은 점점 더 권장되지 않는 레거시 부팅 모드로 제한되어 있어, 이 기능의 미래 접근성에 대한 우려가 있습니다.
     * 일부 사용자들은 VeraCrypt가 완전히 감사되었는지, 또는 TrueCrypt와 유사하게 손상되었거나 백도어가 설치되었는지에 대해 의문을 제기합니다.
     * Mac 생태계로 이동한 사용자들은 Mac이 SSD 암호화를 제공하므로 VeraCrypt를 계속 사용할 필요성에 대해 의문을 제기합니다.
"
"https://news.hada.io/topic?id=11191","일런 머스크의 X에 대한 계획: 쇼핑과 스포츠","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       일런 머스크의 X에 대한 계획: 쇼핑과 스포츠

     * 일런과 새 CEO 린다 야카리노는 X를 쇼핑 데스티네이션으로 만들고 싶어함
     * 이커머스의 X 관리자들이 X 사용자들에게 원클릭 체크아웃 링크를 DM으로 보낼수 있도록하고, 크리에이터가 제품 구매 링크를 팔로어에게 직접 보내는 것도 가능
     * 라이브 쇼핑을 통합하는 것도 논의중
     * NFL 리그와 오랜 계약을 통해 스포츠 클립을 운영중. 클립전에 광고를 보여주는 것은 매출이 늘어나고 있음. X의 광고 사업중 전망이 밝은 분야중 하나
     * 야카리노는 스포츠 비디오를 더 확장할 계획
          + NASCAR/NBA 와 만나서 논의했음
          + 일런의 트위터 인수전에 번성했던 광고 프로그램인 Twitter Amplify를 부활시키려는 계획의 일환
     * 하지만 트위터는 지난 1년간 직원의 80%를 해고했지만 여전히 적자
          + 야카리노는 지난주 CODE 컨퍼런스에서 BEP에 근접했으며, 2024년에는 수익을 낼 수 있을것이라고 말함
     * 쇼핑의 경우는 광고/스팸 이슈가 있겠지만, Amplify 부활계획은 성공 가능성이 더 큼
     * 물론, 광고주들이 X를 광고채널로 인식하는 것은 별도의 이야기. 현재는 많은 이슈들 때문에 광고주가 X를 광고 채널로 원하는 경우가 거의 없다고
"
"https://news.hada.io/topic?id=11208","Ask GN: 슬랙 GeekNews 봇에서 GN+ 를 제외하는 방법이 있을까요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Ask GN: 슬랙 GeekNews 봇에서 GN+ 를 제외하는 방법이 있을까요?

   안녕하세요, GeekNews 챗봇에서 항상 업계 최신 소식 감사하게 받아보고 있습니다.

   최근에 GN+ 의 소식도 추가되어 더 다양한 뉴스를 빠르게 접할 수 있게 되어서 기쁘게 사용하고 있는데요,

   저희는 GeekNews 만의 채널을 분리해서 사용하고 있는데, 아직은 사람이 정리한 글과 AI가 요약한 글의 품질 차이가 뚜렷하다보니 AI가 요약한 글을 주로 올리는 다른 채널로 분리해내고 싶은 수요가 있습니다.

   혹시 다른 GeekNews 구독자분들께서는 이런 수요가 없으셨는지, 있으셨다면 어떻게 해결하셨는지 여쭙고자 글을 작성합니다.

   한국은 슬슬 추워지는데 다들 환절기 건강 조심하시고 즐거운 가을 되시길 바랍니다 ㅎㅎ

   GN+에 있는 글의 경우, 전체가 아니라 일부 괜찮은 글만 Moderator가 검수한 뒤에 슬랙Bot 등의 소셜 채널로 공유가 됩니다.
   그래서 작성 시점과 공유된 시점이 달라서 최신글에는 정렬이 안된 것 처럼 보이기도 합니다.
   요약 품질의 이슈는 계속 개선해 보겠습니다.

   항상 서비스 너무 감사히 이용하고 있습니다. 저희도 회사 관련 키워드로 뉴스를 검색해서 봇이 요약해서 채널에 올리게 하고 있는데, 구현 과정에서 GPT3.5에서 GPT4 로 바꾸니 품질이 훨씬 나아졌었습니다. GN+ 의 설명에서 보았는데 나중에 GPT4가 열리면 한 번 비교해보셔도 좋을 것 같아요. 커뮤니티에 큰 기여해주셔서 정말 감사합니다.

   흑 이미 GPT-4 로 반영되어 있긴 한데요. 프롬프트 엔지니어링이 좀 더 필요할듯 합니다 ㅎㅎ

   저도 비슷하게 느끼고 있었는데 그냥 적응했습니다.
   예전에는 AI 가 요약한 글들은 그냥 걸렀는데 요즘은 GN+ 에 들어가서 따로 찾아보기도 합니다. 볼만한 것들이 종종 있더라고요.

   다른 이야기이지만, 저는 주로 ""최신글"" 에서 최근에 올라온 것들을 보는데 정렬이 가끔씩 안되는지 아니면 다른 이유가 있는지 모르겠지만 이전에 봤을땐 없었던 글들이 중간중간 새로 작성된 경우가 보이더라고요.

   제가 적응할 시간이 부족했던 것일 수도 있네요. 생각해보면 컨텐츠가 다양해지는 것도 좋을 것 같아요. 감사합니다 ㅎㅎ
"
"https://news.hada.io/topic?id=11250","프로그래밍 40년의 역사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             프로그래밍 40년의 역사

     * 저자인 Fabien Sanglard는 40년 동안 프로그래밍을 해 왔으며, 그 중 절반은 전문적으로 활동하였습니다.
     * 그는 104 키보드, 평평한 마우스, 앉아서 사용하는 책상이 포함된 ""표준"" 설정을 사용하였습니다.
     * 10년 전, 그는 프로그래밍을 할 때 팔과 어깨에 통증을 느꼈습니다.
     * 이 문제를 해결하기 위해, 그는 Evoluent VerticalMouse 4와 같은 수직 마우스를 사용하기 시작했습니다.
     * 그는 나중에 Apple의 Magic Trackpad를 선택했는데, 이는 세 손가락으로 작업 공간을 전환하거나 확대/축소하는 등의 기능이 훌륭했습니다.
     * 그는 KINESIS Freestyle2와 Advantage2를 포함한 다양한 인체공학 키보드를 시도했지만, Ergodox EZ가 그에게 가장 잘 맞는 것으로 판단하였습니다.
     * Ergodox EZ는 그에게 모든 세 축에서 손목을 휴식 상태로 유지할 수 있게 해주어, 통증 없이 하루 종일 프로그래밍을 할 수 있게 하였습니다.
     * 그는 또한 DROP Carbon 키캡, pexonpcs.co.uk의 맞춤형 케이블, Brown Gateron G Pro로 Ergodox EZ를 개인화하였습니다.
     * 손과 손목의 움직임을 최소화하기 위해, 그는 대부분의 에디터에서 VIM 모드를 사용하여 마우스 없이 프로그램을 탐색할 수 있게 하였습니다.
     * 그는 자세를 개선하기 위해 모터화된 서서 작업하는 책상을 만들었고, 하루 동안 앉아서 일하는 것과 서서 일하는 것을 번갈아 가며 하였습니다.
     * 그는 Wall Angel 스트레칭을 정기적으로 하여 휴식을 취하고, ""움직이는 명상""이라고 묘사하는 암벽 등반을 통해 스트레스를 관리하였습니다.

        Hacker News 의견

     * 댓글 작성자는 반복적인 움직임으로 인한 문제를 피하기 위해 가능한 한 모든 것을 다양하게 하고 마우스, 트랙볼, 트랙패드와 같은 다른 입력 방법을 사용하는 것을 권장합니다.
     * 프로그래밍은 타이핑보다 생각하는 것이 더 많으므로 표준 기계식 키보드를 사용하고 핫키를 사용하기 위해 손을 지속적으로 비틀어야 하는 에디터/IDE를 피하는 것을 제안합니다.
     * 코드의 가시성을 높이기 위해 큰 모니터를 사용하고, 등 문제를 피하기 위해 ""불안정한 의자""를 사용하는 것을 권장합니다.
     * 댓글 작성자는 손에 가해지는 부담을 줄이기 위해 사용자 정의 가능한 음성 코딩 도구인 Talon Voice를 사용하는 것을 제안합니다.
     * 다른 댓글 작성자는 관절 통증을 피하기 위해 키보드 중심의 환경을 포기하고 마우스 중심의 환경을 선택하는 것을 제안합니다.
     * 한 댓글 작성자는 자신이 앉아 있지 못하고 계속해서 앉은 자세를 바꾸는 데 그들의 관절 통증 부재를 돌리고 있습니다.
     * 댓글 작성자는 40년 동안의 프로그래밍 경력의 장수를 칭찬하며, 이는 지속적으로 향상시키고 배울 수 있는 분야라고 주장합니다.
     * 컴퓨터 입력의 가장 인체공학적인 방법으로 속기가 제안되며, 댓글 작성자는 속기 학습을 위해 Plover와 Javelin을 추천합니다.
     * 팔목 통증을 관리하기 위해 분할 키보드와 CTRL, SHIFT, ALT에 프로그램된 풋 페달 사용을 권장합니다.
     * Vim 초보자에게는 불편함을 피하기 위해 Esc 키를 더 접근하기 쉬운 키로 재매핑하는 것이 좋습니다.
     * 댓글 작성자는 프로그래밍의 긴 시간 동안 편안한 앉은 자세와 책상 높이를 갖는 것의 중요성을 강조합니다.
     * 단축키를 활성화할 때 불편함을 피할 수 있도록 도와주는 자주 무시되는 기능으로 스티키 키가 권장됩니다.
"
"https://news.hada.io/topic?id=11190","그래프 마이닝 라이브러리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             그래프 마이닝 라이브러리

     * 본문은 Google Graph Mining 팀이 개발한 도구들을 포함하는 프로젝트인 Graph Mining Library에 대해 논의합니다.
     * 이 도구들은 그래프 구조를 본질적으로 가지거나 그래프 문제로 공식화 될 수 있는 데이터 마이닝 및 머신 러닝 문제를 해결하기 위해 설계되었습니다.
     * 이 라이브러리는 수십억 개의 에지를 가진 그래프를 처리할 수 있는 공유 메모리 병렬 클러스터링 알고리즘을 포함하고 있습니다.
     * 이 알고리즘들은 ""Poly-Logarithmic Depth에서의 Hierarchical Agglomerative Graph Clustering"", ""Parallel correlation clustering을 통한 Scalable community detection"", ""Affinity Clustering: Hierarchical Clustering at Scale"", 그리고 ""Distributed Balanced Partitioning via Linear Embedding"" 등 여러 연구 논문을 기반으로 합니다.
     * 각 논문과 관련된 저장소의 특정 섹션에 대한 링크가 제공됩니다.
     * 질문이나 의견이 있을 경우, 사용자들은 저장소에 이슈를 생성하도록 권장됩니다.
     * 본문은 또한 Bazel을 설치하고 예제를 실행하는 방법을 안내하는 빠른 시작 가이드를 제공합니다.

        Hacker News 의견

     * 소셜 네트워크의 부상과 함께 그래프 마이닝이 10년 전에 인기를 끌었습니다.
     * 기하학적 학습, 그래프와 다른 구조에서의 머신러닝 형태, 또한 잠재 디리클레 할당 모델(LMMs)이 더욱 널리 퍼지기 전까지 인기가 있었습니다.
     * 데이터베이스 시스템인 Arangodb는 NetworkX, DeepGraphLibrary, cuGraph, PyG 등 다양한 그래프 라이브러리와 머신러닝 프레임워크와의 통합을 포함합니다.
     * 소프트웨어 빌딩과 테스팅을 자동화하는 도구인 Bazel을 사용하여 라이브러리를 어떻게 구축하는지에 대한 질문이 있습니다.
     * 라이브러리는 그래프 기반 클러스터링 알고리즘을 통합하기 위해 래퍼 또는 확장 라이브러리와 통합될 수 있습니다.
     * 대규모 그래프 처리 시스템인 Pregel과 라이브러리의 관계에 대한 질문이 있습니다.
     * 라이브러리의 잠재적인 용도와 응용 예제에 대한 설명 요청이 있습니다.
     * 라이브러리는 C, C++, Starland로 작성되었으며, Starland이 무엇인지에 대한 질문이 있습니다.
     * Basic Linear Algebra Subprograms (BLAS) 및 Linear Algebra Package (LAPACK)와 유사하게 그래프 알고리즘에서의 표준화를 요구하는 목소리가 있습니다.
     * 일부는 라이브러리가 이상 탐지를 위한 통계 그래프 마이닝에 사용될 수 있기를 희망했습니다.
"
"https://news.hada.io/topic?id=11245","SlowLlama - Llama2-70b 와 CodeLLama를 M1/M2에서 양자화없이 파인튜닝","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         SlowLlama - Llama2-70b 와 CodeLLama를 M1/M2에서 양자화없이 파인튜닝

     * 애플 M1/M2 및 소비자용 nVidia GPU에서 LLama2-70B 같은 모델을 파인튜닝
     * 양자화(quantization)를 사용하는 대신, 포워드/백워드 패스 모두에서 모델의 일부를 SSD또는 메인 메모리로 오프로드 하는 방식
     * 현재 버전을 LoRA를 사용하여 업데이트를 더 작은 매개변수 셋으로 제한
          + 첫번째 버전은 전체 파인튜닝도 가능했지만 지금은 제거
"
"https://news.hada.io/topic?id=11255","아이폰용 Blackmagic 카메라","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          아이폰용 Blackmagic 카메라

     * Blackmagic Camera, 아이폰을 위한 디지털 필름 소개, 전문 디지털 필름 카메라 컨트롤 및 이미지 처리 제공
     * 이 앱은 사용자가 할리우드 특징 영화와 유사한 '시네마틱' 룩을 만들 수 있게 해줍니다.
     * 사용자는 프레임 속도, 셔터 각도, 화이트 밸런스, ISO 등의 설정을 한 번의 탭으로 조정할 수 있습니다.
     * 이 앱은 최대 4K까지의 업계 표준 10비트 Apple ProRes 파일로 Blackmagic Cloud에 직접 녹화를 허용합니다.
     * Blackmagic Camera는 시네마틱 룩과 방송 품질의 ENG로 YouTube 및 TikTok 콘텐츠를 만드는 데 적합합니다.
     * 이 앱은 상태 및 녹화 매개변수를 보여주는 헤드업 디스플레이(HUD), 히스토그램, 포커스 피킹, 레벨, 프레임 가이드 등을 포함한 빠른 설정을 위한 대화식 컨트롤을 포함합니다.
     * 이 앱은 16:9 또는 수직 비율로 촬영을 허용하며, 미디어 관리를 위한 탭을 포함하여 Blackmagic Cloud에 업로드합니다.
     * 사용자는 전화 저장소에 녹화하거나, DaVinci Resolve에 녹화하거나, Blackmagic Cloud를 통해 선택한 클립을 업로드할 수 있습니다.
     * Blackmagic Camera는 Blackmagic Cloud 프로젝트 멤버들이 촬영에 대해 의사소통하고 창의적인 아이디어를 공유할 수 있는 내장된 채팅 작업 공간을 포함합니다.
     * 이 앱은 App Store에서 무료로 다운로드할 수 있습니다.

        Hacker News 의견

     * 아이폰 카메라와 Blackmagic 앱의 영상을 나란히 비교하는 데 사용자들이 관심을 보임
     * Blackmagic의 명성과 앱의 무료 이용 가능성이 긍정적인 점으로 여겨지며, 사용자들이 영화 학생들에게 추천
     * 앱이 비디오 녹화에서 전문적이고 시네마틱한 '룩'을 어떻게 만드는지에 대해 사용자들이 궁금해함
     * 채팅 기능이 앱에 포함된 것에 대한 비판이 있으며, 사용자들이 이를 불필요하고 자원 낭비로 여김
     * 전화의 자동 회전 설정이 꺼져 있어도 앱이 기본적으로 회전하고 가로로 촬영하도록 사용자들이 요청
     * 앱이 카메라 제조업체에게 전진적인 전략으로 여겨지며, 아이폰 카메라의 인기를 인정
     * 사용자들이 애플이 카메라의 이러한 제어를 허용하는 것에 놀라며, 이것이 API를 통한 것인지 직접 하드웨어 접근을 통한 것인지 의문을 제기
     * 사용자들이 앱 사용법에 대한 튜토리얼이나 지침을 찾고 있음
     * 앱의 ISO 설정에 대한 질문이 있으며, 이들이 정확하게 표현되는지 여부에 대해 의문을 제기
     * 사용자들이 앱의 출력을 OBS에 직접적으로 공급하여 실시간 방송하는 간단한 방법을 원함
"
"https://news.hada.io/topic?id=11203","HTTP/3 채택이 빠르게 증가하고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         HTTP/3 채택이 빠르게 증가하고 있음

     * 하이퍼텍스트 전송 프로토콜(HTTP)은 인터넷의 기본적인 부분으로, 웹 페이지를 로드하고, 비디오를 스트리밍하고, 앱을 위한 데이터를 가져오는 데 사용
     * HTTP/3는 지난해 인터넷 엔지니어링 작업 그룹(IETF)에 의해 표준화됨
     * HTTP/3와 관련된 QUIC 프로토콜은 공개 웹에서 빠르게 채택되었음
     * HTTP/3 지원은 출처와 측정방법에 따라 다르지만 전 세계 웹 서버와 네트워크에서 19% ~ 50% 이상이 지원중
     * 구글과 메타와 같은 대형 기업들은 이러한 새로운 프로토콜을 많이 사용하며, 이는 현재 인터넷 트래픽의 상당 부분이 HTTP/3를 사용함을 의미
     * HTTP/3는 여러 문제를 해결하고 이전 버전보다 성능이 뛰어나므로 빠르게 채택됨
     * 네트워크 프로토콜은 웹용으로 제작된 다양한 소프트웨어 간의 상호 운용성을 보장하기 위해 표준화되어야 함
     * 인터넷의 원래 프로토콜은 80년대와 90년대에 표준화되었으며, 그 당시의 목표와 제한 사항을 염두에 두고 제작됨
     * 인터넷을 통해 데이터를 신뢰성 있게 전송하는 데 사용되는 전송 제어 프로토콜(TCP)은 나이가 들어 교체가 필요하게 됨
     * QUIC 프로토콜은 TCP를 대체하며, 중요한 변화와 함께 동일한 고급 기능을 많이 포함
     * QUIC은 웹의 민감한 데이터를 암호화하는 전송 계층 보안(TLS) 프로토콜과 밀접하게 통합
     * QUIC은 TCP보다 더 광범위하게 암호화되어, 새로운 기능을 변경하거나 추가하는 것을 용이하게 하며, 미래에도 적합한 프로토콜
     * QUIC은 또한 TCP에 비해 많은 보안 관련 기능과 효율성 및 성능 향상을 포함
     * HTTP/3는 HTTP/2와 거의 동일하지만, QUIC의 새로운 기능을 모두 사용할 수 있는 능력 때문에 웹 페이지를 로드하고 비디오를 스트리밍하는 데 더 효과적일 것으로 예상
     * QUIC 또는 TCP 위에 기능을 기술적으로 구현하는 것이 HTTP/3와 HTTP/2 사이의 주요 차이점
     * 저자인 로빈 마르크스는 아카마이의 웹 프로토콜 및 성능 전문가

   궁금해서 찾아봤네요.
   퀵 udp 인터넷 커넥션의 약자 였군요.

        Hacker News 의견

     * 중국 사용자들이 QUIC 프로토콜의 낮은 지연 시간과 높은 처리량을 칭찬하며, 이를 중국의 방화벽 우회에 효과적이라고 평가.
     * QUIC는 종단 간 암호화 및 인증 채널을 제공하며, 병렬 및 양방향 통신을 위한 여러 스트림 전송 가능.
     * QUIC 위의 프로토콜인 HTTP/3는 qpack 헤더 압축과 같은 기능을 도입하여 일반적으로 사용되는 헤더 값을 작게 압축.
     * 웹사이트를 로드하기 위해 지속적인 연결을 유지하는 TCP와 HTTP/1의 역할에 대한 혼란이 있음.
     * 기업 IT 관행이 QUIC를 차단할 수 있으며, 이로 인해 TCP로 전환되어 사용자 경험에 영향을 줄 수 있음.
     * 일부 사용자들은 커널이 데이터 패킷을 서버가 처리할 수 있는 스트림으로 조립하는 방법과 같은 기본 네트워킹 개념에 대한 이해가 부족하다고 표현.
     * HTTP/3의 채택률이 두 해 동안 약 27%로 증가하였으며, 2021년 중반과 2022년 7월에 두 차례의 큰 증가가 있었음.
     * QUIC의 CPU 바인딩 특성으로 인해 고처리량 사용 사례에서의 성능이 TCP+TLS에 비해 제한될 수 있다는 의문이 제기되었음.
     * HTTP/3를 구현하고 지원하는 복잡성으로 인해 그 채택이 이를 감당하고 이익을 얻을 수 있는 인터넷 거인들로 제한될 수 있음.
     * HTTP/3는 아직 nginx와 같은 일부 웹 서버에서 실험적으로 간주됨.
     * 모든 웹 콘텐츠가 HTTP/3를 통해 로드되는 것은 아니며, 일부 서드파티 리소스인 captcha 스크립트 등이 이 프로토콜을 사용함.

   중국 사용자들이 방화벽 우회를 잘한다고 높게 평가하는거면 보안 프로토콜 쪽은 꽤 신뢰가 가네요
"
"https://news.hada.io/topic?id=11172","이상한 A.I. Yankovic: 음성 복제 세계로의 저주받은 깊은 탐구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                이상한 A.I. Yankovic: 음성 복제 세계로의 저주받은 깊은 탐구

     * 기사는 A.I. 음성 복제를 사용하여 Weird Al Yankovic의 원래 노래를 다른 아티스트가 커버한 것처럼 재현하는 것에 대해 논의합니다.
     * 저자는 Michael Jackson의 목소리로 Weird Al의 노래 ""Eat It""을 커버하는 실험을 했으며, 원래의 피치에 맞게 조정했습니다.
     * 저자는 또한 다른 아티스트의 A.I. 음성 모델을 사용해 보려 했지만, Weird Al의 독특한 목소리와 발음이 그의 보컬을 설득력 있게 대체하는 것을 어렵게 만들었습니다.
     * A.I. 커버 노래 커뮤니티는 A.I. Hub라는 Discord 서버를 중심으로, 회원들이 팁, 기법, 그들이 훈련시킨 음성 모델을 공유합니다.
     * 음성 모델은 Hugging Face라는 A.I. 스타트업에서 호스팅되며, 이 회사는 8월에 시리즈 D 라운드에서 2억3500만 달러를 모집하고, 45억 달러로 평가 받았습니다.
     * 미국 녹음 산업 협회(RIAA)는 음성 모델을 훈련시키는 데 사용된 저작권이 있는 노래를 업로드한 A.I. Hub를 대상으로 삼았지만, A.I. 모델 자체에 대해서는 조치를 취하지 않았습니다.
     * 저자는 또한 Madonna와 Kurt Cobain의 A.I. 음성 모델로 Weird Al의 노래를 커버하는 실험을 했으며, 성공 정도는 다양했습니다.
     * Google Colab은 생성적 A.I. 워크플로를 실행하는 데 유용한 도구로 언급되며, 특히 호환 가능한 GPU가 없거나 터미널에 익숙하지 않은 사람들에게 유용합니다.
     * 저자는 기존 모델에서 A.I. 커버를 생성하는 과정을 단순화하는 AICoverGen 패키지를 사용했습니다.
     * 기사는 또한 노래 음성 합성(SVS)과 노래 음성 변환(SVC)의 빠른 발전에 대해 언급하며, 이는 곧 다른 사람의 스타일로 작성된 가사에서 새로운 노래를 생성하는 것을 가능하게 할 수 있습니다.
     * 저자는 A.I. 음성 복제를 사용하는 것의 윤리적, 법적 함의에 대해 논의하며, 일부 아티스트는 이에 대해 흥분하고, 다른 일부는 반대한다고 지적합니다.
"
"https://news.hada.io/topic?id=11219","Bruno - API 테스팅을 위한 오픈소스 IDE","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Bruno - API 테스팅을 위한 오픈소스 IDE

     * Postman/Insomnia 의 경량 대체제
     * API 리퀘스트 관련 정보를 파일시스템의 폴더에 플레인 마크업 텍스트로 저장하여 Git에 저장 가능
     * 오프라인 온리 클라이언트, 클라우드 동기화 기능등은 개발할 예정 없음
     * 멀티 플랫폼 지원(데스크탑 앱, CLI, VSCode 확장)

   Postman의 대안이라고 나온 게 많았는데, 실질적인 대안을 아직 찾지 못했는데...

   한 번 살펴봐야겠네요. git 동기화가 되는 건 마음에 듭니다.
"
"https://news.hada.io/topic?id=11169","Meta, 32k 토큰의 컨텍스트 윈도우를 지원하는 LLAMA 2 Long 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Meta, 32k 토큰의 컨텍스트 윈도우를 지원하는 LLAMA 2 Long 공개

     * 파운데이션 모델의 효과적인 장기 컨텍스트 확장(Effective Long-Context Scaling of Foundation Models)이라는 논문을 통해 LLaMA2 Long 모델을 공개
          + 논문 링크: https://arxiv.org/pdf/2309.16039.pdf
     * 컨텍스트 윈도우(context window)의 길이가 32K(32,768) 토큰까지 지원
     * 70B 버전은 이미 긴 컨텍스트 작업 모음에서 gpt-3.5-turbo-16k의 전체 성능을 능가
     * 기존 모델 구조는 유지하면서, 위치 인코딩(Positional Encoding)에 RoPE(Rotary Positional Embedding)을 적용하여 적은 정보로 더 나은 응답 생성
          + RoPE 설명: https://blog.eleuther.ai/rotary-embeddings/
"
"https://news.hada.io/topic?id=11159","2023년에 모든 소프트웨어 개발자가 알아야 할 Unicode에 대한 정보","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               2023년에 모든 소프트웨어 개발자가 알아야 할 Unicode에 대한 정보

     * 20년전 Joel은 ""Plain Text 라는 것은 없다"" 라며, 인코딩을 꼭 알아야 한다고 강조함
     * 유니코드는 모든 인간의 언어를 컴퓨터에서 사용할 수 있도록 통합하는 표준
     * 각기 다른 문자에 고유한 번호를 할당하는 코드 포인트 시스템
     * 가장 큰 코드 포인트는 0x10FFFF로, 약 110만 개의 코드 포인트 공간 제공
     * UTF-8은 가장 일반적인 인코딩으로, 98%의 확률로 사용됨
     * UTF-8은 가변 길이 인코딩으로, 코드 포인트는 1~4바이트의 시퀀스로 인코딩될 수 있음
     * UTF-8은 ASCII와 바이트 호환성이 있으며, 기본 라틴어에 대해 공간 효율적임
     * UTF-8은 내장된 오류 탐지 및 복구 기능을 가지고 있어, 완전하고 유효한 UTF-8 바이트 시퀀스를 식별할 수 있음
     * 확장 그래피엠 클러스터 또는 그래피엠은 코드 포인트가 아닌 반복되어야 하는 단위임
     * 유니코드는 매년 업데이트되며, 그래피엠 클러스터를 정의하는 규칙이 매년 변경됨
     * 유니코드는 로케일에 따라 다르게 렌더링될 수 있음
     * 유니코드의 서로게이트 페어는 단일 유니코드 코드 포인트를 인코딩하는 데 사용되는 두 개의 UTF-16 단위임
     * UTF-16은 일부 시스템에서 메모리 내 표현으로 여전히 사용됨
     * 유니코드 문자열은 비교하기 전에 정규화되어야 함
     * 기사는 strlen, indexOf, substring과 같은 기본적인 연산조차도 유니코드 라이브러리를 사용하는 것의 중요성을 강조함

   ""‍♂️"".length 의 경우 Python3.11 에서는 1 을 반환하네요.

   이모지가 댓글에 깨져서 나오네요

        Hacker News 의견

     * 본 기사는 유니코드의 복잡성과 소프트웨어 개발에서의 활용 방법에 대해 논의한다.
     * 한 댓글 작성자는 ""확장 그래피 클러스터""가 유니코드의 문자를 생각하는 최선의 방법이라는 기사의 주장에 동의하지 않으며, ""문자""의 정의가 그것이 의도된 사용에 따라 달라질 수 있다고 주장한다.
     * 댓글 작성자는 문자열 반복이 유니코드가 작동하는 기본 수준인 코드포인트에 기반해야 한다고 제안한다.
     * 다른 댓글 작성자는 기사를 칭찬하고 ""fi"" 리가튀어가 자체 코드 포인트를 가진 이유에 대한 저자의 질문에 대답하며, 이는 유니코드의 원형 복원 호환성 원칙 때문이라고 설명한다.
     * 한 댓글 작성자는 페이지를 읽는 동안 화면에 여러 마우스 포인터가 보이는 것에 대해 불평한다.
     * 다른 댓글 작성자는 사용자가 여러 언어를 읽고 쓸 수 있을 때 컴퓨터의 로케일을 설정하는 도전과 리눅스가 윈도우에 비해 사용자 정의 옵션이 부족하다는 비판을 논의한다.
     * 한 댓글 작성자는 강조 문자가 처리되는 방식 때문에 제3자 시스템에 대한 사용자 입력을 정화하는 데 문제를 겪었던 이야기를 공유한다.
     * 다른 댓글 작성자는 코드 포인트가 작동하는 최선의 단위가 아니라는 기사의 주장에 반박하며, 코드 포인트에서 작동하는 많은 상황이 있다고 주장한다.
     * 한 댓글 작성자는 ""é""가 유니코드에서 어떻게 인코딩되는지에 대한 기사의 예시를 비판하며, 이는 오해를 불러일으키고 일반적으로 문자가 인코딩되는 방식을 대표하지 않는다고 주장한다.
     * 다른 댓글 작성자는 중국어, 일본어, 한국어 로고그램이 동일한 코드 포인트에 할당되는 문제를 논의하며, 시스템 로케일이 중국어가 아닌 경우 윈도우에서 중국어 파일 이름의 렌더링이 나쁘게 되는 것을 이끈다.
     * 한 댓글 작성자는 페이지에 마우스 커서 효과가 있음에 혼란스럽고 짜증이 난다.
"
"https://news.hada.io/topic?id=11243","Patreon과 경쟁하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Patreon과 경쟁하는 방법

        Hacker News 의견

     * Patreon이라는 창작자를 재정적으로 지원하는 플랫폼 개념에 대한 기사
     * Patreon이 누군가의 여분으로 재정 지원되는 창작자들을 위한 기본 소득 형태로 보는 시각
     * Patreon이 부드러운 NSFW 콘텐츠를 합법적인 결제를 통해 수익화하는 독특한 플랫폼으로 보는 사용자들
     * Patreon 계정을 이미 가지고 있는 편리함이 결제 정보를 가진 회사의 수를 제한하려는 일부 사용자들에게 주요 판매 포인트
     * Patreon의 인터페이스와 수수료율에 대한 비판에도 불구하고, 사용자들은 대안을 찾는데 열성적이지 않음
     * 처리 수수료를 전가하지 않고 5% 수수료 이하로 Patreon과 같은 플랫폼을 구축하고 유지하는 것에 대한 회의론
     * Patreon이 결제를 묶는 것을 중단한 결정이 사기 탐지 및 예방과 관련이 있다는 추측
     * 디지털 창작자들을 위한 작품별 결제 모델이 고액 고객 부족과 수요 제한 때문에 실행 가능하지 않다는 주장
     * 창작자들이 익명성을 원하는지에 대한 의견 차이, 익명 플랫폼이 탈세와 돈세탁을 초래할 수 있다는 주장
     * 경쟁사를 위한 API를 개방하는 아이디어에 대한 의문, 일부 사용자들이 그러한 움직임의 이점을 의심
     * Patreon 대안으로 BTC lighting 결제와 podcasting 2.0 운동 언급
     * Patreon이 창작자들에게 제공하는 것의 자체 호스팅 버전에 대한 관심, 일부 사용자들이 무료 대안을 개발 중
     * 마이크로 결제, 사기, 그리고 대안적인 거래 모델에 대한 주제가 향후 기사의 논의 포인트로 제안됨
"
"https://news.hada.io/topic?id=11277","공정한 동전은 시작했던 면으로 착지하는 경향이 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      공정한 동전은 시작했던 면으로 착지하는 경향이 있음

     * Persi Diaconis가 개발한 인간의 동전 던지기에 대한 물리학 모델을 테스트한 연구에 대한 기사
     * 모델은 사람들이 일반적인 동전을 던질 때, 시작했던 쪽으로 착륙하는 경향이 있으며, 같은 쪽으로 결과가 나올 확률은 약 51%로 예측한다.
     * 연구는 350,757번의 동전 던지기 데이터를 수집하고 이 예측에 대한 강력한 지지를 발견했으며, 동전이 더 자주 같은 쪽으로 착륙했다 (같은 쪽 확률 = 0.508).
     * 데이터는 이 같은 쪽 편향의 정도에서 사람들 사이에 상당한 차이를 보여준다.
     * 연구는 또한 사람들이 초기 면을 무작위로 결정하여 일반적인 동전을 던질 때, 앞면 또는 뒷면으로 착륙할 확률이 동일하다는 것을 확인했다 (앞면 확률 = 0.500).
     * 앞면-뒷면 편향의 부재는 동전 간에 차이가 없어 보인다.
     * 연구는 일부 (하지만 모든 사람들이 아닌) 사람들이 공정한 동전을 던질 때, 그것이 시작했던 쪽으로 착륙하는 경향이 있다는 강력한 증거를 제공한다.
     * 데이터는 Diaconis의 동전 던지기에 대한 물리학 모델에 대한 강력한 통계적 지지를 제공한다.

        Hacker News 의견

     * 해당 기사는 공정한 동전이 시작했던 면과 같은 면으로 더 자주 떨어지는지를 결정하기 위해 350,757번의 동전 던지기 데이터를 수집한 연구를 논의합니다.
     * 연구에서는 ""같은 면"" 편향에 대한 증거를 발견했으며, 평균 추정치는 50.8%였습니다.
     * 48명의 동전 던지기 참가자들 사이에서 편향이 달랐으며, 표준 편차는 1.6%였습니다.
     * 참가자들 사이의 ""불안정성"" 정도의 차이로 인해 변동이 있을 수 있습니다.
     * 동전 던지기의 시작 위치를 알고 있다면, 동전 던지기 결과에 1달러를 1000번 걸 경우 평균적으로 19달러를 벌 수 있습니다.
     * 연구의 원고는 arXiv에, 그리고 개방 데이터, 코드, 비디오 녹화는 OSF에 공개되어 있습니다.
     * 일부 댓글들은 높은 횟수의 동전 던지기로 인해 던지는 사람들이 사용한 물리적 행동과 힘에서 변동성이 줄어들었을 수 있으므로, 실험이 '정상적인' 동전 던지기를 대표하지 않을 수 있다고 제안합니다.
     * 한 댓글에서는 동전 던지기의 결과가 시작 상태에 크게 의존한다고 제안합니다.
     * 다른 댓글에서는 Von Neumann이 설명한 편향된 동전에서 공정한 결과를 얻는 방법을 언급하며, 이 방법은 동전을 두 번 던지고 두 번의 결과가 다르면 첫 번째 결과를 사용하는 것입니다.
     * 일부 댓글들은 관찰된 편향의 메커니즘을 논의하며, 이는 세로 회전축의 방향이 동전의 궤적을 따라 변화하는 선행으로 인해 발생할 수 있다고 제안합니다.
     * 다른 댓글들은 주어진 편향으로 새로운 동전 던지기를 생성하는 방법과 동전 던지기에 편향을 주는 방법을 논의합니다.
"
"https://news.hada.io/topic?id=11228","Show HN: 오래된 태블릿을 추가 모니터로 사용하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Show HN: 오래된 태블릿을 추가 모니터로 사용하기

     * 기사는 터미널 사용을 위해 오래된 태블릿을 추가 모니터로 사용하는 방법에 대해 논의합니다.
     * 저자는 이 목적을 위해 오래된 Kindle Fire 태블릿을 사용하고, Android SSH 클라이언트를 사용하여 컴퓨터에 연결했습니다.
     * 저자는 태블릿에 직접 입력할 수 있게 해주는 프로그램을 만들었으며, 이로 인해 실제 터미널처럼 느껴집니다.
     * 저자는 모바일 앱에 전체 컴퓨터 접근 권한을 부여하거나 공공 네트워크를 사용할 때 컴퓨터를 해커에게 노출시키는 등의 잠재적 보안 위험을 인정합니다.
     * 저자는 xterm.js를 사용한 대안적 접근법을 제안하며, 이를 통해 터미널이 웹 브라우저에 표시되고 문자가 웹 소켓을 통해 전송될 수 있습니다.
     * 저자는 컴퓨터에서 SSH를 활성화하고, 타이핑 프로그램을 설치 및 실행하고, SSH 세션이 열릴 때마다 타이핑 프로그램을 시작하는 서비스를 만드는 등, 그들의 방법에 대한 자세한 설정 가이드를 제공합니다.
     * 저자는 제어 문자를 삽입하는 데 어려움이 있거나 일부 오래된 장치에 대한 터미널 클라이언트를 찾는 등, 그들의 방법에 대한 잠재적 문제를 인정합니다.
     * 저자는 블루투스 키보드를 사용하거나 타이핑 앱이 태블릿에 대한 블루투스 키보드처럼 작동하게 하는 등, 그들의 방법에 대한 잠재적 개선점에 대해 논의합니다.
     * 저자는 아직 복사 기능을 구현하는 방법을 찾지 못했지만, tmux 클립보드를 그래픽 클립보드로 보내는 쉬운 방법이 있을 수 있다고 제안합니다.
     * 저자는 타이핑 애플리케이션에 대한 키코드를 개발하고 테스트하기 위한 Python 스크립트를 제공함으로써 결론을 내립니다.

        Hacker News 의견

     * 오래된 태블릿을 추가 모니터로 사용하는 방법에 대한 기사
     * 한 사용자는 태블릿이 Linux GNOME DE에서 단순한 터미널 이상의 용도로 사용될 수 있음을 언급하고, 아이패드를 Ubuntu 22.04의 두 번째 모니터로 사용하는 방법에 대한 가이드 링크를 공유
     * 또 다른 사용자는 유료 프로그램 SuperDisplay를 사용하여 안드로이드 장치를 윈도우의 두 번째 화면으로 사용하는 것을 제안, 무선 또는 USB를 통해 가능
     * Weylus는 LAN을 통해 작동하고 태블릿에서 마우스를 제어할 수 있는 기능 때문에 한 사용자에게 추천, 가끔 지연이 발생할 수 있음
     * SpaceDesk는 추가 노트북이나 장치를 가진 윈도우 사용자들에게 좋은 무료 앱으로 제안, 이들을 외부 디스플레이로 사용할 수 있게 함
     * 한 사용자는 장치에 대해 표준화된 LVDS 리본 케이블 커넥터를 더 원하며, 이를 통해 HDMI/Display Port로의 변환이 더 쉬워질 것이라 표현
     * 오래된 전화를 TouchPortal과 함께 Streamdeck 대안으로 사용하는 것을 한 사용자가 제안, 무료는 아니지만 잘 작동한다고 언급
     * 한 사용자는 Duet를 사용하여 노트북 화면을 아이패드 화면으로 확장하는 것에 대해 언급
     * 논의에는 Linux (Wayland)를 호스트 OS로 사용할 때 발생하는 지연에 대한 이전 논의 언급도 포함
     * 일부 사용자들은 태블릿이 HDMI/Displayport 입력을 가지고 직접 디스플레이로 사용할 수 있기를 바라며, 태블릿을 추가 모니터로 사용한 경험을 공유
"
"https://news.hada.io/topic?id=11194","아마존, 가격 인상 가능성을 시험하기 위해 알고리즘 사용: FTC","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  아마존, 가격 인상 가능성을 시험하기 위해 알고리즘 사용: FTC

     * 아마존, ""프로젝트 네시""라는 코드명의 알고리즘을 사용해 경쟁사가 따라올 수 있는 가격 인상 범위를 테스트
     * 이 정보는 연방거래위원회(FTC)의 아마존에 대한 독점 소송에서 삭제된 부분에서 밝혀짐
     * FTC 소송은 FTC 의장인 리나 칸이 메타와 마이크로소프트를 상대로 한 더 넓은 범위의 노력의 일부
     * 칸의 행동으로 그녀는 기술 산업에서 논란의 인물로 떠올랐음
     * 이 기사는 알고리즘 또는 그 사용 범위에 대한 추가적인 세부사항을 제공하지 않음

        Hacker News 의견

     * FTC에 따르면 Amazon은 알고리즘을 사용하여 가격 인상 가능성을 테스트했습니다.
     * 가격 결정 시스템은 예상보다 더 구식이었으며, Vendor Manager들이 주요 가격 변동을 검토하였습니다.
     * 가격 인상은 어려웠으며 관리자의 승인이 필요했습니다.
     * Amazon의 Costco와의 가격 매칭 전략은 높은 2일 배송비를 초래했습니다.
     * 프랑스는 ""무료"" 배송을 약탈적인 가격 정책으로 사용하는 E-commerce 플랫폼을 방지하기 위한 법을 시행하고 있습니다.
     * Amazon이 Walmart의 가격을 맞추는 데 집중함으로써 문제가 발생했으며, 이는 경쟁자의 가격을 맞추기 위해 물품의 가격을 계속 낮추는 ""죽음의 나선""을 초래했습니다.
     * Amazon은 Walmart의 최저 가격을 맞추는 것을 중단하고 대신 경쟁자의 다음으로 낮은 가격을 맞추기로 결정할 시기를 파악하기 위해 Project Nessie라는 프로그램과 전문 팀을 만들었습니다.
     * Project Nessie는 이 도구가 더 이익을 내는 결과를 가져오지 못했을 때 중단되었습니다.
     * 일부 사용자들은 FTC가 특히 Amazon을 대상으로 한 것에 놀라움을 표하며, 이는 이러한 행동이 얼마나 임의적이고 정치적일 수 있는지를 보여준다고 생각합니다.
     * 일부 사용자들은 Amazon이 회사의 규모를 고려할 때 가격을 분석하기 위해 알고리즘을 사용하는 것이 놀랍거나 잘못된 것이 아니라고 주장합니다.
     * 알고리즘은 Amazon이 쇼핑 카테고리 전반의 이익을 향상시키는 데 도움을 주었으며, 경쟁자들이 가격을 인상하도록 이끌었습니다.
     * 알고리즘은 또한 경쟁자의 할인된 가격을 맞추는 데 사용되어 가격 인하의 주기를 만들었습니다.
     * 일부 사용자들은 이런 행위와 고객 행동 및 경쟁자 가격에 따라 가격을 조정하는 실제 상점 사이에 차이를 보지 않습니다.
"
"https://news.hada.io/topic?id=11248","나는 왜 더 이상 동료 시각장애 컴퓨터 사용자들에게 Mac을 추천할 수 없는지","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              나는 왜 더 이상 동료 시각장애 컴퓨터 사용자들에게 Mac을 추천할 수 없는지

     * 본 기사는 Mac의 VoiceOver에서 오래된 문제에 대해 논의하며, 이는 Safari가 자주 응답하지 않아 사용자의 Mac이 몇 분 동안 사용할 수 없게 되는 문제를 일으킵니다.
     * 이 문제는 Safari에만 국한되지 않고 Apple의 WebKit 브라우저 엔진을 사용하는 다른 애플리케이션에도 확장됩니다.
     * 이 문제는 Mac의 사양 수준에 관계없이 지속되며, 최신 Apple 실리콘 장착 Mac에서도 16GB 이상의 RAM이 있는 경우에도 경험되었습니다.
     * 이 문제는 Apple로부터 영구적인 해결책이 없는 상태로 여러 MacOS 버전에 걸쳐 수년 동안 지속되었습니다.
     * 저자인 David Goodwin은 이 문제 때문에 VoiceOver를 사용하는 사람에게 더 이상 Mac을 추천할 수 없습니다.
     * 이 문제는 Apple의 접근성에 대한 약속에 대한 의문을 제기하며, 이는 시각 장애 및 저시력 사용자의 Mac의 생산성과 사용성에 큰 영향을 미칩니다.
     * 저자는 이 문제를 해결하는 데 Apple의 엔지니어링 팀이 아마도 직면하게 될 어려움을 인정합니다.
     * 저자는 VoiceOver 사용자들이 Apple의 접근성 팀에 연락하고 이 문제에 대한 경험을 공유하도록 권장하며, 이는 Apple에게 문제 해결을 우선시하도록 공손한 압력을 가하는 것입니다.
     * 저자는 또한 ""Safari가 응답하지 않음"" 버그가 Mac의 VoiceOver 사용자에게 영향을 미치는 유일한 문제가 아니지만, 이는 Apple의 전반적인 성능과 접근성에 대한 약속이 판단되는 척도가 되었다고 강조합니다.
     * 저자는 소비자들이 이 문제에 대해 목소리를 내고 문제가 해결될 때까지 새로운 Mac 구매를 자제해야 한다고 제안합니다.
"
"https://news.hada.io/topic?id=11212",""Adam? ... 당신의 노트북이 냉장고에 있는 이유가 있나요?" (2006)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ""Adam? ... 당신의 노트북이 냉장고에 있는 이유가 있나요?"" (2006)

     * 저자가 고장나가는 하드 드라이브에서 데이터를 복구하기 위해 냉장고에서 냉각시키는 시도에 대한 개인적인 경험담 기사
     * 저자의 파워북 노트북이 부팅을 멈추고 클릭 소리를 내며 하드 드라이브가 고장나는 것을 나타냄
     * 보증이 무효화될 수 있는 노트북 해체 대신, 저자는 하드 드라이브를 냉각시켜 신뢰성을 높이는 이론을 테스트하기로 결정
     * 노트북은 냉장고에 10분 동안 두었더니 성공적으로 부팅되어 저자는 중요한 파일들을 외장 드라이브에 복사할 수 있었음
     * 그러나 큰 iMovie 프로젝트를 복사하는 도중에 하드 드라이브가 다시 뜨거워지고 클릭 소리를 내며 복사 과정이 중단됨
     * 저자는 다시 노트북을 냉장고에 20분 동안 두었고, 그 후에 성공적으로 부팅되어 복사 과정이 재개되었음
     * 하드 드라이브가 뜨거워지고 클릭 소리를 내면서 복사 과정이 다시 75%에서 중단됨
     * 남은 파일들을 작은 묶음으로 복사하는 대신, 저자는 노트북을 다시 냉각시키고 노트북이 아직 냉장고에 있을 때 복사 과정을 시작하기로 결정
     * 저자의 방법이 성공적이었고, 이 경험이 다른 사람들에게 도움이 될 수 있을 것이라는 희망을 가지고 경험을 공유했음

        Hacker News 의견

     * 사람들이 과열된 노트북과 다른 전자기기를 식히기 위해 비정상적인 방법을 사용하는 다양한 일화를 공유하는 기사.
     * 한 사용자는 오래된 Dell 노트북에 Ubuntu를 설치하려고 했지만 과열되어 과정 중에 충돌하는 경험을 이야기한다. 사용자는 겨울 날씨에 노트북을 밖에 두어 설치를 완료할 수 있었다.
     * 또 다른 사용자는 뜨거운 전원 브릭 위에 노트북을 두어 과열된 노트북의 이야기를 공유한다. 사용자는 하드 드라이브를 밤새 냉동고에 넣어 다시 작동하게 했다.
     * 여름철 고온의 도시에서 사용자는 PlayStation 2 아래에 얼음 블록을 놓아 과열을 방지하는 방법을 공유한다.
     * 인도의 또 다른 사용자는 Surface Book을 대리석 바닥에 놓으면 큰 히트싱크 역할을 해 비디오 인코딩 속도를 60% 높였다는 것을 발견했다.
     * 일부 사용자들은 파일을 복구하기 위한 최후의 수단으로 고장난 하드 드라이브를 냉장고에 넣는 관행을 언급한다.
     * 한 사용자는 과열된 노트북을 밤새 냉동고에 잊어버린 이야기를 공유한다. 초기의 공포에도 불구하고 노트북은 이후에 정상적으로 작동했다.
     * 사용자는 손상된 휴대폰이 매일 몇 분 동안 냉동고에 넣은 후에만 제대로 작동했던 이야기를 공유한다.
     * 또 다른 사용자는 덴마크 사무실에서 과열된 로봇을 식히기 위해 냉장고를 사용한 경험을 이야기한다.
     * 사용자는 Gentoo 설치 중 노트북을 냉장고에 넣어 과열과 충돌을 방지한 경험을 공유한다.
"
"https://news.hada.io/topic?id=11262","pgroll - 제로 다운타임, 원복 가능한 Postgrest 스키마 이관 도구 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           pgroll - 제로 다운타임, 원복 가능한 Postgrest 스키마 이관 도구 오픈소스

     * 안전한 스키마 Migration용 CLI 도구
     * 이관 중에 기존/신규 스키마 버전이 동시에 동작하도록 유지
     * 이슈 발생시 즉시 롤백 가능
     * 필요시 자동 컬럼 백필링(Backfilling) 지원
     * JSON 포맷으로 Migration 동작을 정의
     * 기존 스키마 대상으로 동작. 처음부터 시작할 필요 없음
     * Postgres 14+ 이상에서만 동작
     * RDS/Aurora 등 모든 Postgres 서비스에서 동작
     * Go 로 작성된 크로스 플랫폼 싱글 바이너리. 외부 의존성 없음
     * Expand and Contract Pattern 으로 동작
"
"https://news.hada.io/topic?id=11167","Meta, 모든 곳에 AI 챗봇을 도입 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Meta, 모든 곳에 AI 챗봇을 도입 예정

     * 왓츠앱, 인스타그램, 메신저등에 MrBeast/Charli D'Amelio 같은 셀럽을 모델로한 수십개의 AI 캐릭터들을 도입
     * 그룹 채팅에서 친구들과 여행을 계획하는 것부터 일반적으로 검색 엔진에 묻는 질문에 답변하는 것까지 모든 것에 대한 도움을 제공하는 무료 AI
     * 실시간 웹 결과 제공을 위해 Microsoft Bing과 파트너십 발표
     * ""/imagine"" 프롬프트를 통해서 Midjourney/Dall-E 처럼 고해상도 이미지를 생성해줌. 이 역시도 무료
     * 정확히 어떤 모델을 사용하고 있는지 밝히지는 않지만, Llama 2 의 핵심 원칙을 공유하는 맞춤형 LLM 이라고만 얘기함
     * 간결한 답변 제공 및 대화적이고 친근한 톤 유지를 위해 설계됨
     * 메시징 앱 전반에 걸쳐서 28개의 AI 캐릭터를 출시, 일부는 유명인 기반
          + Charli D’Amelio, Dwyane Wade, Kendall Jenner, MrBeast, Snoop Dogg, Paris Hilton 등
          + 다른 캐릭터들은 여행 에이전트 같은 특정 유스케이스에 맞는 테마
     * 챗봇 중 한 명과 채팅을 하면 대화에 따라 프로필 이미지가 미묘하게 움직여서 더 몰입감을 높임
     * AI가 문제가 될 수 있는 대화에 참여하는 것을 방지하기 위한 안전장치를 구현했음
     * 현재 Meta AI는 Instagram과 Facebook의 공개 사용자 데이터에 대해 학습하지 않지만, 이 기능은 향후 도입될 수 있음
     * 메시징 앱에서의 방대한 사용자 기반 때문에, ChatGPT와 같은 다른 챗봇에 대한 경쟁 우위로 보고 있음
     * OpenAI가 챗봇 경쟁을 시작했을 수도 있지만 소셜 네트워크를 통한 Meta의 엄청난 규모를 고려하면 Meta의 챗봇은 실제로 대부분의 사람들이 처음으로 사용하는 AI가 될 수도

   마지막 줄에 오타가 있는 듯 합니다.
   문맥상 ""OpenAI의 챗봇은"" -> ""Meta의 챗봇은"" 이 맞을 것 같아요.

   헛 엄청 중요한 곳에 오타가 있었네요. 수정했습니다.
"
"https://news.hada.io/topic?id=11258","아더 8.0","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 아더 8.0

     * 디지털 오디오 워크스테이션인 Ardour 8.0이 출시되어 Linux, Windows, 최신 버전인 macOS Sonoma를 포함한 macOS에서 사용 가능합니다.
     * 새로운 버전은 믹스 관련 컨트롤을 위한 ""Quick groups"", 곡 섹션 관리를 위한 배치 마커, 편집 창에서 더 쉬운 멀티-리전 편집을 위한 영구적인 리전 그룹 등, 상당한 품질 향상을 가져옵니다.
     * Ardour 8.0은 전용 자동화 레인에서 속도 편집, 모든 컨트롤러에 대해 자유롭게 자동화 그리기, 템포 맵을 인간의 공연에 맞추기, Novation Launchpad Pro를 DAW/Session 모드에서 사용하기 등의 새로운 기능을 도입했습니다.
     * 이 소프트웨어는 이제 아르페지에이터 플러그인을 사용한 새롭고 흥미로운 진행을 지원합니다.
     * Ardour 8.0은 이전 버전과의 호환성을 유지하므로, 이전 버전으로 생성된 세션은 새로운 문제 없이 로드해야 합니다.
     * 이번 릴리스에는 macOS에서의 MIDI 캡처/재생 정렬 문제 수정, 템포 맵 기반 그리드 계산 성능 향상, BBT 마커 수정 등 여러 버그 수정 및 개선 사항이 포함되어 있습니다.
     * Ardour 8.0은 또한 새로운 MIDI 아르페지에이터 플러그인을 도입했으며, 이는 악기 플러그인 이전에 MIDI 트랙에 추가할 수 있습니다.
     * 소프트웨어는 이제 Novation Launchpad Pro의 ""Session"" 모드의 전체 제어를 지원하며, 사용자가 클립과 큐를 트리거하고, 트랙 및 버스의 게인 레벨, 패닝, 전송 레벨을 제어할 수 있습니다.
     * Ardour 8.0은 템포 맵 마커 숨기기 또는 비활성화 옵션, ""막대 & 비트에 붙이기"" 옵션, ""Audition tool"", 스크럽 드래깅 시도 등 잘못 구상되거나 구현된 특정 기능을 제거했습니다.
     * 이 소프트웨어는 GNU Public License v2에 따라 라이선스가 부여됩니다.

        Hacker News 의견

     * Ardour, 2배속 오디오 재생 중 편집 등의 기능을 갖춘 인기 팟캐스트 편집 도구
     * 일부 사용자들은 버전 6 이후 특정 기능이 악화되어 버전 5를 계속 사용하게 됨
     * Ardour의 새로운 기능들이 때때로 유머러스하게 느껴지는 이유는 그것들이 이미 수년 동안 다른 디지털 오디오 워크스테이션(DAWs)에 존재했기 때문
     * Ardour의 창시자인 Paul은 리눅스 오디오 커뮤니티에서 활발하고 도움이 되는 사람으로 알려져 있음
     * Ardour는 그 기능과 창시자의 헌신 때문에 ""해커 영감""으로 여겨짐
     * Ardour는 기본적인 것들을 이해하면 사용자 친화적이며, YouTube에 도움이 되는 튜토리얼이 있음
     * Ardour의 스크린샷에는 매우 추천되는 Surge 신디사이저가 특징임
     * Ardour는 GPLv2 오픈소스이지만, 개발자들은 소스에서 빌드하는 것을 권장하지 않고, 대신 미리 빌드된 바이너리에 대해 요금을 부과함
     * Ardour 8이 ""Novation Launchpad Pro""와 더 비싼 ""Novation Launchpad Pro [MK3]"" 모두를 지원하는지에 대해 일부 혼란이 있음
     * Ardour 8의 새로운 Arrangement 뷰와 Launchpad 지원은 긍정적으로 받아들여짐
     * Ardour의 사용자 인터페이스는 깔끔함, 좋은 색상, 그리고 제공하는 컨트롤과 정보의 양에 대해 칭찬받음
"
"https://news.hada.io/topic?id=11231","시카고 맥코믹 플레이스의 유리가 새들에게 치명적인 장애물이 되다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  시카고 맥코믹 플레이스의 유리가 새들에게 치명적인 장애물이 되다

     * 북미 최대 규모의 컨벤션 센터인 시카고의 맥코믹 플레이스와 충돌하여 하루 만에 적어도 1,000마리의 새가 사망했습니다.
     * 건물은 대부분 유리로 덮여 있어, 특히 이동 기간 동안 새들에게 치명적인 장애물이 됩니다.
     * 이 사건은 2023년 10월 5일, 추정 150만 마리의 새가 쿡 카운티 상공을 날던 이동 최고조에 발생했습니다.
     * 시카고 시내 주변에서 새들을 계속 주워 올리는 사람들로 인해 영향을 받은 새들의 실제 범위가 몇 일 안에 드러날 것입니다.
     * 도시의 빛 오염뿐만 아니라, 반대풍, 비, 안개와 같은 날씨 조건은 새들이 방향을 잡는 것을 어렵게 만들고, 그들을 치명적인 구조물로 끌어들일 수 있습니다.
     * 매년 충돌로 인해 최대 10억 마리의 새가 죽으며, 시카고의 경우, 죽거나 부상한 새들은 대부분 캐나다에서 출발하여 남미와 중앙아메리카로 향하고 있었을 가능성이 높습니다.
     * 새들은 경제적 가치를 가지고 있으며, 생태계의 기능을 위해 필수적인 생태계 서비스를 수행합니다.
     * 시카고의 빛 오염은 모든 미국 도시 중에서 이동하는 새들에게 가장 큰 위험을 끼칩니다.
     * 2021년 연구에 따르면, 대형 건물의 절반의 불을 끄면 충돌을 6배에서 11배까지 줄일 수 있습니다.
     * 맥코믹 플레이스는 건물이 비어 있지 않는 한 밤에 불을 끄거나 어둡게 하는 Lights Out Chicago 프로그램의 참가자입니다.
     * 점이나 패턴과 같은 시각적 표시가 있는 창문 유리는 반사의 모양을 깨트리고 새들이 안전하게 날아갈 수 있는 통로가 있는지 인식하게 할 수 있습니다.
     * 2020년에 시카고는 새 친화적인 디자인 조례를 승인했지만 아직 시행되지 않았습니다. 2021년에는 일리노이 주지사 JB 프리츠커가 새 친화적인 디자인을 주 소유 건물의 건설과 개조에 포함시키는 Bird Safe Buildings Act를 서명했습니다.
     * 개조에 대한 투자, 이러한 환경 이니셔티브에 대한 세액 공제를 만들고, 창문을 더 새 친화적으로 만드는 것은 이 문제를 해결하는 경제적인 방법이 될 수 있습니다.

        Hacker News 의견

     * 시카고 McCormick Place의 유리는 새들에게 위험요소입니다.
     * 한 댓글러는 새들의 충돌을 방지하기 위해 건물의 유리 벽을 30도로 외부로 기울이는 시도를 한 경험을 공유했습니다. 이로 인해 새들은 투명한 유리가 아닌 땅의 반영을 볼 수 있었습니다.
     * 또 다른 댓글러는 창문에 흰색 점 스티커를 설치하여 새들의 충돌을 방지하자고 제안했으며, 이를 설치한 이후 단 한 번의 새 충돌도 없었다고 밝혔습니다.
     * 한 사용자는 토론토가 2007년부터 새 친화적인 디자인 가이드라인을 가지고 있었다며, 시카고가 비슷한 해결책을 도입하지 않은 것에 놀랐다고 표현했습니다.
     * 한 댓글러는 창문을 만났을 때 새들의 다양한 행동을 관찰하고 공유했습니다. 일부 새들은 같은 창문에 계속해서 부딪히는 반면, 다른 새들은 열린 창문을 드나들 수 있었습니다.
     * 한 사용자는 갑작스러운 기온 하락과 폭우로 인해 많은 새들이 한꺼번에 이동하게 되어, McCormick Place의 유리 창문과 새들의 충돌이 많이 발생했다고 설명했습니다.
     * 한 댓글러는 기사에 건물의 사진이 포함되지 않은 것을 비판했습니다.
     * 또 다른 사용자는 미국에서 야외에서 자유롭게 돌아다니는 가정용 고양이들이 매년 수십억 마리의 새와 포유류를 죽인다며, 건물의 치명성을 맥락에 두고 설명했습니다.
     * 한 댓글러는 자신의 집에서 새-창문 충돌에 대한 해결책을 공유했습니다. 이는 새들이 관점을 파악할 수 있는 무언가를 제공하기 위해 야외 예술품을 걸어두는 것을 포함했습니다.
     * 기사의 제목은 한 사용자에 의해 명확히 설명되었으며, 새들의 충돌이 매일 발생하는 것이 아니라 한 이동 날에 발생했다고 지적했습니다.
"
"https://news.hada.io/topic?id=11170","레드핀, 미국 부동산 중개인 협회(National Association of Realtors) 탈퇴","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        레드핀, 미국 부동산 중개인 협회(National Association of Realtors) 탈퇴

     * 부동산 중개업체인 Redfin, 구매자 대리인에 대한 수수료 정책과 조직 내 성희롱 주장 등 두 가지 주요 이유로 전국 부동산 중개인 협회(NAR) 지원 중단.
     * Redfin은 2017년부터 NAR의 일원이었으며, 개방적이고 기술 중심의 시장을 위해 NAR에 영향을 미치려는 시도로 1300만 달러 이상의 회비를 지불했음.
     * Redfin은 성희롱 주장이 알려지기 전인 6월에 이미 NAR 이사회에서 사임했음.
     * NAR의 정책은 판매자가 구매자 대리인에게 수수료를 지불하지 않는 주택을 나열하는 것을 방지하고, Redfin.com과 같은 웹사이트가 대리인이 나열한 주택 옆에 판매자 직접 판매 주택을 보여주는 것을 차단함.
     * Redfin은 이제 중개인과 대리인들에게 가능한 한 NAR를 떠나도록 요구하고 있으며, 이는 수익을 창출하는 사람들을 소외시킬 수 있는 결정이므로 가볍게 내린 결정이 아님.
     * NAR의 규칙은 Redfin이 문제가 국가협회에만 있을 때도 지역 및 주 협회를 떠나도록 요구함.
     * 많은 미국 시장, 주요 도시를 포함하여, Redfin은 중개인이 목록 데이터베이스, 보관함, 업계 표준 계약에 접근하기 위해 NAR 회원이어야 하므로 NAR를 그만둘 수 없음.
     * Redfin은 NAR에게 이러한 도구에 대한 지역 접근을 국가 로비 조직에 대한 지원과 분리하도록 요청하고 있음.
     * NAR와의 불일치에도 불구하고 Redfin은 부동산 업계에 대한 약속을 유지하고 중개인이 목록 데이터를 공유하는데 사용하는 다중 목록 서비스(MLSs)를 계속 지원할 것임.
     * Redfin의 임무는 소비자를 위한 부동산을 재정의하는 것이며, 그들은 NAR이 업계의 미래가 아니라고 믿음.

        Hacker News 의견

     * Redfin, 부동산 산업 혁신을 주장하는 일부 사람들의 찬사를 받으며 미국 부동산 중개인 협회(NAR)를 떠나기로 결정했습니다.
     * 비평가들은 부동산 중개인들이 주택 거래에서 상당한 비율을 차지하면서 가치를 거의 더하지 않고, 로비 활동과 규제 포획을 통해 과정을 인위적으로 복잡하게 만들었다고 주장합니다.
     * 많은 국가에서는 직접 고객 간 거래가 더 흔하며, 공증인이 계약이 구속력을 갖도록 보장합니다.
     * NAR과 주요 중개업체들은 강력한 반독점 법적 압박에 직면해 있으며, 최근에는 REMAX가 약 5000만 달러를 지불하고 사업 방식을 변경하겠다는 약속을 한 소송을 해결했습니다.
     * Redfin이 NAR와의 관계를 끊기로 한 결정은 일부에게서는 예상되는 산업 혼란 속에서 시장 점유율을 늘리기 위한 전략적인 움직임으로 보입니다.
     * Redfin은 또한 MLS 접근을 NAR에서 분리하는 노력을 하고 있으며, 이는 산업 발전의 중요한 장애물로 보입니다.
     * 일부 사용자들은 Redfin과의 긍정적인 경험을 칭찬하며, 그들의 데이터 공유 능력과 서비스 비용 모델을 찬양했습니다.
     * 그러나 다른 일부는 Redfin의 동기에 대해 회의적이며, 그들의 목표가 거래 비용을 줄이는 것이 아니라 그 비용을 자신들에게 돌리는 것이라고 의심합니다.
     * 일부는 부동산 중개인이 온라인 정보 접근성 때문에 필요하지 않을 수 있지만, 기술 회사에서 수수료를 통합하는 것이 사회적인 이길 수 없다고 주장합니다.
     * 부동산 중개인들이 MLS 시스템에 대한 접근을 개방하면, 이 시스템에 대한 산업의 의존성 때문에 그들의 직업이 하루아침에 붕괴할 수 있다는 추측이 있습니다.
"
"https://news.hada.io/topic?id=11206","Database Performance at Scale - 오픈소스 e북[270p PDF]","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Database Performance at Scale - 오픈소스 e북[270p PDF]

     * 대규모 환경에서 데이터베이스 성능 최적화 및 레이턴시 와 처리량에 영향을 미치는 일반적인 실수 방지를 위한 책
     * 카산드라와 호환되는 오픈소스 컬럼기반 NoSQL DB 인 ScyllaDB의 직원과 기여자들이 함께 작성
     * 여러 저자들의 수천건에 달하는 실제 DB 배포 경험에 기반하여 명확하고 실용적인 추천사항들을 정리
     * ScyllaDB 에만 대한 책이 아니고 DB 전반에 대해 다루긴 하지만, ScyllaDB 사용중이거나 고려중인 사람에게 도움이 됨
     * MongoDB, MySQL, Postgres, Cassandra, DynamoDB와 같은 다른 데이터베이스 사용자에게도 적용 가능
     * Creative Commons Attribution 4.0 International License 조건에 따라 무료로 제공
     * 책은 Apress의 ""Open Access"" 시리즈의 일부로, 저자들이 오픈 소스를 지원하는 것을 반영

목차

     * Chapter 1: A Taste of What You’re Up Against: Two Tales
     * Chapter 2: Your Project, Through the Lens of Database Performance
     * Chapter 3: Database Internals: Hardware and Operating System Interactions
     * Chapter 4: Database Internals: Algorithmic Optimizations
     * Chapter 5: Database Drivers
     * Chapter 6: Getting Data Closer
     * Chapter 7: Infrastructure and Deployment Models
     * Chapter 8: Topology Considerations
     * Chapter 9: Benchmarking
     * Chapter 10: Monitoring
     * Chapter 11: Administration
     * Appendix A: A Brief Look at Fundamental Database Design Decisions

   다운로드 링크: https://link.springer.com/content/pdf/10.1007/978-1-4842-9711-7.pdf

   Cassandra 대체제로 ScyllaDB를 선택해야 하는 이유
   수조개 메시지 스케일링하기: Discord가 Cassandra에서 SyllaDB + Rust로 전환한 이유

        Hacker News 의견

     * '대규모 데이터베이스 성능'에 대한 무료 책에 대한 기사
     * 한 댓글 작성자가 S3와 같은 오브젝트 스토어 또는 소프트웨어 정의 스토리지 구축에 대한 권위있는 자료를 원함
     * 다른 댓글 작성자는 책을 데이터베이스 공급업체의 마케팅 전략으로 비판하며, 대규모 성능에 대한 공급업체 중립적인 논의가 아니라고 주장함
     * 한 사용자가 Aurora나 Azure Managed Database와 같은 관리형 데이터베이스에 의존하지 않고 VM에서 앱을 실행하기 위해 MySQL 데이터베이스를 확장하는 방법을 배우는 것에 흥분함
     * 책의 오픈소스 주장에 대한 회의론이 있음, 책의 저장소가 본질적으로 비어있기 때문임
     * 책에서 첫 번째 코드 예제는 89페이지에서 발견됨
     * 한 사용자가 책이 일반적인 '데이터베이스 성능' 책인지, 아니면 ScyllaDB에 대한 장편 팜플릿인지 의문을 제기함
     * 왜 더 많은 회사/스타트업이 Postgres나 MySQL보다 ScyllaDB를 선택하지 않는지에 대한 논의가 생김, ScyllaDB의 속도와 확장성 장점을 언급함
     * 한 댓글 작성자가 데이터베이스 정규화와 인덱싱에 대한 기본 지식의 손실을 애도하며, 팀들이 종종 핵심 쿼리를 최적화하는 대신 캐시와 더 많은 하드웨어를 추가하는 경향이 있다고 제안함
     * 추가 팝업이나 뉴스레터 구독 없이 책의 PDF 버전에 직접 접근할 수 있다는 것이 인정받음
"
"https://news.hada.io/topic?id=11158","잘가 Integer, 안녕 UUIDv7","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         잘가 Integer, 안녕 UUIDv7

     * Buildkite는 PK로 새로운 UUIDv7 표준을 채택하여 이전의 시퀀셜 PK와 UUID 보조 키 시스템을 대체
     * UUIDs (Universally Unique Identifiers)는 독립적으로 생성할 수 있는 고유 식별자로, 분산 시스템과 데이터베이스에서 널리 사용중
     * UUIDs는 예측 불가능성, 내부 정보의 민감한 정보 공개 방지, 추가적인 방어층 제공 등 순차적 정수 식별자보다 여러 가지 장점을 제공
     * 그러나 표준 비시간 순서 UUID의 무작위성은 데이터베이스 성능 문제를 초래할 수 있음
     * 이를 해결하기 위해, Buildkite는 시간 순서의 UUIDv4 호환 UUID를 실험했고, 이는 주 데이터베이스의 Write Ahead Log (WAL) 비율을 50% 줄였음
     * UUID 버전 7 (UUIDv7)은 가장 중요한 48비트에 유닉스 타임스탬프를 밀리초 단위로 인코딩하고, 나머지 74비트는 무작위로 생성됨
     * Buildkite는 모든 새 테이블의 주요 키로 UUIDv7을 사용하기로 결정했으며, 이는 식별자 생성의 조정 필요성을 제거하고 애플리케이션 로직을 단순화함
     * Instagram의 ShardingID 구현과 Shopify의 복합 주요 키 구현과 같은 대안이 고려되었지만, 팀은 UUIDv7을 선택
     * UUIDv7로의 전환은 UUID의 128비트 길이로 인해 추가 저장 공간이 필요하지만, 이는 데이터베이스 행의 나머지 저장 공간에 비해 미미함
     * 현재 가장 큰 Postgres 데이터베이스를 샤딩하고 있으며, 필요한 경우 식별자에 샤드 번호를 포함하기 위해 미래에 UUIDv8을 사용할 가능성이 있음

        Hacker News 의견

     * UUIDv7는 순서가 있는 키로 인해 내부 분산 시스템에 유익하지만, 잠재적인 보안 문제로 인해 공개 식별자로는 적합하지 않을 수 있다.
     * 무작위 ID는 성능에 안 좋다고 주장되지만, 실제로는 단일 노드의 핫스팟을 방지하기 때문에 분산 저장 시스템에 더 좋다.
     * 식별자의 변화하는 요구사항과 원하는 속성 때문에 UUID의 여러 버전이 있다.
     * UUIDv7는 효율적인 색인화를 위한 순차적인 기본 키의 이점과 외부 사용을 위한 UUID 보조 키를 결합한다.
     * UUIDv7의 잠재적인 문제점 중 하나는 사용자가 ID에서 생성 시간을 추출할 수 있다는 것이다.
     * PostgreSQL용 UUID v7 함수가 오픈소스로 공개되어, 일괄 삽입의 속도 향상과 같은 이점을 제공한다.
     * UUIDv7는 Postgres uuid 타입과 함께 사용할 수 있으며, 이는 올바른 길이를 가진 모든 데이터를 받아들인다.
     * 일부는 데이터 크기와 생성 날짜에 대한 정보를 숨기기 위해 순차적인 64비트 기본 키와 추가적인 무작위 64비트 키를 외부 사용을 위해 선호한다.
     * UUID는 나중에 병합해야 하는 많은 분리된 소스로부터 키를 생성하는 데 유용하다.
     * GUIDs/UUIDs를 ""검증""할 필요성에 대한 논쟁이 있다. 이들은 종종 불투명한 식별자로 취급된다.
     * UUIDv7과 ULIDs 사이의 선택은 특정 요구에 따라 다르며, ULIDs는 UUIDs가 메타데이터에 사용하는 것보다 6비트의 추가 무작위성을 제공한다.
"
"https://news.hada.io/topic?id=11271","방어자의 이점을 위해 중세 계단이 시계 방향으로 건설되지 않았다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  방어자의 이점을 위해 중세 계단이 시계 방향으로 건설되지 않았다

     * 중세 계단이 시계 방향으로 만들어진 것은 방어자의 이점 때문이라는 오해를 깨는 기사
     * 계단이 방어 목적으로 시계 방향으로 만들어졌다는 주장을 뒷받침하는 기본적인 증거가 없음
     * 약 30%의 성이 반시계 방향의 계단을 가지고 있어, 계단의 방향에 대한 합의가 없었음을 시사하는 기사
     * 계단의 방향은 교통 흐름, 오른손잡이 석공의 편의, 또는 건축적 제약 등의 요인에 의해 영향을 받았을 수 있음
     * 제한된 공간 때문에 계단이 싸움에 적합하지 않다는 것을 주장하는 기사, 그 방향에 관계없이
     * 오해가 에드워디안 시대의 역사가인 Sir Theodore Andrea Cook의 이론에서 비롯되었을 수 있다는 기사 제안
     * 중세 출처의 증거가 나타날 때까지, 시계 방향의 계단이 전술적인 이유로 선호되었다는 생각은 오해라는 기사 결론
     * 독자들이 중세 전투에 훈련 받았고 성의 계단에 접근할 수 있다면 자신들만의 실험을 진행하도록 권장하는 기사

        Hacker News 의견

     * 중세 계단이 시계 방향으로 건설된 것은 전투에서 방어자에게 이점을 주기 위한 것이라는 일반적인 믿음에 대한 기사 토론
     * 일부 댓글은 중세 군사 매뉴얼인 'De Re Militari'를 인용하여 이에 반박하며, 고지를 점유하는 것의 중요성을 강조하고 계단을 중요한 전술적 요소로 보았음
     * 다른 이들은 성이 주로 내부 위협, 즉 반란이나 폭동에 대비하여 건설되었으므로 외부 전쟁에 대한 방어를 포기하는 논쟁은 관련이 없다고 주장
     * 이러한 계단의 일반적인 폭에 대한 의문이 제기되며, 일부는 계단의 좁고 가파른 특성이 방향에 관계없이 전투를 어렵게 만들 것이라고 제안
     * 반시계 방향 계단이 있는 성의 비율에 대한 회의론이 있으며, 일부는 이를 건축가들의 서툴러짐이나 지식 부족으로 돌리고 있음
     * 일부 댓글은 시계 방향 건설에 대한 대체 이론을 제안하며, 이는 숙련된 건축가로부터 전해진 전통의 결과이거나, 오른발을 주로 사용하는 사람들에게 더 편안하기 때문일 수 있음
     * 다른 이들은 계단의 방향이 문의 위치에 의해 결정될 수 있으며, 또는 내려갈 때 더 많은 추락 사고가 발생하여, 내려갈 때 외벽에서 오른손으로 난간을 잡는 것이 더 안전하다고 제안
     * 기사의 제목은 일부에게 모호하고 오해를 불러일으키는 것으로 간주되며, 탐구하고 있는 주장에 대해 더 구체적이어야 한다고 제안
"
"https://news.hada.io/topic?id=11199","구글재팬, 머리에 쓰는 모자형 키보드 Gboard CAPS 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  구글재팬, 머리에 쓰는 모자형 키보드 Gboard CAPS 공개

   머리에 쓰고 모자의 각도로 문자를 정해 입력하는 방식.

   만우절용 제품 같은데.. 너무 진지하군요 ㅋㅋㅋ
   3D 프린트 가능하다고 해서 봤는데, 정작 안전모인 INC-100(폴리에틸렌 모자) 구입을 해야합니다.
   https://ec.midori-anzen.com/shop/g/g4007030303/ 요게 374엔
   이 모자를 산 다음, 부착용 부속을 3D 프린트해서 모자와 연결하는 방식입니다.

   주요 하드웨어는 ESP32 인 M5StickC Plus 인데 얘가 $19.95고, SS-10GL13 스위치가 2천원쯤 하니 6-7만원선에 조립은 가능할듯 합니다.
"
"https://news.hada.io/topic?id=11224","Paperless-ngx - 오픈 소스 문서 관리 시스템","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Paperless-ngx - 오픈 소스 문서 관리 시스템

     * 문서를 스캔, 인덱스, 보관하여 검색가능한 온라인 아카이브로 만들어주는 오픈소스
     * 유지보수가 중단된 paperless-ng 를 포크하여 계속 업그레이드 및 유지보수
     * 문서 OCR 하여 검색 가능한 텍스트를 추가, 태깅 및 타입을 추가
     * PDF , 이미지, 플레인 텍스트, 오피스 문서(워드, 엑셀, 파워포인트 및 LibreOffice 파일) 지원
     * 문서는 파일시스템에 그대로 저장되며 파일명/폴더를 Paperless 가 관리
     * SPA 프론트 엔드 : 대시보드, 필터링, 개인화 가능한 뷰 제공
     * 전문 검색 지원: 자동 완성, 쿼리 관련도에 따른 정렬, 문서 내부의 일치하는 부분 하이라이팅, 비슷한 문서 검색 지원
     * 여러개의 이메일 계정 안의 문서도 자동 추가 가능
     * 머신러닝 기반의 문서 매칭
     * 멀티 코어 시스템에 최적화

   오픈소스 소개글이어서 https://github.com/paperless-ngx/paperless-ngx Repo의 내용을 요약했습니다.

        Hacker News 의견

     * Paperless-ngx는 오픈 소스 문서 관리 시스템으로 HackerNews에서 논의되고 있습니다.
     * 한 사용자는 DEVONthink의 학습 분류 기능을 칭찬하며, 이 기능이 Paperless-ngx에도 있었으면 좋겠다는 바람을 표현했습니다.
     * 다른 사용자는 카테고리/태그/폴더별로 문서에 사용자 정의 메타데이터를 추가하는 기능을 찾고 있습니다.
     * 한 사용자는 프린터/스캐너가 쓰기 전용 삼바 공유를 가리키도록 설정함으로써 종이 처리 과정을 간소화했습니다.
     * 한 사용자는 리눅스 기반 시스템에서 Paperless-NGX를 빠르게 설정하는 데 도움이 되는 자신의 사이드 프로젝트 링크를 공유했습니다.
     * 한 사용자가 Paperless-ngx를 위한 iOS/macOS 앱을 개발 중입니다.
     * 한 사용자는 완전히 자동화된 SaaS 문서 관리 시스템을 개발 중입니다.
     * Synology NAS 소유자들에게는 synOCR, 문서 관리 시스템을 확인해 보라는 권고가 있습니다.
     * 한 사용자는 Paperless-ngx의 설정 과정이 복잡하다고 느끼며, 간단한 네이티브 설치 프로그램이 필요하다고 제안했습니다.
     * 한 사용자는 Paperless-ngx 또는 DevonThink의 필요성에 대해 질문하며, macOS의 내장 기능인 OCR, 태깅, 스포트라이트 검색과 비교합니다.
     * 한 사용자는 복잡하지만 효율적인 문서 관리 시스템인 MayanEDMS를 추천합니다.
"
"https://news.hada.io/topic?id=11200","Ask GN: 이번 주말에 뭐 하시나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Ask GN: 이번 주말에 뭐 하시나요?

   이번 주말에 뭘 하려고 계획 중인지 편하게 얘기해 보아요.

   읽을 책, 가볼 곳, 해볼 것.. 어떤 것이든 좋습니다.
   도움 요청이나 피드백 요청도 좋습니다.
   물론! 아무것도 하지 않고 쉬는 것도 훌륭합니다.

   지난 주말에 계획하셨던 일의 회고도 한번 남겨봐 주세요.

   다음주에 회사에 대규모 감원이 있을 예정이라, 회사 서버 홈디렉토리를 정리하려고 합니다. 업무에 무관한 개인파일들, dotfiles 도 github에 백업하고... 몇년을 정리를 안했더니 너덜너덜 하네요. 짤리면 바로 랩탑반납이라...

   칩워 번역서를 선물 받아서 한 번 읽어보려고 합니다 :)

   재택으로 할 수 있는 일자리를 계속 찾아보려 합니다.

   독서하고 전세 아파트 보러가네요.ㅠㅠ

   주말에 태백으로 2박3일 등산 갑니다~ 태백산의 정기를 받고 올려고요.

   이번에 테슬라 모델 Y RWD를 출고해서 강원도로 드라이브를 갈 예정입니다.

   우왕 축하드립니다. 안전운전하세요!

   주말에 장인 장모님께서 홍천 리조트를 예약하셔서 좋은 술들고 갈 예정입니다.
   연휴라서 1박 2일 다녀오고 하루 정도는 월동준비를 할 것 같아요
   날씨가 빠르게 추워졌는데, 다들 몸 관리 잘하시면 좋겠습니다.
"
"https://news.hada.io/topic?id=11259","잠 부족의 영향","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                잠 부족의 영향

     * 수면 부족이 신체적, 정신적 건강에 미치는 부정적 영향에 대한 기사
     * 수면 부족이 신진대사를 느리게 하고 식욕을 증가시켜 체중 증가를 초래할 수 있음
     * 수면 부족은 우울증, 불안증, 과민성, 스트레스와 같은 정신 건강 문제를 일으킬 수 있음
     * 수면 부족으로 인한 당뇨병 위험 증가
     * 수면 부족은 알코올과 카페인 중독 등 더 많은 물질 남용을 초래할 수 있음
     * 수면 부족은 수명과 인지 성능, 특히 추론/논리 능력을 감소시킬 수 있음
     * 수면 부족은 장기적, 단기적 기억 문제를 일으킬 수 있음
     * 수면 부족으로 인한 치매 위험 증가 33%
     * 수면 부족은 피로, 의욕 상실, 성욕 감소를 초래할 수 있음
     * 이러한 건강 문제로 인한 사회적, 개인적 영향에 대한 기사, 예를 들어 관계의 긴장, 생산성 감소, 의료비 증가 등
     * 기사는 하버드와 의학보건 저널의 자료를 인용하여 주장을 뒷받침함
     * 기사는 해커 뉴스에서 토론을 불러일으켜 기술에 능통한 커뮤니티의 관심과 관련성을 보여줌

        Hacker News 의견

     * 많은 사용자들이 ""복수의 잠 못 이루기""를 경험하며, 자신의 일상에 대한 불만족으로 인해 개인적인 시간을 즐기기 위해 늦게까지 잠을 미룹니다.
     * 수면 부족은 주의력 감소, 반사 신경 약화, 사고 발생 가능성 증가 등으로 인한 신체적 손상을 초래할 수 있습니다.
     * 수면 부족은 또한 면역 체계의 효과 감소, 뉴런 사멸, 불안과 편집증과 같은 장기적인 정신 건강 문제를 초래할 수 있습니다.
     * ""카페인 함정""은 특히 카페인을 느리게 대사하는 사람들의 수면 패턴을 방해할 수 있습니다. 하루가 늦게 카페인을 섭취하면 몸의 수면 신호를 방해할 수 있습니다.
     * 수면 부족은 부모들에게 흔한 문제로, 자주 개인적인 시간을 위해 수면을 희생합니다.
     * 일부 사용자들은 카페인 제한, 암막 커튼 사용, 시각화 기법 등 수면을 개선하기 위한 전략을 공유하였습니다.
     * 일부 사용자들은 화면에서 더 많은 시간을 떼어내고 운동과 신선한 공기를 더 많이 취하면 자신의 수면 품질이 향상되었을 것이라고 후회하고 있습니다.
     * 수면 부족의 주장된 효과에 대한 회의론이 있으며, 일부 사용자들은 과로가 이러한 문제의 실제 원인일 수 있다고 제안하고 있습니다.
     * 일부 사용자들은 밤에 6-7시간의 수면을 취하더라도 절대로 휴식을 취하지 못하는 문제에 직면하고 있으며, 자신의 정신 상태가 수면 품질에 미치는 영향을 탐구하고 있습니다.
     * 잠들기 어려움과 수면 중단은 흔한 문제로, 일부 사용자들은 수면 보조제의 수면 품질에 대한 우려로 인해 사용을 망설이고 있습니다.
     * 일부 사용자들은 우울감, 불안, 고통과 같은 감정을 수면 부족이나 나쁜 날씨와 연관시키게 되었으며, 상황을 과도하게 분석하기 전에 이러한 요인을 해결하려고 노력합니다.
"
"https://news.hada.io/topic?id=11182","Show HN: 클래식 비디오 포커","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Show HN: 클래식 비디오 포커

     * HTML5 캔버스가 일부 브라우저에서 지원되지 않는 문제에 대한 기사
     * 현재 브라우저 업데이트 또는 다른 브라우저 사용이라는 두 가지 잠재적 해결책 제안
     * HTML5 캔버스를 프로젝트에 사용하는 사람들에게 특히 관련된 이슈
     * 영향을 받는 브라우저를 구체적으로 명시하지 않아 추가 연구가 필요한 기사
     * HTML5 캔버스 작업을 시작하는 초급 소프트웨어 엔지니어들에게 중요한 정보
     * 브라우저를 최신 상태로 유지하는 것의 중요성을 강조하며, HTML5 캔버스와 같은 새로운 기술과의 호환성을 강조하는 기사
     * 개발자들이 다양한 브라우저에서 애플리케이션을 테스트해야 하는 필요성을 강조하는 내용

        Hacker News 의견

     * 'Classic Video Poker' 게임은 CRT를 닮은 시각적 효과로 칭찬받았다.
     * 여러 사용자들이 'Jacks or Better'로 지불되지 않는 에이스 한 쌍의 버그를 보고했다.
     * 한 사용자가 하트 2와 클럽 3을 이용한 무한 돈 버그를 보고했다.
     * 일부 사용자들이 Unity, Unreal, Godot를 언급하며 게임 개발 경험을 공유했다.
     * 한 사용자가 90년대 핀란드에서 비슷한 게임을 플레이한 그립다는 기억을 공유했다.
     * 한 사용자가 키보드 플레이와 베팅 조정을 포함한 게임 개선을 제안했다.
     * 또 다른 사용자가 Godot를 사용한 경험을 공유하며, 더 나은 디버깅 도구의 필요성을 언급했다.
"
"https://news.hada.io/topic?id=11234","베리는 초경량 동적 타입 임베디드 스크립팅 언어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       베리는 초경량 동적 타입 임베디드 스크립팅 언어

     * 이 기사는 Berry라는 초경량, 동적 타입의 내장 스크립팅 언어를 소개합니다.
     * Berry는 성능이 낮은 임베디드 장치를 위해 특별히 설계되었습니다.
     * Berry 인터프리터 코어의 코드 크기는 40KiB 미만이며, 4KiB 힙 이하에서 실행할 수 있습니다. 이는 ARM Cortex M4 CPU에서 Thumb ISA와 ARMCC 컴파일러를 사용하여 테스트되었습니다.
     * Berry의 인터프리터는 원 패스 컴파일러와 레지스터 기반 가상 머신(VM)을 포함합니다. 모든 코드는 ANSI C99로 작성되었습니다.
     * Berry에서 모든 타입이 클래스 객체는 아닙니다. int, real, boolean, string과 같은 단순 값 타입은 클래스 객체가 아니며, list, map, range는 클래스 객체입니다. 이는 성능 고려 사항 때문입니다.
     * Berry의 맥락에서 ""레지스터 기반 VM""이라는 용어는 일반 컴퓨팅에서의 의미와 동일합니다.

        Hacker News 의견

     * Berry는 40KB 런타임에 놀랍게도 풍부한 기능 세트를 갖춘 초경량, 동적 타입의 내장 스크립팅 언어입니다.
     * Python/Ruby와 비슷한 언어를 실행하며, 절차적, 객체 지향, 또는 함수형 스타일을 지원합니다.
     * Berry는 상수 객체를 미리 생성하고 대부분을 ROM에 넣어, MicroPython이나 Lua에서 찾아볼 수 없는 RAM을 가변 데이터에 절약하는 기능으로 두드러집니다.
     * Berry는 IoT 장치용 플랫폼인 Tasmota에서 사용됩니다.
     * 언어의 문서화는 포괄성과 경험 많은 개발자를 위한 ""짧은 매뉴얼"" 포함으로 매우 칭찬받고 있습니다.
     * 일부 사용자들은 구성 언어로 사용하기 위해 패러다임이 더 적고 정적 타이핑이 있는 비슷한 언어를 원한다는 의사를 표현하였습니다.
     * 다른 언어에 바인딩을 제공하는 것에 대한 제안과 함수 재개나 생성자의 가능성에 대한 질문이 있습니다.
     * 사용자들은 Berry와 Lua의 성능 및 메모리 사용량 비교, 믿을 수 없는 코드를 실행하기 위한 샌드박싱 기능에 관심이 있습니다.
     * 네이티브 스택 추적에서 스크립트 함수의 이름으로 스택 프레임을 표시하는 가능성에 대한 질문이 있습니다.
"
"https://news.hada.io/topic?id=11239","뺄셈이 기능적으로 완성되다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             뺄셈이 기능적으로 완성되다

     * IEEE-754 부동 소수점 뺄셈의 맥락에서 기능적 완전성 개념에 대한 기사
     * 모든 이진 회로가 부동 소수점 뺄셈만을 사용하여 구축될 수 있다는 설명
     * IEEE 754-2019 표준, 6.3 섹션에 대한 상세 설명, 피연산자나 결과가 0 또는 무한일 때 적용되는 부호 비트와 규칙
     * 뺄셈이 합으로 간주되는 방법과 0이 부호를 가질 수 있는 방법, -0과 +0이 별개의 개체임을 저자가 보여줌
     * 0을 뺀 결과를 보여주는 참/거짓 표 제시, -0이 거짓이고 +0이 참임을 제안
     * 결과 참/거짓 표는 A∨¬B 또는 B→A (IMPLY 게이트로도 알려짐)와 동등하며, 이는 기능적으로 완전함
     * NAND와 NOR이 특정 상수 값에 접근하지 않아도 자체적으로 기능적으로 완전하다는 저자의 설명
     * 부동 소수점 뺄셈을 사용하여 NOT 게이트와 OR 게이트를 구축하는 Python 데모 포함
     * OR과 NOT을 사용하여 AND와 XOR 같은 다른 게이트를 구축하는 방법을 저자가 보여줌
     * 부동 소수점 연산만을 사용하여 정수를 구현하는 Rust 구현으로 기사를 마무리, 두 개의 8비트 정수를 부동 소수점 명령어를 사용하여 더하는 방법을 보여줌

   제목에 오류가 있네요. 뺄셈이 완성된게 아니라 뺄셈으로 모든 기능을 표현할 수 있다는 의미로 기능적으로 완전하다고 표현했네요
"
"https://news.hada.io/topic?id=11215","어려운 것들을 쉽게 만드는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           어려운 것들을 쉽게 만드는 방법

     * 저자가 '어려운 것들을 쉽게 만들기'라는 제목의 Strange Loop에서의 강연에 대한 기사
     * 강연은 어떤 기술 개념들이 배우기 어려운 이유와 그것들을 어떻게 쉽게 만들 수 있는지에 초점을 맞춤
     * 저자는 DNS 학습에 대한 그녀의 고군분투와 이해하는 데 오랜 시간이 걸렸던 경험을 공유
     * '나만 어렵게 느끼는 것'이라는 태도가 종종 장려되는데, 이것이 오히려 낙담을 초래할 수 있다고 언급
     * 저자는 DNS를 이해하는 여정을 공유하고, 복잡한 주제를 명확하게 설명하기 위해 Wizard Zines라는 출판사를 창립한 과정을 소개
     * 강연은 bash, HTTP, SQL, DNS 네 가지 주요 주제를 다루며, 그것들이 어려운 이유와 어떻게 쉽게 만들 수 있는지를 논의
     * 저자는 유용한 도구 공유, 참조 자료 제공, 컴퓨터에서 일어나는 일의 시간 순서대로 이야기하기, 실제로 사용하는 몇 가지 항목으로 큰 목록을 축소하기, 숨겨진 것들을 보여주기, 혼란스러운 도구를 시연하기 등 복잡한 주제를 쉽게 만드는 여러 전략을 제안
     * 저자는 모두가 기본적인 것들에 어려움을 겪는다고 강조하며, 이러한 어려움이 왜 발생하는지 이해하는 것이 해결책을 찾는 데 도움이 될 수 있다고 말함
     * 저자는 특정한 것들이 왜 어려운지 이해하고 그것들을 쉽게 만드는 방법을 찾는 작업을 계속하는 것에 대한 그녀의 흥분을 표현하며 결론을 맺음

        Hacker News 의견

     * 소프트웨어의 숨겨진 측면을 드러내는 도구의 중요성 강조, 웹 브라우저의 개발자 도구 및 네트워크 패킷용 Wireshark 등
     * 오픈 소스 소프트웨어의 투명성 칭찬, 사용자가 버그의 원인을 이해하고 프로그래밍 개념에 대해 더 배울 수 있음
     * bash의 복잡성 논의, 대부분의 프로그래머들이 이해력이 부족하여 bash 코드에 대한 자신감이 부족함을 제안
     * 기술 작가인 Julia의 찬사, 기술 주제에 대한 흥미를 불러일으키는 능력
     * 복잡한 주제를 이해하고 관리하기 쉽게 만들기 위한 적절한 추상화의 필요성 논의
     * 소프트웨어의 과도한 엔지니어링과 산업의 중앙집중화 비판, 이로 인해 문제 해결 접근법에 다양성이 부족하다는 제안
     * SQL과 bash의 어려움에 대한 논의, 두 가지 모두에 대한 개선 제안
     * Strange Loop에서의 발표 품질 칭찬, 더 이상 계속되지 않을 것이라는 실망 표현
     * bash 명령에 대한 참조 링크 포함
     * SQL 쿼리의 선언적 논리를 이해하는 것이 언어를 숙달하는 데 중요하다는 제안
     * bash의 복잡성과 'dig' 및 'man'과 같은 도구의 유용성에 대한 주장에 동의하며 기사를 칭찬
     * 일반적인 커맨드 라인 도구와 그들의 ""gotchas""를 기억하기 위해 Anki와 기억법 사용을 제안
"
"https://news.hada.io/topic?id=11153",""좋아, 회귀분석을 실행하겠지만 그것이 당신을 행복하게 만들지 않을 것"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ""좋아, 회귀분석을 실행하겠지만 그것이 당신을 행복하게 만들지 않을 것""

     * 기사는 주의 정당성향, COVID 백신 접종률, COVID 사망률 간의 관계를 논의한다.
     * 저자 Nate Silver는 주의 정당성향과 COVID 백신 접종률이 COVID 사망률을 강력하게 예측한다고 주장하며, 이는 연령을 고려해도 마찬가지다.
     * Silver는 회귀 분석을 사용하여 주장을 뒷받침하며, 더 높은 Biden 승리 마진(민주당 성향을 나타냄)을 가진 주들이 백신이 나온 이후 COVID 사망률이 더 낮다는 것을 보여준다.
     * 연령을 분석에 추가하면, 노령화된 주들이 백신이 나온 이후 COVID 사망자가 더 많았지만, 이는 주의 정당성향에 대한 판단에 영향을 미치지 않는다.
     * Silver는 또한 COVID가 백신을 맞지 않은 사람들에게 더 치명적이며, 공화당원들이 민주당원들보다 백신 접종을 덜 받을 가능성이 높기 때문에, 주의 정당성향이 이를 대신한다고 주장한다.
     * 백신 접종률이 모델에 포함될 때, 이는 주의 정당성향보다 COVID 사망률을 더 잘 예측한다.
     * 연령과 백신 접종률만으로도 2021년 2월 이후 주 간 COVID 사망률의 변동을 절반 이상 설명한다.
     * Silver는 자신의 분석에 대한 잠재적인 비판과 질문을 인정하지만, 그의 주장이 견고하며 소규모, 중규모, 그리고 종종 상당히 큰 이의에도 견딜 수 있다고 주장한다.
     * 기사는 Silver가 인터넷 상의 장황한 통계적 논쟁의 유용성에 대한 회의감을 표현하면서도, 그의 플랫폼인 Silver Bulletin에서 더 건설적인 논쟁을 기대하며 마무리된다.

        Hacker News 의견

     * COVID 보호 조치의 영향과 저자의 2020년 10월 반-봉쇄 선언에 대한 동의에 대한 기사
     * 일부 댓글 작성자들은 다양한 조치의 비용-효과 분석과 우울증, 고립, 학교 결석 등의 요인의 영향을 정량화하는 어려움에 의문을 제기
     * 공식 정책이 실제 행동을 얼마나 잘 반영했는지, 어떤 구체적인 행동이 차이를 만들었는지에 대한 불확실성
     * 기사의 주요 포인트는 모델의 복잡성에 관계없이 신중한 검토에 견딜 수 있는 강력하고 단순한 사실에 초점을 맞추는 것
     * 일부 댓글 작성자들은 COVID 사망 데이터의 신뢰성과 사망 보고에 대한 인센티브의 잠재적 영향에 대해 회의적
     * 분석에 사용된 소프트웨어는 Stata로 보임
     * 일부 댓글 작성자들은 정치적 의견이 사라진 후의 COVID에 대한 미래적인 관점을 기대
     * 기사의 사망에 대한 초점에 대한 비판, 일부는 장기 COVID와 무증상 사례도 사회적 파괴에 기여한다고 주장
     * 댓글 작성자가 다른 주에서 COVID 사망자 수를 100,000명당 분석, 원래 기사의 분석에서 혼동 요인의 가능성을 제안
"
"https://news.hada.io/topic?id=11230","Show HN: DotBigBang - 120fps 및 2초 로딩 시간을 가진 멀티플레이어 게임 엔진","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Show HN: DotBigBang - 120fps 및 2초 로딩 시간을 가진 멀티플레이어 게임 엔진

     * 'DotBigBang'이라는 새로운 멀티플레이어 게임 엔진 소개 기사
     * DotBigBang, 초당 120프레임(fps)과 2초의 짧은 로딩 시간으로 뛰어난 성능 자랑
     * 엔진은 알파 단계에 있음을 나타내, 아직 개발 중인 상태
     * 현재 소프트웨어는 렌더링을 사용하고 있으나, 모든 사용자에게 최적이지 않을 수 있음을 텍스트에서 제안
     * 개발자들은 사용자들이 도움과 추가 정보를 위해 Discord 커뮤니티에 가입하도록 권장
     * 수천명의 회원이 있는 것으로 보아 Discord 커뮤니티는 꽤 크며, 이는 프로젝트에 대한 높은 관심을 나타냄

   2초까지는 아니지만 로딩속도는 꽤 빠르네요.

        Hacker News 의견

     * DotBigBang 멀티플레이어 게임 엔진, 모바일 기기에서의 뛰어난 로딩 시간과 성능으로 호평
     * 사용자들, 비사실적 게임의 데스크톱에서의 빠른 로딩 시간에 만족
     * 개발자 중 한 명, DotBigBang에서의 게임 개발에 대한 질문에 초대하고 관심있는 개발자들을 위한 랜딩 페이지 링크 공유
     * 플랫폼, Meta의 horizon 플랫폼에 비해 유리하게 비교되며, 한 사용자는 Meta가 아직 물건을 사도록 허용되었다면 개발자들이 억만장자가 될 수 있었을 것이라 제안
     * 플랫폼을 구축하는 데 필요한 시간과 자원에 대한 의문 제기, 한 사용자는 이를 신진 게임 개발자에게 영감을 주기 위해 공유하고자 하는 흥미 표현
     * 일부 사용자들, 주장된 2초 로딩 시간에 대해 회의적으로 보이며, 한 사용자는 그들에게는 그렇게 빠르게 로드되지 않았다고 주장
     * 로딩 화면의 구현에 대한 의문 제기, 리소스가 많이 필요한 설정이나 오래된 기기에 대한 진행 상황을 보여주는 제안
     * 한 사용자, 플랫폼의 퀵스타트 가이드에 대한 링크에 접근하려고 할 때 SSL 오류 보고
     * 플랫폼의 성능, 오래된 모바일 기기에서도 작동한다는 한 사용자의 언급과 함께 칭찬받음
     * 플랫폼의 아키텍처, 브라우저 기반 게임 엔진에서 흔하지 않은 Entity Component System (ECS)의 사용으로 칭찬받음
     * 플랫폼, Krunker.io와 비교되며, 한 사용자는 5초 미만의 시간-투-펀 메커니즘에 대한 흥미 표현
     * 개발자들에게 잠재적인 공급업체 락인에 대한 우려 제기, 한 사용자가 이를 방지하기 위한 보장을 요청
"
"https://news.hada.io/topic?id=11238","Homebrew, HashiCorp에 대해 경고 추가 및 폐기 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Homebrew, HashiCorp에 대해 경고 추가 및 폐기 예정

     * 라이선스 변경으로 인해 homebrew-core에서 더 이상 버전 업데이트가 불가능할 수 있기에 Homebrew에서 HashiCorp의 Formula를 폐기하자는 제안
     * Homebrew 커뮤니티에서 대화를 촉발시켰으며, 일부 회원들은 지지를 표현하고, 다른 일부는 우려를 표현
     * 일부 회원들은 Terraform 종속 항목 대체를 위해 OpenTofu를 사용하는 것과 같은 대안을 제안
     * 제안은 아직 검토 중이며, 아직 확정되지 않았음
     * 댓글에서 HashiCorp의 Formula가 폐기되면 일부 종속 Formula도 폐기해야 할 수도 있다고 언급

        Hacker News 의견

     * Homebrew, HashiCorp 도구의 사용 중단을 고려 중이지만, 대체품을 찾을 수 있는지 확인하기 위해 의존성 중단은 보류 중입니다.
     * OpenTofu는 Terraform에 의존하는 프로그램의 대체품으로 사용될 수 있습니다.
     * 현재 Vault, Consul, Nomad에 대한 오픈소스 대안은 없습니다.
     * HashiCorp는 자체 tap을 유지하고 있으며, 이는 https://github.com/hashicorp/homebrew-tap에서 찾을 수 있습니다.
     * Homebrew가 HashiCorp 도구의 사용 중단을 결정한 것은 무료 소프트웨어만 포함하는 정책 때문일 수 있습니다.
     * Terraform은 고정된 버전이 필요하기 때문에 Homebrew 외부에서 관리하는 것이 더 나은 특수한 경우로 간주됩니다.
     * Homebrew의 설계 선택, 새로운 전용 Python 설치와 최신 버전이어야 한다는 요구 등에 대해 의문이 제기되었습니다.
     * 일부 사용자들은 Homebrew 내 다른 패키지들이 더 이상 업데이트를 받지 않지만 사용 중단되지 않은 것처럼, HashiCorp 도구의 사용 중단 결정이 정치적 동기에 의한 것이라고 생각합니다.
"
"https://news.hada.io/topic?id=11251","2023년, 벡터 데이터베이스 선택을 위한 비교 및 가이드 / Picking a vector database: a comparison and guide for 2023 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2023년, 벡터 데이터베이스 선택을 위한 비교 및 가이드 / Picking a vector database: a comparison and guide for 2023

     * LLM, RAG, Semantic Search 등의 어플리케이션에 사용하는 Vector Database를 선택하기 위한 비교 및 가이드 글로, Vectorview 공동 창업자, 에밀 프뢰베르크(Emil Fröberg)의 글을 번역하였습니다.
     * Pinecone, Weviate, Milvus, Qdrant, Chroma, Elasticsearch 및 PGvector의 7개 Vector Database를 비교하였습니다.
     * 비교 항목은 다음과 같습니다.
         1. 오픈소스 여부
         2. 자체 호스팅 가능 여부
         3. 클라우드 관리 여부
         4. 벡터 전용 여부
         5. 개발자 경험과 커뮤니티
         6. QPS(Query-per-Second) 및 지연시간(Latency)
         7. 지원하는 인덱스의 종류
         8. 하이브리드 검색 및 디스크 인덱시 지원 여부
         9. 역할 기반 접근 제어(RBAC) 지원 여부
        10. 동적 세그먼트 vs. 정적 데이터 샤딩
        11. 무료 호스팅 키어 제공 여부 및 가격
     * 원문: https://benchmark.vectorview.ai/vectordbs.html
"
"https://news.hada.io/topic?id=11254","2023년 말 현재의 나의 개인적인 C 코딩 스타일","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2023년 말 현재의 나의 개인적인 C 코딩 스타일

     * 2023년 말까지의 개인적인 C 코딩 스타일에 대해 저자가 논의하며, 기법에서의 중요한 변화와 개선점을 강조합니다.
     * 저자는 원시 타입에 대해 짧은 이름을 사용하기 시작했으며, 이는 명확성을 높이고 코드 검토를 더 즐겁게 만든다고 발견했습니다.
     * 저자는 typedef uint8_t u8; 및 typedef char16_t c16;과 같은 원시 타입에 대한 새로운 명명 규칙의 예를 제공합니다.
     * 저자는 함수처럼 보이는 매크로에 대해 소문자를 채택했는데, 이는 읽기 쉽고 다른 매크로 정의와 같은 네임스페이스 문제가 없기 때문입니다.
     * 저자는 const의 사용을 중단했는데, 이는 최적화에서 실질적인 역할을 하지 않고 실수를 잡아내지 못했기 때문입니다. 그들은 C에 포함된 것이 실수라고 믿습니다.
     * 저자는 null-terminated 문자열을 거부하고 기본 문자열 타입을 받아들였으며, 이는 더 생산적이라고 발견했습니다.
     * 저자는 out 파라미터 대신 구조체 반환을 선호하며, 이를 통해 여러 값 반환을 효과적으로 허용합니다.
     * 저자는 초기화자에서 벗어나 전통적인 제로 초기화자를 제외하고는 할당으로 초기화하는 것을 선호합니다.
     * 저자는 __attribute를 __attribute__보다 선호하며, 후자를 과도하고 불필요하다고 판단합니다.
     * Win32 시스템 프로그래밍에 대해, 저자는 빌드 시간을 줄이고, 네임스페이스를 정리하고, 프로그램과 더 깔끔하게 인터페이스하기 위해 사용자 정의 타입을 사용하여 프로토타입을 수동으로 작성하는 것을 권장합니다.
     * 저자는 wordhist.c와 asmint.c와 같은 작은 프로그램에서의 코딩 스타일 예를 제공합니다.

        Hacker News 의견

     * 2023년 말에 저자의 개인적인 C 코딩 스타일에 대한 기사.
     * 일부 댓글 작성자들은 저자가 자신의 타입을 정의하는 방식에 동의하지 않으며, 이것이 이미 C 타입에 익숙한 사람들을 혼란스럽게 할 수 있다고 주장합니다.
     * 상수에 대해 ""ALL_CAPS"" 사용에 대한 논란이 있으며, 일부는 이것이 전처리기 매크로에 예약되어야 한다고 주장합니다.
     * 저자가 signed 크기를 사용하는 것에 대한 비판이 있으며, 일부 댓글 작성자들은 unsigned 크기가 결함에 덜 취약하다고 주장합니다.
     * 저자가 기존의 관례, 예를 들어 표준 uint8_t 또는 int32_t 대신 u8 또는 i32를 사용하는 것에서 벗어나는 것이 다른 사람들에게 혼란을 줄 수 있다고 보입니다.
     * 일부 댓글 작성자들은 저자의 접근 방식이 C 코드를 모두가 쉽게 작업할 수 있게 만드는 것보다는 개인적인 선호에 더 초점을 맞춘 것 같다고 주장합니다.
     * 저자가 32비트 boolean을 사용하는 것에 대한 의문이 제기되며, 일부는 이것이 명확한 이점 없이 메모리를 낭비한다고 주장합니다.
     * float가 32비트이고 double이 64비트라는 저자의 가정에 대한 우려가 있으며, 이것이 잠재적으로 문제가 될 수 있다고 보입니다.
     * 코딩에서 ""개인적인 스타일"" 개념이 문제가 될 수 있다고 보이며, 프로그래밍은 궁극적으로 사회적 활동이기 때문에, 취미 프로젝트에도 해당됩니다.
     * 일부 댓글 작성자들은 저자가 out-parameters보다 structs를 선호하는 것에 동의하지 않으며, 이것이 함수를 구성하기 어렵게 만들고 타입의 증가를 초래한다고 주장합니다.
     * 이 기사는 다양한 코딩 스타일과 접근 방식에 대한 토론을 촉발하며, 프로그래밍 커뮤니티에서 의견의 다양성을 강조합니다.
"
"https://news.hada.io/topic?id=11183","BBC, 'Threads' 포기하고 'Mastodon'에 집중","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   BBC, 'Threads' 포기하고 'Mastodon'에 집중

     * 영국 방송 공사(BBC)는 사용자 참여 부족으로 인해 Instagram의 Threads 사용을 중단
     * 많은 브랜드들이 Threads를 포기하고 있음에도 불구하고, 이전에는 Twitter로 알려져 있던 X를 계속 사용중
     * BBC는 자체 호스팅하는 Mastodon 계정을 계속 유지
     * 미국 프로 축구 리그(NFL)와 CBS 뉴스와 같은 다른 조직들도 Threads에 게시를 중단했음
          + NFL은 6주간 아무것도 포스팅하지 않았음. 무려 190만 팔로워가 있음에도 불구하고
          + BBC도 11주 전에 포스팅을 중단했고, CBS News도 5주간 아무것도 포스팅 하지 않음
     * BBC는 2023년 7월에 Mastodon과 함께 6개월 실험을 시작하여, 사용자 정의 도메인에서 콘텐츠를 자체 호스팅
     * BBC의 Mastodon 계정은 활성 상태를 유지하고 있지만, Threads 계정은 포기된 것으로 보임
     * BBC가 Threads를 포기한 세 가지 원인 추측
          + Meta의 캐나다 뉴스 매체에 대한 지역적 차단(캐나다 국회의원들이 뉴스 세금 법을 통과시켰음)
          + 소셜 내러티브를 통제하려는 욕구
          + Threads에서 뉴스 게시를 자동화하기 위한 공개 API의 부재
     * 6개월간 실험한다고 했지만, BBC는 온라인에서의 목소리를 제한하지 않기 위해 Mastodon 계정을 활성 상태로 유지할 수 있다고 생각함

   Threads는 뭔가 좀.... 여러가지로 너무 미국식 인싸 문화 느낌이 나는 UX 뿐이라 한 번 써보고는 손이 안가더라구요.

   저는 공개 API의 부재가 가장 크다고 생각합니다. 당장 저 조차도 GeekNews 연결을 하고 싶지만 그게 공식적으로 안되니 별로 쓸생각이 안들더라고요.

   그리고 홈화면 피드가 너무 저와 관련없는 것들이 많이 나와서 안보게 되더군요.

   API도 없었다니... 엄청 급했군요. 런치할때 Minimum viable product for boosting stock price... 같은 느낌이었어요.

        Hacker News 의견

     * BBC는 소셜 미디어 플랫폼 Threads에서 활동이 줄었지만, Mastodon 계정은 계속 유지하고 있다.
     * 일부 사용자들은 BBC의 Mastodon에서의 활동이 상대적으로 적다고 지적하며, 주당 몇 개의 게시물만 올라온다고 말했다.
     * Threads에서 뉴스 콘텐츠 부족에 대한 비판이 있으며, 이는 일부 사용자들이 Twitter와 같은 플랫폼을 선호하는 주요한 이유이다.
     * 일부 댓글은 기사 제목이 오해를 불러일으키고 있다고 제안하며, BBC가 공식적으로 Threads를 포기한다고 발표한 적이 없다고 지적했다.
     * BBC가 Mastodon 계정을 유지하기로 한 결정은 흥미롭게 보이며, 아직도 이 플랫폼을 실험하고 있을 수 있다는 것을 시사한다.
     * 일부 사용자들은 Mastodon의 분산화된 특성 때문에 대형 기관들이 Mastodon에 존재해야 한다고 주장한다. 이 특성은 더 많은 통제와 독립성을 가능하게 한다.
     * Mastodon과 같은 대안 플랫폼이 Twitter를 대체할 수 있는 가능성에 대한 회의론이 있으며, 이는 사용자들이 기존 플랫폼에 익숙하고 편안하기 때문이다.
     * 일부 댓글은 Threads의 알고리즘이 다른 웹사이트로 연결하는 게시물을 억제함으로써 BBC의 활동 감소에 기여했을 수 있다고 제안한다.
     * BBC는 Twitter와 같은 다른 플랫폼에서 활동을 계속하고 있다.
"
"https://news.hada.io/topic?id=11233","Rails 7.1 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Rails 7.1 출시

     * Rails 7.1.0, 172개의 새로운 커밋과 함께 출시됨.
     * 로그 메시지를 다양한 싱크로 전송할 수 있게 하는 새로운 공개 API가 도입됨.
     * 로그 방송을 처리하기 위해 ActiveSupport::BroadcastLogger가 추가됨.
     * Ruby 버전 3.3 미만에서 빈 범위를 고려하도록 Range#overlap?가 수정됨.
     * Bigdecimal이 Active Support 의존성으로 추가되어, Ruby 3.4에 번들된 젬 후보가 될 것임.
     * 캐시 스토어는 이제 :compressor 옵션과 성능 최적화를 위한 :serializer 옵션을 통해 기본 압축기를 교체하는 것을 지원함.
     * ActiveSupport::Inflector.humanize(nil)는 더 이상 NoMethodError를 발생시키지 않음.
     * ActiveSupport::KeyGenerator#inspect와 MessageEncryptor#inspect에서 비밀이 더 이상 표시되지 않음.
     * Deprecation 경고는 이제 Deprecation의 :report 동작을 사용하여 ActiveSupport::ErrorReporter에 보고될 수 있음.
     * ActiveSupport::Cache::Store는 이제 ActiveSupport::MessagePack을 기반으로 하는 사전 설정된 serializer를 :serializer 옵션을 통해 지원함.
     * Object#deep_dup는 이제 명명된 클래스와 모듈을 중복하지 않음.
     * ActiveSupport::Deprecation.warn은 이제 오류를 보고된 것으로 표시하여 두 번 보고하는 것을 피함.
     * ActiveSupport::Deprecation 동작 콜백은 이제 deprecator 인스턴스를 인수로 받을 수 있음.
     * ActiveSupport::Cache::MemoryStore#write(name, val, unless_exist:true)는 이제 만료된 키를 올바르게 작성함.
     * ActiveSupport::ErrorReporter는 이제 source: 매개변수를 받아 전달함.
     * ActiveSupport::MessageEncryptor와 ActiveSupport::MessageVerifier는 이제 :message_pack과 :message_pack_allow_marshal을 serializer로 받아들임.
     * 뷰 프래그먼트와 같은 베어 문자열 값에 대한 최적화를 포함하는 새로운 7.1 캐시 형식이 사용 가능함.
     * ActiveSupport::Cache:Store#fetch는 이제 블록에 옵션 접근자를 전달하여 캐시 옵션을 재정의할 수 있게 함.
     * ActiveSupport::Deprecation#disallowed_warnings는 이제 그것이 구성된 인스턴스에 영향을 미침.
     * ActiveSupport::Deprecation.behavior=는 이제 호출에 응답하는 모든 객체를 받아들임.
     * ActiveSupport::MessageEncryptor는 이제 :url_safe 옵션을 지원함.
     * ActiveSupport::MessageVerifier 초기화 프로그램은 이제 url_safe 인수를 받아들여 URL 안전 문자열을 생성할 수 있게 함.

        Hacker News 의견

     * Rails 7.1 출시 및 사용자들의 경험과 의견 공유
     * Django와 Laravel과 같은 다른 프레임워크에 비해 Rails의 단순성을 칭찬하고 다른 사람들이 시도해 보도록 권장하는 사용자
     * 13,000 줄의 Rails 7.0 앱을 7.1로 업그레이드하는 긍정적인 경험을 공유하는 사용자, 테스트 구성 코드 한 줄만 변경 필요
     * 대규모 Rails 6 코드베이스를 Hotwire를 사용한 새로운 “non”-JS 방식으로 업그레이드하려는 사용자, Rails가 기본값을 따르면 좋지만 이를 벗어날 때는 도전적일 수 있다는 점을 강조
     * 새로운 노트북에서 Rails를 실행하는 과정에 대한 불만을 표현하는 사용자, 모든 요구 사항을 설정하는 설치 프로그램의 필요성 제안
     * Rails 7.1 출시의 공식 발표 공유, 빠른 성능 향상을 위한 새로운 비동기 쿼리 메소드 강조
     * 백엔드에서의 Rails가 받아야 할 인정을 받지 못한다고 지적하는 사용자, 그러나 프론트엔드가 한동안 복잡했다는 것을 인정
     * Rails + HTMX의 부활을 희망하는 사용자, 오늘날의 애플리케이션의 불필요한 복잡성을 비판하면서 매우 상호작용적인 페이지에 JS를 약간 뿌리기를 희망
     * 많은 팀들이 ActiveRecord와 함께 깨끗한 코드베이스를 구축하는 데 문제가 있다고 공유하는 사용자
     * Rails 7.1 업그레이드에 대한 PR을 제출하려고 한다는 것을 유머러스하게 공유하는 사용자, 그러나 7.0 업그레이드 PR은 몇 달 동안 보류 상태
     * 여전히 Rails 4.2를 사용하고 있고 그것에 만족하다는 사용자, 업그레이드의 필요성에 의문을 제기
"
"https://news.hada.io/topic?id=11180","CRDTs에 대한 인터랙티브한 소개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          CRDTs에 대한 인터랙티브한 소개

     * Conflict-free Replicated Data Types (CRDTs)에 대한 인터랙티브 소개글
          + 다른 컴퓨터(피어)에 저장되고 네트워크 요청 없이 다른 피어와 확인하는 것 없이 즉시 업데이트 될 수 있는 데이터 구조 유형
     * CRDTs는 Google Docs와 Figma와 같은 풍부한 협업 앱을 중앙 서버의 동기화 요구 없이 구축하는 데 훌륭
     * CRDTs에는 상태 기반과 작업 기반 두 가지 종류가 있음
          + 상태 기반 CRDTs는 모든 상태를 피어 간에 전송하고, 새로운 상태는 모든 상태를 병합함으로써 얻어짐
          + 작업 기반 CRDTs는 사용자가 취하는 행동만을 전송하며, 이는 새로운 상태를 계산하는 데 사용될 수 있음
     * 이 글은 상태 기반 CRDTs에 초점을 맞추고 원시 CRDT를 구축하는 방법, 더 복잡한 데이터 구조로 구성하는 방법, 그리고 협업 픽셀 아트 에디터를 구축하는 방법을 설명
     * Last Write Wins Register (LWW Register)라는 개념을 소개하며, 이는 단일 값을 보유하고 타임스탬프를 사용하여 현재 값을 마지막으로 작성된 값으로 덮어쓰는 간단한 유형의 CRDT
     * 또한 Last Write Wins Map (LWW Map)이라는 더 복잡한 유형의 CRDT 개념을 소개하며, 이는 하나 이상의 값을 보유함
     * LWW Registers와 LWW Maps의 작동 방식을 이해하는 데 도움이 되는 인터랙티브 플레이그라운드가 포함
     * 다음 글은 이 기사에서 설명한 개념을 사용하여 협업 픽셀 아트 에디터를 구축하는 데 초점을 맞출 것

   상당히 재미있는 내용이네요. 구글 문서 같은 실시간 협업이 가능한 앱들은 어떻게 구현된건지 궁금했었는데...

        Hacker News 의견

     * 개발자를 위한 Conflict-free Replicated Data Types (CRDTs)에 대한 훌륭한 소개로 찬사를 받는 기사, 실제 코드 예시와 명확한 설명이 포함되어 있음
     * CRDTs는 제품 개발에 사용되며, 다루기 어려울 수 있지만, 제로 지연 시간과 최종 일관성과 같은 이점을 제공함
     * CRDTs는 무효화 로직 없는 분산 캐시를 허용하여 캐시 관리를 단순화하고 성능을 향상시킴
     * CRDTs는 시스템 부하를 줄이고 엣지 컴퓨팅을 가능하게 하는 오래된 쓰기 작업의 삭제를 가능하게 함
     * 그러나, CRDTs를 사용하는 것은 역할 기반 인증의 어려움, 가산 데이터 모델 변경의 필요성, 디버깅 문제 등의 도전과제를 제시함
     * Liveblocks와 같은 서비스들은 CRDTs의 사용을 단순화하려고 하지만, 독립 개발자들에게는 비용이 많이 들 수 있음
     * CRDTs는 TTRPG 캠페인 관리자, 자동 동기화 데이터베이스, 협업 노트북 도구 등 다양한 애플리케이션에서 사용되었음
     * CRDTs는 데이터 관리에 매우 유용하고 흥미롭다고 여겨지지만, 사용자 중심 애플리케이션에 대한 중요성은 논쟁의 여지가 있음
     * 일부는 CRDTs의 주요 이점은 실시간 협업이라고 주장하며, 이는 이미 Google Docs와 같은 중앙 솔루션에 의해 해결되었다고 주장함
     * 다른 일부는 CRDTs가 다중 장치 지원과 오프라인 액세스와 같은 이점을 제공하지만, 이러한 기능들도 중앙 솔루션에서 사용 가능하다고 지적함
     * 데이터 모델 업데이트가 쉽지 않고 다른 피어들이 데이터를 변경할 수 있기 때문에, CRDTs와 함께 데이터의 장기성과 사용자 제어에 대한 우려도 있음
     * 이러한 논쟁에도 불구하고, CRDTs에 대한 지속적인 관심이 있으며, 이 분야에서의 연구와 개발이 계속되고 있음
"
"https://news.hada.io/topic?id=11264","OpenAI, 자체 AI 칩 개발 고려 중","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        OpenAI, 자체 AI 칩 개발 고려 중

     * AI 칩 부족 악화로 작년부터 회사내부에서 AI 칩 전략에 대한 논의가 진행중
     * AI 칩 제조업체를 인수하거나, 내부에서 설계하는 등 여러가지 전략을 고려중
     * CEO인 Sam Altman은 더 많은 AI칩을 확보하는 것을 회사의 최우선 과제로 삼고 있음
     * OpenAI는 GPU 기반 하드웨어를 사용, 하지만 GPU 공급망은 매우 딸리고 있음
     * ChatGPT가 구글 검색 규모의 1/10 정도로 커지게 된다면 초기에 $48B(64조원) 규모의 GPU가 필요하고, 매년 $16B 규모의 칩이 추가로 필요함

   마이크로소프트도 그렇고... 엔비디아가 AI를 독점(?)하는걸 막아줬으면 좋겠습니다.
"
"https://news.hada.io/topic?id=11236","이해 가능한 구성요소로 언어 모델 분해하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        이해 가능한 구성요소로 언어 모델 분해하기

     * 이 기사는 데이터에 대한 훈련, 규칙이 아닌 신경망 이해의 복잡성을 논의하며, 이로 인해 수백만 또는 수십억의 매개변수가 업데이트됩니다.
     * 각 뉴런의 수학적 연산이 관찰된 행동을 초래하는 이유를 이해하는 것이 도전이며, 이로 인해 실패 모드를 진단하고 수정하며 모델 안전성을 인증하는 것이 어렵습니다.
     * 이 기사는 인공 신경망 이해와 인간 행동의 생물학적 기초 이해 사이에 유사점을 그립니다.
     * 저자들은 개별 뉴런이 네트워크 행동과 일관된 관계를 가지지 않으며, 단일 뉴런이 많은 관련 없는 맥락에서 활성화된다고 지적합니다.
     * ""Towards Monosemanticity: Decomposing Language Models With Dictionary Learning""이라는 논문은 개별 뉴런보다 더 나은 분석 단위가 있으며, 이를 특징이라고 하며, 이는 뉴런 활성화의 패턴에 해당한다고 제안합니다.
     * 저자들은 512개의 뉴런으로 구성된 계층을 DNA 시퀀스, 법적 언어, HTTP 요청, 히브리어 텍스트, 영양 성명 등 다양한 것을 나타내는 4000개 이상의 특징으로 분해합니다.
     * 이 특징들은 눈가림된 인간 평가자에 의해 검증된 모델의 뉴런보다 훨씬 더 해석 가능하다고 밝혀졌습니다.
     * 저자들은 또한 ""자동 해석"" 접근법을 사용하여, 큰 언어 모델을 사용해 작은 모델의 특징에 대한 짧은 설명을 생성하며, 이는 뉴런보다 높은 점수를 받습니다.
     * 특징은 모델을 조정하는 목표 지향적인 방법을 제공하며, 인공 활성화는 모델 행동의 예측 가능한 변화를 초래합니다.
     * 학습된 특징은 다른 모델 간에 대체로 보편적이며, 이는 한 모델에서 특징을 연구함으로써 얻은 교훈이 다른 모델로 일반화될 수 있음을 제안합니다.
     * 저자들은 이 작업을 언어 모델의 메커니즘 이해를 향한 중요한 한 걸음으로 보며, 이는 모델 행동의 모니터링과 조정을 내부에서 가능하게 하여 안전성과 신뢰성을 향상시킬 수 있습니다.
     * 다음 도전은 이 접근법을 보여준 작은 모델에서 더 크고 복잡한 모델로 확장하는 것이며, 현재의 주요 장애물은 공학이지 과학이 아닙니다.
"
"https://news.hada.io/topic?id=11263","모든 DB는 머지않아 벡터 데이터베이스가 될 것이다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      모든 DB는 머지않아 벡터 데이터베이스가 될 것이다

     * 벡터 DB는 별도의 DB 카테고리가 아님
     * 머지않은 시일내에 그래프, 관계형, 문서 및 키 밸류 DB 및 캐시를 포함한 모든 DB는 어떤 형태로든 ""벡터 검색""을 지원하게 될 것임
     * 벡터 DB와 그렇지 않은 것의 경계가 모호해 지고, Pinecone, Weaviate, Milvus 등 전문화된 벡터 DB는 경쟁속에서 추진력과 차별성을 잃게 될 것
     * 현재의 DB들은 기존 워크로드/사용자 기반을 사용하여 새로운 RAG(Retrieval Augmented Generation) 워크로드를 잡으려고 시도하게 될 것이라 예상

   postgresql도 벡터 모듈을 지원하더라구용! 다른 엔진들도 빨리 지원했음 좋겠습니다 ㅎㅎ

   글쎄
   28년차 개발자인 나로서는 글쎄???
   차트 개발 라이브러리가 사라지지 않고더발전할텐데 . . db에 차트가 들어갈 필요가 없을듯
   Db와 차드등이 합쳐진들 db의 부히만더하기에 개발자로서는 더걱정하게된다 . 그렇지않아도 가장큰문제가 , 날로 커가는 db양으로 점점느려지는 문제를 해결하느라 , 최대한 분리시켜 속도 커스트마이징이 관건인데 말이다 .

   벡터 검색이라는 건 LLM 등 딥러닝 모델들이 사용하는 Embedding을 vector로 저장하고 그들간의 유사도 등을 내부적으로 빠르게 계산해서 찾아주거나 저장하는 등을 수행하는 건데, 차트라는 건 어떤 걸 의미하시는지 궁금합니다.

   벡터라는 단어를 보고 요즘 차트 라이브러리가 SVG 같은 벡터 이미지로 렌더링되다보니 동의어라 생각하고 사용하신 것 같습니다.

   뭔가 업계의 사정을 알 것 같은 코멘트라 재밌었습니다.

   저기서 말하는건 이론으로만 언급되던 Content-based address(reference)를 최근 AI(이 안에 vectorizing 등 관련 내용이 포함되죠) 기술이 급격히 발달하면서, 전통적 DBMS에서도 곧 그 기능을 만나볼 수 있을거라 전망될 정도로 너무나 쉽게 할 수 있게 되었다는걸 의미합니다.
"
"https://news.hada.io/topic?id=11174","개발자 모집 공고 - Jellyfin","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          개발자 모집 공고 - Jellyfin

     * 개발자들이 자유롭고 오픈 소스인 미디어 서버 소프트웨어인 Jellyfin 프로젝트에 기여하도록 촉구하는 기사
     * DigitalOcean이 주최하는 올해의 Hacktoberfest는 Jellyfin에게 특히 중요하며, 팀은 프로젝트의 발전을 돕기 위해 새로운 아이디어와 기여자를 찾고 있다.
     * Jellyfin은 반상업적 입장으로 FLOSS(자유/리브레 및 오픈 소스 소프트웨어) 세계에서 독특하다. 팀은 자원봉사자로 구성되어 있으며, 그들의 작업에 대해 어떠한 형태의 대가도 받지 않는다.
     * 프로젝트는 어떤 회사나 조직에도 지원받지 않으며 수익화 계획이 없다. 기부금은 받지만, 이는 인프라 비용과 가끔의 개발자 하드웨어 필요성을 충당하기 위한 것이다.
     * Jellyfin 팀은 현재 약 30명의 활동적인 핵심 기여자 기반으로 인해 부담을 겪고 있다. 팀은 지난 세 년 동안 크게 성장하지 않았다.
     * 팀은 클라이언트 지원 부족과 소프트웨어의 거친 면에 대한 사용자의 불만을 인정한다. 그들은 이러한 측면을 개선하고자 하는 의지를 표현하지만, 그러기 위해서는 더 많은 자원봉사자가 필요하다.
     * 팀은 개발자, 작가, UI/UX 디자이너, 비영어권 사용자, 열정적인 사람들이 경험 수준에 상관없이 프로젝트에 기여하도록 요청하고 있다.
     * Jellyfin은 새로운 기여자들이 시작하는 데 도움이 될 자원을 제공하며, Matrix/IRC/Discord 및 포럼에서 활발한 채팅 채널을 유지하여 지원한다.
     * 팀은 품질 있는 기여와 참여 의지를 증명한 후에 새로운 멤버가 공식적으로 가입하는 것에 개방적이다.
     * 최종 목표는 Jellyfin을 영원히 모두에게 무료인 최고의 스트리밍 서버로 만드는 것이다.

        Hacker News 의견

     * C# 기반 소프트웨어 프로젝트인 Jellyfin에 개발자들의 기여를 촉구하는 기사
     * C# 개발자인 한 댓글 작성자가 Jellyfin이 C# 기반임을 알고 기여에 관심을 표현
     * 다른 댓글 작성자가 사용자들이 기능을 요청하는 곳에 Jellyfin 팀이 개발자를 모집하는 글을 게시해야 한다고 제안
     * 한 개발자가 Jellyfin에 기능을 추가하려 했으나 여러 저장소에서 PR을 관리해야 하는 어려움 때문에 과정이 도전적이라는 경험 공유
     * 한 Linux 개발자가 Linux 시스템에서의 C# 개발 경험에 대해 묻고, Windows 환경 외의 언어에 대한 낯섦을 표현
     * 한 댓글 작성자가 Jellyfin GitHub 저장소의 열린 PR 수가 많아 개발자 모집의 효과성에 의문을 제기
     * 여러 댓글 작성자들이 Jellyfin에 대한 사랑을 표현하며, 한 사람은 이미 첫 이슈 작업을 시작했고, 다른 사람은 Hacktoberfest에 참여할 계획을 밝힘
     * 일부 사용자들이 Apple TV용 공식 클라이언트와 Jellyfin iOS의 Chromecast 지원과 같은 특정 기능을 원하는 바를 표현
     * 한 사용자가 Jellyfin의 부모 컨트롤에 대한 어려움을 공유하고, Emby와 같은 다른 옵션을 고려하고 있다고 언급
"
"https://news.hada.io/topic?id=11177","Show GN: KiwiTalk - Tauri(Rust) + SolidJS로 구현한 오픈소스 KakaoTalk 클라이언트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Show GN: KiwiTalk - Tauri(Rust) + SolidJS로 구현한 오픈소스 KakaoTalk 클라이언트

배경

     * 카카오톡은 대한민국에 사는 사람이면 99% 이상이 사용하는 메신저
     * 하지만 공식 클라이언트는 Windows와 macOS만 지원, Web이나 Linux는 전혀 지원되고 있지 않음 (Android나 iOS는 제외)
     * Wine을 사용하여 억지로 구동할 수는 있지만, 오류로 인해 실행되지 않고 꺼지거나, 심각한 버그로 인해 실사용할 수 없음 (채팅방을 로드할 수 없고, 큰 파일이나 이미지를 내려받을 수 없음)
     * 따라서 Linux 환경에서도 잘 작동하는 클라이언트를 만들기로 함

개발

     * 초기에는 React.js와 nw.js를 사용했음. 하지만 코드가 지나치게 비대해져서 관리하기 힘들어짐 (특히 React의 상태 관리와, nw.js의 JavaScript 컨텍스트 개념은 문제를 유발하기 너무 쉬웠음)
     * 이 문제를 해결하기 위해, 최근 SolidJS와 Tauri로의 재작성을 진행했음
     * 현 상태에서는 로그인 및 채팅 알림 등의 간단한 동작이 가능

  앞으로...

     * Windows나 macOS 카카오톡 클라이언트의 동작을, 가능하다면 모두 동일하게 작동하도록 구현할 예정
     * 다만, 구현해야 하는 기능이 너무 많고 비공개 프로토콜에 관한 연구도 많이 필요함
     * 기여나 피드백 주시면 정말 감사하겠습니다!

   이런 시도 너무 좋습니당 카카오에서 왜 지금까지 이런걸 직접 만들지 않았는지 참,,,, 윈도우폰 카카오톡 앱 담당 개발자가 1명이었다는 거 보면 비주류 플랫폼(리눅스가 비주류는 아니지만..)엔 정말 무관심하네요

   Kakaotalk Matrix Bridge

   카카오가 긍정적으로 반응해주길 기대하구요... 이런 움직임이 카카오가 좀더 오픈된 환경을 만들어주는데 좋은 자극제가 되길 바랍니다. (API를 오픈한다던지...)

   리눅스 유저입니다. 그저 응원하겠습니다.
   카카오가 이런 노력까지 건드리는 회사가 아니길..

   저도 메인으로 리눅스를 사용하는데 바로 설치하고 사용해볼게요~

   와우.. 리눅서로써 너무 꿀같은 정보네요..! 집에가서 한번 써보겠습니다. 프로토콜에 대한 역공학을 하지 않았을까 생각되는데 오픈소스로 공개되었을때에 문제의 소지가 있지 않을지 걱정되긴 하네요.

   키위톡 개발 방향 자체는 좋다고 생각됩니다. 다만, 이러한 비공식 클라이언트는 엄연한 카카오의 운영 정책 위반입니다. 이에 대한 대책이 마련되어 있는 건가요?

   카카오 측에 부정적인 영향을 주지 않도록, 최대한 원본 클라이언트의 동작을 모방하려고 합니다. (버그성 동작마저도)
   다만, KiwiTalk은 카카오 측에서 만들거나, 인가한 클라이언트가 아니기 때문에 반드시 사용자 본인의 판단과 책임 하에 사용하셔야 합니다.

   pidgin 프로토콜 플러그인 개발 계획은 없나요?

   아주 바람직한 개발 방향 이군용

   승인되지 않은 로코 프로토콜 사용에 따른 불이익이 있지 않을까요?

   KiwiTalk이 원본 클라이언트와 상이한 동작을 할 경우 이용자의 계정에 불이익이 있을 수 있기 때문에,
   최대한 원본 클라이언트의 동작과 동일하게 동작하게끔 구현하는 것이 목표입니다. 말씀 감사합니다!

   예전에는 직접 빌드해야 해서 써보기 힘들었는데
   이제는 빌드된 버전도 배포하시는군요

   궁금했는데 함 써봐야 겠습니다

   제가 이쪽에는 문외한이라 바보같은 질문일수도 있지만... 혹시 웹브라우저 익스텐션 형태로 사용이 가능할까요? 윈도우나 맥에 native client가 있기는 하지만, 저는 윈도우나 맥에서도 웹브라우저에서 사용이 가능하다면 매우 좋을것 같습니다. 또, 크롬북에서도 아주 유용하게 쓰일 수 있을것 같아요. (물론 크롬북이 native linux 프로그램을 실행하수는 있지만, 웹기반이면 더 쉽게 쓸수 있을것 같습니다.)

   현재로써는 Linux 환경에서의 정상적 사용만을 목표로 하고 있습니다. 말씀 감사합니다!

   좋아보이네요! 근데 혹시 법적인 문제는 없나요? 그러니까 혹시 카카오톡 이용 조항에 관련 내용이 있어서, 프로젝트 공헌자나 단순이용자의 계정이 정지되어도 권리를 주장할 수 없게 된다거나 하는..

   프로젝트 기여자라고 해서 따로 정지는 할 수 없는 것으로 압니다만, KiwiTalk에서 원본 클라이언트와 상이한 동작이 발생할 경우 계정이 정지될 수 있습니다.
   따라서 원본 클라이언트의 버그성 동작까지도 최대한 동일하게 만드는 것이 목표입니다.
   (Linux 기기에서의 정상적인 사용이 목표이므로)
"
"https://news.hada.io/topic?id=11151","[2023/09/25 ~ 10/01] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2023/09/25 ~ 10/01] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)

  개요

     * DAIR.AI에서 매주 공개하는 ML 논문들에 대한 글을 자동 번역해보았습니다.
     * 이번 주의 논문들은 대부분 LLM(Large Language Models)에 초점을 맞춘 것으로 보입니다. 그 중에서도 여러 환경에서의 LLM 프로세스 효율성 알고리즘 개선, LLM의 Graph Neural Prompting, 논리적 사고 과정의 적용 등 다양한 주제들을 다루고 있네요.
     * 이번 주에 선택된 논문들 중에는 'Boolformer'와 'Vision Transformers Need Registers' 같은 논문들은 다른 AI 분야와 융합하여 연구가 진행되는 추세도 볼 수 있습니다.
     * 이렇듯 AI 기술의 발전은 각 분야를 개별적으로 발굴하는 것뿐만 아니라 여러 분야를 융합하여 새로운 접근법과 해결책을 모색하는 중요한 일환임을 알 수 있습니다.

  반전의 저주 / The Reversal Curse

    논문 소개

     * 'a는 b'라는 형식의 문장에 대해 학습된 인공신경망은 그 반대 방향인 'b는 a'로 자동 일반화되지 않는다는 사실, 즉 반전 저주를 발견하고, 가상의 문장에 대한 인공신경망을 미세 조정하고 모델 크기와 모델군 전반에 걸쳐 그 효과를 입증합니다. #llm-reasoning

     Finds that llms trained on sentences of the form “a is b” will not automatically generalize to the reverse direction “b is a”, i.e., the reversal curse; shows the effect through finetuning llms on fictitious statements and demonstrating its robustness across model sizes and model families.

    논문 링크

   https://owainevans.github.io/reversal_curse.pdf

    더 읽어보기

   https://x.com/OwainEvans_UK/status/1705285631520407821

  파운데이션 모델의 효과적인 장기 컨텍스트 확장 / Effective Long-Context Scaling of Foundation Models

    논문 소개

     * 긴 컨텍스트 작업 모음에서 이미 gpt-3.5-turbo-16k의 전체 성능을 능가하는 70b 변형을 제안합니다. 여기에는 사람이 주석이 달린 긴 명령어 데이터가 필요하지 않은 비용 효율적인 명령어 튜닝 절차가 포함됩니다. #1b-context-window #100k-context-window

     Propose a 70b variant that can already surpass gpt-3.5-turbo-16k’s overall performance on a suite of long-context tasks. this involves a cost-effective instruction tuning procedure that does not require human-annotated long instruction data.

    논문 초록

     * 최대 32,768개 토큰의 효과적인 컨텍스트 창을 지원하는 일련의 긴 컨텍스트 LLM을 소개합니다. 당사의 모델 시리즈는 더 긴 학습 시퀀스와 긴 텍스트가 업샘플링된 데이터셋을 사용하여 Llama 2에서 지속적인 사전 학습을 통해 구축됩니다. 언어 모델링, 합성 문맥 프로빙 작업 및 다양한 연구 벤치마크에 대한 광범위한 평가를 수행합니다. 연구 벤치마크에서 우리 모델은 대부분의 일반 작업에서 일관되게 개선되었으며, 긴 컨텍스트 작업에서는 Llama 2에 비해 상당한 개선이 이루어졌습니다. 특히, 사람이 주석이 달린 긴 명령어 데이터를 필요로 하지 않는 비용 효율적인 명령어 튜닝 절차를 통해 70B 변형은 이미 긴 컨텍스트 작업에서 gpt-3.5-turbo-16k의 전체 성능을 능가할 수 있습니다. 이러한 결과와 함께, 저희는 이 방법의 개별 구성 요소에 대한 심층적인
       분석을 제공합니다. Llama의 위치 인코딩에 대해 자세히 살펴보고 긴 종속성을 모델링할 때의 한계에 대해 논의합니다. 또한 데이터 조합과 시퀀스 길이의 학습 커리큘럼 등 사전 학습 과정에서 다양한 설계 선택이 미치는 영향을 살펴봅니다. 제거 실험을 통해 사전 학습 데이터셋에 긴 텍스트가 많다고 해서 강력한 성능을 달성할 수 있는 것은 아니며, 긴 시퀀스로 처음부터 사전 학습을 하는 것보다 긴 컨텍스트 연속 사전 학습이 더 효율적이고 비슷한 효과를 낸다는 사실을 경험적으로 검증합니다.

     We present a series of long-context LLMs that support effective context windows of up to 32,768 tokens. Our model series are built through continual pretraining from Llama 2 with longer training sequences and on a dataset where long texts are upsampled. We perform extensive evaluation on language modeling, synthetic context probing tasks, and a wide range of research benchmarks. On research benchmarks, our models achieve consistent improvements on most regular tasks and significant improvements on long-context tasks over Llama 2. Notably, with a cost-effective instruction tuning procedure that does not require human-annotated long instruction data, the 70B variant can already surpass gpt-3.5-turbo-16k's overall performance on a suite of long-context tasks. Alongside these results, we provide an in-depth analysis on the individual components of our method. We delve into Llama's position encodings and discuss its limitation in modeling long dependencies. We also examine the
     impact of various design choices in the pretraining process, including the data mix and the training curriculum of sequence lengths -- our ablation experiments suggest that having abundant long texts in the pretrain dataset is not the key to achieving strong performance, and we empirically verify that long context continual pretraining is more efficient and similarly effective compared to pretraining from scratch with long sequences.

    논문 링크

   https://arxiv.org/abs/2309.16039

    더 읽어보기

   https://x.com/omarsar0/status/1707780482178400261

  대규모 언어 모델을 사용한 그래프 신경망 프롬프트 / Graph Neural Prompting with Large Language Models

    논문 소개

     * 지식 그래프(Knowledge Graph)에서 유용한 지식을 학습할 수 있도록 사전 학습된 머신러닝을 지원하는 플러그 앤 플레이 방식을 제안하며, 표준 그래프 신경망 인코더, 크로스 모달리티 풀링 모듈, 도메인 프로젝터, 자기 감독 링크 예측 목표 등 다양한 설계가 포함되어 있습니다. #knowledge-graph

     Proposes a plug-and-play method to assist pre-trained llms in learning beneficial knowledge from knowledge graphs (kgs); includes various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective.

    논문 초록

     * 대규모 언어 모델(LLM)은 다양한 언어 모델링 작업에서 뛰어난 성능으로 놀라운 일반화 능력을 보여 왔습니다. 그러나 여전히 근거 지식을 정확하게 포착하고 반환하는 데는 내재적인 한계가 있습니다. 기존 연구에서는 공동 학습 및 맞춤형 모델 아키텍처를 통해 언어 모델링을 향상시키기 위해 지식 그래프를 활용하는 방법을 모색했지만, 이를 LLM에 적용하는 것은 많은 수의 매개변수와 높은 계산 비용으로 인해 어려움이 있습니다. 또한 사전 학습된 LLM을 활용하고 맞춤형 모델을 처음부터 학습하는 것을 피하는 방법도 여전히 미해결 과제로 남아 있습니다. 이 연구에서는 사전 학습된 LLM이 KG로부터 유용한 지식을 학습할 수 있도록 지원하는 새로운 플러그 앤 플레이 방법인 그래프 신경 프롬프트(GNP)를 제안합니다. GNP는 표준 그래프 신경망 인코더,
       크로스 모달리티 풀링 모듈, 도메인 프로젝터, 자가 감독 링크 예측 목표 등 다양한 설계를 포함합니다. 여러 데이터셋에 대한 광범위한 실험을 통해 다양한 LLM 크기와 설정에 걸쳐 상식 및 생의학 추론 작업 모두에서 GNP의 우수성이 입증되었습니다.

     Large Language Models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. In addition, how to leverage the pre-trained LLMs and avoid training a customized model from scratch remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments
     on multiple datasets demonstrate the superiority of GNP on both commonsense and biomedical reasoning tasks across different LLM sizes and settings.

    논문 링크

   https://arxiv.org/abs/2309.15427

    더 읽어보기

   https://x.com/omarsar0/status/1707211751354212382

  비전 트랜스포머에는 레지스터가 필요합니다 / Vision Transformers Need Registers

    논문 소개

     * 내부 계산을 위해 용도가 변경된 비전 트랜스포머 네트워크의 피처 맵에서 아티팩트를 식별하고, 해당 역할을 수행하기 위해 입력 시퀀스에 추가 토큰을 제공하는 솔루션을 제안합니다. 이 솔루션은 문제를 해결하고 피처 및 주의 맵을 더 매끄럽게 만들며 밀집된 시각 예측 작업에서 새로운 최첨단 결과를 설정합니다. #vision-transformer #transformer

     Identifies artifacts in feature maps of vision transformer networks that are repurposed for internal computations; this work proposes a solution to provide additional tokens to the input sequence to fill that role; the solution fixes the problem, leads to smoother feature and attention maps, and sets new state-of-the-art results on dense visual prediction tasks.

    논문 초록

     * 트랜스포머는 최근 시각적 표현을 학습하기 위한 강력한 도구로 부상했습니다. 이 논문에서는 지도형 및 자가 지도형 ViT 네트워크의 특징 맵에서 아티팩트를 식별하고 그 특성을 분석합니다. 이러한 아티팩트는 주로 이미지의 정보가 적은 배경 영역에서 추론 중에 나타나는 하이노멀 토큰에 해당하며, 내부 계산을 위해 용도가 변경됩니다. 우리는 비전 트랜스포머의 입력 시퀀스에 추가 토큰을 제공하여 이러한 역할을 수행하는 간단하면서도 효과적인 솔루션을 제안합니다. 이 솔루션은 지도 및 자율 지도 모델 모두에서 이러한 문제를 완전히 해결하고, 고밀도 시각 예측 작업에서 자율 지도 시각 모델을 위한 새로운 최신 기술을 설정하며, 더 큰 모델에서 객체 발견 방법을 가능하게 하고, 가장 중요한 것은 다운스트림 시각 처리를 위한 더 매끄러운
       특징 맵과 관심 맵으로 이어진다는 것을 보여줍니다.

     Transformers have recently emerged as a powerful tool for learning visual representations. In this paper, we identify and characterize artifacts in feature maps of both supervised and self-supervised ViT networks. The artifacts correspond to high-norm tokens appearing during inference primarily in low-informative background areas of images, that are repurposed for internal computations. We propose a simple yet effective solution based on providing additional tokens to the input sequence of the Vision Transformer to fill that role. We show that this solution fixes that problem entirely for both supervised and self-supervised models, sets a new state of the art for self-supervised visual models on dense visual prediction tasks, enables object discovery methods with larger models, and most importantly leads to smoother feature maps and attention maps for downstream visual processing.

    논문 링크

   https://arxiv.org/abs/2309.16588

    더 읽어보기

   https://x.com/TimDarcet/status/1707769575981424866

  불포머: 트랜스포머를 사용한 논리 함수의 기호적 회귀 / Boolformer: Symbolic Regression of Logic Functions with Transformers

    논문 소개

     * 부울 함수의 종단 간 기호 회귀를 수행하도록 학습된 최초의 트랜스포머 아키텍처를 제공하며, 복잡한 함수에 대한 간결한 공식을 예측하고 유전자 조절 네트워크의 역학 모델링에 적용할 수 있습니다. #transformer

     Presents the first transformer architecture trained to perform end-to-end symbolic regression of boolean functions; it can predict compact formulas for complex functions and be applied to modeling the dynamics of gene regulatory networks.

    논문 초록

     * 이번 연구에서는 부울 함수의 종단 간 기호 회귀를 수행하도록 학습된 최초의 Transformer 아키텍처인 Boolformer를 소개합니다. 먼저, 깨끗한 진리 테이블이 주어졌을 때 학습 중에 볼 수 없었던 복잡한 함수에 대한 간결한 공식을 예측할 수 있음을 보여줍니다. 그런 다음 불완전하고 잡음이 많은 관측값이 주어졌을 때 대략적인 식을 찾을 수 있는 능력을 보여줍니다. 광범위한 실제 바이너리 분류 데이터셋에서 Boolformer를 평가하여 기존 머신러닝 방법의 해석 가능한 대안으로서의 잠재력을 입증합니다. 마지막으로, 유전자 조절 네트워크의 역학을 모델링하는 광범위한 작업에 적용합니다. 최근 벤치마크를 통해 Boolformer가 몇 배의 속도 향상으로 최첨단 유전 알고리즘과 경쟁할 수 있음을 보여줍니다. 코드와 모델은 공개적으로 사용할 수 있습니다.

     In this work, we introduce Boolformer, the first Transformer architecture trained to perform end-to-end symbolic regression of Boolean functions. First, we show that it can predict compact formulas for complex functions which were not seen during training, when provided a clean truth table. Then, we demonstrate its ability to find approximate expressions when provided incomplete and noisy observations. We evaluate the Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods. Finally, we apply it to the widespread task of modelling the dynamics of gene regulatory networks. Using a recent benchmark, we show that Boolformer is competitive with state-of-the art genetic algorithms with a speedup of several orders of magnitude. Our code and models are available publicly.

    논문 링크

   https://arxiv.org/abs/2309.12207

    더 읽어보기

   https://x.com/stephanedascoli/status/1706235856778834015

  대형 멀티모달 모델을 사실적으로 증강된 RLHF로 정렬하기 / Aligning Large Multimodal Models with Factually Augmented RLHF

    논문 소개

     * 대규모 멀티모달 모델을 정렬하기 위해 사실적으로 증강된 rlhf를 적용합니다. 이 접근 방식은 rlhf의 보상 해킹을 완화하고 텍스트 전용 gpt-4의 94% 성능 수준으로 llava 벤치 데이터 세트의 성능을 개선합니다. #llm-alignment #multimodal #rlhf

     Adapts factually augmented rlhf to aligning large multimodal models; this approach alleviates the reward hacking in rlhf and improves performance on the llava-bench dataset with the 94% performance level of the text-only gpt-4.

    논문 초록

     * 대규모 멀티모달 모델(LMM)은 여러 모달리티에 걸쳐 구축되며 두 모달리티 간의 정렬이 잘못되면 문맥상 멀티모달 정보에 근거하지 않은 텍스트 출력이 생성되는 ""환각""이 발생할 수 있습니다. 멀티모달 오정렬 문제를 해결하기 위해 텍스트 영역의 인간 피드백 강화 학습(RLHF)을 시각 언어 정렬 작업에 적용하여 인간 주석가에게 두 가지 반응을 비교하고 더 환각적인 반응을 찾아내도록 요청하고, 시뮬레이션된 인간 보상을 최대화하도록 시각 언어 모델을 학습합니다. 이미지 캡션 및 사실 기반 객관식 옵션과 같은 추가 사실 정보로 보상 모델을 보강하는 사실 증강 RLHF라는 새로운 정렬 알고리즘을 제안하여 RLHF의 보상 해킹 현상을 완화하고 성능을 더욱 향상시킵니다. 또한, 이전에 사용 가능한 사람이 작성한 이미지-텍스트 쌍으로 GPT-4에서 생성된 학습
       데이터(비전 명령 튜닝용)를 강화하여 모델의 전반적인 기능을 개선했습니다. 실제 시나리오에서 제안된 접근 방식을 평가하기 위해 환각에 대한 불이익에 특별히 초점을 맞춘 새로운 평가 벤치마크 MMHAL-BENCH를 개발했습니다. RLHF로 학습된 최초의 LMM으로서, 우리의 접근 방식은 텍스트 전용 GPT-4의 94% 성능 수준(이전 최상의 방법은 87% 수준만 달성할 수 있음)으로 LLaVA-Bench 데이터셋에서 괄목할 만한 개선을 달성했으며, 다른 기준선보다 MMHAL-BENCH에서 60% 향상된 성능을 보였습니다. 코드, 모델, 데이터는 https://llava-rlhf.github.io 에서 오픈소스입니다.

     Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in ""hallucination"", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written
     image-text pairs to improve the general capabilities of our model. To evaluate the proposed approach in real-world scenarios, we develop a new evaluation benchmark MMHAL-BENCH with a special focus on penalizing hallucinations. As the first LMM trained with RLHF, our approach achieves remarkable improvement on the LLaVA-Bench dataset with the 94% performance level of the text-only GPT-4 (while previous best methods can only achieve the 87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We opensource our code, model, data at https://llava-rlhf.github.io.

    논문 링크

   https://arxiv.org/abs/2309.14525

    더 읽어보기

   https://x.com/arankomatsuzaki/status/1706839311306621182

  대규모 언어 모델 정렬: 설문 조사 / Large Language Model Alignment: A Survey

    논문 소개

     * 외적 정렬, 내적 정렬, 기계론적 해석 가능성, 정렬된 LLM에 대한 공격, 정렬 평가, 향후 방향 및 토론을 주제로 하는 LLM 정렬에 대한 포괄적인 조사 보고서입니다. #survey-paper #llm-alignment

     A comprehensive survey paper on llm alignment; topics include outer alignment, inner alignment, mechanistic interpretability, attacks on aligned llms, alignment evaluation, future directions, and discussions.

    논문 초록

     * 최근 몇 년 동안 대규모 언어 모델(LLM)이 괄목할 만한 발전을 이루었습니다. 이러한 발전은 큰 주목을 받으면서도 동시에 다양한 우려를 불러일으키고 있습니다. 이러한 모델의 잠재력은 부인할 수 없을 정도로 방대하지만, 부정확하거나 오해의 소지가 있거나 심지어 해로운 텍스트를 생성할 수도 있습니다. 따라서 이러한 모델이 인간의 가치에 부합하는 행동을 보이도록 하기 위해 조정 기술을 사용하는 것이 무엇보다 중요합니다. 이 설문조사는 이 분야의 기존 역량 연구와 함께 LLM을 위해 설계된 정렬 방법론에 대한 광범위한 탐색을 제공하기 위해 노력합니다. AI 정렬이라는 렌즈를 채택하여 LLM의 정렬을 위한 일반적인 방법과 새로운 제안을 외적 정렬과 내적 정렬로 분류합니다. 또한 모델의 해석 가능성, 적대적 공격에 대한 잠재적 취약성 등 중요한
       문제를 조사합니다. LLM 정렬을 평가하기 위해 다양한 벤치마크와 평가 방법론을 제시합니다. LLM에 대한 정렬 연구 현황에 대해 논의한 후, 마지막으로 미래를 향한 비전을 제시하고 앞으로의 유망한 연구 분야를 고려했습니다. 이 조사에 대한 우리의 열망은 단순히 이 영역에 대한 연구 관심을 불러일으키는 것 이상으로 확장됩니다. 또한 유능하고 안전한 LLM을 위해 AI 정렬 연구 커뮤니티와 LLM의 기능 탐색에 몰두하는 연구자 간의 간극을 좁히고자 합니다.

     Recent years have witnessed remarkable progress made in large language models (LLMs). Such advancements, while garnering significant attention, have concurrently elicited various concerns. The potential of these models is undeniably vast; however, they may yield texts that are imprecise, misleading, or even detrimental. Consequently, it becomes paramount to employ alignment techniques to ensure these models to exhibit behaviors consistent with human values. This survey endeavors to furnish an extensive exploration of alignment methodologies designed for LLMs, in conjunction with the extant capability research in this domain. Adopting the lens of AI alignment, we categorize the prevailing methods and emergent proposals for the alignment of LLMs into outer and inner alignment. We also probe into salient issues including the models' interpretability, and potential vulnerabilities to adversarial attacks. To assess LLM alignment, we present a wide variety of benchmarks and
     evaluation methodologies. After discussing the state of alignment research for LLMs, we finally cast a vision toward the future, contemplating the promising avenues of research that lie ahead. Our aspiration for this survey extends beyond merely spurring research interests in this realm. We also envision bridging the gap between the AI alignment research community and the researchers engrossed in the capability exploration of LLMs for both capable and safe LLMs.

    논문 링크

   https://arxiv.org/abs/2309.15025

    더 읽어보기

   https://x.com/omarsar0/status/1706845285064818905

  Qwen 기술 보고서 / Qwen Technical Report

    논문 소개

     * 언어 에이전트 생성을 위한 도구 사용 및 계획 기능과 관련된 작업에서 RLHF의 강점을 보여주는 일련의 LLM를 제안합니다. #qwen-vl #rlhf

     Proposes a series of llms demonstrating the strength of rlhf on tasks involving tool use and planning capabilities for creating language agents.

    논문 초록

     * 대규모 언어 모델(LLM)은 인공지능 분야에 혁명을 일으켜 이전에는 인간의 전유물로 여겨지던 자연어 처리 작업을 가능하게 했습니다. 이번 글에서는 대규모 언어 모델 시리즈의 첫 번째 제품인 Qwen을 소개합니다. Qwen은 다양한 매개변수 수를 가진 여러 모델을 포괄하는 포괄적인 언어 모델 시리즈입니다. 여기에는 사전 학습된 기본 언어 모델인 Qwen과 휴먼 얼라인먼트 기술로 미세 조정된 채팅 모델인 Qwen-Chat이 포함됩니다. 기본 언어 모델은 다양한 다운스트림 작업에서 일관되게 우수한 성능을 보여주며, 특히 인간 피드백을 통한 강화 학습(RLHF)을 사용하여 학습된 채팅 모델은 경쟁력이 매우 높습니다. 채팅 모델은 상담원 애플리케이션을 만들기 위한 고급 도구 사용 및 계획 기능을 갖추고 있어 코드 인터프리터 활용과 같은 복잡한 작업에서 더 큰
       규모의 모델과 비교했을 때도 인상적인 성능을 보여줍니다. 또한 기본 언어 모델을 기반으로 구축된 코딩 전문 모델인 Code-Qwen 및 Code-Qwen-Chat과 수학 전문 모델인 Math-Qwen-Chat도 개발했습니다. 이 모델들은 오픈소스 모델에 비해 현저히 향상된 성능을 보여주며, 독점 모델에 비해서는 약간 뒤떨어집니다.

     Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce Qwen, the first installment of our large language model series. Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter.
     Furthermore, we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models.

    논문 링크

   https://arxiv.org/abs/2309.16609

    더 읽어보기

   https://x.com/omarsar0/status/1707776749042364729

  MentalLLaMA: 대규모 언어 모델을 사용한 소셜 미디어에서의 해석 가능한 정신 건강 분석 / MentalLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models

    논문 소개

     * 지침 추종 기능을 갖춘 해석 가능한 정신 건강 분석을 위한 오픈소스 llm 시리즈로, 105,000개의 데이터 샘플이 포함된 소셜 미디어에서 멀티태스크 및 멀티소스 해석 가능한 정신 건강 지침 데이터셋을 제안합니다. #medical #llm-for-clinical-task #llama

     An open-source llm series for interpretable mental health analysis with instruction-following capability; it also proposes a multi-task and multi-source interpretable mental health instruction dataset on social media with 105k data samples.

    논문 초록

     * 웹 기술의 발달로 소셜 미디어 텍스트는 자동 정신 건강 분석을 위한 풍부한 소스가 되고 있습니다. 기존의 판별 방법은 해석 가능성이 낮다는 문제가 있기 때문에, 최근 소셜 미디어에서 해석 가능한 정신 건강 분석을 위해 예측과 함께 상세한 설명을 제공하는 것을 목표로 하는 대규모 언어 모델이 연구되고 있습니다. 그 결과 ChatGPT는 정확한 분류에 대해 인간에 가까운 설명을 생성할 수 있음을 보여주었습니다. 그러나 LLM은 여전히 제로 샷/소수의 샷 방식으로 만족스럽지 못한 분류 성능을 달성합니다. 도메인별 미세 조정은 효과적인 솔루션이지만 두 가지 문제에 직면해 있습니다: 1) 고품질 학습 데이터가 부족합니다. 2) 미세 조정 비용을 낮출 수 있는 해석 가능한 정신 건강 분석용 오픈소스 LLM이 출시되지 않았습니다. 이러한 문제를 해결하기 위해
       Facebook은 소셜 미디어에서 105만 개의 데이터 샘플로 구성된 최초의 다중 작업 및 다중 소스 해석 가능한 정신 건강 지침(IMHI) 데이터셋을 구축했습니다. 원시 소셜 미디어 데이터는 8가지 정신 건강 분석 작업을 다루는 10개의 기존 소스에서 수집됩니다. 전문가가 작성한 몇 장짜리 프롬프트와 수집된 레이블을 사용하여 ChatGPT에 메시지를 표시하고 응답에서 설명을 얻습니다. 설명의 신뢰성을 보장하기 위해 생성된 데이터의 정확성, 일관성 및 품질에 대해 엄격한 자동 및 인적 평가를 수행합니다. IMHI 데이터세트와 LLaMA2 파운데이션 모델을 기반으로, 지침 추종 기능을 갖춘 해석 가능한 정신 건강 분석을 위한 최초의 오픈소스 LLM 시리즈인 MentalLLaMA를 학습시킵니다. 또한 10개의 테스트 세트로 구성된 IMHI 평가 벤치마크에서 예측의 정확성과 설명의 품질을
       검사하여 MentalLaMA의 성능을 평가합니다. 그 결과, MentalLLaMA는 최첨단 판별 방법에 근접한 정확도와 고품질 설명을 생성하는 것으로 나타났습니다.

     With the development of web technology, social media texts are becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear the problem of low interpretability, the recent large language models have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions. The results show that ChatGPT can generate approaching-human explanations for its correct classifications. However, LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner. Domain-specific finetuning is an effective solution, but faces 2 challenges: 1) lack of high-quality training data. 2) no open-source LLMs for interpretable mental health analysis were released to lower the finetuning cost. To alleviate these problems, we build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset on social media, with 105K data samples.
     The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We use expert-written few-shot prompts and collected labels to prompt ChatGPT and obtain explanations from its responses. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA, the first open-source LLM series for interpretable mental health analysis with instruction-following capability. We also evaluate the performance of MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their correctness for making predictions and the quality of explanations are examined. The results show that MentalLLaMA approaches state-of-the-art discriminative methods in correctness and generates high-quality explanations.

    논문 링크

   https://arxiv.org/abs/2309.13567

    더 읽어보기

   https://x.com/SAnaniadou/status/1707668936634794442

  로직을 통해 대규모 언어 모델에서 제로 샷 연쇄 추론 강화하기 / Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

    논문 소개

     * LLM의 제로 샷 사고 연쇄 추론을 개선하기 위한 새로운 신경 기호 프레임워크, 기호 논리의 원리를 활용하여 추론 프로세스를 검증하고 수정하여 LLM의 추론 기능을 개선합니다. #chain-of-thought

     A new neurosymbolic framework to improve zero-shot chain-of-thought reasoning in llms; leverages principles from symbolic logic to verify and revise reasoning processes to improve the reasoning capabilities of llms.

    논문 초록

     * 최근 대규모 언어 모델의 발전은 다양한 영역에서 놀라운 일반화 가능성을 보여주었습니다. 그러나 추론 능력은 특히 다단계 추론이 필요한 시나리오에 직면했을 때 여전히 상당한 개선의 여지가 있습니다. 대규모 언어 모델은 광범위한 지식을 보유하고 있지만, 특히 추론 측면에서 이러한 지식을 효과적으로 활용하여 일관된 사고 패러다임을 구축하는 데 실패하는 경우가 많습니다. 생성적 언어 모델은 추론 절차가 논리적 원칙의 제약을 받지 않기 때문에 때때로 환각을 보이기도 합니다. 대규모 언어 모델의 제로 샷 사고 연쇄 추론 능력을 향상시키기 위해, 우리는 기호 논리의 원리를 활용하여 추론 과정을 검증하고 그에 따라 수정하는 신경 상징적 프레임워크인 논리적 사고 연쇄(LogiCoT)를 제안합니다. 산술, 상식, 상징, 인과 추론, 사회 문제 등
       다양한 영역의 언어 과제에 대한 실험적 평가를 통해 논리에 의한 향상된 추론 패러다임의 효과를 입증했습니다.

     Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their behavior, particularly in terms of reasoning, often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. Generative language models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming to improve the zero-shot chain-of-thought reasoning ability of large language models, we propose Logical Chain-of-Thought (LogiCoT), a neurosymbolic framework that leverages principles from symbolic logic to verify and revise the reasoning processes accordingly. Experimental evaluations conducted on language tasks in diverse domains, including arithmetic, commonsense,
     symbolic, causal inference, and social problems, demonstrate the efficacy of the enhanced reasoning paradigm by logic.

    논문 링크

   https://arxiv.org/abs/2309.13339

    더 읽어보기

   https://x.com/omarsar0/status/1706711389803287019

  원문

   https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-c24

   와..정성글 재미있게 보았습니다.

   감사합니다 ^^;
"
"https://news.hada.io/topic?id=11232",".git 디렉토리안에는 무엇이 있을까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         .git 디렉토리안에는 무엇이 있을까?

     * git init 시 생성되는 .git 디렉토리에 대한 상세 설명
     * .git 디렉토리에는 config, HEAD, hooks, objects, refs 등 여러 파일과 폴더 포함
          + config 텍스트 파일은 현재 저장소의 git 설정, 작성자 및 파일 모드와 같은 기본 설정 포함
          + HEAD 파일은 기본 브랜치를 가리키는 저장소의 현재 헤드 포함. 기본 브랜치를 뭘로 했냐에 따라서 master 또는 main 등
          + hooks 디렉토리는 git 동작 전후에 실행할 수 있는 모든 스크립트 포함
          + objects 디렉토리는 저장소의 파일과 커밋에 대한 데이터 포함
          + refs 디렉토리는 브랜치와 태그를 가리키는 참조 또는 포인터 저장
     * 파일이 저장소에 추가되면, index 파일을 수정하고 objects 디렉토리에 새 폴더와 파일 추가
     * objects 디렉토리의 새 파일은 추가된 파일의 유형, 크기, 데이터를 포함하며, 파일명은 내용의 sha1에서 가져옴
     * 파일이 커밋되면, 커밋 메시지를 포함하는 COMMIT_EDITMSG라는 새 파일 생성 및 objects 디렉토리에 새 객체 추가 등 여러 변경 발생
     * git에서 브랜치 생성은 refs/heads 디렉토리에 브랜치 이름과 최신 커밋의 ID를 가진 새 파일 추가를 포함하는 간단한 과정
     * 브랜치 체크아웃은 .git/HEAD 파일을 체크아웃된 브랜치를 가리키도록 업데이트하는 것을 포함
     * 브랜치 병합은 세 가지 방법으로 수행 가능: fast forward merge, rebase merge, 별도의 merge commit 생성
     * 저장소가 푸시되면, objects 디렉토리의 모든 것과 명시적으로 푸시된 refs 아래의 모든 브랜치와 태그가 다른 git 저장소로 전송됨

   보통 config 만지려 들어가는 폴더죠 ㅎㅎ
"
"https://news.hada.io/topic?id=11280","새로운 HTTP/2 'Rapid Reset' DDoS 공격","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    새로운 HTTP/2 'Rapid Reset' DDoS 공격

     * 2023년 8월, Google 서비스와 Cloud 고객들이 이전에 보고된 Layer 7 공격보다 훨씬 큰 새로운 HTTP/2 기반 DDoS 공격의 대상이 되었다.
     * 가장 큰 공격은 초당 398백만 요청을 초과했지만, Google의 글로벌 로드 밸런싱 인프라에 의해 네트워크 가장자리에서 대부분 차단되었다.
     * Google의 DDoS 대응팀이 공격을 검토하고 유사한 공격을 더욱 완화하기 위해 추가적인 보호 조치를 취했다.
     * 2021년 말 이후 Google 서비스와 Google Cloud 프로젝트에서 관찰된 Layer 7 DDoS 공격의 대부분이 HTTP/2 기반으로 이루어졌다.
     * HTTP/2는 ""스트림""을 사용하여 엔드포인트 간에 다양한 메시지 또는 ""프레임""을 전송하며, 이는 DDoS 공격을 더 효율적으로 만드는 데 사용될 수 있다.
     * HTTP/2 Rapid Reset 공격은 클라이언트가 한 번에 많은 수의 스트림을 열고, 서버나 프록시로부터 각 요청 스트림에 대한 응답을 기다리는 대신 즉시 각 요청을 취소하는 것을 포함한다.
     * 이 공격은 서버와 클라이언트 간에 이용 가능한 비용 비대칭을 만들며, 서버는 취소된 요청에 대해 상당한 작업을 계속해야 한다.
     * Rapid Reset 공격의 변형이 관찰되었으며, 이는 일반적으로 초기 버전만큼 효율적이지 않지만, 표준 HTTP/2 DDoS 공격보다는 더 효율적일 수 있다.
     * 이 공격 벡터에 대한 완화 조치는 여러 형태를 취할 수 있지만, 주로 연결 통계를 추적하고 다양한 신호와 비즈니스 로직을 사용하여 각 연결의 유용성을 판단하는 데 중점을 둔다.
     * Google은 현재 HTTP/3가 대규모 DDoS 공격 벡터로 사용되는 것을 보지 않지만, HTTP/3 서버 구현이 단일 전송 연결에 의해 수행되는 작업량을 제한하는 메커니즘을 미리 구현하는 것을 권장한다.
     * Google은 생태계 전반에 걸쳐 새로운 HTTP/2 벡터를 해결하기 위한 조정된 취약성 공개 과정을 주도적으로 도왔다.
     * HTTP/2 서비스를 제공하는 모든 공급자들은 이 문제에 대한 노출을 평가하고 가능한 한 빨리 일반 웹 서버와 프로그래밍 언어에 대한 소프트웨어 패치와 업데이트를 적용해야 한다.

        Hacker News 의견

     * 'Rapid Reset'이라는 새로운 유형의 DDoS 공격에 대한 기사
     * 지금까지 가장 큰 DDoS 공격과 HTTP/2 Zero-Day 취약점에 대한 지속적인 논의
     * 2018년에 haproxy 팀이 HTTP/2와 관련된 유사한 문제를 식별하고 완화했던 사실
     * 일부 사용자들이 Google이 HTTP/2를 만들고, 그들이 만든 문제로부터 구원자로 자신을 제시하는 것을 비판
     * 공격이 HTTP/2 서버 구현에서 비용 비대칭을 이용하는 방식
     * 다른 프로토콜에서 이미 알려진 증폭 공격을 고려하면, 이 취약점이 HTTP/2 설계 과정에서 예상되지 않았다는 것에 대한 일부 사용자들의 놀라움
     * 이 공격이 광고, 추적기, 부피가 큰 프론트엔드 프레임워크를 더 빠르게 전달하기 위한 HTTP2의 필요성의 결과로 보는 시각
     * HTTP/2의 존재 이후 10년 만에 이 공격 유형이 나타났다는 점을 고려하면, HTTP/3와 QUIC에서 잠재적인 취약점에 대한 일부 사용자들의 우려
     * Microsoft가 이 취약점에 대한 패치 세부 정보를 발표
     * 일부 사용자들이 블로그 헤더가 계속 뜨면서 페이지를 읽을 수 없게 만드는 것을 발견
     * 이 공격이 단순한 요청 플러드가 아닌 새로운 점에 대한 설명 요청
"
"https://news.hada.io/topic?id=11205","Bitmagnet - 독특한 기능을 가진 셀프호스팅 BitTorrent 인덱서","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Bitmagnet - 독특한 기능을 가진 셀프호스팅 BitTorrent 인덱서

     * DHT Crawler + Content Classifier + 토렌트 검색엔진
          + DHT(분산 해시 테이블) 네트워크를 크롤링하여 가져온 토렌트 해시 정보를 통해서 메타데이터를 수집
          + 가져온 메타데이터를 분류하여 알려진 콘텐츠와 연결하고 인덱싱
          + 이 인덱스를 통해 외부 트래커/인덱서 의존없이 모든 토렌트 검색이 가능
     * Web UI(Angular) 와 GraphQL API 지원
     * Servarr 스택 연동(Torznab 스펙을 지원하는 모든 어플리케이션과 연동 가능)
     * 현재 알파 버전
     * 아직 구현되지 않은 고우선 순위 기능에는 다른 종류의 콘텐츠를 위한 분류기, 검색 결과의 정렬, 검색 성능 최적화, 모니터링 API 및 WebUI 대시보드, 인증, API 키, 접근 수준, 관리 API, 보다 완전한 GraphQL API, 보다 완전한 웹 UI, 특정 관심 콘텐츠에 대한 저장된 검색, 스마트 삭제, Prowlarr 인덱서 프록시와의 양방향 통합, 더 많은 문서화, 더 많은 테스트 등을 포함
     * 미래에 구현할수 있는 기능들 : 인기 있는 BitTorrent 클라이언트와의 통합, 분산형 개인 트래커, BitTorrent v2 프로토콜 지원 등이 포함

        Hacker News 의견

     * Bitmagnet은 자체 호스팅 BitTorrent 인덱서, DHT 크롤러 및 토렌트 검색기입니다.
     * Bitmagnet의 DHT 크롤러 기능은 독특하지 않으며, 처음으로 magnetico라는 다른 오픈 소스 프로젝트에서 구현되었습니다.
     * Bitmagnet의 DHT 크롤러는 shiny-adventure 및 DHT-Torrent-database-Worker와 같은 이전 프로젝트와 비교됩니다.
     * 많은 유사 프로젝트들이 그들이 사용하는 것과 동일한 서비스를 제공하는 적절하고, 사양 준수 노드를 구현하지 않는다는 비판이 있습니다.
     * Bitmagnet은 btdig.com과 비교되며, 더 높은 품질의 자체 호스팅 버전을 제안합니다.
     * 저작권 침해를 피하기 위해 Bitmagnet 웹사이트의 스크린샷에서 저작권이 있는 영화를 제거하라는 요청이 있습니다.
     * Bitmagnet은 Magnetissimo, Torrentinim, Spotweb 등과 같은 유사 프로젝트와 비교됩니다.
     * Bitmagnet과 같은 DHT 크롤러에서 예상되는 대역폭 사용에 대한 질문이 제기됩니다.
     * DHT 크롤링의 도전 과제에 대한 논의가 있으며, 이에는 DHT의 ""계층""과 더 긴 관계를 가진 노드의 선호도가 포함됩니다.
     * 이 기능이 왜 두꺼운 데스크톱 BT 클라이언트에 내장되지 않았는지에 대한 질문이 제기됩니다.
     * Bitmagnet은 piratebay 및 그 전신인 rarbg-selfhosted와 비교됩니다.
"
"https://news.hada.io/topic?id=11249","[2023/10/02 ~ 10/08] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2023/10/02 ~ 10/08] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)

  개요

     * DAIR.AI에서 매주 공개하는 ML 논문들에 대한 글을 자동 번역해보았습니다.
     * 이번 주에 주어진 논문들을 살펴본 결과, 장기간 컨텍스트(Long Context)를 다루는 언어 모델(Language Models, LLM)에 대한 연구들이 많았습니다. 특히 'LLMs Represent Space and Time', 'Retrieval meets Long Context LLMs', 'StreamingLLM', 'The Dawn of LLMs', 'Training LLMs with Pause Tokens' 등의 논문들에서는 LLM의 다양한 측면을 조명하고 있습니다.
     * 이러한 트렌드는 머신러닝과 딥러닝에서 언어 모델의 중요성이 계속 증가하고 있음을 보여주는 대표적인 예입니다. LLM은 대량의 언어 데이터를 학습하여 문장 생성, 기계 번역, 철자 교정 등 다양한 언어 이해 작업에서 전반적인 성능 향상을 가능하게 하는 기술입니다. 그러나 장기간의 컨텍스트를 처리하는 데에는 여전히 많은 어려움이 있습니다. 이를 해결하기 위한 다양한 접근 방식들이 제시되고 있는 것으로 보입니다.
     * 또한 'Neural Developmental Programs', 'Recursively Self-Improving Code Generation', 'Retrieval-Augmented Dual Instruction Tuning'과 같은 논문들에서는 AI의 자가학습 및 코드 생성, 지시어 튜닝 등의 주제를 탐구하고 있습니다. 이는 AI에서 더욱 새로운 방법론들이 등장하고 있다는 것을 보여주며, 이러한 연구들은 AI 기술의 자체 학습 능력과 적응성을 향상시키는 데 매우 중요한 역할을 할 것으로 예상됩니다.
     * 따라서 이번주 논문들의 트렌드는 언어 모델의 장기 컨텍스트 처리와 AI의 자가학습 및 코드 생성 분야에서의 새로운 연구 방향성을 보여주고 있다고 할 수 있습니다.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  공간과 시간을 표현하는 언어 모델 / Language Models Represent Space and Time

    논문 소개

     * 언어 모델이 여러 척도에 걸쳐 공간과 시간의 선형적 표현을 학습하고, 이러한 표현은 변형을 유도하는 데 강력하며 다양한 개체 유형에 걸쳐 통합되어 있음을 발견하고, 언어 모델이 피상적인 통계가 아닌 문자 그대로의 세계 모델을 학습한다고 주장하면서 공간과 시간과 같은 기본적인 구조화된 지식을 습득한다는 사실을 입증했습니다. #llm #llama2

     Discovers that llms learn linear representations of space and time across multiple scales; the representations are robust to prompt variations and unified across different entity types; demonstrate that llms acquire fundamental structured knowledge such as space and time, claiming that language models learn beyond superficial statistics, but literal world models.

    논문 초록

     * 대규모 언어 모델(LLM)의 기능은 이러한 시스템이 피상적인 통계의 방대한 모음을 학습하는 것인지 아니면 데이터 생성 프로세스의 일관된 모델, 즉 세계 모델을 학습하는 것인지에 대한 논쟁을 불러일으키고 있습니다. 우리는 Llama-2 모델 제품군에서 세 가지 공간 데이터 세트(세계, 미국, 뉴욕 장소)와 세 가지 시간 데이터 세트(역사적 인물, 예술 작품, 뉴스 헤드라인)의 학습된 표현을 분석하여 후자에 대한 증거를 찾았습니다. 그 결과, LLM이 여러 척도에 걸쳐 공간과 시간의 선형적 표현을 학습한다는 사실을 발견했습니다. 이러한 표현은 다양한 변형을 유도하는 데 강력하며 다양한 엔티티 유형(예: 도시 및 랜드마크)에 걸쳐 통합됩니다. 또한 공간 및 시간 좌표를 안정적으로 인코딩하는 개별 '공간 뉴런'과 '시간 뉴런'을 식별합니다. 우리의 분석은
       현대의 LLM이 공간과 시간과 같은 기본 차원에 대한 구조화된 지식을 습득하여 피상적인 통계가 아니라 문자 그대로의 세계 모델을 학습한다는 견해를 뒷받침합니다.

     The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a coherent model of the data generating process -- a world model. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual space neurons'' and time neurons'' that reliably encode spatial and temporal coordinates. Our analysis demonstrates that modern LLMs acquire structured knowledge about fundamental dimensions such as space and time, supporting the view that they learn not merely superficial
     statistics, but literal world models.

    논문 링크

   https://arxiv.org/abs/2310.02207

    더 읽어보기

   https://x.com/wesg52/status/1709551516577902782
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  검색과 긴 문맥의 대규모 언어 모델의 만남 / Retrieval meets Long Context Large Language Models

    논문 소개

     * 다운스트림 작업에 대한 검색 증강과 긴 컨텍스트 창을 비교하여 두 가지 방법을 결합하여 두 가지 장점을 모두 얻을 수 있는지 조사합니다. 간단한 래그를 사용하는 4K 컨텍스트 창을 가진 llm은 16K 컨텍스트를 가진 미세 조정된 llm과 비슷한 성능을 얻을 수 있으며, 검색은 확장된 컨텍스트 창 크기와 관계없이 llm의 성능을 크게 향상시킬 수 있으며, 32K 컨텍스트 창을 가진 검색 증강 llama2-70b는 질문 답변 및 쿼리 기반 요약 등 7개의 긴 컨텍스트 작업에서 gpt-3.5-turbo-16k보다 성능이 뛰어납니다. #llama #llama2-7b-32k-context #llama2-long #100k-context-window #streamingllm

     Compares retrieval augmentation and long-context windows for downstream tasks to investigate if the methods can be combined to get the best of both worlds; an llm with a 4k context window using simple rag can achieve comparable performance to a fine-tuned llm with 16k context; retrieval can significantly improve the performance of llms regardless of their extended context window sizes; a retrieval-augmented llama2-70b with a 32k context window outperforms gpt-3.5-turbo-16k on seven long context tasks including question answering and query-based summarization.

    논문 초록

     * 대규모 언어 모델(LLM)의 컨텍스트 창을 확장하는 것이 최근 인기를 얻고 있는 반면, 검색을 통해 LLM을 보강하는 솔루션은 수년 전부터 존재해 왔습니다. 자연스러운 질문은 i) 검색 증강과 긴 컨텍스트 창 중 어떤 것이 다운스트림 작업에 더 적합한가? ii) 두 가지 방법을 결합하여 두 가지 장점을 모두 얻을 수 있는가? 이 연구에서는 두 가지 최신 사전 학습된 LLM, 즉 독점적인 43B GPT와 LLaMA2-70B를 사용하여 두 가지 솔루션을 연구함으로써 이러한 질문에 답합니다. 놀랍게도, 생성 시 간단한 검색 증강을 사용하는 4K 컨텍스트 창을 가진 LLM이 긴 컨텍스트 작업에서 위치 보간을 통해 16K 컨텍스트 창을 가진 미세 조정된 LLM과 비슷한 성능을 달성하면서도 훨씬 적은 계산을 할 수 있다는 사실을 발견했습니다. 더 중요한 것은 검색이 확장된 컨텍스트 창 크기에
       관계없이 LLM의 성능을 크게 향상시킬 수 있음을 입증했다는 점입니다. 32K 컨텍스트 창을 사용하는 검색 증강 LLaMA2-70B는 질문 답변 및 쿼리 기반 요약 등 7개의 긴 컨텍스트 작업에서 평균 점수 측면에서 GPT-3.5-turbo-16k 및 Davinci003보다 성능이 뛰어납니다. 또한 비검색 LLaMA2-70B-32k 기준선보다 큰 차이로 성능이 뛰어나며 생성 속도도 훨씬 빠릅니다. 이 연구는 실무자가 검색 증강과 긴 문맥 확장 중 어떤 것을 선택할지 고민하는 데 도움이 되는 일반적인 인사이트를 제공합니다.

     Extending the context window of large language models (LLMs) is getting popular recently, while the solution of augmenting LLMs with retrieval has existed for years. The natural questions are: i) Retrieval-augmentation versus long context window, which one is better for downstream tasks? ii) Can both methods be combined to get the best of both worlds? In this work, we answer these questions by studying both solutions using two state-of-the-art pretrained LLMs, i.e., a proprietary 43B GPT and LLaMA2-70B. Perhaps surprisingly, we find that LLM with 4K context window using simple retrieval-augmentation at generation can achieve comparable performance to finetuned LLM with 16K context window via positional interpolation on long context tasks, while taking much less computation. More importantly, we demonstrate that retrieval can significantly improve the performance of LLMs regardless of their extended context window sizes. Our best model, retrieval-augmented LLaMA2-70B with
     32K context window, outperforms GPT-3.5-turbo-16k and Davinci003 in terms of average score on seven long context tasks including question answering and query-based summarization. It also outperforms its non-retrieval LLaMA2-70B-32k baseline by a margin, while being much faster at generation. Our study provides general insights on the choice of retrieval-augmentation versus long context extension of LLM for practitioners.

    논문 링크

   https://arxiv.org/abs/2310.03025

    더 읽어보기

   https://x.com/omarsar0/status/1709749178199318545
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  주의 싱크가 있는 효율적인 스트리밍 언어 모델 / Efficient Streaming Language Models with Attention Sinks

    논문 소개

     * 초기 토큰의 kv 상태가 창 주의 성능을 크게 회복하는 현상인 주의 싱크가 있는 효율적인 스트리밍 llms를 가능하게 하는 프레임워크; 주의 싱크의 출현은 초기 토큰에 대한 강력한 주의 점수 때문이며, 이 접근 방식을 사용하면 유한 길이의 주의 창으로 학습된 llms가 추가적인 미세 조정 없이 무한한 시퀀스 길이로 일반화할 수 있습니다. #streamingllm

     A framework that enables efficient streaming llms with attention sinks, a phenomenon where the kv states of initial tokens will largely recover the performance of window attention; the emergence of the attention sink is due to strong attention scores towards the initial tokens; this approach enables llms trained with finite length attention windows to generalize to infinite sequence length without any additional fine-tuning.

    논문 초록

     * 긴 상호작용이 예상되는 다중 라운드 대화와 같은 스트리밍 애플리케이션에 대규모 언어 모델(LLM)을 배포하는 것은 시급히 필요하지만 두 가지 주요 과제가 있습니다. 첫째, 디코딩 단계에서 이전 토큰의 키 및 값 상태(KV)를 캐싱하는 데 많은 메모리가 소모된다는 점입니다. 둘째, 널리 사용되는 LLM은 학습 시퀀스 길이보다 긴 텍스트에는 일반화할 수 없습니다. 가장 최근의 KV만 캐싱하는 윈도우 어텐션은 자연스러운 접근 방식이지만, 텍스트 길이가 캐시 크기를 초과하면 실패하는 것으로 나타났습니다. 초기 토큰의 KV를 유지하면 윈도우 어텐션의 성능이 크게 회복된다는 흥미로운 현상, 즉 어텐션 싱크가 관찰됩니다. 본 논문에서는 먼저 주의 싱크의 출현이 의미적으로 중요하지 않더라도 '싱크'로서 초기 토큰에 대한 주의 점수가 높기 때문임을
       증명합니다. 위의 분석을 바탕으로 유한 길이의 주의 윈도우로 학습된 LLM을 미세 조정 없이 무한한 시퀀스 길이로 일반화할 수 있는 효율적인 프레임워크인 StreamingLLM을 소개합니다. StreamingLLM을 통해 최대 4백만 개 이상의 토큰으로 안정적이고 효율적인 언어 모델링을 수행할 수 있는 Llama-2, MPT, Falcon, Pythia의 성능을 보여드립니다. 또한 사전 학습 중에 플레이스홀더 토큰을 전용 주의 싱크로 추가하면 스트리밍 배포를 더욱 개선할 수 있다는 사실도 발견했습니다. 스트리밍 설정에서 StreamingLLM은 슬라이딩 윈도우 재계산 기준선보다 최대 22.2배 빠른 성능을 발휘합니다. 코드와 데이터 세트는 https://github.com/mit-han-lab/streaming-llm 에서 확인할 수 있습니다.

     Deploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach -- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of window attention. In this paper, we first demonstrate that the emergence of attention sink is due to the strong attention scores towards initial tokens as a ``sink'' even if they are not semantically important. Based on the above analysis, we introduce StreamingLLM, an efficient framework that
     enables LLMs trained with a finite length attention window to generalize to infinite sequence lengths without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more. In addition, we discover that adding a placeholder token as a dedicated attention sink during pre-training can further improve streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2x speedup. Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.

    논문 링크

   https://arxiv.org/abs/2309.17453

    더 읽어보기

   https://x.com/Guangxuan_Xiao/status/1708943505731801325

   https://discuss.pytorch.kr/t/…
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  신경 발달 프로그램을 통한 인공 신경망 자가 조립을 향하여 / Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs

    논문 소개

     * 생물학적 유기체의 배아 발달 특성을 반영하는 발달 과정(신경 발달 프로그램이라고 함)을 통해 스스로 조립되는 신경망을 사용할 것을 제안하고, 연속 제어 문제와 성장하는 토폴로지에서 이 접근법의 가능성을 보여줍니다.

     Proposes to use neural networks that self-assemble through a developmental process that mirrors properties of embryonic development in biological organisms (referred to as neural developmental programs); shows the feasibility of the approach in continuous control problems and growing topologies.

    논문 초록

     * 생물학적 신경 시스템은 현재의 인공 신경망과는 근본적으로 다른 방식으로 만들어졌습니다. 딥러닝은 다양한 영역에서 인상적인 결과를 보여주지만, 고성능 신경 아키텍처를 설계하는 데 상당한 엔지니어링 노력이 필요한 경우가 많습니다. 이와 대조적으로 생물학적 신경계는 역동적인 자기 조직화 과정을 통해 성장합니다. 이 논문에서는 생물학적 유기체에서 배아 발달의 주요 특성을 반영하는 발달 과정을 통해 성장하는 신경망을 향한 초기 단계를 밟습니다. 성장 과정은 신경 발달 프로그램(NDP)이라고 부르는 또 다른 신경망에 의해 안내되며, 이 신경망은 국소적 통신만으로 작동합니다. 다양한 머신러닝 벤치마크와 다양한 최적화 방법(진화적 학습, 온라인 RL, 오프라인 RL, 지도 학습)에서 신경 성장의 역할을 조사합니다. 또한, 신경망의 성장을
       주도하는 자기 조직화를 통해 가능한 미래의 연구 방향과 기회에 대해서도 살펴봅니다.

     Biological nervous systems are created in a fundamentally different way than current artificial neural networks. Despite its impressive results in a variety of different domains, deep learning often requires considerable engineering effort to design high-performing neural architectures. By contrast, biological nervous systems are grown through a dynamic self-organizing process. In this paper, we take initial steps toward neural networks that grow through a developmental process that mirrors key properties of embryonic development in biological organisms. The growth process is guided by another neural network, which we call a Neural Developmental Program (NDP) and which operates through local communication alone. We investigate the role of neural growth on different machine learning benchmarks and different optimization methods (evolutionary training, online RL, offline RL, and supervised learning). Additionally, we highlight future research directions and opportunities
     enabled by having self-organization driving the growth of neural networks.

    논문 링크

   https://arxiv.org/abs/2307.08197

    더 읽어보기

   https://x.com/risi1979/status/1708888992224362742
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  LMM의 여명기: GPT-4V(ision)를 사용한 예비 탐색 / The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)

    논문 소개

     * 대규모 멀티모달 모델(LMM)에 대한 이해를 심화하기 위해 gpt-4v를 종합적으로 분석하고, 다양한 애플리케이션 시나리오에서 gpt-4v를 프로빙하는 데 중점을 두며, 비전을 갖춘 코드 기능부터 검색 증강 LMM에 이르기까지 다양한 예제를 제공합니다. #multimodal #gpt-4v

     A comprehensive analysis of gpt-4v to deepen the understanding of large multimodal models (lmms); it focuses on probing gpt-4v across various application scenarios; provides examples ranging from code capabilities with vision to retrieval-augmented lmms.

    논문 초록

     * 대형 다중모달 모델(LMM)은 시각적 이해와 같은 다감각 능력을 갖춘 대형 언어 모델(LLM)을 확장하여 더 강력한 일반 지능을 달성합니다. 이 논문에서는 최신 모델인 GPT-4V(ision)를 분석하여 LMM에 대한 이해를 깊게 합니다. 이 분석은 GPT-4V가 수행할 수 있는 흥미로운 작업에 초점을 맞추고 있으며, GPT-4V 기능의 품질과 범용성, 지원되는 입력 및 작업 모드, 모델을 효과적으로 유도하는 방법을 조사하기 위한 테스트 샘플을 포함하고 있습니다. GPT-4V를 탐색하는 접근 방식에서는 다양한 영역과 작업에 걸쳐 신중하게 설계된 정성적 샘플 모음을 큐레이팅하고 구성합니다. 이러한 샘플을 통해 관찰한 결과, 임의로 인터리빙된 멀티모달 입력을 처리하는 GPT-4V의 전례 없는 능력과 그 기능의 범용성이 결합되어 강력한 멀티모달 제너럴리스트 시스템이 될 수 있음을
       입증했습니다. 또한 입력 이미지에 그려진 시각적 마커를 이해하는 GPT-4V의 고유한 기능은 시각적 참조 프롬프트와 같은 새로운 인간-컴퓨터 상호 작용 방법을 창출할 수 있습니다. 본 보고서에서는 새로운 응용 시나리오와 GPT-4V 기반 시스템의 향후 연구 방향에 대한 심도 있는 논의를 끝으로 보고서를 마무리합니다. 이 예비 탐색이 차세대 멀티모달 작업 공식화, 실제 문제 해결을 위해 LMM을 활용하고 향상시키는 새로운 방법, 멀티모달 기반 모델에 대한 더 나은 이해에 대한 향후 연구에 영감을 줄 수 있기를 기대합니다.

     Large multimodal models (LMMs) extend large language models (LLMs) with multi-sensory skills, such as visual understanding, to achieve stronger generic intelligence. In this paper, we analyze the latest model, GPT-4V(ision), to deepen the understanding of LMMs. The analysis focuses on the intriguing tasks that GPT-4V can perform, containing test samples to probe the quality and genericity of GPT-4V's capabilities, its supported inputs and working modes, and the effective ways to prompt the model. In our approach to exploring GPT-4V, we curate and organize a collection of carefully designed qualitative samples spanning a variety of domains and tasks. Observations from these samples demonstrate that GPT-4V's unprecedented ability in processing arbitrarily interleaved multimodal inputs and the genericity of its capabilities together make GPT-4V a powerful multimodal generalist system. Furthermore, GPT-4V's unique capability of understanding visual markers drawn on input images
     can give rise to new human-computer interaction methods such as visual referring prompting. We conclude the report with in-depth discussions on the emerging application scenarios and the future research directions for GPT-4V-based systems. We hope that this preliminary exploration will inspire future research on the next-generation multimodal task formulation, new ways to exploit and enhance LMMs to solve real-world problems, and gaining better understanding of multimodal foundation models.

    논문 링크

   https://arxiv.org/abs/2309.17421

    더 읽어보기

   https://x.com/omarsar0/status/1708860551110041871

   https://discuss.pytorch.kr/t/gn-chatgpt/2543
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  말하기 전에 먼저 생각하세요: 일시 정지 토큰으로 언어 모델 학습하기 / Think before you speak: Training Language Models With Pause Tokens

    논문 소개

     * 학습 가능한 <pause> 토큰을 사용하여 llms에 대한 학습 및 추론을 수행하여 모델의 답변 생성을 지연시키고 상식적인 질의응답 및 수학 단어 문제 해결과 같은 일반적인 이해 작업에서 성능 향상을 달성하는 데 도움이 됩니다. 실험 결과, 관련 및 다운스트림 미세 조정 모두에서 지연이 도입되는 경우에만 이점이 있는 것으로 나타났습니다. #pause-for-thought

     Performs training and inference on llms with a learnable <pause> token which helps to delay the model's answer generation and attain performance gains on general understanding tasks of commonsense qa and math word problem-solving; experiments show that this is only beneficial provided that the delay is introduced in both pertaining and downstream fine-tuning.

    논문 초록

     * 언어 모델은 일련의 토큰을 연속적으로 생성하여 응답을 생성합니다. $(K+1)^{th}$ 토큰은 레이어당 $K$ 개의 숨겨진 벡터를 조작한 결과이며, 이전 토큰당 하나의 벡터를 조작한 결과입니다. 대신 모델이 $(K+1)^{th}$ 토큰을 출력하기 전에 $K+10$ 개의 숨겨진 벡터를 조작하도록 한다면 어떨까요? 이 아이디어는 입력 접두사에 추가되는 시퀀스인 (학습 가능한) $\textit{pause}$ 토큰으로 언어 모델에 대한 학습과 추론을 수행함으로써 작동합니다. 그런 다음 마지막 일시 중지 토큰이 표시될 때까지 모델의 출력 추출을 지연시켜 모델이 답을 내리기 전에 추가 계산을 처리할 수 있도록 합니다. C4에 대한 인과적 사전 학습이 포함된 1B 및 1억 3천만 개의 매개변수로 구성된 디코더 전용 모델과 추론, 질문-답변, 일반적인 이해 및 사실 회상을 포함하는 다운스트림 작업에서
       $\textit{pause-training}$ 을 경험적으로 평가합니다. 주요 결과는 모델을 사전 학습하고 지연을 통해 미세 조정할 때 추론 시간 지연이 개선된다는 것입니다. 1B 모델의 경우, 9개 과제 중 8개 과제에서 개선이 있었으며, 가장 눈에 띄는 것은 SQuAD의 QA 과제에서 $EM\ 점수가\ 18%$, $CommonSenseQA에서\ 8%$, $GSM8k의\ 추론\ 과제에서\ 정확도가\ 1%$ 향상되었다는 점입니다. 저희의 연구는 지연된 다음 토큰 예측을 널리 적용할 수 있는 새로운 패러다임으로 만들기 위한 다양한 개념적, 실용적 미래 연구 질문을 제기합니다.

     Language models generate responses by producing a series of tokens in immediate succession: the $(K+1)^{th}$ token is an outcome of manipulating $K$ hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, $K+10$ hidden vectors, before it outputs the $(K+1)^{th}$ token? We operationalize this idea by performing training and inference on language models with a (learnable) $\textit{pause}$ token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate $\textit{pause-training}$ on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that inference-time delays show gains when the model is
     both pre-trained and finetuned with delays. For the 1B model, we witness gains on 8 of 9 tasks, most prominently, a gain of $18%$ EM score on the QA task of SQuAD, $8%$ on CommonSenseQA and $1%$ accuracy on the reasoning task of GSM8k. Our work raises a range of conceptual and practical future research questions on making delayed next-token prediction a widely applicable new paradigm.

    논문 링크

   https://arxiv.org/abs/2310.02226

    더 읽어보기

   https://x.com/omarsar0/status/1709573238123122959
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  자가 학습 최적화 도구(STOP): 재귀적으로 스스로 개선되는 코드 생성 / Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation

    논문 소개

     * 언어 모델이 주입된 스캐폴딩 프로그램을 사용하여 재귀적으로 스스로를 개선하고, 시드 개선자가 먼저 최상의 솔루션을 반환하는 입력 프로그램을 개선한 다음 추가 작업을 통해 스스로를 개선하고, gpt-4 모델이 스스로를 개선하기 위해 스스로를 호출할 수 있는 코드를 작성할 수 있음을 보여 줍니다. #self-training-survey-paper

     Proposes the use of a language model-infused scaffolding program to recursively improve itself; a seed improver first improves an input program that returns the best solution which is then further tasked to improve itself; shows that the gpt-4 models can write code that can call itself to improve itself.

    논문 초록

     * 최근 AI 시스템의 몇 가지 발전(예: 사고의 나무 및 프로그램 지원 언어 모델)은 언어 모델에 대한 여러 호출을 구조화하여 더 나은 출력을 생성하는 '스캐폴딩' 프로그램을 제공함으로써 문제를 해결합니다. 스캐폴딩 프로그램은 Python과 같은 프로그래밍 언어로 작성됩니다. 이 작업에서는 언어 모델이 주입된 스캐폴딩 프로그램을 사용하여 스스로 개선합니다. 언어 모델을 여러 번 쿼리하고 최적의 솔루션을 반환하여 주어진 유틸리티 함수에 따라 입력 프로그램을 개선하는 시드 '개선자'로 시작합니다. 그런 다음 이 시드 임프로버를 실행하여 스스로 개선합니다. 작은 다운스트림 작업 세트에 걸쳐 결과적으로 개선된 개선자는 시드 개선자보다 훨씬 더 나은 성능을 가진 프로그램을 생성합니다. 그런 다음 빔 검색, 유전 알고리즘, 시뮬레이션 어닐링 등
       언어 모델에서 제안한 다양한 자체 개선 전략을 분석합니다. 언어 모델 자체는 변경되지 않으므로 완전한 재귀적 자기 개선은 아닙니다. 그럼에도 불구하고 개념 증명 실험에서 최신 언어 모델인 GPT-4가 스스로를 개선하기 위해 호출할 수 있는 코드를 작성할 수 있다는 것을 보여줍니다. 저희는 자기 개선 기술 개발에 대한 우려를 비판적으로 고려하고 생성된 코드가 샌드박스를 우회하는 빈도를 평가합니다.

     Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a ""scaffolding"" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed ""improver"" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered,
     this is not full recursive self-improvement. Nonetheless, it demonstrates that a modern language model, GPT-4 in our proof-of-concept experiments, is capable of writing code that can call itself to improve itself. We critically consider concerns around the development of self-improving technologies and evaluate the frequency with which the generated code bypasses a sandbox.

    논문 링크

   https://arxiv.org/abs/2310.02304

    더 읽어보기

   https://x.com/ericzelikman/status/1709721771937587541
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  RA-DIT: 검색 증강 이중 명령어 튜닝 / RA-DIT: Retrieval-Augmented Dual Instruction Tuning

    논문 소개

     * 검색 기능을 갖춘 인공신경망에 경량 미세 조정 방법을 제안합니다. 1) 사전 학습된 인공신경망을 업데이트하여 검색된 정보를 더 잘 활용하고 2) 검색기가 더 관련성 높은 결과를 반환하도록 업데이트하는 2단계 접근 방식을 포함합니다. 결과는 지식 활용과 문맥 인식이 모두 필요한 작업에 대한 미세 조정이 각 단계에서 추가적인 이득으로 이어짐을 보여줍니다. 65b 모델은 다양한 지식 집약적 제로 샷 및 소수 샷 학습 벤치마크에서 최첨단 결과를 달성하며 기존 검색 증강 언어 접근 방식보다 최대 +8 % 더 우수한 성능을 발휘합니다.제로 샷에서는 9%, 5샷에서는 +1.4%. #rag #instruct-tuning

     Proposes a lightweight fine-tuning method to retrofit llms with retrieval capabilities; it involves a 2-step approach: 1) updates a pretrained lm to better use the retrieved information 2) updates the retriever to return more relevant results, as preferred by the lm results show that fine-tuning over tasks that require both knowledge utilization and contextual awareness, each stage leads to additional gains; a 65b model achieves state-of-the-art results on a range of knowledge-intensive zero- and few-shot learning benchmarks; it outperforms existing retrieval-augmented language approaches by up to +8.9% in zero-shot and +1.4% in 5-shot.

    논문 초록

     * 검색 증강 언어 모델(RALM)은 외부 데이터 저장소의 롱테일 및 최신 지식에 액세스하여 성능을 향상시키지만 구축하기가 어렵습니다. 기존 접근 방식은 LM 사전 학습에 많은 비용이 드는 검색 관련 수정 작업을 수행하거나 데이터 저장소의 사후 통합을 사용해야 하므로 성능이 최적화되지 않습니다. 저희는 검색 기능이 있는 모든 LLM을 개조하여 세 번째 옵션을 제공하는 경량 미세 조정 방법론인 검색 증강 이중 명령어 튜닝(RA-DIT)을 소개합니다. 유니티의 접근 방식은 두 가지 미세 조정 단계로 작동합니다: (1) 하나는 검색된 정보를 더 잘 활용하도록 사전 학습된 LM을 업데이트하고, (2) 다른 하나는 LM이 선호하는 대로 더 관련성 높은 결과를 반환하도록 검색기를 업데이트하는 것입니다. 지식 활용과 문맥 인식이 모두 필요한 작업에 대한 미세 조정을 통해 각
       단계가 상당한 성능 향상을 가져오고, 두 단계를 모두 사용하면 추가적인 이득을 얻을 수 있음을 입증했습니다. 최고의 모델인 RA-DIT 65B는 다양한 지식 집약적 제로 샷 및 소수 샷 학습 벤치마크에서 최첨단 성능을 달성하여 기존의 인컨텍스트 RALM 접근 방식보다 평균적으로 0샷 설정에서 최대 +8.9%, 5샷 설정에서 +1.4%의 성능을 크게 뛰어넘습니다.

     Retrieval-augmented language models (RALMs) improve performance by accessing long-tail and up-to-date knowledge from external data stores, but are challenging to build. Existing approaches require either expensive retrieval-specific modifications to LM pre-training or use post-hoc integration of the data store that leads to suboptimal performance. We introduce Retrieval-Augmented Dual Instruction Tuning (RA-DIT), a lightweight fine-tuning methodology that provides a third option by retrofitting any LLM with retrieval capabilities. Our approach operates in two distinct fine-tuning steps: (1) one updates a pre-trained LM to better use retrieved information, while (2) the other updates the retriever to return more relevant results, as preferred by the LM. By fine-tuning over tasks that require both knowledge utilization and contextual awareness, we demonstrate that each stage yields significant performance improvements, and using both leads to additional gains. Our best model,
     RA-DIT 65B, achieves state-of-the-art performance across a range of knowledge-intensive zero- and few-shot learning benchmarks, significantly outperforming existing in-context RALM approaches by up to +8.9% in 0-shot setting and +1.4% in 5-shot setting on average.

    논문 링크

   https://arxiv.org/abs/2310.01352

    더 읽어보기

   https://x.com/omarsar0/status/1709204756013490494
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  Kosmos-G: 멀티모달 대규모 언어 모델을 사용하여 컨텍스트에 맞는 이미지 생성 / Kosmos-G: Generating Images in Context with Multimodal Large Language Models

    논문 소개

     * 여러 이미지에 걸친 일반화된 비전 언어 입력에서 고충실도 제로샷 이미지 생성을 수행하고, 제로샷 피사체 중심 이미지 생성을 다중 엔티티 시나리오로 확장하며, 클립을 대체하여 컨트롤넷, 로라 등 다른 U-Net 기술로 새로운 애플리케이션의 잠금을 해제할 수 있는 모델입니다. #multimodal

     A model that performs high-fidelity zero-shot image generation from generalized vision-language input that spans multiple images; extends zero-shot subject-driven image generation to multi-entity scenarios; allows the replacement of clip, unlocking new applications with other u-net techniques such as controlnet and lora.

    논문 초록

     * 최근 텍스트-대-이미지(T2I) 및 시각-언어-대-이미지(VL2I) 생성 기술이 크게 발전했습니다. 그러나 특히 여러 이미지를 포함하는 일반화된 시각 언어 입력으로부터의 생성은 아직 충분히 연구되지 않은 상태입니다. 이 논문에서는 앞서 언급한 과제를 해결하기 위해 다중 모드 대규모 언어 모델(MLLM)의 고급 인식 기능을 활용하는 모델인 Kosmos-G를 소개합니다. 당사의 접근 방식은 텍스트 양식을 앵커로 사용하여 MLLM의 출력 공간을 CLIP과 정렬하고 큐레이팅된 데이터에 대해 구성 명령어 튜닝을 수행합니다. 코스모스-G는 제로샷 멀티 엔티티 피사체 중심 생성이라는 독보적인 기능을 보여줍니다. 특히 스코어 증류 인스트럭션 튜닝은 이미지 디코더를 수정할 필요가 없습니다. 따라서 CLIP을 원활하게 대체하고 세밀한 제어부터 개인화된 이미지 디코더 변형에
       이르기까지 무수히 많은 U-Net 기술과 손쉽게 통합할 수 있습니다. 우리는 코스모스-G를 ""이미지 생성에서 외국어로서의 이미지""라는 목표를 향한 초기 시도로 간주합니다

     Recent advancements in text-to-image (T2I) and vision-language-to-image (VL2I) generation have made significant strides. However, the generation from generalized vision-language inputs, especially involving multiple images, remains under-explored. This paper presents Kosmos-G, a model that leverages the advanced perception capabilities of Multimodal Large Language Models (MLLMs) to tackle the aforementioned challenge. Our approach aligns the output space of MLLM with CLIP using the textual modality as an anchor and performs compositional instruction tuning on curated data. Kosmos-G demonstrates a unique capability of zero-shot multi-entity subject-driven generation. Notably, the score distillation instruction tuning requires no modifications to the image decoder. This allows for a seamless substitution of CLIP and effortless integration with a myriad of U-Net techniques ranging from fine-grained controls to personalized image decoder variants. We posit Kosmos-G as an
     initial attempt towards the goal of ""image as a foreign language in image generation.""

    논문 링크

   https://arxiv.org/abs/2310.02992

    더 읽어보기

   https://x.com/omarsar0/status/1709934741158510625
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  유추 추론자로서의 대규모 언어 모델 / Large Language Models as Analogical Reasoners

    논문 소개

     * 이 접근 방식은 추론 프로세스에 대한 레이블이 지정된 예시가 필요하지 않다는 점에서 연쇄 사고와 다르며, 유추 추론에서 영감을 받아 맥락에서 관련 예시나 지식을 스스로 생성하도록 유도하는 새로운 프롬프트 접근 방식입니다. #llm-reasoning #chain-of-thought

     A new prompting approach to automatically guide the reasoning process of llms; the approach is different from chain-of-thought in that it doesn’t require labeled exemplars of the reasoning process; the approach is inspired by analogical reasoning and prompts lms to self-generate relevant exemplars or knowledge in the context.

    논문 초록

     * 언어 모델에 대한 연쇄적 사고(CoT) 프롬프트는 추론 작업 전반에서 인상적인 성능을 보여주지만, 일반적으로 추론 과정의 예시 라벨이 필요합니다. 이번 연구에서는 대규모 언어 모델의 추론 과정을 자동으로 안내하도록 설계된 새로운 프롬프트 접근 방식인 유추 프롬프트를 소개합니다. 인간이 새로운 문제를 해결하기 위해 관련성 있는 과거 경험을 활용하는 인지 과정인 유추 추론에서 영감을 얻은 이 접근 방식은 언어 모델이 주어진 문제를 해결하기 전에 맥락에 맞는 예시나 지식을 스스로 생성하도록 프롬프트합니다. 이 방법은 예제에 라벨을 붙이거나 검색할 필요가 없어 일반성과 편의성을 제공하며, 생성된 예제와 지식을 각 문제에 맞게 조정할 수 있어 적응성을 제공한다는 몇 가지 장점이 있습니다. 실험 결과에 따르면 이 접근 방식은 GSM8K 및
       MATH의 수학 문제 해결, Codeforces의 코드 생성, BIG-Bench의 기타 추론 작업 등 다양한 추론 작업에서 0샷 CoT 및 수동 소수 샷 CoT보다 우수한 성능을 보였습니다.

     Chain-of-thought (CoT) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, Analogical Prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot CoT and manual few-shot CoT in a variety of reasoning tasks, including math
     problem solving in GSM8K and MATH, code generation in Codeforces, and other reasoning tasks in BIG-Bench.

    논문 링크

   https://arxiv.org/abs/2310.01714

    더 읽어보기

   https://x.com/michiyasunaga/status/1709582150025240854

  원문

   https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-9d9
"
"https://news.hada.io/topic?id=11201","피타고라스보다 1000년 더 오래된 점토판에 발견된 피타고라스의 정리 (2009)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             피타고라스보다 1000년 더 오래된 점토판에 발견된 피타고라스의 정리 (2009)

        Hacker News 의견

     * 피타고라스는 다양한 문화에서 지혜를 축적하고 여러 신비주의 종교에 입문한 것으로 알려져 있다.
     * 피타고라스의 시대에는 수학과 영성 사이의 관계가 강했다.
     * 피타고라스는 피타고라스의 정리를 발견한 후 100마리의 황소를 제물로 바친 것으로 전해진다.
     * 직사각형 구조물을 지은 많은 문화권에서는 피타고라스 이전에 변의 길이와 대각선 사이의 관계를 파악했다.
     * 기사에서 언급된 바빌론의 정제판은 이 정리를 증명하지 않지만, 그리스인들은 그렇게 했다.
     * sqrt(2)=1+24/60+51/60^2+10/60^3의 근사값은 단순한 아이디어에 기반하고 있으며, 제곱근에 대한 긴 나눗셈 알고리즘으로 코딩될 수 있다.
     * 서양 문화는 고대 그리스에 대한 깊은 매료감을 가지고 있으며, 이는 우리 과학의 어휘에 반영되어 있다.
     * 19세기와 20세기의 고고학적 발견들은 역사가 고대 그리스보다 수천 년 더 깊게 이어진다는 것을 보여주었다.
     * 피타고라스의 정리는 수세기 동안 경험적으로 알려져 있었지만, 피타고라스는 대부분의 직각 삼각형에 대해, 다리 A와 빗변 C에 대해 PA = QC인 유리수 P, Q가 없다는 것을 처음으로 증명했다.
     * 바빌로니아인들은 피타고라스의 정리를 ""발견""했다고 말하지만, 그들이 그것을 연역적으로 증명했다는 증거는 없다.
     * 고대의 지식은 종종 구두로 전달되거나 이후에 부식된 자료에 기록되어 발견의 오인을 초래했다.
     * 피타고라스의 정리는 피타고라스 이전의 중국에서 알려져 있었으며, 이는 2600년 된 중국의 책에 의해 입증되었다.
"
"https://news.hada.io/topic?id=11217","한국신용데이터 분석","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               한국신용데이터 분석

   한국신용데이터: 국내 핀테크 3번째 유니콘에 대한 분석.
    1. thesis
       ○ 금융의 frontend를 바꾸다.
       a. 금융의 변하지 않은 본질은 장부에 담긴 정보
       b. 동사는 사업자 대상 금융 산업의 frontend 혁신으로 모바일 장부 속 정보 독점적 소유
       ○ 금융의 backend를 바꾸다.
       a. 자영업자 대상의 중금리 대출 시장의 의사결정은 리스크 관리에 최우선
       b. 사업 실적등의 실질 데이터 반영하지 못하는 문제 발생
       c. 동사의 데이터 활용해 위 문제 해결하고자 CB사 설립 및 은행업에 도전
       => 이를 위해 연 240조 규모의 데이터를 바탕으로 다음을 성공시켜야
       [1] 수직확장한 계열사들의 매출 확장
       [2] 자영업 특화은행으로의 진출
       [3] 식자재 시장 진출
    2. founding story
       ○ 아이디인큐 exit 후 4개월만에 연쇄창업
       ○ 핀테크 흐름 속의 변화 포착, 자영업자의 금융 생활 혁신하는 서비스 창업
    3. product
       ○ 캐시노트 (고객과 접점 확보)
       ○ 한국평가정보 (국내 최초 전업 개인사업자 신용평가사)
       ○ 한국결제네트워스, 아임유 (VAN, POS사)
       ○ 한국사업자경험 (토스CX와 유사한 포지션)
       ○ 한국비즈커넥트 (정부 정책 및 지원 사업 안내)
    4. market
       4.1) customer: 200만 동네 가게 사장님
       4.2) market size: bottom up으로 약 8조원 / 개인사업자 대출 시장은 연간 1000조에 이름.
    5. traction
       ○ PMF 검증: 17년 출시 후 3개월만에 1000개 고객사 확보
       ○ 그로스: 점유율 50% 이상으로 확장
       ○ 고객경험/수익성 강화: M&A로 공동체 확장, 광고 매출 강화
    6. business model
       ○ VAN/POS 서비스 매출 (약 90%)
       ○ 캐시노트 구독 / 광고 매출 (약 10%)
    7. competition
       ○ 캐시노트는 압도적 사업자
       ○ 금융상품 중개에선 토스와 카카오페이와 경쟁
       ○ 개인사업자 CB업에선 전통 은행과 핀테크 기업과 경쟁
    8. valuation
       ○ 금융 상품 중개업으로 평가 시 상방은 카카오페이
       ○ 종합 금융 플랫폼으로 평가 시 상방은 미국의 Square (cap $45B)
    9. key opportunities
       ○ 데이터와 생태계
       ○ 챌린저 뱅크 설립
       ○ 식자재 마켓으로 확장
   10. key risks
       ○ 수익성 증명
       ○ 금융업 고유의 리스크
"
"https://news.hada.io/topic?id=11155","12,000년된 현실적인 인간 조각상 발굴","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        12,000년된 현실적인 인간 조각상 발굴

     * Göbeklitepe와 Karahantepe에서 새로운 고고학적 발견, 현실적인 인간 조각상 포함
     * 약 12,000년 전의 Göbekli Tepe, 세계에서 가장 오래된 대형석조 시설, Karahantepe라는 '자매 사이트'가 있다.
     * Göbeklitepe에서 발견된 그림이 그려진 멧돼지 조각상, 그 시대 최초의 그림 조각상
     * H자형 심볼, 초승달, 두 개의 뱀, 세 개의 인간 얼굴 또는 가면 등 다양한 장식으로 장식된 받침대에서 멧돼지 조각상 발견
     * Karahantepe에서 발견된 인간 조각상은 가장 현실적인 시대의 조각상 중 하나로, 높이 2.3미터에 이르며 생생한 표정을 보여줌
     * 조각상은 두 손으로 생식기를 잡고 있는 인물을 묘사하며, 이는 2021년 Sayburç 발굴에서 발견된 유사한 relief와 뚜렷한 차이점을 보여줌
     * 조각상은 땅에 고정된 벽감에서 발견되었으며, 강조된 늑골, 척추, 어깨뼈를 가진 사망한 인간의 이미지를 강하게 연상시킴
     * 같은 지역에서 벽에 배치된 독수리 조각상과 땅에 남겨진 돌판도 발견되었음
     * 최근 터키 Şanlıurfa 지방에서의 연구는 선도기 신석기 시대 내에서 다른 단계를 나타내는 정착지를 확인하였음
     * 이 정착지의 지역은 ""Taş Tepeler""로 명명되었으며, 이는 가장 오래된 정착지를 가진 아나톨리아와 상메소포타미아 지역을 의미함

        Hacker News 의견

     * 12,000년 전에 만들어진 사실적인 인간 동상의 발견이 인류 문명의 시작에 대한 기존 이론에 도전하며, 복잡한 창조물인 동상이 약 6,000년 전까지는 불가능하다고 여겨졌습니다.
     * 이 동상과 같은 장소에서 발견된 다른 대형 돌 기념물들은 이러한 예술을 위해 필요한 도구, 교육 기법, 그리고 사회 구조가 이전에 생각했던 것보다 훨씬 더 이른 시기에 존재했음을 시사합니다.
     * 동상의 생생한 얼굴 표정은 '인간의 보편성'으로 주목받았으며, 이는 모든 인간 문화와 시대에 걸쳐 일관된 특성으로, 우리의 공유된 인류성을 보여줍니다.
     * 동상의 발견은 고대 예술과 문화에 대한 관심과 감상을 불러일으켰으며, 일부 사용자들은 터키 고고학적 사이트에 대한 정보를 제공하는 YouTube 채널인 Miniminuteman과 같은 추가 학습 자료를 추천했습니다.
     * 이 발견은 또한 다른 묻힌 고고학적 사이트의 가능성에 대한 논의를 이끌어냈으며, 이들을 찾기 위해 이미징 위성이나 지하 투과 레이더를 사용하는 가능성에 대해 논의하였습니다.
     * 일부 사용자들은 동상의 사실성에 의문을 제기하였으며, 사진에서 얼굴이 빠져있음을 지적하고 '생생한' 얼굴 표정에 대한 강조를 의심하였습니다.
     * 이 발견은 예술의 '진보'와 세련미에 대한 논쟁을 촉발하였으며, 일부는 선사 시대 사람들이 현실을 모방하지 않기로 선택한 고도로 숙련된 돌 조각가들이었을 수 있다고 주장하였습니다.
"
"https://news.hada.io/topic?id=11204","구글 독스, 문서 내보내기 링크에 추적 기능 추가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      구글 독스, 문서 내보내기 링크에 추적 기능 추가

     * Google Docs가 문서 내보내기에서 링크 추적을 추가하는 것으로 밝혀졌으며, 특히 HTML 및 EPUB 형식에서 그렇습니다.
     * 이 사실은 Mastodon이 지원하는 분산형 소셜 네트워크인 fosstodon.org의 사용자에 의해 발견되었습니다.
     * 추적은 문서의 원래 링크를 대체하는 보이지 않는 Google 추적 리다이렉트를 통해 이루어집니다.
     * 이 방식은 Google의 제품을 사용하지 않는 사람들을 디자이너나 최종 사용자의 지식이나 동의 없이 추적할 수 있게 합니다.
     * 이를 발견한 사용자는 Google Docs 대신 Collabora Office, Etherpad, OnlyOffice, CryptPad 등을 제안하였습니다.
     * Collabora Office는 Libre Office 기술을 기반으로 한 무료 대안이며, Nextcloud 인스턴스가 있다면 쉽게 설치할 수 있습니다.
     * Etherpad, OnlyOffice, CryptPad도 협업 문서 편집에 추천됩니다.
     * 이 발견은 개인 정보 보호, 데이터 추적, 그리고 오픈 소스 대안이 대중 소프트웨어에 필요한지에 대한 논의를 촉발하였습니다.

        Hacker News 의견

     * Google Docs, 문서 내보내기 링크에 추적 기능 추가.
     * 이 기능은 Google Docs가 악성 소프트웨어 전파 수단으로 사용되는 것을 방지하는 조치로 사용됨.
     * 사용자가 Google을 떠나 다른 사이트로 이동할 때 경고하는 추적 기능, Google Docs를 통한 악성 소프트웨어 배포의 효과를 줄임.
     * 리디렉션의 명시적인 목적은 피싱을 방지하고, Google이 사용자에게 알려진 위험한 사이트 방문에 대해 경고하는 기회를 제공함.
     * Microsoft도 Teams에서 비슷한 기능을 사용하여 플랫폼 내에서 공유된 링크를 리디렉션하고 확인함.
     * CryptPad, Google Docs에 대한 오픈 소스 E2EE 대안이 개발 중. 실시간 문서 편집과 여러 사람들과의 협업을 가능하게 하며, 서버는 내용에 접근할 수 없음.
     * 고급 보호가 켜져 있는 경우 Gmail에서 IMAP를 통해 액세스한 이메일의 URL을 Google URL 리디렉터 서비스를 사용하도록 Google이 다시 작성함.
     * 추적 기능은 추적 목적만을 위한 것이 아니라, Google이 링크 목적지가 해로운 것으로 판단하면 사용자를 가로채는 것으로 믿어짐.
     * 일부 사용자들은 Google 제품을 사용하는 사람들이 개인 정보 보호나 활동 추적에 대해 걱정하지 않아야 한다고 믿음. 이러한 회사들의 사업은 사용자 데이터 채굴을 기반으로 함.
     * 링크는 리디렉션 공지를 트리거하고 새 탭에서 열리는 것으로 보이며, 이는 Google docs 편집기 내에서 좋은 행동으로 간주됨.
     * 링크 재작성이 내보낸 버전만을 위해 추가되지 않았다는 추측이 있지만, 내보낸 버전에서 제거되지 않은 것은 실망스러움.
"
"https://news.hada.io/topic?id=11171","298MB의 RAM에서 안정적으로 실행되는 Diffusion XL 1.0","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                298MB의 RAM에서 안정적으로 실행되는 Diffusion XL 1.0

     * 이 기사는 Raspberry Pi Zero 2라는 512MB RAM을 가진 마이크로 컴퓨터에서 Stable Diffusion XL 1.0을 실행하는 논의를 다룹니다.
     * 도전 과제는 스왑 공간을 늘리거나 중간 결과를 디스크에 오프로드하지 않고 거의 10억 개의 파라미터를 가진 대형 트랜스포머 모델인 Stable Diffusion 1.5를 실행하는 것입니다.
     * 저자는 메모리 소비를 최소화하는 데 초점을 맞춘 작고 해킹 가능한 추론 라이브러리인 OnnxStream을 만들었습니다.
     * OnnxStream은 추론 엔진과 모델 가중치를 제공하는 컴포넌트를 분리하여 모델 파라미터의 다양한 유형의 로딩, 캐싱, 프리페칭을 허용합니다.
     * OnnxStream은 OnnxRuntime보다 메모리를 55배 덜 소비하면서도 0.5-2배 느릴 뿐입니다.
     * 이 기사에는 OnnxStream을 사용하여 VAE 디코더의 다양한 정밀도에서 Stable Diffusion 예제 구현에 의해 생성된 이미지가 포함되어 있습니다.
     * OnnxStream Stable Diffusion 예제 구현은 이제 SDXL 1.0을 지원하며, 이는 SD 1.5보다 계산 비용이 더 많이 들지만 더 큰 이미지를 생성할 수 있습니다.
     * OnnxStream은 SDXL 1.0을 300MB 미만의 RAM에서 실행할 수 있어 Raspberry Pi Zero 2에 적합합니다.
     * 이 기사는 SDXL 1.0에 대한 특정 최적화를 논의하며, 이에는 메모리 소비를 4.4GB에서 298MB로 줄이기 위해 타일 디코딩을 사용하는 것이 포함됩니다.
     * OnnxStream의 기능에는 추론 엔진과 WeightsProvider의 분리, attention slicing, 동적 및 정적 양자화, FP16 지원 등이 포함됩니다.
     * 이 기사는 다양한 운영 체제에서 Stable Diffusion 예제를 구축하는 방법에 대한 자세한 지침을 제공합니다.
     * sd.cpp의 Stable Diffusion 구현은 다른 두 프로젝트를 기반으로 하며, NCNN 대신 OnnxStream을 사용하도록 수정되었습니다.

        Hacker News 의견

     * OnnxStream의 사용에 대한 기사, OnnxRuntime보다 메모리를 55배 덜 소비하면서 0.5-2배 느린 것으로 나타남.
     * 메모리 사용량과 추론 시간 간의 트레이드오프는 일부 시나리오에서 유리할 수 있으며, 동일한 RAM에서 더 큰 배치 크기를 허용할 수 있음.
     * 일부 사용자들은 invoke.ai를 통해 MacBook Pro에서 Stable Diffusion을 사용하고 있지만, 더 나은 매개변수화를 위한 추천을 찾고 있음.
     * 이 방법을 사용하여 이미지를 생성하는 데 오랜 시간이 걸린다는 기사 언급, Readme에는 11시간이 걸린다고 명시됨.
     * 메모리 사용량과 추론 시간 간의 트레이드오프는 지연 시간이 중요한 요소인 실시간 또는 거의 실시간 애플리케이션을 방해할 수 있음.
     * ""0.5-2배 느림""이라는 표현에 대한 혼동이 있음, 커뮤니티 내에서의 의사소통에서 명확성이 부족할 수 있음을 나타냄.
     * 일부 사용자들은 주요 오픈소스 모델을 실행하고 생성하기 위한 최소 요구 사항에 대한 요약을 찾고 있음.
     * 이 분야에서의 빠른 진전이 주목되며, 특히 지난 6-18개월 동안의 속도 향상이 인상적임.
     * Stable Diffusion 유형의 기술을 규제하려는 시도는 허사일 수 있음을 제안, 이러한 모델과 그들의 추론 인프라는 PS2에서 실행 가능한 크기로 축소될 수 있음.
     * 생성 시간이 길지만, 일부 사용자들은 Stable Diffusion이 Pi Zero와 같은 하드웨어에서 실행될 수 있다는 사실에 감탄함.
"
"https://news.hada.io/topic?id=11216","'Gov.uk 양식에 대한 접근 권한을 개방하다'","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      'Gov.uk 양식에 대한 접근 권한을 개방하다'

     * 정부 디지털 서비스(GDS)가 정부 부서의 디지털 양식 생성을 간소화하기 위해 GOV.UK Forms라는 온라인 양식 제작 도구 개발 중
     * 이 도구는 양식을 더욱 접근하기 쉽고 사용자 친화적으로 만들어, 양식을 처리하는 부서와 사용자 모두에게 시간을 절약하게 함
     * GOV.UK Forms는 현재 문제를 식별하고 해결하기 위해 소수 팀과 함께 사적 베타 테스트 중
     * '조기 접근'이라는 다음 단계에서는 더 많은 사용자가 제품을 시험하고 현재 기능만을 요구하는 양식을 만들 수 있게 될 것
     * 파산 서비스는 2022년 10월에 GOV.UK Forms를 사용하여 양식을 게시한 첫 번째 정부 기관이었음
     * 새로운 기능에는 라우팅 또는 건너뛸 수 있는 질문, 실시간 양식의 초안 작성, 그리고 질문에 대한 자세한 안내 추가가 포함됨
     * GDS는 사용자 인증을 위해 GOV.UK Signon에서 Auth0로 이동하고 사용자가 자신의 시험 계정을 만들 수 있도록 계획 중
     * 계획된 다른 기능에는 각 양식에 대한 분석 페이지, 제출 배달의 이메일 확인, 그리고 자세한 공개 로드맵이 있는 업데이트된 제품 페이지가 포함됨
     * '조기 접근' 단계는 2023년 11월에 시작할 예정이며, 2024년 상반기에 공개 베타 출시가 계획되어 있음
     * 공개 베타 출시 전에 작업할 예정인 미래의 기능에는 파일 첨부 업로드, 양식 완성 진행 상황 저장, 그리고 양식 내에서 서비스 결제가 포함됨
     * 현재는 중앙 정부 기관만 지원하고 있지만, GOV.UK Forms의 범위는 2024년 이후에 지방 공의회, NHS, 경찰을 포함하도록 확장될 것으로 예상됨

        Hacker News 의견

     * GOV.UK 생태계는 간결함, 일관성, 그리고 정적 HTML의 사용으로 다른 국가의 시스템에 비해 호평받고 있다.
     * GOV.UK 디자인 시스템 팀의 작업이 칭찬받으며, 다른 정부에서도 비슷한 이니셔티브를 기대한다.
     * 사용자들은 특히 COVID-19 팬데믹 기간 동안 Gov.uk 양식의 직관적이고 사용자 친화적인 특성을 감사한다.
     * 사용자가 시스템을 실행하는 데 관심이 있는 사람들을 위해 Docker 이미지, signon 서비스용 스텁, 그리고 Docker Compose 스택에 대한 링크를 제공한다.
     * 사용자가 gov.uk 페이지에서 progressive enhancement에 대해 놀라움을 표현하며, 이 기술이 구식인지 의문을 제기한다.
     * '랜딩 페이지' 패턴에서 양식의 과도한 사용이 비판되며, 원하는 양식이 같은 페이지에 있기를 선호한다.
     * 영국의 gov.uk 생태계는 디지털 경험, 특히 일본의 시스템과 비교할 때 칭찬받고 있다.
     * 사용자들은 gov.uk 팀의 작업에 대해 자부심을 표현하며, 다른 시스템 간의 청결함, 접근성, 예측 가능성을 강조한다.
     * 사용자가 gov.uk에서 제공하는 ""유지 가능한 소프트웨어 제작 방법에 대한 매뉴얼""을 추천하며, 이를 준수하면 소프트웨어 세계가 개선될 것을 제안한다.
"
"https://news.hada.io/topic?id=11276","지금까지 가장 큰 DDoS 공격, 최고치 398M rps 도달","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   지금까지 가장 큰 DDoS 공격, 최고치 398M rps 도달

     * 2023년 10월 11일에 초당 398백만 요청(rps)으로 최고치를 찍은 역대 가장 큰 DDoS (분산 서비스 거부) 공격을 Google이 성공적으로 완화했습니다.
     * 이 공격은 스트림 다중화를 기반으로 한 새로운 기술인 HTTP/2 Rapid Reset을 사용했습니다.
     * 이 공격의 규모는 매우 크며, 2023년 9월에 Wikipedia에서 보고된 전체 기사 조회수보다 2분 만에 더 많은 요청을 생성했습니다.
     * 이 공격은 Google 서비스, Google Cloud 인프라, 그리고 그들의 고객을 포함한 주요 인프라 제공업체를 대상으로 했습니다.
     * Google의 글로벌 로드 밸런싱 및 DDoS 완화 인프라는 공격에도 불구하고 서비스를 계속 운영할 수 있게 도왔습니다.
     * DDoS 공격은 인터넷을 향하는 웹사이트와 서비스를 방해하고, 대상에 대한 압도적인 인터넷 트래픽을 통해 접근 불가능하게 만드는 것을 목표로 합니다.
     * 이 공격은 널리 채택된 HTTP/2 프로토콜의 기능인 스트림 다중화를 활용하는 새로운 ""Rapid Reset"" 기술을 사용했습니다.
     * Google은 네트워크 가장자리에서 공격을 완화할 수 있었으며, 이는 가장자리 용량에 대한 중요한 투자를 활용한 것입니다.
     * Google은 HTTP/2 프로토콜 스택을 구현하는 다른 클라우드 제공업체 및 소프트웨어 유지 관리자와 함께 산업 간 대응을 조정하고, 공격 및 완화 방법에 대한 정보를 실시간으로 공유했습니다.
     * 이 공격에 대한 집단적 취약성은 CVE-2023-44487로 추적되고 있으며, CVSS 점수가 7.5 (10점 만점)인 고위험성 취약점으로 지정되었습니다.
     * HTTP 기반 작업을 인터넷에 제공하는 모든 기업이나 개인은 이 공격의 위험에 노출될 수 있습니다.
     * Google Cloud 고객은 Google의 글로벌 규모의 용량 투자를 활용하여 Cross-Cloud Network에서 응용 프로그램을 제공하고 보호할 수 있습니다.
     * 글로벌 또는 지역 Application Load Balancer를 사용하는 Google Cloud 고객은 Cloud Armor 항상 켜져 있는 DDoS 보호를 통해 CVE-2023-44487과 같은 취약점을 악용하는 공격을 빠르게 완화할 수 있습니다.
     * Google은 또한 Cloud Armor 사용자 정의 보안 정책의 배포와 AI 기반 Adaptive Protection을 통해 공격 트래픽을 보다 철저하게 감지, 분석, 완화하는 것을 권장합니다.

        Hacker News 의견

     * 지금까지 가장 큰 DDoS 공격에 대한 기사, 최고치는 398M rps를 넘어섬
     * 신종 HTTP/2 'Rapid Reset' DDoS 공격 및 HTTP/2 Zero-Day 취약점에 대한 논의가 진행 중으로, 이로 인해 기록적인 DDoS 공격이 발생했다.
     * 이러한 DDoS 공격을 수행하는 동기와 기업 클라우드 인프라에 대한 복잡한 공격을 개발하기 위해 많은 금액을 지출하는 이유에 대한 의문 제기
     * 공격이 경쟁사들이 비즈니스를 약화시키려는 시도 또는 외국 정부가 미국 기술 회사를 불편하게 하려는 시도로부터 비롯된 것일 수 있다는 추측
     * Google, AWS, 그리고 다른 주요 산업 플레이어들이 동시에 공격을 인지함
     * 주요 공급업체들이 이러한 대규모 공격을 어떻게 처리하는지, 공격을 완화하기 위해 실시간으로 조정하는지 아니면 자신들의 문제를 해결하는 데 집중하는지에 대한 호기심
     * 동일한 공격이 Cloudflare에게도 경험됨
     * DDoS 완화가 어떻게 작동하는지, Cloudflare 뒤에 웹사이트를 두어 DDoS 공격을 완화하는 것이 무엇을 의미하는지에 대한 의문 제기
     * 기사는 DDoS 공격의 일부로 사용된 HTTP2의 빠른 재설정 기능에 대한 추가 정보를 제공
     * 공격으로 인해 HTTP/2의 견고성에 대한 논의가 이루어지고 있으며, 제품에 대한 신뢰를 잃게 되면 더 많은 사람들이 HTTP/3/QUIC로 전환을 고려할 것인지에 대한 의문 제기
     * 이러한 공격의 기원에 대한 정보는 없으며, 대량의 하드웨어가 필요하다고 추측되며, 봇넷이 관여하지 않는 한 추적될 수 있다.
     * Cloudflare 및 기타 큰 공급업체들이 사용자에게 그들의 네트워크가 DDoS 공격에 참여하고 있는지 알려주는 것이 좋을 것이라는 제안
"
"https://news.hada.io/topic?id=11175","크롬북 플러스: 더 강력해진 성능과 AI 기능","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       크롬북 플러스: 더 강력해진 성능과 AI 기능

     * 기존 대비 2배의 성능, 2배의 메모리, 2배의 저장공간
     * $399 부터
     * 구글 포토 Magic Eraser, 어도비 포토샵 웹버전(별도 구독 필요), LumaFusion 지원
     * 2024년 까지 더 많은 AI 기능들이 크롬OS에 도입될 예정(글 작성, 이미지 생성)
          + AI 기반 데스크탑 배경 화면
          + 영상 대화할때 배경도 AI로 생성
     * 10월 8일부터 판매 시작(미국)
     * 모델들(모두 8GB+램, 128GB+ 저장소, 1080p+ 웹캠 내장)
          + Acer Chromebook Plus 515, FHD 15.6인치, 인텔 코어 i3+
          + Acer Chromebook Plus 514, FHD 14인치, AMD Ryzen 3+
          + ASUS Chromebook Plus CM34 Flip, FHD 14인치, AMD Ryzen 3+
          + ASUS Chromebook Plus CX34, FHD 14인치, 인텔 코어 i3+
          + HP Chromebook Plus 15.6, FHD 15.6인치, 인텔 코어 i3+
          + HP Chromebook x360, FHD 14인치, 인텔 코어 i3+
          + Lenovo Flex 5i Chromebook Plus, FHD 14인치, 인텔 코어 i3+
          + Lenovo Slim 3i Chromebook Plus, FHD 14인치, 인텔 코어 i3+

   은근히 개발자들이 쓰기에도 괜찮더라구요.
   에이서 713을 한동안 사용 했었는데, 백엔드 개발도 그렇고 안드로이드 개발도 큰 무리 없었던 기억 입니다.
   성능이 더 좋아진다니 나름 시장 점유율이 올라갈 것 같습니다.

   맞아요.. 리모트로 접속해서 작업하는 환경인 경우는 일부러 크롬북을 지급하기도 하더라구요.
"
"https://news.hada.io/topic?id=11184","ChatGPT API를 이용한 Hacker News 책 추천 정보 추출","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ChatGPT API를 이용한 Hacker News 책 추천 정보 추출

     * ChatGPT API를 사용하여 Hacker News (HN) 스레드에서 책 추천을 추출하는 기사
     * 저자가 ""book""이라는 단어를 제목에 포함하고 다른 페이지에 연결되지 않은 HN의 거의 200개의 이야기를 분석
     * 저자가 GPT API를 사용하여 데이터를 분류하고 정보를 JSON 형식으로 출력
     * 데이터는 Hacker News API에서 가져왔으며, 저자는 Chat Completions API를 호출하여 텍스트에서 책 제목, 저자, URL을 추출
     * 상위 50개의 책 추천이 나열되었으며, Abelson과 Sussman의 ""Structure and Interpretation of Computer Programs""이 가장 추천되었음
     * API가 때때로 유효한 JSON을 반환하지 않는 경우, 특히 ChatGPT가 ""thanks""라는 댓글에 응답하거나 질문할 때 발견
     * 저자가 제목이 없는 응답을 버리도록 프롬프트를 설계, ChatGPT가 때때로 특정 책의 제목 없이 저자의 언급을 포함하기 때문
     * 57k 댓글 처리는 GPT 3.5 터보 API를 사용하여 약 $40 비용 발생
     * 저자가 온도가 0일 때도 GPT의 결과가 호출마다 다르며, 이전 GPT-3 모델에 비해 더 큰 변동성을 보임을 발견
     * 저자가 GPT가 텍스트에서 링크를 식별할 수 있지만, URL 대신 잘린 링크 텍스트를 선택하는 것을 방지하기 위해 HTML 태그를 제거해야 함을 발견
     * 저자가 ChatGPT에 의한 JSON 출력과 작업에 사용된 프롬프트의 예를 공유했음
     * GPT에 의해 생성된 원시 데이터는 제목별로 정렬되어 추가 분석을 위해 공유되었음
     * 저자가 학습 연습으로 표의 Amazon URL에 Amazon 제휴 링크를 추가했음

        Hacker News 의견

     * Hacker News에서 ChatGPT API를 이용해 책 추천 정보 추출에 대한 기사
     * 일부 사용자들이 ChatGPT가 몇몇 책 추천 정보를 놓친 것으로 지적
     * 사용자가 ""books""라는 키워드를 이용해 Hacker News에서 책 추천 정보를 검색하고, 플랫폼에서 찾은 추천 정보의 품질을 칭찬
     * 사용자가 Hacker Recommended Books와 Hacker News Books 등 다른 책 추천 정보 리소스를 언급
     * 'Code' by Charles Petzold와 Knuth의 책 등 일부 책들이 상위 50 리스트에 빠진 것에 대해 일부 사용자들이 놀라움 표현
     * AI가 생성한 책 추천 정보의 품질에 대한 우려, 일부 사용자들이 이를 Amazon affiliate 링크 생성에 이용될 수 있다고 제안
     * 'How to Win Friends and Influence People'와 'Atlas Shrugged' 등 일부 책들이 리스트에 포함된 것에 대해 일부 사용자들이 의문 제기
     * 사용자가 'Meditations' by Marcus Aurelius가 Descartes의 'Meditations on First Philosophy'와 혼동되어 리스트에 오류가 있을 수 있다고 지적
     * 일부 사용자들이 Hacker News 게시물의 댓글에서 찾은 덜 인기 있는 책 추천 정보에 가치를 발견
     * ChatGPT를 이용하는 것의 필요성에 대한 의문, 일부 사용자들이 Algolia와 데이터 분석이 충분하다고 제안
"
"https://news.hada.io/topic?id=11265","Microsoft, Ignite 2023에서 첫번째 AI칩을 발표할 수도","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Microsoft, Ignite 2023에서 첫번째 AI칩을 발표할 수도

     * Microsoft의 연간 개발자 컨퍼런스 Ignite 2023은 11월 14~17에 개최될 예정
     * 소식통에 따르면 이때 최초의 전용 인공지능 칩을 공개할 수도 있음
     * 이 칩은 Microsoft의 데이터 센터 서버와 생산성 앱 전반에서 AI 기능을 강화하는 데 사용될 예정
     * NVIDIA는 GPU에 대한 높은 수요를 충족할 수 없으며, 이는 잠재적으로 Microsoft의 AI 기술에 영향을 미쳐 수익성에 영향을 미칠 수 있음
     * 코드명 Athena로 알려진 이 칩은 아마도 Nvidia H100 GPU와 비슷할 듯
"
"https://news.hada.io/topic?id=11185","Forbes가 선정한 탑 크리에이터 2023","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Forbes가 선정한 탑 크리에이터 2023

    1. MrBeast: 수익 $82M(년 110억원), 팔로워 3.1억명. 스낵바, 버거레스토랑 프랜차이즈 및 머천다이즈 라인을 구축. 회사 매각이 완료되면 Forbes 이사회의 멤버가 될 예정
    2. KSI: $24M, 1.1억명. 코미디언/복싱선수/래퍼. 스포츠 음료인 PRIME의 얼굴(6등인 Logan Paul과 함께)
    3. Jake Paul: $34M, 6600만명. Vine에서 스턴트로 인기를 얻다가 유튜버로 전환. 그리고 현재는 복싱선수로 변신. 스포츠 베팅 앱 ""Betr""을 만드는 회사 설립
    4. Rhett & Link : $35M, 5100만명. 초등학교 동창인 두명의 엔지니어. 2006년부터 유튜브에 코미디쇼를 올리기 시작. Mythical 이라는 회사를 차려서 100명이 넘게 근무하며, 버라이어티 쇼, 요리쇼, 코미디 등의 콘텐츠를 제작
    5. Charli D’Amelio : $23M, 2.1억명. 틱톡에서 유명한 최고의 여성 크리에이터. 프라다의 얼굴이며, 킴 카다시안의 의류브랜드 SKIMS의 광고 모델. 본인의 향수 Born Dreamer는 미국/유럽 전역의 매장에 진열. Hulu에서 ""The D'Amelio Show""의 세번째 시즌 촬영중. 신발 브랜드도 런칭. 이 모든게 그녀가 20살 이전에 이뤄낸 것(2004년생)
    6. Logan Paul: $21M, 7400만명. #3인 동생 Jake의 영상에서 인기를 얻고나서 자신의 채널을 개설. 복싱선수에서 WWE 레슬러로 전환. #2 KSI와 결투하기도
    7. F*ckJerry : $30M, 1700만명. Meme의 왕. 그의 수익은 파티게임인 ""What Do YoU Meme""을 비롯한 보드게임들을 타겟,월마트,아마존 등에서 전국적으로 판매하는 것에서 나옴. 데킬라 브랜드 Jaja도 출시
    8. Emma Chamberlain: $20M, 2800만명. 유머와 패션. 루이비통/까르띠에/랑콤/리바이스/캐논 등의 회사와 파트너십. 체임벌린 커피를 월마트에서 판매. 영상 팟캐스트는 Spotify 에서 독점
    9. Matt Rife : $25M, 2200만명. 스탠드업 코미디언. 인기를 이용해 라이브쇼 매진. 틱톡에서 여성팬과 농담을 주고 받는 영상으로 입소문을 탐. 넷플릭스에서 스탠드업 스페셜 ""Natural Selection"" 방영 예정
   10. Brent Rivera: $17.5M, 9600만명. Vine,Youtube,Tiktok. 코믹 동영상(종종 여동생 Lexi가 출연). 스타벅스,XBox,프라다 등과 파트너십. 다른 크리에이터 지원 회사인 Amp Studios를 운영

   팔로워수는 돈 버는 것과 크게 관련이 없네요. 순위 자체는 예상 수입, 팔로워수, 참여율, 기업활동 들을 합산한 거라고 합니다.
   총 50명인데요. 10위까지만 옮겼습니다. 그외에 특이한 사람들 몇명 더 옮겨보면
   17. Ryan Kaji : $35M, 3600만명. 9세에 장난감 언박싱 및 리뷰로 시작해서 인기를 얻고, 가족이 함께 Ryan's World 라는 회사로 전환. 장난감, 보드게임, 의류를 판매. 연 30억 조회수
   18. Dixie D'Amelio : $11.5M, 9100만명. 5위인 Charli D'Amelio 의 언니
   19. Marques Brownlee : $8.5M, 2900만명. 기술 제품 리뷰로 유명.
"
"https://news.hada.io/topic?id=11214","Krita 기금, 기업 지원 없음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Krita 기금, 기업 지원 없음

     * Krita 개발 기금은 현재 2023년을 위한 캠페인을 진행 중이며, 10명 이상의 전임 Krita 개발자를 지원하고 있습니다.
     * 이 기금은 Krita의 개발을 지원하기 위해 매달 $17k를 모으는 것을 목표로 하고 있습니다.
     * 현재 기금은 350명의 개인 기부자들로부터 매달 $5096를 받고 있습니다.
     * 현재 Krita 개발 기금에 대한 기업 지원은 없습니다.
     * 기금은 월 $5.80의 Bronze부터 월 $290의 Diamond까지 다양한 회원 등급을 제공합니다.
     * 기업 회원 옵션도 사용 가능합니다.
     * 회원들은 자신의 배지, 이름, 또는 회사를 공개하거나 비공개로 유지할 수 있는 옵션을 가지고 있습니다.
     * 기금은 또한 기부 총액에 이전 시스템에서의 기부를 인정합니다.
     * Krita 개발 기금은 인기 있는 오픈 소스 그림 프로그램인 Krita의 개발에 노력하는 Krita 재단을 지원합니다.

        Hacker News 의견

     * 사용자들이 오픈소스 그림 프로그램인 Krita에 대한 기업 지원 부족에 대해 논의 중
     * 한 사용자가 오픈소스 도구를 위한 소프트웨어 Bill of Materials (SBOMs)를 집계하는 도구를 제안, 이를 통해 다양한 프로젝트에 기부금을 분배하는 데 도움이 될 수 있음
     * 전문 사용자들은 종종 유료 도구를 선호하며, 가끔 사용하는 사용자들은 Krita와 같은 무료 도구를 선택하는 경향이 있어, 기업 기부금 확보가 어려움
     * 한 사용자가 협업 필요성으로 Krita에서 Photoshop으로 이동한 경험을 공유, 예술가들 사이에서 .psd 형식의 널리 사용되는 것을 강조
     * 다른 사용자가 Krita가 디지털 스토어에서 유료 버전을 제공하고 있어, 프로젝트에 안정적인 수입을 제공할 수 있음을 지적
     * 한 사용자가 기업 지원이 없다는 주장에 의문을 제기, Krita 웹사이트에 기업 후원자인 Intel에게 감사의 글을 인용
     * 한 사용자가 ""결국 오픈"" 라이선스 모델을 제안, 기업들이 최신 버전과 기능에 대해 지불하고, 취미로 하는 사람들은 상대적으로 최근의, 기능이 풍부한 릴리즈를 무료로 받음
     * 한 사용자가 상황을 HeartBleed 취약점과 비교, 중요한 프로젝트에 하나의 급여를 받는 사람만 있었음
     * 일부 사용자들이 Krita의 Wayland 지원 부족과 비표준 단축키를 비판, CSP와 Procreate와 같은 다른 도구와 경쟁력이 없다고 주장
     * 한 사용자가 오픈소스 애호가들이 소프트웨어에 대해 지불하는 것을 꺼리는 경향에 대해 논평, 이미 무료로 제공되는 것에 대해 지불함으로써 얻을 수 있는 추가적인 이점이 무엇인지 의문을 제기
"
"https://news.hada.io/topic?id=11176","ByteDance(틱톡), 1분기에 9.2조원($6.8B) 가까운 현금을 벌어들임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ByteDance(틱톡), 1분기에 9.2조원($6.8B) 가까운 현금을 벌어들임

     * 2023년 1분기 매출은 34% 상승한 33조원($24.5B)으로, 2022년 1분기 38% 성장보다는 느려짐
     * 하지만 9.2조원의 영업 현금을 창출하여 전년 동기의 7.8조원보다 개선 됨
     * 매출면에서는 1분기에 38조원이었던 Meta(페이스북)에 가까워 지고 있음
          + 바이트댄스는 자본 지출 내역을 공개하지 않기 때문에 FCF(잉여 현금 흐름)에 대해서는 비교는 불가
          + Meta는 1분기에 FCF에서 9.7조원($7.2B)를 만들어 냄
     * 바이트댄스의 현금 보유액은 2022년말 $22.3B에서 3/31기준 $30.4B로 증가
     * TikTok을 소유하고 있지만, 대부분의 수익은 중국내에서 서비스하는 같은 서비스 Dǒuyīn에서 내고 있음(국제판인 틱톡과는 분리된 서비스임)
     * 현재 추정 가치 약 300조원($223B)으로 세계 최대의 비상장 기업중 하나

   듀...인? 이 메인이군요

   중국 게임 시장에서도 유저들이 특정 분기의 게임 매출을 틱톡의 매출과 비교하고 그러더라구요. 원신이나 스타레일 같은 게임들...
"
"https://news.hada.io/topic?id=11161","Python 3.12 릴리즈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Python 3.12 릴리즈

     * 더 유연한 f-string 파싱 (PEP 701)
     * Python 코드에서 버퍼 프로토콜 지원 (PEP 688)
     * 새로운 디버깅/프로파일링 API (PEP 669)
     * Per-Interpreter GIL 지원으로 각 Sub-interpreter 당 별도의 GIL이 생성됨 (PEP 684)
     * 오류 메시지가 개선되었으며, 오타로 인해 발생할 수 있는 더 많은 예외가 사용자에게 제안됨
     * Linux perf 프로파일러를 지원하여 Trace에서 Python 함수 이름이 포함됨
     * 크고 작은 성능 개선으로 전체적으로 5%의 성능 향상
     * 일반 클래스를 위한 새로운 타입 주석 구문 (PEP 695)과 메소드를 위한 새로운 오버라이드 데코레이터 (PEP 698)가 도입
     * 유니코드 객체의 C 구현에 대한 wstr 및 wstr_length 멤버, unittest 모듈의 특정 메소드와 클래스, smtpd 및 distutils 모듈과 같은 사용 중단된 기능이 제거됨
     * 문자열에서 잘못된 백슬래시 이스케이프 시퀀스는 이제 DeprecationWarning 대신 SyntaxWarning으로 경고함
     * 성능 향상을 위한 준비로 정수의 내부 표현이 변경됨

   Per-Interpreter GIL은 흥미롭네요.

   What’s New In Python 3.12

        Hacker News 의견

     * Python 3.12, kwargs 유형 선언을 위한 새로운 문법 도입, 라이브러리에 필요한 데이터 이해도 향상
     * 새 버전에는 iterable을 청크로 분할하는 itertools.batched 포함, 환영받는 추가 기능
     * Python 3.12, 프로파일러, 디버거 및 기타 도구가 CPython 이벤트를 모니터링하기 위한 새로운 API 도입, 거의 제로 오버헤드 디버거 및 커버리지 도구 지원 가능
     * Python 3.12의 새로운 기능, 더 유연한 f-string 파싱, Python 코드에서 버퍼 프로토콜 지원, 새로운 디버깅/프로파일링 API, 별도의 Global Interpreter Locks를 가진 고립된 서브 인터프리터 지원 포함
     * 업데이트는 오류 메시지 개선, Linux perf 프로파일러가 추적에서 Python 함수 이름을 보고하는 지원, 많은 크고 작은 성능 향상도 가져옴
     * 제네릭 클래스를 위한 새로운 타입 주석 문법과 메소드를 위한 새로운 오버라이드 데코레이터도 업데이트의 일부
     * 사용 중단된 기능 제거, smtpd 및 distutils 모듈 포함, 성능 향상을 위한 준비로 정수의 내부 표현 변경
     * 사용자들은 오류 메시지 개선에 대한 감사를 표현하고, 디버깅을 더 쉽게하기 위한 실제 리치 텍스트 도입을 원함
     * 별도의 Global Interpreter Locks를 가진 고립된 서브 인터프리터 지원은 어떤 형태의 동시성 제공을 위한 중요한 단계로 간주됨
     * Python 3.12, 계산 집약적인 작업에서 눈에 띄는 성능 향상을 보여줌
     * 사용자들은 CPython 이벤트 모니터링을 위한 새로운 API인 PEP 669를 최적으로 활용하는 방법에 관심이 있음
"
"https://news.hada.io/topic?id=11260","Zimaboard: 내 꿈의 홈 서버 설정에 가장 가까운 것","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Zimaboard: 내 꿈의 홈 서버 설정에 가장 가까운 것

     * 저자의 Zimaboard 경험에 대한 기사, 이는 그가 이상적인 홈 서버 설정으로 가장 가깝게 생각하는 작은 단일 보드 컴퓨터입니다.
     * 저자의 꿈의 홈 서버 설정은 낮은 전력 사용, 8GB 이상의 RAM, 컨테이너화된 작업 부하를 실행할 충분한 성능, 2x SATA 또는 NVMe SSD 슬롯, 패시브 쿨링, 컴팩트한 크기, 그리고 기가비트 이더넷 이상을 포함합니다.
     * 저자가 구매한 Zimaboard 모델은 832 모델로, 8GB의 RAM, 32GB의 eMMC 저장 공간, 그리고 쿼드 코어 Intel Celeron N3450 CPU를 포함하며, 가격은 200 USD입니다.
     * Zimaboard는 세련된 제품 느낌, 케이스와 쿨링 설정, 그리고 무거운 부하 하에서 CPU를 약 72°C로 유지하는 실용적인 히트싱크를 포함하여 독특합니다.
     * 보드는 전원 공급이 연결되자마자 켜지므로 홈 서버 설정에 적합합니다.
     * Zimaboard는 운영 체제를 호스팅하기 위한 32GB eMMC 저장 공간과 추가 저장 공간을 위한 두 개의 SATA 포트를 포함합니다.
     * 저자는 두 개의 2.5"" 드라이브를 수용하는 디자인을 만들기 위해 3D 프린터를 사용했습니다.
     * Zimaboard의 전력 사용량은 낮으며, 두 개의 SSD가 부착된 최대 부하에서 2.5W에서 14W까지 측정됩니다.
     * Zimaboard의 성능은 저자의 홈 서버 작업, GPU 가속 트랜스코딩을 포함하여 적절합니다.
     * 저자는 Zimaboard와 함께 제공되는 Linux 기반 OS, CasaOS를 사용하지 않고, 대신 Fedora Server와 btrfs RAID1 설정을 선택했습니다.
     * 저자는 USB 3 포트에 대한 몇 가지 문제를 지적하고 PCI Express 포트는 테스트하지 않았습니다.
     * 저자는 Zimaboard의 성능, 낮은 전력 사용량, 조용함, 그리고 미적 매력에 대한 만족감을 표현하며 결론을 내립니다.

   이렇게 예쁜 디자인의 미니pc를 가지고 싶었는데 구매를 고려해봐야겠네요.

        Hacker News 의견

     * Zimaboard의 하드웨어는 2016년도의 오래된 디자인을 기반으로 하며, 가성비가 최고라고는 할 수 없다.
     * 같은 가격이나 더 낮은 가격에 더 좋은 기능과 성능을 가진 대안이 있다.
     * Zimaboard의 브랜딩과 스타일링은 평균-좋음으로 평가된다.
     * 일부 사용자들은 Zimaboard에서 광고된 것보다 저장 공간이 적거나 LAN에서 docker 서비스에 접근하는 데 어려움을 겪는 등의 문제를 경험했다.
     * Zimaboard에는 SATA 드라이브를 직접 장착하는 방법이 없지만, 제작자들은 별도의 금속 브래킷을 판매하고 있다.
     * Zimaboard에서는 ZimaCube와 Zima Blade와 같은 다른 제품들도 제공하며, 이들은 다른 기능을 제공한다.
     * Zimaboard의 대안으로는 Odroid HC4가 있으며, 이는 두 개의 Sata3 인터페이스를 가지고 있고 전력 소비가 더 적다.
     * 일부 사용자들은 무팬 디자인에 과도한 강조가 있어, 표준 미니 PC가 더 나은 선택일 수 있는데도 Zimaboard와 같은 특수 보드가 생겨나는 것을 보고 있다.
     * Zimaboard의 케이스 디자인은 매력적으로 여겨지지만, 일부 사용자들은 PCIe/SATA 포트를 위한 추가 케이스나 케이스가 필요하다는 점에서 그 실용성에 의문을 제기한다.
     * Zimaboard의 btrfs 사용은 특히 RAID 5 & 6 설정에서 문제가 있을 수 있다.
     * 더 빠른 네트워크 옵션을 원한다면, R86s 버전이 추천된다.
"
