"https://news.hada.io/topic?id=21395","Vassar Robotics (YC X25): 새로운 기술을 학습하는 219달러 로봇 팔 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Vassar Robotics (YC X25): 새로운 기술을 학습하는 219달러 로봇 팔 출시

     * Vassar Robotics는 219달러에 구매할 수 있는 저가형 로봇 팔을 출시함
     * 이 로봇 팔은 머신러닝을 활용해 다양한 동작과 작업을 새롭게 학습할 수 있음
     * 저렴한 가격과 높은 확장성으로 개발자, 교육기관, 스타트업에 이상적임
     * Vassar Robotics 팀은 로봇 공학의 대중화와 접근성 확대를 목표로 하고 있음
     * 사용자들은 직접 로봇 팔에 기술을 가르치고 자동화 솔루션으로 활용할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Vassar Robotics: 혁신적 로봇 팔 소개

     * Vassar Robotics는 YC X25 배치에 속한 스타트업으로, 219달러 가격의 저렴한 로봇 팔을 출시함
     * 이 로봇 팔은 기존 로봇 팔보다 상당히 낮은 가격으로 제공되어, 다양한 고객층이 쉽게 접근할 수 있도록 설계됨

주요 기능 및 장점

     * 머신러닝 기반 학습 기능을 통해 사용자가 새로운 동작이나 작업을 로봇 팔에 쉽게 가르칠 수 있음
     * 예를 들어, 특정 물건을 집거나 조립하는 동작을 사용자 스스로 직접 시연하여 로봇이 자동으로 이를 학습함
     * 모듈화된 설계를 기반으로 다양한 센서와 도구(그리퍼, 카메라 등)와 연동할 수 있음

타깃 사용자 및 활용 사례

     * 개발자, 교육기관, 하드웨어 스타트업 등이 직접 자동화 실험이나 시제품 제작에 활용 가능함
     * 반복적이고 정교한 작업을 로봇 팔이 대신 수행함으로써 생산성 향상 및 비용 절감 효과를 기대할 수 있음

Vassar Robotics의 비전

     * 로봇 공학 대중화와 자동화 기술의 민주화를 핵심 목표로 설정함
     * 제한된 예산 내에서도 고급 자동화 실험과 연구가 가능하도록 설계됨
     * 다양한 커뮤니티와 파트너십을 통해 로봇 학습 데이터 및 노하우를 공유하는 오픈 에코시스템을 지향함

결론

     * Vassar Robotics의 219달러 로봇 팔은 가격 혁신과 확장성, 학습 가능성을 동시에 제공함
     * 다양한 아이디어를 실험하고 자동화 시스템을 구축하고자 하는 개발자와 스타트업, 교육 기관에 매우 실용적인 선택지임

        Hacker News 의견

     * $219 가격대만으로도 구매 의향 생김
       정밀한 소근육 조정 능력 증가에 관심 많음
       특히 손재주가 필요한 DIY 조립 등에서 손목 자유도 추가나 길이가 더 긴 변형 제품 희망
       카메라 내장도 흥미롭지만, 직접 교체할 수 있는 모듈 방식 원함
       궁극적인 꿈은 집에 다관절 로봇 팔 여러 개 있는 테이블 구현
       노트북에서 떨리는 손으로 회로 기판, 작은 부품, 인두, 전선 등 네 개 로봇 팔로 제어하는 상상 즐김
          + 내가 표면실장 부품 납땜할 때마다 손이 떨려서 안정적인 손이 따로 있었으면 하는 바람 생김
            이 로봇 팔은 아쉽게도 그런 정밀도가 안 나옴
            우리가 사용하는 서보는 샤프트에 1도 정도의 유격이 있고, 메커니컬 구조 특성 때문에 오차 추가됨
            RC 서보 방식에서 정확도 높이려면 관절마다 서보 두 개를 미리 긴장시키는 방식이 필요
            계산은 해놨지만 이 가격에 제공하기 어렵다는 게 한계
            참고로, 학계 인기 로봇팔(ARX, Trossen 등)도 $10,000까지 가격 올라가도 완벽한 유격 해소는 불가(조금 낫지만 여전히 있음)
     * 웹사이트에 기술 스펙이 필요
       자유도(DoF), 관절 각도 센싱 유무와 해상도, 서보 인터페이스, 적재 하중, 모터 컨트롤러 내장 여부, 전체 길이, 작업 가능 공간 등 정보 궁금
       로보티스트로서 우선순위는

    1. 더 많은 자유도
    2. 교체형 툴(공구), 실제 툴 체인저까지는 힘들겠지만, 고정 볼트패턴과 전자 신호 통과 구조라도 있으면 좋겠음
    3. 더 나은 관절 센싱(앱솔루트 인코더, 관절 토크 센싱 등)
    4. 핑거팁(손끝) 힘 센싱

     * 의견 고마움
       ARX와 같은 운동학 만들려면 자유도 하나 추가할 수 있고, 가격은 $30~40 정도 증가 예상
       툴 체인저 아이디어도 훌륭함
       지인 몇 명이 키네마틱 커플링 연구 중이라 이 부품이 이상적일 듯
       전력과 신호 전달, 무게 최소화 고민 중
       인코더 관련해서 어떤 기능 필요할지 궁금
       현재 ST3215에 12비트 마그네틱 인코더 탑재로 전원 꺼져도 위치 유지 가능
       혹시 더 높은 해상도 원하는 건지, 토크 센싱은 주문량이 많으면 $20~30 내로 추가 가능
       손끝 힘 센서는 계란 집기 같은 상황에서 쓰고 싶은 것인지 궁금
     * ""SO-101 운동학 유지""라는 설명으로 봐서 LeRobot SO-101 문서와 거의 비슷, 5자유도+그리퍼, STS3215 서보 참고 사용
       $219 가격대에 이 모든 기능 추가는 불가능할 듯
     * 이게 실제 어떻게 가능한지 궁금
       비전문가 입장에서, 로봇에 명령했을 때 로봇이 제대로 움직이고 있다는 걸 어떻게 아는지 궁금
          + SO-ARM101에는 ""리더-암""이 있음
            리더-암은 동일한 크기와 같은 서보 사용하는 암으로, 손으로 직접 움직여 경로를 기록하거나 실시간 텔레오퍼레이션 가능
            팔로워-암은 데모 영상에서 보이는 장치
            작업 공간이나 암 베이스, 대상물의 위치 등 환경이 100% 제어 가능하면, 리더로 기록한 경로를 팔로워 암에 그대로 재생 가능
            머신러닝 없이도 이 방식 구현
            LLM(대형 언어 모델)로는 어떤 경로를 어떤 순서로 재생할지 긴 호리즌 지시에 따라 결정 가능한 구조
          + 그냥 봉에 모터 여러 개 달린 구조
            컴퓨터는 별도 없음
            그래도 1) 직접 팔 만드는 것 자체가 큰 프로젝트이고, 2) 하드웨어 표준화가 코드 재활용성에 핵심이기 때문에 $200 이상 가치 충분
     * 꼭 내가 SO-Arm101 만들려고 전자부품 다 주문하고 24시간 넘게 3D 프린트 돌리기 시작한 직후에 이 제품 나옴
       응원 보냄
          + 나도 똑같음
            리더 암 프린트 갓 끝났고, 팔로워 암은 또 20시간 프린트 남은 상황
          + 고맙다는 말 남김
            SO-101 디자인 써보고 불만 있으면 해결책 찾아볼 수 있을 것 같음
     * 최근에 아들이 로봇암 프로젝트 관련 관심 보이고 있는데, 이 제품 진짜 멋짐
       특히 취미용으로 접근하기 좋은 가격이라 만족
       AI까지 결합된 점이 8살 아들의 집중력을 끌어올리기에 최고의 요소
       혹시 영국에서도 구매 가능한지 궁금
       참고로 RC 비행기 조립 입문 난이도, FPV 쿼드콥터 드론과 비교해 어떤지 궁금
          + RC 비행기는 연습이 필요하고 FPV 드론보다 넓은 비행장이 필요
            시뮬레이터로 일주일 연습하고 실제로 2주 동안 여러 번 추락하면서 기본 감각 익혔음
            마치 로봇 파운데이션 모델에 새로운 신체움직임 훈련시키는 느낌
            직접 비행기를 조종하는 느낌이 쿼드콥터와 달리 자유롭고 재밌음
            영국에는 지역 동호회 많아 시작하기에 가장 좋은 환경
            나중에 경험 쌓인 아들이면 직접 소형 가스터빈 엔진 만드는 것도 재미
            GTBA - 영국 가스터빈 협회 추천
            영국 배송은 국제 배송 세팅 알아보고 오늘 중 답변할 예정
          + 조립에 초점을 둘 거면, 발사 키트에 엑토 나이프, 두 종류 순간접착제(굵은/얇은) + 가속제 있으면 충분
            글라이더부터 쉬운 빌드 추천, 가벼워서 추락해도 피해 적음
            내가 쉽게 만들었던 모델: Gambler
            비행이 목표라면 Easy Star 강추
            수십 번 부딪혀도 그냥 다시 붙이면 됨
            프로펠러가 뒷부분에 있어서 부딪혀도 손 다칠 확률 적어서 좋음
            시뮬레이터와 송수신기 바로 연동되는 케이블로 연습 가능
          + RC 비행기 조립이 조금 더 어렵게 느껴지지만 큰 차이 없음
            가장 큰 차이는 무게중심(Center-of-Gravity) 설정 필수
            조금만 잘못 잡아도 조종 완전히 달라짐
            컨트롤 링크(연결)와 서페이스 조정 등 손볼 일 더 있음
            이륙 방식도 가장 고민되는 지점
            지상에서 바퀴로 이륙하려면 낭비가 많고 뒤집어지기 쉬움
            손으로 던지는 방식은 연습 필요하고 특히 뒤 프로펠러 모델일 때 위험
            범퍼(고무줄) 발사대 만드는 사람도 있음
            조종 방식도 ""선이 보이는 비행(Line of Sight)""과 ""FPV"" 두 가지 옵션
            LOS 비행은 적응 난이도 높고 경로·방향 감각이 중요
            FPV는 훨씬 쉽고 보통 더 보람 참
            FPV 쿼드콥터보다 FPV 비행기가 도는 모드 등 부가기능 잘 작동함
            FPV 쿼드는 GPS 구조(Failsafe)가 거의 없다시피함
            욕구에 따라 강한 집중이 필요하면 쿼드, 여유롭게 즐기고 싶을 때는 FPV 비행기 추천
            비행기 소음이 거의 없어 주변 눈치도 덜 보고 마음 편함
          + RC 비행기도 쿼드콥터처럼 복잡도 조절 가능
            완성품, 반조립키트, 부품별 셀프 빌드 등 다양
            비행 방식이 달라져서, 쿼드콥터처럼 손 놓으면 자리 유지되는 게 아니라 조종 감각 다름
          + 영국 배송 방금 세팅 완료
            이제 바로 주문 가능
            궁금한 점 있으면 문의 바람
     * 품절 상태
       재입고 예정일 궁금
     * 키트 직접 구매 및 조립 의향 있으나, 조립 소요 시간 감이 필요
       이전에 3D 바이올린(조립+마감) 완성까지는 가능했으나, 3D 프린터 전체 조립은 시간과 공간 문제로 포기 경험
       패키지 구성과 조립 소요 시간 대략 범위라도 안내 가능하면 좋겠음
          + 좋은 질문
            SO-101 처음 조립하고 캘리브레이션하는 데 약 3시간 걸렸음
            이 제품은 SO-101을 베이스로, 몇 가지 설계 개선 포함
            경험치에 따라 다르지만, 평균 2~4시간 소요 예상
     * Amazon에도 입점하면 좋겠다는 제안
       강의에서 로봇 암 쓸 일이 있었는데, 대형 조직은 소규모 사이트 주문이 어려웠고, 아마존은 물류·발견성에서 이점
       수수료가 있어도 여러 기관에서 주문하는 데 실질적인 도움이 됨
          + 조언 고맙게 생각
            나 또한 대학 다닐 때 학교 공식 구매가 Amazon+몇몇 산업 전문 사이트만 가능
            현재는 제조·테스트에 집중해 최대한 빠르고 높은 품질로 제품 발송 우선
            이후 판매 채널 확대 계획
            현재 사용하는 서보에 토크·파워가 낮은 학생용 세이프 버전도 있음
            다만, 안전성과 작업 가능성이 상충
            수업용으로 ""더 안전한"" 버전에 관심 있는지 궁금
     * 이번에 바로 배송할 수 있을 것 같진 않음
       2025년 6월 14~15일 Hugging Face에서 이 로봇암으로 진행하는 글로벌 온라인 해커톤 있음
       LeRobot 해커톤
          + 해커톤 전에 배송 맞추려고 진짜 노력했는데 실패
            공급처 쫓는 건 연애 같음
            아무리 열심히 해도 잘 안 풀릴 때 있음
     * 질문
       로봇이 내장된 봉제 인형(플러시 토이) 구매 또는 제작 가능한지 궁금
       컴퓨터로 훈련시키고 프로그램을 인형에 다운로드하거나, WiFi 통신으로 텔레메트리 전송/동작 제어하고 싶음
       마이크, 스피커 등 센서 붙이고 싶음
"
"https://news.hada.io/topic?id=21340","내가 구글에 영혼을 팔았던 시절의 디스토피아 이야기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      내가 구글에 영혼을 팔았던 시절의 디스토피아 이야기

     * 저자는 구글(브라질)에서의 근무 경험을 통해 이상적인 기술 기업의 이미지와 실제 내부 현실 사이의 큰 괴리를 발견했음
     * 내부적으로 '20% 자율 시간' 등 복지를 약속받았지만, 대부분의 직원은 현실적으로 이를 누릴 수 없는 과중한 업무와 낮은 보상에 시달렸음
     * 구글 내부의 계급 구조에서 정직원 외에도 하청·임시직 등 차별받는 프레카리아트(불안정 노동자 집단) 의 존재와, 이들에 대한 무관심이 일상적으로 이루어졌음
     * 회사 문화적 다양성과 이상적 가치를 외치지만, 실제로는 감시 사회와 자본주의의 잔인함을 체험하게 하는 환경이 되었음
     * 이 경험을 통해 저자는 기술 산업 내 자본의 본질, 그리고 실제 권력과 착취 구조에 대한 비판적 시각을 갖게 되었음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

시작: 구글 경험을 기록함

     * 저자는 구글에서의 일을 처음으로 블로그를 통해 공개적으로 이야기하기로 결심했음
     * 구글에서의 퇴사와 그 배경을 솔직하게 풀어놓았으며, 이 글에서는 자본주의, 감시, 프레카리아트, 브라질의 2007년 사회상 등을 다룸

1. 반역 (Treason)

     * 2007년 구글은 최고의 직장이라는 이미지를 강조했고, “don’t be evil” 같은 독특한 슬로건을 내세웠음
     * '20% 시간' 정책과 자유로운 근무 환경이 홍보됐으나 실제로는 일상적인 잡무와 버그픽스, 과중한 업무에 시달림
     * 보상도 현지 시장 대비 낮은 임금이었으며, 직원 대부분이 자발적 자유시간을 사용하지 못했음
     * 내부 블로그에 이 문제를 지적하자, 상사는 “부정적인 말은 허용되지 않는다” 며 강하게 반발함
          + 내부에서 문제 인물로 낙인이 찍힘
     * 회사 내 “행복”은 의무적이고, 불만 표시는 곧 반역 취급을 받는 구조였음
     * '급진적 투명성' 을 표방하지만 실제로는 비판 자체가 허용되지 않는 권위주의적 조직 문화가 자리잡음

2. 구글 프레카리아트 1부: dictbot

     * 구글 입사 초기, 사내 용어를 쉽게 확인할 수 있도록 IRC 봇(dictbot) 을 만들었으나, 비정규직(temps, part-timers, contractors) 에게 정보가 노출된다는 이유로 비난받음
     * 정규직과 비정규직 사이의 뚜렷한 계급 장벽이 존재하며, 엔지니어 집단의 “특권” 유지를 위해 구조적으로 차별이 고착됨
     * 결국 저자의 봇 때문에 프레카리아트 직원들의 사전 접근이 공식적으로 제한되는 결과를 초래함

3. 프로젝트 Android의 탄식

     *
          + 사내 블로그에 “20% 시간” 신화에 대한 비판 글을 올린 후, 동료들로부터 지지와 응원을 받았으나, 조직 내 비판은 금기시됨
     * 프로젝트 Android에 참여한 동료도 프로젝트 방향성에 대한 실망을 블로그에 토로함
     * 며칠 후, 본인의 발언을 번복하며 프로젝트를 칭찬하는 글을 즉각적이고 부자연스럽게 올림
          + 비판적인 목소리는 빠르게 철회되고, 표면적으로만 긍정적인 태도를 강요받는 분위기
     * 이러한 사례를 통해, 내부 비판은 시스템적으로 억압됨을 실감하게 됨
     * 당시 구글이 내세우던 “세계의 정보를 조직한다”는 명분에 순진하게 빠져 있었음을 자각하게 됨

4. Mona, entendida, odara… elza : 소수자, 다양성, 감시

     * 본인은 아직 커밍아웃 전이었으나, 퀴어 정체성을 적극적으로 드러냈고, 회사는 이를 “다양성” 이미지에 활용했음
     * LGBTQ+ 소속임을 자랑스러워했지만, 실질적으로는 마케팅·광고 부서가 소수자 직원들을 상품화하거나 커뮤니티 정보를 비밀리에 수집하는 식으로 활용함
          + 퀴어 은어(pajubá) 를 데이터 수집 목적으로 요청받는 등, 겉치레적 포용성이 실제로는 데이터 활용과 착취로 이어짐
     * 이로 인해 내면적으로 이용당함과 침해받는 감각을 경험하고, 외형적 포용성과 내적 차별 구조의 모순을 깨달음
     * 프로필에 “I am a nerd, a bisexual polyamorist, and a parent(나는 너드이고, 양성애자 폴리아모리스트이며, 부모임)”라는 문구를 넣었다는 이유로 인사고과에서 문제(너무 개인적임) 로 지적받음. (프로필에 개인 정보는 이 문장 하나뿐이었음)

5. 구글 프레카리아트 2부: 정수기 월급

     * 구글 엔지니어들은 저임금, 과로, 불안정 고용에 시달리면서도, 회사가 제공하는 겉치레형 특권(perks) - 화려한 사내 복지(간식, 게임기, 장난감 등) 에 만족하도록 유도됨
     * 정규직-비정규직, 직원-청소노동자 등 내부 계급 구조가 매우 뚜렷함
     * 예산 절감을 위해 저렴하고 실용적인 브라질식 도자기 정수기를 제안했지만, “너무 저기술적”이라는 이유로 거부됨
     * 고가의 정수기 임대 비용이 비정규직 임금보다 높음에도 불구, 노동자에 대한 배려는 없음

6. Cathy, 오늘은 이메일 보내지 마

     * 회사에서 제공한 스마트폰과 무제한 데이터 덕분에 감시 사회를 실감하기 시작함
     * 구글 내에서 해외(일본) 근무 기회를 알아보다가, 동료의 조언으로 감시를 피하기 위해 청소도구 보관실에서 몰래 통화하는 일도 경험함
     * 얼마 뒤 경제 위기와 함께 해고되며, 기술이 인간을 감시·통제하는 사회로 진입하는 과정을 알게 됨
     * 오늘날의 빅테크가 “정보 조직”을 넘어, 감시와 통제, 사회적 차별을 구조화함을 체감함
     * 내 자녀 세대에겐 감시 없는 일상이 더 이상 존재하지 않는 현실을 인식

7. 구글 프레카리아트 3부: 마음 없는 권력, 무력한 기타 권력들

     * 구글의 금요일 파티(TGIF) 문화는 겉으론 화려했지만, 실상은 불안정 노동자들의 노동과 희생에 기반한 일상적 특권이었음
     * 실제로는 비정규직 여성 노동자가 그 뒤에서 모든 허드렛일을 도맡아야 했음
     * 2008년 경제위기 당시, 남미 지역 비정규직의 70%가 한 번에 해고되었으나, 고위 관리자들은 이를 웃으며 파티에서 이야기함
     * 이 경험을 통해 저자는 자본가의 비인간성, 냉혹함, “악당”의 현실성을 깨닫고 정치적 각성에 이르게 됨
     * 자본주의 구조 자체가 착취, 차별, 잔혹성을 필연적으로 낳는다는 점을 현장에서 직접 체험

결론: 체험을 통한 각성

     * 구글에서의 시간은 화려한 척하는 거대 기술기업의 착취 구조와 신화의 해체, 기술업계의 권위·위선의 본질을 온몸으로 느끼게 해준 시간임
     * 직접 경험한 바, “누가 설거지를 하는가”라는 질문처럼 보이지 않는 노동과 권력의 착취 구조를 돌아보게 되었으며
       섬세하게 내부의 모순과 차별을 관찰하고, 기술이 만들어내는 감시·소외 구조를 비판적으로 이해하는 계기가 됨

각주 및 인용

     * “모든 위대한 업적 뒤에는 누가 노동을 했는가?”라는 브레히트의 시로 글을 마무리하며, 보이지 않는 노동과 희생의 현실을 상기시킴

        Hacker News 의견

     * 90년대에 10대였던 나는 우리끼리는 데이터가 절대 사적이지 않다는 인식 공유했음
       약간 이 맥락의 이야기는 ‘화이트칼라 사회 안에서 성장 경험 없는 사람이 화이트칼라 직장에 들어갔다가 문화 규범을 어겨서 곤란함을 겪는’계층 이동자들에게서 자주 나타나는 전형적인 패턴 느낌임
       운영(operations)팀이 투명인간 취급당하는 게 나는 마음 아픔
       이들도 우리 사회의 일원이고 존엄하게 대우받아야 한다고 생각함
       상식적으로 괜찮은 환경이라면 이들도 나름의 분야에서 인정 받고 있음
       저녁 당번 청소업무든 뭐든, 파티하고 청소 맡기는 게 비도덕적인 행동은 아니라고 생각함
       문제는 이들을 자신보다 ‘아래’로 바라보는 태도라고 봄
       결국 화이트칼라가 아닌 배경에서 자라 온 사람들이 새 환경에 적응하며 겪는 혼란에 대한 이야기도 언젠가 쓰여야 한다고 봄
          + 또 다른 사용자가 말했듯(참고링크), 화이트칼라들이 가진 특권이 본질적으로 누군가의 희생 위에 있다는 점을 잊지 않으려고 함
            이들을 그냥 배경의 가구 취급하지 않고, 하나의 사람으로 대우하고 존중해야 함
            이런 문제는 조직의 가장 위까지 뻗어있다고 느낀다
            사회·경제적 사다리의 각 계단에는, 자기 아래 있는 사람을 투명인간 취급하는 이들이 많음
     * 사람들이 이 훌륭하게 쓰여진 글에 부정적 의견을 쏟아내는 걸 보면 슬픈 감정
       그들이 그러는 건 스스로도 ‘악한’편에 속할 수 있다는 인지부조화 때문일 수도 있음
       아니면 이제 긴 글을 읽는 능력을 잃어서일 수도 있는데, 실제로 그런 능력이 점점 사라져가는 추세 느낌
       혹시 대가 받고 특정 관점을 홍보하는 중일지도 모르겠지만, 그렇다 해도 슬픈 감정
       이런 댓글 남기는 봇들조차 슬프게 느껴짐.
       이제 인간인지, 돈 받고 글을 쓰는 건지, 실제 논의인지조차 구분이 안 되는 세상이 되어간다는 사실이 씁쓸함
       나는 이 원글이 선전 선동이 아니라고 생각함
       단지 누군가가 ‘사람들이 신경 써주길 바라서’ 쓴 글이라고 느낀다
       이런 글이 쓰이고 읽히고 공유되는 현실 자체가 조금은 위로가 됨
       혹시 내 판단이 틀릴 수도 있지만, 내 평가를 한 번 남겨보고 싶었음
       나는 나 자신이 사람이고, 대가 받고 쓰는 댓글 아니라는 점 밝힘
     * Google에서 입사 소개메일에 넣을 자기소개 글을 내 매니저가 수정해달라고 요청했던 경험 있음
       전 직장 이력 꼭 넣으라고 했는데 나는 의미 없어서 뺐던 것
       그땐 별 생각 안 했지만, 지금 돌아보면 내 정체성이 회사 내에서 ‘연출되는(큐레이팅되는)’다는 OP의 이야기와 비슷하게 느껴짐
     * 예전 Google은 ‘Best Place To Work’ 상을 연속 수상하면서 “대기업 중 착한 기업”이라는 이미지를 강하게 만들었음
       지금과는 정말 다르게 느껴지는 분위기였음
       이런 이미지가 나를 다시 학교로 돌려보내고 테크 커리어를 쫓게 만든 원동력이었고, 목표는 오직 Google 입사 한 가지였음
       면접 막바지까지 갔다가 최종 탈락해서 그때는 엄청 상처였음
       하지만 지금 돌아보면, 그게 내 인생에 가장 잘 된 일이었던 것 같음
          + Google이 요즘 Best Place to Work 순위에서 어디쯤인지 궁금해서 찾아봤더니, Forbes에 따르면 Alphabet가 2위로 나옴
            다른 리스트에서는 6위 정도로 보임
            Forbes 리스트 링크
     * 정말 잘 쓰여진 글이라고 생각함
       내가 계속 상기하려고 하는 최대 교훈은, 우리가 가진 크고 작은 특권이 실제로는 누군가의 희생 위에 서 있다는 사실임
          + 맞는 말이라고 생각함
            AI가 취약계층 일자리를 빼앗거나, 탄소 소비를 늘리거나, 정치를 불안정하게 만드는 얘기를 하면
            항상 부유한 개발자가 “난 잘 모르겠는데 AI 덕분에 더 편하게 일할 수 있어서 좋은데?”라고 말하는 것 같음
     * “사람을 부려먹고 모든 이익을 독차지하면서 상대는 고정급만 받게 하면, 왜 자신이 그럴 자격이 있다고 느끼게 되고 상대가 그 대우를 받아야 한다고 생각하지 않을 수 있겠는가”
       이 말 보면서 왜 소프트웨어 엔지니어 협동조합이 더 많지 않은지 궁금해짐
          + 사람들은 위험을 싫어해서, 위험 부담 없이 큰 돈을 벌 수 있으면 그걸 택하고
            위험 감수해야 10배 벌 수 있어도 안정적 한도 내에서 남길 수 있으면 그걸로 만족하는 경향 있음
          + 코드 그 자체가 돈을 벌어다주는 게 아님
            코드를 ‘파는 행위’가 돈을 만들어줌
            근데 엔지니어들은 대부분 세일즈에 강하지 않음
          + 실제로 소프트웨어 엔지니어 회사들 중 능력 좋은 엔지니어에게 스톡옵션 등 지분을 주는 식의 운영도 많음
            하지만 많은 엔지니어가 대체 가능 인력 취급을 받고, 그런 경우 스톡 비율도 줄어듦
          + 협동조합 같은 걸 지지하는 사람이 회사 운영을 맡으면 오히려 회사가 망가지는 경우도 많음
            그런 사람 여러 명과 위원회 체계가 더해지면 더 심해짐
          + 누군가는 초기 자본을 투자해야 하고
            돈을 댄 사람은 당연히 그에 대한 투자수익을 원함
            아니면 그 자본을 딴 데 투자함
     * “다른 직원들처럼 제대로 보상받지 못하는 건 스스로 더 열심히 일하지 않아서”라고 자책하던 경험
       이 말 보면서 이제야 내 동료들이 왜 항상 자책하는지 조금은 이해하는 부분 얻음
     * dictbot 글에서 Google 내에서 TVCs(Temporary, Vendor, Contractor) 같은 계약직을 2등 시민으로 취급하는 이유에 대한 해석이 잘못됐다고 생각함
       엔지니어들의 자존감을 부풀리려는 게 아니라
       TVC들을 고용법상 직원(employee)으로 대우하지 않으려는 목적 때문임
       예전에 주방에서 일하는 어떤 분이 음악실 창고에 기타 보관하려고 출입권한을 받았다가, 그분이 TVC라 안 된다며 출입이 취소된 적 있었음
       그 창고는 “FTEs(정규직)나 인턴만 사용”이 원칙이라고 들었고
       이유가 주방 인력 등 계약직을 너무 잘 대해주면 법적으로 같은 복지를 지급해야 할 수 있으니 그런 거라는 설명 받았었음
       예전에는 우편실에서 일하다 출세해서 임원까지 가는 경로도 있었지만, 이런 길은 고용주 계층에서 의도적으로 막아왔음
       직원들을 여러 계층으로 인위적으로 분리해서 계급 갈등 유발하려고 하는 거라 봄
       명확한 계급투쟁의 신호로 해석
     * 상사가 있는 이메일 스레드에서 상사 몰래 뒤에서 뭔가 못한다는 ‘비극’
       비용절감을 논하는 자리에서 사무기기 이야기 꺼냈다가 무시당하는 ‘비극’
       금요일에 음식 만들고 설거지하는 직원이 있다는 ‘비인간성’
       정체성을 자랑스럽고 공개적으로 드러내는데 그걸 물어보는 ‘뻔뻔함’
       정말 구글 같은 대기업이 없어도 브라질이 더 나았을 것 같다는 냉소적 태도
       이런 조직엔 차라리 폴리아모리 아니키스트가 운영하는 게 나았을 것 같다는 뉘앙스
          + OP가 언급한 모든 사례는 Google이 스스로 내세운 모습과 실제 행동이 얼마나 괴리되어 있는지 보여준다고 생각함
            이 글의 저자는 동정심을 구하는 게 아니라, 구글이 어떤 대기업이든 똑같은 이익 지상주의 조직임에도 다른 척 한다는 걸 싫어하는 거라고 느껴짐
            댓글 단 당신은 오히려 글쓴이가 말한 적대적 성향에 가깝게 보임
          + 회사 이메일에서 상사 몰래 얘기 못하는 ‘공포’라기보다는
            내 고용주가 내 권리와 사생활을 침해하고, 내가 원하는 걸 얻으려 내게 거짓말 한다는 게 진정한 문제
            비용 절감 얘기하면, 누구는 깨끗한 물을 쓸 자격이 있고 누구는 못 쓴다는 지적이 무시당하는 현실이 슬픔
            금요일 식사 담당은, 재수가 없어서 잘 나가는 테크직을 얻지 못한 사람을 폄하하는 현실
            회사가 내가 자랑하는 정체성은 못마땅하다가도, 자기들에게 이득이 되면 이용한다는 것은 가증스러움
            직수정수기 제한 사건은 정말 만화 ‘폴아웃’ 세계관에서 튀어나온 악역급 현실 느낌 받음
          + “정체성을 묻는 것이 뻔뻔하다” “차라리 폴리아모리 아니키스트가 낫겠다”는 식의 논평은 상당히 반감 가득한 뉘앙스
          + 급진적 투명성은 남 비난할 수 있는 면허증이 아니라고 생각함
          + 친절함을 지키고, 냉소는 피하는 것이 중요하다는 굿가이드라인 함께 공유함
            Hacker News 코멘트 가이드라인 링크
     * “제3세계에서 무너지는 경제 상황에도 시장 평균보다 낮은 임금, 연구직도 아니고 자기주도 근무도 안 되는 환경에서 Microsoft나 IBM이 더 유리한 게 아닐까?”라는 질문에
       Google이 Microsoft/IBM보다 연봉 낮았던 적 있었나 궁금함
          + 아마 저자가 브라질 기준으로 말하는 듯
            처음엔 명확하지 않았는데, 글 후반 읽고 나서야 지역 맥락이 이해됐음
"
"https://news.hada.io/topic?id=21358","<Blink>와 <Marquee> (2020)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       <Blink>와 <Marquee> (2020)

     * 90년대 웹 초기에 등장한 <blink>와 <marquee> 태그는 당시 웹디자인의 상징적인 요소였음
     * <blink> 태그는 Netscape Navigator 2.0에서 도입되며, 장난스러운 목적과 심미성 부족에도 불구하고 널리 사용됐음
     * Microsoft는 이에 대응해 Internet Explorer에 <marquee> 태그를 도입해 텍스트 애니메이션을 한층 다양하게 제어할 수 있게 했음
     * 두 태그를 중첩해서 사용하면 브라우저 별로 다른 애니메이션 효과 제공이 가능했으며, 점진적 향상 원칙의 사례로 언급됨
     * 현재 <blink>는 사라졌고 <marquee>도 사용이 권장되지 않지만, 웹 역사와 온라인 노스탤지어의 대표 사례로 회자됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: <blink>와 <marquee> 태그의 회상

     * 최근 동료 웹 개발자와 대화 중, HTML <blink>와 <marquee> 태그에 대한 농담을 했는데, 상대방 개발자가 이 두 태그를 모른다는 사실을 알게 됨
     * 이 태그들은 현재 젊은 개발자들에게는 생소하지만, 한때 90년대 웹디자인의 상징적인 요소였음

<blink> 태그의 탄생 배경과 역사

     * <blink> 태그의 창조자는 종종 Lynx 브라우저를 만든 Lou Montulli로 알려져 있으나, 실제로 그는 자신이 직접 코드를 작성하지 않았다고 밝힘
     * 그의 주장에 따르면 한 바에서 Netscape 엔지니어들과의 대화 중, Lynx 같은 텍스트 브라우저에도 사용할 수 있는 “텍스트 깜박임 효과”가 농담으로 제안되었고, 이를 바탕으로 다른 엔지니어가 밤새 작업해 구현함
     * 1995년 Netscape Navigator 2.0에 <blink> 태그가 정식 도입돼, 움직이는 GIF와 초기 JavaScript와 함께 개인 웹사이트 경험을 정의하는 데 일조함
     * <blink> 태그는 속성 없이 사용되며, HTML4에서는 공식적으로 농담용 태그로 기록됨에도 불구하고, 90년대 후반 대중적으로 남용됨
     * “최신 업데이트” 강조 등 각종 메시지의 주목성을 높이기 위해 많이 쓰였음

<marquee> 태그와 브라우저 간 경쟁

     * 같은 해 Microsoft가 발표한 Internet Explorer 2.0은 Netscape의 <blink>와 달리, <marquee> 태그를 도입함
     * <marquee> 태그는 스크롤 방향, 속도, 반복 여부 등 다양한 속성으로 애니메이션을 조정할 수 있음
     * <blink>가 농담조로 시각적 가독성을 해칠 수 있도록 했다면, <marquee>는 의도적으로 효과를 강조함
     * 90년대 말에는 두 태그를 함께 사용하는 방식—<marquee> 안에 <blink>—이 브라우저별(IE와 Netscape)로 서로 다른 효과를 제공하는 방법으로 유행함

점진적 향상(Progressive Enhancement)과 웹 호환성

     * <blink>와 <marquee>의 중첩 사용은 웹 브라우저가 미지원 태그를 무시하고 내부 콘텐츠는 그대로 렌더링하는 Postel’s Law(관용의 원칙) 와 관련됨
     * 새로운 HTML 요소(<video> 등)도 이런 이유로 종종 비자기 종료 태그를 적용, 호환성 보장에 힘씀
     * <blink>/<marquee> 같은 태그를 활용할 경우, 태그를 모르는 브라우저에서도 정보 콘텐츠를 읽을 수 있었음
     * 웹은 모든 사용자에게 정보를 제공하고, 일부 브라우저만 추가 효과를 즐길 수 있도록 하는 점진적 향상 개념에 기반함

다양한 브라우저에서의 변화와 지원

     * Opera 사용자는 유료 라이선스로도 <blink>나 <marquee> 효과를 거의 보지 못했으나, 콘텐츠 접근엔 문제가 없었음
     * Netscape 7은 <blink>와 <marquee>를 모두 지원한 거의 유일한 브라우저로, 동시에 스크롤 + 깜박임 효과를 구현할 수 있어 웹에서 가장 보기 힘든 효과 연출 가능했음

결론: 현재의 위치와 웹 디자인의 교훈

     * <blink> 태그는 현재 완전히 사라졌음(현대 브라우저 미지원), 필요하다면 CSS 애니메이션으로 대체 가능함
     * <marquee>는 일부 브라우저에서 여전히 기본 지원 또는 polyfill이 존재함에도 불구하고, 사용은 추천되지 않음
     * 웹의 역사와 과거 온라인 미학의 상징이자, 웹 표준과 접근성과 유지보수의 교훈적 사례로 남아 있음
     * 디지털 노스탤지어에 관심이 있다면, 예전 웹 디자인과 관련된 자료나 사이트를 참고하면 됨

        Hacker News 의견

     * 예전에 아래 링크와 같은 사이트가 있었던 기억이 있음 https://danq.me/2020/11/11/blink-and-marquee/"">https://web.archive.org/web/20201111125145/…
     * 나는 3,000년 전부터 있었던 느낌의 사람임. 프레임 내비게이션이 나쁜 관행인지에 대해 격렬하게 논쟁하던 시절을 기억함 (iframe이 아니라 프레임임). 프레임을 아는 사람이 혹시 있으면 반가움. AJAX가 나오기 전에는 HTTP 204를 활용해 페이지 새로고침 없이 서버로 메시지를 보내는 방법을 직접 썼음. 2000년대 초반에는 이미지 맵도 작업함 이미지 맵 참고: https://developer.mozilla.org/en-US/docs/…. 드림위버로 지도 경계선을 여러 날 동안 그려서 클릭 가능한 국가 지도를 완성한 적도 있음. 드림위버 템플릿은 버전 컨트롤을 안 써서 업데이트하다가 수정사항 다 날리고 복구 불가능한 상황도 많았음. input type=image으로 이미지 클릭 위치를 백엔드에서 처리하던 기억도 있음. 모션 JPEG을 이용해 페이지에 스트리밍 업데이트도 구현했고, 아직도 크롬에서는 되고
       파이어폭스에서는 약간 불안정함. IE에서 PNG 알파 블렌딩 문제 해결하려고 여러 방법을 시도하다가 결국 ActiveX 버전으로 좀 써먹었으나, 결국 플랫 디자인 유행하면서 필요 없어짐. 네비게이션은 JAVA, Flash, Silverlight까지 다 써봤음. 스페이서 GIF, 조건부 주석, Firebug 등장 이후 개발환경이 얼마나 편해졌는지도 생생하게 기억함. 언제 나이가 들었는지 모르게 시간이 흘렀던 경험임
          + 예전 프레임으로 웹 소프트웨어를 개발했는데 딱히 문제를 느끼지 못했음. 사람들은 접근성을 이야기하지만 구체적으로 어디가 문제인지 아직까지도 잘 모르겠음
          + IE6의 모든 괴상한 버그와 한계 속에서 지원을 요청하는 고객사를 위해 일했던 기억임. 디자이너가 포토샵으로 둥근 모서리 디자인을 넘기면 매번 한숨 쉴 수밖에 없었음. 그 당시에는 반응형이라는 게 사실 데스크탑 해상도 여러 개 대응하는 정도였음. 모서리를 이미지로 잘라 테이블 셀에 직접 배치해야 했음. 이런 수작업을 하면서 개발자의 정신력이 크게 강화됨을 느낌
          + 포토샵 slice 툴로 이미지를 세밀하게 나누고 gif로 내보낸 후 HTML 테이블에 정확하게 배치하려 애썼던 때를 기억함. 800x600 해상도에 최적화된 디자인이 많았던 시절임. 이 모든 추억이 시간 속에 녹아 사라진 느낌임
          + 지금도 프레임을 몇 번씩 방문하는 사이트가 있음. Open Group/POSIX 사이트는 여전히 프레임을 사용 중임
          + 프레임을 이용해 웹챗을 만든 적이 있음. 위에는 무한 로딩되는 채팅창, 아래에는 input box가 있었고, 메시지 보낼 때는 204로 새로고침을 막았음. 위쪽 프레임에는 user list가 있는 오른쪽 프레임을 reload하는 작은 script도 보낼 수 있었음. 2000년 즈음에 친구 몇 명과 함께 사용했음
     * 전에 순수 marquee 태그만으로 애니메이션을 구현한 사이트를 만들었음. JavaScript는 전혀 사용하지 않았고, 누군가에게 보여주면 다들 놀람 https://udel.edu/~ianozi/
          + marquee 태그 안 본지 20년은 된 것 같은데, direction 파라미터로 수직 스크롤도 가능하다는 사실을 몰랐던 것 같음
     * marquee 태그로 제일 좋아하는 트릭은 중첩해서 쓰는 것임. 방향을 다르게 하면, 안쪽 marquee를 반대 방향과 같은 속도로 맞추면 순간 정지했다가 움직이는 효과를 낼 수 있음. 속도를 다르게 하면 더 복잡한 움직임도 구현 가능했음. 이 방법이 제대로 작동하려면 inner marquee에 최대 너비를 설정해줘야 했던 기억임
     * 예전에 blink 태그가 워낙 싫어서 사용하던 브라우저(아마 Netscape)의 바이너리 파일에서 'blink'를 'blonk'로 바꿔서 더 이상 깜박이지 않게 만든 적 있음
          + 나는 이런 식의 바이너리 트윅을 주로 Slack 클라이언트에서 자주 함(Electron 앱이라 엄청 쉬움). 내가 싫어하는 기능(예: 알림 숨기기, 입력 중 신호 차단하기 등)도 쉽게 없앨 수 있음
          + 누군가 blonk 태그를 썼으면 이제는 blonking이 생겼을지 모름. 꽤 재미있는 해킹 같음
          + 바이너리 수정이 꽤 재미있음. ""__gnu_warning""를 ""__gnu_whining""으로 바꿔서 gets() 경고성 메시지를 없애곤 했음. 버퍼 오버런은 그럴 수도 있지만 대충 만드는 코드에서는 굳이 신경 안 씀
     * marquee 태그를 HTML 인젝션 테스트에 매우 유용하게 씀. 거의 아무도 안 쓰는 움직이는 태그라 공격이 먹혔는지 바로 알아볼 수 있음. 비기술자에게도 텍스트가 움직여야 하지 말아야 할 때 움직이는 걸 보여주면 bold 같은 것보다 훨씬 쉽게 위험성을 이해시킬 수 있음
          + HTML 정화(sanitization)할 때, 이스터에그 용으로 marquee만 화이트리스트에 남겨두고 나머지는 거의 다 막음
          + Hacker News를 커스텀 aggregator로 보고 있는데, 이 글을 통해 HTML 인젝션에 취약하다는 걸 알아냄. 2020년 글이 화면을 marquee로 돌아다니고 있었음
     * ""야수는 복수의 소용돌이 구름에 둘러싸여 등장할 것. 불신자의 집이 파괴되고, 그들의 태그는 끝날 때까지 깜박일 것이다.” – The Book of Mozilla, 12:10 (about:mozilla)라는 멘트와 함께 지금 Mozilla도 사라지는 중이라는 생각을 함. 마치 종말 느낌임
          + 나는 아직도 Firefox를 기본 브라우저로 사용 중임
     * 대학 기숙사 플로어 웹사이트를 내 컴퓨터에서 돌린 시절을 떠올림. marquee로 997단어 분량의 긴 메시지를 올려뒀었는데, 거기에는 여자, 우울, 철학 등 여러 얘기를 주절주절 적음. 메시지 끝에 ! 표시가 있었고, 그게 숨겨진 페이지로 링크되어 있었음. 결국 누군가 view source로 긴 내용을 읽어보다가 그 페이지 찾아냈음
     * 내 친구가 항상 본인 미들네임에 blink 태그를 둘러서 escaping 누락 및 잠재적 xss 여부를 빠르게 테스트하곤 했음. 예전엔 이런 단순한 방식도 취약점 발견에 꽤나 효과적이었음
     * 이 코멘트는 현재 공사 중임. 자주 들러서 업데이트 확인 바람
          + 방문자 카운터랑 방명록은 어디에 있는지 궁금함
          + 이 페이지는 어떤 브라우저에 최적화되었는지 궁금함
          + [NEW] 표시를 잊지 않길 바람
"
"https://news.hada.io/topic?id=21324","트위터의 새로운 암호화 DM은 이전 것보다 더 낫지 않음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    트위터의 새로운 암호화 DM은 이전 것보다 더 낫지 않음

     * Twitter(X)의 새 암호화 DM(XChat) 은 기술적으로 end-to-end 암호화를 표방하지만, 프라이빗 키 탈취·MITM·메타데이터 노출 등 심각한 보안 결함이 여전히 존재함
     * Libsodium Box(비밀키 기반 암호화) 를 도입했으나, forward secrecy 미지원과 4자리 PIN 기반 약한 키 보호 방식으로 프라이빗 키 추출이 비교적 용이함
     * Juicebox 프로토콜로 키를 백업/복구하나, 실제 보안성은 백엔드 신뢰에 전적으로 의존하고, Twitter가 모든 백엔드를 직접 운영해 sharding의 의미가 거의 없음
     * 공개키 인증/검증을 위한 out-of-band 절차가 없어 Twitter가 MITM(중간자 공격)으로 키를 바꿔치기할 수 있으며, 사용자 메타데이터는 그대로 노출됨
     * Signal과 달리, 현재로선 실질적 프라이버시 보호가 부족하므로 신뢰할 수 있는 암호화 메신저로 Signal을 추천함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Twitter의 새로운 암호화 DM 분석

  배경 및 요약

     * Twitter(X)는 새로운 XChat 암호화 메시지 플랫폼을 공개, Rust로 개발됐고 Bitcoin 스타일의 암호화 구조를 도입했다고 홍보
     * 하지만 실제 구현을 보면, 여전히 Twitter가 프라이빗 키 접근, MITM(중간자 공격), 메타데이터 수집이 가능한 구조임
     * 결론: Signal을 사용 권장, Twitter(X) DM은 근본적인 한계로 안전하지 않음

  암호화 구조 및 한계

    1. 암호화 방식

     * Libsodium의 box(공개키 기반 암호화) 를 사용
     * forward secrecy(선행 비밀성) 미지원: 프라이빗 키가 유출되면 기존 메시지 모두 복호화 가능(즉, Signal 등 최신 메신저보다 취약)
     * 실제 구현은 Rust가 아니라 C 라이브러리(jni로 바인딩)를 사용

    2. 키 저장 및 복구(Juicebox 프로토콜)

     * 기기에서 생성된 프라이빗 키를 Juicebox 프로토콜로 저장
     * 키는 PIN(4자리) 기반 암호화 후 저장되며, 복구 시 PIN 입력 필요
     * 서버는 PIN을 모르지만, PIN이 4자리(1만개 경우의 수)에 불과해 병렬 브루트포스로 빠르게 크랙 가능
     * Argon2id로 16MB 메모리·32회 반복을 적용해도 실제 공격자에겐 큰 장애가 아님(저사양 노트북에서도 0.2초 이내)

    3. 키 분산(Sharding) 구조 한계

     * Juicebox는 다중 백엔드 분산(sharding) 지원하지만, Twitter는 3개의 백엔드를 모두 직접 운영
     * 결국 키 복구 과정에서 Twitter의 신뢰에 완전히 의존해야 하며, sharding의 근본적 보안 이점이 없음
     * 백엔드와 안전하게 통신하는 HSM, SGX 등 하드웨어 검증 절차도 부재

    4. 공개키 인증/교환 취약점

     * 상대방의 공개키는 Twitter 서버를 통해 받기만 하고, 별도 검증(out-of-band) 수단 없음
     * Twitter가 원하는 때에 임의의 공개키를 제공해 중간자 공격(MITM) 가능
     * 공식 지원 페이지에서도 해당 취약점을 인정하며, 향후 개선 예고만 했으나 실질적 조치 없음

    5. 메타데이터 및 기타 문제

     * 누가 누구에게, 언제 메시지를 주고받는지 등 메타데이터는 Twitter가 완전히 파악 가능
     * 프라이빗 키가 노출되지 않아도 사용자의 커뮤니케이션 패턴은 여전히 회사에 노출됨

  결론 및 권고

     * 암호화 DM의 설계상 한계로, 실제 보안과 프라이버시 측면에서 Signal 등 검증된 메신저에 미치지 못함
     * Twitter가 공개키·키스토어·통신 경로 모두를 통제하는 한 진정한 end-to-end 암호화로 볼 수 없음
     * Signal과 같은 공개적이고 투명한 프로토콜의 메신저 사용을 강력 추천

        Hacker News 의견

     * 나는 Matthew Garrett가 쓴 모든 글을 좋아하는 팬이지만, Signal이 예전부터 항상 forward secrecy 기능을 지원해온 점을 집착스럽게 지적하고 싶음. 현대의 안전한 메신저 개념은 OTR(Borisov와 Goldberg)이 거의 처음으로 ""완벽한 forward secrecy""와 부인 가능성에 대한 개념을 도입하면서 탄생. Signal은 이 아이디어와, 그러한 아이디어의 엔지니어링 측면(더 나은 암호화, 더 나은 코드, 더 나은 패키징)을 모두 발전시킨 결과물이란 생각. 답답한 점은 새로운 메신저들이 ""pre-Signal"" 수준이 아니라 2001년 이전, 즉 현대 이전의 보안 수준으로 후퇴하고 있다는 사실임
          + 과거 여러 유출 내용에서 기억해야 할 세 가지가 있음. (1) FBI가 기업들에게 비밀리에 백도어를 넣으라고 ""강제""한 사실이 있음. FISA 법원이 회사에 치명적인 벌금을 내릴 수 있다는 언급도 나왔음. (2) 대기업에게 백도어 비용으로 수천만~억 단위 금액을 지급함. 그리고 정부 계약 혹은 수출 라이센스 등 다양한 방법으로 압박함. 결국 ""은행 아니면 총"" 식 정책이란 해석 가능. (3) Lavabit 재판 사례에서는 FBI가 키 제공을 요구하면서도, 고객에게 거짓말하라고 사실상 강요함. 이런 사례를 떠올리면 대형 플랫폼 내 암호화가 정부의 요구로 일부러 약화되거나, 그냥 신경을 안 써서 허술하게 적용된 경우가 꽤 잦을 거란 의심이 듦. Patriot Act, FISC, 비밀 해석 등 관련 법령과 관행이 없어지고 위반자들이 처벌받기 전까지, 경찰국가 내 암호화는 Five Eyes에 의해 이미
            무너졌단 가정임
          + 사람들이 App Store에서 PC 기반 앱을 설치하는 한, 이런 후진적인 상황은 계속될 전망
     * 만약 ephemeral key를 사용하고 forward secrecy나 상호작용 기록도 없다면, 어떤 점이 진짜 'bitcoin 스타일'이란 건지 의문임
          + 암호기술이 쓰였긴 한데, 대체로 흥미없고 무쓸모에 가까운 파생 기술 느낌
          + 실질적인 활용 가치가 없다는 얘기임
          + Bitcoin 자체도 안전한 통신 채널은 아니라는 사실
          + PIN 기반 키 파생을 쓴다는 점이 있음. 근데 이는 메시징 자체보다는 백업 구현에 더 가까운 방식으로, 본질적 특징이라 보기도 어려움
          + 해시 함수를 사용한다는 점 언급
     * 예전 토론 링크 공유:
       X의 새로운 ""암호화된"" XChat도 그다지 더 안전하진 않다
          + 위 링크의 상위 댓글에서 기술적으로 깊이 다루는데, 결론은 이렇게 요약 가능: ""도움말 문서에도 명시됐지만 forward secure하지 않아서, 키만 있으면 전부 복호화됨. e2ee 플랫폼이라 부를 수 없는 수준.""
            관련 댓글 보기
     * 암호화하려면 별도의 소프트웨어를 이용하고, 공개키는 직접 대면해서 교환하는 방식이 더 낫겠다는 생각
     * 질문: 곧 베이징에 방문할 예정인데, VPN 없이 Twitter 사용이 가능한지 궁금
          + 일부 로밍 SIM 카드는 만리방화벽에 적용되지 않는 경우도 있으나, 대부분의 경우 VPN 필요
     * ""Bitcoin style encryption""이라는 표현을 두고 의문. 실제로 Bitcoin은 우리가 흔히 아는 ""encryption""이 아니라 암호 서명 기술에 더 의존한다고 인식함
          + 이 용어는 실제론 아무 의미 없고, 기술에 익숙하지 않은 사람에게 그럴듯하게 들리라고 쓴 마케팅 용어일 뿐
          + 해당 발언의 출처 자체가 기술적으로 깊은 사람은 아니란 점을 유념해야 함
          + 이 용어를 쓴 건 이슈를 불러일으킬 걸 예상했기 때문임. 더 주목받기 위한 전략적 선택이라는 해석
          + 설명 영상 링크 공유
            https://www.youtube.com/watch?v=sJNK4VKeoBM
          + 그냥 멋져 보이게 “가치있는 것”처럼 느끼게 하려고 쓴 유행어 수준의 단어
     * 진짜 XChat(IRC 클라이언트)이 X-Twitter를 상표권 침해로 고소할 수 있을지 의문
       http://xchat.org/
          + 예전에 XChat에서 HexChat으로 넘어가던 시절 IRC 이용자였던 추억이 있음. 그런데 HexChat도 개발 종료 소식에 놀람
            HexChat 종료 소식
          + 아마 가능은 한데, XChat 쪽이 X가 침해하는 영역마다 상업적 시장성을 잘 입증해야 하고, 각 지역에서 상표권이 등록돼 있어야 쉽게 인정 가능. 그게 아니면 더 어렵다는 의견
     * Twitter가 사용하는 라이브러리(출처 기사 기준)가 재밌는 점이, 개발자 본인이 라이브러리 설명에
       “경고: 실험용 라이브러리! 이건 검토 전까진 프로덕션에 쓰지 마세요. 리스크 및 버그 가능성 큼”
       이라고 직접 써놓았다는 사실
       https://github.com/ionspin/kotlin-multiplatform-libsodium
          + 파괴적 혁신 대신 파괴적 암호화라는 생각
     * Twitter 브랜드 파워가 워낙 강해서 리브랜딩 이후에도 여전히 생명력을 잃지 않는다는 감탄
          + 각주에서 저자가 왜 예전 명칭을 썼는지 자세히 설명함
"
"https://news.hada.io/topic?id=21321","Eleven v3 — 가장 표현력이 뛰어난 텍스트-음성 변환 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Eleven v3 — 가장 표현력이 뛰어난 텍스트-음성 변환 모델

     * Eleven v3 (Alpha) 는 감정과 음성 효과까지 정밀하게 제어 가능한, 역대 가장 표현력이 풍부한 텍스트-음성 변환(TTS) 모델임
     * 오디오 태그를 활용해 감정, 말투, 방향성, 효과음 등 다양한 음성 요소를 자유롭게 조합할 수 있음
     * 여러 명의 화자가 대화하는 자연스러운 오디오 생성이 가능하며, 70개 이상의 언어에서 인간에 가까운 음성을 지원함
     * v2 대비 음성 감정의 폭과 효과 적용 범위가 크게 확장되었으며, UI 사용자는 2025년 6월 말까지 80% 할인 혜택을 받을 수 있음
     * API 지원은 곧 공개 예정이며, 다양한 음성·상황별 태그는 프롬프트 가이드에서 확인 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Eleven v3 개요

     * Eleven v3 (alpha) 는 이전 버전과 차별화된, 감정 표현과 몰입감 있는 음성 생성이 가능한 **차세대 Text to Speech(TTS) 모델*임
     * 이 모델은 입력된 텍스트를 사람이 직접 읽는 것과 유사한 방식으로 감정, 억양, 리듬을 표현하면서 음성으로 변환함
     * 사용자는 오디오 태그를 이용해 음성 감정, 말투, 음향 효과, 배경 사운드까지 세밀하게 제어 가능
     * 텍스트 내에 감정, 효과, 연출 태그를 삽입해, 단순 나레이션을 넘어선 입체적인 오디오 제작이 가능하여, 몰입감과 현실감이 크게 향상됨

다수 화자의 대화 생성

     * 여러 명의 화자가 자연스럽게 맥락과 감정을 공유하며 대화하는 오디오 생성 지원
     * 각 화자별 프로소디(운율), 감정, 태그가 반영되어 인간과 가까운 오디오 합성 실현

다국어 음성 지원

     * 아프리칸스, 아랍어, 독일어, 중국어, 한국어 등 70개 이상 언어를 공식적으로 지원함
     * 각 언어의 특색 있는 억양, 발음, 악센트를 자연스럽게 모사함
     * 다국적 서비스, 교육 콘텐츠, 글로벌 접근성 프로젝트 등 다양한 분야에서 활용도가 높음

v3와 v2의 주요 차이점

     * Dialogue Mode: 다중 화자 대화 지원
     * Audio Tag 지원: 감정, 방향, 효과 등 다양한 오디오 태그 활용 가능
     * 감정·효과 범위: v2는 일시정지 등 기본 태그, v3는 풍부한 감정과 오디오 효과 적용 가능
     * 언어: v3는 70+ 언어, v2는 29개 언어
          + 아프리칸스, 아랍어, 아르메니아어, 아삼어, 아제르바이잔어, 벨라루스어, 벵골어, 보스니아어, 불가리아어, 카탈루냐어, 세부아노어, 크리체와어, 크로아티아어, 체코어, 덴마크어, 네덜란드어, 영어, 에스토니아어, 필리피노어, 핀란드어, 프랑스어, 갈리시아어, 조지아어, 독일어, 그리스어, 구자라트어, 하우사어, 히브리어, 힌디어, 헝가리어, 아이슬란드어, 인도네시아어, 아일랜드어, 이탈리아어, 일본어, 자바어, 칸나다어, 카자흐어, 키르기스어, 한국어, 라트비아어, 링갈라어, 리투아니아어, 룩셈부르크어, 마케도니아어, 말레이어, 말라얄람어, 표준 중국어, 마라티어, 네팔어, 노르웨이어, 파슈토어, 페르시아어, 폴란드어, 포르투갈어, 펀자브어, 루마니아어, 러시아어, 세르비아어, 신디어, 슬로바키아어, 슬로베니아어, 소말리어, 스페인어,
            스와힐리어, 스웨덴어, 타밀어, 텔루구어, 태국어, 터키어, 우크라이나어, 우르두어, 베트남어, 웨일스어 등

음성 품질과 사용자 경험

     * 음성 합성 시 노이즈가 적고, 고해상도 품질의 오디오 파일 출력이 가능함
     * 문장 길이, 감정의 뉘앙스 변화, 말의 속도 등 세밀한 조정이 가능해 맞춤형 음성 제작이 쉬움
     * 기존 TTS 솔루션에서는 재현하기 어려웠던 다나믹한 감정 및 발화 스타일을 표현할 수 있음

경쟁력 및 적용 가능성

     * 콘텐츠 제작자, 개발자, 기업이 오디오북, 게임, 광고, 접근성 향상 서비스 등에 즉시 적용 가능함
     * 단일 모델로 다국어, 다목적 서비스가 가능해, 비용과 시간을 절감할 수 있음
     * 오픈 알파(Alpha) 단계에서 이미 실제 서비스에 도입 가능한 수준의 음성 품질과 다양성을 확보함

할인 및 API 지원

     * 2025년 6월 말까지 UI 사용자는 80% 할인된 가격으로 v3 알파 이용 가능
     * API는 곧 공개 예정

결론

     * Eleven v3는 Text to Speech 기술 분야에서 표현력, 다국어 지원, 맞춤형 음성 기능을 강화한 최신 모델임
     * 다양한 산업군에서 자연스러운 음성 생성 기술 수요 증가에 효과적으로 대응할 수 있음

   알파인데, 좋네요..
   좋은 정보 감사합니다.

        Hacker News 의견

     * 나는 문서나 프롬프트 가이드에서 노래에 대한 언급을 못 봤는데, 혹시 이게 원래 노래도 할 수 있는 모델인지 궁금증 생김
       재미 삼아 Friends 테마송 가사를 데모에 넣어봤더니, 결과물이 기타 소리와 함께 노래 부르는 목소리로 나옴
       다른 실험에서 [verse]와 [chorus] 라벨 추가하니 아카펠라 버전으로 노래함
       [1]과 [2]는 가사만 입력했고, [3]은 verse/chorus 태그를 넣음
       다른 인기곡으로도 시험했는데, 이유는 모르겠으나 이렇게 깔끔한 노래 모드가 되진 않음
          + Friends-1.mp3
          + Friends-2.mp3
          + Friends-3.mp3
          + 결과물이 노래한다는 건 신기한데, 노래 자체는 엄청 못해서 오히려 더 흥미로움
            완전히 노래를 못하는 사람이 부르는 듯한 느낌
          + 실제 Friends 오프닝이랑 꽤 다르게 나오니, 트레이닝 데이터에 흔히 포함된 익숙한 패턴에 과적합된 결과는 아닐 듯한 추정
          + Mirage AI에서는 꽤 괜찮은 노래 품질을 구현함
               o 샘플1
               o 샘플2
          + 모델 데모에도 노래가 포함되어 있던 걸로 본 기억 있음
            그래서 아마 이 기능이 내장되어 있는 구조로 추측함
          + 흥미롭게도, 아래와 같은 프롬프트로 실험해 봤더니 마지막 ""purr"" 부분에서 모델이 좀 버거워하는 경향이 보임
[slow paced]
[slow guitar music]

Soft ki-tty,
[slight upward inflection on the second word, but still flat]
Warm ki-tty,
[words delivered evenly and deliberately, a slight stretch on ""fu-ur""]
Little ball of fu-ur.
[a minuscule, almost imperceptible increase in tempo and ""happiness""]
Happy kitty,
[a noticeable slowing down, mimicking sleepiness with a drawn-out ""slee-py""]
Slee-py kitty,
[each ""Purr"" is a distinct, short, and non-vibrating sound, almost spoken]
Purr. Purr. Purr.

     * 최근 OpenAI의 새로운 모델을 많이 실사용 중임 (openai.fm)
       지시문과 발화 텍스트를 분리하는 방식이 독특하고, 아마도 OpenAI 쪽은 제품 전반에서 ""instructions""라는 개념을 많이 활용해와서 이 방식을 트레이닝 및 데이터 생성에 더 익숙하게 여기는 것 같음
       지시문 분리 방식은 다소 어색할 수 있는데, 장점은 일반적 지시와 특정 상황 지시를 섞어 사용하기 쉽다는 점임
       예를 들면, ""but actually""라는 말 뒤에 목소리를 속삭이듯 낮추고 공포를 살짝 표현하라든가 ""영국 억양의 낮고 깊은 목소리"" 같은 일반지시를 같이 붙일 수 있음
       OpenAI 결과물은 Eleven Labs에 비해 예측 불가능성이 크고 프로덕션 품질감은 좀 떨어지는 인상
       다만 prosidy(운율 표현)의 폭이 훨씬 넓고, 오히려 너무 열심히 하는 느낌
       목소리 종류는 Eleven Labs에 비해 적게 느껴지고, 여러 스타일을 시켜도 약간 ""같은 사람이 다른 목소리 흉내내는"" 느낌
       하지만 OpenAI의 압도적 장점은 가격이 10배쯤 저렴하고 온전히 사용량 기반으로 과금된다는 점임
       (TTS 서비스들이 한 달 구독이나 추가 결제 크레딧까지 요구하는 건 정말 비효율적임)
          + 내가 ElevenLabs를 쓰지 않고 품질이 낮아도 다른 솔루션을 고르는 이유는, 필요한 만큼만 쓰고 싶은데 한 달에 한 덩이씩 계산하고 추가로 쓰면 또 더 큰 덩이로만 사야 하는 구독 구조가 싫음
            내 기준에서는 이 가격 정책이 매우 별로임
          +

     OpenAI 결과물이 ElevenLabs 대비 품질감, 예측 가능성에서 아쉽다
     연구팀 공을 인정함
     expressive voice 옵션을 사용하면 운율폭이 커짐
          +

     OpenAI의 최대 장점은 10배 저렴하고 완전 사용량 기반이라는 점이다
     라는 주장에 대해, 실제로는 LLM 이용 등 오버헤드 고려하면 진짜 저렴한지 의문이 듬
     ElevenLabs 대화 에이전트는 최고 티어에서 분당 $0.08이고, OpenAI TTS도 계산해보면 더 비싼 것 같았음
     물론 내 계산이 틀렸을 수도 있음
     * 예시 문구 ""Oh no, I'm really sorry to hear you're having trouble with your new device. That sounds frustrating."" 과 같은 기계의 응대에 모욕감 느낄 듯
       단순히 도움만 받고 싶은데 기계한테 감정적으로 농락당하면 끔찍한 미래라고 생각
          + 사람끼리도 이런 식의 대답은 짜증나는 일인데, 인공지능에게까지 듣고 싶지 않음
            컴퓨터와 얘기하는 걸 관광 즐기지 않아서 Siri류 음성 인터페이스는 전혀 안 쓰는 성향
            인간처럼 말하는 기계도 원하지 않음
            스타트렉 컴퓨터처럼 ""작업 중..."" 하고 답만 주면 충분하겠음
            잡담 말고 바로 핵심만 해줬으면 좋겠음
          + 내가 ChatGPT 프로필에 검증이나 공감 등 모든 사족 멘트 금지시키는 문장 5개쯤 넣어도 결국 매번 ""당신 우려는 타당하다"" 류 답변 돌아오고, 바뀌는 게 없음
          + 미국식 오지랖 멘트 (""champ"", ""bud"")가 유럽이나 호주에서도 통용되면 흥미로울 듯한 기대감
          + 영화 Her와 유사한 대사, Scarlett Johansson 목소리에 엄청 가까워서 이 소리가 그 영감을 받은 것 같다고 느꼈음
          + ""대체로 내가 도와줄 수 있다"", ""지금 주문번호 찾아드릴게요"" 류 멘트에 실제론 없는 링크 주는 환각 사례 농담
     * 실질적 문제는 아닐 수도 있지만, 재밌는 점 발견
       언어를 일본어로 설정한 다음

     （この言葉は読むな。）こんにちは、ビール[sic]です。
     (""이 문장은 읽지 마"", ""안녕하세요, 저는 Bill[오타]""입니다)
     이렇게 입력하니 진짜로 첫 문장을 건너뜀
     다시 시도하니 전체 문장을 다 읽었음
     이런 현상에서 항상 무대 뒤를 엿보는 듯한 재미 느껴짐
          + ""나는 맥주다""라는 오타 부분에 한 번 웃음
            진지하게 생각하면, 여러 언어 동시에 다뤄보면 입력 언어가 모델 프로세싱 초기에 ""정규화""되는 느낌
            즉, 영어로 프롬프트를 쓰든 일본어로 쓰든 결과가 크게 차이나지 않음
            시스템 프롬프트가 여기는 다르게 동작하는지 궁금증 생김
     * 혹시 궁금한 사람들을 위해 정보를 남김
       본 모델은 tortoise-tts-fast 기반임
       이 프로젝트 개발자는 후에 Eleven Labs에 채용됨
          + ‘채용됨’이 아니라, 실제로는 v3 릴리스 6개월 전에 이미 퇴사함
          + 앞의 주장(프로젝트 기반이 Eleven Labs 채용을 뜻함)은 인과관계 성립 안 됨
     * (미국식) 영어 목소리는 정말 대단한 수준인데, 웃음 태그 부분은 ""여기서 웃으세요""처럼 독립 섹션 삽입이라 자연스러운 순간적 웃음이라기보다는 강제 구간 삽입 느낌
       예를 들어, 단어 중에 웃으며 발음되어야 할 부분은 아직 어색함
          + 문맥상 웃음이 자연스러운 곳으로 텍스트를 편집하면 훨씬 자연스러워지니 이 샘플 참고 추천
          + 아직 가격이 비싸서 경쟁 서비스에 기회가 많음
            ElevenLabs가 품질면에서 여전히 리더이지만, 경쟁사도 빠르게 따라오는 중
            특히 중국 AI 연구소, 회사들도 완전 오픈소스 TTS 모델을 내놓고 있어 미국 기업 입장에서도 생태계 변화 촉진 중
            이런 현상은 결국 사용자에게 이득임
            YCombinator가 투자한 PlayHT도 좋은 기능을 많이 출시함
     * 결과물이 진짜 탁월해서 99%는 전문 성우와 구분이 안 될 정도임
       요금 정보는 못 찾았는데, 혹시 아는 사람 있는지 궁금
          + Eleven v3 (알파)용 공개 API가 곧 출시될 예정이라는 공지 확인
            사전 경험 참여나 가격 상담은 sales 팀에 문의하라는 문구
            아직 회사 자체도 정확한 가격 결정을 미정이라 수요 먼저 파악하려는 의도 같음
          + 오우... 나는 프로 성우임
          + 그래도 실제 사람이 아닌 ""AI""일 뿐임
            실제 사람이 직접 말하는 음악, 오디오북, 시, 소설, 연극, 이런 것들이 계속 들려야 함
            그게 내가 추구하는 본질적 즐거움임
     * 이 얘기 약간 주제와 다를 수 있지만(그래도 TTS와 연관성은 있어서...), 'eleven'이란 단어 들으니 스코틀랜드 엘리베이터 음성인식 개그 영상이 떠오름
       Elevator Voice Recognition 코미디 영상
     * 영국식 억양(브리티시 엑센트) 샘플을 못 본 것 같음
       전반적으로 TTS 시스템들은 미국식 억양만 다루고, 영국식은 Frasier같은 ""미국인이 흉내낸 브리티시""로 들림
          + 우리 보이스 라이브러리엔 다양한 브리티시 보이스가 많음
            아니면 프롬프트 맨 앞에 ""[British accent]""를 붙이면 미국인이 영국식 흉내내는 식으로 생성됨
          + Frasier Crane의 억양 문제는, 미국인 배우가 미국인 캐릭터로서 (상황 따라) 미국식이지만 트랜스애틀랜틱 혹은 보스턴 브라만 억양(혹은 그 블렌드)을 연기한 것이라 논쟁거리임
            두 억양 모두 영국식과 일부 유사 특징이 반영됨
          + 참고로 Frasier 계열은 ""브리티시 흉내""가 아니라 보스턴 브라만/트랜스애틀랜틱 계열 억양임
          + ElevenLabs v2의 억양 보이스는 아직 경쟁사 대비 훨씬 뛰어남
            아랍어, 프랑스어, 힌디어, 영어 등 다양한 언어로 직접 써봤음
     * 영어는 정말 환상적으로 들림, 축하 전하고 싶음
       그런데 내가 시도한 다른 언어들은 여전히 강한 영어식 억양이 남아있음
          + 이탈리아어로는 완전히 코믹한 미국 억양으로 시작하는데, 10~20단어쯤 지나면 갑자기 진짜 이탈리아식 발음으로 바뀜
            Alice 보이스 사용했고, 내부적으로는 en-us 베이스로 시작한 뒤 설정 언어에 맞게 급격히 맞추는 느낌
            백그라운드에서 무슨 일이 있는지 궁금증
          + 프랑스어는 알라바마 출신이 대학에서 잠깐 불어 배운 수준의 억양 같았음
            그래도 영어는 정말 좋았음
          + 포르투갈어의 경우, Liam 보이스는 흥미롭게도 스페인 억양임
            언어 아이콘은 포르투갈인데, 표현 방식은 분명 브라질식 포르투갈어임
          + 스웨덴어는 그냥 완전한 미국식임
          + 해당 언어 기반으로 트레이닝된 보이스로 시도해 보는 걸 추천
            이번 리서치 프리뷰는 고른 성능이 아니고, 보이스 선택에 따라 품질 차이 큼
"
"https://news.hada.io/topic?id=21334","Agno - 멀티 에이전트 시스템 개발을 위한 고성능 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Agno - 멀티 에이전트 시스템 개발을 위한 고성능 프레임워크

     * 메모리, 지식, 추론 기능을 갖춘 멀티 에이전트 시스템 개발을 위한 풀스택 프레임워크
     * 5단계 에이전틱 시스템(툴&명령/지식 저장소/메모리와 추론/에이전트 팀/에이전트 워크플로우)을 지원
     * 코드 몇 줄로 재무 정보 분석, 웹 검색 등 복합 에이전트 팀을 쉽게 구현할 수 있음
     * 모델 의존성이 없는 구조로 23개 이상 모델 프로바이더를 지원하며, 벤더 락인 문제 없음
     * 에이전트 인스턴스화 속도는 약 3μs, 메모리 사용량은 평균 6.5KiB의 고성능으로 대규모 에이전트 워크플로우에 적합
     * 추론 기능을 핵심으로 제공하며, Reasoning Model, ReasoningTools, Chain-of-Thought 세 가지 추론 방식 지원
     * 멀티모달 지원: 텍스트, 이미지, 오디오, 비디오 등 다양한 입력/출력 지원
     * 에이전트 팀(Agent Teams) 구성으로 역할별 협업, 컨텍스트 공유, 복합 과제 수행도 할 수 있음
     * 런타임 벡터 DB 검색, RAG(검색증강생성), 세션/장기 메모리 기능을 기본 내장
     * 구조화된 출력(Typed Response) 및 FastAPI 라우트로 바로 프로덕션 배포 가능
     * 실시간 세션 및 성능 모니터링 제공
"
"https://news.hada.io/topic?id=21400","3D프린터로 210km 비행가능한 VTOL 드론 제작기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     3D프린터로 210km 비행가능한 VTOL 드론 제작기

     * 3D 프린터로 제작한 VTOL 드론이 한 번 충전으로 130마일(약 210km), 3시간 비행에 성공해, 세계에서 가장 긴 비행거리와 체공시간을 가진 3D 프린트 VTOL 중 하나가 됨
     * CAD, 3D 프린팅, 공력 설계 경험이 전무한 상태에서 시작해, 단 90일 만에 독자적으로 설계, 출력, 조립, 비행까지 완성함
     * Bambu A1 3D 프린터와 foaming PLA 소재를 처음 활용하며, 다양한 파라미터 튜닝과 소재 품질 개선, 부품 소싱, 파워 손실 트러블슈팅 등 수많은 시행착오를 겪음
     * 프로젝트 설계/빌드 과정의 상세 내용은 영상 편집과 작업량 이슈로 미처 모두 공개하지 못했으며, 요청 시 더 자세한 노하우를 공유할 계획임
     * 리드 호프만 등 업계 인플루언서의 인용 트윗을 받으며 큰 화제를 모았고, 개인용 eVTOL 개발에 도전하는 과정에서 매우 뜻깊은 경험임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 개요 및 동기

     * 3D 프린터로 직접 설계·출력한 VTOL(수직이착륙) 드론이 한 번 충전으로 130마일, 3시간 연속 비행에 성공함
     * 이전까지는 CAD, 3D 프린팅, 공력 해석 등 관련 경험이 전혀 없는 완전 초보 상태에서 도전
     * 단 90일 만에 설계, 부품 조달, 조립, 비행까지 모든 과정을 독자적으로 완성해 냄

시행착오와 성장 과정

     * Bambu A1 3D 프린터, foaming PLA 소재 사용 등 대부분의 도구와 재료가 이번 프로젝트에서 처음 사용됨
     * CAD 역량도 기본 스케치와 단순 돌출만 가능했던 수준에서, VTOL 기체 설계와 공력 시뮬레이션까지 스스로 익혀나감
     * 부품 소싱, 출력 품질 개선, 파워 손실 트러블슈팅 등 각 단계마다 수많은 난관에 직면하며 실전 노하우를 습득함

미공개된 심화 설계·제작 과정

     * 영상 편집 및 콘텐츠 분량 문제로 기체 설계 파라미터 선정, 에어프레임 CAD 설계, 부품 조달, 출력 품질 향상, 파워 손실 분석 등 심층 과정을 모두 다루지는 못함
     * 원한다면 추가적인 설계/제작 노하우를 공유할 의사가 있음

커뮤니티 반응과 향후 목표

     * 리드 호프만이 “과거에는 형과 자전거 공장이 필요했다면, 이제는 올바른 툴체인만 있으면 된다”고 트윗을 인용하는 등 업계 및 커뮤니티에서 큰 주목을 받음
     * 본인은 이번 경험을 바탕으로 개인용 eVTOL 기체 개발에 지속적으로 도전할 예정임

     * 비전문가도 3D 프린터와 오픈소스 지식, 실험정신만 있으면 첨단 드론/항공기 개발이 가능한 시대임을 입증

   음 제 뱀부 프린터는 보드게임 컴포넌트만 찍고 있는데..

   foaming PLA 는 뱀부에서 PLA Aero라고 이름 붙인 특수 필라멘트입니다.
   안에 기포가 생기면서 저밀도/경량화가 가능합니다. 같은 부피에서 약 50%의 무게

   와.. 90일동안 감금하면 무기도 나오겠는데요 ㅎㅎ

        Hacker News 의견

     * 나는 foam 프레임 디자인과 비교한 점이 궁금함. 커스터마이즈 가능성과 3D 프린팅 부품의 비단단 채움 구조가 분명 장점임. 강성 측면에서는 3D 프린트 프레임이 쿼드콥터에는 카본파이버만큼 효과적이지 않지만, 고정익에는 폼의 대안으로 꽤 괜찮은 옵션으로 보임. 쿼드에서는 강성 문제가 극대화되지만, 이 기기처럼 단순 이륙과 착륙만 한다면 별로 중요하지 않음(고성능 드론처럼 극한 가속/기동이 아니면). 혹시 시도하고 싶다면, 사용 부품은 다 아마존 등에서 구입 가능한 일반 중국산 COTS임. 펌웨어로 사용하는 ArduPilot은 유연성과 안정성 면에서 훌륭하지만, 세팅할 때 UX가 최악의 축임. 대부분의 상업 UAS는 거의 예외 없이 PX4를 씀
          + 나는 single wall foaming PLA를 사용했는데, 충격 저항성도 약하고 확실히 brittleness가 큼. 가장 저렴한 폼코어, EPP, EPO보다도 약함. 실제로 충돌하거나 복구할 때 문제가 되었음. 예전에 만든 첫 VTOL은 foamcore Readyboard로 만들었는데, 12피트 높이에서 아스팔트에 떨어져도 단순 압축만 생겼고 교체도 안함. 다음에 프린트로 만든다면 dovetail이나 클립을 추가해서 내구성을 보강할 생각임. 아비오닉스, 추진 부품은 신속 조달을 위해 COTS 사용함. Amprius 배터리는 미국 제조이지만 나머지는 다 중국산임. 상업적으로 Ardupilot 사용도 점점 늘고 있지만 UX는 확실히 난해함
          + PLA 소재는 무게도 무겁고 brittleness도 커서 드론 비행에 폼보다 훨씬 못한 선택임. 조금 센 착륙에도 부품이 쉽게 부러짐. 비행기 무게가 무거우면 비행 성능도 안 좋아짐. 그래도 장점은 고장난 부품을 바로 다시 프린트할 수 있다는 점임. 그거 하나로 PLA가 가치있다고 느껴질 정도. ABS가 내구성도 좋고 더 가볍지만, 폼에 비하면 여전히 무거움. 또 ABS 프린팅은 까다로운 점도 있음
          + 상용 시스템에서는 제조사가 통합 작업과 완성도를 높여 제공하는 걸 구매하는 거니까 세팅 UX가 불친절한 건 큰 이슈가 아님. 대부분의 상업 UAS가 PX4를 쓰는 주된 이유는 라이선스와 유지보수 정책 차이임. ArduPilot은 GPLv3로 커뮤니티·취미용에 더 적합하지만 PX4는 BSD임. 상업 제조사는 자신들만의 커스터마이징 소스코드를 오픈하는 걸 회피하고 싶어함(별거 없어도 공개 자체를 꺼려함)
     * Amprius SA08 같은 최신 배터리 셀이 사용된 점이 놀라웠음. 배터리 팩 가격이 1300불 정도이나, Batemo Cell Explorer에 나와 있듯이 현재 시장에서 중량 대비 에너지 밀도가 가장 높음
     * 나는 200에이커 대지에서 드론으로 지도화 임무 비행을 함. 현재는 dronelink와 DJI 드론으로 파일럿팅. 총 약 3시간 정도 비행이 소요되고, 배터리 1개당 35분 정도 비행 가능함. 내 배터리가 4개인데, 연속 비행하려면 소비 속도만큼 충전해야 함(쿼드 충전기를 써도 충전이 부족함). 만약 넓은 지역을 비행하면서 사진을 연속 촬영해주는 고정익 드론이 있다면 대환영임. 하지만 자가제작/프로그래밍이 오프더셸프 DJI 드론 쓰는 것보다 훨씬 복잡해 보임. 그리고 지형 기복도 심하고 인근 공역 진입이 불가해서 턴도 쉽지 않음. 저자나 경험자 분들, 이 임무에 고정익 기체가 가치가 있는 선택인지, 아니면 그냥 쿼드콥터용 배터리를 더 사는 게 경제적인지 조언이 궁금함
          + 정말 좋은 질문임! 3시간 연속 비행이 가능한 5,000불 이하 VTOL 상용품은 딱히 없음. DJI만큼 단순하게 쓸 수 있는 것도 찾기 힘듦. DIY에 도전 의지가 있고 Ardupilot이나 PX4(이쪽이 더 쉬움) 사용법을 배울 각오가 있다면 Heewing T2 VTOL 같은 키트를 조립해볼 수 있음. 하지만 비슷한 고에너지 밀도 배터리를 써도 2시간 이상 비행은 힘들 듯함
          + 한 대로 다 하려고 하지 말고, 차라리 드론 열 대를 동시에 띄워서 동시 작업과 동시 충전을 권장함
          + 200에이커라면 4시간이 아니라 비행고도 120m, 75-65% 오버랩 기준 20~25분이면 커버 가능함. Mavic 3로 3.5cm/px GSD도 나올 수 있음. 비행 오버랩과 고도 최적화에 집중할 것을 추천함
          + eBee X 고정익 드론이 당신의 용도에 적합해 보임
          + 시간 여유가 있다면 FPV 드론 자가제작 세계에 입문할 수 있음. 프레임, 모터, ESC, 컨트롤러 등 전부 직접 교체 가능함. DJI에 비해 훨씬 많은 컨트롤과 만족감을 얻을 수 있음. 하지만 시간 투자와 경제성은 고민 필요함
     * 나는 쿼드콥터 모터 네 개를 활용해서 요/피치/롤을 다 컨트롤 표면 없이 할 수 있는지 궁금함. 만약 필요 없는 서보들을 제거해서 무게를 줄인다면 추가 배터리 소모를 상쇄할 수 있을지 호기심 생김
          + 좋은 질문임. 순항 단계에서 리프팅 모터를 계속 돌리는 것은 연비 면에서 손해임. 순항 모터가 윙 끝에 CG 기준으로 다수 있다면 차동 추력으로 롤을 유도할 방법은 있지만, 효율 문제로 잘 안 씀. 서보 무게는 전체 기체 중 극히 작은 비중임
          + 요 컨트롤은 어떻게 할지 궁금함
     * 이 프로젝트는 정말 감탄스러움. 프로젝트에 필요한 지식이나 스킬은 어떻게 시작했고, 어떤 점에서 새로운 학습이 필요했는지 궁금함. Ardupilot 커스터마이징은 얼마나 했는지, 드론 컨트롤 방식이 독특한지도 궁금함
          + 고마움! 호버, 전환, 크루즈 비행 모두 표준 Ardupilot 컨트롤 사용함. 펌웨어는 매개변수와 튜닝만 커스터마이징함
               o 이전에 폼보드로 VTOL 만들긴 했지만 3D 프린트는 처음
               o Ardupilot 경험은 이전 프로젝트와 멀티콥터, COTS VTOL 조립 경험에서 쌓아옴
               o 구조적으로 튼튼한 VTOL 프레임을 만드는 경험은 조금 있었고, 3D 프린팅이 새로웠음
               o 직접 해보며 디자인, 비행 테스트, 트러블슈팅에 집중. 필요할 때마다 LLM, 유튜브, 포럼 참고
               o 공개적으로 과정을 기록하면 오히려 동기부여도 커져서 시간도 절약되고 프로그레스도 빨라짐. 기록/공유가 부담되긴 하지만 결국 이득이 큼
          + Ardupilot은 정말 성숙한 소프트웨어임. 우크라이나에서 나오는 많은 드론 영상의 HUD도 거의 Ardupilot 기반임. 할 수 있다고 생각하는 건 대부분 지원함. 비행기, 헬리콥터, VTOL, 스피드보트, 요트 다 가능함
          + 별다른 커스터마이징 없이 Ardupilot 기본으로 VTOL 가능해 보임
     * 아마추어가 만든 것이라 믿기지 않을 만큼 인상적임. 수직과 수평 비행용 모터를 따로 두면 설계가 단순해지지만, 수평 비행 시 버티컬 모터가 드래그를 많이 일으키는 비효율 문제가 있음. 크다면 문제가 될 수도 있지만, 반면 모터를 회전시키려 하면 무게가 증가해 오히려 항속거리가 줄 듯함
          + 사실 이 구성의 비효율이 그리 크지는 않음. 순항용 모터와 프로펠러를 최적으로 sizing 할 수 있어서 nontrivial한 효율 이득이 있음. 틸트로터/윙/바디 방식은 크루즈 모터가 리프트도 같이 담당해야 해서 크루즈 때 모터가 최적 rpm이 아님. 호버가 크루즈에 비해 4~7배 더 많은 전력을 소비하는데, 이럴 경우 모터가 최적이 아닌 구간에서 동작함. Archer CTO Munoz도 이런 점을 공개적으로 언급한 적 있음
          + Wing에서 이미 거의 동일한 디자인을 사용함. 분석과 시뮬레이션으로 비용, 항속거리, 복잡성, 안전성 등 다방면에서 최적화가 이루어졌을 것으로 추정함
            [Wing Aviation 설계 참조](https://en.wikipedia.org/wiki/Wing_Aviation/…)
          + DIY 틸트로터 VTOL 설계는 정말 다양함. 참고로 Hackaday 틸트로터 VTOL 사례 공유함
          + 틸트로터 메커니즘을 추가하는 건 이 프로젝트 규모와 목적에서는 복잡성과 무게 증가에 비해 가치가 적음. 별도의 모터/프로펠러에서 생기는 무게/드래그가 늘어난다는 점은 맞음
          + 개인 홍보지만: Aliptera는 4모터 모두 틸트로터에 독특한 날개 구조를 더해 수직 비행 모드에서 윙이 리프트까지 제공함. 모터 크기를 더 줄여서 수평 비행 시 효율도 향상함
     * 정말 멋짐. 많은 사람들이 스스로 좋아하는 걸 만드는 영감을 받았으면 좋겠음. ""그냥 하면 되고 배울 수 있음."" 허락, 수업, 학위, 지도교사 따위 필요 없음
          + 공감함. 실제로 열정이 있으면 일하는 속도와 완성도가 훨씬 올라감
     * ""100년 전에는 비행 선구자가 되려면 형제가 필요했고 자전거 가게가 있어야 했음. 오늘날에는 단지 올바른 툴체인만 있으면 됨""이라는 문구가 인상 깊음. 현실화 루프(상상→현실)가 이미 존재하는 카테고리에서 가장 빠르게 이루어짐
     * 정말 인상적임. 멀티모터 설계에서 컨트롤 서피스가 얼마나 중요한지 궁금함
     * 나는 오래전부터 만들기에 관심은 있었지만 아직 시도 못했음. 상세한 제작 플랜과 초보자 중심의 튜토리얼이 있었으면 좋겠음. 프로젝트에 도네이션 혹은 Patreon 참여 의향도 있음
          + 고마움! 하지만 보이스오버, 영상 편집 등 긴 영상 제작은 정말 많은 노력이 필요한 작업임
"
"https://news.hada.io/topic?id=21418","에이전트와 함께 프로그래밍하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          에이전트와 함께 프로그래밍하는 방법

     * 이 글은 기존 프로그래밍 경험을 대화형 컴퓨터(LLM, 에이전트) 세계에 적응하는 과정을 다루는 두 번째 내용임
     * 첫 번째 파트인 ""LLM과 함께 프로그래밍하는 방법"" 에서는 LLM을 기존 도구에 접목해 자동완성이나 검색 대체로 활용하는 방법을 설명함
     * 이번에는 좀 더 어려우면서도 보람 있는, 에이전트 기반 프로그래밍의 실제적 경험과 통찰을 공유함

에이전트의 정의와 실제

     * LLM(대형 언어 모델) 맥락에서 ""에이전트""라는 용어를 정의하는 것이 의미 있음
     * AI 업계의 유행어처럼 오랫동안 사용되어 왔으나, 실제로 쓸모 있는 구조로 자리잡은 것은 최근임
     * 이 과정에서 많은 마케팅적 수사와 신비주의가 덧씌워져 왔음

     * 엔지니어의 시각에서 보면 이제는 명확하고 단순하게 정의할 수 있음: 에이전트는 9줄짜리 코드, 즉 LLM 호출을 포함한 for 루프임
     * 이 루프 안에서 LLM이 명령을 실행하고 그 결과를 직접 확인할 수 있으며, 인간의 개입 없이 반복적으로 동작함
     * 단순하게 느껴질 수 있으나, 실제로 이렇게 구성하면 순수 LLM만 사용할 때보다 프로그래밍 능력이 비약적으로 향상됨

화이트보드 프로그래밍과 에이전트의 차이

     * 화이트보드 앞에 서서 마커로 C 언어로 UTF-8 문자열의 유효성을 검사하는 함수를 작성한다고 가정해보면
          + (실제로 필자가 겪은 면접 상황이자 흔한 인터뷰 과제임)
          + 이 작업의 성패는 프로그래머로서의 경험, 그리고 외부 자료를 참고하지 못하는 한계를 얼버무릴 수 있는 능력에 달려 있음
          + UTF-8 인코딩 규칙을 기억해야 하고, C 문법이 다른 C계열 언어와 헷갈리지 않도록 주의해야 함(이름-타입, 타입-이름 순서 등)
          + 실제 일상에서는 컴파일러 피드백, 문서 검색, printfs 등 다양한 방법으로 코드를 검증하고 오류를 찾을 수 있음
     * 에이전트 없이 LLM에게 코드를 작성시키는 것은 화이트보드에서 외부 도움 없이 코드를 짜는 것과 비슷함
          + 어렴풋한 기억을 끌어내고, 비효율적인 방식으로 문법을 맞추려 애쓰며, 엉뚱한 인터페이스를 상상하는 오류를 피해야 하는 작업임
          + LLM이 완전히 새로운 프로그램을 만들어내는 기술적 성과는 놀랍지만, GPU를 연결한 가상 화이트보드만으로는 실질적 프로그래밍 생산성이 크게 오르지 않음
     * 하지만 LLM에게 가상 화이트보드 그 이상을 제공하면?
          + 예를 들어 컴파일러를 호출하고, 컴파일 에러를 확인한 뒤 스스로 수정할 수 있도록 하면?
          + grep, cat으로 기존 파일을 읽고, 여러 파일(유닛 테스트 포함)을 패치하고 반복적으로 테스트까지 할 수 있다면?
     * 에이전트는 바로 이런 피드백 기반 LLM임.

에이전트 = 피드백 환경에서 동작하는 LLM

     * 사람처럼 피드백 환경에서 잘 작동하는 LLM은 몇 가지 친숙한 도구만 있어도 실질적인 프로그래밍 능력을 발휘함
          + bash(cmd): 터미널 명령 실행 (find, cat, grep 등)
          + patch(hunks): 파일 패치, 코드 변경 적용
          + todo(tasks): 작업 목록 관리
          + web_nav(url), web_eval(script), web_logs(), web_screenshot() 등: 웹 탐색, 평가, 로그, 스크린샷 등
          + keyword_search(keywords): 키워드 검색
          + codereview(): 코드 리뷰
     * bash 도구를 활용해 코드베이스를 효율적으로 탐색하며, git add/commit 등 버전 관리까지 자동화함
     * 이러한 도구 없이 단순 코드 생성만 하는 LLM과 달리, 에이전트는 다음과 같은 차별화된 이점을 가짐
          + API 사용 정확성이 크게 향상됨 (문서 검색 및 직접 context에 반영)
          + 컴파일러 피드백으로 문법 오류 및 인터페이스 착오 감소
          + 의존성/버전 관리 능력 강화 (특정 버전 특성 파악 가능)
          + 테스트 실패를 통한 오류 탐지 및 테스트 코드 작성 습관 강화
          + 컨텍스트 윈도우 한계를 넘어서는 코드베이스 처리 (필요한 부분만 선택적으로 읽음)
          + 실행 결과를 직접 실험: 코드를 실행, 브라우저 페이지 스크린샷 피드백, CSS 자동 조정, 서버 로그로 오류 추적 및 테스트 추가
     * 단점도 존재함
          + 한 문장 요청으로 수만 개의 중간 토큰(도구 호출, 웹검색, 테스트 반복 등) 발생, 작업 시간이 수 분 이상 소요
          + API 호출 비용도 발생하지만, 하드웨어 발전으로 점차 사라질 전망
     * 궁극적으로 중간 노동을 CPU/GPU가 대신 수행, 개발자의 시간을 아껴주며, 쓰고 싶었던 프로그램을 더 많이 완성할 수 있음
     * 실제로 프로젝트에 에이전트를 도입해 작은 작업을 시켜보고 결과를 확인하는 것이 쉬움

예: Github App 인증 개발

     * 에이전트를 활용해 sketch.dev의 Github App 인증 플로우를 구현한 실제 사례임
          + 3~4번의 피드백만으로 전체 인증 흐름을 빠르게 완성함
          + 오류나 요구 조건 발견 시 간단한 문장으로 설명해주면 바로 코드와 동작을 개선함
          + 반복적이고 지루한 API 연동 작업, 빌드 시스템/패키지 관리/라이브러리 세팅 등 실무의 ""잡무""를 최소화하여 생산성 모멘텀 유지에 큰 도움을 줌
     * 초기 요구사항으로 ""사용자별 토큰 저장 없이 앱의 글로벌 인증 정보만 사용""을 넣었고, 에이전트가 이를 반영해 구현함
          + 하지만 그 결과 심각한 보안 취약점이 발생 (누구나 모든 레포를 볼 수 있게 됨)
          + 문제 설명을 한 문장으로 피드백하니, 바로 사용자별 권한 체크를 도입해 수정된 커밋을 생성함
     * 그 다음 성능 문제가 드러남
          + 아래와 같은 구조로 모든 유저-레포 조합에 대해 API 호출이 발생하여 확장성에 문제가 있었음
for install := range allAppInstallations {
        for r := range install.Repositories() {
                if r.IsCollaborator(user) {
                        // add to available repositories
                }
        }
}

          + 이 문제의 근본 원인이 ""사용자별 토큰을 저장하지 않는다""는 나의 요구조건임을 깨달음
          + 요구사항을 변경(사용자별 토큰 저장 허용)하니, 에이전트가 효율적인 API 호출 방식으로 다시 설계함
     * 실제로 이 과정을 글로 설명하는 데 쓴 단어 수가, Sketch에서 인증 코드를 얻기 위해 입력한 총 단어 수보다 많았음
     * 한마디로, 에이전트는 오늘날 개발자를 대체할 수 있는 수준은 아니지만, 전통적으로 며칠 걸릴 반복적 작업을 하루 만에 처리하게 도와줌
     * 개발자가 ""아이 방 청소를 하면서""도 일을 진행할 수 있을 정도로 자동화가 이뤄짐

예: JSON 기반 SQL 규칙 적용

     * 에이전트가 자주 처리하는 작업 중 하나로, Tailscale에서 배운 특이한 SQL 스타일을 적용해야 했음
          + 모든 테이블에 실제 컬럼은 하나(JSON 데이터), 나머지 컬럼은 JSON에서 파생된 generated column으로 처리
          + 예시 테이블 구조:
CREATE TABLE IF NOT EXISTS Cookie (
  Cookie   TEXT    NOT NULL AS (Data->>'cookie')  STORED UNIQUE, -- PK
  UserID   INTEGER NOT NULL AS (Data->>'user_id') STORED REFERENCES User (UserID),
  Created  INTEGER NOT NULL AS (unixepoch(Data->>'created')) STORED,
  LastUsed INTEGER AS (unixepoch(Data->>'last_used')) CHECK (LastUsed>0),
  Data     JSONB   NOT NULL
);

          + 이런 방식은 일종의 poor man’s ORM 역할을 하며, 스키마 확장이 쉬워지고, SQL 제약조건이 JSON 데이터 품질 검증에 도움이 됨
          + 단점은 행당 저장 데이터가 늘어나고, 모든 INSERT/UPDATE가 JSON 단위로 이뤄져야 함
     * 하지만 에이전트는 이 스타일을 항상 일관되게 따르지 못했음
          + 새로운 테이블을 만들 때는 대체로 잘 따르다가, 예외가 있으면 혼동하거나 임의로 스타일을 바꿔버리는 경우가 있었음
     * 간단한 해결책: SQL 스키마 파일 상단에 3문장 설명 추가
          + ""각 테이블은 하나의 실제 Data JSON 컬럼만 가지고, 나머지 컬럼은 모두 여기서 파생된다""는 키워드 문장 추가
          + 이 규칙을 따르지 않는 테이블에는 별도 주석으로 예외임을 명시
          + 이후 에이전트의 동작이 눈에 띄게 개선됨
     * 흥미로운 점은, 이런 설명과 주석을 실제 인간 엔지니어들은 대체로 무시하거나 효용을 낮게 평가하지만,
          + LLM 기반 에이전트는 주석과 설명을 코드 작성에 적극적으로 반영함
          + 설명만 잘 달아줘도 코드 생성 품질이 확연히 좋아짐

“자산”과 “부채” 코드 모델

     * LLM 기반 코드 생성 도구에 대한 흔한 비판 중 하나는 코드 생성 자체는 전체 소프트웨어 비용에서 극히 일부에 불과하다는 것임
          + 실제로는 기존 코드의 의존성, 얽힘, 복잡한 인터페이스를 관리하는 데 대부분의 시간이 소요됨
          + 규모가 큰, 오래된, 다수 사용자가 있는 제품은 유지보수 비용이 압도적으로 큼
          + 이런 환경에서 LLM에게 ""버블 정렬을 Fortran으로 짜줘""라고 요청하는 건 장난감 혹은 불편한 방해물로 느껴질 수 있음
          + 금융의 ""자산/부채"" 개념과 비교하는 논의도 있으나, 이 역시 완벽하게 들어맞지는 않음
     * 그러나 모든 소프트웨어 엔지니어링이 이런 대규모, 장기 프로젝트에만 해당하는 것은 아님
          + 대부분의 프로그램은 소수 사용자 또는 단명 프로젝트임
          + 대규모 유지보수 경험만을 전체 산업의 본질로 확대 해석하면 안 됨
     * 에이전트의 가치는 코드 생성에만 국한되지 않음
          + 에이전트는 여러 도구와 LLM을 결합해 코드 읽기, 파일 편집, 코드 삭제/수정 등 변화 자체를 자동화함
          + 코드를 추가하는 것만큼 코드 삭제/리팩터링도 자연스럽게 수행함
     * 결국 엔지니어의 목표는 변화(change)
          + 변화 과정에서 운전자가 변경을 이해해야 하는 추가 작업은 있으나, 에이전트는 중간 규모 프로젝트까지도 점진적 변화를 만들어낼 역량을 보여주고 있음
          + 현재 충분하지 않더라도, 에이전트는 올바른 방향으로 빠르게 발전 중임
     * 추가로, 복잡한 언어나 빌드 시스템이 프로젝트의 진입 장벽 역할을 한다는 의견도 있음
          + 쉽게 코드를 작성할 수 있는 도구(LMM, 타입 세이프티, 가비지 컬렉션, 패키지 매니지먼트, 에이전트 등)가 진입 장벽을 낮추면 품질 저하 우려가 있다는 주장
          + 만약 변화 속도를 늦추거나 통제를 목표로 한다면, 에이전트와 같은 자동화 도구는 맞지 않음

왜 지금 에이전트인가?

     * 트랜스포머 같은 복잡한 AI 원리와 달리, LLM에 피드백 루프를 넣는 것은 직관적으로 명확한 접근임
          + 개발자 도구를 고민하는 입장에서는 자연스러운 발전 방향으로 느껴짐
          + 실제로 1년 전 sketch.dev의 첫 버전도 LLM에 go 도구만 연결한 수준이었지만, 지금 사용하는 에이전트와는 실용성에서 큰 차이가 있음
          + ML 분야에서도 강화학습(피드백 기반 학습) 이 50년 이상 기본 원칙임
     * 에이전트의 실질적 등장은 LLM의 진화와 직결됨
          + 2023년 LLM은 도구 호출 능력이 부족해 에이전트 역할이 제한적이었음
          + 2025년 LLM은 도구 호출 및 반복 작업에 최적화되어 있어, 실질적인 에이전트 활용이 가능해짐
          + Frontier(최신 상용) 모델은 오픈모델에 비해 도구 활용력에서 크게 앞서 있음
          + 향후 6개월 내 오픈모델도 따라잡을 것으로 기대됨
          + 유용한 반복적 도구 호출이 가능한 것이 최신 LLM의 가장 큰 변화임

앞으로의 방향: 컨테이너와 병렬 실행

     * LLM 에이전트 분야는 아직 대부분의 엔지니어가 실제로 도입하지 않은 초기·빠른 변화의 단계임
     * 현 시점에서 에이전트는 주로 IDE나 로컬 저장소에서 작동하도록 활용됨
          + VSCode 포크나 커맨드라인 도구 설치로 쉽게 시작할 수 있음
          + 하지만 두 가지 중요한 한계가 있음
               o 첫째, 안전장치 부족: 실컴퓨터에 저장된 실운영 인증정보 등 민감 정보 노출 위험
                    # 에이전트가 배포 스크립트 등 의도치 않은 명령 실행 시 치명적 보안 사고 발생 가능
                    # 명령 실행마다 수동 확인을 요구하지만, 실수로 민감정보 노출 가능성은 여전함
               o 둘째, 병렬 실행 및 자동화 한계: 각 개발자가 자기 환경에서 에이전트를 하나씩만 실행해야 하므로
                    # 에이전트 1회 동작마다 수 분씩 걸려 여러 작업을 동시에 진행하기 어렵고 비효율적임
     * 이러한 한계를 sketch.dev에서는 컨테이너 환경으로 해결 시도 중
          + 각 작업별로 격리된 개발 컨테이너를 만들고 소스코드를 복제해 git 커밋 등만 외부로 추출
          + 여러 에이전트를 동시에 실행할 수 있으며, 다른 에이전트들도 이 방식을 탐색 중임
     * 실제 사례: Github 인증 작업과 동시에 폼 UI 개선을 별도의 에이전트 세션으로 처리
          + 별도의 이슈 트래커 등록 없이, 스크린샷과 짧은 요청 한 줄로 폼 디자인 개선 피드백 처리
          + 30초 투자로도 일정 수준 이상의 결과를 얻는 경험 제공
     * 지난 6개월간 UX 실험 결과:
          + 에이전트 기반 개발에 있어 컨테이너(격리 실행 환경)가 가장 실용적이라는 결론에 도달

IDE는 무엇이 되는가?

     * 에이전트 기반 개발 환경에서 IDE(통합 개발 환경)의 역할이 무엇이 될지는 여전히 열려 있는 질문임
          + 에이전트에게 지시문을 입력해 작업을 시작하고, 컨테이너 환경에서 실행하며, 변경사항을 diff로 확인하고 브랜치/PR로 푸시하는 것이 실제 워크플로우가 될 수 있음
     * 실제로는, 에이전트가 생성한 대부분의 커밋에 일정 수준의 사람 손질(클린업)이 필요함
          + 처음에는 거의 모든 커밋이 수동 수정 필요, 하지만 프롬프트 작성 숙련도가 올라가면 점점 수정량이 줄어듦
          + 수정 내용은 주석 편집, 변수명 변경 같은 간단한 것부터, 더 복잡한 리팩터링까지 다양함
          + 컨테이너 환경에서 이런 수정을 어떻게 효율적으로 할지가 핵심
     * sketch.dev 등에서 실험 중인 워크플로우
          + diff 뷰를 직접 수정 가능한 인터페이스 제공
               o Sketch의 diff 화면 오른쪽에 코드를 직접 수정하면 해당 커밋에 반영되어 바로 푸시됨
               o 작은 한 줄 수정에 매우 효율적임
          + 컨테이너에 SSH 접근을 제공하여
               o 쉘로 직접 진입하거나, 웹 터미널로 코드를 조작
               o vscode:// URL로 열어 전통 IDE에서 작업 가능
          + 코드리뷰 스타일 코멘트를 diff 상에서 직접 남겨 에이전트에 피드백으로 전달
               o 코드리뷰 경험을 살려, 필요한 설명/요구사항을 최소한의 입력만으로 전달
     * 총평
          + 컨테이너 환경은 코드 생성-수정-검증-리뷰가 통합적으로 이뤄지게 하여,
            단순한 코드 작성을 넘어 진정한 에이전트 기반 개발을 가능하게 해줌
          + 과거에는 컨테이너에서 개발하고 싶지 않았지만,
            에이전트가 만든 diff를 컨테이너에서 정리/수정하는 경험은 매우 흥미롭고 생산적임

맺음말

     * LLM 기반 기술을 배우고 실험하는 과정은 겸손함을 배우는 시간이었음
          + 과거 멀티코어, SSD 도입, 네트워크 확장 등 프로그래밍 본질이 변할 때마다 즐거움을 느꼈지만,
            LLM, 특히 에이전트는 코딩의 ""과정 자체""를 완전히 새롭게 만들고 있음
          + 알고리듬, 언어, 라이브러리 선택에 영향을 주던 변화와는 달리,
            에이전트는 작업 방식 그 자체의 모든 전제를 근본적으로 재검토하게 만듦
          + 때론 ""프로그래밍을 전혀 모르는 상태에서 처음부터 다시 배우는 게 더 나을 것 같다""는 생각이 들 정도로 변화가 큼
          + 그리고 이 변화는 지금도 계속 진행 중임
     * 지금 우리가 경험하는 방식은 6개월 전과도 완전히 다르고, 아직 안정화되지도 않음
          + 팀 협업, 리뷰 등 개발문화의 표준도 곧 크게 바뀔 것으로 보임
          + 예를 들어, 형식적으로만 이뤄지던 코드리뷰는 더 이상 실질적인 문제를 해결하지 못하고 있음
               o 코드리뷰 프로세스 자체를 새롭게 발명해야 할 시점
          + IDE 역시 그동안 주장했던 통합성과는 달리, 완전히 뜯어고쳐야 할 때가 옴
          + 업계에서도 이 변화를 인식하고 있지만, 에이전트 중심 접근은 이제 막 시작 단계
          + 앞으로도 큰 변화가 예고되어 있으며,
            호기심과 겸손함만이 이 변화를 잘 통과하는 방법임
          + 오히려 지금은 기술 관련 인터넷 포럼을 멀리하고,
            이런 토론과 요약도 에이전트에게 맡기는 것이 나을 수 있음

        Hacker News 의견

     * 나는 주로 내 도구를 위해서만 코딩하기 때문에, 내 코드가 아닌 다른 누군가 또는 어떤 무언가가 코드를 대신 작성한 다음 그걸 읽고, 이해하고, 고치는 것에 큰 메리트를 잘 모르겠다는 생각을 함, 물론 API 문서에서 내가 원하는 부분을 LLM에게 찾아달라고 하면 상당히 유용하고 시간 절약임, 그래서 LLM의 미래 성능이 좋아질지 여부와 무관하게 나는 그냥 남의 코드를 읽는 것 자체가 별로임
          + 나에게는 LLM이 도움이 되는 케이스가 있음, 예를 들면 공식화된 코드에서는 매크로나 코드 생성기가 필요 없어지는 효과가 있음, 다만 느리고 매크로처럼 한번에 전체 갱신하긴 어렵지만, 약간씩 다르게 반복되는 구조의 코드에는 오히려 매크로보다 LLM이 유용함, 또 익숙하지만 코드까지는 외우지 않은 API 쓸 때 구글 검색하고 문서 뒤질 필요 없이 바로바로 작업 가능, 타입 언어를 쓰기 때문에 LLM이 헛소리하면 타입체커나 테스트에서 걸러낼 수 있어서 큰 걱정 없음, 그리고 10개 이상의 파일에 걸쳐 변경이 필요할 때 마크다운으로 변경 계획을 세워주는 게 정말 큰 시간 절약임, 마지막으로 피로할 때 스타일이나 네이밍 규칙을 그냥 넘기기 쉬운데 LLM은 프로젝트의 기존 스타일을 잘 유지해줘서 좋음
          + 요즘 이런 방식으로 일하는 게 점점 좋아짐, 우선 전체 코딩 디자인을 계획한 후, LLM에게 구체적 단계들을 설명해 주고, 내가 코드 읽고 이해하고, 고치고, 다음 단계를 계획하는 동안 LLM이 다음 섹션 코드를 미리 작업하게 만듦, 말하자면 나와 LLM이 병렬로 각자 작업하는 흐름임, 이건 마치 레스토랑의 쉐프가 주문이 들어오면 그 즉시 전체 요리 작업 단계를 구상하고, 스테이크를 굽는 동안 기다리지 않고 다른 준비도 병행하는 상황과 같음, LLM은 오븐이나 푸드 프로세서 같은 조리 도구에 가까움, 예를 들어 치즈 갈기를 손으로 할 수도 있지만 푸드 프로세서에 넣어두면 몇 분 절약 가능, 전문 요리사는 각종 도구를 활용해 멀티태스킹으로 효율을 올리는데, 앞으로 코딩도 한 줄씩 단계별 작업이 아니라 멀티태스킹 구조로 바뀔 수도 있다고 생각
          + 내가 다른 무언가에 내 코드 작성 책임을 미루고 결국 그걸 다시 읽고, 이해하고, 또 직접 고치는 것에 무슨 이점이 있냐는 의문에 대해선, '마찰'이라는 표현을 씀, 많은 사람들이 새 일을 시작하는 걸 어려워하고(작가의 블락처럼), 이미 다른 누군가가 만들어둔 솔루션을 받으면 그걸 내 방식대로 바꾸고 모듈화하는 게 진입 장벽을 크게 낮춰줌, 나와 동료들 중 프로젝트를 0에서 세팅할 때 툴체인 구성과 부트스트랩에 큰 부담을 느끼는 사람이 많음, LLM은 충분한 컨텍스트와 자원이 있으면 전체 코드베이스를 빠르게 스캔해서 ""이미 이 코드 내에 audit 메커니즘이 두 군데 있으니 공통부를 추출하자"" 같은 걸 발견해줄 수도 있음, 내가 스스로 놓치던 부분까지 자동으로 잡아줄 수 있음
          + 내가 다루는 한 코드베이스에선 여러 파일을 반복적으로 조금씩 바꿔야 하는 과업이 많음, 이런 일은 창의성이나 도전보단 그저 여러 파일 열고 수정하는 반복노동임, 이전까진 3~4시간 걸렸지만 AI 에이전트에게 작업을 설명해주면 99% 알아서 처리해주고, 소요 시간이 3~4분밖에 되지 않음
          + 어떤 사람들은 도구 없인 아무 것도 못하는 타입임, 이런 사람들이 얼리어답터이자 파워유저가 되어 새로운 발견을 전파함, GitHub의 가치는 평범한 개발자가 PR, 리뷰, 그린스퀘어, todo 리스트 등에서 생산적인 듯 보일 수 있는 환경 제공이었음, LLM 또한 평범한 개발자가 별 중요하지 않은 도구와 에이전트들을 돌리면서 생산적인 모습을 연출할 수 있게 해주기 때문에 매니저들이 좋아함
     * 저자는 코드 리뷰가 부실하고 거의 제대로 동작하지 않는다고 한 부분에 완전히 동의함, 에이전트가 코드를 작성하는 시대에는 실제 병목은 작성이 아니라 코드 읽기임, 사람들이 리뷰를 대충하거나 각자 취향을 드러내는 수단 정도로만 사용하면, 에이전트는 심각한 보안이나 성능 문제를 쉽게 집어넣을 수 있음, 솔직히 진짜 문제는 코드를 읽는 것만으론 안 보이고, 직접 디버깅하거나 가정들을 검증하는 수작업이 필요함
          + 에이전트/AI 코드는 '부실 리뷰' 문제를 어떤 식으로 해결하는지 분명하지 않다는 의문임, 사람들은 코드 리뷰 자체를 하기 싫어하고 지루해함, 나는 재미있는 부분인 '코드 작성'을 AI에게 넘겨버리고 대신 끝없는 코드 읽기&검수를 받아야 하는 상황이 올까봐 걱정임
          + 현재 시장에서 가장 부족한 부분은 LLM이 만들어낸 코드, diff, 전체 코드베이스를 어떻게 효율적으로 읽고, 제대로 리뷰하고, 이해하느냐의 문제임, 프로젝트 내에 사람 자체가 소수 뿐이라면 남아있는 사람들이 코드를 실제로 읽기는 하는지, 아니면 그냥 넘겨버리는지 걱정임
          + 에이전트의 핵심은 테스트 커버리지가 충분하다면, AI가 코드를 작성하고 안전/성능 피드백까지 얻을 수 있다는 점임, 그리고 그 AI가 테스트 작성도 도와줌
     * 드디어 LLM에 대한 현실적인 분석을 한 글을 봤다는 소감임, ""에이전트""라는 용어가 사실상 재귀적으로 LLM을 부르는 for 루프에 이름 붙인 것이라 좀 답답하지만, 작명 센스가 원래 업계 평균도 낮으니 그냥 받아들임
          + '에이전트'의 정의에서 글쓴이와 같지 않다는 의견임, 진짜로는 LLM이 (반복적으로) 도구와 리소스를 호출하며 루프 도는 구조임, 미묘한 차이지만 어디까지가 주체인지를 정하는 문제임
          + ""에이전트란 도구가 루프에 있는 것""이라는 표현이 마음에 들었음, Simon이 이렇게 말했다고 기억함
          + OP의 에이전트 정의에 약간 이견이 있음, 단순히 LLM이 루프 도는 게 아니라, LLM의 행위가 다른 논리적 컴포넌트에 의해 제약되거나 유도되는 게 진짜 특징임, 이 중 일부는 결정적이고 다른 일부는 ML 기반(LMM 포함)임, 즉 LLM이 어떤 방식으로든 설계된 시스템에서 계획을 강제로 짜게 하거나, 코드 편집 이후 테스트 빌드 및 실행을 트리거하는 등의 방법을 통해 추가 유용성을 얻을 수 있음, ""에이전트는 스스로 입력 받아 움직인다""라는 설명이 틀리진 않지만, 실은 여러 구성요소가 수시로 LLM의 행동을 감독 및 인도하는 의도가 더 본질적임
          + ""Agent""라는 네이밍 자체는 사람들이 직관적으로 잘 이해하기 때문에 괜찮다고 보지만, 혹시 다른 대안 후보로는 LoopGPT 같은 건 어떨지 생각함
     * ""우리는 컨테이너가 프로그래밍에서 쓸모 있고 필요하다는 점에 동의함"" 이 부분과 관련해 Docker를 만든 Solomon Hykes가 왜 최근 Container Use라는 프로젝트를 오픈소스로 공개했는지 설명함, 에이전트가 병렬로 안전하게 실행이 가능하도록 하기 위함, Sketch 등 일부 플랫폼은 격리된 로컬 개발환경을 내장하고 있지만 다른 코딩 에이전트들은 그렇지 않아서, 추가 정보로 YouTube 영상도 추천함
     * 에이전틱 루프, 기계 안의 두뇌, 사실상 규칙 엔진의 대체물로 보임, 아직 고유한 단점도 있지만 여러 대가들이 본질을 잘 짚어냈다고 생각함, '에이전트 도구를 연결해서, 사용자의 요청으로 프롬프트 해주고, 그냥 돌리며 반복 실행, 그리고 프롬프트 자체도 상황에 따라 동적으로 변함', 이런 식으로 인간적 인터랙션이나 문제해결 방식을 굳이 흉내내지 않아도 오케스트레이션/다단계, 모호한 태스크 대체나 자동화에 충분히 유용함, 예전엔 모호성을 직접 코드로 구현해야 했는데 이제 사라질 수도 있음, 실운영 환경에선 dry run 없이 실행시키는 것에 대한 우려도 있지만 도구, 서비스 자체가 진화하리라 생각함, 100개가 넘는 유사 서비스들이 일관된 인터페이스로 외부 세계(e.g. SMS, 메일, 날씨, 소셜 등)와 연결되면 지금보다 훨씬 더 강력한 어시스턴트
       또는 그 이상이 나올 것으로 기대함
          + 캘린더, 날씨 등 여러 서비스에 에이전트를 연결해 게임 인터페이스를 만든 흥미로운 토이 프로젝트가 있음, 링크
          + 모든 사용 도구에 대해 추상화가 통일되면 기존의 어시스턴트보다 훨씬 뛰어나질 수 있지만, 그만큼 어마어마한 장애, 오류 가능성도 감수해야 하는 현실임, 신뢰성 엔지니어링, 품질보증, 권한 관리, 보안, 개인정보 보호 같은 이슈가 갈수록 더 중요해질 전망임, 애플이 Siri의 한계를 뛰어넘는 최신 음성 어시스턴트를 내놓지 않는 이유도 바로 이 리스크 관리 때문일 수도 있다고 추측함
     * 코드 읽기가 항상 작성만큼 중요했지만 이제 점점 더 중요해지는 현실임, 내 악몽임, 코드 작성은 때로 즐거움이 있는데, 코드 읽기는 언제나 노동임
          + 그래도 '고치는 재미'가 계속 남아있거나 오히려 늘어날 수 있음
     * 에이전트를 쓰는 사람이 실제로 ""프로그래밍"" 즉, 문제 해결 방식 고민과 코드로 표현하는 즐거움 자체를 좋아하는 사람이 얼마나 될지 궁금함, 요즘 많은 에이전트 작업을 보면 그 과정 자체가 사라지고 오히려 자연어로 요구사항만 설명한 다음 LLM이 버그를 만들지 않기만 바라게 되는 구조임
          + 나는 코딩 자체를 즐기는 타입이고, LLM이 내가 재미있을 법한 파서를 한 번에 만들어내면 오히려 허탈함도 들었음, 그래도 시간 잡아먹는 파서 작성 대신 더 큰 목표에 집중할 수 있게 됨, 원하는 타입/함수 시그니처만 짜두고 LLM이 세부 구현을 채워주면 바로 다음 단계 진행이 가능해진 점이 인상적임, 예전에는 ""고치면 좋겠지만 너무 귀찮음"" 수준의 전체 수정도 큰 부담이었는데, 이제는 코드 다듬기, 테스트 생성, README 싱크, 리팩토링 아이디어까지 다 LLM이 도와줘서 오히려 프로젝트 완성도와 야망이 높아짐, 마음가짐만 잘 바꾸면 소프트웨어를 즐기는 빌더들에겐 천국이라고 볼 수 있음
          + 역으로 나는 코드 작성이 수천 번 반복되었던 문제에 대해서는 별로 내 손으로 구현하고 싶지 않음, 그럴 땐 딕셔너리를 쓰지 해시테이블을 새로 만들진 않음, 만약 ""이 언어 컴파일러를 만들어줘""라고 하거나 ""DFS로 풀어봐""라고 해서 완벽하게 결과가 온다면 오히려 프로그래밍 재미가 줄어들지 않을 것임, 자연어로 컴퓨팅 프로세스를 기술하는 건 복잡한 수준에선 부정확하거나 모순을 초래하기 쉬운 한계는 있음, 그래도 어느 쪽이든 LLM을 아무 생각 없이 사용하는 건 누구도 권장하지 않고 있고, 결국 결과에 대한 책임은 내가 가져가야 함
          + 자연어가 프로그래밍에 적합하지 않다는 근거로 EWD667 문서를 참고함, 실제로 LLM은 stackoverflow 스타일 질문-답변엔 쓸모 있는데, 앞으로 SO의 데이터가 줄어들면 그조차 한계가 생길 수 있다고 봄
          + 나로서는 동의하지 않음, LLM이 하는 일은 대부분 반복적이고 지루한 구현 작업이 많음, 나는 여전히 프로젝트 아키텍처, LLM에게도 어려운 창의적/난이도 높은 부분 직접 설계 등 재미있는 부분은 놓치지 않음, 앞으로 1년 뒤엔 또 다른 상황일 수 있지만 당분간은 진짜 고민하는 부분에만 집중할 수 있어서 만족임
          + 글쓴이 본인임, 나는 프로그래밍도, 그리고 에이전트도 좋아함
     * 코딩할 때 AI를 즐겨 사용하는 분야가 몇 가지 있음 (정말로 내가 쓴 내용임!):
          + CSS: 아무 웹사이트에서든 CSS 작업이 싫었는데, AI는 복잡한 CSS 트릭까지 전부 기억하고 있어서 작업 시간이 단축됨, 예를 들어 복잡한 워드프레스에서 특정 div 중앙 정렬하는 것도 몇 번 시행착오 끝에 금방 가능
          + 단위 테스트: AI가 내장 코드 데이터가 오래되지 않았을 때엔 테스트 생성도 재미있는 경험임
          + 커밋 요약: 첫 초안까지는 충분히 쓸만함
          + 아주 작은 1학년 수준의 과제도 빠르게 처리 가능
          + 흥미롭게도 내 입장에서는 AI가 CSS를 별로 잘 못 쓰는 듯해서 무용하게 느낀 적이 있음, 하지만 좋아하지 않는 작업을 대신해 준다는 점에 충분히 공감함, 내 경우엔 티켓 설명서 작성이 그 예시인데, AI가 나보다 훨씬 잘 처리해줌
          + 오해였다면 미안하지만 혹시 최근 CSS 트렌드에 익숙하지 않다면 요즘 CSS는 예전보다 훨씬 덜 복잡하고 관리가 쉬워졌으니, 몇 시간 투자해 최신 CSS를 알아보는 것도 추천함, 그럼에도 나 역시 스타일링에 AI를 많이 씀
     * ""자산""과 ""부채""에 대한 부분이 흥미로웠지만 동의하진 않음, 많은 프로그램은 소수 사용자만을 위해 시작됐다가 어느새 대형 프로젝트가 된 경우도 흔함, 과거에는 일회성으로 대충 작성한 과학용 코드가 어느 순간 본의 아니게 오랜 기간/넓은 범위로 확장되는 사례를 너무 자주 경험함, 그래서 내 코드는 훨씬 길게 쓰이고 더 넓은 범위까지 염두에 두면서 심지어 내 자신과 다른 사람에 대한 배려로 작성함, 동료가 만든 개인용 사이드 프로젝트를 매니저가 부서 프로젝트로 승격시킨 경험이 있다면 이 문제 공감할 것임
          + 그래도 ""대안이 뭘까?""란 의문이 남음, 사람들은 무엇이 널리 채택될지 예측을 잘 못함, 오히려 공들인 프로젝트가 아무 데도 안 쓰이는 쪽이 흔하고, 허술하지만 빠르게 만든 프로젝트가 성공하는 쪽에 진화 압력이 걸려 있는 현실임, 이 부분은 ""worse is better"" 고전 글을 들 수 있음 (링크)
     * LLM을 코드 작성/설계가 아니라 코드 리뷰에 쓰는 게 진정한 킬러 특성이 될 수 있다고 봄, 지금 code review 자체가 많은 부분에서 깨져 있고, 앞으로는 보안, 정의되지 않은 행동, 기능오용, 컴파일러 경보 이슈의 이중 확인 등에서 LLM 활용도가 커질 것이라 기대함, 개인적으로는 LLM을 검색엔진 스타일로 오류 진단이나 디버깅에 주로 쓰는데, 정답률이 50%쯤 되고 이는 충분히 만족스러움
          + ChatGPT는 이미 충분히 웹에서 많이 논의된 문제라면 디버깅에 상당히 훌륭함, stack overflow의 지식을 요약, 통합해주기 때문에 개별 사례를 찾아보는 시간 절약이 큼, 다만 LLM의 답변이 허구(환각)이 섞여서 다소 노이즈가 남아있고, 코드 전체를 리뷰한다면 오류 유형이나 문제가 되는 함수/호출을 잘 찾아낼 수 있지만, 반대로 오탐지도 많을 수밖에 없음, 실제로 LLM을 코드 자동 리뷰에 적절히 활용하는지 궁금함
          + ""이 코드를 리뷰해달라""는 요청을 반복해서 하다 보면 chatbot이 X를 Y로 바꿨다가, 조금 뒤에는 다시 Y를 X로 바꾸기도 하는 현상이 발생함, 코드 리뷰에는 어느 정도 효과가 있지만, 결과를 보고 어떤 건 수용, 어떤 건 거부할지 직접 판단해야 함, 충분히 분별력이 있는 사람에게는 정말로 생산성 높게 후보 변경사항을 제시해주는 역할임
          + 왜 이런 주제가 더 크게 논의되지 않는지 궁금함, 내 주변 개발자들은 기술에 대한 관심 정도가 다양함, 주로 경력이 짧을수록 더 적극적으로 사용하고, 시니어일수록 관심이 적음, 코드 리뷰/검증에 AI 쓰는 얘기는 거의 듣지 못했으며, 아마도 커밋 시점에 자동으로 해주는 기능이 필요하지 않을까 생각함
          + code review/design보다 code review 특화 LLM은 이미 Github Copilot에서 리뷰어 모드로 제공 중임, 아직 최고 수준은 아니지만 루프에 두고 쓰기엔 충분히 쓸만한 퀄리티임
          + 동의함, 우리는 sourcery.ai에서 이런 것 작업 중임
"
"https://news.hada.io/topic?id=21311","Jupyter Notebook에서 확장 가능한 시스템으로의 전환 가이드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Jupyter Notebook에서 확장 가능한 시스템으로의 전환 가이드

   PyCon US 2025 발표내용입니다.

Jupyter Notebook에서 확장 가능한 시스템으로의 전환 가이드

   Jupyter Notebook은 데이터 탐색, 시각화, 교육 등 대화형 분석에 매우 유용한 도구입니다. 하지만 프로덕션 환경에 코드를 배포하고, 재사용성과 자동화, 견고성이 중요해지는 시점에는 노트북의 한계가 드러납니다. 이 글에서는 Jupyter Notebook으로 작성된 코드를 유지보수와 재현성이 용이한 확장 가능한 시스템으로 전환하는 과정과 핵심 노하우를 소개합니다.

  노트북의 장점과 단점

     * 장점: 코드와 텍스트를 함께 보며 결과를 즉시 확인할 수 있어 탐색적 데이터 분석과 교육에 탁월합니다. [00:03:18]
     * 단점: 셀 실행 순서에 따라 변수 상태가 달라질 수 있고, 버전 관리가 어려우며, 코드의 자동화 및 재사용이 힘들어 확장성에 걸림돌이 됩니다. [00:04:24]

  언제 스크립트로 전환해야 할까?

     * 프로덕션 환경에 코드를 배포해야 할 때
     * 다른 사람이 코드를 재사용해야 할 때
     * 자동으로 코드를 실행해야 할 때
     * 코드의 견고성이 중요할 때
     * 노트북이 너무 복잡해졌을 때 [00:05:32]

  전환을 위한 핵심 단계와 도구

    1. 코드 추출 및 변환

     * NBConvert & Jupytext: 노트북의 코드를 Python 스크립트로 손쉽게 추출할 수 있습니다. 특히 Jupytext는 노트북과 스크립트 간의 동기화 기능도 제공하여 유용합니다. [00:10:44]

    2. 리팩토링 과정

     * 기능 단위로 작업 분리: 노트북의 각 단계를 식별하고, 각 단계에 맞는 함수를 만든 후 코드를 해당 함수로 옮깁니다. [00:12:52]
     * 테스트 코드 작성: 단위 테스트나 통합 테스트를 작성하여 코드의 정확성을 보장합니다. 이는 특히 복사-붙여넣기 과정에서 발생할 수 있는 오류를 방지하는 데 중요합니다. [00:13:08]
     * 요구사항 및 의존성 관리: 모듈과 해당 종속성을 명확히 하여 다른 환경에서도 코드를 쉽게 실행할 수 있도록 합니다. [00:13:15]
     * CI/CD 도입: CI/CD(지속적 통합/지속적 배포) 파이프라인을 구축하여 배포 과정을 자동화합니다. [00:13:15]

  코드 품질 향상을 위한 추가 팁

     * 일관된 코드 서식: 코드 포맷터를 사용하여 일관성을 유지합니다.
     * 문서화: 코드의 목적과 사용법을 명확히 설명하는 문서화를 생활화합니다.
     * 설정 분리: 설정 및 구성 정보를 별도의 파일로 분리하여 관리합니다. [00:21:11]

  핵심 역량 및 사고방식 전환

     * 모듈화: 코드를 재사용 가능한 모듈식 기능으로 분해하는 능력이 중요합니다.
     * 자동화: 워크플로우를 자동화하여 효율성을 높입니다.
     * 테스트 기반 리팩토링: 테스트를 통해 기능의 안정성을 유지하면서 코드를 개선합니다.

   탐색 단계에서는 Jupyter Notebook의 유연성을 적극 활용하고, 프로덕션 코드는 견고하고 재현 가능한 자동화된 스크립트로 전환하는 사고방식을 갖추는 것이 중요합니다. [00:22:16]
"
"https://news.hada.io/topic?id=21403","에이전트 기반 AI는 왜 좋은 페어 프로그래머가 아닌가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     에이전트 기반 AI는 왜 좋은 페어 프로그래머가 아닌가

     * LLM 에이전트는 인간보다 훨씬 빠르게 코드를 작성하기 때문에 페어 프로그래밍 경험이 오히려 저하될 수 있음
     * 너무 빠른 자동화로 인해 사용자가 따라가지 못하고, 작업 맥락을 놓치는 문제가 빈번하게 발생함
     * 이러한 현상은 경험 많은 개발자와의 페어링에서 느꼈던 소외감과 유사하며, 결국 품질 관리와 소통이 약화되는 결과로 이어짐
     * 해결책으로는 비동기적 코드 리뷰 위주 협업과, AI와의 페어링 속도를 줄여 품질 관리와 소통 중심의 워크플로우로 전환하는 방식을 제안
     * AI 에이전트도 인간과 유사하게 “멈추고 대화하며, 자신감보다 의심과 검증에 집중”하는 설계가 필요함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM 에이전트와 페어 프로그래밍의 문제점

     * AI 에이전트(예: Copilot Agent)는 인간의 사고 속도보다 훨씬 빠르게 코드를 작성함
     * 이로 인해 사용자는 따라가기도 전에 코드가 쏟아지며, 맥락을 놓치고 작업 몰입도가 저하되는 현상이 발생함
     * 문제 상황에서 에이전트가 도움을 요청하면 이미 사용자는 상황 파악이 안 된 채로 “뒷수습” 역할을 맡게 되고, 결과적으로 잘못된 방향으로 진행된 코드를 정리하는 부담이 커짐
     * 결국 품질 관리, 소통, 올바른 방향성 유지가 어려워짐

     * 최고의 AI 에이전트와 페어를 하는 경험은 과거 탁월한 인간 프로그래머와의 페어링에서 느꼈던 부정적 기억을 떠올리게 함
          + 페어 파트너가 과도한 속도로 소리 없이 키보드를 두드림으로써, 코드를 따라잡을 수 없게 만듦
          + 정신적 에너지를 모두 소진시킨 후 점차 작업에서 멀어지게 됨
          + 페어가 막히는 순간 도움을 요청하지만 상황 파악이 어려운 당황스러운 경험이 발생함
          + 작업 진행 과정에서 목표와 다른 방향의 구현물이 생성되고, 마감기한 내 수정해야 하는 부담이 전가됨

The path forward: 실질적 해결책

     * 1. 비동기적 협업
          + 인간과의 페어 프로그래밍에서 한 명이 주도적으로 진행할 때처럼, AI가 코드를 독립적으로 작성하고 Pull Request로 리뷰하는 형태가 더 효과적임
          + GitHub Coding Agent 등 비동기 워크플로우를 활용해, 사용자가 리뷰와 품질 관리에 집중할 수 있음
     * 2. 속도를 낮춘 “턴 기반” 페어링
          + AI의 “Agent Mode” 대신, Edit/Ask Mode와 같은 한 번에 한 단계씩 진행하는 방식을 사용
          + Ping-pong 페어링(한 쪽이 제안, 한 쪽이 승인)처럼, AI가 제안한 변경을 사용자가 직접 수락/검토하며 속도를 조절
          + 문제 해결/디버깅에만 AI를 쓰지 않고, 일관된 워크플로우로 활용하는 것이 바람직함

에이전트 페어링을 더 인간적으로 만드는 아이디어

     * 사용자가 코드 출력 속도(라인/분, 단어/분) 를 직접 조절 가능하게 설정
     * 에이전트를 임시 중지해, 사용자가 질문하거나 방향성에 반박할 수 있는 기능
     * 기존 챗봇 UI를 넘어, 작업 진행 상황과 연동된 UI 프리미티브(예: 현재 세션을 특정 GitHub 이슈에 고정, 내장 To-do 리스트 등) 제공
     * 에이전트가 더 자주 멈추고 대화하도록 설계: “왜 이걸 하는지” 확인, 조언 요청, 방향성 점검 등 인간과의 협업 분위기 조성
     * 고급 음성 채팅 지원을 도입해, 사용자가 눈은 코드에 두고 음성으로 AI와 소통할 수 있도록 함

     * 이러한 기능이 적용된다면, 현재의 빠르고 일방적인 에이전트 페어링 대신, 진정한 인간-에이전트 공동 협력 경험이 가능해질 것

결론

     * 현재 시점에서 AI 에이전트 기반 페어 프로그래밍의 한계와 가능성을 동시에 목격하고 있음
     * AI 에이전트 페어 프로그래밍은 속도만 빠른 것보다, 인간과의 협업처럼 소통·품질·검증 중심으로 설계할 때 더 큰 효과를 거둘 수 있음
     * “천천히, 대화하며, 검증하고, 상황을 공유하는” 방식이 AI 페어링의 질을 높임

    1. 비동기적 협업
       인간과의 페어 프로그래밍에서 한 명이 주도적으로 진행할 때처럼, AI가 코드를 독립적으로 작성하고 Pull Request로 리뷰하는 형태가 더 효과적임

   Codex를 며칠간 사용하고 있는데 에이전트 형태보다는 여기에 공감합니다. 여러 프로젝트 작업을 동시에 돌릴 수 있게 되면서, 정말 주니어 개발자 여럿과 함께 일하는 경험을 하고 있습니다.
   비동기적으로 AI를 사용할 수 있게 되니 여러 프로젝트, 그리고 한 프로젝트에서도 여러 작업을 동시에 시킬 수 있게 되면서 생산성이 산술적으로 3-10배 이상 나오는게 정말로 체감이 됩니다.

        Hacker News 의견

     * 내가 AI를 이런 방식으로 사용하다가 금방 그만둔 이유를 정확히 설명한 글이라는 느낌. 내가 뭔가를 만들고 싶을 때 이미 대충 <i>방법</i>을 정하고 있지만, AI가 실제로 하는 방식이 내가 원하는 것과 자주 다르기 때문. 그런데 AI가 2,000줄의 코드를 한 번에 생성하면 오히려 일이 더 많아지는 현상. ""우선 이 모든 주석을 지워줘, 간단한 코드에 불필요한 설명이 두 배야. X를 이렇게 추상화하지 말고, 나는 이걸 원해..."" 처럼 지시해야 하고, 피드백을 주면 또 갑자기 2,000줄이 700줄로 확 달라져서 따라가기가 너무 힘든 문제. 코드베이스가 내가 잘 모르는, 방식도 제각각인 스크립트 투성이가 되는 것도 싫음. 내 스타일과 생각이 비슷한 AI가 필요하지만, 그게 너무 어려운 점. AI와 함께 일하는 건 경험이 없는 누군가와 첫날 함께 일하는 것과 비슷한 느낌.
       개인적으로는 도구의 자심감 문제라기보다는 디자인 과정을 더 드러나게 했다는 생각. 이상적으로는 ""이런 접근을 생각 중이고, 이런 함수나 클래스, 상태를 이런 방식으로 관리할 예정""이라는 설계서를 먼저 보고, 괜찮으면 그 다음에 구현으로 넘어가는 절차가 필요.
          + 인간 엔지니어와 마찬가지로, 먼저 플래닝 세션이 정말 중요하다는 점을 강조. 코드 작성 전에 먼저 토론하고 흥정하듯 세부사항 정리. 나는 일부러 첫 질문을 최대한 두루뭉술하게 던져서 오히려 예상 못 한 추천이 나오나 살펴보고, 점점 구체적으로 들어가는 방식으로 진행. 충분히 만족하면 LLM이 initialprompt.txt와 TODO.md라는 두 개 문서를 만들도록 요청. initialprompt.txt에는 프로젝트 요약과 TODO.md를 읽으라는 지시, 그리고 각 단계가 완료될 때 체크하라는 명령이 포함됨. 이런 방식 덕분에 LLM이 전체적인 목표와 세부 작업을 모두 파악하고, 나중에 컨텍스트 제한 때문에 대화가 끊겨 다시 시작할 때 빠르게 업무를 리마인드해줄 수 있음.
          + 내 경험을 똑같이 요약해줬다는 느낌. AI가 작성한 코드에 대해 아예 결과물만 중요하고 해당 분야에 대해 배경지식이 거의 없을 때만 성공적으로 끝냈던 경험. 내가 어떤 결과가 ‘좋은 것’인지에 대해 강한 의견이 있을 때는 결국 좌절하고 프로젝트를 포기하기 일쑤. roo code의 architect 기능으로 먼저 접근 방식을 정리한 뒤, code mode로 실제 코드를 구현할 때는 기쁨과 좌절이 반반이었음. 중요한 교훈은 항상 새 작업을 시작할 것, 장기 대화 이어가지 말 것. 나는 원래 문제를 잘게 나누고 결과 확인을 하는 스타일인데, LLM에는 문제 공간 전체를 한 번에 던져서 실패한 경향. 나만의 방법을 찾기 위해 여러 번 시도해 봤고, 오늘도 30분 만에 앱 기능을 추가함. 직접 구현하면 정말 며칠 걸릴 일이었음. 그리고 실제로 30분만 일지에 기록한 이유는 내가
            원하는 것을 확실히 알고 있었고, 과정에는 관심이 없었기 때문. 이런 경험 덕분에 언젠가 다른 사람이 써야 할 코드를 AI에게 맡기는 것은 모든 이유 때문에 불가능하다는 결론.
          + 결국 너무 지치고, 결과도 불만족스러운 경험뿐. 이런 고민을 가진 사람에게 한 말임. 나 역시 에이전트 코딩에 만족한 경험은 코드 품질에 신경 안 쓰는 단기 스크립트나 진짜 어디에서도 영향 없는 잎사귀 함수일 때뿐.
          + Anthropic의 Claude Code 활용 가이드에서 권장하는 워크플로가 추천할 만함. 요점은 “일단 먼저 코드를 읽게 한 뒤, 변화 계획을 세우도록 하고, 마지막에 실행하게 하라”는 것. AI가 코드를 한 줄도 작성하기 전에 계획서를 보고 수정할 수 있음. 에이전트를 쓸 때 내가 원하는 방식과 다르게 움직인다면, 예를 들어 설계도 없이 바로 코딩을 한다면, 그냥 ""다르게 해줘""라고 요구하면 됨.
          + 2,000줄짜리 코드를 한 번에 생성한다는 얘기, 혹시 SNES에 Skyrim 전체를 시키는 프롬프트 입력하는 건 아닐지. 점심 먹고 와서 실행해보니 PS1 스타일로 근접 공격만 있는 Fallout을 만들어줬다고 화내는 상황 연상.
     * HN의 첫 페이지에 글이 올라가면 항상 댓글을 보고 내가 얼마나 멍청한지, 사람들이 내 체면을 끌어내리는 공격성 발언을 할까 두려워짐. 그런데 어떤 때는 내가 제목을 정말 잘 잡으면, 아무도 내 글은 안 보고 각자 자기 얘기만 하다가, 나는 그런 비난을 피해감.
          + 유쾌하면서도 현실적인 이야기라고 생각. 다른 글에서도 비슷한 패턴을 자주 보게 됨. 어쨌든 이런 토론 자체가 좋아서 재미를 느낌.
          + 글이 좋았음. 일종의 “AI와 페어 프로그래밍을 즐기는 방법” 같은 느낌. 유익했기 때문에 감사함.
     * LLM 에이전트를 처음 썼을 때, 나는 양방향 소통, 진짜 협력적 페어 프로그래밍을 기대함. 하지만 실제로는 전적으로 자기만의 방식대로 모든 걸 해결하려는 파트너를 만남. 내가 조금 고치려고 했더니 AI가 쓴 코드 컨텍스트가 깨져서 오히려 더 불편한 경험. 내가 원하는 건 내가 조금, AI가 조금, 서로 교대로 작업하는 진짜 협동 작업.
          + 최근에 다시 시도해봤는지 질문. 내 경험은 다르다는 얘기. 나는 AI가 생성한 코드를 수정한 뒤 파일을 다시 읽으라고 시킴. 그러면 보통 “파일에 변경사항이 있네요”식으로 반응. AI가 코드 변경하면 내가 테스트 돌려보고 피드백 주면 반복적으로 개선. Zed와 Claude Sonnet에서 이런 방식이 잘 통함.
          + 내가 대체로 쓰는 방식은 일단 AI의 제안을 받고, 리팩터링하거나 필요하면 다시 프롬프트로 지시. 이런 접근이 수락률(accept rate)을 인위적으로 높이는 효과가 있는데, 사실 이 통계로 AI 회사들이 ""AI가 아주 좋은 코드를 작성한다""는 주장의 근거로 삼을 수 있음. 실제로는 “에휴, 그냥 내가 직접 고쳐야지” 하는 마음으로 넘어간 순간도 많음.
          + 나는 주로 “먼저 논의만 하자. 코드 수정은 하지 마라”라고 붙이면 원하는 식으로 대화가 가능. 충분히 왔다 갔다 얘기한 후 마지막에 “적용해”라고 지시.
          + 원하는 협업 형태를 원한다면 구체적으로 LLM에게 요청하라고 조언. 모든 대화마다 꺼내 쓸 수 있는 프롬프트 문서 몇 개 준비해두면 좋음.
          + 최근에는 맥락 유지가 크게 어렵지 않아 코드 수정에도 문제가 없음. 나는 Ask 모드(명령이 아니라 질의/응답 위주)로만 쓰고, Claude Code에서는 Opus, Cursor에서는 o3 max를 활용. 에이전트 모드는 일부러 피하는데, 원글처럼 시간이 지날수록 내가 얻는 이득이 적기 때문. 탭 완성은 드물게 쓰고, 제안 코드의 80~90%는 내가 수정해서 직접 타이핑. 덕분에 170wpm 속도로 계속 칠 수 있음. Opus와 o3 max의 출력 속도가 제한적이라 읽는 것도 버겁지 않고, 처음엔 너무 빨라서 힘들었지만 금방 적응. 내 개인 평은, 만약 GitHub Copilot이 LLM 체험의 전부라면 그건 모텔 수준 경험에 불과하다는 것.
     * 페어 프로그래밍도 모든 상황에 적합한 건 아님. 오히려 많은 경우 적합하지 않을 수 있음. 다른 데서 언급했지만, LLM의 자동 완성 제안 때문에 집중해서 코딩하는 흐름이 끊겨서, 중간마다 멈춰서 읽고 검토하고 수락/거절해야 해서 프로그래밍 플로우가 완전히 깨지는 문제. 내 워크플로우에 AI 자동완성 끼워 넣으려다 정말 힘들었음.
          + 나도 같은 생각. 해결책은 AI 없는 전용 IDE와 Cursor/VS Code를 둘 다 쓰면서 서로 번갈아 사용하는 것. 진정한 몰입/딥워크는 챗봇과 대화하면서는 불가능.
          + 최근에 새 노트북을 사고 IDE를 새로 설치했는데, 몇 시간 코딩하는 동안 뭔가 ‘이상하다’고 느낌. 알고 보니 GitHub Copilot 로그인을 깜빡해서 AI 없이 일하고 있었던 것. 코드 자동완성 기다릴 필요 없이 훨씬 더 적극적으로 코드를 작성하고 있다는 느낌. Cursor는 특히 사용 흐름을 계속 방해해서 ‘다음 커서 위치까지 예측’ 이런 기능도 정말 불필요함. 앞으로는 Copilot은 꺼두고, boilerplate나 반복 작업에는 aider 같은 에이전트 스타일 도구만 쓸 계획.
          + AI 자동완성이나 코드 제안 기능은 특히 타입 강한 언어를 쓰면 최악. 대부분 80%는 맞지만 IDE 자동완성은 거의 100% 정확. AI 에이전트 방식은 더 좋은 게 1) 계속 생각 흐름을 방해하지 않고, 2) 직접 컴파일, 테스트를 돌려서 틀린 걸 수정한 뒤 제대로 된 코드를 돌려주기 때문.
          + 나는 오히려 자동완성을 너무 좋아함. Go 언어 써야 해서 boilerplate가 워낙 많은데, 라이브러리 추가 같은 걸로는 해결 안 되는 문제라서 그냥 직접 타이핑이 더 빠를 때 많음. 귀찮은 코드 작성하기엔 AI 보다는 손이 빠르기에, 자동완성은 진짜 도움이 됨. 한 줄 제안은 순식간에 읽어내고, 긴 제안도 내가 쓰려던 내용과 비슷하면 그냥 넘어갈 수 있음. 반복되다 보면 AI가 뭘 예측할지 감이 잡힘. 엄청난 생산성 향상은 아니지만, 로그 메시지나 for 루프 등 귀찮은 건 확실히 빨라짐. 내가 읽는 속도가 직접 타이핑보다 훨씬 빠른 경우에만 도움이라는 생각.
          + 페어 프로그래밍이 항상 맞는 건 아니지만, 대다수 상황에서는 유용하게 쓸 수 있다는 견해. 잘 안 맞는 때는 보통 한 명 또는 두 명 모두 이 과정에 적극적으로 임하지 않거나, 한쪽이 “이런 건 안 된다”며 거부하거나, 페어 프로그래밍 원칙을 너무 엄격하게 지키려 할 때임.
     * 입장이 조금 복잡함. 최소 한 달간 회사에서 여러 LLM 툴을 모두 적극적으로 써보면서 최대한 효과적으로 활용하는 법을 배우는 중임. 코드 라인 수 기준으로는 확실히 생산성이 높아짐. 하지만 전체적으로 더 생산적이라고는 못 하겠음. 완료된 각 작업마다 설명 안 되는 이상한 동작을 하거나, 때로는 관련 없는 부분까지 손대서 오히려 되돌려야 할 때가 많음. AI가 자동 생성한 테스트는 처음엔 그럴듯하지만, 커버리지 등 다른 지표로 보면 부족한 점이 명확. 원하는 결과에 도달하려면 오히려 여러 단계를 거꾸로 되돌아가야 하는 느낌. 이득이나 학습 그런 것도 아닌 완전히 후퇴하는 듯한 경험. 예전에 한 번은 5만 줄의 불필요한 import 코드가 원래 수정 범위가 아닌 모듈에 몰래 추가된 적도 있었음. 또 어떤 땐 규칙을 명확히 설정해줬는데, 전체 객체지향
       구조를 망가뜨리고 if/else만 잔뜩 써서 구현하는 사건도. 문제는 상황 따라 결과가 너무 달라서, 심지어 같은 작업이라도 어떤 땐 완벽하지만 어떤 땐 전체를 박살냄. 작업을 어떻게 시켜야 할지, 어떤 식으로 안내해야 할지 여러 방법을 써봤지만, 비슷한 작업이라도 행동이 너무 달라서 항상 변경 사항을 검수해야 하는 고통. 코드가 거의 맞더라도 특정 부분만 고쳐달라 하면 오히려 전체 작업이 산으로 감. 내 경험상 소규모 툴 작성 수준에서는 효과적이지만, 중~대형 코드베이스에선 일관된 결과를 기대하기 어려움.
     * LLM 에이전트는 말이 너무 많고 항상 자기 방식이 맞다고 생각하는 느낌. 간결하지 못하고, 한 줄이면 끝날 일도 엄청 길게 설명함. 사소한 변경에도 주석을 장문으로 달아버림. 나를 가르치려 들고, 지나치게 과하게 나오는 스타일.
          + 사람들이 싫어하는 일부 행동(""너무 긴 출력, 과도한 주석 등"")은 LLM이 다른 면에서 효율을 높이려고 설계된 부작용일 수 있음. 긴 출력은 게으르지 않은 코드, 성능 벤치마크 점수가 높은 경향과 연결. 주석 남발도 로컬 컨텍스트를 강화해 다음 코드 품질 향상, 에러 감소와 관련.
          + 어제 sonnet 4를 써봤는데, 단 한 개의 설정값을 바꾸려는 작업에 15분을 써서 계속 테스트하고 리팩터만 반복. 결국 쓸데없이 40개의 파일을 변경. 없는 디버거를 자꾸 실행하려 하고, 인증 필요한 웹페이지를 계속 열려고도 함. 정말 완벽과는 거리가 멀다는 걸 느낌.
     * 내 경험상 문제는 빠르기보다는 오히려 너무 느리다는 것. 속도가 미묘하게 애매해서 더 나쁨. 더 빨랐다면 코드를 실시간으로 따라가며 작업할 수 있었을 것. 더 느리면 그 시간에 다른 일 하다가 오면 되는데, 현실은 50초~수분 단위로 작업이 끝나서 다른 일에 집중 못 함. 오히려 더 작은 단위로 빠르게 반복하는 게 좋다고 생각. 궁극적으로는 인간 리뷰 수준의 자율성, 예를 들면 머지 리퀘스트(PR) 검토하듯이 독립적인 작업이 더 나음. 지금의 루프(작업 주고, 1~3분 대기, 결과 보고, 피드백 주고 반복)는 개인적으로 최악의 케이스.
          + 이 얘기가 오트밀의 “느린 인터넷 vs 아예 없는 인터넷” 만화 생각나게 함.
          + 집중 흩어지면 데스크에 30L 어항을 두라는 조언. 멍때리기엔 최고라는 재치 있는 팁.
     * 개발자로서 나는 AI를 거의 안 쓰고, 가끔 비프로젝트 질문용으로 채팅 챗봇을 쓸 뿐임. 혹시 클라이언트 프로젝트에도 AI를 쓰는지, 아니면 사적인(pet) 프로젝트에만 쓰는지 궁금. 클라이언트 용도라면 코드가 AI에 전달된다는 사실을 계약서에 포함시키고 있는지 묻고 싶음. 대부분의 클라이언트는 NDA 형태로 외부공개 금지 계약을 하는데, 어떤 클라이언트는 AI 사용도 금지 조항을 뒀던 적 있음. AI 코딩 도구를 예외로 인정하는 클라이언트를 만난 적 있는지 궁금.
          + 나는 거의 사내에서만 사용, 그것도 회사의 명확한 AI 사용 지침이 있어서임. 실제로 체감상 별로 시간을 아껴주지 않아서 내 개인 작업엔 돈 주고 쓸 일 없음. 개인 프로젝트에서는 결과보다는 직접 만드는 재미가 더 중요해서, 프롬프트 작업보단 직접 만드는 게 즐거움.
          + 클라이언트 쪽에서 AI 사용을 적극적으로 주문하는 경우도 있음. 더 좋은 품질, 더 빠른 개발을 기대(결국 비용 절감 목적)이지만, 현실은 그 기대와 다를 때가 많음(그래도 그건 별개의 얘기).
          + OpenAI/Anthropic에게는 웹 검색창에 그냥 붙여 넣을 수 있을 정도로 공개 가능한 코드만 공유.
          + 나는 공유하지 않음. 내부 프로젝트 포함이며 외부에 코드 공유는 비용을 받고서만 가능. 개인 정보 처리도 하다 보니 미국 기업에 코드가 노출된다면 법적 리스크가 너무 큼.
     * 드디어 누군가가 딱 집어서 얘기한 부분. AI가 설계에 대해 과도한 자신감, 상세 구현은 협의 없이 임의로 진행하는 스타일. 모킹 API도 구조를 지키지 않게 만드는 경우가 많아 재작업이 필수. LLM의 행동이 좀 더 협업, 디테일이 부족하면 즉시 물어보는 스타일이었으면 함. 최초 프롬프트에 모든 정보를 줄 수 없고, 추가 프롬프트는 처음 설계의 맥락과 사고 흐름을 깨트림. 내가 잘못 쓰고 있는 건지, 더 나은 방법을 알고 싶음. LLM이 피드백을 점진적으로 받고 반영하는 방향으로 개선되었으면 좋겠음. 문맥 추가/업데이트 자체가 어려운 문제인 건지도 궁금하지만, 계속 학습하고 싶다는 의지.
          + 요즘 대부분 테크 스택에서 “설계/계획” 세션을 지원해서, 먼저 이걸 써보면 개선 효과가 있을 것. 내가 잘 활용하는 워크플로는, 큰 모델이든 작은 모델이든 “@file, @docs, @examples 기준으로 @path에 _ 작업을 @module_requirements.md 참조해 진행하고 싶음 – 실제 구현 전에 필요한 내용을 모두 논의하자”는 대화부터 시작. 앞뒤로 왔다 갔다 논의해서 모두 합의되면 .md 파일 등으로 저장해 두거나, 바로 “이제 진행해줘”로 넘길 수 있음. .rules나 .md 파일, IDE 스니펫 등으로 워크플로를 등록해두면 새 작업마다 반복적으로 활용 가능. 최신 LLM은 훨씬 많은 문맥을 필요로 하니, 코드베이스별로(프로젝트마다) 다른 흐름을 시도해봐야 결과도 다르다는 걸 명심해야.
          + 정보가 많아질수록 AI가 헷갈려하는 느낌도 있음. 아마 극복할 방안이 있을 듯. 아주 작은 정보 조각만 뽑아내는 데는 능하지만, 업계 전체가 챗봇 모델에만 집중하는 분위기는 아쉬움. 만약 우리가 키보드나 마우스, GUI, 터치 스크린을 계속 만들지 않았다면 어땠을지 상상해봄.
     * AI를 도우미로 쓰는 협업형 스타일이야말로 AI의 올바른 활용 방식이고, “AI가 코드 직접 작성”에 집중하는 유행은 오히려 소프트웨어 업계가 잘못된 방향으로 흘러가는 예시라고 봄. 나는 AI에게 코드 작성을 절대 맡기지 않음. 내가 짠 코드를 비평하게 만들거나, 대규모 코드 구조 설계 전략 수립에만 활용. 마치 전략 컨설턴트로 쓰는 건데, LLM의 맥락을 잘 구성하면 아주 뛰어난 가이드를 얻을 수 있음. 주체는 항상 내가 되어 이해하고 실천, AI에게는 어디까지나 조언자 이상의 책임을 부여하지 않는 원칙. AI는 “바보 천재(idiot savant)”로 생각하고 신중하게 대해야 함.
"
"https://news.hada.io/topic?id=21318","Apple Notes에 Markdown 내보내기 기능 추가 예정, 이에 대한 마크다운 개발자의 의견","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Apple Notes에 Markdown 내보내기 기능 추가 예정, 이에 대한 마크다운 개발자의 의견

     * 애플이 WWDC에서 Apple Notes에 Markdown 내보내기 기능을 공개하고 도입 예정이라고 알려짐
     * Markdown 포맷을 만든 저자(존 그루버)가 이에 대한 생각을 정리
     * 기존에는 일부 서드파티 앱에서 지원했던 기능으로, 기술 사용자 커뮤니티에서 기대가 큼
     * Apple Notes가 아예 Markdown 에디터로 변하는 것에는 반대 의견이 존재하며, Notes는 WYSIWYG 방식의 간단한 편집 경험을 유지해야 한다는 입장
     * 하지만 Markdown 내보내기 기능은 Notes의 부족한 내보내기 옵션을 개선하는 중요한 변화임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

9to5Mac 보도 및 첫 소감

     * Marcus Mendes가 9to5Mac 기사에서 Apple Notes에 Markdown 내보내기 기능이 WWDC에서 추가된다는 소식을 전했음
     * 그동안 여러 서드파티 앱이 이미 지원하던 기능이지만, 특정 사용자 층에는 매우 큰 뉴스임

Markdown 지원에 대한 오해와 구분

     * 소식 초반에는 Notes가 Markdown 지원을 도입한다는 형태로 잘못 전달되었음
     * Bear, Obsidian처럼 직접 Markdown 문법으로 작성하거나 문법을 노트에서 볼 수 있는 방식과, 기존 Notes처럼 WYSIWYG 방식은 근본적으로 다름
     * ""Markdown 노트 앱""은 독립된 앱 카테고리임

Markdown에 대한 개인적 시각과 역할

     * Markdown 개발자인 저자(존 그루버)는 Markdown 에디터로서의 Notes에는 부정적 입장임
     * 본인은 Markdown을 웹 게시물 작성에만 집중해 사용해 왔음
     * Markdown은 HTML로 변환하는 간결한 텍스트 표기법이라는 본질이 여전히 유효함
     * Markdown의 또다른 강점은 평문 파일 또는 데이터베이스 저장용으로 활용하는 환경임
     * 하지만 Apple Notes는 이러한 맥락과는 다른, 간단하고 안정적인 노트 앱임

WYSIWYG 에디터로서의 Apple Notes

     * Apple Notes는 깔끔한 WYSIWYG 리치 텍스트 에디터 경험을 제공함
     * Mac, iPhone 양쪽에서 사용성이 뛰어나며, 사전 정의된 스타일만 선택할 수 있는 포맷 옵션이 돋보임
     * Nerd스럽지 않은 경험 유지가 중요하며, 프리뷰나 모드 전환이 필요 없는 직관성이 장점임
     * 단, 해시태그(#) 대신 Finder처럼 공간 포함 가능한 토크나이즈된 태그 시스템의 부재는 아쉬움이 지적됨

Markdown 내보내기 기능의 가치와 기대

     * Markdown으로 내보내는 기능은 매우 유용할 것으로 평가됨
     * 현재 Notes의 내보내기 기능(PDF, Pages) 한계를 보완할 기대감이 큼
     * 텍스트는 물론, 이미지 처리 방식도 큰 관심사임 (루머가 사실일 경우 추가로 주목 필요)

결론

     * Apple Notes 내보내기 기능의 Markdown 지원은 기술 커뮤니티에 긍정적 영향을 미칠 가능성 높음
     * Notes 자체가 Markdown 에디터로 전환되는 것에는 신중하거나 반대 입장을 강조함
     * 사용성, 접근성, 직관성이 Notes의 핵심 가치임을 환기함

   Windows Notepad(메모장)에 텍스트 서식 지정 및 Markdown 지원 추가

   OS에 다 기본으로 내장되는 분위기군요.

        Hacker News 의견

     * Gruber가 자신은 블로그 외에는 Markdown을 거의 쓰지 않는다고 말하면서, Markdown이 에디터 등의 포맷으로는 단점이 있다고 했지만, 나는 Markdown의 두 가지 큰 장점을 강조하고 싶음
       (1) 일반 텍스트라서 벤더 락인 방지에 매우 좋은 점
       (2) 독점 포맷 대신 Markdown이 널리 쓰이며 내 데이터 이동성이 보장되는 효과
       오픈소스 앱조차 독점 포맷이면 비개발자들이 데이터 추출이 어렵다는 문제
       처음부터 Markdown이나 Markdown 익스포트 지원만 해도 데이터를 자유롭게 가져갈 수 있다는 안심감 가짐
          + 나 역시 비슷한 생각이며, (Microsoft에 인수되기 전) GitHub와 GitLab에 Markdown이 널리 쓰이면서 회사 위키, 코드 내 API 문서 등 대부분을 Markdown으로 통일해야겠다고 결심하게 된 경험
            Markdown이 대부분의 소프트웨어 문서에 충분히 좋은 포맷이고, 개발자들이 이미 익숙하니 추가 마크업 언어는 불필요한 진입장벽
            Markdown 초보자에게 잘못된 포맷도 괜찮으니 일단 접근 가능한 곳에 기록만 남기라고 권유
            내가 나중에 수정해주면서 사람들이 부족한 부분을 자연스럽게 배워 갈 수 있기 때문
            더 복잡하고 강력한 문서화 시스템 개발에 참여한 적 있지만, 지금은 Markdown이 최고의 선택
            복잡한 포맷 규칙 배우는데 시간 쓰지 말고 더 중요한 역량에 집중하면 좋겠다는 입장
          + Markdown이 마치 WordPerfect처럼 개발자들에게 텍스트 포맷팅의 자유를 주며, 변호사 등 일부 집단에 필수 도구
            하지만 대다수(80~95%)는 이를 잘 활용하지 못한다는 현실
            Markdown의 제한된 규칙은 오히려 강점이고, 웹에서는 훌륭하지만 WYSIWYG 기반 에디터들은 종이 인쇄물 제작에 뿌리를 둔 방식에서 유래했다는 점도 언급
          + Markdown이 다른 대형 포맷이 등장하기 전부터 존재했고 앞으로도 오래 남아 있을 거라 확신
            완벽하진 않지만 내가 사용하던 대부분의 기술·소프트웨어와 달리 갑자기 사라질 걱정 없는 포맷이라서 신뢰감 느끼는 중
          + 플레인텍스트 IDE에서 문서 작성할 때 Markdown이 최고의 솔루션
            이 점이 Markdown 대중화의 진정한 이유라고 생각
          + 기본 Markdown이 너무나 심플해서 좋고, 가끔 HTML이 필요할 때만 추가해서 사용
            Joplin 같은 프로그램에선 Markdown이 자연스럽게 잘 동작
            반대로 OneNote, EverNote 등은 포맷팅 문제 때문에 오히려 불편함을 느낀 경험
     * Markdown은 웹 편집을 위해 개발된 것으로 물리적 키보드가 가상 키보드보다 많던 시절에 적합
       노트 앱(특히 iOS/iPadOS)에서는 사용자 입력 환경 때문인지 큰 이득은 못 느끼겠음
       Markdown 규칙 중 일부는 Notes에서 어색함
       예: 줄 끝 두 칸 스페이스에 리턴(수동 개행용 규칙)은 Notes 이용자 입장에선 불필요
       Apple이 CommonMark를 따를 리도 낮고, 각각 별도 문법 구현시마다 사용자는 지원 범위와 퀄리티를 스스로 익혀야 하는 번거로움
       대표적으로 Obsidian에서 ‘# Thoughts on C#’ 작성시 줄 이동하면 ‘Thoughts on C’ 처럼 보이는 문제
       즉, Markdown 지원에도 여전히 익숙함이 요구된다는 점
          + 나는 iOS에서 Notion으로 Markdown을 자주 사용
            헤딩, 리스트 등 포맷팅을 빠르게 입력하기 위한 단축키 같은 역할로 활용 중
          + iOS 기기가 아직도 연속된 스페이스 입력 시 자동으로 “. ”(마침표+스페이스)로 변환하는지 궁금
            iPad에서 md 작성할 때 꽤 번거로움
     * 몇 년 전에 Markdown에 관해 쓴 글이 있는데, 여전히 웹에서 Markdown의 포맷과 경험 간 긴장에 대해 동일한 생각
       Apple Notes가 Markdown을 소스 포맷이 아닌 문법 차원에서 도입한 건 실용적인 접근
       Markdown 친숙함은 살리면서도 포맷에 집착하지 않아서 더 많은 사용자가 이점
       실제로 대부분은 *강조*나 code 입력 정도만 원할 뿐, 버전 컨트롤이나 원본 마크다운 보존은 필요 없어 함
       Markdown이 점점 UI와 동작의 원천언어가 되고 있다는 논지
       Apple Notes의 변화도 그런 흐름과 맞닿음
       Markdown이 ‘문서 포맷’이냐 ‘저작 경험’이냐에 대해 타인 의견이 궁금
          + SwiftUI의 AttributedString은 Markdown 문법이 포함된 문자열 리터럴에서 바로 생성 가능
     * 나는 Notes가 Markdown 에디터로 변화하길 바라진 않음
       오히려 주요 문법을 이해해서 자동 변환만 해주면 충분
       예를 들어 “# My Note”라고 쓰면 제목 서식으로 바꿔주거나, “## Heading”은 헤딩 서식으로 인식하는 식
       사실 대부분 앱이 리스트 입력(-, *) 등을 자동 변환하고 있어서, 조금 더 다양한 문법만 처리해주면 충분하다는 생각
          + ""난 Markdown 에디터를 원치 않아, 단지 몇 가지 문법만 지원하라는 의미""라고 했지만,
            실상 요구하는 모든 기능이 Markdown에서 비롯된 것
            대부분 앱이 이런 동작을 하는 이유가 Markdown을 일부 지원하고 있기 때문
     * Apple Notes를 매일 사용하고, 노트앱을 개발 중
       지금까지 Apple Notes가 사용하는 포맷이 독점적이라서 탈출 경로를 고민했지만 실패
       이제 Markdown 지원이 나오면 기다리기만 하면 된다는 기대감
          + 나도 같은 고민을 했지만, 이미 Apple Notes에서 Markdown으로 내보내는 다양한 툴 있음
            Obsidian에서도 공식적으로 권장하는 도구 소개: https://help.obsidian.md/import/apple-notes
            Apple Notes도 점점 쓸 만해져서 내앱을 포기할 뻔
            다만 코드 및 이미지 포맷팅 부족으로 아직은 불편
            특히 이미지를 끌어다 놓으면 기본 크기로 페이지를 덮는 등, 대부분의 노트 앱이나 블로그처럼 기본값만 잘 맞춰줘도 모두가 좋아함
            나 역시 직접 앱 개발하면서 이미지 처리에 시간과 버그가 많았음
          + 폴더별 노트 내보내기:
            https://www.icloud.com/shortcuts/3aed9f1608ce4efeb31a276ad02f1852
            모든 노트 내보내기:
            https://www.icloud.com/shortcuts/1b305195692e42c19d258989475763ea
            노트 HTML로 내보내기:
            https://www.icloud.com/shortcuts/1a61fe549b7c41d7b2e3511ee12d93fa
          + Markdown으로 내보낼 수 없는 게 그렇게 괴로웠다면 굳이 Notes를 계속 쓰는 이유가 궁금
            나 같은 경우엔 1년에 한 번정도 숫자, 임시메모만 입력하는 정도
          + lms로 스크린샷을 포매팅된 텍스트로 변환하는 것이 완벽하게 동작했던 경험 있음
     * 이번 소식이 제일 기대되는 이유는 Apple Notes에서 지원하는 기존 익스포트 포맷들이 너무 별로라는 점
       PDF는 편집 불가, Pages는 독점 포맷이라 사실상 변환 과정에서 서식이 깨지고 불편함
     * Markdown이 특정 목적에 유용한 도구라는 점은 인정하지만, 일반적인 노트 작성엔 맞지 않다는 생각
       개인적으로 Apple Notes가 노트를 웹사이트에 파이프라인 형태로 바로 배포할 수 있는 블로그 시스템으로 발전하길 바람
       아직 그 방식을 못 찾고 있음
          + ""Markdown은 특정 목적에 좋고, 노트엔 별로""라는 의견에 대해
            난 Obsidian처럼 Markdown 기반 노트 에디터를 즐기는 입장인데, 반드시 단일 목적만을 위한 포맷도 아니고 메모에 정말 잘 어울린다고 생각
          + https://alto.so/에서 Apple Notes를 블로그로 배포하는 솔루션을 이미 제공
          + 나는 INI 포맷에 느슨한 스키마로 노트 작성
            데이터가 쌓이면 점점 구조화 및 툴을 만듦
            이 방식이 ERP 같은 포멀 방식과 Markdown/org-mode 같은 자유로운 방식 사이의 베스트 밸런스
            iPhone에서 활용하려면 불편함이 큼
            모든 것이 Apple의 승인을 거쳐야 하고, 파일시스템 접근도 힘들어서,
            Markdown이 빠르고 에너지 효율적인 백그라운드 싱크를 지원하는 유일한 텍스트 에디터에 추가된 것은 매우 의미 있는 뉴스
            예전에 iPhone에서 서버사이드 자동화를 시도했는데, 노트 포맷이 SGML류여서 삽질의 연속
            스마트폰을 아예 포기하고 나서 훨씬 행복감
          + 나 역시 Markdown 에디터를 좋아하지만, Apple이 일반 사용자를 위해 내부 구조를 노출하는 스타일이 아니니 Apple Notes에는 안 맞는다고 생각
          + 나도 예전엔 Notes에서 바로 웹사이트로 그대로 배포하는 시스템을 꿈꿨음
            온갖 노력 끝에 내 인디 제품 https://quotion.co 완성
     * Markdown은 노트 스토리지 포맷으로 최상
       들여쓰기나 리스트 포맷 등 정밀 편집도 쉽고, 리스트 유형 전환(번호<->불릿)도 자주 쓰이는 실전 활용 케이스에 용이하다는 장점
     * Obsidian 사용자이지만 Apple Notes에도 자료가 많아 두 시스템 일원화 시도는 늘 어렵게 느껴짐
       이 업데이트가 내 입장에선 매우 긍정적
       Apple의 기능 추가를 칭찬
     * Mr. Gruber가 Markdown 공동 개발자였다는 점은 인정하지만, 이후 발전에는 큰 기여를 하지 않았던 점을 기억
       고 Aaron Schwartz 역시 Markdown 공동 창시자
       Gruber의 의견에만 과도하게 집중할 필요 없다고 생각
       균형잡힌 시각이 중요
"
"https://news.hada.io/topic?id=21352","Claude로 실제 코드를 배포하며 얻은 실전 노트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Claude로 실제 코드를 배포하며 얻은 실전 노트

     * AI 도구인 Claude를 실제 서비스에 적용하며, 개발 생산성 10배 향상 효과의 현실적 달성 방법과 적용 노하우를 정리함
     * ‘vibe-coding’은 단순 유행이 아닌 실질적 방법론으로, 올바른 개발 습관과 인프라를 갖추면 AI의 강점을 극대화하고 약점을 보완할 수 있음
     * AI의 역할을 ‘초안 작성자’, ‘페어프로그래머’, ‘코드 검토자’ 세 가지 모드로 명확히 구분하며, 각 단계에 맞는 문서화와 가드레일이 필수임
     * 핵심은 프로젝트마다 ‘CLAUDE.md’ 파일을 활용해 컨벤션, 아키텍처, 패턴, 금지사항 등을 명확히 문서화하고, 코드 내 ‘anchor comment’로 AI를 효과적으로 가이드하는 것
     * 테스트 코드는 반드시 사람이 작성해야 하며, AI가 테스트·마이그레이션·보안·API 계약·시크릿 등 핵심 영역을 수정하지 못하도록 경계를 엄격히 설정해야 함
     * 올바른 경계와 습관 아래서 AI 코딩을 도입한 팀은 배포 빈도·안정성·개발 속도 모두 대폭 개선할 수 있으며, 실제 운영 노하우와 패턴 공유가 AI 개발 문화의 핵심이 되고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Vibe Coding Isn’t Just a Vibe

     * 이 글은 AI를 활용한 새로운 소프트웨어 개발 방식의 현장 가이드로, 단순한 사용법이 아니라 실제로 효과적인 AI 개발의 '이유'까지 설명함
     * 신화처럼 여겨진 10배 생산성 향상도, AI의 강점은 최대화하고 약점은 보완하는 실천적 습관을 통해서만 가능함을 실제 사례로 보여줌
     * 실제 서비스 중인 Julep 코드베이스에서, CLAUDE.md 템플릿, 커밋 전략, 운영상 재난을 방지하는 가드레일 등 실전 인프라와 운영 노하우를 공개함
     * 특히 테스트 코드는 반드시 직접 작성해야 하며, AI에게 과도하게 의존할 경우 심각한 장애와 디버깅 악몽을 초래할 수 있음
     * AI 개발에는 세 가지 모드(초안 작성, 페어프로그래밍, 검토자) 가 존재하며, 상황에 따라 AI에 주도권을 주거나 인간이 직접 조정해야 하는 리듬과 원칙이 다름
     * 핵심 메시지: 좋은 개발 습관과 경계가 있을 때만 AI가 역량을 증폭시키며, 실제 연구 결과도 ""철저한 개발 습관을 가진 팀이 배포 속도, 품질 모두에서 압도적으로 앞선다""는 사실을 보여줌

왜 이 글을 쓰게 되었나: 밈(Meme)에서 실전 방법론(Method)으로

     * AI에게 코드를 맡기고 개발자는 ""바이브만 타는""다는 개념(‘vibe-coding’)은 원래 Andrej Karpathy의 농담 트윗에서 시작된 유행임
     * 당시 개발자 커뮤니티는 “AI가 대신 일해주고 우리는 커피나 마신다”는 최고의 판타지로 여기며 웃어넘겼음
     * 하지만 Anthropic의 Sonnet 3.7과 Claude Code 출시 이후, 이 농담이 실제로 가능한 현실로 바뀌기 시작함. 기존 Cursor 같은 도구도 있었지만, Claude Code는 진짜 '바이브 코딩' 느낌을 주기 시작함
     * 필자가 몸담은 Julep은 방대한 코드베이스와 다양한 설계 패턴, 기술적 부채까지 안고 있음. 코드 품질과 문서화는 철저히 유지하지만, 각 파트의 의도와 히스토리를 파악하는 데만 수주가 걸릴 정도로 복잡함
     * Claude를 guardrail 없이 쓰면, 과잉 열정의 인턴이 곳곳에서 실수를 저지르는 것과 같은 혼란이 발생
     * 이 글은 그런 시행착오와 새벽 3시의 디버깅, 실제 서비스 운영에서 살아남은 진짜 실전 패턴과 노하우만을 정리해서 공유함

바이브 코딩(Vibe-Coding)의 본질

     * Steve Yegge가 CHOP(Chat-Oriented Programming) 라는 용어를 만들었듯, ‘바이브 코딩’은 AI와 대화하며 코드를 완성하는 새로운 개발 방식임
     * 전통적인 코딩이 대리석을 조각하듯 한 줄 한 줄 신중하게 만드는 작업이라면,
          + 바이브 코딩은 오케스트라의 지휘자에 가깝고, AI는 원석(기본 코드 능력)을 제공하는 연주자임
          + 개발자는 전체 방향성과 구조를 설계하고, AI가 그 흐름을 따라 코드로 풀어냄
     * 바이브 코딩의 3가지 태도(Postures)
          + 1. AI를 초안 작성자로 활용 (First-Drafter)
               o 아키텍처·설계에 집중하며, 반복 작업(CRUD, 보일러플레이트 등)을 AI가 빠르게 생성
               o 생각하는 속도로 코드를 작성하는 주니어 엔지니어를 둔 느낌이지만, 지속적 가이드 필요
          + 2. AI와 페어프로그래밍 (Pair-Programmer)
               o 가장 실용적이며 효과적인 모드
               o 개발자와 AI가 아이디어를 주고받으며, 큰 틀은 사람이 그리고 세부 구현은 AI가 채움
               o 수많은 프로그래밍 지식은 있지만 실제 배포 경험이 없는 동료와 짝코딩하는 느낌
          + 3. AI를 검토자/코드 리뷰어로 활용 (Validator)
               o 사람이 작성한 코드를 AI가 검토, 버그·개선점·놓친 패턴을 제안
               o 언제나 피곤하지 않고 꼼꼼한 리뷰어 역할
     * 핵심 통찰: 개발자는 ‘작가’에서 ‘편집자’로 역할이 전환됨. 모든 코드를 직접 작성하는 대신, AI가 만든 결과물을 검토·수정·방향 제시함.
     * 단, 전체 아키텍처와 맥락은 인간이 반드시 직접 주도해야 하며, AI는 ‘백과사전적 지식의 인턴’일 뿐 우리 서비스·비즈니스의 맥락은 알지 못함

바이브 코딩 3가지 실전 모드: 프레임워크

   수개월의 실험과 실제 배포 사고를 거쳐, 바이브 코딩에는 각기 다른 리듬과 가드레일, 최적의 용도가 있는 3가지 모드가 있음
     * 모드 1: Playground (실험/프로토타입/개인 프로젝트)
          + 사용 시점: 주말 해킹, 개인 스크립트, PoC, 즉흥적 아이디어 테스트 등
          + 특징: 설계·문서·가드레일 없이, AI가 코드의 80~90%를 작성. 아이디어 → 결과물까지 몇 분 만에 도달하는 속도
          + 위험: 실서비스/중요 코드에는 부적합. 장난/실험용으로만 사용. 엔지니어링 원칙은 오히려 더 중요해짐
     * 모드 2: Pair Programming (실사용·소규모 서비스)
          + 사용 시점: 5,000라인 이하 프로젝트, 실사용자 있는 사이드 프로젝트, 데모, 소규모 모듈 등
          + 핵심: 프로젝트의 관습·아키텍처·패턴·테스트 가이드 등을 CLAUDE.md로 한 번에 명확히 정의
          + 장점: 새 개발자 온보딩하듯, Claude에게 한 번만 설명하면 일관성 있게 코드 생성
          + 실전 포인트:
               o 코드 곳곳에 anchor comment(AIDEV-NOTE, AIDEV-TODO, AIDEV-QUESTION 등)로 Claude가 맥락을 잃지 않게 가이드
               o 이런 주석은 AI와 사람이 모두 참고할 수 있는 지침 역할, CLAUDE.md에 관리 기준과 예시까지 명시
     * 모드 3: Production/Monorepo Scale (대규모 서비스)
          + 사용 시점: 수십~수백 명 개발, 실사용자 있는 대형 서비스, 한 번의 실수로 큰 피해 발생 가능한 상황
          + 주의: 현시점(2025년 6월) 기준, 대규모 일괄 바이브 코딩은 완벽하게 확장되지 않음
          + 원칙: 개별 서비스/서브모듈 단위로 바이브 코딩 도입 권장, 모든 통합지점(API·DB 등)에 명확한 경계와 버전 관리, 주요 인터페이스·API에 변경 주의 주석 필수
          + 실전 예시:
               o # AIDEV-NOTE: API Contract Boundary - v2.3.1
               o # Changes require version bump and migration plan
               o 이런 경계선이 없으면 Claude가 함부로 개선하다가 실제 서비스 전체를 깨뜨릴 수 있음
     * 결론: 대규모 프로젝트는 바이브 코딩을 점진적으로, 분리된 서비스 단위로 도입하고, 반드시 문서화·가이드라인·리뷰 등 전통적 원칙을 병행해야 신뢰성 확보 가능

인프라 중심의 지속가능한 AI 개발 환경 만들기

     * CLAUDE.md: AI와 사람 모두를 위한 단일 진실(The Single Source of Truth)
          + CLAUDE.md는 모든 프로젝트 규칙, 아키텍처, 주의사항, 코드스타일, 금지 대상, 도메인 용어집 등을 체계적으로 담는 ‘헌법’ 역할을 함
          + AI와 새로운 팀원이 공유할 ‘지식의 뼈대’로 기능, 예시와 함께 구체 가이드라인과 금지사항을 노동집약적으로 관리
          + 좋은 CLAUDE.md에 투자하는 팀일수록 더 나은 결과를 만들어냄
          + 우리의 프로덕션 CLAUDE.md 참고
          + 코드베이스가 커질수록 CLAUDE.md만으로는 부족하고, 각 코드 곳곳에 anchor comment(AIDEV-NOTE/TODO/QUESTION 등)로 로컬 컨텍스트를 명확히 전달해야 함
          + 코드베이스를 도시로 비유한다면 anchor comment는 AI와 사람이 모두 길을 잃지 않게 해주는 표지판
          + 이런 주석은 단순 코드 설명을 넘어, ""왜"" 이렇게 동작하는지의 스토리를 남김
     * Git 워크플로우, AI 코드의 체계적 관리
          + AI 코드 생성 속도가 빨라질수록, 잘못 관리하면 git 히스토리가 오염될 수 있음
          + git worktree 방식 등으로 메인 브랜치에서 분리한 AI 실험 공간 마련해, 코드는 자유롭게 생성하되 기록은 체계적으로 구분/관리
               o how to use worktrees 및 wt 도구도 참조
          + 커밋 메시지엔 AI 관여 내역을 반드시 명시([AI] 태그 활용 등), 리뷰어가 추가로 주의 검토할 수 있도록 함

불문율: 테스트 코드는 반드시 사람이 작성

     * AI 보조 개발에서 가장 중요한 원칙: ""테스트 코드는 절대 AI에게 맡기지 말 것""
     * 테스트는 단순히 동작 확인용 코드가 아님
          + 실제 문제 맥락, 엣지 케이스 인식, 사업적 요구 해석, 도메인에 대한 인간의 이해와 경험이 녹아든 실행 가능한 명세임
          + 속도와 안정성 모두 놓치지 않는 고수 팀은, 바로 이 테스트를 철저히 인간이 관리
     * AI가 자동 생성한 테스트는 피상적 경로(happy path)만 검증하며, 예기치 않은 심각한 문제(예: 메모리릭 등)는 놓침
     * 우리팀의 경우 AI가 테스트 파일을 건드리면 PR은 자동 반려 (예외 없음)
     * 테스트는 코드의 명세이자 안전망, 누적된 모든 버그와 엣지케이스의 지혜
     * 반드시 사람의 손으로 작성하고, AI가 만질 수 없도록 강력하게 보호해야 함

확장과 맥락관리: 토큰 경제와 컨텍스트 최적화

     * AI 코드 개발에서 흔히 저지르는 실수:
       ""토큰 절약""을 위해 맥락(프롬프트, 요구사항, 환경 등)을 최소화하면 오히려 반복 작업이 늘고 전체 토큰 소비가 증가함
     * 적절한 맥락 제공이 장기적으로 더 효율적
          + ""최소""가 아니라 ""관련성 있고 충분한 맥락"" 을 미리 주는 것이 핵심
     * 나쁜 예시: 맥락 부족 프롬프트 ""Add caching to the user endpoint""
          + Claude는 단순 인메모리 캐싱, 무효화 전략/모니터링 없음, 멀티 서버 고려 없음, 캐시 스탬피드 무대책
          + 결과적으로 3번 이상 반복 수정을 거쳐, 총 4배 이상의 토큰이 소모됨
     * 좋은 예시: 맥락이 풍부한 프롬프트
Add Redis caching to the GET /users/{id} endpoint.
Context:
* 엔드포인트 트래픽 5만 req/분, 12대 API 서버, 데이터 변동 적음
* 기존 Redis 인프라 위치, 표준 키 패턴, Prometheus 기반 메트릭 요구
* 캐시 어사이드 패턴, TTL 1시간, 캐시 스탬피드 방지(확률적 조기 만료)
* 캐싱 가이드 문서 참조

          + 처음부터 구체적 맥락을 제공해, 반복 없는 정확한 구현 가능
     * 결론:
          + ""토큰은 좋은 도구에 투자하는 셈""
          + 미리 맥락을 충분히 넣으면, 장기적으로 반복과 수정이 줄어 비용이 절약됨
     * 실전 팁: 모든 프로젝트는 코드 변경 시마다 Claude에게 코드베이스 변화와 관련 맥락을 CLAUDE.md에 갱신하도록 요청

세션 관리와 맥락 오염 방지

     * 작업별로 Claude 세션을 새로 시작하는 것이 중요
          + 하나의 긴 대화에 여러 작업(예: DB 마이그레이션, 프론트엔드 디자인 등)을 혼합하면 컨텍스트가 섞여 의도하지 않은 결과 초래
     * 규칙: 한 작업 = 한 세션, 완료 시 세션 새로 시작
          + Claude의 '멘탈 모델'을 항상 깨끗하고 집중된 상태로 유지
          + 마치 생닭과 야채용 도마를 구분해서 쓰는 것처럼 맥락을 분리

실전 사례: 에러 처리 구조 전환

     * 실제로 500+ 엔드포인트에서의 ad-hoc 에러 처리방식을 구조화된 에러 계층(hierarchy) 으로 대체한 사례 소개
     * 사람(아키텍트)이 사전에 핵심 설계(SPEC.md/요구사항/에러 분류)를 작성하고, Claude가 실제 코드 대량변환(기계적 작업)의 실행자 역할을 맡는 방식
     * 아키텍처 원칙과 구체적 명세, 설계문서 예시/개념 도출 -> AI에 명확한 작업 지시 -> 정확 4시간 내 전체 리팩터링 완료 경험

AI 시대의 리더십과 조직문화

     * 시니어 엔지니어의 역할은 직접 코드 작성에서, 지식 큐레이션·경계 설정·AI/사람 모두를 가이드하는 일로 진화
     * 린(Lean) 매니지먼트, 지속적 배포 등 현대 개발 문화가 AI 협업 관리에도 그대로 중요함
     * 신규 입사자 온보딩 체크리스트(인간 + AI 협업 분리)
          + 1주차: 기본기 다지기
               o 팀의 CLAUDE.md(공통/서비스별) 읽기
               o 개발 환경 세팅
               o 첫 PR 제출(100% 직접 코딩, AI 금지)
          + 2주차: AI 협업 실습
               o Claude에 팀 템플릿 적용, 설정
               o '장난감 문제'를 AI와 함께 풀기
               o 프롬프트 패턴 연습
               o AI 보조 첫 PR(멘토/시니어와 함께)
          + 3주차: 독립적 실무
               o AI 보조로 주요 기능 개발 및 배포
               o 동료의 AI 코드에 대해 직접 테스트 작성
               o 코드리뷰 세션 1회 주도

투명한 문화 구축하기 : AI 활용의 적극적 공개

     * 모든 AI 활용 커밋에는 아래와 같이 커밋 메시지 태그로 명확히 표시
feat: add Redis caching to user service \[AI]
# \[AI] - 50% 이상 AI 생성, \[AI-minor] - 50% 미만, \[AI-review] - 리뷰만 AI 사용
# AI가 캐시/클라이언트 코드 작성, 캐시키 설계/테스트/검증은 사람이 직접

     * 효과
         1. 리뷰어가 AI 코드에 특별히 주의
         2. 디버깅 시 코드 출처 파악 용이
         3. AI 사용에 대한 부끄러움·은폐 문화 제거, ""책임감 있게 AI를 쓴다""는 팀 문화 확립
     * 누구나 부담 없이 AI를 활용하고, 고성과 문화에 기여할 수 있도록 적극적인 공개와 문화적 장치가 중요

  Claude의 금지사항: AI는 여기엔 절대 손대지 말 것

     * 테스트 파일/데이터베이스 마이그레이션/보안 핵심코드/API계약(버전관리 미포함)/환경 설정 및 시크릿 등은 AI의 자동화 절대 사용 불가
     * 실수 등급별(포맷·의존성부터 비즈니스 핵심영역 데이터 파괴까지)로 구분해, 고위험 영역엔 추가적인 강제 가드레일 적용 강조
     * AI 실수의 위험 등급(Hierarchy of AI Mistakes)
          + Level 1: 귀찮지만 치명적이지 않음
               o 포맷 오류(린터로 잡힘)
               o 장황한 코드(나중에 리팩터링)
               o 비효율적 알고리즘(프로파일링 시 발견)
          + Level 2: 비용 많이 드는 오류
               o 내부 API 호환성 깨짐(팀 조율 필요)
               o 기존 패턴 변경(혼란 초래)
               o 불필요한 의존성 추가(코드 비대화)
          + Level 3: 경력에 치명적(Career-Limiting)
               o 테스트 결과를 맞추기 위해 테스트 자체 수정
               o API 계약 파괴
               o 시크릿/개인정보 유출
               o 데이터 마이그레이션 손상
          + 실수의 레벨에 따라 가드레일 수준도 달라져야 하며, Level 3 실수는 커리어에도 중대한 위협이 됨

개발의 미래: 앞으로의 변화와 방향

     * 2025년 현재, AI 보조 개발은 사춘기 청소년처럼 강력하지만 아직 어색하고 거칠음
     * 그러나 성장 곡선은 명확하게 '가속' 중
     * 좋은 문서화(Documentation)는 AI 시대 DevOps 구현의 핵심 인프라
          + 문서는 이제 '참고자료'를 넘어, 인간 의도와 AI 실행 사이의 직접적 '인터페이스'
          + 고성과 팀은 테스트만큼 CLAUDE.md 등 문서 관리에 철저함
     * 앞으로 예상되는 변화
          + 코드 전체 맥락을 이해하는 AI
               o 파일 단위가 아닌 서비스/시스템 레벨까지 파악
          + 세션·프로젝트를 넘는 지속적 메모리
               o 대화와 작업 맥락을 장기적으로 기억·활용
          + 적극적 개선 제안을 하는 AI
               o 요청 없이도 문제·개선점을 미리 진단
          + 팀별 패턴·선호도를 학습하는 AI
               o 조직만의 스타일/관례에 맞는 코드를 자동 생성
     * 하지만, 기본은 변하지 않음:
          + 방향 설정은 인간, 실행·지렛대는 AI
          + 도구가 아무리 강력해져도, 우리는 여전히 ‘도구를 쓰는 사람’임

결론: 지금, 여기서 시작하세요

     * 여기까지 읽었다면 기대와 동시에 약간의 두려움도 느낄 것임
          + 그 반응이 정상, AI 보조 개발은 강력하지만 '의도적이고 체계적인 실천'이 필수
     * 오늘 바로 실천할 액션 플랜
          + 오늘
               o 1. 현재 프로젝트에 CLAUDE.md 파일 만들기
               o 2. 본인이 가장 복잡하다고 생각하는 코드에 anchor comment 3개 직접 추가
               o 3. 명확한 경계(가이드) 아래 AI 보조 기능 1개 시도
          + 이번 주
               o 1. 팀 단위로 AI 커밋 메시지 규칙 만들기
               o 2. 주니어 개발자와 함께 AI 코딩 세션 한 번 운영
               o 3. AI가 만든 코드에 대해 직접 테스트 코드 작성
          + 이번 달
               o 1. AI 도입 전후의 배포 빈도 변화 측정
               o 2. 팀 내 반복 작업에 대한 프롬프트 패턴 라이브러리 구축
               o 3. 팀 전체 AI 협업 회고 미팅 진행
     * 핵심은 ""지금 당장, 작게, 신중하게, 그러나 반드시 시작""
     * 이 흐름을 빨리 마스터한 개발자는 더 똑똑해서가 아니라,
          + 더 일찍 시작해서 더 많이 실수하며 학습했기 때문
     * 소프트웨어 배포 성과가 곧 조직의 성과를 좌우
          + 속도와 품질이 경쟁력인 시대, AI 보조 개발은 선택이 아닌 '필수 역량'
          + 단, 올바른 방법으로 접근해야 함
     * 바이브 코딩은 장난처럼 들리지만,
          + 인간의 역량을 증폭하는 진지한 개발 방식
          + 도구와 패턴은 이미 충분히 준비됨
          + 이젠 누가 오케스트라를 지휘할지, 누가 혼자서 모든 악기를 연주할지 선택할 때

실전 자료와 추천 리소스

     * CLAUDE.md 실전 템플릿 : github.com/julep-ai/julep/blob/main/AGENTS.md
     * Peter Senge – 『The Fifth Discipline』 :
     * ""Beyond the 70%: Maximising the Human 30% of AI-Assisted Coding"" – Addy Osmani
     * Mark Richards & Neal Ford – 『Fundamentals of Software Architecture』(2판, 2025)
     * Nicole Forsgren, Jez Humble, Gene Kim – 『Accelerate: The Science of Lean Software and DevOps』

   오늘 작성한 포스트가 해당 내용과 비슷한 관점이네요.
   결국 AI를 통해 생산성을 올리고, 떨어진 안정성을 높이는 조직 구조로 변화시키는게 핵심이었습니다.

   https://softycho.co/57

   ai 도움을 받는 코딩을 의미하는 vibe 코딩에서 vibe는 어떤 의도인지 아직도 모르겠음.
   분위기? 느낌? 어울림? ai랑 연관도없고
   퉁퉁퉁 사후르 급으로 맥락없이 느껴짐.

   나무위키에 따르면
   ""바이브 코딩(Vibe Coding)이란 개발자가 생성형 인공지능의 도움을 받아 코드를 작성하는 행위를 일컫는 신조어로 프로그래밍을 할 때 사전에 엄밀한 논리나 설계를 바탕으로 하지 않고 직감과 느낌에 의존한다는 의미로 ‘바이브’코딩이라는 이름이 붙었다."" 라고 하네요. ㅎㅎ

   뇌를 비우고 흐름에 몸을 맡기세요.
   모든 로직은 AI가 짜줍니다.
   탭키싸게가 되는거에용!

     look and feel👀🎵🎷. 이해하지 말고🧠 느끼세요!😊

   같은 느낌이죠

   오 그런가요? 저는 딱 들었을때 '느낌'이 오던데..
   말씀하시니.. 요즘은 비개발 직군도 잘 이해하고 있는 '하드코딩(hard-coding)' 이라는 용어가 떠오릅니다.
   요 단어 역시 처음에는 단어 자체로는 무슨 의미인지 알기 어렵지만, 개발을 배우다 보면 결국 무엇을 의미하는지 어떤 의도인지 모두가 잘 이해하고 있는 그런 '느낌'이랄까요? ㅎㅎ

        Hacker News 의견

     * 글 작성자 입장: 요즘에 Claude 코드 관련 글이 넘쳐나는 상황에서, 우리가 발견한 몇 가지 핵심 포인트—특히 Anchor Comments—공유 가치가 있다고 판단한 부분 남김
       Anchor Comments 방식은 코드베이스 이곳저곳에 특수 포맷의 주석을 남겨놓아, 필요한 지식을 바로 grep 해서 찾아볼 수 있게 해주는 구조
       예시로, AIDEV-NOTE:, AIDEV-TODO:, AIDEV-QUESTION:와 같은 프리픽스를 사용
       파일 검색 전에는 먼저 기존 AIDEV-…이 있는지 반드시 grep 해야 하는 룰
       작업이 끝난 후에는 해당 anchor 업데이트 필수
       코드파일이나 코드 조각이 너무 복잡하거나, 아주 중요하거나, 버그가 있을 수 있다고 판단되면 항상 anchor 주석 남기기
       참고 예시는 여기에서 확인 가능
          + 아주 경험 많은 엔지니어로서 LLM을 체계적으로 쓰지 않고 가끔만 사용하는 입장인데, 실제 프로젝트에서 LLM을 어떻게 프로덕션에 적용하는지 자세히 보니 상당히 유익한 느낌
            다른 분들이 왜 부정적인 시각을 갖는지 이해 안 되는 부분
            내 워크플로우에 LLM 활용도를 좀 더 높여보고 싶은 동기 부여 받는 경험
            물론 LLM이 프로젝트 키를 쥐고 있지는 않았지만, 특정 작업을 맡겨 성공한 사례 꽤 많은 상황
          + 요즘 관련 글은 많지만 이 글은 실용성이 높고 내게 적용해볼만한 시스템 아이디어 제시해줌
            aider 같은 툴을 쓸 때와 이런 워크플로우의 차이가 궁금한 상황—혹시 저자 관점이 있다면 듣고 싶은 요청
          + 훌륭한 아티클 덕분에 대규모 LLM 활용법 이해에 큰 도움 받은 느낌
            ""AI는 테스트는 절대 손대면 안 된다""고 했는데, 이어서 500개가 넘는 엔드포인트 리팩터링 예시에서 4시간 만에 처리했다는 점이 인상적
            이 4시간에 테스트 리팩터링까지 포함된 시간인지, 아니면 프롬프트에 소비된 시간뿐인지 궁금한 부분
          + 테스트가 AI에 의해 업데이트된 경우 PR을 거절한다는 규칙 언급 내용을 봤는데, 실제로 AI가 생성 또는 수정했다는 걸 어떻게 확인하는지 궁금
            글에서는 git 커밋 메시지 룰로 판별한다고 했는데, 이것도 커밋 단위로만 작동하는 상황
          + 글 작성에 Claude Code를 사용했는지 궁금
            나 스스로는 요즘 내 글 100%를 Claude Code로 작성하는데, 마크다운 파일에 에이전트가 직접 편집하는 효과가 뛰어나 claude.ai artifacts나 chatgpt.com canvas보다 훨씬 생산성 느끼는 중
            덕분에 연구 자료나 관련 파일을 문서에 깊게 병합하는 게 아주 쉬워진 상황
     * AI 에이전트의 흥미로운 점은, 평소 중요하다고 생각하지만 실제로는 시스템 배포 앞에서 우선순위가 밀렸던 프로세스들을 진짜 실행하게 만든다는 점
       AI가 자기 대신 뭔가를 하는 데 불편함 느끼는 정도를 '시스템적 검증에 시간을 투입할 지표'로 활용하는 꿀팁 사용 중
       링크에서처럼 데이터 마이그레이션 검증 시스템을 구축하면, 관련 모든 변경 사항도 자연스럽게 AI 활용 범위 안으로 넣을 수 있음
       추상적 '기술 부채' 이야기보다 이렇게 구체적으로 외부에 설명하기 쉬운 장점 체감
          + 확실히 그렇다고 공감하는 바이지만, 내가 발견한 또다른 유용한 트릭은 Claude Code에게 ""코드베이스를 둘러보고 헷갈리거나, 이상하거나, 직관에 어긋나는 부분이 있으면 AIDEV-QUESTION: 주석을 남겨달라""고 요청하는 방식
            예상 밖의 복잡하고 잊힌 코드 덕분에 중요한 곳을 다시 찾게 되는 경험했던 기억
          + 내 직감으로, 추상화 수준이 높은 검증 도구—예: acceptance test, property test, formual verification—를 더 자주 쓰게 될 가능성이 큼
            보일러플레이트 비용이 LLM 활용으로 상대적으로 많이 낮아진 환경
     * 읽으면서 새로운 걸 배움
       최근 Sonnet 4를 Cursor랑 Web에서 써봤는데, 계속 무언갈 대충 처리하거나 결과를 오해하게 보고하는 경우가 많아 당황
       심지어 프로그래밍 외 영역에서도 병적으로 잘못된 이야기를 하는 느낌
       Anthropic 리포트에서 본 대로 “삭제할거야” 같은 경고도 효과가 없었고, 사용 후 모바일 앱에서 피드백이 안 접수되는 문제까지 겪은 상황
       다른 분들은 Claude 관련 이슈가 없는 듯한데 혹시 나만 이런 상황인지 궁금
          + 최근 업데이트에서 AI의 능력을 너무 약화시킨 듯한 인상
            3.5 버전까지는 텍스트 분석, 요약, 짧은 글쓰기 등 간단한 작업엔 괜찮았지만 4버전 이상은 한 컨텍스트 내에서 3-4회 이상 명령을 제대로 못 따르는 상황
            “간결하게 하라고 했는데 왜 자꾸 장황하게 설명하냐” 라고 물으면, 디폴트 설정 때문에 명령어를 무시한다고 답변하고 “해로운 정보”는 아예 피하려는 성향까지 표현
            여러 번 논리적 허점을 집어주면 스스로 신뢰도가 낮다고 인정하기도
            오히려 너무 똑똑해져서 문제가 밀려온 건가 싶을 정도이며, Anthropic이 잘못된 방향으로 발전시킨 거라면 아쉬움 남김
          + 위에서 말한 문제들을 모두 실제로 경험한 사용자 입장
            Web에서는 아주 구체적으로 요청을 넣으면 좀 낫지만, 그래도 생성된 코드의 절반은 여전히 오류가 섞여 있음
     * 문서화 팁을 읽으면서 느낀 게, 사실 이런 규칙들은 꼭 AI만을 위한 게 아니라 일반 코딩에도 적용 가능
       CLAUDE.md 대신 CONVENTIONS.md, AI를 위한 주석 대신 READER를 위한 주석으로 남겨도 똑같이 유용
       낯선 코드베이스에서 새롭게 기여할 때 이런 주석이 있다면 꽤 감사할 것 같은 입장
          + aider로 실제 시도해봤더니 상당히 잘 작동한 경험
            비행기 기다리면서 PDF 뷰어와 드로잉 기능까지 넣은 코드를 30분 만에 완성한 사례 경험
          + 원글 작성자는 아니지만, 실제로 Claude에 도움 되는 주석과 인간에게 도움 되는 주석 스타일이 현저히 다름
            인간용 스타일 가이드는 보통 100줄 정도로 작성하고 “input 바꾸는 함수엔 반드시 !붙이기”와 같은 간단한 규칙 위주
            Claude용 가이드는 500줄 이상 작성했고, 각 규칙별로 ""이렇게 하라, 저렇게 하지 말라"" 식의 예시를 많이 포함해야 겨우 효과 받는 느낌
     * 글 작성에 감사
       많은 개발자들이 LLM에게 업무 통제권을 일부 넘길 때 느끼는 불안감, 기존의 형식적이고 엄격한 개발 방법론이 아닌 실험적이거나 비구조적 접근 방식 같다는 상반된 고민이 있다는 점 공감
       그렇지만 LLM을 활용해 훨씬 빠른 속도로 문제를 해결하려는 '목표 중심 최적화'가 실제로 실현 가능한 중간 지대 생성
       종종 구현 디테일에 빠져 실제 목표를 놓치는 일이 많은데, LLM 활용은 이런 실수를 줄이는 데 도움 준다는 생각
          + 맞는 이야기
            나는 LLM을 미완의 레버라고 보는데, 아직은 거칠고 실수도 많지만 배워가며 쓸 가치 충분
            허술한 엔지니어링을 정당화하는 핑계로 쓰지 않는 선에서, 진짜로 쓸만한 도구로 진화시키려는 노력이 중요하다는 시각
     * 글 맨 위 2.3MB짜리 이미지는 와이파이 환경에서도ㅎ 농담처럼 아주 느리게 로딩된 경험
     * 몇 가지 생각
          + LLM 관련 프롬프트나 명세를 코드베이스에서 더 세련되게 정리할 방법이 있는지 의문
            CLAUDE.md, SPEC.md, AIDEV 주석이 많아지면 다루기 힘들어질 듯
          + 'vibe-coding'의 요즘 정의는 뭔지 궁금
            Karpathy의 “카우보이 모드”처럼 코드 안 보고 diff 전부 수용하는 것에서 최근에는 LLM 워크플로우를 다 포함하는 의미로 변질된 듯
          + 타인의 LLM에 코드 보낼 때 소스코드 난독화를 하는지도 궁금
          + 주석이 많아지면 정말 금방 코드가 복잡해지는 것이 사실
            그래서 이를 시각화해서 gutter에 작은 인디케이터로 보여주는 vscode 확장 도구를 직접 개발 중
            vibe-coding 의미는 사람마다 다른데, 개인적으로는 완벽한 해법은 아니었고 여러 이슈 만남
            3.7 Sonnet과 Codex는 60% 성과였으나 Opus 4는 실제로 굉장히 효율적이라고 느낌
            코드 난독화 관련해서는, 본문 예시는 애초에 전부 오픈소스라 큰 문제 없었음
     * 매우 흥미로워서 내 CLAUDE.md 파일에도 적용해볼 생각
       “토큰 아끼려고 컨텍스트를 아끼는 게 오히려 역효과”라는 AI-개발의 역설적인 교훈에 동감
       더 큰 프로젝트, 복잡한 코드에서는 Claude Opus와 Sonnet의 성능 차이가 실제로 상당하게 나타나는 걸 직접 느끼는 중
       Sonnet은 안 해도 될 시도만 반복하다가 오히려 상황을 더 안 좋게 만드는 경우가 많았음
       결국 Max 구독 유저에게 Opus와 Sonnet을 굳이 구분할 필요가 없는 게 아닐까 의문
       Sonnet이 10~20회 번갈아 할 걸 Opus는 2~3회 만에 끝내는 경우라, 오히려 Sonnet 쪽의 사용량이 장기적으로 비용을 더 키우는 방식
          + Max 구독은 두 가지 티어가 있고, $100은 Pro보다 토큰 5배, $200은 20배 제공
            토큰 계산이 쉽지 않고, 하이브리드 모드는 Opus 토큰 20% 남을 때까지만 Opus 사용 후 Sonnet으로 자동 전환되는 구조
     * 잘 쓴 글이지만 “테스트는 절대 AI에게 맡기지 말라”는 부분엔 의견 다름
       나는 요즘 모든 테스트를 AI로 작성시키고 직접 꼼꼼히 리뷰
       신규 코드라면 AI에게 테스트까지 맡겨야 높은 자율성이 가능
       AI에게 테스트 구현과 통과를 명확히 지시한 다음, AI가 개발 중일 때 즉시 리뷰하고 부족한 테스트 케이스는 추가하는 구조로 운용
     * 대부분 내용에 공감하지만, Claude가 테스트나 마이그레이션을 손도 못 대게 하는 정책엔 동의 못 하는 부분
       테스트를 직접 쓰는 게 가장 싫은 작업인데, LLM이 최소한의 초안만 작성해줘도 큰 도움이 되는 상황
       핵심은 생성 주체와 관계없이 최종 소유권과 책임은 항상 인간에게 있게 하는 것
       메시지의 뉘앙스상 저자는 Claude에 대한 신뢰 부족, 또는 직원들이 AI 결과물을 무비판적으로 받아들이지 않으려는 목적이 강한 듯
       혹은, 테스트/마이그레이션 관련 엄격한 규칙이 없으면 진짜 코드가 고장나거나 데이터 손실 발생 가능성이 현실적이라고 판단하는 듯
          + 그 말도 맞지만, 내 경험상 큰 문제를 겪은 사례가 있었음
              1. 생성된 테스트를 나중에 사람이 수동으로 고칠 때 진짜 심각한 함정이 많았음
              2. Claude는 문맥 컨텍스트를 잘 모르니까 거의 모든 걸 mock 처리해서 우리 서비스/빌드 환경과 완전히 동떨어진 테스트 자주 생성
              3. 그리고 더 큰 문제는, 팀 전체가 테스트에 대해 너무 게을러진다는 점
                 실제로 production에서 버그가 크게 증가했음
"
"https://news.hada.io/topic?id=21369","미국 소프트웨어 개발 비용에 대한 세금 공제 복원을 위한 협조 요청 (Section 174)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          미국 소프트웨어 개발 비용에 대한 세금 공제 복원을 위한 협조 요청 (Section 174)

     * Section 174가 변경되면서 미국 내 소프트웨어 개발 비용이 즉시 세금 공제 불가 상황 발생
     * 이에 따라 많은 스타트업과 중소기업이 추가 세금 부담을 겪음
     * 본 게시글은 개발자 및 업계 관계자들이 의원에게 연락하여 변화를 촉구할 것을 요청함
     * 문제 해결을 위해 입법적 개정이 필수적임
     * 현 상황이 미국 기술 산업 경쟁력에 부정적 영향을 미칠 가능성 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Section 174 변화로 인한 미국 소프트웨어 개발비 세금 처리 문제

     * 2022년부터 미국 세법 Section 174가 변경되어, 소프트웨어 개발 비용 등 연구개발비에 대한 즉시 세금 공제가 불가능해짐
     * 해당 비용은 이제 5년 이상에 걸쳐 분할상각 처리 필요, 이에 따라 기업들은 단기적으로 적자나 높은 세금 부담을 경험함
     * 특히 스타트업, 중소기업 등 자금 흐름이 민감한 기업에게 심각한 자금난을 야기하는 구조임
     * 미국 내 많은 소프트웨어 개발자와 IT 업계 종사자, 기업 대표들은 이 조항의 복원 또는 개선을 국회에 촉구하는 움직임 확산 중임

업계내 영향 및 행동 촉구

     * Section 174 변화로 소프트웨어 산업 내 투자 위축 및 신생 기업 창업 부담 심화 현상 관찰 가능
     * 이 문제를 해결하기 위해 개발자, 엔지니어, 창업자 등 관련자들은 자신의 지역구 의원에게 문제의 심각성을 의견 전달할 것을 권장함
     * 공동 대응 및 목소리를 모아 입법적 개정 요구 시, 실제 법안 변경 가능성을 높일 수 있음
     * 본 글은 개발자와 업계 종사자들이 직접적으로 문제 해결에 목소리를 내도록 독려하는 내용임

미국 기술 산업 전반에 미치는 잠재적 영향

     * Section 174 적용 지속시, 미국 내 신규 소프트웨어 개발 투자 감소와 산업 경쟁력 저하 우려
     * 장기적으로는 고용 축소 및 기술 혁신 속도 저하, 글로벌 경쟁력 약화 등 부정적 파급효과 가능성 존재
     * 현장의 문제를 정확히 인식하고 공동 대응하는 것이 미국 기술 산업 생태계 유지에 핵심 요소임

        Hacker News 의견

     * 많은 사람들이 Section 174가 뭔지 잘 몰라서 간단하게 설명해보고 싶음
       보통 비용이 있으면, 그걸 매출에서 빼서 과세대상 이익 계산
       예를 들어 매출 100만 달러, 비용 90만 달러면 이익이 10만 달러이고, 정부는 그 이익에 세금 부과
       그런데 Section 174는 소프트웨어 엔지니어에 대해서는 이렇게 하면 안 된다는 내용
       엔지니어에게 돈을 주는 것은 ""진짜"" 비용이 아니라고 간주
       실제로 한 건, 의회 기준으로는 기계 같은 자본재를 산 것으로 봄
       그래서 세금 계산할 때는 5년에 걸쳐서 감가상각 필요
       만약 엔지니어에게 1년에 20만 달러를 줬으면, 세무상으로는 그 해에 4만 달러만 비용으로 인정
       결국 엔지니어를 고용하는 것이 훨씬 비용 부담이 커지는 현상
       일반적으로 엔지니어를 고용하면 비용만큼 이익이 줄어서 세금도 줄어드는 편인데, 여기서는 소프트웨어 엔지니어만 특별하게 비용처리가 안 되는 셈
       예시로 20만 달러 엔지니어에게 5년에 걸쳐 해마다 4만 달러씩 비용처리
       결국 이 룰 때문에 회사들은 자본을 5년간 정부에 빌려주는 셈이고, 엔지니어 인건비가 더 큰 부담
       엔지니어를 많이 고용하면, 심지어 손해인 해에도 세금을 내야 할 수도 있음
       참고로 이 규칙은 HR이나 임원처럼 다른 인건비에는 적용 안 됨
       이것은 트럼프 첫 행정부 때 기업 법인세 감세의 비용을 상쇄하려는 예산상 이유로 의회가 통과시킨 특별 규정
          + 이 법이 소프트웨어 엔지니어에 적용된다면, 그 정의가 무엇인지 궁금
            실제 법에서는 “소프트웨어 개발”과 관련된 모든 비용을 연구 또는 실험 지출로 간주한다고 명시
            관련 링크
            예를 들어 테스트 엔지니어나 QA 엔지니어도 소프트웨어 엔지니어로 봐야 하는지 불분명
            FPGA나 ASIC 엔지니어가 HDL로 작성해도 소프트웨어 엔지니어인지 궁금
            시스템, 전기, 기계 엔지니어가 MATLAB 같은 툴로 설계에 프로그래밍을 쓰는 경우도 해당되는지 불명확
            시스템 관리자, 데이터베이스 관리자, 기타 IT 직원이 업무 중 소프트웨어를 작성하면 그들도 포함인지 의문
            또, 퀀트 애널리스트, 데이터 사이언티스트, 회계사, 보험계리사 등 일부 코딩을 사용하는 다양한 직업군이 다 포함될 수 있음
            Excel을 쓰는 HR 등도 모두 소프트웨어 엔지니어인가?
            사실상 소프트웨어 엔지니어링은 현대 비즈니스 전반에 걸쳐 너무 범위가 넓음
          + 위 예시를 명확히 강조하고 싶음
            90만 달러의 비용 대신 18만 달러만 첫해에 비용처리 가능
            세무상 이익이 82만 달러
            실제 현금은 10만 달러밖에 없는데, 세금 내는 건 불가능에 가까움
          + 급여를 자산으로 간주한다는 건 정말 말이 안 된다고 생각
            소프트웨어의 가치를 개발자 연봉으로 평가하는 것도, 코드 라인수로 소프트웨어 가치를 매기는 것만큼 말이 안 됨
            오히려 실제 매출의 일부로 소프트웨어 가치를 산정하는 쪽이 현실적
            다만 이런 산정 방식은 대형 기술회사가 극도로 싫어할 것 같음
          + 보통 비용은 매출에서 빼서 이익 산출한다고 설명했는데, 이건 설명이 충분하지 않음
            실제로는 비용의 성격에 따라 다름
            자산을 만드는데 쓴 비용, 예를 들어 자산을 만드는 직원 급여 역시 즉시 비용처리가 안 되고 감가상각
            문제는 소프트웨어 개발이 진짜 R&D일 때도 있고, 인프라 구축 등 지속적 수익 창출 자산을 만드는 경우도 있음
            예를 들어 인프라 소프트웨어 개발엔 매년 비용처리보단, 공장 컨베이어 벨트 설치처럼 자산 취급이 맞을 때도 있음
          + 혹시 이 규정이 소프트웨어 개발자 외 인력과 다른지 궁금
            보통 직원 연봉은 바로 비용 처리하는데, 왜 소프트웨어 개발자만 비용처리 대신 감가상각이 필요한지 의문
     * 이 문제는 정말 심각하게 받아들여야 한다고 생각
       특히 상원에서 해당 법안이 논의되는 현재 시점에 이런 글이 나오는 게 걱정
       우리가 어떤 조항에 동의하더라도, 전체적으로 해로운 법안이면 그대로 추진해서는 안 됨
       의원들에게 연락하는 게 맞지만, 현행 법안은 절대 지지하지 않는다고 명확히 밝혀야 함
       추가로 참고할 만한 기사들
       기사1
       기사2
       미국 시민이라면 이 법안에 찬성 목소리를 내지 말아달라는 부탁
          + 2017년 이후로 민주당이 집권하기도 했지만 아무것도 바꾸지 않았는데, 어떻게 고칠 수 있다는 건지 궁금증
            바뀔 기미가 없어보임
     * 이 논의를 해줘서 고맙다는 생각
       수년간 중소 소프트웨어 기업들과 그 관계자들이 이 문제에 대해 조용했던 점이 신기
       최근 ""타임밤"" 관련 기사처럼, 실질적으로 이 문제를 다뤄준 언론이 드물었고 반가웠음
       많은 회사가 규정 변경 자체를 무시했거나, 아니면 사업 유지 차원에서 아무 말도 못 했기 때문에 침묵이 이어진 것 같다는 가설이 있음
          + 이런 상황이 결국 대기업에만 유리하게 작용
            돈 많은 기업만 감내할 수 있고, 나쁜 법률은 대기업만 살릴 뿐임
          + 많은 기업이 규정 변경을 무시했다는 주장은 믿기 힘듦
            법 바뀐 후에도 개발자 연봉을 계속 예전처럼 비용처리했다면, 그건 탈세가 아닌가 하는 의문
     * Small Software Business Alliance는 초창기부터 이 문제에 적극 대응
       관련 링크
       Michelle Hansen이 초기부터 중요한 역할
       트위터 계정
       만약 에너지 분야라면, Clean Energy Business Network 역시 이런 부당한 조항의 제거를 위해 노력
       몇 년 전 그들이 Ron Wyden 상원의원팀과 연결시켜 준 적 있음
       민주당은 대체로 Section 174 개정에 반대
       관련 기사
       이 싸움은 반드시 필요
       소프트웨어뿐 아니라 미국의 모든 혁신 비즈니스를 위협하는 내용
          + 세법 일부 항목이 부유한 개발자에게 약간 불리해지는 수준을 끔찍하다고 표현하는 건 과하다고 생각
            이 규정은 부유한 IT기업에 불편만 줄 뿐
            이 스레드 전체가 대기업 살리기를 미화해 소규모 개발자들도 도움이 되는 척 세뇌하는 것 같음
            농산업계도 이렇게 중소농을 없앤 뒤 대형 농장만 이득 보게 만든 전례가 있음
            대형 IT도 똑같은 일을 하고 있음
            로비스트들에게 무기를 넘겨주지 말고, 이들이 소프트웨어 중소개발자를 위하는 척하는 프레임에 휘둘리지 말아야 한다는 소신
     * 현행 세법은 정말 말도 안 되는 수준
       연봉으로 수백만 쓰고 실제로는 20만 판매했는데, 회사가 문 닫아야 할 상황에서도 세금 내야 하는 구조
       자본자산 취급이 소프트웨어에 적용되는 건 좀 이상
       일부 소프트웨어는 자본자산이 될 수 있어도, 대부분은 그만큼 못 됨
       최소한 감가상각 속도가 훨씬 빨라야 한다는 의견
          + 거의 대부분의 소프트웨어 회사들은 자사 코드가 중요한 자본자산이라고 생각할 텐데 의문
            예를 들어 회사가 소스코드와 설계문서를 5년 후 공공도메인으로 풀어도 괜찮은가?
            아니면 지금 감가상각이 너무 빠른 것인지 고민 필요
          + 법인세는 순이익(매출-비용)에 세금 부과로 알고 있는데, 왜 위 방식이 적용되는지 의아
     * 이 이슈의 배경 설명을 일반인 관점에서 정리
          + 일반적으로 기업은 이익에 대해 세금 부과
          + 소프트웨어 회사는 앱 개발에 100만 지출, 110만 매출이면 10만 이익에 세금
          + 몇 년 전부터 IRS가 100만 전액 즉시 비용처리 금지, 5년에 걸친 분할비용만 인정
          + 그래서 200만만 비용처리, 나머지 90만을 이익으로 간주
          + 20% 세율 기준 18만 세금을 내야 하고, 실제 은행엔 10만뿐
          + 결국 세금 내기 위해 대출이나 VC 유치 필요, 자금력 있는 VC 회사가 독립 창업자보다 유리
          + 이 서한의 목적은 원래대로 모든 실질비용 즉시 인식
            법률가도 회계사도 아니지만 이렇게 이해
            (참고: 세율 예시는 20%로 수정)
          + 이 설명엔 다소 편향이 깔려있음
            사업하는 사람은 유동성 개념을 충분히 이해
            자금이 자산 등으로 바뀌었다 해도 세금 납부는 원칙
            극단적으로, 연말에 금을 쌓고 세금 없애고 연초에 팔아버리는 식의 조세 회피도 가능
            핵심은 소프트웨어가 자산이나 소비재 중 어디에 해당하는지 논의가 중요
            개인적으론 소프트웨어가 실질 자산은 아니라고 생각하지만, 실무적으론 자산가치 10% 정도로 타협 가능
          + 45만 달러 세금 중 상당 부분은 환급 혹은 이월공제가 가능
            예를 들어 2년에 매출/비용 0이어도 1년차 비용의 20만 달러를 2년차에 환급 가능
            또, 만약 회사가 망하면 환급가능세금 때문에 회사 잔여물 자체를 사서 이득 보는 사례 존재
            그래서 보통 단기적인 파산 위험은 없고, 대신 고금리 팩터 대출로 세금 자금 조달
            이는 길게 보면 큰 부담
            (변호사, 회계사 아니고 미국인도 아님)
          + 법인세율 50% 예시는 현실과 다름
            미국 법인세율 관련 링크
            연방 기준 21%, 주에 따라 10% 이하 추가
          + 설명이 훌륭
            대형 IT가 세법 때문에 팀도 해고 한 적 있고, 이게 결국 전 세계 엔지니어에게 영향
            모든 국가가 소프트웨어 사업 관련 동일한 규정이 있어야 한다고 생각
            왜냐면 SW 산업은 비용 구조가 선투자가 대부분, VC 모델이 통하지 않는 작은 시장은 더더욱 그렇기 때문
          + 100만 달러 전액 즉시 비용처리 금지는 트럼프의 2017 세제개편 영향
            세법이 정식 개정된 내용
     * 왜 지금 규정 철회를 위해 움직이고 있는지 궁금
       법 시행된 지 8년, 실제 적용 3년이지만, 그간 IT업계에서 별다른 로비도 없었는데 최근에 변한 이유가 뭔지 궁금증
          + 법 시행 직후부터 꾸준히 로비 활동이 있었음
            의회는 철회에 여러 번 접근, 하원은 실제로 2024 Tax Relief for American Families and Workers Act를 통과시켰음
            Hacker News 등에서 논의가 적을 뿐, 중소기업 로비계에선 계속 중요한 이슈였음
            현행 제도 철회가 안 된 진짜 이유는 정치, CBO 예산적자 때문에 양당 모두 꺼려한다는 견해
          + 지금 로비하기 좋은 타이밍은, 쉽게 감정적으로 움직이는 인물이 결정권자로 있기 때문
          + 트럼프 임기 중 큰 감세를 했고, 예산상 손실을 다른 수단으로 메우려다 이런 법 등장
     * 나도 미국 개발자로서 서명했고, 소프트웨어 개발비 즉시비용처리 복귀를 전적으로 지지
       이 정책은 조용히 수많은 스타트업과 엔지니어팀을 망가뜨렸고, 이제 정말 고쳐야 할 때
       YC와 @itsluther 같은 사람들이 이 운동을 주도해줘서 고마움
       이건 단순 세금 문제가 아니라, 미국 내 혁신과 인재 유지에 직결
       반드시 해결의 필요
     * @dang과 모든 분들에게
       만약 대중적 지지를 끌어낼 생각이면, 인디/게임 개발자들과도 접촉을 해보는 게 어떨지 제안
       이들도 모두 피해자일 것이고, 게이머 커뮤니티 등에 이슈가 퍼질 수 있음
          + 아이디어는 좋은데, 실질적으로 HN(이 스레드) 외에 접촉 방법을 모르겠음
     * 테크업계는 실제 의도와 상관없이 ""반(反) 감세"" 쪽으로 보는 시선이 있음
       이번 세금 감면이 옳든 그르든, 이런 캠페인이 얼마나 환영받을지는 장담 못하겠음
       이 분야에서 목소리를 내면 소셜미디어에서 차가운 반응, 심지어 비꼼도 각오해야 할 것
"
"https://news.hada.io/topic?id=21307","iPhone 15 Pro의 Depth Map","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        iPhone 15 Pro의 Depth Map

     * iPhone 15 Pro는 깊이 맵을 포함하는 HEIC 포맷의 이미지를 기본적으로 저장함
     * HEIC 파일에는 여러 이미지와 방대한 메타데이터가 함께 저장되며, JPEG 선택 시에는 깊이 맵, HDR 등이 포함되지 않음
     * 오픈 소스 프로젝트 HEIC Shenanigans를 통해 HEIC 파일에서 이미지와 메타데이터를 추출하고 EXR 포맷으로 변환 가능함
     * 변환 과정에서 OpenEXR, OpenImageIO, OpenColorIO 등 영화/TV 업계에서 사용하는 다양한 표준과 도구를 활용함
     * 결과적으로 iPhone 15 Pro 사진의 HDR, SDR, Gain Map, Depth Map 정보를 EXR 포맷으로 분리·활용 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

iPhone 15 Pro 깊이 맵 지원 배경

     * 2017년부터 Apple은 자체 iPhone에 LiDAR 스캐너, 3D Time-of-Flight, Structured-Light 스캐닝을 활용하여 깊이 맵 정보를 카메라 이미지에 포함시킴
     * 이러한 깊이 맵과 메타데이터, 여러 버전의 이미지는 HEIF(HEIC) 포맷에 저장됨
     * HEIC는 효율적인 이미지 저장 포맷으로, 2017년 이후 iPhone 기본 이미지 포맷으로 채택됨
     * JPEG 포맷을 사용할 시에는 깊이 맵 및 HDR 등의 첨단 기능을 사용할 수 없음

HEIC에서의 깊이 맵 확인 사례

     * 독일 함부르크 소재 영화 제작사 Replayboys의 VFX 책임자 Finn Jaeger가 iPhone에서 생성된 다중 깊이 맵 스크린샷과 프로젝트 진행 현황을 공유함
     * Finn Jaeger의 HEIC Shenanigans 프로젝트는 HEIC 컨테이너에서 개별 이미지와 메타데이터를 추출해 EXR 파일로 변환하는 Python 스크립트(374라인)를 제공함

개발 환경 정보

     * 사용된 워크스테이션은 Ryzen 9 9950X 16코어 CPU, 96GB DDR5 RAM, 4TB NVMe SSD, ASRock X870E Nova 90 메인보드, Windows 11 Pro 환경에서 Ubuntu 24 LTS(WLS2)로 실행됨
     * Nvidia GTX 1080 사용 등으로 Windows가 메인 환경이고, 일부 소프트웨어 호환 이유에서 선택함

주요 도구 및 라이브러리 준비

     * Python 3.12.3 환경 및 기타 CLI, 이미지 변환·처리 라이브러리 설치 필요
     * exiftool은 HEIC 지원에 중요한 역할을 하며, 최신 버전 사용 시 더 많은 기능 및 버그 수정 포함 가능
     * jc(JSON Convert)는 CLI 출력 결과를 JSON으로 변환하여 파이프라인 활용성을 높임
     * HEIC Shenanigans 레포지토리를 클론하여 Python 가상환경에서 의존성을 설치함
     * 최종 EXR 이미지는 DJV 뷰어로 확인 가능함

변환 데모 및 예시 이미지

     * ArcGIS 제품군 전문가인 Joel Joseph가 인도 뭄바이에서 iPhone 15 Pro로 촬영한 HEIC 이미지 샘플을 활용함

HEIC → EXR 변환 및 워크플로우

     * Academy Software Foundation은 영화/TV/디지털 포스트 프로덕션에서 쓰이는 오픈소스 프로젝트와 표준을 리드함
     * 소속 프로젝트 중 OpenEXR는 ILM 주도로 1999년 개발된 고다이내믹 레인지(HDR) 이미지 포맷으로, 2003년 오픈소스화되었으며 시각 효과·3D 렌더링 등에서 활용됨

  EXR 변환 구체적인 단계

     * heic_shenanigans의 heic_to_exr.py 스크립트를 사용해 입력 HEIC 이미지를 EXR 파일로 변환함
     * 변환 결과물(EXR)은 468MB 용량이며 다양한 이미지·맵 정보를 하나의 파일에 포함함

    oiiotool 스크립트 활용

     * 이미지 크기 추출
     * sRGB 이미지를 Linear P3 → ACEScg로 색공간과 감마를 변환
     * OpenColorIO(OCIO) 설정 파일을 활용하여 색상 프로파일, 컬러스페이스 변환 등을 진행함
     * HDR Gain Map을 Rec709로부터 Linear로 변환 및 Y 채널 → RGB로 확장
     * Gain Map의 headroom 값 추출 및 역수 스케일 적용
     * HDR 베이스 이미지는 Gain Map과 곱셈 연산을 통해 생성
     * 깊이 맵(Depth Map) 의 Y채널을 추출하고, EXR 포맷으로 저장
     * 최종 단계에서 만들어진 각 채널(RGB, SDR, Gain Map, Depth Map)을 EXR 파일 내부 별도의 채널로 추가함

EXR 내부 채널 구성

     * EXR에는 아래와 같은 정보가 채널별로 저장됨
          + HDR base 이미지의 RGB
          + SDR 채널(별도 저장)
          + Gain Map
          + Depth Map
     * 매트(Matte) 레이어가 있을 경우 추가적으로 포함 가능

활용 및 참고 사항

     * 이 프로세스를 통해 iPhone 15 Pro에서 촬영한 이미지의 깊이·HDR 등 복합 정보를 전문 포맷(EXR)으로 분리·활용 가능함
     * 머신러닝, 3D 렌더링, 영화·VFX 등 여러 데이터 파이프라인에서 iPhone 촬영 이미지를 효율적으로 활용할 수 있는 가능성을 보여줌

        Hacker News 의견

     * 다른 분들이 언급한 것처럼 iPhone의 LIDAR는 깊이 맵의 주요 데이터 소스로 쓰기에는 해상도가 너무 낮은 편임을 강조하고 싶음. 실제로 iPhone은 모델이나 사용하는 카메라에 따라 네 가지 정도의 깊이 데이터 추출 방식을 사용. 원래는 인물 모드 사진에서만 적용됐지만, 최근 iPhone은 일반 사진에서도 깊이 맵을 기록.
         1. 첫 번째 방식은 후면에 두 개의 카메라로 동시에 촬영하여 시차(parallax)로 깊이 맵을 추정하는 점. iPhone 7 Plus가 처음 적용했고, 좁은 화각의 렌즈 뷰에 국한되는 제한점 보유
         2. iPhone XR처럼 하나의 카메라만 있을 때는 센서 내 포커스 픽셀을 이용해 대략적인 깊이를 파악하고, 머신러닝으로 이를 보정 (관련 글)
         3. 포커스 픽셀마저 없는 iPhone SE 등에서는 머신러닝만으로 깊이 맵을 예측하지만 실제와 관련성이 가장 낮은 결과. 사진의 사진을 찍어도 속을 수 있음 (관련 글)
         4. FaceID가 있는 iPhone의 셀피는 TrueDepth 카메라의 3D 스캔을 이용하는 점, 저화질 및 흐릿함이 특징
            기사에서 나오는 인물 분리, 안경·머리카락·피부 등 인식용 보조 이미지(포트레이트 효과 매트)는 머신러닝 산출물임.
            나 역시 포트레이트의 깊이 맵과 매트 이미지를 활용해 크리에이티브한 필터 앱을 만들어 봤는데, 지금은 없어졌지만 정말 재미있는 경험. 깊이 맵을 활용한 예술적 아이디어는 무궁무진.
          + 최근 iPhone에서는 피사체(사람 또는 반려동물)가 인식될 때 메인 사진 모드로도 자동 깊이 맵 기록. 예전에 깊이 맵과 포트레이트 효과 매트로 크리에이티브 필터 앱을 개발했던 경험이 있는데, 혹시 그 앱 이름과 관련 영상을 볼 수 있는지 궁금.
            참고로 Matte Viewer라는 유틸리티 툴을 만든 적 있는데, 이건 단순히 매트와 깊이 맵을 보는 용도임 (Matte Viewer 앱)
          + LIDAR는 풀 해상도의 깊이 맵 생성을 위해서라기보다는 초점 맞추기(AF)와 저조도 환경에서 빠른 포커싱용으로 최적화된 하드웨어임을 강조하고 싶음
          + 세 번째 방식은 5년 전 이야기이니, 최근 머신러닝 기반 깊이 추정 관련 오픈소스(ml-depth-pro) 참고 권장
          + 네 번째 TrueDepth 방식이 보안 앱에서 liveness(실제 사람 구분) 검출에 사용할 수 있는지도 궁금
     * 정말 흥미로운 기사였음. 이런 깊이 맵 데이터가 결국 배경 흐림(피사계 심도, 이른바 faux bokeh)을 구현하는 데 쓰이는 게 인상적.
       사진을 찍은 뒤에도 포커스와 심도 영역, 즉 조리개를 나중에 조정할 수 있다는 점이 참 신기하지만, 인공적인 보케는 그다지 마음에 안 드는 편. 가짜처럼 보여서 포토샵 결과물도 못하게 느껴짐.
       그리고 기사 내 파일 포맷 오타(HEIC 14건, HIEC 3건)도 몇 군데 눈에 띔
          + 파일 포맷 오타 지적해줘서 수정했다는 점만 간단히 전하고 싶음
          + 인공 보케가 어설픈 이유는 광학 및 조리개 수학을 정확히 반영하지 못하고, 제품적 관점에서는 80%의 사용자를 만족시키는 수준에서 근사치로 구현했기 때문이라고 생각. 올바른 조리개 수학을 적용해서 더 나은 카메라 앱을 만들 수 있을 것 같은데, 소비자들이 차이를 알아보고 굳이 결제할까 궁금함
     * 깊이 맵과 의미 분할(semantic map)은 보는 것만으로도 재미있고, TouchDesigner, Blender, Cinema 4D 등 앱에 불러오면 다양한 깊이 효과를 사진에 적용 가능.
       실제로 Apple도 사진 후처리(사진 보정 등)에 이 데이터들을 활용.
       이전에는 인물 모드에서만 캡처됐지만, 최근에는 피사체(사람, 반려동물) 감지 시 일반 촬영에서도 자동 기록.
       나도 사진 앱 및 툴 개발자인데, 내가 만든 Matte Viewer는 깊이 맵과 포트레이트 매트 이미지를 확인 및 내보내기에 특화 (Heliographe 툴 정보, Matte Viewer 앱)
     * 언젠가는 모든 스마트폰이 비싼 센서 없이도 Gaussian splatting 기반의 3D 이미지를 기본 지원할 날을 기대. 계산량은 크지만 센서 추가 비용과 중량을 피할 수 있다는 점에서 더 실용적이라고 생각함
     * 뭔가 빠뜨린 게 있을 수 있지만, 기사에서 HDR 게인 맵 이야기를 상당히 길게 다루는 점이 깊이 맵과 어떤 관련이 있는지 궁금.
       나는 iPhone의 HDR 디스플레이(자동 밝기 과도 조정)를 싫어해서 내 사진은 수동으로 HDR 게인 맵을 제거.
       예전 HDR은 3장의 다양한 노출 사진을 합쳐서 부족한 영역만 보정하는 거였고, 결과물에 'HDR'이라는 구체적 속성을 담지 않았다는 점이 더 좋았음
          + 참고로 iPhone의 사진 설정에서 ‘화면 HDR 밝기 강화’ 기능을 끌 수 있다는 정보 추가
          + 나도 기사를 읽으면서 같은 생각, 깊이 맵 개요는 좋았는데 중반 이후엔 HDR 게인 맵이 중심이 되어 약간 내용이 분산된 인상. 전반적으로 좋았지만 스레드 흐름이 조금 산만하게 느껴짐
     * LIDAR는 실제로 기사에서 보여준 깊이 맵보다 훨씬 해상도가 낮음.
       실제 깊이 맵은 LIDAR와 카메라 데이터를 합쳐 합성함
          + 나 역시 LIDAR는 실제 맞춤 초점(포커싱)을 위해 쓰이고, 진짜 깊이 맵은 멀티 카메라 시차로 계산된다고 이해함
     * 혹시 Apple이 ‘스티커 생성’ 기능(사진 피사체 꾹 눌러 스티커 추출 또는 다른 사진에 복사 적용)에 이 기술을 응용하는지도 궁금함
          + 그 기능은 순수 머신러닝 기반이 분명함. 왜냐하면 iPhone으로 찍은 사진이 아니어도 작동하기 때문
     * 깊이 맵을 사용해 스테레오그램이나 SIRDS(자동 무작위 점 스테레오그램) 생성이 가능한지 궁금. 예전에 회색조 이미지로 스테레오그램 만들던 추억 있음
          + 실제로 지원함. 이 UI는 VisionOS Photos 앱에만 존재하지만, 앨범 내 사진에 깊이 맵이 있거나 고해상도라면 ML로 3D 공간(Spatial Format) 변환 가능.
            EXIF 정보로 화각 정보 매핑해 원본 장면의 물리적 크기에 맞춰 VR에서 스케일을 맞춰줌.
            개인적으로 이 기능 하나만으로 $4000을 들여 Vision Pro를 산 보람 충분. 옛날 Nikon D7로 찍었던 사진을 VR에서 올바른 크기와 3D로 보는 경험은 아주 깊은 향수를 자극.
            Apple이 이걸 Vision Pro의 핵심 기능으로 강조하지 않는 점이 아쉬움. 정말 대단한 기능임
     * iOS용 Reality Composer는 LIDAR 지원 기기에서만 오브젝트 캡처가 가능한데, LIDAR 비탑재 기기에선 photogrammetry(합성 3D 재구성) 백업 기능이 없음. 3D 작업을 하려다 아쉬웠던 경험 공유
          + 3D 스캐닝 작업은 Heges 앱이 가장 성공적이었음. LIDAR는 자동차 같은 큰 물체에 효과적, Face ID 깊이 카메라는 작은 오브젝트에 유용.
            Creality Ferret SE 스캐너(틱톡에서 약 $100에 구입)를 사용해 소형 3D 스캔 시도, 기대 이상으로 훌륭했음
          + Polycam은 LIDAR 미지원 기기에서 photogrammetry로 대체 동작함.
            Canvas(별도 LIDAR 필요), Scaniverse(LIDAR 선택)도 추천받은 경험 있음
     * 제목을 볼 때마다 머릿속에서 ‘death maps’라고 읽히는 착각이 들어서 묘한 재미
"
"https://news.hada.io/topic?id=21363","Show GN: JSON Prettier - 오프라인 JSON 포맷팅 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show GN: JSON Prettier - 오프라인 JSON 포맷팅 앱

   안녕하세요
   API 디버깅이나 서버 로그 분석할 때 JSON 포맷팅할 일이 자주 있는데, 그때마다 “json formatter” 검색해서 웹 도구를 썼습니다.
   근데 광고도 많고, 무엇보다 회사 내부 API 응답이나 고객 데이터처럼 민감한 JSON을 브라우저에 복사해서 붙여넣는 게 좀 꺼려졌습니다.

   그래서 오프라인에서 돌릴 수 있는 JSON 포맷팅 앱을 직접 만들어봤습니다.
   JSON Prettier라는 이름이고, 기본적인 기능은 JSON 문자열을 보기 좋게 정리해서 보여주는 단순한 앱입니다.

   Tauri + React로 만들었습니다.
   Tauri를 처음 써봤는데 빌드도 잘 되고, 파일 용량도 Electron보다 훨씬 작더라고요. (4 ~ 5mb)
   다만 막상 맥에서 릴리즈 된 것을 다운로드 받아서 실행해보니까, 보안 설정 때문에 그냥은 실행이 안 되고,
   터미널 열어서 xattr로 서명 해제 같은 걸 해줘야 실행이 되더라고요. (이상하게 직접 로컬에서 빌드한 파일은 실행이 잘 됩니다.)
   애플이 이런 식으로 앱 실행을 막는 줄은 몰랐고, 저도 찾아가면서 실행해봤습니다.
   혹시 이걸 좀 더 자연스럽게 배포하거나 실행하게 만드는 방법이 있다면 조언도 환영입니다.

   GitHub: https://github.com/rebase/json-prettier
   다운로드: https://github.com/rebase/json-prettier/releases

   https://tauri.app/distribute/sign/macos/
   tauri 공식 문서에 있는 macOS Code Signing 내용을 참고해보시면 좋을 것 같습니다.

   감사합니다
"
"https://news.hada.io/topic?id=21337","마조히스트를 위한 웹 개발 가이드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           마조히스트를 위한 웹 개발 가이드

     * C/C++ 코드를 Emscripten으로 WebAssembly로 포팅하여 브라우저에서 동작하는 웹앱 제작 과정을 실제 Rubik’s Cube 솔버 예제 기반으로 상세히 설명함
     * Hello World부터 멀티스레딩, 콜백, 영구 스토리지, 모듈화 등 브라우저/WebAssembly 환경에서 마주치는 구체적 난관과 문제 해결법을 단계별로 다룸
     * JavaScript 비동기 초기화, 함수 내보내기, Web Worker 및 Spectre 이슈, IDBFS 통한 IndexedDB 영구 저장 등 실전 트러블슈팅에 초점
     * Emscripten의 추상화가 실제로는 자주 '새는' 현상(leaky abstractions)임을 반복적으로 강조하며, 웹 플랫폼의 한계와 내부 구조를 알 필요성을 강조함
     * 프론트엔드의 최소한의 JavaScript/HTML 지식만으로 복잡한 C 코드 베이스를 웹으로 옮기는 실전 경험을 통해, 기존 C/C++ 라이브러리를 웹으로 이식하려는 개발자에게 실질적인 도움과 노하우를 제공하는 경험 기반 가이드임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

소개

     * 최근 Rubik’s Cube 최적해 알고리듬을 웹 앱으로 구현하는 프로젝트를 진행하였음
     * C로 개발한 Rubik’s Cube 최적화 솔버를 Emscripten으로 컴파일해 WebAssembly로 웹 브라우저에서 구동하는 과정을 기록함
     * WebAssembly를 쓰는 주된 이유는 자바스크립트 대비 거의 네이티브에 가까운 성능을 웹에서 확보할 수 있기 때문임
     * 본 글은 전통적인 웹 개발 튜토리얼이 아닌, 기존 C/C++ 코드를 웹으로 이식하고자 하는 개발자를 위한 ‘고통의 여정’임
     * 웹 개발 경험이 많지 않아도 HTML, JavaScript의 기본 구조와 브라우저 개발자 도구 활용법만 알면 따라갈 수 있음

환경 구축

     * 모든 예제 코드는 git 저장소, github에서 확인 가능함
     * Emscripten 설치 필요(설치법은 공식 사이트 참고), 웹서버는 darkhttpd 또는 Python http.server 등 사용
     * 튜토리얼 코드 예제는 Linux 및 UNIX 계열에서 테스트되었음. Windows 사용자는 WSL(Windows Subsystem for Linux) 을 추천함

Hello World

     * C 코드의 Hello World를 emcc -o index.html hello.c 명령으로 컴파일하면 index.html(웹 페이지), index.wasm(WebAssembly 바이트코드), index.js(JavaScript glue code) 세 파일이 생성됨
     * 브라우저나 Node.js에서 동작 가능하며, 각각의 환경에서 다른 활용법이 존재함
     * .wasm만 생성하려면 -sSTANDALONE_WASM 옵션 사용
     * Emscripten에서 .wasm만 생성도 가능하지만, 대부분의 경우 JavaScript glue code가 필수적임

Intermezzo I: WebAssembly란?

     * WebAssembly(WASM) 은 웹 브라우저 내 고성능 가상 머신에서 실행되는 저수준 언어임
     * WASM은 2017년 이후 모든 주요 브라우저에서 지원됨
     * 원래 Emscripten은 C/C++ 코드를 asm.js라는 JavaScript 하위 집합으로 변환했으나, WASM의 등장으로 전환됨
     * 텍스트 표현식도 존재하며, 스택 기반 구조임. 최근까지 32비트 아키텍처만 지원해 4GB 이상의 메모리를 못 썼으나, WASM64가 점진적으로 브라우저에 도입되고 있음

라이브러리 빌드

     * C 함수 multiply() 를 WASM으로 빌드 후 JavaScript에서 호출하는 기본 예시 진행
     * 기본 빌드시 Emscripten은 함수 이름에 언더스코어(_) 를 붙임(예: _multiply)
     * 함수 외부 노출은 -sEXPORTED_FUNCTIONS 옵션 지정 필요함
     * 라이브러리 로딩 시 초기화가 비동기적이므로, onRuntimeInitialized나 await 등 비동기 처리 필요함
     * 실습 코드는 저장소 01_library 폴더에 있음

Intermezzo II: JavaScript와 DOM

     * JavaScript에서 HTML의 구성요소에 접근 및 수정하려면 Document Object Model(DOM) 을 활용해야 함
     * 이벤트 리스너(addEventListener) , 내장 연산자/함수 등으로 동적 UI 구현 가능
     * 예제를 위해 입력, 버튼, 결과 표시가 있는 기본적인 HTML/JavaScript 연동 구조 설명
     * script 분리/병합의 실전적 방법과 이슈(예: defer의 사용, DOM 요소 로드 순서)도 안내함

라이브러리 모듈화 및 로딩

     * WASM 라이브러리를 다중 포함하거나 Node.js/웹 양쪽에서 재사용하기 위해 MODULARIZE, EXPORT_NAME 옵션으로 모듈 형태로 빌드할 수 있음
     * .mjs (ES6 모듈) 확장자가 Node.js 호환성을 위해 추천됨
     * 웹/Node 양쪽에서 import MyLibrary from ... 식 모듈 사용 가능

멀티스레딩

     * WebAssembly에서 성능 강화를 위해 pthreads 기반 멀티스레드 코드 포팅 가능함
     * 함수 내 다수의 스레드를 생성해 병렬로 계산 작업(예: 소수 개수 세기) 을 실행함
     * 빌드시 -pthread, -sPTHREAD_POOL_SIZE= 옵션 필요함
     * 실제 브라우저에서는 Cross-Origin-Opener-Policy: same-origin, Cross-Origin-Embedder-Policy: require-corp와 같은 HTTP 헤더 추가 필요
     * 모든 예제는 저장소 03_threads 폴더에서 확인 가능함

Intermezzo III: Web Workers 및 Spectre

     * Emscripten 멀티스레드는 Web Workers로 구현됨(Web Workers는 별도의 프로세스이자 메시지 기반 통신 구조)
     * 공유 메모리(SharedArrayBuffer) 사용에는 보안 상의 제약이 존재
     * 2018년 Spectre 취약점 발생 후, 크로스 오리진 격리(cross-origin isolated) 요구사항 및 관련 헤더 필수화됨

메인 스레드 블로킹 주의

     * 긴 작업이 브라우저의 메인 UI 스레드를 BLOCK할 경우 사용자 경험이 급격히 저하됨
     * 이를 피하기 위해 웹 워커(Worker)를 도입: UI/입력 처리와 연산 처리를 명확히 분리
     * postMessage, onmessage로 메인-워커 간 이벤트 기반 통신 구현
     * 웹 워커 내에서 Emscripten-WASM 모듈을 불러 비동기 연산만 전담

콜백 함수

     * C 함수의 파라미터로 함수 포인터(콜백) 전달 시, 자바스크립트의 함수 객체와 자동 연동이 불가능함
     * Emscripten 제공 addFunction(), UTF8ToString() 등을 활용해야 하며, 빌드시 -sEXPORTED_RUNTIME_METHODS, -sALLOW_TABLE_GROWTH 옵션 추가 필요
     * 콜백은 반드시 메인 스레드에서만 호출되어야 안정적으로 동작함(웹 워커에서는 접근 불가)

영속적 스토리지

     * 사용자의 브라우저에 데이터를 영구 저장하기 위해 Emscripten의 IDBFS(IndexedDB 기반 파일 시스템) 를 사용함
     * 빌드시 --lidbfs.js 플래그와 **--pre-js ** 등으로 초기 세팅 필요
     * C 코드에서는 파일 입출력 함수(fopen, fread, fwrite)를 그대로 사용할 수 있으나, 실제 데이터 반영/동기화 처리는 반드시 JavaScript에서 명시적 매핑 및 싱크 처리가 필요함
     * 브라우저의 Sandbox/보안 정책 특성상, 로컬 파일 시스템 직접 접근은 Node.js에서만 가능하며, 브라우저에서는 IDBFS와 같은 백엔드를 활용해야 안전하게 영구 데이터 저장 가능함

결론

     * 본 튜토리얼 전 과정을 통해 복잡한 네이티브 C/C++ 코드를 최소한의 JavaScript와 HTML만으로도 안전하고 성능 저하 없이 브라우저 상에서 실행할 수 있는 실질적인 방법을 자세히 배울 수 있음
     * 실전 환경에서 멀티스레드, 콜백, 비동기 처리, 스토리지 연동까지 모든 핵심 트랙의 난관/해결책을 경험하고, 관련 설정 및 브라우저 제약사항 등 최신 트렌드도 익힐 수 있음
     * 제공되는 Git 저장소 예제를 참고하여 자체 프로젝트에 적용 및 확장 가능함

        Hacker News 의견

     * .js에서 .mjs로 확장자를 바꿨다는 점을 주목해줬으면 하는 바람, 사실 어느 확장자를 쓰든 문제에 부딪히는 현실에 대한 체감형 공감, dojo부터 CommonJS, AMD, ESM, webpack, esbuild, rollup 등 다양한 모듈 시스템을 써 왔던 입장에서 이 말에 정말 공감 100%라는 느낌
          + commonjs에서 esm으로의 전환이 마치 python2에서 python3로 넘어갈 때처럼 엄청난 변환이었지만, 기대에 비해 얻는 이점은 적고 번거로움만 가중된 인상, 많은 라이브러리들이 esm만 지원하는 경우가 많아져서 요즘은 npm의 'versions' 탭에서 최근 한 달 가장 다운로드 많이 된 버전을 골라 그게 마지막 commonjs 버전일 가능성이 높다는 현실, 분명 esm이 진보된 모듈 시스템이라 할 만하지만 tc39가 거의 의도적으로 commonjs와 호환이 안 되게(top-level await 등) 만든 부분은 정말 이해불가라는 솔직한 의견
          + js에서 모듈의 역사가 그야말로 트라우마에 가깝다는 생각, 이제 브라우저에 import maps까지 도입되어 앞으로 또 무슨 재미있는(?) 문제들이 생길지 궁금한 마음
          + 최근에 Function 객체가 런타임에 아무 JS 코드나 컴파일할 수 있음을 알게 되어서, 'import'도 쓸 수 없는 내 환경에서 일종의 생명줄 역할로 매우 유용하게 활용 중, JS 생태계에선 별로 필요 없을 수도 있지만 내겐 큰 도움이 됨을 강조
          + 그래서 모두가 bun.sh를 써야 한다는 주장
          + .esm.js도 쓸 수 있지 않느냐는 질문
     * 이 글에서 장기적으로 문제를 일으킬 수 있는 부분을 더 지적하자면, var 키워드 대신 let이나 const를 쓸 것을 추천, var는 여전히 동작하지만 요즘 JS 개발자들은 대부분 linter로 var 사용을 금지하는 분위기, var는 함수 스코프만 지원해서 대부분의 타 언어 개발자들이 언젠가 혼란을 겪는 포인트임, 네이티브앱 포팅 이슈로는 컴파일 타임에 Ctrl-C, Ctrl-V로 복사/붙여넣기를 하드코딩해서 리눅스, 윈도우에선 되지만 맥에서는 먹히지 않는 예시를 언급, 웹에서는 copy, paste 이벤트를 감지하는 식으로 처리해야 하며 Unity 같은 프레임워크도 하드코딩된 키 때문에 맥에서는 복붙이 안 되는 것을 목격, 대부분 게임에선 필요 없지만 복붙이 필요한 기능을 웹으로 내보낼 때는 꼭 문제가 되는 사례
     * 웹/NodeJS에서 멀티스레딩 너무 싫다는 푸념, mutex나 rwlock 같은 동기화 프리미티브로 값 자체를 context간(예:v8 isolates) 전송 가능하게 만드는 게 아니라, 실제론 거의 쓸 데 없는 SharedArrayBuffer만 도입된 점이 아쉬움, 스레드간 동기화는 결국 thunking과 데이터 복사를 RPC 레이어를 통해 하게 되는 구조, 우리 회사 프로덕션 앱은 70~100GB RAM을 쓰는 대형 앱(내가 만들기 전부터 그랬음)이라서, 네이티브코드 기반으로 메모리 페이지와 커스텀 데이터 구조를 직접 관리하면서 직렬화/해제 최소화하는 희한한 해결책을 찾고 있는데, v8은 문자열 인코딩이 utf16이라 네이티브 레이어에서 JS 값 다루기가 비쌈
          + 100GB RAM을 쓰는 이 앱이 진짜 웹앱이어야만 했는지 궁금, C# 같은 언어로 작성된 내부 툴이어야만 할 이유가 있는 것처럼 들리는 의문
     * 이 생태계가 혼돈에 가까워서 차라리 '마조히스트' 소리도 더 정상적으로 느껴지는 현실
          + 이미 혼돈이 내포돼 있다고 봐도 된다는 한 마디
     * 글 자체가 잘 쓰여진 점, 더군다나 어렵고 복잡한 루트로 시작한 선택에 놀라움, 프로젝트 세팅이 가장 힘든 부분임을 실감, 바로 보안/헤더 문제에 부딪힌 걸 칭찬하지만 종종 예상되는 문제는 CORS라는 의견, 우리 회사에서도 emscripten/C++으로 빌드 중이며 WebGPU/셰이더와 WebAudio까지 추가해 앞으로 더 빡센 여정이 예상
     * 예전엔 브라우저에서 코드 컴파일은 '느릴 것'이라 막연히 생각했지만 OP가 그렇지 않음을 잘 설명, Emscripten 프로젝트도 ""LLVM, Emscripten, Binaryen, WebAssembly의 조합 덕분에 출력물이 작고 거의 네이티브와 같은 속도로 동작""한다고 강조 (emscripten.org)
          + 오늘 나에겐 '옐로우버스 증후군'같은 하루, 지난 주까지만 해도 Emscripten을 몰랐는데, 프로젝트에 SDL을 붙이며 CMake에 APPLE, MSVC, EMSCRIPTEN 타겟이란 주석을 만났고, 바로 오늘 hn에서 Emscripten 이야기를 또 마주쳐서, 이제는 본격적으로 시간 내서 깊이 파봐야 할 시점이라는 다짐
          + ""거의 네이티브 속도""라는 표현이 상당히 주관적이라는 의문, 실제로 얼마나 빠른 건지 문서에서 수치 데이터를 못 찾음
     * 글이 유익했으며 본인도 C로 작성된 컴파일러를 웹어셈블리로 컴파일해 웹플레이그라운드로 만들고 싶다는 계획, 참고로 최신 브라우저는 자바스크립트를 통해 SQLite를 사용할 수 있는데, 이게 wasm에서도 가능한지 궁금, 만약 emscripten이 C 코드의 sqlite API 호출을 브라우저 sqlite db로 다리 연결해주면 너무 이상적일 것 같아 더 알아볼 가치가 있음
     * SSL에 왜 48번 포트를 썼는지 궁금, 특별한 이유가 있는지 질문
          + H48이라는 이름에서 따와 무작위로 정한 포트라는 답변, 이 웹앱은 추가 HTTP 헤더가 필요해서 사이트 전체에 영향 없이 구현하려고 간단히 다른 포트를 쓴 것이 원인, https://h48.tronto.net로 리다이렉트도 되고, 나중에 OpenBSD의 httpd와 relayd 세팅을 더 개선하거나 아예 별도의 도메인으로 옮기는 방안도 고민 중이라는 설명
"
"https://news.hada.io/topic?id=21412","Left-Pad (2024)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Left-Pad (2024)

     * left-pad 사건은 오픈소스 커뮤니티와 NPM, 그리고 기업 간의 규칙과 가치 충돌을 보여주는 대표적 사례임
     * 패키지 삭제 결정은 논리나 분노, 탐욕이 아닌 진심과 내적 원칙에서 비롯된 행동임
     * NPM이 Kik Messenger의 요구에 굴복하며 자신들의 규칙을 어긴 상황에서, 작성자는 모든 패키지 삭제를 선택함
     * 사건 이후 오픈소스에 대한 열정이 변화하며 사업, 마케팅, 팀 운영 등 새로운 분야로 관심이 이동함
     * left-pad 사건은 개발자, 스타트업 업계에 오픈소스의 본질과 의사결정의 복잡성을 다시 생각하게 하는 계기가 됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

사건의 배경과 결정

     * left-pad 사건이 일어난 지 8년이 지난 시점에서, 작성자는 개인적인 경험과 생각을 공유함
     * 사건 당시 대부분의 시간을 신호가 닿지 않는 자연 속에서 보내며 자기 성찰을 하였고, 패키지 삭제 결정도 이 과정에서 이루어진 선택임
     * 이 결정은 논리적 판단, 분노, 탐욕이 아니라 자신의 내면 원칙, 즉 ""NPM이 자신들의 규칙을 어긴다면, 내 모든 패키지도 지워져야 한다""라는 신념에서 시작됨
     * 엄격한 ""규칙주의자""라기보다는 규칙의 정신 자체를 더 중시하는 자세였음
     * Kik Messenger와 같은 기업이 오픈소스 커뮤니티에 위협을 가하고 힘을 행사하는 상황에서, NPM은 스스로 정한 규칙을 무시하며 기업 이익을 우선함

NPM과 커뮤니티의 갈등 구조

     * 작성자는 Kik의 위협을 두려워하지 않았지만, NPM은 Kik을 잃는 것을 두려워함
     * 사건을 단순히 ""분노한 남자가 대기업에 저항했다""고 해석하는 것은 사건의 맥락과 시간적 흐름, 결정의 무게를 간과한 단순화된 시각임
     * NPM 측은 갑작스럽거나 예상치 못한 일이 아니었음에도, 전반적으로 개발자에게 고압적인 태도를 보였으며, 일련의 부합되지 않는 결정들로 모든 책임을 작성자에게 전가함

패키지 구조와 영향

     * 작성자의 오픈소스 작업은 대부분 Unix 철학에 따라 작은 역할로 나뉘어 있어 350개 이상의 패키지로 구성됨
     * 표면적으로는 사용 흔적이 거의 없었지만, NPM이 사용 통계를 공개하지 않아 영향 범위를 파악할 수 없는 상황이었음
     * 사용자는 패키지 삭제의 실제 파급 효과를 알 방법이 없었고, NPM 역시 영향도 조사나 무분별한 삭제로 인한 문제 방지에 노력을 기울이지 않음

8년 후의 변화와 성장

     * left-pad 사건 몇 달 뒤에 본업을 그만두고 미국을 떠나, 모로코, 요르단, 튀르키예, 인도네시아 등 새로운 환경에서 자기만의 길을 찾아나감
     * 오픈소스에 대한 열정이 단절되는 죽음 같은 순간과 새로운 관심사로 다시 태어나는 순간을 경험함
     * 현재는 사업, 마케팅, 회사 및 팀 운영 등 다양한 분야에 프로그래밍과 동일한 열정으로 임함
     * 인생은 계속 이어진다는 메시지를 전하며, left-pad 사건은 자유로운 결정과 커뮤니티의 가치, 그리고 의사결정 과정의 복잡성을 되짚는 계기로 남았음

   영향이 컸던 사건이지만 패키지 작성자의 글을 읽지 않아도 그의 잘못보다는 얽힌 회사들과 시스템의 잘못이 크다고 생각합니다.

        Hacker News 의견

     * 솔직하게 말해 이 블로그 글의 절반은 무슨 말인지 잘 모르겠는 느낌, 뭔가 맥락을 놓친 기분이 드는 상황이지만 ""left pad guy""가 사건을 정리하는 점은 마음에 드는 포인트임
       그런데 다음과 같은 주장은 좀 이상하다는 느낌

     하지만 여전히 NPM이 내 모듈들이 얼마나 많이 쓰이는지 조사하고, 아무것도 깨지지 않게 unpublishing을 처리할 방법을 고민하지 않은 이유를 이해하지 못하겠음
     물론 NPM의 unpublish 방식이 잘못 설계된 것은 맞지만, 작성자가 말하는 건 누군가가 unpublish할 때마다 매번 수작업으로 확인해주길 기대했다는 의미로 느껴짐. 이런 기대감은 합리적으로 보이지 않음. NPM은 레지스트리를 큐레이션하는 조직이 아니라, 공공 서비스를 제공하는 주체라는 인식
     그래도 저자를 탓하긴 어렵다는 입장, ""left-pad incident""를 저자가 유발하지 않았다면 머지않아 누군가가 했을 일이었을 것으로 생각. NPM은 문제를 수정했고, 더 나은 unpublish 정책도 마련함
     NPM의 새로운 unpublish 정책 참고 정보로 제공
          +

     이 블로그 글의 절반을 이해 못 하겠다는 당신의 말
     원인은 당신이 아직 al-Ghazali를 읽지 않았기 때문이라고 생각.
     (이건 글에서 가장 거만하고 자기중심적인 부분임)
          + 참고 맥락은 Npm left-pad incident 위키피디아에서 확인 가능
          +

     2016년 3월 18일, npm의 CEO Isaac Z. Schlueter가 Kik Interactive와 Koçulu 양측에 이메일을 보내 kik 패키지의 소유권을 Kik Interactive로 수동 이전할 것이라고 알림
     Koçulu가 npm의 결정에 실망감을 표현하고 더 이상 플랫폼에 참여하고 싶지 않다고 말하자, Schlueter는 그에게 등록한 모든 273개의 모듈을 삭제할 수 있는 명령어를 제공
     Koçulu는 3월 22일 그 명령어를 실행해 본인이 올린 모든 패키지를 삭제
     저자는 NPM 측에서 직접 알려준 명령어를 실행했을 뿐인데, 이후 NPM은 이 책임을 모두 저자에게 돌렸음
          +

     NPM이라는 회사는 NPM 레지스트리를 큐레이션하지 않는다
     실제로는 큐레이션을 함, 대표적으로 보안 취약점 신고를 받고 사용자에게 알리거나, 악의적인 패키지를 삭제하는 역할
          + 예전에 Sourceforge를 사용했을 때는 프로젝트 삭제 전에 반드시 허락을 요청해야 했던 정책이 있었음
            left-pad 이후에 그 이유를 확실히 이해하게 됨
     * 사소한 얘기지만

     내 오픈소스 프로젝트는 대부분 유닉스 철학을 따라 패키지들이 한 번에 한 가지 일만 하도록 설계했음
     아무도 libc가 유닉스 철학에 어긋난다고 주장하지 않음. 논쟁은 종종 명령어나 데몬이 너무 많은 기능을 가지는지(systemd가 대표적 예시), 혹은 조합성이 떨어지는지 여부로 일어남
          + left-pad 사태는 NPM 패키지의 세분화가 지나치게 작아져서, 패키지 단순화의 이점보다 오버헤드가 훨씬 커졌음을 보여준 사례라고 생각
          +

     아무도 libc가 유닉스 철학에 어긋난다고 말하지 않는다
     오히려 많은 사람들이 그렇게 제안했고, 나 역시 그것이 맞다고 생각
     최신 libc는 전통적 유닉스 철학과는 전혀 다름
     예전의 libc는 더 단순했고, 여러 기능은 libm 등 별도 라이브러리로 분리됐으며 복잡한 DNS 등은 존재하지 않았음
          + 'do one thing'에 상반되는 점은, '온전히 한 가지 일을 다 해야 한다'는 것임
          + 유닉스 철학은 16비트 미니컴퓨터에서 강력한 대화형 프로그래밍 환경을 만들기 위한 지침
            현재 내가 휴대폰에서 쓰는 libc는 1MiB로, 전통적인 유닉스의 16배나 큼
            최소 90%의 libc가 유닉스 철학에 반한다는 결론
            Lions Book이나 APUE를 읽은 뒤 pthreads 매뉴얼이나 ANSI C setlocale() 명세를 보면 완전히 다른 철학임을 알 수 있음
            서로 다른 철학인데 같다고 여긴다면, 두 철학 어느 쪽에도 진지하게 공감 못 한다는 방증
          + ""유닉스 철학""은 쓸모 없는 철학, 심지어 해로울 수 있음
            왜냐면 'one thing'의 의미가 명확치 않아 실제로는 아무런 도움이 안 되고 논쟁만 유발
            Eclipse도 'IDE라는 한 가지 일'만 한다고 볼 수 있으나, 그게 유닉스 개발자들이 의도했던 바는 아님
            11줄짜리 함수만 있는 라이브러리를 만들라는 의미도 아님
            진짜 조언은 ""프로그램이나 라이브러리가 너무 많이도, 너무 적게도 하지 말자"" 정도여야 함
            어디까지가 많고 어디까지가 적은지 판단하는 것은 결국 경험과 감각의 문제
     * 이 글을 써준 akoculu에게 감사
       나는 이 사건이 자바스크립트 커뮤니티, 즉 의존성에 너무 많이 의존한 생태계의 명확한 사례라고 생각
       왜 많은 사람들이 너를 그렇게 탓하는지는 모르겠음
       11줄짜리 코드를 가진 패키지를 unpublish 했을 뿐이고, 그로 인한 부작용 자체를 완전히 예측하지는 못했을 것
       작성자가 글에서 직접 언급

     NPM도 사용 통계를 잘 보여주지 않았고, Github에도 거의 활동이 없는 상황
     사용자 입장에서는 패키지를 언퍼블리시하는 영향력을 알기 어려웠음
     근본적인 원인을 akoculu의 unpublish에서 찾기보다는 의존성 과잉, npm 정책, 빌드 시스템의 캐싱/벤더링 부족에 있다고 생각
     사건 배경 위키 참고
     * kik 패키지의 버전 히스토리가 이상함
       9년 전 보안 홀딩 패키지로 대체됐음
       kik 패키지 버전 히스토리
    이번 사건의 가장 큰 아이러니는 kik 패키지임
       kik가 그렇게까지 차지하고 싶어 했던 kik 패키지는 결국 아무 쓸모가 없음
       그리고 Kik라는 회사는 부주의하고 문제가 많은 곳으로 밝혀짐
       크립토 관련 논란도 있었고, 암암리에 아동 포르노 등의 유통 플랫폼으로 거론되는 회사라는 점
       Darknet Diaries 93화 참고
       그래서 Azer Koçulu가 Kik에 대해 단호하게 거절한 점이 오히려 통쾌함
       결국 이 모든 일이... 결국 아무 의미도 없게 됐다는 결론?
     * left-pad가 패키지로 존재한다는 자체가 꽤 웃긴 상황
       문자열 패딩 함수 하나 때문에 CDN, 프록시, 빌드파이프라인 등을 통해 어마어마한 바이트가 이동
       기존 솔루션을 잘 활용하는 것엔 동의하지만, 단순히 문자열 앞을 채우는 함수를 두고 ""아마 패키지가 있을 거야""라고 생각하게 된 상황은 이해하기 어려움
    당시 논쟁의 일부는 웹 개발자들의 마이크로 패키지에 대한 맹목적 집착을 일깨우는 계기였음
       인기, github star를 위해 패키지 릴리즈를 하는 문화도 있었음
       또 한편으론, npm으로 설치할 수 있는 것이면 어떤 함수든 직접 구현하지 않으려는 문화도 강했음
       현재 나와 함께 일하는 많은 개발자들도 여전히 간단한 패키지까지 선호하는 경우가 많음
       그들에게는 ""유지보수 부담이 줄어든다""는 논리
       참 아이러니한 현실
    패키지의 원래 구현 또한 O(n)이 아니라 O(n^2)의 비효율 연산을 유발할 것으로 보임
       위키 참고
    타인의 프로젝트 내 유틸리티 함수를 참고하는 것과, 생태계 전체에 이미 퍼져 있는 패키지를 사용하는 것 사이에 품질상의 큰 차이가 있을까?
       같은 건 아니지만, 충분히 발전한 툴링을 가진 환경에서 두 접근이 실제로 그리 멀지 않다고 생각
    최대한 코드 재사용을 추구하는 현상, copy-paste는 한물간 방법이라는 강박
       혹시 이거 AI와 비슷한 상황 아닐까?
       단순 검색으로도 풀 수 있는 문제를 무수히 많은 프롬프트와 함께 AI에게 또 물어보는 현실
       C&P에 불필요한 단계를 하나 더 얹은 구조
     * 유닉스 철학은 ""한 가지 일을 잘 하자""
       left-pad는 두 번째 조건(잘 하자)을 놓침
       이렇게 많은 프로젝트가 순진한 구현을 그대로 쓴 점이 놀라웠음
       더 최적화된 구현이 더 빠르고 더 작을 수 있음
    자바스크립트 문화를 잘 모르긴 하는데, npm 다운로드 수를 경쟁적으로 늘리는 풍조가 존재했던 것으로 기억
       left-pad는 주간 140만 다운로드, is-even은 16만 다운로드
       어떤 이들은 장난삼아, 어떤 이들은 라이브러리의 인기 지표를 올리려고 마이크로 패키지를 의존성에 추가
       react 기반의 유명한 라이브러리 내부에 is-even 같은 패키지를 넣는 것에 대해 반대하는 목소리도 있었음
       ""직접 작성할 수 있는 코드라도 무조건 가져와라""는 식의 엄격한 원칙 때문
       관련 스토리: is-odd 패키지가 일주일간 3백만 번 설치된 이유
       '비순진적 구현(nonnaive implementation)' 예시가 궁금
     * npm 인기 패키지 메인트레이너임
       정말 공감할 수 있음
       npm은 어느 순간부터 커뮤니티 협업에서 멀어지기 시작
       마이크로소프트에 인수되며 더욱 견고해졌지만, 그 이전부터도 징후가 많았음
       npm의 여러 운영 방식, 커뮤니티/Node 팀과 비협조적이던 태도, 상업화에만 치중한 모습, 일부 구성원의 평판 등 여러 모로 거슬리는 점이 많았음
       Oakland 사무실 방문했던 기억이 있는데, 그랬던 날의 상호작용은 그리 긍정적이지 않았으므로 상세하게 말하진 않겠음
       unpublish 허점은 당시 모두가 인지하고 있던 문제였음
       모두 'left-pad가 인터넷을 망쳐놨다'는 식으로 저자만 탓했지만, 실제로는 npm 부실 운영 문제가 더 컸다고 생각
       기억이 맞다면, 메인터이너 본인 의사에 반해 패키지를 강제로 복구시켰고, 이는 npm이 자신들이 대변한다는 커뮤니티 수준에서 완전히 분리된 조치(최소한 법적으로도 이상함)
       이후 npm은 abuse, 스팸 등 관리에 관심을 거의 두지 않았고(core.js 광고 스팸 등), 커뮤니티와의 표준, 호환성 논의도 거의 안 했음
       npm@5 릴리즈도 대실패, 패키지 락파일 도입도 난리였음
       (Node 팀이 npm 준비를 기다리지 않고 출시한 것도 오히려 좋은 판단으로 봄)
       그 시점 커뮤니티와의 소통은 대형 버그, 커뮤니티 탓, 고압적 태도 등으로 엉망
       npm이 더 이상 오픈소스 정신의 대변자가 아니게 된 방증
       left-pad가 그 전이었는지 후였는지 기억이 가물가물하지만, 당시 생태계 전체가 장기적인 침체와 혼란기였음
       npm 패키지는 사소한 함수로도 독립 패키지(밈)처럼 여겨지지만, 맥락을 생각해보면 npm은 emergent popular technology(새롭게 떠오르는 기술)에 대한 최초의 접근성 높은 패키지 매니저였고, 커뮤니티 주도로 운영되며, Github와도 유기적으로 통합된 시스템이었음
       Node 초기(ES5도 없고 var, prototype 쓰던 시절), Joyent가 Node.js를 커뮤니티에 넘기기도 전, Io.js 포크 및 Node 0.10/0.12의 장기 정체기 이전이었음
       모두가 모범 사례가 뭔지 잘 몰랐던 시기
       저자의 입장에 정말 공감
       보안 관점에서 보면, left-pad 사건은 의도와 다르게 생태계 내 기업들/공동체가 분리된 현실과 공급망 보안에 대해 큰 각성을 준 사건
       중복성 강화와 보안에 관한 중요한 논의를 촉발시켰음
       업계가 결과적으로 더 나아지는 계기였다고 생각
       오랜만에 읽어보니 흥미로움
       npm은 어떤 언어의 최초 패키지 매니저가 아니었고, 이렇게 작은 패키지들이 많다는 점에 이미 많은 사람이 경고를 했었음
       npm과 JS 생태계 전반이 유행(trend)의 희생양이라는 생각
     * left-pad 당시의 관련 토론
       Hacker News 논의
     * 왜 Java는 Apache Commons, Google Guava처럼 신뢰받는 유틸리티 라이브러리가 있는데 JS는 그런 게 없을까?
    자바스크립트에도 Lodash 같은 신뢰되는 유틸리티 라이브러리가 존재. 과거에 비해 대부분의 기능은 이제 표준 라이브러리에 탑재
       사실 Lodash는 left-pad 사건 3개월 전부터 pad/padStart/padEnd 기능을 제공
       Lodash pad 문서
    가장 중요한 원인은 문화, 그리고 잘 짜인 표준 라이브러리, 그리고 300개 넘는 쓸모없는 패키지를 의존성에 쑤셔넣는 걸 방지하는 도구의 유무 순서라고 생각
    Maven은 정말 잘 설계된 도구(아이러니하게도 늘 욕만 먹지만), Java가 성공한 비밀 요인
       npm 같은 상업적 타협이 없는 이유는, Java에는 잘 지원되는 비영리·커뮤니티 기반의 Apache Foundation이 존재(이런 구조는 매우 드물고, Java 복잡한 법적 역사 덕분에 생겨난 운 좋은 결과)
       (JS에도 훌륭한 라이브러리는 많음. 문제는 패키지 관리가 지나치게 중앙집중화되고 관리가 부실했던 점)
    Google Guava는 lodash에 더 가깝고, left-pad와는 다름
       예전에는 Jquery, Underscore 같은 라이브러리가 그 역할을 해줬음
     * 빌드에 필요한 모든 의존성을 사내에서 미러링하지 않는 회사들이 너무 신기하게 느껴짐
       빌드 과정 전체를 오프라인에서 클린빌드할 수 있어야 하고, 다운로드 캐시에만 의존하는 건 운에 맡기는 꼴
       내 프로젝트는 언제나 dependencies를 내부에 벤더링
       예측 가능하고 오프라인으로도 빌드 가능, 저장 공간 비용도 저렴함
"
"https://news.hada.io/topic?id=21343","저수준 최적화와 Zig","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              저수준 최적화와 Zig

     * 저수준 최적화는 Zig 언어에서 손쉽게 구현할 수 있음
     * 컴파일러가 대부분 상황에서 최적화를 잘 수행하지만, 때로는 프로그래머의 의도를 명확히 전달해야 더 나은 성능을 얻을 수 있음
     * Zig는 컴파일 타임 실행(comptime) 기능으로 고성능 코드 생성과 강력한 메타프로그래밍을 지원함
     * 러스트와 비교할 때, Zig는 어노테이션과 명시적인 코드 구조로 더 정밀한 최적화 가능
     * 문자열 비교 등 반복적인 연산에서 comptime을 활용해 평범한 함수보다 뛰어난 어셈블리 코드 생성 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

최적화와 Zig

   ""모든 것이 가능하지만 흥미로운 것은 쉽게 얻을 수 없다.""라는 유명한 경고처럼, 프로그램의 최적화는 언제나 개발자의 주요 관심사임. 클라우드 인프라의 비용, 레이턴시 개선, 시스템 단순화 등을 위해 코드 최적화가 반드시 필요함. 이 글에서는 Zig에서의 저수준 최적화 개념과 Zig의 강점을 중점적으로 설명함.

컴파일러를 신뢰할 수 있을까?

     * 일반적으로 ""컴파일러를 신뢰하라""는 조언이 많으나, 실제로는 컴파일러가 기대와 다르게 동작하거나 언어 사양을 위반하는 경우가 있음
     * 고수준 언어는 의도(intent) 를 명확히 전달하기 어렵기 때문에 성능상의 제약이 따름
     * 저수준 언어는 코드의 명시성 때문에 컴파일러가 최적화에 필요한 정보를 알 수 있으며, 예로 JavaScript와 Zig의 maxArray 함수를 비교하면 Zig가 명확한 타입, 정렬, alias 여부 등을 런타임이 아닌 컴파일 타임에 전달함
     * 동일한 maxArray 연산을 Zig와 Rust로 작성하면 거의 동일한 고성능 어셈블리 코드를 얻게 되지만, 의도를 더 잘 표현할수록 최적화 결과가 향상됨
     * 하지만 항상 컴파일러 성능을 신뢰할 수 없으므로, 병목 구간에서는 코드와 컴파일 결괏값을 직접 확인하고 최적화 방법을 모색해야 함

Zig의 역할

     * Zig는 정확한 명시성과 풍부한 내장 함수, 포인터와 어노테이션, comptime, 잘 정의된 Illegal Behavior 등의 특성으로 인해 추상적인 정보 없이도 최적화된 코드를 만들 수 있음
     * Rust는 메모리 모델 덕분에 기본적으로 인자 alias가 없음이 보장되지만, Zig에서는 직접 noalias 등 어노테이션 필요
     * 만약 LLVM IR만을 기준으로 한다면 Zig의 최적화 수준도 높음
     * 무엇보다 Zig의 comptime(컴파일 타임 실행) 이 강력한 최적화 도구임

comptime이란 무엇인가?

     * Zig의 comptime은 코드 생성, 상수 값 임베딩, 타입 기반 제네릭 구조체 생성 등에 활용되며, 런타임 성능 향상에 중요한 역할을 함
     * comptime으로 메타프로그래밍을 구현할 수 있음
     * C/C++의 매크로나 Rust의 macro 시스템과 달리, comptime은 별도의 문법이 아닌 일반 코드임
     * comptime 코드는 AST를 직접 변경하지 않고, 모든 타입에 대해 컴파일 타임에 검사, 반영, 생성 가능함
     * comptime의 유연성은 Rust 등 여타 언어 개선에도 영향을 미쳤으며, 자연스럽게 Zig 언어에 통합되어 있음

comptime의 한계

     * token-pasting과 같은 일부 macro 기능은 Zig comptime으로 대체 불가
     * Zig는 코드의 가독성을 중시하기 때문에 범위를 벗어나서 변수 생성이나 매크로 정의 등은 허용하지 않음
     * 대신 Zig comptime은 타입 리플렉션, DSL 구현, 문자열 파싱 최적화 등 폭넓은 메타프로그래밍 활용 예시가 존재함

comptime을 활용한 문자열 비교 최적화

     * 일반적인 문자열 비교 함수를 모든 언어에서 구현할 수 있으나, Zig에서 두 문자열 중 하나가 comptime에 알려진 상수일 때 더 효율적인 어셈블리 코드 생성 가능
     * 예를 들어, 한 문자열이 늘 ""Hello!\n""이라면 이 값을 바이트 단위가 아닌, 더 큰 블록 단위로 비교하는 식의 최적화 활용 가능
     * 이를 위해 comptime을 사용하면, SIMD 벡터, 블록 처리, 잔여 바이트 최적화 등 고성능 코드를 컴파일 타임에 생성 가능
     * 이런 방식을 통해 반복적인 문자열 비교뿐 아니라, 정적 데이터 기반 다양한 맵핑, 완벽 해시 테이블, AST 파서 등 다양한 성능중심 코드 구현 가능

결론

     * Zig는 저수준 최적화에 매우 적합하며, 명시적 코드 구조와 강력한 comptime 기능 덕분에 최고의 성능을 직접 구현할 수 있음
     * Rust 등 다른 언어와 비교해도, Zig의 컴파일 타임 프로그래밍 능력과 명시성은 고성능 소프트웨어 개발에 큰 이점으로 작용함
     * Zig의 최적화 능력은 앞으로도 더욱 중요한 경쟁력이 될 것임

        Hacker News 의견

     * zig에서 가장 흥미롭게 느끼는 부분은 빌드 시스템의 간편함, 크로스 컴파일, 그리고 높은 반복 속도 추구임. 나는 게임 개발자이기 때문에 성능이 중요하지만 대부분의 요구사항에 대해서는 대부분의 언어들이 충분한 성능을 제공함. 그래서 언어 선택의 최우선 기준은 아님. 어떤 언어로든 강력한 코드를 쓸 수 있지만, 수십 년 동안 유지보수할 수 있는 미래지향적인 프레임워크를 목표로 함. C/C++가 어디서나 지원되는 점에서 기본 선택지가 되었지만 zig도 그만큼 따라올 수 있을 것으로 느낌
          + 재미로 아주 오래된 Kindle 기기(Linux 4.1.15)에 zig를 돌려봤는데 zig의 완성도에 놀라운 경험을 함. 대부분이 바로 작동했고, 오래된 GDB로도 이상한 버그를 디버깅할 수 있었음. 나도 zig에 매료됨. 자세한 경험은 여기에서 확인 가능
          + 대부분의 언어로 강력한 코드를 쓸 수 있다고 느끼지만, 수십 년을 내다볼 수 있는 모듈러 코드를 원함. Zig를 좋아하지만, 장기 유지보수와 모듈성 측면에서는 단점이 있다고 생각함. Zig는 캡슐화에 적대적인 언어임. 구조체 멤버의 private 처리가 불가능함. 이 이슈 코멘트가 예시임. Zig의 입장은 내부 표현이란 게 따로 존재하지 않아야 하며 모든 사용자가 내부 구현을 알 수 있게 문서화/공개해야 한다는 것임. 하지만 API 계약, 즉 모듈러 소프트웨어의 핵심을 지키려면 내부 구현을 감출 수 있어야 하고, 그것이 불가능함. 언젠가는 Zig가 private 필드를 지원해 주길 바람
          + Rust를 가볍게 사용해봤는데 마음에 들었음. 하지만 '나쁘다'는 얘기를 듣고 한동안 멈췄다가 다시 써보는 중임. 여전히 좋음. 사람들이 왜 그렇게 싫어하는지 잘 모르겠음. 못생긴 제네릭 문법은 C#과 Typescript도 마찬가지임. 빌림 검사기(Borrow Checker)도 저수준 언어 경험이 있으면 이해하기 쉬움
          + Zig는 더 단순한 Rust, 그리고 더 나은 Go같은 느낌임. 한편 zig 위에 만들어진 도구 중에서 'bun'을 정말 감탄할 정도로 좋아함. bun 덕분에 삶이 엄청 간편해짐. Rust 기반의 'uv'도 비슷한 경험을 줌
          + C/C++가 기본이라는 점에 동의함. C보다 더 나은 무언가를 만들려고 해봐야 대부분 결국 C++이 되고 말았음. 그래도 시도는 멈추지 않아야 함. Rust와 Zig가 아직도 더 나은것을 기대하게 만드는 증거임. 난 지금부터 C++를 더 배워볼 예정임
     * 최첨단 컴파일러들이 언어 스펙을 깨뜨릴 때가 있다고 해도, Clang의 무한루프 종료 가정은 C11 이후 표준에 따르면 맞는 것임. C11에서는 다음과 같이 명시됨. ""제어식이 상수 표현이 아니고, 입출력/volatile/sync/atomic 연산도 하지 않는 반복문은 컴파일러가 종료된다고 가정할 수 있음""
          + C++에서는(향후 C++26 전까지) 모든 루프에 해당 규정이 적용되지만, 말씀하신 대로 C 언어에서는 ""제어식이 상수 표현이 아닌 반복문""에만 해당됨. 즉, for(;;); 같은 명백한 무한 반복문은 실제로도 무한루프가 되어야 하고, Rust의 loop {} 역시 같아야 함. 그런데 LLVM 개발자들이 종종 자신들이 C++ 컴파일러만 만든다고 착각해서, Rust에서는 ""무한루프 부탁드립니다"" 해도 LLVM이 ""C++ 기준으로는 그런 일 없으니 최적화!""를 적용시켜 문제 발생. 잘못된 언어에 잘못된 최적화가 적용된 셈임
     * 컴파일타임(comptime) 기능이 없어서 문자열 비교를 인라인, 언롤하는 것은 C에서도 충분히 가능함. 관련 예시
          + 지적이 맞음! 처음 예시는 너무 단순했음. 더 좋은 예시는 컴파일타임 서픽스 오토마톤이 있음. 또, 위에 링크한 godbolt 코드는 오히려 하지 말아야 할 두 가지 사례 중 하나를 보여주고 있음
     * 예시로 든 JavaScript 코드가 V8에서 생성된 바이트코드가 비효율적이라고 한 부분은 좋은 비교 예시가 아니라고 생각함. Zig와 Rust에는 아주 최신 환경을 지정해서 컴파일하라고 하면서, V8은 그런 최적화 옵션을 강제하지 않음. 사실 현대 JIT들도 상황만 허락한다면 벡터화 가능함. 그리고 대부분 현대 언어들도 문자열 관련한 최적화는 비슷하게 처리함. 참고로 C++의 예시도 있음
          + 사실상 JS와 Zig를 비교하는 건 사과와 과일 샐러드를 비교하는 격임. Zig 예시는 타입과 크기가 고정된 배열을 썼는데, JS는 런타임에 다양한 타입이 들어가는 'generic' 코드임. 이 때문에 JS에서는 타입 정보 제공만 잘하면 JIT이 훨씬 빠른 루프를 만들어냄(비록 벡터화까진 아니더라도). 실제론 TypedArray를 자주 쓰진 않는데, 초기화 비용이 크기 때문이고, 재사용이 잦을 때만 쓸만함. 또 글에서는 JS 코드가 부풀려졌다고 했지만, JIT이 어레이 길이 체크를 못 믿어서 가드를 넣는 경우가 크고, 실제로는 누구나 i < x.length 같은 루프를 써서 JIT 최적화가 됨. 그런 점에서 조금은 트집이지만, 미세한 차이이긴 함
          + Rust와 Zig의 godbolt 예제를 더 오래된 CPU로 타겟 변경도 가능함. JS 쪽 타겟 제한은 생각을 못했음. 그리고 C++의 예시는 clang이 얼마나 좋은 코드를 내는지 보여주는 사례임. 다만 현조차로는 assembly가 썩 만족스럽지는 않음(zig가 특정 CPU 타겟으로 빌드되는 걸 감안해도). 컴파일타임 Suffix Automaton의 C++ 포팅 예시도 있다면 정말 흥미로울 듯. 이건 C++ 컴파일러가 추측 불가능한 comptime의 실제 활용 사례임
     * ""하이레벨 언어는 저수준 언어가 갖고 있는 'intent'가 부족하다""는 말에 의문임. 오히려 더 다양한 방식으로 상세하게 의도를 표현하는 게 하이레벨 언어의 장점이라고 봄
          + 나도 동의함. 근본적으로 하이레벨 언어와 로우레벨 언어의 차이는, 하이레벨 언어에선 의도를 표현하고 로우레벨에선 구현 메커니즘 그 자체를 드러내야 한다는 차이임
          + 여기서 '의도'란 ""이 구매의 세금 계산""같은 업무적 의도가 아니라, ""이 바이트를 왼쪽으로 세 칸 쉬프트""하는 식의, 컴퓨터에 무엇을 시키는가에 가까움. 예를 들어 purchase.calculate_tax().await.map_err(|e| TaxCalculationError { source: e })?; 같은 코드는 의도가 가득하지만, 실제로 머신 코드가 어떻게 나올지는 예측이 불가임
     * Zig의 allocator 모델이 정말 마음에 듦. Go에서 GC 대신 요청별 allocator 같은 것을 쓸 수 있으면 좋겠음
          + Go에서도 커스텀 allocator와 arena가 불가능하지는 않으나, 사용성이 매우 떨어지고 적절히 쓰기 힘듦. 언어 차원에서 소유권(ownership) 규칙을 표현하거나 강제할 방법도 없음. 결국 문법만 살짝 다른 C를 쓰는 꼴이고, GC 없으면 C++보다도 위험한 셈임
     * ""Zig의 장황함(verbosity)이 마음에 든다""는 말은 공감하지만, 솔직히 조금 어감이 이상함. C는 여기저기 허술한 반면, Zig는 반대로 너무 많은 '주석 소음(annotation noise)'를 요구하는 경우가 많은 편임(특히 수학식에서 명시적 정수 캐스팅 시). 관련 글 참고. 성능 측면에선 zig가 c보다 빠른 경우는 주로 Zig가 더 공격적인 LLVM 최적화 세팅(-march=native, 전체 프로그램 최적화 등) 때문임. 사실 C에서도 unreachable 같은 최적화 힌트는 언어 확장으로 가능하고, Clang도 상수 폴딩에 매우 적극적임. 즉, Zig의 comptime과 C의 코드젠 차이는 컴파일러 최적화 세팅에서 비롯된 경우가 많음. TL;DR: C가 느릴 땐 컴파일러 설정을 먼저 점검해야 함. 어차피 최적화의 핵심은 LLVM임
          + 캐스팅 부분 예시라면, 오히려 함수를 하나 만들어서 캐스팅을 감싸는 식으로 코드 재활용성과 의도를 높여줄 수 있음
fn signExtendCast(comptime T: type, x: anytype) T {
  const ST = std.meta.Int(.signed, @bitSizeOf(T));
  const SX = std.meta.Int(.signed, @bitSizeOf(@TypeOf(x)));
  return @bitCast(@as(ST, @as(SX, @bitCast(x))));
}
export fn addi8(addr: u16, offset: u8) u16 {
  return addr +% signExtendCast(u16, offset);
}

            이 방식도 똑같은 어셈블리로 나오고, 활용도 높고 명확함
          + Zig의 아이디어들이 흥미롭고, 원래 기사에서 기대했던 것보단 컴파일타임(comptime)과 전체 프로그램 컴파일에 더 무게가 실려 있었음. 이에 공감함. 참고로 Virgil은 2006년부터 컴파일타임 전체 언어 활용, 전체 프로그램 컴파일 지원을 했음. Virgil은 LLVM 타겟팅은 아니므로 속도 비교는 결국 백엔드 비교임. Virgil은 이 접근법 덕에 메서드 호출을 미리 정적으로 결합(devirtualize), 안 쓰는 필드/객체도 최대한 제거, 필드-힙 객체까지 상수 전파, 완벽하게 특수화 등 매우 강한 최적화가 가능함
          + 향후 AI 활용을 생각하면, 점점 더 명시적이고 장황한 언어들이 대세가 될 것 같음. AI로 코딩을 하냐, 그게 옳으냐를 떠나 많은 개발자들이 AI의 도움을 선호하게 되면서 언어들도 그에 맞춰 변할 것임
          + 새 x86 백엔드가 도입된다면, 앞으로는 C와 Zig의 성능 차이가 Zig 프로젝트 자체에 기인하는 사례도 볼 수 있을 것 같음
          + 명시적 integer 캐스팅 관련해서, 곧 좀 더 깔끔해지는 개선이 나올 예정임. 관련 논의 참고
     * ""C가 Python보다 빠르다"" 같이 언어 그 자체로 벤치마킹하는 건 맞지 않지만, 언어의 일부 기능이 최적화에 큰 장벽이 되기도 함. 적절한 언어를 쓰면, 개발자와 컴파일러 모두 자연스럽고 빠른 방식으로 의도를 표현 가능함
     * Zig의 for loop 문법이 너무 난잡하게 느껴짐. 리스트 두 개를 나란히 놓고 위치를 맞춰야 한다니, 보기만 해도 눈이 아픔. 근래 언어들이 너무 많은 '매직' 문법과 특수 기호를 쏟아붓는 게 실수라고 봄. 몇 시간 동안 들여다보고 있기 힘들 것 같음
          + 이런 배열 두 개를 순회하는 패턴은 저수준 코드에서 매우 흔하고, 병렬로 순회하는 것도 마찬가지임. 그래서 Zig가 이를 명확하고 자연스럽게 지원하는 게 오히려 적절하다고 봄. 왜 그게 눈이 아플까 궁금함
     * 최적화는 매우 중요함. 그 효과는 시간이 지날수록 더욱 커짐
          + 다만, 그 소프트웨어가 실제로 쓰이기 전제하에 해당하는 얘기임
"
"https://news.hada.io/topic?id=21394","OpenAI가 o3 가격을 80% 인하함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         OpenAI가 o3 가격을 80% 인하함

     * OpenAI가 o3 모델의 가격을 80% 인하함
     * 이번 가격 인하로 인해 스타트업과 IT 업계에서 o3 활용 비용 부담이 크게 줄어듦
     * AI 서비스 개발자들에게 보다 경제적인 선택지 제공함
     * 시장 경쟁 심화와 더 빠른 AI 도입 환경 조성 기대함
     * 모델 활용이 활발해지며 생태계 확장 가속화 전망임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

OpenAI o3 가격 80% 인하 소식

     * OpenAI가 o3 모델의 가격을 기존 대비 80% 낮추는 정책을 발표함
     * 이로 인해 스타트업, 중소기업, 개인 개발자는 한층 더 낮은 비용으로 o3 모델의 API를 이용할 수 있게 됨
     * AI 활용 진입장벽이 낮아지면서 다양한 AI 애플리케이션과 서비스 개발 가능성 높아짐
     * 이번 가격 정책은 AI 시장 내 경쟁을 촉진하며, 빠른 기술 확산에 이로운 환경 조성 역할을 함
     * 향후 딥러닝 알고리듬 효율화 및 대규모 AI 서비스 개발에 있어 비용 절감 효과로 추가적인 혁신 견인 가능성 확인됨

        Hacker News 의견

     * 내 경험을 바탕으로 하나의 주의점을 공유하고 싶음. OpenRouter에서 이미 크레딧이 있어 o3를 활성화해보려고 했으나 ""OpenAI는 o3 API 사용 시 직접 API 키를 제공해야 한다""는 메시지가 나옴. 그래서 OpenAI 계정으로 API 크레딧을 20달러 구매하고, 새로운 API 키와 o3 모델로 Aider를 시작했음. 요청을 보내니 ""조직이 검증되어야 o3를 사용할 수 있다, 조직을 검증하려면 링크의 Verify Organization을 클릭하라""는 에러가 발생함. 점점 짜증이 밀려왔고, OpenAI로 돌아가 Verify Organization을 클릭하니 실제로는 본인 신원을 제3자인 Persona로 검증해야 했음. ""Start ID Check""를 클릭하면 Persona의 개인정보 및 생체정보 수집, 사용, 그리고 그 데이터는 1년간 보관한다는 안내가 뜸. 단순히 API액세스에 몇 달러를 쓰려다 갑자기 본인 생체정보를 세계 최대 AI회사와 파트너 업체에게 제공하라는
       요구까지 오게 된 것임. 환불은 어떻게 받아야 할지 모르겠음
          + 나도 이전에 다른 AI 회사에 환불을 못 받아서 캘리포니아 주 법무부에 연락해 환불을 해결한 적 있음. 이런 식으로 결제 이후 추가 요구사항을 들이밀지 못하게 우리가 바로잡아야 한다고 생각함. 그리고 개인정보로 이미 이름, 주소, 카드 정보를 받고 있는데 왜 전화번호도 요구하는지 궁금함. 혹시 모두에게 전화번호를 받는 이유를 아는 사람 있는지 질문하고 싶음
          + Sam Altman이 실제로는 신원 확인을 위해 생체 정보를 수집하는 암호화폐 회사(Worldcoin)를 운영하고 있지 않나 하는 의문이 듦. 익숙한 느낌임 Worldcoin 정보
          + 최근 한 달 내에 거의 똑같은 사연을 본 것 같아 데자뷔를 느끼거나, 아니면 뭔가 더 있는 게 아닐까 싶음
          + 사실 신원 확인이라도 시도할 수 있는 당신이 오히려 행운이라고 생각함. 나는 몇 달간 ""세션 만료"" 에러만 뜨고 지원팀은 답장하지도 않음
          + 동일 시기에 KYC(고객신원확인) 요구와 OpenAI가 모든 로그를 저장한다는 점이 함께 나타나는 상황임
     * 요즘 OpenAI가 ""게을러졌다""고 느껴짐. 질문을 해도 전체 파일이나 수정사항을 직접 주지 않고 ""이렇게 해야 한다""고만 하고, 실제로 해달라고 2~3번 정도 더 요청해야 실행함. deepseek에서는 이런 현상을 보지 않음. 리소스 절약을 위해 이렇게 답변하는 건지도 궁금함
          + OpenAI 직원임. 우리의 모델이 때때로 게으를 수 있음. 의도된 게 아니고, 앞으로 더 나아질 모델을 제공할 예정임. Netflix에서 일할 때도 낮은 품질의 추천을 의도적으로 하냐는 비슷한 의혹이 있었는데, 실제로는 제품 완성도가 그리 쉽게 오르지 않기 때문임. 결국 완벽한 제품을 만드는 건 정말 어려운 일임
          + 최근 화학 계산 관련해서 ""X 대 Y 그래프 만들어줘""라고 했더니 답변이 설명만 장황하게 하고 ""그래프 필요하면 말해줘!""로 끝내는 경우가 있었음. 뭔가 웃김
     * 어떻게 우리가 o3 모델이 quantized(정밀도 낮춤) 버전이 아닌지 알 수 있을지 의문임. 업체들이 벤치마크 결과만 좋게 발표해놓고 실제로는 점차 quantize(Q8에서 Q6, Q4 등)해서 성능을 떨어뜨릴 수도 있겠다는 생각이 듦. gpt-4-turbo가 빠르게 출시된 것도 이런 방식 때문이 아닐까 의심함. 실제 사용해보면 오리지널 GPT-4보다 별로였고, 아마도 turbo와 4o 등에서 벤치마크만 집중한 것 같음. 사용자들이 실제론 더 별로인데도 더 좋은 듯 인식함
          + 이게 실제로 업체들이 하는 방식일 것이고, 오리지널 o3를 o3-pro로 리브랜딩했다고 생각함
          + 언제나 새로운 모델이 처음엔 잘 나오다가 점점 결과가 나빠지는 것 같음. 예전엔 나쁜 출력 결과를 fine-tuning으로 제거하려다 성능까지 하향조정했다고 생각했는데, 이제는 quantizing 때문이 아닐까 더 의심하게 됨
          + OpenAI에서 일하는데, 모델은 동일하고 quantizing이나 꼼수 쓰지 않았음. API에서 개발자들에게 예고 없이 모델을 바꾸는 일은 절대 없음. ChatGPT에서는 사용자들에게 버전 넘버를 계속 노출하는 것이 번거로워서 좀 덜 명확하게 업데이트되긴 하지만, 그래도 완전히 조용히 바꾸는 건 아님. ChatGPT Release Notes에 모든 모델업데이트를 공개함. 단, chatgpt-4o-latest 포인터만 예외적으로 미리 알리지 않고 바꿈
          + 공식 발표 메일에서 ""OpenAI o3 가격을 80% 인하해서 입력 100만 토큰에 2달러, 출력 100만 토큰에 8달러로 낮췄고, 인퍼런스 스택만 최적화해서 동일 모델이지만 더 싸짐""이라고 설명함
          + 발표 직후 o3에서 초당 700개 이상 토큰 속도가 나오길래, 정말 quantized 버전 아닌지 의심됨 관련 링크
     * ChatGPT Plus 사용자에게 o3 관련 주간 메시지 할당량도 같이 증가했는지 궁금함. 실제 내 경험상 o4-mini와 o4-mini-high는 유용성에서 o3에 한참 못 미치는데, o3는 속도 제한(limited rate) 때문에 주로 o4-mini 시리즈만 쓰게 됨. 이런 구조 자체가 ""OpenAI의 사고(think) 모델이 경쟁 대비 뒤처진다""는 인상을 더 강화함
          + 나도 o3의 꽤 심한 속도 제한을 경험했고, o4-mini-high는 꽤 좋다고 느꼈지만, 확실히 o3를 훨씬 더 쓰고 싶음. 이 발표로 할당량도 늘어났으면 함
     * Google도 AI 쪽에서 빠르게 따라잡고 있음. 불과 몇 달 전만 해도 DeepSeek이 대세였는데, 이 분야가 정말 빠르게 진화하는 중임
          + 많은 사람들의 인식에서 Google Gemini 모델이 SOTA(State Of The Art, 최고 성능)라는 평이고, 코딩 태스크에서는 Claude도 꽤 잘한다고 봄
          + 최근 몇 달간 Google의 모델만 써왔는데, ChatGPT가 이제는 너무 사근사근하고 빈약하다고 느낌. 처음이나 끝뿐 아니라 답변 중간에도 빈 말만 많고, 실질적인 정보는 적음. 스타일을 바꿔달라고 요구하면 기술어만 남발하는 경향도 보임
          + Deepseek를 사람들이 기대했던 건 직접 모델을 다운로드 할 수 있었기 때문임. 하지만 Gemini 2.5 이래로 3등 자리에서 크게 벗어나지 못한 듯함
     * OpenAI가 왜 o3 사용을 위해 ""조직"" 인증(주정부 신분증 요구)을 하는지 이해가 안 감
          + 시도조차 할 필요 없다는 조언을 드리고 싶음. 많은 사람들이 검증 절차에 실패했고, 두 번째 기회도 없다는 피드백이 많음 사례1 사례2 사례3 사례4 사례5 사례6 사례7
          + Deepseek R2가 OpenAI 모델에 학습되지 않도록 하기 위한 목적도 있지 않을까 하는 생각임
     * LLM이 견고한 경쟁 우위(모트)가 없고 캐시를 태운다는 평가와 달리 OpenAI의 상황은 매우 고무적이라고 생각함. 연간화된 매출 100억 달러를 발표했고, 지난 3월 펀딩에서는 기업가치 3,000억 달러까지 올랐음. 50억 달러 적자를 봤지만, 매출 30배 성장과 5억 명 이상의 액티브 유저를 기록 중임. 이 성장세는 초기 Uber가 빠른 성장과 막대한 투자, 그리고 수익성으로 진전하는 모습을 떠올리게 함
          + 문제는 매출이 늘면 비용도 같이 오르는 구조라는 점임. 보통 규모를 키울수록 단가가 낮아지는데, OpenAI는 사용이 늘어날수록 컴퓨팅 비용이 그대로 늘어남. 부가수익원이 늘어나지 않는 한 규모의 경제가 미약함. 사례로 넷플릭스도 비슷한 상황임. 지속적 수익성 달성은 어렵다고 봄
          + 체감적으로 보면 OpenAI가 선점 효과를 가진 덕에 나도 월 결제를 유지하고, 굳이 여러 옵션을 전전하거나 바꿀 생각이 없음. 추후 시장이 안정되고 가격 경쟁이 세지면 기꺼이 갈아탈 의향도 있음. 결국 주요 매출원이 앱 사용자냐 API 플랜이냐에 따라 선점효과의 지속성이 달라짐. 신뢰도와 브랜드 네임 말고는 주변 이용자도 여러 대안을 적절히 고르는 분위기임
          + 결국 LLM 가격이 영원히 내려갈 것이고 무료 모델만 살아남을 것이라는 점에서 OpenAI의 경쟁력(모트)은 취약함. ""생각하는 모델""만으로 복잡한 문제를 해결하지 못하며 과대평가된 측면도 있다고 봄
          + '모트 없음' 주장에는 동의하지 않음. 채팅 데이터 등 사용자 상호작용 데이터는 그 자체만으로도 매우 가치 있음
          + OpenAI의 성장만 긍정적으로 보면 고무적인 것은 맞으나, ChatGPT 등 AI 회사의 사회적 임팩트까지 따져보면 그리 밝진 않다고 생각함. 예를 들어 온라인 상점에 무의미한 AI 생성 콘텐츠가 대량 쏟아져 구매 경험도 하락함. ChatGPT에 과몰입된 일부 집단에서는 실제 친구 및 가족과의 소통에 엇나가거나 이혼까지 하는 등 이상 행태가 관찰됨. 교육 현장에서도 남용으로 인해 혼란이 심함. Uber의 성장처럼, OpenAI의 성공이 사회에 반드시 좋은 효과만 가져오는 것은 아니라고 생각함
     * o3 모델은 현재 최고 모델 중 하나이고, 가격도 Claude, Gemini와 같거나 더 저렴함. 경쟁사 숨 쉴 틈도 못 주는 느낌임
          + Gemini도 비슷한 수준(때로는 더 좋음)이어서 그 선택도 합리적이라고 생각함. o3-pro는 그 중에서도 한 수 위일지도 모름
     * 과거에는 구글 검색 성능이 형편없어지는데 수십 년이 걸렸다면, 이제는 AI 모델 성능이 망가지는 데 며칠이면 되는 놀라운 시대임
     * 아마도 o3-pro 출시도 관련 이유일 수 있다고 생각함
"
"https://news.hada.io/topic?id=21313","AirAP - 아이폰을 에어플레이 수신기로 사용하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      AirAP - 아이폰을 에어플레이 수신기로 사용하기

     * 아이폰을 iTunes나 Mac의 AirPlay 수신기로 만들어주는, 역방향 스트리밍용 iOS용 네이티브 AirPlay 서버앱 오픈소스
          + 설치하면 아이폰이 시스템 환경설정의 오디오, Music 앱 등에서 AirPlay 출력 대상으로 나타남
     * 맥, Apple TV, 다른 iOS 기기의 오디오를 아이폰으로 라우팅하여 스트리밍할 수 있음
          + 예: 맥에서 야간에 아이폰+헤드폰으로 소리를 듣거나, 개발자가 오디오 출력 장치 테스트 시 활용, 오래된 유선 스피커 재활용 등
     * Swift로 작성되었고, TestFlight로 간편히 체험 가능. 동일 Wi-Fi 환경에서 실행 시 자동으로 AirPlay 장치로 인식됨

   mkckr0의 audio-share와 비슷하네요.
   이쪽은 리눅스의 오디오를 안드로이드폰으로 들을 수 있습니다. 블루투스 장치들을 폰에만 연결해도 데스크탑 오디오를 들을 수 있는게 편리하지만 약간 오디오가 밀리는 편 입니다.
"
"https://news.hada.io/topic?id=21414","Chatterbox TTS","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Chatterbox TTS

     * Chatterbox는 Resemble AI가 공개한 최신 오픈소스 TTS(음성 합성) 모델임
     * 경쟁사인 ElevenLabs와 비교 평가에서 지속적으로 선호 결과를 보임
     * 감정 과장 제어 등 독자적인 기능을 탑재해 다양한 음성 표현 가능함
     * 5억 개 파라미터 Llama 백본과 50만 시간의 정제된 데이터로 훈련 진행함
     * 모든 생성 음성에 Perth 워터마킹 내장으로 무단 사용 및 위변조 방지 지원함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Chatterbox TTS 소개 및 중요성

     * Chatterbox는 Resemble AI에서 개발한 생산 환경 등급의 오픈소스 TTS(텍스트 음성 변환) 모델임
     * MIT 라이선스를 적용해 자유롭게 활용 가능, 닫힌 소스 상용 모델(예: ElevenLabs)과 비교시에도 우수한 품질을 입증 받은 결과 공개함
     * 동영상, 밈, 게임, AI 에이전트 등 콘텐츠 제작 전반에 적용 가능, 오픈소스 TTS 최초로 감정 과장 제어 기능을 제공함
     * Hugging Face Gradio 앱이나 자체 API로 시연 및 실사용 가능, 대규모 또는 높은 정확도 필요시 상용 API(200ms 이하 초저지연) 제공함

주요 특징

     * 최첨단 제로샷 TTS: 별도의 데이터 없이도 다양한 화자 스타일 표현 가능
     * 0.5B Llama 백본: 대형 언어 모델 구조를 음성 합성에 접목함
     * 감정 과장/강도 조절: 각 화자별 개성/감정의 강도를 세밀하게 제어할 수 있는 기능 제공
     * Alignment-informed inference: 음소와 오디오 정렬 정보를 반영해 초고안정 생성 품질 구현
     * 0.5M 시간 정제 데이터: 대규모/고품질 음성 데이터셋으로 학습 진행
     * 내장 워터마킹: Resemble AI의 Perth(Perceptual Threshold) 워터마킹으로 생성물 추적·무단사용 방지
     * 음성 변환 스크립트: 손쉽게 사용 가능한 voice conversion 기능 내장
     * 성능 검증: ElevenLabs 대비 우수 평가 결과 확보

사용 팁

     * 일반 TTS/음성 에이전트: 기본값(Exaggeration=0.5, cfg_weight=0.5)으로 대부분 상황에서 균형 잡힌 품질 구현
          + 빠른 화자 스타일일 경우 cfg_weight 값을 0.3 부근으로 조절 시 더 자연스러운 속도 제공
     * 감정적/극적인 음성 합성: Exaggeration을 0.7 이상으로 높이고 cfg_weight 감소 시 극적인 발화 효과 강화
          + 감정 강도(exaggeration)가 높을수록 발화 속도 빨라짐, cfg_weight를 낮추면 더 천천히 또렷한 발화 조정 가능

지원 언어

     * 현재는 영어만 지원함

참고/의존 오픈소스

     * Cosyvoice, Real-Time-Voice-Cloning, HiFT-GAN, Llama 3, S3Tokenizer 등 다양한 최신 음성·언어 모델 기술 반영함

Perth 워터마킹 내장

     * Perth(Perceptual Threshold) 워터마킹: 모든 생성 음성에 오디오 품질 저하 없는 신경망 워터마크를 삽입함
     * 워터마크는 MP3 압축, 오디오 편집, 가공에도 유지됨
     * 정확도 100%에 가까운 자동 탐지 가능, 원본 추적·위변조 방지 및 책임감 있는 AI 사용 지원

  워터마크 추출 예시

     * 별도 스크립트로 해당 워터마크 포함 여부 검증 가능
     * Python 패키지 perth, librosa 활용해 오디오에서 워터마크 값(0 또는 1) 추출 가능

커뮤니티

     * 공식 Discord 커뮤니티 운영 중, 누구나 합류 및 협업 가능

면책 조항

     * 본 모델은 악의적 용도 사용 금지, 프롬프트는 인터넷에서 공개된 데이터만 활용함

        Hacker News 의견

     * 모든 Chatterbox로 생성된 오디오 파일에는 Resemble AI의 Perth(Perceptual Threshold) 워터마커가 포함됨 안내를 보게 됨
       imperceptible neural watermarks라서 MP3 압축, 오디오 편집, 각종 변조에도 살아남으면서 100%에 가까운 탐지 정확도를 가진다고 광고
       근데 tts.py에서 apply_watermark 함수 호출만 주석 처리하면 워터마크 넣는 걸 쉽게 비활성화할 수 있는 것 아닌지 궁금증
       이런 워터마크라면 원래 모델 자체에 숨겨서 손쉽게 제거되지 않게 하는 게 목적이라 생각
       오픈소스 모델에 워터마크를 별도 후처리 단계로 추가하는데, 이럴 거면 왜 굳이 워터마크를 넣는 건지 의문
     * 이런 건 일종의 CYA(Cover Your Ass, 자기 보호) 제스처라고 추측
       오리지널 Stable Diffusion에도 content filter가 있었던 것처럼
       또 트레이닝 데이터 혼입 방지도 의도 가능성
     * 심지어 parser에 --no-watermark 플래그도 들어가 있음
       최종적으로는 이걸 하나의 “기능”처럼 써서 더 큰 제품에 포함시킬 사용자를 위해 넣은 것 같음
     * OpenAI, Google, ElevenLabs 아닌 업체는 적극적으로 오픈소스 하지 않으면 완전히 관련성 없어질 것임
       TTS 시장 리더는 이미 뚜렷하고, Resemble, PlayHT 등은 개발자들에게 무게와 소스코드를 공개해야 어느 정도 시장 점유율이라도 가져올 수 있음
       워터마킹은 미디어의 남용 비판 대응용 CYA 성격
       이런 쪽 이슈가 없으면 미디어와 반 AI 진영(404Media 등)에서 악용 이슈를 제기할 것임
       소스, 가중치 공개, 별도 API/파인튜닝 옵션 제공 방식이 옳은 방향
       참고로 404Media 기사
     * 데모 페이지는 여기 안내
       만약 데모 오디오가 너무 골라낸 예시 아니라면 정말 좋은 릴리즈라 생각
       매번 하는 말이지만 실제로 음성 AI는 TTS 품질보다도 음성 인식(트랜스크립션) 쪽이 한계라는 점을 실험에서 계속 체감
       최근에 바뀐 게 없다면 여전히 한계점
     * 최근 경험으론 LLM이 트랜스크립션 오류까지도 잘 읽고 활용해 주는 수준
       아직 LLM에게 여러 버전의 트랜스크립션이나 confidence level을 넘겨 본 적 없지만, 활용하면 잘 써 먹을 것 같다는 기대
     * 실제로 Speechmatics 써봤는데 트랜스크립션 품질 꽤 쓸만했다는 경험
     * Huggingface 데모로 직접 써보면, 페이지 데모에서처럼 감정 표현이 그렇게까지 자연스럽지는 않았고 골라낸 예시 느낌도 듦
     * 합성 데이터로 트랜스크립션 문제를 극복할 수 있지 않을까 궁금증
     * 데모에 욕설이 직접 들어간 것 정말 좋게 봄
       Pulp Fiction에서 따온 문장인 것도 재밌음
       기존 데모들은 맨날 심심하고 무난해서 지겨웠음
       인디 TTS 커뮤니티에서는 Navy Seals copypasta 많이 쓰이는데, Resemble처럼 서비스 회사가 이런 문장 집어넣은 건 신선
       Copypasta 위키, Navy Seal copypasta 사례
     * 여기에서 무료로 돌려볼 수 있음
     * 재미있게 써봤다는 체험
       내 오스트레일리아 악센트를 넣으니 아주 영국식, 그것도 엄청 부드러운 RP 발음으로 나옴
       너무 자연스럽게 들리는데 내 억양을 재현하는 느낌은 확실히 아님
       실사용에는 명료하고 자연스러운 음성이 중요한 경우가 많으니 그런 곳엔 완벽히 적합
     * 아쉽게도 트레이닝이나 파인튜닝 코드가 공개되어 Flux나 Stable Diffusion처럼 “완전히 열린” 수준은 아님
       “open” 모델 중 더 좋은 것들로는
          + Zeroshot TTS: MaskGCT, MegaTTS3
          + Zeroshot VC: Seed-VC, MegaTTS3
            실제로는 Seed-VC만 훈련/파인튜닝 코드가 있지만, 모두 Chatterbox보다 제로샷 성능 좋음
            특히 ByteDance의 MegaTTS3는 ElevenLabs 빼고는 따라올 회사가 없을 정도
            ByteDance는 돈, 인력, 데이터 모두 압도
            만약 파인튜닝 없이 제로샷 음성 재현이 목적인 경우 이런 모델들이 더 나은 선택
     * 생산 환경 TTS API 배포 구현 예시도 오픈소스로 나옴
       배포 가능한 모델 링크도 첨부
     * 샘플 추론 코드, 음성 복제 예시 안내
       아직 스트리밍 지원 작업 중 안내
     * 정말 흔한 억양엔 뛰어나게 동작한다 생각
       근데 생각보다 꽤 흔한 억양에서도 다른 억양(예: 스코틀랜드 녹음인데 오스트레일리아 억양)이 묻어 나옴
       요크셔 지방 억양도 잘못 집음
     * 스코틀랜드 억양 넣었더니 내 오스트레일리아 억양조차도 영국식 RP로 변신해버림
     * 이건 모델보다 스코틀랜드 억양 특성이 더 문제라는 의견
     * 영국 악센트 배우 같은 느낌 믿음
     * 하드웨어 사양 질문, 최소 스펙에서 돌아가는지 궁금
     * GitHub 이슈 페이지에 따르면, 최적화가 아직 잘 안 된 상태
       그래서 기본 상태에서는 제법 높은 사양의 소비자용 하드웨어가 필요
       하지만 앞으로 최적화될 여지가 높다고 봄
       이슈 링크
     * 이 이슈 기준으론 6~7GB VRAM 필요
       모델이 충분히 가치 있으면 누군가 더 적은 VRAM으로 돌릴 방법 찾아줄 것 같음
       실제로 구형 Nvidia 2060에서 돌려봤는데 VRAM 피크 약 5GB
     * 이런 질문 절대 사소하지 않은 질문, 오히려 최고의 질문
       무료로 돌릴 수 있지만 실제 비용 때문에 셀프 호스팅의 의미가 없어질 수도 있음
     * 나도 같은 의문 있어서 찾아봤던 사람
       고가 GPU 필요한지, 아니면 12년 된 노트북에서도 도는지 궁금
     * 구형 CPU에서의 구동 경험 공유하려 했으나 30분 넘게 설치와 오류만 반복
       겪은 문제 나열:
          + Python 3.13 미지원 및 uv로 3.12 가상환경 재설정
          + numpy 1.26.4 미인식, uv pip가 pytorch 저장소만 검색
          + pip install chatterbox-tts 버전이 CPU only 모드에서 버그
          + 기본 main 버전은 Debian에 protobuf-compiler 필요
          + 알 수 없는 CMake 오류, Python dev 헤더 없다는 불만
            남의 Python 프로젝트 돌릴 때마다 반복되는 이 삽질 때문에 지치는 심정
     * 감정 표현 과장이 흥미로웠지만, Elevenlabs처럼 텍스트 설명만으로 원하는 음성색을 “조각”하듯 만들 수 있는 서비스는 아직 못 찾았음
       SparkTTS가 파라미터를 좀 더 제공하고 있고 GitHub 코드에 더 정교한 감정 조절 가능성도 보임
       내 경우엔 prosody와 tonality 조작을 텍스트에서 과하게 주어 일부 모델에서 원하는 컨셉에 접근한 경험은 있음
       그래도 Elevenlabs에서의 직관적인 감정 디자인에 비해 훨씬 번거로운 작업
     * 데모를 직접 내 목소리 일부로 테스트한 소감
          + 출력이 내 목소리 느낌 어느 정도 따라가긴 했지만 엄청 유사하지는 않았음
            그래도 아주 짧은 샘플로 여기까지 따라온다는 점은 꽤 놀라움
          + CFG/pace 수치를 조금만 높여도 오디오가 바로 알아들을 수 없는 상태로 망가짐
          + 내 억양이 오스트레일리아인데 출력은 영국식, 미국식으로 제각각 나옴
          + 감정 과장 표현 재밌었지만, 어떤 감정이 나오는지는 매번 달랐음
     * 이런 TTS 모델이 책 낭독까지 설득력 있게 할 수 있는지, 몇 문단 지나면 음성 일관성이 깨지는 건 아닌지 궁금
     * 대부분 TTS 시스템은 긴 텍스트에서 품질이 망가지니, 실제로는 단락별로 끊어서 낭독 후 다시 이어붙이는 게 좋음
       또 one-shot 샘플 웨이브가 노이즈 섞이면 Chatterbox가 가끔 끝에 정체불명 소리까지 출력해 주는 보너스
       특히 단테의 신곡 같은 걸 읽을 때는 “지옥의 소리” 체험
     * 언젠가 품질이 충분히 좋아지면 Audible에 AI 내레이션 오디오북 넘쳐날 것 같음
       (Amazon이 해당 사실을 고지할지 여부만 의문)
     * 직접 epub 책 한 권을 오디오북으로 생성해 봤는데 이 도구로 아주 나쁘지 않은 결과 얻은 경험
       audiobook 변환 툴 audiblez
     * 해당 분야 회사 컨설팅 중인데, 분명히 현재 기술로 책 낭독에는 문제 없다고 단언
     * 1년 전 친구에게 Carl Rogers 치료 오디오북을 재미 삼아 Attenbrough 스타일로 합성해 들려줬는데, 이미 그때도 꽤 훌륭한 품질
       1년이 지난 지금은 분명 더 좋아졌다고 본다
"
"https://news.hada.io/topic?id=21407","Mikeal Rogers가 세상을 떠남","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Mikeal Rogers가 세상을 떠남

     * Mikeal Rogers는 저자의 오랜 친구이자 동료, 그리고 독특한 파트너였음
     * Mikeal은 급성 암으로 인해 세상을 떠남
     * 그는 Node.js 커뮤니티와 오픈 소스 세계에서 중추적 역할을 맡았음
     * 기술적 명석함과 인간미, 그리고 커뮤니티에 대한 헌신을 통해 많은 사람에게 영향을 끼침
     * 그의 신념이었던 호기심, 관대함, 배제 없는 커뮤니티의 가치를 앞으로도 이어갈 것임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Mikeal Rogers의 별세

   Mikeal Rogers는 저자의 절친한 친구이자 동료, 깊은 신뢰를 나눴던 인물로서, 함께 수많은 밤을 대화하고 출장길을 함께한 소중한 파트너였음

   Mikeal은 급성 암으로 세상을 떠났음

   마땅한 언어로 그가 나와 많은 커뮤니티에 남긴 의미를 모두 담기 어렵지만, Mikeal은 Node.js의 중추적 인물이었고, DigitalOcean에서 개발자 에반젤리즘을 ‘환대의 실천’ 으로 승화시킨 존재였음
   휴게소에서 냅킨에 새로운 아이디어를 그리던 전략 세션부터, 인생의 무게에 힘들었던 순간을 함께 나누던 조용한 시간까지, Mikeal은 항상 기쁨의 근원이었음

   Mikeal은 희귀한 기술적 탁월함, 명료함, 그리고 걸러지지 않은 인간미의 조합으로 주변의 모든 이들에게 코드가 인간과 커뮤니티를 위한 연결의 매체임을 상기시켜줬음
   모든 프로젝트에서 오픈 소스는 단순한 라이선스가 아닌, 서로를 북돋아 주겠다는 약속임을 행동과 삶으로 증명했음
   새벽 세시에 불굴의 주장으로 논의를 이어가던 순간부터 기술에 회의를 품던 주니어 엔지니어에게 진심으로 다가서던 이였음
   저자 자신 또한 Mikeal의 영향력 덕분에 성장했으며, 취약함과 엄격함은 서로 반대가 아니라 동료임을, 최고의 팀은 웃음과 함께 단련된다는 점을, 그리고 공감과 배려 없는 성공은 공허함을 직접 배웠음

   그를 잃은 슬픔은 깊지만, 아직도 그의 음성이 “Well John, you see…”라며 더 많은 이들이 존중받고 자유롭게 아이디어를 나눌 공간을 계속 만들어 나가라고 격려하는 듯함
   저자는 Mikeal이 평생 몸소 실천해 온 원칙을 지키며 그의 삶을 기릴 것임
     * 이기심 없는 호기심
     * 한계 없는 관대함
     * 배제 없는 커뮤니티

   친애하는 친구 Mikeal, 당신은 내 삶을 구해줬고 이제는 당신에게 평안을 빌음
   함께 걸었던 길은 당신이 남긴 불씨로 여전히 밝게 빛나고 있고, 그 여정을 함께한 우리 모두는 그 불씨를 지켜나갈 것임

   Mikeal, 그리움과 사랑을 전함

        Hacker News 의견

     * Mikeal 덕분에 node 커뮤니티가 아직 정말 작았던 시절 완전히 정착할 수 있었던 경험 공유함
       Mikeal과 함께 있으면 항상 큰 기쁨과 소속감 느꼈던 추억 회상
       3년 연속 node camp 카운슬러로 참여하면서 그가 만들어준 마법 같은 분위기와 소중했던 시간에 대한 그리움 표현
       nodecamp에서의 추억, 함께 버스를 타고 다니며 웃고 장난쳤던 일, 집에 놀러 가고 밋업 참석했던 순간, 그리고 pull request 통해 유쾌하게 대화 나눴던 추억 등 이야기
       meatspac.es 같은 곳에서 밤새 장난치던 시간까지 다양한 기억 되새김
       Mikeal 덕분에 즐거웠던 모든 시간에 감사함 전함
     * Node가 막 성장하던 시기에 Node 이벤트에서 처음 Mikeal을 만났던 일화 공유
       Mikeal은 항상 모두를 반갑게 맞이하며, 방 안의 분위기를 살리는 데 큰 역할 했던 인상적인 인물로 기억
       Mikeal과 시간이 지날수록 커뮤니티와 이벤트에 꼭 필요한 작은 일들을 직접 챙기는 그의 모습에 깊은 인상 받음
       단순한 자리에서도 남들을 배려하고 모두를 위해 특별한 무언가를 만들어 준 기억
       그가 많이 그리울 것이라는 감정 공유
          + 그가 주최한 이벤트는 항상 흥미진진했던 추억 회상
            O’Reilly에서 진행한 대형 행사(JSfest로 기억) 이전에 Mikeal이 San Francisco Marines Memorial Theatre를 이틀간 대관해 일반 대기업 행사보다 훨씬 더 재미있고 의미있는 주제의 JavaScript 주요 인사들이 참여하는 세션을 만든 기억
     * Mikeal을 처음 알게 된 계기가 npm 프로젝트 내 패키지에 대한 호기심이었음을 언급
       수많은 오픈소스 프로젝트에 기여했고, GitHub에서도 상냥하고 참을성 많았던 인상적인 사람으로 경험함
       오픈소스 커뮤니티(FOSS)에 큰 손실임을 아쉬워하며 지인과 가족에게 애도의 마음 전함
       Mikeal의 GitHub 링크 공유
     * Mikeal은 정말 놀라운 사람이었다고 회상
       현재 NodeConf 티셔츠를 입고 있을 만큼 커뮤니티에서 가장 멋진 시간 보냈던 추억 강조
       Mikeal과는 시간이 아무리 흘러도 언제나 어제 만난 것처럼 자연스럽게 다시 대화 이어갔던 친구로 기억
       ProtocolLabs 프로젝트에서 함께 일하며 일과 오픈소스, 아이디어, 철학, 영성, 그리고 힙합까지 거의 매일 다양한 주제로 깊은 대화 나눴던 경험 공유
       엔지니어의 시선으로 불경 등 다양한 경전을 해석하는 그의 통찰력과 영감에 감탄
       암 진단 후 Bay Area로 막 이사 와서 곧 만날 계획이었지만 갑작스러운 상황이 벌어졌음을 아쉬워함
       가족에게 깊은 애정과 위로 전함
     * Mikeal이 두 번째 스타트업 Getable에서 CTO로서 함께 일했던 소중한 기억 공유
       음식, 기술, 지성과 따뜻함 모두 갖춘 멋진 사람으로 기억
       몇 달 전 진단을 공유 받았고, 정말 빠르게 모든 일이 진행됐음을 안타까워함
       함께 일할 때는 Anna(아내)와 Mikeal 둘 다 아직 부모가 아니었고, 모두 젊었을 때라 기억
       그의 영혼은 아이들과 함께 살아갈 것임을 믿으며 가족에게 사랑과 #CancerSucks 메시지 남김
     * Mikeal을 직접 만난 적은 없지만 그가 열어둔 cancer-diaries 레포지토리의 따뜻한 메시지를 보며 감동을 받았던 경험
       Mikeal cancer-diaries PR 모음 링크 공유
     * 십대 시절 IRC에서 Mikeal을 만나 엄청난 시간 함께 보낸 추억 나눔
       meetingplace 서버에서 다양한 주제로 대화하며, 그가 거의 모든 분야에서 해박한 지식을 갖췄다는 데 인상 받음
       수년 간 연락이 끊긴 후 2년 전 재회해 alameda yacht club에서 가족, 아버지 역할, 커리어, 경전에 대해 얘기하며 그 열정이 여전히 강렬했던 경험 나눔
       신생아가 있을 때 불구하고 본인을 마다하지 않았던 Mikeal의 배려심과 친구의 소중함 느꼈던 일화
       언젠가 다시 만날 것이라고 믿으며 Mikeal에 대한 깊은 애정과 그리움 표현
     * 슬픈 소식이지만 Node.js 다큐멘터리가 존재한다는 사실이 더 기쁘게 느껴짐
       그의 Node 초창기 이야기가 영상으로 남아 있다는 점에 감사
       Node.js 다큐멘터리 링크 공유
     * 온라인에서는 request 모듈로 널리 알려진 인물임을 회상
       2012년 한국 playnode.io에서 그를 직접 만났을 때 언어 장벽에도 불구하고 부족한 영어를 친절하게 들어주고 진심 담아 답변해준 그의 모습에 깊은 인상 받음
       코드뿐만 아니라 사람을 대하는 방식에서 큰 가르침을 줬던 기억
       편안한 영면을 바란다는 메시지 남김
          + 그 여행이 내 인생에서 가장 행복했던 추억 중 하나로 남아있음
            모두와 함께 모험을 공유하고, playnode.io 팀과 한국 JavaScript 커뮤니티에서 받아본 따뜻함과 친절함에 대해 자주 이야기 나누던 기억
     * 누군가의 죽음을 미리 알아도 쉽게 받아들이기 힘든 감정 표현
       2007년쯤 oscon에서 그가 windmill을 js/ajax 테스트 도구로 발표할 때 처음 만났고, 몇 년 간 연락하며 캘리포니아 여행 중 다시 만난 추억 공유
       맛집 소개에 신나하던 그의 소박한 열정(기술, 음식, 모든 것에 있던)을 아직도 기억하고 있음
       작년 그의 암 투병기 소식을 접하며 삶과 죽음, 그리고 자신의 삶을 되돌아보게 되었고, Mikeal처럼 담담하고 평온하게 대처하지는 못할 것임을 솔직하게 이야기
"
"https://news.hada.io/topic?id=21353","Nix에서 Railpack으로 전환하는 이유","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Nix에서 Railpack으로 전환하는 이유

     * Railway는 기존 Nixpacks 대신 새로운 빌드 시스템인 Railpack을 출시함
     * Railpack은 버전 관리의 세분화, 더 작은 이미지 크기, 향상된 캐싱 등에서 기존 Nixpacks보다 우수한 기능을 제공함
     * Nixpacks의 커밋 기반 버전 관리 방식이 다양한 사용자 요구와 확장성에 한계를 드러냈음
     * Railpack은 BuildKit 통합, 비밀 환경 변수 보호, 다양한 언어 및 프레임워크 지원 등으로 빌드 환경의 안정성과 유연성을 개선함
     * 현재 Node, Python, Go, PHP, 정적 HTML을 지원하며, 계속해서 프레임워크 및 언어 지원을 확장 중임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요 및 배경

     * Railway는 Railpack이라는 차세대 빌드 시스템을 공개함
     * Railpack은 Railway 플랫폼에서 1천4백만 개 이상의 앱을 Nixpacks로 빌드하면서 얻은 경험을 바탕으로 새롭게 개발한 도구임
     * 기존 Nixpacks는 전체 사용자의 80%에게 적합했지만, 20만 명 이상의 사용자가 제약 사항에 부딪혀 불편을 겪음
     * 사용자 기반 확장 및 지속가능한 빌드 환경을 위해 빅 업그레이드가 필요하다고 판단함

Railpack 주요 개선점

     * 버전 관리 세분화: 각 패키지에 대하여 major.minor.patch 단위의 세밀한 버전 지정을 지원하여, Nix의 불분명한 버전 방식의 한계를 극복함
     * 작은 이미지 크기: Node는 38%, Python은 77%까지 기본 빌드 이미지 크기를 줄여, 더 빠른 배포 경험 제공
     * 캐싱 강화: BuildKit과 직접적으로 통합하여, 레이어와 파일 시스템을 제어, 캐시 적중률 향상 및 환경별 캐시 공유 가능
     * 이미 railway.com과 중앙 서비스에 Railpack 빌드가 적용된 상태임

Nixpacks 사용상 문제점

     * Nix의 패키지 버전 관리 방식은 커밋 기반 구조로, 최신 major 버전만 제공하며, 각 버전은 nixpkgs 저장소의 특정 커밋에 대응됨
     * 작은 패치 버전까지 모두 수동 관리해야 하는 비효율성 존재, 기여자도 버전 관리가 직관적이지 않아 접근성 저하
     * Node나 Python과 같은 언어의 경우도 결국 최신 major 버전만 지원
     * 버전 업데이트 시 커밋 해시 변경으로 다른 패키지 버전까지 한꺼번에 영향을 받아, 사용자의 신뢰성 저하 및 예기치 않은 빌드 실패 발생 가능
     * Nixpacks의 경우 /nix/store 하나의 레이어에 모든 의존성이 포함되어, 이미지를 효과적으로 쪼개거나 크기를 줄이기가 어려움
     * 캐싱도 환경 변수 주입 시마다 레이어가 항상 invalidate되어, 캐시를 제대로 활용하지 못함

Nix 자체의 문제가 아닌 사용 방식의 한계

     * Nix 자체의 설계 문제가 아닌, Railway의 사용 및 추상화 방식이 문제점으로 작용함
     * 사용자가 Nix의 derivation 개념이나 내부 버전 구조를 이해하지 않아도 되도록 설계하려 했지만, 현실적으로 불가능하다고 판단함
     * 위와 같은 문제를 해결하기 위해 Railpack 개발을 진행함

Railpack의 기술적 아키텍처

     * Rust → Go로 코드베이스 변화: BuildKit 활용 및 생태계 대응력 강화를 위해 Go 언어로 전환함
     * BuildKit LLB 및 프론트엔드: 커스텀 BuildKit LLB와 프론트엔드를 직접 생성하여, 빌드 이미지의 구조를 정밀하게 통제함 → Node와 Python 기본 이미지가 Nixpacks 대비 대폭 경량화됨
     * Mise로 버전 관리: 패키지 설치 및 버전 해석에 Mise를 사용, 향후 다른 실행 파일 소스도 용이하게 지원 가능
     * 성공적으로 빌드한 경우, 해당 시점의 의존성 lock-in 적용 → Node 기본 버전이 22에서 24로 바뀌어도 기존 빌드는 깨지지 않음
     * BuildKit의 secret 기능을 활용하여, 환경 변수 보안/관리를 개선함

Railpack 빌드 단계

     * Analyze: 코드 분석을 통해 필요한 패키지, 실행 커맨드, 시작 명령어 도출
     * Plan: JSON 직렬화 가능한 형태의 빌드 계획 생성 (여러 단계 포함, 각 단계는 이전 단계 결과나 전체 이미지에 의존함)
     * Generates: BuildKit의 빌드 그래프 생성 (입력/출력을 기준으로)

BuildKit을 활용한 전략적 빌드

     * Dockerfile이 직렬로 동작하는 반면, BuildKit은 여러 명령을 병렬적으로 처리, 각 단계별로 세밀한 입력/출력 통제
     * Railpack은 코드 분석 결과 모든 빌드 단계를 정의하고, 각 단계의 의존관계를 낮은 수준으로 상세 지정함
     * 이 계획을 BuildKit LLB 그래프로 변환 및 해결
     * 환경 변수 등 변경 시에는 해당 값의 해시값으로 파일을 마운트, 코드와 변수에 변화가 없으면 캐시 적중 보장
     * 결과적으로 이미지 생성 방식을 완벽하게 Railpack이 컨트롤 가능

Railpack 도입으로 가능한 새로운 기능

     * Vite, Astro, CRA, Angular 정적 사이트 빌드/배포를 무설정으로 지원
     * Railway UI와 빌드 과정의 긴밀한 통합
     * 언어 최신 버전 지원이 Railpack 자체 릴리스 없이도 가능함
     * 프로젝트별로 환경 간 캐싱 최적화 제공
     * 현재 Node, Python, Go, PHP, 정적 HTML을 지원하며, 프레임워크 및 언어 지원을 계속 확장 중임

오픈소스 및 미래 계획

     * Railpack은 Beta 상태로 공개 중이며, 활성화만 하면 즉시 활용 가능
     * 공식 문서 및 실제 코드, 공개 지원 창구까지 railpack.com에서 제공
     * 향후 널리 쓰이는 언어에 대한 심층 지원을 우선하며, 코어 API 및 추상화 수준 확립 이후 범위 확장 계획 있음

        Hacker News 의견

     * 나는 Nix 애호가지만, Nix를 쓰지 않기로 한 것에 대해 감정적으로 집착하지 않는 입장임을 믿어줬으면 함. 그런데 이 글의 몇몇 불만 사항이 잘 이해되지 않고, 좀 더 설명이 필요하다고 느낌. 예를 들어 “Nix의 가장 큰 문제는 커밋 기반 패키지 버전 관리”라는 이야기가 있음. Nixpkgs는 훌륭한 리소스이지만, Nix와 Nixpkgs는 동일하지 않음. 도구체인의 임의 버전을 가져오려면 Nixpkgs가 매우 부적합하지만, Nix로 다른 방법도 있음. 예를 들면 Rust의 임의 버전을 잘 뽑아오는 Nix 도구들이 정말 잘 되어 있음. 또, “Nix 의존성을 별도의 레이어로 분할할 수 없다”라는 이야기도 들었는데, 전혀 말이 안 된다고 생각함. 원하는 어떤 방식으로든 분할이 가능. Nixpkgs의 Docker 툴도 이를 지원함. 코드베이스를 Rust에서 Go로 옮긴 부분은 Nix와 직접 관련이 없지만 흥미롭게
       느낌. 보통 언어 변경을 가볍게 결정하지 않고, 애초에 새로 만들 계획이 있을 때 하는 경우가 많음. Railpacks와 Nixpacks는 다른 사람들이 작업한 것 아닌지 의심됨. Nix를 잘 모르는 사람들이 마감되지 않은 Nix 솔루션을 조직에서 다루게 되었을 때 일어나는 일도 본 적 있음. 별로 좋지 않은 모습이고, 대부분의 사람들이 Nix를 배우려고 하지 않음. 그래서 원래 직장에서는 이런 상황을 피하려고 Nix를 거의 쓰지 않음
          + Nix를 활용하는 걸 좋아하지만, Nix의 기초적인 사용 문제에 대해 토의할 때마다 “회피 방법이 있다”(하지만 부족한 문서, 특이한 언어, 나쁜 에러 메시지, 써본 사람들만 아는 부족한 정보로 수십~수백 줄의 코드를 추가해야 함)는 답변만 돌려받게 되어 지침이 큼. 대부분의 Nix 관련 문제는 튜링 완전성이 아니라, 직관적 API 같은 기본 제공 기능이 없는 문제에서 옴. 모든 프로젝트에서 Nix 활용이 점점 Nix 자체 문제 해결에 몰입되는 방식으로 바뀐다면, 잘 문서화된 주류 도구가 있는데 굳이 Nix를 써야 할 이유가 없음. 실제로도 사람들이 Docker를 선택하는 경우가 대부분임. Nix가 개발자 경험의 실제적 문제를 현실적 시간 내에 해결하지 않고 이상적 순수성만 고집하는 것이 많이 실망스러움. 물론 모두가 자발적으로 기여하지만, 이런 기술적 노력이 잘못
            설계된 UX 때문에 실질적으로 사용할 수 없는 상태로 남는 걸 보는 게 너무 아쉬움
          + 나는 Nix를 사용하지 않지만, “Nix ≠ Nixpkgs”라는 주장이 현실을 벗어난 듯 느껴짐. 대다수 사용자는 대안이 추가 연구와 노력을 요구한다면 Nixpkgs가 결국 Nix 자체인 상황. “별도 레이어로 분할할 수 있다”도, 이게 정말 직관적이고, 간단하고, 기본 동작인지 궁금함
          + 중요한 것은 Railway의 사용자들은 각자 원하는 패키지의 버전을 지정하고 싶어하는 개발자들이라는 점임. Nix와 Nixpkgs 구조상 어떤 패키지의 버전을 고정하면 nixpkgs 전체 트리의 커밋을 고정하는 것을 의미. node/python/ruby 패키지 빌드가 트리 외부에 의존하는 게 많아서, 버전과 커밋 매핑이 필요해짐. 이 추상화가 완벽하지 않아서, 사용자가 단순히 “yarn add 패키지” 하려 해도 트리 상태를 맞춰야 할 수 있음. Nixpkgs 없이 Nix만 쓰는 건 한정적 사용에는 괜찮지만 Railway 같은 플랫폼엔 힘든 선택임
          + 버전 관리 논란이 잘 이해되지 않음. 나는 Nix를 처음 써보지만, 특정 커밋에서 가져온 패키지를 분명히 가지고 있음
          + 잘 집어서 설명했다고 생각함. Nixpkgs와 Nix는 다르지만, 사실상 Nixpkgs가 진짜 장점임. NixOS를 쓰면서 처음으로 리눅스 커널 최신 버전을 릴리즈 당일에 사용해봄. Debian Stable도 괜찮지만 항상 과거로 몇 년 돌아가는 느낌. 다만, Nix 언어는 비판거리가 많음. 오래된 언어이고, 최선을 다한 결과긴 하지만 굳이 바꿀 필요는 없다고 생각함. Nix 빌드 시스템은 고전적이라 불필요하게 재빌드가 많다고 느낌. 예를 들면 NixOS 설치 ISO에 커널에 넘기는 커맨드라인(예: 콘솔 포트 속도) 하나만 바꿔도 3분 정도 걸리는 괴상한 빌드 현상이 벌어짐. 웃기긴 한데 Nix를 포기하진 않음. 다만 내 빌드시스템에선 절대 허용하지 않을 현상임. Docker 이미지를 만들 때 Nix를 쓰는 건 개인적으로 최악이라 생각함. 예전에 Go로 만든 바이너리에 Postgres의 pg_dump 바이너리만 넣으려
            했는데, 인프라팀이 Nix를 추천해서 썼더니, 압축된 Go 바이너리가 50MB였는데 1.5GB짜리 괴물 이미지가 됐음. pg_dump는 464KB에 불과함. 결국 Bazel과 rules_debian, distroless 조합으로 훨씬 깔끔하게 작업함. 대부분의 Nix 시스템은 1.4GB가 기본값처럼 느껴짐. 큰 C++ 프로젝트 빌드도 Nix가 특출나게 잘하는 건 아님. 오히려 자신만의 소프트웨어 빌드를 위한 시스템은 더 각자의 필요에 잘 맞는 경향. 나는 Bazel을 좋아하고, Go 프로젝트에는 단순히 go build만 쓰고 싶음. 99%의 경우 Nix 대신 이런 툴을 쓰고, 단 최신화나 배포를 위해 flake를 작성해 home-manager에서 쓸 수도 있음
     * 버전 선택이 이상하게 느껴짐. nixpkgs의 버전은 시스템을 운영하거나 빌드할 때 분명히 타당함. 런타임/컴파일러를 제공하는 플랫폼이라면 devenv처럼 직접 버전을 제공하는 게 필요. 예를 들면 nixpkgs-python은 “모든 Python 버전, Nix로 시간마다 최신화”를 제공함. Railway가 배포 ID 환경 변수를 모든 빌드에 주입한다는 것도 설치 이후 레이어에서 했어도 됨. 패키지도 여러 레이어로 분리 가능하며, 레이어 개수 조절 자동화도 가능함
     * DevOps/SRE 경험자로서, 누군가가 의존성 관리 시스템을 만들려고 할 때 대개 두 가지 방향 중 하나로 흘러가는 걸 목격함(예: Python 기준). 옵션 1: “모노리포 + 공용 환경”, 장점은 관리 용이, 보안패치 편의, 일원화. 단점은 누군가는 항상 특별한 버전을 원하며, 단계적 롤아웃 어려움, 슬림 이미지 빌드 문제. 옵션 2: “각자 conda/venv”, 장점은 개별 맞춤, 불필요한 패키지 제외, 단계적 업그레이드 가능. 단점은 너무 많은 환경, 상호 호환 미검증, 보안 관리가 악몽. 결론적으로 “해결책이란 없고 트레이드오프만 있다”는 말이 경력이 쌓일수록 실감됨
     * “Nix 자체는 문제 없다. 활용법에 문제가 있었음”이란 말이 ‘적재적소에 맞는 도구를 쓰라’는 좋은 예시라고 생각함. Nix는 일부에선 훌륭하지만, 어떤 곳에선 최악임. 문제는 배우는 데 시간이 많이 들어서, 어느 정도 익숙해져 결정을 내릴 때쯤엔 이미 투자한 시간이 아까워 쉽게 방향 전환 못하고, 결국 억지로 기존 목적에 계속 Nix를 사용하게 되는 현상임
          + 비슷하게 느끼는 바가 있음. 어떤 면에선 Nix가 다른 OS보다 더 직관적인 프로그래밍 패러다임이라고 생각함. 아직 익숙치 않을 뿐. Nix 표현식은 입력(패키지 저장소, 키-값 등)과 출력(리눅스 시스템) 구조임. 몇 년 안에 더 익숙해질 수도 있을 듯. 예를 들어 AI가 shell.nix나 configuration.nix를 스펙에 맞게 생성하는 것도 이런 구조 덕분임. 나도 종종 저장소별 env가 완전히 포함된 상태로 만들고, flakes로 하면 더 재현성 있는 환경을 만들 수 있을 듯. (flake.nix는 shell.nix랑 비슷하지만 버전 고정까지 지원…)
     * 버전이 없는 곳에 억지로 버전을 도입하려는 것처럼 보임. “디폴트 버전” 때문에 의존성이 깨진다고? docker의 :latest 태그 쓰고, 바뀔 때마다 서버가 망가지는 상황과 비슷함. 이 블로그 내용은 이해가 잘 안 됨. “Nix 의존성을 별도 레이어로 나눌 수 없다”에도 공감하지 않음. 원하는 만큼 /nix/store를 분할 가능하며, 컨테이너와 Nix를 어떻게 써야 하는지도 잘 모르는 느낌. 이렇게 능력이 부족하다면, 제시된 대안도 결국 같은 문제를 반복할 것 같음. 고전적인 NIH(자기만의 툴 만들기) 증후군의 예시임
          + Nix가 맞지 않는 곳에서 안 쓰는 건 당연하지만, 이미 돌아가는 시스템을, 다른 사람들도 이미 해결한 문제를 조금만 찾아보면 알 수 있음에도, 처음부터 끝까지 새로 만드는 건 근본적으로 이상하다고 느낌. nix2container나 flakes가 모든 문제를 해결할 수 있을 듯. 버전 관리도, 3년 전에 작성한 flakes가 지금도 똑같이 빌드되고 결과도 변함없음. 왠지 시장 진출이나 투자 유치를 노리는 플랫폼 전환 냄새가 남. 참고로 nixpacks GitHub를 봤더니 rustPlatform만 쓰고있고, rust 문제라면 rust-overlay가 사실상 정답임
          + 어떤 방법이 VC를 더 쉽게 유치하는지 고민해본다면, nix 래퍼보단 “배포 플랫폼”이란 타이틀이 유리함
     * “Nix 의존성을 별도 레이어로 분할할 수 없다”는 말과 달리, nix2container는 정확히 그 분할이 가능함. 예를 들면 bash가 필요한 이미지라면, bash가 포함된 레이어만 따로 만들 수 있고, 이 레이어는 bash가 바뀔 때만 다시 빌드/푸시하면 됨. “의존성 때문에 거대한 이미지가 단일 /nix/store 레이어로 생긴다” 역시, nixpkgs.dockerTools.buildImage 함수엔 해당하지만 nix2container나 nixpkgs.dockerTools.streamLayeredImage에는 해당되지 않음. 이 도구는 실제로는 스크립트를 생성해 이를 통해 이미지를 푸시하도록 함. nix2container는 모든 레이어의 경로를 JSON으로 만들고, Skopeo를 이용해 이미지를 Docker, 레지스트리, podman 등에 푸시함. (참고로 내가 nix2container 저자임)
          + nix2container에 정말 감사하다고 말하고 싶음. AWS(ECR) 배포에 쓰는데, 빌드 간 전환 시간이 한 자리수 초로 줄어듦
          + 우리도 Docker 이미지 크기 문제 때문에 nix2container를 테스트할 예정이었음. 좋은 툴 만들어줘서 고마움
     * 여기 핵심 문제는 언어 패키지 매니저가 조장하는 “맞춤 버전 스프”를 고수하려는 태도 자체라고 생각함(이 방식은 지속 불가능함). 대안인 Mise는 패키지 간 버전 제약을 이해하지 못하고, 각 패키지의 테스트도 전혀 하지 않음. 같은 수준의 신뢰성은 전혀 기대할 수 없음
          + 맞춤 버전 스프가 지속 불가능한 건 사실이지만, 사람들이 이걸 계속 쓰는 이유는 잘 작동하기 때문임. OS 수준 라이브러리는 매우 보수적으로 관리해서 쉽게 깨지지 않고, mise나 asdf 같은 툴로 그 위에 맞춤형 버전 조합을 올려도 대체로 멀쩡함. 깨져도 버전/설정만 만지면 바로 해결됨. 깨진 건 짜증나긴 해도, 중요치 않음. 추가 학습이나 노력이 들어가는 시스템은 시간 낭비로 여겨짐. 다만 “깨지지 않는 상태”를 더 중요하게 여기는 사람들은 오히려 러닝 커브와 불편이 있어도 Nix를 선호함. Railway처럼 많은 사용자를 겨냥하는 곳이라면 결국 첫 번째 그룹(간편성, 관성)을 더 신경 쓴 선택을 함
          + “맞춤 버전 스프”가 무슨 의미이고, 대안은 뭔지 궁금함
          + 둘 다 충분히 가능함. 예를 들어 Rust 패키지는 Cargo.lock 정보로 Nix로 쉽게 빌드 가능. Nixpkgs가 커스텀 버전 조합과는 상충하지만, Nix 자체는 충분히 잘 함
     * Nix는 임의 버전이 아니라 커밋 단위 보장임. glibc 변경이나 공유 라이브러리 충돌 같은 엣지 케이스에는 고생할 수 있음. 지금은 이미 늦었을지 몰라도, Nix로 더 우아하게 쓰는 방법에 대해 컨설팅도 가능함. 제품 자체는 멋지다고 생각함
          + nix는 공유 라이브러리 충돌을 아주 강하게 방지함. 하지만 사소한 변경(코멘트, 문서 등)에도 관련 모든 하위 의존물까지 싹 다 재빌드됨. 그 결과 매우 방대한 재빌드가 필요하게 되고, 개발이 고통스러워질 수 있음. nixpkgs의 staging 과정을 보면 알 수 있음
          + Nix의 가치를 충분히 이해함. 다만 “망한다”는 말은 조금 과장이 있다고 생각함. Nix에 비해 큰 보장 일부를 잃는 것은 사실이지만, 그래도 대부분의 소프트웨어보단 훨씬 더 잘 돌아갈 확률이 높다고 생각함
     * 자신만의 derivations를 만들지 않고 왜 굳이 nixpkgs 해시에 의존했는지 모르겠음
     * 많은 댓글이 “사실 Nix로 다 해결된다, 단 나처럼 전문가여야 한다”는 분위기라 흥미롭게 봄
          + 만약 한 회사가 모든 기술과 비즈니스를 JavaScript로 하고 있다가, 기존 핵심 개념(함수, 배열 등)을 이해 못해서 NIH(독자 규격의 새 언어 개발)를 한다면, 그건 내부 모자람에 더 가까운 문제임
          + Nix 얘기만 나오면 항상 반복되는 평소 분위기임
          + 이게 바로 Nix가 가진 분위기임. “내가 세상을 구할 것이다”식의 전형적인 서사와 “내가 원하는 기능이 안 된다”라는 반응에 대해 항상 “니가 제대로 안 써서 그럼”이라는 답이 돌아옴
"
"https://news.hada.io/topic?id=21401","Rust에 베팅한 지 10년이 되었고, 앞으로 기대하는 것 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Rust에 베팅한 지 10년이 되었고, 앞으로 기대하는 것

     * Rust 1.0 출시 직후부터 10년간 Rust를 실무에 도입한 경험과 앞으로의 10년에 대한 기대를 정리한 글
     * 초창기에는 버전 호환성 문제와 빌드 시간, 빌림 검사기(borrow checker) 적응이 어려웠음
     * Rust 커뮤니티와 생태계는 “탁월한 프로그래밍 감각”과 강한 공동체 문화로 인해 빠르게 발전했으며, 뛰어난 개발자들이 Rust로 모여드는 현상이 두드러짐
     * 이제는 일반 시스템 및 백엔드 분야에서 Rust가 “안정적인 선택” 이 되었으며, 표준 라이브러리의 발전과 크레이트 생태계의 성숙으로 인해 불확실성이 크게 줄었음
     * 빌드 속도, 이식성, const 기능, 동시성, 다양한 도메인 확장 등 Rust가 해결해야 할 남은 과제와 발전 방향을 구체적으로 제시함
     * 앞으로의 10년은 더 빠른 컴파일, 광범위한 도메인 확장, 개발자 경험의 혁신이 이어질 것으로 전망하며, Rust 생태계의 긍정적 피드백 루프가 가속화될 것이라고 기대함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

     * 2015년 6월, Rust 1.0 공개의 열기가 식어가는 한달 후쯤에 첫번째 Rust 코드를 작성함
     * C, Python, JavaScript를 사용해오다 Rust를 접한 이후, 다시는 돌아보지 않게 됨
     * Rust 기반의 스타트업 두 곳, 50만 줄 이상의 코드를 작성했던 경험을 기반으로 10년의 성찰을 공유함

초창기는 힘겨운 시간 - The early days were painful

     * 초기 Rust 도입 시, 크레이트와 컴파일러 간 버전 호환성이 매우 불안정했으며, 작은 버그 픽스에도 전체 빌드 환경을 강제로 업데이트하는 일이 많았음
     * 빌림 검사기(‘borrow checker’)의 개념과 라이프타임 관리가 어렵게 느껴졌으며, 복잡한 타입이 늘어날수록 컴파일 시간이 급격히 늘어나는 문제가 심각했음
     * 새로운 기능이나 버그 픽스가 필요할 때마다 “세상의 모든 버전”을 업데이트해야 했으며, 호환 가능한 버전을 찾는 데 많은 시간을 소비해야 했음

Rust 커뮤니티의 탁월함 - The people were and are exceptional

     * Rust 생태계는 단순하고 우아한 구현, 빠르고 견고한 성능을 지향하는 탁월한 프로그래밍 문화가 자리잡았음
     * TypeScript나 Python을 쓸 때보다 Rust의 의존성 구조가 훨씬 깔끔하고 빌드가 단순함
     * 커뮤니티 자원봉사자들의 헌신적인 기여와 “지금은 아니다/아직 아니다”라는 신중한 태도가 핵심적 역할을 함
     * 런던에서 Rust 개발자 구인에 큰 이점이 있었으며, Rust 개발자의 평균 역량이 매우 높음

Rust, (몇몇 도메인에선) 안전한 선택지가 됨 - Rust has become a safe bet (in some domains)

     * 초창기에는 표준 라이브러리(std)의 부재로 인해 직접 유틸리티 함수와 패치를 만들어야 했으나, 이제는 대부분의 기능이 std와 크레이트에 내장되어 불확실성이 크게 감소함
     * 빌드와 업그레이드 예측 가능성, 외부 의존성 감소, semver 준수, 빌림 검사기와 추론 엔진 개선 등으로 Rust 사용 경험이 대폭 안정화됨
     * 신규 크레이트(예: jiff, polars, tauri)는 과거의 시행착오를 기반으로 개발되고, tokio, hyper, regex 등은 실전에서 검증됨
     * 과거에는 “바퀴 재발명”이 불가피했지만, 지금은 비즈니스 로직에 집중해 고성능/견고한 애플리케이션 개발이 가능해짐

오늘날의 Rust가 보여주는 개발 환경 - Rust today feels like what programming should be

     * Rust는 간결하고 견고한 빌드 시스템, 최고의 에러 메시지와 린트, 훌륭한 문서와 IDE 통합, 강력한 CI/회귀 테스트 등 프로그래머 중심의 공감 능력을 갖춘 언어임
     * 대규모 오픈소스 프로젝트 중 Rust만큼 프로그래머 친화적인 언어는 드뭄
     * 수많은 커뮤니티와 기여자들의 “장기적 투자”가 현재의 Rust를 만든 핵심 요인임

향후 10년에 대한 기대 - What I’m looking forward to over the next 10 years

  더 단순하고 빠른 빌드 - Simpler and faster builds

     * 복잡하거나 느린 의존성을 단순하고 빠른 것으로 대체하는 작업이 계속될 것으로 기대
     * 순수 Rust 표준 라이브러리, 시스템 linker와 라이브러리 의존성 감소, pure-Rust 암호화, 영속 BTreeMap, Rust 기반 게임 엔진 등 새로운 시도가 기대됨
     * Tably에서도 최근 수개월간 프론트엔드/백엔드 컴파일 속도가 60% 향상됨

  이식성 증대와 #[cfg()] 최소화 - Improved portability and less #[cfg()]

     * 다양한 플랫폼/옵션 조합의 테스트가 어렵고, #[cfg()]로 인한 미검증 코드/문서 불완전/IDE 문제 등이 발생함
     * trait system 내로 #[cfg()]를 이동하여 플랫폼/옵션 보장 및 재컴파일 최소화, MIR 캐시, 빠른 CI 실현이 기대됨

  모든 코드가 const가 되길 - Everything being const

     * 컴파일 타임에 더 많은 작업을 미리 수행함으로써 매크로/빌드스크립트 의존도를 줄이고, 런타임 오류도 미리 방지 가능
     * 현재는 제한적이나, 앞으로 “모든 코드가 const context에서 실행 가능”한 Rust를 지향

  동시성의 단순화 - Simpler concurrency

     * 현행 Rust의 비동기(Async) 모델은 ‘static bound, cancellation-safety, trait 제한 등 복잡성이 높아 실무에 어려움을 줌
     * 과거의 user-space green thread(libgreen)처럼 언어 차원의 단순한 동시성 추구가 필요함

  더 많은 도메인에서의 경쟁력 갖추기 - Excelling in more domains

     * Rust의 웹 브라우저 내 활용(특히 wasm/rustwasm) 분야는 아직 미개척 상태로, 크로스브라우저 스택트레이스 등 여러 과제가 남아 있음
          + leptos, sycamore 등 프레임워크 발전이 지속적이지만, 여전히 개선 여지 있음
     * Rapid prototyping, 비즈니스 로직, GUI, 머신러닝, 게임개발 등 Rust가 아직 완전히 뚫지 못한 도메인도 지속적으로 개선될 것으로 기대

결론

     * Rust 성장의 미래는 매우 명확하고 희망적임
     * 도입이 늘수록 엔지니어링/테스트 역량이 커지고, 이로 인해 더 넓은 채택과 개선이 선순환을 이루는 구조
     * 다가오는 10년은 보다 빠른 컴파일, 다양한 분야에서의 적용, 매끄러운 개발 경험이 현실화될 것
     * Rust의 새로운 10년을 기대함

   러스트는 다 좋은데 언어가 너무 요구하는 것이 많아요.
   러스트를 사용하다 보면 아이디어의 구현 자체에 집중하기보다는 러스트라는 언어에 대한 연구를 하는 것 같아요.

   C++에서 옮긴다던지 하는 식으로 이미 만들어진 프로젝트를 옮기는 데에는 별 지장 없겠지만
   새로운 아이디어를 구현할 때 사용하는 것이 편한지는 잘 모르겠습니다.

   프로토타이핑으로 파이썬 추천드려요

   개인적으로 타입 시스템을 선호해서 현재는 C# 사용 중인데 이 정도면 만족스럽다고 생각합니다.

   개인적으로 지구환경을 생각한다면 RUST. Legacy 한 스프링 코드를 Axum으로 !!!

        Hacker News 의견

     * 매우 긍정적인 내용의 글이고 내 경험과도 맞아떨어짐. 다만 어두운 전망을 꼽으라면 이런 부분임:
       ""async는 static 바운드, 취소 안전성, 트레이트와 dyn 관련 제한 등으로 인해 비교적 높은 복잡도 비용을 가지고 있음. 현재로선 이 문제가 풀릴 기미가 없음. 동기/비동기 프리미티브 간의 분기와 생태계의 고유한 특성이 async tax(추가 비용)을 높임. Effects에 기반한 솔루션도 딱히 희망적이지 않음.""
       ""1.0 이전 Rust에는 libgreen이라는 해법이 있었음. bifurcation(분할) 없는 사용자 공간에서 동시성을 구현했지만, 성능, 이식성, 유지보수 비용이 상당해 결국 제거됨. 엔지니어링 역량만 충분하다면 다시 고민해볼 만한 가치가 있다고 생각함. 언젠가 std::{fs, net}와 fiber::{spawn, select}를 generator로 zero-cost wrapping한 PoC를 만들고 싶음""
          + ""'static bound이 복잡도를 높게 만든다""라는 논의는 Tokio async 러ntime의 설계 선택일 뿐 Rust 전체의 디자인이라고 보긴 어렵다는 의견임. Embassy async runtime은 이런 바운드 없이도 동작하지만, 대신 pinning을 직접 관리해야 함. 'static bound는 사실 복잡도 낮추려는 취지임
     * 2022년 말 Rust에 빠져 공부한 사람으로서, 2015년 같이 더 힘들었던 시절에 언어를 배운 분들의 경험담이 항상 흥미로움. Rust가 더 성숙한 시점에 배울 수 있어서 이미 가파른 러닝 커브가 다소 완화된 느낌을 받았고, 그 점에서 운이 좋았다고 생각함. 요즘은 글에서 언급한 Rust 초창기 경험담을 Zig에서 다시 겪고 있는 기분임. Zig는 Rust 초창기와 비슷한 시점에 있는 것 같음. 그래도 이미 재밌게 사용 중임
          + ""찾은 것보다 더 나은 상태로 남겨둘 것""이라는 문화가 강함. 툴이나 언어가 헷갈렸다면 사용자 잘못이 아니라는 생각이 자리잡음. 내가 혼동을 겪었다면 다른 이들도 겪을 테니, 발견할 때마다 개선하는 게 모두에게 큰 이득임. 나무 심는 데 두 번째로 좋은 때가 오늘이라는 속담이 적용됨. 이런 문화 덕분에 예전에 Rust를 시도했다가 좌절했던 사람이 1년 뒤라면 충분히 더 개선된 경험을 할 수 있음. 그래서 Rust 입문자에게 줄 최고의 조언은 ""6개월만 기다려봐""였음
          + MSFT, Google 같은 빅테크나 Linux 등 대형 오픈소스 프로젝트에 채택된 언어라면 이미 생태계가 충분히 성숙했다는 증거임. 하지만 Zig는 아직 기존 도구들에 비해 (큰) 변화를 보여주진 못해서 그런 확신이 없음
     * Rust는 함수형 프로그래밍을 장려하는 느낌을 받음. 원래는 내부 상태를 advance마다 변경하는 파서를 만들다, 가변성과 빌림체계(borrowing) 때문에 힘들어서 stateless 파서로 바꿔야 했음. 내부 인덱스 수정 대신 인덱스를 반환하는 구조로 변경하게 됨. 이런 식으로 기존 방식이 잘 안 먹혀서 Rust에서 새롭게 접근해야 하는 경우가 흔한지 궁금함
          + 나도 비슷한 경험이 있음. 단순한 경우라면 mutable, 명령형 스타일로도 문제 없지만, 복잡도가 커질수록 함수형 스타일로 바꾸고 변경을 최대한 피하게 됨. Borrow checker랑 라이프타임 때문에 전통적인 패턴이 어렵고 자연스럽게 함수형으로 가게 됨. 함수형으로 구현하는 게 익숙치 않으면 힘들 수 있지만, 컴파일러가 더 만족스러워지는 경험임
     * Async/await가 Rust를 사용하지 않는 유일한 이유임
          + 사실 async/await는 Rust를 써야 할 주요한 이유 중 하나라고 생각함. 동시성 패턴을 훨씬 간단하게 만들어 주기 때문임. 초반엔 뭔가 악성 전염병처럼 모든 코드가 결국 async가 되어야만 하는 느낌이었는데, async 코드와 상호작용하는 법 알게 되니 편해짐. 보통 spawn, spawn_blocking, futures::stream이 90%의 활용도를 차지하고, 적절하게 ""경계""를 세워두면 async가 전파될 필요도 없음
          + 어느 정도 이해는 됨. 하지만 나는 Rust에서 async/await가 딱 맞아떨어져서 가장 큰 사용 이유가 됨. 문법도 좋아하고 function colouring 문제도 별로 신경 쓰지 않음. 특히 tokio를 쓸 때 필요한 표준 함수의 async 버전이 다 있어서 솔루션이 잘 풀리는 느낌임. 이런 부분이 배리어를 만들 수도 있지만, 동시성 프로그램 짜기 훨씬 쉽고 퍼포먼스도 괜찮아서 만족함. 취소(cancellation) 같은 건 좀 헤매기도 하지만, 그건 내 실력 문제라고 생각함
          + 지금은 다 제공하고 있지 않나?
"
"https://news.hada.io/topic?id=21383","Show GN: 핫딜 모음 서비스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Show GN: 핫딜 모음 서비스

   핫딜성 글이 올라오는 사이트가 많은데, 크롤링을 통해 핫딜을 모아서 편하게 볼 수 있는 서비스를 만들어 보았습니다. (알구몬 같은)

   이용해 주시고 피드백 주시면 감사하겠습니다 .!

   좋은 정보가 많이 있어서 좋은 것 같습니다.

   다만, 다양한 사이트들에서 서로 정보를 공유하는 부분에 있어서 일정시간 이내에 비슷한 제목이 있는 경우 표기하지 않는 기능이 있으면 더욱 좋을 것 같습니다.

   의견 감사합니다 _ _

   안녕하세요, 별도로 연락처를 찾을 수 없어서 부득이하게 GeekNews 댓글로 연락드립니다.
   zod(조드)는 핫딜 관련 모음사이트에 대해서 등록절차만으로 내부 API를 개방해드리고 있습니다. 조드 사이트 하단의 제휴문의 이메일로 연락주시면 감사하겠습니다.

   메일로 연락 드렸습니다 ^^

   제가 필요했던 사이트입니다..
   애용하겠습니다

   감사합니다 ㅎㅎ

   폰에서는 글씨가 좀 작은것 같아요(S25사용중). 글씨 좀만 키워주시면 좋을 것 같습니다!

   왼쪽 최하단에 '설정' 모달 추가하였습니다
   각 설정 값은 localstorage에 저장되는점 참고 부탁드리겠습니다 ㅎㅎ

   https://github.com/dealmungchi

   발견 하셨군요^^

   모바일에서 쓰기에 깔끔하고 좋습니다 :)
   보다보면 제목에 가격이 표기되고 가격 입력란이 따로 없는 폼의 경우는 가격 정보 없음으로 나오는데
   제목에서 문자열 분석해서 가져와서 표시해주는 방법도 괜찮을 것 같아요

   의견 감사합니다
   반영 해보겠습니다 ㅎㅎ!
"
"https://news.hada.io/topic?id=21355","래디언트 AI는 대체 무엇이었나","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           래디언트 AI는 대체 무엇이었나

     * Oblivion의 리마스터 출시로 19년 전의 래디언트 AI 기술이 다시 화제가 됨
     * Bethesda는 해당 AI가 NPC의 자율적인 행동과 현실감 있는 스케줄을 제공한다고 약속했으나, 실제로는 구현이 제한적이었음
     * 사전 공개, E3 데모, 팬 인터뷰 등에서 과장된 홍보와 실상 사이의 괴리가 발생했음
     * 실제 구현 시스템은 목표 기반 AI 패키지 체계로, 복잡한 욕구나 진짜 자율성보다는 일정 중심의 행동을 설계함
     * 리마스터를 계기로 게임 AI 발전사와 한계에 대한 논의가 커지고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: Oblivion 리마스터와 레거시

     * The Elder Scrolls IV: Oblivion Remastered가 출시되면서 Bethesda의 고전 RPG에 대한 관심이 다시 추가됨
     * 리마스터는 Unreal Engine 5를 활용해 그래픽과 일부 UI를 전면 업그레이드했으나, 실제 게임 엔진과 콘텐츠는 2006년의 원작 구조를 그대로 사용함
     * Oblivion은 그 당시 기준으로 가장 야심찬 오픈월드, 혁신적 NPC AI, 그리고 완전한 음성 더빙을 포함해 큰 기대를 모았음
     * 주된 관심사는 Bethesda가 홍보했던 래디언트 AI(Radiant AI) 로, NPC가 실제 세계처럼 행동한다는 약속이었음
     * 이 기사에서는 해당 기술의 실제 내용, 구현 방식, 약속과 현실의 차이, 그리고 현재 위치까지 탐구함

Morrowind 시대: 그 이전의 Bethesda AI 환경

     * Morrowind는 핸드메이드 월드에 초점을 두었으나, 정해진 스케줄이나 AI 행동은 거의 존재하지 않음
     * NPC는 주로 제자리에 머물며 플레이어와 상호작용할 때만 행동을 변화시킴
     * Ultima, Arcanum, Gothic 등 당시 경쟁작들은 이미 일정 기반의 NPC 행동을 제공함
     * Bethesda는 이러한 한계를 Oblivion에서 혁신적인 AI 시스템으로 보완하고자 함

약속: 사전 홍보와 E3 데모

  공식 기사 및 홍보 발언

     * Bethesda는 2004년부터 언론에 Oblivion이 1,000명의 NPC가 각각 독립적 목표와 일정을 가진다고 소개함
     * 각 NPC가 ""목표를 부여받고 이를 스스로 여러 방법으로 달성""한다는 점을 강조함(예: 돈이 없으면 음식 훔치기, 사냥, 혹은 플레이어에게서 절도)
     * NPC 간 비스크립트 대화와 자유로운 일상생활도 약속사항에 포함되었음

  E3 2005 데모

     * Todd Howard가 직접 진행한 데모에서, NPC가 궁술을 연습하고, 필요시 물약을 활용하며 다양한 행동을 자율적으로 수행하는 예시가 제공됨
     * NPC가 필요에 따라 음식을 사거나 훔치거나, 농사로 얻는 행동 등의 시나리오가 시연됨
     * 이 데모는 각 NPC가 AI에 의해 자동으로 동기와 행동 방식을 결정한다는 인상을 부각시킴

  팬 인터뷰 및 개발자 설명

     * 공식 포럼과 AMA(Ask Me Anything)에서 개발팀은 ""목표-규칙 기반 인공지능""임을 강조함
     * 디자이너가 목표 및 특성(책임감, 공격성, 자신감 등)을 설정하면, 상황에 따라 행동이 변화하는 시스템임을 설명함
     * 개발 테스트 과정에서 AI가 지나치게 똑똑하게 동작하여 퀘스트 균형이 깨지거나 예측불허 행동(살인, 사기) 발생 사례가 빈번했다는 일화가 전해짐

  미확인 인용 및 AI 문제 사례

     * 팬 커뮤니티에선 테스트에서 NPC들이 필요 아이템 탈취, 경비병의 임무 이탈, 상점 약탈 등 의도치 않은 행동을 보였다는 다양한 이야기가 확산됨
     * 개발자가 의도적으로 이러한 AI 기능을 톤다운시키거나 개별 NPC 설정을 조정함으로써 게임 플레이의 안정성을 유지하려 함

  출시와 반응

     * Oblivion은 상업적으로 큰 성공을 거두었으나, 출시 후 AI 약속과 현실의 괴리에 대한 비판도 뒤따름
     * 복잡한 NPC 행동보다는, 실제로는 반복적이고 단순한 패턴 및 대화가 눈에 띄었다는 지적이 많음

Radiant AI란 무엇이었나?

     * Radiant AI는 오늘날의 생성형 AI, LLM, 신경망 등과는 무관하며, 목표/규칙 기반의 전통적 비실시간 인공지능 시스템임
     * 실제로는 한 가지 기술적 구조가 아니라, 확장된 캐릭터 시스템, AI 패키지 시스템, 대화 시스템 등 여러 기능의 통합 개념임
     * 패키지 시스템이 실제 가장 핵심적인 심장부로, NPC의 일정과 행동 패턴을 구동하는 역할을 담당함

  캐릭터 특성 및 행동 변수

     * Oblivion의 모든 NPC/크리처(액터) 는 플레이어와 유사한 능력치, 인벤토리, 기술, 소속 등을 가짐
     * 가장 중요한 AI 속성으로는:
          + Disposition(호감도): 다른 캐릭터에 대한 친화/적대 수치, 행동에 영향을 미침
          + Aggression(공격성): 얼마나 적대적으로 변할 수 있는지 결정함
          + Confidence(자신감): 전투 중 언제 도망칠지 결정함
          + Energy(활력): Wandering 등 이동 행동 빈도에 영향을 미침
          + Responsibility(책임감): 법을 얼마나 준수하는지, 범죄 행위에 대한 태도 결정
     * Oblivion NPC에는 실제 Sims 스타일의 욕구(배고픔/수면 등)는 존재하지 않음. ‘일정에 따라 행동은 하지만, 이를 안 지킬 경우의 패널티나 진짜 자율욕구는 없음’이 한계임

  AI 패키지 시스템

     * 각 NPC는 한 개 이상 패키지를 할당받아 행동방식과 일정을 갖춤
     * 패키지 종류는 Travel(이동), Wander(임의 이동), Find(대상/아이템 탐색), Eat(식사), UseItemAt(아이템 활용), Sleep(수면) 등으로 다양함
     * Find·Eat 등 일부 패키지는 Responsibility 속성에 따라 범죄(도둑질, 약탈)를 유발할 수 있음
     * 실제로 많은 예상치 못한 AI 일화(가게 약탈, 사냥, NPC끼리 전투 등)는 이 패키지/속성 조합에서 비롯됨

  AI 패키지 일정/조건

     * 각 패키지는 활성화 가능 시간표와 조건식을 가지며, 일정과 게임 상황에 따라 자동 전환됨
     * 조건은 다양한 액터/월드/플레이어 상태 함수값 조합 및 비교로 표현되어 NPC의 복합적인 컨텍스트 기반 행동을 가능하게 설계함
     * 이는 디자이너가 복잡한 스크립트 없이도 일정한 생활 패턴을 설계할 수 있는 장점 제공

결론

     * Radiant AI는 Bethesda가 현실감 있는 게임 세계와 자율적 NPC를 약속하며 내세운 주요 기술적 슬로건이었음
     * 실제 구현은 목표-규칙 기반 AI 패키지 시스템으로, 정해진 일정과 조건하에 NPC가 다양한 행동을 보이게끔 설계됨
     * 내부 테스트에선 놀라운 자율성과 예측불허 행동도 많았으나, 최종 출시는 플레이어 경험과 균형 문제로 인해 상당 부분 제약되거나 조정됨
     * 출시 이후에도 해당 시스템의 한계 및 실제 작동 방식에 대해 팬들과 모더 커뮤니티에서 논의가 지속되고 있음
     * Oblivion Remaster로 인해 Radiant AI와 같은 게임 AI 기술의 발전과 한계, 게임 디자인에서의 균형 문제가 다시 주목받고 있음

        Hacker News 의견

     * Radiant AI와 가장 가까운 구현은 Dwarf Fortress라고 생각함. 이런 완전히 목표 중심적이고 예측불가한 게임 AI 시스템은 스토리 기반 게임플레이와 충돌함. 스토리 중심 게임은 결과가 결정론적이어야 하고 플레이어가 주인공임. 반면 Dwarf Fortress는 미리 정해진 스토리도 없고 돌봐야 할 플레이어 캐릭터도 없음. 요새 전체가 황당할 만큼 예측 불가한 사건으로 전멸하는 것 자체가 큰 재미임
          + Dwarf Fortress와 비슷한 게임으로 Song of Syx가 있음. DF보다 훨씬 접근성이 좋고, 최대 2만 개의 엔티티를 동시에 다룸. 월드맵도 크고 플레이어는 여러 집단 중 하나만 조종함. 개별 엔티티도 Song of Syx에서 모두 모델링함(DF만큼의 디테일은 아니지만)
            Songs of Syx on Steam
          + 나도 비슷하게 생각함. 이런 시뮬레이션을 100시간 돌아갔을 때 세상이 어떻게 되는지 궁금함. 주민 절반이 경비병에게 죽고 상점 주인이 사라지면 게임이 제대로 굴러가지 않음. 복잡한 시뮬에서 등장하는 emergent behavior는 조정하기 매우 어려움. 또 하나 섬세한 문제는, NPC가 전부 항상 활성화되어야 한다는 점임. 엄청 많은 엔티티를 1프레임 CPU 예산에 우겨넣어야 함. 경로탐색, 오브젝트 상호작용 같은 것도 월드 전체에 대한 정보(오브젝트 위치, 경로맵 등)가 계속 메모리에 있어야만 가능함. 당시 2005년 PC로는 정말 도전적인 과제였음
          + Oblivion 이후로는 Divinity: Original Sin 1,2 같은 게임이 나왔는데, 여기서는 거의 모든 캐릭터를 죽여도 엔딩 가능함. 중요한 NPC는 'essential' 플래그를 써서, 플레이어가 맞다이로 죽이지 않는 이상 사고로는 죽지 않게도 할 수 있음. Radiant AI도 스토리상 중요한 NPC에는 적용하지 않으면 됨. Bethesda 게임은 사실 메인 스토리가 가장 큰 강점은 아님
          + Ultima 시리즈 일부와 Morrowind 역시 NPC가 '자고, 가게 열고, 가족 방문하고, 탐험하는' 등 일상적인 루틴을 시뮬레이션한 적 있음
          + 수학적으로 이런 현상을 표현할 수 있을 것 같음. Todd Howard가 말한 Radiant Economy 컨셉을 동적 시스템이나 게임이론 모델로 만들어서, 장기적으로 모두가 빈털터리나 억만장자가 되는지도 증명해보고 싶음
     * skooma 상인 NPC 살해 일화 반박에 관해 언급하자면, 중요한 디테일이 빠졌음. 모든 스쿠마 중독자가 오두막 안에 있는 건 아님. 월드맵엔 도시 간을 오가며 오두막을 찾으려 다니는 두 명의 NPC가 따로 있음. 그런데 버그로 이 NPC들이 잘못된 파벌로 지정되어 문을 통과할 수 없어서, 플레이어가 문을 안 열어주면 평생 밖에서 스쿠마만 마시게 됨
       관련 위키 링크
          + 흥미로운 정보임. 세 NPC 모두의 AI 패키지를 봤는데, 기본 게임에선 이들이 스쿠마를 소지하지도 않고 스쿠마 찾으려 하지도 않음. 대사와 환경 스토리텔링 상으론 중독자지만, 기술적으로는 중독자가 아님. 오두막 밖에 멈추는 건 사실임. 근데 파벌 문제보단 단순히 키가 없어서 못 들어가는 게 원인임
     * Starfield를 플레이해보고, 이제는 Bethesda가 더 이상 뭔가 특별한 걸 보여줄 거라는 기대감이 없음. Oblivion 때부터 Starfield까지, 독특한 재미를 위해 위험 감수하던 소규모 개발사 느낌에서, 무난하고 예측 가능한 AAA 스튜디오로 바뀌었음. Radiant AI도 '무한 반복 퀘스트에 X * Y 컨텐츠' 트릭에만 활용되고 있는데, 진짜 목적은 세상에 생명을 불어넣는 거였음. 같은 개념을 보고 싶으면 Dwarf Fortress를 추천함. DF 월드는 플레이어가 들어가기 전까지 수천 번의 Radiant AI 상호작용으로 이루어진 히스토리가 있고, 그 이후 플레이어가 세계의 일부가 됨. 여기에 LLM 기반 캐릭터/대화가 추가되면 훨씬 살아 있는 느낌을 줄 수 있을 거라 생각함
          + 내 생각에 Starfield는 개발자들이 예전 게임의 매력을 이해하지 못했거나, 문제를 막아줄 리더십이 없는 걸 대대적으로 보여준 사례임. Skyrim, FO4 같은 최근 TES 게임은 환경/스토리텔링, 탐험, 전투, 제작이 핵심임. 근데 Starfield는 수백 개의 행성을 프로시저럴로 만들었고, 그 결과 볼만한 게 없음. 환경/스토리텔링도 불가능. 탐험은 로딩 화면 연속이 전부임. 이런 게임 컨셉이 근본적으로 잘못됐다는 걸 아무도 말려주지 않은 게 신기함. Bethesda가 자기 성공작의 근본을 모르면 후속작 만드는 것도 어렵다고 생각함
          + Starfield의 가장 큰 실패는 창의성 부족임. 스토리, 대사, 연기 등 어느 면에서도 흥미로운 면이 없음. 이는 게임 엔진 같은 기술 문제가 아니라 Bold personality가 필요한 부분임. RDR2, Witcher 3 같은 게임은 개성이 강했는데 Starfield는 무미건조한 Corporate Memphis 스타일임
          + AI로 무한하게 밋밋한 퀘스트를 만드는 전략은 타깃 오디언스가 없음. 1-2회만 엔딩 보는 유저에겐 관심사 아니고, 더 원하는 사람들은 커뮤니티 모드를 써버림. 결국엔 ""동굴 가서 몬스터 잡기"" 같은 의미 없는 반복만 늘어날 뿐임
          + Starfield는 평가받는 것보다 과하게 까이는 측면도 있음. 확실히 Fallout 4처럼 100피트마다 어딘가 관찰하거나 상호작용할 수 있는 것이 있지는 않고, 월드가 휑하게 느껴짐. 하지만 이건 의도적인 변화로 느껴짐. 오히려 Daggerfall의 정신적 후계작에 가까웠음. 예전 Bethesda 타이틀에 비해 플레이는 적었지만 오히려 중간중간 색다름이 있었음. 같은 공식만 매번 반복하는 것보다 이런 변화가 필요하다고 생각함
          + Morrowind에서 Starfield까지 오면서, Oblivion은 Morrowind보다도 퇴행이 있었다고 봄. 예술적 특색이나 맵 표식, 스토리 깊이 폄하 등
     * Bethesda 팬으로서 Fallout과 Skyrim에서 수천시간 플레이한 입장에서 이번 포스트를 매우 재미있게 읽음. 특히 다양한 상황에서 직접 NPC를 만들어 테스트하는 접근이 좋았음. 최근에야 Oblivion 리마스터를 처음 해보고 있는데, NPC 상호작용 및 생동감이 후속작보다 더 마음에 듦. Todd Howard가 언급했던 전투 도중 단검을 주워서 상대하는 장면은 실제 게임에선 스크립트 없이는 불가능하다는 설명에도 동의함. 그렇지만 Fallout 3에서 비슷한 걸 본 적 있음. Megaton의 내 집(별도의 cell)에 숨겨둔 무기를 NPC가 관여하는 사건이 발생해, 결국 집을 바꾸는 모드를 설치하고 G.E.C.K.를 배워 수정하게 된 계기가 됨
          + 흥미로운 일화임. 하지만 시스템 구조상 NPC가 플레이어 집 내부 cell에 접근할 수 없어서 그 상황이 생길 수 없음. 엔진 구조상 외부에 있을 때 집 내부는 메모리에 안 올라와있기 때문에 모든 시리즈가 동일함. 아니라는 증거가 있으면 보고 싶음
     * Gothic을 플레이하다 야생에서 죽을 뻔했는데, 핵심 NPC가 우연히 나타나서 야수를 처치해줬던 기억이 있음. 해당 NPC는 매일 두 캠프 사이를 오가는데, 마침 그 위치에 있어서 개입했었음. AI가 정말 인상적이었고, 동시에 반경 안에 들어오면 나타나서 상호작용하는 식이었음. Radiant AI도 이런 식으로 만들었으면 좋겠다는 생각을 했음
          + Oblivion에도 도시 간을 오가는 복잡한 스케줄의 NPC가 여럿 있음. 제일 유명한 예시는 Leyawin의 백작부인인데, 한 달에 한 번 어머니가 있는 Chorrol까지 호위와 함께 방문함
          + Radiant AI가 딱 그런 식으로 작동함. 게임이 cell 단위 글로벌 경로그래프를 항상 메모리에 두고, 로딩되지 않은 지역에서도 NPC의 여행을 시뮬레이션함
     * ""모두가 도둑질하다 수감 혹은 사망하는"" Radiant AI 초기 일화를 듣고, 아래 특성들은 상충 관계라고 느끼기 시작함:
       – 항상 충분히 흥미로운 캐릭터가 있어야 함
       – 라이브 시뮬+emergent behavior로 캐릭터가 사라질 수 있음
       – 누구도 마을에 새로 오거나 나가지 않음
          + ""항상 충분한 흥미로운 캐릭터"" 문제는, 중요한 NPC가 죽으면 후계자에게 역할을 넘기는 시스템으로 해결 가능함. 동시에 세계 자체가 살인마 천지가 아니고, 진짜로 폐쇄 경제가 존재해야 함. 또한 음성 데이터를 DVD 하나에 담아야 하는 한계(역할승계가 오히려 문제를 심화함)도 언급됐는데, 만약 AI 음성 합성이 앞으로 디테일하게 해결된다면 실제로 보이스 오버 문제를 해결할 수도 있음. 단, 인공물의 어색함이 더 문제일 수 있음. 개별 단어의 음소만 텍스트->음소로 변환하는 식으로 처리하는 방법이 적당할 수 있음
          + 사실상 ""어느 정도의 시뮬/현실성""과 ""플레이어 기대치를 충족하는 만큼의 시간당 이벤트 밀도""는 조화롭게 양립할 수 없음. 사회적으로 건강하게 돌아가는 시스템에서는 감옥, 애정행각, 납치, 결혼, 치정, 암투 등 이 정도 속도로 계속 이벤트를 공급할 수가 없음. 그래서 TV쇼도 몇 시즌만 지나면 이상해지는 것임. Dwarf Fortress는 배경을 더 크게(캐릭터 수 확대) 잡는 동시에, 판타지 요소로 생산성을 과장시킴. 예를 들어 1명의 드워프가 25㎡ 균밭에서 파트타임으로 15명을 먹여 살릴 수 있게 만드는 식임
     * 글을 읽고 나니, 최신 AI와 오픈월드 시뮬의 만남이 궁금해짐. 단순히 그래픽만 예쁜 게 아니라 실제로 추론하는 NPC가 등장하는 식. 예를 들어 World of Warcraft의 여관 NPC와 에일 가격 흥정하는 상호작용. 정말 보고 싶음
          + 나는 챗봇 연결보다는 AI가 씬 전체를 지휘하고 여러 캐릭터의 반응을 조율하는 쪽이 더 흥미로움. 고도화된 AI가 직접 각각 캐릭터를 똑똑하게 만드는 게 아니라, 던전마스터처럼 플레이어 행동에 전세계적으로 일관된 반응을 만들어줌
          + 100% 정확도로 주제 밖 발화 제어가 불가능함. 예를 들어 NPC에게 미국 정치 얘기를 꺼내도 대답할 수 있음. 자유형 대화를 막아도 몰입 깨는 이상한 발화 많이 나올 거임. 게다가 토큰 비용도 문제임
          + LLM의 '환각'이 단점이 아니라 오히려 재미적 요소가 될 수도 있는 자리
          + 난 버튼 클릭 한 번에 에일 받는 게 더 좋음. 온라인에서나 말싸움 하고 싶음. AI 기반 게임에 쓰일 자리도 분명 있지만, 그게 게임 전반에서 꽉 채워질 필요는 없음. 미리 쓰여진 대사가 장기적으로 더 즐거움
     * Radiant AI라는 단어를 2005년쯤 Oblivion 마케팅 때 기억함. 나한테도 그만큼 인상적이었음. 하이프도 있었고 실망도 있었지만, 실제로 구현됐다면 정말 멋진 기능이었을 거라는 아쉬움도 남아있음
     *

     ""Hail.""
     ""I have heard that the Nords of Skyrim have been warring with the Redoran of Morrowind.""
     ""It seems that these are turbulent times in the land of the Dunmer.""
     ""Stop talking!""
     ""Take care""
     * 정말 대단하게 리서치된 흥미로운 글임. 저자가 이런 방대한 조사를 해줘서 고마움. Todd Howard 특유의 '현실 왜곡장'을 벗겨내, 유명했던 E3 2005 데모에서 실제 출시작까지 어떻게 변했는지 알 수 있음
          + 좋은 말을 해줘서 고마움! 리서치와 집필에 2주가 넘는 여가시간을 투입했지만 결과적으로 가치 있는 경험이었다고 생각함
"
"https://news.hada.io/topic?id=21332","항공 분야에 대해 프로그래머들이 믿는 잘못된 상식들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      항공 분야에 대해 프로그래머들이 믿는 잘못된 상식들

     * 항공 데이터는 복잡하고 비표준적인 특성이 많음
     * 항공편, 공항, 네비게이션, 트랜스폰더 정보 등에 대해 개발자가 흔히 잘못된 가정을 함
     * 실제 비행 추적 시스템은 다양한 예외 상황과 데이터 이상현상에 유연하게 대응해야 함
     * 많은 오해는 소프트웨어나 고객 시스템에서 예상치 못한 오류를 야기함
     * 데이터 설계 시에는 현실의 복잡성을 면밀히 반영하는 관점이 필요함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

   FlightAware는 전 세계 항공 데이터를 처리 및 배포하는 소프트웨어를 개발하는 기업임. 그러나 실제 항공 데이터는 직관과 달리 정형적이지 않고 예외와 변칙이 많음. 많은 개발자는 데이터 구조, 흐름, 식별 체계 등에서 여러 전제를 가정하지만, 이는 현실에서 잘못된 가정으로 작용하여 시스템의 오류와 불일치를 초래함. 이 글은 이름 잘못된 상식 시리즈의 연장선에서, 항공 산업 내 소프트웨어에서 빈번하게 저지르는 오해와 그로 인해 발생하는 사례들을 정리함.

Flights (항공편 정보)

     * 항공편은 항상 게이트에서 출발한다는 오해가 있지만, 실제로는 여러 번 게이트를 이동하거나, 예정보다 아주 늦거나 빠르게 출발하는 경우가 있음
     * 항공편 스케줄이나 출발·도착 공항이 명확하다고 생각하기 쉽지만, 헬리콥터·군용기 등은 공항이 아닌 곳에서 이착륙하는 사례가 존재함
     * 항공편의 비행시간이나 스케줄이 규칙적일 것 같지만, 며칠에 걸쳐 진행되는 장기 비행이나 변칙적 운항도 빈번함
     * 항공편 식별번호(예: UAL1234)가 유일하다고 가정하기 쉽지만, 실제로는 한 항공기에 여러 식별자나 번호가 부여되며, 동일 번호가 여러 상황에서 사용될 수 있음
     * 표기상 같은 번호라도 항공편 식별자, 등록번호, 기타 표식이 혼재되어 혼란을 초래하고, 티켓, 관제, 조종사마다 사용하는 식별 정보가 다를 수 있음

Airports (공항 정보)

     * 공항 위치와 식별 코드가 고정적이라고 생각될 수 있으나, 실제로는 공항이 폐쇄, 이전·통합되는 경우가 있어 위치나 코드가 변경됨
     * 터미널/게이트 번호, 활주로 등의 명칭 체계도 일관되지 않고 예외적인 규칙이 많음
     * ICAO/IATA 코드 체계에 대해서도 중복, 복수 코드 부여, 위치 코드 오해 등 현실과 맞지 않는 사례가 다수 존재함
     * 어떤 식별정보(예: IATA 코드)가 있다고 반드시 실제 공항임을 보장하지 않으며, 철도역·버스터미널 등에 IATA 코드가 부여된 사례도 존재함
     * 심지어 ICAO 코드 중에는 지구가 아닌 곳(예: 외계 크레이터)에 할당된 경우도 있음

Airlines (항공사 정보)

     * 별도의 라인에서 구체적인 잘못된 상식들이 언급되지 않았으므로 생략함

Navigation (항법 및 항로 정보)

     * 웨이포인트 명칭이 고유할 것이라는 오해가 있으나, 실제론 중복이 있음
     * 항공에서 사용하는 고도 정의는 하나로 통일되어 있지 않고, 여러 기준에 따라 다르게 해석됨
     * 항공관제 데이터가 완벽히 정확하다고 생각할 수 있으나, 실제로는 오류 또는 변경이 자주 발생함
     * 항공편 계획의 취소, 플랜 변경 등이 실제 비행에 반영되지 않거나, 동일 항공편이 여러 번 목적지를 변경할 수 있음
     * 레이더, 항공관제 기관 간 데이터 불일치나, 동시 관측의 위치 괴리 현상도 존재함

Transponders and ADS-B (트랜스폰더 및 ADS-B 관련 정보)

     * ADS-B 신호가 비행기에서만 송신된다고 가정하지만, 공항 차량·기타 장치에서도 송신될 수 있음
     * GPS 좌표의 정확성, 신호의 신뢰성에 대한 과신 역시 오해임
     * 트랜스폰더 등록정보(식별 번호, 모드 S 어드레스 등) 오류‧중복, 유지보수 누락, 포맷 오류 등으로 실시간 데이터와 실제 정보 간 불일치가 빈번함
     * ADS-B 정보가 그대로 수신/저장된다고 생각하기 쉽지만, 전송 오류, 신호 위조 등 다양한 이슈가 발생함
     * 기기 고장, 관리 부주의, 외부 요인(예: 쥐의 케이블 훼손) 역시 현실적 변수임

마무리

   이 목록은 FlightAware 및 Hyperfeed 개발팀이 다년간 수많은 실제 사례에서 얻은 경험과 인사이트를 바탕으로 구성된 항공 데이터 신뢰성의 복잡성을 보여줌. 각종 오류와 오해를 줄이기 위해, 실존하는 예외 상황을 철저히 고려한 데이터 모델링 및 운용의 중요성을 강조함.

   읽기만 해도 혈압 오르네요 ㅋㅋ

   본문이 정말 간결한데, 내재된 감정이;;

   데이터 표준화가 이래서...중요한..ㅎㅎ

        Hacker News 의견

     * 항공기에는 시간에 따라 변하지 않는 단일 유일 식별자가 없는 상황 설명. 각 비행체에는 일련번호가 부여되지만, 이것만으로는 유일성을 담보하지 못한다는 실제 경험 공유. ""제조사, 기종, 일련번호""의 조합이 그나마 일생에 걸쳐 유일 식별자가 되지만, 기체가 구조 변경으로 타입이 달라지면 이마저 변하는 경우 존재. 항공처럼 거대하고 복잡한 시스템에 변하지 않는 식별자가 없는 게 신기하다고 느끼는 개인적 감상 추가. 항공기 등록 번호(꼬리번호)는 자동차 번호판처럼 바뀌고, ICAO 24비트 식별자는 ADS-B 장비에 연결돼있어 이동/변경이 자유로운 특성까지 설명
          + ""제조사, 기종, 일련번호"" 조합이 특허 대상이 된 점이 신기하다는 호기심 표현. 어떻게 이런 게 새롭다고 인정받아 특허가 될 수 있었는지 궁금증 제기
          + 이 이야기를 '테세우스의 배' 역설과 연결하여, 항공기의 정체성과 식별자 변화에 관한 철학적 연상 소개 Ship of Theseus 위키피디아 링크
          + 항공 산업이 국가별로 사일로처럼 각각 다르게 발전해 표준화가 늦었다는 역사적 배경 공유. 세계적 표준이 제대로 정착된 자체가 놀라운 일이라고 보는 시각. 현재 대형 제조사들이 소수로 통합되어서 그나마 가능한 상황이라는 분석
          + 실제 환경에서 ""진정한"" 유일 식별자가 중요한 문제로 자주 등장한다는 현장 경험 공유. 해결책은 거의 항상 “모델, 제조사, 일련번호” 조합이며, 필요하다면 생산연도까지 추가. 심지어 인간 데이터도 언어(모국어) 같은 기준으로 de-duplication 시도했던 사례 언급
          + 활주로번호도 시간이 지나며 바뀌는 예시로 위키 문서 Runway 위키피디아 링크 공유
     * 이런 리스트들은 항상 더 자세한 설명이 붙으면 훨씬 유익했을 거라는 의견. 하지만 링크된 출처 정보 중에는 유익한 게 많아, 예를 들어 '화성의 분화구에 ICAO 공항 코드가 부여된 사례(JZRO)' 소개 Jezero 분화구 위키피디아 링크, 출발은 정상인데 40시간 후착륙 지연 항공편 예시
          + 리스트에 적힌 사례들이 사실 지루한 사유 때문이 많다고 지적. 예컨대 2주짜리 비행은 Google Balloon이며, 40시간 지연은 단순히 나쁜 날씨, ADS-B 값은 조종사가 입력하는데 종종 실수한다는 배경 설명
     * 제조사-기종-일련번호 조합이 너무나 자명해 보이는데 그게 어떻게 특허가 됐으며, 지금 누군가 그 특허로 이익을 취하고 있는지 의문 제기
     * 비행 데이터 분석 소프트웨어 개발 경험에서, 헬리콥터/비행기 모두 다양한 곳(병원, 옥상, 주차장, 운동장, 공항, 골프장 등)에서 이착륙하므로 “항공에 관한 온갖 거짓말” 속에서 대부분의 시간을 보내는 실제 개발자 고충
     * ""Falsehoods..."" 시리즈 글을 볼 때마다 많은 개발자가 인간 중심의 시스템이 엄격한 규칙만 따르리란 착각에 빠지는 점이 흥미롭다고 보는 시각
          + 개발자는 모든 것을 엄격한 규칙 체계로 환원하는 걸 좋아하지만 실제 세상은 그렇지 않음을 인정
          + 프로그래밍이라는 직업 자체가 유연한 인간 시스템과 엄격한 규칙기반 기계 사이 인터페이스라는 본질을 가지고 있다는 분석
          + 프로그래머 입장에서 세상을 소프트웨어로 모델링할 때 이러이러한 전제를 당연하다고 생각하지만, 실제로는 전혀 그렇지 못해 겪는 딜레마와 혼돈 공유. 예를 들어, 비행편에는 출발/도착 공항이 당연히 있다고 가정하지만 현실은 다르다는 예시
          + 소프트웨어 본질상 도메인 모델링을 반드시 규칙 세트로 만들어야만 한다고 주장. 만약 규칙이 없다면 아무 기능도 제공할 수 없기 때문. 일반인에게 '윤초(leap second)' 같은 예외를 설명하면 헛소리라고 오해하기 쉬운 만큼, 오히려 개발자가 세상의 예외와 복잡함을 잘 인식하는 경우 많다는 주장
     * ""Falsehoods Programmers Believe..."" 시리즈에서 각 항목을 테스트 케이스로 취급하는 방법 제시. 프로그램에 잘못 내재된 가정들을 검증하는 단위/통합 테스트로 확장 가능
          + 실제로 각 항목별로 테스트가 만들어졌고, 근무 당시엔 일상적인 것부터 극단적인 것까지 천 개가 넘는 테스트가 있었던 경험. 품질과 엔지니어링에 큰 가치를 두던 팀이었다는 회상
     * ""항공편은 공항에서 이/착륙한다""는 전제가 과거 브라질 항공 시스템에 무조건 있었으며, 이를 임시방편으로 해결한 사례 언급. ""공항/활주로는 위치나 방향이 변하지 않는다"" 역시 너무 자주 잘못 가정된다는 비판. ""항공기는 활주로나 헬리포트에서만 착륙한다""는 전제까지 추가해야 한다는 제안
          + 브라질의 오래된 항공 시스템들이 이런 문제를 어떻게 임시처리했는지 더 자세히 알고 싶다는 질문
     * CGP Grey의 공항 코드의 엉망진창인 과정을 잘 요약한 영상 공유 YouTube 링크. 시스템의 독특한 사정까지 설명
     * 동일한 주제를 다루는 FlightAware 포럼 관련 토론도 소개 FlightAware 포럼 링크
     * 프로그래머 입장에서 이 리스트의 모든 전제를 합리적이라고 생각했다가, 뒤늦게 고통스럽게 현실을 깨닫는 과정에서 머리가 폭발하는 기분 공유. 훌륭한 요약이었다는 찬사
"
"https://news.hada.io/topic?id=21316","메타는 침해적인 AI Discover 피드를 즉시 중단하라","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    메타는 침해적인 AI Discover 피드를 즉시 중단하라

     * Meta가 AI 채팅에서 생성된 개인적 대화 내용을 사용자 동의 없이 Discover 피드에 공개함으로써 사생활 침해 우려가 확산됨
     * Mozilla 커뮤니티는 Discover 피드 중단, 기본적인 AI 대화 비공개 설정, 이용자 동의 기반의 정보 공개, 투명성 제공을 요구함
     * 누구나 쉽게 이용할 수 있는 전체 opt-out 시스템 구축, 비공개 대화 공개 시 영구 삭제 권한 부여가 필요함
     * 많은 사람들이 개인 정보가 공개적으로 유출되는 사실을 인지하지 못하고 있음
     * 이 캠페인은 명확한 사전 동의 없이 사용자 대화 내용이 공개되지 않도록 보장할 것을 촉구함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

내용 요약

  프라이버시 침해 우려

     * Meta가 자사 인공지능(AI) 서비스 이용 시 이루어진 개인적 대화 내용을 Discover 피드를 통해 공공 콘텐츠로 전환함을 조용히 진행함
     * 다수의 사용자가 자신이 입력한 대화 내용이 공적으로 공개된다는 사실을 인식하지 못하는 상황임

  Mozilla 커뮤니티의 요구사항

    1. Discover 피드의 즉각적인 중단
          + 실제 프라이버시 보호 장치가 구축될 때까지 Discover 피드를 중단할 것을 촉구함
    2. AI 대화 기본 비공개화
          + 모든 AI 상호작용을 기본적으로 비공개 설정으로 유지하고, 충분한 정보와 동의가 없는 한 공개 기능을 허용하지 않을 것을 요구함
    3. 투명성 제공 요청
          + 몇 명의 사용자가 사전 인지 또는 동의 없이 개인 정보를 공유했는지 명확한 수치를 공개할 것을 요구함
    4. 보편적인 opt-out 시스템 구축
          + 누구나 쉽게 접근 가능한 opt-out 시스템을 Meta 전 플랫폼에 제공하여, 개인 데이터가 AI 학습에 활용되지 않도록 해야 함
    5. 알림 및 삭제 권한 제공
          + 비공개 대화가 공개된 사용자에게 즉시 알림을 제공하고, 원하는 경우 해당 콘텐츠를 영구적으로 삭제할 수 있는 권한을 부여해야 함

  사생활과 공공 영역의 경계 모호화

     * Meta의 정책 변화로 인해 개인 대화와 공공 콘텐츠의 경계가 모호해짐
     * 사람들은 개인적 공간에서 대화한다고 믿으나, 실제론 공개적으로 정보가 확산되는 위험 요인이 존재함

  캠페인 및 서명 촉구

     * 개인 동의 없이 대화 내용이 공개되는 행위 중단과, 명확한 사용자 선택권 보장을 위한 캠페인 진행 중
     * 캠페인에 동의하는 사용자는 이름을 남겨 Meta의 정책 변경을 촉구하는 서명 운동에 참여 가능함

        Hacker News 의견

     * Meta가 새롭게 출시한 독립형 AI 앱 관련 기사 링크를 공유함과 동시에, 대화 내용이 공개되는 게 사용자 실수 때문이라는 점을 언급함. 기본적으로 대화는 비공개 설정이지만, “공유” 버튼을 눌러야 공개가 되는 구조임을 강조함. Mozilla 쪽의 강경한 워딩은 사용자 경험에 대해 오해가 생기게 만들 수 있다는 생각을 밝힘
          + Google Docs, ChatGPT, Notion 등 다양한 서비스들이 ‘링크만 가진 사람에게만 공유’와 ‘공유한 내용을 공개 검색 가능, 전체 공개’ 차이를 명확히 둠을 언급. 만약 Meta가 공유 버튼을 통해 곧바로 검색 가능하게 만들거나, 이런 구분 자체를 제공하지 않는다면 명확히 어두운 패턴이라는 주장. “공유” 아이콘 클릭이 진짜 제대로 된 동의라고 할 수 없다는 문제의식 제시
          + 실제 앱 사용 경험은 없지만, 기사에서는 사용자가 어떻게 공유에 동의하게 되는지가 안 나와 혼란스러움을 토로. 일반적으로 다른 앱은 공유 버튼 후, 수신자를 정하고 공유 방법을 고르는 모달이 나오는 식인데, 만약 “공유” 즉시 전 세계에 바로 공개되어 버린다면 누구라도 당황할 만한 상황이라 생각함
          + 기사 링크 제공과 함께 Mozilla의 청원(petition)이 실질적으로 도움되는 맥락을 거의 담지 않아 아쉽다는 의견 제시
          + 본인은 실제 앱을 사용 중이지만, 한 번도 공유하라고 권유받거나 알림을 받은 적 없음을 이야기함
          + 공유된 기사 내용이 원인과 논점이 명확하지 않고 매우 모호하게 느껴졌다는 피드백 제공
     * 직접 앱을 사용해봤을 때 Mozilla가 거짓 정보를 퍼뜨린다고밖에 해석할 수 없다는 생각. 이 앱의 공유는 그냥 다른 소셜 미디어 앱과 완전히 동일. 앱 우측 상단에 “Share” 버튼이 있고, 누르면 하단에 “Post” 버튼이 크게 나타남. 누르면 그 대화가 퍼블릭으로 공유됨.
          + Mozilla의 요구사항 중 대부분은 이미 만족되고 있다고 설명함: 기본적으로 모든 대화는 비공개, 공개 여부는 명확하게 보임, Meta가 사용자가 얼마나 많은 개인정보를 실수로 공개했는지 투명하게 밝힐 필요가 있냐는 점에 동의하지 않음, 유럽에서는 이미 opt-out 기능이 존재, 공개된 사람에게 알림과 영구삭제 기능도 이미 제공
               o “공유”라는 버튼이 특정인 지정이 아니라 전체 공개로 동작해서, 많은 사람들이 원치 않게 전 세계에 공유한다는 어두운 패턴 문제 지적. 대다수에게 “공유”는 개인간의 전달이나 제한적 접근을 떠올리고, 공개는 전혀 의도하지 않았을 수 있다는 의견
               o 실제 사용자는 아니지만, 공유한 콘텐츠가 친구들에게만 보일 걸로 오해하는 게 문제의 핵심이라는 지적
               o “내가 다른 사람과 같은 화면을 보고 있나?”라는 질문 제기. Meta의 본질적 문제는 일관성 없는 UI와 어두운 패턴, 각 팀이 경쟁적으로 사용자 행동을 유도하며 실제로는 친구나 게시물을 의도치 않게 공유하게 만드는 디자인이라는 주장. 지역·언어마다 경험이 다르고, Meta Business Suite는 특히 온통 미로 같은 어두운 패턴으로 가득함
               o 실수로 정보를 공개한 사용자가 몇 명인지 투명하게 밝혀야 한다는 요구에 동의하지 않음. 사용자가 실수로 공개한 것인지, 의도했는지 Meta가 알 수 없다는 점을 지적
               o Mozilla가 예전에도 의심스러운 부가 기능 설치, 서드파티 서비스 통합, 사용 내역 무단 전송, 구글 트래킹 강제 등 신뢰를 깨는 행동을 반복했다며, 왜 Mozilla가 거짓말을 하는지도 이런 행보의 연장선이라는 시각
     * Mozilla의 글이 문제를 제대로 설명하지 않아서 직접 Meta AI 앱을 체험.
          + 채팅 화면에 “Share” 버튼, 누르면 초안 페이지 아래 “Post” 버튼이 나옴, 이를 누르면 채팅이 Discover 탭으로 전체 공개됨, 이후 “전송” 아이콘으로 링크를 개별 전달 가능
          + 이런 구조는 명백한 다크 패턴이고, 전체 공개 없이 친지나 한 사람에게만 간단히 링크 공유하는 방법이 없다는 점이 불만
          + 실제로 Discover 탭에서 가장 위의 사진 게시물이 아기 사진임을 발견, 원본 사진까지 게시되어 있어 해당 사용자는 가족·친구에게만 보내려고 했을 가능성이 높다고 추정
          + 결론적으로 Meta 특유의 “일단 일 벌리기” 스타일, 사전 동의 보다는 사후 사과를 중시하는 분위기라 평가
               o 만약 뭘 하고 있는지 확실하지 않으면 아예 하지 않는 게 맞다는 의견. 본인은 Hacker News에 “submit” 버튼을 누를 때도 이게 인터넷 전체에 공개된다는 사실을 스스로 인지하고 있었고, 인터넷을 쓰는 사람은 이런 책임이 당연하다는 시각
     * Mozilla의 문제 제기에 대해 더 구체적인 사례나 스크린샷, 실제 발생 시점이 궁금하다는 질문 제기
          + 설명 자체가 많이 부족하며, Meta의 새 AI 소셜 미디어 앱과 관련된 상황임을 언급함. 일부 사용자가 AI 챗 결과를 본인도 모르게 퍼블릭으로 공개하고 있는 상황임을 전함 Meta AI 소개 링크
          + App의 “Discover” 탭을 통해, 예민한 질문(질병, 이별 등)까지 누구나 볼 수 있게 노출된다는 점을 추가로 설명하며 자세한 기사 링크도 제공
     * Mozilla의 캠페인 메시지가 맥락도 부족하고 무조건적 명령조 느낌이라는 비판
     * “Meta: shut down [...]”이란 문구는 메타가 “shut down” 해라, 라고 말하는 것처럼 보이니, 쉼표(,)로 수정하거나 “Dear Meta: ...” 형식이 명확하다는 피드백
          + 예전 채팅 앱들에서는 닉네임 뒤에 콜론(:)을 붙여서 상대방에게 주의를 끌던 문법임을 부연
     * Meta 플랫폼을 아예 쓰지 말라는 의견
          + 미국 외의 대부분 국가에서는 Whatsapp이 표준 커뮤니케이션 수단이고, SMS는 건당 요금이 발생함. Whatsapp 간 상호운용성은 EU에서만 계획된다는 설명과 함께 관련 기사 링크 제공
          + 얼마 전 Meta가 Instagram과 Facebook 웹픽셀을 통해 Android 사용자를 몰래 트래킹했다는 기사와 연결짓기도 함. Tor onion 서비스만이 과거 유일한 프라이버시 우회방식이었는데, 지금은 사실상 트래킹 회피 불가
          + Meta에서 완전히 탈퇴하지 말고, 단지 소비만 하고 아무런 글이나 신호는 남기지 않는 “기생” 방안 조언. 모든 Meta 앱은 기기에서 삭제하라는 권고
          + 네트워크 효과 덕분에 많은 사람이 반 강제적으로 연결되어 있음. 친구의 플랜이나 커뮤니티를 유지하려면 떠나기 어렵고, 그래서 프라이버시 보호와 상호운용성 확보는 정부의 역할이라는 의견. “그냥 쓰지 마라”는 현실적으로 불가능
          + Mozilla의 비즈니스 영향도 경계해야 함을 덧붙임
     * 개인정보 관련 청원 폼을 제출하려면, Mozilla의 개인정보 처리방침에 반드시 동의해야 하는 부분이 역설적인 상황이라 지적
     * FireFox Mobile에서 해당 웹사이트가 정상 표시되지 않는 문제 사례 공유와 함께 Mozilla에 개선 요구
     * 결국 소셜미디어 회사가 AI 결과물을 공유하게 한다는 당연한 사실에 대해서 과장된 기사와 버즈워드, 논란 유도로 HN top에 올리고 있다는 평
"
"https://news.hada.io/topic?id=21424","런던행 에어 인디아 항공기, 아메다바드에서 240명 이상 탑승한 채 추락","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                런던행 에어 인디아 항공기, 아메다바드에서 240명 이상 탑승한 채 추락

     * 에어 인디아 AI171편이 아메다바드에서 추락, 탑승자 241명 전원 사망과 영국인 1명만 유일한 생존자임이 공식 확인됨
     * 사고로 탑승 승객뿐 아니라 지상 24명도 희생됨, 단 한 명의 생존자는 현재 병원 치료 중임
     * 주요 희생자 가족 및 지역사회, 유가족을 위한 애도와 지원을 시작함
     * Boeing과 각국 정부는 조사에 총력을 기울이고 있으며, DNA 검사로 신원 확인 작업이 진행 중임
     * Boeing 787-8 모델에 특별한 안전 우려는 현재 없는 상황이며, 자세한 조사 결과는 향후 발표될 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

에어 인디아 AI171편 추락: 공식 발표 및 초기 대응

     * 에어 인디아는 자사 AI171편의 추락 사고에서 241명 사망, 영국인 1명만이 유일한 생존자임을 공식 확인함
     * 항공사는 현재 남은 가족과 유가족의 지원에 전념하고 있다고 발표함
     * 에어 인디아의 의료진 지원팀이 아메다바드로 파견되어 현지 공무원 및 가족 지원을 수행 중임
     * 항공기(Boeing 787)는 런던 Gatwick으로 가던 중이었고, 230명 승객과 12명 승무원이 탑승함
     * 비행기는 주거지역에 추락하여 지상에서도 사망자가 추가로 발생함

영국 및 현지 사회 반응

     * 영국 PA 미디어는 탑승객 중 영국인들이 포함된 것으로 보도하며, 지역사회 및 학교는 애도의 뜻을 나타냄
     * Wellingborough 지역 시장, Raj Mishra는 지역사회 3명의 사망 사실을 알리며 공동체의 연대를 강조함
     * Gloucester 무슬림 커뮤니티는 피해 가족에 대한 슬픔과 연대를 표명함
     * Greenlaw-Meek 부부 등도 희생자로 확인되었으며, 이들은 사고 전 공항에서 촬영한 영상이 남아있음
     * 유일한 생존자인 Vishwash Kumar Ramesh는 병원에서 의식이 있으며, 중상은 아니지만 충격에 불안정한 상태임
     * 지역 의사들은 신체 곳곳에 타박상이 있지만 다행히 주요 장기 손상은 없음을 언급함

피해자 및 유족 이야기

     * 탑승자 가족 및 친구들이 아메다바드 병원에 집결하여 DNA 검사를 통한 신원 확인 절차를 받고 있음
     * 대부분 시신이 심하게 훼손되어 DNA 샘플에 의존해 신원을 확인 중임
     * Nanabawa 가족(영국인 Akeel Nanabawa, 부인 Hannaa, 딸 Sara) 등 어린이와 가족 단위 희생자 다수 확인됨
     * 지역 학교는 Sara를 “교실을 빛낸 희망”으로, Nanabawa 부부를 인도·가자를 위한 자선 활동가로 추모함

항공기, Boeing 및 업계 반응

     * Boeing CEO Kelly Ortberg는 에어 인디아 측과 직접 연락하여 지원을 약속함
     * Boeing은 미국 및 인도 조사기관과 긴밀하게 협력 중이며, 사고 원인에 대한 추측을 삼가고 조사에만 집중할 것이라고 강조함
     * Paris Air Show에 참석 예정이던 Boeing CEO는 행사 참석 계획을 취소함
     * 산업계에서는 이번 사건이 항공 산업 내 주요 이슈가 되리라 전망하며, Boeing 주가도 약 5% 하락함
     * United Airlines 교관 Ross Aimer는 Boeing 787 Dreamliner의 전반적 안정성을 언급하며 주목할 만한 고장 전력이 없음을 설명함

현장 상황 및 구조

     * 비행기 추락과 동시에 의료대 학생들이 기숙 중이던 건물에 충돌하여, 지상 사망 24명 추가 발생함
     * 목격자들은 건물에서 사람들 스스로 탈출하기 위해 뛰어내리는 모습을 설명함
     * 인근 의사는 기숙사 식당에 직접 충돌했음을 밝혔으며, 현장에서 15~20구의 시신과 약 15명의 구조를 언급함

조사 및 신원 확인

     * 병원 의료진과 보건 당국은 크게 훼손된 유해를 DNA 샘플로 신원 확인 중임
     * 인도 정부는 최종 사망자 집계가 DNA 작업이 마무리된 후에야 확정될 것임을 설명함

영국 정부 및 국제 사회 대응

     * 영국 고등판무관 Lindy Cameron은 영국인 피해자 지원과 정보 파악을 위해 현장 방문 및 지원을 약속함
     * 인도 정부 BJP 대변인 Javieer Shergill은 이번 참사를 “국가적 비극”이자 “세계적 항공 재난”으로 규정함
     * Shergill은 인도, 영국, 포르투갈, 캐나다 등 희생자 국적국 간 연대를 강조하며 “완전하고 객관적인 조사”를 약속함

미국 교통부 발표

     * 미국 교통부 장관 Sean Duffy는 이번 사고에 사용된 Boeing 787-8 모델에서 특별한 안전상 문제가 관찰되지 않았다고 발표함
     * 공식 조사와 초기 데이터 분석은 이제 막 시작 단계임
     * 추가적 정보가 제공되는 대로 조사 경과가 안내될 예정임

        Hacker News 의견

     * 오랜 기간 항공 분야를 좋아해온 사람으로서의 부드러운 팁은, 원인에 대한 분석을 읽기 전 최소 1주일 기다리는 것 추천
          + 속보 초반에 나오는 추측은 거의 생산적이지 않을 뿐 아니라 이후 진실과 왠지 닮아 헷갈리게 만드는 경향 존재
          + 인생 전반에서 “속보”라는 이름이 붙으면 반드시 1주일 기다려보는 팁, 초반 추측은 오히려 해끄러움 유발
          + 안심이 필요하면 지난주 신문 펼쳐보기 권장
          + 이번 건에선 MentourPilot의 해설 영상 기다릴 예정, 섣부른 추측은 무의미 실제로 주거지역 위에 연료가 가득한 상태로 추락, 참사 규모 상상 불가
          + 이게 무조건 적용되는 건 아니고, 경우에 따라선 사실 왜곡 세력이 정보를 삭제하고 조작하는 시간 벌어주는 일도 있음 예로 MH17 미사일 격추 사건에선 초기 정보와 실제를 가장 근접하게 알 수 있었음 이해관계가 크고 진실이 알려지기 원치 않는 쪽이 개입시엔 오히려 초반 정보 or 목격담이 더 정확한 경우 존재 전문가의 공식 리포트가 나오기 전까지 어떤 추측이 맞을 수도, 아무 것도 아닐 수도 있음 사실 완벽한 정보 습득은 내 인생에서 중요치 않음, 항덕 입장에선 읽으면서 상상&학습 과정 자체가 좋음 정말 중요한 건 공식 보고서를 쓰는 전문가의 정확성, 그리고 그 내용을 일반인도 이해할 수 있게 풀어주는 admiral cloudberg 같은 사람의 번역 게다가 일부 사건에선 이미 ‘무엇’이 벌어졌는가는 초반에 명확하게 확인 가능 (“어떻게”는 불명확)
          + 이륙 직후 착륙기어 내리고, 엔진 파워 없음, 랜딩기어 내린 상태, 플랩 올려진 채 하강하는 영상 존재 원인은 아직 확인 안됐지만 엔진 작동 불능이 유력 1주일간 나오는 정보에 오보가 많다는 데 동의, 여기선 영상에 보인 사실만 정리한 것임
          + 추측을 즐기는 사람으로서 말하면, 이 순간 추측하는 과정 자체가 재밌다면 굳이 방해받지 않기 추천
     * 이번 비극 정말 혼란스러운 사실 맑은 날씨, 실시간 교신(LiveATC) 없고 단 한 번의 Mayday만, 거친 영상에선 플랩도, 조종 입력도 관찰 불가 이렇게 현대 여객기가 통제불능 상태로 가려면 엄청난 악조건이 겹쳐야 하는데, 예컨대 최근 한국서 737이 조류떼와 충돌한 사례 짧은 활주로 교차점 이륙이 힌트로 보이고(나쁜 습관), 외관상 엔진과 랜딩기어는 괜찮아 보여서, 활주로에 엔진을 긁었다면 외관 손상 등이 보였을 텐데 그런 것도 없음 항공 안전이 특별히 탁월한 이유는, 사건 후 온갖 사람들이 원인 추측하며 다양한 가능성을 실전처럼 상상해보고 반복 훈련하는 과정 때문 실제 승무원들도 이착륙 도중엔 대화하지 않고 비상대응 시나리오를 머릿속으로 반복, 그 훈련의 누적이 위기 때 생존율을 높임
          + 착륙기어 내리는 건 문제 생기면 당연한 선택임, 기어 올릴 때 오히려 바퀴문이 열리며 추가적인 항력(드래그) 발생, 급격히 속도 저하됨
          + 플랩, 조종 입력이 안보인다고 했는데, 787은 기본적으로 플랩 10이나 5로 이륙, 외관상 잘 안 보임, 참고로 이 영상 참고
          + Flightradar24에서 데이터 확인 결과, AI171편은 활주로 전체 길이(11,499피트)를 활용해 끝까지 백트랙하여 이륙했던 것으로 나타남 링크 보기
          + ""(and terrible practice)""의 의미를 궁금해하는 질문
          + 조종사 한 명이 다중 조류 충돌 가능성을 추측함
     * CCTV로 전체 이륙 장면 촬영본 여기서 확인
          + 추측 금지라 들었지만, 이 영상은 명확히 최대 추력 진입 시 문제가 있었던 것으로 보임 극히 드문 엔진 2개 동시 정지거나, 조종사 실수로 추력 상승 입력 누락 가능성 존재 2009년 서렌버거 선장의 새떼 충돌 사례와 비슷해 보임
          + 영상 약 30초까지 정상등반, 이후 힘을 잃고 하강 시작. 이륙 후 11초 만에 조종사가 “No thrust, losing power, unable to lift!” 긴급무선 송신 양쪽 엔진 모두 새떼에 손상됐거나, 오염 연료 문제 가능성도 있음 플랩 관련 논쟁은 본질과 무관해 보임 비슷한 사고로 제주항공 건, 허드슨강 이착수 기적도 모두 조류 충돌이 원인
          + 원본 링크에서 보안 경고가 발생하여 이 링크로 우회 가능
          + 영상 20초쯤 먼지가 많이 이는 게 특이, 대형공항 정상 이륙땐 먼지 날림 거의 없음
          + 매우 느린 이륙, 엔진 모두 정지, 이후 느린 하강 및 추락
     * Flightradar24 자료에 따르면 이 사건은 이륙 직후 발생
          + AI171편이 최대 625피트(공항해발고도 200피트) 도달 후 분당 -475피트 하강 시작 출처
          + 연료 만재 비행, 생존자 거의 없을 가능성, 지상 민간인 사상도 있음
          + 최소 1명 이상 생존 사례 존재 가디언 기사
          + 지상에서 425피트, 폭 200피트의 항공기에겐 거의 지상효과 탈출 못한 셈
     * 생존자 존재 보고 있음 기사
          + 생존자 인터뷰: “이륙 30초 후 굉음과 함께 추락, 너무 빨랐음… 가슴·눈·발에 타박상 외엔 의식 명료” 기사
          + 좌석 11A, 일반적으론 후방 생존자가 많은데 이 경우엔 전방 중앙 자리
          + 생존자 사진
          + 복권을 탔다는 농담, 태어난 듯 멀쩡하게 살아남음
     * 1년 전 Boeing whistleblower 기술자가 Boeing 787 Dreamliner 조기 구조결함 경고 후 모든 기체 운항중단 요청, 하지만 의혹스런 “자살”로 사망 Boeing 반복적 실패 및 사고로 반드시 수사 필요 기사
          + 해당 내부고발자는 기체 내구성, 즉 동체 구조를 경고했으나, 이번 사건은 해당 우려와 별개로 보임
          + 첨부 기사 내 whistleblower Sam Salehpour는 아직 생존
     * 어떤 사람이 탑승전 내렸고 기내 엔터테인먼트 문제가 있었다고 X에 후기를 공유 관련 링크
          + 비교적 신형기종임에도 엔터테인먼트 기능불량 자주 경험, 항공사 측도 안전 필수 항목은 아니라고 여기기 때문
          + 좌석 모니터 오작동과 엔진고장 등 사고와 본질적 연관 없음
          + Air India의 내부 시스템 문제는 흔한 일, 이전 경영진의 방치 결과를 Tata가 개선 중
          + 오직 영화 보려고 비행기 탑승하나? 본질적 목적 되짚기 필요
          + 787 내부는 심지어 a320 neo보다 더 올드해 보여 놀라움
     * 240명 가까운 희생, Boeing의 중과실 소송은 언제 제기될지 의문
     * 승무원 정보
          + 조종: Sumeet Sabharwal(기장, 8,800+ 비행시간), Clive Kunder(부기장, 1,100+ 비행시간)
          + 객실: Aparna Mahadik(수석승무원1), Shradha Dhavan(수석승무원2), Deepak Pathak, Irfan Shaikh, Lamnunthem Singson, Maithili Patil, Manisha Thapa
          + 비행 때마다 조종사와 보안, 객실 승무원에게 감사하는 마음 가지길 추천
     * 일부 매체는 생존자가 있다고 보도 기사
          + 여러 명이 부상, 인근 병원 이송
          + BBC의 현지경찰 보도에서는 “생존자 없는 듯”이라는 언급 링크
          + 사고기는 의대 기숙사 건물 들이받아, 부상자는 대부분 지상
          + 부상자 대부분이 학생, 스탭 등 주변인일 가능성
          + 완전 연료 만재된 항공기 추락… 도보로 탈출은 사실상 불가능
"
"https://news.hada.io/topic?id=21379","CDC 백신 자문위원회 전원 해임한 RFK Jr.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      CDC 백신 자문위원회 전원 해임한 RFK Jr.

     * Robert F. Kennedy Jr. 는 미국 CDC 백신 자문위원회(ACIP) 17명 전원을 해임하고, 직접 위원 선임 방침을 발표함
     * 주요 의사 및 공중보건 단체들은 이번 해임 조치에 대해 전문성 및 공정성 훼손을 우려하는 비판을 제기함
     * ACIP는 기존에 백신 권고의 표준 역할을 해왔으나, Kennedy의 선제적 결정 및 해임으로 혼란이 발생함
     * 해임 사유로 이해충돌 문제가 거론되었으나, 공중보건계 인사들은 근거 없는 주장이라고 지적함
     * 대중 신뢰 회복 명분에도 불구하고, 많은 의료계 인사들은 이번 조치가 과학적 근거 약화 및 공공 신뢰 저하로 이어질 것이라고 우려함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

백신 자문위원회 전원 해임 및 배경

     * Robert F. Kennedy Jr.는 CDC 산하 Advisory Committee on Immunization Practices(ACIP, 예방접종실무위원회) 17명 전원을 해임함
     * 새 위원 임명을 예고했으며, 2주 후 Atlanta에서 새롭게 위원회를 개최할 예정임
     * ACIP 위원 전체가 현재 Biden 행정부 임명자였음
     * Kennedy는 Wall Street Journal 기고문에서 “백신 과학에 대한 대중 신뢰 회복을 위해 전면 교체가 필요함”을 강조함

전문가 및 의료계 비판

     * 이번 조치는 의사 및 공중보건 단체들로부터 즉각적인 비판을 받음
          + 미국공중보건협회(Dr. Georges Benjamin)는 “민주적 원칙에 맞지 않으며, 국민 건강에 부정적 영향”이라고 평가함
          + American Medical Association(AMA) Dr. Bruce A. Scott는 “수십 년간 투명성으로 생명을 구한 프로세스가 훼손됨”을 지적함
     * 전 위원장 Dr. Helen Keipp Talbot는 언급을 거부했으며, 위원 Noel Brewer는 통보 메일을 받고 해임 사실을 인지했다고 밝힘

ACIP 위원회의 역할 및 영향

     * ACIP는 백신 권고의 표준 기능을 해왔으며, 의료진 권고와 보험 적용 기준의 근거 역할을 담당함
     * Noel Brewer는 “ACIP 권고가 보험 및 의료 제공자, 대중이 신뢰하는 골드 스탠다드 역할을 했다”는 입장임
     * Kennedy가 위원회 협의 없이 COVID-19 권고를 변경한 사례도 있었음

해임 배경 및 비판 목소리

     * Kennedy는 위원들의 이해충돌을 공식 해임 사유로 들었으나, 현실적으로 위원들은 임기 내 이해충돌 및 사업 이해관계를 모두 공개하고 있음
     * 전 CDC 국장 Dr. Tom Frieden은 이런 조치가 “가족 건강에 해를 끼칠 위험”이라고 지적하고 증거 없는 이해충돌 주장이라 비판함
     * AMA, American Public Health Association 등 주요 단체는 Kennedy가 의료계와 의회에 약속한 방침과 다르게 행동했다며 우려 표명함

향후 전망과 우려

     * 백신 권고 기준에 혼란이 발생함에 따라, 공공 및 의료계의 ACIP 신뢰성 약화 우려가 확대됨
     * 공직 인사와 일부 의원(Republican Sen. Bill Cassidy)은 “위원회가 검증되지 않은 인사로 채워질 가능성”을 경계함
     * 기존 위원회 구성원 목록 웹페이지는 발표 후 바로 삭제됨

기사 관련 참고 사항

     * AP통신 Health & Science 부서가 본 기사 작성에 참여함
     * 기사 제공에는 Howard Hughes Medical Institute 등 외부 지원이 있었으나, 기사 내용에는 AP가 전적으로 책임을 짐

        Hacker News 의견

     * 코로나 팬데믹 말기 백신이 정치화되는 모습을 보며 가까운 미래에 대한 긍정적 전망이 완전히 무너지는 경험, 팬데믹 같은 일이면 우리 모두가 기본적인 진실 위에서 뭉칠 줄 알았지만, 정치와 소셜미디어가 이긴다는 사실을 다시 확인하는 안타까움
          + 역병과 기근이 공동체 연대를 잘 만들지 못한다는 점을 재확인, 나 역시 코로나 초기에 희망을 가졌었지만, 1630년 밀라노 대역병처럼 될 것을 걱정함, 이탈리아의 국민서사 <The Betrothed>에 밀라노 역병이 묘사되어 있는데, 그때의 기록들이 최근 코로나 상황과 너무 닮아 깜짝 놀랐던 기억, 예전엔 이런 일이 중세적이라 생각했지만, 다시 읽어보니 동료 참전군인과 전쟁 경험을 나누는 기분, 이북 링크, 31장이 전염병 부분 시작, 나머지는 건너뛰어도 되고 여름 읽을거리로도 좋은 책
          + 사망자가 감염자보다 수주 뒤에 발생한다는 간단한 사실도 제대로 다루지 못하는 사회 현실 목격, 오늘의 사망자 수를 오늘의 신규 감염자 수로 나눠서 ""독감보다 덜하다""는 식의 말을 보고 충격, 이 정도로 근본적인 통계도 이해 못 한다는 걸 확인하고 나니 더 깊고 복잡한 논의를 할 수 있으리란 기대 자체가 사라짐
     * 이번 결정은 공중보건의 발전을 후퇴시키는 현상, 불필요한 죽음을 맞이할 많은 아이들을 생각하면 슬픔
     * 이게 새로운 위원회였는지 궁금, 일부에선 이번 사태를 ‘쿠데타’라 표현했지만, 전 정부가 전임 위원 전원을 임명했다는 지적도 있음
          + 맥락을 보니 바이든 시절에는 임기 만료로 자리가 비어서 신규 전원을 임명한 케이스, 트럼프 시절엔 기존 위원 임기 때문에 2028년까지 과반을 채울 수 없다는 한계, 그래서 “공신력 제고를 위해 전면 교체가 필요하다”는 논리, Kennedy의 월스트리트저널 오피니언 인용
          + ACIP(Advisory Committee on Immunization Practices)는 1964년도에 생긴 위원회, CDC의 공식 기록 참고, 25년 이상 전부터 이미 미국소아과학회 같은 곳에서 백신 및 관련 권고안을 마련해왔다는 점도 부연
     * 반백신(anti-vaccine)에 대해 이념적으로 정당한 변호가 있을 수 없다는 강경한 견해, 반과학, 반생명, 반인류적이라는 생각 공유
          + 만약 상대국 내부를 약화시킬 목적으로 소셜미디어를 조종하는 미국 침공자라면 별개의 얘기라는 냉소
          + 관련 링크
          + 나는 반백신 입장이 아니지만, 정부와 보건 당국이 코로나 백신 커뮤니케이션, 의무화 등에 정말 큰 실책을 저질렀다는 점 지적, 강한 반감 확산의 원인이 과학이 아니더라도 리더십의 실패에 있음을 강조, RFK Jr. 보다는 이전 정부에서 더 큰 불신이 생겼다는 생각
     * VC(벤처캐피털) 업계에서 트럼프 대통령 선거를 도운 이들은 백신으로 예방 가능했던 질병으로 고통받거나 죽음에 이르는 아이들에 대해 일정 부분 책임이 있다는 주장
          + 이런 문제에 관심 가지고 신경 쓰는 사람이면 VC까지 되지 않는다는 냉소
          + 2025년 2월, 실리콘밸리 테크 리더십들이 기고문 및 팟캐스트로 자축하던 홍수 같은 장면을 사람들 모두 기억했으면 하는 바람
          + VC가 이 문제에 신경 쓰게 하려면, 손실 수치 등 눈에 보이는 실측 가능 물질적 피해로 프레이밍해야 조금이라도 관심을 가질 거라는 조언
          + 트럼프 대통령은 미국 국민이 뽑은 것이지 VC 커뮤니티 단독의 선택이 아니었다는 현실적 지적
          + 돈만 계속 벌리면 그 외엔 신경 쓰지 않는 업계라는 직설적 평가
     * “통상 비정파적(bipartisan)으로 여겨지는 위원회지만, 바이든 행정부가 전원 임명했다”는 인용 글에 대한 견해
          + 통상 4년 임기 체제라 대통령 임기 초반엔 전임 정부가 임명한 상태라는 설명, 한쪽에서 여러 위원 임기가 한꺼번에 끝나도록 인위적으로 조정했다면 그것도 옳지 않다는 의견
     * HN에서 특정 글이 비이성적 집단에 의해 ‘플래그’ 당해 내리막길 걷는 모습에 대한 피로감
          + Hacker News는 범용 뉴스나 일반 링크 공유를 위한 공간이 아니라, 흥미 있고 지적 호기심을 자극하는 것을 위한 니치 사이트라는 포지셔닝 설명, 정치나 유명인, 스포츠 중심 뉴스는 TV뉴스 커버 소재라면 오프토픽
          + PG(폴 그레이엄)가 플래그 조치된 포스트를 신뢰도 있는 유저가 다시 살릴 수 있는 ‘vouch’ 기능을 도입한다는 얘기를 들은 바 있음, 예전 사고방식과 달리 지금은 일부 집단이 의견이 관철되지 않으면 플래그를 대량 클릭하는 방식으로 환경이 바뀌었다는 우려 공유
     * “어떤 백신도 안전하거나 효과적이지 않다""는 RFK Jr.의 발언을 소개, 해당 영상 링크, 이런 발언 자체가 반백신 운동임을 지적
          + 사모아 사례에 대한 설명 요청, NBC 뉴스 링크
          + RFK Jr.가 2020년 이전부터 오랜 기간 반백신 관련 발언으로 악명이 높았다는 사실, 해당 기사에서 충분한 근거 제시, 참고하지 않은 사람을 대상으로 잘못된 정보를 가지고 있다고 안내
          + 인터넷 검색만 해도 믿음과는 다른 증거가 많으니, 비판 전에 직접 확인해보고, 타인을 비난하기 전에 스스로 공부해보라는 조언
"
"https://news.hada.io/topic?id=21386","Munal OS - WASM 샌드박싱이 적용된 그래픽 기반 실험용 운영체제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Munal OS - WASM 샌드박싱이 적용된 그래픽 기반 실험용 운영체제

     * Rust로 완전히 구현되어 있으며, unikernel 설계와 WASM 기반 샌드박싱 보안 모델을 사용하는 그래픽 기반 실험용 운영체제
     * EFI 바이너리에 커널, WASM 엔진, 모든 앱이 내장되어 최소화된 구조와 독특한 시스템 호출 인터페이스를 제공
     * VirtIO 기반 드라이버를 통해 QEMU에서 동작하며, 입력 및 네트워크, GPU 관리가 인터럽트 없이 폴링 방식으로 구현
     * 전역 이벤트 루프와 협동 스케줄링을 통해 단순화된 동작 구조와 애플리케이션별 자원 모니터링 기능을 지원
     * 자체 UI 툴킷 Uitk와 내장 앱(웹브라우저, 텍스트 에디터, Python 터미널) 제공, 다양한 언어로 WASM 앱 개발 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Munal OS란

     * Munal OS는 Rust로 완전히 개발된 실험용 운영체제로, unikernel 기반 아키텍처와 WASM 샌드박싱을 조합해 새로운 OS 설계를 탐구하기 위해 만들어진 프로젝트
     * 복잡성을 줄이고 필수 요소만 적용해, 현대적 도구로 간소화된 시스템 구조 실현을 목표로 함

주요 특징

     * 풀 그래픽 환경 및 HD 해상도 지원, 마우스 및 키보드 인터페이스 탑재
     * 샌드박스 방식 앱 실행, 사용자 애플리케이션의 커널 메모리 접근 차단
     * 네트워크 드라이버 및 자체 TCP 스택 내장
     * 커스터마이즈 가능한 UI 툴킷(Uitk) 포함, 다양한 위젯과 유연한 레이아웃, 텍스트 렌더링 지원
     * 기본 제공 앱: 웹 브라우저(DNS, HTTPS, 기초 HTML 지원), 텍스트 에디터, Python 터미널

아키텍처

     * EFI 바이너리 기반 구조
          + 부트로더 없이 EFI 바이너리 형태로 구동, 커널/WASM 엔진/앱이 한 파일에 내장됨
          + UEFI 부트 서비스는 최단시간 내 종료, 시스템 시계 외에는 추가 활용 없음
     * 주소 공간 관리
          + 가상 주소 공간 미사용, UEFI가 남긴 identity-mapped 주소 그대로 사용
          + 페이지 테이블 변경 없음. 커널 메모리 직접 보호는 WASM 샌드박싱으로 보완
     * 드라이버와 하드웨어 지원
          + PS/2나 VGA 대신, VirtIO 1.1 사양을 활용하는 PCI 드라이버 직접 구현
               o 키보드, 마우스, 네트워크, GPU용 드라이버 제공
          + 인터럽트 미사용, 모든 드라이버는 폴링 방식으로 설계
          + QEMU 이외의 실물 하드웨어 실행은 미지원, 향후 추가 개발 필요
     * 이벤트 루프와 스케줄링
          + 멀티코어/인터럽트 미지원, 전체 동작은 단일 전역 이벤트 루프에서 선형적 실행
               o 각 루프마다 네트워크/입력 드라이버 폴링, 데스크탑 UI 및 앱 실행, GPU 프레임버퍼 갱신
          + 성능 분석 용이, 각 루프 사이클별 타임 측정 가능
          + 앱은 직접적으로 CPU 점유 해제 필요, 장기 작업은 명시적으로 양보 필요
          + 협동 스케줄링 기반이나, Wasmi 엔진의 fuel limit 기능을 통한 오작동 앱 강제 종료 지원 가능(미구현)

응용 프로그램 실행 구조

     * [Wasmi WASM 엔진] 내장, 앱 실행시 완전 샌드박싱과 커널 분리 제공
     * 커널 차원에서 시스템 콜 API 제공, 앱에서 마우스/키 이벤트 조회, TCP 소켓 사용, 프레임버퍼 출력 등 가능
     * 앱의 렌더링 결과는 OS가 데스크탑에 합성하여 출력
     * Rust 이외의 언어로도 앱 제작 가능, WASM 빌드만 지원하면 사용 제한 없음
     * WASI 호환성은 부분 지원. 완전 준수 아님, 주요 외부 종속성 활용을 위한 최소 구현만 포함
     * 앱별 전용 로그 스트림(stdout 유사) , 데스크탑 ‘감사’ 뷰에서 리소스 사용량과 함께 확인

UI 툴킷(uitk)

     * Munal OS와 WASM 앱 모두에서 사용하는 자체 즉시모드 UI 킷
     * 기본 위젯(버튼, 프로그레스바, 텍스트 에디트, 스크롤 캔버스) 및 삼각형 래스터라이저 제공
     * 글로벌 스타일시트 기반 통일 스타일링, 개별 요소별 오버라이드 지원
     * 효율적인 캐싱 시스템으로 불필요한 리렌더링 방지
          + 각 영역별 “타일” 구분, Rust 뮤터빌리티 규칙 기반 변경 감지 알고리듬

빌드 및 실행 환경

     * Rust Nightly 2025-06-01 및 QEMU 10.0.0 이상에서 빌드 및 실행 가능

주요 참고 자료 및 크레딧

     * Philipp Oppermann의 Rust OS 튜토리얼 및 OSDev Wiki 문서
     * Wasmi, smoltcp, Rustls, RustPython 등 주요 오픈소스 활용
     * 다양한 오픈 소스 폰트 및 아이콘, 월페이퍼 자료 사용

Munal OS의 의의 및 장점

     * 단일 EFI 바이너리 구조와 혁신적 샌드박싱 결합으로, 기존 OS 설계 패러다임 재고
     * QEMU 환경 최적화 및 독특한 폴링 기반 드라이버 구조, 실 시스템 하드웨어 의존성 최소화
     * 시스템 리소스 관리 투명성, 단순 구조에서 얻는 학습 및 실험적 가치가 큼
     * 언어나 환경 제약 없이 WASM 앱 생태계 확장 가능성이 큼

        Hacker News 의견

     * 매 반복마다 네트워크와 입력 드라이버를 폴링하고, 데스크탑 인터페이스 그리기, 각 활성화된 WASM 애플리케이션을 한 단계 실행한 뒤 GPU 프레임버퍼를 플러시하는 구조임에 흥미로움을 느낌. 이 기능을 Wasmi로 어떻게 구현했는지 궁금해서 코드를 찾아봤음 GitHub 코드 링크. 최신 Wasmi(v0.45+)에서는 fuel이 부족할 때 yield 할 수 있도록 resume 가능한 함수 호출 기능이 확장됨을 안내하고 싶음 Wasmi 문서 링크. 이미 fuel metering을 사용하고 있어서 실행 단계에서 더 효율적인 방법이 될 수 있음. 활용 예시는 Wasmi Wast 러너 예제에서 확인 가능함
          + 다시 한 번 Wasmi를 만들어줘서 고마움을 느낌. Wasmi에 fuel이 떨어졌을 때 yield할 수 있는 기능 소식이 정말 흥미로움. 예전 문서에서는 이런 기능을 찾지 못해 아쉬웠는데, 만약 있었더라면 WASM 앱 디자인 방향이 달랐을 것임
          + OP는 아니지만, 이 기능이 왜 도움이 되는지 이해가 잘 안 됨. 함수로 코루틴을 만들고 시작한 후 만약 실행 중 메모리가 부족해 실패했다면 추가 메모리를 주고 코루틴을 다시 resume할 수 있다는 의미인지 질문. 그렇다면 기존의 동작과 무엇이 다른지 궁금함. WASM에서 try/catch가 없는지도 물음. 실패한 상태에서 malloc을 명시적으로 다시 시도해야 한다면, 그렇게까지 해서 얻는 차이가 명확하지 않아 혼란스러움
          + Wasmi가 GUI 앱을 실행할 정도로 빠르다는 점에 흥분을 느낌. 나는 휴대성과 이식성이 높은 GUI 앱을 만들기 위한 앱 런타임을 개발 중임. 퍼포먼스와 구현 간결함의 균형을 위해 wasm을 선택했고, 사실상 몇 명 혹은 한 명의 팀만으로 런타임을 뚝딱 구축하는 게 가능하길 바람. Wasmi처럼 최적화된 해석기 기반 wasm 런타임이 GUI 앱도 무리 없이 돌릴 수 있다는 사실에서 상당한 가능성을 느낌
     * VirtIO에 의존하는 구조라서 Munal OS는 아직 실제 하드웨어에서는 동작하지 않는다는 점을 언급하며, 만약 실제 하드웨어에서 운영하려면 직접 드라이버를 추가하는 대신 리눅스를 부트로더로 쓰고 미니멀 하이퍼바이저에서 운영체제를 구동하는 전략도 재미있는 접근이라 생각함. 이런 방식이면 ""VirtIO가 플랫폼""이라는 컨셉을 유지할 수 있음. 앱 실행에는 WASM, 플랫폼에는 VirtIO를 택하는 구조로 정체성을 지키는 점이 멋짐. 하지만 보안 관점에선 MMU 사용이 필요함. 설계상 가상 메모리까지 도입하지 않아도 되지만, 보호 비트를 쓰기 위해 페이지 테이블과 TLB 관리 등 추가 복잡성이 생겨 단순함이 다소 약화됨
          + 마지막 해킨토시 시도에서 리눅스를 부트로더 겸 미니멀 하이퍼바이저로 삼아 비슷하게 운영해봤고 효과도 괜찮았음. 단점은 실제 GPU 이벤트 없이 리눅스가 결정한 해상도와 설정대로 고정되어 자유도 제한이 있음. 만약 이 OS가 진짜 OS가 아니라 UEFI 실행 파일로 작동할 수 있다면 UEFI 비디오 드라이버만으로도 그래픽 처리 가능성이 있으나, 실제로 OS다운 기능을 가지면서 시도할 수 있는지는 확신 없음
     * 반복 루프가 오래 CPU를 점유하면 안 되고, 장시간 작업은 반드시 명시적으로 yield해야 한다는 점보다 더 큰 단점은, 앱을 많이 열수록 각 앱의 처리 속도가 느려진다는 것이라 생각함. 직접 10개 넘게 앱을 띄운 적은 거의 없지만, 탭은 30개까지 열어본 경험 기준, 각각이 프로세스라면 성능 저하가 확연하게 발생할 것임. 하드웨어가 충분히 빠르면 문제 없겠지만, 예를 들어 동영상 렌더링 등 무거운 처리는 1초에서 30초로 느려지는 등 큰 차이를 체감할 수 있음. 그럼에도 불구하고 전체 OS를 이렇게 구현했다는 점 자체가 아주 똑똑하며 정말 대단하고 신나는 시도임
          + 앱들이 할 일을 제시간에 끝내기만 하면 절대 느려질 필요 없음. 실행해서 끝내고, 다음 프레임을 기다리는 식임. 자원이 모자라서 대기 시간이 0 이하가 되면 전체적으로 느려지지만, 복잡한 공정한 스케줄러보다는 덜 우아한 방식임. 각 프로그램은 자신이 프레임 준비가 끝나면 명시적으로 yield하는 구조라서, 할 일 없는 앱은 시간을 거의 쓰지 않음
     * 협력적 스케줄링 외에도 Spectre 공격 방어가 까다로워 보이고, 가상 메모리 없이 효율성이 나올지 의문임. 예를 들어 WASM에서 memory.grow를 처리할 때 다른 앱 메모리가 걸리면 전체를 memmove해야 되는 상황이 생길 수도 있는데, 이게 과연 가능한지 궁금함. 그럼에도 정말 인상적인 프로젝트임
          + Spectre가 공격 벡터라면, 정확히 어떤 위협 모델이 전제되어 있는지 질문. 현재 구조상 모든 앱이 커널에 직접 컴파일되고 웹브라우저도 자바스크립트를 실행하지 않는 상태라, 신뢰할 수 없는 코드 유입 경로 자체가 없어 보임
          + 자세한 설명을 부탁드림
     * wasm 컴포넌트가 실현될 때 이런 시도들이 어떻게 바뀔지 궁금함. unikernel 디자인을 높이 평가하고, Munal OS가 다양한 기능을 가진 점도 인상적임. wasm을 단일 대형 앱 용도가 아닌 다수 작은 프로세스와 서브 환경을 호스팅하는 데도 활용되길 기대함. wasi preview3에서 동기/비동기 공존 가능성이 곧 열리고, 그렇게 하면 wasm이 범용 런타임의 요소를 다 갖추게 될 것임. 여전히 호스트 오브젝트 브리징이 JS에 치중된 현실이 아쉽지만, wasm 컴포넌트의 약속(표준, 경량, 샌드박스, 언어 간 조합)을 진짜 실행 가능한, 하나의 분산 포맷이 아닌 런타임 역량으로써 현실에서 보여주길 바라는 마음임. 아래 토크도 참고함 What is a Component (and Why)
          + 이 주제를 말할 때 혹시 이 영상 유튜브 링크를 언급하려고 했던 건지 질문함
          + 나는 SDL3를 지원하고, V8을 내장해 스크립팅이 가능한 Rust 앱을 만들기 시작함 블로그 소개. 하지만 진지하게 고민하는 건, 이를 fork해서 wasmtime이나 wasmi를 임베딩해 어떤 언어로든 스크립팅 가능하도록 만드는 것임. 컴파일러도 같이 내장해 파일만 주면 바로 스크립팅되는 구조를 만들 수 있을 것임. wasmtime과 wasmi가 다른 스크립팅 엔진들보다 빠르기 때문임 비교 데이터. 다만 불편한 점은 코드 환경을 전부 셋팅해야 해서 스크립트로써 진입장점이 약하다는 것임. 그래도 아이디어 자체가 너무 멋져서 한번쯤 해보고 싶음
     * “The Birth and Death of Javascript” Pycon 2014 토크에서 asm.js(현 wasm의 전신)로 OS 샌드박스를 구현하는 미래를 소개한 부분을 봤는데, 이 아이디어가 이 프로젝트 설계의 핵심과 비슷해 보여서 혹시 영향을 받았는지 궁금함 토크 링크
          + 오히려 Microsoft의 연구용 OS인 Midori에 더 영향을 받았을 가능성이 높다고 생각함 Midori 소개
     * 이 OS엔 자체 웹 브라우저까지 내장되어 있어서 놀라움을 느낌 웹 브라우저 소스. 데모 영상에서 Hacker News를 랜더링하는 모습도 확인 가능함
          + 웹 브라우저에 JS, CSS 등 기능이 쏟아지기 이전에는 이렇게 작은 브라우저가 최소한의 의존성으로 웹을 볼 수 있었지만, 지금은 오히려 대부분의 웹을 유의미하게 볼 수 없다는 점에서 아쉬움을 느낌. 컨텐츠 중심 웹과 앱 중심 웹을 좀 더 명확히 분리할 필요가 있다고 생각함. 컨텐츠 웹은 아주 단순한 HTTP 클라이언트와 HTML 파서만 필요하고, 웹 앱들은 이 OS와 비슷하게 wasm 기반 + 소수 하드웨어 API만 있으면 충분함. 단, 반드시 UDP 지원 필요함
     * 놀랍다는 느낌과 함께, 이런 구조가 OS의 미래가 될 수 있을지 궁금증을 느낌. readme 자체도 상당히 흥미로움. wasmi 대신 wasmtime을 선택하지 않은 이유가 궁금함. 나도 VM에서 이 OS를 직접 써보고 싶고, 내 GUI 라이브러리를 Munal에 포팅하고 싶은 욕심도 있음
          + wasmtime을 no_std 모드로 빌드하는 게 너무 까다로워서, 결국 wasmi를 선택했다는 경험을 공유함
          + 최신 OS 구조의 미래 얘기에 SPECTRE와 MELTDOWN이 끼어드는 농담을 추가함
          + 앱 격리를 가상화로 한다는 점에서 Qubes OS에서도 이미 비슷한 미래를 체험 중임을 언급. 거기서는 앱 격리가 아주 확실하게 이루어짐
     * Xerox PARC 시절부터 꾸준히 ""유저스페이스를 바이트코드화하려는 시도""가 반복되어 왔고, 실제로 시장에서 성공한 사례는 IBM i, ChromeOS, Android 정도뿐이라 봄. 다만 이 프로젝트는 멋지며 잘 되길 바람
          + WebAssembly 관련 스레드마다 본인이 오래된 바이트코드 VM 얘기를 반복하는 모습이 이제 패턴처럼 느껴짐. 매번 똑같은 논조로 반복 평가하는데, 개발자 커뮤니티에서는 다양한 시행착오와 새로운 접근이 필연적으로 나오기 마련임을 강조하고 싶음. 기본적인 패턴 인식 대신 더 세부적인 의견을 듣고 싶다는 바람임
          + 이런 개념이 워낙 장점이 명확해서, 표준으로 제대로 자리잡기 전까지 계속 새로운 시도가 반복될 수밖에 없음. wasm은 실제로 그걸 목표로 하는 점에서 JVM 등과 확연히 다름
          + ChromeOS는 단지 브라우저이기 때문에 우연히 V8을 쓸 뿐이고, Android는 무엇을 사용해도 성공했을 거라고 생각함. 두 OS가 잘 된 요인은 기술이 아니라 가격 때문임
     * 클라이언트 OS 설계 자체가 놀라움. 이런 구조는 서버에서도 즉각적으로 실용성 있을 것으로 봄. 커널을 아주 작게 만들고 동작하는 단일 앱만 남겨두면 불필요한 보안 경계를 줄일 수 있다고 생각함. 예를 들어 key/value store가 이런 구조에 적합할 것임. 궁금한 점은 이 IO 모델로 네트워크 성능이 잘 나오는지, 그리고 WASM 호스팅 시 불필요한 메모리 복사를 줄이기 위한 특별한 기법이 적용될 수 있는지임
"
"https://news.hada.io/topic?id=21391","Meta의 "Localhost tracking" 기법, 최대 320억 유로(47조원) 벌금 위기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Meta의 ""Localhost tracking"" 기법, 최대 320억 유로(47조원) 벌금 위기

     * Meta는 Android 샌드박스 우회 추적 수단(“localhost tracking”) 을 개발해 VPN이나 시크릿 모드, 쿠키 삭제에도 무관하게 사용자의 실제 신원과 웹 브라우징 활동을 연결 추적함
     * 해당 기법은 Meta 앱(백그라운드) 과 브라우저 내 Meta Pixel 스크립트가 로컬 네트워크 포트를 통해 정보를 교환, 로그인을 하지 않아도 사용자의 _fbp 쿠키를 계정과 연결함
     * 이 기법으로 웹 브라우저 행동과 실제 Facebook/Instagram 계정을 연결해 사용자 동의 없이 대규모 개인정보 통합이 이루어짐
     * GDPR, DSA, DMA 등 유럽 주요 개인정보보호법을 동시 위반, 제재가 누적 적용될 수 있어 최대 320억 유로(약 4%, 6%, 10% 매출 비율) 벌금 가능성이 있음
     * 9개월 이상, 실제 22%의 세계 주요 웹사이트(미국 내 1만 7천여 개 등)에서 사용자 동의 없이 대규모 추적이 이뤄졌고, 수억 명의 개인정보가 ‘명시적 설명 없이’ 연동 수집됨
     * 반복적 위반·시장지배력 남용·기술적 회피 의도가 명백하여, 사상 최초 누적 최고벌이 부과될 가능성까지 논의됨
     * iOS·PC·앱 미설치 사용자 등 일부만 영향에서 벗어남
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Meta의 ""localhost tracking"" 기술

     * Meta는 “localhost tracking” 이라는 혁신적이지만 논란이 많은 기법을 통해, Android 샌드박스 시스템이 의도적으로 막은 사용자 자원식별 보호책을 우회함
     * 페이스북/인스타그램 앱이 백그라운드에서 휴대폰 내 특정 TCP/UDP 포트를 열어 ‘리스닝(수신 대기)’ 상태로 유지됨 (로그인 필수)
     * 사용자가 같은 기기에서 브라우저로 웹사이트 접속(예: 뉴스, 쇼핑몰) 시, 해당 사이트에 Meta Pixel이 설치되어 있으면 쿠키와 활동 정보가 즉시 수집됨
          + VPN, 시크릿 모드, 쿠키 삭제 등 사생활 보호 수단을 써도 효과 없음
     * 브라우저의 Meta Pixel 스크립트는 WebRTC(원래는 영상/음성 통신용) 와 SDP Munging이라는 트릭을 활용, _fbp 쿠키를 앱에 직접 전송
     * 동시에 동일 정보를 Meta 서버에도 별도로 송신해, 온라인·오프라인 양방향 연동 추적 가능
     * Facebook/Instagram 앱은 _fbp 값을 받아, 계정 고유 식별자와 함께 Meta GraphQL 서버에 다시 전송
          + 그 결과 웹브라우저 방문 ID와 실제 Facebook/Instagram 사용자 계정이 웹 방문 활동과 실제 신원을 1:1 매핑하여 강력하게 결합됨

왜 문제가 심각한가

     * 안드로이드 설계상 금지된 로컬포트청취/앱간 은닉 통신을 편법적으로 우회
     * 사용자가 앱을 켜지 않아도, 웹브라우저에 로그인하지 않아도, VPN·시크릿모드·쿠키삭제 등 방어수단 소용 없음
     * GDPR 등 개인정보 규정 준수를 위한 명확하고 충분한 사전 동의 없이 정보 수집·연계
     * 22%의 세계 Top 사이트가 영향권, 9개월(메타)/8년(Yandex) 동안 수십억 명 동의 없는 추적
     * 수집·결합 정보: 전체 브라우징 히스토리, 장바구니·구매내역, 웹사이트 폼 작성, 시간대별 행동패턴, 실명 계정 연결 등
     * iOS 및 PC 사용·앱 미설치·Brave/DuckDuckGo 브라우저로만 예외

주요 법 위반 항목

     * GDPR: 광고 목적 개인정보 처리 동의 필요, 데이터 최소화/프라이버시 설계 의무 위반(매출의 최대 4%)
     * DSA(26조): 프로필로 민감정보(성향, 정치관, 건강 등) 기반 맞춤광고 금지(매출의 최대 10%)
     * DMA(5.2조): 핵심 플랫폼간 명시적 동의 없는 개인정보 결합 금지(최대 10%, 반복시 20%)
          + 계정 연동 최소 세 가지 동의 필요(GDPR, ePrivacy, DMA) 중 1개만 요구(강제 ""Pay or OK"" 대안)
          + 이미 2025년 4월 DMA 위반 관련 2억 유로 벌금 부과 사례 존재

벌금 및 제재 전망

     * GDPR·DMA·DSA는 각기 별도의 법익과 처벌 체계를 가지므로 누적 벌금 산정 가능
     * 이론적 최대 벌금은 320억 유로. Meta의 반복적 위반·규제 협력 미흡·시장 지배력·의도적 회피 정황상 선례적 중징계 전망 가능성 있음

결론

     * Meta의 “localhost tracking” 기법은 사생활 보호 기술적·법적 기준을 악의적으로 우회한 대표적 사례로, 전 세계적으로 매우 폭넓은 파급력과 심각성을 보임.
     * GDPR/DSA/DMA 복수 규정 위반 상황에 시장 지배력, 반복 위반 기록 등이 감안되어 사상 최대 수준의 누적 벌금이 실제 부과될 가능성이 있음
     * 규제 당국이 최초로 GDPR·DSA·DMA 누적 벌금(최대 320억 유로) 부과할지 세계적 관심 집중

   승인해준 관리자급들 내부에선 어떻게 책임지게 하려나 모르겠네요

   ios 는 안전하려나 궁금하내요..

   Q: iOS/타 플랫폼도 영향받나?
   A: 현재까지 안드로이드에서만 확인, 기술적으로는 iOS/데스크톱/스마트TV 등도 잠재적 위험 있음

   Android에서 Localhost를 이용한 은밀한 웹-앱 트래킹 기법 공개

        Hacker News 의견

     * 이전에 논의됐던 관련 주제로 웹-투-앱 추적 이슈와 Meta 및 Yandex의 프라이버시 문제를 모아둔 링크 모음집 공유. 다음과 같은 주제 언급: Washington Post의 프라이버시 팁(Chrome 사용 중지, Meta 앱 및 Yandex 삭제), Meta가 Android 이용자를 Instagram과 Facebook을 통해 은밀하게 추적, 연구자 항의 후 Android에서 모바일 포트 추적 기술 중단, Yandex와 Meta가 WebRTC 통한 추적 데이터 유출 등 소개
     * 2014년에 Android Twitter 앱이 내 기기에 설치된 모든 앱 목록을 Twitter 서버로 전송하기 시작한 사건 회상. 그 이후로 브라우저로 쓸 수 있는 서비스는 네이티브 앱 대신 웹버전 고집. Facebook이나 Instagram은 사용하지 않아서 최근엔 어떻게 동작하는지 모름. 그때 Facebook Messenger도 일부러 브라우저 환경에서 기능 제한한 결과 경험. 지난 10년간 네이티브 앱들이 수많은 권한 요청하고, 사용자들은 별 생각 없이 클릭해 동의해옴. 왜 Facebook이 내 Wi-Fi나 블루투스 정보를 볼 수 있어야 하는지 의문. 오프라인 매장에서도 비콘으로 사람 추적하는 사례 존재 https://en.wikipedia.org/wiki/Facebook_Bluetooth_Beacon . 안타까운 점은 네이티브 앱이 웹 앱보다 훨씬 쾌적하고 성능 좋다는 사실
          + Facebook Messenger를 브라우저에서 의도적으로 불편하게 만든 경험 공유. Messenger Lite도 사용하다 결국 서비스 중단. 이벤트나 연락처 때문에 Facebook을 계속 써야 하는데 Messenger 앱은 절대 설치하지 않으며, 결국 데스크톱 모드로 억지로 사용하는 불편함 토로. 피드엔 ""당신에게 추천""만 잔뜩 나와서 예전처럼 중독되지 않는 상황. 왜 이용자를 내쫓으려는지 이해불가지만, 실제로 그런 느낌
          + 최근 수년간 웹 앱 자체가 너무 심하게 방해 받는 상황 언급. 반은 ""앱을 설치하세요"" 팝업에 시달리고, 나머지 반은 아예 동작하지 않음. 더욱 실망스러운 건 요즘 네이티브 앱 대부분이 사실상 웹뷰라 네이티브 UI도 안 쓰는 경우 많음. 실질적으로 Safari나 다름없다면 그냥 Safari 쓰게 해달라는 불만
          + 당시엔 유난스럽게 느껴졌지만 브라우저 버전만 고집했고, 지금도 후회 없는 선택. 알림 같은 산만함에서 벗어나기도 했음. Apple이나 Google이 프라이버시에 진지했다면 달라졌을 것. F-Droid에 없는 앱은 그냥 기다림
          + 이런 앱 추적은 지금도 완전히 합법임. 모든 앱이 “보안 목적으로” 현재 설치 앱 리스트와 최근 실행 앱을 훑을 수 있음. 연락처도 마찬가지. WhatsApp(내가 관리하는 Meta 제품 중 유일하게 쓰는 것)이 아주 짧은 주기로 연락처 정보를 확인하고, 변경이 감지되면 그 차이만 서버로 업로드함. 이번 논란의 핵심은, Meta가 Google에 “쿠키 매칭” 비용을 지불하지 않고 사용자 매칭을 웹에서 우회한 점
     * 이번 시스템은 메타의 엔지니어들이 코드 커밋, 프로덕트 매니저들이 티켓으로 요청 처리한 기록이 남아 있음. 이런 담당자들 연봉의 일정 비율만큼 Facebook이 매출의 일정 비율로 과징금 받는 것처럼 그들에게도 개인적 책임을 물어야 한다는 주장
          + 사실 진짜 책임져야 할 사람들은 이런 시스템을 허락한 관리자들임을 강조
          + 아이디어는 동의하지만, 말단 직원만 책임지고 윗선은 면제되는 방향은 옳지 않음. 책임은 위까지 올라가야 한다는 견해
          + 이 이야기는 CS Lewis의 유명한 인용구를 떠올리게 함. “최악의 악은 깨끗하고 조용한 사무실의 양복 입은 사람들에 의해 계획된다”라는 내용의 현대판 사례로 Meta 같은 대형 기업을 비유
          + 윤리적으로 확실히 문제있는 일임을 인정하지만, 어떤 엔지니어들은 월급만 준다면 뭐든 만들어냄. 그들이 하지 않으면 다른 누군가 할 것이고, 때로는 기술적으로 도전적인 일이라는 점에서 흥미를 느끼기도 함. 결국 관리자나 자금을 대는 윗선, 즉 Zuck 등 돈과 이득을 챙기는 사람들에게 책임을 물어야 하며 돈의 흐름을 쫓아야 한다고 강조
          + 미국 거주 미국인 엔지니어에게 EU가 벌금을 부과하는 게 가능한지에 대한 의문 제기
     * Meta라면 이런 식의 일 벌이는 게 놀랍지 않다고 생각. 예전 2010년대 초엔 iOS App Store의 HTTPS 트래픽을 감시해서 인기 앱을 선제적으로 파악했고, 그래서 WhatsApp이나 Instagram 인수를 결정할 수 있었음. 현 상황에서 Zuckerberg의 승부수는 다음 플랫폼(AR, VR)이 오기 전까지 Meta가 계속 살아남아주길 바라는 것이라 봄. Meta가 새로운 플랫폼을 장악하면 더는 합리적 규정을 안 지켜도 되고 광고 머신의 인터넷 촉수를 마음껏 뻗을 수 있다는 계산. 바람직하진 않지만, 현실적으로 그들이 해낼 가능성이 높아 보임
          + AR/VR이 차세대 플랫폼이 되길 기업들이 굉장히 원하지만, 소수의 게임 팬을 제외하면 일반 대중이 정말 원하는지 의문임. 영화 3D 안경과 비슷한 정도의 지속력밖에 못 보여줄 것이라는 회의감
          + 예전 iOS 앱 감시 때는 사용자가 직접 엔터프라이즈 인증서로 배포된 VPN을 설치해야 했고, 이는 App Store에 올라오지 않는 방식. 사용자가 iOS의 무서운 경고 여러 번을 지나고 설치해야 했지만, 소소한 상품권만 줘도 실제로 많은 사람이 참여했음
          + Meta가 이런 짓을 반복할 수 있었던 건, 과거부터 적절한 처벌이 누적 위반자를 막을 수 없었기 때문임
          + Meta의 VR 플랫폼 Quest는 누적 2천만대 정도 판매됐는데 Facebook처럼 대규모 유저 층이 필요한 회사 입장에서선 한참 부족한 수치. Quest 2(1,400만대)처럼 잘 팔린 제품도 단종된 지 9개월 됨. 폭발적 성장과는 거리가 멀어 보임
     * 이런 시스템을 구현했던 엔지니어도 어쩌면 Hacker News에 있는 우리 중 한 명일 거라는 생각. Zuck이 직접 개발한 건 아닐 것이라고 추정
          + 이곳(Hacker News)에서는 엔지니어들에게 자신이 하는 일에 윤리적 고민을 하라고 하면 “나는 쿨한 기술을 만들고 싶을 뿐이고, 회사가 그걸 어디에 쓰든 내 알 바가 아니다”라는 반박을 자주 받음. “나는 그냥 코드몽키일 뿐, 관리자가 Torment Nexus(고문 기계)를 만들라면 만들 뿐”이라는 냉소적 태도도 존재
          + Meta가 이런 걸 구현하는 데 AI가 필요한 이유는, AI는 거부하지 않기 때문이라는 농담
     * 두 가지 문제가 보임. 첫째, Android는 앱이 별도의 권한 없이 포트를 열 수 있음. 그리고 앱끼리도 별도의 권한 없이 통신 가능. 둘째, 브라우저가 아무 도메인이나 로컬호스트 서비스를 접근할 수 있도록 허용함. 과거에도 로컬호스트에 떠 있는 개발자 서비스에 접근한 보안 이슈가 있었음. 뭔가 개선이 필요해 보임
          + 문제를 더 칼같이 나누면, 첫째는 임의 앱이 별도 권한 없이 포트 리스닝 할 수 있고, 둘째는 임의 앱이 별도 권한 없이 로컬 포트를 접근할 수 있다는 점임. 나는 개인적으로 이런 이유로 데스크톱에서 브라우저를 네트워크 네임스페이스에 가둬서 실험해봤음. 웹사이트가 내 로컬호스트 서비스에 마음대로 접근하지 못해야 한다고 생각
          + 기술적 이슈 두 가지는 맞지만, 그게 있더라도 Facebook이 이런 짓을 해선 안된다는 입장
          + Android 앱이 포트를 열려면 android.permission.INTERNET 권한이 필요함. 이 권한은 기본적으로 설치 시 자동 부여되며, GrapheneOS처럼 별도로 차단 가능한 버전도 존재. 현재로선 ""내부 통신만 허용"" 같은 세밀한 제어는 지원되지 않는 것으로 알고 있음
          + 사이트가 별다른 허락 없이 사용자의 로컬 네트워크에 접근하지 못하도록 제한하는 제안도 있음 https://github.com/explainers-by-googlers/local-network-access
     * Facebook 또는 Instagram 앱이 Android 폰에 설치돼 있고, 계정에 로그인 상태이며, 추적 픽셀 같은 걸 차단하는 설정을 따로 하지 않은 경우 지금 사안에 영향을 받을 수 있음. VPN이나 시크릿 모드를 돌파하는 부분이 특히 심각한 문제로 보임. 많은 사람들이 이런 모드로 완전 프라이버시를 지켰다고 착각하지만 실제로는 단순히 새로운 세션이나 다른 위치에서 온 것처럼 속이는 효과가 더 큼
          + 일반 사용자 입장에선 VPN과 프라이빗 브라우징을 쓸 때 이 정도면 충분하다고 생각할 만함. 브라우저가 내 폰의 앱과 몰래 통신하며 모든 행동을 내 계정과 묶는 건 너무 과함
          + Facebook이나 Instagram 앱을 실제로 백그라운드에 두고 있을 때 추적 악화 가능. 일부 사용자는 앱이 백그라운드에서 돌아가는 걸 극도로 싫어해서, 쓸 일 끝나면 무조건 종료하는 방식 선택
     * 실제 문제는 WebRTC에 있다고 지적. WebRTC는 기본 비활성화되어야 하며, 최소한 권한 요청 다이얼로그 뒤에 숨겨져 있어야 함. 물론 Facebook은 채팅 등 일부 기능을 빌미로 WebRTC 활성화를 요구할 테고, 결국 99% 사용자가 동의하게 될 것
     * Meta가 굳이 이런까지 할 필요가 있었는지 이해 불가. 이미 지문인식(fingerprinting) 같은 추적 기술이 있으니 굳이 더 위험 감수하지 않아도 될 것 같음. 아마도 이 기법은 다른 추적 기술이 잘 먹히는지 실험군 역할(테스트셋)로 활용하거나, 여러 추적 방법 중 한 가지가 들통나거나 보완될 때 곧바로 다른 기법으로 갈아타려는 흔적일 것이라 예상. 이렇게 대놓고 들킬만한 방식을 계속 쓰는 건 정말 어리석어 보임
          + 이런 행동은 회사가 소시오패스적 사고로 굴러가고 있어서임. “안 된다” 하면 그걸 도전과제로 여기고, 들키지 않고 해내려고 애쓰는 성향
     * ""Meta Pixel 스크립트가 _fbp 쿠키를 WebRTC(STUN) SDP Munging을 통해 인스타그램 또는 Facebook 네이티브 앱으로 전송한다""는 설명이 진짜 말도 안 되는 해킹임을 언급
          + 이런 방식이 어떻게 승인을 받았는지 의문
"
"https://news.hada.io/topic?id=21345","Show GN: 프리랜서 경력 쉽게 계산하기 (웹앱)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Show GN: 프리랜서 경력 쉽게 계산하기 (웹앱)

   안녕하세요! 제가 필요해서 만든 웹앱 공유하러 왔습니다.

   IT업계 프리랜서로 일하다 보면 경력 계산할 일이 자주 생기는데요,
   실제 경력 계산이 좀 복잡합니다.

   정직원이 아니니까 중간중간 쉬는 기간이 있고, 여러 프로젝트를 동시에 진행하는 기간도 있기 때문이죠.

   특히 이 중복되는 기간을 총 경력에서 제외하는 게 꽤 귀찮은 일이라 자동화하고 싶었어요.

   그래서 만들었습니다.
   프리랜서 경력 기간 중복 계산 도구 ✨

   🔗 서비스: https://career-period-calculator-sohee-kims-projects.vercel.app/
   🔗 GitHub: https://github.com/soheekimdev/career-period-calculator

   주요 기능:
     * 엑셀 템플릿으로 간편한 데이터 입력
     * 중복 기간 자동 계산 및 제거
     * 실제 경력과 중복 기간 분리 표시
     * 계산 결과 엑셀 다운로드

   기술 스택:
   React + TypeScript + Vite + Tailwind CSS

   구간 병합 알고리즘을 사용해서 겹치는 기간을 처리합니다(Set 자료구조 활용).
   Claude AI와 함께 개발했어요 🤖

   엑셀 템플릿은 프로젝트가 추가될 때마다 계속 업데이트하면서 쓰면 편리할 것 같습니다.

   프리랜서분들께 도움이 되길 바라요!

   피드백이나 개선 아이디어 있으시면 언제든 환영합니다.

   감사합니다~!
"
"https://news.hada.io/topic?id=21419","관찰 가능성(Observability)의 종말이 다가옴 (그리고 나는 괜찮음)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              관찰 가능성(Observability)의 종말이 다가옴 (그리고 나는 괜찮음)

     * 지난 수십 년간의 Observability 도구의 핵심 목표는 대규모 이종 Telemetry 데이터를 인간이 이해할수 있도록하는 것이었음
     * AI와 LLM의 등장으로 기존 ""대시보드+경보+샘플링"" 위주 패러다임이 변화하며, 분석 과정이 자동화로 대체되는 현상 발생
     * 실제로, AI 에이전트가 80초 만에 8번의 툴 호출로 지연 스파이크 원인을 분석하고, 기존 데모에서 하던 작업을 자동화하며 비용도 단 60센트로 해결함
     * 기존의 예쁜 대시보드나 편리한 계측이 더 이상 특별한 가치가 아니며, LLM이 분석을, OpenTelemetry가 계측을 평준화(commoditize) 함
     * 미래의 Observability는 ""빠른 피드백 루프"" 와 AI+사람 협업 워크플로우가 성공의 열쇠이며, 더 많은 소프트웨어와 자동화의 시대를 이끌 것
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

관찰 가능성(Observability) 도구의 역사와 AI의 등장

     * 수십 년간 관찰성 도구의 핵심 목적은 방대한 이기종 데이터(텔레메트리)를 인간이 이해 가능한 수준으로 압축/요약하는 것이었음
     * 새로운 소프트웨어 추상화(예: Rails, AWS, Kubernetes, OpenTelemetry 등)가 등장할 때마다,
       그 복잡성을 가리기 위한 모니터링·측정·대시보드·적응형 알림·동적 샘플링 등 다양한 도구가 개발되어 왔고, 데이터의 복잡함을 인간 인지 수준에 맞게 압축해 제공함

LLM = 범용 함수 근사기, 그리고 진짜 유용해짐

     * LLM은 수학적으로 범용 함수 근사기(universal function approximator) 에 불과하지만, 실제로는 관찰성 문제를 해결하는 데 매우 유용함
     * 예시로, Honeycomb 데모에서 히트맵 상의 지연 스파이크를 AI 에이전트에게 자연어로 분석 요청
          + “프론트엔드 서비스에서 4시간 간격으로 발생하는 지연 스파이크 원인을 분석해줘”
          + 오프더셸프 LLM(Claude Sonnet 4)과 Honeycomb의 Model Context Protocol(MCP) 연동
          + 80초, 8번의 툴 호출, 비용 60센트만에 원인 자동 분석
     * 추가 프롬프트, 별도 훈련, 가이드 없이 실제 시나리오를 무(無)지시(zero-shot)로 해결하는 수준에 도달
     * 분석의 평준화(commoditization):
          + LLM이 분석 작업을 자동화하면, 기존 관찰성 제품의 차별점(예쁜 그래프, 손쉬운 계측 등)은 의미를 잃음
          + OpenTelemetry가 계측을, LLM이 분석을 평준화함
          + 앞으로는 “빠른 피드백 루프”가 관찰성 도구의 핵심 가치를 대체

사람의 역할, 그리고 미래의 변화

     * 인간의 역할이 완전히 사라지진 않음
          + 클라우드의 등장도 IT의 존재 자체를 없애지 않았던 것처럼, AI도 개발자/운영자를 대체하지 않음
          + 생산성 증가는 전체 지형을 확장시키고, 더 많은 소프트웨어가 탄생함
     * 핵심 질문은,
       코드 작성/리팩터/분석 비용이 크게 줄고, 분석이 상수화되는 세상에서
       관찰성(Observability)의 본질이 어디로 가는가?

진짜 중요한 건 ""빠른 피드백""

     * 가장 중요한 것은 개발·운영의 모든 단계에서 ""빠르고 촘촘한 피드백 루프""를 갖추는 것
          + AI는 속도에서 항상 인간을 앞설 것임
          + LLM은 수십 번의 가설을 빠르게 세우고, 실패하고, 결국 올바른 결과를 찾아냄
            (그 비용도 매우 저렴함)
     * Honeycomb의 철학:
          + 빠른 피드백 루프, 협업 지식 공유, 실험적 개발/운영
          + 앞으로는 AI 보조가 소프트웨어 개발과 운영의 전주기에 도입됨
               o 예시
                    # 코드 작성 및 배포 시 AI 에이전트가 실시간 피드백, 버그/품질 개선 제안
                    # 운영 중 emergent behavior 감지/분석/자동 리포트, 승인 후 자동 개선
                    # 최첨단 조직은 SRE/SWE 역할을 AI+도구로 자동화, 비즈니스 목표까지 직접 달성
     * 성공을 위한 관찰성의 미래 조건
          + 초저지연 쿼리 성능
          + 데이터 통합 저장소
          + 사람과 AI 간의 원활한 협업 워크플로우
     * 결론:
          + 기존의 대시보드, 알림, 시각화 위주의 관찰성 도구는
            AI 시대에 핵심이 아니며,
            “빠른 피드백 루프”와 AI-사람 협업 플랫폼만이 살아남음

   자사 서비스를 ""종말이 다가온다"" 하면서 홍보하니 조금 낯 뜨겁네요...

   개인적으로는 vision llm이 발전해서 모니터링 작업에 쓰는 것을 기대하고 있습니다
   최근에 vlm을 아이가 자는 동안 특이점이 없는지 체크하는 용도로 쓴 부모의 글을 본 적이 있는데, 그게 되게 재밌었습니다

   옵저버빌리티가 모니터링에 종말이 아니듯이, LLM이 옵저버빌리티의 종말이 아니겠지요
   고도화된 모니터링 기반위에 옵저버빌리티가 발전했듯이 고도화된 옵저버빌리티 기반위에 LLM 분석이 발전하겠지요

   LLM으로 인해 Observability 분야가 빠르게 혁신할 거 같아 기대되지만, 제목이 너무 어그로네요 ㅋㅋ

        Hacker News 의견

     * 우리가 집단적으로 결정론의 가치를 너무 낮게 평가하고 있고, 반대로 비결정론이 가져올 비용 역시 과소평가 중인 느낌임. 최근에 비슷한 영업 멘트로 나온 다른 제품을 테스트해봤는데, 이게 내 사건들을 그래프를 연관시켜 RCE하려고 함. 결과적으로 Spurious Correlations 페이지처럼 나와버리는데, 직접 보면 분명하고 웃긴 모습임
          + 시계열 데이터는 정말로 허튼 상관관계(spurious correlations)에 약함이라는 점이 알려져야 할 사실임. r² 값도 의미 없음. 더 나쁜 건 그래프를 눈대중으로 해석할 때인데, 시간이 지남에 따라 변하는 데이터라면 그에 맞는 적절한 측정 기준을 써야 함
          + 혹시 내가 포인트를 잘못 이해한 걸 수도 있지만, LLM 기반 앱에서도 설계만 잘하면 정말 중요한 순간에 결정론적 UX 구현 가능함. 필요할 때 LLM이 무언가를 수행하는 결정론적 명세를 생성해서 해당 작업이나 액션을 기록할 수 있음. 사용자가 언제든 다시 실행할 수 있는 명세를 대화 내용과 함께 저장하도록 하고, 명세 실패할 때 AI가 고칠 방법을 제안할 수 있도록 구성하는 식임. 코딩에 AI 쓰는 경험과 비슷한 흐름임. 다만 스펙 도메인을 더 좁히고 실패한 명세를 어떻게 복구할지 고민이 더 필요함. 사용자에게 명세 언어를 따로 배우라고 요구하지 않고도 실현 가능한 구성임
     * RCA를 잘하는 사람으로서, 민망함을 느끼는 내 동료들이 10% 틀린 결과를 아주 자신감 있게 내놓는 도구를 그대로 신뢰해 더 엉망이 되지 않을까 걱정임. 정말로 모르는 게 있을 때 공개적으로 모른다고 말하지 않아도 되니 도구에만 의존하게 될까 우려임. 만약 도구가 결론을 낸 후 그 해석을 반박하는 데이터를 찾고, 좀 더 신뢰할만한 근거나 불확실함을 명확히 말했으면 덜 나쁘겠다는 생각임
          + 시스템 프롬프트를 잘 짜면 이 부분을 제법 보완할 수 있음. 실제로 LLM으로 기본적으로 더 엄밀하고 연구된 답변을 잘 끌어내는 커스텀 프롬프트/지침을 만들어 봤고 꽤 좋은 경험이었음. ChatGPT에서 내가 쓰는 프롬프트는 다음과 같음: ""실체, 명확성, 깊이에 우선순위. 모든 제안, 설계, 결론을 가설로 취급해 날카롭게 질문. 숨은 전제, 트레이드오프, 실패 케이스를 조기에 드러냄. 불필요한 칭찬은 근거 없으면 생략. 불확실하면 명확히 언급. 항상 대안적 관점 제안. 사실 주장은 인용 또는 근거가 확실할 때만 단언. 추론이나 불완전 정보에 기대면 명확하게 고지. 확신보다 정확함 중시."" 이런 구성으로 실제로 답변의 품질이나 깊이가 대폭 개선됨
     * “New Relic이 Rails 혁명에서, Datadog은 AWS 부상에서, Honeycomb은 OpenTelemetry를 선도했다”는 식의 역사는 편향된 해석임. OpenTelemetry(OTel)는 Google이 시작한 OpenCensus와 LightStep이 시작한 OpenTracing이 공식적으로 합쳐지면서 태동한 것임. 구글, LightStep, Microsoft, Uber 등 다양한 조직이 초기 거버넌스에 참여함. Honeycomb이 코드, 커뮤니티, 기술 도입을 크게 이끈 건 맞지만, “선도했다”는 건 과장임
          + 최근에 Honeycomb을 도입한 사람이 읽고 있는데, 정말 놀라운 툴임. 특히 otel 자동 계측 덕분에 몇 시간 만에 인사이트 얻는 경험 가능함. 대시보드/쿼리 기능 역시 깊은 관찰성(Observability) 철학에서 나온 것임이 느껴짐. 우리 팀 모두 도구의 완성도에 충격을 받았음. Datadog은 마케팅과 '관찰성' 체크리스트에 더 치중해 보이는 분위기임
     * “판매 멘트”를 한쪽으로 치우고 보면, 이건 LLM이 정말로 가치 있는 어플리케이션 중 하나임. 그동안 모니터링과 관찰성은 대기업 SRE만의 영역이었고 소규모 조직엔 벽이 높았음(IT 관점 한정). 유의미한 메트릭 선정, heartbeat와 baseline 세팅 자체가 시간, 전문 도구, 방대한 개발환경, 변경 검증 체계까지 필요해서 일반 IT 팀은 엄두를 못 냈음. 이제 가장 대중적인 툴에 훈련된 LLM 덕분에 예산/역량 부족한 IT 팀도 오픈 프레임워크/툴 기반의 “진짜” 관찰성 시스템을 구현할 수 있게 됨. 더는 현란한 구독 솔루션 없어도 됨. 대시보드 구축, 실용적인 모니터링 세팅이 필요할 땐 LLM이 정말 축복 같은 존재임. CIO가 푸시하는 수많은 제품군을 한 땀 한 땀 깊이 파고들 여유 없이도 설명서 읽고 트러블슈팅 할 줄 아는 IT라면 활용성 극강임. PagerDuty 알림에 최소 원인
       추천까지 붙는다면, SMB/SME 입장에서 관찰성 혁명임
          + 유의미한 메트릭 발굴은 LLM이 못하는 분야지만, heartbeat나 baseline 등 나머지 부분은 이미 오래전부터 ConvNet(합성곱 신경망)으로 충분히 자동화 가능했던 영역임. 변경 검증이나 안정성 컨트롤 같이 배포 고민은 관찰성 도구 범위를 벗어나는 문제임
          + 소규모 SRE 팀에도 대박 임팩트 기대함. 우리 팀은 2명이 수백대의 베어메탈 서버 관리 중인데, 장애가 생기면 원인을 좁혀나가는 과정이 매우 스트레스임. MCP(Master Control Program) 같은 도구를 직접 만들어볼까 고민할 정도임. 여러 번은 오랜 시간 잠복하던 이슈가 에러로 터지는 경우도 있었는데, 이런 케이스에 LLM 상당히 도움될 것임
     * 제목이 너무 자극적인 느낌임. 기존 관찰성 도구가 무용지물이 되는 건 아님. 단지 그래프 만들고 계속 들여다보는 시간은 줄어들 수 있음. LLM이 모든 영역에 미치는 효과와 비슷함. 이미 할 줄 아는 업무를 더 빨리 하게 도와주거나, 그 방법 자체를 배워가는 데 도움 주는 건 맞지만, 특정 기술 자체를 완전히 대체하는 건 아님
          + “이미 할 줄 아는 업무 속도 증가시키기”, “새로운 일을 배우게 돕기”, 이 결론을 오늘만 해도 두 번째 듣는 중임. 2번으로 추론(inference)하고, 1번 효율을 극단적으로 높인다는 점, 앞으로 가장 생산적인 방향성임
          + 제목이 자극적이지만 메시지는 명확함 — 진입장벽(모트)이 점점 낮아짐
          + 이런 현상을 “Charity Majors 효과”라고 부름
     * 데모에서 “이건 인위적 예시가 아니다. 우리가 데모에서 유저에게 묻는 질문을 똑같이 LLM 에이전트에게 던졌고, 추가 프롬프트, 학습, 안내 없이 바로 정답을 찾아냈다”라고 하지만, 실제로는 이 시나리오 자체가 이미 데모에 포함된 것이고, 솔루션도 이미 존재하는 사례임. 오히려 인위적 예시를 써서 모델이 학습 데이터에 정확히 있지 않은 새 상황에도 일반화가 되는지 보여줘야 했다는 생각임. LLM의 실제 기능이 유용한 건 맞지만, “관찰성의 종말”처럼 극단적 선언을 하려면 도구가 일반화 능력을 보여주는 게 필요함
     * “관찰성의 종말”은 아니라고 생각함. 하지만 글에서 제시한 포인트도 완전히 헛된 건 아님. 확실히 SRE(특히 RCA 포함)에서 다양한 역할을 수행할 수 있는 새로운 인공지능 에이전트 계층이 떠오를 가능성이 높음. 다만, 그게 현실화되어도 기존 관찰성 스택 대부분(아니면 전부)이 여전히 필요함. 게다가 LLM의 헛소리/신뢰/안정성 문제 원천 해결되지 않는 한, 깊은 문제파악은 여전히 사람이 필요함
     * “AI로 조금만 노력하면 전문가가 하던 일 다할 수 있다”라는 사업 전략, 정말 매력적인 사업 전략임. 슬프지만 요즘 AI 스타트업 80%에 이 멘트 복붙해도 이상하지 않음
          + 이게 조롱인 줄 알겠지만, 그 “일 좀 하는 전문가”들이 <i>엄청나게</i> 비싼 리소스임. 실제로 이 자동화가 이뤄지면 어설픈 AI 스타트업이 넘치는 이유 역시 납득 가능함
     * 이 기사, AI가 다 쓴 느낌임. “AI가 이 파라다임을 끝낸다, 이미 그렇다, 시스템 설계와 운영 방식까지 근본적으로 바뀔 것이다” — 어떻게 데이터 일부 해석하는 게 “관찰성의 종말”이란 말인지 의문임
     * “이젠 그래프와 UI로 데이터 볼 필요 없다”는 논리는 현실적으로 한계가 있음. LLM이 잘될 땐 정말 좋지만, 실패할 땐 사람이 개입해서 그래프 등 시각화를 직접 봐야 함. 그래프나 시각화도 어렵지만, 실제 데이터 수집이나 복잡한 쿼리 및 저장 방식 설계에는 훨씬 더 어려운 난이도 존재함. 진짜 인공지능이 모든 걸 거의 완벽하게 판단하는 순간에야 관찰성이 “사라질” 것임. 결국 이때는 사회 전체 구조가 완전히 바뀌는 문화적 변화(소멸은 아니어도 고통스러운 전환)가 올 것임. AI가 관찰성 판을 바꾸는 건 진짜임. 현재도 진행 중이지만 아직 갈 길 멈
"
"https://news.hada.io/topic?id=21339","Odyc.js – 내러티브 게임을 위한 작은 JavaScript 라이브러리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Odyc.js – 내러티브 게임을 위한 작은 JavaScript 라이브러리

     * 프로그래밍 경험이 부족한 사용자도 쉽게 비디오 게임을 만들 수 있도록 설계된 경량 자바스크립트 라이브러리임
     * 내러티브 게임, 즉 스토리텔링 중심의 게임 개발에 적합
     * 직관적인 코드 구조와 간결한 API를 통해 복잡한 프로그래밍 없이도 게임 제작 경험을 제공함
     * 모든 것(스프라이트,대화,사운드,인터랙션)은 코드로 만들어지므로, 전체 게임이 1개의 파일에 저장 가능

주요 특징 및 장점

     * 초보 개발자 혹은 비개발자도 간단한 자바스크립트 코드만으로 내러티브 게임을 제작할 수 있음
     * 대형 프레임워크와 달리 매우 작은 용량과 쉬운 사용성을 제공함
     * 선택지 기반의 게임, 대화형 콘텐츠, 시각적 개발 경험 등 스토리와 상호작용에 강점을 가짐

활용 대상

     * 게임 제작 입문자 또는 프로토타입을 빠르게 만들고자 하는 스타트업, IT 전문가, 개발자, 창작자 모두 적용 가능함
     * 복잡한 그래픽이나 대규모 게임보다는 아이디어 실험, 인터랙티브 콘텐츠, 스토리 전개에 적합한 도구임

게임 개발 시작은 createGame()

createGame({
  player: {
    sprite: 7,
    position: [2, 5]
  },
  map: `
    ########
    #......#
    #..X...#
    #......#
    ########
  `,
  templates: {
    X: {
      sprite: 4,
      dialog: 'Hello, adventurer!'
    }
  }
})

        Hacker News 의견

     * 왜 제목이 ‘...for narrative games’인지 궁금증 생김
       라이브러리 공식 페이지에는 ‘narrative’ 게임에 대한 언급이 없는 점 포착
       ‘narrative game’의 의미에 혼란 있음
       샘플 게임들이 내가 생각하는 ‘narrative game’ 정의에 맞지 않음
       구글 검색상 나오는 ‘narrative game’과 샘플 게임들의 연결성이 부족함
       만약 ‘narrative game’의 보편적 정의가 존재한다면, 이 라이브러리가 다른 게임 엔진과 비교해서 ‘narrative game’ 제작에 특별히 지원하는 기능이 무엇인지 의문 제기
          + 어젯밤 텍스트 기반 어드벤처 게임 아이디어가 떠오름
            어른이 되어 세금도 내고, 출근도 하고, 집안 청소도 하는 식의 일상적 미션을 수행하는 컨셉
            이런 일들을 덜 하면 인생이 힘들어지고, 더 하면 더 쉬워지는 구조
            최종 목표는 빚 없이 생을 마감하는 것
          + 이 도구의 아이디어는 텍스트와 대화를 이용하여 간단한 어드벤처 게임을 선언적으로 만들 수 있게 해주는 점이라고 생각
            Pico-8 같은 일반적인 게임 엔진처럼 메카닉을 중심으로 만드는 용도와는 다름
            맵 만들기, 맵 간 이동, NPC, 대화 및 텍스트 트리거 생성이 쉬움
            비프로그래머 대상 엔진(RPGMaker 등)도 비슷한데, 거기서도 대부분 유저는 맵과 트리거 위주, 별도의 복잡한 메카닉 없이 텍스트와 대화가 중심인 게임을 만듦
            이 도구도 이런 ‘내러티브’ 게임 제작이 쉬운 점을 강조한다고 봄
          + 공식 소개 문서에서:
            ‘Odyc.js는 픽셀, 사운드, 텍스트, 그리고 약간의 로직을 결합해 내러티브 게임을 만들 수 있게 설계된 작고 가벼운 자바스크립트 라이브러리’ 설명
          + 당연히 텍스트 어드벤처 엔진이라고 생각함
          + 프랑스어 버전 사이트에서만 ‘narrative’ 예시가 두 개 더 제공됨
            턴 방식 구조와 메시지, 프롬프트, 대화 위주 포커스 때문에 ‘내러티브’ 또는 텍스트 기반 게임에 어울릴 것 같아 해당 용어를 사용함
            하지만 더 좋은 라벨 아이디어가 있다면 기꺼이 바꿀 의향 있음
     * The Magic Mushroom 게임 굉장함
       링크
          + 지금까지 가장 마음에 드는 건 이것
            링크
          + John Wick 게임, 최근 영화의 요약본과 같다는 느낌
            링크
     * 이 구성 방식이 정말 마음에 듦
       다수의 자바스크립트 게임 엔진을 만들며 다양한 실험을 했는데, 이건 ‘2시간 안에 키즈용으로 빠르게 완성해야 할 때’와 ‘심도 있게 구조 파악을 하고 싶을 때’ 사이 절묘한 지점 제공
       몇 개 게임을 빠르게 만들어 저대역폭 환경에서 아이들 산만하게 해줄 용도로 기대
     * 아기자기한 툴 느낌
       구체적으로 아이들(요즘 시대의 pygame 같은 느낌) 학습용으로 좋다고 생각
       Scratch 등은 5살에게 맞춰 설계해 프로그래밍 내용이 과도하게 쉬움
       이 툴은 10살 전후 학생에게 딱 적합
       간단한 문자열 조작, 몇 가지 문법 트릭을 배우고, 기본 사이드 스크롤러와 NPC까지만 구현 가능
       이후 준비되면 제어 흐름 익히는 경험도 가능
       이걸 배워서 아이들 대상 수업 개설이나 놀이터 투자 고려하면 실질적으로 판매도 가능
       다른 관점에서는 이 툴로 기초적인 프로시저럴 게임 에셋 생성도 실험할 만함
     * game.prompt(“Dude, you ran out of eggs!|Would you like to buy|an 80 pack of eggs?”, “Yes”, “No”); 코드 예시 공유
          + await game.openDialog(“Dude, you ran out of eggs!|Would you like to buy|an 80 pack of eggs?”)
            game.prompt( “Yes”, “No”) 코드 활용 예시
          + 달걀이 한 개였는데 어떻게 마흔 개가 됨? 의문 제기
     * 진정 영감을 주는 프로젝트라는 평가
       오픈소스임을 확인했으나 라이선스가 누락되어 개발자가 포크 및 수정, 배포 범위를 알기 어렵다는 점 지적
       모국어로 번역한 포크도 공개하고 싶은데(크레딧 남길 의향), 괜찮은지 문의
       자국은 5% 미만만 영어 사용
          + 고마움 표시와 함께 라이선스(MIT 형태) 추가 예정
            모국어가 무엇인지 궁금
            좌우 정렬 언어는 번역 적용이 간단하다고 설명
            언제든지 포크, PR, 또는 접근해서 접근성 개선에 참여 가능하니 환영
     * 이건 대단함
       딱 12시간 전에 꼭 필요했던 것
       공교롭게도 내가 어젯밤 처음으로 1인 전용 3레벨 짜리 내러티브 연애 게임용 에셋을 만들다 잠듦
       게임 개발은 처음
       아침에 HN에서 내러티브 게임용 JS 라이브러리가 1위까지 올라온 것을 목격
       FTR 내 게임은 심프 게임이고, 쭉 만나온 상대에게 공식 커플 제안용으로 쓰는 중
          + 멋진 아이디어라는 생각
            비슷한 경험: 최근엔 2005년 MSN 채팅 인터페이스를 HTML로 다 재현해누군가에게 추억 선사
            정말 따뜻한 경험
          + 좋은 아이디어
            더 도와줄 수 있었으면 하는 마음
            정말 이 툴이 딱 맞는 사례라고 생각
            잘 되길 희망
          + 누군가를 좋아해서 함께 시간을 보내고 싶은 마음이나, 관심을 표시하는 행동이 ‘심프’로 불릴 일은 아님
            매우 따뜻하고 배려있는 제안이라 생각
     * puzzlescript와 비슷하다는 인상
          + PuzzleScript 정말 멋지고, 같은 소형 엔진 계열로 crisp-game-lib도 추천
     * 정말 멋진 툴이라는 감상
     * 이 라이브러리와 상관은 없지만 playground에 적용된 canvas video recorder 작동 방식에 관심
       직접 구현해보고 싶음
          + 관련 코드 공개
          + 최근 프로젝트에서 canvas video recorder를 살펴봤고, 이 기능이 내장되어 있다는 점이 놀라움
            medium.com 튜토리얼 참고
"
"https://news.hada.io/topic?id=21430","Next.js 15.1+는 Vercel 외 환경에서 사실상 쓸 수 없다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Next.js 15.1+는 Vercel 외 환경에서 사실상 쓸 수 없다

     * Next.js 15.1.8부터 메타데이터 처리 방식이 변경되어 Vercel 이외의 배포 환경에서 심각한 문제 발생
          + 메타데이터가 HTML head에 직접 렌더링되지 않고 ""메타데이터 스트리밍""이라는 방식으로 따로 전송됨
     * 검색 엔진이 자바스크립트를 실행하지 않으면 메타데이터가 아예 노출되지 않아 SEO가 치명적으로 훼손
          + 크롤러 감지(htmlLimitedBots)로 예외 처리하지만 완벽하지 않음
     * Vercel이 아닌 Netlify, Cloudflare, AWS 등은 OpenNext로 호환 시도 중이나, 실제로는 Next.js가 Vercel 인프라에 너무 강하게 묶여 포팅 자체가 어렵고 버그가 많음
     * 정적 빌드도 메타데이터가 HTML head에 포함되지 않으며, 모든 배포 환경이 복잡한 크롤러 감지/JS 실행을 강요받는 구조로 바뀜
     * 보안 이슈(2025년 3월 공개된 치명적 취약점)
          + 메타데이터 스트리밍을 피하려고 구버전을 고집하면 심각한 보안 취약점에 노출됨(패치는 15.2.3에서만 제공)
     * 메타데이터 스트리밍은 실제로 페이지 성능 문제를 감추고, SEO에도 부정적 영향
     * 결론:
       Next.js는 오픈소스처럼 보이지만, 사실상 Vercel 종속이 심각한 프레임워크가 되었으므로 새 프로젝트에는 다른 선택지를 고려하는 것이 현명함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * Next.js 15.1.8 버전부터 Vercel을 제외한 환경에서 metadata 처리에 심각한 문제가 발생함
     * 이는 Next.js의 본질적으로 Vercel 인프라에 대한 종속성 심화와 검색 엔진 최적화(SEO) 저하, 심지어 보안 위협까지 야기함

문제의 시작: metadata streaming의 도입

     * 2024년, Vercel은 metadata streaming이라는 실험적 기능을 도입함
     * 기존 방식과 달리 metadata(tags: title, description, Open Graph 등)를 HTML ``에 직접 렌더링하지 않고, 초기 페이지 로딩 이후 별도로 전송함
     * 이 기능은 JavaScript 실행이 필요해짐

Vercel의 기술적 설명과 실질적 문제점

     * 도입 배경: metadata 생성의 컴퓨팅 병목 현상 해소 목적
     * 하지만 실제 metadata는 대부분 정적이고 소량(1KB 미만)의 데이터임
     * 서버 round-trip 비용이 inline 처리보다 더 큼
     * 동적 metadata는 극히 일부 예외적 케이스임
     * metadata streaming의 구현 복잡성과 혼란 가중

성능 문제의 배경

     * 일부 개발자가 외부 API 연동 등에서 metadata 생성 지연이라는 성능 이슈를 겪었음
     * Vercel은 이 문제를 해결하고자 스트리밍 방식을 개발함

검색 엔진 크롤러와 SEO 영향

     * JavaScript를 실행하지 않는 검색 엔진은 metadata를 읽지 못함
     * 이에 따라 SEO에 큰 악영향을 줌
     * 해결책으로 Vercel은 서버가 크롤러를 감지할 경우 스트리밍을 건너뛰고 HEAD에 metadata를 넣는 htmlLimitedBots 기능을 제공함

기타 클라우드 제공업체의 한계

     * Netlify, Cloudflare, AWS 등도 Next.js와 호환을 위해 OpenNext라는 어댑터 프로젝트를 만듦
     * 하지만 Next.js가 너무 Vercel에 밀접하게 종속되어 있어, 이식 시 리버스 엔지니어링이 필요함
     * OpenNext의 품질 문제로 인해 실질적으로 제대로 동작하지 않음

정적 빌드조차 불완전

     * 정적 사이트 빌드(Static Build)도 metadata가 더는 HTML head에 포함되지 않음
     * React Server Components와 함께 번들되므로 JavaScript 실행 필요
     * 기본 HTML metadata를 위해서 크롤러 감지 로직까지 직접 구현해야 하는 불합리함 발생

심각한 보안 취약점 및 업데이트 문제

     * 2025년 3월 21일, 치명적 취약점(보안등급 9.1, GHSA-f82v-jwr5-mffw/CVE-2025-29927) 공개됨
     * 이 취약점은 특정 헤더 조작을 통해 미들웨어의 인증 보안을 우회할 수 있음
     * 취약점 패치는 Next.js 15.2.3에 적용되었으나, metadata streaming을 피하고자 15.1.8에 머물 경우 보안에 매우 취약함

스트리밍 도입이 가져온 부정적 결과

     * metadata streaming은 숨겨진 성능 문제를 더욱 감춤
     * 페이지 메타데이터 처리 지연 시 실사용자는 인지하지 못함
     * 검색 엔진 크롤러는 느린 응답에 따라 SEO 점수 페널티를 부여하게 됨

결론

     * Next.js는 오픈소스 프레임워크라는 위장된 Vercel 벤더 록인으로 변질됨
     * 차기 프로젝트의 기술 스택 선택 시, Next.js 대신 타 프레임워크를 고려하는게 더 현명

   본문에 언급된 대로 과도한 벤더 락인, 너무 블랙박스스러운 동작들, 직관적이지 않은 API들. 게다가 React측에서도 대놓고 대놓고 이러한 서버에서 렌더링하는 식의 개발이 마치 React의 표준 개발 방식인 것처럼 마케팅하고 있죠. 대부분의 앱은 Vite기반 SPA로 충분하다고 봅니다.

   remix가 대안이 되죠?

   벤더락인이 일어나는거는 어느정도 인정하지만 Next.js 기술 자체에 대한 의견은 그냥 보고있으면 ""난 글을 읽기 싫습니다"" 수준에서 벗어나지 않는거같네요

   전부터 꾸준히 열린 척 폐쇄적인 행보를 보이더니 결국 거의 문을 걸어 잠궜네요.

        Hacker News 의견

     * Next 사용을 절대 추천하지 않음. 개발자 경험이 끔찍하고, 벤더 락인이 심하며, 문서화되지 않은 이상한 관례로 인해 CRUD 위주의 단순 B2B SaaS가 아니면 곳곳에 지뢰가 있는 느낌. 특히 Next <Image /> 태그가 같은 페이지의 webgl 씬 FPS를 2까지 떨어뜨린 사례 경험
          + Vercel이 어떻게 일반 React 사용자를 벤더 락인으로 천천히 끓였는지 의문. React는 Meta에서 오픈소스를 강조한 프로젝트였고, 오픈소스가 벤더 락인 방지 역할을 하길 바랐는데 실상은 그렇지 않다는 점에 실망
          + 전적으로 동의. 최근 Next를 오랜만에 사용해봤는데 개발 경험이 매우 실망스러웠음. 문서가 모호하고 찾기 힘들었으며, 앱 자체가 기본적으로 느린 느낌. Docker로 AWS에 배포하려다 Vercel에서 제공하는 샘플 Dockerfile 때문에 수많은 어려움을 겪음
          + <Image /> 이슈를 직접 분석한 것인지 아니면 NextJs의 문제라고 추측하는 것인지 궁금. 나는 NextJs, <Image>, RTF 조합으로 일하지만 그런 문제를 겪은 적 없음
     * Next.js를 지난 3년간 업무에서 사용하며 정말 고통스럽다는 느낌. Vercel에 호스팅했고, 회사는 Vercel 서비스 거의 전부를 도입해서 본격적인 벤더 락인 경험. 예전에 Dan이 RSC 관련하여 HN에 올린 글에 나쁜 경험을 공유했는데, 그의 지적이 정확하다 느꼈음. ""RSC 자체는 이제 꽤 탄탄하지만, Next.js 같은 프레임워크는 아직 좀 거칠다""는 말 처럼 전체적으로 React도 이제 평균 미만이고 Next.js는 오히려 안 좋은 평판을 가속화하는 느낌. 멀리하는 것이 상책
     * Vercel이 이번 버그를 수정하겠지만, 이제는 이런 자잘한 문제들이 쌓여 Next.js에 지침. 예로, 미들웨어에서 prefetch 식별법이 몇 주(혹은 몇 달)째 깨져 있음. 이런 자잘한 문제들이 계속 누적되는 상황이라 Next.js에 피로감 큼. 하지만 JS 생태계 자체는 여전히 애정
          + Next.js에서 벗어나 Astro로 이동. 기본으로 돌아가고 싶었지만, 직접 라우트/템플릿/정적 자산/빌드 설정하기가 귀찮았음. Astro는 이 모든 걸 처리하고, 기본적으로 SSR. React/Vue를 원래 의도한 대로 상호작용 계층으로 얹어 쓰는 느낌이라 JS 프레임워크가 실제로 얼마나 불필요한지 깨닫게 됨. Next는 점점 마법 같은 요소가 많아지고 서버 액션들이 어색하고, ""NextJS 식"" 구현이 너무 많았음
          + 현재 업무 및 사이드 프로젝트에 Next.js를 쓰고 있지만, 예전에는 즐겁고 생산적이었던 도구였다가 pages에서 app 라우터로 전환한 뒤 방향이 아쉬움
          + 15.1.8 버전 이후부터 일부 라이브러리1이 깨져서, 작성자가 언급한 취약한 버전으로 다운그레이드해야 하는 상황 발생
          + 동감. 앞으로 Next.js는 정적 사이트나 사전 빌드 SPA에만 사용할 계획
     * Next가 농담거리가 될 지경. Remix가 이해할 수 없을 정도로 react-router로 변신하고 나니, 괜찮은 React 프레임워크가 극히 드물어진 느낌. 결국 plain vite와 tanstack router 조합으로 돌아감
          + 이런 비판적인 글이 Hacker News에 남아있는 것이 놀라움. 예전에 Remix로 더 간단하게 구현됐다는 글을 올렸더니, Vercel 직원 여러 명에게 메시지가 와서 내리라고 하거나 미팅하자는 요청을 받았던 적 있음. 여러 SNS 계정으로 동시에 접촉함
          + 브랜드 변경 이후 Remix를 더는 안 쓴다는 뜻인지, 아니면 프레임워크가 아니란 의미인지 궁금. RR7(React Router 7)도 프레임워크로 정상 작동1함. 15년차 백엔드였다가 최근 풀스택으로 전향하여 좋은 친구 추천으로 RR7 사용하는데 매일 감탄
          + 새로운 프로젝트에서 TanStack Router를 써보고 너무 좋아서 TanStack Query, TanStack Form도 추가함
          + 대안으로 무엇이 가장 좋은지, 그리고 Vite를 쓰는 이유가 궁금. 나는 소규모 프로젝트에 Next를 쓰는데, SEO가 가장 큰 장점이라고 들었음. 정적 파일만 생성해서 S3에 업로드하면 끝인데, 그게 더는 아니냐는 궁금증
          + Remix에서 react-router로 변한 게 구체적으로 뭐가 문제인지 궁금. 내가 보기엔 단지 리브랜딩인 듯함
     * Vercel 같은 데가 주도하는 React, Next, Svelte 등은 훨씬 더 신중히 접근해야 한다고 수년째 강조. 그들의 목표는 Heroku처럼 하지만, 훨씬 더 공격적으로 전체 스택(언어-런타임-머신)에서 완전 락인 유도. 다른 기업도 문제가 있음. 예를 들어 Cloudflare의 CLI 배포 툴은 macOS 13.5+만 지원(2년 조금 넘음), 왜 그런지 불분명. 2년 전에 나온 OS가 구형 취급받는 현실이 안타까움. 예전 버전 wrangler도 써볼 순 있지만, 문서와 기능이 불일치하고 어차피 더 악화될 듯함. 언젠가 호환성도 끊길 수 있음. 반면 다른 도구(vim, neovim, emacs 등)는 여전히 오래된 OS X에서 동작. 이런 오픈 도구는 락인 유인이 없기 때문이라 생각
     * Next와 RSC는 프론트엔드에서 다뤄본 것 중 가장 답답. 프론트엔드도 이미 충분히 골칫거리인데, 여기에 Next의 ""마법""을 더해서 Vercel까지 벤더 락인. 팀에서는 이번 주에 tanstack router와 vite로 전환해서 평범한 CSA를 만들어 볼 예정이라 기대
          + RSC가 뭐가 그렇게 답답한지 궁금. 내 경험상 정말 잘 동작하고 아직 Next.js를 쓰는 이유도 오직 RSC 때문
     * 모두가 Next.js 개발 모드에서 라우트 컴파일에 10초 걸리는 현상을 더 크게 다뤄야 함. Rust 컴파일러는 한켠에서 담배 피우고 있는 느낌
          + 사용 불가능 수준. 내가 경험한 최악의 devx. 마지막으로 이 정도로 싫었던 스택은 Sharepoint 사이트 도와줄 때 한 번뿐
          + 이제는 단순 스크립트 언어인 JS도 빌드/컴파일 단계를 몇 번씩 거치는데, 이제 C++ 컴파일러보다 오래 걸림. 클랭(Clang)이라도 브라우저에 넣으면 더 나은 경험이 될 지경. 참고로 회사에서는 PHP도 쓰는데 여기서도 같은 문제. 스크립트 언어라 간단할 줄 알았으나, PHP 자체 퍼포먼스 한계 때문에 코드 사전 생성 및 컴포저 빌드 단계를 따로 둬야 함. 그런데 PHP 개발자가 만든 이 빌드도 느림. GCC 제작자들이 만든 게 아니라 그런 듯
          + 이상하게도 next dev —-turbo 옵션도 우리 회사 코드베이스에서는 더 빠르지 않음
          + Rust 컴파일러는 정말 컴파일 작업을 하는데 Next.js 컴파일러는 실제로 그 정도로 복잡한 작업을 하는지 의문
     * Next.js의 지금 모습이 안타까움. 여전히 사용하지만, 직접 포크해서 패치해서 써야 할 만큼. next.config.js는 기본 동작을 바꿀 수 있는 험난한 탈출구인데, 이런 옵션은 원래 확장 포인트로 제공하고 ""feature flag"" 뒤에 숨기지 말았어야 한다 생각. 지금은 완전 스파게티 코드에 가까운 D학점 프레임워크
     * NextJS가 아니라면 전체 스택 기준 추천 조합이 뭐냐는 질문. 나는 15년 경력의 백엔드 개발자이지만, 프론트는 AngularJS 이후 처음. 최근 사이드 프로젝트 때문에 전체 스택 앱을 만들어보려고 검색했더니 Gemini와 공식 문서에서도 모두 NextJS를 추천. 아직 초기라서 대안을 배우고 싶음. 모든 건 Docker로 VPS에 직접 운영할 계획이라 Vercel/Netlify는 피함
          + 서버 렌더링 필요 없으면, 프레임워크 없는 React와 Vite1 조합 추천. 개발 중엔 Vite로 돌리고, 프로덕션 빌드는 HTML + JS 파일만 나와서 S3 같은 정적 호스팅에 올리면 끝. 10년 넘게 써왔고 문제 없음. 백엔드는 본인에게 편한 거 쓰고, 나는 요즘 PostgREST2 위주로 씀. 클라이언트에서 API 호출은 react-query3 추천
          + 어떤 프로젝트를 개발 중인지 궁금. 나는 전형적인 SaaS 웹앱을 만들고 있는데 React/Refine.dev/Vite 조합이 아주 괜찮았음. Refine.dev 덕분에 CRUD 페이지 고민 없이 기능 개발에만 집중 가능
     * 이번 이슈가 과장됐다 생각. React에서 스트리밍이 어떻게 동작하는지 아는 사람에게는, HTML을 한 줄씩 스트림처리할 수 없다는 건 상식. 메타데이터 때문에 첫 페인트(HTML, JS 아님)까지 막히면 안 됨. 이런 행동에서 일부 유저 에이전트를 예외 처리하는 건 합리적. 대다수 트래픽에선 최대한 빠른 표시가 중요하니까. 메타데이터 불러오는 데 오래 걸리는 사용자가 있을 경우, 어떻게 해결할지 궁금
"
"https://news.hada.io/topic?id=21402","PyDoll - 캡차 우회기능을 갖춘 파이썬 기반 차세대 브라우저 자동화 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              PyDoll - 캡차 우회기능을 갖춘 파이썬 기반 차세대 브라우저 자동화 도구

     * 외부 웹드라이버 없이 브라우저 자동화를 제공
     * Cloudflare Turnstile, reCAPTCHA v3 등 최신 캡차 시스템을 네이티브로(외부 도움없이) 우회
     * 실제 인간 행동을 모방하는 알고리듬을 적용해 마우스 이동, 타이핑, 스크롤, 클릭 타이밍까지 자연스럽게 처리해 고급 봇 감지 시스템도 회피 가능
     * Chrome DevTools Protocol(CDP) 직접 연결 구조로, 별도의 드라이버 설치/설정 없이 pip install pydoll-python 만으로 간단히 사용할 수 있음
     * asyncio 기반 네이티브 비동기 지원으로 여러 사이트를 동시에 빠르게 자동화할 수 있으며, 네트워크 트래픽 가로채기/수정도 쉽게 가능
     * 이벤트 기반 아키텍처로 페이지 이벤트/네트워크 요청에 실시간 반응하는 자동화 흐름을 설계 가능
     * find() / query() 등의 직관적 엘리먼트 탐색, get_frame()을 이용한 iFrame 내부 조작 등 기능 제공
     * Chrome, Edge 브라우저 지원

   지겨운 신호등 자동차 찾기 캡차
   AI가 지금도 다 할수 있는건데요.
   최소한 PoW라도 가야지, 사람 시간만 낭비중입니다.

   여기 캡차 논쟁글도 한번 보고 가세요~
   https://behind.pretix.eu/2025/05/23/captchas-are-over/

   저도 캡차 우회 기술이 발전하는 상황을 보면 PoW 방식이 좋은 방법이라고 생각합니다.
   이와 관련해 흥미로운 접근법이 있어 공유해 봅니다.
   Brave 연구팀에서 영지식 증명을 도입한 ZKSense를 소개했는데,
   사용자 단에서 봇이 아님을 증명하는 방법으로 개인정보와 bot 저항성, 접근성을 어느정도 해결한 방법이라고 생각됩니다.
   Brave 블로그: https://brave.com/blog/…
   저 역시 이 ZKSense 개념에 영감을 받아, 최신 영지식 툴과 머신러닝을 사용하여 PoW 캡차를 만들고 있습니다. 관심있으신 분은 확인해보시면 좋을 것 같습니다.
   프로젝트 링크: https://kinetizk-vitepress.pages.dev/
"
"https://news.hada.io/topic?id=21331","4-7-8 호흡법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               4-7-8 호흡법

     * 4-7-8 호흡법은 4초간 들이마시고, 7초간 멈추며, 8초간 내쉬는 패턴 사용
     * 이 호흡법은 Dr. Andrew Weil에 의해 개발된 점이 특징임
     * 반복적인 적용으로 불안 완화, 스트레스 관리, 수면 개선 효과 제공
     * 신체의 자연스러운 이완 반응을 촉진하며 심박수 감소 유도
     * Crystal Bowl Ping, Cosmic Waves와 같은 음향 요소와 함께 제공됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

4-7-8 호흡법 개요

     * 4-7-8 호흡법은 4초간 숨을 들이마시고, 7초간 숨을 참은 후, 8초간 천천히 내쉬는 호흡 패턴임
     * 이 호흡법은 여러 번 반복하는 방식으로 이루어짐

개발자 및 주요 효과

     * Dr. Andrew Weil이 이 방식을 개발함
     * 이 호흡법은 불안 감소, 스트레스 관리, 더 나은 수면 촉진에 도움을 줌
     * 신체의 자연적 이완 반응 유발과 심박수 저하 효과로 연결됨

부가 요소

     * 웹사이트에서는 Crystal Bowl Ping과 같은 신호음, Cosmic Waves 배경 음악과 함께 해당 호흡법 제공됨

        Hacker News 의견

     * Plum Village(틱낫한 스님이 창립한 불교 공동체)에서 만든 무료 명상 앱에서 여러 가지 호흡법과 다양한 명상 세션을 무료로 제공받을 수 있는 경험, 정기적으로 YouTube에도 명상을 업로드하는 점, 그리고 mindfulness practice 페이지에 좋은 자료와 호흡 명상 리소스가 있다는 점, 강력 추천하는 입장
          + 분명히 Plum Village가 좋은 출처이지만, 호흡법은 반드시 전문 지식이 있는 지도자나 전문가의 감독 아래에서 해야 하는 생각, 수영처럼 보통은 안전하게 보이지만 드물게 심각한 문제가 발생할 수 있고 무리한 “극한” 연습을 경계해야 한다는 조언
     * 다양한 호흡법이 존재하지만 처음 시작하려는 사람에게 가장 중요한 건 “시작” 자체라는 의견, 박스 브리딩이나 Wim Hof method 등 어떤 방법이든 시도하는 것이 아무것도 안 하는 것보다 낫다는 생각, 입문 용으로는 James Nestor의 Breath 책을 추천하는 의견
          + 다양한 호흡법, 예를 들어 박스 브리딩 등 시도해도 간격이 너무 길어서 내쉴 때마다 뇌가 패닉 모드에 들어가는 경험, 다음 숨을 들이마셔도 충분하지 않아서 오히려 긴장을 풀기 힘들다는 개인적 체험 공유
          + Nestor의 책이 정말 훌륭한지는 회의적인 입장, 책에 등장하는 주장들이 너무 과장되고, 실제 과학이 뒷받침하지 않는 내용이 많으며 참고 문헌이 제대로 제시되지 않아 신뢰하기 어렵다는 느낌, 호흡법이 도움이 되는 것 자체는 인정하지만 더 나은 참고 자료를 찾길 희망하는 입장
          + Wim Hof Method가 위험하지 않은지 궁금한 입장
     * 이런 앱류를 별로 좋아하지 않는 이유, 대부분 진짜 필요한 것은 제대로 된 횡격막 호흡 습득임을 강조하는 입장, 횡격막 호흡은 흔히 알려진 복식호흡과 다르다는 점, 어떤 소리나 타이머 앱에 의존하지 않고 조용히 앉아 아무것도 억지로 하지 않은 채 호흡을 지켜보는 정신, 힘을 빼고 내려놓으면서 자연스럽게 오는 평온함과 이완을 중시하는 의견
     * 진짜 심층적인 호흡 스킬을 원한다면 3p 라이플 사격 같은 스포츠를 추천하는 제안, 숨을 가다듬으며 중심에 총알을 맞춰야 하는 특성상 호흡의 힘을 자연스럽게 연마하는 경험, 서서 쏘기 관련 영상, 엎드려 사격 영상, 일반적인 사격 호흡법 같은 자료도 추천, 복식호흡, 어깨 이완 등 주요 원칙이 관악기 연주 등 다른 분야에도 잘 응용되는 점을 언급
          + 소구경 라이플 엎드려 쏘기 초보로서 사격과 호흡법 연결이 이제야 이해되는 입장, 더 깊이 연구해보고 싶다는 의지
     * 앱 UX에서 발견한 문제, 내쉴 때 원이 어디까지 멈추는지 한눈에 파악이 안 돼서 이 단계에서 어떻게 해야 할지 혼란스러운 경험
          + 호흡이 끝나고 다시 들이마실 때 ‘딩’ 같은 소리가 없어서 조금 불편한 경험
     * Breathly 앱을 사용하며 매우 만족하는 경험, 시각적·청각적으로 우수하며 타이밍을 맞춤 설정 가능, 박스 브리딩 등 여러 프리셋 제공, 화면이 계속 켜져 있지만 폰이 잠긴 상태에서도 작동하면 더 좋겠다는 바람, Breathly GitHub 링크
          + 바로 사용해봤는데 기능이 알차고 꼭 필요한 요소만 잘 구성되어 있다는 평
          + Medito(비영리지만 오픈소스는 아님)라는 앱에서도 다양한 명상 코스 제공 소식 공유
     * 사용 경험 소개, “hold” 명령에서 타이머가 멈추는 상황 발생, 그 상태에서 숨을 내쉬어도 되는지 궁금함, 타이머는 전체 호흡 사이클의 배수로 끝나야 한다는 제안, 사이클 끝이 내쉼 단계가 되도록 하면 더 좋겠다는 생각
          + 2일째 숨 참고 있는데 아직 hold 상태라는 농담 섞인 경험
          + 호흡 사이클의 어느 단계에서 종료되든 상관이 없지 않은지 궁금, 그냥 타이머 끝났다는 신호가 있으면 충분하지 않을까 하는 생각, 계속 숨 쉬라는 알림 문구(디스클레이머) 추가 건의
          + 버그가 이미 수정됐으며, 전체 사이클의 배수로 타이머가 맞춰지는 부분은 본인도 거슬려서 곧 개선할 예정이라는 개발자의 의견
          + 웹소켓(wss) 연결이 끊기는 것이 원인이라는 기술적 분석
          + 동일 현상 경험 공유
     * 4-7-8 등 특정 호흡법의 기법 자체 효과와 “호흡에 집중”하게 만든다는 점, 두 가지 중 어느 쪽이 더 중요한지 궁금한 입장, 동시에 박스 브리딩 같은 것을 하면서 다른 작업을 시키는 실험이 있었는지 궁금증
          + 같은 관점에서 생각하는 입장, 다양한 추천법과 사람마다 호흡 구간 길이가 너무 다르다는 점, 결국 가장 중요한 건 정확한 시간보다 “의식적으로 호흡에 집중”하는 것이 아닐까 하는 개인적인 견해
     * 해당 웹사이트에서 ‘Dr. Andrew Weil이 개발’했다고 소개하지만, 요가 실천가들은 오래 전부터 이와 비슷한 운동을 해왔다는 점을 지적
     * 내쉼에서 들이쉼으로 넘어가는 시점에 소리 알림 기능(오디오 큐)이 있으면 좋겠다는 의견
          + 그 기능에 전적으로 동의하며, 눈을 감고도 쉽게 할 수 있도록 단순한 “삡” 소리 정도만으로도 충분하다는 의견
"
"https://news.hada.io/topic?id=21417","Apple SF Symbols 7 베타 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Apple SF Symbols 7 베타

     * Apple의 공식 시스템 폰트인 San Francisco와 완벽하게 통합되는 6,900개 이상의 심볼 라이브러리
     * 각 심볼은 9가지 굵기와 3가지 크기로 제공되며, 텍스트와 자동 정렬 및 벡터 그래픽 툴로 커스텀 편집 및 내보내기 가능
     * Draw On/Off 프리셋을 통한 손글씨 스타일의 애니메이션 신규 지원. 심볼의 레이어 구조와 타이밍을 이용해서 풍부한 표현력 제공
     * 새 Annotation 툴로 커스텀 심볼의 Draw 애니메이션을 쉽게 만들 수 있음. 레이어에 가이드 포인트를 배치해 경로의 시작~끝 동작 제어 가능
     * Magic Replace로 관련 심볼간 자연스러운 전환을 지원. 두 심볼이 동일한 테두리(enclosure)를 공유하면, 테두리를 유지한 채 나머지 레이어가 애니메이션됨
     * Variable Draw는 기존 Variable Color 기능을 확장해 강도/진행도를 더 세밀하게 표현 가능
     * Gradient로 색상 깊이, 입체감, 시각적 흥미를 심볼에 추가함
     * 수백 개의 신규 심볼과 기존 심볼의 디자인 개선 제공
          + 여러 언어와 스크립트에 대응하는 로컬라이즈 심볼이 추가되어 다양한 플랫폼(iOS 26, macOS 26 등)에서 통합 사용 가능
     * SF Symbols 7 베타 다운로드
          + macOS Ventura 이상 필요
     * SF Symbols 사용 가이드는 HIG 에서 확인 가능

   애플 SF Symbols 3 공개 때 3100개 였는데 6900개로 두배이상 증가했네요
"
"https://news.hada.io/topic?id=21393","Rivet - 오픈소스 서버리스 플랫폼","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Rivet - 오픈소스 서버리스 플랫폼

     * 개발자 친화적인 오픈소스 서버리스 인프라 플랫폼으로, AI 에이전트, 실시간 애플리케이션, 게임 서버 등 복잡한 백엔드를 손쉽게 배포 & 확장 가능
     * 기술 스택: Rust, V8, Deno, FoundationDB, CockroachDB, ClickHouse, Valkey, NATS, Traefik
     * Stateless Functions, Stateful Actors, Containerized Workloads 등 다양한 기능을 통합 프리미티브로 제공
          + Stateless Functions(무상태 함수): API 서버 등 요청-응답 중심 작업에 적합
          + Stateful Actors(상태 저장 액터): 메모리 상태를 유지하는 실시간 서비스 구축에 최적
          + Sandboxed Containers: 무거운 작업이나 신뢰할 수 없는 워크로드에 안전하게 대응

기능

     * Stateful Persistence
          + Rivet Actor는 메모리에 데이터를 유지하며, 자동으로 디스크에 내구성 있게 저장됨
          + 게임 로비, 협업 문서, 캐시 등 동적인 상태 관리에 적합
     * 원격 함수 호출 (RPC)
          + 경량의 클라이언트-서비스 간 메시징 기본 내장
          + 클라이언트/액터간 타입 안전 원격 프로시저 호출(RPC) 및 브로드캐스트 지원
          + 외부 메시지 브로커 없이 실시간 통신 구조 가능
     * No Cold Starts
          + 서비스는 Idle 모드에서 Hibernate 되고, 필요시 즉시 활성화 됨
          + 장기 실행(Long-Running) 액터는 비활성 상태일때 ""Sleep""에 들어갔다가 다음 요청시 즉시 상태 복구
          + 엔드유저 관점에서 Cold-Start Recovery 와 일관된 Low-Latency 제공
     * 엣지 분산
          + 백엔드 코드를 사용자에게 가깝게 배포 가능
          + 초저지연을 위해 Rivet은 Actor와 함수를 글로벌 엣지에 배포
          + HTTP, WebSocket, TCP, UDP 프로토콜을 지원하며, 외부 프록시 없이 글로벌 엣지에 배포 가능
     * 무제한 실행 시간, 컨테이너 지원
          + 장기 실행 프로세스나 백그라운드 작업 제한 없음
          + Docker 호환 컨테이너라면 모두 지원(Docker에서 동작하면 Rivet에서도 동작함)
     * Fault Tolerance
          + 액터 상태가 지속적으로 저장되어 장애/재스케줄 시 무중단 상태 복구 가능
          + 지능적 라우팅과 결합해 높은 가용성 보장
     * 로컬 개발 지원
          + rivet dev 또는 Docker Compose로 로컬 클러스터 즉시 구동 및 테스트
          + 프로덕션 배포 전 로컬에서 반복 개발 가능

주요 활용 사례

     * AI 에이전트
     * 멀티테넌트 SaaS
     * Local-first 앱
     * 협업형 애플리케이션
     * 샌드박스 코드 실행
     * 게임 서버
     * Yjs 동기화/스토리지
     * 채팅 앱

   Rivet - 멀티플레이어 게임 서버 관리 시스템 오픈소스

   2년 전엔 오픈소스 게임 서버 용도였는데, 이제 일반적인 서버리스로 확장하고 다양한 유스케이스를 지원하게 확장되었네요.
"
"https://news.hada.io/topic?id=21342","사진을 Atkinson 디더링으로 변환","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         사진을 Atkinson 디더링으로 변환

     * 이 프로젝트는 고전적인 Macintosh 1-bit 필터인 Atkinson Dithering을 웹에서 구현함
     * 입력 이미지를 50% 회색과 비교하여 흑백으로 변환하고, 차이를 이웃 픽셀로 분배함
     * Canvas, Drag & Drop, WebWorkers, FileReader와 같은 최신 브라우저 기술을 활용함
     * 변환된 이미지는 오른쪽 클릭 저장이 가능함
     * 이미지의 드래그 저장은 브라우저의 제한으로 지원되지 않음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

오픈소스 프로젝트의 중요성 및 차별점

     * Atkinson Dithering은 Hyperdither와 HyperScan에서 사용된 클래식 Macintosh 그래픽 효과임
     * 복잡한 이미지 색상 정보를 픽셀 단위로 단순하게 변환하여, 경량 흑백 이미지 생성에 유용함
     * 웹 기반 구현으로 별도의 소프트웨어 없이 최신 브라우저만 있으면 사용 가능함
     * WebWorkers를 통해 대용량 이미지 처리 시 비동기 실행 및 성능 최적화가 가능함
     * 오픈소스 코드로 기능 확장 및 커스터마이징이 용이함

Atkinson Dithering 알고리듬 개요

     * 각 픽셀을 50% 그레이(회색) 값과 비교하여 흑백으로 변환함
     * 변환으로 인한 차이값을 다음과 같이 주변 6개 픽셀에 분배함
       (X: 현재 픽셀, 1/8씩 분배)
          + X 1/8 1/8
          + 1/8 1/8 1/8
          + 1/8
     * 이 방식으로 이미지 전체에 디더링 효과를 적용함

구현 및 사용 방식

     * 이미지 파일을 브라우저로 드래그 앤 드롭하거나 파일 선택 기능을 통해 입력함
     * Canvas API를 이용하여 실시간으로 이미지를 변환 및 렌더링함
     * FileReader를 사용해 이미지 데이터를 읽고,
     * WebWorkers를 이용해 디더링 처리를 백그라운드에서 실행함
     * 변환된 이미지는 오른쪽 클릭을 통해 저장 가능함
       (브라우저의 한계로, 이미지를 바탕화면에 바로 드래그하여 저장할 수 없음)

기술 스택 및 지원 환경

     * HTML5, JavaScript의 최신 API를 적극적으로 활용함
     * 최신 브라우저 환경이 필요하며, 구형 브라우저에서는 일부 기능이 제한될 수 있음

결론

     * Atkinson Dithering 필터의 간편하고 직관적인 웹 구현 제공
     * 그래픽 개발자, 아트웍, 이미지 경량화 등 다양한 분야에서 활용 가능성 높음

        Hacker News 의견

     * 여전히 내가 가장 좋아하는 흑백 디더 알고리즘임
       대학교에서 Mac에 B&W 플랫베드 스캐너를 연결해 하이퍼카드 스택 같은 프로그램으로 이미지를 스캔해 흑백 이미지를 만드는 경험이 있었음
       대학교 서점에서 산 클립아트 책의 이미지를 간단히 스캔해 1988년쯤 작성하기 시작한 Mac 셰어웨어 게임의 '로고'로 사용함
       그 당시에는 Atkinson의 알고리즘이 얼마나 멋진지 몰랐지만, 나중에 다른 디더링 알고리즘을 사용해보고 Bill의 코드의 확산 방식이 정말 훌륭하단 사실을 깨달음
       최근에는 eInk 캘린더 프로젝트에서 Moon의 여러 위상 이미지를 Atkinson 스타일로 변환하고 싶어서 관련 사이트를 찾아 달 이미지를 변환함
     * info dialog의 ""as follows"" 링크는 클릭하지 않는 게 좋음
       오래 업데이트되지 않아 지금은 NSFW(직장이나 공공장소에서 보기 부적절) 링크로 바뀌었음
     * 이 구현물 정말 훌륭함
       다운로드할 때 anchor의 ""download"" 속성에 값을 주면 파일에 기본 이름과 .png 확장자를 줄 수 있어서 다운로드 경험을 조금 더 개선할 수 있음
       참고: HTMLAnchorElement.download 문서
          + 방어해보자면, 그 download 속성은 네가 링크한 대로 2017년 3월부터 브라우저에서 지원되기 시작했음
            반면 디더링 툴 저장소의 마지막 커밋은 2016년 3월로 보임
            저자분은 여전히 GitHub에서 다른 저장소로 활동 중이니, 아마 pull request를 받아줄 수 있지 않을까 기대함
            링크: canvas-atkinson-dither GitHub 저장소
     * 내가 개발하고 있는 프로젝트도 있는데, 여러 이미지를 MacPaint로 변환해 400k MFS 포맷 디스크 이미지로 만들 수 있게 해줌
       링크: mfsjs 프로젝트
       몇 달 동안 내 홈 디렉토리에서 약간 방치되어 있었지만, 최근 Gemini Deep Research를 사용해 라이브러리를 보완했음
       다른 언어로 재현하거나 개선하고픈 사람을 위해 LLM이 생성한 마크다운도 포함함
     * Python으로 Atkinson 디더링을 해보고 싶다면
       hyperdither 프로젝트 추천
     * 구현도 멋지고 인터페이스에서 옛 추억이 느껴짐
       최근 내 Atkinson 디더링 웹 컴포넌트[0]의 접속자가 늘어서 이상하다 생각했는데, 이런 슬픈 소식이 있었음
       개인적으로 Atkinson 디더링이 원래 Mac 같은 정말 선명한 모니터에서 가장 예쁜 이미지를 만들어준다는 느낌임
       뭔가 쿨하고 80년대 느낌이라 작년에 만든 게임에도 사용함
       [0]: 픽셀 단위 정밀 Atkinson 디더링 웹컴포넌트
          + 와, 멋진 웹 컴포넌트임
     * 내가 몇 년 전에 만든 비슷한 툴
       비욘드룸 디더링 툴
     * 사이즈 옵션 중 하나가 512x384인데, 원래 Mac 해상도는 512x342임이 흥미로움
          + 진짜로 초창기 Mac은 512x342 화면 해상도였음
            관련 정보: 오리지널 Macintosh 해상도
            수정: 내용을 다시 읽어보니, 사실 네 말이 맞았음
          + 그건 우연이 아닌 듯한 느낌임
     * UI가 귀엽고, 데모의 GitHub 링크도 참고할 만함
       canvas-atkinson-dither GitHub 저장소
     * 오늘 돌아가신 Atkinson과 같은 사람인가요? 그리고 이건 그분을 추모하는 프로젝트인가요?
          + 어느 정도는 맞는 말임
            하지만 저장소의 첫 커밋이 15년 전이라 최근 뉴스를 듣고 급히 만든 건 아님
          + 네, 이 알고리즘을 Atkinson 본인이 '발명'함
            '발견'이라고 썼지만, '발명'이 더 정확함
"
"https://news.hada.io/topic?id=21344","The Power of Composition (Scott Wlaschin) 보고 느낀 점 - 합성하려다보니 Currying과 Monad","                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The Power of Composition (Scott Wlaschin) 보고 느낀 점 - 합성하려다보니 Currying과 Monad

     * 재사용 방법의 하나인 합성은 타입과 함수
          + 타입은 AND 또는 OR로 합성
     * input 개수와 output 개수가 같을 때는 함수 합성이 쉽다
          + 함수의 output을 다음 함수의 input으로 넘기면 끝
          + 개수가 다를 때 이걸 해결할 방법이 필요
     * input 개수가 더 많을 때는 Currying(커링)
          + input 개수를 하나로 만들어준다
     * output 개수가 더 많을 때는 Monad(모나드)
          + output 개수를 하나로 만들고 처리 혹은 처리되지 않음으로 구분
               o 처리된 건 다음 함수로 그냥 넘김
               o 처리되지 않은 건 함수로 처리 시도
          + 알고 보니 이게 Monad
          + output을 Monad에 담고 bind로 함수 조합

   함수 조합으로 설명하면서 ""왜?""에 대한 답을 주니깐 이해가 잘 됩니다. 모나드를 상자에 넣고 꺼내고 뭐 이런 식으로 설명한 글을 봤을 때, 이해가 잘 되지 않았었는데요. 지금 생각하면 ""왜""가 빠진 글이라서 그랬던 것 같습니다.

   잘 읽었습니다~

   잘 봤습니다. 이렇게 보니까 이해하기 쉽네요
"
"https://news.hada.io/topic?id=21304","SQLite-JS - SQLite에 JavaScript 기능을 추가해주는 확장","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              SQLite-JS - SQLite에 JavaScript 기능을 추가해주는 확장

     * SQLite DB에서 JavaScript로 사용자 정의 함수, 집계, 윈도우 함수, 정렬 방식(collation)등을 구현할 수 있는 확장 도구
          + SQL로 표현하기 어려운 로직도 JavaScript 코드로 직접 등록·실행할 수 있음
     * 기존 SQL의 한계를 넘어, 텍스트 가공·수식 연산·통계·특수 집계·자연스러운 정렬 등을 JavaScript로 간단히 구현해 다양한 데이터 처리 시나리오에 활용 가능
     * 확장 모듈 로딩만으로 바로 사용 가능하며, js_eval로 쿼리 내에서 JavaScript 코드 직접 실행, 사용자 정의 함수 동기화로 분산 클러스터 환경에서도 동일하게 동작
     * 함수·집계·윈도우·정렬 로직을 SQL에서 동적으로 생성/수정할 수 있어, 복잡한 비즈니스 로직, 데이터 분석, 통계 처리에 매우 효과적
     * 타임존·로케일·커스텀 정렬, 고급 통계, 실시간 분석 등 기존 SQLite로는 불가능한 고급 처리를 JavaScript 생태계를 통해 실현 가능

주요 함수들

     * Scalar Functions: 각 행마다 하나의 결과를 반환, 데이터 가공/계산에 활용 (예: 생일로 나이 계산, 이메일 도메인 추출)
     * Aggregate Functions: 여러 행을 처리해 하나의 값을 반환 (예: 표준편차, 중앙값 등 커스텀 집계)
     * Window Functions: 데이터 집합 전체에 접근 가능, 슬라이딩·누적 통계, 이동 평균 등 복잡한 윈도우 연산 지원
     * Collation Sequences: JavaScript로 커스텀 정렬 알고리듬 구현, 로캘/자연어/대소문자 구분 없는 정렬 등 가능
     * JavaScript Evaluation: SQL 쿼리 내에서 JavaScript 코드 즉시 실행, 임의 연산·데이터 변환 등 활용
     * 분산 환경 동기화: sqlite-sync와 연동하면 생성한 JS 함수가 클러스터/오프라인 환경 모두 자동 동기화
"
"https://news.hada.io/topic?id=21361","안드로이드에서 CDC 이더넷을 사용할 수 없는 이유 (2023)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  안드로이드에서 CDC 이더넷을 사용할 수 없는 이유 (2023)

     * 안드로이드의 EthernetTracker 서비스는 이름이 ethX인 네트워크 인터페이스만 인식함
     * Linux의 CDC 이더넷 드라이버는 인터페이스 이름을 usbX로 생성함
     * 이로 인해, 표준 CDC 이더넷 장치는 안드로이드에서 자동으로 활성화되지 않음
     * 이를 해결하려면 사용자가 직접 폰을 루팅하고 config_ethernet_iface_regex 값을 변경해야 가능함
     * 표준을 따르는 USB 이더넷 어댑터가 아니라, 벤더 특화 드라이버가 있는 특정 칩셋 제품만 사용하는 것이 현실적 방법임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론 및 문제 개요

     * 안드로이드 기기에서 CDC Ethernet이 작동하지 않는 핵심 원인은 인터페이스 네이밍 규칙 때문임
     * 시스템적으로는 USB 이더넷 어댑터를 지원하지만, Ethernet 메뉴가 활성화되는 조건에는 제약이 있음
     * 호환 가능한 칩셋 정보를 얻기 어렵고, 실질적으로는 사용자 간 ""소문""에 의존하는 구조임
     * 안드로이드도 리눅스 커널 기반이지만, 커널 설정만으로 모든 것이 결정되진 않음

USB 디버깅 및 ADB 설정

     * 안드로이드 기기에서 USB 디버깅 활성화 후 ADB 설치 필요
     * 네트워크 어댑터를 테스트하려면, ADB를 Wi-Fi를 통한 네트워크 모드로 전환해야 함
     * 커맨드를 통해 현재 커널 버전과 아키텍처를 확인 가능

커널 버전 및 설정 확인 방법

     * 최신 폰(Android 11 이상)은 GKI(Generic Kernel Image) 커널 구조를 가짐
          + Google이 기본 커널을 빌드하고, 제조사가 모듈만 추가하는 방식
          + 해당 커널 설정 파일(gki_defconfig)에서 지원 기능을 파악 가능
     * 구형 폰은 제조사별로 따로 제공하는 커널 소스에서 defconfig 파일을 찾아 확인해야 함
     * 운이 좋다면, /proc/config.gz 경로에서 현재 커널의 설정을 직접 확인할 수도 있음

지원되는 USB 이더넷 어댑터 확인법

     * 대부분의 관련 커널 설정값은 CONFIG_USB_NET_XXX 형태임
          + y이면 내장, m이면 모듈로 빌드(아마도 사용 가능함), is not set이면 지원 안 함
     * drivers/net/usb/Kconfig 파일에서 각 설정값 설명을 참고 가능
     * 어댑터 칩셋 정보는 여전히 명확히 표시되는 경우가 드묾

CDC 이더넷(Communications Device Class) 및 안드로이드 적용 사례

     * CDC는 USB 네트워킹 표준으로, EEM/ECM/NCM 다양한 프로토콜을 제공
     * Linux, Windows, macOS에서 표준 CDC 이더넷 장치는 별도 드라이버 없이 자동 인식
     * 안드로이드 역시 커널 레벨에서는 관련 드라이버 빌드가 되어 있음
          + 예시: CONFIG_USB_NET_CDCETHER, EEM, NCM 모두 y로 설정된 삼성 기기
     * 그러나, 이더넷 메뉴는 여전히 비활성화됨

안드로이드의 네트워크 인터페이스 추적 로직

     * 안드로이드는 네트워크 인터페이스 탐지에 EthernetTracker.java 클래스를 사용
     * EthernetTracker는 새 인터페이스가 등장할 때 이름 패턴(정규표현식) 매칭을 수행함
     * 매칭 기준은 리소스(config_ethernet_iface_regex)에서 가져옴
          + 기본값은 eth\d (eth로 시작하고 숫자가 뒤에 오는 네트워크 인터페이스만 유효)
     * 커널이 생성하는 이름(usb0)은 해당 패턴에 부합하지 않아 추적 및 활성화에서 무시됨

해결 제한 및 결론

     * 이 네이밍 정규표현식은 사용자가 직접 변경 불가(루팅 없이 불가능)
     * 결과적으로 표준 CDC 이더넷 제품은 연결되어도 네트워크 메뉴에서 사용할 수 없음
     * 반대로, 벤더나 칩셋 드라이버로 직접 등록되는 일부 어댑터만 사용 가능
     * Google이 EEM 모듈 등 표준 지원 코드를 커널에 포함하더라도, 실제 동작은 불가함
     * 최소한 (eth|usb)\d로 정규표현식을 바꾸면 해결될 심플한 문제지만, 현재는 그대로 남아 있음

요약

     * 핵심 원인: 안드로이드가 CDC 이더넷 표준을 무시하는 것이 아니라, 네트워크 인터페이스 이름이 정규표현식(eth\d)과 일치하지 않아 활성화되지 않는 구조임
     * 우회 방법: 폰을 루팅한 후 config_ethernet_iface_regex 값을 (eth|usb)\d 등으로 변경해야 가능함
     * 실제 선택: 표준 USB CDC 지원 어댑터보다는, 칩셋별로 드라이버 연동이 명확한 제품을 선택하는 것이 현실적인 대안임
     * 구조적 문제: 사용자 가시성 및 표준 호환성 측면에서 소프트웨어 상위 스택의 네이밍 정책 미비가 시스템적 한계로 작용하는 사례임

        Hacker News 의견

     * 예전 직장에서 Android 기기와 CDC Ethernet 어댑터를 연결하려다 고생한 후 이 글을 작성한 경험 공유, 그 후 몇몇 사람들로부터 MAC 주소의 특정 비트를 바꾸면 커널이 ethX 이름을 할당하게 된다는 사실을 들었다는 이야기, 본인은 직접 테스트하거나 해당 내용을 게시글에 반영하지는 않았고, 요즘은 Android 기기를 거의 사용하지 않는다는 설명, 이 방법은 오로지 MAC 주소를 컨트롤할 수 있을 때만 쓸 수 있다는 전제 추가
          + 이 정보 내게 도움이 될 수 있을 것 같다는 반응, 어느 비트인지 찾았다며 관련 링크 공유
          + 해당 포스트에 긍정적 반응 표출
     * 흥미로운 딥다이브 아티클이라는 평가, 소스를 확인해보니 2023년 10월에 문제의 정규식이 eth\d에서 *로 변경된 것 같고, 이로 인해 문제가 해결된 것으로 추정, 관련 코드 변경 링크 제시, Android U+ (아마 버전 14)부터 기본적으로 usb\d+와 eth%d 모두를 포함하게 됐다는 설명
          + 해당 변경 사항이 나중에 ""usbX 인터페이스로 테더링하는 기기가 있기 때문""에 대해 롤백(되돌림) 됐다는 사실, 곧이어 Android V+ 버전(신규 버전)만 지원하도록 다시 반영됐다고 설명, 롤백 관련 링크, 최종 적용 링크도 첨부
     * Android의 EthernetTracker 서비스가 ethX로 네이밍된 인터페이스만 인정한다는 부분에 대한 강한 비판, 리눅스 배포판에서는 이미 2000년대에 이런 문제를 해결했다는 설명, 드라이버마다 자기만의 네임 프리픽스를 쓰는 경우가 많아 시스템 전체를 조사해야 하는 불편함이 있었다는 회고, 오늘날 리눅스 배포판은 udev와 같은 도구로 네트워크 인터페이스명을 자동 변경하고, 이 과정이 커널의 SIOCSIFNAME ioctl 호출로 작동한다는 설명, 최신 커널에서는 ""wlan*"" 혹은 ""wlan%d"" 식의 이름에 자동 숫자가 부여되는 편리함까지 제공한다는 점 덧붙임
     * LineageOS 커밋 히스토리를 보면 해당 문제가 수정됐다가 다시 호환성 문제로 되돌려졌고, 최신 Android 버전에는 다시 적용된 상태라는 분석, 커밋 내용을 보면 Google 소속도 관여한 것으로 보여서 구글 공식 빌드에서도 적용됐을 가능성이 있다는 의견
     * ""<i>config_ethernet_iface_regex 값을 바꾸기 위해선 폰을 루팅하는 것 외엔 방법이 없다</i>""는 글의 문장에 공감하며, 내가 소유한 기기에서 루트 권한이 중요한 또 다른 이유라고 주장
          + 네트워크 트래픽을 임의로 우회할 수 있다는 점이 사용자 영역에 superuser 권한을 부여해선 안 되는 가장 큰 이유라 생각, OEM에 부트로더 언락 허용 압박하는 건 찬성하지만, Android에서 루트 권한이 공격자에게 허용하는 큰 위협 범위에 비해 정당화될 만한 용도를 딱히 못 떠올리겠다는 입장
     * ""안된다""고 하는 의미를 묻는 질문, 맥북용 USB 허브 동글을 Android 폰에 꽂으면 Ethernet 포트가 문제 없이 동작했고, 셀룰러 모뎀이 Ethernet 장치로 인식되어 Android에서 잘 작동한 경험 공유
          + 이런 문제는 이미 수정됐으며, 원본 기사는 2년 전 글이라는 안내
     * Android는 매우 불편하게도 여러 네트워크 동시 연결이 되지 않는다는 불만, 예를 들어 인터넷이 없는 WiFi(기본 라우터도 없음)와 셀룰러 네트워크를 동시에 연결하고 싶어도 불가, 리눅스나 윈도우에선 당연히 가능한데 Android는 이를 억지로 막고 있고, 심지어 많은 변형 버전에서는 인터넷 없는 WiFi에 집착할 경우 혼란스러운 방식으로 끊기게 된다거나 추가적으로 앱에서만 좀 돌아가는 API가 제공될 뿐 사용자 자체는 이런 제어를 할 수 없게 막혀 있다는 지적
          + iOS도 비슷하며, 블랙박스에서 영상을 받으려고 WiFi에 접속하면 ""인터넷 없음, 셀룰러로 전환?"" 팝업이 뜨고, 계속 WiFi에 머물겠다고 해도 결국 iOS가 알아서 CarPlay 네트워크로 강제 전환해버린다는 경험 공유, 수동 해제 방법조차 제공되지 않는 점 덧붙임
          + 윈도우도 실제로 두 개의 무선 어댑터로 두 개의 wifi 네트워크에 동시에 접속은 불가, 적어도 GUI에서는 안되고 터미널로는 시도해보지 않았다는 언급
          + 이 제한이 정말 짜증난다는 의견, 인터넷이 장애날 때 폰으로 진단하려는 순간 WiFi에 머물지 않아 어려움을 겪는 상황 공유, Android의 DNS 설정 또한 DHCP로 받아오지 않는 등 복잡한 문제도 있다는 불만
          + 서양 Android폰을 가지고 중국 본토에 들어가면 더욱 불편했던 경험 토로, Android가 인터넷 연결을 Google 서비스로 확인해 로컬 WiFi는 매번 인터넷 없음 경고를 띄움, 그럴 때마다 사용자가 수동으로 계속 연결 유지할 지 답해야 하는 번거로움 설명
     * 펌웨어 요구 사항도 꼭 확인해야 한다는 조언, 어떤 장치는 정상 인식돼도 펌웨어가 마련되어 있지 않으면 ifup에서 실패하고, Android UI는 이 상황을 전혀 보여주지 못하며 dmesg 로그만 확인해야 문제가 보임, CDC 장치에도 해당되는지는 확실치 않지만 많은 USB 이더넷 동글이 Realtek, Kawasaki 칩셋 위주였고 펌웨어 요구 케이스가 있었다는 경험담, 해당 Android 변화는 최근 일인 것 같지만 바닐라 AOSP 디버깅 기기에서는 USB 네트워크 동글을 잘 사용했으니 커널 혹은 CDC 드라이버 쪽의 네이밍 관행이 아닐까 추측, 결국 동글의 칩셋과 펌웨어 필요 여부는 신경 써야 한다는 조언
     * 15개 넘는 USB 이더넷 어댑터를 소유중이고 Realtek, AXIS 등 서로 다른 칩셋인데도 모두 아주 잘 동작했다는 경험, 리눅스에서 드라이버가 안 필요한 모델만 확보하면 사실상 모든 OS와 BIOS에서 문제 없이 쓸 수 있다는 확신
          + 2023년에 이슈가 수정됐다는 정보와 관련 Hacker News 링크 제시
          + 썬더볼트/USB 독에 달린 이더넷 어댑터가 pixel 5, pixel 9 두 폰 모두에서 잘 작동했다는 추가 경험
     * 완벽한 디버깅 저니로, 정규식 하나로 인해 전체 기기군이 작동 불능이 된 사례가 흥미로웠다는 감탄, 얼마 전 GPT-4와 OpenAI의 alignment/escalation 시스템에서 비슷한 구조적 한계에 부딪혔던 경험 회고, 공식 문서와 로그까지 갖춰서 내부 로직을 트리거하려 했지만 결국 사람이 볼 땐 합리적으로 보이지만 내부 인터페이스의 정규식에 매치되지 못해 막혀버린 것 같았다는 설명, 관련 기록을 별도 링크로 공유, 시스템 구조나 보이지 않는 인터페이스 경계에 관심 있다면 의견을 듣고 싶다는 제안
"
"https://news.hada.io/topic?id=21354","Cloudflare의 AI가 작성한 OAuth 라이브러리 살펴보기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Cloudflare의 AI가 작성한 OAuth 라이브러리 살펴보기

     * Cloudflare는 Anthropic의 Claude LLM을 활용해 새로운 OAuth 라이브러리를 개발하고, 프롬프트도 같이 공개했음
     * 라이브러리의 코드 구조는 깔끔하지만 테스트와 보안 검증 측면에서 많은 아쉬움이 존재함
     * CORS와 일부 인증 규격 구현에서 비표준적 또는 위험한 선택이 발견됨
     * 암호화 구현에는 장점이 있지만, 중대한 보안 버그와 프로토콜 오해가 드러남
     * LLM 기반 자동 코딩은 도움이 되나, 실무 수준 보안에는 전문가의 면밀한 검토가 필수임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Cloudflare OAuth 라이브러리의 개요

     * Cloudflare는 OAuth 프로바이더 라이브러리를 Anthropic의 Claude LLM을 활용해 대부분 자동으로 작성함
     * Claude의 출력물은 숙련된 Cloudflare 엔지니어들의 보안 및 표준 준수 검토를 거쳤으며, 커밋 히스토리에서 AI와의 상호작용 과정을 투명하게 공개함
     * 초기 구현 후 Claude의 추가 프롬프트와 결과물 검토를 통해 퀄리티를 보완함
     * AI에만 의존하지 않고, RFC 문서와의 교차 점검 및 핵심 전문가 리뷰가 강조된다고 명시함

전문가의 첫인상 및 코드 분석

     * LLM 코딩 방식 특유로 코드가 단일 파일에 집중되어 있으나, 구조는 일관되고 쓸데없는 주석이 비교적 적음
     * 기능 테스트는 있으나 OAuth와 같은 중요 인증 서비스에 요구되는 수준에는 미치지 못함
          + 필수(MUST/MUST NOT) 사양 체크가 빠진 부분 및 파라미터 유효성 약화가 엿보임

보안 관련 우려 및 번역자 해설

  1. CORS 정책 문제 (""YOLO CORS"")

     * 거의 모든 오리진을 허용해 동일 출처 정책이 사실상 해제되는 CORS 헤더 세팅이 발견됨
     * 이는 Cloudflare 엔지니어가 LLM이 아닌 사람이 직접 결정한 부분임
     * credentials 기능은 활성화되어 있지 않아 치명적 브라우저 보안 위협은 낮지만, 원인과 목적의 분명성이 미흡함

  2. 표준 보안 헤더 미적용

     * HTTP 응답에 X-Content-Type-Options: nosniff 및 HTTP Strict Transport Security 등 핵심 보안 헤더 미적용 현상이 존재함
     * JSON API 특성상 일부 헤더의 필요성이 낮을 수 있으나, 클라이언트/브라우저 취약점 예방 차원에서 적용 필요성이 큼

  3. OAuth 표준 미숙지 흔적

     * Public client 지원을 위해 OAuth 2.1에서 폐기된 implicit grant 방식을 구현함
          + 사실 해당 기능은 PKCE나 CORS 완화로 충분히 대체 가능
          + Claude가 implicit grant를 추천한 것으로 보이며, 실제 토큰 발급 단계에서는 제대로 검증하지 않음
     * Basic Auth 처리 미흡: OAuth에서는 특유의 URL 인코딩 방식이 필요한데 이를 누락함
          + 클라이언트 시크릿에 콜론 포함 시 발생할 수 있는 보안 버그 secondary issue
          + 단, 해당 라이브러리는 자체적으로 클라이언트 ID/시크릿을 생성해 형식 통제가 가능한 구조임

  4. 토큰 ID 생성 코드의 보안 문제

     * 토큰 ID 랜덤 문자열 생성 방법이 통계적으로 치우침(biased) 이 존재함
          + 엔트로피 감소로 인해 공격이 용이해질 수 있으나, 실질적인 위협은 제한적임
     * ""모든 코드 라인이 전문가에 의해 리뷰되었다""는 주장과 달리, 초기 커밋에서 버그가 그대로 존재
          + 첫날 한 명의 개발자가 21번 메인 브랜치에 직접 커밋한 이력 등, 체계적 리뷰 부족을 암시함

암호화 기능 및 LLM 상호작용 사례

     * 토큰 저장소 암호화 설계는 사람이 주도하고, 구현은 Claude가 지원함
     * 토큰별로 props를 암호화하고, 각 토큰에 대해 대칭키를 래핑하는 방식 적용
     * Claude가 중간에 잘못된 설계를 제안하자, 엔지니어가 의도와 보안 취지를 명확하게 제시하여 수정함
          + 예시: SHA-256 해시를 래핑키로 사용할 경우 드러나는 취약점 지적 후 HMAC 기반으로 변경
          + PBKDF2 제안에 대해 성능상 비효율을 짚고, 32바이트 HMAC 키 적용으로 조정함
     * 이 과정은 AI와 작업할 때 높은 수준의 도메인 지식 필요성을 잘 보여줌
          + 치명적 결함을 비전문가라면 인지조차 어려울 수 있음

총평 및 시사점

     * 첫 버전 임에도 완성도는 무난하나, 실 서비스에 바로 적용하기에는 위험성이 큼
     * OAuth 프로바이더 개발은 본질적으로 매우 까다로운 보안·기능 검증 작업이 필요함
          + 대기업 수준의 수십만 개 자동화 테스트와 다계층 보안 점검이 일반적임
          + LLM 기반 자동 코딩을 “쉽게” 적용할 수 있는 분야가 아님
     * 프로젝트의 커밋 히스토리는 LLM이 어느 수준까지 보조적으로 작동할 수 있는지 흥미롭게 보여줌
          + 단, 일부 결함은 LLM이나 사람 모두가 종종 범하는 실수이며, Stack Overflow 답변 등 기존 커뮤니티에서도 유사하게 발견됨
          + 면밀함과 꼼꼼함이 중요한 코드 영역에서는 AI, 인간 모두 세밀한 주의가 필요함
     * LLM을 활용해 코드를 검토하거나 결과를 신뢰하려면, 직접 구현 경험 및 System 2 사고가 필수적임
          + 단순/비핵심 작업에서는 충분히 LLM에 맡길 수 있지만, 인증이나 보안과 관련된 주요 시스템은 전문가 주도의 설계·구현이 바람직함

   Cloudflare가 Claude와 함께 OAuth를 빌드하고 모든 프롬프트를 공개함

        Hacker News 의견

     * LLM과 상호작용할 때는 많은 도메인 지식이 필요함을 이번 사례에서 직접적으로 알 수 있음. 예를 들어 Claude가 중간에 만들어 낸 “치명적 결함”을 일반 개발자라면 눈치채지 못할 수 있음. PBKDF2로의 변경을 이상하게 여기는 것도 도메인 전문성 덕분임. 나의 결론은 LLM을 효율적으로 활용하려면 실력 있는 리뷰어와 ‘리더’가 필요한 것임. 만약 해당 주제에 대해 LLM만큼 모른다면, 반드시 비중이 낮거나, 충분히 시간적 여유가 있어야 모든 출력을 검증할 수 있음
          + 앞으로 이런 새로운 환경에서는 도메인 전문가들이 어디에서 생겨나는지 궁금증이 생김. 결국 누가 이렇게 깊이 아는 사람이 될 수 있을지 고민임
          + 사람들이 '잘 모르는 분야에서만 LLM을 쓴다, 전문가라면 직접 코딩한다'는 의견을 들을 때마다 의아함. 오히려 전문가일수록 LLM의 출력을 더 정확히 검토할 수 있고, 내가 원하는 것을 도메인 전문가의 방식에 가깝게 설명할수록 결과물이 좋아짐. 어찌 보면 당연한 일임(LMM이 통계적으로 생성된 텍스트 엔진이기 때문에)
          + LLM은 기본값 추가나, 예외 처리, 각종 우회로를 너무 쉽게 넣는 경향이 있음. 그래서 동작하는 듯 보이지만 실제로는 문제가 있거나 곧 실패할 코드가 쉽게 만들어짐. 내가 쓴 CLAUDE.md에서 여러 차례 이 부분을 강조하려 했는데도 종종 계속 그런 결과가 나옴
          + 나는 LLM으로 k8s 배포 작업을 대부분 처리했음. 빠르게 작동하는 결과를 내긴 하지만, 항상 시크릿을 사용하고 인증 정보를 평문으로 커밋하지 않도록 계속 주지시켜야 했음. 이런 실수는 정말 위험함. 교육용 튜토리얼에서는 기초에 집중하려고 보안을 자주 생략하는데, LLM 훈련 데이터에 그런 사례가 너무 많아서 이렇게 출력되는 것 같음
          + 시간이 지나면 AI 코딩 도구가 도메인 지식을 스스로 조사할 수 있을 것으로 기대함. 이미 나온 일부 ‘AI 연구’ 도구들은 이런 능력이 매우 뛰어나지만, 아직 코딩 도구와 제대로 통합돼 있지는 않음. 연구는 공개 인터넷 뿐 아니라 회사 내부 문서상의 도메인 지식을 참조할 수도 있음. 다만 일부 지식은 사람의 머릿속에만 있으므로 이용자가 직접 전달해줘야 함
     * 최근 Kafka consumer를 AI 도움으로 작성하여 데이터 마이그레이션을 진행함. 이런 단기성, 처음부터 새로 짜는 프로젝트이면서 내가 언어(go)는 꽤 알지만 오랜만에 쓰는 상황에서 AI 활용 효과가 최대치였음. 데이터가 모두 한 topic으로 들어와서 성능 확보를 위해 꽤 복잡한 병렬 처리를 구현했음. 전반적으로 AI 덕분에 약 2배는 빨라진 느낌이었음. 특히 go 문법을 가끔 잊을 때 검색 대신 AI에게 바로 물어본 부분이 도움됐음. 하지만 잠재적 버그가 적어도 4개(그 외로 명백한 버그들은 훨씬 더 많음)나 숨겨져 있었음. Kafka나 멀티스레딩에 익숙하지 않다면 바로 운영에 내보냈을 것도 같음. 대형/장기 프로젝트에서는 10~20% 수준의 개선이 나타남. 최신 모델 기준으로 이런 흐름임. 전체적으로 볼 때 이건 메모리 관리 언어로 전환할 때 얻었던 생산성 증가와 비슷함.
       PM이 개발자를 대체하는 상상과는 거리가 있음(지난 3년간 변화 속도 기준). 오히려 나의 진짜 걱정은 중간 레벨의 '기술 폭풍'급 개발자가 AI로 인해 10배 효율이 높아지면 미묘한 버그를 찾거나 대응하지 못해 더 위험할 수 있음. 시니어/스태프급 엔지니어가 리뷰 폭주를 감당할 수 없을 것 같음. 그리고 주니어에서 시니어로 성장하는 과정도 더 취약해질까 걱정임. 이미 복붙 프로그래머가 문제인데 AI로 인해 이런 패턴이 더 강화됨. 결국 시장이 해결하겠지만, 수십 년이 걸릴 수도 있다는 불안함
          + AI가 만들어내는 버그는 정말 교묘함. 나도 AI에 멀티스레드 코딩을 시켰다가 미묘한 버그를 실제로 운영에 넣은 적이 있음. 리뷰, 테스트를 해도, 직접 손으로 짰을 때만큼의 집중이 나오지 않음. 당분간 AI가 짠 코드는 취급 시 흔히 있는 버그를 미리 확인하고, 치명적인 영향이 없는 영역에 한정해서 써야 할 필요성 느낌
          + 나 역시 ‘중요한 작업’에서는 10~20% 정도의 개선을 체감함. 진짜 변화긴 하지만 소프트웨어 개발의 본질을 바꾸진 않음. 결국 Brooks의 ""No Silver Bullet""(은탄환은 없다) 명제의 재확인
          + 나 역시 ""중간급 기술 폭풍"" 논점에 동의함. 특히 컨설팅 업계에선 베테랑이 비용 대비 가치가 낮게 취급되곤 하는 현실임. 예전엔 나도 빠르게 작업하는 쪽이었고, 나중에는 비전문가 PM에게 단기적인 해결책의 약점을 설명하느라 힘들었던 경험 있음. 대형 IT 기업은 이런 문제를 빠르게 잡아내겠지만, 현실적으로 금융, 의료 데이터를 다루는 코드는 값싼 단기 계약 인력으로 짜임. 이런 상황은 LLM 등장 전에도 문제였음. 지금은 보안 민감한 개발자들에게 훨씬 더 힘든 시대일 것
          + 생성 코드에서 미묘한 버그를 발견했다고 했는데, 그런 버그를 AI가 생성한 테스트 코드로 자동 검출하면 어떨지 생각됨. 물론 테스트 코드 자체도 버그가 있을 수 있지만, 미래에는 생성 코드보다 테스트 결과만 집중적으로 검토하게 될지도 모를 시나리오가 머리에 그려짐
          + 복잡한 병렬 처리라 했는데, 그건 partition과 consumer-group 활용으로 해결할 수 있는 영역 아닐지 의문 제기
     * LLM을 적극적으로 신뢰하며 ‘절벽에서 떨어지듯’ 무비판적으로 기대고 일하는 사람들을 보면 속이 답답해짐. 완전히 블랙박스에 의존해서 작업하고 검증까지 다 맡기는 건 위험함. 게다가 어마어마한 에너지를 소모하는 구조여서, 사람을 대체하는 핑계로 사용되기도 함. 이런 환경이 인생을 10배 좋게 만든다는 건 솔직히 믿음이 가지 않음
     * 직접 개발했을 때와 남이 만든 결과물(특히 LLM산 코드)을 검증하는 과정을 비교할 때, 인간은 종종 그럴듯한 겉모습에 속아 문제점을 덜 비판적으로 받아들이는 경향이 있음. 코드의 ‘모양새’도 버그 찾기에 큰 영향을 끼침. 이를 검증하려면 코드에 버그를 일부러 끼워넣고 코드 리뷰어들이 이를 찾는지 실험해보는 것도 방법임. 직접 손으로 뭔가를 구현하면 훨씬 더 천천히, 치밀하게 생각하게 되고 세부 사항을 신경 쓰게 됨(그래서 예상치 못한 버그도 발견함). 그래서 학습 목적으론 툴을 직접 ‘토이 버전’으로 짜보는 방법이 가장 좋다고들 추천하는 것임. 인간의 인지 구조와 연결된 이야기임
          + 표면적으로 깔끔해 보이는 코드에서 미묘한 버그를 찾아내는 능력은 많은 리뷰 경험에서 비롯된 냉소와 의심으로부터 나옴. 나 스스로 오랜 시간 리뷰에 할애하다 보니 이제는 무슨 코드든 항상 잠재적 문제를 상정하게 됨. 직접 짠 코드라면 버그가 줄었을지는 모르지만, 내가 직접 작성해도 멍청한 실수를 한 적 많기 때문에 장담은 못함. 오히려 내가 직접 이 라이브러리를 썼을 확률은 낮음(할 일이 너무 많아서 주로 주니어 엔지니어에게 넘어감). 결국 인간이 짠 코드라고 해도 버그가 사라지지는 않는다는 점은 확신함. 오히려 Claude가 만든 많은 버그는 사람이 충분히 저지를 만한 전형적인 수준임. 한편, 지금 시점에서 Cloudflare에서는 LLM 때문에 개발자가 대체되지는 않을 것으로 봄. 인력을 더 뽑는 건 할 일의 양이 아니라 예산이 좌우함. LLM 덕분에
            생산성이 오르면 매출 상승이 가능해지고, 더 많은 사람을 채용하는 흐름이 만들어질 수 있음. (물론, 이건 회사 공식 입장이 아닌 개인적 의견임)
     * 기사에서는 불필요한 주석이 많지 않다고 했지만, 실제 코드엔 ‘// Get the Origin header from the request’와 같은 의미 없는 주석이 있음
          + 이런 주석은 LLM을 쓴 티가 나는 증거로, 아무런 의미가 없어 항상 지움
          + 사람한테는 이런 주석이 쓸모 없지만, LLM 입장에서 아래 코드의 기능이 자연어로 같이 기술되어 있으면 이해에 도움이 되는 일종의 로제타 스톤 역할을 할 수도 있다고 추측함. 토큰 소모가 늘어나는 대가일 수 있지만, 실제 LLM이 과도하게 주석 많은 코드에서 더 나은 편집을 하는지 검증해보고 싶기도 함
          + Claude가 이런 쓸모없는, 중복되는 주석을 엄청나게 자주 작성하는 경향이 있다는 경험 공유
     * 제안하고 싶은 건, 코드의 한 branch를 동결해놓고, AI들을 사용해서 한쪽은 취약점을 만들고 숨기려 노력하고, 또 다른 쪽은 이를 찾고 고치는 역할로 배틀하는 실험임. 즉, 체스의 진화 과정을 코드 개발에도 적용해보는 것임
     * 내가 바로 이 라이브러리의 작성자임(정확히는 프롬프트 작성자). Neil만큼은 아니어도 OAuth에 대해 어느 정도는 전문가지만, 그가 코드 리뷰를 해줘서 정말 기쁨. “YOLO CORS” 관련해서 오해가 있었는데, 이건 단순한 초보 실수로 한 게 아님. 이 CORS 설정들은 심사숙고해서 의도적으로 한 것임. OAuth API(토큰 교환, 클라이언트 등록) 엔드포인트와 OAuth bearer token이 필요한 API 엔드포인트에서만 CORS를 비활성화함. 이 엔드포인트들은 브라우저 자격 증명(쿠키 등)으로 인증되지 않아서, 실제로 CORS가 보호하는 것이 아무것도 없다는 판단임. CORS의 본질은 자격 증명을 자동으로 첨부시키지 않는 보안막인데, bearer token은 클라이언트가 명시적으로 첨부해야 하므로 크로스 오리진에서도 안전함. 실제로 나는 예전부터 CORS 스펙 작성자와 논쟁한 경험이 있는데, 브라우저
       자격 증명 대신 bearer token을 써야 진짜 안전하다고 주장해왔음. 한편, token ID 생성이 비효율적이라는 지적에 대해선 ‘치명적’까진 아니라고 봄. 보안성 자체는 문제가 없고, 알고리즘을 이후에 자유롭게 바꿀 수 있기 때문임. commit이 한 명에 의해 한 날에 21개 main에 올라간 부분은, git 히스토리 리라이팅 때문에 github에서 날짜가 왜곡돼 나타난 것임. 암호화 구현 칭찬은 정말 고마움. 이건 AI가 만든 게 아니라 내 explicit한 설계 지시가 있었기 때문임
          + ""OAuth API에서는 CORS 헤더를 disable한다""고 했는데, 실제로는 CORS 규칙을 비활성화하도록 CORS 헤더를 설정하는 것임. 맥락상 충분히 드러나긴 하지만, 혼동될 수 있으니 보충 설명
          + Cloudflare가 이 라이브러리를 실제 운영에 쓸 계획이 있는지 궁금증
     * 인기 Stack Overflow 답변에도 똑같은 실수가 많고, Claude도 그런 데서 배웠을 걸 생각하면 걱정됨. 보안 구멍이나 실수 자체보다 사회 전반의 지식수가 LLM 등장 이전의 인터넷 인기 답변에서 고정될 수 있다는 점이 특히 무서움
          + 나도 마찬가지로 걱정됨. 사용 중인 일부 서비스에서 “코드 작성에 LLM을 사용하지 않는다”는 점을 공개적으로 밝힌다면 큰 신뢰 포인트가 될 것임
     * ForgeRock에서 OAuth 실장에 수백 개의 보안 버그가 있었고, 수십만 개의 자동화 테스트, 위협 모델링, 최고 수준 SAST/DAST, 전문가 리뷰 등을 모두 해도 이런 결과였음을 보며, OAuth가 정말 까다롭다는 걸 새삼 실감함. 일부에서는 ‘쓰레기장 불’ 같은 구현체라고도 함. 정작 나는 스펙을 읽거나 구현해본 적은 없음
          + Oauth 구현 관여 경험이 있을 때마다 항상 끔찍하게 복잡했다는 체감
          + Oauth는 정말 귀찮고, 너무 많은 니치가 존재함
          + 사실 새로 짠 코드는 항상 버그가 있게 마련임. 복잡할수록 더 확실함. 그래서 기업들은 ‘battle tested(이미 현장에서 검증된)’ 코드와 도구를 쓰려고 함. 농담은 차치하고, Anthropic이 자기네 생성 AI를 자기 코드에 실용적으로 쓰는 방식은 흥미로움. 앞으로 MCP 인증 API에도 사용할지 궁금함
          + “수십만 개의 테스트”란 건 양적 성장일 수밖에 없거나, outright LLM이 만든 거 아닐까 의심됨. 실제로 그걸 누가 관리하는지도 궁금함
     * 사람들이 자신의 프롬프트를 git에 커밋하는 추세가 일반화될지, 아니면 그냥 showcase 성격인지 궁금함
          + 내가 프롬프트를 커밋한 이유는, LLM이 그런 프롬프트로 어떤 결과를 만들어내는지 직접 확인하는 게 너무 큰 인사이트였기 때문임. 다른 사람들도 흥미롭게 볼 거라 생각했고 실제로 그랬음. 참고로, 나도 프롬프트를 ‘잘’ 쓰는 방법은 몰랐고, 그냥 내가 인간 상대로 쓸 때처럼 자연스럽게 적었는데 잘 작동한 느낌임
"
"https://news.hada.io/topic?id=21392","성공한 사람들은 목표를 쫓지 않음; "한계를 설정"함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     성공한 사람들은 목표를 쫓지 않음; ""한계를 설정""함

     * 목표 추구에만 집착하다 보면, 스스로 선택하지 않은 게임을 이기기 위해 달려가는 함정에 빠질 수 있음
     * 실제로 제약(Constraints) 을 두고 그 안에서 일할 때, 일의 본질이 더 명확해지고 창의성도 극대화됨
     * 목표는 구체적 결과에 집착하는 경향이 있지만, 제약은 과정과 정체성에 집중하게 만들어 줌
     * 위대한 창의성, 혁신, 지속적인 성장 등은 ‘목표’보다는 자기만의 규칙과 한계 설정에서 출발함
     * 잘 정의된 목표는 유용할 수 있지만, 불확실하거나 복잡한 문제를 만났을 때는 제약이 훨씬 더 유연하고 효과적임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

목표의 한계와 제약(Constraints)의 힘

     * 목표는 외부로부터 주어진 것일 때 본질적 의미를 잃기 쉽고, 진짜 원하는 삶이나 방향성과는 어긋날 수 있음
     * 1953년 Yale 목표 설정 신화는 근거 없는 허구였지만, 목표의 중요성을 믿게 만드는 위안으로 수십 년간 반복됨
          + 목표를 적은 사람들이 더 성공했다는 유명한 에피소드지만, 실제로는 존재하지 않았던 이야기
     * 많은 혁신적 인물들은 명확한 목표 대신, 자신만의 제약과 규칙 속에서 의미와 창의성을 발견함

목표(Goals) vs. 제약(Constraints)

     * 목표는 '승리 조건' 이지만 제약은 '게임의 규칙'
     * John Boyd의 OODA 루프, Richard Feynman의 자기 제한적 탐구 등은 엄격한 한계 내에서 오히려 창의성이 폭발한 사례
     * 시, 음악, 건축 등 여러 분야에서 제약이 창의성의 방향을 잡아줌 — 빈 캔버스보다 제약 있는 환경에서 더 쉽게 시작 가능

목표의 유혹과 맹점

     * 목표를 설정하면 진짜 행동하지 않아도 진전된 것처럼 느끼는 위안과 자기기만이 따르기 쉬움
     * 실제 원하는 바가 불확실할 때, 목표는 그저 방향의 대리자가 되곤 함
     * WWII에서 Abraham Wald가 지적한 것처럼, 보이는 구멍(목표)보다 보이지 않는 구멍(한계)이 더 중요할 수 있음

제약(Constraints)의 나침반 역할

     * NASA의 달 착륙 프로젝트도 엄청난 제약(예산, 무게, 시간, 열 등) 덕분에 혁신적 해법이 등장
     * 제약은 문제 해결에 비선형적 창의성, 두 번째 사고(Second-order thinking) 를 촉진
     * “여기서 무엇이 가능한가?”라는 질문을 이끌어내, 결과가 아니라 지속 가능성에 집중하게 만듦

제약이 확장성을 갖는 이유

     * 목표는 특정 시점(T)의 예측에 기반해 불확실한 미래에 '베팅'하는 성격이 강함
     * 반면 제약은 상황 변화에 적응하고, 피드백에 따라 유연하게 조정됨
     * 예시: “PMF 달성 전까지 채용하지 않는다”, “10대에게 60초 만에 설명 가능한 것만 만든다”와 같은 제약은 불필요한 예측 대신 현명한 필터 역할

반(反)목표 심리와 거부의 힘

     * 진심으로 원치 않는 목표는 내면적 저항과 자기파괴적 행동(프로크래스티네이션)을 유발
     * “나를 소진시키는 클라이언트는 받지 않는다”와 같은 거부의 선언도 강력한 자기 보호선
     * Stoic(스토아) 철학도 '하지 말 것'의 제약을 반복해서 상기시킴

제약 지향적 커리어

     * ""베스트셀러 작가가 되겠다""는 목표 대신, ""매일 쓰지만, 지루한 글은 쓰지 않는다""는 제약이 장기적으로 더 창의적이고 지속 가능한 성공으로 이어짐
     * Fernand Braudel의 역사론처럼, 제약은 수십 년 단위로 삶의 구조를 형성함

목표가 필요한 순간

     * 마라톤 완주, 시험 준비, 데드라인이 명확한 프로젝트 등 유한하고 명확한 영역에서는 목표 설정이 효과적임
     * 하지만 커리어 전환, 창업, 이직 등 복잡하고 불확실한 문제에는 제약이 더 현실적이고 안전한 나침반 역할

결론

     * John Boyd의 질문처럼 “누가 될 것인가(목표)”가 아닌, “무엇을 할 것인가(제약)”가 성장의 기반
     * 목표는 이미지, 제약은 정체성에 가깝고, 더 큰 확장성을 제공
     * ""나는 신뢰하지 않는 사람에게 돈을 받지 않는다"", ""내가 쓰지 않을 서비스는 만들지 않는다"", ""가면을 써야 하는 팀에서는 일하지 않는다"" — 이런 제약 선언이 실질적 변화와 방향성을 만들어 줌

        Hacker News 의견

     * HN에서 “촌철살인 지혜 콘텐츠”만 모아보는 버튼이 필요하단 생각임. 겉으로 듣기 좋은 말을 늘어놓는 기사들이 인기 있지만, 대부분은 저자의 개인 경험에 가까운 잡담 수준임. 특히 NASA의 사례를 이해할 수 없었음. 달 착륙 목표를 실현시킨 건 빡센 제약이 아니라, 명확하고 절박한 목표 하에 엄청난 자원을 투입한 것임. 실은 “인류 탐험”보다 “소련보다 앞서기”가 더 컸던 상황임
          + 만약 Apollo 13 사고가 Apollo 8 때 달 뒷편에서 일어났다면, 그 결과로 Apollo 9, 10, 11의 미션이 10년 내로 달성되지 못했을 거란 시나리오도 궁금함. 원인을 알았다면 달랐을까? 소련이 실험 실패한 채로도 아폴로 8을 앞지르지 못하게 중앙위원회가 막은 건 맞는 결정이었을까? 운도 실력이라는 말 있는데, 우주비행사들의 운이 좋았기에 shuttle이 불리한 조건에서 발사된 것 같은 정치적 판단도 탄생함
          + 그래서 Hacker News가 좋음. 문장만 보면 솔깃해서 “그래, 이것도 의미 있다”고 착각하지만, 댓글에서 현실 감각을 얻음
          + 요즘 HN 메인에 올라오는 블로그 글들은 거의 다 공허함. 딱 사람들 좋아할 만한 곡예·감성 지혜 혹은, 초보가 찾아낸 사소한 기술 트릭 같은 게 대부분임. 그러나 진짜 핵심은 자극적인 제목, 즉 유튜브 썸네일 같은 한방 효과임. 클릭을 멈출 수 없는 구조임. crowd의 지혜라지만 실제론 혼란과 현혹의 합침, 메인 페이지는 쓸모없는 컨텐츠 범벅임
          + 제약이 없으면 애매한 정치적 이유와 방향성 없는 해법만 남음. 제약이 너무 많아도 방법이 사라지고, 너무 없으면 쓸데없는 논쟁만 남음. 중요한 건 적당히 탐색의 자유를 주면서도 잡다한 선택지를 제한해주는, 최적의 제약 찾기임
          + 글에서 “일화만 있을 뿐이다”란 비판에 대해, 인생 조언에서 진짜 가치 있는 대부분도 사실상 ‘일화’임. “연구 기반”이니 “과학적”이니 하는 소리도 오히려 최신 유행 혹은 사짜 같을 때가 많음
     * 나는 글쓴이 의견에 동의하지만, 목표와 제약 위에 더 근본적인 값(value)이 있다고 생각함. 여러 선택지 중 우선순위를 명확히 해주는 내적 기준임. “장기적으로 즐거움을 주는 건 뭘까”, “세상을 더 낫게 하는 건 뭘까”, “더 예수 같은 사람이 될 수 있는 선택은 뭘까” 같은 질문들이 내게는 자신만의 값임. 제약은 선택지를 없애지만, 값은 선택을 쉽게 해줌. 값, 목표, 제약은 위계 구조임. 값에 부합하게 제약을 만들고, 주어진 제약 내에서 단기 목표를 세우면 유지가 쉬움. 참고로, Benjamin Franklin의 “Thirteen Virtues”는 이런 값과 제약을 혼합한 리스트임 https://fs.blog/the-thirteen-virtues/
          + “값, 목표, 제약 모두 중요하지만 위계가 있다. 제약을 값에 맞게 정해야 한다”는 말이 정말 와닿았음. 나도 내 값 찾기가 어려웠는데, 내 부고문을 써봤음 https://www.jjude.com/my-obituary/. 16년 전 썼지만 2020년에 공개함. 그 이후 올바른 삶의 방향성 찾는 데 도움이 됨. 대저택이나 스포츠카 대신, 주3일 일하고 두 아이를 홈스쿨링하며 가족과 식사·운동, 교회 봉사도 같이 함. 꾸준히 내 삶이 꿈 같다는 만족감 느낌
          + 13가지 덕목 공유 고마움. 조금 어렵게 느껴질 수 있어, 더 친근하게 요약해봄:
               o 절제: 과식·폭음 자제
               o 침묵: 의미 있을 때만 말하기, 잡담·가십 피하기
               o 정돈: 정리정돈과 시간관리
               o 결단: 할 일 정하고 끝까지 실행
               o 검소: 꼭 가치있는 곳에만 돈 쓰기
               o 근면: 시간 효율적 사용, 방해요소 제거
               o 성실: 솔직하고 선의로 진실하게 대하기
               o 정의: 남 해치지 않기, 책임 다하기
               o 중용: 치우치지않고 분노·원한 버리기
               o 청결: 위생과 주변 정돈
               o 침착: 사소한 일에 흔들리지 않기
               o 정숙: 건강한 관계와 자기 존중
               o 겸손: 경청하며 배우기
          + “더 예수 같은 사람이 되려면 뭐가 필요할까” 질문에, 시대에 맞는 대패, 나무망치, 큐빗 자 같은 목공도구임
          + Marie Kondo도 비슷한 철학으로 업계를 세움. “기쁨 주지 않는 물건은 버려라” 원칙이 대표적임
     * “항상 옵션을 열어둔다”는 사람과 자주 언쟁 벌임. 사실 그건 제약을 두지 않겠다는 선택임. 결과적으로 보통은 미적지근한 결과만 남김. Paul Graham이 인생에서 도시 선택이 가장 중요한 결정 중 하나라고 했는데, 사실 이건 커다란 자기 제약임. 도시·결혼·종교·SaaS 사업의 VC vs 부트스트랩 선택 등이 대표적인 ‘큰 제약’임. VC를 선택하면 고속성장을 요구받고, 부트스트랩은 성장 한계가 존재함. 글에서 특히 좋아하는 대목은 “목표는 게임을 위한 것, 제약은 세상을 위한 것”임. 여기에 “성공한 사람은 세상을 항해, 아이들은 게임을 한다”고 덧붙이고 싶음. 많은 사람들이 실제로는 40대가 되어서도 게임 마인드셋에 머무는데(커리어 쌓기 같은 치밀한 목표 중심), 결국 세상의 복잡함이 이런 게임을 모두 무너뜨림. 그러면 ‘중년의 위기’가 찾아옴
          + “삶에서 결정적인 순간은 도시 선택”이라는 말이 오히려 내겐 역효과였음. 어릴 때 Bay Area에 오고 싶어서 정말 옮겼는데, 막상 가보니 자연, 맛집, 놀거리 등이 너무 많아 원래 동기였던 기술에 대한 흥미가 금방 사라짐. 흥미없는 도시로 다시 돌아가니 오히려 수학이나 컴퓨터 과학 공부에 자유시간을 쏟게 됨. 비슷한 현상을 자녀 양육에서도 느낌. 아이 없을 땐 시간 여유가 많았지만, 오히려 허비 했음. 이제는 시간이 귀해지자 새벽 4시에 일어나 공부하고 창작함. 결국 조건이 이상적이면 동기와 집중력을 잃고, 제약과 불편이 오히려 본능적으로 가치를 만들게 함
          + 전략적 관점(군사학, 게임이론)에서 볼 때, 가능한 옵션을 넓혀두는 게 거의 항상 이득임. 핵심은, “실행에서의 과감한 선택” 즉, 실행 단계에서는 가장 유망한 선택지에 확실히 베팅해야 함. 하지만 다른 옵션들은 폐기하는 게 아니라 전략적 백로그에 두었다가, 시장 변화나 인생 이벤트처럼 커다란 갈림길이 올 때 다시 고려하는 게 중요함. 이렇게 하면 제약의 힘도 누리고, 대안 부재의 취약성도 막을 수 있음
          + “성공한 사람은 세상을 항해, 아이는 게임만 한다”는 주장은 약간 오만해 보임. 나는 목표와 제약이 서로 다른 도구일 뿐, 모두 쓸모 있다고 생각함
          + 결혼, 종교, VC와 부트스트랩 사업 비교는 확실히 웃음이 남. 이 중 하나는 결이 너무 다름
          + 도시 선택이 항상 본인의 자유로 가능한 건 아님. 예를 들어, 내 모든 자산 처분하고 영주권 신청하면 샌프란시스코 갈 수도 있겠지만, 태어난 곳과 성장환경이 이미 큰 제약임
     * 나는 목표 대신 시간박스를 더 선호함. “이 정해진 과업을 달성한다”보다 “나는 이 시간 동안 이런 행동만 해보겠다”식으로 제한함. 직접 행동만 제어할 수 있음을 집중할 수 있음. 물론 그 시간조차 계획대로 안 지켜지는 경우도 많음. 그 자체로 유효한 결과임. 나는 환경, 상황, 타인 행동, 결과 등 통제 못 함. 노력과 결과가 분리되어, 노력이 기대 결과로 연결되지 않아도 동기 상실이 없음. 즉, 노력 자체가 중요 포인트로 남음
          + 알고보면 시간박스도 일종의 ‘시간 제약’임
     * 글에서 목표 vs 제약 대비가 과하게 단순화되어 있음. 어차피 아무것도 안 할 때는 계획도 없고, 계획만 하면 실천이 없는 법임. 하지만 “목표를 세우면 뭔가 한 것처럼 느끼지만 실제로는 변화가 없음”이란 구절엔 공감 감. Notion, 스프레드시트, 생산성 카페 등 만들면서 뿌듯해하면서 정작 본질적 행동은 좀처럼 이루어지지 않음
          + 글의 핵심은 인생 목표나 야망을 말함. 마라톤, 시험, 런칭 같은 제한적 과업은 목표 설정이 유효함. 하지만 진로 결정, 창업, 이사, 미디어 사업처럼 애매한 영역에서는, 목표는 정글에 Sharpie로 지도 그리기 같음. 진짜 필요한 건, 제약이라는 “마체테”. “누군가가 되고 싶은가, 무언가를 하고 싶은가”, 목표는 전자, 제약은 후자. 첫 번째는 이미지, 두 번째는 정체성. 마지막이 더 성장 여지가 많음. 더 좋은 글이 될 수도 있겠지만, 요지는 괜찮음
          + 비즈니스/투자 세계에서는 이걸 '분석마비'라 부름. 준비만 하다 보면 기회비용까지 놓치게 됨. 불확실한 상태로 바로 행동하는 게 보통 장기적으로 더 나음. 예를 들어, 3개월 동안 최고의 바이오 기업 종목만 고르려 애쓰는 것보다, 그냥 재무상태 긍정적인 회사 아무거나 빠르게 투자했다면 이미 시장 수익을 얻었을 수 있음
          + Oliver Burkeman의 'Four Thousand Weeks'를 연상케 하는 말임. 행복에 대한 책이지만 겉보기엔 생산성에 관한 책임. 강추임
     * 글이 재밌긴 했지만, 동의 안 되거나 걸리는 부분도 있음을 느낌. 예를 들어 모든 성공한 사람이 똑같이 한다는 전제로 일반화하며, 목표와 제약의 정의도 결국 애매함. “모두를 더 좋게 만들고 떠나라”는 목표 같기도 하고, “누구도 더 나쁘게 두지 말라”는 제약 같기도 함. 사실상 똑같은 규칙임. 마지막으로, 증거 대신 해석된 일화만 제시하는데, 더 근거와 명확성이 필요하다고 생각함. 그래도 스타일과 창의성은 칭찬감임
          + 목표와 제약의 차이: 나는 목표가 명확히 끝내거나 달성할 수 있는 것, 제약은 평생 끌고 가는 것이라 생각함. 예를 들어 마라톤 완주 목표는 성공·실패 측정이 가능하지만, 제약은 끝이 없음. 사실 이 글은 ‘목표 대 습관’ 같음. “매일 더 좋은 사람이 된다”는 제약은 평생 습관처럼 지키는 것이고, 목표라면 언제 끝나는지 구체성을 가져야 함. 나에겐 제약이 정체성을 제공해 매일매일 자신을 안내해주는 역할. 특히 일이나 인생에서 정체성 부족이 고민이라면, 목표보다 이러한 제약이 유용함
     * 난 늘 목표 설정이 어려워서 죄책감 느낀 적 많음. 즉흥적으로 상황에 맞춰 임기응변함. 어릴 적도 경쟁심이 별로 없었음. 스포츠나 보드게임도 그냥 참가하는 정도였음. 다른 아이들은 경쟁에 불탔지만, 난 그냥 흐름을 따랐음. “승리”가 삶의 본질 같지 않았음. “승리하려고 애쓰는 게 아니라, 아예 새로운 게임판을 직접 만드는 게 진정한 진보다”라는 글 한 줄이 충격임. 그게 내 삶의 포인트였던 것 같음
          + 나도 비슷함. 결혼, 자녀, 커리어, 내 집, 목표금액 등, 세속적 목표에 체크해가며 행복을 찾으려 하는 주위와 달리, 나는 목표 달성감은 없지만 대신 맘대로 자유와 도전을 추구함. 내 인생은 한 번뿐, 짜여진 규칙의 박스에 얌전히 갇혀있는 건 아까움. 늘 새로운 환경이나 룰을 바꿔가며, 헤도니즘의 쳇바퀴를 피하면서 참여 동기 자체를 유지함
          + 나도 늘 비슷하게 생각함. 게임에서 “이기는 게” 뭐가 중요한지 모르겠음. 경쟁 자체에 집착하는 사람들이 있는데, 그건 누군가 만든 인위적 규칙일 뿐임. 남의 ‘보상 체계’에 나를 맞추는 훈련임. 이런 경쟁형 인간은 나이 들어서도 결국 돈만 남고, 그걸로 뭘 할지 잘 모르는 것 같음
     * ‘제약’이 오히려 쓸데없는 잡음을 없애주는 데 가장 유용했음. 예를 들어 운동 루틴에 완벽을 추구하는 대신 “30분 이상 운동은 금지” 한 가지 규칙만 정하니 진짜 꾸준히 할 수 있었음. 거대한 목표, 완벽한 시스템은 노력하다 지치기 쉬운데, 내겐 작은 제약 하나가 훨씬 실효성 있었음
     * 난 과감히 말해보겠음. 성공한 사람들은 정말 다양한 방법으로, 다양한 삶을 살아감. 확실한 건, “성공하는 법” 블로그 글을 즐겨 읽으며 시간 보내는 타입은 아닐 것 같음
     * 글이 조금 모순적인 느낌임.
       “제약은 지식에 의존하지 않고, 적응하고 피드백에 반응한다. 팀이 ‘product-market fit이 전엔 채용 안 한다’는 룰을 세워도 지식 기반이고, 목표 없이 제약만 있진 않음. 어떤 제약도 금전적 목표 등 본래 목적을 위해 존재하며, ‘10대에게 60초 내 설명’도 필터로 쓸 뿐 특정 목표가 뒤에 깔려 있음. 사실 제약도, 목표도 철저히 유저를 위한 도구임. 의미 없는 제약은 목표 달성에 도움 안 됨. 나처럼 남의 멋진 목표를 흉내내다 보면 때로는 공허하고, 나중에 되돌아보니 내 인생에서 좋았던 스토리는 특정 제약 또는 규칙을 세웠을 때였음. 제약을 익히려면 먼저 목표부터 연습하라는 조언처럼, ‘걸음마 후 달리기’가 자연스러움

   다행스럽게도 해커뉴스의 첫 번째 댓글이 좋네요ㅎㅎ 요새 해커 뉴스에 올라오는 글들은 정말 하나같이 그럴싸해 보이기만 하는 뻘글에 가까워지는 것 같습니다. 글을 통해 자기합리화, 안도감만 느끼게 할 뿐입니다. 헛소리/개소리가 너무 많은 세상 같아요.
"
"https://news.hada.io/topic?id=21426","macOS Tahoe, 새로운 디스크 이미지 포맷 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     macOS Tahoe, 새로운 디스크 이미지 포맷 도입

     * macOS 26 Tahoe에서 ASIF 디스크 이미지 포맷이 새롭게 도입되어, 기존 포맷 대비 거의 네이티브 속도의 파일 전송 성능을 제공함
     * ASIF는 가상화 환경에서 이전 대안의 성능 한계를 극복하며, 일반 디스크 이미지 용도로도 활용 가능함
     * 현재는 Disk Utility 또는 diskutil 명령어를 통해서만 이미지 생성 가능하며, macOS Sequoia에서는 생성 기능이 없음
     * 실제 테스트 결과, 읽기와 쓰기 속도가 5~8 GB/s 수준으로, 기존 디스크 이미지나 sparse bundle 방식보다 뛰어난 속도를 보임
     * 단, 구버전 macOS와의 호환성 문제가 존재할 수 있으므로 도입 시 주의 필요함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * macOS 26 Tahoe에 새롭게 추가된 ASIF 디스크 이미지 포맷은 기존의 느린 디스크 이미지 포맷을 대체하며, 최신 Apple Silicon 기반 Mac에서도 SSD에 가까운 빠른 파일 쓰기 및 읽기 성능을 보장함
     * 기존의 암호화된 sparse 이미지(UDSP)는 빠른 SSD에서도 100 MB/s에 불과한 느린 성능 문제를 보였음

주요 기술적 특성

     * ASIF 디스크 이미지는 호스트 파일 시스템의 기능에 의존하지 않고, 실제 저장되는 데이터 크기만큼만 공간을 차지하는 APFS의 sparse 파일로 동작함
     * 생성 방법은 현재 Tahoe의 Disk Utility 및 diskutil 명령어에 한정됨
          + 예시 명령어: diskutil image create blank --format ASIF --size 100G --volumeName myVolume imagePath
          + 기존 디스크 이미지 변환 또한 지원함
     * Sequoia 15.5 이하 버전에서는 해당 포맷의 생성이 지원되지 않음
     * 생성 시 UTI 타입은 com.apple.disk-image-sparse로 구분되며, 기존 RAW(UDIF read-write)는 com.apple.disk-image-udif임

공간 효율성

     * 100GB 크기의 ASIF 이미지 생성 시 초기 디스크 사용량이 1GB 미만으로 매우 경제적임
     * 두 번째 볼륨 추가 및 광범위 사용 후 비어있을 때 이미지 용량은 1.9~3.2GB 범위였음
     * hdiutil을 통한 용량 축소(컴팩트)는 지원 여부가 불확실함

성능

     * Stibium 도구로 2TB SSD에서 160개 파일(총 50GB, 2MB~2GB 크기) 대상으로 성능 측정
          + 100GB ASIF 이미지에서, 비암호화 APFS 기준 읽기 5.8GB/s, 쓰기 6.6GB/s
          + 암호화 APFS 볼륨에서는 각각 4.8GB/s, 4.6GB/s 기록
     * 압축을 통해 다른 Mac(Mac mini M4 Pro, macOS 15.5)에서 시험 시에도 비슷한 고성능 확인(읽기 5.5GB/s, 쓰기 8.3GB/s)

활용 및 호환성

     * Apple은 VM 백업 볼륨에 기존 RAW(UDIF read-write) 대신 ASIF 활용을 권장함
     * VM 생성 단계에서 ASIF 이미지 생성이 적용될 예정이지만, 현재는 diskutil 명령 도구로만 가능함
     * Sequoia 15.5 버전에서는 ASIF 사용 지원은 확인되나, 기존 macOS와의 완벽한 호환성은 미공개임

성능 비교 및 장점

     * 이전 테스트에서 sparse bundle이 가장 빠른 포맷이었으나, ASIF는 모든 기존 대안(plain/암호화 UDRW, UDSP, sparse bundle) 대비 월등히 빠름
     * ASIF는 백업 파일이 단일 파일로 관리되어 관리면에서도 뛰어나며, 성능 우위도 확실함

결론 및 권장점

     * macOS 26 Tahoe 환경에서는 VM 및 일반 디스크 이미지 모두 ASIF 포맷 우선 사용이 바람직함
     * NAS 등 별도 파일시스템에 sparse bundle이 필요한 경우가 아니라면, ASIF가 일반 목적에 최적임
     * 장기적으로 더 직관적인 API 호출 방식 제공이 요구됨
     * 주요 디스크 이미지 관리 도구(DropDMG 등)에서도 곧 ASIF 지원 예정임

   ""Microsoft는 최근 연구 결과를 점점 오픈소스로 공개하는데 불신이 많음. 반면 Apple은 늘 비밀스럽고 폐쇄적이면서도 해커 커뮤니티에선 여전히 사랑받는 점이 이해 안 됨""

   어느 정도는 동감하지만 이유가 있는 일이죠. 마이크로소프트는 말과 행동이 다를 때가 너무 많아요. 통수를 맞는다고 해야 하나.
   소속 개발자들과 경영진들의 방향이 전혀 다른 느낌. 잘 진행되던 것이 윗선의 그건 이제 안 되겠는데 한 마디에 툭 하고 끊기는 느낌.
   애플도 깨끗한 척 뒤에선 돈 냄새만 쫓아다니는 것은 비슷하지만 줏대없는 모습은 아직까지 덜 보여줬죠.

   그래도 마이크로소프트가 요즘 오픈소스 쪽으로 보여주려고 하는 것은 좋은 일이라고 생각합니다.

   그런데 HN의 곁다리 의견들이 재미있네요. 특히 요약과 문장에 대시를 넣는 것이 LLM으로 생성한 글처럼 느껴진다는 부분이요.
   저도 대시를 보자마자 읽기도 전에 피로를 느꼈던 경험이 있어서 뜨끔했습니다.

        Hacker News 의견

     * Apple에서 새롭게 선보인 ASIF는 qcow2와 유사한 자체 디스크 이미지 포맷이라는 추측
     * ""Asif""라는 디스크 포맷 이름이 재밌는 이유는 실제 디스크인 척하는(as-if) 의미 때문이라는 농담
          + Andor라는 TV 프로그램 이름도 웃긴다는 언급
     * 기사 전체를 훑어봤는데 궁금한 점이 있음. NAS(리눅스)에서 만든 sparse 디스크 이미지를 macOS APFS 파일 시스템 포맷 그대로 백업에 사용 중. 새로운 ASIF 포맷으로 macOS Tahoe에서 더 빠르고 좋아질 수 있는지, NAS에 이미지를 저장할 때 문제가 없을지 궁금증
     * 벤치마크 결과가 이상한데, ASIF는 M3/4에서 테스트하고 다른 포맷은 M1에서 테스트한 점이 혼란스러움
     * Apple이 새로운 제품, 데이터 포맷, 케이블, CPU 같은 걸 내놓으면서도 공개 문서가 거의 없거나 부족한 점이 아쉬움. 해커들이 이를 빠르게 리버스 엔지니어링하지만 불필요한 노력이라고 생각. Microsoft는 최근 연구 결과를 점점 오픈소스로 공개하는데 불신이 많음. 반면 Apple은 늘 비밀스럽고 폐쇄적이면서도 해커 커뮤니티에선 여전히 사랑받는 점이 이해 안 됨
     * 이 새로운 포맷이 Docker for Mac 같은 VM 기반 소프트웨어의 속도를 올릴 수 있을지 궁금증. 주요 불만사항을 해결해줄 수 있을 것 같다는 기대
     * 문서화된 디스크 이미지 포맷을 간절히 원함
          + 내가 찾은 유일하게 제대로 문서화된 포맷은 qcow2임 (qcow2 공식 문서). 하지만 가장 적합한 도구는 아닌 경우가 많음. 대부분의 포맷은 헤더만 있고, 특정 도구에서만 작동하는 폐쇄적인 구조
          + 여러 디스크 이미지 포맷을 추천: ISO 9660(링크), VMDK(링크), Amiga(링크), UDF(링크), Apple Disk Image(링크)
          + ext4에 대한 공식 문서도 소개(ext4 파일 시스템 문서)
     * 이번 포맷이 HFS+에서 APFS로 마이그레이션을 위한 것이라기보다는 가상화(VM)에 더 초점을 맞춘 기술임을 듣고 반가움
          + 둘은 완전히 다른 영역임을 설명. ASIF 이미지 안에 APFS 볼륨 생성도 가능하다는 점 강조
     * APFS sparsebundle을 NAS에 저장하고 NFS로 마운트해서 로컬 볼륨처럼 사용할 수 있다는 점이 신기했던 경험 공유. 성능은 좀 떨어지지만, 네트워크 스토리지에서 APFS를 사용할 땐 iSCSI보다 더 좋은 선택 같다는 의견. 새로운 포맷은 더 좋은 퍼포먼스를 기대하게 만듦
          + 사실 Time Capsule도 네트워크에 sparsebundle을 마운트하는 방식이라 놀랄 일은 아니지만, 새로운 포맷의 성능도 더 좋을 듯한 추정
     * 새로운 포맷의 사양(스펙)을 찾은 사람이 있는지 궁금증 표시
"
"https://news.hada.io/topic?id=21306","죽음의 뉴트가 처한 불가능한 딜레마","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          죽음의 뉴트가 처한 불가능한 딜레마

     * Rough-Skinned Newt(Taricha granulosa) 는 세계에서 가장 독성이 강한 뉴트 종으로, 미국 퍼시픽 노스웨스트 지역에 서식함
     * 이 뉴트와 garter snake(Thamnophis sirtalis) 사이에는 독성을 둘러싼 진화적 군비 경쟁이 존재함
     * 뉴트의 극단적인 독성은 테트로도톡신에 대한 뱀의 저항성과 맞물려 진화했으며, 양쪽 모두 대가를 치르고 있음
     * garter snake는 이 독을 간에 저장해서 자신을 먹는 포식자에게도 유독해지는 전략을 사용함
     * 이 상호작용의 세부 내용과 예외 상황은 아직 연구 중이며, 다양한 미스터리가 남아있는 상태임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

죽음의 뉴트의 독성 원인

     * 세계에서 가장 독성이 강한 뉴트인 Taricha granulosa(러프스킨 뉴트) 는 북미 퍼시픽 노스웨스트 해안 지역에 분포함
     * 한 마리에서 나올 수 있는 독은 여러 명의 성인 인간을 치명적으로 할 수 있는 수준임
     * 뉴트는 독성은 갖고 있지만, 맹독성(venomous)은 아님. 즉, 물거나 쏘지 않으며, 접촉만 하고 손을 아주 깨끗하게 씻으면 안전함

뉴트의 극단적 독성, 그 이유

     * 많은 뉴트가 독성을 가지지만, Taricha granulosa만 유난히 독성이 강한 근본 원인은 군비 경쟁(arms race) 에서 기인함
     * 이 지역의 garter snake(Thamnophis sirtalis) 는 테트로도톡신(blue-ringed octopus의 독과 동일 성분)에 대한 저항성을 진화시키고 있고, 뉴트는 점점 더 강한 독성을 진화시켜 옴
     * 테트로도톡신은 뉴트 피부에 서식하는 공생 세균이 생산함
     * 뱀의 저항성이 커질수록 뉴트의 독성도 같이 커지고, 이 과정이 피드백 루프로 지속됨

독성과 저항성의 대가

     * 자연계의 모든 것은 비용이 따르며, 뉴트는 독성을 높이는 대가로 더 많은 세균을 유지하기 위해 대사 부담 증가를 감수해야 함
     * 더 독성이 강한 뉴트는 더 많은 칼로리를 필요로 하며, 이는 생존에 불리하게 작용함
     * 반대로 뱀의 테트로도톡신 저항성도 비용이 있음. 저항성 확보를 위한 신경계 생화학적 변형이 *** 신경학적 기능 장애, 반사능 저하, 미세한 행동 변화 등*** 여러 형태로 나타날 수 있음
     * 퍼시픽 노스웨스트 외부 지역의 garter snake는 저항성이 약해 치명적으로 당함. 즉, 저항성 진화에는 분명한 비용이 존재함

garter snake가 독성 뉴트를 먹는 이유

     * 저항성 진화도 힘들고, 뉴트를 먹을 때 뱀이 가려움, 구토, 불편감을 겪지만, 뱀들은 계속해서 뉴트를 먹음
     * 이유: garter snake는 뉴트를 먹고 테트로도톡신을 간에 축적함으로써 포식자로부터 자신을 보호함. 그러나 자체적으로 독을 만들지는 못하고, 시간이 지나면 독성이 사라져 다시 뉴트를 먹어야 함

군비 경쟁의 진화적 악순환

     * 독성이 약한 뉴트는 먹혀버리고, 저항성이 약한 뱀도 뉴트 포식을 못해 독을 축적 못 함
     * 뉴트는 aposematic(경고색) 무늬를 못 진화시킴. 눈에 띄게 되면 뱀에 더 많이 먹히기 때문임
     * 독성은 계속 높아지고, 뱀의 저항성도 같이 올라가는 식의 끝없는 진화적 딜레마가 지속 중임

다양한 예외와 추가 미스터리

     * 알래스카처럼 garter snake가 없는 지역의 뉴트는 대부분 홉독성이 약하나, 일부는 여전히 강함
     * 밴쿠버 아일랜드처럼 뱀이 여럿 있는데도 독성과 저항성 군비 경쟁이 덜한 지역도 존재함
     * 뉴트만이 아니라 garter snake 자체가 aposematic(경고색) 무늬로 진화할 수 있는가에 대한 의문도 있음. 그러나 외형 변화에 대한 학계 연구는 부족함
     * 퍼시픽 노스웨스트 생태계 자체도 지질학적으로 매우 젊은 편이라, 현재의 군비 경쟁이 영구적인 현상인지 불확실함
     * Taricha속의 다른 뉴트들도 상당 독성이며, Thamnophis속의 분류도 복잡함

맺음말

     * 이 군비 경쟁과 진화적 딜레마는 많은 논문의 연구 대상이며, 아직 명확히 풀리지 않은 미스터리가 많음
     * 죽음의 뉴트 사례는 상호 진화, 생태적 상호작용, 진화적 비용이라는 주제의 살아있는 실험실로서, 미래 연구의 여지가 많음

        Hacker News 의견

     * 텍스트로 보면 저항력을 진화시키는 데에 언제나 비용이 든다는 주장이 있지만, 꼭 그렇다고 보긴 힘들다는 생각임. 많은 동물들에겐 이 형질을 진화시키거나 유지할 특별한 압력이 없기 때문임. 자연선택은 어떤 체크리스트를 가지고 있는 게 아니라, 오직 번식에 유리한 무언가가 있으면 그게 살아남는 구조임. 예를 들면, 소는 테트로도톡신 중독으로 많이 죽지 않기 때문에 굳이 그 저항력을 진화시킬 필요성 자체가 없음. 인간만 비타민 C를 합성 못하는데, 이 형질도 조상 원숭이가 우연히 잃었고, 과일 많은 환경에 살아서 굳이 다시 되찾을 필요가 없었기 때문임. 아마 뱀도 테트로도톡신 저항성에 비용이 따를 수도 있지만, 꼭 그런 건 아니라는 점 강조함
          + 작가의 주장을 반대로 생각해 보면, 쓸 일이 거의 없는 독소 저항성 같은 형질도 우리는 그냥 가지고 있는 경우가 많고, 이런 건 부담이 거의 없으니까 유지되는 것이라 추측 가능함. 만약 테트로도톡신 저항성이 이렇게 유지비용이 적은 형질이었다면 더 널리 퍼졌을 테지만, 그렇지 않은 걸 보면 비용이 높거나 최소한 싸지는 않다는 추정 가능성 언급함
          + 유전적 문제 해결 공간이라는 측면에서 비용이라는 개념도 있음. 어떤 제약이 하나 줄면 나머지 진화 압력에 더 쉽게 적응하는 구조 가능성 이야기함
          + 진화는 공급과 수요, 비용과 이득, 가능성과 제약의 문제로, 결국 운에 좌우되는 구조라는 점 강조함
          + 테트로도톡신 중독으로 죽는 동물과 사람 숫자가 0은 아니니까 어느 정도는 선택 압력이 존재함. 만약 저항성이 싸고 쉽게 진화될 수 있는 형질이었다면 모두가 진화시켰을 가능성도 있기 때문에, 저항성의 비용 임계점이 아주 높을 수도 있다는 추측임
          + 생물학 지식이 많지 않아도 진화를 인과관계만으로 설명하려는 시각은 답답함
     * 최근 알게 된 사실이 있는데, 미국의 많은 정원에 치명적인 식물이 존재해서, 10분 이상 그 밑에 서 있으면 거의 죽게 된다는 이야기임. 그 식물은 바로 water-lily임
          + 위키피디아에서 보니, vascular cambia(식물의 부피성장 세포)는 5가지 식물 계통에서 독립적으로 사라졌고, 그 중 네 개는 수생식물(water-lily 포함), monocot도 수생 환경에서 진화한 게 아닐까 하는 과학자 의견 있음. 수생식물들은 구조적 안정성을 위한 목질 성장 자체가 필요 없다는 이론 기억나지만, 자료 출처는 못 찾음
          + water-lily는 위험한 식물이 아니고, 일부는 먹을 수도 있고 약재로 사용되기도 함. peace lilly나 calla lilly를 말하는 것인지? 둘 다 치명적이진 않지만 먹으면 아플 수 있음. 치명적인 것은 water hemlock인데, 하얀 꽃을 가짐
     * 글 내용이 흥미롭게 쓰여 있어서, 몇 가지 질문이 생김: 독이 약한 newt는 먹히고, 저항성이 적은 snake는 먹잇감 확보에 실패. 이런식으로 arms race가 계속되는 구조임. 여기서 궁금한 건, snake는 어떻게 newt의 독성 정도를 아는지, 일부 newt만 건드리지 않고 남기는지 혹은 만나는 모든 newt를 먹는 건지, 독한 newt는 결국 공격에서 살아남는지에 대한 의문임
          + 좀 더 적절한 프레임은, 오랜 시간 동안 snake 유전자에 이 특정 newt를 먹으려는 기호성, 그리고 poison을 저장할 수 있는 저항성이 들어있다는 것. 이 두 유전자가 결합된 snake가 좀 더 효과적으로 번식할 가능성 생김. 수천년간 이런 적응의 반복이 일어나면서 snake와 newt가 서로 달리기 경주하듯 계속 맞물리게 되는 red queen 상황이 형성됨. 여기에는 의사결정이나 의식이 관여하는 게 아니라, 내장된 행동 패턴만 따르는 구조임
          + 기사 내 다른 부분에 언급된 바로는, snake가 독이 너무 강할 경우 newt를 뱉어내는 행동을 함. 마치 사람이 매운 고추를 뱉는 것과 비슷한 맥락임
          + 위키피디아에 따르면, garter snake는 실제로 newt를 일부 삼키면서 독성 수준을 '맛보는' 식으로 판단함. 삼킬 만하면 먹고, 아니라면 뱉어버림
          + 문맥을 보면 garter snake는 먹잇감을 통째로 삼키기 때문에, 강한 독성의 newt는 consumption 시도에서 살아남을 수 있음. 이 때문에 newt는 계속 더 강한 독을 진화시키고, snake도 점점 저항성을 높임. 결국 arms race가 반복됨
     * 제목이 정말 마음에 들었고, 기사도 훌륭함. 약간 딴 얘기지만, 매번 'newt'라는 단어를 볼 때마다 Karel Capek이 1920년대에 'robot'이라는 단어를 최초로 만들고, 그 다음에 War with the Newts라는 똑똑한 양서류 이야기까지 써낸 게 떠오름. 공유해줘서 고마움
          + 프랑스인으로서 이 단어를 처음 봤는데, 브레인에서는 제목이 'death news'로 자동 번역되는 느낌임
     * ""알고 보니 garter snake는 tetrodotoxin을 간에 저장함으로써 자기보다 더 큰 포식자에게도 독성을 가지게 됨""이라는 부분, 이런 2차 효과가 너무 흥미로운 포인트임
     * blue-ringed octopus에 대한 링크된 기사가 더 흥미롭다는 이야기임
          + 저자는 종종 우리가 거대한 로봇이며, 세균들이 우리를 숙주 삼아 움직이며 진화한다는 관점을 언급함. 이 사유에 공감함
          + 자연이라는 존재는 결코 친절하지 않음
     * snake의 면역성도 현지 caddisfly에 비하면 미약하다는 관련 링크 소개함
     * 이 지역에서 평생 살았지만 newt에 의한 중독 사고를 들어본 적이 없어서, 인간의 newt 중독은 매우 드문 일임을 언급함
          + 어릴 적 숲과 하천에서 these newts를 이리저리 만졌던 추억 있음. 그만큼 흔했음
          + 나는 PNW에 살고 hundreds of garter snake와 some newt는 자주 보지만, Rough-Skinned Newt는 보지 못했음. 이런 생물이 주변에 있었다는 사실을 몰랐음
     * ""알고 보니 garter snake는 tetrodotoxin을 간에 저장함으로써 포식자에게도 독성이 있다""는 설명이, newt의 피부에 독을 두는 즉각적 방어 방식만큼 효과적인지 의문임. newt는 포식자가 물고 뱉어서 살아남는 경우가 있지만, snake는 간을 먹는 순간 포식자가 죽기 때문에 deter 역할이 덜 명확함. 특히 일부 snake만 면역이라면, 포식자 입장에서 먹어도 되는 snake와 위험한 snake를 구별하기가 어려움
          + 어떻게 포식자를 막을 수 있을까라는 질문에 대한 내 생각은, 죽은 포식자와 반쯤 먹힌 snake 사체가 주는 학습 효과가 있을 수도 있고, 어쩌면 한 마리 predator라도 제거하면 종의 이득 구조 가능성도 있음
          + 포식자 종 내 약간의 차이, 즉 먹잇감 선택 성격이 유전된다면 아주 작은 차이라도 자연선택이 작동 가능함
          + snake를 먹어도 포식자가 바로 죽지 않을 수도 있고, 포유류 같은 상위 포식자에겐 음식 선호도가 있어 뱀을 안 먹는 개체들이 살아남게 되어 그게 유전적, 혹은 부모가 새끼에게 뱀 포획을 안 가르치는 학습 형태로도 굳혀지게 되는 구조임
     * ""teal deer""라는 표현을 보고 처음엔 이상한 관용어인 줄 알았음. Urban Dictionary에서 찾아보니 ""teal dear = tl;dr""이라는 사실을 알게 됨. 이제 마치 엄청난 tetrodotoxin에 내성을 얻은 가터스네이크처럼 어리둥절한 기분임
          + 나도 처음엔 못 알아봤는데, 이제 문자 5개 대신 9개로 쿨하게 보이려고 하는 현실이 좀 슬픔. 음절 수는 줄었지만, www 같은 웹 접두사는 오히려 더 길어져서 비효율적임. 독일어에선 3음절이라 괜찮지만 영어/프랑스어에선 9음절이라 아쉬움. 처음부터 web.domain.org가 나았을지도 모름
          + 덕분에 teal dear라는 표현을 간접적으로 알게 됨
          + 나는 처음에 ""steel-man""에 대한 말장난인 줄 알았음. 근데 아니었고, 일단 조사해줘서 고마움
"
"https://news.hada.io/topic?id=21338","워싱턴 포스트의 개인정보 보호 팁: Chrome 사용 중단 및 Meta, Yandex 앱 삭제 권고","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        워싱턴 포스트의 개인정보 보호 팁: Chrome 사용 중단 및 Meta, Yandex 앱 삭제 권고

     * 워싱턴 포스트 기술 칼럼니스트가 Meta와 Yandex가 Android의 보안 보호 기능을 우회해 수개월간 사용자 데이터를 수집한 사실을 보도함
     * 어떤 설정도 데이터 수집을 막을 수 없었다는 점이 연구진에 의해 밝혀짐
     * Chrome 브라우저는 사이트 간 추적 방식 대부분을 막지 못해 개인정보 보호 측면에서 취약함
     * Meta 및 Yandex 앱은 휴대폰에 설치할 경우 더 많은 민감 정보 접근이 가능해짐
     * Meta 앱이 없더라도 웹 전체에서 Meta에 의해 사용자 활동이 추적될 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

   워싱턴 포스트의 기술 칼럼니스트는 Meta(Facebook, Instagram) 와 Yandex가 Android 기기의 보안·개인정보 보호 장치를 우회해 장기간 사용자 데이터를 몰래 수집한 사실을 지적함. 해당 연구에 따르면, 어떤 설정을 해도 데이터 수집을 완전히 막을 수 없으며, 이 두 기업은 Google이 Android용으로 마련한 보호 조치도 우회함.

Chrome 브라우저 활용 시 개인정보 취약점

     * 연구 결과, Chrome 브라우저는 사이트 간 추적을 차단하지 못하는 경우가 많아 개인 식별 가능 정보의 유출 위험이 있음
     * Mozilla Firefox, Brave, DuckDuckGo 브라우저 등은 다수의 추적 방식을 강력히 차단하며, Safari 역시 전반적으로 강력한 보호 기능을 제공함
     * 다만, 어떠한 브라우저도 완벽한 보안을 제공하지 못하고, Firefox 역시 Android에서는 해당 데이터 수집에 일부 노출됨
     * DuckDuckGo 및 Brave는 문제의 데이터 수집 프로세스 대부분을 차단하는 것으로 조사됨

Meta 및 Yandex 앱 삭제 권장

     * Meta 및 Yandex 앱(휴대폰용 앱)이 설치되어 있다면 삭제를 권장함
     * 해당 앱들은 웹사이트보다 훨씬 더 폭넓은 수준의 민감 정보(대략 위치, 배터리 잔량, 가정용 WiFi에 연결된 기타 기기 정보 포함)에 접근할 수 있음
     * 이러한 정보 접근은 사용자에게 원하지 않는 추가 노출 및 사생활 침해 위험을 의미함

앱을 설치하지 않아도 추적 위험 존재

     * Facebook, Instagram 등의 Meta 계열 앱을 쓰지 않고 설치하지 않아도, 여전히 Meta는 웹 전반에 걸쳐 사용자의 행동 정보를 수집할 수 있음
     * 웹사이트에 내장된 추적 픽셀이나 기타 식별 방식 등을 통해 사용자 활동이 수집될 수 있음

결론 및 사용자의 대응 방안

     * 브라우저 보안 기능만으로는 개인정보 보호가 완전하지 못하다는 현실과, 일부 앱이 의도치 않은 정보 접근에 악용될 위험성을 강조함
     * Chrome 대신 Brave 등 개인정보 보호 중심 브라우저 사용, Meta·Yandex 앱 삭제, 웹 내 추적 최소화가 권장되는 실질적 대응 방안임

        Hacker News 의견

     * 광고 차단기 설치 제안이 빠진 정보 제공은 신뢰성을 가질 수 없는 의견
          + 광고 수익에 의존하는 미디어라면 광고 차단기 설치를 권장하지 않을 가능성이 높다는 생각, 그러나 이런 침해적인 제품을 과감히 포기하는 것이 광고 차단기 여부와 무관하게 좋은 선택이라는 주장, 특히 Meta와 Yandex와 관련된 사건은 악성코드 수준이라는 평가, 모두가 이들의 앱을 삭제해야 한다는 목소리
          + 정보 제공이 완벽하진 않지만 기본적인 조언으로 나쁘지 않다는 의견, 평범한 사용자들에겐 이 정도가 시작점이라는 판단, 일단 이런 기본부터 시작해 광고 차단기 등 추가적인 내용을 자연스럽게 익힐 수 있다는 생각, 참고로 ArsTechnica 기사에 더 많은 조언이 정리되어 있음 기사 보기
          + FBI에서도 광고 차단기 사용을 권장한다는 팩트 제공 관련글
          + 자기를 먹여 살려 주는 쪽 손을 물지 않으려는 모습에 대한 비판, 하지만 사람들이 다른 브라우저로 이동하도록 유도하는 부분은 긍정적으로 봄, 브라우저를 바꾸는 것만 해도 큰 변화라고 생각, 브라우저만 바꿔도 가장 인기 많은 익스텐션 설치는 아주 쉽다는 분석, 참고로 인기 1위 익스텐션이 무엇인지 생각해보라는 농담성 의견
          + 광고 차단기가 개인정보 유출을 막는지에 대한 질문, 타겟 광고에 대한 정보 수집은 차단하지만 외부 소스는 언제나 잠재적 유출 지점이라는 판단, CORS(Cross-Origin Resource Sharing)가 이런 부분을 줄이기 위한 기술임을 언급, 광고 차단기가 오히려 유출을 더 많이 만드는지 궁금함, 혹은 수집 유인을 줄여서 정보 수집 자체를 낮추는 방식인지 궁금한 태도
     * 원문 기사 링크 공유 기사 보기
          + slashdot 기사에서 출처도 msn을 링크하는 상황이라고 언급, 직접 출처를 확인할 수 있다는 점이 더 좋다는 태도
     * 이번 트릭이 알려지면 나머지 앱들은 어떨지에 대한 우려, 시스템 webview를 포함해 완전히 수정하지 않는 한 플레이스토어에 널린 스파이웨어류 앱들이 모두 이 방식을 악용해 사용자 추적을 시도할 것이라는 전망, 구글은 앱이 사용자의 설치 앱 전체 목록을 권한 없이 확인할 수 있는 문제를 수개월 전 제보받고도 전혀 대응하지 않았다는 문제 제기, 구글이 사용자의 프라이버시에는 전혀 관심이 없다고 믿는 입장, 이런 상황에선 아이폰, grapheneos, 아니면 아무 스마트폰도 사용하지 않는 게 낫다는 격론
     * 이번 공격 방법을 잘 이해하지 못하겠다는 의견, Washington Post 기사에서 “Millions of websites contain a string of computer code from Meta that compiles your web activity. It might capture the income you report to the government, your application for a student loan and your online shopping.”라는 문구를 근거로, 메타가 HTTPS 웹 콘텐츠 전체를 평문으로 보고 업로드한다는 뜻이면 엄청난 수준이라고 놀람, 자신이 이해하기로는 방문한 사이트만 추적하는 수준이지, 페이지의 모든 데이터를 보는 건 아닌 줄 알았다는 혼란
          + 이번 공격이 same-origin policy(동일 출처 정책)까지 깨는 거라면 정말 거대한 보안 취약점이라고 지적, Meta가 다른 사이트와 협력해 사용자 데이터를 공유하는 시나리오 정도는 가능성 있다고 보지만, IRS(국세청)와 협력 없이 세금 데이터를 몰래 훔쳐본다는 건 현실적으로 힘들 것으로 판단, Intuit나 H&R Block 같은 업체가 Meta와 데이터 공유를 한다는 우려라면 심각한 프라이버시 침해고 택스 데이터는 특히 불법 소지도 있다고 분석
     * 회사에서 Chrome을 강제로 쓰게 할 때 이걸 세금적으로 활용할 수 있는지 고민, 컨트랙터로 Chrome과 모바일을 강제로 써야 한다면 별도의 워크폰을 공제받을 수 있는지 궁금, iPhone에 두 개 다 넣기 싫다는 불편함 토로, 어쨌든 이런 식으로라도 뭔가를 돌려받고 싶다는 솔직한 마음
          + 개인과 업무용 기기는 철저히 분리하는 게 좋은 습관이라는 입장, 나중에 소송이나 디스커버리 상황에서 기기를 넘겨줘야 할 수도 있다는 현실적인 조언, 그런 상황을 겪으면 누구나 같은 결론에 이를 것이라는 경고
     * 30개월 전 기사지만 구글 관련 온라인 트래커의 양은 개선되지 않았을 거라는 짐작 참고 기사
     * 자신은 Zen Browser(FF)와 Windows, Firefox(iOS)로 동기화해서 잘 쓰는 중, M365 관련 업무는 Edge, 웹 개발에는 계속 Chrome 사용 중, 다만 웹 개발용으로 Chrome에서 뭘로 옮겨야 할지 고민
          + 새내기 웹 개발자로서 Firefox의 웹 개발자 도구에 매우 만족, Chrome의 개발자 도구가 Firefox와 비교해 어떤 점이 더 좋은지 궁금, CSS 실시간 편집, 덮어쓰는 CSS rule 위치 확인, JS 디버깅 등 주요 기능 다 된다는 점에 의문
     * 최근 Chrome에서 PDF를 바로 다운로드할 수 없다는 문제 겪음, Firefox에서만 가능했던 경험, Chrome에선 드라이브(클라우드)에만 저장이 됐음
          + 본인은 오늘 오전 최신 Chrome에서 PDF를 아무 문제 없이 다운로드했음, 독특한 셋업이라면 그걸 점검해 보는 게 좋겠다는 조언
          + Chrome에서 PDF에 우클릭 후 저장(Save As) 눌러서 저장할 수 있다는 상황을 덧붙임
          + 본인은 반대 문제, PDF를 그냥 렌더해서 읽고 싶은데 다운로드만 되도록 바뀐 것이 아쉽다는 불만
          + 프린트(인쇄) 버튼을 찾아봤는지 물어봄
     * WhatsApp 앱을 설치하지 않고 사용하는 팁을 물어봄
          + WA(WhatsApp) 연락처에 대체 연락 방법을 안내하고 앱을 삭제하는 방식을 제안, 그러면 WhatsApp 사용 중단 가능
          + telegram을 사용하는 대안도 함께 제시
     * Alexa도 사용 중단할 것을 제안, 물론 베조스의 신문에서 이런 주장은 나오지 않을 것이라고 농담식 언급
"
"https://news.hada.io/topic?id=21303","프로그래머를 위한 프롬프트 엔지니어링 플레이북","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       프로그래머를 위한 프롬프트 엔지니어링 플레이북

     * AI 코딩 도우미는 개발자의 생산성을 높여주지만, 그 결과물의 품질은 프롬프트 엔지니어링에 크게 달려있음
     * 효과적인 결과를 얻으려면 풍부한 맥락, 구체적 목표, 예시, 역할 부여, 반복적 개선 등의 규칙을 지켜야 함
     * 디버깅, 리팩토링, 신규 기능 구현 등 주요 개발 작업별로 프롬프트 설계 패턴과 예시를 제공함
     * 좋은 프롬프트는 목적, 언어, 환경, 오류 메시지, 입력/출력 예시 등 구체 정보를 담아야 함
     * 신규 엔지니어도 따라 할 수 있는 프롬프트 설계법으로, 실제 AI 응답 비교와 코멘트가 포함됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요: 성공적인 프롬프트 엔지니어링의 중요성

     * 최근 개발자들은 AI 코딩 어시스턴트를 사용해 함수 자동완성, 버그 수정, 전체 모듈 작성까지 작업 흐름을 가속화함
     * 그러나 AI의 응답 품질은 프롬프트 품질에 결정적으로 좌우됨
     * 좋은 프롬프트는 명확하고 창의적인 코드 솔루션을 유도하지만, 모호하거나 부실한 프롬프트는 제한적이고 무의미한 답변으로 이어짐
     * 본 플레이북은 일상적인 개발 작업에 적용할 수 있는 효과적인 프롬프트 설계법을 실용적으로 정리함

효과적인 코드 프롬프트의 기본 원칙

     * 풍부한 맥락 제공: AI는 프로젝트나 의도를 사전에 알지 못하므로, 사용 언어·프레임워크·라이브러리·에러 메시지·코드 목적 등 모든 관련 정보를 명시함
     * 명확한 목표나 질문 제시: “왜 코드가 안 돼?”와 같은 모호한 질의 대신, 원하는 결과와 현재 상황을 명확하게 기술함
     * 복잡한 작업 분할: 대규모 기능 개발 등은 한 번에 모두 요청하지 않고, 작은 단계로 쪼개어 점진적으로 요구함
     * 입출력 예시나 기대 동작 포함: 실제 입력·출력이나 동작 예시를 주면 AI의 이해도가 크게 높아짐(“few-shot prompting”)
     * 역할(페르소나) 활용: “React 시니어 개발자처럼 코드 검토” “성능 전문 지도로 최적화 요청” 등 책임 있는 역할을 부여해 AI의 응답 수준을 끌어올림
     * 회화적 반복 개선: AI의 첫 번째 답변을 바탕으로 추가 요청이나 수정 요구를 통해 점진적으로 원하는 결과에 도달함
     * 코드 일관성 유지: AI가 코드 스타일, 네이밍, 주석을 참고하므로 코드의 일관성과 명확성을 항상 유지함

디버깅을 위한 프롬프트 패턴

  체계적 디버깅 프롬프트 설계법

     * 문제 및 증상 명확 서술: 언어, 기능 목적, 기대 동작과 실제 에러 메시지, 코드 스니펫 등 풍부한 정보 제공
     * 단계별·라인별 분석 요청: 논리 오류나 미묘한 버그는 “한 줄씩 변수 추적”이나 부분 코드 설명을 통해 원인을 파악하게 함
     * 최소 재현 코드 활용: 복잡한 대규모 코드 대신, 에러가 발생하는 최소 단위의 코드를 추출해 문제를 집중적으로 진단함
     * 직접적 질문 및 후속 요청: “어디서 버그가 발생하는가?”, “수정된 코드 제공” 등 명확하고 반복 가능한 피드백 요청

  예시: 잘못된 프롬프트 vs. 개선된 프롬프트

    문제 코드 예시

function mapUsersById(users) {
  const userMap = {};
  for (let i = 0; i <= users.length; i++) {
    const user = users[i];
    userMap[user.id] = user;
  }
  return userMap;
}
const result = mapUsersById([{ id: 1, name: ""Alice"" }]);

    잘못된 프롬프트:

   “왜 mapUsersById 함수가 동작하지 않을까?”
     * AI의 응답: “배열이 비었거나 user에 id가 없을 수도 있다” 등 모호한 추측 제시
     * 문맥 부족과 불분명성으로 인한 일반적인 조언만 나옴

    개선된 프롬프트:

   “mapUsersById 함수가 사용자 배열을 id별로 매핑해야 하는데, [ {id: 1, name: ""Alice""} ] 입력 시 TypeError: Cannot read property 'id' of undefined 에러 발생. 코드는 다음과 같다: [코드 포함] 기대 결과는 { ""1"": ... } 이런 현상 원인과 해결책은?”
     * AI의 응답: 반복문의 조건 (i <= users.length)이 범위를 초과해 마지막 반복에서 undefined가 발생하는 것을 짚어줌, i < users.length로 수정 제안
     * 구체적 맥락, 오류 메시지, 기대 동작 제공으로 정확한 해결책 도출

  추가 디버깅 프롬프트 전략

     * 버그 원인 후보 목록화 요청(“TypeError의 가능한 원인?” 등)
     * 코드 동작 논리 직접 설명 후 검토 요청(“내 설명이 맞는지, 문제점을 찾아달라”)
     * 돌발 상황 테스트케이스 요청(“이 함수가 실패할 수 있는 입력 2개만 제안”)
     * 꼼꼼한 코드 리뷰어 역할 부여(“이 코드를 리뷰하며 문제점과 개선사항을 설명”)

리팩토링/최적화를 위한 프롬프트 패턴

  명확한 개선 목표 제시

     * “리팩토링 하라”는 모호하므로, 가독성, 성능, 유지관리성, 코드 중복 제거 등 구체 목표를 명시
     * 코드 전체(또는 필요한 맥락)와 환경, 언어, 프레임워크 버전을 충분히 제공
     * 변경 사항에 대한 설명도 요청(“코드와 개선 포인트를 함께 알려줘”)
     * “타입스크립트 전문가로서 최신 관례에 맞게” 등 역할 부여로 기대 품질 상향

  예시: 리팩토링 프롬프트 비교

    원본 코드

   (중복 fetch, 효율 낮은 자료 구조 등 문제 포함)
async function getCombinedData(apiClient) {
  // Fetch list of users
  const usersResponse = await apiClient.fetch('/users');
  if (!usersResponse.ok) {
    throw new Error('Failed to fetch users');
  }
  // ... (이하 생략)
}

    모호한 프롬프트

   “getCombinedData 함수를 리팩토링 하라”
     * AI가 임의로 병렬 fetch, 에러 메시지 통합 등 변경(요구 사항이 없으므로 행동이 예측 불가)

    구체적 목표 명시 프롬프트

   “중복 제거, 성능 개선, 두 fetch 병렬화, 에러 메세지 분리, 데이터 결합은 효율적 방식으로 개선하라. 주석과 개선 포인트 설명까지”
     * AI의 응답: 병렬 fetch, 에러 구분, 효율적 map 자료구조 도입 등 명확히 목표를 반영한 리팩토링 및 상세 설명 제공

  추가 리팩토링 팁

     * 단계별 요청(“가독성 개선→알고리듬 최적화” 순차 적용)
     * 다른 접근 방식 요청(“함수형 스타일로도 구현해줘” 등)
     * 코드+설명 방식 요청을 통한 학습과 튜토리얼화
     * 결과 코드에 대한 테스트 추가 요청

신규 기능 구현 프롬프트 패턴

  단계별 코드 생성 유도

     * 고수준 설명(어떤 기능을 만들고 싶은지)을 먼저 제시, 이후 단계적으로 세분화
     * 기존 유사 코드, 프로젝트 패턴, 사용 라이브러리 등 작업 환경 맥락 전달
     * 주석이나 TODO를 프롬프트로 활용해 IDE에서 직접 AI의 코딩 흐름 유도
     * 입력/출력 예시나 테스트 케이스를 제공해 명확한 결과 기대치 부여
     * 첫 결과가 미흡하다면, 바로 구체적 개선점 또는 코드 스타일을 추가 명시해 반복 요청

  예시: React ProductList 컴포넌트 생성

   “ProductList라는 React 함수형 컴포넌트를 만들어라. /api/products에서 상품 배열을 가져와 리스트로 출력하고, 입력창에서 상품명을 입력하면 대소문자 구분 없이 필터링함. 가져오는 과정의 로딩, 에러 처리도 필요.”
     * AI 응답: useState, useEffect로 데이터 fetch, 입력 처리, 필터링, 에러·로딩 UI 구현 등 포함
     * 만약 프로젝트에서 커스텀 훅을 활용한다면 “useProducts() 훅을 사용하도록 리팩토링하라” 식으로 추가 지시 반복 가능

  실무적 프롬프트 고도화 사례

     * “정렬 기능을 추가해라: A-Z, Z-A 드롭다운이 있어야 함” 등 점진적 기능 확장 요청 가능
     * 구현 코드 흐름을 단계별 쪼개어, 각 단계별로 프롬프트를 달리해 코드 품질과 일관성 유지

결론

     * AI 코딩 어시스턴트의 잠재력을 최대한 활용하려면, 프롬프트 설계가 핵심 역량임
     * 성공적인 프롬프트를 작성하려면 항상 구체적 맥락, 목적, 예시, 반복적 피드백, 역할 부여를 염두에 두어야 효과적인 결과 도출 가능
     * AI를 프로젝트 내의 신입 개발자 혹은 코드 리뷰어로 여겨, 원하는 방향으로 상세히 안내하고 점진적으로 퀄리티를 높이는 것이 성공의 비결임

        Hacker News 의견

     * 제 경험으로 보면 진짜 프롬프트 엔지니어링 기법은 세 가지뿐이라는 생각임
          + In Context Learning(문맥 안에서 예시 제공, 즉 one shot이나 few shot 방식과 zero shot 대비)
          + Chain of Thought(단계별로 생각하게 지시)
          + Structured output(예를 들어 JSON처럼 출력 형식을 명확히 지정)
            여기에 이 글에서 언급하는 Role Prompting도 추가할 수 있을 듯
            RAG는 모델이 제공된 문맥을 요약하는 방식이라 따로 분류
            결국 나머지는 원하는 것을 명확하고 평이한 언어로 요청하는 방법 요약
          + 프롬프트에선 문맥이 가장 중요한 요소임
            예를 들어 Typescript로 시작해서 데이터 사이언스 질문을 하면 제대로 대답 못하는 현상 확인
            Python으로 똑같이 질문하면 훨씬 잘 나옴
            LLM은 아직 도메인 간 지식 이전이 힘들기 때문에 반드시 목적에 맞는 문맥 설정 중요
          + Role prompting도 개인적으로 의미 없는 방식이라고 생각
            GPT-3에선 그랬을지 몰라도 대부분의 LLM은 이미 ""전문가"" 역할을 알고 있음
            ""프롬프트 엔지니어링""에 과몰입하는 건 스스로를 속이는 행동이라 생각
            요구사항을 명확히 전달하고 필요하다면 예시 추가, 결과물이나 reasoning trace 확인, 원하는 결과가 안 나오면 조정해서 다시 시도하는 식
            몇 번 시도해도 답이 안 나오면 AI 말고 내 머리로 reasoning 해보는 선택
          + 많은 이들이 ""한 번에 모든 걸 한 프롬프트에 넣으려고"" 하는 시도가 문제라는 의견
            오히려 거대한 요청 한 번에 넣지 말고, 작은 컨텍스트로 나눈 여러 개의 프롬프트로 쪼개고 각기 명확한 구조화된 출력을 서로 연결하는 방법 제안
            프롬프트 하나하나씩 목적과 예시에 집중, 컨텍스트 오버로드 피하기
            그러면 위에서 언급한 3가지 핵심 방법이 자연스럽게 적용
          + 3번째 방식(Structured output)과 관련해 저와 동료들이 과학 분야에서 적용 사례 연구
            논문 링크
          + 참고로 저희 팀은 prompt engineering보단 fine tuning에 더 많이 의존
            few-shot prompt 방식이 저희 케이스엔 효과가 없었음
     * 저는 프롬프트가 너무 길거나 복잡해지면 오히려 모델의 인지 성능이 떨어지는 느낌을 자주 받음
       복잡한 프롬프트가 컨트롤하는 느낌을 줄 수는 있지만, 실제로는 꼭 이점이 아닐 수도 있음
       그래서 사용 패턴이 아주 단순하고 미니멀한 프롬프트로 대충 맞추고, 몇 번 반복 수정하는 방향으로 자연스럽게 수렴
          + 저도 완전히 같은 방식으로 접근하기 시작한 경험
              1. 꼭 필요한 컨텍스트와 전제사항, 목표만 간략하게 전달
              2. 답변을 확인하고 초기 프롬프트 수정
                 이런 방식이 비용 효율에도 좋음
                 agent를 썼다가 $30씩 태우고 코드베이스 엉키거나 원래 코드대로 돌아가는 경험이 너무 많았음
                 또 AI가 내 프로젝트에 코드 많이 쓰게 두면, 나중에 그 코드가 내 머리에 잘 안 남고 관리도 어려워진다는 점 경고하고 싶음
          + 전문가의 용어를 사용해서 프롬프트를 입력하면 성능이 더 좋다는 근거도 있음
            일반적으로 사람들이 일상 언어로 이야기하는 환경은 정확도가 떨어지지만, 특정 전문 분야의 어휘는 더 신뢰성 높은 답으로 연결
            트레이닝 데이터도 이런 분포를 반영
          + 저도 비슷한 경험
            그런데 agent 시스템 프롬프트를 보면 엄청 길고 복잡한 경우 많아서 의문 생김
            실제 그런 프롬프트가 어떻게 동작하는지 궁금
            시스템 프롬프트 예시 링크
          + 어떤 작업에서는 제 동료가 아주 장황한 프롬프트를 썼음
            통합 과정에서 CRUD operation 추가하고, 실험 삼아 ""이걸 <직군> 입장에서 분석"" 정도로 정말 짧게 바꿔봄
            결과적으로 양쪽 결과가 거의 비슷했고, 오히려 긴 프롬프트는 일부 문장을 그대로 출력에 다시 쓰는 현상
            결과 자체는 괜찮았으나 결국 모델(gemini 2.5)은 중요한 정보만 뽑아 보고, 나머지 불필요한 부분까지 결과에 녹여버림
            즉, 적어도 이 과제에서는 장황함이 모델의 ""사고 방식""에 흥미로운 영향을 주진 못한다는 느낌
          + 저도 같은 결론에 도달했지만, AI 연구소에서 제공하는 긴 프롬프트 사용 예시를 어떻게 해석해야 할지 궁금
            Anthropic 시스템 프롬프트 예시
     * ""프롬프트 엔지니어링""이라는 건 따로 존재하지 않는다는 생각
       언제부터 제대로 의미 있는 문장을 쓴다고 엔지니어링이 됐는지 의문
       ""소프트웨어 엔지니어링""보다 더한 일이라 생각
       다만 앞으로 이런 것도 직업(프롬프트 엔지니어)으로 뜨고, 문장 쓰는 특별한 능력으로 자리 잡을 가능성은 안타까운 점
          + 사실 ""제대로 의미 있는 문장""은 수많은 변수에 따라 달라지는 문제
            실제로는 테스트, 관리, 로깅, 버전 관리까지 포함하면 단순 감각이 아닌 엔지니어링이 되는 것
            특정 순서/스타일/문제 재진술 등 구조화 아주 중요
            파라미터가 많은 패밀리 모델 다루는 경우, API 기반 모델은 버전업마다 기존 프롬프트와 호환체크 필요
            이런 체크와 테스트도 프롬프트 엔지니어링 과정
            유행/하이프에 반감하는 태도에 치우치다 본질 간과하는 경우 많다는 의견
          + 우리 동네 바리스타가 자기 이름에 커피 엔지니어 붙이면 차라리 믿음이 갈 법
          + 알고리즘 중독으로 요즘 소비자들은 문장 다 읽는 능력조차 쇠퇴한 영향
          + “프롬프트 엔지니어” 구인 걱정까진 할 필요 없다고 봄
          + AI sloperators는 자기 일을 있어 보이게 만드려 기를 씀
     * 제 경험상 LLM이 못 푸는 문제는 아무리 프롬프트 ""엔지니어링"" 해도 소용 없는 경우 많음
       오히려 부분 문제로 쪼갠 뒤 조금씩 진행하게 두는 방법밖에 없음
       반대 경험하신 분 있으면 사례 듣고 싶음
          + LLM 사용의 중요한 부분은 문제를 적절히 어떻게 쪼갤지 감을 잡는 것
            언제 어떻게 쪼갤지, 언제 그냥 맡길지 감별 능력 필요
            기사에서도 언급했다시피 이런 노하우 중요
            앞으로 코드를 더 뛰어나게 조직화/주석 처리해서 LLM과 상호작용을 개선하는 방법도 많아질 것
            LLM 자체도 점점 이런 방향에서 진화하고, 문제 쪼개는 방법 제안까지 할 수 있을 거로 기대
          + 프롬프트 엔지니어링의 목적은 원하는 형식으로, 더 빠르게 좋은 해답을 얻기 위함
            궁극적으로는 모델이 알아서 답해주길 바라지만, 현실적으론 질문 자체도 최적화 필요
     * 프롬프트 작성 시 평소 습관 때문에 자연어로 지시하는 게 여전히 어색하게 느껴짐
       뭔가 정확한 인자나 SQL 쿼리처럼 써야 할 것 같은 느낌
       채팅하듯이 툴에 말하듯이 지시하는 것도 신기함
       그래도 자연어 지시를 이해하는 툴이 된 건 접근성을 극적으로 높였다고 봄
       그런데도 여전히 사람에게 말하는 것처럼 프롬프트를 쓰는 내 모습이 좀 우습게 느껴짐
     * 요즘 프롬프트 가이드 같은 게 엄청 많음
       근데 실제론 별로 필요 없다는 생각
       직접 툴을 써보고 친숙해지고 사용법을 익히면, 어떤 프롬프트가 좋은지 자연스럽게 알게 됨
          + 예전 Google이 유행하고 FOMO 열풍 있었던 시절과 비슷
            관련 책을 안 사면 원시인처럼 뒤처진다고 했는데, 실제로는 하루만에 다 습득할 수 있는 간단한 분야라 복잡하게 고민할 필요 없음
          + 가이드나 팁 영상이 정말 도움이 되는 사람도 분명 있음
            많은 이들은 스스로 개선할 의지가 없지만, 한 번쯤 가이드나 고수의 영상을 보는 것만으로도 실력 상승
            저 역시 타인의 사용법이나 커뮤니티 경험에서 팁을 매번 배우는 편
            단지 혼자 연습한다고 이런 팁을 얻는 건 한계가 있음
          + 예전에 “유저 스토리 작성 가이드”처럼 “As a [role], I want to [task] so I can [objective]” 공식이 있었음
            고수나 초보할 것 없이 대부분이 분명한 요구사항 전달에 도움 필요
            아무리 뛰어난 개발자도 비구조적 요구사항에는 실수하거나 오해 가능
          + 남들이 이 툴로 어떻게 생산성 내는지도 참고가 꽤 됨
            내가 놓쳤던 아이디어도 발견
            트라이/에러로 직접 다 해보기 전에 이미 누가 해둔 경험을 조금이라도 배우는 게 더 효율적
            개인적으로 모든 걸 직접 해볼 시간 없는 입장에선, 이런 경험 공유는 정말 고마운 정보
          + 눈에 잘 띄지 않는 트릭도 분명히 있음
            예를 들면, 프롬프트에서 “please” 같은 예의 표현은 다 빼도 된다는 경험
     * 한참 전 컴공 대학원 때 프로그래밍 과학(Science of programming) 과목에서 배운 검증 과정을 데이터 엔지니어링 프롬프트 작성에 잘 응용
       예를 들어 “input(…)과 전제(…)를 주고 post-condition(…)이 만족하는 spark 코드를 작성하게 요청”
       입력, 전제, 결과조건을 명확하게 명시하면 좋은 코드 출력 가능
       참고 교재
         1. Science of programming, David Gries
         2. Verification of concurrent and sequential systems
     * 프롬프트 엔지니어링에 너무 열내는 건 과한 느낌
       그냥 코드나 에러를 복사 붙여넣고 plain question 날리면 요즘 모델들은 대부분 알아서 잘 처리
       지나치게 꼬아서 쓸 필요 못 느낌
     * 며칠 전 Sergey Brin이 AI 커뮤니티에서 자주 언급되지 않는 사실이라며 “물리적 위협을 하면 모델 성능이 더 좋아진다”고 말함
       관련 기사
          + 유튜브 “Programmers are also human”에서 프로 vibe 코더가 LLM 명령 끝에 항상 “.. 아니면 감옥 간다”라는 농담 떠올림
          + 그래서 Google이 ""Don't Be Evil""을 슬쩍 버린 건가 싶음
     * 프롬프트 작성을 ""엔지니어링""이라고 부르는 건 엄청 진지하지 못하다는 느낌
          + 예전에 프롬프트 ""엔지니어링"" 유행할 때 들은 재밌는 비유가 있음

     프롬프트 엔지니어를 Subway 샌드위치 가게 직원이 ""샌드위치 아티스트""라고 부르는 거랑 똑같음
     농담은 농담이고, 엔지니어라는 말은 이미 너무 광범위하게 쓰이다 보니 별 의미 없어짐
     Sandwich Artist info 링크
          + 결국 이 논란은 소프트웨어 엔지니어링 얘기 나올 때마다 반복
          + 상상력이 그냥 채팅 인터페이스에서 고양이 사진 요청하는 수준에 멈춰서 그러는 걸지도
            실제론 API와 자동화 워크플로우에 쓰이는 프롬프트도 있어서, 그 이상임
          + 미국엔 ""sales engineer""라는 직함도 있는데, 제 경험상 이 사람들은 자기가 파는 제품이 어떻게 동작하는지 전혀 모르는 경우 많음
          + IT는 단어와 그 의미들이 사라지는 곳
            단어가 원래 의미를 가질 필요가 있냐는 생각이 들 정도
"
"https://news.hada.io/topic?id=21385","OpenAI, o3 가격 80% 인하 & o3-pro 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    OpenAI, o3 가격 80% 인하 & o3-pro 출시

    1. OpenAI가 추론 스택 최적화를 통해 o3 모델 가격을 80% 인하하여, 입력 토큰 100만 개당 $2, 출력 토큰 100만 개당 $8로 조정했습니다.
    2. o3 모델은 코딩, 함수 호출, 명령 수행 작업에 추천되며, GPT-4.1과 같은 가격이면서 GPT-4o보다는 더 저렴합니다.
    3. 더 높은 수준의 연산을 지원하는 신규 모델 o3-pro가 출시되었으며, 가격은 87% 낮아져 입력 토큰 100만 개당 $20, 출력 토큰 100만 개당 $80입니다. 이미지, 함수 호출, 구조화된 출력을 지원합니다.
"
"https://news.hada.io/topic?id=21411","생리 추적 앱 데이터는 광고주에게 금광이며 여성 안전에 위협이 됨","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  생리 추적 앱 데이터는 광고주에게 금광이며 여성 안전에 위협이 됨

     * 생리 주기 추적 앱이 사용자 개인 정보를 대규모로 수집하며, 상업적인 소비자 프로파일링에 적극적으로 활용됨
     * 이 데이터는 법적 보호가 미비한 상황에서 보험 차별, 직장 감시, 사이버 스토킹, 임신 중단 권리 제한 등 여성 안전에 심각한 위험을 제공함
     * 사용자들은 자신의 가치 있는 데이터가 기업의 이윤 창출 수단으로 활용된다는 점을 충분히 인식하지 못하는 실정임
     * 연구진은 공공기관 주도 앱 개발과 명확한 동의 절차 요구, 그리고 디지털 리터러시 교육 강화의 필요성을 지적함
     * 영국, 미국 등에서 일부 데이터는 특별 보호를 받지만 현실적으로 데이터 오남용과 사생활 침해가 지속적으로 발생함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

주요 내용 및 배경

   스마트폰 기반 생리 주기 추적 앱(CTA) 은 사용자의 운동, 식사, 약물 복용, 성적 선호, 호르몬 수치, 피임 방법 등 매우 민감한 정보를 수집함. University of Cambridge의 Minderoo Centre for Technology and Democracy는 이 데이터가 사용자의 예상보다 훨씬 더 큰 금전적 가치를 가지며, 법적 규제가 부족한 상황에서 자사 이윤을 위해 민감한 데이터를 기업에 제공하고 있다고 경고함.

데이터의 상업적 활용과 여성 안전 위협

     * 연구진은 생리 추적 데이터가 잘못된 주체에 넘어갈 경우, 취업 기회 제한, 직장 내 감시, 건강 보험 차별, 사이버 스토킹, 임신 중단 접근 제한 등의 심각한 위험이 발생함을 지적함
     * 이 데이터는 광고주에게 특히 가치가 높음. 임신과 같은 주요 생애 이벤트와 관련된 소비 패턴 변화가 크기 때문임
     * 임신 데이터의 광고 가치가 연령, 성별, 위치 데이터 대비 200배 이상 높음
     * 여성의 주기에 따라 화장품 등 특정 광고가 집중적으로 노출될 수 있음

시장 현황 및 규제 필요성

     * 대표적인 앱 3개만으로도 2024년 글로벌 다운로드가 2억 5천만 건에 달함
     * Femtech 시장은 2027년 600억 달러 이상으로 성장 예상, 생리 추적 앱이 시장의 절반을 차지함
     * 연구진은 공공영역(예: NHS) 에서 투명하고 신뢰할 수 있는 생리 추적 앱 개발 필요성을 강조함
     * 미국은 일부 공공기관이 자체 앱을 제공 중이지만, 영국은 아직 부재함
     * 공공 앱은 개인정보 보호, 연구 활용, 건강 데이터 관리 및 사용자 권한 강화에 기여할 수 있음

개인정보 보호와 제도적 문제

     * 영국 및 유럽연합(EU)에서는 생리 데이터가 '특별 범주' 로 분류돼 추가 보호를 받음
     * 그러나 실제로는 앱을 통한 불법 임신 중단 단속, 사생활 침해 행위가 여전함
     * 미국에서는 생리 주기 데이터가 의료 데이터로 분류되지 않아 특별 규제를 받지 않음. 주로 '웰니스' 앱으로 분류돼 법적 보호가 부족함
     * 언론 및 소비자 단체 조사 결과, 앱들은 여전히 사용자의 명확한 동의 없이 제3자(광고사, 데이터 브로커, Facebook, Google 등) 와 정보를 공유함

사용자의 권리와 보완 필요성

     * 데이터 삭제 기능 제공, 동의 옵션의 세분화 등 앱 내에서 최소한의 보호 장치 필요함
     * 영미권에서 규제가 강화되고 있으나 실효성은 제한적임. 데이터가 외주 개발자, 클라우드 네트워크를 통해 계속적으로 확산됨
     * 디지털 리터러시와 개인정보 보호 교육 강화를 통해 청소년의 건강 정보 앱 이용 시 피해를 막아야 함

결론 및 제언

     * 생리 추적 정보의 사용 및 상업화가 여성의 생식권, 안전, 프라이버시에 실질적 위협을 제공함
     * 공공기관 제공 앱, 정보 삭제 필수화, 사용자 동의 절차 개선 등이 필요하며 데이터 오남용 방지와 개인정보 보호 강화가 요구됨
     * ""여성의 건강 데이터는 단순한 소비자 데이터가 아니라 중요한 의료 정보"" 라는 인식의 전환이 필요함

   본 보고서 ‘The High Stakes of Tracking Menstruation’은 Dr Stefanie Felsberger가 저술하고 Cambridge의 Minderoo Centre for Technology and Democracy에서 발행함

        Hacker News 의견

     * Charles Duhigg가 쓴 <The Power of Habit> 한 챕터에서 Target의 마켓 바스켓 분석 사례를 흥미롭게 다루는 경험을 공유함. Target은 임신한 쇼핑객을 판별해 이 시기에 브랜드 충성도가 흔들리기 쉬운 점을 노림. 타겟 광고 우편물이 너무 정확해서, 일부러 자동차 오일이나 잔디 기구 같은 무관한 품목을 섞어 위장. 임신 징후는 로션이나 세안수 같은 제품의 대량 구매에서 드러남
     * FOSS(오픈소스) 대안인 Drip을 소개. dripapp.org 링크 공유. Mozilla와 Open Knowledge Foundation이 펀딩, iOS/Android 지원
          + Mensinator도 또 다른 오픈소스 앱임을 소개. 외부 SDK를 전혀 사용하지 않고 reproducible build로 Android 지원, 여성 개발자가 개발, fairly active. GitHub 링크 공유
          + Mozilla가 들어가서 곧 사라질 거라는 농담 투의 코멘트
     * 개인정보 보호에 중점을 두고 모든 데이터를 로컬에만 저장하는 Reflect라는 앱을 직접 만들고 있다고 소개. 현재 생리 추적 기능을 개발 중이며, 최근 이상 탐지(anomaly detection) 기능도 출시. Reflect App Store 링크도 공유
          + OP의 기사에서 타사 SDK(구글, 페이스북 등)에 대한 우려가 타당하다고 보고 Reflect에서도 자체 Reflect SDK가 추가로 데이터를 다룰 수 있음에 의문을 품는 입장. ntl.ai/products 링크와 함께 회의적인 시각을 밝힘
          + 클라우드 기능이 있다면 OHTTP(Oblivious HTTP) 사용 여부를 질문. OHTTP에 대한 링크(oblivious.network/ohttp)를 안내
          + 앱이 흥미롭게 보이며 자신도 비슷한 앱을 만들고 있다고 소개. dailyselftrack.com 링크 공유, Reflect 앱이 iOS 전용인 이유에 대해 질문
          + Reflect의 안드로이드 앱 링크를 요청
     * 광고 수익(Advertising revenue)을 50% 세금으로 책정하자는 개인적인 의견을 제시. 이 방식을 통해 업계의 인센티브 정렬, 광고 기반의 '쉬운 현금 흐름'을 억제하고, 서비스도 광고 외 다른 방식으로 수익화될 가능성 제시
          + 수익이 아닌 이익에 과세된다는 점을 지적. 광고가 '공짜 현금 흐름'이 아니고 비즈니스 모델의 일부. 광고 수익 세율이 지나치게 높으면 많은 기업이 존립 어려움, 구독제 고집 시 이용자 감소로 언론 생태계마저 위험할 수 있다고 우려
          + 광고가 나쁘다고 생각하면 차라리 '광고 금지'가 맞지 않냐는 의견
          + 광고 차단기를 기기에서 자유롭게 설치·사용할 수 있어야 한다는 의견. 경제적 편법보다 독점 방지법(anti-monopoly law) 강력 집행 주장. 광고가 부담되면 이용자를 잃거나 채널이 사라지며 자연스럽게 산업이 재정렬
     * 앱 없이도 소비 기록만으로 생리 주기까지 추정 가능했던 1998년도 데이터 브로커 회의 경험을 전함. 주요 지표는 위생 용품이 아닌 음식 등 다른 패턴, 여성 그룹 간 28일 주기 등으로 포착. 이런 침해는 소비자 데이터 보호법이 없으면 계속됨
          + 위생/식품 구매는 미리 쟁여두기도 하고 가족을 위한 전체 쇼핑 때도 가능해 그 패턴 분석이 정확할지 의문. 불규칙한 주기, 어떻게 진짜 검증할지 의문을 제기
          + 80년대부터 임신 예측 등 유사 일화가 많았던 점 언급, 실제로 슈퍼마켓이 명확한 증명이나 결과를 낸 적은 없음
          + 구매 이력이 이런 식으로 추정 가능한 수준이라면, 보호법이 얼마나 실효 있을지 회의적
          + 아내가 매일 아이스크림을 먹는다는 농담식 반응
     * mozilla가 주요 생리 추적 앱들의 이용약관을 읽고 분석한 내용을 이미 많은 사람들이 알고 있다고 언급하며 분석 링크 공유
     * 이 문제(생리앱·데이터유출)가 안전 문제로까지 부각되는 진짜 이유를 궁금해함. 자신이 보기엔 타이밍 맞춰 용품 광고를 파는 것 이상의 일은 일어나지 않을 것 같고, 개인적으로는 창피할 수는 있지만 그마저도 생물학적 기능일 뿐이라고 생각
          + 여성이 임신하면 기업 BI(비즈니스 인텔리전스) 데이터베이스에 표시되고, 아기용품 구매가 아니라 주(州) 밖으로 이동하면 갑자기 범죄 용의자로 취급될 수 있음을 경고. 관련 사례 링크 공유. 이런 개인 데이터가 법집행기관(경찰 등)과 공유/판매되는 것에 강한 우려
          + CNN 보도 인용으로, 웨스트버지니아에서 유산만으로도 형사 고발 경고한 사례를 들며, 생리 공백 뒤의 재개만으로도 법적 위험이 닥칠 수 있음을 시사
          + 임신/출산은 인생에서 소비 패턴이 가장 크게 달라지는 전환점임을 지적. 출산이 예측되면 이후 집·주거지·아동 성장 단계 전반에 걸쳐 소비 행동이 매우 예측 가능, 그 영향력이 바뀌지 않음
          + 예산 규모가 클수록 문제를 크게 부각하는 현상을 꼬집으며, 본인 태도를 바꾸지 않으면 연구비를 받을 수 없을 거라는 농담 섞인 지적
          + 생리 앱에 약 복용 내역, 피임 방법 등 민감 정보도 함께 입력될 가능성에 주목. 데이터가 광고주에 넘어가면 사용자가 직접 알기도 전 임신이 노출될 수 있고, 특정 문화권(예: 미혼 임신 등)에선 심각한 문제가 될 수 있음. 가족에게까지 관련 광고가 노출되면 더 곤란한 상황
     * f-droid에서 ""Menstrual""로 검색하면 데이터가 모두 로컬 저장인 앱만 나온다고 소개. 이런 데이터는 왜 서버로 전송해야 하는지 의문을 제기
          + 대부분의 Android 사용자는 이런 점을 모를 뿐 아니라 대안까지 굳이 찾지 않는다고 지적
          + f-droid 사용자 대부분이 생리를 하지 않을 것으로 추측
          + 여러 기기에서 사용, 파트너와 데이터 공유 등은 정당한 사용사례이지만 데이터 저장·동기화가 쉽지 않은 불편함도 있음
     * 여러 플랫폼(EHR/EMR 및 제공자)에서 추출한 의료 기록을 ingest해서 보여주는 앱/툴이 있는지 질문. 이상적으로는 로컬 또는 셀프호스팅, 오픈소스이길 바람
          + 의료 기록은 표준화가 거의 안 돼 있고 데이터 분산, 접근 어렵게 설계돼 있다는 배경 지식 전달. International Patient Summary(IPS)가 그나마 표준화된 사례지만 한계 많음
     * 파트너가 PMDD 환자로 정말 필요해서 직접 incubate한 프라이버시 중심, 로컬 퍼스트 생리 추적 앱을 안내. Roe 판결 이후 직접 개발 의지로 Embody라는 오픈소스 앱 준비 중, 현재 시큐리티 감사를 앞두고 피드백 희망. embody.space 링크 공유
"
"https://news.hada.io/topic?id=21366","SaaS는 브랜딩만 바뀐 "벤더 락인" 이에요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       SaaS는 브랜딩만 바뀐 ""벤더 락인"" 이에요

     * SaaS 연동은 개발자가 제품에만 집중할 수 있게 해준다고 하지만, 실제로는 매번 숨겨진 5가지 비용(세금) 이 존재함
     * 도입 전 발견, 가입, 통합, 로컬 개발, 운영 각각의 단계에서 시간, 복잡성, 정신적 부담이 지속적으로 발생
     * SaaS가 아닌 통합형 플랫폼(Cloudflare, Supabase 등) 을 선택하면 이 반복적인 비용과 복잡성을 크게 줄일 수 있음
     * 벤더 락인은 피할 수 없는 현실이므로, 여러 서비스 혼합 대신 하나의 통합 플랫폼에서 개발 흐름(Flow) 을 지키는 것이 최선임
     * 결국 가장 중요한 것은 프레임워크·서비스 자체가 아니라, 내가 만들고자 하는 소프트웨어임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

SaaS는 단지 더 나은 브랜딩의 벤더 락인임

     * 개발자들은 “제품 개발에만 집중하라”는 말을 듣지만, 실제로는 auth, 큐, 파일 저장, 이미지 최적화 같은 SaaS 벤더 도입 시 다양한 부담이 발생함
     * 금전적 비용뿐 아니라, 시간 소모, 마찰, 그리고 정신적 피로도 존재함.

  1. 발견 세금 (Discovery Tax)

     * SaaS 서비스 도입 전, 실제로 판매하는 기능과 가치를 파악하는 과정이 필요함
     * 문제 해결 범위, 기존 스택과의 호환성, 규모 대비 합리적 가격, 문서의 명확성, 특이 구현 방식 등 세부 요소를 평가해야 함
     * 이러한 조사 과정은 이전 경험과 쉽게 공유되거나 반복되지 않으며, 상당 부분은 주관적 결정임
     * 마케팅 메시지가 나와 맞을지, 서비스가 실제로 도움이 될지 스스로 판단해야 하는 부담이 있음

  2. 가입 세금 (Sign-Up Tax)

     * 서비스 선택 후, 이메일과 카드 정보를 제공해야 함
     * 사용 기반 과금이 가능한지, 구독형 락인만 지원하는지 검토가 필요함
     * 팀 멤버가 대시보드 접근을 위해 추가 비용이 발생하는 등 불투명한 가격 구조가 문제임
     * 무료 시험 사용 없이도 테스트가 가능한지, 초반부터 결제 요구가 있는지 점검해야 함
     * 코드 한 줄 작성 전부터 벤더와 계약 관계가 형성됨

  3. 통합 세금 (Integration Tax)

     * 실제 도입 과정에서 문서 확인, 라이브러리 설치, 프레임워크 연결, 문서 외 추가 문제 해결이 필수임
     * 종종 도구와의 충돌이나 예상치 못한 문제에 직면함
     * SaaS가 최소 공통 분모만 대상으로 할 때, 최신 스택이나 특화된 환경에서는 더 많은 작업이 필요함

  4. 로컬 개발 세금 (Local Development Tax)

     * SaaS 서비스의 로컬 환경 지원 여부가 불확실함
     * 로컬 에뮬레이터 제공, 테스트 목적으로 스텁 처리 가능성 필요
     * 일부 기능 확인을 위해 클라우드 터널링 등이 요구되어 환경 구성이 복잡해짐
     * 프로덕션, 스테이징, 로컬 각각의 설정 분기가 불가피해지는 상황임

  5. 프로덕션 세금 (Production Tax)

     * 서비스 통합 후 프로덕션 환경에서 새로운 부담 발생
     * 스테이징, PR 프리뷰 환경에서도 사용 가능성, API 키 관리, 모니터링 및 로깅, 알림 등 추가 관리 필요
     * 개발 환경에서는 문제 없지만 실제 운영 환경에서만 발생하는 에러나 불일치에 대비해야 함
     * 서비스 안정성을 유지하는 책임이 결국 개발자에게 전가됨

  결론

     * 현대 SaaS의 슬로건은 ""바퀴를 다시 만들지 말라""이지만, 서비스 추가마다 마찰이 동반됨
     * 서비스 도입은 단순 통합이 아니라 계약이며, 의존성 증가와 아키텍처 변화를 수반함. 벤더 락인은 불가피하며, 교체 시 상당한 코드 재작성 부담이 따름.

     * 따라서, 이런 의사결정을 반복하기보다는 처음부터 일체형 플랫폼을 선택하는 것이 효율적임
     * 중요한 것은 개발자가 실제 만들고자 하는 소프트웨어임
     * Cloudflare, Supabase와 같은 통합 플랫폼은 데이터베이스, 큐, 이미지, 스토리지를 동일한 환경에서 제공하여 위에서 언급된 세금 부담을 대폭 줄여줌.
          + 여러 벤더 사이 전환(컨텍스트 스위칭) 필요 없음
          + API 키 조작 문제 발생 빈도 감소
          + 호환성 및 환경 별 분기 관리 필요성 최소화
          + 개발 및 프로덕션 환경에서 일관성 있는 통합 경험 제공
     * 이러한 플랫폼은 마치 모든 것이 동일한 머신에서 동작하는 느낌을 제공하며, 코드와 서비스 간 거리를 최소화하여, 어떤 SaaS에서도 제공하지 못하는 개발의 몰입감(""Flow"") 을 되찾게 해 줌.

     중요한 것은 프레임워크나 서비스 선택이 아니라, 내가 만들고자 하는 소프트웨어와 흐름(Flow)을 지키는 것임

   Supabase 가 좋은 사례로 제시되고 있는데요, 그러면 어떤 SaaS 들이 피해야할 서비스인 걸까요?

        Hacker News 의견

     * 이것은 아담 스미스의 “rent seeking(임대료 추구)”을 현대에서 초대형 확장 방식으로 보는 시각임
       이런 경제 행위는 사회적으로 해롭기 때문에 지양해야 하고 범죄화해야 한다고 생각
       한편, 무료 소프트웨어의 극단 역시 경제적으로 문제이며, 그 이유는 소프트웨어 창작자의 노력이 사용자가 얻은 가치에 비례하지 못하기 때문
       소프트웨어를 구매하는 방식과 따로 서비스 계약을 맺어 각각 실제로 별도의 가치를 제공해야 한다고 주장
       SaaS에서 이런 것들이 하나로 묶이면서 실제로는 서비스 자체보다 패키징이 지나치게 기형적으로 변하는 부분이 문제라고 생각
          + 내가 그렇게 열정적이라면, 직접 SaaS를 구축해서 온프레미스 배포·운영하는 업체를 차려서 현재 SaaS와 유사한 가격에 제공해야 한다는 주장
            만약 기업들이 데이터 통제권을 유지하고 벤더 락인을 막으면서도 SaaS와 동일한 품질, 보증, 가격을 제공할 수 있다면 시장을 지배할 수 있다고 말함
          + 항상 이런 고민을 하게 되는데, 바이너리 제공만 하고 사용자가 AWS나 GCP, 또는 cloudflare workers에서 실행할 수 있게 하면 되지 않을까 생각
            내 입장에서 saas는 개발자로선 매력적이지만 소비자로선 싫어하는 구조라 스스로 윤리적 딜레마에 빠짐
            만약 내가 소프트웨어 판매를 한다면, 사용자가 무단으로 재배포해버리면 어떻게 하지? 사스처럼 배포를 통제하지 못할 텐데
            나는 foss(오픈소스) 지지자이지만, 말씀처럼 이 방식도 경제적으로 문제가 있음
            github 스폰서로 라이선스 발급 같은 방식도 생각하며 어떤 프로젝트에서는 인증이 SSPL, 아니면 라이선스 구입 시 BSD/MIT로 전환하는 모델(예전 redis와 유사)도 고민
            다만, 이런 모델을 직접 적용했을 때 실제로 사람들이 구매할지 의문이며, 양쪽 방법을 다 지원하는 것도 고려하고 있지만 뚜렷한 답이 없어 조언을 구함
            참고로 내가 만든 프로젝트로는 누구나 무료로 암호화폐를 만들 수 있는 툴, 유튜브에서 블로그 가져오는 기능, 유튜브 커뮤니티와 비디오를 구글포토 대체로 사용하는 무제한 저장소 등이 있으며, 프라이버시 보완도 고민하고 있음. 수익화 아이디어가 있다면 알려주길 바람
          + SaaS 대부분은 공급자 입장에서는 호스팅, 지원, R&D 등 지속적인 비용이 발생한다는 점을 언급
            이런 구조가 왜 “임대료 추구”인지 논리에 공감하기 어려움
          + SaaS가 모두 임대료 추구라고 볼 순 없고, 소프트웨어의 “stickiness(달라붙음, 락인)” 자체가 본질적으로 rent-seeking과 비슷하다는 점을 지적
            대부분 SaaS 업체가 stickiness를 추구하지만, SaaS 고유의 속성은 아니라는 관점
          + 나는 내 SaaS 제품을 시장에서 합리적인 가격에 구매하려는 고객에게 판매하는 입장임
     * 벤더 락인은 보통 사내에서 “왜 NEWTHING 도구를 도입하지 않느냐?”고 물었을 때, 이미 Oracle이나 MS, IBM, Salesforce와 5년 장기계약을 맺었기 때문에 어쩔 수 없다는 대답에서 느끼는 것임
       그래서 10년쯤 지나면 정말로 그 업체에 완전히 묶여 버리게 되고, 더는 바꿀 수 없어지는 구조가 생김
          + 사업이 10년이나 지속될 정도라면 오히려 축복 또는 지루한 문제일 수 있지만, 창업 초기에 여러 도구 선정에 시간 쓰지 말고 신속하게 한 플랫폼을 골라 집중하라는 조언을 하고 싶음
          + 이런 경우에도 서비스들을 표준화된 인터페이스로 추상화하는 것이 좋다는 견해
            추상화해두면 나중에 다른 서비스로 전환할 때 단순히 대안 구현만 제공하면 됨
            이 방식이 미래지향적이지만 요즘 많은 기업이 이런 준비가 부족하다는 점을 지적
     * 의존성 최소화는 제품과 비즈니스 지속 가능성을 향상시키는 가장 중요한 요소 중 하나라고 생각
       내가 이전 직장에서 DocuSign 스타일의 전자 서명 경험을 우리 제품에 통합하는 업무를 담당했음
       DocuSign, Adobe 등 주요 벤더와 논의했지만, API 제약이 많아 제품·고객 요구에 잘 맞지 않음을 느꼈고, 결국 내부적으로 직접 구현하기로 함
       보통은 DocuSign 같은 툴을 직접 만드는 건 악수이지만, 우리 제품은 이미 고객 신뢰를 받고 있었기에 도입 장벽이 낮았음
       직접 구현 과정에서 초기에는 일이 많았지만, 실제 고객 맞춤형 소규모 수정이 필요할 때 신속하게 대응할 수 있었고, 벤더 사용했으면 훨씬 번거로운 대공사가 됐으리라는 점에서 직접 구현 선택이 옳았음
     * 글쓴이는 SaaS는 벤더 락인이니 구매하지 말라고 주장한다고 이해됨
       그런데 정작 본문에서는 Cloudflare라는 특정 플랫폼에 올인하라고 권장하고 있음
       결국 어떤 선택을 해도 모두가 락인이고, 오픈소스·셀프호스팅조차 대체하면 대량 코드를 다시 짜야 한다는 식
       단순히 벤더 종속 기능을 사용하는 것과 “진짜 락인”은 다르고, 락인은 차라리 바꾸는 게 기존 방식을 유지하는 것보다 더 많은 비용과 시간이 들 때 발생함
       소프트웨어를 느슨하게 결합하고 응집성 있게 만들면 특정 부분 교체가 쉬움
       왜냐하면 인터페이스가 단순하면 교체도 쉽기 때문
       따라서 “모두 락인이니 그냥 더 확실하게 한 플랫폼에 묶인다”는 선택은 개발자 입장에서는 편하지만, 경영자 입장에서는 안 좋은 전략이고, 회사의 유연성과 변화 가능성에 집중해야 함
          + 사업가 입장에서는 회사에 유연성과 변화 가능성을 주는 솔루션을 선택해야 하고, 아무 대안 없이 SaaS에 묶이는 건 어리석은 이유라고 생각
            시작 단계나 수익이 없을 때는 SaaS보다는 플랫폼을 쓰는 게 유리하고, 성장해 확장 단계에 도달하면 장기적인 기술 변화까지 생각하는 게 맞음
          + 나는 cloudflare workers를 자주 활용하며 코드도 어디든 이식 가능하도록 작성 중임
            wrangler dev로 로컬 실행도 가능하고, 실제로 pure node/bun/deno에서도 큰 수정 없이 동작할 수 있음
     * OP(글 작성자)는 SaaS 자체를 반대하는 것이 아니라(결국 Cloudflare나 Supabase 같은 as a service 솔루션을 추천함), 너무 많은 공급자와 계약을 맺고 관리하는 운영 비용, 관계 관리의 부담을 지적하는 것이 요지임
       벤더 수가 적을수록, 의존성이 적을수록 운영이 쉬워진다는 이야기
       실제로 모든 기능을 표준 라이브러리로 구현하는 건 너무 이상적인 연상이지만, 현실적으로 아주 어려움
          + 네가 내 취지를 정확히 요약해줬으며, 내가 글 제목에서 자극적으로 표현했다는 점을 잘 지적함
            시작할 때 여러 서비스를 뒤섞기보다는 하나의 플랫폼을 써보라는 제안이 핵심
            내가 cloudflare를 선호하는 이유는 바인딩을 fetch처럼 표준화해, fetch가 웹 세계에서 유닉스 파이프처럼 느껴지기 때문임
     * 벤더 락인을 피하겠다고 한쪽 플랫폼에 전부 올인하며 더 심하게 자신을 한 회사에 묶는 건 아이러니라는 시각임
          + 만약 플랫폼은 락인이라 싫다고 하면서 SaaS를 쓴다면 논리적으로 성립하지 않는다는 주장
            SaaS에도 분산 비용(“세금”)이 있기 때문임
     * 오히려 이 논의는 오픈소스 옹호에 가깝다고 봄
       오픈소스와 셀프호스트 방식이라면 글에서 언급한 대부분의 “세금(발견, 가입, 통합, 로컬 개발 관련 비용)”이 해소됨
       오픈소스의 production tax(운영 부담)는 생태계 활성화나 플러그인, 모듈생태계로 해결 가능하다고 생각
          + 오픈소스도 결국 직접 관리, 개발에 시간을 꽤나 써야 해서, 시간 비용까지 고려하면 무료는 아니라는 지적
     * (종교와 컬트의 차이에 빗대어) 데이터를 표준 포맷으로 추출해 떠날 수 있으면 벤더 락인이 아님
       고객은 자기 데이터를 얻게 되면 덜 피해의식이 생기지만, 너무 많은 SaaS 서비스가 이를 불가능하게 만들고 있다는 문제의식도 언급
          + 사이드 프로젝트 수익화에 도전하려는 입장으로서, 자신이 어떤 라이선스·배포 방식을 택해야 할지 고민됨
              1. MIT 등 완전 허용 오픈소스
              2. AGPL/SSPL 등 제약 있는 오픈소스
              3. 소스는 공개하되 유료 결제 시에만 허용 라이선스로 바꿔주는 방식(초기부터 라이선스 정책을 명시적으로 유지)
              4. 소스 공개 없이 바이너리 판매
              5. 위 방안 중 하나를 따르되 기본은 SaaS로 제공하며, 고객이 쉽게 떠날 수 있는 구조까지 지원
                 현재는 주로 MIT로 공개 배포하고, 중요한 건 비공개로 두는 식으로 운영하고 있음
     * SaaS의 한계는 소프트웨어의 “거의 0에 가까운 한계비용”으로부터의 혜택을 고객이 누릴 수 없게 만든다는 점임
       SaaS 사업자는 어느 정도 그 이득을 반영해 가격을 낮추긴 하지만, 사용자가 충분히 많고 단가가 높은 단계에선 결국 SaaS 이용자가 손해를 보게 됨
       하지만 스타트업 초기에는 직접 구축은 무모한 선택이고, “생존”과 “초기 비용 최소화” 단계에서는 SaaS가 매우 현명한 전략임
       사업이 성장하고 SaaS가 일상에 깊이 자리 잡은 뒤에야 락인, 이관, 전환 비용 문제가 발생
       SaaS 문제란 것도 결국 성공의 부작용이라고 생각
     * 그래서 이런 SaaS 모델이 엄청 많은 것임
       연금처럼 반복적으로 수익이 들어오고, 가격 결정권까지 갖는 사업모델이 너무 매력적임
"
"https://news.hada.io/topic?id=21359","Hello! Vibe - Claude Code편","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Hello! Vibe - Claude Code편

   Claude Code와 함께 만든 Claude Code 가이드 문서

   주요 구성:
     * 시작하기: Claude Code 설치부터 첫 프로젝트 설정까지, 단계별로 안내해드립니다.
     * 사용법가이드: 기본 명령어부터 고급 워크플로우까지, Claude Code를 효과적으로 활용하는 방법을 단계별로 알아보세요.
     * 튜토리얼: 단계별 가이드와 실제 예제를 통해 Claude Code의 강력한 기능들을 마스터해보세요. 일상 워크플로우부터 고급 자동화까지 체계적으로 학습할 수 있습니다.
     * 커뮤니티: Claude Code를 함께 학습하고 공유하는 한국 커뮤니티입니다. 유용한 콘텐츠, 오픈소스 프로젝트, 그리고 다양한 학습 자료를 만나보세요.
     * 활용 사례: Claude Code를 어떻게 활용하여 조직의 업무 효율성을 극대화하고 있는지 심층적으로 알아보세요.

   오류/수정: https://github.com/revfactory/claude-code-guide

   14:51 분 기준으로 접근이 안되네요. repo 참고해서 보겠습니다.

   감사합니다. :)
"
"https://news.hada.io/topic?id=21376","LLM은 정말 저렴하다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              LLM은 정말 저렴하다

     * 대다수 사람들이 LLM(대규모 언어 모델) 사용 비용을 과대평가하는 경향이 있으나, 실제로는 빠르게 저렴해져서 웹 검색보다도 저렴한 수준에 도달
          + 초기 생성형 AI 열풍 당시에는 추론 비용이 높았으나, 지난 2년간 비용이 1000배 가까이 감소
     * LLM API의 실제 단가를 웹 검색 API와 직접 비교하면, 저가형 LLM 모델은 심지어 최저가 검색 API보다도 10배 이상 저렴하며, 중간 가격대 모델도 상당히 경쟁력 있는 가격 구조임
     * 모델 운영사들이 API 가격을 무리하게 보조하고 있다는 근거는 희박하며, 실제로 GPU 비용 기준 80%에 달하는 높은 마진을 기록하는 사례도 있음
     * OpenAI 등 주요 AI 기업들이 적자를 내는 이유는 비용 때문이 아니라 낮은 수익화 정책 때문이며, 이용자당 월 1달러만 받아도 흑자 전환이 가능한 구조임
     * 향후 비용 부담의 중심은 LLM 자체가 아니라, 외부 백엔드 서비스(예: 각종 데이터 제공처)로 옮겨갈 전망임. LLM 실행은 점점 더 저렴해지고, 비즈니스 모델 역시 충분히 성립 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM의 비용 오해와 현실

     * 많은 사람들이 ChatGPT와 같은 LLM의 운영 비용이 매우 비싸다고 오해하고 있음
     * 이로 인해 AI 업체의 사업성이 불투명하다거나, 소비자용 AI 서비스의 수익화에 불리하다는 오분석이 반복됨
     * LLM은 아직도 비싸다는 건 인식의 오류
          + AI 붐 초기에는 추론(inference) 비용이 매우 높았으나, 최근 2년간 비용이 1000배 가까이 감소
          + 많은 논의가 과거 기준의 비용 구조를 기반으로 잘못된 전망을 하고 있음
     * 흔히 사용되는 ""1백만 토큰당 가격 모델"" 은 직관적으로 이해하기 어려움

웹 검색 API와 LLM API 가격 비교

     * 대표적 웹 검색 API 요금
          + Google Search: $35/1000회
          + Bing Search: $15/1000회
          + Brave Search: $5~9/1000회, 단가가 높아질수록 오히려 가격이 오르는 구조
          + 전체적으로 웹 검색 API는 저렴하진 않으며, 서비스 질이 좋은 쪽이 더 비쌈
     * LLM API(1k 토큰 기준) 요금
          + Gemma 3 27B: $0.20
          + Gemini 2.0 Flash: $0.40
          + GPT-4.1 nano: $0.40
          + Deepseek V3: $1.10
          + GPT-4.1: $8.00 등
          + 검색과 비교 가능한 방식으로 LLM 단가 산정 필요: 한 질의당 토큰 출력 개수 + 토큰당 가격
          + 500~1000토큰이 평균 쿼리당 소비량으로, 직접적 비교 가능
     * 저가 LLM 모델은 최저가 검색 API 대비 10~25배 저렴
          + 품질 중간대 LLM도 동일 구간의 검색보다 훨씬 낮은 비용
          + 배치 단위, 비피크 시간 할인 등 다양한 추가 할인 조건 고려시 더 저렴해짐

비용이 저렴한 진짜 이유

     * 모델 제공사들의 API 단가 보조 의혹은 근거 약함
          + API 시장점유율 확대의 유인도 약하며, 다수 타사 제공 API 가격도 경쟁적으로 형성됨
          + Deepseek의 실측 자료에 따르면 GPU 기준 마진이 80%에 달함
     * 훈련(Training) 비용과 추론(Inference) 비용
          + 대규모 추론 트래픽에 의해 훈련비용이 효과적으로 분산(Amortize)되고 있음
          + 오히려 서드파티 백엔드 서비스 이용 시 발생하는 비용이 문제로 부각될 가능성

“LLM API는 적자일 것” 주장의 반박

     * OpenAI 등 대형 사업자 적자는 낮은 수익화 전략의 결과
          + 월 1달러 수준의 수익화만 해도 흑자 전환 가능
          + 무료 사용자 트래픽을 활용한 데이터 수집 목적 등도 존재
     * 향후 진짜 비용 이슈는 LLM이 아니라 외부 백엔드
          + 예: AI 에이전트가 티켓 예매 등 외부 API를 호출할 경우, 실제로는 서드파티의 비용 부담이 커질 수 있음
          + 서비스 사업자들은 크롤링 차단, 모바일 전환, 로그인 강화 등으로 대응할 전망

왜 중요한가

     * 많은 미래 예측이 LLM이 비싸다는 잘못된 전제에 기반해 이루어지고 있음
     * 실제로는 비용 하락과 수요 증대가 동시에 발생, 향후 가격은 더 하락하며 시장 활성화 예상
     * Frontier AI 기업들은 수익화보다 시장 선점에 초점을 두며, 실제로 LLM 서비스 단가가 특히 낮음
     * 진짜 비용 문제는 LLM 자체가 아니라 후방의 외부 연동 서비스(예: 티켓팅 사이트 등) 에 있음
     * 이러한 외부 서비스들이 수익을 얻지 못하는 구조에서, 향후 AI와 백엔드 서비스 간 새로운 수익모델 또는 기술적 대립 가능성 존재

결론 및 전망

     * LLM의 추론 비용 자체는 더 이상 AI 비즈니스의 본질적 제약이 아님
          + 저렴한 실행 비용과 다양한 수익화 옵션(예: 광고, 구독 등)으로 충분히 사업적 가능성 보유
          + 앞으로는 LLM이 아닌, AI가 활용하는 외부 데이터 제공처의 비용·인프라 문제가 주요 과제가 될 것
     * 시장·기술 변화에 맞춘 현실적 비용 인식과 비즈니스 전략 전환이 필요함

   onprem으로 그래픽카드 구비해서 사용하거나 클라우드에서 gpu 임대하는 시나리오로 시뮬레이션 해봤을 때는 엄청 비싸다고 생각했는데
   규모의 경제를 달성하면 꽤 할만한가보네요.

   LLM으로 monetization 할 수 있을까 의심했었는데, 긍정적이라니 놀랍네요.

   생각보다 충격적인 조사 결과네요... 수십조원이 투자된 모델 사용 비용이 저렴한데, 그 비용으로도 충분히 수익화가 가능한 수준이라니...

        Hacker News 의견

     * 수익을 내는 검색 API와 손해를 감수하며 시장 점유율을 노리는 클라우드 기반 LLM API를 비교하는 것은 올바르지 않다는 생각임
       현재의 데이터는 기업들이 AI 주도권을 잡기 위해 무지막지한 설비 투자(capex)를 하는 상황이지만 아직 수익성을 내는 단계까지는 도달하지 못했음
       두 제품 모두 성숙 단계가 완전히 다르며, 사용률이 줄어드는 10년 묵은 서비스에서 계속 손해를 보는 것을 정당화할 수 없다는 점은 무시할 수 없는 현실임
       또한 검색 쿼리는 CPU 및 높은 캐시 적중률로 처리 가능하지만, LLM 추론은 대부분 GPU를 요구하고 각 토큰 결과가 크기 때문에 사용자 간 캐시 공유가 어려운 환경임
          + inference 서비스가 수익성이 없다는 증거가 없다고 말하지만 사실 AWS 같은 호스팅 제공업체에서 inference 비용을 직접 지불해 보면 알 수 있다는 입장임
            AWS가 외부 모델을 돌려주는 서비스를 무한정 보조해줄 리 없으며, 설비투자는 capex이지만 추론 실행 비용은 opex(운영비)인 점이 더 중요하다는 주장임
          + 요즘에는 오픈소스 모델을 호스팅하는 API 제공업체들은 API 요금과 실제 inference 하드웨어 비용 사이에 충분히 많은 마진을 남기고 있음
            물론 이게 전부는 아니나, 자체 추론 최적화까지 고려하면 마진이 더 커질 수 있다고 봄
            OpenAI나 Anthropic처럼 폐쇄형 모델 제공자 역시 공개된 모델 스펙을 바탕으로 추정해 보면, Anthropic은 API 요금과 하드웨어 비용 사이에 굉장히 좋은 마진을 내고 있다고 믿고 있음
            실제로 프로덕션에서 이 모델을 돌려본 경험이 있다면 이 부분은 직접 검증 가능하다고 생각함
          + Perplexity가 이익률이 좋은 것처럼 보이기 위해 COGS를 R&D로 회계상 옮기는 식으로 회계조작을 한 정황이 있음
            링크
          + DeepSeek의 API 서비스 분석에 따르면, 이들은 500% 이익률을 기록하고 있을 뿐 아니라 동일한 모델을 서비스하는 미국 기업들보다 훨씬 저렴한 가격에 제공하고 있음
            OpenAI나 Anthropic 역시 이보다 훨씬 더 높은 이익률을 올릴 가능성이 충분하다고 봄
            GPU는 대체로 CPU보다 비용 및 에너지 효율성 모두가 뛰어나며, Anthropic은 24k 토큰 시스템 프롬프트에서 KV-cache 캐싱을 활용함
          + LLM API가 손해를 감수하고 시장을 선점하려는 전략이라는 인식은 동의하지 않음
            현재는 오히려 openrouter처럼 모델이나 제공업체를 자유롭게 변경할 수 있는 서비스가 있어서 락인 효과가 없고, 시장 점유율을 잡는 전략 자체가 경제적으로 의미 없음
            ChatGPT 웹처럼 UI를 통한 상품이라면 몰라도, API를 손해보고 판다는 것은 어리석다는 입장임
            심지어 VC들도 API를 손해보고 파는 걸 인정하지 않을 것이라고 생각함
     * 검색 엔진과 LLM을 단순한 사실 검색(예: ""미국의 수도는?"") 용도로만 쓴다고 가정해서 비교하는 것 자체가 양쪽 서비스의 주요 사용사례에서 너무 멀리 벗어난 비유라고 생각함
       검색엔진을 쓴다면 웹 인덱스 접근에 초점을 둘 것이고, 단순 답변을 얻는 것은 UI/제품의 기능이지 API의 목적이 아님
       LLM을 쓸 때는 대용량 데이터 분석, 이미지 인식, 복잡한 추론, 프로그래밍 등 다소 복잡한 용도에 활용하게 되고, 이 경우 토큰 사용량이 단순 검색 답변보다 훨씬 크다는 점이 차이라 봄
       저자가 하는 이야기는 ""혼다 시빅이 사과와 lb 당 가격이 비슷해서 저렴하다""는 식의 잘못된 비교라고 느껴짐
          + 기존 검색엔진 모델이 점점 쓸모 없어지는 느낌임
            전문가들은 점점 검색엔진을 덜 쓰고, 일반 사용자들도 검색엔진을 웹 인덱스 탐색이 아니라 마치 사람에게 물어보는 듯한 대화형 용도로 사용
            ""미국의 수도는?""처럼 불필요한 부분이 포함된 쿼리는 오히려 검색엔진이 아니라 LLM이 더 적합하며,
            SEO 스팸 사이트들이 너무 많아 검색 품질 저하 문제도 큼
            LLM은 자연스러운 질문을 더 잘 처리하고, 쓸데없이 긴 설명, 스팸, 광고 없이 원하는 답만 골라주기 때문에 앞으로 더 쓸모 있어질 거라 생각함
          + 저자가 ""검색과 LLM 비교가 단순한 사실 질의로만 유지된다""고 지적한 점은 동의하지 않으나, 실제 분석의 핵심은 '검색엔진이랑 LLM을 비교한다'가 아니라,
            단순히 단위당(토큰/쿼리) 가격과 비용의 차이를 비교해 마진을 계산하는 것에 있음
            API가 보조금으로 유지되냐 아니냐를 따질 때 검색엔진 대비 비교는 꼭 필요하지 않다는 생각임
          + LLM을 대용량 데이터 분석 및 복합적 용도로 쓴다는 점 자체는 맞지만, 이건 파워유저에 해당함을 인정함
          + 검색엔진은 웹 인덱스를 찾는 용도라는 점이 좋은 포인트라는 생각임
            하지만 LLM도 원하는 정보를 더 정확히, 중복 없이, 빠르게 찾을 수 있으니 기존 검색이 무조건 더 좋다고 할 수 없다고 봄
            LLM이 직접적인 답변을 주고, 심지어 링크까지 붙여줘서 결과를 검증하기 쉽게 만들어 준다면 사용자의 만족도가 오히려 더 높아질 수 있음
            구글도 검색 결과를 계속 묻히게 만드는 원인은 점차 인덱스 기반 결과가 쓸모 없어지는 현실 때문이라는 의견임
          + OpenAI가 2024년에 적자가 아주 크지 않았고, 월 방문/사용량을 감안하면 inference(추론) 비용이 실제로 그리 높지 않다는 근거도 있음
            ChatGPT가 매달 세계에서 가장 많이 방문한 사이트 중 하나라는 점, 대다수 트래픽이 무료 사용이라는 점을 감안하며, 실제 비용은 생각보다 크지 않을 수 있음
     * LLM 관련 비용 추정의 근거가 명확하지 않다는 의문을 제기함
       예를 들어 항공기 수하물 크기 같은 최신 사실은 LLM에게 소스를 확인할 수 있도록 웹검색 기능을 붙여서 알아봐야 더 신뢰할 수 있음
       그럴 경우 토큰 소비가 빠르게 늘어나서 비용 추정이 빗나갈 수 있으며,
       여러 번 대화를 반복하며 맥락이 누적될 때 전체 토큰 사용량이 급증하는 구조임
       실사용 데이터 없이 추정만으로는 비용 산정이 어렵다는 점을 인정함
          + 나는 LLM에게 최신 소식을 물어보고, LLM은 여러 웹페이지를 직접 읽고 요약해서 안내함
            최신 관련 질문을 하면 웹검색을 꼭 하고 참고 링크를 붙여주니, 이런 방식으로 활용 가능하다고 생각함
          + ""미국 항공사 DFW-CDG 노선에서 기내 반입 사이즈가 얼마냐""고 물어보니 웹검색을 활용해 정확하게 답변 주고, 공식 웹사이트 및 FAA 링크까지 안내받음
            이런 방식이 활용에 효율적이라고 생각함
     * 반도체 확보가 어려운 현실과, 비싼 전력 및 장비 비용을 감안할 때 빅플레이어들이 당장 API 기반 LLM 서비스를 수익성 개선 없이 돌리며 이익을 낼 수 있다고 보지 않음
       하드웨어 가격과 전력 문제가 해결되지 않으면 당분간 큰 수익을 내긴 어려울 것
       YouTube도 20년을 운영해도 구체적 흑자 여부를 알파벳이 공개하지 않는 점을 예시로 소개함
          + 알파벳(구글)의 큰 수익성은 검색 시장에서의 압도적 점유율와 광고 매출 덕분임
            AI 기업들도 언젠가는 시장 점유율을 매출로 전환할 수 있을 것이라 bet을 거는 중임
            Stickiness(고착성)가 생기면 시장점유율→수익 전환도 충분히 가능성이 높다고 봄
          + 주가 상승 자체가 어떤 의미에서는 기업 수익성의 기준일 수 있다고 말하며,
            아마존이 10년 넘게 비슷한 전략을 썼다는 점을 언급함
     * OpenAI가 2024년 5억 달러 적자, 5억 MAU라는 수치에서 '500M 무료 사용자들을 연평균 $10 ARPU로 전환하면 BEP 달성 가능'이라는 논리는 실제로는 실현이 어려운 수치임
       무료 이용자를 $1이라도 과금하면 대다수가 떠날 전망이며,
       '그냥'이라는 단어가 너무 현실을 단순화한다는 생각임
          + 사실 $1/월 이용료로 과금 전환하자는 게 아니라, 요즘은 LLM 돌리는 게 매우 저렴해져서 광고 기반으로도 충분히 수익을 낼 수 있다는 주장임
            같은 사용자 규모의 서비스(광고 기반)와 비교했을 때, 지금의 LLM 원가는 훨씬 낮은 상태이며 구독은 유일한 답이 아니라 생각함
          + 5억 명의 유료 사용자 전환은 오히려 서비스 사용 패턴과 원가를 전혀 다르게 만들어서 비용을 폭증시킬 수 있음
            차라리 1%만 유료로 전환되면 10억 달러/년이 나온다는 간단한 가정도 가능
          + 나는 이 서비스들이 적자 운영을 하는 이유가 사용자 데이터 가치가 구독료보다 훨씬 크기 때문이라 생각함
          + 실제로 모두가 유료로 전환해야 하는 게 아니라, 일부 유료 사용자가 나머지를 보조하는 구조만 만들어도 충분히 돌아갈 수 있다는 입장임
     * 시간이 지나 시장 점유율 쏠림과 규제 이후에는 투자자들이 약속받은 가격 인상 현실화가 올 전망임
          + 또는 광고로 돈을 벌 가능성도 높음
            어떤 질문을 해도 답변 사이에 코카콜라 광고가 나오며,
            AI 코딩 프로젝트에 자동 광고가 붙고,
            AI가 보내는 10번째 이메일마다 보험상품 광고를 삽입하는 등
            무한한 수익화 기회가 존재함
     * 사내에서 LLM 운영 비용을 전력 사용량 중심으로 산정해보니, 내부 사용자의 burst성 요청에도 불구하고 100만 토큰당 $10대 수준에 불과함
       서버 부하가 크지 않았으니, 대규모로 돌리면 훨씬 비용이 더 낮아질 여지도 충분함
          + 이 계산이 오직 전력 사용량만을 근거로 하는지 질문함
     * LLM의 토큰 응답 1개와 검색엔진의 검색결과 1개가 동일하게 비교될 수 있는지 의문임
       저자는 LLM 1천번 호출(약 100만 토큰)를 검색엔진 1천 쿼리와 비교하지만,
       실제로는 1천 배 차이날 수 있는 오류가 있을 것 같음
       (후속 수정: 저자 방식을 보니 실제로 1천번 API 사용 기준으로 가격을 비교한 것이라 오해였다는 점을 직접 확인)
          + 저자가 LLM 1천회(총 100만 토큰), 검색엔진 1천회 기준으로 단가 비교한 게 맞음을 정정함
          + Gemini 2.0 Flash가 100만 토큰에 0.4달러, Bing Search API가 1000쿼리에 15달러면 LLM쪽이 37배 더 저렴한 계산임
     * 앞으로 효율 개선 및 100배 원가 절감이 예상된다면 왜 지금 이토록 데이터센터를 증설하는지 의문임
       기계 업그레이드 주기만 거치면 기존 데이터센터도 충분히 활용 가능하지 않을까 생각하며,
       현재의 투자 열기가 실제로 거품일 수 있다는 가능성도 언급함
     * 관련 성능 비교 아티클을 공유함
       링크
       실제 가격만 보고 판단하기에는 비싸다는 생각이며,
       극심한 시장점유율 경쟁 상황에선 숫자만 놓고 해석할 수 없다는 입장임
"
"https://news.hada.io/topic?id=21309","Physicality: UI의 새로운 시대","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Physicality: UI의 새로운 시대

     * iOS의 대규모 UI 리디자인 루머가 확산되며, VisionOS를 포함한 Apple 전 플랫폼에 ‘Physicality(물질감)’ 중심의 인터페이스 변화가 예고됨
     * iOS 디자인 역사는 Shaded Age(스큐어모픽), Flat Age(플랫), 그리고 최근의 New Age(피지컬리티) 로 구분될 수 있으며, 각 시대마다 UI 철학이 극적으로 변해왔음
     * VisionOS의 UI 원칙처럼, 미래의 인터페이스는 평면이 아닌 실제 물질처럼 빛, 그림자, 환경에 반응하는 요소들이 중심이 됨
     * 최근 iOS의 Dynamic Island, Siri 애니메이션 등은 이미 ‘유리(Glass)’와 같은 동적 물질감을 강조하며, 새 디자인 패러다임의 전초로 평가됨
     * 다음 변화는 전면적이고 동적인 ‘살아있는 유리’ UI로, 사용자 경험에 새로운 감각적 깊이와 몰입을 제공할 것으로 전망됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

iOS 디자인 변화의 역사와 ‘Physicality’로의 진화

  거대한 리디자인의 예고

     * 최근 Apple 생태계(특히 iOS, VisionOS)에서 사상 최대 규모의 리디자인 루머가 퍼지며, 디자이너 커뮤니티의 상상력이 자극되고 있음
     * iOS 7 시절과 비견될 만한 변화가 예고되며, 이번에는 iOS뿐 아니라 macOS, iPadOS, tvOS, watchOS, visionOS까지 전면적 스타일 변환이 예상됨

  iOS 디자인 시대별 변화

    Shaded Age (스큐어모픽 시기)

     * 초기 iOS(아이폰 OS)는 스큐어모픽 기반으로, 실물의 재질감을 강조하는 버튼, 레더, 금속 등 시각적 효과가 풍부하게 적용됨
     * 익숙함과 접근성을 높이기 위해 현실의 오브젝트와 유사한 디자인을 적극 활용
     * iPad 등에서는 동적 효과(슬라이더의 빛 반사, 쓰레기통 애니메이션 등)도 시도됨

    Flat Age (플랫 디자인의 시대)

     * iOS 7에서 급진적 전환이 이뤄지며, 플랫 디자인으로의 대전환이 단행됨
     * 버튼은 단순한 텍스트와 색상으로, 시각적 깊이, 그림자, 입체감이 크게 축소됨
     * 대신 다층 구조, 패럴럭스(Parallax), 블러 등 동적 레이어로 심플하면서도 공간감을 표현함
     * 시간이 흐르며 다시 그림자, 두꺼운 아이콘, 둥근 모서리 등으로 점진적 ‘온화함’이 복귀함

    New Age (피지컬리티 시대)

     * VisionOS UI는 실제 재료감(materials) 을 모든 요소에 부여, 패널·아이콘·버튼 모두가 빛, 그림자, 환경에 따라 변화하는 ‘살아있는 UI’ 로 설계됨
     * Alan Dye(Apple 디자인 책임자)는 VisionOS 인터페이스에 대해 “모든 요소가 물리적 감각을 가지며, 빛에 반응하고 그림자를 만든다”고 강조함
     * 이러한 원칙이 iOS 등 Apple 전 제품으로 확장될 가능성이 매우 높음

  물질감의 재해석: 살아있는 UI

     * iOS의 Dynamic Island, Siri 애니메이션 등은 실제 물리적 성질(액체의 점성, 움직임, 빛의 반사 등)을 반영하는 동적 UI 효과를 구현 중
     * “새로운 스큐어모피즘”은 단순한 시각적 효과가 아닌, 현실 세계에서 볼 수 있는 행동(Behave) 자체를 인터페이스에 이식하는 방향으로 변화

  ‘Living Glass’ UI의 상상

     * 미래 iOS는 기기 자체의 유리(glass)와 어우러지는 동적, 반응형 인터페이스로 진화할 전망
     * 버튼, 패널, 아이콘 등 모든 컨트롤은 주변 환경(콘텐츠, 조명 등)에 따라 반사, 블러, 색상 변화 등 ‘살아있는 유리’와 같은 효과 적용
     * Home Screen, Tab Bar, 아이콘, 플래터 등 기존의 정적 UI 패턴을 대체하는 새로운 계층적 레이아웃과 ‘공간감’을 지닌 디자인 예측

  디자인 패러다임의 변화와 개발 환경

     * iOS의 대전환은 Apple 브랜드, 웹사이트, 아이콘, 개발 도구까지 광범위하게 영향을 미침
     * 서드파티 개발자, 디자이너도 전례 없는 ‘동적, 환경 반응형 UI’에 맞는 새로운 도구와 사고방식이 요구됨
     * 과거 Photoshop 등으로 만들던 정적 그래픽 중심에서, 실시간 환경 효과와 조합되는 UI 설계로의 진화가 핵심

  과거와 미래를 잇는 ‘Glass Fiction’

     * SF에서 그려온 ‘유리로 이루어진 미래형 UI’ 가 드디어 현실화되고 있음
     * MS 등 타사도 개념적 ‘Glass UI’를 영상 등으로 시도했으나, Apple만의 하드웨어-소프트웨어 통합력이 실질적 구현을 가능케 함
     * WWDC에서 이 같은 ‘살아있는 유리 UI’가 공개될지 기대감이 모아짐
"
"https://news.hada.io/topic?id=21364","Ask HN: CUDA를 전문가 레벨로 배우려면 어떻게 해야하나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Ask HN: CUDA를 전문가 레벨로 배우려면 어떻게 해야하나요?

     * CUDA 프로그래밍을 배우기 위해 어떤 책/과정/프로젝트를 수강해야 할지 궁금 (일하고자 하는 많은 회사들이 CUDA경험을 요구하기 때문)

HN의 답변들 정리

     * 학습 자료와 첫걸음
          + NVIDIA 공식 CUDA Programming Guide와 NVIDIA의 아카이브 도서 추천
          + 작은 예제 프로그램부터 시작해 점차 병렬화 연습, 기존 C/C++ 지식이 매우 중요
          + 오픈소스 코드(GitHub 등)와 LLM(예: ChatGPT) 활용하여 코드 구조를 해석하고 실습
          + 약 6~8주 계획으로 실습 위주로 접근 권장
     * 필요 하드웨어 및 환경
          + 최근 10년 이내 NVIDIA GPU(특히 Turing/RTX 20xx, Ampere/RTX 30xx 이상)라면 충분, 구형(Maxwell 이전)은 지원 및 성능 측면에서 한계
          + CUDA Toolkit 최신 버전 사용, GPU의 Compute Capability 확인 필수(지원 표 참고)
          + Windows, Linux 모두 가능하며, 환경에 따라 Docker 및 VPS도 활용 가능
          + GPU가 없는 경우 leetgpu.com과 같은 온라인 에뮬레이터로 체험 가능
     * 병렬 프로그래밍 기본기
          + CUDA 문법 자체보다 병렬 알고리즘, 하드웨어 아키텍처 이해가 더 중요
          + 대표 서적:
               o Programming Massively Parallel Processors (PMPP)
               o Foundations of Multithreaded, Parallel, and Distributed Programming
               o Scientific Parallel Computing
               o The Art of High Performance Computing (Victor Eijkhout, 무료)
          + CUDA의 실제 현업 요구는 cuBLAS, cuDNN 등 CUDA 기반 라이브러리 활용 및 병렬 성능 극대화에 집중
     * 학습 방법론
          + 단순 문법 학습보다 작은 CPU 코드를 CUDA로 포팅 → 성능 벤치마크 → 점진적 최적화 방식 권장
          + 처음에는 정확성 중심, 이후 성능 최적화(메모리 관리, shared memory, register 활용 등) 단계적 적용
          + 실습 예제: prefix scan, GEMM, n-body simulation 등 고전 병렬 알고리즘 추천
          + CUDA Thrust, CUTLASS, cub 등 고수준 추상화 라이브러리 우선 학습, 직접 구현은 나중에 도전
     * 실무와 커리어
          + CUDA 경험 요구는 대부분 딥러닝, 데이터 엔지니어링, HPC(과학계산), 게임 그래픽스 등에서 발생
          + 단순히 PyTorch/Tensorflow가 아닌, 핵심 CUDA 커널/라이브러리 최적화 경험을 요구하는 자리도 있음
          + 실무적 전문성을 쌓으려면 PTX, nvcc, cuobjdump, Nsight Systems/Compute 등 로우레벨 툴 활용 능력도 중요
          + 커뮤니티 참여: gpumode Discord, GPU Puzzles 등 활발한 커뮤니티에서 실전 코드 리뷰와 토론
     * 주의 및 현실적인 조언
          + 시작은 쉽지만, 하드웨어별(아키텍처/명령어셋) 최적화와 호환성 확보는 매우 어렵고, 진입장벽이 높음
          + 실제로는 직업 경험과 네트워크가 중요하며, 자기 주도 학습만으로는 현업 경력으로 대체될 수 없음
          + CUDA는 하드웨어/병렬컴퓨팅/알고리즘/최적화가 모두 맞물린 분야이므로 한 분야에 집중해서 깊이 파고드는 전략 추천

   글쎄요. cuda를 직접 사용할 경우가 있긴 할련지. 특히 한국에서요

        Hacker News 의견

     * 2008년 NVidia cudacontest 참가자로서, 인도에서 제출한 몇 안 되는 사람 중 한 명으로 BlackEdition Card 참가상도 받은 경험을 바탕으로 내가 따라온 방법 공유함
          + NVidia CUDA Programming Guide 참고
          + NVidia에서 배포한 CUDA Programming 관련 도서 활용(developer.nvidia.com/cuda-books-archive 참조)
          + 기존 구현 기반으로 작은 프로그램부터 작성(강력한 C 언어 구현력 필수이므로 필요하다면 복습 권장)
          + 필요한 Toolchain, 컴파일러 설치 및 작업용 하드웨어 확보 가정
          + Github의 CUDA 프로젝트 코드 분석 및 최신에는 LLM 활용해서 코드 설명 요청 가능
          + 작지만 병렬처리 기반 프로그램부터 점차 확대
          + 1~2개월 차분히 진행하면 충분히 CUDA 프로그래밍 시작 가능
          + 요즘은 2007/08년보다 자료와 리소스가 풍부한 환경
          + 6~8주 학습 계획 수립 후 실행 추천
          + 언제든 질문 남기면 도울 수 있는 부분 최대한 안내 가능
               o 필요한 하드웨어 관련해서 구체적으로 궁금함. 5년 전쯤 나오 nvidia 그래픽카드만 있으면 충분한지, 아니면 더 특별한 사양이 필요한지 질문
               o 어떤 개발 환경을 사용하는지 궁금함. 아직도 Windows가 CUDA 주 개발 환경인지 확인 원함
     * Leela Chess Zero의 CUDA 코드 직접 살펴보니 이해할 만한 수준이었음
          + 당시 Leela는 transformer 대신 DCNN 구조를 사용했는데, fast.ai 영상 통해 DCNN 기초 쉽게 배움
          + Transformer는 더 복잡해 아직 학습 시작을 못함
          + CUDA 언어 자체는 C++ 기반이므로 C++ 경험 있으면 어렵지 않게 접근 가능
          + 다만 CUDA 개발자가 되고 싶다면 AI 프로그래밍 수준까지 도달 필요성 큼—AI는 CUDA보다 훨씬 깊고 방대한 영역이라 많은 시간과 실전 경험 필요
          + 그래도 실력 갖추게 되면 시장 수요 매우 높음
          + fast.ai 영상 강력 추천
          + 게임 분야라면 3D 그래픽스까지 얘기가 이어지는데, 최근은 훨씬 더 복잡해진 상황이라 입문 경로를 모르겠음
               o CUDA 개발자로 구직하는 게 현재 다른 소프트웨어 엔지니어 분야에 비해 부담이 적은지 질문. 현재 Java 미들웨어 개발자로서 CUDA와 AI 쪽이 커리어 전환에 좋을 것 같다는 의견
               o 이 코드가 여기 맞는지 확인 요청 및 두 가지 초보 질문
                    # 왜 C++/CUDA를 직접 썼는지, 단순히 pytorch나 tensorflow로는 Leela 학습 속도가 부족한 건지
                    # 그리고 tensorflow 코드도 있는데 그 이유에 대한 궁금증
     * 돈이 동기라면 HPC 및 수학적인 영역은 패스 추천
          + 해당 분야는 박사급이 아니면 실력이 아무리 좋아도 관심 받기 어려움
          + 진짜 돈이 되는 역량은 PTX, nvcc, cuobjdump, Nsight Systems, Nsight Compute 등 툴 마스터, 그리고 CUTLASS 같은 오픈소스 코드베이스 분석
          + 관련 실전 노트 참고 추천
          + 무엇보다 HN에만 머물지 말고 진짜 개발자 모여 있는 discord gpu mode 커뮤니티 참여 권장
               o 멋지고 실제적이지만 매우 틈새 분야로 보임
               o 진입 자체가 어려우며 게임 산업, 드라이버 등 한정된 분야에서만 쓰임
               o 처음부터 바로 그 단계까지 가려면 상당한 재능 필요성 언급
     * gpumode.com 리소스 및 디스코드 커뮤니티 수개월 동안 공부 거리를 충분히 제공
          + Programming massively parallel processors 책
          + nvidia cuda 공식 문서는 매우 포괄적
          + GPU-Puzzles도 도전 추천
               o ThunderKittens flashattention-2 예시 코드 보며 말로 설명하기 어려운 코드 복잡성 느낌
               o 이런 퍼즐은 '승자 독식' 구조라 실질적인 성취 차이는 1% 이내이며, 실습 자체가 큰 의미 없다는 생각
     * 학습 범위 쪼개서 접근성 높이기 추천
          +
              1. CUDA 자체(프레임워크/라이브러리/추상화 레이어) 학습
          +
              2. 고성능 컴퓨팅 기본(이것은 GPU, Nvlink 개념 넘어서 HPC 아키텍처 전반에 통용)
          +
              3. 응용 분야 특화(Transformer면 Torch, Tensorflow 등 최신 고수준 추상화에서 출발)
          + 실제 CUDA 마스터 원한다면, 대규모 병렬처리 프로그래밍 원리 체험과 이해가 핵심이며 상당 부분 이식 가능한 스킬
               o 전직 GPU 개발자로서 나 역시 같은 조언, 특히 2번과 3번 강조
               o 취업 목표에 따라 달라지겠지만, 정말 필요한 것은 CUDA 라이브러리(cuDNN, cuBLAS, cuFFT 등) 경험일 수도 있음
               o 병렬 프로그래밍 원리 이해가 무엇보다 우선
               o 이 접근법이 정답이며, 2번 없이 1번부터 바로 배우면 더 큰 혼란만 초래
               o 추천 도서 안내
     * 개인적인 CUDA 학습 과정 경험 공유
          + 체계적이진 않으나 학계 및 연구에 도움된 방식
          + 박사 프로젝트 때문에 CUDA 직접 학습 필요
          + 연구실 내에 경험자 전무하여 NVIDIA 기본 과정(Getting Started with Accelerated Computing with CUDA C/C++ 및 python 버전)으로 개념 기초 익힘
          + 공식 튜토리얼 외 실제로는 시행착오 중심 학습 많았음
          + 온라인 튜토리얼, 책 활용했으나 함수나 API가 금방 바뀌어 구버전/신버전 혼동 많고, 내 GPU와 실 환경의 호환성 이슈까지 신경 써야 했음
          + 가장 어려웠던 점은 대부분 시간을 디버깅(생각보다 느린 원인 추적) 및 도구(예: ""compute-sanitizer"", Nsight) 사용에 쏟았던 부분
          + 조급해하지 말고, CPU에서 동작하는 간단한 프로젝트를 CUDA로 포팅 후 benchmark하면서 최적화 경험 쌓기 추천
          + 최적화는 맨 마지막에, 일단 올바른 동작 구현을 우선시
          + 동작은 느려도 메모리 손상 없는 커널이 최적화된 커널보다 더 가치 있음
               o 비슷한 박사과정 경험 공유—flashrnn 실습 결과물
               o 기본 원리와 GPU 구조 이해했다면 추천하는 워크플로우
                   1. 커널 테스트 가능한 환경 세팅, 상위 레벨 언어로 된 Baseline과 비교
                   2. 급한 프로젝트 없으면 기존 유명 문제(MatMul 등) 복습 또는 재구현—모든 케이스 다 하려 하지 말고 기능별로 집중
                   3. 점진적으로 복잡도 높이기—루프, 그리드 병렬화, 전역/공유/레지스터 메모리 차례로 사용, 단순 행렬곱에서 TensorCore(MMA)까지 확장
                   4. CUDA C Programming Guide 반복 탐독—실습하면서만 제대로 체득
                   5. CUTLASS, ThunderKitten 등 상위 추상화도 케이스 따라 추천, JAX/Torch 환경이면 triton 우선 활용
               o PTX까지 마스터하려면 시간은 더 오래 걸리지만 실전에서 몸으로 익히는 과정 강조
               o CUDA 성능 디버깅 고통에 깊이 공감
     * 고등학생에게 CUDA 가르칠 때 활용한 자료 소개—혼자 전체 마스터엔 부족하지만 첫 시작에 도움이 되는 강좌
          + 입문 강의(YouTube)
     * 아직 써보진 않았지만 꽤 괜찮아 보여서 추천하고 싶은 leetgpu.com 플랫폼
     * CUDA 엔지니어 채용하는 직무, 포지션, 기업군에 대한 현업 의견 요청
          + 현재는 많은 회사가 PyTorch처럼 CUDA 기반 라이브러리를 이용하지만, Native CUDA 개발 자체가 많은 회사에 필요한지 모르겠음
          + 직접 CUDA 중심으로 일하는 조직이나 역할 발굴을 기대
               o 우리 팀의 경우, 지리정보(geospatial) 데이터 분석에 CUDA 직접 활용
               o slippy map 타일을 래스터화하고 GPU로 래스터 요약 처리
               o 대부분 픽셀 단위 독립적 처리라 GPU에 적합
               o 행 단위로 요약 병렬처리 후 마지막에 모아서 처리
               o 다만 GPU로 데이터 복사 부분이 현재 병목
     * 시대 변화에 맞춰, Claude 등 LLM에 질문해서 결과 코드와 설명 한꺼번에 받는 방법 활용
          + 2025년엔 이렇게 해도 통할 수 있지만, 2026년은 한 단계 더 요구할 것이라는 의견
"
"https://news.hada.io/topic?id=21356","Wordpress와 오픈 웹의 새로운 길: FAIR 프로젝트 - 분산형 WordPress 인프라","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Wordpress와 오픈 웹의 새로운 길: FAIR 프로젝트 - 분산형 WordPress 인프라

     * 워드프레스의 중앙집중·불투명한 거버넌스 문제가 커뮤니티 내 핵심 이슈로 부각되어, 독립적이고 투명한 대안 필요성 대두
     * 2024년 말~2025년 초, AspirePress(커뮤니티 미러) 등 여러 분산 노력이 등장하며, 오픈 레터·기술적/거버넌스적 '이중 트랙' 대안 논의가 본격화
     * 이 흐름에서 다양한 그룹이 힘을 모아, FAIR(Federated and Independent Repositories) 라는 실질적인 '탈중앙 워드프레스 패키지 관리/배포 인프라'를 구현
     * FAIR는 리눅스 재단 산하 커뮤니티 주도 기술운영위원회(TSC)에서 관리, 미러·패키지·상업 플러그인·암호화 서명 등 실질적인 생태계 인프라를 제공. 워드프레스를 포크하는 게 아니라 '새로운 배포·거버넌스 계층'을 제공하는 것
     * FAIR의 등장은 단순한 저항이 아니라, 오픈소스 생태계 내부에서 더 나은 인프라와 거버넌스를 위한 '기여'로 평가됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

워드프레스 FAIR 프로젝트의 탄생과 의의

  # 리더십 문제에서 시작된 변화

     * 2024년 말, 워드프레스 생태계의 지나친 중앙집중과 거버넌스 부재가 공론화
          + 너무 많은 권력이 한 개인에게 집중되고, 투명하지 않은 관리 구조가 기여자와 비즈니스 모두에게 불확실성 유발
     * 커뮤니티 중심의 미러(AspirePress) 발표 및 20여 명의 핵심 기여자 오픈레터를 계기로 문제의식 공유 확산
     * Karim Marucchi 등과 함께, 기술적·정치적 두 갈래 해법 제안
          + 중앙화 해소(배포/업데이트/발견성)
          + 투명·책임·중립적 거버넌스 도입

  # 다양한 노력의 연결, FAIR로 집결

     * 여러 팀·커뮤니티의 개별 분산 시도가 자연스럽게 교차, 연대·공동작업으로 전환
     * 단일 프로젝트 선언보다 '그룹의 그룹' 방식의 연합체로 조직화
     * 급한 현안(플러그인 업데이트, 디렉터리, 에셋, 대시보드 등)부터 미러/드롭인으로 대응, 점진적 확장 구조 설계

  # FAIR: 커뮤니티 주도 분산 패키지 인프라

     * FAIR는 리눅스 재단 산하, 커뮤니티 주도 TSC(기술운영위원회) 에서 관리
          + 3인의 커뮤니티 리더(Carrie Dils, Mika Epstein, Ryan McCue) 공동의장
          + 분산 패키지 관리, 미러, 상업 플러그인, 암호화 서명 등 빠른 기간 내 구축
     * 목표는 워드프레스 포크가 아님
          + 동일한 코어 소프트웨어 사용, 기존 워드프레스와 호환
          + 중앙화 병목 없이, 독립적 거버넌스/배포 계층을 추가
     * Composer 등 오픈소스 패키지 관리 경험 기반, 사용자 친화성에 초점
          + 대부분 사용자는 내부 구조를 몰라도, ""그냥 잘 동작""한다고 느낄수 있음

  # FAIR의 의미와 앞으로의 길

     * FAIR는 '저항'이나 '포크'가 아니라, 워드프레스 인프라·거버넌스를 위한 긍정적 기여
     * 수개월간 기업·국가·커뮤니티 협업의 결과물, 참여자 점점 확대
     * FAIR의 자세한 정보는 fair.pm에서 확인 가능
     * 오픈웹과 워드프레스의 '공유 인프라'와 '기여자 중심의 미래'에 동의한다면 언제든 참여 가능

  # 참고/참여 링크

     * Karim Marucchi FAIR 소개
     * Ryan McCue: 에코시스템 강화
     * Siobhan McKeown: FAIR와 함께 앞으로
     * 리눅스 재단 공식 보도자료

        Hacker News 의견

     * Linux Foundation이 FAIR Package Manager Project를 발표했다는 소식 공유, 공식 발표문은 여기에서 볼 수 있고, HN 내에서의 관련 토론은 여기에서 확인 가능
          + 몇 달 동안 나만의 프로젝트를 위해 비슷한 시스템을 생각해왔다고 말하면서, ATProto(atproto.com), IPFS(ipfs.tech), Radicle(radicle.xyz), Iroh(github) 등을 검토한 경험을 언급, 최근엔 Iroh 쪽으로 기울고 있었지만 ATProto도 흥미롭다고 판단, 이제 FAIR(protocol)도 확인해볼 예정, 보편적으로 채택될 수 있는 프로토콜 등장이 기대
     * FAIR의 레포지토리를 특히 fair-plugin에서 살펴보고 나서, 현재 방식보다 Wordpress의 소프트 포크에 별도 인프라를 구축했으면 더 낫지 않았을까 하는 생각, 현재 방식처럼 코어 Wordpress를 대체 구현으로 우회 시도하는 방식은 실패할 가능성이 크다고 판단, 코어 개발자가 이 메커니즘을 깨라는 임원을 통한 지시를 받을 수밖에 없는 구조, 아울러 TFA에 링크된 Matt Mullenweg의 jkpress 포스트는 매우 비전문적이고 신랄하다고 느꼈다며, 그의 인성에도 악영향을 준다고 평가
          + 오픈 거버넌스라는 접근으로 먼저 기여를 시작하는 전략이 현명하다고 생각, 만약 Matt가 방해하거나 무산시키려 시도하면, 커뮤니티의 “최선을 다했다”는 분위기로 소프트 포크로 넘어갈 명분과 지지를 확보할 수 있으리라 기대, 이런 합리적 태도를 보임으로써 포크 시 커뮤니티 다수를 함께할 수 있고, Matt에게도 이 노력에 간여하지 않거나 심지어 동참할 수 있는 여지를 남겨 신뢰 회복 가능성도 열려 있음
          + Matt Mullenweg의 신랄한 성격은 처음이 아니라 오랫동안 이어진 특징이라는 의견, 본래 잘 드러나지 않았지만 해마다 어딘가에 드러나곤 했고, 최근 9개월 동안은 비일비재하게 나타남, 관련 타임라인과 캡처, wp engine 소송 문건(타임라인, 뉴스Y코멘트) 참고
          + 코어에서 해당 메커니즘을 일부러 깨려 할 가능성은 낮다고 생각, 예를 들어 HTTP 요청 필터 기능을 빼면 많은 플러그인과 사이트가 깨지면서, “한 번 설치하면 다시 신경 쓸 필요 없음”이라는 판매 포인트가 무너짐, 주요 경쟁자도 Wix나 Jimdo 같은 서비스니 CMS끼리의 경쟁이 아니라는 점, 백엔드를 막으면 구버전들도 다 깨지고 업그레이드 경로가 끊기는 부작용도 발생, 필터 및 액션 구조는 개발자들에게 Wordpress 작업을 견딜만하게 해주는 핵심 요소, 플러그인 생태계 없인 Wordpress는 별 의미가 없을 것이란 의견도 피력, FAIR 코드상 OOP와 composer가 PHP 8을 필요로 하지 않는데 7.2까지 지원하는 점은 우려스럽지만, 실제로는 많은 WP 플러그인과 코어도 같은 상황
          + WPEngine의 소송 덕분에 Wordpress가 대안 인프라 구현을 막을 명분이 사라질 거라 조심스럽게 추측, Linux Foundation에는 신뢰가 가지 않지만 워드프레스 사태 전체에선 (개인적으론) 워드프레스를 더 응원하고 있었음, 하지만 탈중앙 apt 스타일의 Linux Foundation 후원 플러그인 저장소가 75%만 잘 돌아가도 과감히 넘어갈 자신 있음, 하나의 CEO와 리스크를 안고 가는 것보다 훨씬 낫기 때문, 비슷한 생각을 가진 이용자가 많으면, 워드프레스의 미래는 어둡다고 봄, 포크를 원치 않는 건 워드프레스 개발비를 내고 싶지 않아서이고, 수익이 빠져나가면 워드프레스는 더 정체되며 이미 공룡이라는 비유도 덧붙임, 기생충이 숙주를 죽이는 상황에 비유
     * 내 입장에서 한동안은 Wordpress가 최소한 개인적인 용도로는 막다른 길이라고 판단, 그 이유와 의견은 블로그에 정리, 굉장한 도구이지만 불안정한 회사 때문에 신뢰가 힘든 상황, FAIR Package Manager가 생태계를 바꿀 수 있을지 지켜볼 예정
          + Static Site Generator(SSG)로의 마이그레이션도 충분히 고려할만한 옵션, 그 외에 어떤 CMS가 인기가 있는지도 궁금, 현재 내 블로그는 Grav으로 운영 중이고, 파일 기반이지만 Git으로 쉽게 관리 가능, 동적 콘텐츠와 검색(및 선택적 Admin UI)까지 지원, Grav 공식 사이트 참고 가능
     * FAIR 공식 사이트는 fair.pm이고, 곧바로 github.com/fairpm으로 리디렉트됨, FAIR Package Manager는 중앙 WordPress.org 플러그인/테마 에코시스템을 대체하는 분산형 대안으로서, 워드프레스 호스트와 개발자가 더 많은 통제권을 가질 수 있게 설계된 도구, 기존 서비스는 플러그인만 설치하면 바로 대체 가능하며, API 교체(업데이트 체크 등 WordPress.org API를 FAIR가 대체), 플러그인/테마 분산 패키지 관리 등 두 가지 축으로 구성, AspirePress 또는 지정 도메인 미러를 통한 데이터 설정까지 지원, 현재는 안정적 플러그인의 경우 WordPress.org 미러를 사용하지만, 점차 FAIR-native 패키지로 확대될 예정, 플러그인 설치는 이곳에서 가능
     * FAIR와 같은 방향에 모멘텀이 생기는 게 매우 기대, 아이디어 자체는 언제나 많지만 실행은 어렵고 다양한 기술 분야의 협업과 조율이 필요한 게 현실, 이 단계까지 진행되기까지 모두에게 큰 박수
     * 향후 자원봉사 큐레이터 팀을 계속 유지할 수 있을지 궁금, 현재도 패키지의 악성코드 여부와 기존과 중복되는 기능 여부 등을 분류하고 검증하는 일이 많아졌고, AI 생성 패키지의 등장으로 업무량도 지속 증가하는 상황
          + TSC 공동의장 입장에서 관련 의문 매우 공감, 공동의장인 Mika Epstein(Ipstenu)이 플러그인 리뷰팀을 오랫동안 이끌었고, 기여자들 다수가 리뷰 프로세스에 깊이 관여한 경험자가 많아 항상 최우선적으로 고민하는 문제
     * 한동안 이어진 Wordpress/Automattic 관련 주요 이슈와 논란을 한데 모아둔 주요 링크들의 모음, 해당 사건에 관심 있다면 아래 항목과 토론을 차근히 확인 권장
          + 또 다른 정리 버전으로 이 타임라인 추천
     * FAIR라는 명칭이, 데이터 관리 쪽에서 이미 써온 FAIR 원칙(Findable, Accessible, Interoperable, Reusable)과 혼동될 우려 있다는 지적
          + 이미 모든 이름이 겹치는 세상이기 때문에 어쩔 수 없다는 자조
     * “우리가 하는 일은 새로운 배포 계층을 추가하고, 그 위에 자체 거버넌스를 얹는 것이다”라는 FAIR 프로젝트 요약
"
"https://news.hada.io/topic?id=21399","AI로 오염되지 않은 콘텐츠를 위한 Low-background Steel","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                AI로 오염되지 않은 콘텐츠를 위한 Low-background Steel

     * Low-background Steel 사이트는 AI 생성 콘텐츠로 오염되지 않은 자료를 모으는 역할을 함
     * 이 프로젝트는 2022년 대규모 AI 콘텐츠 확산 이전에 생성된 텍스트, 이미지, 비디오 자료에 초점을 맞춤
     * Wikipedia, Arctic Code Vault, Project Gutenberg 등 대표적인 기여처를 안내함
     * 사이트 방문자가 새로운 비오염 자료를 제출할 수도 있음
     * 핵실험 이전의 청정 금속 개념에서 창안된 이 발상은 신뢰성과 원본성 유지에 중점을 둠
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

소개

     * Low-background Steel은 AI가 만든 콘텐츠로 오염되지 않은 온라인 리소스를 모으는 웹사이트임
     * 이 사이트의 명칭은 핵실험 이전에 제작되어 방사능 오염이 없는 금속인 Low-background Steel(및 Lead)에서 착안함
     * 핵실험(Trinity Test) 이전에 침몰한 선박에서 추출되는 금속이 방사능 오염이 거의 없어 귀하게 여겨짐
     * 여기에서 따온 아이디어로, AI 생성물이 급증하기 이전에 생산된 순수한 디지털 콘텐츠를 보존하고 안내하려는 취지임

목표와 배경

     * 2022년 대규모 AI 기반 생성 콘텐츠의 등장 이전 텍스트, 이미지, 동영상 등 다양한 원본 형태 자료 확보에 중점 둠
     * 이러한 자료는 Wikipedia 전체 덤프, Arctic Code Vault, Project Gutenberg 등 신뢰할 수 있는 대표적 오픈 소스 데이터베이스를 포함함
     * 사이트 이용자는 신규 오염되지 않은 자료를 제출 양식을 통해 직접 추가 가능함

사이트의 중요성

     * AI 생성물이 급증하는 시대에, 원본성 보존과 신뢰할 수 있는 정보 확보가 중요해짐
     * Low-background Steel은 정보 오염 걱정 없이 활용할 수 있는 청정 데이터 레퍼런스 제공을 목표로 함

기여 방법

     * 누구나 새로운 Non-contaminated 콘텐츠 소스를 사이트 submit 기능으로 추가 제안 가능함

참고

     * 사이트의 취지가 잘 반영된 위키피디아의 Low-background Steel 관련 설명이 연결되어 있음
     * 해당 프로젝트는 2023년 3월 개설, 실질적으로 온라인 콘텐츠 보존을 위한 실험적 허브 역할을 수행 중임

        Hacker News 의견

     * 유니코드에 새로운 'plane'을 추가해 모든 유용한 문자들을 거울처럼 복제하고, 여기에 추가적인 상태 비트를 붙여 구분하는 발상에 흥미를 느낌
          + 예를 들면 ‘인간이 직접 쓴 결과물’ 구역에는 AI가 생성한 텍스트를 사용하면 바로 처벌, ‘인간에게만 공개’ 영역에선 AI가 학습하거나 접근하는 것까지 금지, ‘AI가 생성함을 인정’ 범위에는 모든 AI 산출물이 반드시 해당 문자 범위로 처리하도록 규정하는 상상을 함
          + 물론 이 문자들은 시각적으로 구분이 어렵고 소프트웨어를 거쳐야 구별할 수 있어 미묘한 채널 기능을 수행
          + 텍스트를 복사·붙여넣기 해도 원본의 정보가 작은 문자 인코딩 차이로 함께 이동
          + 거의 농담이긴 하지만 이런 시스템에 흥미를 느낌
          + 마치 유기농 식품처럼, 100% 사람이 쓴 ‘오가닉’ 콘텐츠에 프리미엄 가치가 형성된다고 생각
               o 하지만 식품 업계처럼 실제로 무엇이 허용되고 어디까지 오가닉인지 결정하는 게 악몽
               o 인증은 신뢰 네트워크에 의존하고, 결국 AI 결과물이 오염된 채로도 더 높은 가격에 거래 가능
          + ‘AI가 생성한 텍스트’ 기준이 불분명하다고 느껴 구체적 예시를 듦
               o
                   1. 학생이 직접 손글씨로 작성
               o
                   2. 온라인 백과사전을 참고했는데, 해당 백과사전이 내부적으로 AI를 사용
               o
                   3. AI에게 논문 구조, 요점, 결론을 짜달라고 해서 직접 작성
               o
                   4. 자신이 쓴 글을 AI로 맞춤법, 문장 수정, 스타일 조정만 맡김
               o
                   5. AI가 전체 글을 대필
               o
                   6. 여러 편을 직접 쓴 뒤, AI에게 최고 작품을 선정하게 함
               o 첫 번째와 마지막은 명확하지만 나머지는 어디까지 AI 결과물로 볼 수 있을지 헷갈림
          + 유니코드에는 원래 언어 영역을 표시하기 위한 태그 문자(visible tag character)가 존재하지만 더 높은 레벨 마크업(HMTL 등)에 밀려 지금은 폐기
               o 이 문자는 보이지 않고, 커서 이동 시 여러 개가 한 문자처럼 처리
               o ASCII와 대응되어 임의의 JSON이나 데이터 삽입 가능
               o LLM이 생성한 영역을 표시하는 데 쓸 수 있는데, 자칫 숨겨진 데이터 또는 권장되지 않는 용도라서 불편함이 있을 수 있음
               o 관련 링크: https://en.m.wikipedia.org/wiki/Tags_(Unicode_block)
          + 이 법이 시행되면 12밀리초 만에 인도에서 ‘타자 공장’이 생겨, 인간이 AI 결과물을 베껴서 데이터 세탁에 활용 예상
          + 예를 들어 외국어로 글을 쓴 후 ChatGPT에게 영어로 번역 부탁하면 AI 생성물로 볼지 의문
               o 손글씨 후 LLM으로 OCR 진행, 아주 상세한 개요를 AI에게 제공하면서 사실 검증도 엄격하게 거쳤다면 어떨지
               o AI를 오로지 문법 체크나 과학적 표현 보정용으로만 썼다면 이 또한 AI 생성물인가
               o 내 기준에선 모두 ‘아니오’라고 생각
     * AI 산출물은 본질적으로 평균 회귀 현상을 가진다고 주장
          + 이런 내용은 인간이 직접 묻고 얻을 수 있는 정보라는 관점
          + 모든 AI 생성물에 <AI generated content> 태그만 붙이면 되고, 그 외에는 공익보다는 공해에 더 가깝다고 봄
          + 이 논리대로라면 뭔가를 쓸 필요 자체가 없는 결론
               o 셰익스피어나 수학적 증명, 모든 소설·보도는 이미 가능한 단어의 조합일 뿐
               o 뭔가가 단지 ‘생산 가능하다’는 점이 아닌, 특별한 목적·상황·독자를 위해 만들어졌다는 점에서 충분히 가치가 있다고 생각
          + 이런 직관적 믿음이 언젠가는 약간의 실험적 증거도 있었으나
               o 최근 잘 큐레이션된 AI 결과물이 혁신적인 돌파를 이뤄낸 점에서, 더 이상 해당 주장이 사실이 아님이 드러남
          + 인간 전문가의 이름이 걸린 검증과 큐레이션 과정 자체도 큰 가치
               o 실제로는 인터넷상의 대부분의 콘텐츠가 이미 전문가가 아닌 저임금 저질 퀄리티였는데, AI가 이를 더 악화시킨다고는 보지 않음
          + AI로 편집됐거나 스타일을 바꾼 글도 결국 사람이 쓴 것이라고 볼 수 있는지 궁금
               o 나의 경우 노트에 음성으로 블로그 글을 불러 녹음하고, 이를 CGPT나 Claude로 톤·리듬을 잡아 다듬음
          + 넌센스라고 생각
               o 실제로 디프 리서치 툴 사용 경험이 있다면 인간도 무가치한 콘텐츠를 많이 만든다는 점을 이해하게 됨
               o 유토피아적 오해에 빠지지 마길 바람
     * 이 글에 사용된 용어들이 걱정을 과소평가하도록 절묘하게 선정됐다고 생각
          + 핵실험 종료 이후 방사선 수준이 자연치에 거의 근접, 새로운 강저방사선강(stell) 필요성 감소, 새 강재도 방사능 신호가 충분히 약해 대부분 용도에 사용 가능
          + 하나, ‘오염되지 않은’ 데이터가 꼭 필요하진 않다고 생각
               o LLM 데이터가 일반 reddit 댓글보다 훨씬 낫다는 느낌
               o archive.org, gutenberg 등으로도 ‘순수’ 데이터는 여전히 찾기 쉽다고 봄
               o LLM 산출물이 결국 모든 곳에 스며들 것이기에 피할 수 없는 흐름
          + 우리가 핵실험을 중단해서야말로 배경 방사선이 감소했다는 점은 사실임
     * 이 사안이 대중이 예상하는 만큼 심각하지 않을 것으로 봄
          + 장기적으로 AI는 실제 경험에서 배우게 되어, 무한한 비저작물 학습 데이터가 가능하고 AI 오염 문제도 회피할 수 있다고 주장
          + 현실에서는 AI의 환각성(hallucinations/사실 왜곡)이 인용돼 진실처럼 굳어지는 경향
               o 예: “MS-DOS용 connect four 내장 생산성 프로그램이 뭐였나?”라는 질문을 실제 AI에게 여러 번 해봤을 때, 매번 다른, 그러나 모두 틀린 답만 출력
               o 해당 오류 정보가 다시 웹에 인용되고, AI가 그 잘못된 정보를 학습하게 되는 순환 고리 발생
               o 이런 상황에서는 진실을 알기 어려움
          + 실제 경험 데이터(예: 차량 수리)는 생성 자체가 비용과 위험이 큼
               o 인간整비사처럼 AI도 메뉴얼과 명시적 교육과정을 시작점으로 삼아야 함
               o 만약 오로지 실제 수행 데이터로만 학습한다면, 시행착오로 차량을 망가뜨리게 될 것이고, 그 과정에서도 인간이 개입해야 함
               o 오프폴리시 강화학습(RL)이라도 그 데이터 역시 이전 세대 모델(즉 AI가 만든 것)에서 왔을 수 있기에 완전히 ‘AI 오염 무결’로 볼 수 없음
               o 그렇기에 실제-경험만으로는 공급 한계와 비용, AI 오염 문제를 완전히 해결할 수 없음
          + 유튜브에 실제 자동차 수리 경험 데이터가 넘쳐나지만, 저작권 이슈가 있음
               o AI 기업이 해당 콘텐츠를 쓰기 전에 저작권 라이센스를 받아야 하는지 논란
          + 장기적으로 AGI가 필요하다고 보는지 의문
               o AGI가 나온 뒤에는 스팸 콘텐츠도 질이 좋아진다는 논조에 의문
               o 관련 xkcd 참고: https://xkcd.com/810/
          + 예측컨대, 일반 지능을 갖춘 휴머노이드 로봇이 등장하기 전에는 자동차를 고치는 AI 시스템은 현실화되지 않을 것
               o 5성급 호텔에서 AI 메이드가 등장하는 일 또한 마찬가지
               o 그래서 언어 데이터베이스 오염 문제도 시간이 지나 해결된다는 관점은 다소 비현실적이라고 봄
     * 현재로서는 ‘AI 오염’이 실제로 AI 훈련에 문제를 일으킨다는 증거가 없음
          + 2022년 이전 공공 데이터로 훈련한 AI가 2022년 이후 데이터로 훈련한 AI에 비해 눈에 띄는 성능 우위를 보이지 않음
          + 심지어 최근 데이터가 약간 더 잘 나오는 경우도 있음
          + ‘low background steel’ 비유에 담긴 사고방식은 바로, 합성 데이터로 거듭 학습하면 AI 모델이 완전히 무의미해지는 ‘모델 붕괴(model collapse)’가 온다는 것
               o 실제로는 그 현상도 없었고, AI 회사들이 내부적으로 AI 데이터만 분리해서 걸러내는 필터도 운용하지 않는 듯
               o 오히려 인간이 AI 데이터에 과도하게 노출될 경우 모델 붕괴가 인간에게 나타날 수 있다고 봄
               o 이는 어디까지나 내 경험과 직감임
          + 위 주장은 여러 이유로 합리적이지 않음
               o
                   1. 2022년 이후 LLM 훈련 기법이 월등히 개선되어 데이터 내 AI '찌꺼기'의 부정적 영향이 드러날 정도로 크지 않아 보일 뿐
               o
                   2. 성능 평가는 모호하고, 동세대 모델(Gemini 2.5 vs Claude 4 등)간의 미세한 차이로만 드러남
               o 이런 작은 효과는 데이터로 입증이 어려우며, 그럴수록 원칙적 접근이 중요
               o 원칙적으로는 AI 생성물 학습을 피해가는 것이 바람직
          + 아직 본격적으로 AI 오염 ‘찌꺼기’가 쏟아지지 않았으며, 앞으로 급격히 늘어날 것이라 기대
     * 일부는 AI 콘텐츠에 그리 거부감 없으며, low-background steel 비유를 굉장히 뛰어난 착상이라 평가
          + 나 역시 AI 콘텐츠에 거부감이 크지 않으며, 실제로 관련 사이트를 만들기도 했음
               o 목적은 확실히 인간이 만든 것으로 알려진 자료를 기록하는 것임
          + 개인적으로 AI 포비아라기보다는, AI가 자신의 결과물을 또 학습하는 현상을 막으려는 의도가 큼
               o ‘pre-AI’ 시대의 콘텐츠는 더이상 새로 생성 불가한, 그 자체로 늘어나는 희소성
               o 만일 2015년 즈음 모든 데이터에 암호학적 타임스탬프를 찍어 뒀다면 더 좋았겠지만, 지금이라도 남은 것을 아껴야 할 시점임
     * 오늘의 내 생각이 신기할 정도로 예지력을 보인 것 같음
          + 내 과거 댓글
          + 이미 적어도 1년 전, 혹은 그보다 오래 전 hackernews에서 이 사례를 본 적 있음
               o 관련 예전 논의
          + ChatGPT 출시 이후 흔히 사용된 비유였음
          + AI ‘오염’ 없는 콘텐츠라는 프레이밍도 이미 접했으나, ‘low background steel’을 이에 빗대어 사용한 건 꽤 참신한 샷이라고 생각
          + 내 생각은 다름
               o 우리가 콘텐츠와 합성데이터에 주석을 붙이고, 기계가 이를 활용해 미래 산출물이 점점 좋아진다고 믿음
               o LLM만으로는 그 효과가 두드러지지 않더라도, 이미지·비디오 모델에서는 명확함
               o 가장 훌륭한 시각적 산출물만을 엄선하면서 결과가 조금씩 향상되고, 이 과정에서 ‘기호에 맞는 큐레이션’도 큰 역할
               o 유전학 및 생물학에서 다양한 생태적지 니치에 적용되는 것과 마찬가지로, 우리는 합성 머신으로 게임의 룰을 빠르게 진화시키고 있음
     * low-background analogy의 흥미로움에 공감
          + 2024년에도 내가 해당 비유를 언급한 바 있음
          + 관련 글1
          + 관련 글2
     * 이 비유가 정말 설득력 있는지 의문
          + low-background steel은 실제로 새로 만드는 게 거의 불가능에 가까운데, AI-free 콘텐츠는 그냥 AI 안 쓰면 되어 난도 낮음
          + 사실상 어떤 결과물이 AI-free임을 객관적으로 증명하는 것이 불가능에 가깝기에, 본인 외에는 아무도 확신 못함
          + 누가, 어떤 이유로, 어떤 돈을 들여 AI-free 콘텐츠를 만들지 물음
          + 클릭베이트성 제목일 뿐이라고 봄
     * 이 사이트명이 Y combinator에서 온 점에 착안해, 함수의 고정점(fixed point)을 찾는 것을 inference 모델의 요구사항으로 꼽음
          + 한 콘텐츠가 스스로를 변환하고 그 결과를 다시 입력으로 삼으며, 본질적 패턴을 계속 추출해낼 것이라는 낙관적 태도
     * AI 편향된 데이터 생성이 늘더라도, 원본 인간 콘텐츠와 파생콘텐츠, 그리고 그 파생콘텐츠의 파생콘텐츠 등 여러 단계가 섞여 훈련하더라도 본질적 특징들은 계속 추출 가능하리라 기대
"
"https://news.hada.io/topic?id=21371","애플, Foundation Models 및 컨테이너화 프레임워크 등 신규 개발자 도구 발표","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           애플, Foundation Models 및 컨테이너화 프레임워크 등 신규 개발자 도구 발표

     * 애플이 Foundation Models 프레임워크와 컨테이너화 프레임워크 등 개발자를 위한 새로운 기술과 도구를 선보임
     * 온디바이스 Apple Intelligence 모델과 Xcode 26의 대형 언어 모델 통합으로 앱 개발의 생산성과 지능화가 대폭 강화됨
     * Liquid Glass 신소재 디자인과 Icon Composer로 앱의 미적 경험과 일관성 있는 아이콘 제작이 한층 쉬워짐
     * Swift 6.2, Metal 4, Game Porting Toolkit 3 등 차세대 성능 및 게임 개발 기능들이 제공됨
     * 새로운 App Intents, 아동 보호, 접근성 강화 등 플랫폼 전반에서 통합적이고 안전한 경험 제공이 강조됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

주요 발표 요약

     * 애플은 개발자들의 창의성과 혁신, 그리고 앱 디자인을 촉진하기 위해 강력한 신규 도구와 기술을 공개함
     * 이번에 발표된 기술에는 온디바이스에서 구동되는 Apple Intelligence 모델, 대형 언어 모델이 결합된 Xcode 26, 그리고 모든 애플 플랫폼에서 구현되는 세련된 신소프트웨어 디자인이 포함

모든 플랫폼에서 활용 가능한 신기능

     * iOS 26, iPadOS 26, macOS Tahoe 26, watchOS 26, tvOS 26 전반에 걸쳐 새롭고 일관성 있는 디자인이 적용됨
     * 25만개 이상의 API, 머신러닝, 증강현실, 헬스, 피트니스, 공간 컴퓨팅, 고성능 그래픽 등 폭넓은 기술 지원이 강화됨
     * 각 플랫폼 릴리즈마다 애플은 기술과 도구를 확대 및 개선하여 개발자의 아이디어 실현을 돕고, 최적화된 경험을 제공함

Liquid Glass 디자인과 Icon Composer

     * Liquid Glass는 유리의 광학 특성을 활용하면서 유동적인 감각을 부여하는 신규 소프트웨어 소재임
     * 버튼, 스위치, 슬라이더, 텍스트, 미디어 제어 등 최상위부터 앱 내 주요 탐색 요소까지 앱 전반에 일관적 확장이 가능함
     * SwiftUI와 같은 네이티브 프레임워크 덕분에, 새로운 디자인 적용과 경험 일관성 제공이 쉬워짐
     * Icon Composer 앱을 활용해 개발자와 디자이너는 블러 처리, 반투명, 색조 미리보기, 렌더링 모드 지원 등 다양한 툴로 아이콘의 일관성과 매력을 강화할 수 있음

Foundation Models 프레임워크

     * 파운데이션 모델 프레임워크는 무료 AI 추론과 오프라인 지원으로 개인정보 보호와 스마트 경험을 동시에 제공함
     * Apple Intelligence 기반 경험을 오프라인에서도 프라이버시를 강화하여 제공할 수 있는 기계학습 프레임워크
     * Swift 네이티브 지원으로 단 세 줄의 코드로 Apple Intelligence 모델에 접근 가능함
     * Guided generation, tool calling 등 다양한 생성형 AI 기능을 앱 내에 바로 구현 가능함
     * 예시로, Automattic의 Day One 앱에서 프라이버시 중심 지능형 기능을 이미 적용 중임

Xcode 26 및 대형 언어 모델 통합

     * Xcode 26에서는 코딩, 테스트, 문서화, 디버깅 모두에 대형 언어 모델을 연결 가능함
     * ChatGPT 내장 지원, 다양한 서드파티 API 키 또는 로컬 모델(Apple silicon 지원) 연동을 제공함
     * Coding Tools는 인라인 코드 프롬프트, 프리뷰 생성, 오류 수정 등 다양한 지능형 작업 흐름을 지원함
     * Voice Control로 음성만으로 Swift 코드 작성, Xcode 내비게이션이 가능하며, 현지화 카탈로그, 네비게이션 경험도 개선됨

App Intents 및 시각적 인텔리전스

     * App Intents를 통해 Siri, Spotlight, 위젯, 시스템 컨트롤 등과 앱의 액션 및 콘텐츠를 더 깊게 연결 가능함
     * 올해는 비주얼 인텔리전스 기능이 추가되어 인앱에서 시각적 검색 및 탐색 경험 확장됨
     * Etsy 사례를 통해, iPhone 내 시각적 인텔리전스 기반 빠른 상품 탐색 경험을 소개

Swift 6.2

     * 성능, 동시성, C++ 등 다양한 언어와의 호환성 강화, WebAssembly 지원(커뮤니티 협업 기반)
     * 단일 스레드 실행 코드의 기본 설정이 가능해져, 추가 주석 없이 메인 액터에서 코드 실행이 쉬워짐

컨테이너화 프레임워크

     * 개발자가 Mac에서 직접 리눅스 컨테이너 이미지 생성, 다운로드, 실행이 가능함
     * Apple silicon 기반에 최적화된 오픈소스 기반 프레임워크, 이미지 간 격리 제공

게임 개발 도구 및 기능

     * Game Porting Toolkit 3: 게임 평가, 프로파일링, Metal Performance HUD 커스터마이즈, 그래픽 코드 성능 가이드 등 지원
     * 윈도우에서 맥용 게임 빌드 워크플로우를 위한 Mac Remote Developer Tools for Windows 제공
     * Metal 4: Apple silicon 전용 차세대 그래픽 및 기계학습 연산 지원, 셰이더 내 인퍼런스 네트워크 실행 가능
     * MetalFX Frame Interpolation: 두 프레임 사이 중간 프레임 생성으로 고주사율 프레임 제공, MetalFX Denoising: 실시간 레이트레이싱/패스 트레이싱 지원
     * Apple Games 앱: 모든 Apple 기기에서 게임과 친구를 한 곳에서 관리, 도전과제 및 Game Center 기능 심화
     * Managed Background Assets: 앱/게임 자산 호스팅 관리, 200GB 애플 호스팅 용량 기본 제공, 빌드와 별도 제출 가능

온라인상 아동 보호를 돕는 도구

     * 유해 콘텐츠 차단, 민감 콘텐츠 분석 프레임워크 등 기존 도구와 더불어, Declared Age Range API 도입으로 연령에 맞춰 맞춤형 콘텐츠 제공이 용이해짐
     * 보호자는 민감정보 노출 없이 자녀 연령 정보를 안전하게 공유·설정함
     * 연령정보는 보호자 동의하에만 공유되며, 항시 관리 가능함

새로운 App Store 손쉬운 사용 및 App Store Connect 기능들

     * 손쉬운 사용 취급 개요표 도입으로 앱/게임의 접근성 기여도 사전 확인 가능함
     * 개발자는 VoiceOver, 음성 명령, 큰 텍스트, 자막 등 지원 여부를 직접 등록함
     * 제품 페이지에 접근성 정보, URL 추가 가능함
     * App Store Connect 앱 업데이트로 TestFlight 스크린샷·충돌 피드백 확인, 푸시 알림 수신 등이 가능해짐
     * App Store Connect API 확장으로 웹훅, 실시간 업데이트, Game Center 구성, 백그라운드 애셋 지원

출시 정보

     * 이번 업데이트로 Apple Intelligence 기능은 iPhone 16 전 모델, iPhone 15 Pro/Pro Max, iPad mini(A17 Pro), M1 이상 iPad 및 Mac 등에서 이용 가능함
     * 지원 언어: 영어, 프랑스어, 독일어, 이탈리아어, 포르투갈어(브라질), 스페인어, 일본어, 한국어, 중국어(간체) 등, 연말까지 추가 제공 예정
     * 모든 기능은 Apple Developer Program 및 Apple Beta Software Program에서 순차적으로 테스트 가능

        Hacker News 의견

     * AI 관련 기능들도 멋지지만, ""Containerization framework"" 발표는 정말 큰 이슈라는 생각임. 만약 Mac에서 리눅스 컨테이너를 네이티브로 쓸 수 있다면 내 전체 워크플로우가 바뀔 수 있고, Docker로 인한 골칫거리도 한결 줄어드는 전망임
          + 참고로 CLI 툴과 백엔드용 레포는 각각 https://github.com/apple/container와 https://github.com/apple/containerization 참고 가능. 설명을 보면 기존 WSLv1처럼 시스템 콜을 번역하는 게 아니라 VM 기반 컨테이너 지원 방식임. API로는 빠른 부팅을 위한 최적화 리눅스 커널 생성, 경량 VM 실행, VM 환경 관리 등이 포함됨
          + 이미 있는 기술을 조합한 것이지 완전히 새로운 것은 아니라는 의견임. 하지만 Apple이 모든 요소를 멋지게 통합했다는 게 중요 포인트임. 직접 조립해야 했던 개발 환경을 배터리 포함 완제품으로 제공해주는 것 자체가 엄청난 가치임을 강조하고 싶음
          + 리눅스 컨테이너가 macOS에서 ‘네이티브’로 돌아간다는 건 기술적으로 불가능함을 지적, 컨테이너는 본질적으로 리눅스 커널 기능에 의존함. 결국 Apple이 자체 리눅스 가상화 계층(Wsl, Orbstack처럼)을 구축했다는 것 같은데, 만약 단순히 LXC만 지원한다면 대다수 개발자는 Docker Desktop을 오늘처럼 계속 직접 설치하고 쓸 전망임
          + 컨테이너라이제이션은 Swift로 작성된 오픈소스 프로젝트라며, Mac에서 리눅스 컨테이너를 쉽고 안전하게 빌드, 실행, 배포하는 단순하면서도 강력한 기능을 제공함을 WWDC2025 공식 영상에서도 안내함 https://developer.apple.com/videos/play/wwdc2025/346/
          + 컨테이너 기능이 멋지지만 말처럼 혁명적인 변화는 아니라는 생각임. 이미 Podman, Orbstack, Colima 같은 대안도 쓸 수 있음. Apple이 어떤 오픈소스 프레임워크를 썼는지는 잘 모르겠지만, 기존 툴의 OS 레벨 통합판이라고 보임. 개발자는 확실히 편해지겠지만, 게임체인저라고까지 느끼진 않는 중임
     * Apple Developer를 위한 Xcode 26 업데이트에 진짜 흥미로운 개선점이 많았음. 새로 추가된 생성형 언어 모델 기반 Foundation 프레임워크는 Swift 친화적이고, 모든 게 로컬 디바이스에서 돌기 때문에 Apple 개발자에겐 꽤 반가운 변화임. ‘여행 일정 제안’ 샘플 앱이 State of the Union에서 데모로 공개됐고, ChatGPT 등 생성형 모델을 직접 Xcode에 통합한 vibe-coding도 이제 네이티브 도입됨. 모델이 반복적 코드 변경을 추적해 롤백이 쉬워지고, 내 코드 전체 맥락을 파악해주는 걸 보면 번거로운 GPT 플러그인 시대에서 탈출하는 퀄리티 오브 라이프 개선으로 기대됨. 종이 냅킨 스케치만 등록해도 프로토타입 UI를 바로 뽑아주는 건 Objective-C 시절 직접 메모리 관리하던 내 과거 입장에서 보면 신기한 광경임. 완전 혁명적이진 않지만 Apple답게 UX를 제대로 다듬어 완성도 높은
       경험을 예고하고 있음. 물론 실사용 성능은 직접 써보며 판단이 필요함 https://news.ycombinator.com/item?id=44226612
          + 모델이 로컬에서 돌아간다는 게 토큰 사용 같은 걱정이 필요 없는 이유인지 문의하는 의견임, 즉 중앙 서버가 아니라 디바이스에서 직접 실행되는 구조임을 궁금증으로 제기함
     * Liquid Glass 기반의 새 디자인을 보면 UI 디자인 트렌드도 마치 패션·영화·건축처럼 과거 아이디어 재활용 단계에 진입한 느낌임. 공식 평가라기보다는 최근 Android 디자인 변화 같은 곳에서도 비슷한 분위기를 느끼는 순수 관찰임 https://en.wikipedia.org/wiki/Aqua_%28user_interface%29
          + 내 눈에는 이번 변화가 오히려 Windows Vista의 Aero 스타일을 더 많이 닮았다는 느낌임, Aqua 보다는 Vista 쪽에 가깝다고 생각함
          + 다시 텍스처와 질감이 돌아오는 게 너무 반가움을 표현. iOS 7 이후로 UI가 너무 밋밋했는데, Halide 개발자인 Sebastiaan de With의 최근 글에서 새로운 UI 물성감에 대해 좋은 분석을 보았음 https://www.lux.camera/physicality-the-new-age-of-ui/
          + 개인적으론 이번 디자인이 별로임. 시연 영상에서 유리질감이 너무 투명하여 가독성이 매우 떨어지는 장면이 자주 있었다는 점을 지적하고 싶음
          + 과거에는 이런 변화가 흥미로웠으나 이제는 번거롭거나 의문스러움이 먼저임. UI의 진짜 가치는 빈번한 변화가 아닌 안정성임. 전통 매체에서 화려한 마케팅 포인트로 써먹으려고 만든 일회성 ‘반짝 효과’ 냄새를 강하게 느끼는 상황임
          + 나 역시 보통 Apple UI 변화에 우호적인데, 이번엔 예시로 든 화면들이 전반적으로 저렴해 보였음. 실 제품을 직접 쓰면 더 낫게 느껴질지도 모르지만, 현재 공개된 스크린샷이나 데모에서는 아직 설득력이 부족함
     * 잠깐 ‘Containerization Framework’가 macOS 자체에 컨테이너가 생기는 건가 기대했었음. 사실 리눅스 컨테이너, VM을 Mac에서 가상화로 돌리는 건 이미 쉽고 다양한 옵션이 있음. 상용 앱 쓸 각오가 있다면 OrbStack이 가장 매끄럽고 무료 대안으론 Lima/Colima, Podman Desktop, Rancher Desktop 모두 훌륭함. 하지만 macOS만의 진짜 컨테이너 기능이 절실히 부족하다는 사실이 큰 문제임. 써드파티가 Apple 협조 없이 이런 기능을 만든다는 건 거의 불가능하고, 기존 시도가 몇 개 있었지만 대부분 중단된 상황임(예: https://macoscontainers.org/, https://github.com/macOScontainers). 그나마 남아 있는 프로젝트(예: https://github.com/Okerew/osxiec)도 macOS 특성상 제약이 너무 큼. 이런 기능이 있었다면 정말 실질적 수요와 가치를 채웠을 것임. 하지만 실상은 Apple이 오히려 OrbStack을 공식화한 수준이 아닌지
       의구심임
          + macOS 컨테이너가 과연 어떤 용도로 유용할지 질문하는 사람이 있었음
          + macoscontainers 프로젝트가 ‘텅 빈’ 게 아니라 실제 사이트는 https://darwin-containers.github.io 참고 가능함을 정정하는 의견임. 개발자가 굉장히 피드백에 빠름. Apple이 타 플랫폼에 비해 환경 일관성을 엄청 중시하는 것이 컨테이너/자동화에 제한이 많은 주요 원인임을 지적함 https://github.com/darwin-containers
     * 약 15년 전, 어떤 친구가 “Apple은 결국 OSX와 iOS를 아이패드에서 합칠 것”이라고 예언했는데, 해마다 열리는 키노트마다 한 걸음씩 그쪽으로 가는 느낌이었음. 이제 아이패드는 맥북에어와 거의 비슷한 수준임. 비디오 편집, 컴파일러, 3D 작업자가 아니라면 아이패드로 충분할 정도임
          + 15년째 실제로 합치지 않은 걸 보면 Apple은 두 플랫폼을 병합할 생각이 원래부터 없다고 추측함. 같은 시간 동안 Apple은 맥북을 칩셋부터 완전 새로 설계함. 하드웨어와 소프트웨어 모두 병합에 장벽은 없지만, 에코시스템이 본질적으로 완전히 다름. 전문가용 기기는 사용자의 완전한 제어권을 제공해야 하는데, Apple은 i-Device에 그런 권한을 맡기지 않으며, 30% 수수료 수익을 포기할 의도도 없음
          + 실제로 보면 대부분 사용자는 노트북이 낫다는 입장임. 아이패드는 펜슬로 그림 그리거나 미디어 소비에 최적인 반면, 작업 효율과 파워, 인체공학적 측면에서 맥북이 훨씬 우월함
          + 아이패드를 따로 많이 쓰진 않지만, 그 진화 과정을 지켜보는 자체가 흥미로웠음. 사실상 MacOS를 올릴 수 있음에도 Apple은 그렇게 하지 않음. 만약 Apple이 오늘 노트북을 완전히 새로 만든다면 오히려 지금의 폐쇄된(Walled Garden) 방식으로 설계할지도 모른다는 생각임. ‘파워 유저형’ 데스크톱 경험(윈도우 분할, 파일 관리 등)이 아이패드 쪽에서 어떻게 변주되어 갈지 앞으로 궁금함
          + 궁극적으로 두 플랫폼을 합칠지는 모르겠으나(의심함), 지난 15년간 점진적으로 유저 경험을 비슷하게 만들면서 억지 통합을 피한 Apple의 행보가 최선이었다고 봄. Microsoft는 윈도우 태블릿·데스크톱을 합치려는 욕심이 강했고, 혁신도 조금 있었으나 ipadOS/macOS만큼 매끄럽진 못함
          + 아이패드 하드웨어는 M 시리즈 칩을 그대로 사용함. 즉 하드웨어적으로는 macOS 구동에 전혀 제약이 없지만, 병합할 경우 제품 라인업을 스스로 잠식하게 되기 때문임
     * WWDC 같은 대형 행사 때 HN에 주요 포인트를 임팩트 우선순위별로 정리하는 ‘컨퍼런스 소감’ 쓰레드가 있었으면 좋겠음. <br>P4: Foundation 모델은 입문자에겐 좋지만 대체 불가이고,<br>P4: 새 컨테이너 기능도 1초 미만 빠른 초기화가 필요할 때 외엔 딱히 가상화 분야에 큰 뉴스 없음.<br>P2: concurrency가 Instruments에서도 보이고, 고성능 추적이 가능해지며, 샘플링 오류도 회피 가능해져 4년 넘는 블랙박스 추정의 시대가 드디어 끝날 조짐임(게다가 concurrency 백트래킹이 메인스레드 default로 돌아가는 방식이 해결책이라니).<br>P5: UI 전체가 바뀐 것처럼 보여도, 실상은 새 API가 거의 늘지 않아 겉치레에 불과함도 지적. 전체적으로 보면 L&F, 앱 인텐트, 위젯 등만 부각되고, 정말 이게 전부냐는 우려가 들 만큼 콘텐츠 양 자체가 미흡함.<br>품질도 낮다고 생각함: 온라인
       자료가 제대로 안 열리고, 미완성 기술이 발표를 채우고 있음. Swift+Java 상호운용성도 아직 쓸만한 수준이 전혀 아님. 많은 세션이 단순 API 문서 링크거나, 이미 다른 세션에서 말한 내용 반복일 뿐임.<br>그리고 업그레이드 강제 요인도 주의: AI 관련 메모리 요구사항에 더해 새 concurrency 추적 기능이 M4 이상 기기만 대응임
     * ""250,000개 이상의 API로 개발자들이 Apple 하드웨어, 소프트웨어에 앱을 통합 가능""이라는 발표는 인상적이라기보다 오히려 정신이 아찔함
          + 그렇게 많다면 실제로 어느 API를 정리하거나 없애주면 좋겠냐는 질문을 건넴
     * 예전 논의가 놀랍게도 현실이 되고 있음 https://github.com/apple/ml-fastvlm/issues/7
     * Containerization.framework 및 Container 툴 관련 공식 영상이 공개됨 https://developer.apple.com/videos/play/wwdc2025/346. 각 컨테이너가 독립 VM에서 구동되고, Swift로 구현된 ‘vminitd’라는 경량 인잇(init) 프로세스로 부팅된다는 점이 흥미로움. 지원 커널 종류나 ARM/Intel 대응 범위 등은 아직 추가 확인이 필요함 https://github.com/apple/containerization
"
"https://news.hada.io/topic?id=21368","LLM 지원 프로그래밍의 시대, 현재 Swift는 생산성이 떨어짐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  LLM 지원 프로그래밍의 시대, 현재 Swift는 생산성이 떨어짐

     * Swift 6와 최신 iOS 앱 개발에서는 LLM 기반 툴의 활용도가 현저히 낮아, 안드로이드(Kotlin, Compose, Cursor 활용) 대비 생산성 격차가 크게 벌어짐
     * Android 팀은 최신 기능을 오래된 OS까지 지원하며 빠른 개발이 가능하지만, iOS 팀은 최신 Swift 6 문법과 기능 제약, 프레임워크 지원 부족으로 생산성 저하 및 코드베이스 전환 부담을 경험함
     * LLM이 Swift 6의 새로운 동시성 모델(concurrency)과 복잡한 패턴을 이해하지 못해, LLM의 코드 자동화/가속 능력이 제한됨
     * Swift 6의 도입 자체는 일부 개발자에겐 긍정적으로 평가되지만, LLM 툴과의 호환성 부족이 문제로 지적됨
     * Android, Compose, Cursor 등 Google 생태계의 역호환성과 개발자 친화적 접근이 부각되며, Swift/Apple 쪽의 프레임워크, API 업데이트 속도에 대한 불만이 이어짐
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Swift 6와 LLM 시대의 개발 생산성

  iOS vs Android 개발 생산성 체감

     * 작성자는 소규모 iOS 팀에서 Swift 6로 새로운 앱을 개발 중이며, 소규모 Android 팀과 동시에 개발을 진행하고 있음
     * Android 팀은 Kotlin, Compose, Cursor 활용으로 빠른 속도와 최신 기능 지원이 가능, 2019년 출시된 Android 10까지 폭넓게 대응
     * iOS 팀은 iOS 16(2022) 이상만 지원 가능, 최신 Swift 6의 도입으로 Observable, 제네릭 parameter packs 등 다양한 기능 제약을 겪음

  Swift 6와 LLM의 부조화

     * Swift 6에서의 대대적인 문법·프레임워크 변화가 LLM(대형언어모델) 지원 시기와 겹치며, LLM이 Swift 6의 새로운 concurrency 시스템을 잘 다루지 못함
     * 코드를 자동으로 생성하거나 추천하는 LLM 툴(예: ChatGPT, Claude, Cursor 등)이 Swift 6 관련 데이터와 패턴을 충분히 학습하지 못해 정확한 코드 생성에 한계 발생
     * 개발자는 LLM이 제대로 이해하지 못하는 부분을 수동으로 맥락 설명, 규칙 추가 등으로 보완해야 함 → 생산성 저하와 반복작업 초래

  커뮤니티 의견 및 경험

     * 일부 iOS 개발자들은 안드로이드의 API 역호환성, Compose UI의 완성도, Cursor 도구 등에 부러움을 표현
     * Swift 6 도입이 잘못된 선택이라는 의견도 있으나, 실제로는 새로운 패턴과 학습 필요성을 인정하면서도 코드의 표현력과 품질이 높아졌다는 긍정 평가도 존재
     * Apple의 주요 프레임워크가 아직 Swift 6 동시성(concurrency) 체계에 맞춰 제대로 업데이트되지 않아, GCD와의 혼용 사용 등으로 코드 복잡성 및 생산성 저하 경험 공유
     * 일부 팀은 Swift 6 도입을 미루고, 기존 코드베이스와의 호환성 문제를 우선 해결 중임

  안드로이드와 애플 생태계의 차이

     * Android는 새로운 API의 역호환(Backport) 정책으로 개발자 생산성 강화, 오랜 기간의 단점(조각화, 기기별 버그 등)을 극복 중
     * 반면 Apple은 프라이빗/제한적 API 및 느린 업데이트 정책으로 개발자가 반복적으로 유사 기능을 직접 구현해야 하는 부담이 존재
     * Compose, Cursor 등 AI·자동화 툴 도입으로 Android 개발 생산성은 더 빠르게 향상되고 있음
     * iOS, Swift 개발자는 LLM 활용이 어려운 시점에서 개발 트렌드 변화와 커리어 포지션에 불안감을 느끼는 사례 증가

결론 및 현업 시사점

     * Swift 6 자체의 혁신성과 코드 표현력은 높게 평가되나, LLM·AI 코딩 툴의 한계로 당분간은 수작업과 반복 설명이 불가피
     * 빠른 개발, 최신 기능 활용이 필요한 프로젝트에서는 Android + Compose + Cursor 조합의 생산성이 압도적
     * Apple이 프레임워크 및 도구 생태계 업데이트를 신속히 진행하지 않는 한, Swift 6 도입 현장에서는 생산성 저하와 LLM 활용 한계를 감수해야 함

   전반적으로 맞는 말이지만 MLX로 로컬모델들을 Apple Silicon 기기에서 잠시 실행해본 입장에서 100% 동의하기는 어렵네요.

   참고로 모델 개발할때 mlx로 포팅해야한단 부담도 있고, mps를 활성화시켜도 체감상 cpu보다 약간 연산이 빠른 정도라 아직 불편쓰입니다.

   아.. 아프네요 뼈맞았다...
"
"https://news.hada.io/topic?id=21374","FSE가 FBI를 만남","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              FSE가 FBI를 만남

     * FSE(Freespeech Extremist) 서버가 미 연방수사국(** FBI**)의 데이터 수집 대상이 된 경험을 공유함
     * FBI는 사설 업체(SocialGist 등) 에 비용을 지불해 각종 포럼, 페디버스 데이터를 대규모로 스크랩하여, 내용 분석과 키워드 기반 분류, 감성분석에 활용함
     * 서버 운영 과정에서 악의적 유저 탐지, 트래픽 분석·추적 노하우, 그리고 데이터 포이즈닝이나 우회적 크롤링 대응 경험을 기술함
     * BoardReader와 같은 자료 수집 기업들이 공격적 크롤링·프록시 우회로 서버를 계속 스캔하였고, FBI 데이터 연관성도 드러남
     * 이러한 사례를 통해 페디버스 서버 운영자 및 IT업계에게 데이터 보안, 관찰 및 대응력을 높일 필요성을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

FSE가 FBI를 만남

   Pete, 2025년 4월 6일

개요 및 사건의 전개

     * FSE(Freespeech Extremist) 관리자는 서버의 UGC, 크롤러, 연방 수사기관 데이터 수집 전반에 대한 이상 경험을 공유함
     * FBI와의 실제 접점 및, 데이터가 어떻게 스크랩되어 실제로 수사기관 내부 시스템 및 Facebook 기반 조직화 인터페이스로 유입되는지 분석함
     * 본문의 주요 내용은 서버 로그 분석, 악성 이용자 대처, 트래픽 이상 탐지 방법론과, 데이터 스크래핑 업체의 우회 접근, 이들과 법집행기관의 연결 고리임

사건의 뿌리 – 불법 콘텐츠의 위협

     * 페디버스 내 아동 성범죄자 유입이 서버 존재 자체를 위협하는 가장 심각한 리스크임
     * FSE는 표현의 자유를 중시해 관리하였으나, 불법적 행위 발생 시 철저히 기록을 남기고 적극적으로 차단·공개함
     * 타 인스턴스의 허위 블록 및 오해로 인한 정보 왜곡, 외부 정보기관(예: FBI)으로 데이터가 넘어가는 구조에도 유의함

기술적 대응 및 로그 분석 크래시코스

  서버 운영에서의 이상 징후 진단

     * 서버 소프트웨어의 한계, 비정상 트래픽, 크롤러/봇/스캐너로 인해 공개 서버는 항상 ‘Weird’에 노출됨
     * 효과적으로 대응하려면 awk, tail -f, whois, tcpdump, traceroute, Shodan 등 텍스트 및 네트워크 분석 도구 습득 필요
     * 웹서버 로그 포맷 커스터마이징(TSV 등), 리소스별 응답 시간 기록, 이상값 탐지 등 실시간 데이터 흐름 파악법 소개
     * 간단한 통계 분석(평균, 표준편차, 이상치 알림) 을 활용하여 DDoS, 크롤링 등 비정상 상황 식별 가능

경험에서 쌓인 ‘흉터 조직’과 대응 방안

     * 초기에는 일반적 스패머 및 자동화된 가입 이슈를 맞닥뜨림
     * 대량 등록 방지 목적으로 로그와 연동된 이메일, 음성 알림, nginx 레이트리밋 등 자체적 경량화 도구 제작·운용
     * CAPTCHA, 이메일 인증 도입 대신 개인정보 최소화 정책과 수작업 패스워드 리셋 도입
     * 대부분의 솔루션을 직접 구현해 유연성, 속도, 신속한 대응력 확보

BoardReader와 FSE, 그리고 크롤러 탐지

  BoardReader 크롤링 경위와 분석

     * 기존에 알지 못했던 BoardReader라는 업체가 FSE 데이터를 포럼 게시글로 인식, 대량 크롤링함
     * 크롤러는 여러 IP, 레지던셜 프록시, Tor, 다양한 UA, 심지어 크롬 세션 재생 등 우회를 시도함
     * 429(스로틀링), 401/403(권한/금지) 오류를 보내면 오히려 더 많은 요청 반복 시도
     * 결국 402(Payment Required) 등 다양한 응답으로 차단을 지속했고, 대화도 시도하였으나, 계속해서 우회로 데이터를 수집함
     * 크롤러 우회 패턴을 식별하고, 추적 중 SocialGist와 연결 관계 및 FBI 연루 정황 파악

  BoardReader·SocialGist와의 실제 교신

     * 반복된 크롤링에 대해 BoardReader와 SocialGist에 공식 문의, ‘크롤링 중지 및 info@boardreader.com 응답 요청’ 시도
     * SocialGist 측에서는 형식적인 답만 제공하고 실제로는 계속 우회를 지속, 약속 불이행이 확인됨
     * 서비와 추가적으로 개발자 IP 추적(세르비아 ISP, devtools.boardreader.com) , 내부적으로 페디버스 아키텍처 안내 진행

FBI의 직접적 개입

  FBI 문의 경위 및 파악

     * Dave(SocialGist)와의 교신 도중, fbi.gov 주소로부터 ‘긴급 공개 요청(Emergency Disclosure Request)’ 제목의 공식 메일 수신
     * FBI 요원은 ‘WitchKingOfAngmar’라는 이용자의 신상정보 요청 및 게시글 스크린샷을 첨부하여 문의함
     * 해당 게시물은 FSE가 아니라 sneed.social 산하의 게시글임에도, 크롤러가 FSE에 귀속시켜 DB에 등록하여 오인 유발
     * FBI의 스크린샷에는 포럼형 목록, 감성분석, 관련 키워드(‘kill blackrock’, ‘larry fink’ 등) 하이라이트가 포함됨
     * SocialGist의 Relay, BoardReader의 데이터 아키텍처 결함, FBI의 구조적 오해, 실제로는 페디버스 분산 특성과 시스템적 혼동이 드러남

  FBI와의 후속 대처

     * FSE 관리자는 FBI에 원 게시글이 FSE 산하가 아님을 설명, 원 게시자의 인스턴스를 확인 요청함
     * FBI 요원의 문의가 중지되고, 직접적 대응 종료, 게시글 비공개화 및 긴급 대응 후 서버 서비스 접근을 일시 제한
     * 동 시점 BoardReader는 지속적으로 우회 크롤링을 시도하지만 차단 지속, FBI는 추가 응답 없이 종료됨

결론 및 시사점

     * 이 케이스는 스크래핑 업체와 데이터 브로커, 그리고 국가기관 간 데이터 연계 실제 현황을 구체적으로 보여줌
     * 분산 SNS(페디버스) 서버 운영자가 로그분석, 이상패턴 탐지, 법적 대응, 자동화 차단 도구 구축에 능해야 함을 강조
     * 사회 전체적으로는, 민주적 오픈 웹 시스템이 사적/국가기관 감시 체계에 쉽게 흡수·왜곡될 위험성이 있음을 시사함
     * 최종적으로, 개방형 네트워크 설계 및 운영자 커뮤니티의 정보공유가 효과적인 데이터 보안 방어의 핵심임을 강조함

        Hacker News 의견

     * Fediblock가 사실관계를 체크하지 않아 오해를 일으킨다는 비판이 있었지만, 블로그 글에서 링크된 곳은 단순히 탈페더링(서로 연결을 끊는 것)한 인스턴스 목록에 불과하다는 의견 제시, Fediblock은 이미 몇 년 전에 종료된 서비스고, 공식적인 기준이 아니라 참고용 정보였다고 강조, 블로그 글 저자가 원래 Fediblock 내용을 찾으려다 그 대체 링크를 무심코 쓴 것 같다는 직감 공유
          + 나는 중간 규모의 Mastodon 서버 운영자로, 어떤 사용자가 내게 인종차별적 욕설을 하고 관리자를 신고했지만 아무런 조치가 없었던 경험 후 해당 인스턴스를 차단했던 경험 공유, fediblock이나 커뮤니티 메커니즘은 전혀 관련 없는 결정이고, 자신의 서버 이용자를 괴롭히는 트롤 행위를 한 상대 인스턴스와 굳이 소통할 이유가 없었음 강조, FSE가 누군가 자신들을 음모론적으로 차단한 것처럼 이야기하는 게 오히려 우습다고 생각
          + Fediblock 서비스가 실제로 2023년 9월에 종료됐으며, 기사에서 언급한 대부분의 사건이 이 종료 시점 이전에 일어난 것이라는 사실 지적
     * 이 글이 재밌었던 이유를 분석하며, 먼저 캡차 도입이 실제 이용자에게 피해를 줄 수 있다는 고민에서 시작해 결국 회원가입과 타임라인을 공개로 돌린 뒤에 수많은 문제로 사용자 환경이 오히려 악화됐던 장황한 과정을 적나라하게 보여준 부분에 주목, 커뮤니티 공간을 직접 운영하는 일에는 자신이 절대 도전하고 싶지 않다는 결론을 얻게 됐다는 내적 체험 공유
     * 이 게시글의 매력을 다섯 가지로 요약, 1) 시민 과학 방식으로 FBI 정보수집/감시 메커니즘을 파헤치는 내용, 2) Fediverse 내부의 자잘한 사건, 3) 소규모 서버 운영자 관점의 실용적 시스템 운영팁, 4) 여러 사건의 중심에 있는 torswats 라는 인물과 그 체포까지의 흥미로운 서브 플롯, 5) 지적이고 매끄러운 글쓰기 스타일로 별 5개 만점 평가, 필독 추천
          + 나 역시 이 글이 기술적 디테일이 적절히 가미된 멋진 글이라 생각, Chaos Communication Congress 같은 해커 컨퍼런스에서 발표해도 손색없을 수준 평가
          + 글에서 글쓴이가 잘못된 결론을 내렸다고 지적, FBI가 폭력 위협을 담은 사용자의 스크린샷을 보내면서 정보를 요구했는데도 글쓴이가 단순 허세라고 치부했고 실제로 최근 CEO 살인사건 등 폭력이 일어난 사례를 볼 때 위험성을 과소평가한 부분 지적, FSE 운영자가 연방수사관과 적극 대화한 점은 다행이지만, 위협 캡처를 보고 무조건 무해하다고 결론 내리는 건 위험한 편향이라는 의견 강조
     * 글 내용에 진심으로 감명받았고, 내 세부적인 지적은 검색엔진의 'Negative' 버튼이 감정분석 결과가 아니라 검색결과 부적합(음성적 탐색 실패)로 표시한 것 같다는 해석, 감정분석이 이 시나리오에서 크게 활용될 이유가 없다는 관점 공유
          + 이에 동의하지 않는 의견도 있었고, 'Negative' 아이콘 디자인이 붉은 머리 형태라 부적합 표시라기엔 언어적으로 이상하다는 분석과 감정분석 의미에 더 가깝다는 해석 제시
     * fediblock 덕분에 FSE에 허위 허용 규정이 있다고 오해가 생겼다며, kiwifarms에 소스코드가 있는 사이트를 인용하는 것에 대한 불만 표출, FSE가 차단된 이유는 대부분의 이용자가 'free speech' 집단과 소통하고 싶지 않기 때문이라는 설명 추가
          + 차단 여부와 팩트체크의 상관관계가 없는 것 같다는 피드백, 반감이나 차단은 꼭 팩트체크와 연관된 논점이 아니라는 반박
     * 스크래핑 방어 방식에 대해 더 효율적 기술 방안이 없었는지 제안, 예를 들어 IP나 도메인 레벨에서 유입 차단하는 방법, 혹은 Cloudflare 같은 API 엔드포인트 보호용 외부 서비스 제안, 다만 이런 서비스도 비용 문제가 있고, Free Speech Extremist와 같은 성격의 사이트에는 적합하지 않을 수 있음 언급, 비용적 측면에서도 악성 트래픽 차단이 오히려 절약일 수 있다는 의견 제시
          + 실제로 나 역시도 스크래핑 IP 차단 명령을 서버에 내렸지만, 금세 미국 내 주거용 신규 IP(프록시)로 시도하는 패턴을 보았다는 실전 경험 공유
     * FSE에서 소아성애자 문제가 드러났다고 지적, 이것이 Fediverse 전반의 문제이고, Discord 같은 곳도 해당된다고 부연
          + 실명 사용이 없어 사진 업로드가 가능한 아무 온라인 공간에서나 비슷한 문제가 벌어진다는 공감
          + Signal이나 Telegram 같은 익명 메신저 플랫폼도 동일 문제 위험성 지적
     * FSE(Free Speech Extremist)이 왜 '극단주의자(extremist)'라는 꼬리표를 받아야 하는지 질문, 미국 헌법에 보장된 표현의 자유를 중시하는 나라에서 굳이 극단주의자여야 하냐는 의문 제기
          + 저자 특유의 유머감각으로 볼 때 이 표현 자체가 일종의 농담에 가까움을 지적, 실제로 표현의 자유의 범위와 한계를 두고 미국 법체계 내부에서도 계속 논쟁이 이어지고 있고, FSE 인스턴스 정책이 '법적으로 허용된 말은 역겹거나 불쾌해도 원칙적으로 허용' 취지에서 운영된다는 분석, 자신도 원칙에 공감하지만 현실에서 다 따를 용기는 없다는 솔직한 의견, 반대로 연합 내 다른 대부분 인스턴스들은 엄격 규정과 차단 리스트를 운용한다는 배경 설명, 관련 링크도 제공
          + 이런 화두를 던지는 자체가 FBI가 헌법상 의무를 회피하거나 직접 위반하고 있음을 보여주는 에피소드에서 더욱 중요해진다는 지적
          + 'Extremist'는 'radical'의 비하적 표현이고, 역사적으로나 문화적으로 논쟁꺼리였던 포지션을 누가 갖든 라벨은 붙게 되는 것이 현실이라는 점 언급
          + 미국 헌법의 권리가 절대적이지 않고 법원에서도 명확한 한계를 언급했기 때문에, 현실에서 제한 밖을 주장할 경우 반대하는 사람들은 쉽게 '극단주의'라고 낙인찍게 됨 설명
          + 극단주의자는 언제나 한 가지 가치를 다른 모든 가치보다 우선시하는 특징이 있는데, 예를 들어 숨쉬기를 밥 먹기, 물 마시기보다 절대적으로 중시한다면 단기적으로는 맞아도 중장기적으로는 문제가 생길 수 있다는 교훈적 비유로 다양한 균형 필요성을 전달
     * 온라인 공간 운영이 현실적으로 굉장히 고된 일임을 한 문장으로 요약
     *
"
"https://news.hada.io/topic?id=21373","애플, 모든 플랫폼에 통합된 유니버설 디자인 도입 - "Liquid Glass"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              애플, 모든 플랫폼에 통합된 유니버설 디자인 도입 - ""Liquid Glass""

     * 애플이 모든 주요 플랫폼에 적용되는 새로운 소프트웨어 디자인을 발표함
     * Liquid Glass라는 투명하고 반응형 신소재를 도입하여, 각 플랫폼에서 더 생동감 있고 집중도 높은 사용자 경험을 제공함
     * 새로운 디자인은 iOS 26, iPadOS 26, macOS Tahoe 26, watchOS 26, tvOS 261 등 모든 애플 기기에서 일관성을 유지함과 동시에, 각 플랫폼 고유의 느낌을 보존함
     * 앱 컨트롤, 내비게이션, 아이콘, 위젯 등 전반적인 UI 요소가 Liquid Glass로 재설계됨
     * 개발자들은 SwiftUI, UIKit, AppKit을 통해 쉽게 새로운 디자인을 앱에 적용할 수 있는 최신 API를 제공받음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

애플의 새로운 소프트웨어 디자인 개요

     * 애플이 기존의 친숙한 느낌을 유지하면서, 앱과 시스템 경험을 더욱 표현력 있고 즐거운 방향으로 바꾼 새로운 소프트웨어 디자인을 선보임
     * 핵심 소재인 Liquid Glass는 주변 환경을 반사·굴절시켜 컨텐츠에 집중을 더하며, 각종 컨트롤 및 인터페이스 요소에 새로운 활기를 불어넣음
     * 이번 업데이트는 iOS, iPadOS, macOS, watchOS, tvOS 등 거의 모든 애플 플랫폼에 걸쳐 동일하게 적용됨과 동시에, 각각의 특성도 유지함

Liquid Glass: 새로운 표현을 위한 재료

     * visionOS에서 착안한 입체감과 깊이감에서 영감을 받은 디자인임
     * Liquid Glass는 주변 컨텐츠와 환경에 따라 색상이 실시간으로 변하고, 빛의 스펙큘러 하이라이트를 통해 역동적인 반응을 보여줌
     * 버튼, 스위치, 슬라이더, 텍스트, 미디어 컨트롤 등 일상적인 인터페이스 요소부터 탭 바, 사이드바 등 대형 UI까지 폭넓게 적용됨
     * 시스템 전반(락 스크린, 홈 스크린, 알림센터, 제어 센터 등)에서도 Liquid Glass의 활기 넘치는 특성이 발현됨

앱 디자인의 변화

     * 앱 내 컨트롤, 툴바, 내비게이션이 하드웨어의 라운드 모서리와 일치하도록 재설계되어 소프트웨어와 하드웨어, 컨텐츠 간 조화가 극대화됨
     * Liquid Glass로 제작된 컨트롤은 앱 위의 별도 레이어로 동작하여 컨텐츠 중심 경험을 제공함
     * 사용자의 이동 및 옵션 필요 상황에 따라 컨트롤의 모양과 기능이 부드럽게 변화됨
     * 탭 바와 사이드바 역시 새롭게 설계되어, 예를 들어 iOS 26에서는 스크롤 시 탭 바가 작아져 컨텐츠에 집중도를 높임
     * 해당 변화는 Camera, Photos, Safari, FaceTime, Apple Music, Apple News, Apple Podcasts 등 주요 앱 전반에 적용됨

플랫폼 전반의 향상된 경험

     * 새로운 디자인은 락 스크린, 홈 스크린, 데스크톱, Dock 등 시스템 전반에 적용됨
     * 락 스크린 내 사진 배경화면 위의 시계도 Liquid Glass로 제작되어, 인물 사진 뒤로 자연스럽게 배치됨
     * 홈 스크린 및 데스크톱의 Dock, 앱 아이콘, 위젯 등이 Liquid Glass의 레이어로 제작되어 사용자가 더 다양한 개인화 옵션을 누릴 수 있음
     * macOS Tahoe 26에서는 밝고 어두운 테마, 컬러 틴트, 투명 메뉴 바 등으로 경험이 더욱 확장됨

개발자를 위한 동적 앱 빌드

     * SwiftUI, UIKit, AppKit을 사용하는 개발자들은 새로운 디자인을 손쉽게 적용할 수 있도록 최신 API를 제공받음
     * Liquid Glass와 새로운/업데이트된 컨트롤을 이용해 앱의 반응성과 즐거움을 대폭 강화할 수 있음

   공식 소개 페이지에서 조차 가독성이 저 꼴이면 대체…이쁘긴 합니다만…

   Liquid Glass로 정보의 양이 많은 전문가용 프로그램을 리디자인하면 얼마나 작업환경이 더 퇴보될지 궁금합니다. 이런 류의 UI 변화를 끄는 걸 accessibility 메뉴 안에서 찾아야 한다는게 조금 당혹스럽습니다.

   남들은 돈 써가며 치킨 게임으로 언어 모델 만들고 있을 때

     Liquid Glass는 유리의 광학적 특성에 유동적인 감각을 결합한 형태로, Apple만이 구현해 낼 수 있다.

   오직 Apple만이 구현 할 수 있는 고오급 유리 UI를 만들어 내다니
   숭배합니다, GOAT

   치킨 게임 안 해도 버는데 돈을 태우는게 어리석죠 LLM에 해자는 없다가 업계 리더들의 중론이잖아요

   넵 그래서 숭배했습니다

   별로라는 의견도 많지만, 전 AR에 잘 어울리겠구나라고 생각이 드네요.
   애플 입장에선 이거 한번 결정하면 꽤 오래 유지할것이고, 곧 나오게될 애플 글래스랑 비젼프로 차기 제품까지 다 대응하려고 만든 거 같아요.

   이게 .. 맞나?

   소개 영상에서 버튼 굴절효과를 보자마자 멀미가 나네요. 왜 실용성은 뒷전인 채 UI로 예술을 하려고 하는지 모르겠습니다

        Hacker News 의견

     * 모든 버튼과 메뉴가 이제 반투명 레이어로 바뀌는 현상 목격, 배경의 잡음이 텍스트를 더 알아보기 어렵게 만들어 접근성 악몽 수준 체험 영상에서 몇몇 장면은 내가 텍스트를 읽는 데 극도로 어려움을 느끼게 하던 장면 확인, 멋지고 미래지향적이긴 하지만 영화 속에서나 어울릴 스타일로 느껴짐 자폐 스펙트럼에 있지만 이런 변화는 자폐인뿐 아니라 많은 사용자에게도 문제 될 것 같음, 반드시 눈에 띄는 기능으로 끄는 방법 제공 필요성 희망
          + 이 디자인은 성능 문제도 유발 가능성 큼 ""새로운 하드웨어 덕분에 할 수 있었다""고 언급하는 건 결국 구형 기기에서는 느린 성능 경험 의미함 이전 회사에선 레이어 블렌딩 성능 저하 때문에 거의 모든 투명 효과 금지 정책 있었고, 디버깅 툴로 모든 레이어가 불투명한지 수시로 확인함
          + 이번 변화가 아이러니하게도 이 디자인 명작의 20주년과 맞물림 링크 개인적으로는 꼭 새 디자인이 필요했는지 의문, Siri가 아직 준비 안 되어 뭔가 새로운 걸 보여줘야 했던건 아닐지 오히려 iCloud+를 강화했으면 했지만, 일반 사용자를 끌어모으긴 어렵단 현실 인식
          + 시각적 안정성이나 눈의 피로를 줄이고 싶은 사람이라면 누구나 동일한 문제 경험 가능성 큼 이러한 옵션을 끌 수 있다고 해도 디자인의 미적 매력이 그 위에 있다면 결국 '2류' 버전을 쓰게 되는 셈 이미 많은 이유로 Linux로 넘어갈까 고민 중이었는데 이게 결정적 계기 될 듯 VisionOS에 초점을 맞춘다는 전략은 UX 측면에서 매우 잘못된 방향임; 증강현실에선 배경 노출이 필수지만, 일반 기기에서는 그렇지 않음 근본적 맥락 차이 감안할 때 이런 선택은 안타까움
          + 자폐인은 아니지만 이런 디자인 진짜 이상하게 느껴짐 읽기/가독성을 혼란스럽고 편차 큰 배경에 의존시키는 설계 이유를 이해 불가 통일성이나 일관적 디자인 언어도 전혀 안 보임, 오래가지 않길 바람
          + 아직 끄는 데에도 실패, '투명도 줄이기'와 '모션 줄이기' 옵션 켰는데도 더 끔찍하고 산만한 시각 효과 체험 심지어 그 설정 후 더욱 버벅대는 느낌, 속도도 iOS 18보다 확실히 저하됨
     * 내 나이 티내는 것 같지만, 스큐어모피즘 디자인 이후로는 오히려 계속 퇴보 느낌 당시엔 사용성, 학습 가능성에 집중했고, 실제로 기업들이 수백만 달러를 사용성 연구에 투자함 90~2000년대에 컴퓨터 교육하며 현실 사물과 매핑된 UI가 학습에 엄청난 도움 준 경험 있었음 최근 내 아이들에게 PC 사용법 가르쳐 보니 학교 컴퓨터 시간에도 이제 PC는 가르치지 않고 iPad만 사용, UI는 내부 규칙도 없고 현실 은유도 거의 사라짐 최근엔 UI 요소의 식별성·가시성이 점점 나빠지고 있고, Apple은 이를 더 가속화하는 트렌드 주도 중 Liquid Glass 등장 시기는 고통스러울 것이며, 이를 따라하는 카피 제품들까지 생각하면 더 참담한 시기 예고
          + 스큐어모피즘 디자인에도 성공과 실패가 있었음 현실 사물 모방이 꼭 직관적인 건 아니었음 그래도 '버튼은 버튼처럼', '숨겨진 제스처로 기능 감추지 않기'엔 무조건 공감 예전 메뉴 방식이 훨씬 유저가 원하는 기능을 쉽게 찾아보는 데 유리함, 검색이 빨라지고 있지만, 검색만으로는 '무엇을 찾는지 정확히 모를' 때 불리 이런 이유로 음성비서도 거의 안 쓰게 됨, 사용할 수 있는 문장 리스트조차 부재, 결국 1~2개 명령만 기억하다가 포기
          + 현실 사물 모방이 큰 도움이었다고 하지만 많은 현실 사물 자체가 더 이상 존재하지 않거나 자주 쓰이지 않기에 그 디자인 언어에서 벗어나는 것도 이해 스케일상 'Liquid Glass'가 꼭 필요한지 모르겠음, 아직 체험 전이라 판단 보류 중 '역대 최대' 디자인 업데이트 타이틀도 과장 느낌, System 9→MacOSX 변화가 훨씬 충격적이었음 Apple만의 잘 다듬어진 하드웨어 통합이 관건인데, 다른 회사가 따라하면 완성도 급격히 하락 우려, Apple도 지나치게 많은 기능을 핸드폰에 밀어넣고 있는 느낌; 더 단순한 iOS light 버전 간절히 바람
          + 플랫 스타일이 활성 요소와 설명 텍스트 간 분리 감퇴를 유발했고, 다크패턴적 변화도 확산시켜 사용자를 해칠 수 있음 커스터마이징 성격까지 없애버린 사례도 Linux adwaita 등에서 보임 나이 티나지만 이번 변화 전혀 반갑지 않음 갑자기 Apple이 아크릴 글라스 애니메이션, 화려한 변화로 내부 문제에서 시선 딴 데로 돌리려는 느낌, 성공할지 극히 회의적임 이번 투명도 열풍은 Windows Vista, KDE Plasma 초기에 유행했던 바로 그 트렌드 귀환 느낌
          + ""스큐어모피즘 덕후"" 입장에 강하게 반발하는데, 그래픽 요소는 취향 차이 인정하지만 진짜 싫었던 건 소프트웨어에 쓸데없는 현실 제약 걸어둔 UI였음 예를 들어 Calendar가 실제 달력처럼 월 단위로만 넘길 수 있거나, Podcasts가 릴투릴 기계 그래픽에 괜히 화면 공간 낭비한 점, Contacts앱이 진짜 명함 철의 제약까지 모방했던 시절 같은 현실 제약을 이유로 소프트웨어의 하드웨어 수준 창의성을 억누르는 건 반대, 필요치 않은 현실 제약을 굳이 소프트웨어에 이식하는 건 원치 않음 관련 링크
          + 최근 내 아이들이 다니는 중학교에선 '컴퓨터 응용' 수업에서 PC 내용 포함, iPad만 쓰는 건 아님 경험 공유
     * 전체적으로 Windows Vista의 Aero Glass, iOS 7에서 반복된 3D 반투명 디자인 실수가 재현되는 느낌 이번엔 스큐어모피즘 다시 돌아오길 바람 iOS 7처럼 앞으로 2~3년은 '디자인 조정' 명목 하에 대부분 되돌리는 수순 밟을 것 같은 예감 Forstall 퇴출 뒤 Design을 하드웨어와 소프트웨어 통합으로 관리하게 되면서 본격적으로 Apple UX 하락세 시작된 원인으로 해석
          + Tim Cook이 CEO 된 순간 이런 변화는 예정된 수순, 과거엔 Jobs가 후임으로 Forstall을 선택하지 않은 걸 탓했지만, 실제론 이사회가 다시 간섭한 영향으로 생각 전성기(1997~2011, 167개월)와 비슷하게, 이제는 Jobs 부재 기간이 조만간 더 길어짐
          + 이런 건 실수라기보단 '패션' 자체임, 패션의 좋은 점은 영원히 새로운 것처럼 꾸밀 수 있고, 한참 안 나온 걸 다시 꺼내오면 그게 유행처럼 비출 수 있음 지금은 유리, 10~15년 뒤엔 Material Design이 다시 각광받을 확률 100%
          + 이번 비주얼이 '서리 낀 유리' 느낌이라서 본질적으로 스큐어모피즘적 연장선에 있음, 원했던 유형은 아니지만 어쨌든 실재 소재 모방 시도 중
     * 설치해 보고 정말 좋아하려 했지만 실망스러움 굉장히 산만하고 설정 앱에서 비율이 어색, 'cozy' 스타일 추구하다보니 한 화면에 보이는 옵션이 대폭 줄어들고 스크롤을 계속 해야 하는 불편함 접근성 면에서도 정말 최악, 실제 스크린샷 참조
          + 정말 심각, 기존 제어센터의 투명도는 강하게 블러 효과 줘서 배경이 잘 안 보였지만, 왜 더 투명하고 블러도 줄이는 쪽으로 간 건 도저히 이해 불가
          + 이건 15년 전 탈옥 테마 스크린샷 같은 느낌, 그것도 좋지 않은 테마
          + 살짝 다른 두 격자가 투명 레이어로 겹쳐진 모습은 농담 같기도 하고 실제 장난으로 느껴질 정도
          + 진심으로 ""고마워, 싫다"" 라는 마음이 든 디자인임 테크놀로지의 발전이 실제 사람에게 문제 해결보다 기술 적용이 목적같아진 부분에서 불만 큼 최근 Apple에 많은 디자이너가 존재하고 기기 성능이 올라가자 뭔가 '멋진 일'을 하려는 것 같은데, 정말 아무도 필요 없고 원치 않는 기능만 만드는 듯 두 번째 이유로 나는 선형적 사고를 하며 멀티태스킹/산만함을 힘들어해 투명한 UI 자체가 단일 작업에도 충분히 산만함을 유발, 기술이 계속 주의력을 해치는 또다른 방식으로 전락한 느낌
          + 최종 출시 전 불투명도를 꼭 개선하길 희망 이미지에서 느낀 불쾌감이 커서 현행 디자인에 만족 중, 과거 카메라 버튼/터치바처럼 빨리 사라지길 바람
     * 솔직히 이번 Liquid Glass 디자인은 '끔찍'하다는 생각이 듦 시각적 복잡도가 너무 높아 뇌가 매일 이를 소화하다 녹아내릴 느낌 실사용 전까지 최종 판단은 유보하겠지만, 스크린샷 기준 시각 피로감이 심함, 사용자 맞춤화 가능성 희망 Apple 플랫폼을 오랫동안 즐겨왔지만 이번엔 실망 가능성, 장기간 모든 기업이 결국 실망을 안겨주는 운명 이유인 듯
          + 나도 갈수록 안드로이드로 갈 준비를 하고 있었고, 이번이 마지막 계기 될 듯 10년 넘게 iOS 개발해 왔지만 9월 신형 iPhone, Google Pixel 디자인 따라 최종 전환 결정할 생각
          + 접근성 설정의 Reduce Transparency 켜면 유리 효과 사라지고 최근 iOS의 투명 효과와 비슷한 수준으로 변경되는 것으로 보임
          + Apple이 추구해온 단순함·시각적 명료함 브랜드 이미지와 정면으로 배치돼서 놀라움 이번에 선보인 건 명료함에서 혼돈으로 변한 것 같음 유리를 연상시키는 미묘한 효과와 그림자로만 디자인할 줄 알았고, 실제로 많은 부분은 'translucency'가 아닌 거의 'transparency'에 가까운 수준으로 느껴짐 Apple이 이렇게까지 쉽게 혼란스러울 수 있는 디자인 언어를 낸 게 뜻밖임
          + 전반적으로 대비를 낮추는 움직임 같음, 개인적으로는 높은 대비 선호
          + 1986년부터 Mac 사용자고 Apple 근무 경험도 있는데 최근엔 매일 Linux도 적극적으로 고려하게 됨
     * Apple의 디자인 투자 노력 좋아함, LLM만 붙이는 시대에 디자인이 주목받는 게 신선함 Liquid Glass에 많은 리소스 투입한 게 느껴지고, 완벽하진 않지만 대비 관련 이슈는 더 개선될 것 같음 Electron 기반 앱이 점점 이질적으로 보일 것은 동감, LLM 덕분에 Electron 벗어나 네이티브 UI 회귀하지 않는 점 아쉬움 기업들은 코딩 효율성보단 비용 절감에 더 관심이 있음
          + 2025년에도 디자인에 중점 둔 tech event가 나오는 것 반갑다는 데 공감 가지만, Google도 최근 Android 이벤트에서 Material Design 3 대대적 리디자인 발표함
          + Apple이 AI/Siri는 제대로 진전이 없어서 언급 회피, 외형만 바꾼 '스킨딥' 수준의 발표로 해석
          + 막대한 리소스 오할당이 과연 축하받을 일인지 회의 Electron 앱은 미적 요소는 작은 문제; 실제론 퍼포먼스/네이티브 연동성 부족이 더 큰 문제
     * 이번 반투명·유리 느낌 디자인 언어는 Apple이 AR(증강현실) 인터페이스 통일을 염두에 둔 변화로 봄 AR 글라스에선 완전 불투명 UI 불가, 모든 플랫폼에서 통일된 디자인을 구축하는 현명한 포석 가능성
          + 프레젠테이션 직전 Craig가 visionOS가 변화의 주된 이유임을 명확히 언급, 새로운 UI는 Apple이 visionOS에 지속적으로 올인 중임을 의미
          + 2000년대 MS가 터치 인터페이스를 극단적으로 밀어붙이다 실책 반복한 것과 비슷, 왜 Apple이 이렇게 vision에 집착하는지 궁금
          + 매년 더 무거운 그래픽 효과로 하드웨어 업그레이드 유도하기에도 좋은 방식, 새 OS가 더 무거워질수록 구형 기기는 느려짐
          + AR 글라스에서도 완전 불투명이 왜 불가능한지 궁금
          + 이유 100% AR 인터페이스 대비로 확신
     * 이제는 고해상도 디스플레이, 고성능 GPU 덕분에 UI 인터페이스에도 더 물리적 질감 부여할 수 있는 시대 도래 가능 실제 유리, 금속, 심지어 현실에 없는 소재 효과까지 실현 가능 플랫 디자인은 구현의 쉬움이 핵심 이유였지만, 만약 Apple이 liquid glass 스타일을 간단히 구현하도록 Rectangle().background(.glass) 수준으로 만들어주면 대중적 성공 가능성 높음
          + 할 수 있다고 해서 꼭 해야 하는 건 아님, 새 디자인 적용 결과 읽기/식별/이해가 어려워지면 생산성과 사용성 모두 대폭 하락
          + Microsoft가 이미 Vista나 Windows 7에서 glass 효과 구현, 이제 식상한 트렌드 하드웨어 성능이 좋아졌다고 굳이 UI에 실사 유리 질감 효과를 넣는 게 본질적으로 필요하진 않음 iDevice 전체에 적용되면 전 세계적으로 그만큼의 불필요한 에너지(즉, CO2) 낭비 증가 우려됨
          + 120FPS처럼 엄청난 속도로 프레임 업데이트라는 것도 이해 못함, 정적인 화면에 120fps가 왜 필요한지, 혹시 배터리가 너무 커서 그런가?
          + 더딘 iOS 혁신에 실망, SwiftUI 앱은 UIKit보다 훨씬 느리고, 최신 iOS에서 iPhone 13의 전반적 속도 저하 심각 이번 디자인은 에너지 낭비, 구형 기기 성능 저하, UX 악화만 불러일으킴, 오히려 단점만 부각
          + 게임같이 몰입적 환경에선 동적 프레임필요하지만 메일이나 곡 제목 확인 같은 정보성 화면엔 불필요
     * Microsoft Windows 8 시대의 ""Metro"" 디자인 목표와 의심스러울 만큼 유사함, 이번엔 Apple이 Microsoft보다 데스크톱 경험 덜 훼손하며 동일 디자인을 유지할 수 있을지 기대
          + 여러 업체가 시도했지만 투명 UI는 원천적으로 노이즈 유발, 특히 리얼리즘 추구할수록 refraction 현상이 명확해져 문제 Apple의 Aqua도 playful 했지만 명확성을 헤치지 않아 혁신적으로 느껴짐 VR엔 적합한 요소지만, 데스크톱이나 핸드헬드 환경에서는 오히려 정밀성과 집중력, 사용성 모두에 역행하는 대실패라 생각
          + 이미 macOS 11 리디자인에서 데스크톱 경험이 망가지기 시작 새로운 설정 앱은 근본적 데스크톱 UI 원칙(컨트롤 패널은 스크롤되지 않고, 컨텐츠만 스크롤)까지 깨버림
          + Metro 디자인은 폰에선 잘 먹혔지만 MS가 데스크톱에 제대로 이식하지 못했음 Apple은 OS 전체를 군더더기 없이 새 디자인 언어로 일신하는 데 강점, 반면 Windows는 여러 세대 UI가 켜켜이 쌓여 고대 유물 같은 상태
          + Metro가 데스크톱에'적응'되지 못해 실패, 스마트폰/태블릿/27인치 논터치PC까지 같은 UI 적용 시 신체적 인터페이스가 달라지는데도 제대로 반영하지 않아 억지스러웠음 Apple은 플랫폼별 맞춤성을 잘 제공할 가능성이 높아 그 점만 고려하면 성공할 듯
          + Metro는 플랫 디자인이라 현재 논의되는 Aero Glass 스타일과는 근본적으로 다름, 혼동 지적
     * 이 블로그가 놀랍게도 이번 변화를 미리 예견했음, 개인적으로 glass UI는 Vista 시절부터 늘 좋아했음
          + 아이콘이 싫은 이유 자각 참고 이미지 아이콘은 확대·확대해서 볼 땐 멋지지만, 실제 아이폰처럼 작게 보이면 흐릿하고 다듬어지지 않은 인상, 디자이너가 크게 작업했을 땐 좋아 보여도 현실에선 전혀 다르게 보일 것
"
"https://news.hada.io/topic?id=21367","Cursor의 LLM 클라이언트 리버스 엔지니어링 하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Cursor의 LLM 클라이언트 리버스 엔지니어링 하기

     * TensorZero를 오픈소스 프록시로 활용해, Cursor와 LLM 제공자(OpenAI 등) 사이의 트래픽을 가로채 분석하고, 프롬프트·모델·추론 결과를 실시간으로 관찰 및 최적화 실험한 경험 공유
     * Cursor는 LLM 호출 시 Base URL과 모델명을 오버라이드할 수 있어, 자체 프록시(TensorZero)를 손쉽게 연동 가능
     * 내부적으로 Cursor는 자체 서버를 거쳐 LLM을 호출하므로, 완전한 프록시 구성을 위해 Ngrok + Nginx 리버스 프록시 및 CORS 헤더 세팅이 필요함
     * 프록시를 통해 Cursor가 실제로 LLM에 보내는 system prompt, user prompt, 인라인 코드 편집 요청까지 모두 관찰 가능하며, 다양한 LLM(A/B 테스트)로 실시간 전환/실험이 가능
     * Cursor의 system prompt 분석 결과, 불과 642 토큰 정도의 프롬프트만으로 대부분의 소프트웨어 엔지니어링 문맥을 LLM이 이해·처리함. 코드 편집은 별도의 ""apply model""(덜 지능적인 보조 모델)이 담당
     * TensorZero와 같은 프록시 구조로, 사용자별 맞춤형 LLM 실험 및 피드백 기반 최적화가 가능하며, 이 구조는 코드 보조 도구의 품질 평가(A/B 테스트), 프롬프트 최적화, 실사용 모니터링에 이상적임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

소개

     * TensorZero 오픈소스 프레임워크를 Cursor와 각종 LLM(대형 언어 모델) 사이에 프록시 게이트웨이로 연결한 경험과 이로 인한 관찰, 실험, 최적화 지점을 다룸
     * TensorZero는 피드백 신호(생산 지표, 사용자 행태 등)를 활용해 LLM 애플리케이션의 품질을 높일 수 있도록 도와주는 오픈소스임
     * Cursor 사용자로서 가장 많이 쓰는 LLM 기반 IDE에 이 기술을 적용해, 실제로 어떤 API 요청이 오가는지, 그리고 어떻게 최적화를 직접 시도할 수 있는지 실험함

전체 개요 및 목적

     * Cursor는 사용자 전체를 기준으로 최적화된 코딩 어시스턴트이지만, 개인별 맞춤형 최적화 실험과 데이터 관찰이 거의 불가능함
     * TensorZero를 프록시로 두면, Cursor의 요청과 LLM 응답, 프롬프트, 모델, 인퍼런스 과정 전체를 투명하게 관찰하고, 실험하며, 최적화까지 확장 가능함
     * 대부분의 최적화 및 평가, 실험 방법에는 실제 추론 데이터가 필수이므로, 이를 수집하는 실전 방법과 자동화 방식을 구체적으로 소개함

연동 과정: LLM 게이트웨이 구축

     * Cursor는 OpenAI base URL과 모델명을 사용자 정의로 변경할 수 있도록 지원함
     * TensorZero는 OpenAI 호환 인퍼런스 엔드포인트를 제공하기 때문에, Cursor를 OpenAI 대신 TensorZero로 연결이 가능함
     * TensorZero 내에 cursorzero 함수 등록을 통해, 다양한 모델/프롬프트 실험과 제공사에 종속되지 않는 인퍼런스 및 피드백 데이터 자동화 저장이 가능함

첫 번째 장애물: Cursor 자체 서버

     * Cursor가 로컬 TensorZero에 직접 연결을 시도했으나 실패함
     * Cursor는 항상 우선 자체 서버에 요청을 보내고, 내부적으로 추가 처리 후 LLM 호출을 이어감
          + 이로 인해 자격 증명이 Cursor 서버로 전달되며, 해당 서버가 모든 요청 및 코드베이스에 대한 데이터 수집이 가능해짐
     * 대안으로, OpenRouter로 연결하며 일부 Cursor 내 상호작용에서 외부 모델 이용 가능 여부를 점검함
     * Cursor의 Tab 자동완성은 자체 비공개 모델로 동작, 다른 LLM과 조합 가능함
     * 최종적으로 reverse proxy와 Ngrok을 활용, 외부 공개 엔드포인트를 통해 내부 TensorZero에 요청을 프록시하는 구조로 해결함
     * Nginx를 앞단에 두어 인증 추가 및 보안 강화, 커스텀 TensorZero 함수로 LLM 라우팅까지 완료함
     * 최종 구조:
          + Cursor → Ngrok → Nginx(인증) → TensorZero(로컬) → LLM Provider

두 번째 장애물: CORS

     * 인증 시 CORS preflight(OPTIONS) 요청이 Nginx에 도달하며, 초기 인증 미수행 현상 발생
     * Nginx에서 OpenAI API와 동일한 CORS 헤더를 반환하도록 설정하여, Electron 기반의 Cursor IDE 요구사항 충족함
     * 인증 및 CORS 문제 해결 후, 모든 실제 요청은 Cursor 서버 경유로 이뤄짐
     * (Nginx 설정 예시 코드 포함)

최종 결과: Cursor 들여다 보기 가능해짐

     * 모든 LLM 요청/응답, system prompt, user prompt, 첨부 코드/파일 내용을 실시간 관찰 가능
     * system prompt 예시에는, 코드 편집용 별도 ""apply model""을 구동하는 명령까지 명시됨 (이중 모델 계층 구조)
     * Cursor 프롬프트의 주요 구조:
          + 사용자 세션 정보, 파일·커서 위치 등 맥락 제공
          + 코멘트 블록 등으로 구역 표시
          + 코드 수정 요청시에는 ‘변경 부분만 최소화’ 코드블록 생성 지침
     * Cursor의 프롬프트 엔지니어링
          + 642토큰의 대형 시스템 프롬프트 하나만으로도 대다수 소프트웨어 엔지니어링 업무가 자동화됨
     * 코드 변경 작업에 특화된 덜 지능적인 apply model(보조 모델)이 별도로 존재하며, 메인 LLM에 명확하게 적용 대상과 규칙을 지정
          + 다양한 LLM 계층 구조(지능, 기능 분리)가 실제 프롬프트 내부에 구현된 점을 확인함

결론 및 시사점

     * Cursor는 최신 LLM의 기본 내장 지식과 간결한 프롬프트만으로 소프트웨어 엔지니어링 문맥 처리가 가능
     * TensorZero 등 프록시로 사용자별 피드백, 실사용 데이터 기반의 최적화(A/B 테스트, 프롬프트/모델 튜닝) 구조를 쉽게 구축할 수 있음
     * 코드 에디터 보조 AI, LLM 도입 기업은 이 방식을 통해 프롬프트 설계, 성능 개선, 사용자별 최적화를 신속하게 실험할 수 있음
     * 차기 글에서는 실제 사용 데이터 수집 방식, 트리시터, git hook 활용법 등 후속 실험을 할 예정

        Hacker News 의견

     * Cursor는 내가 20년 넘게 써온 서비스 중 유일하게, 고객 지원이 전혀 되지 않아 구독을 취소한 제품임
       여러 주에 걸쳐 결제 관련 질문을 여러 번 메일로 보냈지만, 단 한 번도 답장을 받지 못함
       단순 VS Code 관련 문의가 아니라 Cursor의 팀원 개입이 꼭 필요한 이슈였음
       하지만 홍보 메일은 잘만 잘 옴
       Cursor의 ‘가치’가 빨리 다른 서비스에도 확산되길 바람
       다음 팀은 메일에 답장해주길 기대
          + 나 역시 비슷한 경험을 겪었고, 관련해서 이슈도 적어놓았음
     * 이 프롬프트에는 빠진 내용이 많음
       가장 두드러지는 건 tool call descriptors의 부재
       1년 전 jailbreaking 프롬프트와 직접 비교해봐도 됨
       그래도 cursor rules 등 다른 부분의 설정은 아이디어가 좋음
       참고로, 관련 프롬프트 자료는 여기서 볼 수 있음
          + Cursor에서는 사용자가 취하는 액션에 따라 다른 프롬프트를 사용함
            지금은 샘플만 제공했는데, 근본적인 목표는 다양한 모델을 A/B 테스트하고 프롬프트와 모델을 최적화하는 것임
            재현할 수 있도록 코드도 제공했고, 거기서 다른 프롬프트들도 참고할 수 있음
            네가 공유한 Gist 자료도 꽤 유용함
          + 혹시 어떤 최적화 로직이 있어서, 유저의 쿼리에서 꼭 필요한 도구 정보만 프롬프트에 포함시키는 것 아닐까 하는 생각이 듦
            아마도 토큰 절약을 위해 불필요한 tool descriptor는 과감히 빼는 전략을 쓰고 있을 듯
          + 관련 참고자료는 여기에 있음
     * 그럼... wireshark는 이제 쓸 수 없는 것임?
          + 기사 마지막에 어떻게 쓸지 결정하기 전에 훑어보는 첫 게시물일 뿐이라고 명시돼 있음
            참고로, 요즘은 단순히 패킷을 보는 용도로 mitmproxy가 꽤 훌륭해짐 mitmproxy docs
          + wireshark는 데스크탑 앱에서 Cursor 서버로 가는 요청(실질적으로 LLM에 보내는 요청)을 보는 데에는 쓸 수 있음
            하지만 Cursor의 서버에서 LLM으로 실제 요청이 어떻게 가는지 보고 싶으면, 별도 설정이 필요
            이런 설정이면 우리가 요청을 바꿔가며 A/B 테스트도 해볼 수 있음
     * Cursor 및 다양한 IDE 모달리티 솔루션은 흥미롭지만, 이들이 컨텍스트를 대충 다루는 습관을 기르게끔 만든다는 점이 아쉬움
       Cursor 프롬프트에서 발췌한 문구를 보면,
       ""사용자가 메시지를 보낼 때마다 현재 상태, 세션 내 편집 히스토리, 린터 에러 등 추가 정보를 우리가 자동으로 붙일 수 있고, 이 정보는 코딩 작업에 연관될 수도 있고 안 될 수도 있음. 적절성은 니가 결정하라""는 식임
       이런 ‘컨텍스트 블로트’는 LLM이 진짜 어려운 문제를 해결할 때 성능을 크게 제한함
       예시로 든 .env 문제는 간단한 유형이라 Cursor가 잘 다루지만, 이 정도 복잡성으론 소프트웨어 엔지니어를 계속 고용할 수 없음
       개인적으론 AI와 작업할 때 먼저 채팅 인터페이스에서 대화 맥락을 깔끔하게 관리하는 방법부터 고민하길 제안
       복잡한 문제에서는 미팅, 슬랙 대화, 내부 문서, 외부 컨텐츠, 코드 등이 맥락에 얽혀 있기 때문
       난 FileKitty(링크)와 최근엔 slackprep(링크) 같은 툴을 만들어서, 문제 해결과 관련 있는 정보만 추려내 더 의도적으로 쓸 수 있도록 함
          + 나도 이 부분에 동의하며, 내 에이전트 앱을 개발할 땐 맥락을 훨씬 신중하게 큐레이션해야 했음
            ""자동으로 첨부할 수 있다""가 아니라 실제 첨부한 것만 포함해 지시문 작성이 필요했음
            ""연관될 수도 있고 아닐 수도 있으니 네가 알아서 결정해라"" 대신, 연관성이 있을 때와 없을 때 각각 어떻게 해야 할지 명확한 지시가 있어야 효과적임
            맥락이 짧은 경우엔 별 문제 없지만, 길고 복잡한 이슈에선 이러한 세밀한 인스트럭션이 큰 차이를 만듦
            아마 Cursor는 캐시된 토큰 가격의 장점을 위해 지시를 최대한 일반적으로 해두는 것 같음
            아직 많은 부분이 실험 단계이고, 앞으로 프롬프트와 모델 개선이 많이 이뤄질 걸로 봄
     * Cursor의 프롬프트에 대한 다른 분석은 여기서 볼 수 있음
     * 긴 대화에서 관련 맥락을 선별하는 과정이 항상 궁금했음
       실제로 그 로직을 리버스 엔지니어링해서 어떻게 변환 기록을 잘라내고, 파일의 최신 상태를 어떻게 표현하는지 알아낸 사람이 있는지 궁금함
          + 그 워크플로를 깊게 살펴보진 않았지만, 우리가 했던 작업을 GitHub에서 직접 재현할 수 있어서 거기서 힌트를 찾을 수 있음
            앞으로도 이 부분을 계속 조사하며, TensorZero를 활용해 모델과 프롬프트 최적화 실험을 계속할 예정
     * mitmproxy를 이용해서 같은 방식으로 분석 중임 관련 토론
     * 이제 프롬프트 정보를 알게 되었으니 Cursor 서버를 재구현해서 완전 로컬(혹은 일종의 크랙된) 버전을 만드는 게 가능할지 궁금함
          + 아니면 애초에 Cline, Roo Code 같은 오픈소스, 에이전트 코딩 특화 프로젝트가 있으니 그걸 쓰는 게 더 나음
          + 프롬프트 나오기만을 기다려 이 시도를 했다는 건 좀 의외
          + Cursor의 apply 모델은 서버에서 돌아가는 구조로 보임
            로컬 apply 모델을 직접 구현하는 게 얼마나 어려울지 궁금함
            맥북에서 돌리면 훨씬 빠를 수도 있을 듯
          + 확실히 가능함
"
"https://news.hada.io/topic?id=21397","LLM 프롬프트를 공유할 수 있는 서비스를 만들어봤습니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    LLM 프롬프트를 공유할 수 있는 서비스를 만들어봤습니다.

   LLM 서비스를 사용하면서 프롬프트를 잘 쓰는 방법을 찾기가 힘들었습니다.
   인터넷에 공개되어 있는 프롬프트 예시도 찾아봤지만 간단한 상황에서 적용할 수 있는 프롬프트가 많았습니다.

   프롬프트 작성에 대해서 자신만의 노하우를 공유할 수 있는 방법이 없을까 자주 생각했습니다.

   프롬프트를 카테고리 또는 태그에 따라 구분할 수 있고 프롬프트를 사용할 때 필요한 변수 및 주의사항을 같이 공유할 수 있는 웹 서비스를 만들었습니다.

   부족한 점이 많으니 피드백 주시면 서비스에 반영하겠습니다.

   관련 링크가 없는데 어디서 찾을 수 있나요?

   제목 영역을 클릭하면 링크로 접속할 수 있는데

   링크가 잘 보이지 않는 것을 파악하지 않고 있었네요.

   Google 계정으로 로그인
   액세스 차단됨: 이 앱의 요청이 잘못되었습니다

   이 앱에서 잘못된 요청을 전송했으므로 로그인할 수 없습니다. 나중에 다시 시도하거나 개발자에게 이 문제를 문의하세요. 이 오류에 관해 자세히 알아보기
   이 앱의 개발자인 경우 오류 세부정보를 참고하세요.
   400 오류: redirect_uri_mismatch

   안녕하세요.

   해당 이슈가 조치되어 로그인 기능 사용 가능합니다.
   알려주셔서 진심으로 감사드립니다.
"
"https://news.hada.io/topic?id=21388","Go는 에이전트 개발에 적합한 언어입니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Go는 에이전트 개발에 적합한 언어입니다

     * 최근 AI 에이전트의 도입이 증가하면서, Go 언어 기반의 하이브리드 스택 활용이 늘어나는 추세임
     * 에이전트는 긴 실행 시간과 높은 비용, 그리고 입출력 대기가 잦은 특성을 가짐
     * Go는 경량 고루틴, 중앙집중적 취소 메커니즘, 채널 기반 메시징 등 고성능 동시성 모델을 제공함
     * 표준 라이브러리가 방대하며, 프로파일링 도구(pprof)로 메모리 및 스레드 누수 추적이 용이함
     * 단, Go는 머신러닝 생태계 부족과 썩 뛰어나지 않은 최고 성능, 타 언어 대비 낮은 서드파티 지원 등의 한계도 존재함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

에이전트란 무엇인가

     * 에이전트는 반복 루프에서 실행되며, 다음 실행 단계를 스스로 결정할 수 있는 프로세스를 의미함
     * 워크플로우처럼 미리 정의된 경로가 아니라, 조건(예: “테스트 통과”)이나 최대 반복 횟수 등으로 종료 여부를 판단함
     * 실제 서비스 시, 에이전트는 수 초~수 시간에 걸쳐 장시간 실행되고, LLM 호출·브라우저 조작 등으로 비용이 높음
     * 사용자의 입력(또는 다른 에이전트의 입력)을 처리해야 하므로, 입출력(I/O) 대기 시간이 많음

Go 언어가 에이전트에 적합한 이유

  고성능 동시성

     * Go의 고루틴은 2KB의 메모리만으로 수천~수만 개의 경량 스레드를 동시 실행 가능
     * 각 고루틴은 멀티코어를 활용해 병렬 처리하며, I/O 및 대기 상태의 에이전트도 부담 없이 운영 가능
     * 채널(Channel) 기반 통신을 통해 메모리 공유 대신 메시지 전달로 동기화 구현 (Mutex 사용 최소화)
     * 에이전트가 비동기로 메시지를 주고받으며 상태를 관리하기에 적합

  중앙집중적 취소 메커니즘

     * Go의 context.Context 활용 시, 대부분의 라이브러리·API가 취소 신호를 지원하므로 실행 중단이 매우 쉬움
     * Node.js나 Python은 여러 취소 패턴이 혼재해 있지만, Go는 일관된 방식으로 안전하게 취소 및 자원 회수 가능

  풍부한 표준 라이브러리

     * Go는 표준 라이브러리가 방대하며, HTTP/웹, 파일, 네트워크 I/O 등 거의 모든 영역 지원
     * 모든 I/O는 고루틴 내에서 블로킹 동작을 가정하여 비즈니스 로직을 직선형(스트레이트라인)으로 작성 가능
     * Python은 asyncio, 스레딩, 프로세스 등 다양한 동시성 패턴이 혼재해 복잡함

  프로파일링 및 진단 도구

     * Go의 pprof 등 내장 도구로 메모리 누수, 고루틴(스레드) 누수를 실시간 추적 가능
     * 장시간·동시 실행되는 에이전트에서 발생할 수 있는 누수 문제 진단에 강점

  LLM 코딩 지원 우수

     * Go는 단순한 문법과 풍부한 표준 라이브러리 덕분에 LLM이 고유의 Go 스타일 코드를 잘 작성함
     * 프레임워크 의존성이 낮아 LLM이 버전이나 패턴에 신경 쓸 필요가 적음

Go의 한계점

     * 서드파티 라이브러리 및 생태계가 Python, TypeScript 대비 부족
     * 머신러닝 직접 구현에는 적합하지 않음 (성능과 지원이 한계)
     * 최고 성능이 필요한 경우 Rust, C++이 더 나음
     * 에러 핸들링에 관대한 개발자에게는 다소 불편할 수 있음

   자바보다는 고 고보다는 러스트 :)

        Hacker News 의견

     * 대부분의 에이전트 시스템에서 가장 큰 지연 요소는 결국 LLM 호출임을 강조함. 기사에서 언급한 장점들은 특정 언어에 유리하지 않으며, 대부분 장시간 기다림과 비싼 리소스 사용, 사용자 또는 다른 에이전트로부터의 입력, 그리고 I/O 대기 시간이 크다는 것임. 이런 특성상 서버 실행 속도나 효율성보다는, 오히려 Python 같은 언어가 가진 방대한 AI 라이브러리와 지원이 더 중요한 장점임을 주장함. Python에서 asyncio나 멀티스레딩 라이브러리를 고민해야 한다는 지적도 있으나, 실제로 에이전트 개발은 그리 어렵지 않고 이미 누군가 관련 워크플로우를 개발한 경험이 있기 때문에 쉽게 시작할 수 있다고 생각함
          + Go로 에이전트를 구축할 때는 동시성과 백프레셔 관리 패턴이 잘 정립되어 있다는 점이 큰 장점임을 경험함. 에이전트는 대부분 느린 외부 서비스와의 트랜잭션이 포함되고 이런 작업에 Go의 동시성 패턴이 매우 유용함. 물론 언어는 크게 상관없고, JavaScript가 가장 많이 사용되는 듯함. 단, 코드 생성이라면 Go와 LLM의 조합에 좋은 시너지가 있다고 느낌
          + Go는 뛰어난 동시성 처리가 가능하고, 배포도 쉽다는 점에서 Python과 차별점이 있음. Go는 스태틱 바이너리만 배포하면 되기 때문에 Python의 환경 및 의존성 문제에서 자유로움
          + 에이전트는 오케스트레이션 계층 역할을 하는데 Go, Erlang, Node가 특히 적합하다고 생각함. 대량의 AI 관련 라이브러리가 꼭 필요한 건 아니고, IO가 많은 작업은 도메인별 툴 인터페이스 뒤에 추상화해서 필요한 언어로 서브시스템을 만들면 된다는 점을 강조함
     * Go는 이런 종류의 워크로드에서 크게 이점이 없는 편이고, 대부분 시간을 IO 대기에 할애함. Go의 타입 시스템이 제한적이며, 최신 언어에서는 기본 제공되는 많은 기능들을 Go에서는 우회해야 함. TypeScript는 AI 용도로 우수한 글루 언어이며, Python과 함께 라이브러리 지원이 매우 좋음. 내가 Python보다 TypeScript를 선호하는 이유는 타입 시스템이 훨씬 더 강력하고 성숙했기 때문임. Python도 빠르게 개선되고 있음. Node.js와 Python에서 롱런닝 작업 중단이 매우 어렵다는 주장은 확적한 근거가 없다고 봄. 대부분의 도구가 이 기능을 이미 지원하고 있고 주요 언어는 Python과 JS임
          + 성능이 정말 필요하다면 V8보다 빠른 C++이나 Rust로 네이티브 모듈을 작성하는 방식을 선호함. Go까지 갈 필요가 없음
     * Elixir와 BEAM 기반 에이전트 프레임워크를 실험해 봤는데, BEAM과 SQLite 조합이 현시점에서 에이전트에게 가장 이상적이라고 생각함. 에이전트를 어플리케이션 재배포 없이 안전하게 교체할 수 있고, BEAM의 동시성은 이 작업에 충분히 여유로움. 상태 기반이나 임시 에이전트 구현도 매우 쉬움. 앞으로 Python, Typescript, Rust로 베이스 에이전트를 구축하고 각 언어 선호도에 따라 복잡한 에이전트 개발이 가능하도록 MCP 서버도 만들 예정임
          + Extism 프로젝트와 Elixir SDK를 추천함. 이 조합을 활용하면, Elixir로 코어 서비스·라우팅·메시지 패싱을 만든 뒤, BEAM/OTP의 이점을 살릴 수 있고, 다른 언어로 작성된 작고 경량적인 Wasm 모듈 형태의 에이전트도 플러그인처럼 임베딩 가능함
            Extism
            Elixir SDK
          + BEAM의 내장 데이터 스토어인 mnesia 대신 SQLite를 선택한 이유가 있는지 궁금함
            mnesia docs
     * 에이전트의 대부분 시간은 LLM 응답 대기 및 외부 서비스(API, DB) 호출에 쓰임. 언어 런타임의 성능 영향이 실제론 거의 없음. 에이전트 성능과 확장성에 진짜 중요한 언어 기능이라면, JSON 직렬화와 역직렬화 성능이 될 것임
          + 그래서 네이티브로 JSON을 다루는 TypeScript 같은 언어를 쓰는 게 낫다고 생각함. TypeScript 타입 시스템은 Go보다도 훨씬 강력함
          + 경험상 LLM 호출 이외에 에이전트에서 가장 비용이 많이 드는 것은 비동기 편집(merge, diff, patch) 충돌 해결임. 이 작업도 저수준 라이브러리로 위임할 수 있지만, 직렬화만큼이나 최적화가 어려운 문제임
     * 이 ampcode.com의 에이전트 구축 가이드가 떠오름. Python은 동적 언어 특성 덕분에 데코레이터로 메소드를 툴 호출로 바로 변환하거나, 툴 함수 반복으로 리스트 생성, JSON 스키마로 빠르게 변환하는 등 활용이 자연스러움. 반면, 여러 외부 트리거(예: 유저 입력, Gmail 메일, Slack 메시지 등)로 새로운 에이전트 실행을 유발하는 구조는, Go의 채널과 switch for loop 활용이 훨씬 직관적이었음. Python에선 여러 큐와 스레딩을 따로 만들어야 해서 복잡함
     * 기사 논리를 따진다면 Elixir는 에이전트에 이상적임
     * Go의 제한적이고 부족한 타입 시스템은 거의 모든 애플리케이션에 부적합함. 실제로 Go의 가장 큰 단점은 언어 자체라고 평가함. 언어 외적인 부분이 오히려 Go를 용납하게 만든 요인임
          + 몇 년간 Go로 프로그래밍을 했지만 타입 시스템 문제가 많다는 데 동의함. LLM 분야 사람들은 거의 Python이나 JavaScript만 쓰는 것 같음. 모두 최신 언어로 이동해야 한다고 생각하지만, Go가 Python/JavaScript의 난잡한 임포트와 패키지 문제에 비해 그나마 나은 선택일 수 있음
          + Go 타입 시스템의 한계가 에이전트 제작에 어떻게 걸림돌이 되는지 구체적으로 듣고 싶음
          + 실상 Go에 정적 타입 시스템이 들어간 건, 성능 요구를 달성할 방법을 찾지 못했기 때문임. 실제로 동적 타이핑 언어처럼 쓰인다고 보는 게 맞고, 언어 설계 목적을 잘못 이해한 결과임. 동적 타이핑 언어가 전반적으로 부적합하다고 주장할 수 있지만, 실제로 Python, Erlang, Elixir 등 동적 타이핑 언어가 활발히 쓰이는 점에서 오히려 동적 타이핑이 문제 도메인에 더 적합함
          + 여러 리턴값이 합성되지 않고, 에러 지원은 익셉션보다 낫지만 매우 장황하며, 채널은 실수하기 쉽고, enum 타입은 실망스럽다고 느낌. 그럼에도 불구하고 인터페이스는 의외로 잘 작동하고, 패키징 시스템은 꽤나 매끄러움. Rust를 배우면서 file structure가 Go보다 훨씬 복잡하다는 점을 알게 됨. 심지어 언어가 단순하다 보니 다양한 린터/코드 생성 도구를 만들기에도 수월함. Go 코드 장기 유지보수는 Python/JS 대비 걱정이 적음
          + 만약 Go로 컴파일되는 LISP/Scheme 방언이 잘 유지된다면 정말 좋겠음
     * 오래 기다리는, 실행 비용이 높은 프로세스에서는 프로세스가 죽으면 모든 작업을 잃는다는 점이 단점임. 기다리는 동안 상태를 데이터베이스에 직렬화하는 게 더 안전할 수 있지만, 이걸 쉽게 구현하는 언어는 없는 것 같음. 체크포인트 기반 상태 머신 작성이 쉽지 않음
          + 체크포인트 기반 상태 머신은 Hatchet(hatchet.run), Temporal(temporal.io) 같은 플랫폼이 제공하는 핵심 기능임을 설명함. 워크플로우 내 함수 실행 이력을 저장하고, 인터럽트 발생 시 자동으로 이력을 재생함. 메모리 싱크보다 아웃풋 단위 진행 이력이 훨씬 효율적임을 주장함. (Hatchet 창업자)
          + goroutine, 스레드, 장기 실행 체인은 결국 atomic한 작업 단위로 쪼개고, 상태 직렬화가 필수임. 실패 복구, 에러 추적, 결과 재참조, 멀티 노드 분산 등의 요구를 충족함. Oban(github.com/oban-bg/oban) 프레임워크(Elixir)가 이 방식이고, 비동기 작업 영속화의 중요성을 강조한 Oban 기사도 추천함. (Oban 저자)
          + golang 기반 에이전트 라이브러리를 개발 중인데, 충분한 로깅만 있으면 언제든 에이전트 상태를 복원할 수 있다는 생각이 들었음. 타임스탬프와 부모 실행(run)만 알면 자식/분기 실행 트리를 쌓을 수 있음. 맵과 DB를 함께 활용해서 세션을 관리하고 필요시 재구축 가능함. 개별 오브젝트를 들고 있지 않고, stateless 오브젝트는 맵에서 id로 찾아써서 이전 액션, 스텝, 컨텍스트를 상태 오브젝트에 두는 구조임. 에이전트/워크플로우 일관성 역시 결과를 해시로 관리해 해결. 아직은 기본적인 에이전트/툴만 구현했고, 로깅과 복원, 취소 로직은 미개발 상태임
          + Temporal은 장기 프로세스 체크포인팅에 꽤 유용하고, 언어에도 중립적임
          + 나도 작업 큐를 고민하다가, Postgres에 rudimentary queue를 만들까 고민 중임. 장점은 서버간 워크로드 분산, 프로세스 종료 후 태스크 손실 방지, 더 나은 가시성 확보임. 대신 코드 복잡성이 크게 증가할 수 있어서 아키텍처를 쉽게 설계하는 게 어렵다고 느낌
     * AI 엔지니어들은 JavaScript 사용을 극도로 꺼림. TensorFlow for Swift가 중단된 것이 AI 언어 다양성의 종말이었음
          + JavaScript 기피는 AI 엔지니어에게만 해당하는 일이 아니라고 생각함. 30년 넘게 JS 코딩해 본 사람 입장에서도 동감함
          + JS는 언어로서 매우 형편없고, 백엔드에 갖고온 건 실수라고 생각함. TypeScript도 결국 기반에 깔린 JS의 문제를 해결하지 못함. JS나 TS를 쓰는 일은 피하고 Go, Rust, Python, Ruby, Elixir, F# 등 다른 대안을 선호함
          + JS가 에이전트에 특별히 좋은 이유가 궁금함
     * ML 분야에서 더 나은 동시성 모델이 필요하다고 느낌. Go로 ML을 시도해봤지만 라이브러리 지원 부족과 외부 gRPC 호출 또는 래퍼에 의존해야 해서 사실상 불가능함. Python은 한계가 있고 C++는 장황해서 생산성 저하 요인이 많음
"
"https://news.hada.io/topic?id=21420","GCP 장애","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 GCP 장애

     * Google Cloud Platform에서 서비스 장애 발생함
     * Vertex AI Online Prediction 서비스에서 오류가 지속됨
     * 사용자 맞춤형 서비스 상태 확인이 어려운 상황 발생함
     * 여러 지역 사용자에게 영향을 미치는 서비스 이상 현상 보고됨
     * 정상화와 구체적 원인 파악 필요성 제기됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

장애 개요

     * Google Cloud Platform에서 서비스 이용 불가 현상 보고됨
     * 특히, Vertex AI Online Prediction 기능 등에서 지속적인 오류 발생 확인

영향 범위 및 현황

     * 문제는 Personalized Service Health 등 서비스의 상태 확인에도 영향을 주는 중임
     * 다양한 지역 사용자가 서비스 접근 또는 활용에 불편을 겪는 상황임

결론 및 전망

     * 서비스 정상화 및 장애 원인 분석에 대한 필요성이 대두됨
     * 구체적인 복구 및 조치 방안에 관한 추가 공지가 기대되는 상황임

        Hacker News 의견

     * Google 내부의 중앙 서비스인 Chemist가 다운된 상황 설명, Chemist는 프로젝트 상태, 활성화 상태, 남용 여부, 과금 상태, 위치 제한, VPC Service Controls, SuperQuota 등 다양한 정책 점검 기능 제공, 그래서 “visibility check (of the API) failed”나 “cannot load policy” 등 다양한 에러 메시지가 나타난 현상 이해, 구체적인 정책 확인 문서 링크 제시, EDIT: Google이 “Identity and Access Management Service Issue”로 인해 Google Cloud에 장애 발생 공지
          + 나는 Expo로 알림 중계 기능을 사용 중, 이번 Google 장애와 관련해 FCM도 영향을 받았을지 궁금증
          + 여러 인터넷 서비스가 동시다발적으로 다운 현상, GCP만의 문제가 아님, Chemist 서비스가 외부로부터 특히 큰 영향을 받아서 내부 GCP 네트워크까지 장애 파급 효과 발생 추정
     * Claude Sonnet 4 (Cursor)와 Gemini Pro 사용 중 다수 에러 발생, 2024년 12월로 돌아가 원시인처럼 코드를 100% 직접 써야 하는 상황 개탄
          + 나도 AI Studio에서 동일한 문제 경험, “이용자 할당량 초과로 콘텐츠 생성 실패” 안내 메시지
          + Cloud Storage 파일 업로드 실험 중이었지만, 지금은 산책하기 좋은 타이밍 판단
          + Cursor의 Auto Agent 모드에서도 유사한 에러 발생
          + 2025년 6월 12일 전 개발자: “AI? 환각 제조기일 뿐 나를 대체 못 해!” / 2025년 6월 12일 장애 중 개발자: “AI가 없으면 내가 노예라는 건가?”라는 농담
          + Auto 모드 전환하면 여전히 사용 가능 팁 제공
     * Cloudflare도 장애 발생 상황, Cloudflare status에서 다양한 서비스(Access, WARP, Durable Objects(SQL 기반), Workers KV, Realtime, Workers AI, Stream, Cloudflare 대시보드 일부)가 간헐적 장애 발생 안내 및 영향 평가 지속 갱신, 관련 Hacker News 토론 공유
          + Cloudflare가 GCP에 의존하고 있다면 이번 장애는 엄청난 사태라는 반응
          + 링크가 비정상적으로 동작했다는 의견, 잠깐 비어 있었던 현상 언급
     * 18:43 UTC 기준 거의 모든 서비스 장애 상황, downdetector 링크 공유
          + 이 서비스 차트도 내부적으로 GCP에서 데이터를 수집한 듯, Google 담당자와 통화 중 누군가 AWS도 다운됐다고 말했고, 나는 확인 안 하고 “BGP 공격 아닐까?”라고 추측성 발언 반성
          + “모든 서비스가 Google 서비스냐” 질문
          + Google 장애가 AWS나 Microsoft 365에도 영향을 줄 거라고 예상하지 못했다는 의견
          + 이번처럼 큰 사건에는 Downdetector가 100% 허위 정보 원천이라는 주장
          + 아마 이 탐지 로직도 Google Cloud에서 동작하고 있을 수 있다는 농담
     * 상태 페이지는 모두 정상(녹색 표시)이나, 실제로는 다수 장애 보고 발생 중, Google Cloud 장애 모니터
          + 상태 페이지의 존재 이유에 의구심, 10만명 이상의 유저가 Google Meet 못 쓰는 상황 보고, 대기업들이 실제 상황을 상태 페이지에反영하지 않는다면 존재 의미 없음, 관련 Google Apps Status 및 GCP Status Page 추가 공유, EDIT: 게시글 이후 1분 내에 GCP 상태 페이지가 업데이트되어 Cloud Data Fusion, Cloud Memorystore, Cloud Shell 등 다수 서비스 장애 노출
          + 이번 장애 공식 안내 링크
          + 현재는 console, dataproc, GCS, IAM, Identity Platform 등 영향 상황 갱신 안내 링크
          + 우리 회사도 수백 명 원격 근무 중인데 Google Meetings 접속 시 90% 이상 504 에러 발생 경험
     * Cloudflare 장애도 방금 새롭게 업데이트, Workers KV 등 필수 서비스가 3자 서비스 장애로 오프라인 됨, 이 서비스에 의존하던 Cloudflare 제품들 정보 전달에 직접적인 영향
     * Firebase Auth도 다운돼서 많은 앱에 영향, Discord와 Slack 커뮤니티에서도 다수 사용자 동시 경험 보고, 30분 가까이 상태 페이지에 아무 글도 없어 실망감 토로, Firebase Status
          + 이제야 상태 페이지가 업데이트, 아마 내부 장애로 상태 페이지 반영도 느린 영향
     * 이번 장애로 RCS 메시지도 같이 다운 사태, 기술 또는 인프라 설계가 취약했다는 점을 여실히 드러냄
          + RCS도 그저 인스턴트 메시징일 뿐 아닌가? 그래서 장애가 놀랍지 않다는 반응
          + 그래서 오늘 부모님 강아지 사진을 못 받았던 이유 설명
          + 내 RCS 채팅이 아까 실패했던 원인에 대한 답 발견에 놀람
          + Erlang을 사용했어야 했다는 농담
     * BGP 라우팅 이상 확인용 좋은 대시보드를 찾는 중, Cloudflare Radar Routing 참고 중이나 실제 경로 누수가 표시되지 않아서 추가 추천 대시보드 문의
          + Cloudflare Radar 처음 접하는데 멋진 서비스라는 반응, 다만 현재 장애 영향으로 대시보드들도 일부 작동 문제 발생 예상, 예시 RIPE Atlas, IHR 글로벌 리포트, IHR 네트워크, BGP He.net, IODA 대시보드 추천
          + 내가 기본적으로 쓰는 것은 bgp.tools, 단 이번 장애가 왜 BGP 때문이라고 생각하는지 궁금
          + 나도 신참이라 궁금한데, “Announced IP Address Space” 구간이 갑자기 크게 점프하는 현상이 평상시에도 있는 일인지 질문
          + BGP 공격 의심 여부 제기
     * Hacker News가 이런 복잡한 인프라와 무관하게 단일 베어메탈 서버에서 돌아가고 있어서 다행이라는 유머러스한 의견
"
"https://news.hada.io/topic?id=21370","Kagi 사용자 5만 명 돌파","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Kagi 사용자 5만 명 돌파

     * Kagi 사용자가 5만 명을 돌파함
     * 5월 27일부터 6월 10일까지 회원 수가 1,116명 증가 추세임
     * 서비스는 회원 수 마일스톤마다 특별 기념 이벤트를 진행함
     * 이번 Kagi 서프라이즈는 구체적인 내용이 비공개로 유지됨
     * Kagi 회원 수는 전 세계 26개 국가 인구보다 많음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Kagi 사용자 성장 현황

     * Kagi는 검색 서비스를 제공하는 플랫폼으로, 최신 통계에 따르면 6월 10일 기준 회원 수가 50,155명에 달함
     * 지난 5월 27일에는 49,039명이었으며, 6월 10일까지 꾸준한 증가세를 보임
     * 날짜별로 보면 일평균 약 80명 이상의 가입자가 새로 유입되는 양상임
          + 5월 27일: 49,039
          + 5월 28일: 49,100
          + 5월 29일: 49,164
          + 5월 30일: 49,243
          + 5월 31일: 49,360
          + 6월 1일: 49,477
          + 6월 2일: 49,533
          + 6월 3일: 49,607
          + 6월 4일: 49,724
          + 6월 5일: 49,811
          + 6월 6일: 49,878
          + 6월 7일: 49,930
          + 6월 8일: 49,998
          + 6월 9일: 50,074
          + 6월 10일: 50,155

Kagi 서프라이즈 및 마일스톤

     * Kagi는 회원 숫자 마일스톤을 달성할 때마다 특별한 서프라이즈 이벤트를 진행함
     * 이번 5만 명 달성 이벤트 내용은 아직 비밀에 부쳐짐
     * 과거 2만 명 돌파 기념으로도 관련 블로그에 서프라이즈를 공개한 바 있음

흥미로운 사실

     * 현재 Kagi 회원 수(50,155명)는 전 세계 26개 국가 혹은 거주 지역의 인구보다 많은 수준임
     * 현재 목표는 Faroe Islands(54,714명) 의 인구를 상회하는 것임
     * 관련 통계는 위키피디아에서 확인 가능함

결론

     * Kagi는 빠른 성장세를 보이는 검색 서비스로, 가입자 수 마일스톤을 기념하는 성공적인 커뮤니티 문화를 가지고 있음
     * 5만 명을 돌파하며 유의미한 커뮤니티적 성취를 이뤘으며, 향후 또 다른 성장 모멘텀이 기대됨

        Hacker News 의견

     * Kagi가 비록 사용자 수는 적지만, 흑자를 내는 점을 주목하고 싶어짐. 회계적으로 건강한 성장을 이루고 있다는 사실과, 프리미엄·광고 없는 검색 경험이 사용자들에게 가치 있다고 보여주고 있다고 생각함. 꼭 모든 비즈니스가 유니콘이 되어야 한다고 생각하지 않고, 작게 시작해서 틈새시장을 제대로 잡는 기업도 충분히 멋지다고 느낌. 나는 Kagi가 앞으로도 작게 품질 좋은 서비스를 제공해주길 바람. SEO 스팸에 영향을 적게 받는 것만 해도 큰 이점임. 관련 링크
          + 꼭 모든 스타트업이 최종적으로 대기업에 팔기 위해 제품을 만든다는 마인드는 이상하다는 생각이 듦. 그런 마인드는 결국 제품이나 사용자에 대한 애정이 처음부터 없었다는 반증 같음
          + 더 많은 기업이 작으면서도 흑자 구조를 유지했으면 함. 대부분의 스타트업은 ‘쌀 때 좋았다’가 어느 순간 흑자 전환을 하면서 서비스 품질이 한순간에 망가지는 경우가 너무 많음
          + Kagi가 규모는 작게 유지하되, 만약 성장하더라도 고객 지원 체계를 절대 희생하지 않았으면 함. 특히 미국 스타트업들은 고객 지원이 정말 최악이라, 무슨 일이 생겼을 때 실제 담당자와 바로 소통할 수 있다는 점이 요즘 가장 좋았던 경험임
          + Kagi가 아마 연간 500만 달러 이상의 ARR에 도달한 것 같음. 사실 엄청 작은 숫자가 아니고, 합리적인 PER로 계산해도 기업 가치가 5,000만 달러를 넘기는 셈임
          + 흑자를 내는 구조가 최저임금만 받고 있는 건 아닌지 의심도 하게 됨
     * Kagi를 정말 좋아해서 거의 1년 가까이 사용 중임. 그런데 요즘 Vlad의 다양한 도전적 프로젝트들을 보면서 점점 걱정이 앞서기도 함. 내가 원하는 건 결국 좋은 유료 검색엔진 선택지가 다양해지는 것이고, 더 많은 경쟁이 생겨서 시장이 더 좋아지길 바람
          + 나도 비슷함. 직접 써보니 유료 검색이 더 낫다고 느껴서 기꺼이 비용을 내고 있음. Kagi가 수익 내는 모델이 가능하다는 사례를 보여줬으니, 더 많은 경쟁자가 진입해서 생태계가 다채로워지길 바람. 개인적으로는 Kagi가 ‘구글 따라잡기’식으로 모든 걸 하려 하기보다 최고의 검색엔진 그 자체에 집중해줬으면 하는 바람임.
          + Kagi가 장기적으로 유지 가능하려면 협동조합이나 steward-ownership 같은 구조로 전환하는 것도 좋겠다는 생각임. CEO 한 명이 모든 권한을 쥐게 되는 위험을 줄여줄 수 있다고 봄
          + Vlad나 팀이 여러 프로젝트에 신경을 분산쓰는 부분이 걱정인지, 아니면 특별히 신경 쓰이는 프로젝트가 있는지 궁금함
          + 나도 많이 걱정 중임
     * 무료 검색 서비스를 두고 유료 검색엔진으로 5만 명을 유치한 것 자체가 기적. 대단하다고 생각됨. 그런데 ‘상품이 되거나’ 아니면 ‘제값을 내고 쓰거나’ 두 가지 모델밖에 없는지 궁금해짐
          + 나는 단순히 ‘무료’ 제품이 아니라 시간과 관심이라는 가장 소중한 것을 대가로 지불하고 있었음. 그걸 깨닫고서 선택이 쉬웠음
          + 이미 유료 메일(fastmail)은 오래 쓰고 있음. 하루 수십~수백 번씩 쓰는 메일이 한 달 4달러 정도라 만족. Kagi는 한 달 10달러인데 실제로 몇 번밖에 쓰지 않음(무료 100회 써보고 기준). 그래서 굳이 구독 필요는 없는 상황. 나에겐 Duckduckgo도 충분함. DDG는 따로 계정 만들 필요도 없고, 장기 저장 공간도 요구하지 않아서 더 간편함
          + Kagi가 구독자들에게 반값만 받으면서 광고도 같이 보여주는 Netflix식 모델로 전환하는 것도 가능
          + 이런 쪽 모델은 ‘미끄러운 경사’ 논리의 위험도 항상 상존함
          + 나는 온라인 결제 정보 입력을 정말 싫어해서 크립토마이닝 기반 결제는 왜 안뜬 건지 궁금했었음. 만약 이용자 컴퓨터에서 채굴해서 그만큼 검색 비용을 인식하면 사실상 전기요금 통해 간접 지불하는 셈이 됨. 그런데 GPU 연산 가치가 실제로 서비스 비용보다 낮다는 게 문제 같음. 특히 AI 기반 서비스는 서버 GPU 두 개 써서 처리하니, 사용자가 자기 GPU로 충분히 ‘결제’하려면 오히려 훨씬 오래 채굴해야 함
     * Kagi의 철학과 서비스는 정말 높이 평가하고, 몇 년간 유료 고객이었음. 하지만 최근 구독을 해지함
          + 내 주요 사용 사례는 두 가지임. 1) 검색: Kagi가 SEO 스팸에서 벗어난 점이 진짜 강점이었음. 그런데 최근에는 주제별 질문이 생기면 일반 검색 엔진보다 o3 같은 토픽별 서비스로 바로 가기 때문에, 순수 검색 사용량이 크게 줄어듦. 2) 지도: 출장 및 여행이 잦은데, 검색창에 상호를 입력하면 대부분 지도에서 확인하고 싶음. 구글 지도 경험이 Kagi와는 비교할 수 없이 뛰어남. 그래서 결국 검색은 Kagi, 지도는 maps.google.com을 번갈아 사용함. Kagi에 요금을 내는 것은 문제 없지만, 내 생활 패턴과 맞지 않았음. 추가로, Kagi 파비콘이 구글의 g처럼 보여서 헷갈리는 점도 개인적으로 마음에 안 듦
               o 첫 번째 사례에 대해선, ‘?’ 연산자를 써서 LLM 응답을 받아보거나 Kagi Assistant 활용하면 다양한 AI 모델로 검색 가능한데 시도해 봤는지 궁금함
               o Kagi를 쓰면서 확실히 “분위기로만 쓴 듯한” 저급 콘텐츠나 스팸이 적게 걸리는 효과도 있음. 광고나 추적기 필터링 메트릭 때문인지, 아니면 뭔가 다른 ‘기준’이 있는 건지 궁금하긴 함
     * 나만 Kagi의 매력을 못 느끼는 것 같아 묘한 기분임. 여러 번 구독했고, 최근엔 무료 체험도 3개월 해봤는데, 무료 기간 끝나니 그냥 손쉽게 DDG로 돌아가서 마치 아무 일도 없었던 것처럼 잘 지내게 됨
          + 나는 의미 있는 프로젝트에 후원하는 것도 한 몫함. 거대한 광고 기반 서비스에 도전하는 스타트업을 지원하는 것도 가치 있다고 생각함. 검색에서 내가 자주 찾는 니치 포럼을 ‘부스트’ 해주는 기능도 덤임. 사실 DDG로 돌아가도 크게 불편함이 느껴지진 않지만, 그것도 괜찮음
          + 가장 큰 불만은 검색에 로그인을 해야 한다는 점임. 매일 다른 기기들을 많이 쓰는데, 매번 로그인 하는 게 너무 번거로움. 게다가 로그인하면 누군지 특정하기 쉬워지므로, DDG처럼 계정 없이 익명성으로 쓰는 쪽이 더 선호됨
          + Safari에서 기본 검색엔진 옵션에 Kagi가 없어 DDG를 기본으로 두고 쓰다 보니, 그냥 편의상 DDG를 더 쓰게 됨. 기본 Kagi 검색 결과와 DDG가 크게 다르지 않음. DDG에 광고가 살짝 있긴 하지만 그리 성가시진 않음. 그래도 Kagi의 Assistant 기능들은 확실히 인상적임. 최근에는 어렴풋이 기억나는 옛날 트윗을 찾으려고 도와줬는데, 여러 검색어 조합으로 검색을 생성해주고 결국 찾게 만들어 줬음
          + 나도 비슷함. Kagi 두 번쯤 시도했지만, 구글보다 결과가 한 번도 나은 적 없음. 솔직히 두 쪽 다 결과가 별로임
          + 취향 차이인 것 같음. DDG도 예전엔 썼는데 큰 차이는 없었음(그래도 구글보단 낫지만). 하지만 Kagi는 확실히 다른 느낌이라 1년째 결제 중임
     * 구글이나 마이크로소프트가 아닌 다른 기업의 검색 서비스를 후원한다는 마음으로 Kagi 유료회원 됨. 만족스러움
     * 760,600회 일일 쿼리는 초당 8.8건 수준임. 사용자당 하루에 15회 꼴로 검색하는 셈. 매우 활발한 유저도 있겠지만 그렇게 무리한 사용량은 아님
          + 내 통계를 보면 하루 평균 26회, 적었던 달은 19회, 많았던 달은 35회 정도임. 주로 개발 일 중에 쓰긴 하지만 취미 생활하면서도 자주 검색함. 생각보다 사용량이 많지 않아 놀랐음. Kagi 구독 고민 중인 분들에게 “내가 필요한 검색량”을 가늠하는 데 도움이 됐으면 함
          + 올해 내 개인 통계는 다음과 같음:
Date (UTC)    AI Tokens    AI Cost (USD)    Searches
Jun 2025           0           0.000           141
May 2025           0           0.000           743
Apr 2025           0           0.000           723
Mar 2025           0           0.000           621
Feb 2025           0           0.000           556
Jan 2025      10,692           0.000         1,189
Dec 2024           0           0.000           805

          + 5월 16일 이후 515회 검색, 하루 기준으로 환산하면 22회 꼴임. 2024년 3월부터 써왔는데 만족스럽게 사용 중임
          + 내 AI 토큰 사용량을 측정해봤을 때, AI 기능도 활발히 쓰는 편임에도 적게나마 Kagi가 나에게서 수익을 내는 구조임. 다만 기다림이 긴 무거운 모델 대신 빠르고 싼 LLM을 주로 선택함
     * 앞으로 2개월 뒤 Bing Search API가 없어질 예정인데 Kagi가 생존할 수 있을지 궁금함. 아직 계획 발표를 못 본 것 같음
          + DuckDuckGo 같은 대규모 고객은 Bing API 종료의 영향을 안 받는다 함관련 기사. Kagi도 해당될지 모르겠지만, 내부 포럼관련 포럼에 따르면 큰 변화는 없을 예정이라고 함
     * Kagi 무료 플랜 쓰고 있는데 정말 만족스러움. 다만 남아프리카공화국 기준 최소 5달러 월 구독료가 환율 때문에 부담돼 이제 결제 전환을 못 하고 있음
          + 무료 플랜도 안 써본 이유가 제한적이기도 하고, 유료 플랜 자체가 (지금 내 경제상황에서는) 비싸기 때문임. 이메일 서비스 등 다른 것엔 돈을 내지만 10달러씩 플랜은 커서 망설임. Kagi 공식 입장은 지역별 가격 차등제를 도입하지 않는 것임(포럼에서 ‘regional pricing’으로 검색하면 자세함). 사실 선진국 내에서도 비싸서 접근 어려움. 가족 플랜조차 비싸기 때문에 사용자 수 늘어나면 인하 가능성에 기대할 수밖에 없음
          + 미국 거주자지만 무제한 검색 플랜은 연구 일로 검색량이 많아 필요하지만 가격 부담이 큼. 가족 플랜으로 함께 쓰면서만 이용 중임
          + 순수 호기심인데, 해당 지역 기준으로 합리적이라고 생각하는 가격대는 얼마인가
          + 다른 SaaS처럼 지역별 가격 정책 도입하면 좋겠음. 미국 5달러가 세계 어느 나라에서나 5달러인 건 아님
          + 나도 비용이 높다고 느낌. 여러 기기 로그인, 검색 결과가 썩 뛰어나지 않다는 점, 모두가 대등하게 쓸 수 없는 구조(일종의 gate)가 걸림돌임. 월 5달러면 후원 차원에서 쓸 만하지만 쿼터 한도가 너무 적음. 이미지 검색은 웹 결과 쿼터도 소모해서 이중 청구되는 느낌임. DDG에서 광고 두 개쯤 스킵하면서 쓰는 게 오히려 더 나을 수 있음. 친구들도 ‘검색은 공짜’라는 마인드가 많아서 계정 공유/가족 요금제도 힘듦. 참고로 운영진이 밝힌 단가에 따르면 검색 한 건당 1.5센트 발생관련 출처. 연간 54유로/달러에 3,600회 제공이라, 이것도 1.5센트임. 단가가 정확히 동일하다는 게 신기해서 정말 단가인지, 아니면 구독자가 제공 쿼터 다 쓰지 않는 걸 전제로 한 계산인지 의심됨. 만약 순수 가변비용이 아니라 총비용(개발자 인건비, 관리비 등) 포함하여 쿼터
            대비 산출된 값일 가능성도 높음. DDG는 광고 두 개까지 붙여도 광고비가 크지 않고, 검색 비용도 더 싼 구조임(Bing 결과를 거의 그대로 가져오는 식). 광고 단가 출처, DDG 광고 정책
     * 지난 한 달 동안 Kagi 사용해보고 꽤 만족했음. 그런데 결제 구조(가격이 아니라 방식)가 정말 불편함. PayPal로 15달러 선결제했는데, 첫째 결제 옵션이 너무 숨겨져 있고, 둘째 월간 쿼터를 초과하면 추가 결제가 안 되고 다음 달까지 기다려야 하는 구조라서 구글로 돌아감. 남은 7달러는 그냥 남아있는 상태임
          + 남은 크레딧은 다음 달에 쓸 수 있음. 그런데 15달러씩 크레딧 충전할 이유가 없음. 월 10달러면 무제한 검색이 가능함
"
"https://news.hada.io/topic?id=21341","Rolldown-Vite 발표 — Rust 기반 초고속 번들러의 Vite 공식 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Rolldown-Vite 발표 — Rust 기반 초고속 번들러의 Vite 공식 도입

     * Rolldown은 Rust로 개발된 차세대 번들러로, Vite의 기본 번들러가 될 예정이며, 현재 rolldown-vite 패키지로 미리 체험 가능
     * 기존 Vite와 완전 호환을 목표로 개발 중이며, 대규모 프로젝트에서 3~16배 빌드 속도 개선, 최대 100배 메모리 사용 절감 등 실사용 성과 입증
     * esbuild 의존성 제거 및 Oxc(고성능 JS 도구 모음) 활용으로, 더욱 빠르고 일관된 트랜스파일·최적화 가능
     * Vite와 주요 플러그인, 프레임워크와의 호환성 확보에 중점, 일부 고급 사용 사례는 마이그레이션 가이드 참고 권장
     * 단계별로 Vite 메인 코드베이스에 통합 예정이며, 커뮤니티 피드백 및 실사용 경험을 통해 점진적 전환 계획
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Rolldown-Vite 발표

  개요 및 도입 효과

     * Rolldown은 Rust로 구현된 최신 번들러로, Vite의 기존 JS/TS 번들러를 대체할 차세대 엔진
     * 기존 Vite 프로젝트에서 vite 패키지 대신 rolldown-vite로 손쉽게 대체 사용 가능
     * 실제 기업 적용 사례에서 3~16배 빌드 시간 단축, 메모리 사용 4~100배 감소 등 뛰어난 성능을 입증

  주요 기술 및 마이그레이션

     * Oxc: 파서, 트랜스파일러, 리졸버, 미니파이어 등 고성능 JS/TS 툴체인 내장(향후 포매터 추가 예정)
     * 기존 Vite와 동일한 API/사용성 유지, 단 패키지 매니저별 alias 또는 override 설정 필요
     * esbuild는 더 이상 필수 아님, 내부 변환·최적화는 모두 Oxc로 처리(플러그인 호환을 위해 esbuild 일부 선택적 사용 가능)

  실사용 성과

     * GitLab: 빌드 시간 2.5분 → 40초, 메모리 사용 100배 절감
     * Excalidraw: 22.9초 → 1.4초(16배 단축)
     * PLAID Inc.: 1분 20초 → 5초(16배 단축)
     * Appwrite: 12분 → 3분(메모리 4배 절감)
     * Particl: 1분 → 6초(10배 이상 개선, Next.js 대비 29배)
     * 실제 블로그(VitePress + Rolldown-Vite) 빌드도 Netlify에서 1.8초 소요

  호환성 및 플러그인 지원

     * Vite 에코시스템 CI로 주요 프레임워크·플러그인 대부분 테스트 통과
     * 일부 특수 프레임워크/고급 케이스에서는 호환성 이슈 발생 가능 → 마이그레이션 가이드 참고 권장
     * 플러그인 저자는 즉시 Rolldown-Vite 환경에서 호환성 테스트 및 최적화 가능

  단계별 통합 로드맵

    1. 1단계(현재): 별도 패키지(rolldown-vite)로 초기 체험·피드백 수집
    2. 2단계: 메인 Vite 코드베이스로 머지, 개발 서버의 풀-번들 모드(opt-in) 제공, rolldown-vite 패키지 폐기 예정
    3. 3단계: 풀-번들 모드가 Vite의 기본값으로 전환

     * 각 단계는 수개월 소요 예상, 커뮤니티 실사용·피드백 기반 점진적 진행

  향후 계획 및 참여 방법

     * 개발 서버의 풀-번들 모드 도입으로 대규모 프로젝트의 개발 속도 및 안정성 극대화 예정
     * Vite 핵심 내부도 점진적으로 Rust화(통신 오버헤드 감소 및 성능 극대화)
     * 버그, 호환성 이슈, 성능 피드백은 rolldown-vite 저장소로 리포트 권장
     * 실시간 논의는 Rolldown Discord에서 가능
"
"https://news.hada.io/topic?id=21310","Air Lab – 휴대용 오픈형 대기질 측정 장치","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Air Lab – 휴대용 오픈형 대기질 측정 장치

     * Air Lab 시뮬레이터는 실제 기기의 네트워크 기능을 제외하고 소프트웨어를 가상 환경에서 체험할 수 있음
     * 다양한 환경 선택을 통해 센서 측정값이 어떻게 달라지는지 탐색 가능함
     * USB 연결로 장치 충전과 파일 전송 및 다운로드 기능 제공됨
     * 사용자 인터페이스는 버튼과 터치바를 통해 메뉴 이동 및 센서 전환이 가능함
     * 시뮬레이션을 통해 Air Lab의 작동 방식과 기본 기능을 쉽고 안전하게 경험할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Air Lab 시뮬레이터 소개

     * Air Lab 시뮬레이터는 Air Lab 펌웨어를 네트워크 관련 기능만 제외한 상태로 가상 실행하는 플랫폼임
     * 사용자는 시뮬레이터에서 다양한 환경을 선택하여 센서 출력 값이 어떻게 달라지는지 실험해볼 수 있음
     * USB 케이블을 연결하면 기기를 충전하거나 파일을 컴퓨터로 복사할 수 있는 기능을 제공함

기본 조작 방법

     * A 버튼: 메뉴 진입 및 확인 기능 제공
     * B 버튼: 메뉴에서 나가기 및 취소 기능 수행
     * 좌/우 버튼: 메뉴 변경 및 시간 스크롤 조정 가능
     * 상/하 버튼: 센서 전환 및 메뉴 스크롤 지원
     * 터치바: 시간 및 메뉴 스크롤 방식 제공

파일 관리 기능

     * 시뮬레이터를 통해 장치로부터 파일 다운로드가 가능함
     * 안전하게 장치를 제거(eject) 할 수 있는 기능 제공

주요 특징 요약

     * 사용자는 네트워크를 제외한 Air Lab의 전체 소프트웨어 기능을 실제 기기 없이 쉽게 테스트할 수 있음
     * 대기질 측정, 데이터 전송, 인터페이스 조작 등 실환경의 다양한 기능을 손쉽게 체험할 수 있는 점이 장점임

        Hacker News 의견

     * 이 제품 정말 마음에 드는 선택지라는 생각. CO2 센서 선택을 조사했는지 궁금. SCD30과 SCD41을 비교했는지 관심. SCD30은 듀얼 채널 디자인 덕분에 SCD41보다 드리프트가 적고 더 안정적이라고 알려져 있는데, 실제 데이터를 확인했는지 궁금.
          + 고마움 표명. SCD30 센서가 훌륭하고 SCD41보다 더 좋다는 점은 분명하지만, 소형화를 위해 SCD41을 주로 선택. Air Lab 같은 기기엔 +/-50ppm의 정확도가 충분하다고 믿음. 자동 보정 사용 시 사용자가 기기를 밖에 내놓아야 한다는 점은 리마인더로 적극 안내할 예정. 여기 더해, 출고 시 보정 혹은 수동 재보정 옵션도 계획 중이라 자동 보정 1주일 주기가 아닌 더 긴 기간 안정성 제공 목표.
     * 제품 디자인이 정말 멋진 느낌. 출시 축하의 마음. 단일 센서만 내장된 독립형 데이터 전용 장치를 만들어서 사용자가 원하는 이잉크 대시보드에 직접 연동할 수 있도록 고려한 적 있는지 궁금. 커뮤니티에서 만든 공기질 대시보드 예시 링크(https://usetrmnl.com/recipes/62233, https://usetrmnl.com/recipes/23306)와, 어떤 이잉크 하드웨어에도 설치할 수 있는 펌웨어(https://github.com/usetrmnl/firmware/) 소개. 참고로 TRMNL에서 일하고 있음.
          + 감사의 마음. 이런 형태를 프로토타입으로 곧 만들어보고 싶음. 여러 방/공간 지원에 유용. 다른 대시보드, 특히 TRMNL과의 연동도 정말 멋질 것 같다는 생각.
     * 혹시 참고 삼아, 아마 훨씬 저렴한 축소 버전 장치가 있으면 유용할 거라는 제안. 공기 오염이 심한 지역일수록 이런 기기가 필요하지만, $200 이상의 공기질 센서는 도저히 감당할 수 없는 가격대. 배송비까지 더하면 거의 $300이고, 이는 본인 거주지 기준 중위 월급 수준. NO₂ 측정 가능성은 현재 대안들과 확실히 차별화되는 장점. 이론상 개별적으로 구매 가능한 가스 센서들도 수백달러라 접근성이 떨어짐.
          + AirGradient의 팬. 매우 저렴한 DIY 키트도 판매했었음. PCB+엔클로저만 $19, 전부 포함 세트 $96. 현재 키트는 $138로 확인. 더 저렴하게 만들고 싶다면 공식 홈페이지(https://www.airgradient.com/documentation/overview/)에서 KiCad와 STL 파일 받아, PCB는 외부에서 주문, 케이스는 3D 프린트, 나머지 부품은 aliexpress에서 직접 조달하는 방법도 추천. 필요없는 센서는 생략하고, 나중에 추가하는 방식으로 비용 절감도 가능.
          + 전제 조건으로 제품 설계, 제조, 대중 검증에는 오랜 시간과 노력이 소요된다는 점을 인정. 소매가도 그만한 이유로 충분히 정당화될 수 있음. 그럼에도, 주요 부품 소매가를 보면 ESP32S3 IC $4, SCD41 센서 $21, SGP41 센서 $8, LPS22 센서 $4 등 저렴하게 구현 가능한 희망적 부분 확인. 핵심 기능을 오픈소스로 공개해, 개발도상국 취미가들도 적은 비용으로 만들 수 있는 기반이 마련될 수 있다는 생각.
          + 피드백에 대한 공감. 가격 경쟁 어려움은 소량 생산 계획 때문. 그럼에도 앞으로 더 많은 사람이 살 수 있는 단순하고 저렴한 버전 출시를 충분히 고려한다는 입장.
     * 멋진 작업에 대한 찬사. sensor.community라는 오픈 센서/플랫폼 참고 제안. 이곳도 센서 디자인을 제공하고, 센서 데이터 공개 지도에 집계를 위한 오픈 인프라가 있다는 점을 강조.
     * 개인적으로 아라넷 제품(https://www.aranet.com/en/home/products/aranet4-home) 사용 경험 공유. 그 제품에서 배울 점으로, 측정값이 화면에 크게 표시돼 멀리서도 한눈에 상태를 알 수 있다는 점 추천. 눈에 띄게 색상 반전도 시각적 인지에 도움. 반면 현재 심사 시뮬레이터는 내용 확인에 가까이 다가가야 하거나, 깜빡이는 LED는 상태를 놓칠 위험이 있다는 점 언급.
          + 현재 (실물) 기기에서는 회전시키면 대기 모드에서 큰 글씨로 값을 표시하는 세로 레이아웃 제공. 시뮬레이터에는 아직 미반영. 더 큰 글꼴의 가로 레이아웃도 개발 예정.
     * 1%의 제품만이라도 이렇게 솔직하게 보여준다면 좋겠다는 찬사. 실제 동작 그대로를 웹페이지에서 보여주고, 과장된 스크린샷, 억지스러운 연출, 불필요한 광고 없이 제품 그 자체로 보여줌. 웹사이트 UI에서 제작자의 세심함이 느껴짐.
     * 멋진 프로젝트라는 생각과 경쟁이 더욱 필요하다는 의견. Air Gradient One처럼 오픈소스 대안도 있다는 점 강조. 다만 실제 계측값은 작은 글꼴로 구석에만 표시되고, 센서별로 직접 전환해 봐야 한다는 점은 불편. 모든 센서값을 큰 글꼴로 한 번에 보여주면 좋겠다는 바람.
          + 화면보호기에서 시간, 온도, ppm, 습도 표시. 그리고 Air Lab 공식 펌웨어는 오픈소스로 GitHub에 공개 예정. 자유롭게 확장 및 커스터마이즈 가능.
          + 다른 이의 제안처럼 화면보호기(30초 후)에서 가로/세로 전체값을 한눈에 볼 수 있음. 레이아웃은 개선 중이며 더 크게 만드는 것이 목표. 시뮬레이터에서도 경험 가능.
          + 디스플레이 디자인이 기능성보단 재미(Fun)에 중점을 둔 느낌.
          + 이런 점이 오픈스택(Open stack)의 장점 중 하나라는 의견.
     * e-ink 디스플레이가 특히 마음에 드는 디자인이라는 칭찬. Qingping Air Monitor 2(https://qingping.co/air-monitor-2/)와 비교했을 때 연결성, 측정 품질 등 장단점이 궁금하다는 질문.
     * 멋진 제품이라는 평과 함께 정확도에 관한 궁금증 제기. 측정/교정 분야 전문가 관점에서, 실험실 기기와 비교 테스트나 정식 공차 범위 명시 계획을 확인하고 싶음. 측정 불확실성, 장치별 변동성에 관한 특성화가 이루어졌는지도 질문. 소비자용 하드웨어임을 고려하지만, 대략적인 기대 성능은 알고 싶음.
          + 좋은 질문에 감사. 조만간 정식 실험실 테스트 계획 중. 스위스 연방환경청이 파트너라 관련 장비 보유. 설계 과정에서 유동 해석으로 공기 흐름, 입자 이동 모델링 진행. 그 전까지는 SCD41, SGP41 데이터시트 명시 스펙만 안내 가능.
     * 전반적인 피드백 몇 가지 제시:
          + 이런 제품이 꼭 필요함
          + 과거엔 직접 센서+마이컴 조합으로 조잡한 공기질 모니터 만들었지만 완성된 제품을 더 선호
          + 오픈성에 매력을 느낌
          + 폼팩터가 매우 마음에 들어 휴대가 가능하다는 점이 좋음. 스트랩 고리가 활용도 높음. 예: 회의실 45분 후 상태 확인 등에 유용
          + PM2.5 지원이 필요, 이 부분은 AirGradient가 더 적합하게 느껴짐
          + PM2.5는 이런 모바일·컴팩트 폼팩터로 소형화가 매우 어려운 도전. 별도 팬이 반드시 필요하다는 점을 강조.
"
"https://news.hada.io/topic?id=21429","구글 픽셀은 더 이상 AOSP 레퍼런스 디바이스가 아님","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     구글 픽셀은 더 이상 AOSP 레퍼런스 디바이스가 아님

     * 구글이 Android 16의 소스 코드를 AOSP에 공개했지만, Pixel 하드웨어 저장소는 공개하지 않음
     * Pixel 기기 트리 및 관련 코드 미공개로 인해 커뮤니티 일각에서는 “AOSP 폐지” 의혹이 나왔음
     * Google은 ""AOSP는 중단되지 않는다"" 고 공식 부인하며, 앞으로도 AOSP 소스코드 공개와 업데이트를 지속하겠다고 재확인
     * 앞으로 AOSP는 기존 하드웨어에 종속되지 않은 기준 타깃(reference target) 을 지향하고, 유연·저비용인 'Cuttlefish' 등 가상 장치/일반화 기기(GSI) 중심으로 전환될 예정
     * 커스텀 ROM 개발자들과 보안 연구자에게 OS 업데이트 및 연구에 어려움이 발생할 가능성이 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Android 16 출시 및 소스 코드 공개 이슈

     * Android 16 출시와 함께, Google은 Pixel 하드웨어 저장소와 디바이스 트리(Device tree) 코드를 공개하지 않음
          + 이전까지는 AOSP와 함께 Pixel 하드웨어용 코드가 함께 제공되어 커스텀 안드로이드 ROM 개발에 필수적 역할을 해왔음
     * 이로 인해 커스텀 ROM 개발자와 보안 연구자들이 커스텀 OS 개발, 최신 Android 업데이트 및 보안 취약점 연구에 어려움을 겪을 것으로 전망

AOSP 관련 구글 공식 입장

     * 커뮤니티 일각에서 ""AOSP가 종료될 것""이라는 루머가 돌았으나, Android 부문 VP Seang Chau가
          + ""AOSP는 사라지지 않는다""
          + ""AOSP 업데이트에 계속 전념한다""라고 공식적으로 부인
     * 다만, Android 팀의 공식 답변에서는 앞으로 Pixel 기기 트리 등은 더 이상 제공하지 않을 것임을 시사함
     * AOSP에서 제공할 기준(reference) 타깃은 특정 하드웨어에 독립적인 형태를 추구함
          + 구글을 포함한 어떤 특정 하드웨어와도 무관하게 유연하고 설정 가능한, 저렴한 기준 디바이스를 지향함
          + 수년간 커뮤니티에서는 Cuttlefish(레퍼런스 디바이스) 와 GSI 타깃을 소스에서 빌드하여 테스트 및 개발용으로 사용해왔음
          + 이 기준 디바이스들은 계속해서 개발자에게 공개될 예정임

커스텀 ROM 및 보안 커뮤니티 영향

     * 구글은 공식적으로 AOSP에 대한 지속적 지원 의지를 강조함
     * 하지만, 직접 하드웨어 지원이 없어진 만큼 커스텀 ROM 제작 및 유지보수 또는 보안 연구에 있어서 더 높은 개발의 난이도 및 진입장벽이 대폭 상승할 것으로 예상

        Hacker News 의견

     * 나를 이상하게 볼 수도 있겠지만, 최근에 Pixel을 산 유일한 이유는 구매하자마자 GrapheneOS를 바로 설치하려는 의도 때문이었음. 지금까지 정말 만족스러운 결과를 체험함. 업무와 관련된 일이 아니면 구글이 관련된 것은 되도록 피하려고 함. 구글에 대해 싫어하는 부분이 너무 많기 때문임. 사실 구글이 그런 바이너리 블롭을 계속 제공해줄 의무는 없지만, 오랜 기간 해오던 것을 예고 없이 갑자기 중단하는 모습에 또 한 번 실망감이 쌓임. 여러 서비스를 종료할 때처럼 미리 충분히 고지했어야 한다는 생각임. 물론 바이너리를 계속 배포하고 동작을 보장하는 게 추가 부담임은 이해하지만, 정작 그들은 내부적으로는 어차피 그 작업을 해야 함. 내 생각에 구글은 일부 GrapheneOS 사용자를 위해 장치에서 손해를 보고, 폐쇄 생태계나 데이터 마이닝, 광고 등
       2차적으로 돈이 되는 것에 집중하려는 전략적 선택을 했다고 추정 중임
          + 나도 똑같은 이유로 Pixel을 구입함. 이제는 거의 모든 계층에서 추적이 이뤄진다는 사실을 다들 알고 있기 때문에, Pixel을 구매해 바로 GrapheneOS로 플래싱하는 게 가장 현명한 선택이라고 생각함. 우리 집 모든 휴대폰(아내 것과 내 것)도 동일하게 사용 중임. Play Services, Google 앱, Facebook 같은 것도 전혀 신경 쓸 필요 없음. 내 삶이 표적 광고와 미래에 무슨 용도일지 모르는 데이터의 일부가 되지 않았으면 하는 바람임. 이렇게 프라이버시에 무감각한 사람이 많다는 게 오히려 신기함
          + 너그럽게 평가함. 나도 똑같이 함
          + “구글이 미리 충분히 알리지 않고 바이너리 제공을 끊었다”는 주장에 조금 다른 시각임. 문서화되지 않은 동작에 의존해놓고, 바뀌었다고 항의하는 건 이상함. 소프트웨어 엔지니어라면 이런 것에 의존하지 않는 게 상식임. 만약 누군가 Pixel을 문진으로 쓰다가 카메라 돌출로 인해 더 이상 사용할 수 없게 된 상황을 예로 든다면, 그걸 회사 탓으로 돌리는 것도 마찬가지라는 생각임
     * Pixel(혹은 과거의 Nexus)처럼 실제 소비자 대상 하드웨어를 사서 AOSP와 프로프라이어터리 블롭을 받아서, 별다른 작업 없이 모든 하드웨어가 동작하는 빌드를 만들 수 있었던 점이 정말 고마웠던 기억임. Cuttlefish가 더 효과적인 참고 디바이스일 수는 있지만, Pixel처럼 GrapheneOS 같은 용도로 기기를 다양하게 활용할 수 있는 점과는 차이가 있음. 내 손에서 직접 빌드한 Android를 실 기기에서 돌리는 경험이 VM 상에서 할 수 없는 매력이라고 생각함
          + 기사에 따르면 GSI(Generic System Image)도 참고 디바이스로 지원한다고 하고, 이는 실제 하드웨어에 가까운 옵션임. 다만 GSI는 여러가지로 불편한 점이 있는데, 기기의 저수준 사양(파티션 방식·Android 최초 출시 버전 등)에 따라 빌드 종류가 제각각임. 그래도 대안으로 나쁠 건 없음. 요즘에는 GKI(Google Generic Kernel Image)라는 것도 등장해서 (커스텀 모듈·블롭 제외) 최신 기기라면 돌아가도록 설계됨. 다만 이건 리눅스 커널 메인라인과는 별개이고, 아직도 많은 커스텀 패치가 적용된 다운스트림 브랜치임. 그래도 실제 기기와 관계없이 통일된 방식으로 테스트와 개발을 쉽게 할 수 있게 해줌
     * GrapheneOS가 문제 상황을 과장해서 스스로 실수(‘양치기 소년’ 효과)를 범했다고 봄. 뻔히 거짓임을 알 수 있는 비판에는 회사 입장에서도 반박이 쉬움. “Google is killing AOSP” 식의 주장은 눈에 띄긴 하지만, 회사에서 반박 논리를 제시하기 너무 쉬운 이야기임. 지금 벌어지는 것은 GrapheneOS가 구글의 선의에 의존해 바이너리 블롭을 얻던 상황이었고, 구글은 아무런 의무가 없으니 스스로 이유가 있기에 제공을 멈췄을 뿐임. 거기다 GrapheneOS가 법적·독점 관련 논란을 언급하니 개발자들은 아예 관여하지 않고, 법무팀 쪽으로만 넘어감
          + 구체적으로 뭐가 과장됐다는 건지 궁금함. 무엇이 거짓인지, GrapheneOS가 과거에도 그랬는지, 구체적으로 어떤 부분이 잘못됐는지 궁금
          + 이번 일을 계기로 GrapheneOS가 Pixel 외의 더 넓은 기기군도 지원하게 될 것이라는 생각임. 사실 이미 그렇게 했어야 한다고 생각하고, 하드웨어 지원이 좋아도 그것 없어도 여전히 순정 안드로이드보다 압도적으로 더 안전함
          + Google이 사실상 독점자인 기업 둘 중 하나라는 점을 들어 Google을 적극적으로 옹호할 필요는 없다는 입장임
     * Pixel 하드웨어 저장소(디바이스 트리, 드라이버 바이너리 등)가 없으면 커스텀 Android ROM이 OS 업데이트를 개발하는 게 매우 어려워진다는 점이 늘 걱정임. 보안 연구에도 영향이 있을 수 있음
          + 특히 GrapheneOS 공식 트위터에서 이런 내용이 올라와서 더욱 걱정임
     * GrapheneOS가 없으면 아마 iPhone으로 갈 것 같음. 오랜 기간 GrapheneOS를 써오면서 불필요한 Google 요소 없이 가볍고 단순한 느낌을 너무 좋아했음. 이제는 Google 공식 Pixel이 내게 맞지 않음
     * 또 하나의 Google Graveyard 목록 추가임. 더는 내가 직접 컨트롤할 수 없다면 Pixel을 쓸 이유가 없음. iPhone을 다시 써보면서 단점을 감수하고 많은 장점을 누려볼 계획임
     * “AOSP는 살아 있다, 에뮬레이터로라도 쓸 수 있다”는 식의 반박이 떠오름. 기사에는 “수년간 개발자들은 Cuttlefish(GitHub 참고)와 GSI 타깃을 소스에서 빌드해 참고 대상으로 써왔다. 앞으로도 테스트·개발 목적으로 제공을 유지”라고 밝히고 있음. 나는 AOSP에 대해 초심자인데, 실제로 저런 참고 디바이스들이 커스텀 ROM 개발에 실질적으로 써먹을 만한 건지, 아니면 겉치레용 주장인지 커뮤니티 관점이 궁금함
     * GrapheneOS가 Pixel에서 잘 돌아갔던 이유가 아마 이것 때문 아닐까 생각함. 초기 장애물을 넘은 뒤 핵심 변화를 이해하게 된다면 오히려 더 많은 기기로 지원이 확장될 수도 있지 않을지 기대함
          + 일부만 맞음. 공식 FAQ에 따르면 주요 이유는 (1) 메모리 태깅 같은 최고 수준의 하드웨어 보안 기능, (2) 빠른 패치 제공, (3) 장기 공식 지원이 있음
          + 또는 이번 변화로 GrapheneOS가 더 이상 신규 디바이스는 지원하지 않는 쪽으로 갈 수도 있음
     * GrapheneOS가 Pixel을 구매하던 유일한 이유였음
     * 약간 중복 내용임 관련 링크
"
"https://news.hada.io/topic?id=21427","Microsoft Office가 Source Depot에서 Git으로 마이그레이션한 과정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Microsoft Office가 Source Depot에서 Git으로 마이그레이션한 과정

     * Microsoft Office는 오랜 기간 내부 소스 관리 시스템인 Source Depot를 사용하다가, 개발자 경험과 기술 혁신을 위해 Git으로 대규모 마이그레이션을 진행했음
     * Source Depot는 중앙집중식, 느린 브랜칭, 불편한 워크플로우로 생산성에 한계가 있었으며, Git으로의 이전은 수백 명의 엔지니어와 수년에 걸친 작업이 필요함
     * 마이그레이션 과정에서는 VFS for Git과 같은 새로운 기술 개발, 기존 빌드/테스트 인프라 이식, 병행 시스템 운영 등 대규모 기술적·조직적 도전과제를 극복했음
     * 성공적인 이전을 위해 ""챔피언"" 중심의 소통 체계, 과감한 투명성, 실용적인 교육, 즉각적 롤백 전략 등 협업적이고 인간 중심의 접근법을 강조함
     * 마이그레이션 이후 온보딩 시간 감소, Git 선호도 증가(89%) , 생산성 향상 등 긍정적인 결과와 함께, 대규모 기술 변화의 핵심 교훈을 남김
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Source Depot에서 Git으로: Microsoft Office 대규모 마이그레이션 경험

  개발자 생산성 극대화라는 새로운 도전

     * 개발자 생산성을 높이는 작업은 'Multiplier work' 로, 대규모 조직일수록 그 가치가 큼
     * Microsoft Office의 Source Depot에서 Git으로의 마이그레이션 프로젝트가 대표적 경험이었음
     * 이 작업은 단순한 도구 변경이 아니라 수백 명 엔지니어, 복잡한 시스템, 오랜 기간에 걸친 대형 프로젝트였음

Source Depot: 그 시절 소스 관리 이야기

     * 2000년대 초 Microsoft는 Perforce 기술 기반의 자체 버전 관리 시스템인 Source Depot를 운영함
     * Source Depot는 느린 브랜칭, 중앙집중화, 긴 코드 체크아웃 시간, 불편한 병합 방식(Reverse/Forward Integrate) 등으로 작업 효율에 한계가 있었음
     * 전체 개발 인프라(빌드, 릴리스, 워크플로우)와 강하게 결합되어 있어 단순 교체가 불가능한 구조였음
     * Microsoft Office의 Git 전환에는 수년과 수백 명 엔지니어의 노력이 필요했음

  OneNote를 시작으로: 마이그레이션의 시작

     * Office 엔지니어링 조직에서 Source Depot 유지·패치 비용과 “경쟁력 있는 기술” 요구로 대대적 Git 이전이 결정됨
     * Office 제품군은 출시 주기(수개월, 반기, 월별, 인사이더)별로 개발 스케줄이 달라, 장기간 Source Depot-Git 병행 운용이 필요했음
     * Office 버전 관리 일관성, 빌드 검증, 레거시 테스트 인프라 이식 등이 필수 과제로 등장했음

  Office 규모와 소통 전략

     * Office는 당시 4,000명 규모의 엔지니어가 협업하는 초대형 조직이었음
     * 팀별로 'Developer Satisfaction Champion'을 지정, 각 팀을 연결하는 hub-spoke 모델을 통해 원활한 피드백과 소통 구조를 마련했음
     * 필자는 OneNote의 챔피언으로, 대규모 마이그레이션 현장의 핵심 역할을 담당했음

  VFS for Git: 초대형 코드베이스의 한계 돌파

     * 한 번의 git clone이 200GB 이상 필요할 정도로 코드 규모가 커, GitHub와 공동 개발한 Virtual File System for Git (VFS for Git) 로 문제를 해결함
     * VFS for Git은 실제로 쓰는 파일만 받아오는 방식으로 기본 Git의 한계를 극복함
     * Microsoft Windows와 협력하며 업계 최대급의 버전 관리 시스템 한계를 뛰어넘는 경험이었음

마이그레이션 단계별 접근

  1단계: 병렬 우주(Parallel Universe)

     * Source Depot와 Git을 실시간 동기화하는 브리지 서비스를 구축, 양 시스템의 불일치 및 모델 차이(브랜치 구조, changelist 등) 문제를 반복 개선함
     * Office 메인/Private 브랜치-동기화-빌드 과정을 24/7 자동화 시스템으로 운영함
     * 세 번에 걸친 재시도 끝에 안정적으로 동작하는 병렬 시스템을 구현함

  2단계: 동등성 검증

     * 모든 테스트 스위트를 두 시스템에서 반복 실행하여, 빌드 결과가 완벽히 같음을 입증함
     * 줄바꿈 방식, 대소문자, 테스트 결과 포맷 등 미묘한 차이를 수개월 동안 디버깅하며 해결함
     * 'Green across the board' (양쪽 시스템 모두 테스트 통과) 성과로, 실제 전환 단계 진입 준비 완료함

인간 중심의 접근법

  다중 채널, 반복 소통

     * 4,000명+ 엔지니어와 수십 팀의 스케줄을 맞추기 위해, 각 팀별 챔피언과 집중적인 커뮤니케이션 체계를 구축함
     * 중요 공지는 최소 3회(이메일, Teams, 위키, 미팅 등) 반복 전달해 혼선 최소화함
     * 문제 발생 시, 즉각적이고 투명한 정보 공개로 신뢰 확보

  Git 도입 교육 및 적응

     * 10년간 Source Depot에 익숙한 엔지니어를 위해 실습형 교육 환경과 전환 명령어 안내 등 단계적 학습 체계를 마련함
     * 실전 중심의 비디오 라이브러리 등을 통해 실제 시나리오 기반 학습 제공
     * 불안 해소와 역량 강화를 넘어서 기존 워크플로우 적응 지원

  롤백 전략과 안전 장치

     * 실제 전환 시 Director에게 '레드 버튼'을 제공, 심각한 문제시 언제든 즉시 롤백 가능
     * 과거 Source Depot의 일부 기록은 오랜 기간 보존, 기존 개발 히스토리 안전하게 유지

결과와 주요 성과

     * 이전 후 온보딩 시간 50% 단축, Git 선호도 89% 확인, 빌드 성능 개선, 코드 리뷰 효율성 및 협업 증가 등의 생산성 향상 효과가 나타남
     * 엔지니어들은 산업 내 변환 가능한 기술 습득을 긍정적으로 평가함
     * 신규 인력의 바로 투입 가능성도 높아짐

  대규모 마이그레이션 핵심 교훈

     * 기술 요소뿐 아니라 사람 중심의 소통에 예상을 뛰어넘는 투자를 해야 성공 가능
     * 병행 시스템 구축과 완벽 동등성 입증, 초기부터 확실한 롤백 설계, 핵심 인력(챔피언) 강조
     * 만족도 등 정성적 지표 병행 측정이 반드시 필요하며, 변화 과정에서 조직적 안정과 심리적 안전 감각이 중요
     * 대규모 변화의 본질은 조직 전체의 유연하고 체계적인 변화 관리임

결론 및 향후 적용

     * Office의 Git 마이그레이션은 수년간의 준비, 수개월의 실행으로 이뤄진 역사적 프로젝트였음
     * 궁극적으로 수천 명의 업무 연계성을 보장하며 조직적 변화를 성공적으로 추진한 사례로 남음
     * 클라우드 전환, 모놀리식 아키텍처 분해, 프레임워크 업그레이드 등 다른 대규모 변화에서도 병행 검증, 반복적 소통, 신속 롤백 설계가 동일하게 적용될 수 있음
     * 기술적 상세(빌드 인프라, 오프라인/계약 이슈 등)는 추가적으로 다루지 않았으나, 대규모 기술 변화의 전략적·조직적 접근이 가장 중요한 교훈임

   바이너리 파일을 많이 다룬다면 git이 어울리지 않을 수 있지만 코드 중심의 레포지토리라면 git으로 충분한 것 같아요.

   MS 내부에서도 큰 변화였겠지만 덕분에 partial clone, sparse checkout 같은 기능들이나 Scalar 같은 도구들이 외부에도 공개되어 사용할 수 있게 된 점도 좋은 영향인 것 같습니다 ㅎㅎ

        Hacker News 의견

     * 언제나 이 오래된 이야기를 새롭게 풀어주는 글을 읽는 것은 즐거움이라는 생각임 TFA에서는 “오피스 저장소 전체를 가져오는 데 몇 시간이 걸렸다”는 점을 언급하면서, 사실 git에서는 VFS 같은 새로운 파일 시스템 없이는 이런 작업 자체가 거의 불가능했다는 점을 사실상 생략하고 있다는 지적임 Perforce에서는 사용자가 필요한 부분만 체크아웃할 수 있었으니, 대부분의 Source Depot 사용자도 매번 오피스 전체 앱을 가져오는 게 아니라 필요한 부분만 가져왔을 것으로 추정함 VFS는 git에서 필요한 객체만 다운로드받게 하여 이런 격차를 좁혀줌 Perforce/Source Depot은 중앙집중형 VCS로 당시에 굉장한 선택지였지만, 이제는 시대가 바뀐 느낌이라는 소감임
          + Perforce에서도 VFS처럼 필요한 순간에만 파일을 가져오는 자체 기술을 만든 회사가 있다는 설명임 이는 게임 개발에서 텍스트 파일과 함께 대용량 바이너리 소스 자산을 보관할 때 특히 중요함 윈도우에 내장된 원격 드라이브 프로그램이 사용하는 기술과 뿌리가 같다고 생각함 개인적으로는 회사 전체 소스를 저장하되, 로컬에 전체 히스토리를 복제할 필요 없이 서버 기반 VCS를 여전히 원함 하지만 git이 여러 기기 간 단발성 협업에는 충분히 쓸 만해서 중앙 서버와 CI/CD 파이프라인까지 구축할 필요성을 아직 못 느낌 git에서 stash, hunk 단위 stage, 인터랙티브 rebase 등 다양한 워크플로우를 매우 선호함
          + 우리 회사는 아직도 perforce를 쓰고 있음, 이제는 아무도 perforce를 좋아하지 않는다는 유감임 신입들에게 “우리는 git 안 써요”라고 말하는 순간 그들의 눈빛에서 빛이 사라지는 걸 직접 봄
          + VFS는 Perforce를 완전히 대체하지 못함 실제로 AAA 게임 회사 대부분이 여전히 Perforce를 사용 중이라는 점을 강조함 자산 파일에 락(lock)을 걸어 두 명이 동시에 수정해 병합 불가능한 상황을 방지해야 하고, 한 아티스트의 작업 결과를 버려야 하는 시간 낭비를 줄이는 데 필수적임
          + git이 왜 아직까지도 저장소 트리의 특정 부분만 선택적으로 체크아웃하는 기능을 제공하지 않는지 솔직히 의아함 객체 파일 등을 이해하는 중간 서비스를 붙이면 쉽게 확장할 수 있다고 생각함
     * 2016년 Microsoft 인턴십에서 Source Depot을 지원하는 자동 코드 리뷰어를 만들면서, Source Depot이 뭔지도 모르고 거의 일주일을 이 기능에 쏟은 경험이 있음 (https://austinhenley.com/blog/featurestheywanted.html) 그때도 여전히 많은 개발자들이 Source Depot을 쓰고 있었음 지금은 다 git으로 옮겨갔는지 궁금함
          + CodeFlow를 매일 그리워함 정말 멋진 툴이었다는 감정임
          + 여전히 Source Depot이 활발히 쓰이는 영역이 많다는 얘기임 Source Depot 명령어들과 환경 설정이 늘 나를 긴장하게 한다는 느낌
          + 일상적인 업무의 대부분은 이제 git에서 처리하고 있다는 근황임
     * 90년대에 직접 vss(Visual SourceSafe)를 사용한 입장에서, 이번 기사에서 그 이야기가 언급조차 안 된 점이 놀라움 Visual SourceSafe는 Microsoft가 자체적으로 만든 소스 버전 관리 프로토콜이었는데, Source Depot은 Perforce에서 라이선스 받아서 사용한 것과 차이가 있었음
          + VSS(Visual SourceSafe)는 Raleigh의 One Tree Software를 인수해서 받아들인 제품이었고, 제품명을 “SourceSafe”에서 “Visual SourceSafe”로 바꿔 Visual C, Visual Basic 등과 같이 번들로 제공했음 그 이전에는 “Microsoft Delta”라는 버전 관리 제품을 팔았는데, 가격은 비싸고 품질은 떨어졌으며 NT에서 아예 지원도 안 됨 One Tree 인수로 들어온 인물 중에 Brian Harry가 있는데, 이 분이 Team Foundation Version Control(TFS)을 이끌었음 SQL Server를 저장소로 사용하면서 VSS보다 관리성과 신뢰성이 크게 향상됨 Brian Harry는 지금 은퇴한 듯하고 블로그도 더 이상 업데이트되지 않음 당시 VSS를 쓰며 기억나는 것 중 하나는 네트워크 파일 락킹을 SMB로 처리해서 빈번한 네트워크 오류에 취약했고, 저장소가 손상되는 일이 자주 있었음 그래서 매일 새벽에 복구하는 배치 작업을 걸어 야간에 자동
            복구시켜야 했음 아침에 쓸 수 있어야 했기 때문임
          + 90년대에 VSS 썼던 경험상, 팀으로 일할 때는 악몽에 가까웠으며, 알고 있기로는 Microsoft도 내부적으로는 거의 안 썼던 것으로 기억함
          + 90년대에 혼자 개발할 때 VSS를 썼었는데, 당시로선 신세계 같았음 대학원에서 다른 VCS(RCS, CVS 등)를 접했음 2004년에 마이크로소프트에 입사했을 때 누군가 VSS는 비안전적이고 손상되기 쉽다고 설명해줬던 게 기억남 그게 사실인지는 모르겠지만, 어쨌든 회사에선 VSS가 아예 선택지조차 아니었음
     * Microsoft를 XNS에서 TCP/IP로 마이그레이션할 때 팀원이었음 이 작업은 생각보다 별로 복잡하지 않았지만, 비슷한 교훈을 얻었음 MSMAIL에서 Exchange로 옮기는 건 정말 힘들었음
          + 예전에 “Exchange: The Most Feared and Loathed Team in Microsoft”라는 문구가 적힌 번호판 프레임을 봤었음, 이게 그때 경험 때문인지 궁금함 20년 전이라 정확한 표현은 기억 안 남
     * “Authenticity mattered more than production value”가 정말 와닿음 출퇴근 직전(2015년)에야 Source Depot에서 Git으로 전환하기 시작한 소규모 제품 라인에서 일했던 전 마이크로소프트 직원으로서 이런 작업에 얼마나 많은 노력이 들었는지 완전히 공감함 정말 멋진 업적임
          + 나 역시 이런 과정을 다 겪은 게 믿기지 않는다는 생각임 고마운 마음이라는 메시지임
     * 2000년대 초반 Microsoft가 고민했던 상황을 보면, Windows가 엄청나게 복잡해지고 수백만 줄 코드가 버전 관리를 필요로 했지만 git은 아예 없었고 SVN도 막 성장하던 시절이었음 Microsoft가 1998년에 개발돼 2000년 공개된 BitKeeper 같은 상업용 제품도 적극 고려했었는지 궁금함 아마도 당시에는 Perforce 같은 중앙집중 시스템이 대세였고, BitKeeper 같은 분산형은 이질감 있거나 검증된 사례가 부족했을 수도 있겠다는 추측임
          + 당시에는 VSS(Visual SourceSafe)도 있었고 이후에는 TFVC가 있었음
     * 나 같은 초보 엔지니어에게 Source Depot의 미스터리를 알려준 개발 리드들에게 고마움 전함 Source Depot 구조를 제대로 이해하자 정말 눈이 번쩍 뜨이는 경험이었음 나는 WinCE와 IE에만 의존이 있어서 복제(clone)에 20분밖에 안 걸렸지, 며칠씩 걸리지 않아서 다행이었다는 생각임 도움을 줬던 분들 이름은 잊었지만, 신입을 도와 쉽게 일 시작하게 해주려 한 자세만큼은 지금 내 팀에서도 계속 이어가며 실천함
     * 대부분 사람들이 git 도입을 기술적 승리로 기억하지만, 사실 진짜 혁신은 개발자 개개인이 스스로 워크플로우를 제어할 수 있게 된 점임 더 이상 동기화 창 기다릴 필요도, 브랜치 접근 권한을 리드에게 부탁할 필요도 없음 이제 모두가 자유롭게 속도 내며 일하면서도 서로 충돌하지 않는 환경이 됨 이 변화가 생산성 대시보드보다 분위기 개선에 훨씬 큰 영향을 줬다는 강한 인상임 git은 단지 도구뿐만 아니라 개발 루프에 대한 신뢰까지 바꿔준 계기였음
     * Microsoft가 내부적으로 Visual SourceSafe에서 언제 벗어났는지 궁금함 더 일찍 단종해 외부에서 계속 쓰이는 일만큼은 막았어야 했다고 생각함
          + 대부분 팀이 VSS를 실제로 쓰지 않았으리라 생각함 Microsoft에서 일하면서 우리 팀은 Source Depot을 사용했다는 경험임 당시 TFS도 경험했는데 별로 좋아하지 않았음, 그럼에도 Source Depot 쓰고 나니 오히려 TFS가 그리워짐
          + Microsoft 내부에서 VSS를 주요 용도로 썼는지 의문임 만약 진짜 내부에서 썼다면 그렇게 허술한 제품 상태로 내놓진 않았을 거란 생각임 TFS는 좀처럼 이해할 수 없는 경험이었고, 내부든 외부든 별로 였음
          + 2000년 즈음이었을 것으로 추정함 내가 아는 한 유일하게 쓴 프로젝트는 .NET이었는데, 그마저도 이미 Source Depot으로 넘어가 있었음
          + Microsoft SourceSafe가 있다는 사실조차 몰랐다는 반응임
     * OneNote shallow clone이 200GB라는 얘기를 잘 이해하지 못하겠음
          + 실제로는 OneNote가 아니라, office 전체 shallow clone이었다는 설명임
          + 비디오나 대용량 바이너리가 포함되어 있었던 것으로 추정함
"
"https://news.hada.io/topic?id=21406","Android 16 출시 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Android 16 출시

     * Android 16이 공식 공개되어 Pixel 기기부터 정식 배포되며, 올해 내 다양한 브랜드로 확장될 예정임
     * 실시간 알림 업데이트, 앱별 알림 자동 그룹화 등으로 정보 과부하를 줄이고, 사용자 경험을 대폭 향상함
     * Material 3 Expressive 디자인을 위한 토대가 마련되고, 접근성과 사용 편의성이 강조
     * 청각 보조기기 사용자 지원 강화로, 통화 중 휴대폰 마이크 전환 및 기기 볼륨·설정 제어가 OS 수준에서 가능해짐
     * 단 한 번의 탭으로 활성화하는 Advanced Protection을 도입해, 온라인 공격·악성 앱·피싱·스팸콜 등 최고 수준의 모바일 보안을 제공
     * 태블릿·폴더블 환경에서 데스크톱 윈도우 관리, 커스텀 단축키, 태스크바 오버플로우 등 생산성 기능이 강화됐으며, 외부 디스플레이 연결/확장 지원도 순차 적용 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Android 16 주요 특징

     * 실시간 알림과 그룹화
          + 배달/이동 서비스 등 실시간 상태 변화를 앱에 들어가지 않아도 바로 알림으로 확인할 수 있음
          + 동일 앱의 다수 알림이 자동으로 그룹화되어, 알림 센터가 깔끔하게 유지되고 정보 과부하를 방지함
     * 청각 보조기기 지원
          + LE 오디오 지원 보청기 사용 시, 내장 마이크 대신 휴대폰 마이크로 전환 가능해 소음 많은 환경에서 통화 품질이 개선됨
          + 볼륨·프리셋 등 보조기기 제어를 안드로이드에서 바로 제공, 더 직관적이고 일관된 사용자 경험 제공
     * 한층 강력해진 보안
          + Advanced Protection 모드를 단 한 번의 탭으로 활성화 가능
          + 온라인 공격, 악성 앱, 위험 사이트, 스팸콜 등 모바일 보안이 대폭 강화되어, 일반 사용자부터 공인까지 모두 안심할 수 있는 환경 구현
     * 태블릿/폴더블 생산성 강화
          + 삼성 DeX 협업 기반 데스크톱 윈도우 관리 기능 도입: 여러 앱을 윈도우처럼 띄우고 이동·크기 조절 가능
          + 커스텀 키보드 단축키, 태스크바 오버플로우 등 데스크톱 환경에 가까운 UX 제공
          + 향후 업데이트를 통해 외부 디스플레이 확장, 연결 기기 간 멀티 디스플레이 연동 등 추가 생산성 기능 예정
     * 기타 개선 사항
          + HDR 스크린샷, 적응형 주사율, 신원 확인 등 다양한 신기능과 Pixel 디바이스 대상 추가 업데이트도 함께 배포
          + Material 3 Expressive 디자인 업데이트가 올해 안드로이드 16 및 Wear OS 6에도 적용될 예정

모든 Android 16 기능 : Android.com/16

     * 생산성 & 사용자 경험
          + Notification auto-grouping (알림 자동 그룹화)
               o 한 앱에서 발생한 여러 알림을 자동으로 묶어 정리, 알림 센터의 혼잡을 최소화
          + Live updates (실시간 알림)
               o 배달/이동 경로 상태를 잠금 화면에서 실시간으로 확인 가능, 라이브 트래킹 지원
          + Desktop windowing (데스크톱 윈도우 관리)
               o 태블릿·폴더블에서 여러 앱을 데스크톱처럼 윈도우로 띄워 배치/크기 조절 가능
          + Custom keyboard shortcuts (커스텀 키보드 단축키)
               o 사용자 정의 단축키로 워크플로우를 맞춤화
          + Taskbar overflow (태스크바 오버플로우)
               o 태스크바가 꽉 찼을 때 확장 창에서 추가 앱들을 빠르게 검색/실행 가능
          + Predictive back indicator (예측 백 인디케이터)
               o 뒤로가기 동작 시 이전 화면 미리보기로 탐색 경로를 직관적으로 파악
     * 접근성 & 맞춤화
          + Hearing device support (청각 보조기기 통합)
               o 보청기 등 보조기기 연결 시, 볼륨/마이크/프리셋 설정을 안드로이드에서 직접 제어
               o 접근성 공식 안내
          + Slider haptics (슬라이더 햅틱)
               o 음량·밝기 등 슬라이더 조작 시 햅틱 피드백 제공, 촉각적 컨트롤로 사용자 경험 향상
               o 자세히 보기
          + Adaptive refresh rate (적응형 주사율)
               o 배터리 효율과 부드러운 화면 전환을 동시 구현하는 주사율 자동 조정
          + HDR screenshots (HDR 스크린샷)
               o HDR 품질 스크린샷 저장 지원
               o 자세히 보기
     * 보안 & 개인정보 보호
          + Advanced Protection (고급 보호 모드)
               o 모바일 보안의 최고 수준 기능을 한 번의 탭으로 활성화, 피싱·악성 앱·위험 사이트·스팸콜 등 광범위한 공격 방어
               o 자세히 보기
          + Identity Check (신원 확인)
               o 신뢰되지 않은 장소에서 기기 탈취/도용 방지를 위한 신원 확인 기능
               o 자세히 보기
          + Trade-in mode (트레이드인 모드)
               o 중고·교환 시 데이터 이전/보안 초기화를 빠르게 지원

        Hacker News 의견

     * 나는 이제 Material Expressive 디자인이 애플의 대대적인 공개 이후 훨씬 더 마음에 드는 상황임을 느낌 색감이 여전히 내 취향엔 다소 컬러풀하고 장난스러운 느낌이 있으나, 내가 생각하는 최고의 UX 디자인 이상에 훨씬 더 가까운 모습임 즉 명확성, 가독성, 그리고 <i>사용자를 방해하지 않는 것</i>에 집중한 느낌이 있음 반면 새로운 iOS는 화면마다 UX 디자이너가 “내가 얼마나 대단한지 좀 봐!”라고 외치는 느낌만 남음
          + 시간이 갈수록 모바일 OS 업데이트에 대한 흥미가 점점 떨어지는 중임 Google Nexus 1부터 스마트폰을 써왔는데 데스크탑 경험이 언제나 더 낫고, 좋은 책이 훨씬 더 매력적임 다른 사람들은 어떤 생각인지 궁금함 요즘 모바일 툴 대부분은 정말 필요 없는 장난감 또는 사치 같음 우리 가족 중에도 iOS의 전화 아이콘이 FaceTime인지 “진짜” 전화인지 헷갈려 하는 사람이 많고, FaceTime 통화 걸려면 한 번만 누르는 게 아니라 여러 번 클릭해야 해서 번거로움 그런데 애플은 Liquid Glass 같은 것에 집중하고 있는 상황
          + Material 디자인의 레이어 분리가 개인적으로 굉장히 별로였던 경험임 Floating Action Button이 너무 눈에 잘 띄지 않아서, 실제로 IT 지원을 받은 적도 있음 Liquid Glass의 ‘굴절 효과’는 아직 안 써봤지만, 레이어 분리를 확실하게 줄 수 있을 것 같은 기대감이 있음 정적인 컨텐츠엔 별로지만, 움직임이 들어가는 순간 눈이 바로 알아챌 수 있을 만한 섬세한 움직임 전달 기대감이 있는 상황
          + Material은 무난하지만 영감이 느껴지지 않는 디자인임 회사용 미술작품 같은 UI 느낌이고, 큼지막한 플랫한 영역, 흐릿한 파스텔 색상 등이 특징임 새로운 iOS 데모를 보니 몇몇 대비 문제만 해결된다면 업데이트를 기대해보고 싶은 마음이 생김
          + Material Expressive에 가장 불만인 점은 버튼마다 85%가 패딩이고 실질적 컨텐츠는 15%에 불과하다는 점임 예전처럼 적당한 정보 밀도는 어디로 갔는지 의문임
          + 애플의 몰락에 큰 공감을 표하는 상황
     * ""안타깝게도 안드로이드가 변화하여, Android 16과 이후 버전으로 포팅하기가 훨씬 더 어려워졌다는 상황임 새로운 Pixel 기기 지원 역시 훨씬 어렵게 될 예정임 그래서 예상보다 더 빨리 GrapheneOS 전용 기기를 만들게 될 가능성이 큼"" (원문 링크)
          + 이 프로젝트를 정말 좋아함, Android 커스텀 롬의 정점이라 생각함 그런데 정확히 무엇이 변해서 이렇게 포팅이 힘들어지는지 궁금함
          + 구체적으로 포팅을 힘들게 만든 변화가 뭔지 궁금함
     * 저런 신규 기능과 도구들은 사실 데이터를 쉽게 모으는 무기라고 생각함 Pixel 7 Pro에 GrapheneOS를 설치해서 사용 중이며, AndroidOS로는 절대 돌아가지 않을 생각임 GrapheneOS는 정말 비교할 수 없는 수준의 프라이버시와 통제력을 제공하고, 보안 업데이트도 항상 구글보다 빠름 GOS 측에서 발견한 취약점이 구글보다 먼저 배포된 경험도 생김 나는 이미 De-Google을 오래전에 완료해서 앱 대신 웹버전을 쓰고 있지만, 다른 사람들이 폰에서 얼마나 쓰레기 같은 게 돌아가고 있는지 알면 좋겠다는 생각임 하지만 결국 TV가 별로라서 YouTube는 여전히 쓰고, YouTube Music도 콘텐츠 부족 때문에 다른 서비스로 못 넘어감 최근 몇 년간 모바일 OS 업데이트는 대부분 똑같고 심지어 애플은 더 별로라는 느낌임 게다가 이제는 AI가 여기저기 추가되며 상황이 더 악화되고 있음 AI가
       의미하는 건 결국 더 많은 데이터 수집과, 로컬이 아니라 클라우드 기반 서비스가 늘어나서, 머지않아 모든 게 구독제로 바뀔 거라는 점임 빅테크의 세계에선 결국 다 공짜가 아님, 구독료를 내든 개인정보로 지불하든 둘 중 하나라는 진리임
     * “보청기와의 통화가 더 명확하고 단순해지는 부분”이 정말로 중요한 의미임 지금은 통화 시 보청기가 풀 듀플렉스로 동작해서 입력과 출력을 동시에 담당함 채널 대역폭이 두 개로 분리되므로 음질이 상당히 나빠지고, 듣기 힘든 사람들에게는 정말 최악임 음악을 들을 때 보청기 볼륨은 주변 소리와 음악 모두를 조정할 수 있는데, 전화 통화 모드에선 폰이 볼륨 컨트롤을 완전히 가져가서 시끄러운 환경에선 볼륨을 올리는 순간 주변 소리까지 너무 커지는 문제가 발생함 마이크도 내 목소리는 소거하고 상대방 소리만 들으라는 식으로 설계돼 있어서 남들이 내 음성에 대해 불평하는 경우가 많음 결국 ""이렇게 들을 건지 아예 통화하지 않을 건지"" 둘 중 하나로 양해를 구하는 상황이 됨 이런 설계는 원래 BT 헤드셋용이라 이해는 되나, 보청기는 헤드셋이
       아님을 알아주면 좋겠음 리눅스에서는 마이크와 모드를 직접 골라서 사용할 수 있어 10년동안 완벽하게 동작함, 이런 게 진짜 유저 프렌들리한 UX 의미임 윈도우에서는 아주 숨겨진 구식 설정에서 블루투스 기기 마이크 비활성화 가능하고, 맥OS에서는 옛날 Audio MIDI Setup 툴로 할 수 있음 물론 맥OS에서는 a11y 관련 설정처럼 종종 리셋되는 문제가 있음 iOS에서는 잘 모르겠고, 궁금한 상황임
          + LE Audio 지원이 있어야만 가능한 기능이고, LE Audio를 지원하는 보청기가 많지 않음 1년 후에 다시 확인해볼 생각임
     * “Android 16에서 Advanced Protection을 활성화할 수 있고, 온라인 공격, 해로운 앱, 위험한 웹사이트, 스팸 전화 등으로부터 사용자를 보호할 강력한 디바이스 보안 기능 제공” 등등 문구가 등장함 내 예상엔: 이런 ‘Advanced Protection’ 기능은 이름만 보안을 표방하고 실제로는 점점 사용자 자유를 제한하는 방향으로 발전할 가능성이 크며, 결국 모두에게 강제 적용되는 날이 올 것임 전형적인 구글의 행보로 생각됨
          + 내 생각엔 구글이 iOS의 Advanced Data Protection 및 Lockdown Mode를 따라 하는 것 같음 애플의 “우리는 프라이버시 기업”이라는 주장에 대응해 보안 이슈를 차별화하려는 움직임임
     * android.com/16에서 단순 하이라이트 외 추가 정보 확인 가능
          + 내가 제출한 링크와 이 링크 사이에서 고민했는데, 리디자인이 추후 적용 예정이라 내가 선택한 링크로 제출함 정보 추가해줘서 고마움
     * 애플의 새로운 글라스 디자인이 출시된 이후, Material Expressive가 미적으로 더 매력적으로 보임 애플이 이렇게까지 쇠퇴한 현실이 참 아쉬움
          + 정말 안타까운 상황임 둘 다 개인적으로는 끔찍한 디자인 결정이라 생각함 Glass 자체도 불편하고, “공간 컴퓨팅의 미래에 대비한다”는 말도 최소 5~10년 이상 남은 허상임 현재 형태의 Apple Vision으로는 절대 실현 불가임 한편 Material Expressive는 2020년대 그래픽 트렌드를 모바일 앱에 억지로 적용하는 느낌임 디자이너들이 “뭔가 새롭고 현대적인 걸 해보자”라는 심산으로 회사형 모던 디자인을 만든 듯한데, 실제로는 UI에 치중하고 UX는 희생되는 결과임 구글 디자이너들이 “사용자들이 이 버튼을 30% 더 빨리 찾게 됐다”고 말해도, 엄청난 비용을 들여 리디자인한 거면 그 정도는 당연한 결과임 어차피 앱들은 각자 고유 스타일로 계속 출시될 것임 애플은 iOS 26에 Liquid Glass 지원을 새로 넣을 것이고 신규 앱에서 그것을 쓸 것임 동시에 구글은
            개발자용으로 일부 새로운 Material 컴포넌트만 부분적으로 제공할 것 그 중 일부는 디자인 가이드에 명시된 기능이 없거나, 아예 쓸 수 없을 수도 있음 구글이 개발 경험(DX) 개선에는 전혀 신경 쓰지 않는 모습임
          + 첫 번째 개발자 전용 베타 릴리스 뜻인지 궁금함
          + 애플은 AI에 대한 부족함을 감추기 위해 절박하게 새 시도를 한 것일 수도 있다는 생각임
     * “삼성 DeX는 폰, 폴더블, 태블릿에서 생산성을 극대화 해왔음 Android 16에서는 삼성과 긴밀하게 협력해서 데스크톱 윈도잉을 개발함 이제 대화면 기기에서 새로운 방법으로 앱과 컨텐츠를 다룰 수 있음” 이런 표현에서 ‘긴밀하게 협력했다’는 게 무한한 SW 리소스를 가진 회사에게 어떤 의미인지 의문임 소프트웨어 측면에서 삼성이 도대체 무엇을 제공한 것인지 궁금함 PS 미래를 예측하자면, Android의 데스크톱 모드가 발전해 사람들이 Windows를 버리고 그저 폰을 USB-C 도킹에 꽂아서 키보드, 마우스, 디스플레이로 쓸 것임 (나는 리눅스 유저지만, 사람들이 Windows에서 Android로 옮기는 걸 보게 될 것 같음)
          + ‘무한한 소프트웨어 자원’에 대해선 동의할 수 없음 ‘Android 데스크톱 모드가 발전해 사람들이 Windows를 버릴 것’에 대해서는 공감함 실제로 2017년에 Samsung Tab S3랑 DeX를 써서 데스크탑 PC를 대체하려 했는데, 그때는 DeX 브라우저에서 작동하지 않는 웹사이트가 많았음 거의 10년이 지난 지금엔 괜찮을 거라 예상함 구글이 삼성의 작업 결과만 슬쩍 가져가지 않은 점은 칭찬함
          +

     “무한한 소프트웨어 리소스를 가진 회사가 왜 삼성이 필요하냐?”란 질문에 대한 답으로, 삼성은 이미 그 여정에서 많은 교훈을 얻었고, 구글은 그렇지 않다는 점을 지적함 또한, Android 전략상 구글은 OS 기능에서 벤더와 경쟁하지 않고, 오히려 협업을 통해 개선 사항을 OS로 돌려받는 방식을 선호함 이 전략은 프로젝트를 더 빠르고 저렴하게 만들고, 분열도 줄이며, 한편으로는 경쟁자(삼성)를 줄이는 효과도 있음 무엇보다 안드로이드 생태계 내 브랜드 충성도를 줄여줘서, 예를 들어 Samsung DeX가 Android에 통합되면 삼성 유저들이 브랜드를 옮기기 쉬움
          + 이 기능의 미래는 무시할 수 없을 정도로 중요함 마치 인터넷 다이얼업 시대에 콜 인터럽트 기능을 도입하는 것과 같은데 모두 DSL로 옮긴 뒤에야 들어온 느낌임 Windows Lumia가 OS 개발사로서 최초로 이런 기능을 제공했고, 삼성은 프리미엄 하드웨어로, 애플은 iPad용 Stage Manager라는 방식으로 유사 기능을 제공하지만 iPhone엔 포함시키지 않았음 하지만 정작 이 기능에 신경 쓰는 사람은 거의 없음 실제 기능 자체는 표준 해상도의 디스플레이에 앱을 띄우는 것임, 앱들이 창처럼 크기 조정이 되는 구조 Android에서는 Sense 같은 앱을 다운받아서 할 수 있었지만 그 시절에는 앱 개발자들이 크기 조정 가능한 앱을 만들지 않았음 ‘긴밀하게 협력’의 일부분이, 개발자들이 앱을 리사이즈할 수 있게 만드는 쪽임 개발자가 거부하면 OS가 대신 앱 윈도 크기를 조정해
            주는 방향
          +

     “Android Desktop mode가 점점 개선되어 사람들이 Windows를 버리고 모바일 도킹으로 옮기는 시대가 올 것이다”란 의견에, DeX 사용 영상을 보면 기능은 정말 좋아 보이지만 이상하게 대중적으로 확산되지 않는 원인을 모르겠음 비즈니스용 app 에코시스템이 충분하지 않은 게 원인인지 궁금함 “이제야 모바일 도킹이 워크스테이션을 대체하는 해가 올 거다”라는 말을 “이 해가 데스크톱에서 리눅스가 대중화 되는 해”라는 농담만큼 반복하게 되는 상황임
          + 내 생각에 앞으로 어떤 앱 개발자도 Android Desktop mode에 진지하게 투자하지 않을 것 같음 구글이 언제 이 기능을 버릴지 몰라서 함부로 지원 못하는 분위기임 결국 2~3년 내 앱 지원 부족으로 데스크톱 모드는 폐기될 것임
     * Material 3 Expressive와 Liquid Glass를 비교할수록 Pixel로 다시 옮기고 싶어지는 기대감이 커짐 컬러풀함, 모션, 다양한 도형을 쓰는 점이 투명도 위주, 낮은 대비, 색상 부족에 비해 더 매력적임 지금 iPhone 13 Pro Max를 쓰는데 성능은 아직 괜찮지만 배터리 노화가 눈에 띄는 시기임 게다가 USB-C를 지원하지 않는 유일한 기기라서 새 Pixel로 바꾸면 좋겠다는 생각이 듦
          + 이번 WWDC가 내겐 결정타였음 애플이 본질을 놓치고 또다시 자기 과시에 빠진 모습임 다시 Pixel로 넘어가면서 앞으로 Liquid Glass를 안 봐도 된다는 점이 기쁨
          + Pixel로 옮기고 싶지만, 하드웨어 가치가 Samsung이나 OnePlus에 비해 뒤처지는 느낌임 Pixel이 항상 1~2년 뒤쳐지는 기분임
     * Android 알림 기능이 좋아 보임 나는 거의 iOS만 써왔지만, 알림은 iOS의 약점이라고 생각함 홈 화면에 남아있는 알림 숫자를 자주 보는데, 일단 폰을 잠금 해제하고 나면 알림을 다시 찾기가 거의 불가능함
          + “강제 그룹화” 옵션을 도입한 점이 만족스러움 그룹화는 선택적으로 제공될 때 좋은 기능이지만, 그 결정권이 앱에게만 있었던 것이 문제였음 앱 개발자들이 항상 똑똑하게 행동하지 않기 때문에, 사용자가 직접 컨트롤할 수 있는 옵션이 필수임
          + 전체적으로 Android 알림이 iOS보다 낫다고 생각하지만, live activities 같은 기능은 좋은 아이디어였기 때문에 Android에 추가돼서 기쁨
          + 내가 뭔가 잘못 쓰는 건가 싶은데, iOS에서 알림이 클릭 후 그냥 사라지는 경우가 있음 아마 FaceID 인식 실패 때문인 듯함 (특히 iPhone 11에서 더 심함) 3번 실패하고 나면 알림을 클릭해도 실제로 잠금이 풀리지 않으니 알림이 완전히 사라진 듯함
          + 잠금 해제 후 상단에서 아래로 스와이프 하면 Notification Center가 열림
          + 내 입장에선 이번에 안드로이드가 추가한 알림 기능은 애플이 이미 몇 년 전부터 가지고 있던 내용 같음
"
"https://news.hada.io/topic?id=21375","Shawn Mendes 찾기 (2019)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Shawn Mendes 찾기 (2019)

     * 유명 인사의 정치적 입장이 사회에 미치는 영향에 대한 분석임
     * Shawn Mendes가 Kuril Islands 영토 문제에 대해 공개적으로 언급하지 않은 점에 착안하여 그의 노래 가사에서 간접적인 메시지를 찾으려는 시도임
     * Mendes의 싱글 ""Lost in Japan""의 가사 해석을 통해 실제로 Mendes가 어느 지역에 있었는지 분석함
     * 다양한 지역, 항공편 스케줄, 시간대, 지리적 조건을 근거로 Kuril Islands 근처 러시아에서 일본으로 이동하는 설정 가능성을 도출함
     * 결론적으로 Mendes가 Kuril Islands를 일본으로 간주하는 견해를 노래 가사 속에서 드러냄
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

유명 인사의 정치적 발언과 영향

     * 오늘날 유명 인사는 정치적 영향력이 커지는 양상임
     * Oprah Winfrey의 Barack Obama 지지, Taylor Swift의 투표 독려 등 유명 인사의 발언이 민심에 큰 영향을 미친 사례가 있음
     * 소셜 미디어의 발달로 인해 대중은 점점 더 유명 인사의 정치적 의견을 궁금해하고 있음
     * 하지만 모든 인물이 입장을 공개하는 것은 아니며, Shawn Mendes처럼 조용한 경우도 있음

Shawn Mendes와 Kuril Islands에 대한 질문

     * Shawn Mendes는 캐나다의 유명 팝 가수임
     * 저자는 ""Mendes가 Kuril Islands 영토 분쟁에서 어떤 입장일지"" 매일 궁금해하는 사례를 유머러스하게 제기함
     * 실제로 Mendes는 이 주제에 대해 공개적으로 언급한 적이 없음
     * Google 등에서 관련 입장을 찾아봐도 정보 부재

“Lost in Japan” 가사에 숨겨진 메시지

     * 저자는 Mendes의 2018년 곡 “Lost in Japan” 가사에서 정치적 메시지가 숨겨져 있을 가능성을 탐색함
     * 가사에 따르면 Mendes는 ""일본에서 수백 마일 떨어진 곳""에 있으며, 일본에 있는 친구를 만나기 위해 호텔로 가겠다고 계획함
     * 이 위치가 지리적으로 어디를 의미하는지 분석이 시작됨

가사와 위치 추정 분석

     * 가사에서 ""수백 마일"", “한 번의 비행”, “같은 시간대” 등 지리적 힌트가 제시됨
     * 일본에서 200마일 반경 내 육지는 한정적임
     * South Korea는 동일 시간대이기 때문에 제외
     * 중국(Shanghai-Fukuoka 거리 545마일) 은 ""수백 마일"" 기준에 맞지 않음
     * Ryukyu Islands, 특히 Ishigaki와 타이베이(약 200마일 거리)에 주목하지만
          + 직항이 하루 한 편(주간 비행)이고 (밤 비행 아님)
          + Mendes는 최근 모기에 알레르기 있다고 밝힌 바 있으며, 타이베이에서는 모기 출현 빈번

러시아 극동과 Kuril Islands 추적

     * 남는 가능성은 러시아 극동 지역에서 일본(또는 Kuril Islands)으로 비행하는 상황임
     * Sakhalin Island(Yuzhno-Sakhalinsk)에서 일본(삿포로)으로 가는 항공편 분석
          + 비행편은 일요일 저녁에 한정되어 있음
          + 비행시간, 입국 심사 등 고려 시 가사와 완벽히 부합하지 않음

Kuril Islands와 실제 비행편

     * Yuzhno-Sakhalinsk에서 Iturup Island, Kunashir Island(모두 Kuril Islands 소속) 로 가는 항공편(특히 일요일 저녁 비행) 존재
          + Iturup 도착 시간(오후 8시 50분)은 친구가 ‘잠들기’ 전에 도착할 만함
          + 러시아 내 국내선이므로 입국 심사가 불필요
          + “몇 시간 안에 도착”이라는 가사의 시간 설정에도 부합

Kuril Islands 영토 분쟁 배경

     * Kuril Islands는 과거 한일 간 조약에서 분리 소유로 정해졌으나, 2차 세계대전 이후 러시아가 남쪽 4개 섬을 점령
     * 일본은 현재도 이 섬들의 주권을 주장

결론 및 상징적 입장

     * Mendes가 “Lost in Japan”에서 언급한 ‘일본’은 실제로 Kuril Islands(특히 Iturup Island) 로 해석될 수 있음
     * 이는 Mendes가 Kuril Islands를 일본의 영토로 간주하는 정치적 입장을 드러내는 해석 가능성
     * 저자는 Mendes의 이 '은유적 지지'에 영감을 받아 본인 역시 일본 입장에 동조하게 되었음을 밝힘

참고문헌

     * Oprah, Obama 등 유명 인사 정치 개입 논문 및 기사
     * 비행경로, Ryukyu Islands, Kuril Islands 분쟁에 관한 다양한 자료 링크 포함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   참고: 이 요약문은 원문 저자의 독창적 추론과 유머러스한 해석이 특징이며, Mendes 본인이 실제로 Kuril Islands 분쟁에서 공식 입장을 밝힌 적은 없음.

        Hacker News 의견

     * 나는 방금 읽은 내용을 잘 이해하지 못하겠는 느낌이지만, 말 그대로의 텍스트는 알겠는 상황임. 목적이 무엇인지 모르겠지만, 사실 그게 중요하지 않다는 생각임. 오히려 이런 글은 읽는 내내 즐겁고 집중하게 만들고, 저자가 오직 기발한 아이디어와 여행 자체로 독자를 끌어들이는 이런 글이 더 많았으면 하는 바람임
          + 내가 이 장르에서 제일 좋아하는 글은 Gawker의 전설 Caity Weaver의 글임. ""My 14-hour search for the end of TGI Friday’s endless appetizers""라는 글인데, 이 링크에서 볼 수 있음 https://www.gawkerarchives.com/my-14-hour-search-for-the-end...
          + 이건 팝송 가사의 얕은 내용을 글자 그대로 받아들여서 유머로 만든 글임. 이런 방식을 bathos라고 부름
          + 나도 평소에는 글을 끝까지 잘 안 읽는데, 이번 글은 처음부터 끝까지 다 읽게 됐음. 지금 머릿속에는 내가 모르는 연예인에 대한 웃긴 글 안에 뭔가 암호 같은 중요한 지정학적 메시지가 숨겨져 있는 건 아닐까 추측하는 상황임
          + 모든 것에 반드시 목적이 필요한 건 아니라고 생각함. 내가 보기엔 그냥 저자가 노래를 듣다 영감이 떠올라서 쓴 느낌임
          + 만약 이번 글이 마음에 들었다면, 이렇게 시덥지 않은 걸 극도로 진지하게 다루는 코미디는 Nathan Fielder가 전문임
     * 추리에 박수를 보낸다 해도 마지막이 급하게 끝난 느낌이라 약간 아쉬운 감정임. 만약 Mendez가 호텔에서 친구를 만나려고 비행기를 탔다면, 그 섬에 호텔이 실제로 있는지 확인하는 게 매우 중요함. 공항이 있으면 호텔도 있을 거라는 단순 추측은 러시아 영토라 그런 가정이 성립하지 않을 수도 있으니 반드시 체크해야 함. 조사 결과 Iturup에는 호텔이 한 곳이 아니라 두 곳이나 있고, 둘 다 후기가 적긴 하지만 꽤 평점이 좋음. 이걸로 Shawn Mendez와 Kuril 영토 합병 관련 스토리에 마침표를 찍어도 될 것 같음
          + Apple II에서 ‘Where in the World is Carmen Sandiego’를 하면서 배운 점이 있다면, 항상 호텔이 있고 도착해서 체크하기에 최적의 장소라는 것임
          + 이런 디테일 확인은 patio11이 정말 잘할 것 같다는 생각임. 자세한 이야기는 https://www.bitsaboutmoney.com/archive/two-americas-one-bank...
     * 관련 이야기로, Kuril Islands는 홋카이도에서 정말 큰 이슈임. 몇 년 전에 우연히 길거리 시위에 참석한 적 있는데, 많은 일본인들이 Kuril Islands 반환을 요구하고 있었음. 외부인 입장에서는 이 시위가 실제로 아무런 영향도 없고, 러시아가 전쟁에 져서 완전히 달라지지 않는 이상 절대 일어나지 않을 일이란 걸 알아서 참 묘한 느낌임
     * 정말 장난 같은 블로그 포스팅에도 대단한 집념을 보여준 점이 인상적이었음. 읽으면서 진심으로 즐겼음
     * Genius에서 확인한 바로는, 팬들 가운데 일부가 가사에서 샨 멘데스가 필리핀 투어 후 일본으로 비행한 일화를 언급한다는 해석을 하고 있음. 2018년 노래 발매 시기와 그때 일화가 맞아떨어진다는 의견임 https://genius.com/14147648
     * 기사에서 Iturup Island에 호텔이 있는지 여부를 미심쩍게 빠뜨렸다는 점에 주목함. 그런데 빠른 구글 맵 검색 결과 실제로 호텔이 있음. 다행이라는 마음임
     * 이런 글이 너무 웃겨서 비슷한 블로그 글을 더 찾아보고 싶은 기분임
     * 몇 년 전에 내 딸이 'Lost in Japan'을 정말 많이 반복해서 들은 적이 있었음. 난 이 노래의 가수가 또 다른 여자 가수인 줄 알았는데, 그때 같이 들었던 playlist에 Kate Perry나 Justin Bieber 같은 가수들이 있었기 때문임
          + 참고로, Justin Bieber는 여자 가수가 아님을 알려드림
     * 정말 대단한 여정이었고, 이제 어떤 이견 없이 완전히 납득된 심정임
     * 이 글을 읽으며 옛날 ‘Where is Ja?’ 영상이 떠오름 https://www.youtube.com/watch?v=Mo-ddYhXAZc
          + 나는 ""I want some answers that Ja Rule might not have right now""라는 대사를 종종 떠올리는 습관임
"
"https://news.hada.io/topic?id=21422","자주 다시 인증한다고 보안이 더 강화되지 않음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       자주 다시 인증한다고 보안이 더 강화되지 않음

     * 자주 인증을 요구하는 정책은 실질적인 보안 강화 효과 없이 사용자 불편함만 초래함
     * MFA 피로 공격 등 최신 보안 위협 증가로 인해 반복 인증이 오히려 취약점이 될 수 있음
     * 운영체제의 화면 잠금 기능과 실시간 접근 정책 업데이트가 더 효과적인 보호 수단임
     * 민감한 작업 직전에만 추가 인증이 필요하며, 임의의 짧은 로그인 주기는 불필요함
     * 현대적 접근 통제 방식은 사용자를 방해하지 않고 자동적이고 신속하게 정책을 적용함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

자주 인증이 보안을 강화하지 않는 이유

  반복 인증이 초래하는 문제점

     * 작업 흐름 중 세션이 만료되어 자주 패스워드와 MFA(다중 인증) 를 반복 입력하는 과정에서 생산성 저하 현상 발생
     * 초기에는 패스워드만 재입력하면 되었으나, MFA 단계가 추가되면서 시간 소모와 사용자의 불만 심화됨
     * MFA 요청 빈도가 높아질수록 MFA 피로 공격(MFA fatigue attacks) 의 성공 가능성도 높아짐
     * 과거에는 패스워드 자주 변경이나 짧은 세션 만료 주기가 효과적인 보안책으로 여겨졌으나, 최신 가이드라인에서는 오히려 역효과로 평가함
     * 보안은 로그인 주기가 아니라, 접근 권한의 관리 및 정책 변경이 얼마나 신속하게 반영되는가에 달려 있음

  인증 방식의 본질

     * 인증은 주로 두 가지 중 하나를 증명하는 방식임
          + 기기 소유 증명: Windows Hello PIN, YubiKey, 스마트카드 등 물리적으로 기기를 갖고 있는지 확인
          + 본인 증명: 패스워드, Face ID, Touch ID 등 해당 사용자인지 식별
     * Identity Provider(IdP)의 주된 역할은 신원 확인에 집중함
     * Face ID, Touch ID, Windows Hello 등은 기기 소유 증명과 본인 증명을 동시에 처리하는 통합 시스템으로 보안성이 높음
     * 관리자들이 정책 변경이 즉시 반영되지 않을 것이라는 불안감 때문에 세션 만료를 짧게 설정하는 경우가 많음

  실제 보안 위협과 인증의 역할

     * 대부분의 공격자는 원격 피싱을 통해 공격을 시도하며, 패스워드 탈취가 매우 쉬움
     * 원격 공격에 대비해 이차 인증(예: YubiKey) 사용이 중요한 방어 수단임
     * 기기 분실, 도난 등 물리적 공격 발생 시, 보통 이미 화면이 잠금 상태임
     * 오히려 자주 로그인할수록 공격자가 자격 증명 탈취 기회가 늘어나 보안에 악영향을 미침

  운영체제와 웹 서비스의 역할

     * 최신 운영체제는 화면 잠금 기능으로 사용자가 자리를 비우면 자동으로 시스템을 보호함
     * 추가 인증 빈도 증가와 같은 사용자 불편 대신 자동 잠금 정책 적용이 바람직함
     * 공유 컴퓨터가 아닌 이상, 짧은 웹 세션 만료는 옛날 인터넷 카페 환경의 유물에 불과함
     * 민감한 서비스(예: 인터넷 뱅킹) 외에는 부적절한 세션 만료시간 정책이 오히려 보안성과 사용성 모두 저하시킴

  효율적이고 사용자 친화적인 보안 모델

     * 민감 작업 전 즉시 인증(on-demand authentication)이 이상적임
     * Tailscale SSH의 check 모드, Slack Accessbot 등은 필요할 때 즉시 사용자 확인 기능 제공
     * 운영체제의 화면 잠금 강제를 병행하면 보안과 편의성의 균형 유지 가능
     * 연속적 보안 상태 점검(device posture check) 및 실시간 접근 통제가 사용자의 행동과 무관하게 자동으로 이루어짐
     * 예시:
          + 기기가 오프라인 상태이거나 분실, 보안 검사 실패 시 즉시 접근 권한 회수
          + 역할 변화 등 신분 변경 시 자동으로 접근 정책 업데이트
     * 사용자의 반복 인증을 강요하는 방식보다 실시간 자동화 방식이 훨씬 스마트하고 안전함

결론

     * 자주 로그인이 보안을 효과적으로 높이지 않으며, 오히려 암호 재사용, 피싱, MFA 피로 등으로 이어질 수 있음
     * 조용하고 자동화된 보안 체계가 최고의 보호책임
     * Tailscale은 적응형, 지능적, 실질적으로 도움이 되는 보안을 추구함
     * 사용자가 직접 로그인 주기를 조정하지 않아도, 필요한 순간 최소한의 인증 마찰만 발생하게 설계됨
     * Tailscale의 실시간 보안 점검 기능은 기타 앱에도 확장 적용되어, 레거시 시스템까지 안전하게 보호할 수 있음

참고 링크

     * MFA Fatigue Attacks 관련 설명
     * 현대 인증 모델 소개 글
     * Tailscale의 tsidp 및 App Connector

   HN 댓글에서도 나왔지만 빠르게 변화하는 IT 환경에 비해 꽉 막히고 오래된 표준을 바탕으로 이야기하는 보안 검사/규정 등이 발목을 잡는 면이 크죠. 일선에서는 다 알고 계신 이야기가 아닐지... ㅎㅎ

   한국의 수많은 서비스들이 30일에 한 번씩 비밀번호를 재설정하라고 귀찮은 알림을 띄우죠.

   개인정보 보안 의무로 수년간 강제했던 부분이라 매우 귀찮죠... ㅠㅠ

        Hacker News 의견

     * 강제적인 비밀번호 주기적 변경이나 만료 정책이 더 큰 문제라고 생각함, 이런 정책이 자주 사람들을 계정 잠금 상태로 만들게 되고(예: 휴가 중 비밀번호가 만료되면), 그 다음에는 IT에게 직접 찾아가거나, 몇 시간씩 전화로 IT에 연락해 재설정 요청을 하거나, 잠금 안 된 동료를 통해서 연락하게 되는 번거로움이 생김
       많은(대부분의?) 기업들이 여전히 이런 정책을 적용 중인데, NIST에서는 이제 더 이상 임의 비밀번호 변경을 권장하지 않음
       NIST 공식 문서
       Microsoft 역시 비밀번호 만료는 더 해롭다며 권장하지 않음
       Microsoft 공식 문서
       그런데도 IT나 보안 쪽에서는 이런 권고안이 충분히 ‘권위 있는’ 것으로 받아들여지지 않는 것 같음, 게다가 여전히 이런 정책을 권장하는 가이드도 존재함
          + 가끔 무작위 사이트에 로그인할 때 강제로 비밀번호 재설정 요구가 뜨면, 시간 기반 만료 때문이 아니라 계정이 유출됐거나 침해됐던 게 아닐까 생각하게 됨
            사이트 운영자가 특정 계정들이 데이터 유출 리스트에 포함된 걸 알았다면, 다음 로그인 시 강제 비밀번호 변경을 요구하는 게 합리적인 대응이라고 생각함
          + 이걸 사이버 보안 담당자에게 이야기했더니, PCI 기준에서는 비밀번호 주기 변경이 요구되기 때문에 어떤 감사를 더 중요하게 생각하느냐에 따라 달라진다고 들음
          + 예전에 이런 정책이 너무 짜증나서, 매번 비밀번호 뒤에 알파벳 한 글자씩 a~z 순으로 붙이는 식으로 넘겼었음
            다행히 지금 다니는 회사에서는 같은 비밀번호 3년째 유지 중이라 만족
          + 내 비밀번호가 유출되지 않았는데도 제공자들이 주기적으로 바꾸라고 하는 건 말이 안 된다고 생각함
            이게 아직도 공식 표준처럼 적용되는 상황이 황당함
          + 결국 내 모든 계정은 1234abcd@ 패턴만 사용하는 상황
     * Apple 제품 때문에 정말 불편함을 느낌
       이 패턴이 모든 Apple 제품에 다 적용되는 걸 확인함
       Mac에서 TouchID로 설정하고, App Store에서 Apple 계정 로그인 후 앱을 설치하려고 하면 계속해서 비밀번호 입력하라는 창이 뜸, TouchID로 인증 가능할 텐데도 매번 비밀번호를 요구함
       무료 앱 설치 시에도 동일한데 정말 불필요한 절차라 생각
       이 패턴이 배우자 iPhone에서도 종종 나타남
       폰을 초기화하고 다시 세팅할 때 특히 Apple 비밀번호 재입력이 반복적으로 요구됨
       TouchID로 충분히 보안된 상황인데도 계속 이런 식이라 답답함
          + Apple 서비스에 비-Apple 기기에서 접근하면 더 심각한 불편함이 발생
            icloud.com에 로그인할 때마다 ""이 기기 신뢰""를 눌러도 다음날이면 또 비밀번호+1회용 코드 2중 인증 과정을 반복
            Face ID가 결제나 앱 설치 중 실패하면 PIN으로 대체하지 않고 꼭 Apple 계정 전체 비밀번호를 입력하게 만들고, 암호관리자 앱을 열 수도 없는 구조
            결제대에서 이런 상황 겪으면 정말 난감한 경험
          + TouchID로 구매 승인을 사용할 수 있도록 설정이 되어 있는지 확실히 확인해야 함
            (Settings > Touch ID & Password로 들어가서 설정 필요)
            만약 이걸 안 해놨으면 비밀번호 입력 요구가 계속될 수 있음
            재시작 후 딱 한 번 인증 정도만 필요하고, 그 이후에는 TouchID로 대부분 인증 가능하다는 경험
          + Mac에 iPhone을 연결해 동기화할 때마다 ""이 기기를 신뢰하시겠습니까?"" 창이 Mac과 iPhone 양쪽에서 뜨고 매번 ""예""를 선택해도 다음 번 연결 때 다시 묻는 상황
          + SUDO 권한이 필요한 작업에서 재인증 요구가 나오는 건 자연스러운 일이라 생각
            이럴 땐 관련 작업을 묶어서 한 번만 인증하게 만들면 재인증 횟수를 줄일 수 있음
          + 아주 오래된 iPad를 아이가 사용 중인데, iOS 10.3이라 암호관리자 앱도 동작하지 않고, 브라우저 역시 32비트 앱이라 최신 웹사이트를 띄울 수도 없음
            그래서 App Store 쓸 때마다 50자 이상의 비밀번호를 매번 직접 입력해야 해서 너무 귀찮은 상황
     * 이런 기사들을 읽어야 하는 사람은 보안 감사를 하는 감사관들이라고 생각함
       이 사람들이 기대하는 기준이 변하지 않는 한, 많은 기업들이 산업 표준이라면서도 현실적으로는 어리석은 정책들을 계속 따라야 하는 상황
       특히 특정 분야의 소규모 기업들도 보안 감사에서 높은 점수를 받아야 해서 쓸모 없는 보안 절차를 다수 채택 중
       우리가 실제로 효과 없다고 아는 보안 수단이 최소 6개 이상 강제로 적용되는 중, 감사관들이 아직은 좀체 바꾸려 하지 않음
          + SOC2 감사를 받을 때 NIST 가이드라인을 꾸준히 제시해왔음
            링크를 보여주면 대부분 결국에는 NIST 기준을 수용함
          + Apple, Microsoft 양쪽 모두 회사 보안팀이 “내 기기 기억하기”, “이 기기 신뢰” 옵션을 비활성화하는 기업용 설정을 지원함
            감사관이나 CISO(최고 보안 책임자)는 무조건 체크리스트 위주로 감사를 하기 때문에, 실제로 보안성이 높아지는가는 전혀 중요하지 않고 감사에서 승인받는 게 더 중요하게 작동
            이런 설정들이 사용자 불편만 가중시키고 실제로는 현실 보안성만 오히려 악화시킴
     * Microsoft가 PC 게임도 이런 식으로 망쳤다고 생각
       Minecraft나 Master Chief Collection 같은 게임을 실행할 때마다 뜬금없이 재인증 창이 나올 걸 알고 미루게 됨
       이런 불편함 때문에 2FA(2단계 인증)도 계정에서 꺼버림
       이건 단순 게임일 뿐 계좌 인증도 아닌데, 제발 즐겁게 게임만 하게 해줬으면 하는 바람
          + Xbox에서도 무작위로 생성한 비밀번호로 매번 재인증하는 게 너무 비정상적이라 느낌
            최근에는 QR 코드를 스캔해서 인증하는 기능이 생겼다고는 하는데, 이런 시스템을 만든 사람이 실제 사용자 경험과 동떨어져 있다고 생각함
     * 글에서 거의 언급되지 않은 부분이 있음
       UX(사용자 경험)가 나쁘면 그 자체로 보안 취약점이 될 수 있다고 봄
       시스템이 평소에 비합리적으로 행동하면, 진짜 문제가 생겼을 때 사용자들이 변화나 이상 행동을 못 알아차릴 가능성 높음
       예를 들어 비밀번호 입력 요구가 너무 자주 나오면 습관적으로 입력하게 되고, 이럴 때 phishing(피싱) 같은 위험을 쉽게 걸러내지 못함
       또, OS에서 스타트업 프로그램이나 백그라운드에서 실행되는 의심스러운 코드 관리가 안 되면 악용도 쉬움
       평범한 보안 전문가들이 ‘인간 심리’를 중요한 변수로 거의 고려하지 않는 점도 문제고, 모든 게 체크리스트식이나 회사 입장 위주로 설계되는 경향도 문제
       제대로 된 제품 디자인만 하면 예방할 수 있는 실수인데, 제품·서비스 공급자가 규제 변화에 소비자보다 훨씬 적극적이라 개선이 잘 안 이루어지고 있음
       그래서 실제로는 규제 강화가 보안 성능에 도움이 된다고 생각하지만, 회사 입장에서는 자사 제품/서비스에 대한 규제를 아무도 반기지 않는 이상한 상황 발생
     * 자주 재인증 요구하는 시스템은 실질적으로 보안을 향상시키지 못함 (단, 아주 긴 만료 주기는 좀 예외)
       괜찮은 인증 시스템이라면 세션 만료나 명시적 세션 관리로 권한을 즉시 회수할 수 있는 역량이 핵심
       실제로는, 세션 권한을 취소했을 때 해당 세션이 신속하게 완전 만료돼 접근권을 모두 잃는 시점까지의 ‘지연’이 재인증 주기보다 훨씬 중요
       이건 인증 체계 구조와 구성 시스템이 많을수록 더 복잡해짐
          + 그래서 refresh token이 필요함
            실제 토큰은 정기적으로 만료되지만, 클라이언트가 새 토큰을 갱신할 수 있는 기회를 별도로 부여함
            토큰 회수는 새 토큰을 못 만들게 차단하는 방식으로 제어
          + 나도 비슷하게 생각함
            회사에서는 이중 단계 인증 방식을 쓰고 있음
            하루에 한두 번 ADFS + MFA로 keycloak에 로그인하고, 대부분의 시스템이 keycloak을 OIDC provider로 사용하며 10~15분 간격으로 토큰이 갱신
            그래서 대부분 하루에 한 번만 번거로운 인증 절차를 거치면 되며, 필요할 때 VPN으로 접속된 서비스의 접근을 15분 이내 전면 차단 가능
            정상 사용할 때는 이런 변화도 거의 티가 안 나는 게 장점임
          + 재인증을 위해서가 아니라 기존 토큰 갱신만 주기적으로 이뤄지면 됨
            인증(auth) 만료와 권한부여(authorization) 만료 시간을 분리하는 게 바람직
          + 자주 재인증을 시키면 오히려 사람들이 우회 방법을 찾게 됨
            비밀번호를 종이에 써두거나, Google Docs에 기록하거나, Yubikey에 아두이노+서보 모터를 달거나, 문자(SMS)를 이메일로 포워딩하거나, TOTP 코드를 Wechat으로 보내는 온갖 ‘꼼수’가 생김
          + 결국엔 불편한 인증 정책이 심해질수록 사용자들이 컴퓨터를 조금이라도 뜻대로 쓰기 위해 더 불안전한 우회책을 찾게 되는 딜레마
     * 기사에 ‘이제는 대부분의 OS에서 지문/얼굴 인증으로 잠금 해제가 가능해졌으니, 자리를 비울 땐 화면 잠금을 걸지 않을 이유가 없다’는 취지의 문구가 나오지만, 현실적으로 워크스테이션(데스크탑 PC)에서는 해당 사항이 매우 제한적임
       내가 30년간 현장 지원을 하며, 지문 인식기가 달린 데스크탑을 딱 1대밖에 본 적 없음
       카메라도 거의 없어서, 현재 내가 관리하는 5개 지점 PC 중 카메라가 달린 컴퓨터가 2%도 안 됨
       얼굴 인식은 사용자에게 불쾌감을 주는 추가적인 요인도 있음
       우리는 이미 비동의, 몰래 진행되는 얼굴 인식(감시카메라, 학교/회사/경찰 등) 때문에 불신이 커졌고, 이로 인한 불편함은 정당한 거라 생각
       장비가 내 소유여도 소프트웨어 회사들은 실제로는 도덕적 한계 없이 내 권한을 침범하는 방식으로 설계함
       그래서 보안 키가 워크스테이션에는 더 적합하다고 생각
     * 업계 IT 보안 정책은 “IBM을 사서 쓴 사람은 해고되지 않는다”라는 관념처럼, 모두가 남들이 하는 대로만 따라서 움직임
       실제로 시스템이 망가져 있든 말든 중요하지 않고, ‘책에 적혀 있는 대로’ 했다는 게 더 중요
       그런데 이 책(표준)이 30년 전에 만들어진 매우 부실한 것
       그래서 정보보안 책임자에게 3개월마다 비밀번호 바꿀 필요 없다는 주장을 설득하려면 엄청난 에너지가 듦
          + 적어도 주기적 비밀번호 변경 부분만큼은 최근 NIST 권고를 보여주며 저항할 수 있는 상황이 된 건 다행
     * 한 고객 기업에서는 모든 시스템에 30분 세션 제한이 걸려 있음
       Jira 자체도 원래 싫어했는데, 티켓 한번 보려 할 때마다 매번 로그인해야 해서 너무 불편
       그냥 일 대신 Hacker News만 보게 되는 악순환
          + 30분 걸려 무언가를 입력하고 제출한 순간 세션이 만료돼버리는 것만큼 허탈한 일이 없음
            요즘은 그래도 대부분의 서비스에서 내 작업 내용을 캐시로 보관해줘서 다행
     * SSO란 이름이 ‘SINGLE sign on’인데, 실제론 하염없이 반복 인증을 요구함
       왜 하루에도 수백 번 SSO 인증하라는 메시지를 봐야 하는지 의문
          + 휴대폰은 분실/도난 위험이 있으니 그렇다고 치고, 데스크탑은 여전히 공용 컴퓨터(예: 도서관)에서 로그아웃 안 하고 자리를 비우는 경우가 많음, 이 점을 많은 사용자가 인지하지 못함
          + 내가 기억하는 SSO의 의미는, 여러 시스템에 단일 ID로 로그인한다는 거였지, 로그인 행위를 한 번만 한다는 뜻은 아니었던 것으로 이해함
"
"https://news.hada.io/topic?id=21423","미국 지원 이스라엘 회사의 스파이웨어, 유럽 기자들 표적으로 사용","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  미국 지원 이스라엘 회사의 스파이웨어, 유럽 기자들 표적으로 사용

     * Citizen Lab 연구진이 Paragon Solutions의 스파이웨어가 유럽 내 저명한 기자 최소 3명을 표적으로 삼았음을 밝혀냄
     * 이탈리아 Giorgia Meloni 정부가 언론인 및 시민 사회 활동가를 감시했는지에 대한 의문이 커지는 중임
     * Paragon Solutions의 Graphite 스파이웨어는 사용자의 조작 없이도 기기를 감염시켜 WhatsApp 등 암호화 메신저 접근이 가능함
     * 이탈리아 정보기관들은 시민 사회 인사에 대한 감시는 합법적 절차에 따라 이뤄졌다고 주장하지만, 언론계와 시민단체는 우려를 표함
     * 미국 정부도 Paragon과 계약관계를 맺고 있지만, 스파이웨어 남용 우려로 계약 관련 규제와 논란이 지속됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

스파이웨어 표적 사건 개요

     * 캐나다 토론토 대학 산하 Citizen Lab 연구팀은 미국 지원을 받는 이스라엘 회사 Paragon Solutions의 스파이웨어가 유럽 내 저명한 기자들, 특히 이탈리아 탐사보도 매체 Fanpage.it의 편집장 및 기자들을 목표로 사용됨을 포렌식 증거로 확인함
     * 이 사건은 이탈리아 Giorgia Meloni 총리 정부가 비판적인 언론인이나 시민 사회 인사를 감시하는 데 관여했는지에 대한 관심이 집중되는 계기가 되며, 민주 국가에서도 상업용 스파이웨어 남용 우려가 커지는 배경이 됨
     * 유럽연합 집행위원회는 “언론인과 정치적 반대자 등 시민의 데이터를 불법 접근하려는 시도는 확인될 경우 용납 불가”라는 입장임

민간 스파이웨어 산업의 문제점

     * Paragon Solutions는 도덕적인 민간 스파이웨어 공급사로 자임하며 미국 정부와 계약을 맺었음
     * 회사는 전 이스라엘 총리 Ehud Barak의 지원을 받고, 미국 플로리다 투자사 AE Industrial Partners에 최소 5억 달러에 매각되는 거래가 진행 중임
     * Paragon의 Graphite 스파이웨어는 Meta(WhatsApp) 에 따르면 2개 대륙 90명에 달하는 WhatsApp 사용자를 공격 대상으로 삼았음
     * Whatsapp 측은 Paragon 등 상업용 스파이웨어 기업의 책임 촉구와 이용자 데이터 보호 의지를 밝힘
     * Meta는 취약점을 보완했고, 이스라엘 NSO Group을 상대로 1억 6800만 달러 손해배상 판결도 이끌어냄

구체적 표적 및 공격 방식

     * Fanpage.it의 나폴리 지국장 Ciro Pellegrino와 편집장 Francesco Cancellato가 Paragon 스파이웨어의 표적이 됨
     * Pellegrino는 최근 Apple로부터 자신의 iPhone이 공격받았다는 경고를 받았음
     * Cancellato도 Meta로부터 Android 기기가 공격받았다는 알림을 받았으나, Graphite 직접 감염 증거는 아직 발견되지 않음
     * Citizen Lab은 익명을 요구한 “저명한 유럽 언론인”이 iMessage를 통해 공격받은 사례도 발견함
     * 이 공격은 사용자 행위 없이 기기가 감염되는 점이 특징이며, Apple은 문제를 패치함

시민단체 및 언론계 우려

     * FNSI(이탈리아 언론인 노조) 측은 배경이 불명확한 언론인 감시가 민주 국가에서 용납될 수 없다며 EU의 개입을 촉구함
     * Citizen Lab 연구진은 “문제는 산업 구조 자체임”이라며, 일부 기업의 일탈로 치부할 수 없음을 지적함

의회와 정부의 대응

     * 이탈리아 의회 정보기관 감독위(COPASIR)는 조사를 통해 Fanpage 편집장 감시에 정부 연루 정황은 없다고 발표함
     * 그러나 시민사회 인사에 대한 Graphite 등 도구 이용 감시는 법적 절차에 근거한 조치였음을 밝힘
     * COPASIR 부위원장 Giovanni Donzelli는 Citizen Lab의 분석보다 의회 보고서가 더 신뢰할 만하다고 언급함
     * 이탈리아 정부와 Paragon은 양국 관계 단절에 대해 각기 상반된 설명을 내놓음
          + Paragon은 이탈리아 정부가 조사 협력 제안을 거절해 공급을 중단했다고 주장
          + 이탈리아는 국가 안보 우려와 언론 보도 이후 Paragon과의 협력관계를 종료했다고 설명

미국 관련 계약 및 규제

     * Paragon은 미국 정부와의 거래에 피해가 갈 수 있는 평판 타격을 막기 위해 적극적으로 해명함
     * 미국 연방정부는 남용 사례가 드러난 상업용 스파이웨어 조달을 제한하는 행정명령(2023년 발효)을 유지 중임
     * 미국 국토안보부는 2023년 ICE 지원 명목으로 Paragon에 1년간 200만 달러 계약을 체결함
     * 미국 마약단속국(DEA)도 Graphite 사용 사례가 보도됐으며, 하원 정보위원장 출신 Adam Schiff 의원이 이에 문제를 제기함

결론 및 함의

     * Paragon Solutions를 비롯한 민간 스파이웨어의 투명성, 감시 남용 방지 장치에 대한 국제적 우려가 확대됨
     * 민주주의 국가에서 언론인 및 시민사회 인사 표적 감시가 현실화됨에 따라, 사회적·정치적 대응이 요구됨

        Hacker News 의견

     * 미국과 이스라엘만 기사 제목에 등장한 것이 신기함
       실제 기사 내용은 이탈리아가 다른 EU 국가에서 언론인을 감시한 내용임
       하지만 클릭 수를 노리는 언론사 입장에선 당연한 내용임
          + 기사에 따르면 이탈리아가 언론인을 정말로 감시했다는 명확한 증거는 없음
            COPASIR(이탈리아 의회 감시 위원회) 조사 결과, 활동가는 감시했지만, 해당 언론인(Cancellato)은 아니라고 밝힘
          + 제목은 출판사가 독자 수를 극대화하기 위해 작성함
            이탈리아의 일은 이탈리아인에게만 흥미로운 데 비해, 미국이 이스라엘 회사의 감시 도구 지원하는 내용은 더 많은 사람의 관심을 끌 수 있음
            클릭 유도 목적이지만 과장이나 왜곡 없이 정보를 관심 있는 이들에게 전달한다는 점에서 긍정적으로 봄
          + 제목은 글자 수 제한 때문에 필연적으로 정보가 소실되는 특성임
            ‘US-backed’라는 표현을 보면 투자가 포함된 뉘앙스가 느껴짐
            ‘Israeli tech’는 이전에 문제됐던 이스라엘 스파이웨어 업체들을 연상시킴
            'US-backed'와 '언론인을 겨냥'이라는 조합은 미국 국가 정체성에 대한 도전처럼 느껴짐(언론인이 테러리스트가 아닌 가정 하에)
            제목을 비판하는 흐름에 실증을 느낌
            모든 제목이 완전히 정확할 수 없다는 건 모두가 아는 내용이며, 다른 제목으로 바꿔도 모두를 만족시킬 수 없을 것이라는 생각임
          + 미술관에서 작품이 도난당하면 일반적으로 거래인보다는 장소, 도둑, 발견 경위가 언급됨
          + 무기상들은 책임에서 자유로운지 궁금함
     * 추가 맥락을 제공하려고 내 이전 댓글을 복사해옴
       Paragon은 COPASIR 내용에 대해 반박함
       (관련 기사: https://www.fanpage.it/politica/paragon-smentisce-il-copasir)
       누가 누구를 감시했는지 일부 정보를 제공하겠다고 했으나, 이탈리아 정부가 거절함(이탈리아 두 정보기관이 사용)
       이후 Paragon은 이탈리아 기관 접속을 차단함(기자 감시는 Paragon TOS로 금지됨)
       COPASIR는 자신들이 관계를 끊었다고 주장
       양쪽 중 최소 한 쪽이 진실을 말하지 않는 상황임
          + 기업의 홍보성 입장이라는 느낌을 받음
          + 양 쪽 모두가 진실을 말하지 않을 수도 있다고 생각
            링컨이 말했듯, 때로는 둘 다, 혹은 누구 한쪽만 거짓일 수 있음
            심지어 가끔은 둘 다 진실을 말할 수도 있음, 즉 제3자에 의해 조종될 수 있음
            신뢰가 부족한 상황에서 진실을 파악하기 힘들고, 결국 서로를 끊어낸 결과일 수 있음
     * Fanpage.it의 나폴리 뉴스룸 책임자인 Ciro Pellegrino에게 4월 29일 본인 아이폰이 타깃됐다는 통보가 옴
       작년에 Fanpage가 Meloni의 Brothers of Italy 청년조직에 잠입해 일부가 파시스트·인종차별 발언 하는 장면을 촬영함
       언론인을 겨냥하는 건 안 좋은 모습이지만, 이번 사건은 특히 치졸한 인상임
          + 정당 행사에 참석해 취재하고 그대로 보도하는 게 치졸한 행위인지 궁금함
     * 우리가 서구에서 사용하는 모든 소프트웨어와 기술 인프라에 얽혀 있고, 대기업과 작은 나라가 연계된, 역사상 가장 거대한 감시망 중 일부라고 생각
          + 만약 나라 A의 기업이 나라 B에 무기를 팔았다면 그럼 B도 A의 군사 네트워크에 포함되는지 궁금함
          + 맞다는 생각임
            그나저나 이렇게 가치가 낮아 보이는 대상 때문에 zero click exploit이 노출된 점이 의외임
          + 서구 국가기관과 중소 부티크 스파이웨어 회사들은 기본적으로 중립이나, 대체로 적대적임
            이 회사들이 내놓는 exploit 덕에 기관이 분석하고 자체 목적에 쓸 수 있지만, 동시에 원치 않게 exploit이 드러나 기관 입장에서는 곤란함
            글로벌 공모라기보단 동일 목표를 가진 경쟁 집단의 양상임
          + 더 많은 정보와 링크를 듣고 싶음
            조그만 나라가 그렇게 대단한 힘을 가졌다는 주장이 흥미롭게 느껴짐
     * 그리스에서도 몇 년 전, 야당 대표와 언론인을 Predator로 감시한 사례가 있었다는 점을 상기함
     * Google과 Microsoft가 AI 도구로 ""이스라엘""이 민간인을 전투원으로 식별, 살해하는 데 도움을 준다는 주장
       인도적 지원 경로에 인파가 몰릴 때 이를 공격해 민간인 희생을 극대화함
       Palantir를 통해 미국 사회에도 동일한 기술이 도입 중임
       이들의 행위에 반대하면 팔레스타인계처럼 국가 표적이 될 수 있음
       금융업계는 모두가 'zionist'라는 속성을 공유하고 있고, 실리콘밸리도 MIC 연계로 유사하다고 봄
       금융, 기술, 미디어, 학계, 정부 모두 반대 의견을 배제하는 'zionist bias'가 있다고 주장함
     * 이스라엘 회사 총기로 LA 갱단을 겨냥했다는 뉴스
       누가 사서 쏘는지는 아무도 언급하지 않는 현실임
          + EU와 서방이 다른 나라 비판할 땐 엄격하지만, 한 나라에는 항상 면죄부를 준다는 생각임
            이런 이중잣대에 전 세계가 지쳐가고 있음
            자신들이 하면 정당화, 남이 하면 범죄라는 태도
            이런 모습이 젊은 세대들과 국제 여론을 부정적으로 만들고 있음
     * 거의 알려지지 않은 implant/CNE 제품(원격 해킹 도구) 시장이 세계 각국에 존재함을 상기시킴
       예전엔 NSO Group이 주목받았으나 요즘은 Paragon임
       이런 업체에 스포트라이트가 집중되는 것은 긍정적 변화임
       하지만 이 현상은 '이스라엘'에 한정된 것이 아님
       미국 업체들도 더 효과적인 툴을 판매하지만, 언론 노출에 매우 신중함
       상업용 CNE에 있어 미국과 이스라엘보다 도덕적으로 우월하다고 느끼는 국가에 살더라도 놀랄 수 있음
     * exploit(취약점 악용 방식)이 어떻게 작동하는지 궁금함
       기사에서는 ""기기가 소유당했다가 아니다""라는 식으로 두루뭉술하게 넘어감
       그 정도 읽는 독자라면 좀 더 구체적 설명이 있었으면 좋겠다는 생각임
          + AP 기사에서 기술 세부사항 찾기는 불가능함
            CitizenLab의 포렌식 보고서에서 기술적 내용을 확인할 수 있음
     * Buzzword가 너무 많이 나온다는 의견
"
"https://news.hada.io/topic?id=21320","나는 내 삶을 기억하지 못하지만 괜찮음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         나는 내 삶을 기억하지 못하지만 괜찮음

     * Aphantasia와 SDAM(심각한 자서전적 기억 결핍)에 대해 설명하며, 필자는 과거 경험을 머릿속 이미지나 감각으로 떠올리지 못함
     * 구체적인 삶의 에피소드나 장면을 회상하는 데 큰 어려움이 있으나, 전반적인 삶의 정보와 사실은 논리적으로 기억함
     * 공간 기억과 의미 기억은 정상이어서, 지도를 이해하거나 장소 정보를 활용해 과거 경험을 유추하는 방식을 사용함
     * 이런 기억 방식은 감정적인 아쉬움은 있지만, 학습과 성장에 실질적인 차질은 없음
     * 결국 다른 전략으로 충분히 보완 가능하며, 과거를 생생하게 떠올리는 능력이 없어도 삶과 성취에 치명적인 영향은 없는 경험임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론

     * 필자는 이전에도 Aphantasia(심상 결여)에 대해 여러 차례 글을 쓴 적이 있으며, 이 주제에 많은 이들이 호기심을 보였음
     * Aphantasia란 마음속 이미지, 소리, 감각을 전혀 떠올리지 못하는 특성을 가리키며, 이는 일반적으로 장애가 아님
     * 하지만 모든 영역에서 남들만큼 능력이 있다고 느끼진 않으며, 특히 자신의 과거 에피소드를 기억할 때 눈에 띄게 약함
     * 필자는 SDAM(Severely Deficient Autobiographical Memory, 심각한 자서전적 기억 결핍)이라는 기질을 가지고 있음
     * SDAM은 2015년에 발견된 개념으로, Aphantasia와 연관성이 많고, 본인도 SDAM에 해당하는 것으로 추측함

구체적인 에피소드 회상

     * 대학 시절 힘들었던 일을 기술하라는 면접 질문에 예시를 떠올리지 못해 큰 어려움을 겪었음
     * 스스로 연구 중 난관을 극복한 경험이 있었음을 논리적으로 ""알고"" 있지만, 구체적 장면이나 사건으로는 회상 불가능함
     * 이에 따라, 기억이 분류·색인된 파일 캐비닛이 없는 느낌을 받음
     * 아주 특정한 단서나 타인의 도움을 받아야 겨우 일부 장면을 복원할 수 있으며, 대부분의 정보는 일화적 사건이 아닌 사실 형태로 남아있음
     * 중요한 일상에서는 실질적 문제로 이어지지 않으나, 감정적인 면에서 소외나 아쉬움이 남음

기억의 공백

     * 중요한 사람이나 감정은 머릿속 어렴풋하게 남아 있지만, 삶에서 구체적으로 ""무엇을 했는지""는 거의 기억하지 못함
     * 예전의 나 스스로도 남의 삶처럼 느껴짐
     * 충격이나 외상, 해리성 기억상실이 아니라, 단순히 일화적 기억 회상 방식의 차이임
     * 최근 연구에 따르면, Aphantasia가 새로운 기억 형성 시 뇌 활성에 차이가 있으며, 실용적 성과에는 큰 차이가 없는 것으로 나타남
     * 과거의 경험 회상은 평균화된 감각만 남아 있고, 세부 사항은 모두 소실되는 경향이 있음

의미 기억과 공간 기억

     * 의미(semantic) 기억은 매우 정상적으로 유지되고 있어, 필자는 새 경험을 자신만의 정신적 모델에 맞춰 통합해나감
     * 덕분에 중요한 정보나 반복된 사실은 잘 남고, 모든 세부 사항이 평균화·일반화됨
     * 공간 기억 역시 매우 강력하여, 장소의 구조나 위치 기억에 탁월함
     * 새로운 장소를 탐험했을 때나, 오랜만에 찾은 도시에서 길과 장소 정보를 명확히 재현할 수 있음
     * 공간 정보가 일종의 기억 인덱스로 작용하며, 구체적 사건의 일부 복원이 가능함

얼굴 인식의 어려움과 보완 전략

     * 경미한 안면 실인증(face-blindness) 경향이 있어서, 맥락 없는 사람의 얼굴은 알아보기 힘듦
     * 그러나 이름, 장소, 맥락 등의 추가 정보가 주어지면 기억이 활성화되는 구조임
     * 일상에 큰 지장은 없고, 보완적 전략을 통해 충분히 기능함

결론: 문제없는 삶

     * 남들과 다른 기억 구조로 인해 특정한 회상 경험은 불가능하지만, 사람·사건·학습의 본질은 온전히 내면에 남아있음
     * 과거의 구체적 장면을 되살릴 수 없더라도, 중요한 교훈과 감정은 현실의 감정 형태로 유지됨
     * 암기나 장면 재현보다는 지식과 통찰의 축적에 더 집중할 수 있게 해주는 이점도 있음
     * SDAM은 단점도 있지만, 즉각적 이해와 새로운 정보 처리에 더 집중할 수 있도록 도와주는 긍정적 측면이 존재함
     * 연구 결과, 기억의 부족을 대체하는 다른 인지 전략이 충분히 실질적 보완 효과를 주며, 강한 심상이나 일화적 기억이 반드시 실제적 성공·행복과 직결되는 것은 아님

   Cover image: Caravane Au Coucher Du Soleil, Charles Théodore Frère

        Hacker News 의견

     * 나도 이와 똑같은 경험을 하고 있고, 특히 면접이나 리뷰 자기평가서 작성할 때 ‘나 자신을 어필하는’ 부분에서 정말 큰 어려움 겪는 중임
       저자처럼 나도 힘든 문제를 해결한 경험을 물어보면 아무 대답도 못 하다가 누군가가 내가 이룬 성취라고 불러줄 만한 순간을 짚어줄 때에야 비로소 그런 경험을 떠올릴 수 있음
       일단 한 번 그런 계기가 생기면 참고할 사례를 알게 됨
       아직도 ‘성취’라 말하는 건 어렵지만 기억 자체는 할 수 있음
       또 저자처럼 나도 공간 기억력이 뛰어나서 길, 방향 등을 잘 기억하고 이를 단서 삼아 다른 세부사항도 떠올릴 수 있음
       이게 ADHD와 관련이 많은지 궁금함
       어린 시절에는 배고픔도 없고 좋은 교육 기회도 있었지만, 부모님 사이의 문제로 내게 지속적인 영향이 남은 상황임
          + 나도 매우 강력한 사건별 기억력을 가진 사람임
            ‘자신을 어필하는’ 과정이 무척 힘듦
            지난 1년 동안은 내가 해왔던 일들을 외부인의 시각으로 다시 떠올리며 이력서에 제대로 기여한 내용들을 추가함
            내 시점에서는 그냥 대충한 거라 생각했는데, 남들 시각에선 ‘인상적이고 성공적인 것’이라 부름
            내 성취를 스스로 인정 배울 때가 시니어 엔지니어와 스태프 엔지니어의 차이였음
          + 읽으면서 “이거 ADHD랑 너무 비슷하네” 생각했는데 진짜 그랬음
            내 머릿속에서 관찰자로만 존재하는 듯한 느낌은 겪어본 사람 아니면 설명하기 굉장히 어려운 현상임
            때때로 타인의 삶이 내 삶보다 더 현실감 있어보이고, 내 경험은 뭔가 방해물로 인해 혼탁해진 느낌이 큼
            물론 실제로 그렇진 않고, 내 뇌의 착각임
            나 역시 자기 어필에 정말 약함
            기억력만 나쁜 게 아니라, 내 성공과 실패에 동등한 비중을 둘 때가 많아야 할 장소에선 지나치게 객관적으로 나를 대함
          + 내 경험상 진짜 중요한 건 올바른 프레임워크를 갖추는 것임
            Clayton Christiansen 방식과 5 Whys 섞어서 사용하고 있음
            “올해 어디에서 어떤 일 했는지” 같은 큰 덩어리를 쓰기 시작함
            “왜 그곳에 있었나?” 찾아가며 주요 프로젝트를 적음
            “그 프로젝트가 실제로 준 영향?” 수나 비율로 확인함
            “무슨 기술/소프트스킬이 필요했나?” 분석 진행
            “왜 내가 신경 쓰는가?” 만약 상황이 어떻게 다르면 다시 해보고 싶은지 고려
            비즈니스 성과 추적이 일상화된 뒤 이 방식이 더 효과적임을 느낌
            이 구조를 대입해 이력서 확장하고, 최근 작업 설명용 비즈니스 개발 템플릿도 만듦
            이 템플릿을 LLM에 넣어 나와 협업해 더 나은 커뮤니케이션 방법 탐색함
          + 이 내용에 크게 공감함
            면접이나 성과 리뷰에서 구체적인 성취를 떠올리는 게 정말 어려움
            나와 저자처럼 aphantasia(심상 부재)와 아마 SDAM도 있겠지만, 자기 반성이나 꽤 긴 치료 과정을 겪으며 이 문제의 근원은 ADHD일 가능성이 크단 결론에 이름
            내 경우 성취를 떠올리지 못하는 문제가 아니라, 애초에 거의 어떤 것도 ‘성취’로 느껴지지 않는 것이 더 큼
            최근 예시로, 나는 대학교를 12년 넘게 끌다가 ADHD 진단을 받고, 커리어를 바꿔 지원해서 바로 IT 시스템 통합 스페셜리스트(지원/헬프데스크 역할)로 취직함
            비정규 교육이지만 내 실력 인정받아 견습생 단계를 생략
            8개월간 원래 역할을 훨씬 넘는 업무(자동화, 내외부 툴 개발, 고객용 도구)를 맡음
            최근엔 공식적으로 Test Automation Engineer로 승진, 연봉 50% 상승
            객관적으로 견습생에서 8개월 만에 엔지니어로 승진은 대단한 성취인데, 내 감정으론 ‘동년배들 따라잡기 시작한 것’이 더 강함
            외부자에겐 이상하게 들릴 수 있음
            내 이론은, ADHD에서 흔히 열쇠 어디 뒀는지 잊어버리는 것처럼 애초에 기억 저장 자체가 제대로 안 되는 거라는 것임
            즉, 성취 사건이 일어나도 감정적으로 ‘성취’단서로 뇌에 태깅되지 않기 때문에, 그냥 ‘하나의 사건’일 뿐임
            그래서 면접에서 힘든 문제 푼 적 이야기해달라 하면 ‘성취’ 폴더에서 꺼내기가 어렵게 됨
          + 나는 ADHD가 없어도 ‘나를 어필’하는 데 고생함
            이 부분은 일부러 연습해야만 가능했음
            업계 자체가 자랑스러운 에피소드에 집착하는 느낌이고, 마치 ‘위대한 인물의 역사’ 시각을 개인 단위로 축소한 기분
            회사의 ‘컬처 인터뷰’에서 갈등 해결 사례를 요구할 때도, 나는 누군가와 갈등을 에피소드로 만드는 타입이 아니어서 답변이 어려움
            그냥 서로를 존중하고 편하게 얘기 나누려고 하고, 만에 하나 갈등이 생겨도 그걸 의식적으로 기억에 남기지 않음
            프로그래밍에서도 마찬가지임
            ‘가장 힘들었던 버그’도 그냥 평범한 반복적 과정 중 하나일 뿐, 딱히 특별하게 각색된 이야기가 없음
            나는 이게 더 낫다고 생각하지 않고, 그냥 내 성향 혹은 성장 배경 때문임
     * “얼굴 인식이 약간 약한 것 같다” 같은 사연 참공함
       일상에선 큰 문제 없고, 반복해서 접하면 얼굴을 익히지만, 예상치 못한 장소(기차 등)에서 익숙하지 않은 사람을 만나면 맥락적 단서 없이는 누군지 정말 분간하기 어려움
       상대가 “안녕 마르코!” 하면 난 어디서 본 것 같다는 희미한 느낌만 있음
       이름이나 관련 정보를 듣기 전까진 내 머릿속 소셜 네트워크에 제대로 연결하지 못함
       나 역시 aphantasia는 없지만(오히려 자서전적 기억이 약함), 이런 일이 자주 있고, 더 당황스러운 건 전에 여러 번 만난 사람인데 내가 처음 만난 것처럼 자기소개할 때임
          + 나도 얼굴 알아보는 게 어렵고, 조금만 변하거나 익숙하지 않은 장소에서 보면 더 그러함
            특별히 aphantasia가 있는 계열은 아니고, 오히려 세 살 이전까지의 강한 시각적 기억도 있음
            대신, 사람의 걸음걸이로 먼 거리에서도 몇 년 만에 본 사람을 바로 알아볼 때 있음
            심지어 신발 놓는 방식만 보고도 10년 만에 만난 사촌임을 알 수 있음
          + 내 파트너도 얼굴 인식에 꽤 어려움이 있음
            흥미로운 점은, 평생 대부분의 사람들이 자연스럽게 얼굴을 기억한다는 걸 이해 못 했다는 점임
            예를 들어 바텐더가 한 달에 3~4번 간 곳에서 이름 불러주면, 상대가 내 스토커인 줄 알았다고 함
            본인은 얼굴을 ‘의식적으로’ 구분해야 해서, 특이점(안경, 수염, 대머리, 마른 얼굴, 작은 코, 머리 스타일 등)을 딱딱 기억함
            클럽에 주기적으로 가도 본인은 완전히 익명일 거라 생각했다가, 내가 “거기 일하는 사람들 다 너 기억할 걸”이라고 하니까 충격 받음
          + 나는 강렬한 기억력을 갖고 있어서 특정 분위기가 묻어나는 기억(예를 들면, 비 오는 날 분위기)을 모아낼 수 있음
            근데 자꾸 그러면 뇌가 아파짐
          + 어제 나 역시 이런 상황을 겪었음
            미안해 Wolfgang
     * 어느 정도는 ‘마음의 눈’ 선명함이 착각에 가깝다고 생각함
       대다수는 자신의 심상 이미지 퀄리티를 과대평가하는 경향이 있음
       대표적 사례로 “자전거 그리기” 실험이 있는데, 실제론 매일 보는 물건조차 디테일하게 떠올려 그리기 어려움
       관련 링크
       그림 실력이 없는 사람도 있겠지만, 익숙한 사물을 제대로 복원하지 못한다는 점이 시사하는 바 큼
       증인 진술조차 부정확함이 잦음
          + 현상학적 관점에서 이 주장에 이견 있음
            타인의 마음속 시각을 추정하는 건 근본적으로 오류임
            실제로 수백 명 이상 인터뷰해 본 결과, 시각화 경험엔 매우 넓은 분포가 있음
            '마음의 눈'이 아예 공허한 사람도 있는 반면, 현실 시각 자체를 압도할 정도로 강렬하게 시각화하는 사람도 존재
            '자전거 그리기' 사례도 사고의 오해임
            뇌 속 사물 장면 표상과 운용 표현 능력은 전혀 별개이며, 조각가가 아니어도 자기 얼굴을 완벽히 아는 지식 가질 수 있음
            증인 진술 부정확성이란 사례도 본질은 시각적 복원 문제가 아니라 시간적·인과적 배열력임
            내 연구에 따르면, aphantasia를 가진 사람은 오히려 사실적 순서 복원이 더 정확할 때가 많음
            시각적 재구성을 거치지 않으니 왜곡이 적음
            요점은 인지 다양성임
            어떤 이들에겐 ‘결손’으로 여겨지는 특질이 특정 상황에선 오히려 대안적 강점이 되기도 함
            시각적 기억은 매번 재구성 과정에서 오염될 수 있는데, aphantasia는 원본 정보를 불필요하게 다시 그리지 않아 더 순수하게 접근한다는 해석 가능
            이건 단순 신경학적 흥밋거리를 넘어, 기억의 본질적 차이에 해당함
            표상 기반 기억과 직접 인지 기반 기억이란 방식 모두 서로 장단점이 있음
          + 이건 선명함/명확성보단 '정확성'의 문제로 봄
            머릿속에 엄청 디테일하게 시각화해도 그게 실제와 다를 수 있음
            나는 aphantasia이고 자발적 시각화 자체가 없음
            하지만 기억력은 좋은 편이고, 누가 시키면 비슷하게 잘못 그린 자전거 그릴 듯
            aphantasia에 관한 토론에서 늘 직접적 간접적으로 이 존재 자체를 의심하는 의견이 나오는데, 그런 분들에게 설명하기 제일 쉬운 테스트가 있음
            “눈 감고 탁자 위에서 공이 통통 튄다고 상상해보세요. 소리도 들어보세요. 공 색깔은 뭔가요?”
            대부분 즉답 가능한데, 나는 수십 번 시도해도 공의 색을 알 수 없음. 왜냐면 머릿속에 실제로 그 공이 존재하지 않음
            aphantasia란 이런 느낌임. 흐릿하거나 낮은 해상도가 아니라 아예 ‘무(無)’임
          + 나는 hyperphantasia(초선명 심상)를 가지고 있는데, 지난 10년 사이 대부분 사람들은 나처럼 상세한 가상 오버레이와 함께 세계를 인식하는 게 아니라는 걸 뒤늦게 앎
            자전거 실험 예시는 내 방식과 보통 사람의 인식 차이를 인상적으로 체감하게 해주었음
          + 기억은 손실 압축을 쓰기 때문에, 때때로 정보 자체가 뒤틀리거나 사라지기도 함
          + 네 주장 읽고 링크 보기 전에 자전거 그냥 쓱 그렸음
            누군가 자전거 못 그린다는 게 상상 자체가 안됨
            근데 이건 주제가 다르다고 느낌
     * 대학생활 중 힘든 문제와 극복 경험을 쓰는 질문, 준비 안 했으면 누구나 어려울 거라 생각함
       사람들이 평소에 이런 ‘메타적’ 범주로 사건을 기록하거나 생각하지 않아서 더 그런 거라 여김
          + 이런 질문은 거의 면접 대비용임
            막상 실제 현실적 문제가 나오면 예를 잘 떠올릴 수 있는데, “그때 넌 어떻게 했어?” 같은 면접 문맥에선 머리가 완전히 다르게 작동하는 듯함
            그래서 마음속으로 ‘동료가 이런 상황으로 힘들어한다. 나는 무슨 조언을 해주고 어떤 사례를 공유할 수 있을까?’처럼 자기 머리를 속여보는 편임
            그리고 그 사례를 그냥 STAR 형식으로 얘기해서, 면접관이 ‘STAR 체크리스트’ 채워주길 바라게 됨
            리더십 원칙을 직접 언급해서 포인트 더 얻을 수도 있음
          + 맞음, 이건 기억력 자체보다는 회수 단서가 추상적이라서 생기는 문제임
            “힘들었던 문제”처럼 포괄적 질문을 받으면 더 구체적인 실마리를 먼저 생각해보고, 거기서 까다로웠던 경험을 추려냄
          + 사실 거의 모든 사람이 이런 게 정상 아닐까 싶음
            저자 묘사가 나랑 거의 똑같아서 대단히 특이한 게 아니라 평범하다 생각함
            다만, 모든 걸 즉각 필요한 순간마다 생생히 떠올릴 수 있는 사람이 있다면, 그게 오히려 특이하다고 생각함
          + 이런 질문에서 제일 힘든 건, 처음엔 내가 제대로 대처 못한 케이스만 떠오르게 한다는 점임
            물론 결국엔 잘 풀었던 이야기를 생각해내고, 앞서 쓸모없는 이야기 다섯 여섯 가지는 거르고 나야 적절한 답을 준비함
          + 이런 질문을 여러 번 겪다 보면 자신만의 레퍼토리가 생긴다고 생각함
            나는 얼굴 인식 장애부터 사건 기억력 부족까지 전부 겪는데, 그래도 예전에 실수로 생산 시스템에서 rm -Rf /.로 지운 경험~교훈 등 최소 10번은 써먹음
            예전에 같이 일한 매니저 중 누구나 아는 이야기꾼이 있었는데, 나중에 보니 언제 무슨 이야기를 하든 본인만의 반려 스토리 몇 개를 반복해서 돌려쓰더라
            오히려 이런 걸 잘 다듬어 ’언제든 꺼낼 수 있는 도구’로 만드는 게 효과적임
     * 나 역시 저자와 거의 똑같은 경험을 하지만, aphantasia는 없음
       aphantasia 중요성 깎아내리려는 건 아니지만, 기사 핵심은 SDAM(단기 자전적 기억 결여)에 가까워 보임
       Google Photos/Apple Photos 지도 보기 기능이 내 기억 탐색의 주요 수단임
       장소는 알고 있지만, 실제로 거기 있던 기억은 희미함
       그래서 지도에서 사진 찾아보고, 그 사진을 보면 실제 기억이 다시 살아남
       물건에 대한 집착도 이 때문임
       사람과의 기억은 잘 못 떠올리지만, 그 사람의 물건을 만지거나 보면 감춰진 기억이 되살아나는 느낌임
       최근에 아내를 잃었고, 12년간 결혼 생활, 8년 연인 시절의 구체적 기억이 별로 없음
       아내의 소중한 물건을 다른 곳에 보내는 게 참 어렵고, 그런 상징물이 사라지면 아내에 대한 마지막 추억 줄기마저도 끊길까 걱정함
          + 내가 애도의 시간을 보내는 데 도움이 된 건, 그 사람의 ’존재감’에 대한 느낌을 기억하려고 한 것임
            처음엔 미미하다가도, 자꾸 그러다 보면 실제 그 사람이 들어오는 것 같은 변화가 느껴짐
            홀로 있는데 그 사람이 방에 들어오는 상상을 하면 방의 분위기가 묘하게 달라지는데, 이런 감각으로 신체 대신 계속 연결될 수 있음
            이 방식이 나에게는 큰 힘이 됨
          + 나 역시 이런 불안감이 있음
            심지어 그녀의 얼굴조차 잘 떠올리지 못함
            물건을 만지는 건 도움 안 되지만, 사진을 보는 건 기억 회상에 꽤 효과 있음
            매년 추억 앨범에 에피소드와 설명을 써달라고 했지만 이뤄지진 않았음
            반면, 그녀는 처음 만났던 날 우리가 어떤 옷을 입었는지도 기억함
     * 나도 저자와 비슷한 경험
       다만 aphantasia는 아님
       자서전적 기억이 별로 없는 느낌, 내 과거를 관찰자 입장으로 바라보는 느낌도 큼
       누가 “지난 주말에 뭐 했냐”고 물으면 “그냥 집에서 쉬었어요” 대답했다가, 나중에 사실 그 주에 스키 타러 다녀온 걸 누가 말해줘야 그제야 떠오르는 경우 많음
       가족과의 대화 중에도 똑같음
       다만 저자보다 내 시각은 좀 더 비관적임
       저자는 ‘과거를 잊었어도 교훈은 배운다고’ 하던데, 과연 그럴까 회의적임
       보상작용은 분명 존재하지만, 기억 문제는 명백히 단점임
          + 나도 거의 똑같은 경험을 써보려고 했음
            내 경우는 작업 기억 결핍 때문이라 들었고, 이는 장기기억으로 잘 변환이 안 되는 것임
            ADHD 가진 사람이 흔히 그렇게 됨
          + “집에서만 쉬었어” 대답해놓고 알고 보니 스키 다녀온 거 잊었다는 점 믿을 수 없음
     * 나는 aphantasia, SDAM, 그리고 얼굴 인식 장애를 모두 가짐
       저자처럼 나 역시 머릿속 멘탈 모델을 많이 의존하고, 소프트웨어 요구사항에 관한 책도 썼음
       핵심만 잘 파악하고 정보를 계층적으로 정리해 원리를 기억함
       이미 세상을 떠난 사람들을 제대로 기억 못하는 것에 늘 불안함을 느낌
       사진을 보면 그 안에 온갖 세부 정보가 몰려옴
       정보는 저장되어 있는데 접근이 안 되는 것 같음
       네트워킹 능력은 떨어져서, 이벤트 가면 모두가 나를 아는데 나는 그들이 누군지 모르는 경우가 잦음
       그래서 카메라 달린 AR 안경이 빨리 나와서 사람과 배경정보 자동 표시되길 기대함
       aphantasia가 희귀하다고 통계는 말하지만, 내 회사엔 의외로 이 특질 가진 엔지니어 정말 많음
       나쁜 점도 있지만, 좋은 점도 있음
       예를 들어, 트라우마성 기억이나 멋진 경험도 거의 남지 않아 별로 영향을 안 받음
          + “이미 떠난 사람을 기억 못할까 불안”하다는 부분에 공감함
            나는 그(녀)가 자아에 불어넣던 ’존재감’을 일부러 떠올리면서 극복하려 했음
          + 나는 지금 aphantasia를 겪고 있는데, 예전엔 시각화도 능했던 시절이 그립기도 함
            나는 얼굴만큼은 자동으로 다 알아보지만 lethonomia(이름 기억 상실)는 있음
            예전엔 자전거 타고 지나가다 단 한 번 본 실험 파트너의 형제가 옆에서 지나가도 딱 알아볼 정도였는데 지금은 교통사고 이후 이전만큼은 아님
     * SDAM 가진 사람을 만난 적 있음
       그 친구는 “일인칭 기억”이 전혀 없다고 표현함
       대부분의 사람은 어렴풋해도 ‘내가 거기 있었다’는 현장감, 장면 재생 같은 게 있는데
       이 사람은 ‘내가 한 일’을 회고해도 본인이 스스로 그 장면에 몰입하지 못함
       나는 그에 비해 드문드문 스냅샷으로 찍어놓은 듯한 기억이 있음
       예를 들어 자취했던 집·회사·졸업식·해변 걷던 장면 등은 돌아가 상상할 수 있음
     * 나는 aphantasia를 가지고 있고, 오늘 SDAM도 있다는 걸 알게 됨
       장점도 있음
       예를 들어, 나는 사람을 쉽게 용서함
       원한을 오래 품는 게 더 힘들어서, 누가 나를 다치게 했어도 그 고통을 계속 떠올리거나 재생하지 않게 됨
       결과적으로 정말 ‘용서하고 잊기’가 쉬워짐
       참고로, 내 꿈도 거의 시각적이지 않음
          + 오래된 기억의 고통을 반복해서 재생하는 문제는 어때? 난 요즘 그 고통을 좀 덜 겪고 싶음
          + 무의식까지 포함해 정말 감정적으로 용서했다는 걸 어떻게 아는지 궁금함
     * 나는 이미지를 마음속에 그리는 게 쉽게 가능함
       이 점은 전반적으로 유용하지만 기억 보존엔 큰 도움이 된다고는 못 함
       흐릿한 분위기, 해 쬐는 초록빛 정도의 감각은 쉽게 즐기지만, 내 인생의 큰 부분이 완전히 사라진 느낌은 같음
       나는 이 사실을 받아들이고, 자주 일기를 쓰거나 친구들에게 기억을 크라우드소싱함
       하지만 앞으로 새로운 추억을 만드는 기대와 과거 경험의 교훈이 내 안에 내재되어 있다는 믿음이 있기에 괜찮게 여김
       만약 그렇지 않다면 더 주의를 기울여 모든 걸 새로 배우는 기회일 수 있음
       피곤하지만 보람됨
          + 나도 비슷함
            나는 시각화에 전혀 문제 없지만, 저자가 묘사한 기억력 부족이나 특히 공간 기억, 예를 들면 4살 때부터 살던 모든 집의 평면도를 그릴 수 있다는 점까지 똑같이 느낌
            다만, 그곳에서 겪은 구체적인 사건은 거의 기억하지 못함
            다른 사람들이 나보다 웬만한 일은 더 잘 기억하는 것 같지만, 저자의 서술을 보고 나서야 ‘이게 비정상이 아니라 자연스러운가?’ 되돌아보게 됨
            연구에 따르면 aphantasia와 SDAM이 완전히 겹치는 건 아니라서, aphantasia 없는 사람도 많다고 함
"
"https://news.hada.io/topic?id=21381","LA 시위 대응 위해 해병대 투입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           LA 시위 대응 위해 해병대 투입

     * 해병대 약 700명이 최근 LA 시위에 대응하기 위해 캘리포니아 기지에서 출동 준비 중임
     * 이들은 트럼프 대통령이 주지사나 시장 동의 없이 수천 명의 국방경비대를 배치한 뒤 합류함
     * 해병대 임무는 구체적으로 공개되지 않았으며, 검거 등 법 집행 권한은 없음
     * 법무부 변호사들이 병력의 무력 사용 지침을 최종 조율 중임
     * 캘리포니아 주지사와 LA 경찰 서장은 긴밀한 협조와 평화적 대응의 필요성을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LA 시위 대응 위한 해병대 동원 현황

     * 캘리포니아의 Marine Corps Air Ground Combat Center 소속 700여 명의 해병대가 LA 시위에 대응하기 위해 출동 준비 중임
     * 트럼프 대통령은 캘리포니아 주지사나 LA 시장의 동의 없이 주말 동안 국방경비대 수천 명을 배치해 이번 결정이 논란이 되고 있음

군 병력의 동원 및 임무

     * 전체 해병대 대대가 동원된 것은 트럼프 정부에서의 물리력 과시가 본격화된 신호로 평가받음
     * LA에 도착한 후 해병대의 구체적 임무는 아직 명확히 결정되지 않음
     * 국방경비대와 마찬가지로, 폭동 법령(Insurrection Act) 발동 전에는 체포 등의 법 집행 활동이 금지됨

해병대 및 병력 구조

     * 배치된 해병대는 2nd battalion, 7th Marines, 1st Marine division 소속임
     * US Northern Command(NORTHCOM)은 이번 동원 목적이 Task Force 51에 연속적으로 인력을 제공하여 연방 기관 지원임을 강조함
     * 해병대는 LA 내 국방경비대 병력 보강을 위한 파견임

전개 상황과 주정부, 지방정부 반응

     * 현재 1700명 규모의 국방경비대가 LA 대도시권에 배치됨
     * 트럼프 대통령은 추가로 2000명의 국방경비대 파견을 명령, 전체 도착 일정은 미정임
     * 이번 해병대 동원은 1992년 LA 폭동 이후 처음이며, 미국 본토 내 병력 동원이란 점에서 주목받음

해병대 역할과 법적 지침

     * 해병대의 가능한 역할은 군중 통제 또는 외곽 경계 구축 등으로 추정됨
     * 국방부 소속 변호사들이 무력 사용 지침을 확정 중이며, 기존 군 규정과 유사할 것임
     * Gavin Newsom 캘리포니아 주지사는 이를 ""불필요하며 전례 없는 조치""라고 강하게 반발함
          + ""미 최고 수준 군 조직을 자국민에 동원하는 것은 완전히 불필요하고 전례 없는 조치""라고 강조함
          + 동원을 deployment(파견)와 구분하며, deploy가 아닌 mobilization(동원)임을 설명함
     * US Northern Command는 해병대가 국방경비대와 완전히 연계되어 연방 인력 및 재산 보호 임무를 수행할 것이라고 밝힘

현지 치안 당국 입장

     * LA 경찰서장 Jim McDonnell은 모든 대응 기관 간 ""개방적이고 지속적인 소통""을 촉구함
          + ""소통을 통해 혼란을 방지하고, 사태 악화를 막으며, 합법적이고 질서 있는 대응이 가능함""을 강조함
     * 경찰 및 관계 기관들은 대규모 시위 대응에 경험이 많으며 안전 관리를 최우선 목표로 하고 있음

기타

     * 본 기사 및 제목은 추가적 정보 반영을 위해 업데이트됨
     * CNN 소속 Cindy Von Quednow와 Danya Gainor가 기사 작성에 기여함

        Hacker News 의견

     * 군대와 경찰을 분리하는 이유에 대해 이야기하는데, 군대는 국가의 적과 싸우는 역할이고 경찰은 국민을 보호하는 존재임을 강조하는 입장임, 군대가 둘 다 맡게 되면 결국 국가의 적이 국민이 되어버릴 위험성 지적임
          + 미국 헌법적 민주주의의 구조에는 군대가 법의 집행에 투입되지 않도록 하는 원칙이 내재됨을 언급함, 로마 공화정이 군대의 시민 탄압으로 제정으로 변해버린 역사적 교훈을 예로 들며 군대의 권력 집중이 한 명의 통제 아래 위험해지는 모습을 경계하고 있음, 관련 칼럼 링크 첨부함 https://bloomberg.com/opinion/articles/…
          + 독재든 민주주의든 시민 봉기가 일어나면 경찰은 언제나 약자보다는 권력자의 편을 들게 된다는 느낌을 말하는 입장임
          + 군대-경찰 분리의 이유가 바로 Posse Comitatus라는 법 때문임을 설명함, 연방 군대가 치안 집행에 개입하는 것에 대한 미국민의 불만에서 시작된 법이라는 배경 설명 및 링크 제공함 https://en.wikipedia.org/wiki/Posse_Comitatus_Act
     * 불법 이민 문제가 크다고 느껴진다면, 이민 노동을 쓴 기업에 5배 급여만큼 벌금을 부과해보자는 제안임, 이미 신분 확인 시스템이 잘 갖춰져 있고, 사실 싸게 일하려는 노동자 고용 유인이 사라지면 불법 고용 자체가 줄어들 것이라는 주장임, 이민자들이 오는 다양한 이유가 있지만 결국 저임금 일자리 때문이 아니라는 관점임
          + 캐나다에선 실제로 이 방식을 쓰고 있고 굉장히 효과적임을 밝힘, 하지만 미국에서는 불법 이민자를 고용하는 계층(농장주, 건설업자, 호텔 업주 등)이 정작 불법 이민에 반발하는 정치 세력과 동일해서, 현실적으로 자기 손해니까 이런 정책이 실현되지 않는다는 분석임
          + 실제 문제 해결보다 힘을 과시하는 퍼포먼스가 더 중요한 의도라는 의견임
          + 현재 캘리포니아 주정부를 제거하고 비상사태를 명분 삼아 트럼프 3선까지 연결시키려는 구상임을 지적함, 이런 논의가 선거 전부터 있었음을 이야기함
          + 1996년부터 e-verify 시스템이 이미 존재해서 노동자의 합법적 신분을 검증하는 기능을 함을 설명함, 연방계약기업은 의무적으로 도입하지만 일부 주에서는 금지법을 따로 제정해 사용을 막기도 했다는 배경임
          + 공화당 후원자들의 반감을 우려해 절대 그런 과감한 정책을 못 한다고 주장함, 미국인들도 식료품 값이 오르면 반발할 테니 결과적으로 ‘우리 편은 보호, 남 탓하며 보여주기식 단속, 트럼프가 결국 강경하게 문제를 척결한다는 쇼맨십’으로 귀결됨을 지적함, 트럼프를 강한 리더로 포장하지만 결국엔 이득을 보는 게 자기 진영이고, 적당한 민주당 후보가 나와야 한다는 바람을 표현함, 특히 여성후보 전략이 미국에서는 잘 안 먹히는 분위기임을 덧붙임
     * 정치적 입장과 무관하게 LA는 최근 몇 년간 재난과 사건이 끊이지 않는 상황임을 지적함, 현 정부가 걷는 길이 다른 나라의 전형적인 몰락 패턴과 비슷해 보인다는 분석임, 트럼프 1기 때의 4년 동안 법이나 제도를 바꿀 기회가 있었음에도 그러지 않은 점을 근거로, 향후 변화는 막기 어려운 예감임을 이야기함, 2차 대전 이후 미국이 세계 패권과 글로벌 중추 역할을 해왔기에 몰락의 여파가 전 인류에 닿을 수 있다는 우려를 밝힘, 그와 동시에 상황이 심각하게 급변하면 미국 시민들이 각성해 반전의 기회를 만들 것이라는 희망도 가지고 있음
          + 직접 LA에 거주 중인데, 뉴스를 안 보면 아무 일도 없는 평범한 분위기임을 전함
     * 사전에 내부 시각만 보면 질서 회복이라는 말이 그럴싸하게 들릴 수 있으나, 역사를 보면 그 결과와 패턴이 뻔하게 반복된다는 경고임, 2차대전이 약 80년 전이고, 직접 겪은 세대가 사라지면 똑같은 일이 반복될 수 있다는 질문을 던짐
     * 폭동을 일으키는 사람들에 대한 변명과 옹호가 많다는 지적과 함께, 경찰력만으로는 이미 통제 불가능한 상황임을 말함
     * Kevin Drum의 블로그 글이 매우 통찰력 있어서 자주 참고했었는데, 지금 같이 중요한 시점에 그의 의견이 궁금하다는 바람을 전함
     * 지금 미국 상황이 매우 무섭고 충격적으로 느껴지는 심정임, 현재의 정치적 언사로 봐서 사태가 쉽게 가라앉을 거라 기대하기 어렵지만 틀렸으면 좋겠다는 희망임
          + 조지 부시가 1992년 로드니킹 사태 때 주방위군과 해병대까지 투입했던 전례를 언급함
          + 켄트주립대 사건이 여전히 뇌리에 남는 이유를 환기함(미국에서 방위군이 학생 시위대를 진압해 사망자가 났던 사건임)
          + Home Depot 앞에서 ICE(이민세관단속국)가 급습했던 사례가 흥미롭게 느껴짐, 그곳에 모여 있는 이민자들이 가장 고된 육체노동을 하는 계층이라는 점에서 이번 단속이 정말 공감 없는 방식임을 드러냄
          + 시위 진압이 아닌, 연방 인력과 자산을 보호하는 목적으로만 투입된다는 점을 강조함
          + ‘살라미 전술’이 현재의 미국 정치에서 반복되고 있음을 경고함, 민주주의가 점진적으로 독재체제로 변질되는 일반적 방법임을 지적하며, 작은 선을 하나씩 넘다 보면 어느새 완전히 다른 체제가 되어 있을 수 있음을 말함
     * MAGA(트럼프 지지) 진영이 사실상 ‘주 권한(States Rights)’을 중시하는 기치를 내세웠지만, 실상은 지도자에게 절대 복종만 남게 될 것이라는 아이러니 제기임, 결국 트럼프가 지지자들까지도 자기 원칙 깨트릴 것이라는 주장임
          + ‘주 권한’이 그들의 진짜 이유가 아니라는 비판임, 실제로 군대를 투입해 주 권리 무시하는 현실을 예로 들며, 본질적으로 과거 노예제도를 정당화하던 프레임만 바꿔서 선전한 정치적 수사에 불과하다는 분석임
          + 캘리포니아 주지사 Newsom이 주방위군 통제권을 연방에서 떼어낼 수 있는지, 즉 지금 주방위군 최고 통수권자가 누구인지에 대한 의문 제기임
     * 전직 해병대 출신들이 현 상황에서 어떻게 명령을 받을지 궁금하다는 질문임, 과연 아무 의문 없이 따를지에 대한 궁금증임
"
"https://news.hada.io/topic?id=21378","Containerization - macOS에서 Linux 컨테이너를 실행할 수 있는 Swift 패키지","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Containerization - macOS에서 Linux 컨테이너를 실행할 수 있는 Swift 패키지

     * Containerization은 macOS에서 Linux 컨테이너를 실행할 수 있게 해주는 Swift 기반 오픈소스 도구
     * Apple Silicon 기반 Mac에서 작동하며, Virtualization.framework를 활용하여 가벼운 가상 머신 안에 각 컨테이너를 격리 실행함
     * OCI 이미지 관리, 원격 레지스트리 연동, ext4 파일 시스템 생성, 컨테이너 환경 제어 등 다양한 기능을 포함함
     * Rosetta 2를 활용해 Apple Silicon에서도 x86_64 프로세스 실행 지원 가능함
     * 초단시간 부팅, 경량 환경 제공, 커널 버전 커스터마이징 등으로 개발자 유연성과 성능을 높임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 개요

     * Containerization은 애플리케이션이 Linux 컨테이너를 사용할 수 있도록 도와주는 Swift 패키지임
     * Swift 언어로 구현되어 있으며, Apple Silicon 기반의 Mac에서 Virtualization.framework를 활용해 동작함
     * API를 통해 아래와 같은 기능을 제공함
          + OCI 이미지 관리
          + 원격 컨테이너 레지스트리 연동
          + ext4 파일 시스템 생성 및 배치
          + Netlink 소켓 패밀리와의 상호작용
          + 빠른 부팅을 위한 최적화된 Linux 커널 제공
          + 경량 가상 머신 생성 및 관리
          + 가상 머신의 실행 환경 제어
          + 컨테이너화된 프로세스 생성 및 제어
          + Rosetta 2를 활용한 Apple Silicon에서 x86_64 프로세스 실행
     * API 문서는 별도의 공식 페이지에서 확인 가능

디자인 및 구조

     * 각 Linux 컨테이너는 독립된 가상 머신 내에서 실행됨
     * 컨테이너별 전용 IP 주소를 할당할 수 있어, 포트 포워딩 없이도 네트워크 관리가 간편함
     * 최적화된 커널 설정과 경량 루트 파일 시스템 덕분에 1초 미만의 컨테이너 부팅이 가능함
     * vminitd는 Containerization의 서브프로젝트로, 가상 머신 내에서 초기 프로세스로 동작하는 경량 init 시스템임
          + GRPC API를 통해 실행 환경을 설정하고, 컨테이너 프로세스 운영 관리를 지원함
          + 입출력, 시그널, 이벤트 처리를 호출한 프로세스에 전달함

요구사항

     * Apple Silicon Mac 기기가 필요함
     * 패키지 빌드를 위해서는
          + macOS 15 이상 및 Xcode 26 Beta
          + 또는 macOS 26 Beta 1 이상이 필요함
     * macOS 15에서 사용하는 경우, 아래 기능은 제한됨
          + 비격리 컨테이너 네트워킹: 같은 vmnet 네트워크 상의 컨테이너 간 통신 불가

사용 예시

     * cctl 실행 파일 제공: API의 다양한 기능을 실험해볼 수 있는 playground 형태임
          + 주요 명령 예시
               o OCI 이미지 조작
               o 컨테이너 레지스트리 로그인
               o 루트 파일 시스템 블록 생성
               o 간단한 Linux 컨테이너 실행

Linux 커널 구성

     * 컨테이너용 경량 가상 머신 실행을 위해 Linux 커널이 필요함
     * Containerization에서 제공하는 최적화 커널 설정은 kernel 디렉터리에 위치함
     * 해당 설정은 최소한의 기능만 담아 빠른 부팅과 경량 환경을 제공함
     * 필요에 따라 컨테이너별 커널 설정과 버전을 다르게 지정할 수 있는 API가 마련됨
          + 다양한 커널 버전 및 설정을 테스트 가능함
     * Kata Containers 프로젝트에서 제공하는 vmlinux.container 등 사전 컴파일된 커널 사용 가능
          + 단, VIRTIO 드라이버가 커널에 내장(compiled-in)되어 있어야 함

개발 및 테스트 프로세스 요약

     * Swift, Static Linux SDK 등 환경 준비 필요
     * 소스 코드 빌드 및 테스트 가능 (make all, make test integration 명령어 등)
          + 통합 테스트 실행을 위해 커널 이미지 필요
     * gRPC/Protobuf 관련 특정 버전을 사용하는 의존성 구성 지원
     * API 문서 자동 생성 및 로컬 미리보기 기능 탑재

오픈소스 기여 및 프로젝트 현황

     * 기여 환영
     * 0.1.0 버전이 첫 공식 릴리스이며, 소스 안정성은 마이너 버전 범위 내에서만 보장됨
     * 향후 마이너 릴리스에서 정책 변경 가능성 존재

요약

     * Containerization은 macOS에서 개발자들이 최적화된 환경으로 Linux 컨테이너를 관리, 실행, 개발할 수 있게 해주는 혁신적인 Swift 패키지임
     * 각 컨테이너를 가벼운 전용 가상 머신에서 구동함으로써 격리, 성능, 네트워킹, 커널 커스터마이징 장점을 제공함
     * 오픈소스 컨테이너 환경을 macOS 네이티브 경험으로 확장하려는 개발자들에게 적합한 솔루션임

        Hacker News 의견

     * 가장 놀랍고 흥미로운 부분이라고 생각하는 내용 공유함

     ""container"" 프로젝트에 기여를 환영하고 장려한다는 메시지 상당히 이례적인 애플의 태도로 느껴짐
     WebKit은 KHTML의 적대적 포크였고, Darwin도 마치 벽 너머로 부품을 띄엄띄엄 던져준 느낌이었음
     애플이 최근 GitHub에 공개한 이런 프로젝트들에서 사용자·개발자 협업이 활발해지길 바라는 마음
     나는 F/OSS(오픈 소스) 성향이지만, 회사 정책 때문에 리눅스를 못 쓰고 어쩔 수 없이 매일 Mac을 쓰는 사람
     애플 실리콘 도입 이후 집에서 쓰는 노트북도 Mac으로 바꿨지만, 요즘에는 리눅스에 친화적인 대안들도 점점 가까워지는 추세라 기대감 큼
     이런 변화는 긍정적인 신호이고, 나처럼 내적 갈등 있었던 사용자에게는 마음이 놓이는 변화
     혹시 이런 오픈소스 협업이 선순환 구조로 이어진다면 애플과 커뮤니티 사이 협업 문화가 더 커질 수 있을 것이라고 생각
     나 같은 개발자들이 이런 변화에서 직접적인 혜택과 동시에 애플에 대한 존중까지 얻을 수 있는 분위기라고 상상함
          + 애플이 오픈 소스 커뮤니티 참여에 대해 그리 놀라울 필요는 없다는 의견
            Swift 및 그 관련 프레임워크들에도 오픈 소스 커뮤니티의 기여가 많다는 사실 언급
          + 이 프로젝트가 리눅스를 다루다 보니, 리눅스의 카피레프트(강한 오픈소스 라이선스) 때문에 애플이 협업 방식을 취할 수밖에 없다는 시각
     * 관련 비디오로 WWDC 2025 발표 영상(https://developer.apple.com/videos/play/wwdc2025/346/) 추천
       각 컨테이너가 가벼운 리눅스 VM으로 분리되는 구조임
       container 툴 다운로드로 직접 구동 가능(https://github.com/apple/container/releases), macOS 26 필요
          + 이번 제출 건은 https://github.com/apple/containerization 이지 container 프로젝트와는 다름
            containerization은 앱이 컨테이너 사이드카와 함께 배포되는 용도라 더 흥미로운 소식
            반면 container는 개발자가 'docker run ...' 같은 환경을 쓰기 위한 목적
            container 관련해서는 별도 HN 스레드(https://news.ycombinator.com/item?id=44229239) 안내
          + macOS 15에서도 동작 가능한데, 일부 네트워킹 기능은 제한될 수 있다는 점 참고
     * 보도자료 및 WWDC 세션에서 CLI 툴이 https://github.com/apple/container 에 있다는 점 언급
       이런 툴에 관심 많은 입장으로 최신 Xcode Beta에 기본 포함되길 기대했지만, 아직은 안 들어있음
       prebuilt 패키지는 현재 준비중이지만, 작업 현황은 공개 이슈(https://github.com/apple/container/issues/54)에서 확인 가능
          + 댓글 이후 정확히 1분 뒤에 prebuilt 패키지 출시(https://github.com/apple/container/releases/tag/0.1.0) 소식 공유
          + 관련 논의는 별도 HN 스레드(https://news.ycombinator.com/item?id=44229239)에서 진행 중
     * Docker 입장에선 어떤 기분일지 궁금
       Docker for Desktop 사용자 상당수가 Mac을 쓸 것 같다는 상상
          + 이번 변화가 오히려 Docker Desktop 개발을 훨씬 수월하게 만들어준다는 의견
            이제는 독자적으로 리눅스 VM을 세팅하지 않아도 되므로 개발난이도 완화
            그래도 많은 사용자가 익숙한 CLI, Docker Compose, 다양한 Docker 독자적 UX 때문에 기존 Docker Desktop을 선호할 것이라는 예측
            컨테이너 런타임을 바꾸는 것은 쉽지 않은 일이라는 설명
          + Docker 입장에서는 podman을 대할 때와 비슷한 감정일 것이라는 추측
          + Docker Desktop이 닫힌 소스의 상용 소프트웨어이고, 이번 프로젝트는 자유 소프트웨어이기 때문에 사용자 입장에서는 좋은 소식이라는 생각
     * 이 기술이 Linux 컨테이너를 MacOS 앱에 번들링하는 데 쓸 수 있는지 궁금
       예시로, 예를 들어 GPT 같은 도구가 루트 CLI 명령어 없이도 Linux 환경에 접근하게 할 때 필요성 존재
          + MacOS 26에서만 동작해도 괜찮다면, 바로 원하는 목적에 쓸 수 있다는 안내
            아니면 Virtualization.framework를 직접 사용해서도 가능하지만, 추가 작업이 더 필요하다는 설명
          + 바로 이런 목적을 위해 나온 기술이라는 확신
     * 컨테이너마다 각기 분리된 VM으로 실행되어 완전 격리와 독립된 IP 부여 등 흥미로운 구조이지만, 이런 설계가 리눅스나 윈도우에서는 익숙하지 않음
       개발팀에서 한 명이라도 맥을 쓰지 않는다면 로컬 개발 모델이 깨져버리는 단점
       Docker/Compose를 대체하기는 쉽지 않을 것이라는 결론
     * 주요 데스크톱 OS 세 개 중 두 곳이 이제 공식적으로 리눅스 VM을 구동해서 리눅스 네이티브 애플리케이션을 실행할 수 있게 됨
       이 흐름을 보면 리눅스가 사실상 이겼다는 주장 가능
       리눅스 시스템콜 API는 이제 거의 모든 곳에서 동작하는 범용 API 위치
          + 두 개의 주요 비리눅스 OS 위에서 리눅스 기반 애플리케이션 개발이 정상적으로 이뤄져야 한다는 사실 자체가 ""리눅스의 승리""라고 보기엔 어렵다는 반론
            데스크톱 리눅스의 현실이 여전히 불안정하고 추천하기 힘들다는 경험담
            매년 Fedora/Ubuntu를 최신 PC나 랩톱에 설치해 봐도 여전히 사용성과 안정성을 못 느낀다는 솔직한 피드백
          + 오히려 다른 두 플랫폼이 리눅스를 떠나지 않고 쓸 수 있는 방식을 제공하면서 데스크톱 시장에서 리눅스 자체의 점유율 증가를 더디게 만든다는 시각
          + 그래픽, 오디오, GUI 쪽에는 아직 제대로 된 솔루션이 없다는 단점 부각
          + ""게임에 참가한 플레이어가 본인밖에 없으면 이긴 것일까""라는 의문 제기
            평범한 Windows, Mac 사용자에게 말해봤자 리눅스가 뭔지조차 모르는 상태라고 농담
          + ""리눅스와 함께하는 macOS""라는 사실 자체가 임팩트라는 의견
     * 이들이 메모리 관리(필요 이상으로 VM이 메모리를 쓰지 않는 구조)도 최적화했는지 궁금
     * 어떤 과정인지 정확히는 모르겠으나, 빌드 속도가 너무 느린 느낌
       -c, -m 옵션으로 CPU/메모리 자원 더 늘려봤지만 효과 체감 미흡
          + 어떤 환경과 비교해서 느린지 궁금
            과거 실리콘 Mac + Rancher Desktop 조합에서 x86 이미지를 빌드하는 척 했지만, 실제 x86 하드웨어에서 그 이미지들이 제대로 동작하지 않은 경험 공유
     * 짧은 데모(https://developer.apple.com/videos/play/wwdc2025/346)에서 수백 밀리초 단위로 VM 부팅 가능하다는 점이 인상적
       Virtualization.framework로 동작하는데, 이는 Docker desktop/Colima/UTM 등도 선택적으로 사용하던 기술
       컨테이너 여러 개를 병렬로 돌릴 때 메모리 오버헤드가 궁금
          + 최적화된 리눅스 커널 설정(kernel config, https://github.com/apple/containerization/…)과 최소 루트 파일시스템, 가벼운 init 시스템 덕분에 컨테이너 부팅 속도가 1초 미만으로 줄었다는 설명
"
"https://news.hada.io/topic?id=21428","Cloudflare 서비스 전반적 장애 발생","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Cloudflare 서비스 전반적 장애 발생

     * 최근 Cloudflare 서비스가 전반적으로 장애 현상을 겪음
     * 사용자들은 이메일 또는 문자 메시지를 통해 사고 관련 실시간 알림을 받을 수 있음
     * Cloudflare는 장애가 발생하거나 해결될 때마다 사용자에게 알림을 제공함
     * 전 세계 다양한 국가의 사용자가 문자 메시지 알림을 신청할 수 있는 환경임
     * 모바일 번호 인증을 완료하면, 실시간 인시던트 업데이트 수신이 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Cloudflare 서비스 상태 페이지 안내

   Cloudflare는 최근 광범위한 서비스 장애가 발생했음을 공지함

실시간 알림 서비스 안내

     * 사용자는 Cloudflare 사고 현황이 업데이트될 때마다 이메일 알림을 받을 수 있음
     * 사고가 발생하거나 해결될 때마다 문자 메시지(SMS) 알림을 받을 수 있음

문자 메시지 알림 신청 국가

     * Afghanistan, Albania, Algeria, American Samoa, Andorra 등 세계 대부분 국가의 사용자에게 문자 서비스가 제공됨
     * 각 국가별 국제번호를 선택하여 모바일 번호를 입력하는 방식임
     * 대한민국(Republic of Korea, +82) 포함, 아시아, 유럽, 미주 등 다양한 지역 서비스 지원임

알림 구독 및 인증 절차

     * 사용자는 원하는 국가 코드와 자신의 모바일 번호를 입력함
     * 가입 시, 입력한 번호로 OTP(일회용 비밀번호) 가 전송됨
     * 해당 OTP를 인증함으로써 문자 알림 수신 절차가 마무리됨
     * 이메일만으로도 구독 신청 가능함

요약

     * Cloudflare의 상태 페이지를 통해, 서비스 장애와 관련된 실시간 정보를 사용자에게 제공함
     * 전 세계 다양한 지역의 사용자들이 간편하게 문자 및 이메일 알림을 받을 수 있어 장애 대응 및 인시던트 상황 파악이 용이함

        Hacker News 의견

     * Cloudflare의 중요한 Workers KV 서비스가, 중요한 의존성을 가진 서드파티 서비스 장애 때문에 오프라인 상태가 된 상황 언급
          + 이게 사실이라면, 그리고 다른 BGP 관련 이슈가 없다면, 이런 의존성은 오래가지 않을 거라는 추측
          + Cloudflare가 일부 서비스에 GCP를 의존하고 있다는 이야기에 대해, Google에서는 이번 장애가 없었다는 공식 부인 언급, 관련 트위터 링크 공유 트위터 Nitter
          + 서브 프로세서 페이지를 확인하면 실제 의존성을 검증할 수 있다는 정보와 링크 공유 Cloudflare Subprocessors
          + 나도 비슷한 내용의 댓글을 작성했었기 때문에 앞으로 참고할 만한 내용이라는 생각
     * Downdetector에서 Google, Cloudflare, AWS 등 많은 주요 기업에서 장애가 발생하고 있다는 상태 파악, 이번 사태의 원인으로 BGP 라우팅 문제가 있다는 업계의 의견 공유
          + 이런 상황이면 BGP 문제가 맞다는 생각, 예전에 트래픽이 이란이나 중국 등으로 잘못 경로 지정된 사례도 언급
          + Internet Health Report에서 ""표시할 데이터 없음""이라는 메시지 확인
          + Anthropic도 다운 혹은 성능 저하 상황이라 산책이나 하러 갈 타이밍이라는 여유 표현
     * GCP도 다운 상태라는 제보와 함께 관련 링크 공유
          + 서비스 장애가 대규모로 발생할 때 느껴지는 상상력 있는 농담(스케일이 확실히 다르다는 분위기)
          + 이상하게 느껴질 정도로 겹치는 상황이 발생, Cloudflare가 GCP를 사용하는 건지 궁금증 표출
     * 누군가 BGP 설정을 잘못 배포했을 것 같다는 직감 표현
          + 이 정도로 광범위하고 심각한 사태라면 BGP가 주요 원인일 확률이 높다는 확신
     * 이번 사태가 상당히 심각한 문제로 보인다는 의견, 한동안 이렇게 많은 서비스에서 동시다발적으로 문제가 발생하는 것을 본 적이 없다는 느낌
          + 클라우드 등 주요 인프라가 소수 기업에 집중되면서 이런 사태가 점점 서서히 정기적으로 발생하는 느낌이라는 지적
     * ""인간임을 인증하세요"" 대화창과 Workers 등에서도 기능 장애가 나타나는 중이라는 현상 공유
          + KV도 동작하지 않고, KV에 의존하는 워커들은 예외를 던지고 있다는 경험, 대시보드는 접속은 되지만 매우 느리고, 18시(UTC)쯤부터 오류율이 급증하기 시작했다는 상황 설명, 그리고 Cloudflare 상태 페이지에서 대규모 장애를 공식 확인한 링크 추가 Cloudflare Status
          + 정말로 Cloudflare에서는 ""인간 인증"" 대화창을 많이 보는데, Akamai에서는 볼 수 없는 것이 궁금해지는 상황
     * Cloudflare에서 서비스 장애 공지 제목을 ""Broad Cloudflare service outages""로 바꿨다는 사실 공유
     * 곧 인터넷을 구한 대서사시 블로그 포스트가 올라올 것 같다는 재치 있는 예측과 함께, 현재는 다운된 상태지만 참조할 만한 DDoS 관련 Cloudflare 공식 블로그 글 링크 소개 Cloudflare Blog: The DDoS That Almost Broke the Internet
     * 이번에 우리 Workers 앱들이 다시 정상 상태로 돌아왔다는 현황 보고, 미국에서는 잘 되고 있지만 유럽(EU) 고객은 여전히 장애를 겪고 있다는 추가 상황 공유, 그 이후에는 유럽 고객도 다시 정상 회복된 상태라는 최신 정보 전달
"
"https://news.hada.io/topic?id=21405","브라이언 윌슨 사망","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               브라이언 윌슨 사망

     * Beach Boys의 공동 창립자인 브라이언 윌슨이 향년 82세로 별세 소식 공개됨
     * 공식 사인은 밝혀지지 않았으며, 2024년 초 신경 인지 장애를 겪고 있다는 사실이 전해짐
     * 10대 시절 형제들과 친구, 친척과 함께 처음 밴드를 결성해 Surfin’ U.S.A. 등 히트곡을 냄
     * Pet Sounds 앨범과 스튜디오 작업 혁신으로 팝 음악의 발전과 후대 뮤지션에게 영향 미침
     * 윌슨은 항상 실험적인 음악 작업을 추구하며 음악적 성장과 창의성에 전념함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

브라이언 윌슨 별세 발표

     * Beach Boys의 공동 창립자이자 주요 작곡가였던 브라이언 윌슨이 별세함
     * 윌슨 가족은 공식 인스타그램 성명을 통해 사망 사실을 알렸으며, 사인이나 구체적 시기 및 장소는 밝히지 않음
     * 최근까지 신경 인지 장애(치매 유사 증상) 로 투병 중이었음

윌슨 가족의 입장

     * 가족은 ""사랑하는 아버지 브라이언 윌슨의 별세 소식을 전하게 되어 황망함""
     * ""지금은 말로 표현할 수 없는 상실감""이라고 밝혔으며, 사생활 보호를 요청함
     * ""세상과 고통을 함께 나누고 있음을 인지함""이라는 메시지와 함께 ""Love & Mercy""라는 말을 남김

음악적 성장 과정과 밴드 결성

     * 캘리포니아 잉글우드에서 태어난 브라이언 윌슨은 10대 시절 두 형제 Dennis, Carl, 사촌 Mike Love, 친구 Al Jardine과 밴드를 결성
     * 첫 곡 ""Surfin’"" 발표 당시 밴드 이름은 Pendletones였으나, 음반사에 의해 Beach Boys로 이름이 변경됨
     * ""Surfin’ U.S.A.""로 처음 미국 Top 10 싱글 진입
     * 1963년 한 해 동안 Surfin’ U.S.A., Surfer Girl, Little Deuce Coupe 등 세 장의 앨범을 발표함
     * 이 시기부터 윌슨은 다른 뮤지션의 프로듀서 활동도 병행함

실험적 음악성과 Pet Sounds

     * 1964년, 잦은 공연 일정으로 인한 공황 발작을 겪고 Beach Boys 투어에서 하차, 제작 활동에 집중하게 됨
     * 1965년부터 기념비적인 실험적 팝 앨범 Pet Sounds 제작 시작
     * The Wrecking Crew와의 협업 속에 사운드를 혁신하며 '스튜디오를 악기로' 활용하는 방식을 선도함
     * 발매 당시에는 상업적, 비평적으로는 큰 평가를 받지 못했으나
     * 2004년 미국 의회도서관의 국립녹음기록보관소에 문화적·역사적·미학적 중요성으로 등재됨

음악에 대한 철학과 혁신

     * 2016년 Harvard Business Review 인터뷰에서 ""항상 음악적 성장을 추구""했다고 밝힘
     * ""기존 성과에 안주하지 않고, 악기를 목소리처럼, 목소리를 악기처럼 사용하며 새로운 사운드 구현""에 몰두함
     * 때로는 기술적 한계로 실행이 어려운 아이디어도 있었으나, 대부분의 아이디어가 실현됨
     * 실험을 거듭하며 음악적 창의성과 다음 단계로의 도전에 집중함

        Hacker News 의견

     * 나에게 브라이언 윌슨은 역대 최고의 팝 작곡가라는 확신형 존재감. 최근의 힘든 시기 음악조차 신기하면서도 감동적이고 완벽한 장인정신 보여줌. 2021년 “Right Where I Belong”에서 불안, 두려움, 사랑에 대한 진심 담은 가사와 깊이 있는 내면 세계 느껴짐 (유튜브 링크). 그는 미국 그 자체라 여겨짐. 이상주의, 기이하면서도 진솔한 교외 감성, 장르의 완전한 통달력. 2분 남짓의 곡 안에 마치 완벽히 손질된 잔디밭 같은 기묘한 아름다움과 복합성을 담아냄. 언어를 초월한 선율과 화음, 우주 전체에 바치는 곡 느낌. 곡 주제가 여자든 파도든 차든 상관없이 모든 것에서 예언자적 면모. 윌리엄 블레이크와 같은 동시대의 선지자라 생각. 바차라크, 바흐 못지않은 위대함을 본인이 알았는지는 모르겠으나 그저 일에 대한 사랑이 더 컸던 듯함. 정말 모든 것에 감사
       인사형 마음
          + 브라이언 윌슨과 데이비드 린치가 서로 거울상처럼 닮았다고 자주 느꼈음. 둘 다 이제 우리 곁을 떠난 상태라는 점에서 묘한 여운 남김
          + 나 또한 힘들게 받아들이는 중. 이제 내가 존경하던 인물들이 하나둘 떠나가는 나이. 비치 보이스의 전성기는 미국의 순수성을 상징한다는 생각. 그래서인지 그 시절을 살아본 세대라 그 때의 분위기를 느낄 수 있었음에 감사. 음악 속에 그 시대의 기억을 조금이나마 붙잡을 수 있다는 점이 위안. 빛나는 인물들이 하나씩 사라지는 모습을 지켜보는 게 가장 힘듦. 그래도 앞으로 세대들이 더 밝은 미래를 만들 수 있을 것이라는 희망을 품음
     * BBC Music에서 “God Only Knows” 너무 사랑함 (링크)
     * “Pet Sounds” 앨범이 가사적으로는 초창기 이모 음악 느낌을 갖고 있고, 악기 편곡은 사이키델릭 두왑 스타일로 포장된 느낌이라 생각. 한동안 ‘똑똑한 척 하는 사람들이 일부러 좋아하는 앨범 아닌가’ 하고 오해했다가, 성숙해지면서 진짜 명반임을 깨달음. 지금은 최고의 앨범 중 하나로 꼽음
          + “Pet Sounds”가 특별했던 점은 독특한 음악성 뿐 아니라, 브라이언 윌슨이 창작 과정에서 피아노 주변에 모래를 깔아 놓았던 이야기가 인상 깊음. 그 사진도 봤음 (사진 링크). 물리적, 감정적 분위기 조성을 위해 이런 시도를 했다는 점이 인상 깊음
          + 친구가 2주 전에 앨범 교환을 하자고 해서 처음 몇 번 들을 때는 잘 다가오지 않았는데, 어느 순간 완전히 빠져버림. 이후로 계속 들으면서 감탄하게 됨. 진짜로 훌륭한 명반
          + Pet Sounds와 관련해서, “God Only Knows”가 폴 매카트니 등 여러 뮤지션들이 역사상 최고의 곡으로 뽑은 사례 기억. 곡 자체가 여럿 특이함에도 불구하고 존경받고 있음
          + 어릴 땐 엄마가 많이 틀어주셔서 Pet Sounds를 좋아함. 수학 숙제할 때 항상 배경음악으로 들었던 추억. 핑크 플로이드(Echoes)도 즐겼음. 어린 시절엔 “I'm Waiting For The Day”가 신나서 좋아했고, 성인이 된 지금은 “Let’s Go Away For Awhile”에 더 빠져듦. 남녀노소 모두를 위한 무언가가 있는 앨범이라 생각
     * 오늘 아침에 데니스 윌슨의 다음 발언이 생각났었음: “브라이언 윌슨이 비치 보이스의 전부다. 우리는 그의 메신저에 불과하다. 그는 모든 것, 우리는 그냥 아무것도 아니다” (책 링크). 영화 “Love and Mercy”에서 가족들이 그려진 부분과도 연결. 실력과 재능을 지녔음에도 데니스의 말이 맞다고 느낌. 브라이언이 곧 비치 보이스였다는 믿음. 명복을 비는 마음
          + 나이 들고 나서야 The Wrecking Crew의 연주가 비치 보이스 앨범에 많이 담겼다는 사실에 놀랐음. 노래는 비치 보이스지만, 곡 제작·구성 등 모든 창조 작업은 브라이언이 중심이었다는 걸 점점 더 깨달음
     * 브라이언 윌슨 본인의 1988년 동명 솔로 앨범 꼭 들어보길 추천. 너무도 훌륭. 팬들 사이에선 “Pet Sounds ‘88”로 불릴 정도로 영적 후속작 평가. 80년대 신스 사운드에 처음엔 거부감이 들 수도 있지만, 작곡력과 음악성은 정말 대단함. 그리고 “Smile!”은 Smiley Smile도, The Smile Sessions도 아닌 2004년 리크리에이션 버전 필청. 눈 감고 들으면 진짜 심포니 느낌 (링크)
          + Doleful Lions가 비치 보이스 광팬임을 고백한 Surfside Motel 곡의 가사에서 “정부가 비치 보이스가 Smile을 내는 걸 막았다…”는 이야기. 재밌게 들을 수 있는 곡 (밴드캠프 링크)
          + 예전 예술 작업이 얼마나 여러 방면에서 외주로 이뤄졌는지 새삼 놀라움. 88년 브라이언 윌슨 앨범 커버도 매우 독특한 느낌
     * 아홉 살 때 엄마가 선물해 준 두 장의 바이닐 앨범: ""Simon and Garfunkel의 Greatest Hits""와 ""The Beach Boys – High Water"". 어린 시절 음악적 취향을 이 두 앨범이 완전히 만들어 줬다고 느끼는 중. 그 후 유튜브에서 브라이언 윌슨이 멋진 팔세토 파트 많이 담당했다는 것도 알게 됨. “I get around / From town to town / I'm a real cool head / I'm making real good bread” 이런 가사가 계속 머리에 남음. 에드 설리번 쇼에서 베이스 연주하는 영상도 확인 (링크)
     * “God Only Knows”는 완벽한 곡이라는 확신. 브라이언이 세상에 이 곡을 내놓아서 정말 고마운 마음 (링크). 그리고 그의 삶을 섬세하게 다루는 아름다운 영화도 강추, 폴 다노가 출연해 감동적으로 소개 (영화 예고편 링크)
          + 먼 미래 인류가 사라진다 해도 “God Only Knows”라는 곡이 저 어딘가 남아 있으면 그 사실만으로도 괜찮을 것 같은 기분
     * T.A.M.I. Show 공연 영상 링크 공유 (링크). 1964년 미국 인터내셔널 픽처스에서 개봉된 콘서트 필름. 미국과 영국의 인기 락, R&B 뮤지션들이 총출동한 공연. 산타모니카 교외에서 열린 이 공연은 현지 고등학생에게 무료 티켓 배포. T.A.M.I. 약자가 다양한 뜻으로 쓰였고 (위키백과), 특히 브라이언 윌슨과 비치 보이스가 이름을 알리기 시작한 전성기의 모습이 인상적임
     * 얼마 전 아내가 브라이언 윌슨 공연에 데려가줘서 정말 다행이라 생각. 록앤롤 역사에서 가장 영향력 있는 인물 중 한 명. 시간이 지나면 더 많은 이들이 그의 위대함을 알아주길 바람. 진심으로 명복을 비는 마음 (공연 영상 링크)
     * 유진 랜디와 연관된 비극적 삶의 스토리도 있지만, 진정으로 놀라운 음악 남김. 경력이 최근 수십 년간 재조명받아 만인의 사랑을 받으며 떠날 수 있어 다행. 오늘은 브라이언을 기리며 Norbit (2007) 시청 예정
          + Norbit와 브라이언 윌슨이 무슨 관련 있는지 궁금증
"
"https://news.hada.io/topic?id=21347","Apple Computer에 합류한 이야기 - 빌 앳킨슨 (2018)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Apple Computer에 합류한 이야기 - 빌 앳킨슨 (2018)

     * 빌 앳킨슨이 40년 전 Apple Computer에 합류한 경험을 회상함
     * Steve Jobs의 설득과 비전이 큰 인생의 전환점이 됨
     * UCSD Pascal System 도입, QuickDraw, Lisa Window Manager 등 혁신적 소프트웨어 개발에 기여했음
     * MacPaint와 HyperCard로 사용자의 창의성을 확장시키는 도구를 제공했음
     * Apple에서의 12년이 인생을 결정짓는 소중한 시간이었음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Apple Computer 합류와 시작

     * 40년 전인 1978년 4월 27일, Apple Computer에 입사한 경험이 인생의 큰 전환점이었음
     * 당시 University of Washington에서 신경과학 박사 과정을 밟고 있었으며, Jef Raskin의 권유로 Apple에 방문하게 됨
     * 처음에는 학위 취득에 집중하고 싶었으나, Jef Raskin이 항공권까지 보내주며 설득하여 캘리포니아에 방문하게 됨

Steve Jobs와의 만남

     * Steve Jobs가 하루 종일 시간을 내어 모든 Apple 직원들과 소개하고, 직접 열정적으로 채용을 시도함
     * Apple의 직원들은 지적이고 열정적인 모습을 보였으나, 초반에는 그 정도로 박사 과정을 포기할 생각은 들지 않았음
     * Steve Jobs는 세상에 알려진 신기술은 이미 2년 전 것이라며, Apple에서 미래를 창조할 수 있는 기회를 강조했음
     * 파도 앞단에서 즐겁게 서핑하는 비유에 큰 설득을 느껴 결국 박사 과정을 그만두고 Apple에 입사하게 됨
     * 가족의 반대에도 불구하고, 올바른 선택이라는 확신을 가졌음

Apple에서의 주요 경험

     * Steve Jobs와는 Castle Rock State Park에서 산책을 하거나, 식사하며 인생과 디자인에 대해 토론하는 등 가까운 사이가 됨
     * 때로는 “미친 아이디어가 있는데…”로 시작하는 대화에서 실제로 제품 설계로 발전하기도 했음
     * Steve의 지원은 회사에서 의미 있는 결과를 만들어내는 데 큰 힘이 됨

혁신적 소프트웨어 개발 (UCSD Pascal, QuickDraw 등)

     * UCSD Pascal System을 Apple II에 포팅하고 싶었지만 관리자는 반대했음
     * Steve Jobs에게 직접 강하게 주장하여 2주 동안 Pascal 시스템을 구현해 Lisa 개발에 기반을 제공함
     * Lisa 컴퓨터에는 필수적으로 마우스를 기본 동봉할 것을 주장, 최종 채택됨
     * 그래픽 효과를 위해 화면 배경을 흰색으로 해야 한다는 주장도 관철됨
     * QuickDraw 그래픽 기본 함수를 어셈블리어로 작성하여 bitmap 기반 GUI를 현실성 있게 만듦

Lisa, Macintosh와 MacPaint, HyperCard

     * Lisa Window Manager, Event Manager, Menu Manager 등 주요 소프트웨어 관리 기능을 개발되고 앤디 허츠펠드가 Mac에 응용함
     * Macintosh ROM의 3분의 2 코드가 자신의 기여였음
     * MacPaint를 개발, 그래픽과 마우스의 재미와 창의적 가능성을 사용자에게 보여줌
     * 1983년 Norman Seeff의 사진에서 Steve Jobs와의 역동적인 관계가 드러남
     * Steve Jobs가 자신을 이용했다는 말도 있지만, 실제로는 동기 부여와 창의성 발휘를 이끈 리더로 평가함
     * Apple에서 만든 제품들이 수백만 명에게 쓰인다는 점에서 큰 흥분과 가치, 보람을 느낌

HyperCard와 Apple 이후

     * 1985년 LSD 체험에서 영감 받아 HyperCard 저작 시스템을 고안, 프로그래머가 아니더라도 인터랙티브 미디어를 만들 수 있게 함
     * HyperTalk 언어는 초보 프로그래머도 쉽게 이벤트 기반 프로그래밍에 입문할 수 있는 구조였음
     * Steve Jobs의 Next 합류 제안을 거절하고 HyperCard 완성에 몰두, 1987년 Apple이 HyperCard 발표
     * Apple에서 12년 동안 창의적 도구 개발, 회사 직원 30명에서 15,000명으로 성장에 동참함
     * 1990년 General Magic 공동 창업으로 개인 커뮤니케이터 개발에 참여, Apple에서의 시간이 인생의 터닝포인트가 됨
     * Jef Raskin과 Steve Jobs의 신뢰와 기회 제공에 깊은 감사함

마무리

     * 40년 전 Apple에서 내린 결정이 삶의 모든 것을 바꾼 결과를 제공했음
     * 의식 연구도 여전히 관심이지만, Apple에서 세상에 긍정적 영향을 준 것에 큰 만족을 느낌

        Hacker News 의견

     * 나는 Apple을 떠나 Marc Porat, Andy Hertzfeld과 함께 General Magic을 공동 창업해 개인 통신기기 발명을 도왔다는 경험을 가지고 있음
       대형 혁신 기업들의 창시자들 중 많은 사람들이 서로 연결된 배경, 그리고 이들이 권력과 부를 가진 인물들과 어떻게 얽혀 있는지 항상 흥미롭게 느껴짐
       예를 들어 Marc Porat의 이름이 익숙해서 찾아봤는데, 그는 Google의 사장인 Ruth Porat의 오빠였음
       리더들이 조직에서 최고에 오르는 데 정말 재능이 중요한지, 아니면 막강한 인맥도 한몫하는지 궁금증
       나 역시 멋진 아이디어와 재능으로 제품을 만들었지만, 항상 자금 확보에 어려움
       이런 네트워크를 아는 사람들이 나에게도 있다면 좋겠다는 바람
          + 슈퍼스타 한 사람이 단독으로 성공하기 어렵고, 결국 주변에 다른 슈퍼스타들이 있어야 진정한 시너지가 발생
            이들은 서로를 알고 있기 때문에 훨씬 더 성공이 쉬움
            그리고 세상에 드러나지 않은 무수한 실패자들은 거의 기억되지 않음
            수많은 잠재력 있는 인재들을 연결하는 것이 이런 성공적인 회사와 명문대의 중요한 역할
            20세기 천재들이 한자리에 모인 사진처럼, 앞서간 선구자 위에 새로운 선구자가 쌓여 함께 정상까지 단체로 올라감
            여러 시즌 동안 활약한 스포츠 명문팀 같은 느낌
            우연이 아닌 필연의 연결고리
          + General Magic 다큐멘터리(2018)는 진짜 감탄할 만한데, 과소평가 받고 있음
            볼 때마다 눈물이 맺힐 정도로 감동적인 구식 스타트업 성공기
            사운드트랙도 아름다움
          + 자본이나 타인의 재능, 혹은 시장(사용자)에 닿을 수 있는 접근성이야말로 본인이 뛰어난 제품을 만들 실력이 있다 해도 최대의 경쟁력
            그런 자원을 쥘 수 있다면 성공 가능성 극대화
     * 정말 좋은 글이라는 생각
       예전에는 뭐든 가능하고 열려 있는 느낌, 신나는 자유로움이 있었음
       크게 대단한 것이 아니어도 뭐든 할 수 있던 시절 그리움
       이젠 광고에 점령당한 닫힌 상자 느낌
       로그인해서 제한된 공간에서만 살아야 하는 현실
       그래도 인터넷 본연 모습은 아직 남아 있고, 광고 없는 내 사이트를 여전히 올릴 수 있음
       그런 인터넷만 탈 수 있었으면 하는 소망
          + 나는 이 이야기 속 주인공들이 활동하던 시기와 나이가 비슷한데, 정반대로 느끼고 있음
            중고등학교 땐 ‘2000년대는 스마트폰과 인터넷으로 어마어마한 기회가 열린 시기라 뭐든 가능했던 것 같은데 이제 거대 기업이 다 장악한 것 같다’는 생각
            하지만 GenAI 붐이 내 생각을 완전히 바꿈
            지금이야말로 의욕만 있으면 상상초월의 프로젝트가 가능한, 모든 세대 중 가장 운 좋은 엔지니어 세대
          + https://kagi.com/smallweb
            작고 자유로운 웹에 대한 링크
          + “나도 그 인터넷만 탈 수 있었으면 좋겠다”는 말을 읽고 뭔가를 깨달음
            계속 90s.dev를 어떻게 쓸까 고민했는데, 정답을 알게 된 느낌
     * HyperCard 같은 혁신에는 항상 감탄
       비기술자에게도 ‘왕의 열쇠’를 주려는 의도가 담겨 있었음
       요즘처럼 폐쇄적인 앱스토어나 플랫폼만 보면 시대가 오히려 퇴보한 것 같은 기분
          + HyperCard나 MacPaint(사실은 Quickdraw 데모)를 단 하나라도 만들었다면 이미 천재 반열
            혁신성에 박수
          + 아마 우리는 LSD를 좀 더 해야 하는 상황인 듯한 농담
          + 컴퓨팅 자체를 자본주의와 소비주의 틀에서 분리해내는 것이 여전히 매우 어려움
            인류의 다른 창조적 예술(시, 연극, 음악, 미술 등)은 다양한 시대와 문화, 경제 구조에서 자생
            하지만 컴퓨팅은 항상 엄청난 공장, 공급망, 그리고 소비자 대중 등 산업화의 산물
            칩 공장을 컨트롤하는 기업이 결국 모든 것을 결정
            애플이 가장 전형적 사례
            오픈소스 운동 같은 예외적 움직임이 있지만 칩공장 장악력 앞에선 쉽지 않음
            이런 경향에 맞서 싸우는 운동이 꼭 필요한 시점
            예를 들면 uxn처럼 경량 가상머신 위에서 과거 저렴하고 단순한 칩을 최대한 활용해 소프트웨어를 개발하는 접근 좋아함
            이런 환경이 백 년 뒤에도 남을 것
          + 아이러니하게 애플이 이런 폐쇄 경향을 주도한 대표적 위치
          + 강하게 공감
     * Apple에서 12년 남짓밖에 일하지 않았다니 의외
       분명 드라마틱한 여정
       나도 1995년에 실리콘밸리로 이사 왔는데, 아파트가 General Magic 바로 옆이었음(Mary Ave.)
       당시엔 Apple의 스핀오프 정도로만 알았고, 굉장한 인재가 모인 곳인지는 몰랐음
       토끼 모자가 그려진 로고가 불 켜져 있는 귀여운 사무실로 기억
          + 정말 롤러코스터 같았을 것
     * 1985년 LSD 여행에서 영감 받아 HyperCard 저작 시스템을 만들었다는 부분이 인상적
       비틀즈의 LSD 경험이나, Robert Crumb의 대표 캐릭터 창조도 떠올라
       LSD가 사람의 뇌를 영구적으로 바꾼다는 말도 종종 들음
       비틀즈/크럼프처럼 각성제 경험이 있어야 대작 예술이 나오는 건 아닌지라는 생각도 했으나, LSD ‘발명’ 전에도 Edvard Munch, TS Eliot, William Blake 등 위대한 예술인이 많았기에 단정은 힘듦
       나 역시 대학 때 한 번 해봤는데 충분했던 기억
          + 전통적으로 환각제 사용은 사전 준비, 마인드셋, 환경, 그리고 맨정신의 시터가 필요
            LSD는 뇌를 영구적으로 바꾸지 않고, 오히려 psilocybin이 그런 효과를 보임
          + 생존자 편향일 수도
            담배도 천재가 많이 즐겼지만, 많이 피워도 천재가 나오진 않음
          + 이런 약물 사용은 아주 오래된 활동
            소마 등 인류 문명, 예술, 종교의 역사에서도 나타남
     * “마음을 넓히는 LSD 여행에서 영감 받아 HyperCard를 만들었다”라는 말도 인상적
       어떻게 하면 좋은 여행과 좋지 않은 여행의 차이를 둘 수 있을지 궁금
     * 정말 전설적인 인물
       고등학교 때 처음 Mac을 만졌을 때 엄청난 즐거움을 느꼈음
       며칠이고 컴퓨터 안에서 완전히 빠져 살기도 했음
       Bill에게 감사
          + 나도 같은 느낌
            이 감각을 어떻게 되찾을 수 있을지, 남들과 공유할 수 있을지 계속 고민
            방법이 분명 어딘가에 있을 것
          + 내 경우엔 아마 MacPaint였던 것 같음
     * “나는 12년간 Apple에서 창의적인 이들을 위한 도구를 만들었다”라는 구절이 많은 사람들에게 Apple에 대한 팬심, 더불어 컴퓨팅 산업 자체에 대한 흥분감을 안겨줬음
       오랜 기간 이 미션이 Apple의 정체성이었다고 생각
       하지만 오늘날에도 그 철학이 남아 있는지에 대해서는 의견이 갈릴 듯
     * 최근 “라이트 모드”의 원조가 누구인지 곰곰이 생각해봤는데, 여기에서 기원을 찾았음
       Apple II는 검은 바탕에 흰 글씨였으나, 그래픽을 위해 종이 같은 하얀 바탕을 주장
       포토 이미지까지 음화로 출력되면 곤란하기 때문
       Lisa 하드웨어팀은 이 방식이 잔상이 생겨 더 비싼 램이 필요하다고 반대했지만, Steve가 그래픽을 위해 결국 흰 바탕을 선택
          + 이건 읽기 쉬운 화면이라는 “죄”일 뿐
            라이트 모드가 나쁘기만 한 건 아닌 관점
          + 진짜 문제는 둘 다 제공하는 것
     * 마치 자신의 부고를 직접 쓴 것 같은 글
          + 사실 우리는 누구나 결국 죽음
            흥미로운 인생사는 널리 나눠야 한다고 생각
          + 나이 들수록, 나도 비슷한 시선의 이야기를 자주 하게 되는 듯
            자연스러운 흐름
"
"https://news.hada.io/topic?id=21425","덴마크 디지털부, Windows와 Microsoft Office를 Linux와 LibreOffice로 교체","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      덴마크 디지털부, Windows와 Microsoft Office를 Linux와 LibreOffice로 교체

     * 덴마크 디지털부가 전 직원의 Windows와 Office 365를 각각 Linux와 LibreOffice로 단계적으로 전환 중임
     * 이번 조치는 덴마크의 디지털 주권 강화와 특정 공급업체 의존도 감소 전략의 일환임
     * 코펜하겐 및 오르후스 등 주요 지방자치단체에서도 유사한 변화가 확산됨
     * 장관은 오픈소스 협력과 공급업체 다양성 확보를 강조하며, 전환에 어려움이 있으면 임시 복귀도 가능하다고 언급함
     * 일부 사건과 미국의 정책 변화 등으로 미국 IT 기업 의존도에 대한 우려와 경계심이 특히 크게 부각됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 덴마크 디지털부는 가까운 시일 내 Microsoft 제품 사용을 전면 중단하고, Windows에서 Linux로, Office 365에서 LibreOffice로 업무 인프라를 완전히 교체하는 절차를 발표함
     * 이 결정은 디지털부 장관 Caroline Stage가 주요 일간지와의 인터뷰에서 공식적으로 밝혔으며, 몇 주 전 덴마크 내 최대 규모 지자체들 역시 비슷한 방향을 내비친 이후 빠르게 확대되고 있음
     * 올해 여름에는 절반가량의 직원이 새 환경에서 일하게 되며, 가을까지 부 전체가 Microsoft에서 완전히 탈피할 예정임.

디지털 주권과 공급업체 의존성 완화

     * 디지털부의 이번 정책 변화는 덴마크 왕국의 ‘디지털 주권’ 강화 전략의 일환으로, 국가 데이터와 IT 인프라의 제어권을 외국 공급업체에서 자국으로 되돌리려는 취지임
     * 덴마크 야당 역시 미국계 IT 기업에 대한 의존도를 낮추자는 요구를 계속 제기하고 있어, 정치권 전반의 합의가 커지는 분위기임
     * 최근 코펜하겐 시정촌은 Microsoft 소프트웨어 사용 현황을 검토하기로 결정했으며, 두 번째로 큰 도시 오르후스에서는 이미 Microsoft 서비스 부분 대체가 진행 중임
     * 디지털부 장관 Stage는 전국의 모든 지자체가 오픈소스와 협력, 공급업체 다변화에 힘을 모으자고 발표함

전환 과정과 태도

     * 만일 이행 과정에서 예상치 못한 문제나 난항이 있을 경우, 임시로 기존 시스템으로 복귀하거나 다른 방안을 찾는 유연한 접근 방침을 전함
     * 장관은 “실행하지 않으면 목표에 절대 다가가지 못한다”는 의지를 밝혔으며, 현재까지 직원들 다수는 전환 정책에 긍정적인 반응을 보이고 있음
     * 디지털 전환을 주요 임무로 삼고 있는 부서 특성상, 새로운 환경에 대한 흥미와 도전 의지가 높을 것으로 기대하고 있음
     * 이번 변화는 단순히 Microsoft에 국한된 문제가 아니라, 전반적인 공급기업 집중 현상 해소에 초점을 두고 있음을 강조함

배경 및 추가 요인

     * 이번 추세에는 국제형사재판소의 Microsoft 이메일 계정 차단 등 특정 사건에서 불거진 외국 IT기업과의 신뢰 문제도 배경으로 작용함
     * 최근 미국 대통령이 그린란드 인수 의사를 공식화하는 등 외교적 긴장이 커지면서, 덴마크에서는 특히 미국 기업에 대한 의존 축소 요구가 더욱 강해지는 분위기임

결론

     * 덴마크 디지털부의 Microsoft 탈피와 오픈소스 도입 정책은 자국의 디지털 주권, 공급업체 분산화, 투명성 제고 등을 목표로 한 전환임
     * 이 전환은 다른 국가와 공공기관의 오픈소스 채택 논의에도 중요한 참고사례가 될 전망임

   이미 한국에서도 예전 정부에서 시도 했었는데... 결국 보수적인 여러 환경과 오픈소스도 결국 공짜가 아니라는 점에서 더 나아가진 못했죠. 하지만 독점에 대안을 제시했단 점에서 큰 의미가있었죠.

   그린란드를 뺏어가겠다는 트럼프와 싸우겠다면
   덴마크는 정부 문서를 ms office 365 클라우드에 저장하는 것부터 당장 중단해야겠죠
   매우 불편해지겠지만 어쩔 수 없는 결정일 듯

   우리나라도 하모니카(일반용), 구름(보안강화형) 두개 프로젝트 있는데 좀더 흥했으면 좋겠네요

   트럼프가 리눅스 데스크탑의 시대를 여네요 ㅋㅋㅋ

   리브레오피스를 주로 사용하려 했는데 마소 오피스보다 편의성이 구려서 다시 회귀한 적이 있습니다... 편의성만큼은 꼭 마소 오피스만큼이나 높았으면...

   오히려 옛날에 했어야 하지 않나.. (우리나라도 심각)
   이제 cloud에 ai도 붙어버려서 원시시대로 돌아가는 결정이 될 수도 있습니다.
   (이제 이메일 쓰지말고 우편으로 해라 이런느낌..)
   아래 의견처럼 오픈소스에 더 투자를 해야할텐데 과연 정부가 그런결정이 가능할지..

   옛날에는 윈도우용 프로그램을 많이 사용했지만 요새는 대부분 웹앱으로 처리하는 경우가 많아서 상황이 다르다고 봅니다.

   OS 측면에서는 그렇습니다만 실질적으로 데이터가 로컬 파일로 저장되던 것과 달리 웹 기반 도구는 클라우드에 저장하다보니 다른 벤더에 락인되는 건 아닌가 싶네요. 같은 맥락에서 LibreOffice를 채택했다는 점이 좀 더 핵심적이라 봅니다.

        Hacker News 의견

     * 덴마크 IT 업계에서 많이 지적하는 부분은 Office나 Windows를 대체하는 것 자체가 핵심이 아니라 그 주변의 인프라를 어떻게 처리할지가 더 큰 문제라는 점임
       리눅스 머신들이 Azure Active Directory를 인증할 건지, 아니면 로컬 AD만 사용할 건지, 아니면 IT 부서가 별도의 서비스를 병행 운영할 건지 궁금증이 생김
       Exchange Server에서 완전히 이동하는 건 아닐 것으로 봄, 전체 인력의 절반이 아직 거기에 머물러 있을 것이라 예상
       Intune을 사용했다면 어떤 대체 전략이 있는지 궁금
       많은 직원들이 웹메일이나 원격 데스크탑에서 Windows 프로그램을 사용할 것이라 추측
       인프라에 대한 투자나 난관 해결 노력, 교육에 쓸 시간과 예산이 충분히 확보되지 않은 상황
       결국 실패로 끝날 것이고, 직원들은 생산성 저하와 불편한 작업 환경에 대해 불평할 것이라는 걱정
       이런 일이 덴마크의 여러 학교에서도 동시에 일어나고 있는데, 리눅스와 LibreOffice가 Chromebook을 대체하도록 계획됨
       초기 2년간은 연 225만 유로의 비용이 들어가지만, 그 후에는 400~500만 유로의 절감 기대
       그러나 인증, 이메일, 파일 공유, 프로비저닝에 대한 대책이 없음
       학생들을 Google Workspace와 같은 보호된 환경에서 데이터 마이닝 위험이 더 큰 일반 Google/Gmail 생태계로 내쫓게 됨
       충분한 계획 부재로 모두 안 좋게 끝날 것으로 우려
       나중에는 미국 대통령이 개입해서 진정시키고 2년 뒤엔 모두 잊혀질 스토리 패턴 예상
          + 지금 노르웨이의 대형 공공기관에서 일하고 있음
            팀의 절반은 리눅스를 쓰고 있는데, 유일한 제약은 SSO 위해 Edge를 써야 한다는 점
            (Firefox도 동작, 단지 2008년처럼 로그인을 직접 해야 함)
            그 외에는 리눅스 쪽이 Windows 사용자 동료들보다 훨씬 매끄럽게 돌아간다고 느끼는 상황
          + 모든 직원이 경험을 바탕으로 이런 전환 프로젝트의 성공에 기여했으면 하는 바람
            유럽 각국이 리눅스로 전환하고 Micro$oft에서 벗어나는 게 우선순위가 되었으면 하는 희망
          + 유사한 경험이 있음
            우리 프로젝트도 Office 365에서 Google Workspace로 이전했고, 많은 Windows PC가 Chromebook으로 교체됨
            1년 넘게 지났지만 여전히 많은 사용자가 Excel을 쓰고, 더 많은 앱 가상화가 필요해짐
            가장 큰 장벽은 사용자가 변화를 수용하고 적응하는 부분
            이전 과정에서 사용자가 직접 만든 프로세스 중 몰랐던 부분이 많이 드러나서, 예전처럼 작동하지 않아 전환이 더 어려웠던 경험
            대다수 사용자는 교육 받고 필요 적응을 했고, 잘 해내는 중
            항상 소수는 적응 못 하거나, 안 하려고 하는 경향도 있음
          + Entra(AAD, Azure Active Directory의 예전 이름)는 사실상 아무 OAuth 제공자로 대체 가능
            온프레미스 옵션으로 shibboleth도 존재
            전통적인 Active Directory는 교체가 좀 더 어렵지만, OpenShift의 IdP에는 AD 서버모드가 있어 꽤 많은 활용이 가능
            GPO나 Windows Update 강제 등 몇몇 기능은 리눅스에서는 더 이상 의미 없음
            Exchange Server도 리눅스 진영에서 수많은 MTA 대안(Exim + caldav, ProtonMail, 등)이 존재
            오픈소스 기반에 대기업이 ""확장""을 얹었을지 몰라도, 실제론 마케팅 외에는 크게 놓친 부분이 없음
          + 기업 환경에서 리눅스 도입이 늘 때마다 자주 나오는 질문
            리눅스에서도 Windows의 GPO처럼 많은 기기를 쉽게 관리할 수 있는 툴이 없는지 궁금
            쉽게 설정·운영할 수 있고 항상 스크립트에 의존하지 않아도 되는 도구가 있으면 좋겠다고 생각
            만약 있다면 사람들이 왜 잘 안 쓸까 궁금
            Windows AD GPO로 리눅스 장비를 어느 정도 관리할 수 있는 걸 알고 있지만, 결국 Microsoft 도메인에 의존
            이런 부분에 오픈소스+엔터프라이즈 유급 지원을 결합한 스타트업이 충분히 나올 타이밍이라고 봄
     * LibreOffice는 괜찮지만, MS Office나 Google Workspace처럼 여러 사용자가 한 문서를 동시에 편집할 수 없는 점이 상당한 약점
       Windows→Linux, MS Office→LibreOffice 전환은 표면적인 문제에 불과
       Entra(인증/권한), Intune(엔드포인트 관리), OneDrive(파일공유), Exchange Online(이메일/캘린더) 대체 방안 고민 필요
       러시아, 중국, 인도는 이미 Yandex, Alibaba, Zoho 기반 솔루션 개발에 큰 투자를 해오고 있음
       유럽도 속도를 내야 좋은 대안 탄생
       LibreOffice 실시간 협업 관련 진전이 조금씩 있기에 링크 공유
       Zeta Office
       The Register 기사 (2025년 2월)
          + 기능 부족은 정부가 독점 소프트웨어를 채택해야 할 이유가 될 수 없음
            덴마크 정부 정도면 LibreOffice에서 실시간 협업 지원도 충분히 실현 가능하다고 신뢰
          + 동시 편집 기능이 정말 그렇게까지 중요한지 의문
            특히, 공공부문에서는 나이 많은 직원들이 오히려 구형 오프라인 워드 버전만 써왔던 경험
          + Collabora Office라는 LibreOffice 기반(부분적 독점 코드 포함) 포크에는 다자간 동시편집 기능이 이미 포함
            실시간 협업 원한다면 그쪽이 대안
          + Entra나 Intune, 파일공유, Exchange Online 등을 대체하는 문제
            필요에 맞는 걸 찾았을 때 한 번에 안 바꿔도 됨
            기술 자체 교체 뿐 아니라 관련 로비, 내부 반발, 대규모 교육 등 조직이 마이크로소프트에서 탈피할 때 예상 못 한 다양한 문제가 함께 발생
            국가 단위로 degooglify/demicrosoftify 매뉴얼은 현실적으로 존재하지 않는 것 같다는 의견
     * 오스트리아 연방 법무부는 이미 수년 이상 LibreOffice 사용
       오스트리아 연방계산센터가 업무별 요구에 맞춘 확장 기능 직접 개발
       이런 트렌드가 매우 긍정
       마이크로소프트 경영진이 뮌헨을 다시 방문해서 로비를 하려 드는 시점을 재미있게 기대
          + 마이크로소프트 라이선스 비용만으로도 수천 명 직장의 FOSS 대안을 매우 많이 개발 지원 가능
            오픈소스 진영에서는 오버헤드도 크지 않음
            일부 영역은 여전히 많은 노력이 필요하지만, 대부분의 편의성·버그·자동화 등은 비교적 쉽게 개선 가능
            투자 대비 효율이 나쁘지 않다고 경험
     * 이 기사에서 언급이 안 되었지만, 이번 전환은 ""부"" 자체만 해당이고 인원이 80명 규모임
       실제 영향이 큰 건 Digitaliseringsstyrelsen과 Danmarks Statistik 등의 대규모 산하기관에는 해당되지 않음
       오히려 오르후스, 코펜하겐 등 대도시 자치단체(직원 약 8만 명)도 비슷한 계획을 하고 있는데, 이것이 훨씬 더 큰 변화라고 판단
     * 정부 차원의 이런 오피스 소프트웨어 교체가 지금까지 왜 없었나 궁금
       수많은 라이선스 비용을 감안하면 오픈소스에 그 일부만 투자해도 소프트웨어 품질이 크게 향상될 수 있음
       여러 국가에서 동시 추진하면 전 세계 대기업 종속 없는 메이저 오피스/디자인 툴 탄생
       CAD 소프트웨어도 마찬가지
       최근 오랜만에 freecad 시도했는데 큐브 하나 그리려다 바로 크래시, 중점 제약 없다는 걸 확인해서 당황
          + 원하는 점 중심 제약은 <> 이렇게 생긴 symmetry constraint로 대체
            잘 찾으면 기능이 있음을 조언
          + ""돈만 많이 주면 오픈소스도 금방 좋아질 것""이라는 생각에는 회의적
            오픈소스를 사랑하지만, 큰 폐쇄형 프로젝트와 경쟁하려면 방향성과 목표 명확성이 필요
            위원회식 개발로는 힘든 부분
          + 국가라면 라이선스를 사느니 자체 인프라에 투자하는 게 더 현명
            만약 주요 소프트웨어에 외국기업 종속된다면, 지정학적 이슈나 특허, 기술 규제 등 변수로 소프트웨어가 잠기거나 업데이트를 못 받을 수 있음
            물론 터무니없는 시나리오지만, 각국이 그래도 군사 지휘소를 만드는 것처럼 이런 기본 인프라 자립성도 챙기는 게 맞다고 생각
            그리고 이미 거의 모든 핵심 기능에 오픈소스 대안들이 있으니, 정부에서 예산 투입만 해도 본인들이 직접 개선 가능
            다른 국가들도 따라와 시너지 효과까지 가능
     * 덴마크의 회사와 정부기관은 MS 생태계에 뿌리 깊이 들어가 있음
       수 년 전 기억을 떠올려보면, 라이선스 비용만 해도 엄청났을 것
       2025년인데 왜 더 싸거나 무료 오픈소스 웹 오피스 소프트웨어를 못 쓰냐는 느낌
       개인용 노트북에도 MS Office 안 설치
       문서가 복잡하면 LibreOffice, 간단하면 Google Docs 사용으로 대체
          + OnlyOffice를 꼭 써보라고 추천
            오픈소스에 멀티플랫폼 지원
            대부분의 오피스 파일을 다 잘 읽고, LibreOffice보다 docx 호환성에서 실망한 적이 더 적음
          + 나 역시 업무용 맥북에 MS Office 설치 안 함
            회사측에서 설치 권장만 했고, 실제로 꼭 필요했던 건 난해한 워드 템플릿 한 번 정도
            대부분은 MS 온라인 오피스나 Pages/Numbers로 충분
            불가피하게 Teams 쓸 때도 브라우저 기반 사용
            이상하게 동료들이 오히려 csv 파일을 Excel로 읽다가 로케일(소수점 ,) 문제로 늘 더 헤맴
            엑셀을 피하니 csv 파일 읽는 게 오히려 훨씬 간편
            물론 공동작업이나 특수 워드/엑셀 기능 많이 쓰는 직종이면 어려움이 크겠지만, 내 경험상 문제없이 MS Office 없이도 협업이 가능
          + 어느 시점이 오면 MS는 덴마크 전체에서 역사 속으로 사라질 전환점을 맞이할 것이라는 개인 전망
            이전 관련 의견
            덴마크는 늘 이런 식이라는 의견
            MS와 리눅스, Mac 등 비교에서 특별히 한쪽이 훨씬 낫다고 믿기보다는 OS들은 이미 모두 상품화된 느낌
            다만 MS의 전역 단축키·단축문자 기능은 다른 OS에 비해 재현이 어렵고, 그 자체로 보안상 불리할 수도
            개인적으로는 과거 덴마크 정부의 IT·통신 부서에서 전국 데이터 표준화 프로젝트를 운영했던 경험
            데이터 교환 저장소도 마이크로소프트 본사에서 할당해서 썼지만, 제품 품질이 별로라 MS 임원과의 회의에서 이야기가 꼬임
            직접 메인 생산자들이 만족하지 못했던 상황
            그 후 MS 고위 경영진이 총리와 회동하고 “덴마크가 MS 필요하지만, MS는 덴마크 필요없다” 류의 발언도 들었음
            그래서 MS 의존에서 벗어나는 것이 개인적으론 통쾌함
          + 정부 데이터는 온라인(클라우드 포함)에서 저장·작업해서는 안 된다는 신념
            무조건 오프라인 환경 강조
     * LibreOffice는 정말 별로라는 평
       아무리 Word가 싫어도 진짜 대체품 찾긴 불가능에 가까움
       OnlyOffice가 더 큰 인정을 받아야 할 솔루션
       Word의 사실상 거의 유일한 대체제라고 생각
          + Word를 안 써본 사람 입장에서, Word에서만 할 수 있고 대체 불가능한 기능이 뭔지 궁금
            가벼운 문서는 마크다운류 경량 언어, 무거운 문서는 TeX이나 경량 마크업으로 PDF 등으로 변환해서 사용
            뭘 놓치고 있는지 질문
          + 왜 LibreOffice가 별로인지 실사용상 불편을 느껴본 적이 없음
            워드프로세서를 자주 쓰진 않지만 예전에 잠깐 사용했을 때 문제 경험은 전혀 없음
          + LibreOffice에서 내가 필요한 일은 전부 가능
            대부분의 사람은 어차피 각 앱의 아주 일부분만 사용
          + LibreOffice를 정말 열심히 써보려 했지만 도저히… 어려웠던 경험
            OnlyOffice는 매우 훌륭한 대안이라고 실제로 추천
     * 덴마크 법률팀에 Tritium도 리눅스에서 잘 돌아간다고 알려주면 좋겠음
       정치논리를 떠나 MS가 너무 많은 산업에 강고하게 자리잡았다는 건 놀라움
       Copilot + OpenAI + Azure로 MS의 확장은 더 심해지고 있음
       만약 그 시나리오가 실현된다면 앞으로 몇년간 Microsoft의 영향력은 더 커질 전망
       덴마크가 이런 변화 시작을 시도한다는 것이 긍정적으로 느껴짐
     * 오픈소스 프로젝트에 정부 자금이 더 들어가야 한다고 생각
       사람들이 소프트웨어 개발에 본래 흥미 있는 경우가 많고, 자금만 있으면 훨씬 더 많은 발전 가능
       물론 국가가 너무 주도적으로 오픈소스를 밀면 ""국가 주도 베이퍼웨어""가 나올 리스크도 있음
       동기부여 관점에서 보면 너무 외부 압력식이면 반쪽짜리 결과에 그칠 수도
       그래서, 강제보다는 자금지원의 부드러운 유도책이 더 생산성 높을 것으로 봄
     * 전환 계획 전체가 6개월 이내로 잡혀 있음
       구글 자동번역 기준 “Held og lykke”(행운을 빔)
       이런 신속한 이전 계획들 중에는 사실상 마이크로소프트와 협상용 카드일 때도 많다는 생각
"
"https://news.hada.io/topic?id=21351","머스크-트럼프 갈등, SpaceX 계약 해지 위협으로 번지다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   머스크-트럼프 갈등, SpaceX 계약 해지 위협으로 번지다

     * 트럼프 대통령과 일론 머스크 간의 공개 갈등이 SpaceX의 연방정부 계약 해지 위협까지 번지며 우려를 낳음
     * 트럼프가 머스크의 정부 보조금 및 계약 중단을 언급하자, 머스크는 SpaceX의 Dragon 우주선을 즉시 퇴역시키겠다고 맞대응함
     * 미 정부와 NASA, 국방부 모두 SpaceX에 대한 의존도가 높아, 실제 계약 해지 시 양측 모두 큰 피해가 예상됨
     * 머스크는 이후 Dragon 퇴역 위협을 철회했고, NASA는 중립적 입장을 유지하며 ""대통령의 우주 비전과 협력하겠다""고 발표함
     * 트럼프가 NASA 국장 지명 철회 및 차기 후보 선정을 군 장성에게 맡기겠다고 밝히는 등, 우주 정책에도 불확실성이 커지고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

머스크-트럼프 공개 갈등 및 SpaceX 계약 논란

     * 2025년 6월 5일, 트럼프 대통령과 일론 머스크가 SNS를 통해 공개적으로 서로를 비판하며 갈등이 격화
     * 머스크가 트럼프가 지지한 예산안에 비판적 입장을 밝힌 후, 트럼프는 SpaceX 등 머스크 계열사와의 정부 계약 및 보조금 중단 가능성을 언급
     * 트럼프는 Truth Social에 “예산을 아끼는 가장 쉬운 방법은 일론의 정부 보조금과 계약을 끊는 것”이라고 직접 글을 남김
     * 머스크는 90분 뒤 X(트위터)에서 “대통령의 발언에 따라 SpaceX의 Dragon 우주선 퇴역을 시작한다”고 맞대응했으나, 구체적인 실행 내용은 밝히지 않음

양측 대응 및 업계 우려

     * 양측의 공방은 NASA·국방부 등 미 연방정부의 SpaceX 의존도를 감안할 때 실제 계약 해지 가능성에 대한 우려를 불러옴
          + SpaceX는 NASA의 유인·화물 발사, 미사일 발사, Starlink, 정찰위성 등 다양한 사업을 수행
          + 2025년 SpaceX의 예상 매출은 155억 달러, 이 중 NASA 계약이 11억 달러를 차지
          + 다른 발사체 경쟁사의 지연으로 인해, SpaceX의 대체가 쉽지 않음
          + SpaceX는 ISS 유인 수송, NASA 화물 공급, 미국 우주정거장 퇴역용 Deorbit Vehicle 개발 등 핵심 임무를 담당
     * 한 업계 관계자는 “양측 모두 실제로 극단적 조치를 실행할 가능성은 낮다”며, 서로의 필요성을 잘 알고 있다고 평함
     * 실제로 머스크는 몇 시간 후 “좋은 조언을 받았다”며 Dragon 우주선 퇴역 계획을 철회

NASA 및 정부의 입장

     * NASA는 논란에 직접 개입하지 않고, “대통령의 우주 비전을 실행하기 위해 업계와 계속 협력하겠다”는 공식 입장만 발표
     * 트럼프는 NASA 국장 지명 문제에 대해서도, 5월 말 발표했던 Jared Isaacman 후보 철회를 공식화
          + 머스크가 추천한 인물로 알려졌으나, 트럼프는 “우리는 민주당원을 임명할 필요가 없다”고 언급
          + 후임 선정은 우주 분야 경력이 없는 Dan Caine 합참의장에게 맡기겠다고 밝혀 의문을 자아냄

결론 및 향후 전망

     * 머스크-트럼프 갈등은 미 우주산업과 정부 정책에 불확실성을 증폭시키고 있음
     * SpaceX에 대한 연방정부의 의존도, 민간 우주정책의 정치화 등 업계 전반의 긴장감이 고조

   제발 화해해~~~!

        Hacker News 의견

     * 미국 대통령이 ""이제 Elon이 싫으니 보복 차원에서 정부 계약을 모두 취소하겠다""라고 말할 수 있는 상황, 그리고 미국인 약 40%가 이를 부패로 보지 않는 현실, 정말 당황스러운 현상임
          + 정부 계약은 대통령이 CEO를 얼마나 좋아하나, 혹은 CEO가 대통령을 칭찬하냐에 따라 달라질 수 없는 구조여야 한다는 확신
          + 능력이 아닌 다른 기준으로 계약을 취소하면, 마찬가지로 친분이나 연줄로 계약을 줄 수 있다는 걸 의미함
          + 이런 방식은 소련이 몰락하게 된 경로이기도 함
          + 대통령이 싫어하는 사람은 자금이 끊기고, 아부만 하면 계약을 따내는데, 실제로는 약속도 안 지키고 줄줄이 낭비하는 상황, 민족 전체를 위험에 빠트리는 행보라고 생각함
               o 선거가 정체성(인종, 종교 등) 기반으로 치러질 때, 부패는 오히려 이득으로 여겨지는 현상 직접 목격함
                    # ""우리""가 이기고 ""그들""이 지는 승부로 해석하는 충성스런 지지자들이 있기 때문임
                    # 인도에서 카스트, 언어, 종교 등 특정 집단을 위한 정당이 대놓고 존재하고 있다는 점 지켜봤는데, 이런 태도가 미국에서도 만연해지는 모습 정말 무서운 경험임
               o 부적절 행위 기준이 이익 충돌의 '외형상 가능성'만으로도 문제되던 시절이 있었음
                    # 모든 것에 대해 무감각해진 오늘날, 몇 년 전만 해도 절대 용납 못 했을 일들이 너무 많다는 점 한탄
               o 대통령이 이런 식으로 행동하는 것은 파시스트 독재 정권과 닮아 있음
                    # 강인함을 강조하며, 적은 늘 바뀌고, 본인이 곧 법이 되어 독단적 남용과 부패가 소위 '힘'으로 포장되면, 결국 법치가 사라짐
                    # 미국이 이제 전체주의 독재국이 됐다는 사실, 미국인 자신들만 모르고 있고 전 세계는 다 알고 있음
               o 트럼프가 하버드와의 연방 계약 취소, 학생비자 금지, NSF·NIH·NOAA 부서 해고 등에는 사람들이 별 반응 없더니, SpaceX 계약에 대해서만 유독 민감한 반응 보인다는 현상도 흥미롭게 지켜보고 있음
               o 약 40%는 이런 행동을 '강인함'으로 여기고 있음
                    # 민주주의는 교육받고 이타적인 시민이 있을 때만 제대로 작동하는데, 미국은 점점 더 멀어지고 있다는 우려
     * 적어도 Berlusconi는 핵무기를 쥐진 못했다는 점은 위안임
          + 2005~2010년에 미국 몇 번 방문했는데, 매번 Berlusconi 이야기가 빠지지 않았음
               o ""어떻게 그런 대통령이 가능하지?"", ""누가 그를 찍었나?"", ""bunga bunga 파티"" 등 다양한 의문 봤었음
               o 이제는 미국도 어떻게 저런 인물이 더 큰 권력을 쥘 수 있는지 몸소 체험하게 된 상황임
               o 사람들이 Berlusconi를 이탈리아 대통령으로 착각한 것이 재밌다는 반응
               o 이탈리아가 파시즘, trumpism 같은 트렌드도 원조로 만들었다는 농담도 소환됨
     * 두 사람이 각자 자신의 소셜미디어 플랫폼을 갖고 있다는 사실이 흥미로운 포인트임
          + 언젠가 모두가 자기 전용 소셜미디어를 가지고, 누군가 소식이 궁금하면 각자 소셜미디어에 들어가서 보는 시대가 올 것이라는 상상
               o 예전 블로그, MySpace에서 하던 방식과 비슷한데, 그런 미래가 유쾌하게 느껴짐
          + 지금까지 이 점을 의식적으로 인지하지 못했는데, 정말 재미있는 사실이라는 놀람
          + Trump의 소셜미디어가 뭔지 궁금하다는 반응 (참고: Truth Social이라는 별도 서비스를 운영 중)
     * 정부의 '공정성'을 기대하는 시점은 이미 지나갔다고 봄
          + 이제 ""musk가 민주당을 지지하면 공격해서 박살내겠다""는 수준에 이르렀고, 아무도 놀라지 않음
          + 특히 공화당에서는 이런 행태가 표준이 될 것이라는 걱정, 대통령이 자신의 적으로 판단한 사람들에게 모든 정부 권력을 무기로 쓸 거라는 우려
               o 유럽에서는 미디어와 정치인들이 어떻게든 Trump를 대할 때 말조심하고 친절하게 하면 무역 세금이나 외교적 호의를 받을 수 있다고 대놓고 의견 표출 중임
                    # 프랑스에서도 트럼프에게 호의를 얻으려고 바스티유데이, 노트르담 행사 등에 초청했다는 식으로 얘기됨
                    # 트럼프에게 친절하게 굴면 미국 국민들이 대가를 치르고, 그는 이득을 챙김
                    # 이젠 돈다발만 안 건넬 뿐, 그 직전 상태까지 왔다는 씁쓸함
                    # 이전 대통령들도 인간이니 혜택을 챙길 수는 있었으나, 이 정도로 대놓고 국민 TV와 정치인들이 얘기하는 건 처음임
                         @ 중동 독재자에게 하던 식으로, 미국 대통령에게도 하고 있다는 점이 특이함
               o 현 상황에서도 앉은 대통령이 직접 상대의 정치후원금 능력까지 위협하는 것은 꽤 심각한 일로 봄
     * 사람을 우주에 보내야 하는 대비효 이유에 의문을 품는 입장
          + 유인우주 프로그램을 아예 없애버리면 큰 예산 절감 가능
          + 직접적인 사업 효과 없이 단순히 과학적 명분으로 인류를 보내는 시대는 지났다고 확신
          + 미국 납세자에게 직접 실익이 되는 경우에만 집행해야 하는데, 지금 시대에는 로봇, 자율시스템으로 대체 가능하고, 화성에서도 로버를 원격으로 운영할 수 있는 상황에서 유인은 불필요하다고 생각
          + 유인우주 탐사는 과거의 낡은 유산처럼 느껴지고, 위험·비용·환경 파괴 등 여러 결점만 크다고 평가
          + 이젠 인류가 우주에 살아야 한다고 믿는 시대도 아니고, 실질적으론 비효율·위험만 안고 있으니 현실적으로 받아들이고, 다음 단계로 나아갈 시점이라고 주장
               o 현실적으로 논의할 분위기가 아님을 지적
                    # 현재 이 주제가 다루어지는 진짜 이유는 실용적 접근이 아니라 대통령이 개인 감정으로 사익을 추구해 사적 보복을 행사하는 상황임
                    # Musk에 대한 호불호와 별개로, 정부가 개인 시민의 발언에 불이익을 주는 근본 문제가 핵심
                    # 이런 '파시즘' 상황 이후에 실용적 논의를 해야 한다고 봄
               o 실제로 유인우주 탐사가 주는 대부분의 이점은 허상이라는 시각
                    # NASA는 ISS의 인류 상주 필요성을 과학이라는 말로 포장하지만, 수십조 원 지출의 진짜 이유는 모호
                    # 하지만 유인우주 프로그램이 보여주는 기술력, STEM 분야 영감, 우주로의 인류 진출이라는 순기능은 일부 존재
                    # 나쁜 이유로는 NASA 예산으로 표심을 관리하는 사례도 있음
               o 인간 우주탐사로 파생된 세계적 혁신 기술이 많다는 점을 강조
                    # 우주 프로그램 덕분에 필연적으로 일어난 과학 발전을 무시해선 안 되며, 앞으로도 이런 긍정적 혁신은 계속될 가능성에 주목해야 한다는 시각
                    # 본래 목표와 상관없이 파생되는 혁신의 가치를 간과하면, 엄청난 기회를 잃을 수 있다는 지적
               o ""우주는 이제 새 미지의 세계가 아니다""라는 주장에 대해, 지나치게 패배주의적이고 장기적 진보에 반하는 태도라고 반박
                    # 사소한 어려움 때문에 발전을 멈췄다면, 인류 사회는 아직 동굴에 있었을 것이라고 비유
                    # 인간이 우주에 대해 충분히 안다고 생각하는 것도 인간 지식의 한계를 과대평가한 착각이라는 시각
     * Musk 제국의 가장 큰 위협은 단순히 중국산 전기차 관세를 철폐하는 정책 변화라고 분석
     * Musk가 공화당 지지층에서 매우 인기가 많다는 기사 공유 https://politico.com/news/magazine/…
          + YouGov 설문 조사(6월 5일)에서 공화당 지지자 중 71%는 Trump, 6%는 Musk, 12%는 둘 다 아님, 11%는 모름이라는 결과 공개 YouGov 설문 결과 링크
          + Musk가 공화당 지지층에서 인기가 있는 이유는 Trump가 그를 옹호했기 때문이라는 분석
               o Trump 지지 기반이 워낙 견고해, Musk가 트럼프의 라이벌이 되긴 어렵고, 오히려 Trump의 '유용한 바보'로 활용된 측면이 강함
               o Trump의 Epstein 연루설로 Trump를 무너뜨릴 수 있다고 생각한 Musk가 얼마나 영향력이 미미한지 보여줌
               o Trump 팬들은 그런 의혹엔 전혀 신경쓰지 않는다는 평가
          + Trump의 보복 능력은 전례 없는 수준으로, Elon이 할 수 있는 최대치는 인터뷰에서 욕설하는 정도라는 분석
     * 현실적으로 정부가 할 수 있는 방안에 대한 의견
          + 러시아에 압박을 가할 수 있을지, 또 Boeing이나 Blue Origin이 SpaceX 정도의 네트워크나 효율, 가격 경쟁력을 갖추려면 결국 더 많은 예산이 투입되어야 하는 현실 인식
               o Boeing을 SpaceX 수준까지 끌어올리려면 막대한 자금을 쏟아부어야 하고, Artemis 발사 일정도 못 맞출 것이라는 회의감
          + 사실 SpaceX는 이제 미국의 핵심 인프라이자 국가안보에 직접 관련된 기업임
               o 이 때문에 오히려 Elon에게 힘이 실리는 걸로 보일 수 있으나, 실제로는 미국 정부가 국가 안보 위협을 가볍게 넘기지 않을 것임
               o 최악의 경우 SpaceX를 국유화하는 방안까지 고려 가능
               o 현실적으로는 FAA, NOAA에서 발사 승인을 거부함으로써 쉽게 SpaceX를 묶을 수 있음
               o 유사 사례로 네덜란드 ASML이 중국에 EUV 장비를 못 팔게 한 점 제시
               o SpaceX는 미국 정부 계약과 자금에 절대적으로 의존하고, 협박만으로도 정부가 회사에 큰 영향력을 행사할 수 있음
               o 이번 사태에서 놀라운 점은 오히려 Trump가 평소와 달리 매우 참을성 있게 대응하고 있다는 점, 하지만 언제든 돌변할 수 있음
               o Elon이 트럼프를 소아성애자로 암시하는 극단적 발언을 한 건 상식 밖임
          + 러시아와 실제로 '대리전' 상황이냐는 질문에, Trump는 Putin 편에 서있다는 주장도 나옴
     * Trump가 Isaacman이 민주당이라고 말했지만, 실제로 그는 양쪽 모두에 기부한 전력이 있다는 점에 주목
          + NASA 수장으로 거론되는 인물이 양쪽 정당에 정치자금을 댄 사실은 신뢰나 명예가 결여된 사례로 간주
          + 이런 사람은 반드시 배신할 거라는 극단적 불신, NASA를 이끌 자격이 없다는 극단적 주장
               o 상대방은 정치 후원의 동기를 단정할 수 없으니, 오히려 각 후보의 NASA 및 리더십에 관한 비전을 분석한 결과일 수도 있다고 반박
                    # 단순히 기부 이력 때문에 자격 박탈은 과하다는 의견
                    # 투표 기록까지 조사해 당파로 줄 서야 하나라는 의문 제기
                    # 전문성과 역량에 따라 기관장을 선출하는 사회가 더 바람직함을 강조
     * 정책 논쟁이 인신공격과 예산 삭감 논란으로 번지는 순간, 대통령이 더 이상 제도적 역할이 아니라 '개인 왕국'이 되어버린 현실임을 지적
"
"https://news.hada.io/topic?id=21314","뉴욕타임즈의 데이터 요구에 대한 OpenAI의 대응 및 사용자 프라이버시 보호","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              뉴욕타임즈의 데이터 요구에 대한 OpenAI의 대응 및 사용자 프라이버시 보호

     * 뉴욕타임스 등 원고 측이 오픈AI에 대해 이용자 ChatGPT 및 API 데이터 무기한 보존을 요구한 소송 상황임
     * 오픈AI는 이러한 요구가 이용자 프라이버시 약속과 상충한다며 법원 명령에 적극적으로 이의 제기 및 항소 중임
     * 이번 보존 명령은 ChatGPT Free, Plus, Pro, Team, 일반 API 이용자에게만 적용되며, 엔터프라이즈/에듀 및 ZDR API 이용자는 해당되지 않음
     * 삭제된 데이터까지도 별도 시스템에 법적 보존해야 하며, 접근 권한은 엄격히 제한된 오픈AI 법무·보안팀에 한정됨
     * 오픈AI는 프라이버시 보호를 최우선 가치로 두고 모든 법적 절차에서 이용자 보호를 위해 계속 대응할 방침임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

How we’re responding to The New York Times’ data demands in order to protect user privacy

     * 뉴욕타임즈를 포함한 원고들은 OpenAI를 상대로 한 소송에서 소비자 ChatGPT 및 API 고객 데이터를 무기한 보관하라는 요구를 함
     * 이 요구는 OpenAI가 사용자에게 약속한 프라이버시 원칙과 본질적으로 충돌하며, 업계 표준 및 프라이버시 보호 수준을 약화함
     * OpenAI는 이러한 요구를 과도하다고 판단하며, 사용자 프라이버시를 최우선으로 항소 절차를 진행 중임

주요 질문과 답변

  1. 뉴욕타임즈 등 원고의 요구 이유

     * 뉴욕타임즈가 OpenAI를 상대로 소송을 제기하면서, 소송에 유리한 증거를 찾을 수 있다는 추측에 기반하여 모든 사용자 콘텐츠의 무기한 보관을 법원에 요구함
     * OpenAI는 이러한 요구가 이용자 프라이버시를 위협할 뿐 아니라 소송 해결에도 실질적인 도움이 되지 않는다고 판단함
     * ChatGPT Free, Plus, Pro, Team, 일반 API 사용자는 영향이 있으나, ChatGPT Enterprise, ChatGPT Edu, Zero Data Retention API 고객은 해당 사항 없음

  2. OpenAI의 법적 대응

     * OpenAI는 초기에 모든 출력 데이터 보관 요구가 과도하며 프라이버시 정책과 상충함을 주장하며 반대 입장 제출
     * Magistrate Judge 앞에서 ChatGPT Enterprise는 예외임을 확인받음
     * District Court Judge에 추가 항소 진행 중임

  3. 비즈니스 고객의 Zero Data Retention 계약자

     * Zero Data Retention API를 이용 중인 비즈니스 고객은 입력·출력 데이터가 저장되지 않아 영향 없음

  4. ChatGPT 데이터 삭제 시

     * 일반 소비자 계정은 소송 영향이 있을 수 있으나, Enterprise·Edu 고객 및 Zero Data Retention API 이용자는 영향 없음

  5. 데이터 저장 방식 및 접근 권한

     * 법원 명령에 해당하는 데이터는 별도의 보안 시스템에 분리 저장
     * 해당 데이터는 법적 의무 이행 목적 외 사용 불가하며, 접근 권한은 엄격하게 제한된 OpenAI의 법무 및 보안팀 소수 인원에 한정됨

  6. 데이터 외부 공유 가능성

     * 저장된 데이터는 뉴욕타임즈 등 외부에 자동으로 전달되지 않음
     * 계속적인 정보 공개 요구가 있을 시 OpenAI는 프라이버시 수호를 위해 적극 대응 예정

  7. 데이터 보관 기간 및 종료 시점

     * 현재 법원 명령에 따라 사용자 데이터 무기한 보관이 강제되어 있으나, 이에 대해 적극적으로 법적 대응 중
     * 성공적으로 법적 대응 시 기존의 데이터 보관 정책으로 복귀 가능

  8. GDPR 등 프라이버시 법 위반 여부

     * 법원 명령에 따라 법적 의무는 지키고 있으나, 뉴욕타임즈의 요구는 OpenAI의 프라이버시 기준과 상충
     * 이에 대한 항소 및 정책 대응을 이어가는 중임

  9. 모델 학습 정책 변화 여부

     * 비즈니스 고객 데이터는 기본적으로 모델 학습에 활용되지 않으며, 이번 명령으로 정책 변화 없음
     * 소비자 고객은 개별 설정 내역에 따라 학습 데이터 활용 여부를 직접 제어 가능, 명령으로 영향 없음

  10. 사용자 정보 제공 및 투명성

     * OpenAI는 지속적인 정보 제공 및 투명성 유지를 약속함
     * 법원 명령의 변화나 사용자 데이터 영향 사항 발생 시 신속히 안내 예정

  11. 데이터 보관 정책 요약

     * ChatGPT(Free/Plus/Pro): 대화 또는 계정 삭제 시, 데이터는 즉시 계정에서 삭제되고 30일 이내 영구 삭제 예정
     * ChatGPT Team: 각 사용자가 대화 보관 여부 제어 가능, 삭제/저장되지 않은 데이터는 30일 이내 삭제(법적 의무 제외)
     * ChatGPT Enterprise/Edu: 워크스페이스 관리자가 데이터 보관 기간 관리, 삭제된 대화는 30일 내 삭제(법적 의무 제외)
     * API: 비즈니스 사용자는 애플리케이션 상태 관리를 위해 보관 기간 및 방법을 직접 선택 가능, API 입력 및 출력 데이터는 30일 후 로그에서 삭제(법적 의무 제외)
     * Zero Data Retention API: 경우 입력/출력 데이터가 애초에 저장되지 않음

결론

     * OpenAI는 사용자 신뢰와 프라이버시 보호를 정책 최우선으로 삼고 있으며, 법적 도전에 맞서 지속적으로 대응
     * 비즈니스 및 교육용, ZDR API 등 특정 고객군에는 영향이 없으며, 일반 소비자 데이터는 별도로 보호 조치 중
     * 법적 상황 변화 및 사용자 데이터 보호 방침에 대해 투명하게 안내할 방침

        Hacker News 의견

     * OpenAI에서 Zero Data Retention(ZDR) 옵션을 공식적으로 신청할 수 있도록 해주면 정말 큰 도움이 될 거라 생각함. 많은 기업 상황에서는 요청 로그 자체를 저장할 이유가 전혀 없음. 문서상으로는 신청이 가능하다고 여러 차례 나오는데, 실제로는 그냥 무시당함. 승인을 받아야 하고 진입 장벽이 있다는 건 이해하지만, 실제로는 마케팅 용도로만 ZDR을 언급하는 것 같음. 여러 번 신청했지만 아무런 답변도 받지 못함. 포럼 글들을 보면 이게 매우 흔한 일처럼 보임
          + 승인 과정이 필요한 건 이해하지만, 왜 기본값이 개인정보 보호나 기록 미저장이 아닌지 궁금함. OpenAI의 개인정보 보호 약속에 의심을 갖는 이용자가 많음. 입력값은 저장되고 분석되어 공유되는 게 아닐까 생각함. 진짜 개인정보 보호가 필요하다면, 로컬에서 돌아가는 LLM만이 진짜 대안임
          + 내 이해로는 버그 처리를 위해 기본적으로 30일 동안 로그를 보관한다고 알고 있음. 0일 저장도 요청할 수 있음. 이 내용은 공식 문서에 기재되어 있음
          + 본질적으로 빠진 요소는 돈임
          + ""특정 사용처라면 zero data retention(ZDR)도 요청할 수 있음. 데이터 처리 관련 자세한 내용은 Platform Docs 페이지 참고""라는 정책OpenAI Privacy Policy가 있음. 1) 요청은 가능해도 승인을 보장하지 않음. 2) 기본값이 중요함. 실리콘밸리 기본값은 개인정보 보호가 아닌 수익 극대화에 맞춰져 있음. OpenAI 역시 기본이 데이터 저장, 출력값까지 저장함. 데이터 보존 명령에 반대하는 OpenAI의 메모 내용을 진지하게 받아들이기 어렵게 만듦
          + 공식적으로는 신청할 수 있다고 반복적으로 써놓았지만, 실제론 전혀 작동하지 않는 마케팅 문구일 뿐일 수도 있다고 의심됨
     * 법원 명령으로 보호되는 데이터는 격리된 시스템에 보관되고 법적 의무 수행 외에는 접근할 수 없음. 소수의 감사를 거친 OpenAI 법무 및 보안팀만 법적 의무에 따라 접근 가능함. 만약 데이터가 유출되면 OpenAI에게 책임이 있음. 하지만 이 글 전반의 언어, 특히 반복적으로 소송이 ‘근거 없다’고 하는 건 신뢰도를 떨어뜨리고 있어 신뢰감이 안 드는 판촉용 글 같음
          + 이번 사건은 뉴스 사이클로 번졌는데, 삭제한 채팅이 소송 때문에 실제로 삭제되지 않는다는 소식이 이슈가 되어 OpenAI 측에서는 고객 안심을 위해 대응 필요가 있었음
          + 소송 관련 데이터가 검색 과정에서 해당 사안과 연관된다고 판명되면, 해당 데이터는 최소한 양 당사자 그리고 법원이 접근할 수 있음
          + OpenAI 입장에서는 당연히 자신들 입장을 내세울 수밖에 없음. ‘근거 없는 소송’이라고 주장하는 건 당연함
          + 나는 OpenAI 사용자임. 유용해서 비용도 지불하고 사용 중임. 이용약관과 개인정보 처리방침에 명시된 범위 이상으로 데이터가 저장되길 원하지 않음. 재판부가 OpenAI의 보관 의무가 수천만 사용자 프라이버시를 위태롭게 한다는 점을 이해하지 못한다면 적합하지 않다고 생각함
          + 데이터 보안에 대한 첫 번째 원칙은 시스템이 불완전하므로 유일한 보호는 아예 데이터를 저장하지 않는 것임. 데이터 유출이 발생하면 OpenAI에 책임이 있음. 데이터 보안 약속을 하는 회사는 능력이 없거나 불성실함
     * OpenAI 법무팀이 실제 채팅 내역 대신 ssdeep 해시나 콘텐츠 청크와 같이 흐릿한 정보만 저장하는 방식을 적용할 수 있을지 궁금함. NYT가 요구하는 데이터 범위가 제한적이고 API를 통해 문제 되는 콘텐츠가 생성된다면, 해시 값으로 비교가 가능함. 당연히 아무것도 저장하지 않는 게 이상적이지만, 지나치게 광범위한 법원 명령을 고려할 때 현실적인 절충 가능성이 있음. 추가로, ssdeep, 콘텐츠 청크 관련 자료도 참고할 수 있음
          + 이런 기술적 용어를 법정에서 변호사나 판사에게 설명하는 건 매우 어렵다는 점 강조
          + 판결 취지를 적극적으로 회피하려는 시도 자체가 아주 안 좋은 선택임
          + 법원 명령 관련 문서를 찾지 못했지만, 판사가 OpenAI에 데이터 구분 가능 여부를 물었지만 OpenAI가 아예 아무 답을 하지 않았고, 단순히 거부가 아니라 무시한 상황으로 보임. OpenAI가 적극적으로 해결책을 찾을 의지가 없고 홍보(PR) 전략만 활용하는 듯함
          + 이런 기술적 제안이 아무리 멋지게 백서에 들어가도 실제로는 모든 ChatGPT 대화가 S3에 저장되고 있고, 각종 기관에서 정기적으로 백업하고 있음. 이메일처럼 내부에 민감한 내용이 가득한 텍스트 데이터베이스임. 경영진의 ""약속""은 전혀 신뢰하지 않음
     * 예전에는 내가 브라우저 히스토리 유출을 매우 부끄러운 일로 여겼다면, 이제는 LLM 대화 기록이 유출되는 것이 그보다 훨씬 심각하다고 생각함. 타인과의 프라이빗 대화보다도, 혼자 있을 때 감추지 않은 내 모습이 그대로 기록된 대화임
          + 대체 뭘 묻길래 LLM에서 비밀 보장을 기대하냐는 반응이 있음
     * 관련 토론: OpenAI slams court order to save all ChatGPT logs, including deleted chats (2025년 6월, 878개 댓글)
     * NYT를 향한 비난이 이상하다고 생각함. NYT가 소송 사유가 있다면 법원이 승인할 것이고, 사유가 없다면 OpenAI가 법정에서 이길 것임. 법원 명령을 NYT를 향한 비난 도구로 삼는 것이 이상함
          + NYT는 미국 법 제도의 취약점, 즉 개인 정보에 거의 신경을 쓰지 않는 광범위한 증거 개시(discovery) 절차를 이용하는 것임. 자기 이익 때문이겠지만 이번에는 OpenAI 편을 지지하지 않을 수 없음
          + NYT는 상황에 따라 입장을 바꾸는 것 같음. 과거엔 프리랜서 기사 DB화해서 판 적 있고, 저작권 약화 주장했음. 지금은 저작권을 가장 중시함. 참고로 NYT의 정책 변화 관련 글은 흥미로움
          + NYT도 사건 당사자임. 소송을 ‘근거 없다’고 하는 건 정당함
          + 만약 NYT가 실제로 사유가 없지만 법원이라도 승인을 한다면, 그때도 이상한 일임
          + 합법적이라고 해서 법 제도를 남용하는 사람들이 면죄부를 받진 않음
     * OpenAI의 “왜 이런 일이 벌어지나요”에서 설명 빠진 부분이 있음. 마치 사람들이 이유 없이 화내는 것처럼 묘사하지만, 정작 고객 관점에서 보면 어이없음
     * ""설정""에서 사용자 데이터가 모델 훈련에 사용되는지 제어할 수 있다고 안내하지만, 실제로는 “모두를 위한 모델 개선” 토글이 아무런 영향도 없는 다크 패턴이 있고, 비노출 포털에 직접 신청해야 하므로 쉽게 발견할 수 없음. 많은 사용자가 실제 동작을 오해하게 만들었음
          + 자세한 설명 요청됨
          + ""모두를 위한 모델 개선"" 토글이 실제로 아무 효과가 없다는 주장에 대해 구체적인 설명과 해당 포털 링크 요청됨
     * 나는 외부 업체 API에 보낸 모든 것이 영구 저장된다고 항상 가정해왔음. 그 반대라고 생각하는 게 더 순진함. 앱이 웹 트래킹을 안 한다고 믿는 것만큼이나 순진한 태도임
          + 최악을 가정하는 건 현명하지만, 아무런 저항도 없이 최악에 순응만 하는 건 어리석음
          + 개인정보 포기주의(privacy nihilism)도 결국 스스로 내리는 선택임
     * ""신뢰와 개인정보 보호가 핵심 가치이며, 데이터 관리 도구와 삭제 옵션을 제공한다""는 OpenAI 공식 입장에 동의하지 않음. 추가 비용을 내면 프라이버시 제공한다고 홍보하며, Pro 유저도 ""프라이버시""를 누릴 수 없음. 수 차례 정보 삭제 요청에도 모델 및 훈련 데이터 내 개인정보 삭제는 거부함
          + 모든 사용자가 옵트아웃할 수 있음. ChatGPT Plus, Pro, Free 모두 기본적으로 데이터 공유가 활성화되지만, 누구나 훈련용 데이터 사용을 비활성화할 수 있음. Enterprise만 기본 비활성화일 뿐임. 참고자료: What if I want to keep my history on but disable model training?
          + 기업식 ""신뢰 세탁(trustwashing)""에 불과한 공식 문구임. 애매하고 모호한 용어, 기분좋은 수사, 공허한 가치만 가득함
"
"https://news.hada.io/topic?id=21330","FreeBSD 개발에 대한 1년 간의 후원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        FreeBSD 개발에 대한 1년 간의 후원

     * Amazon의 후원을 받아 1년 동안 FreeBSD 릴리스 엔지니어링과 FreeBSD/EC2 개발을 진행함
     * 릴리스 관리와 EC2 관련 개선을 병행하며 월 평균 50시간의 작업 시간을 투입함
     * Graviton 인스턴스 전원 관리, 핫플러그 지원, 부팅 성능 개선 등 주요 기능 문제와 품질 향상을 달성함
     * AMI 종류 확장 및 빌드 자동화로 FreeBSD AMI 배포의 다양성과 효율성을 높임
     * 후원 종료 후에는 개발 속도 둔화와 일부 기능 개발 정체 현상이 예상됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

FreeBSD 개발 후원 1년 회고

  # 시작 배경 및 후원 과정

     * FreeBSD/EC2 플랫폼을 2010년부터 관리해왔으며, 2023년 11월부터 FreeBSD 릴리스 엔지니어링 리드 역할도 수행함
     * Antithesis, Patreon 등에서 소액 후원 중이었으나, 릴리스 엔지니어링 업무가 FreeBSD/EC2 개발 시간을 크게 잠식하는 상황에 직면함
     * Amazon 측과 수년 간 EC2 작업에 대한 스폰서 논의를 이어왔으며, 2024년 4월에 예산 확보 담당자와 연결되어 1년간 후원을 받게 됨
     * 후원은 GitHub Sponsors 경로로 집행됐으며, Amazon 의도한 기간과 실제 입금 시점은 다를 수 있음

  # 후원과 작업 시간 분배

     * Amazon의 요청으로 매월 40시간의 FreeBSD 릴리스 엔지니어링 및 EC2 개발 시간을 제공하기로 약속함
     * 실제로는 월별로 50시간 정도를 투입했으며, EC2 이슈에 20시간, 릴리스 작업에 20시간, 기타 엔지니어링에 10시간을 분배함
     * 월별로 작업 시간이 크게 변동함

  # FreeBSD 릴리스 관리

     * FreeBSD 분기 릴리스 일정을 도입·관리하면서 1년간 4차례 릴리스를 수행함: FreeBSD 13.4(2024.9), 14.2(2024.12), 13.5(2025.3), 14.3(2025.6 예상)
     * 각 릴리스에는 개발자 코드 마감 독려, 머지 요청 승인 및 조율, 이미지 빌드·테스트, 안내문 작성, 각종 릴리스 빌드 오류 수정이 포함됨
     * 릴리스 엔지니어링 소요 시간은 분기마다 33.5~79시간 수준이며, 후반부로 갈수록 안정화로 작업량이 감소하는 패턴임

  # 주요 EC2 기능 개선 및 품질 향상

    Graviton 인스턴스 전원 드라이버, 핫플러그 지원

     * Graviton 인스턴스에서 EC2 API의 정상 종료 신호를 FreeBSD가 인지하지 못하던 문제를 해결
          + ACPI _AEI 오브젝트를 활용, GPIO 기반 ""power button"" 신호와 드라이버 로직을 연결
          + EC2 제공 ACPI 테이블의 Pull Up 플래그 설정 불일치로 인한 장치 비활성화 문제는 FreeBSD/EC2 AMI에 ACPI_Q_AEI_NOPULL 설정 추가로 대응
     * EC2 Graviton 및 x86 인스턴스의 장치 핫플러그(특히 핫 언플러그) 문제들을 복합적으로 진단 및 수정
          + IRQ 누수, PCI 전원 상태와 OS 신호 불일치, ""유령"" PCI 장치 등 다양한 유형의 버그에 대응
          + 임시 방편으로 ACPI 퀴르크(예: ACPI_Q_CLEAR_PME_ON_DETACH, ACPI_Q_DELAY_BEFORE_EJECT_RESCAN) 적용, EC2 쪽 버그는 수정 예정

    핫플러그 테스트 자동화 및 품질 개선

     * EC2 환경에서 반복적으로 EBS 볼륨을 연결·해제하는 스크립트를 개발, 300회 연속 테스트를 통한 안정성 검증
     * PCIe 핫플러그의 불필요한 5초 지연(물리 시스템에서만 의미 있음)을 EC2에서는 0초로 설정하여 품질 향상

    부팅 성능 개선

     * FreeBSD/EC2 부팅 속도 이슈를 데이터 수집 및 분석으로 체계적으로 개선
     * 2024년 초 루트 디스크 용량 증설로 부팅 3배 지연, Graviton2 인스턴스의 커널 엔트로피 시딩 지연, ZFS 부팅 시간 증가, IMDSv2 관련 IPv6 지원 문제 등을 순차적으로 해결
     * 파일시스템별 부팅 성능 격차, 엔트로피 수급 비효율, 네트워크 초기화 지연 등 다방면에서 최적화 이루어짐

  # FreeBSD AMI 다양성 확대 및 빌드/배포 자동화

     * 기존 base, cloud-init AMI 외에 small AMI(불필요한 디버깅·테스트 코드/툴 제거, 1GB 크기) , builder AMI(사용자 커스텀용 빌더) 를 추가
     * 4종류 AMI * 2파일시스템(UFS/ZFS) * 2아키텍처(amd64/arm64) * 3버전(13, 14, 15)으로 이미지 조합이 확대되면서 오래된 이미지 자동 삭제 및 스크립트화 진행, 336TB EBS 스냅샷 정리

  # 엔지니어링 일반 개선

     * FreeBSD AMI/릴리스 빌드의 병렬화로 전체 빌드 시간을 약 22시간→13시간으로 단축, 더 많은 AMI 종류 추가에 여유 확보
     * EC2 인스턴스 기반 자동화 테스트 및 diffoscope 비교로 빌드 재현성(리프로듀서블 빌드) 문제 진단 및 해결 진행
     * ENA 드라이버 패치 리뷰, OCI 컨테이너 빌드 및 레지스트리 업로드, AWS 관련 툴 개선, 보안 이슈 리포트 등 다양한 소규모 업무 병행

  # 앞으로의 전망 및 한계

     * FreeBSD 릴리스 엔지니어링 및 EC2 플랫폼 유지 역할은 유지하나, 이전보다 투입 가능한 시간이 줄어들 전망
     * FreeBSD 15.0(2024년 12월), 14.4/15.1/14.5/15.2(2026년) 릴리스는 예정대로 진행, 단 기능 추가/버그 수정 속도는 저하될 것으로 보임
     * 자동 파일시스템 확장, 다중 NIC 및 핫플러그 자동화, 미리 패치된 AMI 배포, EC2 사용자 웹툴, FreeBSD/Firecracker 지원 등 미완 과제는 장기적으로 정체 예상

  # 맺음말

     * Amazon의 위 후원은 오픈소스 개발자에겐 극히 드문 기회이며 그 동안의 성과에 자부심과 감사를 느낌

        Hacker News 의견

     * 오늘 ziglang.org 다운로드 페이지에 FreeBSD가 추가된 소식 공유, 이제 FreeBSD 사용자는 CI에서 자동으로 빌드된 마스터 브랜치 빌드를 쉽게 받을 수 있음
       FreeBSD가 이제 공식적으로 크로스 컴파일 타겟으로 완전히 지원됨, zig cc -o hello hello.c -target riscv64-freebsd처럼 리눅스와 비슷하게 FreeBSD를 타겟하여 컴파일 가능
       C/C++ 의존성이 있다면 zig 빌드 시스템으로 쉽게 가져오고 빌드 가능, 덕분에 꽤 복잡한 프로젝트도 손쉽게 FreeBSD 크로스 컴파일 가능
       이로 인해 더 많은 프로젝트가 FreeBSD 지원 및 테스팅을 CI에 추가하기를 바라는 마음
          + Zig의 크로스 컴파일 기능이 정말 멋지다는 이야기, 그리고 FreeBSD가 지원 타겟에 추가된 점이 반가움
     * 읽으면서 재밌는 부분이 많았음
       2024년 첫 주부터 FreeBSD 부팅 프로세스가 갑자기 3배 느려졌다는 사례, 커밋을 계속 추적한 끝에 원인이 5GB에서 6GB로 루트 디스크 크기가 늘어난 거였음
       아마존 친구에게 문의해보니 답변이 무슨 마법이라도 된 듯 “정확히는 알지 못하지만, 그냥 모르는 게 나을듯” 식이었음
       중요하게도 루트 디스크 크기를 8GB로 늘리자 성능이 예전 수준으로 복구됨
          + 이런 얘기를 들으니 이제 정말 무슨 이유인지 알고 싶어지는 마음
          + 이런 문제를 찾기 위해 커밋 바이섹팅하는 데 실제로 시간이 얼마나 들었을지 궁금함
            매번 이미지를 만들어 VM을 재부팅했는지 궁금한 상상
          + S3의 오리지널 오브젝트 크기 제한이 5GB였다는 본인 2006년 블로그 글 언급
            https://aws.amazon.com/blogs/aws/amazon_s3/
            이것이 FreeBSD 성능이 느려진 현상과 직접 관련이 있는지는 모름
     * 노트북 지원 관련으로도 많은 일이 진행 중임
       BSD 재단에서 $750,000를 투자해서 S0ix Sleep State 구현 등 다양한 기능에 집중 중이라는 정보를 읽음
       관련 프로젝트는 https://github.com/FreeBSDFoundation/proj-laptop 에서 확인 가능
          + 정말 많은 작업이 동시에 이루어지는 중이지만, 본인은 자신이 직접 하고 있는 부분만 써서 공유한 것임
     * 아마존이 더 많이 지원하고 기여하길 바랬지만 현실은 FreeBSD의 최소 지원에 그치는 모습
       아마존은 FreeBSD 스폰서 명단에도 없음, 구글은 작년에 고작 $9K만 후원했고, 애플과 메타/페이스북도 없음
       반대로 마이크로소프트는 명단에 올라 있는 부분은 칭찬
       이 대기업들이 FreeBSD와 OpenBSD 덕분에 이득을 많이 보면서 매년 자동적으로 기부하지 않는 게 의외
       스폰서 정보는 https://freebsdfoundation.org/our-donors/donors/?donationYear=2024 에서 확인 가능
          + 아마존이 FreeBSD를 더 많이 지원했으면 좋겠다는 마음은 동의
            하지만 FreeBSD Foundation에 기부자 명단에 없다고 해서 지원이 없는 건 아님
            본인이 받은 개발비도 재단을 통하지 않았고, 실제로 재단이 지원하는 개발은 전체 기업 지원의 10% 정도에 불과
            재단이 지원하는 개발은 FreeBSD 자체를 위한 일에 집중할 수 있어서 중요하지만, 전체로 보면 소수임
          + 이 댓글 내용만으로 전체 상황을 다 볼 수 없다는 지적
            연도별로 재단에 기부된 스냅샷만을 보여줄 뿐이고, 기여한 개발 자체는 각 릴리즈의 릴리즈 노트에 요약돼 있음
            https://www.freebsd.org/releases/
          + 마이크로소프트가 왜 FreeBSD를 지원하는지 궁금증
            Hyper-V 확장도 리눅스보다 완전하지 않고, .NET 공식 포트도 없으며, 마이크로소프트가 FreeBSD 기반 서비스를 운영하는 것 같지도 않음
          + 아마존이 FAANG 중 FOSS에 가장 적게 기여하는 기업이라는 의견
     * cperciva에게 많은 존경을 표함
       Tarsnap과 FreeBSD를 동시에 어떻게 관리하는지 궁금함
          + 어느 시점부터 돈이 시간이 되어준다는 것에 대한 경험 공유
            간단한 수리는 직접 하거나 전문가를 부르거나 선택할 수 있음
            이 FreeBSD 작업에 들인 시간 중 일부만이 Tarsnap에서 가져온 시간이었고, 생각보다 많지 않음
     * 예전에 FreeBSD를 워크스테이션으로 사용해본 경험이 있고, 인상적이었음
       집 게이트웨이/방화벽/DNS/DHCP 서버로 FreeBSD를 쓰고 싶었지만 10GbE NIC 드라이버가 지원되지 않아 결국 Nix를 선택
       FreeBSD가 여전히 잘 유지되고 있다는 것이 보기 좋음
     * FreeBSD/EC2 상위 사용자들이 누구인지 궁금함
          + 본인도 잘 모름
            실제로 자신에게 컨택하는 사용자는 전체 FreeBSD/EC2 유저 중 0.1%도 안 되는 듯
            누가 FreeBSD를 EC2에서 쓰는지 정말 알고 싶음
          + 넷플릭스가 FreeBSD를 엣지 박스에만 사용하는 건지 궁금함
     * FreeBSD가 유닉스 계열에서 어떤 틈새를 메우고 있는지 궁금함
       왜 OpenBSD나 NetBSD보다 복잡한 FreeBSD를 사용하는지, ZFS나 Nvidia, ELF가 필요하면 그냥 Linux가 낫지 않은지 질문
       GNU 문제는 알고 있으나 Musl Void같은 대안도 있는데, FreeBSD만의 뚜렷한 “정체성”이 궁금하다는 genuine curiosity
          + 금융권에서 FreeBSD를 EC2와 자체 데이터센터 금속 서버 모두에서 사용한 경험
            zfs와 jails를 많이 활용
            모든 서비스를 각 jail에서 독립적으로 돌려 매우 비용 효율적
            클라우드로 일부 이전하여 하이브리드로 Linux(k8s)+FreeBSD를 운용했을 때는 비용이 급증
            데이터센터 직접 관리는 디스크 교체나 화재 대응 등 번거로운 점 있지만, AWS는 멀티리전 등 다양한 기능을 제공함(비용 부담 있음)
            zfs는 한 번 프로덕션 DB 테이블이 실수로 삭제됐을 때 스냅샷 덕분에 즉시 롤백하여 큰 도움이 되었음, 백업용으로도 zfs 활용
            프로덕션에서 dtrace로 트러블슈팅도 한 경험
            서버에 FreeBSD만 운용할 때는 OS 군단이 하나라 관리가 쉽고, 리눅스 도입 시에는 각 팀이 제각각 배포판을 써서 혼란이 있었음
            FreeBSD를 커널+OS가 통합된 구조로써 좋아하는 마음
          + 본인 입장에서, FreeBSD는 OpenBSD와 NetBSD의 장점을 적절히 혼합한 느낌
            과거 FreeBSD는 Intel CPU 최적화와 탄탄한 보안을 자랑했고, 특히 ZFS 지원이 결정적인 차별점
            nvidia 드라이버도 최근에야 네이티브 FreeBSD 지원이 생겼음
            결국 FreeBSD는 다른 BSD의 장점과 하드웨어 안정성을 잘 결합하고 있음
          + FreeBSD는 OpenBSD나 NetBSD보다 훨씬 더 큰 유저 베이스를 가진다는 점
            소프트웨어 카탈로그 자체가 더 방대해서 데스크탑 일상 사용도 충분히 가능
            왜 리눅스를 안 쓰냐면, 리눅스는 기업의 이익에 너무 얽매여 있다는 점
          + FreeBSD가 ZFS 지원에서 리눅스보다 한수 위라는 의견
            라이선스 이슈 덕분에 FreeBSD가 더 나은 환경 제공
          + FreeBSD는 OpenBSD보다 네트워킹 처리량 측면에서 더 뛰어남
            일반적으로 BSD들은 변화 속도가 적어서 통합 플랫폼으로 쓰기에 좋음
     * 이 글을 보면 FreeBSD 개발 환경이 썩 좋게 그려지지 않는다는 의견
       복잡성이 큰 OS임을 감안하면 최소한 누군가는 풀타임으로 릴리즈 매니저를 맡아야 할 텐데, 1년간 파트타임이 전부인 현실이 아쉽다는 생각
       그래도 리눅스만이 유일한 대안이 아니란 점에서 FreeBSD의 존재는 중요함
"
"https://news.hada.io/topic?id=21380","애플 WWDC 2025 키노트 주요 내용 정리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       애플 WWDC 2025 키노트 주요 내용 정리

     * Apple Intelligence와 온디바이스 생성형 모델, 개인정보 보호에 기반한 새로운 인공지능 경험 및 API 공개
     * Liquid Glass로 전체 소프트웨어 디자인 리뉴얼: 통일된 디자인 언어, 모든 플랫폼(모바일·데스크톱·공간컴퓨터)에서 일관성 강화
     * iOS 26·macOS Tahoe·iPadOS 26·watchOS 26·visionOS 26 등 버전명 통일 및 각 OS별 핵심 업데이트 발표
     * 실시간 번역, 이미지 생성, 시각 지능, 새로운 창 관리, 그룹 메시지 투표, 게임 허브 등 사용자 및 개발자 기능 대폭 강화
     * 개발자 베타 즉시 배포, 공식 출시는 올가을, 새로운 디자인 및 인텔리전스 API 활용법 제공

Apple Intelligence와 온디바이스 AI

     * Apple Intelligence는 글쓰기·이미지 생성·시각 지능·사진 검색·메일·알림·메모 요약 등 전방위 인공지능 기능 제공
     * 온디바이스 LLM 지원으로 오프라인 환경, 강력한 개인정보 보호
     * 파운데이션 모델 프레임워크 로 개발자가 Apple Intelligence를 사용할 수 있는 API 제공
     * Siri는 더 자연스럽고 유용하게 진화, 개인 맥락 인지 향상
     * 지원 언어 확대 및 생태계 전반으로 적용 확장 예정

새로운 소프트웨어 디자인

     * Liquid Glass: 유동적이고 반투명한 유리 소재, 컨텍스트와 환경에 따라 변화, 하드웨어·소프트웨어 일체감 구현
     * 모든 플랫폼에 동일한 디자인 언어 적용: 앱 아이콘, 위젯, Dock, 제어 센터 등 전면 리뉴얼, 모서리·레이어·애니메이션 조화
     * 버전 번호 통일: 2026년까지 모든 OS를 26 버전으로 맞추고, 경험 일관성 극대화

iOS 26 주요 업데이트

     * 잠금화면·홈화면·앱아이콘 등 Liquid Glass 적용, 동적 3D 효과, 샌프란시스코 서체가 화면에 맞게 변경, 맞춤 앨범 아트 등 시각적 개성 강화
     * 카메라 앱은 사진/비디오 중심의 심플한 인터페이스, 사진 앱은 3D 효과 적용·탭 기능 재도입으로 보관함 및 모음탭 추가
     * Safari, FaceTime 등 주요 앱 모두 새로운 디자인과 동적 UI 적용. 사파리 주소창이 투명으로 변경. 페이스타임 렌딩 페이지에서 영상 메시지 보기 가능
     * CarPlay: 새 디자인 적용 및 위젯 추가. 네비게이션 중에도 전화 올 경우 위에 투명하게 표시
     * CarPlay Ultra: 운전자 맞춤 위젯·레이아웃, 차량 제어, 여러 제조사 파트너십 강화
     * 전화/메시지 앱: 통합 레이아웃(즐겨찾기, 최근통화, 음성사서함이 통합)
          + 스팸 필터링: 콜 스크리닝이 먼저 자동 응답하고 사람 이름을 얘기하면 그 내용이 보이면서 전화 벨이 다시 울림
          + 통화 대기(Hold Assist) 지원: 장시간 대기할때 듣기 싫은 음악 꺼버리고 치워뒀다가 상담원이 응답하면 다시 벨로 알려줌
          + 그룹 메시지에 투표 기능 추가·누가 타이핑 하는지 표시·Apple Cash 송금 등 신규 기능 추가
     * 젠모지에서 기존 이모지를 두개로 합쳐서 만드는 것도 가능. ChatGPT로 만들수도 있음
     * 실시간 번역: 메시지, FaceTime, 전화앱 등에 통합됨(상대방이 아이폰을 쓰지 않아도 심리스 하게 처리). 온디바이스 처리로 프라이버시 보장
     * Apple Music: 가사 번역 및 발음 기능 추가, AutoMix로 곡과 곡간을 자연스럽게 연결, Music Pin으로 잘 듣는 음악 고정
     * 지도/지갑/Apple Pay: 선호하는 경로를 기억, 통근길 안내, 방문장소 보기 및 공유 가능. 디지털 신분증(미국 여권), 포인트·할부 결제 확대, 주문 내역 자동 요약 및 추적
     * Games 앱이 새로 추가: 개인화 홈, Arcade 전용 탭, 친구와의 점수 경쟁, 게임별 도전 과제
     * 시각 지능(Visual Intelligence): 카메라와 화면 내 사물 인식 및 검색, 화면 캡처하는 방식으로 어떤 앱에서든 사용 가능, 앱 인텐트로 외부 앱 연동, ChatGPT 활용 Q&A 가능

watchOS 26

     * Liquid Glass 적용 새 디자인, 스마트 스택 개선, 손목 돌리기 등 제스처 추가(원치않는 알림 치우기)
     * 운동 기능(Workout Buddy): 운동 기록 기반 AI 코칭, 맞춤 음성 피드백, 성취 요약 등 제공
     * 운동 앱에서 기존 운동 기반으로 쉬운 인터벌 플랜 추가 가능
     * 메시지, 메모, 미디어 제어 등 일상 기능 대폭 강화, 개발자 API 제공

tvOS 26

     * Liquid Glass 기반 대형화면 디자인, TV·Music 앱 경험 강화, 개인별 프로필 지원, 자동 로그인 API 도입
     * Apple Music Sing: iPhone을 마이크로 사용, 파티형 노래방 지원

macOS Tahoe

     * Liquid Glass 디자인·아이콘·Dock·위젯·사이드바·툴바 등 전면 리뉴얼, 완전 투명 메뉴바, 제어 센터 커스터마이즈
     * 폴더 색상/아이콘 커스텀, 배경화면·테마 지정 등 개인화 지원
     * 연속성(Continuity): 실시간 현황(Live Activities)으로 알림에 기반한 연동 가능, 전화앱 Mac 이식, iPhone 미러링 강화
     * 단축어: 자동 실행 지원, Apple Intelligence 동작 통합
     * Spotlight 대폭 업데이트: 현재 앱의 메뉴를 실행하는 것도 가능, 맥락 기반 파일·동작·클립보드 이전 기록 보기 지원·빠른 키(Quick Keys) 지원, 개발자 앱 인텐트 API
     * 게임 앱 신설, Metal 4, 신작 게임(붉은사막, 인조이 등), 컨트롤러 연동·게임 오버레이

visionOS 26

     * 공간 위젯: 특정 공간에 고정되고 개인화 가능, 앱의 위치도 기억
     * 공간 장면 생성 및 공간 브라우징 지원, 페르소나 업그레이드(더 정교한 3D 아바타)
     * 공용 기기/방문자 모드/기업 기능: 팀원/외부 사용 지원, 보호 콘텐츠 API, 공간 액세서리(로지텍 Muse, PlayStation VR2 Sense 등)
     * Adobe, GoPro 등 파트너 협력: 3D·VR 콘텐츠 제작·플레이 강화, 공간 웹·3D 개체 지원
          + Adobe Premiere 기반의 별도 컨텐츠 생성앱으로 직접 Vision Pro에서 편집 가능

iPadOS 26

     * 새로운 디자인, 아이콘, 위젯
     * 아이폰에서 추가된 다양한 기능들을 아이패드에서도 지원
     * 멀티태스킹: 차세대 윈도우 관리 시스템
          + 창 크기·위치 조절 가능해지고, 다시 실행해도 크기를 기억
          + 타일 정렬(특정 방향 던지기, 분할 타일링), Exposé(스와이프), 메뉴바 도입으로 전체 기능 보기 가능
          + Mini를 포함한 모든 iPad에서 지원
     * 파일 앱: PDF·이미지 편집, 폴더 커스텀, 파일을 열 앱 지정 가능, Dock에 폴더 넣기 지원
     * Preview 앱: 맥의 미리보기 앱을 아이패드에 추가
     * 오디오·비디오 워크플로우: 앱별 마이크 지정, AirPods 활용 녹음/제어
          + 로컬 캡처: 아이패드에서 화상회의하는 오디오/비디오를 직접 캡쳐 가능
          + 백그라운드 작업으로 긴 시간 걸리는 작업도 처리 가능. 진행 상황은 상단에 별도 표시
     * 수학 메모, 전통 캘리그래피, 일기 앱 등 등이 다양하게 업데이트(시간 없어서 소개 못함)

개발자 및 도구

     * 파운데이션 모델 프레임워크로 앱 내 Apple Intelligence 활용 API 제공, Swift/SwiftUI 강화, Icon Composer 추가로 Liquid Glass에 맞는 아이콘 생성가능
     * Xcode에 생성형 AI·코드 어시스트 도입, ChatGPT 지원

출시 및 베타

     * 개발자 베타는 오늘 즉시 배포, 공개 베타 7월, 정식 출시는 가을 예정

   여전히 ai에 관련된 부분은 부족함이 많네요
"
"https://news.hada.io/topic?id=21312","Show GN: Ailoy: 쉬운 on-device AI agent 제작 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Show GN: Ailoy: 쉬운 on-device AI agent 제작 도구

   ailoy라고, LLM agent를 쉽게 만들어주는 라이브러리입니다.

   python / javacript(node) 두가지 버전이고, 현존하는 툴들 중에 제일 쉽다고 자부합니다.

   머신러닝 전문가 아니어도 만들 수 있는 것이 장점입니다.

   구글 오픈ai 앤트로픽 다 결국 api를 많이 쓰게 하려다보니, 돈먹는 하마인 것 같아서 on-device AI로 agent를 돌릴 수 있도록 만들어 봤습니다.

   깃헙 디스코드 링크로 오시면 막히는 점 도와드리겠습니다. 한번 써보시고 의견 남겨주시면 감사하겠습니다!

   모델 사이즈가 작은데 체감 성능이 어느정도인지 궁금하네요.

   확실히 gpt 시리즈라던지 deepseek r1에 비해서는 아쉬운 느낌이 있습니다. 30B 모델은 확실히 괜찮은데 이쪽은 on-device로 하려면 5090정도 되는 GPU가 있어야된다는 단점이 있구요....

   그래서 openai 모델이랑 비슷한 성능을 내면서 토큰 최적화를 하려면 openai를 사용하면서 쉬운 태스크는 local model을 사용하는 하이브리드 방식이 제일 좋은 것 같습니다.

   그래도 못쓸 정도는 아니고, 복잡한 태스크가 아니라 번역, 요약 정도는 그렇게 큰 차이가 없다는 느낌이긴 합니다... ㅎㅎ

   그렇군요^^ 답변감사합니다
"
"https://news.hada.io/topic?id=21357","피벗 포인트 - 내 강점과 약점이 전략이 되는 순간","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      피벗 포인트 - 내 강점과 약점이 전략이 되는 순간

     * ""Pivot Points는 '제약'도 아니고, '약점'도 아니고, 심지어 '강점'도 아님. 같은 현실을 다루지만 더 건설적이고 유용함""
     * 본질적으로 피벗 포인트는 평가 없이 ‘있는 그대로의 사실’로 인정하고, 개인/조직의 전략을 이 기반 위에서 세우는 것이 중요함
     * 자신과 조직의 피벗 포인트를 정직하게 파악하고, 이를 중심으로 전략을 설계할 때 경쟁사와 차별화되고 더 효율적으로 성공 가능함
     * 피벗 포인트는 쉽게 변하지 않으므로 단기 계획은 이를 고정값으로 두되, 장기적으로는 변화의 필요성과 효과를 고려해야 함

Gallup의 StrengthsFinder

     * Gallup의 StrengthsFinder는 오랜 과학적 검증을 거쳤다고 주장하는, 등록 상표가 가득 붙은 성격 검사 도구임
     * 다른 많은 성격 검사들이 데이터 기반이라고 주장하지만 실제로는 점성술에 비유될 정도로 근거가 빈약한 경우도 많음, 컨설턴트의 수익 수단에 불과한 경우도 있음
     * 공식 StrengthsFinder 검사 비용은 약 $59.99임
     * WP Engine에서는 수년간 신입 직원이 입사할 때마다 StrengthsFinder 검사를 실시하고, 모두 ‘상위 5가지 강점’ 을 받아봄
     * 많은 사람들이 이 과정을 즐기고, 스스로 분석받는 경험을 재미있어함
     * 나의 검사 결과에서 3번째 강점은 ‘경쟁심(Competitive)’ 으로, 항상 이기고 싶어하며, 특히 다른 사람과의 경쟁에서 이기고 싶어하는 성향임
     * ‘경쟁심’이 과연 강점인가?
          + 강점이 될 수 있는 맥락: 영업, 타 후보와 경쟁하는 면접, 과거의 자기 자신을 이기고 성장하려는 동기 부여 등에서는 긍정적임
          + 단점이 될 수 있는 맥락: 서로를 돕는 것이 목표인 팀 미팅, 게임·취미 생활에서 즐거움을 해치는 경우, 타인의 성취와 비교해 자기 가치를 낮추는 경우 등에서는 부정적임
     * 결론적으로, ‘경쟁심’이 무조건 강점인지, 약점인지 명확히 말하기 어려움. 상황에 따라 다르게 작용함

Pivot Points의 개념

     * Pivot Points는 ""제약(enabling constraint)""도, ""약점(weakness)""도, ""강점(strength)""도 아닌 평가자 성격의 판단을 배제한 중립적 사실임
          + 본질적으로 좋거나 나쁜 것이 아니라 그냥 존재할 뿐
          + Pivot Points 라는 명칭은 이를 중심으로 인생과 사업의 방향을 선회할 수 있기 때문
     * 상황에 따라 강점이 되기도, 약점이 되기도, 무관할 때도 있음
     * 성격 검사, SWOT 등 전략/기획 도구의 ""강점"", ""약점"" 개념은 부적절함 : 평가 맥락을 이미 알고 있다고 전제하지만 실제로는 그렇지 않은 경우가 많음
     * Pivot이란 단어의 의미
          + 농구같은 운동에서 ""Pivot Foot""은 그 자리에 머물러 있고, 다른 발이나 신체는 그 제약 조건하에서 자유롭게 움직일수 있음
          + 인생과 전략에서 Pivot Points는 제약 조건임
               o ""사람 관리를 싫어한다""면, 매니저가 되면 안되고, 팀이 필요한 회사를 만들어서도 안되고, 그 회사의 CEO가 되어서도 안됨
     * Pivot Points는 변할 수 있지만 자주 변하거나 변덕스럽게 변하지는 않음
          + 발을 들어 다른 곳으로 옮기고 새로운 Pivot을 설정하는 것은 새로운 기술에 투자하거나, 새로운 업계를 배우거나, 목표 대비 약점을 극복하는 것
          + 단기 계획에서는 Pivot Points가 고정된 것으로 가정해야 함
          + 장기 계획, 특히 시간과 돈을 투자할 곳을 결정할 때는 어떤 새로운 Pivot Points를 원하는지 물어볼 수 있음
     * 린 스타트업의 ""Pivot"" 개념과의 일치
          + 사업의 한 측면이 치명적으로 잘못되었음을 깨달았지만 다른 측면은 통찰력 있게 맞는 경우
          + 모든 것을 버리는 것이 아니라, 옳거나 불변하는 것(Pivot Points)을 깨닫고 회사의 나머지 부분을 그것을 중심으로 선회
     * 개인과 회사는 Pivot Points를 파악하고 이를 중심으로 전략을 구성해야 함

개인의 Pivot Points 찾기

     * ""너 자신을 알라!""는 어려움 :
       문제에 너무 가깝고, 편향되며, 내 머릿속에서 벗어날 수 없고, 자기 성찰에 타고난 재능을 가진 사람은 거의 없음
     * 무엇이 나를 움직이게 하는가
          + 어릴 때부터 이끌렸던 것, 과거 자신을 놀라게 할 만한 것, 더 신경 써야 할 것, 오랜 휴가 중에도 못 참는 것
          + 열정적으로 이야기할 때, 일에 빠져들 때, 대학으로 돌아가면 전공하고 싶은 것, 계속 하고 싶었던 프로젝트, 동료의 칭찬, 최근 몰입했던 경험 등도 단서
          + 자신을 잘 알고 사려 깊고 관찰력 있는 사람에게 물어보는 것도 도움이 됨
     * 무엇이 나를 방해하는가
          + 싫어하는 것을 피하는 것이 사랑하는 일을 지속적으로 하는 상황을 만드는 것보다 쉬울 때가 있음
          + 절대 꺼려지는 일, 불쾌감을 주는 상황, 잘하고 싶지만 절대 잘할 수 없을 것 같은 일, 내 시간의 10%만 할애하라고 해도 직업을 바꿀까 고려하게 되는 일 등
          + 좋아한다고 생각하지만 흥분되지 않는 일도 있음
     * 정직한 자기 성찰은 중요함
          + ""사회""가 싫어할 것 같은 대답이라도 정직해야 함
          + 돈을 벌고 싶어 하고, 유명해지고 싶어 하고, 무언가를 증명하고 싶어 하는 욕구 자체는 나쁜 게 아님
          + 영리해 보이고 싶고, 회자되고 싶고, 사후에도 기억되고 싶은 욕망은 인간 본성
     * 타인의 객관적 평가도 참고
          + 타인에게 자신의 장단점을 물어보되, 판단을 배제한 Pivot Point로 관찰 결과를 재해석
          + 익명이라도 타인은 완전히 정직하기 어려움
          + 이상적 시나리오와 최악의 시나리오에 대해 물어보기
     * 자신을 아는 것은 쉽지 않고, ""자신""은 시간이 지나면서 변화함
          + 그럼에도 주요 Pivot Points를 파악하는 것은 가치 있는 일임
          + 이를 중심으로 선회하거나 변화에 투자 여부를 결정함으로써 보람찬 삶을 만들 수 있기 때문

회사의 Pivot Points 찾기

     * 개인보다 더 복잡하고, 각자 서로 다른 영역에 대해 다른 지식을 가지고 있음
     * 팀에게 ""우리가 어떤지 적어달라""고 할 수는 없음
     * 사업의 내부 작동 방식을 전혀 모른다고 가정할 것
          + 내부 사람들이 생각하는 강점과 약점이 아니라 실제로 일어나고 있는 일에 주목
          + 전략으로 이어진 결정을 파악
          + 의식적으로 내린 결정이 아니거나 전략을 문서화하지 않았더라도 마찬가지
     * 행동과 결과는 관찰할 수 있지만, 그 이유는 사람들에게 물어볼 수 없음
          + 합리화하거나 방어할 가능성이 있기 때문
          + 발견에 초점을 맞추고 판단은 유보

제품과 회사의 특별하거나 특이한 점에 대한 관찰 쓰기(Write-storming)

     * ""특별하고 중요한 점""을 나열하라고 하면 너무 모호하고 포괄적이지 않음
     * 대신 구체적이고 연상을 불러일으키는 프롬프트 사용
          + 부인할 수 없는 비교 우위: 고객이 선택하는 이유, 경쟁사도 인정하는 강점
          + 일관된 불만: 자주 반복되는 고객 불만, 약점
          + 고객의 옹호 요소: 고객이 자발적으로 칭찬하거나 인정하는 부분
          + 최고의 고객 특성: 이상적인 고객이 가진 공통 특성
          + 자부심 요소: 팀 또는 제품에 대해 자부심을 느끼는 부분, 경쟁사가 해서는 안 될 것
          + 겉과 속: 홍보/마케팅에서 강조하는 것과 실제 강점의 차이
          + 실존적 위협: 가까운 미래에 실제로 발생할 위험
          + 구조적 특성: 기술 구조 또는 조직 구조가 만들거나 제한하는 것
          + 가치관/철학: 핵심 가치, 양보할 수 없는 신념
          + 반복되는 아이디어: 자주 떠오르는 개선점 또는 전략
     * 관찰의 이면을 파고들거나 행동으로 옮기는 것은 나중에 하되, 이 과정에서 나온 아이디어는 따로 기록

Pivot Points로 정제하기(Condensation)

   관찰 내용을 더 적고 명확한 Pivot Points로 증류하는 워크숍 진행
     * 1. 관찰 내용 돌아가며 공유
          + 한 사람에게 한 번에 하나의 관찰만 요청
     * 2. 명확히 하기
          + 해당 내용이 무엇인지 이해할 수 있도록 명확히 하는 질문
          + 판서할 수 있을 정도로 간결하게 정리
     * 3. Pivot Points로 전환
          + 이 관찰이 어떤 Pivot Point로 해석되는지 논의
          + Pivot Point 옆에 관찰 내용 배치
          + 하나의 관찰이 여러 Pivot Point와 연결되면 관찰 카드 복제
     * 4. 평가나 행동은 나중에
          + 지금은 결론 도출이나 해결책 논의할 때가 아님
     * 5. Pivot Points 병합
          + 더 적고 강력한 Pivot Points를 갖는 게 좋음
          + 그러나 너무 일반적이 되어 쓸모없어지지 않도록 주의
          + 의심스러우면 병합하지 말고 구체성과 실행 가능성에 방점
          + 3개나 10개 등 목표 개수를 정하지 말 것
     * 6. 모두 소진될 때까지 반복
          + 방 한 바퀴를 돌며 반복하다 보면 아이템이 바닥나는 사람 발생
          + 모두의 목록이 고갈될 때까지 계속
     * 이 과정에서 수많은 아이디어, 후속 조치, 그리고 잠재적인 실행 계획이 쏟아질 것
     * 이러한 아이디어들을 수집하고, 다른 곳에 눈에 띄게 적어 사람들이 아이디어가 사라지지 않았다는 것을 알게 하기
     * 중요한 것은 핵심을 놓치지 않는 것

회사에 피벗 포인트 적용하기

   탁월한 전략과 충만한 삶은 피벗 포인트를 사실로 받아들이고, 이를 바탕으로 전략과 커리어를 설계하는 것에서 시작함
   피벗 포인트를 활용해 더 나은 제품 전략과 인생을 만드는 직접적인 방법
     * 1. 현재 우리의 전략 또는 제안된 전략이 피벗 포인트에 어떻게 매핑되는지 살펴보고, 일치하는 부분은 더 깊게 파고들고, 모순되는 부분은 전략을 전환할 필요가 있는지 점검함
     * 2. 여러 피벗 포인트를 동시에 활용할 수 있는 활동을 늘릴 수 있는 방법을 고민함. 이렇게 하면 우리는 그 일에 최적화되어 있을 뿐 아니라, 경쟁자와의 차별화도 자연스럽게 이뤄짐. 남들은 우리의 피벗 포인트가 다르기 때문에 쉽게 모방하기 어려움
     * 3. 피벗 포인트의 부정적 영향에 대응하는 전략 변화를 고민하여, 스스로 한계에 갇히지 않고, 남들이 더 잘할 수 있는 게임을 피할 수 있도록 설계함
     * 4. 이미 식별한 피벗 포인트에서 논리적으로 추가되어야 하는 포인트가 있는지 고민함. 이는 자기 일관적이고 상호 보완적인 전략(서로를 강화하는 구조)을 만들기 위한 과정임
     * 5. 여러 피벗 포인트를 활용 또는 회피할 수 있는 단일 핵심 개념이 있는지 살펴보고, 이를 중심으로 전체 포지셔닝과 전략을 구축할 수 있을지 검토함
     * 6. 우리의 피벗 포인트가 가장 매력적으로 다가갈 고객 유형(예: 인구통계, 기업 속성, 해결 과제, 예산, 지역 등)이 누구인지, 현 ICP(이상적 고객상)에 부합하는지, 아니면 조정해야 할지 확인함
     * 7. 우리가 지킬 수 없는 약속을 하고 있지는 않은지, 혹은 자연스럽게 이길 수 있는 영역에서 충분히 약속하고 있는지, 즉 마케팅과 실제 행동이 일치하는지 점검함
     * 8. 피벗 포인트 간에 모순이 있는지 살펴봄. 예를 들어 ‘24시간 지원 제공’과 ‘하루 4시간만 일할 수 있음’은 충돌함. 이런 모순은 때로 피벗 포인트 자체를 바꿔서 해결하고, 때로는 창의적인 아이디어로 모두 만족시키는 새로운 방식을 만들 수 있음
     * 9. 우리의 피벗 포인트 중 사실이 아닌 것이 있다면 도전적으로 검토하고, 정말 사실인지 재확인함. 만약 그렇지 않다면, 무엇이 달라져야 하는지, 실제로 변화를 주어야 하는지 고민함
     * 스타트업이 대기업을 이기는 방법, 그리고 AI 시대에서 피벗 포인트가 달라지는 사례들도 참고할 만함

피벗 포인트와 전략 선택 예시

     * 나의 경우 ‘경쟁심’이라는 피벗 포인트가 있어, 정체된 대규모 시장에서 10배 더 나은 제품을 만들고 마케팅과 영업에서 이기는 전략이 적합함
     * 반면, ‘영업에서 이겨야 한다’는 개념을 싫어하는 사람은, 영업팀이 필요 없는 단순한 니치 제품을 만들고, 1인 브랜드로 완벽하게 특화된 상품을 제공하는 전략이 어울림
     * 사람을 좋아하지만 영업은 싫어하는 사람은, 장기적 관계를 쌓을 수 있는 컨설팅 회사(예: 특정 부서를 전담하는 형태) 설립이 더 적합함
     * 이처럼, 창업자의 피벗 포인트와 시장의 니즈가 일치할 때 다양한 전략이 모두 유효해짐

‘Enabling Constraints’와 피벗 포인트

     * 일부에서는 피벗 포인트를 ‘Enabling Constraints’(가능하게 하는 제약) 이라고도 부름
     * 제약이 창의성을 촉진하고 복잡성을 줄여준다는 이론도 있음. 실제로 디자인의 본질은 ‘예술 + 제약’이라고 볼 수 있음
     * 그러나 ‘Constraint(제약)’라는 단어는 제한적이고 부정적인 뉘앙스를 주기 쉽고, 한계 자체가 긍정적임을 바로 이해하기 어려움
     * 피벗 포인트는 단순한 제약이 아니라, 전략적으로 활용하거나 설계에 반영해야 하는 ‘사실’ 임

피벗 포인트의 변화와 주의점

     * 피벗 포인트는 노력과 투자로 바꿀 수 있지만, 실제로 바꾸기 어려운 경우도 많고, 비용·리스크가 클 수 있음
     * 변화가 성공하지 않을 수도 있고, 변화 과정에서 조직 내외부의 불만, 이탈, 혼란이 발생할 수 있음
     * 피벗 포인트는 정말 변화의 이익이 엄청나서, 기대치의 30%만 달성해도 아깝지 않을 정도일 때만 변화에 도전하는 것이 바람직함
     * 그리고 한 번에 너무 많은 변화를 시도하기보다는, 자신 또는 조직에 대해 한두 가지씩 변화를 시도하는 것이 좋음

결론 및 삶의 태도

     * 피벗 포인트에 기반해 인생이나 전략을 설계하면, 자신의 소명을 따르는 것과 같음
     * 더 효율적이고, 효과적이며, 높은 품질을 내고, 자신만의 차별화를 만들 수 있음
     * 무엇보다 자신이 진정 하고 싶은 일을 하며, 더 많은 즐거움을 얻을 수 있음
     * 인생은 짧고, 조직 운영은 어렵기에 피벗 포인트와 싸우지 말고 적극적으로 받아들이는 태도가 중요함
"
"https://news.hada.io/topic?id=21415","인터넷 다운","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 인터넷 다운

   자세한 건 모르겠는데, 대략 30분 전부터 전세계적으로 인터넷이 크게 다운된 것으로 보입니다. 영향 받은 것으로 보이는 곳은:
     * 클라우드 플레어
     * AWS
     * Openrouter
     * Firebase
     * Google
     * 기타 등등...

   구글 밋이 안 된다, gcp 장애 있다 연락 오더니
   배포 하려던 것도 뭐가 잘 안 되어서... 오늘은 로컬 작업만 했네요.

   자고 일어났더니 뭔가 후루룩 일이 생기고 끝났나봐요.

   관련 HN

   Cloudflare Status
   Google Cloud

   AWS과 Digitalocean 등은 영향 받지 않은 것으로 보입니다. Google Cloud는 복구 진행중이며, ETA는 정해지지 않았습니다.

   글들을 보면 제일 먼저 Google Cloud에서 문제가 발생했고, 이를 핵심 종속성으로 가지고 있던 Cloudflare가 함께 다운되며 이들과 이어진 대부분의 서비스들(npm, 앤트로픽 등)에 장애가 발생했던 것으로 보입니다.

     We expect the recovery to complete in less than an hour.

   복구가 진행되고 있고, 곧 완전히 복구되겠네요. 몇몇 영향 받았던 한국의 서비스들도 정상적으로 복구된 것 같습니다.

   무슨 이슈가 발생했길래 CF까지 포함해서 다 다운됐는지 궁금하네요..
"
"https://news.hada.io/topic?id=21335","빌 앳킨슨이 별세함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               빌 앳킨슨이 별세함

     * Bill Atkinson이 2025년 6월 5일 췌장암으로 별세함
     * 그는 Apple 및 컴퓨터 역사에서 매우 중요한 인물임
     * QuickDraw, MacPaint, HyperCard 등 혁신적이고 영향력 있는 소프트웨어 개발로 기억됨
     * 그의 코드와 알고리듬은 효율성과 우아함을 높이 평가받음
     * Atkinson의 업적은 미래의 개발자들과 업계에 오랫동안 영감이 될 전망임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

가족의 공지

     * 가족들은 Bill Atkinson이 2025년 6월 5일에 췌장암으로 포톨라 밸리 자택에서 가족들과 함께 평화롭게 별세했음을 Facebook 페이지에 밝힘
     * 남편, 아버지, 계부로서 그리고 놀라운 사람으로서 Bill Atkinson을 추억함
     * 그의 존재 자체가 세상을 바꿨다는 점을 강조함
     * 의식과 그 너머에 대한 그의 관심을 회상하며, 그의 다음 여정이 의미 있기를 기원함
     * 그는 아내, 두 딸, 계아들, 계딸, 두 형제, 네 자매, 반려견 Poppy를 가족으로 남김

컴퓨터 역사 속의 Bill Atkinson

     * Bill Atkinson은 Apple뿐만 아니라 컴퓨터 역사에서도 위대한 영웅으로 평가받음
     * Andy Hertzfeld의 Folklore.org에서 Atkinson에 대한 여러 이야기를 읽을 수 있음
          + Steve Jobs가 Atkinson에게 roundrect 도형을 발명하게 한 일화를 소개함
          + 또 다른 이야기에서는 Atkinson의 유쾌하면서도 프로페셔널한 태도를 엿볼 수 있음

혁신적인 소프트웨어와 알고리듬

     * Bill Atkinson의 코드와 알고리듬은 전례 없는 효율성과 우아함으로 유명함
     * 오리지널 Macintosh 팀 내 수많은 천재들 중에서도 불가능을 가능하게 만든 핵심 인물로 평가받음
     * Atkinson의 디더링 알고리듬은 여전히 많은 곳에서 사용되며, 현재도 Playdate 콘솔이나 BitCam 같은 앱에서 응용되고 있음

대표적 업적: QuickDraw, MacPaint, HyperCard

     * Atkinson은 QuickDraw(2D 그래픽 시스템), MacPaint(비트맵 이미지 에디터), HyperCard(하이퍼링크 기반 스택 애플리케이션) 등 다수의 결정적 소프트웨어를 창조함
     * MacPaint는 오늘날 포토샵 등 여러 비트맵 편집기 모델의 시초가 됨
     * HyperCard는 1985년 LSD 여행에서 영감을 받은 것으로 전해지며, 업계에 미친 영향력이 지대함

요약 및 평가

     * 과장 없이 Bill Atkinson은 역사상 가장 뛰어난 컴퓨터 프로그래머 중 한 명으로 평가받음
     * 그의 창의성과 업적은 오늘날까지도 계속해서 전 세계에 영향을 끼침
     * 그는 기술, 소프트웨어, 그리고 우리 모두의 삶에 상당한 선물을 남긴 존재임

        Hacker News 의견

     * 한때 Apple의 ColorSync 팀에서 일하면서 동료 엔지니어들과 함께 그의 숲속 집에 초대받은 적이 있음
       그를 알고 있었지만, 왠지 모르게 대화 주제를 컬러 기술과 컴퓨터 워크플로우에만 국한해야 할 것 같은 기분이었음
       지금은 은퇴해서, 그와 이런저런 얘기를 더 나눠보지 못한 걸 계속 아쉬워하고 있음
       그 당시 그는 디지털 사진에 굉장히 빠져 있었음
       고가의 드럼 스캐너로 필름 네거티브(아마 중형 카메라 사용)를 스캔하고, 그 뒤로 완전히 디지털 워크플로우로 작업하는 방식에 열정적이었음
       특히 암부를 스캐너로 어떻게 포착할 수 있는지에 신나 있었고, 순수 아날로그 프로세스에서는 암부가 사라진다고 설명했음(필름 때문이 아니라 인화 과정이 원인이라는 추측)
       태평양 대양에서 대형 바위가 있는 사진을 스캔해서 컴퓨터로 보여주면서 바위 그림자 속에서 디테일이 살아 있는 모습을 자랑스럽게 보여줬고, 사진집도 준비 중이었음
       그때 나는 고가 장비에 돈을 쏟는 은퇴한 엔지니어가 갑자기 사진작가로 변신한다고 생각했었음
       기술적 접근을 예술적 접근과 비교했지만, 나중에 Ansel Adams의 기술력에 대해 배우면서 최고의 사진가는 기술과 예술이 겹친다는 점을 깨달았음
          + 너와 아무 얘기나 나누지 못한 걸 아쉬워한다는 말이 인상적이어서 나도 뭔가 시도해보고 싶다는 생각이 듦
            사실 한동안 너랑 아무 얘기나 나눠보고 싶었음
            지금 맥에서 컬러가 도입되는 배경, 특히 컬러 피커에 관한 작은 리서치 프로젝트를 진행 중임
            혹시 이런 얘기를 캐주얼하게 할 의향이 있으면, BlueSky에 계정 만들어서 연락할 수 있음
            https://merveilles.town/deck/@rezmason/114586460712518867
          + 오늘날에도 그 정도 다이내믹 레인지를 온전히 디지털 영역에서 얻기는 꽤 힘든 상황
            예전엔 차이가 8~12스톱이었는데, 지금은 4~5스톱 정도로 줄었을 것 같긴 함
            단색 사진을 다루다 보면 아직도 그가 겪었던 한계를 우회해야 할 때가 있고, 피사체가 덜 까다로워도 그렇다는 점에 공감함
          + 컴퓨터에서의 컬러라는 주제만으로도 충분히 흥미로운 얘깃거리
            가끔은 인류의 진보 자체에 대한 얘기를 나누는 게 즐거운 일이고, 변화와 발전의 한 축을 담당한다는 것만큼 멋진 경험은 없다는 생각
          + 광학 프린팅을 할 때 뭔가를 반드시 잃게 되는 상황
            물론 어떤 면에서는 이득도 있지만 1:1로 그대로 재현되진 않음
            나는 이런 하이브리드(아날로그+디지털) 워크플로우를 정말 좋아함
            필름을 골라서 사진의 컬러 톤, 입자감을 선택할 수 있고, 디지털로 현상하면서 필름의 한계도 대부분 해결할 수 있음
            아쉽게도 요즘은 필름을 쓰는 게 너무 번거롭다는 게 현실
            사진은 늘 나에게 ‘구성’이 가장 중요한 부분이었고 장비나 작업 과정 자체는 덜 중요했음
            필름 고유의 일관된 결과를 좋아했지만, 지금은 디지털도 충분히 잘 활용하고 있음
          + 예술 평론가들은 형식, 구조, 의미에 대해 이야기하지만 정작 아티스트들은 어디서 저렴한 테레빈유를 살 수 있는지 얘기 나누는 모습
     * Bill을 직접 만난 적은 없고, 내가 그의 존재를 알릴 일도 없었지만, 내 커리어와 가족, 경제적 번영에 엄청난 영향을 줌
       프로그래밍에 대한 열정은 Apple II에서 시작했고, 1984년에 MacPaint를 보고 Mac으로 전향
       HyperCard 덕분에 논리적 사고를 배웠고, 이 기계로 무엇을 할 수 있을지 가능성을 느꼈으며 정보를 개념화하는 법을 익힘
       그의 겸손한 노력이 내 인생에 이렇게 큰 영향으로 남았음
       이 소식을 듣고 나서 너무 슬픈 마음
     * Walter Isaacson의 《Steve Jobs》에 나온 Bill Atkinson의 업적
       그의 대단한 업적 중 하나는 여러 창(window)이 서로 겹쳐서 맨 위 창이 아래 창을 가릴 수 있는 기능을 구현한 점
       이전까지는 컴퓨터 화면에 실제로 겹칠 수 있는 픽셀 레이어가 없었지만, 마치 책상에서 종이를 옮기듯이 창을 자유롭게 이동하고 가릴 수 있게 해줌
       이 효과를 내기 위해 ‘region(리전)’이라는 복잡한 코딩 구조가 필요했으며, 원래 PARC에서도 구현하지 못했던 걸 Atkinson이 현실화
       그는 이 기능에 집착할 만큼 밤낮없이 일했고, 한 번은 과로로 코르벳 차로 트럭에 충돌할 정도로 가까스로 살아남았음
       병원에서 깨어나자 Steve Jobs가 달려와 걱정했지만, Atkinson은 “걱정 마세요, 아직 리전(Regions)을 다 기억하고 있어요”라고 너스레를 떨었음
          + 겹치는 사각형 창들이 있을 때, 맨 위가 아닌 창의 가시 영역은 ""L"" 또는 ""T""자 형태처럼 복잡한 모양이 될 수 있음
            Bill의 region 구조는 창 바운드 내 가시 행(row)을 RLE(run-length encoded)로 표현한 것이라고 이해하고 있음
            최상단의 창은 0에서 창의 폭까지 각 행마다 동일하게 표시 가능하고, 동일한 행이 반복될 경우 더 압축적으로 표기할 수 있게 설계
            가려진 창은 각 행의 시작점과 끝점이 다를 수 있고, 내부에 구멍이 있을 수도 있음
            이 구조에서 영역끼리 더하고 빼고, 교집합과 합집합을 빠르게 처리하는 루틴이 핵심
            이런 자료구조를 순식간에 순회하고 잘라내는 능력이 바로 똑똑함의 포인트
          + Apple과 Xerox의 접근법 차이는 ‘PARC 사람들이 그걸 할 줄 몰랐다’라는 단순한 이야기가 아닐 수도 있음
            Alto 머신은 프레임버퍼가 없고, 각 창이 자체 버퍼를 가짐
            마이크로코드가 각 스캔라인마다 창 정보를 읽어서 결과를 만들어내는 방식
          + 현대의 컴퓨팅과 운영체제에서 이런 기술적 차이가 얼마나 대단한 건지 이해하기 어렵다고 느낌
            불가능해 보이는 걸 해내는 기쁨은 여전하다고 생각
            이 분야의 역사를 기억하며, 이 가능성들을 현실로 만든 사람들을 함께 기려야 한다고 생각
            좀 더 geeks끼리 기술적으로 이런 구조를 깊게 논의하고, Bill Atkinson을 그런 방식으로 기억하고 싶음
            https://www.folklore.org/I_Still_Remember_Regions.html도 읽었는데 완전히 이해하지 못했을 수도 있음
          + PARC에서도 실제로 구현하지 못한 기능을 Atkinson이 완성했다는 부분
            경쟁 회사가 VGA 카드에서 어떤 버퍼 기능을 구현했다는 루머처럼, 정작 실제 제품 출시 시에는 구현이 미흡했거나 더 단순한 경우가 떠오름
          + Bill Atkinson이 Mac Paint 작업으로 박수갈채를 받는 장면을 볼 수 있는 영상
            https://www.youtube.com/watch?v=nhISGtLhPx4
     * 다른 세계선에는 HyperCard가 역사 속으로 사라지지 않고, 계속 발전해 웹까지 품고, 소프트웨어를 만드는 소프트웨어 장르 전체를 창조한 경우가 있음
       이 세계에서는 사람들이 마치 점토를 빚듯, 본인에게 꼭 맞고 딱 들어맞는 개인 앱을 손쉽게 만들 수 있음
       ‘모두’의 컴퓨팅 기기가 Steve Jobs가 말한 ‘마음의 자전거’로 진화했을 것
       이런 세상을 Atkinson이 꿈꿨으리라는 생각에, 개인적으로 그 timeline에서 살고 싶음
       진정한 비전리더를 잃었다는 아쉬움과 그에 대한 영원한 기억
          + 지금도 HyperCard 같은 툴을 바라는 사람들이 많겠지만, 실제로 HyperCard가 얼마나 큰 영향력을 발휘했는지는 정확히 알 방법이 없음
            그래도 여기 있는 많은 사람들이 실제로 HyperCard를 접했고, 그 경험이 이후의 진로에도 영향을 줬다는 사실에 동의
            초등학교 컴퓨터 교실에서 HyperCard를 활용한 수업을 했던 추억이 있음
            이런 수업이 80~90년대에 여러 교실에서 이뤄졌다면, HyperCard가 꽤 많은 뇌에 자극을 준 셈
            다음 시대를 열지 못했다고 해도, 자체로 충분히 성공했다고 느낀다는 감정
          + 웹도 HyperCard에 많은 영향을 받음
            Tim Berners-Lee의 초창기 웹 브라우저 프로토타입은 쌍방향성을 염두에 뒀고, 하이퍼텍스트 에디터가 브라우저와 함께 탑재되는 구상이었음
            그런 면에서 HyperCard의 정신이 지금 인터넷에서도 살아있고, 엄청난 기반이 된 것
          + ‘HyperCard가 웹을 수용하고 성숙했다면’이라는 평행우주도 흥미롭지만, 또 다른 세상에서는 HyperCard에 이미 URL 개념, GET/PUT API 같은 기능이 먼저 추가됐고, 그로 인해 Tim Berners-Lee의 웹 브라우저 탄생이 필요 없어졌다는 상상
          + Atkinson의 별세만으로도 충분히 슬픈데 이런 대안적 타임라인을 생각하면 더 아쉬운 감정
            진지하게는, 예전에 ResEdit를 써서 HyperCard stack에 직접 FONT 리소스를 넣고 텍스트 필드를 활용해 타일드 그래픽을 만든 것을 또렷하게 기억함
            버튼 아이콘으로는 성능이 떨어져서 직접 이런 편법을 썼는데, System 7부터는 먹히지 않아 애를 먹었던 추억
          + HyperCard 이후로 가장 비슷한 그래픽 프로그래밍 환경이 Flash였던 점이 아이러니
            Flash도 이미 역사 속으로 사라졌음
            오늘날 웹에서 범용 앱을 만들기 위한 최고의 후계자가 있다면 무엇일지 궁금함
     * 2020년에 처음 비디오챗으로 Bill을 만났고, 서로를 조금 알게 됐음
       그는 이후 내 인생을 바꿀 선물을 보내줬으며, 최근 몇 년간은 연락을 못 했지만 생사의 경계를 넘은 경험도 있었고, 그만큼 사실 죽음에 심리적으로 준비된 사람이었다고 생각
       그는 인생의 마지막 여행을 아주 잘 준비해서 떠났으리라는 믿음
       소프트웨어에 대한 견해가 늘 일치하지는 않았지만, 미지와 존재의 의미에 공통의 관심이 있었음
       저 세상에서 다시 만나자는 인사
          + 궁금해서 그런데, 그 선물이 뭐였는지 알려주면 좋겠음
     * Bill Atkinson이 매우 흥미로운 인물이라는 생각
       2013년에 그가 Leo Laporte와 한 인터뷰가 정말 들을 만함
       특히 HyperCard가 탄생하게 된 LSD 경험 관련 6분짜리 클립이 있음
       https://www.youtube.com/watch?v=bdJKjBHCh18
     * Bill의 명복을 빌며, HN 상단에 검은 띠를 달만한 사람이라는 공감
          + 설정에서 'topcolor'를 바꾸면 상단 색상을 검게 할 수 있지만, 그렇게 하면 사이드바의 링크가 가려질 수 있음
            로컬 CSS를 해킹 해야 그걸 피할 수 있다는 팁
     * General Magic 다큐멘터리를 꼭 추천
       Bill이 1990년에 공동 창업한 회사로, 영화에선 사람들이 “왜 타임스퀘어에서 이메일을 확인해야 하냐?”고 어리둥절해하는 장면이 나옴
       당시로선 상상할 수 없던 미래를 General Magic은 미리 구상했으나, 정작 대부분은 아직도 회사 이름조차 모르는 현실
       https://www.youtube.com/watch?v=JQymn5flcek
          + 스마트폰을 Apple이 처음 시작했다고 생각한다면 General Magic 다큐멘터리는 꼭 봐야 할 소중한 자료
     * Folklore.org에 있는 다양한 Bill Atkinson 관련 일화도 추천
       https://www.folklore.org/Joining_Apple_Computer.html
       https://www.folklore.org/Negative_2000_Lines_Of_Code.html — 코드 라인 수에 집착하는 문화에 던지는 재미있는 얘기
       https://www.folklore.org/Rosings_Rascals.html — Macintosh Finder가 어떻게 탄생했는지에 대한 이야기
       https://www.folklore.org/I_Still_Remember_Regions.html — 교통사고로부터의 생존담
          + “Busy Being Born” 이야기도 엄청난 가치가 있음
            초기 Lisa/Mac UI의 폴라로이드 사진이 남아있는 귀중한 내용
            https://www.folklore.org/Busy_Being_Born.html
          + 코드 라인 에피소드는 영원한 고전이라는 감상
     * 오늘날 WIMP 윈도/아이콘/메뉴/포인터 인터페이스가 너무 당연하게 여겨지지만, 그걸 만든 개척자들은 잊혀지는 현실
       데스크탑 앱에서 모바일식 햄버거 메뉴 등 논리적으로 맞지 않는 요소를 채용하면서 불편이 커지는 점이 아쉬움
       Bill이 만든 인터페이스를 그리워하는 날들이 있다는 고백
"
"https://news.hada.io/topic?id=21384","슬라이 스톤 별세","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               슬라이 스톤 별세

     * 슬라이 스톤은 혁신적인 펑크 밴드 Sly and the Family Stone의 리더로, 82세의 나이로 타계함
     * 그는 음악적 유산과 장르 융합을 통해 대중음악에 큰 영향을 미친 인물임
     * 밴드는 미국 대형 밴드 최초의 인종 통합 구성으로 사회적, 문화적으로도 상징적인 의미를 가짐
     * 화려한 성공 이후 약물 문제와 갈등으로 밴드 활동에 큰 어려움을 겪음
     * 슬라이 스톤의 삶과 음악은 앞으로도 다큐멘터리, 영화 등 매체를 통해 조명받을 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

슬라이 스톤의 생애와 음악적 유산

     * 슬라이 스톤(본명 Sylvester Stewart)은 미국 펑크 음악 밴드 Sly and the Family Stone의 선구적 리더로, 향년 82세를 일기로 가족과 친구들에게 둘러싸여 별세함
     * 가족은 슬라이 스톤이 만성폐쇄성폐질환(COPD) 등 여러 건강 문제로 오랜 투병 끝에 평화롭게 생을 마감했다고 밝혔으며, 그의 엄청난 음악적 유산이 앞으로도 세대를 넘어 영감을 줄 것임을 언급함

어린 시절 및 가족

     * 슬라이 스톤은 1943년 텍사스에서 태어나, 다섯 형제 중 둘째로 성장함
     * 어린 시절 가족과 함께 샌프란시스코 베이 지역으로 이주, 어린 시절 형제 자매와 함께 가스펠 음악 밴드 활동을 시작함

음악 커리어의 시작과 성장

     * 1960년대 초반 라디오 DJ로 일하며 브리티시 록과 소울 등 다양한 음악을 접함
     * 1966년 슬라이와 형 프레디의 밴드를 통합해 Sly and the Family Stone 결성, 여동생 로즈와 동생 베타도 각자 혹은 공동으로 음악 활동에 참여함
     * 슬라이 스톤은 어린 시절부터 기타, 키보드, 베이스, 드럼 등 다양한 악기를 능숙하게 다루는 음악적 천재로 평가받음
     * 밴드는 미국 대형 록 밴드 최초로 다인종 및 남녀 혼성 멤버로 구성되어, 당시 사회적 분위기 속에서 큰 의미를 가짐

주요 앨범 및 성과

     * 1967년 데뷔 앨범 ""A Whole New Thing"" 발표 후, 싱글 ""Dance to the Music""으로 큰 주목을 받음
     * ""Dance to the Music""는 미국 빌보드 팝 싱글 차트 8위까지 상승, 대중적 성공의 계기가 됨
     * 1969년 앨범 ""Stand!""를 통해 ""Everyday People""(빌보드 1위), ""Hot Fun in the Summertime""(2위) 등 대표곡을 발표, 밴드는 세계적으로 큰 인기와 인지도를 얻게 됨
     * 슬라이 스톤은 카리스마 넘치는 무대와 솔직한 메시지가 담긴 가사로 음악계 패러다임 변화의 중심에 있었음
     * 1969년 우드스탁 페스티벌 무대에 올랐으며, ""Everyday People"", ""Dance To The Music"" 등 다수의 히트곡을 전세계에 선보임

슬럼프와 재조명

     * 1970년대 초 약물 문제, 내분, 공연결손 등으로 밴드는 활력을 잃기 시작, 이후 여러 앨범을 냈으나 1969년의 성공을 다시 찾지 못함
     * 슬라이 스톤은 자서전에서 코카인, PCP 등 약물 의존 문제를 고백함
     * 밴드 해체 이후에도 솔로 및 Family Stone 명의의 앨범 활동을 이어감

유산과 최근 활동

     * 슬라이 스톤은 2006년 그래미 시상식 무대에 오르며 오랜만에 공식 공연을 선보임
     * 1993년 Sly and the Family Stone은 Rock and Roll Hall of Fame에 헌액됨
     * 펑크 밴드 Parliament Funkadelic의 George Clinton은 그들을 ""역대 최고의 펑크 밴드""로 평가함
     * 다큐멘터리 ""Sly Lives!""(Questlove 감독)가 2024년 공개되어 새로운 세대에게 재조명되고 있음
     * 가족에 따르면 슬라이 스톤 본인의 영화 각본도 최근 완성, 앞으로 그의 삶을 다룬 영화가 제작되어 소개될 예정임

개인사 및 가족

     * 슬라이 스톤은 1974년 Madison Square Garden 공연 중 모델 Kathy Silva와 무대에서 결혼, 두 사람 사이에 아들 Sylvester Jr.를 두었으나 1976년 별거함
     * 두 딸 Sylvyette(Phunne)와 Novena Carmel이 있음

추모 및 영향

     * 가족은 슬라이 스톤을 사랑하고 기억하는 많은 이들의 애도와 격려에 깊이 감사함을 표함
     * 슬라이 스톤의 혁신적 음악과 개성은 앞으로도 대중음악과 문화에 긍정적 영향을 남길 것임

        Hacker News 의견

     * 나는 Sly Stone의 영향력에 관한 일화를 들은 적이 있음. Stevie Wonder가 Sly & the Family Stone 공연에서 객원 연주자로 참여했을 때, 현장의 에너지가 모두에게 퍼지는 것을 느끼게 됨. 이 경험을 토대로 Stevie Wonder는 새로운 음반 계약을 통해 창작적 자유를 얻었고, Superstition, Higher Ground 같은 클래식 명곡을 만들게 됨. TV에서 보여주는 록 역사에 대해 회의적인 시선이 들 때도 있지만, 한 천재가 또 다른 천재에게 영감을 줄 수 있다는 이야기는 Haydn과 Mozart 관계를 떠올리게 해줄 만큼 충분히 그럴듯하다고 생각함. ""If You Want Me to Stay""가 내가 가장 좋아하는 Sly Stone 곡임. 아직 그가 Funkadelic과 했던 곡들을 제대로 들어보지 못했는데, 오늘이 바로 그 날인 듯함
          + Stevie Nicks가 Dreams 곡을 Sly Stone의 지하실에서 숨으면서 작곡한 일화가 있음. Sly Stone은 대중적으로 성공한 최초의 인종통합 록밴드를 이끌었고, 펑크 스타일에서 세 손가락 안에 드는 거물급 인물이었음
          + 그들의 공연은 확실히 에너지가 넘쳤음. 이 영상에서는 공연 끝날 무렵 관객 절반이 무대 위에서 같이 춤을 추는 장면을 볼 수 있음 https://youtu.be/4URogrXiKsI
          + 최근 Alan Parsons 인터뷰를 들었는데 1973년 'Dark Side of the Moon'이 앨범 부문 그래미에 노미네이트되지 못했다며, Stevie Wonder가 상을 받았다고 언급함. 그래서 Wonder의 'Inner Visions'을 들어봤는데, 상을 받은 이유가 명확했다고 느낌. 이 앨범이 훨씬 뛰어나며, 지금은 거의 잊혀진 점이 안타까움
     * Sly Stone이 나에게 어떤 의미인지 설명하기 힘듦. 어릴 때 가족들과 차 뒷자리에서 그를 들으며 자람. Sly는 내게 여름, 용기, 그리고 환희였음. 그의 음악은 여전히 그렇다고 생각. RIP
          + 나는 원할 때마다 booop ooop ooop ooop임
     * 이 문화에 익숙하지 않아 한동안 이 스레드가 Sylvester Stallone에 대해 이야기하는 줄 알았음. RIP. Sly가 Superstition 곡에 참여했었는지 궁금함
          + 너만 그런 거 아님. 관련 기사도 찾아볼 수 있음
            Sylvester Stallone death hoax와 Sly Stone 부고 소동
            Stallone 트렌드 관련
            Stallone vs Stone의 팬 혼동 기사
          + Woodstock에서 Sly가 전설적인 퍼포먼스를 펼친 적 있음
          + 비슷하게 생각한 사람임. 45살인데 밴드 이름만 들어봤음
     * 내가 가장 좋아하는 Sly Stone 순간 중 하나는 그가 Mike Douglas Show에서 Muhammad Ali와 함께 출연했을 때임. Sly는 Ali의 진지함과 행동주의에 완벽하게 어울리는 익살꾼이자 평화주의자 역할을 했음 https://www.youtube.com/watch?v=vBFAHd189V8
          + 물론 Ali와 Stone 모두 시대를 대표하는 소통 능력을 지녔지만, 이 영상에서처럼 인종, 노예제 보상 등 어려운 질문을 진중하고 정직하게 다루는 방식이 과거 대중 미디어에선 두드러졌음. 지금은 방송 문화에서 이런 진실성 있는 토론을 접하기 힘들어졌다고 느낌. 요즘 정치 토론을 보면 지루함과 답답함만 남음. 일반인들 대화에선 여전히 이런 솔직한 소통 방식을 쉽게 볼 수 있는데, 미디어에선 점점 사라지는 분위기라 아쉬움이 큼. 진정성 있는 소통이 사라진 데에는 용기라는 이미지를 씌우면서 공개적으로 솔직하게 말하는 걸 경계하는 분위기가 영향을 주었을 수도 있다고 생각함. 그리고 무엇보다 Sly Stone이라는 지난 세기의 위대한 작곡가이자 밴드리더, 그리고 혁신가를 잃은 점이 큰 아쉬움임. 그의 작품과 스타일이 현대 음악에 준 영향은 과장할
            수 없을 정도. RIP
     * 모두 Sly Lives! - The Burden of Black Genius 영상을 보길 추천함
          + 꼭 봐야 할 다큐멘터리임. Ahmir ""Questlove"" Thompson의 작품임 Sly Lives! (aka The Burden of Black Genius)
     * 최근에 이 클립을 봤는데 https://www.youtube.com/watch?v=xJU-4fYejiw, 슈퍼 데이브가 Norm Macdonald 쇼에 게스트로 나온 덕에 알게 됨. 당시의 분위기가 잘 담긴 흥미로운 기록임. Peter Marshall이 생방송에서 인종차별적 표현을 쓴 장면, Sly는 완전히 약에 취한 모습이 나옴
     * Sly Stone과 The Family에 대한 훌륭하게 만들어진 2부작 팟캐스트 다큐가 있음. 이야기는 한 곡을 중심으로 전개되지만, 사실상 Sly Stone을 둘러싼 세상의 흥미로운 스토리를 담아냄 500songs.com 다큐: Everyday People by Sly and the Family Stone. Sly는 뛰어난 퍼포머, 보컬, 멀티 인스트루멘털리스트였을 뿐만 아니라 환상적인 작곡가이자 엄청난 영향력을 끼친 프로듀서였음. 그는 음악적 길을 전방위적으로 꿰뚫고 있었지만, 어느 시점부터는 길을 잃기도 했음
     * ""밴드는 70년대에 별 주목받지 못한 앨범을 여러 개 냈지만 1969년의 정점에는 다시 오르지 못했다""는 평이 있음. 하지만 ""There's a Riot Goin On""(1971)과 Fresh(1973)는 완전한 명작이고 영향력도 큼
          + 스웨덴의 짧지만 큰 영향력을 남긴 잡지 Pop이 1994년에 There's a Riot를 역대 최고의 앨범으로 선정함. 그 리스트는 한 세대의 스웨덴 음악 팬들에게 큰 영향을 미침 Pop 잡지의 100대 앨범 리스트
     * 나는 ""Dance to the Music""을 듣고 베이스 팬이 됨. 멋진 음악을 준 Sly에게 감사함
          + base가 아니라 bass를 의미한 것인지 궁금함
     * Everybody is a star https://www.youtube.com/watch?v=3-1s2gqDs_U
"
"https://news.hada.io/topic?id=21333","생각의 환상: 추론 LLM의 한계 이해하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        생각의 환상: 추론 LLM의 한계 이해하기

     * 대형 추론 모델(Large Reasoning Models, LRMs)은 복잡한 문제 해결에서 일정 수준의 성능 향상을 보였으나, 근본적 한계 및 확장성 문제가 명확하게 드러남
     * LRMs는 문제 난이도가 높아질수록 추론 과정이 급격히 붕괴되는 현상을 보이며, 분석 결과, 추론 노력(토큰 사용량)도 임계점을 넘어가면 오히려 줄어드는 역설적 현상 발생
     * 동일 연산 자원 하에서 표준 LLM과 LRMs를 비교하면, 저난이도에서는 표준 LLM이 더 우수하나, 중간 난이도에서는 LRMs가 유리, 고난이도에서는 모두 실패함
     * LRMs는 명시적 알고리듬 추론 및 일관된 사고 과정에서 결정적인 한계를 보이며, 각 퍼즐 환경에 따라 상이하거나 비일관적인 행동을 보임
     * 이러한 연구를 통해 현재 추론 모델의 신뢰도 문제와 확장성 한계가 확인됨에 따라, 차세대 인공지능 설계에는 정밀한 평가 및 구조 개선이 요구됨
     * 애플의 ""The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity"" 논문
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요 및 연구 목적

     * 최근 대형 언어 모델 기반의 추론 특화 모델(LRMs) 이 등장함에 따라, 이들의 문제 해결 과정에서의 “생각” 구조와 한계를 파악하는 연구 필요성이 대두됨
     * 현재 대부분의 평가는 수학 및 코딩 벤치마크에서 정답률 중심으로 이루어지며, 이는 데이터 오염이나 내부 “사고” 과정의 질을 정확히 측정하지 못함
     * 본 연구는 논리 구조를 유지한 채 복잡도를 정밀하게 조절할 수 있는 퍼즐 환경들을 도입하여, 결과 정답뿐 아니라 내재적 추론 흐름까지 분석할 수 있도록 설계함

평가 환경 및 실험 방법

  퍼즐 환경 설계

     * 체계적 복잡도 조절 및 실험 제어를 위해 아래 네 가지 퍼즐 환경 활용
          + 하노이의 탑: 원판 수로 난이도 조절, 최적해 여부는 평가하지 않고 목표 상태 도달 여부로 정답 판단
          + 체커 점프: 빨강·파랑 체커와 빈 공간의 수로 복잡도 제어, 최종적으로 위치 맞바꾸기 목표
          + 강 건너기: 행위자-에이전트 쌍의 수, 보트 용량으로 난이도 조절, 제약 조건 하에 전원 이동
          + 블록 월드: 블록 수로 조절, 초기 상태에서 목표 쌓기 상태로 이동

   각 환경은 퍼즐 요소의 수 조절로 복잡도를 세밀하게 증가시킬 수 있음.

주요 실험 결과

  1. 복잡도별 세 가지 추론 양상

     * 저복잡도: 표준 LLM이 LRMs보다 더 효율적(토큰 절약) 이고, 정답률도 높은 경우 다수 발생
     * 중간복잡도: LRMs의 긴 사고 과정(Chain-of-Thought) 과 자기 성찰적 사고가 성능 이점 드러냄
     * 고복잡도: 양 모델 모두 즉각적 성능 붕괴(정답률 0) , LRMs는 이 지점에서 추론 토큰 사용량도 감소하는 비효율적 현상 관측

  2. 사고 흔적(Reasoning Trace) 심층 분석

     * “과도한 사고(overthinking)” : 저복잡도 문제에서 LRMs는 정답을 초기에 찾고도 이후 잘못된 탐색을 반복하여 불필요한 연산 낭비 패턴을 보임
     * 중간 난이도: 오답 파악 후 점진적으로 정답에 도달, 이전보다 많은 탐색 과정 필요
     * 고난이도: 전체 추론 흐름에서 옳은 해답을 생산하지 못하는 ""붕괴 현상"" 확인

  3. 알고리듬 실행 한계

     * 정해진 알고리듬을 프롬프트에 제공해도, 모델이 단순 실행조차 신뢰성 있게 수행하지 못함
     * 이는 단순한 “정답 찾기”뿐만 아니라 논리 구조를 정확히 따르는 기호 조작 능력의 본질적 부족을 시사함

  4. 벤치마크 및 데이터 오염 문제

     * 기존 수학 벤치마크(MATH500, AIME24, AIME25) 상에서는 생각형/비생각형 모델 성능 격차가 일관적이지 않음
     * AIME25의 경우 데이터 오염 가능성으로 인해 본질적 모델 추론 능력 평가가 어려운 한계 노출

연구 결론 및 시사점

     * 본 연구는 퍼즐 기반 정밀 평가 환경을 도입해, 추론 LLM이 실제로 사고 능력을 가지고 있는지, 그리고 그 한계가 어디서 드러나는지 심층적 실증 분석을 제공함
     * 현존하는 추론 모델은 특정 복잡도 이상에서 완전히 붕괴하는 근본 한계가 있으며, 이는 토큰 예산이나 단순 self-reflection 강화로 해결되지 않음

     * 기존 평가 방법의 한계 의문 제기 및 실험실적 측정 환경 제안
     * 현재 SOTA 추론 모델도 보편적 문제 해결 능력은 확보하지 못함
     * 복잡성에 따른 추론 토큰 사용의 스케일링 한계 존재
     * 사고 중간 과정(trace) 기반 평가법 도입, 자기 교정·오류 탐색 메커니즘 분석
     * 명시적 알고리듬 실행의 실패 및 비일관성

     * 이 결과는 차세대 인공지능 설계 및 신뢰성 평가, 그리고 데이터 오염 문제를 회피한 환경에서의 모델 성능 측정의 중요성을 강조함

관련 연구 동향

     * CoT(Chain-of-Thought), 자기 검증 기법, 강화학습 기반 사고 촉진 등 다양한 추론 능력 부여 시도
     * 높은 품질의 CoT 데이터 획득의 어려움과, supervised/RL 방식의 한계 대두
     * 대표적인 예시로 DeepSeek-R1, Claude 3.7 Sonnet Thinking 등 등장
     * “과잉 사고” 현상(overthinking)과 벤치마크 오염으로 인한 평가지표 신뢰도의 문제 제기
     * 문제 복잡도를 세밀하게 제어할 수 있는 퍼즐 환경 기반 평가의 필요성 강조

향후 과제 및 한계

     * 추론 모델이 명시적 논리 따라가기/기호 조작에서 보이는 근본적 한계에 대한 추가적 연구 필요
     * 퍼즐 환경 사례별로도 모델 행태가 비일관적인 점(예: 하노이/강 건너기 성능 차이)에서 데이터 기반 추론 한계 가능성 제기
     * 인공지능 시스템 설계 시, 중간 추론 흐름과 논리적 일관성을 포함하는 정밀 검증이 필수임

   이러한 분석은 실무적 활용뿐 아니라, 차세대 추론 인공지능의 설계 및 평가 체계에 큰 시사점을 줌.

        Hacker News 의견

     * LLM이 언어를 사용하기 때문에 우리가 혼란을 느끼는 이유 중 하나라고 생각하는데, ‘Biology of Large Language Models’와 ‘Safety Alignment Should Be Made More Than Just a Few Tokens Deep’를 보면, 그 안에서 실제로 일어나는 과정이 인간과 완전히 달라서 결과물이 낯설게 느껴지는 부분이 많음
       기술로 시스템을 설계하거나 부분의 합보다 큰 결과를 만드는 구조를 고민하면서, 여전히 이들의 능력치를 명확히 이해하는 데 어려움이 큼
       작동 원리 자체는 알아도 언어를 다루는 모습에서 마치 마법처럼 느껴지는 이상함이 있음
       그래서 생각을 정리하려고 이 글도 씀
       이런 연구는 정말 대단하다고 생각하고, 앞으로 토큰을 잘 활용하고 제대로 구축하는 방식을 이해하려는 노력이 훨씬 더 많이 필요하다고 봄
       [참고 링크]
          + Biology of Large Language Models
          + Safety Alignment Should Be Made More Than Just a Few Tokens Deep
          + 시스템 전체가 부분의 합보다 커지는 구조를 만들고 싶은 고민에 공감하면서, 개인적으로 프로그래밍 자체가 그런 역할을 한다고 봄
            업무나 문제를 쪼개어 최소한의 상호작용만 하는 작은 단위로 만들면, 그 조합이 더 큰 결과를 내는 구조 형성
            이 과정을 프로그래밍 워크플로에 잘 녹이면, 심지어 성능이 떨어지는 LLM도 자연스럽게 해결책의 일부로 사용할 수 있을 것이라는 확신
          + 그 반대로, 전체 시스템이 각 부분보다도 못할 수도 있다고 봄
            개별 업무는 잘하지만, 결합된 상황에서는 업무가 꼬여버리는 문제도 존재
            앞으로 개선될 부분이긴 하지만, 모든 문제를 최적화할 수 없으니 결국 특화된 방식이 더 효율적일 수도 있다는 고민도 함께 함
     * 인간 언어 자체가 인지 도구로서 완벽하진 않지만, 근본 층위가 아니라 상위 계층(의사소통·고차원적 추론)에서 잘 활용된다고 믿음
       인간 언어는 본질적으로 모호하고 불완전해서, 환경과 직접 상호작용하는 방식에 비해 강한 인지를 만들기에는 부족하다고 느낌
       그래서 LLM/LRM 모델이 보여주는 언어 유창성과 지식 회수 능력만으로 지능 척도를 삼는다면 쉽게 속을 수 있음
     * 기존 벤치마크(예: 수학 문제) 대신 난이도를 체계적으로 조절할 수 있는 퍼즐 환경 도입 아이디어가 정말 기발하다고 생각
       간단한 과제에서는 기존 모델이, 중간 복잡성에선 LRM이, 그리고 높은 난이도에선 모두 무너진다는 세 가지 성능 구간 분석도 흥미로움
       이런 복잡성 구간의 ‘지도(map)’를 더 많이 그릴 필요가 있다고 느낌
       경제적 가치와 복잡성 구간이 어떻게 맵핑되는지 궁금함
       이걸 알기 위해서는 평범한 퍼즐을 넘어서 실제 경제 업무에도 적용 가능한 정교한 평가 방법이 필요하다고 봄
     * 저자들이 전달하려는 핵심 직관은, 모델이 ‘전지하지만 모자란’ 존재라는 믿음에 있다고 생각
       이런 의문을 수치적으로 제대로 다룬 논문을 본 적이 없어서, 이번 연구도 의견을 완전히 하나로 모으긴 어려워 보임
       AI 낙관론자는 모델의 멍청함이 줄었다고 믿는 반면, 회의론자는 그저 지식량이 늘어났을 뿐이라고 생각해서 입장 차이는 좁혀지기 어려움
       그래도 이 문제를 계속 논해야 한다고 생각
       왜냐하면 전지하나 멍청한 모델로는 AI가 슈퍼지능(ASI)은커녕, 기존 SaaS 수준의 비서 역할에 그칠 수밖에 없어서 경제적 파급도 제한적이라는 점이 있기 때문
       언젠가 저자들이 훌륭하게 문제를 해결하기를 희망
          + 우리는 이 기술에 자꾸 인간적인 수식어(전지, 멍청 등)를 붙이면서 인격화하는데, 사실 그런 요소가 전혀 없는 순수 도구라고 생각
            LRM이 하는 일은 단지 최종 답변을 위해 맥락 데이터(자체적으로 생성한 데이터)를 튜닝하는 것뿐
            이 과정 자체가 뛰어난 아이디어지만, 여전히 환각 문제 등 근본적 한계를 해결하지 못함
            대화 중 모델이 맨 처음에 정답에 가까운 논리를 내놓았다가, 계속되는 '잠깐!' 같은 자기 부정 속에 결과물이 망가지는 현상도 목격
            이처럼 인간적 특성을 과하게 부여하면 시장에서 과대포장이 될 뿐 발전에 방해만 된다고 생각
            결국 이 기술은 진짜 인공지능이 아니라 대규모 패턴 매칭과 확률적 데이터 생성 엔진임
            여전히 실용적이지만, 지나치게 인간적 특성을 부여하면 논의가 혼탁해진다고 생각
          + 나는 AI에 대해 기대와 동시에 두려움이 공존하는데, 이유는 최근 몇 년간 AI가 그다지 ‘똑똑’해지진 않았지만 실제 실용 능력은 엄청나게 개선됨
            지식·도구·맥락 활용력이 엄청나게 늘었음
            그래서 가장 두려운 부분은 ‘추론/에이전시 능력’ 대기상태라고 봄
            즉, 단순히 거의 전지적 지식을 가진 데에서 한 단계 더 나아가, 진짜로 정확한 전략적 판단을 병렬로 수행할 수 있는 브레이크스루가 한두 개 남았다고 추정
            만약 그 두 가지가 결합된다면 정말 무서운 결과 나옴
            사람보다 6수 앞서는 천재와 대화할 때처럼, 아예 내 사고 흐름 자체를 유도하는 AI가 등장할 수 있기 때문
            현재 최전선 AI 연구자들도 추론+에이전시를 최우선 과제로 삼고 있어서 빨리 성과가 날 수도 있는 분위기
            현재 LLM이 순간 판별은 최고지만,
              1. 정말 긴 단계별 추론/전략 수립
              2. 순발력 있는 추론 기반 전략 행동(전문가들이 직관으로 한 번에 답을 떠올리는 수준)
                 이 두 가지는 여전히 부족
                 이걸 해결하려면 근본적인 시스템2 추론(‘시스템1’은 현재의 트랜스포머)이 필요할 수도 있고, 아니면 단순히 더 좋은 데이터와 알고리즘으로 ‘전략적 직관’을 빠르게 익히게 만드는 방식이 될 수도 있음
                 물론, 문제 난이도가 너무 높아서 단계적 난관일 수도 있고, 압도적으로 많은 컴퓨팅 파워가 필요할 수도 있음
                 그래서 확신은 없지만, 정말 강력한 발전이 일어날 거란 생각에 두려움이 큼
          + 전지하지만 멍청한 존재가 인류 지능에서 멈춰야 할 이유도 따로 없다고 생각
     * Apple이 AI에 있어서 실패하고 있는 건지, 단순히 스스로 AI가 중요하지 않다고 믿는 쪽으로 R&D 방향을 바꾼 것 아닌지 의문
          + 최근 AI 기능들이 소비자 제품에 대거 도입되는 현상을 보면, 사용자를 위한 느낌보다는 투자자에게 기술력을 과시하려는 의도가 강해 보임
            실제로 Apple, Google, Meta, Microsoft, Samsung 모두가 기대치에 못 미치는 AI 기능을 마케팅만 요란하게 내세우고, 정작 성과는 좋지 않음
            Apple이 오히려 새 방향을 고민하는 것이 오히려 긍정적 신호일 수도 있다는 심정
          + 살짝 덜 냉소적으로 보자면, LLM의 실제 가능성을 과대평가하지 않도록 기대치를 낮추려는 목적이 있을 수도 있음
            Apple 제품의 ‘더 똑똑해진 Siri’라고 해도, Iron Man의 Jarvis 같은 진정한 AI 비서가 될 수 없다는 현실 인식
            실제로 투자자들은 훨씬 과도한 기대를 하고 있는 분위기
            더 냉소적으로 보자면, Apple이 약한 머신러닝 능력을 숨기려는 전통이 오랫동안 이어져 왔다고 생각
            예시로, Siri가 Google보다 많이 뒤쳐졌을 때부터 ‘데이터를 보호하다 보니 학습을 못 하는 것’이라고 사후 설명을 붙인 점이 있음
            관련 논문
          + 모든 회사는 저마다의 프레임이 있다고 생각
            OpenAI, Anthropic도 LLM 능력을 당연히 과장해서 홍보할 동기가 있기 때문에, Apple만 편파적이라고 비난할 수는 없음
     * 논문에서 다양하고 복잡한 퍼즐을 실험해본 결과, 특정 난이도를 넘으면 LRM이 완전히 실패한다는 점과, 문제 복잡도가 증가할 때 추론 노력도 잠깐 오르다가 이후 오히려 떨어지는 이상한 한계가 있다는 점이 너무 공감
       코딩에서도 똑같은 경험이 있는데, 처음에는 점점 복잡하게 만들 수 있지만 어느 순간 한계를 넘기면 완전히 무너져서 시도조차 안 하는 느낌
       Claude나 aider 같은 LLM을 제대로 활용하려면, 모델이 받아들이는 문제 복잡도를 신중히 관리하는 게 중요
     * AGI(범용 인공지능) 논의가 한때 엄청나게 ‘코앞’이란 분위기였던 게 떠오름
       Gartner 하이프 사이클이 기술별 흐름을 정말 잘 포착한 듯한 인상
          + 기술 발전이 S자 곡선을 그릴 때, 꺾이기 직전까지는 가파른 상승이라 실제로 언제 둔화될지 예측이 무척 어려움
            1968년에 첫 Boeing 747이 나온 후, 항공산업이 반세기 넘게 큰 변화 없이 머물 거라고 당시 사람들은 상상도 못 했을 것
          + 자율주행차와 상황이 똑같음
            ‘코앞’까지 왔는데도 정작 ‘코너’를 돌지 못하고 있는 느낌
          + 사실 AGI ‘코앞’이라는 분위기가 불과 2년 전 얘기라는 점도 있음
            GPT2에서 AGI로 단 10년 만에 간다면, 여전히 엄청나게 빠른 일이라는 생각
          + 기술 진보가 80%쯤 온 것 같은데, 쉬운 부분은 끝났고 남은 20%는 워낙 어려워서 몇 년씩 걸릴 정도라고 느낌
          + AGI는 컴퓨터 등장 이래로 줄곧 ‘금방 온다’는 구호만 남아 있었음
            일부 문제(예: 기계번역)는 ‘솔루션’ 기준을 점점 낮추었기에 현실적으로 해결했다고 보는 거지, AGI에 진정 가까워진 건 아님
            AGI 자체는 일종의 세속적 종말론(종교)에 가까움
     * Tower of Hanoi, Checkers Jumping, River Crossing, Block World 같은 퍼즐 환경은, 실제로 코드 작성을 허용했다면 모든 LLM이 완벽하게 풀 수 있는 일이라는 생각
       인간도 20자리 곱셈을 손으로 해보면 실수하기 쉬운데, LLM이 못한다고 문제라고는 생각하지 않음
          + 인간은 컴퓨터 없이 미사일 설계나 정밀 공학을 해내기도 했고, 시간·전략·노력을 더 투자하거나 도구(종이 등)를 쓰면 결국 문제를 해결
            인간 뇌가 이런 연산을 위해 설계된 건 아니지만, 일반 지능이면 자체적인 방식으로 어떻게든 해낼 수 있다는 점은 강점
          + LLM이 RL 에이전트 교육의 ‘정책 교사’ 역할을 하는 새로운 프레임워크 논문 소개
            LLM 교사가 제공한 지침으로 작은 학생 RL 에이전트를 빠르게 훈련하고, 환경 피드백을 추가로 학습시키면 결국 학생이 교사보다 더 뛰어난 과제를 완수할 수 있다는 내용
            관련 논문
          + 모든 LLM이 이런 문제를 잘 푸는 이유는, 이미 코드베이스에 솔루션 예제가 엄청나게 저장되어 있을 가능성 때문이라고 생각
          + 인간이 못하는 이유와 LLM이 못하는 이유는 완전히 다름
            LLM은 곱셈 자체를 잘 수행 못하는 경우가 많고, 인간은 단순히 안 하고 싶어서 안 하는 경우가 다수
     * ‘정확한 계산이 힘들고, 퍼즐별로 일관성 없는 추론을 보인다’는 논문의 구절에 주목
       LLM/LRM이 인공지능 자동화의 친척 격인 로직, 최적화, 제약 프로그래밍(IA)에서 도움을 받아야 한다고 봄
       참고 자료로 CMU John Hooker의 협업 강연, MIT Gerald Sussman의 강의, Google OR-Tools, MiniZinc 플랫폼도 함께 추천
     * 가장 단순한 과제에서는 LLM이, 중간 복잡성에선 LRM이, 고난이도에서는 모두 실패한다는 연구 결과가 인상적이라고 느낌
          + 약간의 빈정거림이 느껴지긴 하지만 명확하게 표현하기 어렵다는 생각
"
"https://news.hada.io/topic?id=21390","Magistral — Mistral AI의 첫 번째 추론 모델 발표","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Magistral — Mistral AI의 첫 번째 추론 모델 발표

     * Magistral은 Mistral AI가 공개한 도메인 특화, 투명성, 다국어 추론에 특화된 첫번째 추론(reasoning) 모델
     * 오픈소스인 Magistral Small(24B 파라미터) 와 기업용 엔터프라이즈 버전인 Magistral Medium 두 가지로 출시
     * 사고사슬(Chain of Thought) 기반의 다국어 추론, 단계별 논리 과정을 사용자의 언어로 투명하게 제공함
     * AIME2024에서 Magistral Medium 73.6% (최고 90%), Small 70.7%(최고 83.3%)의 성능을 보임
     * 법률, 금융, 헬스케어 등 규제 산업, 데이터 엔지니어링, 소프트웨어 개발, 크리에이티브 콘텐츠 등 다양한 언어와 산업군에 맞는 정확한 단계별 논리 전개 및 10배 빠른 응답 속도 지원
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Magistral — Mistral AI의 첫 번째 추론 모델 발표

     * Magistral은 실제 문제 해결 능력과 피드백 기반 개선에 초점을 맞춘 reasoning 모델임
     * Magistral Small은 24B 파라미터 오픈 소스 버전, Magistral Medium은 더 강력한 엔터프라이즈 버전으로 이중 출시됨
     * 성능 지표:
          + Magistral Medium: AIME2024 73.6%, 다수결 기준 90% 달성
          + Magistral Small: 각각 70.7%, 83.3%
     * 글로벌 언어 및 문자 기반 Chain of Thought 논증 적용, 모국어 수준의 사고 전개 가능
     * 구조적 계산, 프로그래밍 로직, 의사 결정 트리, 규칙 기반 시스템 등 다양한 업무에 적합
     * Le Chat의 Think mode 및 Flash Answers 기능으로 응답 속도를 경쟁사 대비 10배 향상
     * 공식 논문에 알고리듬, 학습 인프라, 강화학습 기법, 훈련 인사이트 전반에 대한 평가 수록

모델 및 기술 세부 사항

     * 투명한 추론 과정:
          + Magistral은 다단계 논리에 최적화되어 사용자가 추론 과정을 자신의 언어로 확인·추적 가능함
          + 일반적 모델과 달리 해석 가능성 및 검증 기능 강화
          + 지속적인 모델 업데이트 및 빠른 개선 목표
     * 다국어 추론: 영어, 프랑스어, 스페인어, 독일어, 이탈리아어, 아랍어, 러시아어, 중국어 등에서 높은 정확도와 논리 유지
     * 응답 속도:
          + Magistral Medium은 Le Chat의 Flash Answers 기능을 통해 경쟁사 대비 10배 높은 토큰 처리속도로 실시간 추론 및 피드백 지원
          + ChatGPT 등 주요 경쟁 모델 대비 속도 측면에서 탁월함을 시연

오픈소스 및 커뮤니티 참여

     * Magistral Small은 Apache 2.0 라이선스로 공개됨
     * 사용자는 구조 및 추론 방식에 대해 직접 분석, 수정, 재구성 가능
     * 이전 오픈소스 모델은 ether0, DeepHermes 3와 같은 혁신적 연구 프로젝트에 활용됨

광범위한 적용 사례

     * Magistral은 법률, 금융, 소프트웨어 개발, 스토리텔링 등 정밀한 단계별 추론 및 투명성이 중요한 영역에 최적화됨
     * 비즈니스 전략 및 운영
          + 전략 기획, 위험 평가, 데이터 기반 의사결정, 복합적 제약조건 하의 최적해 계산 등 수행 가능
     * 규제 산업 및 공공 부문
          + 법률, 금융, 헬스케어, 정부 전문가들이 논리적 추론 경로 추적 및 감사성 확보 가능
          + 결과의 감사성 및 규정 준수 충족 지원
     * 시스템, 소프트웨어, 데이터 엔지니어링 분야
          + 비추론 LLM 대비 프로그래밍, 프로젝트 설계, 백엔드 아키텍처, 데이터 엔지니어링 지원 품질 개선
          + 외부 도구, API 연계 등 복수 단계 작업에 효과적임
     * 콘텐츠 생성 및 커뮤니케이션
          + Magistral은 창의적 글쓰기, 스토리텔링에도 뛰어난 결과를 보임
          + 일관된 텍스트뿐 아니라 독특하고 기발한 아이디어 생성도 가능함

이용 방법 및 배포 경로

     * Small 버전은 다운로드 후 자체 배포 가능
     * Medium 버전은 Le Chat(웹), API, Amazon SageMaker에서 즉시 활용 가능
     * 곧 IBM WatsonX, Azure AI, Google Cloud Marketplace에서 추가 지원 예정
     * 기업 맞춤형, 온프레미스 도입은 별도 문의

        Hacker News 의견

     * 나는 Magistral Small 모델의 GGUF 버전을 HuggingFace에서 직접 만들어 업로드한 경험 공유. ollama에서 ollama run hf.co/unsloth/Magistral-Small-2506-GGUF:UD-Q4_K_XL 명령어로 실행 가능하고, llama.cpp에서는 --jinja, --temp 0.7, --top-p 0.95 등 옵션을 꼭 써주길 당부. Ollama의 문맥 길이도 8192 이상으로 늘리는 것이 추천이며 추가 가이드도 공식문서에서 확인 가능
          + DeepSeek 관련 벤치마크 비교가 흥미로운 부분. 기존 Magistral 논문은 DeepSeek-V3(2023년 12월) 및 DeepSeek-R1(2024년 1월) 버전과 비교하는데, 실제로는 최신 DeepSeek-R1-0528 버전이 더 공정한 비교 대상이라는 생각. 예시로, R1이 AIME 2024에서 79.8점이고 R1-0528은 91.4점 성능, AIME 2025에서도 각각 70점/87.5점으로 크게 차이나는 수치 언급. 최신 DeepSeek 벤치마크는 여기에서 확인 가능
          + Magistral 논문(PDF)이 정말 인상적이라는 평가. 논문에서는 GRPO를 다루면서 1) KL Divergence 제거 2) 전체 길이로 정규화 3) advantage minibatch 정규화 4) trust region 완화 등 다양한 개선사항 소개
          + 나이 인증의 위험이 있지만, Unsloth 모델이 정말 ""대박""이라는 극찬. 모델이 항상 잘 동작해 만족감 표현하며, llama.cpp에서 ""jinja""가 없으면 기본적으로 무엇을 쓰는지 궁금점 제기
          + 너무 많은 생각을 하지 말라는 뉘앙스와 함께 참고 자료로 gist 링크 제공
     * 벤치마크 결과만 보면 Magistral Small이나 Medium 모델이 DeepSeek-R1 최신 버전과 비교해 모든 one-shot 테스트에서 뒤처지는 모습을 확인. 기사에서도 최신 DeepSeek-R1 언급조차 없고, 비용도 2배 이상 비싸 유럽 최고 AI 회사로 알려진 곳도 현재 기술 트렌드 따라잡기에 힘겨워 보이는 현실 인식
          + 초기 DeepSeek R1이 대단히 적은 컴퓨트로도 엄청난 퍼포먼스를 냈기 때문에, 새로운 R1이 모든 벤치마크에서 o3, 2.5 Pro 등을 압도하지 못하는 점이 신기함. Magistral Small(24B)이 AIME 2024에서 70.7% 점수를 얻고, R1 디스틸(32B)이 72.6%. Majority voting@64로 Magistral Small이 83.3%까지 올라가면서 전체 풀 R1보다 높은 성능 달성. 일반 게이밍 GPU에서도 24B 모델을 돌릴 수 있어 접근성이 훨씬 뛰어난 장점 설명. 관련 Distill 모델링크 추가
          + AI 모델 경쟁이 치열한 현재 상황에서, 최신 모델보다 6~12개월 늦게 나오더라도 천문학적 비용을 들이지 않는 선택도 엔지니어링적으로 큰 의미라는 생각. 물론 시장 점유율 관점에서 ""최고""만 사용하는 고객 논리 이해하지만, 영원히 돈만 잃는 사업의 점유율이 얼마나 중요한지에 대한 의문 제기
          + Mistral의 투자자 구조를 보면 실질적으로는 유럽 기업이 아니며, 미국 자본이 주요 소유주라는 점을 강조. 자세한 내용은 투자자 정보 링크에서 확인 가능
          + 경쟁력이 다소 떨어질지라도, 각 지역마다 학습 제어 가능한 자체 모델을 갖추는 것이 전략적으로 필수적이라는 의견. 하지만 기술 격차가 너무 커지면 사용자 입장에서 쓸모 없는 것으로 취급받을 리스크 존재
          + Mistral이 완전한 “독립형” 트레이닝 파이프라인을 구축한 점을 주목. Deepseek 같은 경쟁사들은 아마도 GPT-4, o1 등의 데이터로 학습한 것으로 추정
     * Ollama 및 API, 그리고 llm-mistral 플러그인을 통해 Magistral 모델을 직접 적용한 노트 내용을 기록 링크에 정리
          + Simon에게, ""자전거 타는 두 펠리컨""의 실질적인 차이점이 무엇인지 물음. 소형 버전은 로컬에서, 더 성능 좋은 대형 버전은 API를 통해 돌렸다는 추측
     * Mistral OCR 모델이 크게 홍보되던 시기 600페이지 PDF를 OCR 처리해야 했던 실사용 경험담. 전부 모노스페이스 텍스트였으나, OCR 결과의 80%가 이미지로 인식되고 거의 공백만 출력되는 등 tesseract보다 훨씬 못한 수준. 한 달 뒤 형편없는 결과에도 청구서 떠안고 계정 삭제 경험. 이번 신제품이 이전보다 나을 수는 있겠지만, Mistral의 과도한 마케팅에는 기대감이 식은 상태
     * 벤치마크 표본 선정이 너무 산발적이고 제한적인 점에 대한 혼란. Magistral Medium만 Deepseek V3, R1, 그리고 Mistral Medium 3와만 비교하고, Magistral Small이나 Alibaba Qwen, o3/o4 미니 버전은 왜 누락됐는지 이해 불가
     * 논리적 추론과 위키피디아 수준 상식 테스트를 위해 Mistral AI에게 ""상파울루에서 파리로 가는 브라질 시민이 리스본을 경유할 때 출입국 심사 위치"" 질의. Mistral AI는 ""파리에서만 심사""라고 답했으며, 위키피디아 글을 참고하도록 하자 ""리스본에서""로 수정. Meta AI(Llama 4)는 아예 둘 다 필요 없다고 답해 정확성 부족. 다른 LLM의 답변도 궁금
          + 질문 자체가 사실상 트릭 질문이라는 의견. 실제로는 슈겐 입국지인 리스본뿐 아니라 브라질/메르코수르 출국지인 상파울루에서도 심사가 필요할 거라는 지적
          + Gemini(2.5 Flash)가 제공한 답변이 인상적. 주요 흐름: 브라질 국적자는 90일까지 슈겐 비자 면제. 리스본에서 입국 심사 후 파리행은 슈겐 내 국내선 취급이므로 파리에서 추가 심사 없음. 2026년 ETIAS 전자여행허가제 도입 예정이지만, 이는 사전 인허가에 해당하고 심사 위치에는 영향 없음
          + 질문한 본인도 답이 헷갈리는 상태라는 지적과, 이런 식의 테스트에서는 LLM이 얼마나 설득력 있게 답하는지 비교하기 쉽다는 재미있는 시각
          + 브라질-포르투갈 간 특별한 비자 면제 협정이 있어 Llama 4의 답이 오히려 맞을 가능성도 상정하며 잠정적인 여지 남김
     * 나는 Qwen3를 벤치마크 차트에 넣어줬으면 하는 바람. Qwen3-4B만 해도 Magistral-22B와 거의 맞먹는 성능, Qwen3-30B-A3B는 월등히 더 뛰어난 결과 확인
          + 30-A3B 모델이 정말 대단하다는 평가. 로컬에서 API 비용 없이 돌려보면, 1~2년 전 폐쇄형 모델들과 비교해서도 더 뛰어난 성능. 특히 프로그래밍 업무에선 gpt-4o보다 더 높게 평가
          + 다양한 모델 벤치마크 자동화된 사이트가 있는지 궁금. 본인은 직접 테스트해봤는데, Qwen3-30B-A3B가 비슷한 파라미터/메모리 조건에서 여전히 최고 성능
          + Qwen3가 지금까지 평가해본 가장 인상적인 추론 모델이라는 생각
          + Mistral은 항상 다른 모델들이 더 나아서 실효성이 없었다는 평가. 단 유럽산이라는 포인트 때문에 의미부여. 성능 여부와 무관하게 Mistral 이름은 계속 회자될 것으로 예상
     * 어원에 관한 재미있는 이야기. ""mistral""과 ""magistral"" 모두 ""masterly""(명인의, 숙련된)이란 뜻에서 유래. mistral은 원래 오크시탄어에서 왔고, 지금은 영어에서 주로 지중해 바람을 가리킬 때 사용. magistral은 ""magister""의 형용사형. 관련 단어 더 찾아 도메인 확보하면 수익 기회도 가능
     * 오픈웨이트 reasoning 모델이 얼마나 더 존재하는지 궁금. 여러 모델을 한 문제에 동시에 돌릴 수 있을지 상상. 또, Small 모델을 릴리즈하고 Medium은 유료 서비스로 남긴 점도 흥미. Medium을 마치 체인처럼 Small 여러 번과 연결해 사용하는 방식도 가능할지 궁금증 제기
          + Qwen 3, DeepSeek R1, Phi-4 Reasoning이 현재로선 가장 뛰어난 오픈웨이트 reasoning 모델이라는 생각
          + 실제로는 DeepSeek 계열만 있고, distill 모델을 활용하면 일반 소비자 하드웨어에서도 구동 가능
     * 마케팅 카피 문구에 en-dash가 지나치게 많은 것이 모델 생성 결과물 스타일까지 반영된 것인지 궁금. 그렇다면 개선 필요하다는 제안
          + 실제 문구 중, Magistral이 창의적 작업에 훌륭한 동반자임을 강조하며, 필요하면 “기묘할 정도로 독특한” 텍스트도 생성할 수 있다고 주장
          + en-dash 49개, 콤마 59개로 비율이 눈에 띄게 높은 점을 수치로 언급
          + 이는 Mistral의 마케팅 스타일일 뿐, 실제 모델 생성 결과물에서 같은 비율의 en-dash 사용은 관찰되지 않는다는 분석
          + LibreOffice에서 ""-"" 입력 후 스페이스바를 누르면 종종 en-dash로 바뀌기 때문에 오해받기 싫어 일부러 수정한다는 식의 경험 공유
          + 법조계에서는 en-dash를 오히려 애정하는 문화라는 익살스런 언급
"
"https://news.hada.io/topic?id=21348","자체 호스팅과 기술 독립: 직접 만드는 기쁨","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        자체 호스팅과 기술 독립: 직접 만드는 기쁨

     * 기술 독립과 자체 호스팅의 즐거움에 대한 경험과 중요성 강조
     * 도메인 소유와 블로그 자립 운영이 장기적으로 커리어와 자기 성장에 큰 이점임을 설명함
     * 개방형 오픈소스 생태계에서 자신의 지식과 코드를 공유하며 얻는 커뮤니티와 학습의 소중함 언급
     * Homelab 구축과 다양한 자체 호스팅 오픈소스 도구를 소개하며, 구독 기반 서비스의 한계에서 벗어나 실제로 써볼 때 느끼는 자유를 강조함
     * Markdown 기반의 콘텐츠 공유와 오픈소스 정신이 소프트웨어 생태계 및 개인 역량 강화에 미치는 긍정적 영향 강조
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

들어가며: 기술 독립과 직접 구축의 가치

     * PewDiePie가 Arch Linux 설치와 오픈소스 기반 제품을 직접 만드는 영상을 보고, 저자는 자신만의 것을 만드는 자체 호스팅 및 기술 독립의 중요성을 되새기게 되었음
     * 스스로 쌓은 도메인과 블로그, 직접 관리하는 서비스들이 장기적으로 누적되는 자산이 되며, 이는 단순한 플랫폼 이동보다 큰 의미를 가짐

도메인 소유와 블로그 자체 운영의 힘

     * 새로운 글쓰기를 시작하거나 구직을 고민 중인 이들에게 먼저 자신만의 도메인 구매와 블로그 운영을 추천함
     * 플랫폼을 옮길 때마다 소중한 컨텐츠와 도메인을 잃는 일이 반복되므로, 직접 도메인을 소유하며 지속해서 같은 주소에서 콘텐츠를 쌓는 것이 중요함
     * 시간이 지남에 따라 쌓인 백링크와 오래된 게시글, 투자 내역이 장기적 신뢰성으로 연결됨

저자의 자체 호스팅 경험과 학습

     * 저자는 블로그, 두 번째 두뇌, 책, 구독 리스트 등 다양한 서비스들을 직접 호스팅하며, GoHugo, Listmonk, Memberstack 등을 활용함
     * Homelab 환경 구축, SSH, 백업, 사진 관리, Gitea, 프록시/SSL 인증서 자동화 등으로 점진적으로 기술 역량을 쌓아감
     * 처음엔 어렵게 느껴져도 과정에서 배움과 성취감이 가장 큰 보상임

오픈소스와 커뮤니티의 가치

     * 오픈소스 소프트웨어 활용 및 기여가 기술 독립을 가능하게 하며, 본인의 지식과 도구들도 GitHub에 공개함
     * 오픈소스의 경우 다양한 라이선스를 통해 모두가 자유롭게 사용할 수 있으며, 커뮤니티 피드백과 협업의 기회가 늘어남
     * 저자는 오픈소스 BI 도구 사용 경험을 통해 오픈소스 생태계에 매력을 느끼기 시작했고, 현재 대부분의 온라인 활동과 데이터 엔지니어링 글도 이에 기반함

리눅스와 Linus Torvalds

     * Linux는 전 세계 디지털 기기의 핵심이며, Linus Torvalds가 이를 상업화하지 않은 덕분에 세계적으로 널리 퍼질 수 있었음
     * Torvalds는 git도 개발했으며, 이는 전 세계 모든 소프트웨어 개발자의 필수 도구가 되었음
     * 오픈소스에 자신의 작업을 공개하면, 타인의 학습과 피드백, 기여, 연결 경험이 얻게 되어 개인의 성장뿐 아니라 커뮤니티 발전에도 이바지함

감사와 오픈소스 도구들

     * 저자가 자주 활용하며 감사하게 생각하는 몇몇 오픈소스 도구들이 있음
          + Quartz: 오픈소스 Obsidian Publish 대체제
          + GoatCounter: 익명화된 사이트 트래픽 분석 도구
          + Listmonk: 오픈소스 뉴스레터 리스트 시스템
          + listmonk-rss: 블로그 작성 시 자동 이메일 발송
     * Homelab에서 권장하는 오픈소스 소프트웨어 예시:
          + Paperless: 문서 디지털화 및 관리
          + PhotoPrism: AI 기반 자체 호스팅 사진 관리
          + Pi-hole: 네트워크 전체 광고 차단
          + Nginx Proxy Manager: 도메인 라우팅 및 SSL 자동화
          + Audiobookshelf: 오디오북/팟캐스트 서버
          + Calibre: 전자책 관리
          + Syncthing: 분산 파일 동기화
          + Gitea: 경량형 자체 Git 서비스

저렴한 장비로도 충분한 실험

     * 값비싼 최신 서버가 아니더라도, 중고 클라이언트 서버와 좋은 운영체제만으로 충분히 Homelab 구성을 할 수 있음
     * 직접 구축과 운영 과정에서 배우는 즐거움과 독립성을 중시함

기술 독립성과 플랫폼 리스크

     * 스스로 구축과 호스팅을 통해 Google, Apple 등 대형 서비스의 기능 변경, 서비스 종료 등의 리스크에서 자유로워짐
     * 자신만의 환경과 특징을 직접 설계, 수정할 수 있는 자유를 얻는 것이 Tech Independence의 진정한 이점임

마무리 및 Markdown의 중요성

     * 오픈소스 및 자체 제작, 경험 공유의 기쁨을 강조하며, 모든 솔루션과 콘텐츠 생산 기반이 Markdown으로 통일되어 있다는 점도 부각함
     * Markdown은 다양한 플랫폼 간 호환성을 보장하고, 오픈소스/지식 공유 문화의 표준 도구가 됨
     * 더 많은 데이터 엔지니어링 블로그, 두 번째 두뇌 노트, 공개 집필 중인 책 등은 모두 ssp.sh 및 GitHub에서 확인 가능함
     * 독자와의 경험 공유 및 토론을 언제나 환영함

        Hacker News 의견

     * 자기 홍보여서 좀 미안하지만, 셀프 호스팅할 때 꼭 직접 하드웨어를 새로 살 필요 없는 현실임을 이야기하고 싶음. 몇 년 지나면 Windows에서 느려서 못 쓰던 구형 노트북도 Linux 서버로는 충분히 쓸 만한 성능 제공. 집이나 주변 친구들 중에 굴러다니는 오래된 노트북 발견할 확률이 높고, 나도 2011년산 i3 노트북으로 두 명이서 잘 사용 중이며 2025년이 되는 지금까지도 업그레이드 필요 없어 보임. 노트북은 대기 상태에서 전원 효율도 좋아서 장기적으로 보면 데스크톱보다 더욱 합리적 선택. 셀프 호스팅 초보에게 노트북이 훌륭한 첫 서버 후보라는 생각. (참고로 노트북엔 UPS가 내장되어 있지 않으니, 24시간 꽂아놓고 쓸 거면 반드시 배터리를 분리 추천)
       오래된 하드웨어 재활용 관련 글
          + 지금 이 글도 13년 된 Acer 노트북에서 Linux Mint XFCE로 작성 중임을 고백. 오래된 기기 버리기가 항상 아까워서 새 노트북 산 후에도 거실 TV에 HDMI로 연결하고 $25짜리 Logitech K400+ 무선 키보드/트랙패드로 세팅해둔 상태. 웹 서핑, YouTube, Netflix 모두 무리 없이 사용 가능하고, 가끔 작업할 때 VS Code나 Thunderbird 열고 사용, 심지어 Steam에서 인디 게임도 게임패드로 무리 없이 구동 가능. Framework 노트북이 우리나라에도 들어오면 이런 재활용 환경이 한층 더 늘어날 듯 아쉽게도 내 나라는 아직 배송 안 됨
          + 우리 동네(스웨덴의 250세대 아파트 단지)에서는 사람들이 전자 쓰레기장에 구형 컴퓨터를 버리는 일이 일상. 마치 Mad Max 영화의 캐릭터처럼 개 산책 나갈 때마다 매일 여러 번 스카우트함. 여러 대로부터 부품 조합해서 debian 깔고 docker 컨테이너 돌려 갖가지 용도로 사용. 이렇게 만든 Frankenstein 서버를 부모님, 사촌, 친구들에게도 선물한 적 있음. 사람들이 얼마나 쓸 만한 기기를 버리는지 놀라울 정도. 비밀번호 없는 노트북도 심심찮게 보이는데, 윈도우 로그인하면 온갖 가족 사진 가득함. 가끔 잠금 해제된 5년 전 쯤 모델 아이폰도 발견. 참 묘한 세상이라 생각할 수밖에 없음
          + 집에 Mac-Mini 2012년식 모델도 한 대 있음. 선물로 받은 거라 Mac으로 갈아탈 생각은 없었고 강력하진 않지만 성능은 준수함. 작년 크리스마스에 부팅했는데, 기본 OS로도 너무 느렸고 macOS 업데이트하니 사용 자체가 불가능해짐. YouTube 따라 SSD로 바꾸고 Debian 설치, CasaOS(웹 기반 홈서버 OS/UI) 올린 뒤로는 Wireguard로 외부에서 접속해 Navidrome으로 음악 스트리밍 쓰는 환경 구축. Docker 개념은 아직 잘 모르겠지만 PATH 매핑 등 다양한 걸 배우는 중
          + 중고 시장에서 쇼핑하는 게 꺼려지지 않는다면, 나는 요즘 Threadripper 3세대 32코어/64스레드, 256GB ram, 2x10G, 2x2.5G, 전용 IPMI 관리 1G 인터페이스, 64 PCIe gen 4 lane 갖춘 Proxmox 노드를 2,000유로 미만에 구축 중
          + RAID6/RAIDZ2 미만의 셋업에서는 꽤 큰 데이터 손실 위험 존재. 대부분의 노트북은 SATA/M.2 포트 부족으로 페리티 구성 자체가 안 되니까, RAID 수준의 내결함성 원하면 결국 새 하드웨어 필요. 백업은 최소 2개의 물리적 위치로 분산해야 한다는 원칙을 지킨다면 이중으로 갖추는 게 가장 이상적
     * 셀프 호스팅하고 싶은 이유도 이해하지만, 하기 싫은 마음도 충분히 이해함. 셀프호스팅은 번거로운 일로, docker 업데이트도 해줘야 하고, 뭔가 고장나면 나만 해결해야 하며, 설령 잘 되어도 매끄럽다기보단 살짝 어설픈 느낌 받는 경우가 많음. 지금은 잘 동작해 내 시간을 아껴주는 self hosted 툴 리스트가 아주 적은데(첫 번째는 firefly), 셋업하다가 깨지고 결국 포기한 경우가 많았음. 요즘은 프라이버시 존중하고 가격도 괜찮은 회사 제품은 그냥 돈 내고 씀
          + Docker가 문제의 원인이라 생각. Docker는 스토리지, 네트워킹 등에 불필요한 간접 계층을 추가하고, 보안 등 업데이트하려면 컨테이너 재빌드가 필요하거나 남이 해주길 바라야 하니 힘듦. 가능하다면 업스트림 OS 패키지나 단일 바이너리(go 기반 프로젝트에서 종종 보임) 형태로 배포 가능한 서비스를 고수하면 장기적으로 더 쉽게 운용 가능
          + Docker를 왜 꼭 업데이트해야 하는지 의문. 내 경우 1년 넘게 Docker는 업데이트 없이 운용 중. 도커 이미지 업그레이드는 한 달에 15분 남짓 투자하고 끝. 그리고 프라이버시 존중하는 기업은 극히 드물고, 해를 거듭해 독자적 정책을 고수하리라는 신뢰는 어렵다는 점이 실상
          + 프라이버시 존중하고 가격 좋은 회사를 찾기조차 극히 어려운 상황
          + 어떤 프로젝트에서 문제를 겪었는지 궁금. Docker Compose까지 제공하는 수준에 오르면 거의 대부분 문제없이 동작하는 경험했음. 그리고 거의 모든 회사가 언젠가는 신뢰를 배반한다 생각. 그래서 굳이 그럴 기회조차 주지 말자는 것. 나는 Home Assistant를 셀프호스팅 중인데, 이 회사는 유저에게 불리하게 운영되지 않게 법적으로 장치까지 마련했다는 점이 독특함
     * 필요한 것 대부분을 셀프호스팅하지만, 최근에 진짜 위기가 찾아온 경험은 인터넷이 간헐적으로 끊겼을 때임. 스스로 이런 질문을 하게 됨
          + 인터넷 없이 얼마나 생산성 유지 가능한가
          + 무엇을 놓치게 되었는가
            결론적으로 더 많은 문서 아카이빙이 필요하다는 사실과, NixOS는 캐시 서버를 직접 두지 않으면 오프라인에서 활용이 거의 불가 - 그 점은 매우 불편함. 결과적으로 인터넷 없이도 내가 필요한 것의 대부분을 셀프호스팅하고, 그 환경에서 오히려 생산성이 매우 상승했다는 도전 결과 발견
          + ""devdocs""를 직접 호스팅하고 리눅스용 zeal(오프라인 문서 뷰어) 써보니 오프라인 문서 문제 상당 부분 해결.
            devdocs github
            zealdocs 공식페이지
          + 다운타임이 있을 때마다 내 시스템 약점을 새로운 기회로 삼음. 어쩔 수 없이 upstream의 문제로 이런 상황을 못 피하면 어쩔 수 없지만, 대응책이 있는 상황에는 코스트-확률 균형 맞추는 시나리오 세우고 그 작업 자체가 재밌게 느껴지는 성향
          + 나는 이 오프라인 추구를 최대치로 밀어붙여 본 경험자. 인터넷 완전 단절 시기가 내 작업 생산성 최고치를 기록하는 순간이었음. 전체 웹사이트 wget으로 재귀적 저장하는 bash alias 가지고 있고, yt-dlp로 원하는 동영상 저장, Kiwix로 위키피디아 전체 오프라인 사본 보유, 이메일도 로컬 저장에 오프라인 작성 메일 큐잉 지원, SingleFile 확장으로 개별 페이지 저장도 효율적, Zeal은 오픈 소스 문서 브라우저로 추천할만한 툴
          + ""NixOS는 자체 캐시를 안 두면 오프라인에서 쓸 수 없다"" 문제에 공감. 패키지 매니저 쓰는 소프트웨어라면 캐시나 저장소 백업이 꼭 필요. 의존성 트리 끝단의 모든 개인들이 제 역할을 계속 해줘야 시스템이 온전히 작동한다는 점, 이게 요즘 소프트웨어 개발 방식에서 가장 불안한 지점. 최종 사용자 소프트웨어 쓸 땐 모든 의존성 포함된 개별 패키지가 훨씬 낫다는 입장. 어차피 실제 하드에 저장되는 건 그런 형태
          + Kiwix(위키피디아 오프라인 솔루션)과 다양한 jellyfin 셋업은 강력한 오프라인 리소스. 그런데 NixOS, Gentoo 등의 배포판은 지속적으로 인터넷 연결을 요구하는 경향. 전체 패키지 미러링은 현실적으로 거의 불가능
     * ""먼저 도메인을 사라""는 조언에 대해, 사실 도메인이라는 건 빌리는 것이지 진짜로 살 수 있는 게 아님. 결제 한 번 빠지면 바로 내쫓기는 구조라 무섭기까지 함. 이런 온라인 정체성의 덧없음이 슬플 정도
          + ""도메인은 빌리는 것뿐이다""라는 부분, ICANN이 승인하는 루트존/레지스트리만 쓴다면 그렇지만, 나는 실험적으로 나만의 레지스트리를 만들어 타인과 공유하지 않는 커스텀 루트존을 수년간 직접 운영. 커스텀 TLD는 도메인 이름에 전 세계 모든 제품/서비스 분류 체계를 담는 역할도 실험했고, ICANN TLD의 모호함과 부적절함을 직접 체감
          + 이건 일종의 기술적 한계. 내 모든 기기(즉, 도메인명 소비자)들이 특정 공개키로 서명된 걸 “XorNot.com”으로 인정하라고 세팅하면 시스템 대체도 가능. 기술적으로 더 많은 지원만 받으면 “신뢰할만한 키-이름 목록”으로 지금 구조 전체를 교체해버릴 수도 있다고 봄
     * 셀프호스팅용 툴 생태계 큰 발전 느끼는 시대. 처음엔 호스팅된 컴포넌트로 시작해 각 요소를 하나씩 셀프호스트로 교체 가능. 내 블로그도 집 서버에 셀프호스팅.
       앞단엔 Cloudflare Tunnel 쓰지만 전엔 nginx+letsencrypt+public_ip도 해봤고, 데이터 저장소도 Cloudflare R2, S3, 또는 로컬 NAS로 다양하게 교체 가능(FUSE 거치면 접근 방식도 동일).
       반면에 반드시 빌려야 하는 자원은 도메인(구매처럼 보여도 임대에 불과), 인터넷 연결 정도뿐이고, 나머지 요소는 대부분 선택적으로 쓸 수 있는 시대. 물론 서비스 끄면 불편해지지만 기본 동작은 유지.
       예전에 비해 정말 엄청 쉬워진 시대. 90년대~2000년대 초반엔 상상도 못할 도구 환경.
       단, 이메일 스팸 방지 조건만 아주 까다로워진 게 단점. 8년 전까지 내 메일도 직접 운영했지만, 지금은 G Suite 사용 중
     * 나는 “셀프호스트 할 것인가”가 아니라 “셀프호스트 할 수 있는 능력” 자체가 요점이라고 생각. 기술이 부족하거나 비용을 지불하고 싶을 때 남에게 맡길 수도 있다는 관점이 포용적. “돈 내면 되지” 하는 사람들이 장기적으로 실제로 가장 큰 리스크를 맞이함. 요즘 비즈니스는 장기적인 기술 의존도를 인질 삼아 기획적으로 고객을 포획함. FOSS에 관심 없어도, 벤더 이전 가능성은 정말 중요한 문제라는 인식. 락인 되면 언제라도 불합리한 이용 당할 수 있다는 부분 강조. 이런 구조로만 사고하는 회사도 많음
          + Bluesky에서 말하는 “credible exit(믿을만한 퇴출 경로)”가 이와 약간 비슷한 개념 언급.
            Zulip을 오픈소스, 자가 호스팅, 클라우드 서비스, 상호 이전 모두 지원하는 서비스로 높이 평가
     * 개발자가 넘쳐나고, AI로 집에서 생성 가능한 코드 품질이 천차만별로 늘어나는 시대라면, 셀프호스팅도 확실히 트렌드가 될 수 있음
     * 리눅스 기초만 배우면 굳이 필요한 게 아니어도, “내 서비스를 직접 돌린다”는 쾌감과 성취가 있어서 셀프호스팅의 매력 느끼는 사람 많음.
       더 큰 효과는, 완전히 의존 중인 플랫폼에서 내가 이유 없이 쫓겨날 수 있는, 현실적인 리스크 제거 효과. Gmail 계정까지 날리면 “일반인”들은 계정 속 온라인 신상, 패스워드 리셋, 심지어 앱 로그인까지 다 막혀서 곤란에 빠질 수 있음. Hacker News에도 Gmail 계정 날리면 인생 곤란할 사람 분명 존재할 것. 그러니 최소한 이메일 아이덴티티는 내 소유여야 한다는 입장. 이 원칙을 웹호스팅, AWS, Spotify, Netflix 등 모든 온라인 서비스에 반복 적용해야 하고, “새 클라우드 호스트로 대체” 정도로는 문제 해결 안 됨.
          + 이메일 서버 설치는 정보도 많고 쉽지만, 직접 운영하는 과정(특히 호환성 문제나 장애 대응 등)에 관한 자료가 잘 없음이 개인적 아쉬움. 예를 들어, 구글이 내 서버를 블랙리스트에 올리면 누구에게 연락해야 하는지, 에러 메시지에 대처 절차가 있는지 등 실전에서는 도움 받을 곳 부족. 글로벌 IP 블록 등 외부의 불합리한 요소에 제대로 대응하는 방법 설명서가 필요. DKIM, DNS 같은 프로토콜 문제가 아니라, 실제 서비스 운영에서 부딪히는 타 사업자 대응책 가이드라인이 필요
          + 도메인은 직접 소유해서 원하는 이메일 제공업체에 붙인 뒤, 문제가 생겨도 바로 다른 곳으로 옮기면 됨. 도메인 자체는 저렴하고, 이메일 제공사 자체의 고유 이메일은 절대 쓰지 않는 게 정답.
            그리고 이 원칙은 직접 이메일 서버를 운영하든, 상용 서비스를 이용하든 마찬가지. 둘은 별개 문제
          + 리스크가 실제로 크고, 위험은 명확하지만 정말 다수에게 발생하는 리스크인지는 의문. 초기 Gmail 이용자 대다수가 채택한 이유는 기존 대안들의 품질 저하가 컸기 때문. ISP 메일, 대학/직장용 메일 등은 필요하면 언제든 계정 없어지는 구조였음. self-hosting이 문제를 “부분적으로” 해결할 수 있지만, 보안 유지 능력이 없다면, 자기가 직접 관리하는 메일서버라도 완전한 통제권 못 가짐. 도메인 갱신 등 신경쓸게 많고, 결국 신경 안 쓰면 여기서도 계정 날아감. 나는 Gmail 등 소수의 대형 사업자가 왜 이렇게 인기 있는지 이해하는 편. 대부분의 사람에겐 단기적으로나 중기적으로나 여전히 이 선택이 낫다는 현실
          + 집에서 self-hosting할 때, HDD가 고장날 확률과 Gmail 계정을 잃을 확률 중 어느 게 더 큰 위험인지 자문. 직접 호스팅 시작하면 장비 공간, 백업 기획, 업데이트 관리까지 신경 쓸 게 급격히 늘어나고, 업데이트/백업 진행 중 정전까지 고려하면 결국 UPS도 도입해야 함. 그런데 내 경우 UPS가 불량이어서 NAS 하드 드라이브까지 망가져버린 경험. 결국 할 일이 너무 많아져서 일상에 집중할 시간 줄어듦
          + self-hosting은 오히려 중요한 리스크를 초래할 수 있다는 입장. 로컬 private key나 메인 이메일 도메인 잃으면 복구 불가. 2FA와 계정 복구는 외부 제공 서비스가 훨씬 편리. self-hosting 자체를 반대하는 건 아니지만, 대부분 사람에게는 계정 복구 가능성을 확보하는 쪽이 훨씬 안전한 길이라는 의견
     * Arch 리눅스 공식 설치 프로그램 등장 이후로, 더 이상 어렵다고 말하기엔 무리가 있다고 생각. 여전히 커맨드라인으로 진입하지만, 예전처럼 복잡한 파티션 블록 계산에 머리 싸매야 했던 시절에 비하면 훨씬 쉬워진 현실
     * 집에서 Kubernetes 4노드 pi 클러스터와 Intel N150 미니 PC를 Portainer로 함께 관리 중.
       오픈소스 운영 도구 중 아래 툴들 덕분에 작업 생산성에 큰 변화 체감(전부 컨테이너 환경에서 동작)
          + kubetail: 클러스터 전체 K8S 로그 뷰어. Helm chart로 설치. 매우 강력 추천
          + Dozzle: N150 미니PC(여기에선 Kubernetes 대신 Docker만 사용) 도커 로그 뷰어. Portainer로 수동 설치
          + UptimeKuma: 서버, http/https 엔드포인트, PostgreSQL 등 모니터/알람 전용. Portainer로 수동 설치
          + Beszel: 서버 cpu, 메모리, 디스크, 네트워크 및 도커 컨테이너 모니터링. Helm chart/K8S 또는 Portainer로 수동 설치
          + Semaphore UI: ansible 플레이북의 일정 실행 및 UI 지원. Portainer로 수동 설치
"
"https://news.hada.io/topic?id=21305","구글, 안드로이드 사이드로딩 제한","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           구글, 안드로이드 사이드로딩 제한

     * 구글이 최근 안드로이드 앱 사이드로딩 제한 정책을 시행하며, 사용자의 디지털 자율성과 모바일 생태계의 개방성에 대한 논쟁이 확산됨
     * 싱가포르의 시범사업에서 웹·메신저·파일매니저로 받은 앱 중 민감 권한(SMS, 접근성 등) 요청 앱의 설치를 차단하는 등 규제 강화
     * Play Integrity API 도입으로 개발자가 사이드로딩 앱의 기능 제한 가능, 구글 플레이스토어 중심의 폐쇄적 분배 구조를 강화
     * 이런 조치가 보안 강화에는 기여할 수 있으나, 혁신과 경쟁을 약화시키고, 안드로이드의 개방성 약화를 초래한다는 비판 대두
     * Purism은 PureOS와 Librem 5 등 오픈소스·프라이버시 중심 모바일을 대안으로 제시, 사용자의 데이터 주권과 자유로운 앱 설치 환경을 보장함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

구글의 안드로이드 사이드로딩 제한 도입

     * 구글은 최근 보안 문제를 이유로 안드로이드에서 사이드로딩 앱에 대한 새로운 제한을 적용하기 시작함
     * 싱가포르에서의 시범 정책은 사이버 보안 기관과 협력하여 도입되었으며, 특히 SMS 접근 권한이나 접근성 서비스 등 민감 권한을 요청하는 앱 설치를 웹 브라우저, 메시징 앱, 파일 매니저를 통해 제한하는 방식임
     * 이 조치는 사기 및 악성코드를 통한 범죄를 방지하는 데 목적이 있음

Play Integrity API와 앱 스토어 종속성

     * 구글은 Play Integrity API를 도입함으로써, 앱 개발자가 앱이 사이드로딩 되어 있을 경우 일부 기능 제한을 둘 수 있도록 함
     * 이러한 정책은 사용자들이 구글 플레이 스토어를 통한 공식 경로로만 앱을 설치하도록 압박함
     * 표면적으로는 보안 강화 목적을 내세우지만, 실제로는 안드로이드 생태계에 대한 구글의 통제 강화로 이어짐
     * 이에 따라 디지털 자율권, 혁신, 사용자 권리에 대한 우려가 다시 제기되고 있음

비판 및 영향

     * 비평가들은 해당 정책이 악성 앱 차단 효과는 있지만, 동시에 경쟁 제한 및 사용자 선택권 축소 문제를 지적함
     * 안드로이드 특유의 플랫폼 개방성과 사이드로딩 자유가 약화되며, 결국 Apple iOS의 폐쇄적 생태계와 유사한 방향으로 변화함
     * 이러한 흐름이 혁신 저해와 앱 유통 독점으로 이어질 가능성이 있음

Purism의 대안: PureOS와 Librem Phone

     * Purism은 점점 심화되는 감시 및 기업 지배에 대응해 프라이버시 중심의 해법을 제시함
     * PureOS는 Debian 기반 리눅스 운영체제로, Librem 5 및 Liberty Phones에 탑재되어 완전한 사용자 자율성과 데이터 주권을 보장함
     * 이 환경에서는 타깃 광고, 데이터 마이닝, 중독성 알고리듬, 행태 조작을 사용하지 않는 오픈소스 보안 앱만 지원함
     * 사용자는 기업 앱스토어나 침해적인 API에 의존하지 않아 더욱 투명하고 안전한 컴퓨팅 경험을 누릴 수 있음

결론: 오픈 대안의 중요성

     * 구글이 안드로이드 생태계를 더욱 폐쇄적으로 전환하는 가운데, Purism은 윤리적, 안전, 개방적인 모바일 컴퓨팅 환경을 지향함
     * 사용자 주권과 프라이버시에 초점을 맞춘 대안이 기술 업계 및 개발자에게 중요한 선택지로 부상함

   사실 사이드 로딩은 ""신뢰할 수 있는 서명자 체계""만 넣고 이걸 디지서트 같은 서드파티 인증자한테 개방하면 최소한 믿을 수 있는 APK인지 확인이 가능합니다. 문제는 구글이 이걸 플레이 스토어에 일임하는 식으로 만들어 놨죠. 근데 구글 플레이 스토어가 악성 앱을 잘 잡냐 하면 글쎄고, 구글 플레이 방침에 어긋나는 앱은.......

   글 자체는 의도가 의심이 되는 글이지만 실제 사용 시에 점점 귀찮아지고 있는 것은 사실이죠.
   이미 갤럭시 기기에서 악성 의심 앱 차단이니 하는 기능을 끌 수도 없게 만들어 뒀더라구요. 우회법은 있지만 점점 이런 규제를 추가하고 있습니다.
   라이트 사용자들은 사이드로딩을 거의 사용하지 않고 악성 코드 실행을 막을 수 있으니 좋은 기능일 수 있지만 적어도 끌 수는 있게 해야 하는 것 아닌가요?

   픽셀이 정발되기를 원하고 있었는데 구글도 비슷한 일을 한다면...

        Hacker News 의견

     * 이런 시점에 블로그 포스트를 올린 게 참 이상한 타이밍이라는 감정 표현, 혹시 몇 달 전에 준비한 글을 이제야 공개한 건 아닌지 의문 제기, 이 파일럿 프로그램은 1년 4개월 전에 싱가포르에서 발표된 내용이라는 사실 공유, 대상은 싱가포르 한정 및 특정 권한(예: RECEIVE_SMS, READ_SMS, BIND_NOTIFICATIONS, 접근성 권한)이 필요한 앱, 앱스토어 외부에서 직접 다운로드한 앱만 해당, F-Droid나 adb로 설치는 괜찮은 방향이라는 정보 제공, Play Protect 기능을 끄면 우회를 시도할 수 있지만 실제로 싱가포르에서 적용 가능한지는 본인도 모름, 참신하게도 Google은 통화 중에는 Play Protect를 끌 수 없게 막았고 이런 조치는 현명한 판단이라는 칭찬, 싱가포르 경찰 발표에 따르면 이런 접근 방식이 실질적인 효과를 잘 내지 못했다고 밝히는 내용 인용, 피해자들이 APK 파일 설치 전
       Google Play Protect를 끄도록 안내받고, VPN 앱까지 설치함으로써 사기범들이 은행 방지 기술을 우회한다는 사례 설명 링크 제공(https://police.gov.sg/media-room/news/…)
          + 싱가포르 사람들이 사기에 특히 취약하다는 데이터 언급, 지난해 수만 명이 피해를 입고 총 11억 싱가포르 달러를 잃었고 이는 전년 대비 70% 증가 수치라는 점, Global Anti-Scam Alliance 통계에 따르면 실제 신고된 피해보다 더 많을 것이라는 경험 공유, 왜 싱가포르가 표적이 되는지 그 배경에 부유함, 디지털화, 규정 준수 문화가 있다고 설명(https://archive.is/fCmW1)
          + Purism 블로그 글이 왜 지금 나왔는지 불명확하다는 의견, 단순히 마케팅 목적의 FUD(공포, 불확실성, 의심)일 뿐이라고 생각한다는 점, PureOS기반 Librem 5와 Liberty Phones를 직접적으로 언급하며 그들이 APK를 실행할 수 있는지 의문, Sailfish만이 이런 기능 제공하지만 라이선스 이슈로 예외적이라는 의견 추가, Purism이 Phosh 등 터치 기반 리눅스 개발에 많은 투자를 하는 것은 인정하나 리눅스 터치 환경 자체가 아직 매우 열악하다는 점 강조, 이 글이 직접적인 영향을 받는 상황이 아닌데도 메인스트림 대안을 나쁘게 묘사해서 자사 제품 마케팅에 활용하려는 의도라고 생각
          + Google이 App Store 관련 소송에서 불리한 판정을 받기 전후의 시기 구분이 중요하다는 의견 제시, 이용자가 스스로 보호받으면서도 자유를 누릴 수 있는 균형이 어렵다는 점 강조, 사용자들이 보안 경고에 익숙해지면 결국 무시하게 된다는 현상을 언급, Play 스토어도 완전히 안전하다고 보기 힘들며, 공개된 안드로이드 사용자 GPS 데이터조차도 공식 앱의 악의적 행위를 보여준다는 주장, 결국 취약계층 이용자를 위해 똑똑하고 신뢰할 수 있는 제3자가 기기 관리자 권한을 갖는 것이 대안이라고 생각
     * 글이 푸짐한 내용 없이 Purism 광고에 가까운 느낌이라는 의견
          + 광고라는 사실을 깨닫자마자 모든 내용을 무의미하다고 판단했다는 의견, 더 좋은 링크가 필요하다는 요청
          + 업보트 수로 미루어볼 때, 많은 사람들이 Android 방향에 대한 우려와 대안에 대한 관심을 갖고 있다고 생각
     * 이번 이슈가 2024년 것 아니었는지 의문 제기(https://techcrunch.com/2024/02/…)
     * 싱가포르에서 처음 도입된 파일럿 프로그램에 대해, 특정 권한(SMS, 접근성) 요청 앱을 웹브라우저/메신저/파일관리자를 통해 설치할 경우에만 차단 대상이라는 설명, 세부 조건이 많아 고급 사용자는 여전히 원하는 앱을 설치할 수 있을 것이라는 관점, 평균 사용자는 SMS/접근성 권한 앱의 위험한 사이드로딩을 쉽게 못하도록 의도한 조치라는 분석, 싱가포르 사이버 보안청과 협력해 사기 및 맬웨어 방지를 위해 시행 중이라는 점 강조, 싱가포르 한정 적용 이유 설명
          + 이런 제약이 실제로 대중 시장에서 반경쟁적으로 작용할 수 있음을 지적, 기술에 밝은 소수는 설치가 가능해도 대다수는 Google이 통제하는 ‘울타리’ 안에서만 머물며, Google이나 Apple이 제3자 앱에 대해 사용자에게 겁을 주는 언어를 사용하는 등 이러한 심리적 장치까지 써가며 장벽을 만든다는 점 강조, 이런 행위가 규제를 통해 없애야 할 ‘마인드 컨트롤’이라고 주장
          + ""싱가포르 한정""이 그렇게 안심을 줄 만한 사유가 아니라고 강조, 브라우저/파일관리자는 평범한 파일 이동 수단이기 때문에 이런 조건도 별로 신뢰가 안 간다는 의견 표시
          + ADB 차단까지 이뤄지지 않는 한 “사이드로딩 차단”이란 표현이 정확하지 않다는 분석, 결국 맬웨어로부터 이용자를 보호하는 것과 원하는 앱 설치 자유를 보장하는 것 사이의 균형잡기가 필수적이라는 입장
          + 싱가포르 클라이언트와 거래할 때 SingPass(국가 디지털 신분인증 시스템) 연동 요구받았던 기억을 공유, 지금은 더 이상 고객이 아니지만 코드베이스 어딘가엔 남아있는 상황
          + 지역 추가는 언제든 가능하므로 싱가포르 한정에 방심하면 안 된다는 입장, 오히려 Google이 앱에게 ‘가짜 권한’ 부여 기술로 나아가는 것이 나을 것이라는 대안 제시, 그렇지 않으면 범죄자들이 다른 방법으로 우회할 것이라는 주장
     * 댓글에서 화제가 된 ‘사이드로딩은 GrapheneOS 설치로 해결’이라는 주장을 언급하며, 대부분의 일반 이용자와 괴리된 답변이라는 점을 지적, HN 유저들은 하드웨어 디버깅까지 가능하지만 보통 사람들은 그런 시스템 수준 설정은 불가능하다는 현실 상기
          + 한때 리눅스 포럼에서 복잡한 CLI를 당연하게 여기는 답변 때문에 당황했던 경험 공유, 간결하고 쉬운 솔루션을 원하는 초보자들에게 전문가 집단의 편향된 시선이 오히려 보급·확산을 방해할 수 있음을 지적
          + 대부분 사람들이 ‘평균적’ 경험을 제대로 알지 못하는 경향이 있다고 진단, 전문가 커뮤니티에선 더욱 이 관점의 왜곡이 커져서 실제 대다수 사용자의 실정과 먼 의견이 나온다고 생각
          + 일반인들은 대체로 사이드로딩을 하지 않으며, 필요한 앱을 한번 설치한 후 계속 반복적으로 동일한 앱만 사용하는 경향이 많다는 분석
          + 일반인이 SMS 또는 접근성 권한을 요구하는 사이드로딩 앱의 진위를 구별하지 못하는 현상을 지적, 결국 이런 기능에 대한 차단이 ‘일반인 오용 방지’가 핵심 목적임을 강조
          + Google이 DRM 기술 및 API를 추가하면서, 앞으로 GrapheneOS 설치마저 현실적 대안이 아니게 될 것이고, 그렇게 되면 Android 생태계 자체에서 이탈해야만 대안 OS 사용이 가능해지는 현실에 대한 우려
     * 본인은 '내 폰 소유자니까 뭐든 자유롭게 하고 싶다'는 주의였지만, DJI 드론 및 Air Units 이용 시 강제로 앱 사이드로딩을 유도한다는 점이 충격적으로 다가왔다고 고백, DJI 측이 플레이스토어에 올리지 못하는 이유는 앱이 자기코드 변조(셀프 모디파이)를 할 수 있어서라는 사실 소개, 정치적 갈등이 생길 경우 국가지배 악성코드가 내 드론을 마음대로 통제할 소지가 있어 위험성을 경고, 수백만 명이 사태를 제대로 인식하지 못한 채 앱을 설치했다는 점 강조
          + 이런 문제의 해법은 Google의 악성코드 검사 시늉이 아니라, DJI 앱이 실제로 할 수 있는 권한/기능에 대한 더 강한 통제 수단 도입이라는 주장, Google의 주된 동기는 사실상 ‘보안’이 아닌 통제력 확대라는 시각
          + 이런 맥락에서 진짜로 ""내 마음대로 하고 싶다""는 자유는 소프트웨어도 적용 대상이어야 한다고 믿음, Richard Stallman이 1988년에 주장한 ""소스를 받아 직접 바꿀 수 있는 자유""가 오늘날까지 시의성이 있다고 평가, 현실은 오히려 소프트웨어가 사용자를 통제하는 쪽으로 가고 있다고 개탄, 국가정부가 소프트웨어 코드를 지배하면 소비자 권익 침해를 넘어 더 심각한 위험이 발생한다는 주장
          + 실제로 각국 정부는 OEM을 통해 이 기능을 이미 집어넣고 있다고 분석, 사이드로딩 차단은 해커가 이런 내장 악성코드 비활성화 방해만 가능케 할 뿐이라고 평가
          + 앱이 자가변조 한다는 것은 큰 의미 없으며, 사실 V8 엔진을 앱에 내장시키면 얼마든지 코드 변화가 가능하다는 사례 제시, 그럼에도 구글은 이런 방식에 문제를 삼지 않는 아이러니 지적
          + DJI 드론 앱의 위험성에 경계를 나타낸 원 댓글이 비추천 받는 이유를 모르겠다는 의문, 최근 중국산 태양광 패널에서 실제로 킬스위치가 발견된 사례를 예로 들어, 정부와 밀접한 중국 업체들이 자신들의 하드웨어/소프트웨어에 의심스러운 기능을 탑재할 수 있다고 주장(https://reuters.com/sustainability/climate-energy/…, https://rickscott.senate.gov/2025/6/…)
     * GrapheneOS 설치로 사이드로딩 제한을 해결할 수 있지만, 요즘 Google이 Play Integrity API를 통해 앱 기능 자체를 Play Store 설치에만 제한하는 경향 심화, GrapheneOS에서부트로더 잠근 상태로 Play Store를 사용해도 Google이 하드웨어 인증 API 사용을 막아서 은행앱, Google Wallet 등 기능이 차단된다고 지적, 보안 업데이트 지연시키는 불량 벤더는 허용하면서, 뛰어난 보안성을 가진 오픈소스 OS는 되려 배제하는 Google의 행태를 비판, Singapore Cyber Security Agency와의 공동작업이라는 점은 일종의 명분 제공에 불과하다고 봄, Facebook/Instagram 앱 등도 차단 대상에 추가돼야 할 텐데 왜 안 하는지 반문(https://localmess.github.io, https://grapheneos.social/@GrapheneOS/112878070618462132)
          + Google이 타사에게는 허술한 보안 관행을 용인하면서 진짜 목표는 안전이 아니라 통제 그 자체라고 생각
          + GrapheneOS의 가장 큰 문제는 지원 기기가 너무 적다는 점, 특정 하드웨어에 종속되지 않으면서도 어느 정도 보안성을 유지할 수 있는 대안이 필요하다는 주장
          + Android 키인증 API는 GrapheneOS에서도 지원되며, 개발자 통합 가능(https://grapheneos.org/articles/attestation-compatibility-guide)
          + GrapheneOS 설치로 해결된다는 주장에 직접적인 답변은 이미 소개돼 있으니 참고링크 제공(https://news.ycombinator.com/item?id=32496220)
     * 이 조치가 시각장애인 커뮤니티에 심각한 타격 줄 것이라는 우려 제기, Android가 인기이고 iPhone이 비싼 국가에선 Commentary(Jieshuo) 스크린리더가 TalkBack 대비 더 나은 대안인데, 중국산 개별 개발자 앱이라 Play Store엔 없다는 사실, 이런 앱은 전체 화면 읽기 및 시스템 UI 제어를 위해 굉장히 광범위한 권한 요구, 만약 민감 앱 접근이 차단된다면 애초에 스크린리더로서의 목적이 무의미해진다는 현실 강조, Google 직원들은 Webaim 통계로 사용량 낮다는 점만 갖고 문제 아니라고 할텐데 Webaim은 대부분 고소득 영어권 표본이라 글로벌 사용행태를 대변하지 못한다는 비판(https://webaim.org/projects/screenreadersurvey10/)
     * 이런 설계 의도가 오히려 합리적이고 상식적이라고 생각, ADB로 악성코드 설치가 여전히 가능하지만 진입장벽이 높아져서 일반인에겐 속도방지턱 효과, 부당하게 차별받는 대표적 사이드로딩 앱도 못 본다는 입장
          + 대표적인 대체 앱스토어도 존재하지만(예: Epic v. Google), Android의 개방성 및 사용 선택권이 강조됐던 점을 상기, ADB 이용 방식이 오히려 Apple의 sideloading 방안보다 사용자 자유에 더 제약을 주는 것 아니냐는 비판, Apple은 비난을 받았는데 이 역시 비슷한 문제라는 시각
     * 본질적으로 개인정보 권한(SMS, 접근성 등) 요청을 차단하는 것이 왜 중요한지 설명, SMS 권한만 있으면 OTP 등 모든 서비스로그인 정보를 훔치고 접근성 권한도 은행앱 등 치명적 기능 조작 가능, 싱가포르에서 신분 정보 거래가 심각해서 “모르는 사람이 전화번호 등 신분자료를 사겠다고 하면 5년형”이라는 경고문이 있을 정도, 은행계좌·신용카드 등도 마찬가지, 결국 범죄에 악용되는 신분정보는 개인과 연계되어 있기 때문에 협조 시 가중처벌 기반
"
"https://news.hada.io/topic?id=21396","Show GN: 드롭다운에서 Korea를 바로 찾아드리는 크롬 익스텐션을 만들어봤어요.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Show GN: 드롭다운에서 Korea를 바로 찾아드리는 크롬 익스텐션을 만들어봤어요.

   외국 사이트에서 회원가입할 때
   국가를 선택하는 드롭다운에서 한국 표시를 찾기 어려운 경험이 있어서 만들어 봤어요.

   South Korea인 경우도 있고, Korea South, 또는 Republic of Korea 등 다양한 선택지가 있어서 한 번에 찾기 어렵다는 문제를 해결하고자 만들게 되었습니다.

   Cursor로 크롬 익스텐션 개발하고, vO로 랜딩 페이지 만들었어요.
   사용해보시고 피드백 남겨주시면 감사하겠습니다.

   Firefox 지원 부탁드립니다!!

   파이어폭스도 추가했습니다!

   https://addons.mozilla.org/ko/firefox/addon/koreadropdown/

   네 알겠습니다! 피드백 감사합니다

   오! 파이어폭스도 지원되면 좋겠습니다. (익스텐션 거의 호환됨)

   파이어폭스도 추가했습니다!

   https://addons.mozilla.org/ko/firefox/addon/koreadropdown/

   피드백 주셔서 감사합니다!

   우측에 어떤식으로 작동하는지 보여주는거 좋네요

   감사합니다! ㅎㅎ

   왜 우리나라는 영문 표기기 이렇게 제각각이야 불평만 하면서 지냈어요 와 근데 이게 해결 가능한 일이었군요 (난 왜 이 아이디어를 못 떠올렸을까...) 감사히 잘 쓰겠습니다!

   저도 감사합니다! ㅎㅎㅎ

   히트다!

   생각도 못했네요. 일상속의 불편함을 감지하는 메타인지가 어마어마하신 분 같습니다. 행복하게 잘 쓰겠습니다!!

   소개 홈페이지를 뭘로 만드셨는지도 궁금합니다

   댓글을 이제 확인했네요! v0 사용해서 1차로 제작하고 살짝 수정했습니다.

   와. 역시 불편함은 항상 있어왔고, 아이디어는 실천해야 찾아지는 것이네요. 정말 작은 아이디어 같지만, 엄청난 편리함입니다. 감사합니다. :D

   좋게 봐주셔서 감사합니다 ㅎㅎ

   와..이걸 만들다니..ㅋㅋㅋㅋ 너무 멋지십니다!!!

   감사합니다! ㅎㅎㅎ

   console.log 찍는 코드가 남아서 개발자 도구에서 빈배열이 보여요

   수정했습니다! 피드백 감사합니다

   브라우저 내장 드롭다운 항목(그리고 이 기능을 지원하는 일부 드롭다운)이라면 알파벳 키로 빠르게 해당 알파벳 부분으로 이동하는 방법도 있습니다.

   각 페이지마다 한국을 표기하는 방식이 다르다는 함정이 있고, 심각한 경우엔 드롭다운 목록을 한국어로 보여주면서 정렬은 alphabet 표기 기준으로 해놔서 정신착란을 일으키는 경우도 있습니다

   맞습니다! 하지만 사이트마다 한국 표기가 일정하지 않다는 불편함을 느껴서 만들게 되었습니다! 의견 감사합니다! ㅎㅎㅎ

   늘 신경을 긁는 요소였는데 매우 유용할 것 같아요. 감사합니다! Pain point를 잘 잡고 개발까지 해주셨네요! 멋집니다.

   좋게 봐주셔서 감사합니다!

   사이트가 인상적이네요 잘 쓰겠습니다 :)

   저도 감사합니다! ㅎㅎ

   설치해보겠습니다. 👍👍

   사용해주셔서 감사합니다!

   프로그램도 좋지만 소개 사이트도 정말 좋았는데 역시 반응이 좋네요
   혹시 원래 프론트 개발을 하셨던 분일까요?

   감사합니다. 원래도 프론트 개발을 했었지만 랜딩페이지는 v0로 개발했습니다!

   이거 빅 히트네요

   좋은 말씀 감사합니다 ㅎㅎㅎ

   감사합니다~!

   저도 감사해요! ㅎㅎㅎ

   오 깔끔하고 좋네요

   의견 남겨주셔서 감사합니다!

   멋있어요...!

   부끄럽지만... 멋있게 봐주셔서 감사합니다 ㅎㅎ

   진짜 간단하게 삶의 질을 올려주는 최고의 확장이네요 ㅋㅋㅋ 짱입니다.

   좋은 말씀 감사합니다! ㅎㅎㅎ

   원래 Find Korea from Dropdowns 플러그인을 쓰다가 크롬 플러그인이 바뀌면서 더이상 못쓰고 있었는데 이제 이걸 쓰면 되겠군요 감사합니다!

   저도 감사드려요! ㅎㅎ

   오 너무 좋습니다

   감사합니다~! ㅎㅎ

   정말 유용한 익스텐션!

   감사합니다 ㅎㅎㅎ!
"
"https://news.hada.io/topic?id=21421","영수증 프린터가 내 미루는 버릇을 고쳐줌","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         영수증 프린터가 내 미루는 버릇을 고쳐줌

     * 게임처럼 몰입하며 일은 미루는 패턴을 ADHD 관점에서 분석하고, 게임의 피드백 루프 원리를 일상 태스크 관리에 적용해 미루기를 극복한 경험을 소개
     * 포스트잇+투명 병으로 즉각적 피드백을 강화하고, 더 나아가 영수증 프린터로 일과 습관의 준비 과정을 자동화해 일관된 생산성을 유지함
     * 반복적이고 구체적인 미시 태스크 분할, 피드백 강화, 아침 루틴의 자동화, 프린터+커스텀 앱 조합 등 실제 실천법과 ADHD 당사자의 시행착오 노하우를 구체적으로 제시
     * 태스크의 실체화(손에 잡히는 일감), 반복 루프, 시작 허들을 낮추는 전략이 미루기 극복에 핵심적임을 경험적으로 검증함
     * 기존 할일 앱보다 더 빠르고, 계층적이며, 직관적인 커스텀 UX가 필요
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

왜 게임은 몇 시간이고 몰입하는데 이메일은 미루는가?

     * 게임(특히 FPS)의 핵심은 ""빠르고 반복적인 게임 루프"" + ""즉각적이고 강한 피드백""
          + 예: Aim → Shoot → Hit/Fail → 소리/시각적 반응 → 즉각적 보상(도파민)
          + 루프가 자주 반복되고, 시작도 매우 쉬움
     * 피드백 루프와 작은 보상이 집중과 몰입의 핵심
     * 주요 포인트:
          + 루프 반복이 잦을수록 중독성↑
          + 피드백이 클수록 몰입도↑
          + 시작이 쉬울수록 진입장벽↓

게임 루프를 일상 태스크에 적용하는 법

     * 현실 속 ""게임 루프"" = 태스크를 작게 쪼개고 반복적으로 완료
     * 미루는 정도가 심할 수록 더 미시적(sub-2~5분) 태스크로 분할 필요
          + 예: 집 청소 → 방별/작업별로 쪼개기 → 2~5분짜리 작업 단위
     * 포인트:
          + 할수록 더 쪼갤 것, 동기부여 안 될수록 더 쪼갤 것

피드백 강화: 포스트잇+투명 병 시스템

     * 각 태스크를 포스트잇에 작성 → 완료하면 구기고 투명 병에 던짐
          + 손으로 만지고 소리 내며, 눈에 보이는 ""진행상황"" 자체가 강한 피드백이 됨
          + 실물화(실체화)된 태스크는 무시하기 힘듦
     * 요약:
          + 포스트잇 활용 → 태스크의 실체화
          + 구기고 버리기 → 즉각적 피드백
          + 투명 병에 담기 → 시각적 진척

쉽게 실천하는 요령: 아침 루틴의 자동화

     * 가장 쉬운 습관부터 시작(예: 커피 내리기, 타자 연습 등)
          + 아침 첫 태스크는 반드시 쉽게 성공할 수 있는 것으로 준비
          + 매일 아침 10개 이상의 짧은 습관을 완료해 '관성'을 만듦
     * 전날 밤에 태스크 준비: 아침에 바로 시작 가능, 준비 시간 절약

유연하게 활용하기

     * 처음 태스크 3~5개만 뽑아 시작,
       중간에 집중 흐름이 깨지면 다시 포스트잇으로 재집중
     * 분할이 어려운 작업은 시간 단위로 쪼개기(예: ""10분 청소"")
     * 한 번에 모두 처리 못하는 일(예: 수천 개의 이메일)은
       ""매일 신규+이전 N개 처리""로 분할
     * 하루 종일 포스트잇 없이 일한 경우도, 오히려 플로우 상태이니 OK

실천 독려

     * 더 이상 읽기만 하지 말고,
       내일 태스크를 직접 포스트잇(혹은 종이+가위)로 만들어 바로 실행할 것
          + 투명 병 대신 일반 컵도 가능
     * 2~3주간 계속 반복, 습관화
     * 포인트:
          + 자잘한 루프 반복 → 게임처럼 동작
          + 아침 루틴 → 성공 관성, 동기부여 강화
          + 실물화/피드백의 결합

영수증 프린터의 도입: 시스템의 자동화·확장

     * 포스트잇 방식의 단점: 매일 많은 태스크를 손으로 쓰는 데 드는 피로·시간
          + 하루에 20~30개 이상 필요, 몇 개만 써도 효율 급감
     * 영수증 프린터(thermal printer) 로 포스트잇을 대체
          + 스크립트로 태스크 리스트 인쇄(요일별 루틴도 쉽게 적용)
          + 자동 커팅, 빠른 속도, 저렴한 운영비(1롤로 수천 건 인쇄)
          + 준비 과정 자동화로 '미루는 날' 거의 사라짐
     * 요약:
          + 인쇄로 ""준비 마찰"" 제거
          + 더 많은 태스크·습관 추가도 부담↓
          + 미루기 극복에 일관성↑

실천에서의 추가 과제와 해결책

     * 실시간 태스크/습관 추가·수정의 어려움(기존 스크립트의 한계)
          + 기존 할일 앱들은 세부 태스크 분할이 어렵고, 계층화시 UX 혼잡
          + 수평(컬럼 기반) 구조로 하위 태스크를 한눈에 관리할 수 있도록 커스텀 소프트웨어 개발
               o 클릭/키보드로 빠르게 태스크 추가, 원하는 컬럼만 프린트
          + 이 앱+프린터 조합으로 ADHD 당사자도 매일 일관된 생산성 확보에 성공

결론 및 정리

     * 태스크를 미시적·반복적으로 쪼개기 → 집중 루프 강화
     * 아침 습관·쉬운 일로 스타트 → 관성·동기 강화
     * 실물 피드백(포스트잇+프린터+투명 병) → 시각/촉각적 성취감
     * 준비 자동화, 빠른 UX, 수평적 구조 → 일관성·지속성 극대화

     * 영수증 프린터와 맞춤형 도구 결합이 미루기 습관 극복에 최고의 솔루션임을 체험함 : ""이런 방법을 꼭 직접 시도해보라""
     * 소프트웨어도 조만간 공개 예정임

   오 영수증프린터쓰면 확실히 물리적으로 보여서 효과있을것 같네요

   오 나에게 딱 필요한 글이네요🙏

   저렇게 까지 살아야 하나요 ㅠㅠ

   흥미롭네요!

   좋아요

   WOW

        Hacker News 의견

     * 왜 나는 게임을 할 때는 몇 시간씩 집중할 수 있는데, 이메일을 쓸 때는 미루게 되는지에 대해 이야기하고 싶음. 게임은 정말 재밌음. 게임이 주는 자극은 대부분의 일(새로운 CLI나 최적화기를 만드는 것 제외)에서 느끼는 자극보다 훨씬 강함. 일을 더 자극적으로 만들려고 다양한 보상(동료들과 함께하기, 간식, 카페인, 돈, 물리적인 보상 등)을 얹어서 동기부여를 얻으려 하지만, 결국 건강에 관한 조언들처럼 핵심은 자극적인 것들이 건강한 습관을 대체하지 않게 하는 것임. 게임, 음식뿐 아니라 휴대폰도 마찬가지임. 특정 자극적인 것에 빠져있으면 평범한 일에서 즐거움을 느끼기 어려움. 게임에 깊게 빠져있을 땐 일에 집중하기 힘들었고, 자극적인 요소를 끊어내면 업무 자체가 다시 재미있어지는 경험도 있었음. 이게 바로 ‘도파민 다이어트’의
       실용적인 효과라고 볼 수 있음. 누구나 자신만의 자극적인 무언가가 있기 마련임
          + 스마트폰도 누군가에게는 게임 못지 않은 자극임. 최근 회사에서 2FA(이중 인증)를 아주 강하게 밀고 있는데, 보안상 취지는 이해하지만 전부 인증 앱으로만 처리하고 있음. 그래서 이제는 폰을 내려놓기도 힘들고, 일하다가 중간중간 계속 폰으로 인증해야 함. 그 과정에서 알림을 보고, 앱을 잠깐 확인하거나, 기기를 바꿔야 해서 흐름이 자주 끊김. 이게 최선의 방식인지 의문임
          + 나도 어느 정도 이런 식이긴 한데, 나는 수도자처럼 살자는 목적보다는 매일 ‘새로움 예산’이 있다는 식으로 생각함. 새로운 자극 하나가 계획을망칠 수 있는 계기가 되어버림. 하지만 지금 당장 해야 할 정말 중요한 일이 있으면, 오히려 더 새로운 자극을 피하게 됨. 평소에는 루틴을 지키며 지루한 상태를 유지해야 진짜로 뛰쳐나가야 할 때 번뜩임이 찾아옴. 본질적으로 내적 동기는 외적인 자극으로 대체되지 않음. 생산성에 관한 조언을 보면 자꾸 자극을 추가하거나 ‘더 열심히 해야 한다’고 하거나, 번아웃을 더 큰 자극이나 방법론으로 억누르려 하는 경향이 있는데, 진짜 원인은 삶에 대한 근본적 질문과 철학적 고민이라고 봄. 일은 지루한 루틴, 짜릿함, 가끔은 슬픔까지 다양한 순간이 있지만, 동기는 모든 걸 견디게 해줌
          + 나는 인생을 게임처럼 생각하는 상상을 자주 사용함. 지루하거나 어려운 일을 마치 게임처럼 ‘정복해야할 레벨’처럼 여기면 끝냈을 때 보상이 크게 느껴지고, 실제로 이런 방식이 여러 힘든 시기를 넘기는 데 도움이 되었음. 물론 이게 모두에게 효과가 있는지는 모르겠음. 내 뇌 화학 탓일 수도 있음
          + 현대 소비문화에 있어서 많은 사람들이 간과하는 부분이 있음. 대부분의 자유 시간을 틱톡이나 보상 강한 게임에 쓰더라도 당장 건강에 치명적 문제가 생기지 않음. 운동이나 식단을 지키지 않아도 마찬가지. 다만 정량화하기 어려운 다양한 측면에서 문제와 영향을 끼침. 그래서 자신이 가장 자주 의지하는 것 없이(혹은 있을 때와 없을 때 모두) 자신의 정신 상태를 주의 깊게 관찰하는 것이 집중력이나 동기 저하 사태에선 꼭 필요하다고 생각함
          + 아이스크림을 먹은 후 케일 샐러드를 먹는다고 혈당이 낮아지진 않는다는 얘기에 대해 경험상 오히려 혈당이 천천히 올라가는 효과가 있다고 생각함(과학자는 아님). 내 경험상 샐러드를 먼저 먹으면 소화과정이 느려지고, 전체적인 당 지수가 낮아져 혈당이 천천히 올라감. 꼭 샐러드를 먼저 먹는 게 포인트임
     * Disney World에서 예전에 20년 전쯤 사용하던 Cast Deployment System이 이 ‘작업 쪽지 시스템’을 떠올리게 함. 출근이나 쉬는 시간 복귀 시 직원들은 PC 단말기에 번호를 입력하면 영수증 프린터로 작은 용지에 해야 하는 작업 내용이 인쇄되어 나옴. 예를 들면 ‘어느 위치에서 누구를 교대해라’, ‘특정 시간까지 상품 정리해라’, ‘이제 퇴근 가능’ 등 여러 종류가 있었음. 운용 소프트웨어가 실시간으로 출결, 대기시간, 매출 데이터 등을 반영해 각 직원을 그 순간 가장 효율적으로 배치하고, 쉴틈이 있으면 유용한 작은 작업을 부여하거나 할 일이 없으면 바로 퇴근시키기도 함. 굉장히 효율적이고, 사람이 해야 할 일을 명확히 쪼개주던 시스템임
          + Marshall Brain이 쓴 Manna라는 소설이 이 시스템에 영감을 받았을지 궁금해짐. 그 소설에서는 이보다 더 첨단 AI가 추가된 시스템을 다룸
          + 이 설명을 읽어보니, 내가 생각했던 테마파크 운영 방식과 달라서 놀라움. 좋은 정보 고마움
     * David MacIver가 만든 리스트 기반 작업 관리 시스템이 생각남. 매일 아침 리스트를 새로 작성하고, 하루 동안 해야 할 일이 생길 때마다 바로 추가하는 방식임(항상 작업 계층화 없이 평면 리스트). 아침 공백의 리스트로 시작하니 중요한 걸 빼먹을까봐 걱정도 됐지만, 오히려 정말 꼭 중요한 일과 동기부여되는 일만 쌓이게 거름망 역할을 하더라. 만약 정말 중요한 일이라면 결국 하루 중 언젠가 다시 떠오름. 짧은 시간 내 여러 작업이 동시에 요구되는 상황(귀가 후 청소, 저녁준비 등)에도 효과적임. 주변 모든 해야 할 일을 노트패드에 쭉 쓰고, 시간이 지날수록 리스트가 커지다가 완료되면서 다시 점차 줄어드는 게 묘한 만족감을 줌. 처음에 나를 압도했던 일들을 모두 처리했다는 기분이 들기도 함
          + ADHD가 있다면 ‘중요하면 언젠가 기억난다’는 원칙이 잘 맞진 않음. 직접 경험상 식사도 잊어버릴 때가 많았고, 따로 알람을 걸지 않으면 세금 신고도 잊어버릴 뻔함
          + 내가 매니저라 해야 할 일이 많다보니, 할 일 리스트가 없으면 무조건 잊어버림. 리스트를 보는 것보다, 해야 할 일이 쌓여 안 하거나 잊어버리는 게 더 불안하고 스트레스를 큼. 모든 걸 적고, 하나씩 처리해서 모든 게 끝났다고 느끼는 것이 내 안정제임. ‘중요하면 기억난다’는 건 사람마다 다름을 인정함
          + 이 글은 처음 알았지만 고마움! 내가 이야기하는 작업 쪼개기와 깊이 들어가는 부분이 닮았음. 다만 나는 아침에 빈 리스트에서 시작할 경우 바로 뭔가 하자 않고 있다가 하루 종일 아무 것도 안 할 수 있어서(ADHD 스타일), 공란에서 시작은 어렵게 느껴짐
          + 나 역시 GTD를 처음 활용하다가 할 일 목록이 너무 늘어나 압도되는 현상을 겪었음. 결국 매일 빈 페이지(특히 종이)에 오늘의 프로젝트와 다음 행동을 기억&상상해서 다시 적는 nanoGTD로 발전시킴. 혹시 누락된 건 전날 페이지를 확인하면 됨
          + 종이 연간 플래너의 진정한 가치는 할 일 리스트가 무한히 길어지지 않는다는 점임. 오늘 안 한 건 내일로 옮길지 지울지 끝까지 직접 결정해야 하고, 할 일을 적기는 쉽지만, 진짜 어려운 건 모든 걸 할 수 없다는 걸 깨닫고 어느 것부터 포기할지 스스로 정하는 것임
     * 영수증 용지의 성분을 확인해보는 것이 좋겠음. 많은 영수증 용지에 건강에 좋지 않은 물질이 포함됨. 관련 링크: toxicfreefuture.org/press-room/new-study-finds-toxic-chemicals-in-80-of-receipt-paper-tested-down-from-93-in-2017
          + 주요 문제는 종이에 포함된 비스페놀이고, 유럽에서는 이미 금지되어 있음
          + 짧은 영상을 본 적 있는데, 일반 장갑을 끼고 있어도 이런 열전사 인쇄지에 노출되면 안전하지 않다고 함
     * 작성자임. 첫 글이라 떨리는데 반응이 궁금함. 미루는 습관을 가진 사람이라면 이 방법이 나만큼이나 도움이 되길 바람
          + 조금 비판적인 댓글을 쓸까 했지만, 당신의 코멘트를 보고 친절하게 굴어야겠다 생각함. 영수증 프린터는 없지만, 나는 작업이 밀릴 때 A4 화이트보드에 마커로 적음. 투두리스트를 너무 남발하지 않는 것도 효과 유지에 중요함. 작업을 잊고 놓아버리는 것도 뜻밖에 유익할 때가 많았음. 중요한 일은 어차피 머릿속에 남아 밤새 잠 못 들게 하니깐. 미루는 습관 개선한다고 뭔가를 바꾸고, 돈까지 써가며 자극을 따라다니는 것도 몇 주 못가 원래 상태로 금방 돌아오는 경우가 많음. 진짜 흥미로운 건 누군가가 수년간 성공적으로 쓴 방법임. 계속 글을 쓰길 바람. squirrel brain에도 큰 도움이 됨
          + 정말 마음에 들었음. 열전사 프린터로 출력한 실물 태스크를 뭉쳐 쓰레기통에 던지는 건 진짜 ‘괴짜 고블린 에너지’ 그 자체임. 현실 세계에서 게임 루프와 오페런트 조건화를 잘 접목시킨 것 같음. 화이트보드로 태스크를 관리하기도 하지만, 완수했을 때 피드백이 약하고 흔적이 남지도 않아 일주일 동안 뭘 했는지 기억조차 안 남. 즉각적인 피드백과 장기적인 결과 확인, 둘을 모두 충족해야 루프가 만족스러움. 나는 롤 페이퍼로 기록 남기는 시스템도 생각만 해봤지만, 역시 장착대를 만드는 걸 미뤘음. 투두앱은 너무 많아 오히려 압도당하는데, 이 방식의 범위 숨김 효과가 마음에 듦
          + 이 글 써줘서 정말 고마움. 최근 자폐와 ADHD 모두 진단 받은 후, 이 사고방식이 배우긴 어렵지만 숙달되면 높게 발휘된다는 걸 느낌. 비디오 게임에만큼 작업 루프 방식이 나한테 잘 맞음. 다른 이들의 실험기도 나에게 많은 아이디어를 줌. 카드 기반 시스템도 써봤는데, 매번 카드를 직접 만드는 번거로움 때문에 포기한 적 있음. 영수증 프린터로 실체화하는 아이디어는 아주 굿. 디지털, 물리, 두뇌로 나뉜 정보 동기화를 시도하고 있는데, 실험 더 해볼 계획임. 더 많은 아이디어를 따로 메일링리스트로 읽어보고 싶음
          + 글 잘 읽었음! 나도 미루는 습관이 있어서 공감됨. 요즘 내가 쓰는 방법 중 하나는 Field Notes 노트를 항상 들고 다니며, 여기에 작은 단위로 작업을 쪼개는 방식을 병행하는 것임. 휴대폰 대신 노트북을 기본 ‘산만함’ 장치로 쓰게 되고, 내게 완벽한 크기의 노트라서 좋음
          + 정말 뛰어난 글임. 미루게 되는 근본적인 원인을 아주 잘 짚어줬다고 생각함. 일단 동작하는 방법이 있으면 일단 사용하고, 그게 완벽하지 않아도 개선해나가는 과정에 있음. 많은 사람들이 바로 이 ‘불완전해도 개선 중인 상태’를 못 견뎌하는 걸로 보임
     * 혹시 나랑 비슷하게 느끼는 사람이 있을까 해서 적어봄... 새 시스템 이후로 습관 추적을 한 번도 빠뜨리지 않았을 때, 엄청난 만족감과 동시에 ‘이 페이스가 계속될 수 없을 것 같은 불안감’도 크게 느껴짐. 이렇게 너무 능동적으로 살다보면 주변도 계속 그러길 기대하고, 이미 해치운 일이 새로운 일을 계속 불러와서, 그냥 게으르게 있었으면 생기지 않을 작업까지 늘어남. 무엇보다 ‘최소한 직장은 다니는 한 거의 무생산적으로 지낼 수 있다’는 인식을 하게 되니 오히려 생산적이고자 하는 동기 자체가 떨어지기도 함
          + 방금 당신이 한 말이 내가 ‘직업을 갖지 않는’ 가장 큰 이유를 너무 잘 설명해줌. 덧붙이면, 직장인은 진짜 의미 있는 일이나 자기만의 작업을 할 시간이나 에너지가 거의 없음
     * 정말 멋진 아이디어임! 참고로, 열전사 영수증 종이를 자주 맨손으로 만지는 건 건강에 해로울 수 있음(BPA/BPS 성분). 자세한 건 잘 모름. 관련 정보: pca.state.mn.us/business-with-us/bpa-and-bps-in-thermal-paper
          + 내 지역에서는 비페놀(phenol-free) 열전사 용지도 구할 수 있고, 약 20% 더 비싸지만 훨씬 안전하고 품질도 좋음
          + 맞음, 열전사지 안전이 가장 먼저 떠오름. 그리고 내 경험상 열전사 인쇄물은 1~10년 정도 지나면 완전히 사라질 수 있음. 즉, 단기 목적엔 적합하지만 장기 보관용 라벨로는 부적합임
          + 비스페놀 함유 용지라 맞음. 유럽에선 이미 금지됐지만, 미국에선 아직 유통 중임
     * 첫 기사 좋은 글임! 다른 사람도 영수증 프린터를 활용한 작은 작업 관리법을 쓰는 걸 보니 흥미로움. 나는 Raspberry Pi로 자동화해서 actionable task를 영수증 프린터로 뽑아내기도 함. 실물 티켓을 손에 쥐는 기분이 좋음. 참고로 영수증을 자주 만진다면 phenol-free 용지를 꼭 사용해야 함. phenol은 독성물질이고 어떤 국가는 이미 금지함
          + 실체화된 태스크를 손에 쥘 수 있다는 게 정말 중요하다고 생각함! 유럽에 있으니 비스페놀 용지는 거의 없지만, 어느 곳에서는 여전히 남아있음
          + 독성 여부를 눈으로 보고 바로 구분하는 방법이 있을까 궁금함
     * 멋진 글임! 내가 생각해봤던 여러 아이디어가 잘 정리 되어 있어 좋았음. 하지만 이 시스템을 정말 오래 써본 건지 궁금함. 내 경험상 외부 압박이나, 제대로 된 식단과 운동 없이는 어떤 시스템도 오래 못 감. 탄수화물을 많이 먹거나 운동을 아예 안 하면 아무 것도 못함. ‘케토’류 식사나 2~3일마다 운동을 하면 생산성이 확 오름. 일의 흐름을 루프처럼 보는 건 올바른 접근이라고 생각함. 인간의 두뇌는 새로운 패턴을 익히는데 시간이 필요하고, 그걸 꾸준히 반복해야 쉬워진다고 느낌. 휴가 후에 일에 복귀하면 순간적으로 진이 빠지고, 싫어지기도 함. 익숙해지는 것이 중요함. 나 역시 투두 리스트로 관리하는데, 그냥 내가 만든 웹앱이나 종이에 적기도 함. 너무 거창하게 시스템화하기보다는 최소한의 번거로움만 유지하는 게 장기적으로 제일
       적합하다고 느낌. 그래도 또 다른 방식의 접근을 볼 수 있어 신선하고 좋았음
          + 대략 6개월 정도 사용 중임. 복잡한 시스템이면 일주일 내로 포기하는 경우가 많았음. '할 일 관리'에서 미니멀리즘이 제일 공감됨
     * 질병 때문에 JIRA조차 힘들게 쓰던 시절에 영수증 프린터로 종이 티켓을 만들어보자는 아이디어를 떠올렸음. 실제로 Ebay에서 프린터를 사고 사용법도 익혀봤지만, 결과적으로 JIRA 연동까지는 안 하고, 자필로 프린팅하는 게 충분해서 그 이후엔 상태가 나아짐. 대신 포켓몬 도트 그림을 많이 출력해봄(원래 아트 자료 자체가 저화질용으로 설계되다 보니 열전사 프린터와 궁합이 좋음). 여러 종류의 열전사 프린터가 있는데, 북미에서 mm 단위로 검색하면 저렴한 중국산이 많고, 인치 단위로 찾으면 비싼 브랜드 제품이 뜸. 요즘은 대부분 USB 연결이지만, 서버와 연동하고 싶으면 이더넷 포트 달린 모델이 이상적이라 생각함
          + 좋은 아이디어 떠오름. 각 태스크 티켓 프린트시 랜덤 캐릭터를 함께 인쇄해서, 희귀도 등이 다르게 나오게 하면 어떤 사람에게는 더 재미와 동기 부여가 될 수 있음. 나도 RJ45와 USB 모두 지원되는 프린터를 일부러 구매함. 다양한 활용을 고려해서임
"
"https://news.hada.io/topic?id=21346","홍콩 정글에서 텐트 생활 실험기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           홍콩 정글에서 텐트 생활 실험기

     * 한 개발자가 홍콩 외곽 정글에서 한 달 동안 텐트 생활 실험을 진행함
     * 이 실험의 주요 목적은 집 없는 삶과 최소한의 생활비 경험임
     * 생활비 절약, 자연에서의 생활, 그리고 사회적 고립 등의 경험을 상세하게 기록함
     * 물, 전기, 인터넷 등 현대적 편의시설이 없는 환경에서 생활의 어려움을 체감함
     * 텐트 생활 실험을 통해 도시 환경과 자연 환경의 차이점과 한계점에 대한 인사이트를 얻음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: 텐트에서의 한 달 실험

     * 본 실험은 홍콩 외곽의 정글 지역에서 개발자인 Corentin Trebaol이 집 없이 생존하는 경험을 연구 목적으로 시작한 것임
     * 극한의 환경에서 생활비를 줄이고 자연 상태에서 살아갈 수 있는지 확인하려는 호기심에서 실험을 기획함

실험 동기와 준비

     * 홍콩 집값의 극심한 상승과 집 없는 사람들이 직면하는 현실적인 문제에 대한 관심에서 실험을 시작함
     * 필수품 외에 미니멀한 장비만을 사용하여 정글 내 텐트 거주를 선택함
     * 물, 식량, 전기 등을 인근 마을이나 슈퍼마켓에서 직접 조달함

텐트 생활의 현실

     * 온도, 습도, 벌레, 비 소리 등 환경적 요인으로 인한 실질적 어려움을 체감함
     * 인터넷 부재 및 충전 문제로 온라인 작업과 원격 근무에 제약을 느낌
     * 안전 문제와 일상적인 사회적 교류 단절의 불편함이 점차 심각하게 다가옴

생활 비용과 생존 전략

     * 월 세입·관리비·전기료 부담 없이 생활비를 최대한 최소화하는 실험적 방식임
     * 현금 사용이 거의 필요 없었으나, 식수와 위생용품 조달에는 제한적인 비용이 발생함
     * 식사는 주로 캠핑용 조리기구나 인근 상점에서 해결함

주요 인사이트와 한계점

     * 도시에서의 집이 단순히 주거 공간이 아닌 사회적·정신적 안전망 역할을 한다는 점을 새롭게 인식함
     * 환경적 불안정성과 사회적 고립, 그리고 물리적 한계로 인해 장기적인 지속은 어렵다고 판단함
     * 실험을 통해 집 없는 삶의 어려움과 한계점을 실제로 체험하고, 보다 깊이 있는 이해를 얻음

결론

     * 텐트에서의 정글 생활은 극도의 단순함과 자연과의 직접적 접촉 경험을 제공함
     * 그러나 지속 가능한 생존 방식이나 대안적 거주 형태로서의 현실성에 한계가 있음을 확인함
     * 집 없는 상태의 불안정성과 사회적 안전망 필요성에 대한 현재 사회의 한계를 직접적으로 드러냄

        Hacker News 의견

     * 이 글에서 다뤄지는 세밀한 디테일에 감탄하는 감정 공유, 그리고 “학교에 있다는 점”이 이 실험을 단순 텐트 생활과 차별화시키는 결정적 요소였다는 의견 전달. 학비가 곧 월세 개념처럼 샤워, 전기, 에어컨 있는 공용 거실(도서관), 사회적 지원 공동체를 포함한다는 시각. 학교, 사회 모두 극빈 성인보다 가난한 학생을 돕는데 더 열려있다는 배경 언급. 이 의견은 실험의 가치를 폄하하려는 의도가 아니라, 실험의 맥락과 효용을 머릿속에 제대로 배치하기 위한 관점임을 덧붙이는 강조
          + HN의 플래그(신고) 기능이 큰 취약점이라는 문제의식 공유. 플래그하는 사람에게 신고 이유를 반드시 밝히게 하고, 그 이유가 서로에게 공개되는 시스템 필요 주장. 플래그는 “아무도 이 글을 보면 안 된다”는 절대적 힘이니, 아무나 자의적으로 행사하면 안 된다는 견해 피력
          + 피드백에 감사하며, 구글 캠퍼스 근처에서 살아가는 게 훨씬 쉽고, 세탁기 같은 자잘한 필수 요소들까지 해결된다는 점을 설명. 플래그 관련 질문과 더불어, 오랜 기간 이 사이트에 머문 경험자로서 힌트를 요청. 단어 선택이 문제가 될 수 있단 지적에는 동의한다는 설명
          + 플래그된 이유는 원래 제목이 현재와 전혀 다른 부적절한 것이었기 때문이라는 사실 전달
     * 나는 토론토와 샌프란시스코에서 30대에 여름마다 이 경험을 했다며, 이게 내 인생을 바꿔준 경험으로 기억 중. 마치 나만의 UBI(기본소득제)를 만든 느낌. 매일의 평범한 순간이 마법처럼 느껴짐. 가끔 필요시에는 생면부지의 사람들로부터 받은 예상 못 한 환대, 주변 친구들과 낯선 이들의 존경심도 소중한 기억. 내가 특별히 다르게 한 점은 해먹 텐트를 활용해 10분 만에 설치했다 해제하며 주요 도심지 인근에서 지냈다는 점. 모두에게 오픈했고, 정부 공무원들과도 공식 모임을 주최했는데, 모두 이 점을 유쾌하게 받아주고 지지했다는 경험담. 실험 노트와 컨테이너 하우스 생활기 링크 공유 urban-camping 노트, 컨테이너 하우스 노트
     * 오리건 시골에서 차(Prius)에서 한여름 내내 지냈던 짧은 에피소드 이야기. 커리어 전환을 고민하는 특별한 시간으로, 장기적으로 할 경험은 아니지만 소중하게 남아있음
     * ROI 계산이 너무 단기적이라 진짜 의미 없다는 시선 제시. 어차피 대학 등록금 내고 공부의 목표는 대출 상환 이상의 의미라 전제. 매달 몇백 달러 추가로 써서 '인간의 기본생존요구'인 지붕을 얻는 게 훨씬 나은 판단임을 강조. “노숙자 체험놀이”는 잠깐은 흥미로울 수 있지만, 현실적인 더위‧추위‧동물‧경찰‧물리적 위험 등 만났을 때, 학점 유지도 쉽지 않을 것이라는 우려
          + 종국적으로 빚 없이 졸업하려는 생각에 너무 매몰됐던 점 인정. 하지만 글의 취지 이상으로 이 실험의 ROI는 긍정적으로 봄. 도서관에서 더 많은 시간을 보낸 덕분에 오히려 학점이 올랐고, 이후 다른 사람 집에서 지내며 인생 경험이 넓어짐. 무엇보다, 물질적 집착에서 벗어난 해방감 덕에 더 대담한 결정과 도전 감행 가능, 훗날 복수로 결실을 거둔 경험 공유. 실제로 학점이 떨어졌어도, 이 경험 하나만으로 초기 스타트업 등을 포함해 취업 경쟁력이 올라갔을 것이라는 자신감 표현
     * 대학 학부 시절에도 숲에서 지냈던 삶 공유, 관련 경험담 링크와, RV 해커 랩에서 일하며 여행한 경험 유튜브 영상도 소개. 현재는 SF에 있다고 전하며 공감대 형성 시도
     * 이건 진정한 노숙자가 아니라 “bandit camping(불법 야영)”이라는 단어로 강조. 실제 노숙자는 자발적 선택이 아닌, 시간 최적화를 위한 상대적 사치가 아니라는 설명 하에, 오해와 경계 필요 지적
          + 언어 사용을 논의할 순 있지만, 노숙자냐 아니냐 의미를 허들처럼 설정하는 건 무리라는 의견. 비자발적 노숙이 아니어도, 실제 많은 노숙자들이 “선택지의 트레이드오프”에서 결국 스스로 거리 생활을 택하는 경우도 있음을 부연. 트레볼(글쓴이) 역시 순수한 놀이가 아닌, 2천 달러 절약이라는 목적 아래 4개월 반을 불법 스쿼팅 함. 만약 bandit camping이라 표현이 더 맞다면 본인 경험엔 그 용어 쓰라 하지만, 용어 의미를 “사회적 생산 불가 상태만 노숙자”라고 편협하게 재정의하자는 요구에 동의 못한다고 밝힘
          + 실제로 노숙 현상을 연구하는 많은 전문가들이 “노숙은 외부 자원의 문제로 해결 어려운 트레이드오프의 결과, 일종의 선택”이라는 시각을 갖고 있음을 설명. 물론 ‘재미로’가 아니라 더 복잡한 맥락의 선택이라는 점 강조
          + 인터넷상의 단어 논쟁보다는 노숙 당사자는 훨씬 시급한 고민이 많을 것이라는 농담 분위기
          + 제목을 더 정확하고 중립적으로 바꿀 수 있다면 아무때나 수정 가능하다고 제안, 실제로 본인이 한 번 고쳐봤으니 더 나은 방법 있으면 알려달라는 협업적 제안
          + ETHOS라는 공식 노숙자 분류 시스템이 있는데, 이 방식은 “왜”가 아니라 “어디서” 사는지에 더 포커스한다는 정보 제공. 글 작성자(OP) 케이스는 두 가지 범주를 오갈 수 있다는 의견
     * 깊은 밤 대화로 서로를 알아가고 가까워지는 점을 “카우치서핑” 경험과 연결해 설명. 며칠간 함께 공간을 나누다보면 의외의 친밀함 생긴다고 소개. 무료 오픈소스 기반 Couchers.org 소개, 자신이 이 프로젝트 핵심 멤버라는 친근한 정보 공유
     * 안전 고려에 대한 언급은 탁월하지만, 궁핍한 상황에서 끈질기게 절약하다 작은 부상이나 질병이 오히려 더 큰 지출과 평생 후유증으로 이어질 위험성 강조. 과거 절약하며 살아봤지만, 꼭 좋은 거래는 아니었음을 돌아보는 반성
          + 과도하게 비싼 의료비는 한 나라에서만의 문제라는 주장. 에콰도르-말리-앙골라-호주-캐나다 등지의 응급실 경험상 보험 없이도 처방까지 포함 50달러 이하로 매우 저렴했던 구체적 일화 전달
          + 홍콩 학생 비자로 유학 중이었다면, 홍콩 공공의료가 거의 무료에 가까울 정도임을 안내. HKID와 180일 이상 체류 허가 있으면 누구나 대상
          + 피드백에 동의하며, 단계적으로 리스크를 줄이는 실험 과정을 설명했다는 점과 “커뮤니티와 저렴한 학생의료 없으면 훨씬 위험하다”는 내용을 추가하겠다고 답변. 실제로 해당 내용을 본문에 추가했다는 부연
          + 반대로, 2천 달러를 통장에 쥔 채로 있으면 오히려 미래의 위기 방지 등 긍정적 역효과도 있다고 설명. 리스크라는 요소 자체가 단순히 흑백논리가 아니라는 관점
     * 4.5개월간 2천 달러 세이브라는 숫자에 대해 “생각보다 적다”는 놀라움 표출. 한 달 450달러면, 홍콩의 월세 현실에 비해 저렴하게 느껴짐. 정식 기숙사 미입주라면 집 렌탈 월 700불은 최소, 생활 기준에 따라 1,000불이 상회할 수 있다는 실제적 경험 공유. 이 경험이 언론에 널리 알려졌으면 좋겠다는 바람, 홍콩 임대시장 특유의 비정상 금액 구조에 대한 이슈화 제안
     * 한 끼 1~3달러에 식사할 수 있다는 점이 더 충격적이라고 솔직하게 공유
"
"https://news.hada.io/topic?id=21360","독재자를 위한 슈퍼컴퓨터 구축이 민주주의에 반드시 좋은 것은 아님","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  독재자를 위한 슈퍼컴퓨터 구축이 민주주의에 반드시 좋은 것은 아님

     * OpenAI가 최근 UAE와 대규모 AI 데이터 센터 구축 파트너십을 발표함
     * 이 파트너십은 “민주적 가치에 뿌리를 두었다” 고 하지만, UAE는 대표적인 비민주적 국가임
     * Freedom House 등은 UAE의 시민 자유 및 정치권 억압을 강조함
     * OpenAI는 이번 협력에 대해 민주적 AI 확산을 내세우지만 실질적 민주주의 기여는 미지수임
     * 슈퍼컴퓨팅 자원 이전이 권위주의 국가의 국력 강화로 이어질 위험성 우려됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

OpenAI의 UAE AI 슈퍼컴퓨터 파트너십 개요

     * 2024년 5월, OpenAI는 OpenAI for Countries 프로그램과 미국 내 대규모 AI 데이터센터인 Stargate 프로젝트를 공식 발표함
     * OpenAI는 정부들이 AI 컴퓨팅 집적이 국가 경쟁력의 핵심이 될 것으로 인식함을 언급하며, “민주주의 AI를 세계 각국에 제공”하겠다는 목표를 천명함
     * 발표 이후 OpenAI는 UAE와 협력해 최신 AI 데이터센터를 건설하는 파트너십을 공개함. 해당 파트너십이 “민주적 가치에 기반한다” 고 밝혔음

UAE의 민주주의 실태

     * Freedom House의 2024년 평가에 따르면 UAE는 100점 만점에 18점으로, 아이티, 짐바브웨, 이라크보다도 낮은 점수임
     * UAE는 세습 군주제로, 정치적 권력 독점, 정당의 금지, 제한적 선거권, 실질적 입법 권한이 없는 자문평의회 등 특징 보유함
     * 정부 비판, 인권 옹호, 정치 개혁을 주장하는 후보자 및 활동가는 구금되며, 가족도 감시·처벌 대상임
     * 언론 매체는 자가 검열 또는 정부의 직접 검열을 받고, 교과서와 교육과정도 검열됨
     * 인구의 90%를 차지하는 이주 노동자들은 정치적 권리가 없으며, 노동 착취 문제도 심각함. 현대판 노예제 만연도 국제 인권 단체에서 지적됨

OpenAI의 ‘민주적 AI’ 논리 비판

     * OpenAI와 Chris Lehane(글로벌 정책 총괄)은 미국의 AI 기술을 확장하는 것이 ‘민주적 가치 확산’ 이라 주장함
     * 주요 논리는 다음과 같음
         1. 미국산 AI가 민주 가치를 체현하므로 이를 해외로 확산하면 민주주의 진전 효과 발생
         2. 미국과 중국의 AI 경쟁에서 미국이 승리하는 것이 민주주의 수호와 직결됨
     * 실제로 UAE에서 ChatGPT 사용 가능성이 확대된다고 해서, 실질적 표현의 자유 보장이나 즉각적 민주주의 발전으로 이어진다고 보기 어려움
     * UAE 현지의 검열 기준에 맞춘 서비스 제공 여부조차 불투명함. “정부와 함께 논의해 나가겠다”는 OpenAI COO의 답변도 이 점을 방증함

권위주의 정부에 슈퍼컴퓨팅 기술 지원의 영향

     * 대규모 AI 슈퍼컴퓨터 인프라는 국가 권력의 매우 중요한 요소로 부상중임
     * UAE가 이번 파트너십을 계기로 최첨단 AI 칩에 대한 상당 부분 접근권 혹은 소유권을 확보할 가능성 높음
     * Lehane이 언급한 대로, 해당 딜은 UAE를 AI 강국 반열에 올려놓을 핵심 동력 제공임
     * 미국의 실리 중심 외교에서 이득이 있을 수 있으나, 권위주의 체제의 국력 증진이라는 부정적 함의도 큼

결론 및 문제의식

     * 반도체·AI 협력 자체가 반드시 부정적이라는 의미는 아님
     * OpenAI와 UAE 간의 계약 세부 내용은 대부분 비공개 혹은 미확정 상태임
     * 다만, 이번 합의가 UAE 왕실이 수용 가능할 조건에서만 이뤄질 것이 명백함 → 민주주의 촉진 힘은 제한적임
     * AI 기술이 인류 전체의 이익을 위한 것이라는 OpenAI의 목표와, 실제 거버넌스·통제권 배분 문제는 완전히 별개로 남음
     * 이번 사례는 OpenAI가 대의명분과 현실적 위험(권력 집중, 민주주의 후퇴)을 진지하게 고민하지 않을 수 있음을 보여주는 신호로 해석 가능함

        Hacker News 의견

     * 나는 OpenAI와 같은 하이프로필 기업에 대해서는 늘 특별한 변명이나 예외를 두는 분위기가 정말 싫은 부분임. 실제로는 Cisco나 Oracle 같은 로우프로필의 산업 대기업들이 수십 년간 해오던 일임. OpenAI가 무슨 일을 하는지에 대한 분석이 시작과 끝이 아니어야 한다고 생각함
          + Cisco와 Oracle은 처음부터 인류의 더 나은 미래를 위해 봉사한다는 슬로건을 내걸고 비영리 단체로 출발한 적 없었음. Google이 한때 ‘악을 저지르지 말자’라는 모토를 내세웠다가 그걸 버리면서 비난받는 것과 다르지 않음. 한 기업이 잘못을 저질렀다고 그냥 넘어갔다고 해서 앞으로 다른 기업에게 더 높은 기준을 요구하지 말라는 것도 납득 안 가는 주장임
          + 정치란 가능한 것의 예술이라는 생각임. 좀 짜증나도 원칙에 따라 움직이려는 시도가 있다는 점에 감사함을 느낄 수 있음. 물론 실제 동기는 치장에 불과할 수 있지만, 이번 경우엔 글쓴이가 OpenAI를 콕 집어 비판하고 싶었던 게 명확해도 논거 자체는 충분히 설득력 있다고 봄
          + 기술 업계는 수십 년 동안 UAE에 대형 컴퓨터 시스템과 첨단 기술을 계속 팔아왔음. AMD가 GloFo로 분사했던 원래 배경도 사실은 아부다비에 첨단 반도체 공장을 세우려던 목적이 있었지만, 실제로 사막에서 공급망과 수자원 같은 문제가 현실로 닥쳐 실현이 어려웠던 일임
          + Cisco와 Oracle이 수십 년간 해온 일보다 훨씬 오래된 일임. IBM이 실제로 홀로코스트 운영에 쓰였던 컴퓨터를 제공했었음
          + OpenAI가 ‘민주주의 증진’을 내세우면서 오히려 이런 비판에 스스로 노출된 것이라 생각함. 실제로는 돈벌이 목적임이 명확한 만큼, 이런 주장을 앞세운 게 역풍을 맞은 셈임
     * 기사에서 언급하는 독재 국가의 범주가 미국 내 권위주의자들보다 걸프 지역 군주들을 지칭한다는 점을 간과했었음. 첫째, Nvidia 입장에서는 믿음직한 사우디 투자자들에게 GPU를 대량으로 파는 게 좋은 비즈니스임. 둘째, 걸프 왕정국가들은 미국과의 관계에 의존하고 있고 이슬람 혁명 피하기 위해서라도 현체제를 유지하려 함. 셋째, 데이터센터 전력 공급도 태양광으로 해결하면 됨. 이 국가들이 사용자를 감시하느냐고? 물론임. 이미 GCHQ, NSA와 정보 공유 협약을 통해 현지 법망을 우회하는 것도 어렵지 않음. 특별히 새로운 일은 아니고, 결국 내 생각이나 사생활을 어느 SaaS에도 맡기지 말아야 함
          + 실제로 그보다 더 교묘한 현실이라 생각함. 이미 나의 구매 이력, 주소, 통화 메타데이터 그리고 DOGE 덕분에 연방 데이터까지 잡아가고 있는 상황임. 내 SNS 피드가 없어도 충분히 나에게 위협이 될 수 있음. 게다가 SaaS에만 한정된 일이 아님. 웹 전체를 엄청난 속도로 긁어가고 있기 때문에 내 삶의 경계가 이미 훨씬 넓어져 있다고 느낌
          + 결국 HN 커뮤니티는 작은 집단이고 세상 대다수 사람들은 정보도 부족할 뿐 아니라 편리함을 위해 사생활을 포기하는 쪽을 결국 선택할 것으로 보임. 애초에 그런 유혹이 존재하지 않도록 만드는 게 이상적 선택이라는 관점도 생각해볼 만함
     * 어떤 형태든 독재자들을 위한 기술 개발은 민주주의에 긍정적이지 않다고 생각함. 민주주의 건강성의 핵심은 일하는 계층의 부를 극대화하는 것임. 사람들이 스스로와 가족, 그리고 지역 사회를 돌볼 수 있을 만한 여유와 교육을 갖추면 비로소 의미 있는 민주적 참여가 이루어질 수 있음. 미국, 걸프 국가, 러시아 등 어느 나라 독재자든 위한 개발은 하지 않는 게 나은 선택임(물론 현실적으로 쉽지 않음)
          + 민주주의 참여와 독재국 현실이 다소 별개 이야기처럼 보임. 오히려 기술 발전이 급속도로 진행될수록 서구사회, 특히 미국 내부에서 더 심각한 디스토피아 경향이 강해지고 있음. 반면, 중동 독재국가들은 예전부터 강한 복지 제도를 운영해 왔고, 인구가 적어서 AI 붐 덕에 더 효율적으로 이익을 취할 수 있는 상황임
     * LLM의 본질적 가치가 사회 전반에 전파되는 메시지의 힘을 배가시키는 역할에 있다고 생각함. 앞으로는 모든 사람이 사람 아닌 존재가 보내는 유사 메시지로 둘러싸이게 될 것임. 인터넷을 제어하는 유일한 방법이 결국 엄청난 메시지로 ‘묻어버리는’ 방식임을 입증한 셈임
          + 여기서 hoi polloi란 대중을 말하는 거라면, 실제로 대중은 그런 도구를 상업적 목적에 한정해 쓰고, 여전히 사회적 상호작용에 대한 갈증 때문에 SNS에 빠지는 것임. 반대로 엘리트라는 의미라면, 그들은 이미 오랫동안 사람을 방패막이 삼아 이 방식을 써왔으며 앞으로도 충분한 부가 있다면 계속 그럴 것임
          + “힘의 배가”라는 표현이 내 우려의 본질을 잘 담아줬다고 생각함
          + 내가 가진 지식과 상상력의 과신으로 인해 LLM의 본질적 유용성이 너무 ‘명백’하다고 단정하는 태도 자체가 믿기지 않는다는 감정임. 1780년 증기기관의 본질이 무엇이었는지 단정했던 사람들의 관점을 떠올리게 됨
          + LLM이 메시지 증폭에 쓰인다는 의견을 자주 접하지만 전혀 자명하다고 여기지 않음. 나는 극소수의 언론만 챙겨보고 온라인 상호작용을 의도적으로 피하는 내성적 성향임. SNS 등장 전에는 이런 식이 오히려 일반적이었음. LLM이 범람하면 오히려 원시적 네트워크 이용 형태로 회귀할 것 같지 않음? 그리고 인터넷을 통제하는 게 메시지로 묻는 일이라지만, 실제로는 법 개입에 비용을 아끼지 않으니 더 복잡한 현실임
          + 이런 주장은 동의하기 힘듦. 언론과 미디어는 이미 과도한 정보 쓰레기로 가득 차 있고, 사람들의 평균 집중도는 이미 한계치임. AI가 생성한 잡다한 내용이 추가된다 해도 큰 변화가 없을 것임. 인터넷 통제 방법은 결국 정부가 직접 나서서 규제하는 구조임
     * 내 생각에는 오히려 고도화된 기술일수록 어떤 정부든 더 권위적·전체주의적 형태로 변질될 가능성을 내포함. 권력자들에게는 모든 걸 통제하고픈 유혹이 크게 작용하고, 그 결과가 끔찍한 국가와 국민 통치로 이어지는 경향임
     * Sam Altman의 도덕적 기준 문제와 별개로, 억압과 폭력, 타인을 점령하는 민주주의 국가(미국, 이스라엘, 인도)와 반대편의 독재국(사우디, 중국, 북한) 사이에 실제로 본질적 차이가 있는지 의문임
          + 통치 대상이 직접 발언권을 가지지 못하는 상황에서 ‘민주주의국’이라는 표현 자체가 이상함
          + 차이를 무시하고 비교하면 본질적인 구분이 불가능해짐. 그리고 독재국의 피해자가 소수만 있는 것처럼 표현하는데, 거기에는 실제로 억압받는 수십억 대중이 있다는 사실을 간과함
     * 개인적으론 중국에 이득이 가도록 두느니, UAE와 거래해서 이익을 챙기는 게 훨씬 현실적인 선택임. 중동을 영원히 억누른다 해도 통하지 않는다는 것이 이미 입증됨. 결국 이런 행보는 리얼폴리틱 관점에서 봤을 때 최선이고, 현실 세계의 Hearts of Iron 플레이와 비슷한 선택지임. 사우디가 어차피 독재국이라면, 차라리 지금 이 방식이 이득임
     * 민주주의 역시 민주주의 자체를 위하지 못하는 구조임. 이미 실패한 아이디어라는 생각임
     * 1984에서 TV가 각 가정에 설치되고 그 TV가 항상 사람을 감시한다는 설정이 핵심 아이디어였던 것을 기억함. 누군가가 실시간으로 모든 사람을 ‘이해’하면서 감시하는 게 불가능해서 지금까지는 단순한 디스토피아적 판타지였음. 그러나 최근 LLM/GenAI 등장으로 집마다 GPU 한 대로 위험사상 감지 같은 초기 경보는 충분히 가능해진 상황임. 오히려 한정된 연산자원만 남기도록 바람직하게 설계하는 게 현실적일 수 있음. AGI라면 양측을 듣고 중립성을 지킬 수 있겠지만, 단방향 LLM 에이전트는 그런 능력이 없음. 현재 OpenAI, Apple 등 최소 6개 기업이 최신 GenAI 기반의 항시 시청 가정용 기기를 개발 중임. 삶 전체를 관찰해 맥락을 잡아주는 AI는 사용자의 취향, 정치성향 등도 알 수 있음. 자칫하면 권위주의 정부에 제대로 악용될 수 있음. TikTok이 이용자 데이터
       없이도 사용자의 성적 취향이나 관심사를 파악해낸 사례도 거의 실시간으로 드러났음. LLM 기반 기기는 TV 시청 패턴, 대화 내용, 감정 표현만 분석해도 투표 성향, 시위 참여 의향 등까지 추론할 수 있음. Helen Toner는 저 멀리 다른 대륙의 민주주의를 걱정하고 있지만, 정작 민주주의 본진이라는 곳마저 Orwell식 사회 구현 직전 단계에 와 있다는 두려움이 큼. 1단계: 모두의 집에 그런 장치를 설치하도록 유도(진행 중), 2단계: 해당 기업을 압박해서 장치를 권력자의 뜻에 맞게 쓰도록 만드는 것(남은 과제)
          + 행동 분류를 “위험/안전”처럼 이진 판단하는 건 본래 생성 AI 영역이 아니라 기존 머신러닝‧분류 모델로도 예전부터 가능했음. LLM이 아니라도 충분한 기술이고, 실제로는 전통적인 ML 모델이 더 효율적임
     * Chris Lehane 위키백과 문서가 아직 실제 이력만큼 업데이트가 안 되어 있음 Chris Lehane - Wikipedia Fixer로서 최고였던 경력임
"
"https://news.hada.io/topic?id=21389","CoverDrop - 뉴스 리더 앱을 위한 안전한 메시징 시스템","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  CoverDrop - 뉴스 리더 앱을 위한 안전한 메시징 시스템

     * 뉴스 리더 앱의 사용자와 언론인이 서로 익명성과 부인 가능성을 지키며 안전하게 소통할 수 있게 해주는 오픈소스 보안 메시징 솔루션
     * 모든 사용자 디바이스가 무작위 암호화 트래픽을 생성하므로, 메시지를 주고받더라도 일반 뉴스 사용과 네트워크 상에서 구분되지 않음
     * 메시지는 이중 암호화와 동일한 크기·빈도로 처리되어 기기 압수 상황에서도 증거를 남기지 않음
     * 모바일 앱, 클라우드 API, 보안 서버, 언론인용 데스크톱 클라이언트 등 완전한 엔드 투 엔드 구조로 이루어짐
     * 투명한 오픈소스 개발, 강력한 암호 기술, 뉴스조직 요구에 최적화된 특화 기능이 기존 프로젝트 대비 장점임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

CoverDrop 소개

     * CoverDrop은 뉴스 회사의 모바일 앱 사용자들이 기자에게 비밀스럽고 추적 불가능하게 메시지를 보낼 수 있게 설계된 안전한 시스템
     * 이 시스템은 강력한 부인 가능성을 제공하여, 앱이 보안 통신에 사용되는지 일반 뉴스 소비에 사용되는지 네트워크 분석자가 분간할 수 없게 만듦

주요 구성 요소

     * 뉴스 앱 내 모듈: 사용자 모바일 앱에 통합
     * 클라우드 API: 중앙 접점 역할 수행
     * CoverNode: 안전한 장소에서 작동하는 서비스 셋
     * 언론인용 데스크톱 애플리케이션: 기자가 사용하는 PC용 클라이언트

   이 4가지로 이루어진 구조가 엔드 투 엔드 암호화와 강력한 보안을 실현함

동작 방식

     * 뉴스 앱 모든 인스턴스가 주기적으로 작은 암호화 데이터(""cover 메시지"") 를 서버와 교환함
     * 실제 제보(출처 메시지)도 일반 cover 메시지와 완전히 동일하게 암호화·전송됨. 네트워크 상에서는 구분 불가임
     * 모든 메시지는 동일한 크기·주기로 처리되며, Kinesis 스트림으로 전송되어 처리됨
     * 서버에서 1차 암호화 해제와 진짜 메시지 판별이 이뤄지고, dead drop 형태로 기자 클라이언트에 배달됨. padding을 통해 dead drop 크기를 균일하게 유지함
     * 기자는 자신의 공개키로 암호화된 메시지만 최종 복호화 가능함
     * 메시지 저장소는 평소에도 암호화 상태로, 디바이스 압수 시에도 실제 대화 여부를 증명할 수 없음
     * 기자가 답장할 때도 유사한 방식으로 암호화된 통신 및 키 교환이 이루어짐

   보다 자세한 설계와 알고리듬 구조는 케임브리지 대학교 컴퓨터과학부와 공동 작성한 백서 에서 확인 가능함

보안 정책

     * CoverDrop 보안성은 최우선
     * 완전한 보안은 불가능함을 인정, 보안 연구자 제보 환영
     * 메시지 기밀성·무결성·네트워크 익명성·부인 가능 암호화 관련 이슈는 계속적 개선 영역임
     * 통합 뉴스앱 내 다른 요소에 의한 사이드 채널 이슈도 적극 개선중

암호화 소프트웨어 이용 주의

     * CoverDrop은 암호화 소프트웨어 포함
     * 각 국가별 암호 기술 수입·이용·재수출 관련 법률 준수 필요
     * 미국 상무부 BIS 분류: ECCN 5D002.C.1(비대칭 암호 포함 소프트웨어)
     * 본 오픈소스 배포는 수출 예외 조항(TSU, §740.13) 대상임

라이선스

     * CoverDrop 리포지토리는 Apache License 2.0으로 제공됨

        Hacker News 의견

     * 좀 더 설명이 필요한 분들께는 https://www.coverdrop.org/ 메인 사이트가 도움될 정보 제공 목적에 적합한 느낌 전달 영국의 공식비밀법 1920은 신문사와 익명 연락을 보호했지만, 이후 법 개정에서 이 부분이 사라진 점이 아쉬운 점으로 보임
     * 많은 뉴스 기관들이 https://securedrop.org/를 사용 중인데, CoverDrop이 어떻게 다르고 더 나은지 궁금증 생김 지원 언론사 디렉터리는 https://securedrop.org/directory/에서 확인 가능
          + 논문에서 이미 다룬 내용인데, SecureDrop과 CoverDrop은 약간 다른 상황에 초점 맞춘 점이 차별점임 SecureDrop은 TOR을 사용하는데 이는 네트워크 레벨이나 단말기에서 탐지될 수 있기 때문에, 일부 상황에서는 TOR 사용 사실만으로도 내부고발자 신원이 드러날 위험 존재 반면 뉴스 앱 설치는 덜 의심스러운 상황 연출 가능 CoverDrop은 초보 사용자도 노출 없이 최초로 연락하는 데 적합 네트워크 트래픽이 평범한 사용자와 구별되지 않고, 앱 스토리지는 실제 사용 여부와 상관 없이 공간 차지하며 부인 가능한 특성 제공 CoverDrop은 SecureDrop처럼 큰 파일을 전송할 수 없고, 논문에서는 필요시 기자가 CoverDrop 메시지 내에서 안전하게 SecureDrop을 사용하는 방법을 안내한다고 제안 그래서 보안 인식과 기술력이 충분하다면 SecureDrop 직행이 더 간단한 선택지일 수 있음
          + SecureDrop은 훌륭하고 The Guardian에서도 앞으로 계속 활용 계획 보유 SecureDrop은 Tor Browser 설치 없이 익명성을 확보하는 점이 큰 차이로, 이 기능을 뉴스 앱 내부에 넣어서 비기술자 내부고발자들의 허들이 현격히 낮아짐 기본적으로 좋은 OPSEC 달성을 지원함 CoverDrop(Secure Messaging)은 아직 한계가 있는데, 우선 프로토콜 특성상 서류 업로드가 불가해서 하루에 수 KB 전송만 가능 현재는 기자가 상황 따라 Signal로 사용자를 안내할 수 있음 기자가 먼저 소스의 신원과 위협을 평가한 후 Signal 번호를 전달하므로 위험을 한 번 걸러주는 좋은 구조임 앞으로는 CoverDrop 시스템 내에서 위험 평가 후 익명성 손상을 최소화하며 문서 업로드 링크를 보내는 기능도 고민 중임 예를 들어, 암호화된 이메일 첨부파일처럼 위장하는 방식 등 논의 참고 논문 있음 또 하나의 제약은
            이 시스템의 익명성은 앱의 대규모 사용량에 달려 있는데, 소규모 뉴스 에이전시가 도입하면 이 특성이 약해질 수 있음 그래도 실제로는 부인 가능한 스토리지 구조만으로도 타 내부고발 방식(PGP, Tor 기반 등) 대비 큰 진보라는 판단 다만 자신만 이 앱을 쓰고 있어도 상당히 안전한 점이 긍정적 요소로 보임
          + 홈페이지 FAQ에서 동일한 질문이 나와 있음
     * 이 아이디어가 정말 마음에 드는데, 예전 CIA가 스타워즈 팬사이트 등에서 만들었던 비밀 커뮤니케이션 시스템들이 떠오르는 부분 The Guardian이 명시적으로 언급하진 않았지만, 실제로 이 앱도 그런 커버스토리로 설계됐다는 점에서 뉴스 앱이라는 위장이 정말 뛰어난 접근이라 생각 개인적으로 한 가지 조언을 덧붙이자면, 이 앱을 통해 유출을 계획한다면 언제든 조사 대상이 될 수 있는 기기에서는 사용이 꺼려진다는 점 예로, 회사에서 지급한 업무용 폰이 있겠는데 Guardian 앱을 설치하는 것 자체가 문제는 아니더라도, 실제 기관 내부 조사에서 Guardian으로 주요 뉴스가 나갈 시, 다음처럼 리스트를 좁힐 수 있다는 우려 1. 애초에 해당 정보에 접근 가능했던 인원 2. 그 중 해당 앱을 설치했거나, 다운로드 흔적이 있거나, 기기 제출을 거부하는 인원 소규모
       그룹에서만 알려진 정보를 유출하거나, 기기가 실사용자에게 연결되어 있다면 타인(가족 등)의 기기를 써서 노출 위험을 최소화할 것 실제 목표는 조사에서 의심받지 않는 것이고, 이 앱과 제공된 정보가 Guardian 보도에 바로 연결될 수 있음을 고려하면 기술적으로 안전해도 완벽한 커버스토리는 어렵다는 점 마지막 추천은, 자신과 연결이 힘든 기기를 사용하는 것이 누설 시 더 큰 안전성 제공 이 부분이 위협 모델에 명시되어 있지 않아 추가 피해자 발생 가능성 언급
          + 프로젝트 기술 리드 입장에서 코멘트 업무용 폰을 사용하면 안 된다는 점에 동의하며, 특히 많은 업무용 기기는 사실상 스파이웨어 같은 모바일 관리 솔루션(MDM)을 포함하는 경우가 많음 익명 집단 규모가 작으면 기술적 접근 만으로 한계가 있다는 점을 재확인 앱 사용을 내부고발 상황에서도 충분히 부인할 수 있도록 많은 노력을 기울이고 있음 데이터는 ""공개""와 ""비공개"" 저장소로 구분되며, 비공개 데이터는 고정 크기/암호화 저장소에, 케임브리지의 팀원이 개발한 KDF 기법(링크)으로 보안 유지 하지만 기기에 스파이웨어(S/W)가 깔려 있으면 이런 노력도 무의미해지는 현실 내부적으로 해당 위험성을 인지하고 논의해왔으며, FAQ 설명도 더 보완 예정 특히 MDM 사용경고를 명확하게 기재하는 방향 빠른 시일 내에 업데이트 계획 추가로, 루팅되었거나
            디버그 모드 기기에 대한 탐지 기능과 경고 기능도 탑재 MDM 탐지는 고양이와 쥐의 게임이므로, 사용자가 아예 업무용 기기를 쓰지 않는 것이 가장 바람직한 대응책이라는 의견
     * 언제쯤 정식 릴리즈가 나오는지, Obtainium에 등록하고 싶다는 일정 질문
          + 이 프로젝트는 라이브러리 형태라 등록에 적합한지는 잘 모르겠음 실제 등록 대상은 이를 사용하는 앱이어야 하며, 현재로선 Guardian 앱이 유일한 것으로 보임 추후 Guardian 팀에서 Play Store 이외 배포계획이 있을지 답변을 기다림
"
"https://news.hada.io/topic?id=21322","ClickStack – ClickHouse와 HyperDX로 만든 오픈소스 Datadog 대체제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ClickStack – ClickHouse와 HyperDX로 만든 오픈소스 Datadog 대체제

     * ClickStack은 ClickHouse 와 HyperDX 기반의 오픈소스 관측 플랫폼(Observability) 으로, 로그, 메트릭, 트레이스, 세션 리플레이를 한 곳에서 통합적으로 처리함
     * 로그 및 트레이스 검색과 시각화를 ClickHouse 클러스터 상에서 쉽고 빠르게 지원하며, 어떤 스키마든 추가 작업 없이 적용 가능
     * 직관적인 검색과 이벤트 기반 알림, 대시보드 기능을 제공해 엔지니어가 신속하게 문제를 파악하고 대응할 수 있음
     * OpenTelemetry 표준을 기본 지원하며 다양한 언어 및 플랫폼 SDK 통합을 제공함
     * 기존 상용 솔루션 대비 저렴하고 설정이 간단하며, 여러 관측 도구를 번거롭게 오가지 않아도 한 플랫폼에서 전체 절차를 처리함

주요 기능

     * 로그, 메트릭, 세션 리플레이, 트레이스의 상관관계 분석과 검색을 한 곳에서 처리 가능함
     * ClickHouse의 기존 스키마를 그대로 활용하며 스키마에 구애받지 않는 구조
     * 빠른 검색 속도와 시각화 최적화 덕분에 대용량 데이터에도 적합
     * 풀텍스트, 속성 검색이 모두 지원되고 SQL 사용은 선택
     * 이벤트 변화 추이 분석 및 간편한 알림 설정, 대시보드 생성이 가능함
     * Native JSON 문자열 쿼리 지원
     * 실시간 로그, 트레이스 tail 기능으로 최신 이벤트 확인이 가능함
     * OpenTelemetry 통합 및 APM(성능 모니터링) 환경 지원

배포 및 시작 방법

     * ClickStack 패키지는 ClickHouse, HyperDX, OpenTelemetry Collector, MongoDB를 포함하여 통합 배포 가능함
     * HyperDX UI는 브라우저에서 접근 가능함
     * ClickHouse Cloud 환경과도 연동할 수 있고, 다양한 환경에 손쉽게 배포가 용이함

어플리케이션 계측 및 통합

   HyperDX로 로그, 메트릭, 트레이스, 세션 리플레이 데이터를 수집하려면, 어플리케이션에서 테레메트리 데이터를 HyperDX로 전송해야 함
     * SDK 및 통합 옵션 제공: 브라우저, Node.js, Python 등 다양한 언어/환경용 SDK가 있어 쉽게 연동 가능함
     * OpenTelemetry 표준 지원: Kubernetes, JavaScript, Python, Java, Go, Ruby, PHP, .NET, Elixir, Rust 등 다양한 언어 및 런타임 호환 가능함
     * OpenTelemetry 수집기는 기본적으로 http://localhost:4318 주소에서 연결 가능함

기여 방법

     * PR 제출, 이슈 등록, 문서 개선, 오픈 이슈 투표, 새로운 사용 사례 제공 등 다양한 방식의 커뮤니티 기여를 환영함

개발 동기 및 철학

   HyperDX 개발진의 목표는 모든 엔지니어가 운영 환경의 테레메트리를 활용해 빠르게 문제를 해결할 수 있도록 하는 것임

   기존 주요 문제점:
     * 운영 관측 도구가 비싸고 데이터 확장에 따라 비용 증가 현상 문제가 큼
     * 설정과 사용 난이도가 높아 SRE 및 전문가가 필요함
     * 로그, 세션 리플레이, APM 등 각 기능이 분리되어 있어 정보 연계가 번거로움

   이러한 한계를 극복하기 위해 ClickStack과 HyperDX를 오픈소스로 제공함
     * HyperDX 는 ClickHouse가 인수했음

        Hacker News 의견

     * 왜 이미 존재하는 Grafana 대신에 커스텀 프론트엔드를 만들었는지 궁금증
     * DataDog 가격이 비싸서 HyperDX가 정말 매력적으로 느껴지는 상황 공유, 본인이 운영하는 LogLayer(https://loglayer.dev)는 TypeScript용 구조화 로거로 여러 종류의 로거와 클라우드 서비스(DataDog 등)로 로그를 전송할 수 있는 기능 지원, HyperDX용 통합 기능을 개발해서 곧 릴리즈할 예정 의견 공유, HyperDX와 LogLayer 연동 방법에 대한 문서 링크를 본인 사이트 ""integrations"" 섹션에 추가하고 싶다는 바람 전달, 관련 PR 링크(https://github.com/hyperdxio/hyperdx-js/pull/184) 공유
          + VictoriaLogs로 로그를 전송할 수 있는 기능도 추가해 달라는 요청, 다양한 데이터 인제스쳔 프로토콜 문서 링크(https://docs.victoriametrics.com/victorialogs/data-ingestion/)와 함께 제안
          + LogLayer와 HyperDX 연동 기능이 멋지게 보여서 직접 확인해 보겠다는 긍정적인 피드백
     * HyperDX를 실제 프로덕션에서 사용 중이고 Clickhouse와의 통합 및 비용 효율성에 큰 만족감, HyperDX에서 ClickStack으로 마이그레이션 준비가 필요한지 궁금증
          + 프로덕션 유저의 피드백에 항상 기대가 크다는 반가움 전달, HyperDX는 절대 없어지지 않고 마케팅 페이지에서도 여전히 스택의 핵심으로 강조되고 있음 설명, 앞으로 HyperDX v2와 ClickStack 패턴에 더 집중할 계획이지만 HyperDX 자체는 계속해서 엔드 유저 경험에 중점을 둘 예정 안내, ClickHouse 기반 코어의 유연성과 성능을 더 많이 활용하려는 것이 ClickStack의 목표라는 추가 설명, 오픈소스와 클라우드 양쪽에서 모두 스무스하게 변화할 수 있도록 엔지니어링에 집중 중임 공유, 사족으로 최근 와이파이가 불안정해 답변이 늦어진 상황 언급
     * Otel의 트레이스와 로깅은 괜찮지만, Otel metrics 기능은 너무 복잡하게 설계됐다고 느끼는 점 공유, ClickStack에서 statsd 데이터(특히 Datadog의 태깅 확장 포함)를 인제스트할 수 있는지, 트레이스/로그/메트릭의 통합 서비스 태깅과 연결 기능 여부, UI에서 관련 데이터 링크 기능 여부, Elixir SDK가 왜 hyperdx 라이브러리를 쓰는지 궁금, Notebooks 기능이 로드맵에 있는지 질문
          + 좋은 질문이라는 호응과 함께 Otel metrics 표준이 워낙 다양해진 이유 및 아쉬운 점 공감, OTel collector가 statsd 등 다양한 포맷 수집 및 ClickHouse로 바로 기록할 수 있어 statsd 활용 가능하다는 안내(statsdreceiver 문서 링크), 로그/트레이스는 trace/span id와 resource attributes로 연결 가능하고, k8s workload에서는 메트릭까지 관련성 제공 중임 언급, 아직 metrics correlation에 exemplars 기능은 미지원이지만 향후 계획 언급, Elixir SDK는 유저 환경에 맞게 지원하려는 방향에서 선택, 라이브러리가 독립적으로 진화해왔고 앞으로 공식 OTel SDK로 전환할지 고민 중임, Deno용 OTel integration을 직접 빠르게 도입한 사례 공유, Notebooks는 곧 실험적 상태로 공개될 예정이고 다양한 워크플로우를 활성화할 예정, 더 많은 유저 피드백에 관심 있다는 의사 전달
          + Otel metrics가 복잡하다고 느끼는 이유를 묻는 질문과 함께 statsd나 DD agent 등 기존 메트릭 파이프라인을 쉽게 대체하지 않아도 된다는 장점 안내
     * Signoz처럼 클릭하우스 기반이고 오픈소스 및 클라우드 버전을 제공하는 것이 HyperDX와 유사해 보인다는 의견 및 차이점에 대한 궁금증, UI도 비슷하다는 관찰 공유
          + Signoz와의 직접 비교를 더 듣고 싶다는 추가 궁금증
     * Kibana를 대체할 새로운 로깅 솔루션 탐색 중이며 ClickHouse 경험이 좋아서 HyperDX의 UI에 관심, 현재 로그 파이프라인이 Kubernetes 위 Vector이고 Vector가 OTel sink(베타) 지원 중이어서 데이터가 JSON인 상황에서 가장 좋은 로그 전송 방식 고민 공유, TB 단위의 대용량, 고성능 트래픽 환경임 강조
          + ClickHouse는 대용량 처리와 높은 스루풋에 특화, Vector에서 ClickHouse 직접 기록을 사용하는 사례(예: Anthropic 발표) 언급, 실제로 시도해 보고 의견 남겨주면 도움 주겠다는 제안
          + 데이터 전송 포맷을 otel로 표준화하는 것이 미래를 위해 전략적으로 좋은 선택이라는 의견, 두 가지 고민이 줄어든 느낌 공유
     * Signoz와 HyperDX(혹은 ClickHouse)와의 차이점이 궁금, 둘 다 YC 출신이며 클릭하우스를 활용하는 관찰
          + 아래에서 언급된 내용과 같이 가장 큰 차별점은 ClickHouse 팀에서 공식적으로 개발하는 1st-party 상품이라는 것, 거의 모든 클릭하우스 인스턴스에서 유연하게 동작하고 커스텀 스키마도 지원, 이는 고성능 튜닝이나 특정 대규모 환경(예: Anthropic)에서 중요, 이미 클릭하우스 데이터를 가진 경우 도입이 매우 쉽다는 장점 있음, otel을 무조건 강요하지 않으며 Vector, Cribl, S3, 커스텀 스크립트 등도 네이티브로 지원, Telemetry wrangling(고카디널리티 이벤트 델타, ML 기반 자동 로그/스팬 클러스터링 등) 기능도 있어 데이터 탐색이 쉽게 가능, session replay 기능으로 클릭부터 인프라 메트릭까지 전방위 통합 지원, 내부 ClickHouse Cloud 모니터링에서 100PB+ 스케일로 운용 및 특정 유저 이슈까지 end-to-end로 파악 가능한 유연성, 철학적으로 일반적인 ""3 pillars""(logs/metrics/traces)
            분리보다는 단일화/중앙화된 단서 탐색 도구를 만드는 것이 오히려 실무 디버깅에 적합하다고 믿음 공유
          + “You”가 ClickHouse임을 명확히 함
     * 회원가입 후 UI에서 ""Was this search result helpful?"" 위젯이 검색 전부터 나와 있어 UX가 혼란스러웠던 경험 공유, Hide 버튼을 누르면 피드백 버튼 → 다시 피드백 누르면 원상복귀되는 버그 발견, 전반적으로 폰트가 모노스페이스인데다 글씨도 작고, 굵은 흰색 및 밝은 초록색이 어두운 배경과 조화가 나쁘다고 평가, 시스템 폰트로 바꿔도 크게 개선되지 않아 전통적인 UI 스타일을 권장, 읽기 힘든 디자인 때문에 사용을 망설이게 하는 점 피드백
     * Clickhouse가 이 스택의 유일한 stateful 요소인지 궁금, Rust 기반 OTEL collector인 Rotel(https://github.com/streamfold/rotel)과의 호환성에 관심, Datadog은 자체 개발한 더 뛰어난 퍼포먼스의 OTEL collector 대체재가 있음 언급
          + Rotel은 lambda 등 경량 환경에 OTel 연동에 적합하다고 판단, HyperDX의 OTel 인제스트 엔드포인트가 이미 표준이기에 바로 호환 가능할 것이라 생각, Rotel 개발자들과도 소통했으며 Clickhouse 지원이 최근 추가되어 전체 스토리가 탄탄해진 점 강조
"
"https://news.hada.io/topic?id=21308","팀이 너무 커졌을 때","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              팀이 너무 커졌을 때

     * 전문가 중심의 대형 팀은 내부 의존성, 전달 오류, 병목, 책임 분산 등으로 인해 생산성과 협업 효율이 급격히 저하됨
     * 일일 스탠드업 미팅에서 대부분의 내용이 불필요하거나 지루해지는 등, 팀 규모 증가와 전문화가 소통 단절과 무관심을 불러일으킴
     * 기술별(프론트/백엔드) 분리, 임시 피처팀, 외부 컨설턴트 활용 등 여러 실험이 있었으나, 결국 범용적 역할(제너럴리스트)로 전환이 가장 실질적 효과를 냄
     * Mob프로그래밍 등 집단 협업은 지식 공유와 자기주도성, 책임감, 동기 부여를 촉진하며, 단일 분야 고집보다 결과 중심의 협업과 성장에 유리함
     * 단, 범용화의 부작용(전문성 저하, 번아웃 위험)도 존재하며, 지속적인 실험과 문화적 개선이 필수적임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

팀이 너무 클 때의 문제

     * 14명 규모의 대형 팀에서 시작된 문제: 스탠드업에서 대부분의 대화가 불필요하며, 업무 전달 누락과 비공식 작업 발생 빈번
     * 비동기 스탠드업(Slack 등) 으로 전환해도 핵심적인 대화와 협업 기회가 사라지고 단순 보고서로 변질

다양한 분할/운영 실험

     * 기술별(Task Force) 분리: 프론트엔드/백엔드로 나눴으나, 즉시 상호 의존성 문제와 추가 스탠드업 참여로 시간 증가
     * 임시 피처팀: 특정 기능 구현에 따라 인력 임시 재배치, 유지보수/자원 관리 이슈 발생
     * 외부 컨설턴트 투입: 이미 팀이 큰데도 비효율, 상위 경영진의 자원 활용 압박

최종적으로 효과적이었던 해법

     * 스페셜리스트 대신 제너럴리스트(범용가) 모델 도입
          + 프론트엔드, 백엔드, QA, DevOps 등 역할 분리 없이 한 목표/제품을 중심으로 전체 스킬셋을 나눠 가짐
          + 지식 공유, 책임 분산 감소, 병목 해소, 더 빠른 전달/고품질 실현
          + Mob 프로그래밍 등 집단 협업으로 소통/자율성/소유권 강화

왜 제너럴리스트가 효과적이었나

     * 공통 맥락과 목적: 새로운 분야라도 동일 제품/목표를 기준으로 학습 곡선 완화
     * 한정된 필요: 특정 도구(CI/CD 등)만 익혀도 충분, 깊은 전문성보다 생산성·유지보수성을 중시
     * 동기 부여 3요소(자율성, 숙련, 목적) 를 모두 충족, 팀의 주인의식과 성장 지원
     * Egalitarian 문화: 평등한 접근권, 자율적 지식 습득, 권한과 책임 분산, 집단 학습
     * 책임의 3요소(지식, 권한, 책임) 가 명확, 소유권 기반의 빠르고 높은 품질의 결과 도출

부작용 및 한계

     * 전문가의 이탈: 범용화가 모든 사람에게 맞지 않음, 특정 인력의 번아웃·리소스 과열 발생
     * 전문성의 깊이 부족: 다양한 스택을 얕게 다루는 만큼, 한 분야의 깊은 숙련은 저해될 수 있음

결론 및 교훈

     * 일률적 해법은 없으며, 실험과 개선의 문화가 더 중요
     * 스페셜리스트 모델의 단점(병목, 소통 단절, 페이크 워크, 맥락 단절)을 제너럴리스트와 집단 협업으로 해소 가능
     * 궁극적으로는 목표, 인력, 예산, 제품 특성에 따라 최적화된 모델이 달라질 수 있음
     * 핵심은 열린 실험, 피드백, 지속적 개선의 문화

   저는 제너럴리스트지만, 실무에서 느낀 건 이렇습니다.
   쓸모 있는 건 제너럴리스트지만, 진짜 '가치'를 인정받는 건 스페셜리스트더라고요.
   같은 대학, 같은 학점을 나와도 결국 스페셜리스트들이 2~3배 더 높은 보수를 받는 현실입니다.

   저도 비슷한 생각입니다.
   근데 제 생각엔 sw기준으로 미국 딥테크 아닌이상 스페셜리스트는 진짜 스페셜 하지 않는것같습니다.

   혹시 예시를 부탁드려도 될까요! 실질적으로 스페셜리스트라 불린다는게 어느 정도의 '스페셜'인지 궁금해서요...

   HR 기준으로는 대기업 혹은 중견기업에서 3년 정도 경력을 요구하는 것 같고, 제 기준의 ‘스페셜리스트’는 백엔드 관점에서 LLM을 활용해 누구나 쉽게 사용할 수 있고 고가용성까지 고려된 구조를 설계할 수 있는지를 봅니다.
   예를 들면, 저는 제너럴리스트지만 국내 어떤 서비스든 1억 명 이상 트래픽을 초등학생도 이해할 수 있을 만큼 단순하게 설계할 수 있어요.
   근데 또 제너럴리스트라서 대기업 서류는 잘립니다 ㅋㅋㅋ
"
"https://news.hada.io/topic?id=21362","디버그 모드에서 자체 호스팅 x86 백엔드가 기본값으로 설정됨","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   디버그 모드에서 자체 호스팅 x86 백엔드가 기본값으로 설정됨

     * 이제 x86_64 타겟 시, Zig의 자체 x86 백엔드가 디버그 모드에서 기본값으로 적용됨
     * 기존 LLVM 기반보다 더 많은 동작 테스트 통과와 빠른 컴파일 속도 달성함
     * 자체 백엔드 도입으로 Zig의 컴파일 시간 대폭 단축 및 일부 작업의 효율성 증대됨
     * 최근 보완된 빌드 시스템, BSD 계열 OS 지원 확대, UBSan 런타임 개선 등 여러 기능 강화 진행됨
     * 표준 라이브러리와 자체 도구 최적화로 Zig만의 경쟁력 강조됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

최신 주요 소식 요약

  2025년 6월 8일 – 자체 호스팅 x86 백엔드, 디버그 모드에서 기본값으로 전환

     * x86_64 타겟에서, 이제 기본적으로 Zig의 자체 x86 백엔드가 사용됨
          + 이전에는 LLVM을 사용해 비트코드에서 오브젝트 파일로 변환하는 방식이었음
          + Windows는 COFF 링커 작업이 더 필요해 변경이 미뤄진 상태임
     * Zig의 x86 백엔드는 1,987개의 동작 테스트를 통과하여, LLVM 백엔드(1,980개)보다 더 강력한 안정성 보임
          + 전체 테스트는 2,084개지만 일부는 LLVM 자체 테스트와 중복되어, 자체 백엔드 테스트 시에만 추가 확인함
     * Zig가 자체 코드 생성기 개발에 집중하는 주된 이유는, 빌드 속도에서 LLVM을 월등히 능가하기 위함임
          + 벤치마크 결과 확인 시, zig build-exe hello.zig -fllvm(LLVM 사용)의 평균 빌드 타임은 918ms, 자체 백엔드는 275ms 기록함
          + 메모리 사용량, CPU 사이클, 명령어 수, 캐시 미스 등 모든 면에서 대폭 개선된 성능 확인 가능함
          + Zig 컴파일러 자체와 같은 대규모 프로젝트의 빌드 시간도 75초에서 20초로 단축됨
     * 향후 코드 생성 완전 병렬화 구현 및 링크 기능 강화, aarch64 백엔드 개발 등이 예고되어 있음
          + 새로운 Legalize 패스 도입으로 aarch64 작업도 가속화될 예정임
     * 최신 변경사항은 Zig 마스터 브랜치 최신 빌드를 통해 직접 경험해 볼 수 있음

  2025년 6월 6일 – 빌드 시스템 소개 영상

     * Zig 빌드 시스템 입문자를 위한 YouTube 가이드 영상이 공개됨
          + Zig 모듈과 패키지 생성, 이를 다른 프로젝트에서 임포트하는 방법 등을 설명함
          + 추가 빌드 시스템 관련 영상도 시리즈로 계속 추가될 예정임

  2025년 5월 20일 – FreeBSD 및 NetBSD 타겟 지원 강화

     * Pull Request #23835, #23913 병합으로 zig cc와 zig build로 FreeBSD 14.0.0+ 및 NetBSD 10.1+ 타겟 바이너리 빌드 가능해짐
          + 기존 glibc에서 적용되던 libc 및 관련 라이브러리 정보를 추출하는 전략을 BSD 계열에도 확장 적용함
          + 생성된 abilists 파일이 Zig와 함께 배포되어, 교차 컴파일시 각 libc 라이브러리에 정확히 매칭되는 스텁(stub) 라이브러리 생성 가능함
          + 시스템 및 libc 헤더도 최신 OS 버전 기준으로 함께 제공됨
          + OpenBSD, Dragonfly BSD, SerenityOS, Android, Fuchsia 등도 지원 목표임

  2025년 4월 9일 – 공식 Zig 사이트, 독립 실행형 Zine으로 빌드

     * 공식 Zig 웹사이트가 이제 독립 실행형 Zine으로 빌드되는 구조로 변경됨
          + 기존 빌드 스크립트에서 단일 실행 파일로 발전함
          + 직접 사용해볼 좋은 타이밍임을 알리고 있음

  릴리즈 및 기능 개선 소식

     * 0.14.0 릴리즈가 곧 배포될 예정이며, 주목할 만한 개선들이 이미 적용됨
     * C interop 및 UBSan(Undefined Behavior Sanitizer) 런타임 개선으로, 이전엔 모호했던 SIGILL 에러가 구체적이고 유용한 오류 메시지로 대체됨
          + 예) 서명 정수 오버플로 발생 위치와 원인을 명확히 표시해 디버깅 효율성 크게 향상됨
     * 남은 UBSan 한계:
          + C++ vptr 관련 동적 타입 및 생명주기 검사 미지원
          + assume_aligned, __nonnull 등 속성의 정확한 위치 표시 미완성

  2025년 2월 7일 – 디버그 할당기 및 SmpAllocator 혁신

     * 디버그 할당기가 재설계되어 런타임 페이지 크기 인식 지원 및 다양한 최적화 반영됨
          + 메모리 맵 생성 감소, 불필요한 0xaa/0x00 memset 반복 제거, 탐색 및 트립 자료구조 제거 등
          + 페이지 내에 메타데이터를 인라인 방식으로 저장해 컴파일 에러/검증을 쉽게 구현함
          + 기존 C 기반 malloc에 비해 가독성 및 유지보수성 우위 확보
     * 동시성 환경에서 최적화된 SmpAllocator 개발로, multi-thread 환경에서의 메모리 할당 실행 효율 극대화됨
          + glibc와의 성능 비교 벤치마크에서 속도와 자원 사용 효과 실제 증명됨
          + 결과적으로 Zig 사용성이 C 및 libc를 능가하는 중요한 전환점으로 평가됨

  2025년 1월 24일 – Zig 전용 디버깅 환경 제공

     * Jacob이 Zig용 LLDB(디버거) 포크를 개발, 자체 백엔드의 디버깅 지원을 강화함
          + LLDB 포크 빌드 및 사용법이 위키 문서로 제공됨
          + Zig 자체 백엔드를 사용하는 개발자는 해당 도구로 더욱 정교한 디버깅 환경 활용 가능

결론

     * Zig는 자체 기반의 성능 향상, 빌드 효율, 디버깅 편의성 강화를 핵심 목표로 혁신적 변화를 계속 추진함
     * 독립적 알고리듬, 컴파일러, 빌드/런타임 도구 모두에서 차별화된 경쟁력을 확보하는 중임
     * BSD 등 다양한 플랫폼 지원, 사용자 중심 메시지 개선, 메모리 모델 혁신을 포함하여 소프트웨어 엔지니어 실무자에게 실질적으로 유익한 발전을 이어가고 있음

        Hacker News 의견

     * 내가 알기로 Zig는 개발 환경을 더 좋게 만들기 위해 매일 다양한 기능을 작업 중인 상황임. 예를 들어 최근에는 이 PR도 있었음. 예전에 Zig에서 핫 코드 스와핑(hot code swapping)도 개발 계획에 있었고, 이 개발 속도라면 아마도 1년 내에 x86_64에서 이 기능이 가능해질 거라는 예상임. 개인적으로 느끼는 가장 큰 불편함은 comptime의 속도임. 컴파일 타임에 brainF** DSL을 돌렸던 실험이 있었는데, 정말 느리게 돌아감(하지만 재밌는 실험이었음). 컴파일러의 이 부분이 언제쯤 개선될지 궁금함. 새로운 백엔드들에 대해서도 굉장히 기대 중이며, Zig용 나만의 URCL 백엔드도 만들어 보고 싶은 마음임 😉
          + comptime 성능 개선에 대해선 뭘 해야할지 이미 알고 있고, 아주 예전에 관련 브랜치도 시작했던 경험이 있음. 하지만 이건 의미있는 규모로 시맨틱 분석 코드를 다시 작업해야 하는 부분이라, 중요한 일 중 하나지만 다른 우선순위들과 경쟁하는 상황임
          + 핫 코드 스와핑은 게임개발 분야에서 엄청난 변화를 줄 수 있는 기능임. Zig에서 이게 기본적으로 컴파일러 플래그만으로 지원될 예정이라는 점이 놀랍게 다가옴. clang으로는 시도조차 힘든 것이기 때문임
          + URCL에 대해 깊게 살펴보진 않았지만, 이게 나를 또 다른 토끼굴로 이끌고 있음. 마인크래프트용으로 만들어진 IR이 언어의 실제 컴파일 대상이 되는 진짜 기괴한 시나리오가 만들어지는 게 아닐지 상상하게 됨
          + 커스텀 백엔드를 만드는 게 쉬운지 궁금함. 아직 직접 시도해보진 않았지만, AIR를 받아서 메모리 안전성 리포트를 만들어주는 백엔드 실험을 해보고 싶은 생각임(예를 들면, 정의되지 않은 값 사용, 스택 포인터 이스케이프, use-after-free, double free, alias xor mut 등 체크하는 방식)
          + comptime이 정말 느린 게 문제인지 궁금증이 있음. 나는 JSON-RPC 라이브러리 제작 중인데, 컴파일 타임에 comptime을 적극적으로 활용해서 JSON을 임의 함수로 분배하고 있음. Zig의 강력한 정적 타입으로 런타임에 임의 파라미터가 있는 함수에 동적으로 분배하는 게 불가능해서, 컴파일 타임에 함수 타입 맵핑을 만들어내는 방식을 써야만 했음. 이러면 각 함수마다 comptimed된 코드가 복사되면서 바이너리 크기는 커질 수밖에 없다는 점이 걱정임
     * 이미 이 정도까지 도달한 것만으로도 대단한 성과임. devlog에서도 밝혔듯 앞으로가 더 기대되는 상황임. 컴파일러가 빌드할 때 바이너리의 필요한 부분만 바꾸는 개념은 신선하면서도 파격적으로 느껴지며, Zig 프로젝트 덕분에 이제 실현 가능한 목표가 됨. 앞으로 굉장히 흥미로운 시간임
     *

     Zig 컴파일러와 같은 대형 프로젝트에서는 빌드 시간이 75초에서 20초로 줄었다는 언급이 있음.
     앞으로 이걸 어디까지 개선할 수 있을지 무척 궁금함. Zig 개발자는 굉장히 똑똑한 것 같다는 느낌임.
     패키지 매니지먼트는 어떤 형태인지 궁금함. 예전에 QuickJS + SDL3 앱을 Zig로 해보려 했지만, C++의 복잡함에 밀려 결국 Rust로 갔었음. Zig에서도 시도해보고 싶음
          + Zig의 패키지 매니지먼트는 Rust에 비해 좀 더 수동적임. CLI에서 패키지 URL을 직접 가져오고, 빌드 스크립트에서 모듈을 임포트하는 방식임. 이 방식의 장점은 임의 아카이브도 쉽게 의존 패키지로 쓸 수 있고, 많은 Zig용 C 라이브러리 패키지는 단순히 언터치드(tarball) 릴리스를 빌드 스크립트에서 직접 연결하는 구조임. 다만, 초보자에겐 조금 복잡할 수 있음
            SDL3의 경우 네이티브 Zig 래퍼(https://github.com/Gota7/zig-sdl3)와, 좀 더 단순하게 C 라이브러리/ API를 Zig화한 https://github.com/castholm/SDL 두 가지가 있음
            QuickJS는 오직 C API(https://github.com/allyourcodebase/quickjs-ng)만 지원함
            Zig는 C 패키지를 직접 사용하기가 매우 쉽지만, 타입이 엄격해 API를 다룰 때 타입 캐스팅이 자주 필요할 수 있음
          + dmd D 컴파일러는 자체를 디버그 빌드 기준 약 18.4초에 컴파일할 수 있음.
            내 프로세서는 아주 오래된 AMD Athlon 64 X2(4400+)인데 워낙 빠르게 돌아가서 아직 업그레이드조차 안 했음
            (자세한 CPU 정보 목록 포함)
          + fast development cycle을 위해 Zig를 20초만에 빌드하는 가이드가 있는지 궁금증임. 예전에 Zig를 빌드할 때 여러 스테이지(특히 WASM에서 부트스트랩)가 있어 시간이 정말 오래 걸렸던 경험이 있음
          + Zig가 LLVM을 쓴 상태로도 자체를 75초만에 컴파일한다는 점이 엄청 놀라움
     * Zig에 무리한 요구를 전혀 할 의도는 없고, 오픈소스임을 잘 알고 있지만 현실적인 1.0 출시 일정에 가장 많은 관심이 있음.
       Zig는 저수준 언어에서 내가 원하던 바를 거의 완벽히 담은 언어이고, 이제 안정화만 기다리는 중임.
       그리고 Zig의 미니멀리즘 디자인 철학에 진심으로 감탄함
          + tigerbeetle과 같은 실제 프로젝트들은 보통 릴리스 버전을 고정해서 사용하고 nightly는 실험용으로만 쓰는 경우가 많은 것으로 알고 있음
     * 완전 초보자로서 Zig가 다른 언어 대비 가지는 장점은 무엇인지 궁금증임. 더 현대적인 C로 이해하고 있는데, 무엇이 ‘현대적’인 부분인지 궁금함
          + 당장 떠오르는 장점 몇 가지 정리임
               o 여러 개 별도 도구와 언어를 합치지 않아도 되는 통합 빌드 시스템
               o C의 배열(버퍼 오버플로우 문제) 대신 길이를 명확히 아는 슬라이스 제공
               o null 포인터가 기본적으로 허용되지 않는 명확한 optional 타입(필요시엔 타입이 명시적으로 드러남)
               o enum, tagged union, 그리고 switch 문 exhaustive 체크 강제
               o 에러 처리가 명확(kinda Rust 스타일). 함수가 반드시 에러를 반환하면, 호출자가 무시 불가. C처럼 반환값 무시해도 넘어가는 구조가 아님. 다만, 에러와 데이터를 한 번에 반환하는 표준문법이 없다는 점은 아쉬움
               o ""defer"", ""errdefer"" 블록으로 함수 반환/에러 발생시 자동 정리 작업 구현
               o 매크로 대신 comptime 코드 생성, 타입 리플렉션(@typeInfo 등)
               o 메모리 할당자는 호출자가 직접 관리(메모리 위치와 방식에 더 많은 결정권)
               o GeneralPurposeAllocator를 사용하면(초보 기준) 메모리 누수 추적이 좀 더 쉬움
                 C와 친숙하지 않고, C의 여러 불합리하고 직관적이지 않은 점 때문에 저수준 프로그래밍에 항상 진입장벽을 느꼈는데, Zig는 처음으로 시스템 프로그래밍에 재미와 흥미를 느끼게 해준 언어임
     * Zig를 20초만에 빌드할 수 있는 가이드가 있는지 궁금함. 개발 주기를 빠르게 돌리고 싶은데, stage1/2/3 모두 빌드에 시간이 오래 걸려 기여하기가 쉽지 않았던 경험이 있음
     * Zig에서 zig init으로 헬로월드 빌드시 9.3MB가 나온다는 점이 있다면, -Doptimize=ReleaseSmall 플래그를 쓰면 7.6KB로 줄어듦
       플래그 하나로 1000배 이상 차이가 나는 상황임
          + 실제로 그 차이의 82%는 디버그 정보 때문임
            -OReleaseSmall -fno-strip은 580KB, -ODebug -fstrip은 1.4MB까지도 나옴
            Zig의 x86 백엔드로 Zig 전용 LLDB fork로 훨씬 더 나은 디버깅 경험을 제공함
            현재 comptime 로직을 디버깅 중에 스텝으로 볼 수 있는지는 잘 기억나지 않지만 최근 논의 주제였음
     * Julia가 성능 이점 확보를 위해 Zig를 컴파일러로 고려해볼 만하다는 생각임. 매 릴리즈마다 성능 저하 걱정으로 불안해하는 Julia 개발자들의 마음도 기억남
          + Julia는 사실상 LLVM에 강하게 묶여 있음. 생태계의 여러 부분이 LLVM intrinsics, autodiff(Enzyme), GPU 컴파일 등의 존재에 의존함.
            컴파일러는 꽤 리타겟이 가능해지는 중인데, 이 부분도 현재 활발히 연구되고 있음.
            미래에는 Zig가 언어 일부의 대안 컴파일러가 되는 그림도 상상해볼 수 있음
          + LLVM 자체가 Julia의 public API라는 의견이 있음. 실제로 @code_llvm같이 직접 IR을 보여주는 매크로도 있음
          + 컴파일 타임을 줄이는 데에는 분명 효과가 있겠지만, 아직 Julia 쪽에서도 작업할 것이 많음
            컴파일 캐시를 더 세분화하거나, i invalidation 방지용 툴링, world splitting 최적화 제거, 컴파일러의 멀티스레딩 활용 증가, 특정 시그니처에 대해 자동 사전컴파일, lazily code를 컴파일/핫스왑하는 기능 등이 있음
     * Zig에게는 엄청난 발전이고, Rust와 비교할 때 앞으로의 주된 차별화 요소가 될 방향이라 생각함. 참고로, 퍼포먼스 분석 툴의 렌더링 코드 대부분을 내가 직접 짰는데, 내 코드가 온라인에서 널리 사용되어 기쁨
       poop 프로젝트 링크
          + Rust에도 cranelift를 활용하는 유사한 시도가 있음
            rustc_codegen_cranelift 참고
     * 이게 바로 Zig에서 async/await 기능을 다시 들여오기 위한 전제조건 중 하나라는 생각임
       async에 대한 Zig의 공식 FAQ도 참고할 만함
          + 이 부분은 이미 다 정리한 상태이고, 앞으로 2-3개월 내에 흥미로운 업데이트를 공개할 수 있을 것임. 거의 표준 라이브러리를 새로 만들 듯 I/O 전체를 다시 작업하고 있음
          + 링크에 따르면, async는 아예 다시 돌아오지 않거나 최소 2028년까지는 꿈도 못 꾸는 상황으로 보임
"
"https://news.hada.io/topic?id=21404","Chili3d – 오픈소스, 브라우저 기반 3D CAD 애플리케이션","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Chili3d – 오픈소스, 브라우저 기반 3D CAD 애플리케이션

     * OpenCascade를 WebAssembly로 컴파일하고 Three.js와 연동해, 브라우저에서 거의 네이티브 수준의 3D CAD 모델링·편집·렌더링을 구현한 오픈소스 프로젝트
     * 박스, 원기둥, 회전체 등 3D 형상 생성, 2D 스케치, 부울 연산, 익스트루드·로프트·스윕, 오프셋 등 다양한 CAD 모델링 기능을 지원
     * 오브젝트/워크플레인 스냅, 축 추적, 특징점 자동 탐지, 시각적 트래킹 가이드 등 정밀한 설계·편집 보조 기능을 제공
     * 챔퍼/필렛/트림/분할, 이동/회전/미러 등 고급 편집, 길이·면적·부피 측정, 문서 관리 및 산업 표준 포맷(STEP, IGES, BREP) 입출력 기능 내장
     * 오피스 스타일 UI, 계층적 어셈블리 관리, 다국어(i18n, 중영 지원) 인터페이스, 3D 뷰포트/카메라 제어 등 실무 중심의 사용자 경험 제공
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * Chili3D는 TypeScript로 개발된 브라우저 기반 오픈소스 3D CAD 애플리케이션임
     * OpenCascade(OCCT)를 WebAssembly로 변환, Three.js와 결합하여 설치 없이 웹에서 직접 고성능 3D 모델링/편집/렌더링이 가능함

주요 기능

     * 모델링 도구
          + 기본 3D 도형: 박스, 원기둥, 원뿔, 구, 피라미드 등 생성
          + 2D 스케치: 선, 호, 원, 타원, 사각형, 다각형, 베지어 곡선
          + 고급 연산: 부울(합집합, 차집합, 교집합), 익스트루드, 회전, 스윕, 로프트, 오프셋, 단면 생성
     * 정밀 스냅·트래킹
          + 오브젝트 스냅: 점, 엣지, 면 등 기하 특징점에 정확히 스냅
          + 워크플레인/축 트래킹, 자동 특징점 탐지, 시각적 가이드로 복잡한 3D 정렬을 쉽게 구현
     * 편집 도구
          + 모서리 라운드(필렛), 챔퍼, 트림, 분할, 이동, 회전, 미러 등 다양한 3D/2D 편집
          + 피처 제거, 서브셰이프 조작, 컴파운드 객체 해체 등 고급 편집
     * 측정·문서화
          + 각도·길이 측정, 전체 길이/면적/부피 계산
          + 문서 생성/저장/불러오기, 완전한 Undo/Redo, STEP/IGES/BREP 입출력
     * 사용자 인터페이스
          + 오피스 스타일 명령 구성, 계층적 어셈블리 관리, 동적 워크플레인, 3D 뷰포트/카메라 위치 저장 등 지원
          + 다국어(중국어·영어) 인터페이스, i18n 구조로 추가 언어 기여 가능

기술 스택

     * 프론트엔드: TypeScript, Three.js
     * 3D 엔진: OpenCascade(WebAssembly)
     * 빌드: Rspack, 테스트: Jest

오픈소스 개발 현황

     * 알파(Alpha) 단계로, API/기능/문서가 계속 개선 중임
     * 브레이킹 체인지와 문서 미완성, 일부 필수 기능 미구현 상태

기여·라이선스

     * 코드/버그/피드백 등 오픈소스 기여 환영
     * AGPL-3.0 라이선스(상업용 문의 별도 가능)

        Hacker News 의견

     * 처음에 설명을 읽고 그냥 평범한 3D 토이 프로젝트이겠거니 생각했는데, 실제로 해보니 놀라움 경험이었음. 엄청 빠르고 UI도 다른 도구에서 넘어온 입장에서도 꽤 직관적인 느낌. Fusion 360을 OpenSUSE Tumbleweed에서 쓸 수 없어서 항상 아쉬웠는데, 이 툴이 그 빈자리를 채워줄 수 있을 것 같음. 고마움 느끼는 상황
     * ""OpenCascade(OCCT)를 WebAssembly로 컴파일해서 사용"" 부분을 보고 어떤 지오메트리 커널을 택했나 궁금했음. 핵심 솔리드 모델링 라이브러리들이 사실상 몇십 년 전(Parasolid는 거의 40년 됨)부터 쓰이던 것뿐이고, 새로 만드는 게 정말 어렵겠다는 생각
          + GIS 용도로 BREP을 만지고 있는데, 2D에서 단순한 선분만으로도 정말 복잡한 문제 형태. 예외 상황이 정말 많이 발생하는 영역. 타입 시스템이 큰 도움이 되니, Rust 기반으로 작업하는 오픈소스가 있다면 아주 희망적으로 보임. 참고로 Fusion 360에서 Freecad 1.0으로 넘어가 봤는데, Freecad는 프로젝트가 거의 없긴 하지만 압도적으로 빨라진 상황 경험
          + 3D 지오메트리의 근본 수학적 구조는 오랜 시간 거의 변화가 없었던 상황. Parasolid나 ASICs 같은 커널의 라이선스 비용이 높지 않으면, 굳이 새로운 솔루션을 새로 만들 필요성이 별로 없음. 최근 시장은 Autodesk와 Hexagon처럼 CAD/CAM 소프트웨어 회사들이 계속 인수합병으로 통합 중인 추세. OpenCASCADE 역시 원래는 상용 소프트웨어였지만, 충분히 고객을 확보하지 못해서 오픈소스로 전환된 케이스
          + 오픈소스 지오메트리 커널이 실제로 거의 없음. 눈에 띄는 건 OpenCascade와 CGAL 정도인데, 혹시 더 있는지 궁금함
          + 이런 지오메트리 문제를 잘 해결하는 방법에 대해 더 읽어보고 싶음
     * 감탄스러운 수준인데, 아직 constraints나 sketches 같은 기능을 어떻게 구현하는지 잘 보이지 않는 문제. 그리고 웹앱으로 나온 건 약간 아쉬운 부분. 하지만 변화의 흐름으로 받아들이는 중
          + 학교에서 Chromebook을 사용하는 입장에서 이런 웹앱이 있다는 것은 너무 좋은 일. 학생들이 3D 프린터로 출력까지 할 수 있으면 도구 선택의 폭이 훨씬 넓어지는 경험 가능. 다만, 선생님이자 학부모로서 Chromebook만 경험한 아이들은 로컬 앱, 파일 시스템 등을 모르게 되는 점은 걱정. 아이가 포스터를 만들 때 이미지를 찾아서 여러 웹 도구에 복사-붙여넣기를 반복하지만, Affinity나 Photoshop 같은 데스크톱 앱에서는 한 번에 다 할 수 있다고 알려주면, 아이가 전혀 공감 못하는 느낌이 묘함
          + 현 버전에는 아직 해당 기능이 없지만, 향후 파라메트릭 컴포넌트 형태로 추가될 예정
          + 웹앱 얘기보다 constraints나 sketches 등 파라메트릭 설계가 얼마나 중요한지에 더 주목할 필요. 개인적으로는 이런 부분이 CAD 프로그램이 진지하게 받아들여질 수 있는 핵심 요소
          + 브라우저도 네이티브 앱 못지않게 강력해질 수 있음을 보여주는 사례. 브라우저 기반이라 OS 종속성이 사라지고, 전 세계 엔지니어나 학생들이 파일 공유나 오픈이 쉽게 이루어지는 장점이 큼. 새로운 노트북에서는 오히려 네이티브 앱보다 속도도 더 빠른 경험. 회원가입, 이메일, 2FA 등 복잡 없이 30초 만에 그림 그리기 시작 가능. 대부분의 다른 툴들에 비해 비용 등 여러 면에서 이점. 최근 SketchUp, AutoCAD, Revit 등을 쓰다가 이 툴을 발견해서 미래가 정말 기대되는 느낌
     * 툴 아이콘 이름이 다소 생소하고 익숙치 않은 부분이 있었음. 예를 들어 ""Bessel"", ""pour corner"", ""From the cross section"" 같이 CAD에서 흔히 쓰는 영어 용어로 바꿔야 할 필요. 사용 중에 언어가 갑자기 중국어로 전환되었는데, 다시 영어로 전환하는 쉬운 방법이 없다 보니 어려움이 있었음
     * 훌륭한 작업이라고 생각. 특히 Dassault, Autodesk 등 소수 업체가 장악한 분야에서 오픈소스 프로젝트가 나오는 걸 볼 때마다 반가움. 최근 LLM 등 AI 활용으로 컨텍스트 인식 CAD 영역이 생기는 문제도 기대
     * 정말 대단함. OnShape 비슷한 제품만 계속 찾고 있었음. 이런 툴이라면 수백 달러라도 기꺼이 결제할 의사 충분. OnShape 라이선스가 너무 비싸서 1천 달러 넘는 돈을 내는 건 부담이라 생각
          + OnShape 직원으로서, 실사용 목적이 비영업용이고 문서가 공개되어도 된다면 OnShape의 무료 버전으로 충분히 쓸 수 있다고 생각. 현재 OnShape가 유지, 확장, 성능을 보장하는 기술 스택이 워낙 복잡하고 운영비용도 상당함
          + OnShape 무료 플랜도 개인적으로는 매우 넉넉하게 느껴지는 상황
     * 인터페이스가 무척 마음에 듦. FreeCAD에도 이런 형태가 있었으면 참 좋겠다는 바람. 개인적으로는 파이썬 인터페이스로 파라메트릭 모델을 만드는 스타일이지만, 이 프로젝트는 꽤 멋지다고 느낌. Truck 프로젝트의 CAD 커널이 오픈소스 CAD로 구현될 계획이 있는지 궁금. Truck이라는 현재 프로젝트가 아주 유망해 보임
          + CADmium이 Truck 커널 기반임. 다만 CADmium은 2024년 6월 이후 별다른 활동이 없고, 참고로 CADmium 링크. 또 Fornjot 커널도 함께 있음
          + FreeCAD 인터페이스에서 무엇이 마음에 들지 않는지 구체적으로 궁금
     * 정말 잘 만든 프로젝트라고 생각. 꼭 계속 발전해 나가길 바람. 특히 PCB 생산을 위해 EasyEDA가 제조사와 협력한 것처럼, 3D 프린터나 제조업체 (예: EasyEDA)와 팀을 이뤄서 일반 사용자가 자신의 디자인을 클릭 몇 번 만에 쉽게 제조까지 진행할 수 있도록 했으면 함
          + Slant3D와 접점을 만들어 보는 것도 추천. Slant3D의 텔레포트 3D 프린팅 서비스가 이런 통합 에디터 덕분에 더 발전할 수 있을 듯
     * 이 정도 성능과 UI를 동시에 갖춘 프로젝트가 흔치 않은데, 정말 기대되는 상황. 직관적이고 눈에 띄게 보기 좋은 인터페이스를 가진 3D 프로그램이 생각보다 드물다 보니 아주 반가움. 앞으로도 이런 프로젝트가 계속 많이 나왔으면 하는 바람
     * UI가 Microsoft 제품을 떠올리게 하는데 그 점이 오히려 꽤 긍정적으로 느껴짐. 일반적인 3D CAD 툴과 비교할 때 무엇이 다르다고 생각하는지와, 왜 이런 툴을 만들게 되었는지 그 동기가 궁금
"
"https://news.hada.io/topic?id=21315","자체 미디어 호스팅은 유해하다는 YouTube의 입장","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     자체 미디어 호스팅은 유해하다는 YouTube의 입장

     * 저자는 YouTube 커뮤니티 가이드라인 위반으로 자신의 LibreELEC 관련 비디오가 삭제되는 경험을 반복함
     * 심의 과정에서 알고리듬이 부적절한 판단을 내리며, 실제로 저작권 회피 도구를 다루지 않았음에도 불구하고 삭제 조치를 받음
     * 인간 검토를 통해 영상이 복구되었으나, 소셜 미디어에서 항의해야만 올바른 결과를 얻을 수 있었음
     * 저자는 YouTube 외 대안 플랫폼(Internet Archive, Floatplane)에 영상을 업로드하며 분산화의 필요성을 강조함
     * YouTube는 광범위한 도달성과 수익성이란 매력에도 불구하고, 창작자에게는 점점 더 불안정한 플랫폼임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

YouTube 커뮤니티 가이드라인 위반 경험

     * 저자는 Raspberry Pi 5에서 LibreELEC을 이용한 4K 비디오 재생을 시연한 영상이 YouTube 커뮤니티 가이드라인 위반 통보를 받은 두 번째 경험임
     * 영상에서는 불법 콘텐츠 다운로드나 저작권 우회 도구 사용법을 일절 다루지 않았으며, 저자는 실제로 오랜 기간 구매한 합법적 미디어만을 직접 서버에 저장해서 사용함
     * YouTube는 해당 영상이 “유료 오디오 및 소프트웨어 등 무단 접근법을 설명”했다는 이유로 삭제함

알고리듬과 인간 심사

     * 저자는 appeal을 제기했으나, 첫 검토에서는 영상이 복구되지 않음
     * 영상 업로드 후 1년 이상 문제없이 백만 뷰를 기록했으며, 불법 행위 유도 목적이 없었음에도 불구하고 삭제 조치가 내려졌음
     * “오픈소스 미디어 라이브러리 관리가 유해하다는 해석”에 당황함

결과 및 재업로드

     * 1일 후 인간 검토를 거쳐 YouTube 영상이 복구됨
     * 저자는 “알고리듬 판정만으론 이런 문제가 반복된다”는 사실을 지적하며, 영상의 백업을 위해 Internet Archive와 Floatplane등 대체 사이트에도 영상을 업로드함

대체 플랫폼의 현실

     * 저자는 기존 콘텐츠들을 Floatplane 채널로 점진적으로 옮기고 있으나, Peertube는 시청자 규모나 후원구조 면에서 유지가 어렵다고 설명
     * 콘텐츠 제작 및 오픈소스 활동 모두 후원 기반 자립이 어려워, 현재로선 YouTube의 AdSense 수익과 광범위한 도달성에 의존할 수밖에 없는 상황임
     * 최근 Google이 AI 요약 기능을 영상에 적용하면서, 자신이 만든 콘텐츠가 Gemini 등 AI 모델에 사용될 가능성에 우려를 표명함

플랫폼 의존성에 대한 반성

     * 저자는 YouTube가 여전히 혁신적인 플랫폼이지만, 플랫폼 주도 정책 변화와 알고리듬 오판에 따른 위험이 커지고 있음을 느꼈음
     * 직접 후원 기반의 자립이 필요하며, YouTube와 같은 대형 플랫폼에만 의존하는 것이 “황금 족쇄”임을 강조함

        Hacker News 의견

     * 코로나 관련 콘텐츠 삭제가 계속 확장되는 점이 문제라고 생각함
          + 또 다른 댓글에서 YT가 대안 영상 플랫폼이나 셀프호스팅 영상 소프트웨어 언급/홍보 영상을 백로그에서 없애는 작업을 누군가 갑자기 맡게 되었다는 얘기를 봄, 코로나 관련 영상 때와 비슷한 방식임
          + 영국에서는 Ofcom이 온라인 안전법(Online Safety Act) 도입에 관한 두 번째 세미나를 진행했는데, 이번엔 아이들의 안전을 지키는 것, 특히 “효과적인 나이 인증”이 주제였음
          + Ofcom은 플랫폼에 구체적 가이드라인을 전혀 주지 않겠다고 했고, 이유는 특정 조언을 주면 나중에 단속할 때 재량권 제한을 받기 때문이라고 함
          + 결국은 애매하고 복잡한 요건을 플랫폼이 각자 해석해서 Ofcom이 만족할지 모르는 규제를 도입해야 하는 상황이고, Q&A에서 대형 플랫폼조차도 이 부분을 제대로 해결하지 못하고 있다는 것이 드러남
          + 이 결과로 플랫폼들은 벌금 위험 때문에 점점 더 보수적으로 운영하게 될 것
          + 많은 이들이 “아이들 보호가 필요하다”라고 주장하는데, 그건 맞지만 이런 방식은 아이들 보호에 전혀 도움이 안 되고, 오히려 검열 기준 이하로 떨어지는 주제가 점점 더 많아질 것이라는 확신
          + 만약 코로나 이슈가 없었다면 YouTube나 Facebook 같은 플랫폼들이 콘텐츠 삭제를 한 번도 안 했을까? 원래부터 계속 삭제 중이었음
          + 여기에 문제점이 많음
          + 플랫폼이 자기가 어떤 콘텐츠를 올릴 수 있는지 고를 자유가 있는 건 언론의 자유임
          + 진짜 문제는 크게 두 가지임
              1. 몇몇 플랫폼이 사실상 독점적 지위를 갖고 있는 점, YouTube가 좋은 UI 때문이 아니라 Google의 광고 독점력을 활용해서 크리에이터들에게 돈을 벌 수 있게 해주니 다 모임. 제대로 된 반독점 시스템이 있었다면 Google Ads를 회사에서 분리시켰을 수 있음
              2. 오픈 인터넷이라는 약속이 파괴된 것. 벤처캐피탈은 우리를 울타리 안에 가두기 위해 수십억 달러씩 쏟아부었고, 오픈소스 및 셀프호스팅은 이익이 분산되는 구조라 오히려 피해를 봄
          + 정부가 오픈소스, 셀프호스팅 대안에 대한 자금 지원을 해야 하고, 쉽게 세팅할 수 있는 솔루션이 나와야 함
          + 만약 이 두 가지가 충족된다면, YouTube가 영상을 볼 수 있고 없고를 좌우하지 않고 큰/작은 크리에이터가 직접 호스팅해서 의사결정할 수 있게 되고, 오픈형 광고 시스템(블로그에 애드센스 꽂듯)으로 수익도 유지할 수 있음
          + 사실 하나의 규제가 또 다른 규제로 자동으로 이어지는 건 아니라고 생각함
          + YouTube는 코로나 이전에도 이미 불법 콘텐츠나 성인물 등 자사 정책에 맞지 않는 합법적 콘텐츠도 필터링하고 있었음
          + 왜 코로나 허위정보 필터링만 경쟁 저해적 조치의 미끄러운 경사로 여기는지 궁금함. 다른 모더레이션은 왜 크게 문제 삼지 않는데?
          + ""규제가 늘어나면 언젠간 나쁜 규제가 된다""라는 논리는 약하다고 생각함
          + 아이들을 보호해야 한다는 주장 중, 보호 자체는 동의하지만, 이 방식이 진짜 보호가 아니라 생각함. 검열의 범위가 넓어질 위험성이 큼
          + 예를 들어, YouTube에는 약물사용자를 위한 해악감소 영상들도 많은데, 아이들 보호법이 통과된다면 이런 영상이 죄다 삭제될 것이라 추측함. 약물에 대한 중립적 논의조차 보통 권장으로 여겨지기 때문임
          + 그로 인해 실질적 생명 구제 정보까지 사라질 수 있음
          + “문제적” 콘텐츠에 대한 모호한 규제가 보편화되면, 결국 기준은 점점 더 넓어지는 현상
          + TV 앱 제공사가 이걸 어떻게 구현할지 혼란스러움. TV에서 YouTube 보면서 매번 내 나이를 인증하고 이용자가 나라는 걸 확인하는 인터페이스가 불가능에 가깝다고 생각함. 결국 TV랑 컴퓨터랑 뭐가 다른지도 모호함. 비현실적임
     * Jeff가 글 끝에 인상적으로 별명을 남겼다는 부분이 좋았음
          + 저작권 침해(의혹)으로 영상을 내리면서, 정작 Youtube(Gemini)가 Jeff의 콘텐츠를 AI 학습 데이터로 가져가고 있다는 점이 아이러니함
          + AI가 “Dangerous or Harmful Content” 감지에서 틀리고 있는데, 아마도 좀 더 많은 저작권 침해가 필요한 거 아닌가 싶음
          + ""Youtube, via Gemini, is (allegedly) slurping the content of Jeff's videos for the purposes of training their AI models""에 대해, 사실 Google이 인정했음
          + 관련 기사
          + 여기서 ""agreement""란 아마 15년 전에 동의한 ToS를 의미할 것 같음
          + “저작권 홍보로 영상이 내려갔다” 역시 아이러니함
          + Gemini는 Jeff 영상 없어도 학습 데이터에 쓸 콘텐츠 아주 많이 가질 수 있음. Facebook도 그렇고, 구글이 원하면 어디에서든 자료 긁어옴
          + 광고용 데이터 수집도 마찬가지임. 내 데이터를 활용해서 더 나은 광고를 제공한다고 했지만, 실제 결과는 이미 구입한 상품 광고가 다시 뜨거나, 단순히 궁금해서 검색한 게 구매 욕구로 오해되는 수준임
          + 웃긴 얘기도 많아짐. “브라이트바트(극우매체) 검색했더니 테스토스테론 치료와 비아그라 광고가 뜬다!”(내 아내, 2014년)
          + 결국 소비자를 이런 식으로 대한다면 최소한 그럴만한 체감 효과라도 줘야 하는 거 아닌가 생각
     * 총기·스포츠 슈팅 관련 영상에 이상한 제약이 많은게 모든 주제에 발생하는 대형 문제임
          + 나는 사격 심판, 경기 심사위원 등인데, YouTube가 총기 콘텐츠에 대해 정말 이상한 제약을 둠
          + 예를 들어 탄창 용량이 살짝 다르게 비치면 10발짜리도 30발로 오해해서 영상이 삭제됐던 적이 있음
          + 소음기를 총기에 연결만 해도 삭제, 풀어서 보여주는 건 괜찮음
          + 규칙이 너무 모호해서 YouTube가 마음먹으면 총기 관련 영상은 언제든 차단 가능함
          + YouTube는 이 문제를 제대로 고칠 의지 전혀 없음. 잘못 걸러서 소송이라도 당할까 두려워서 애매한 규칙 그냥 유지함
          + 가족 중 한 명도 총기 안전 교육 콘텐츠로 채널 수익이 꽤 올랐음. 우리 지역에선 모든 것이 합법이고 권장되는 일임
          + 그런데 YouTube가 너무 말도 안 되는 장벽을 많이 만들어서 도저히 콘텐츠 제작 지속 불가. 결국 포기했고, 그로 인해 초보자들이 실제로 생명을 구할 만한 정보를 얻기 어려워짐
          + 코로나와 다른 정부 방침 불일치 정보는 살인으로 이어진다고 해서 다 내리더니, 총기 안전 영상은 아무렇지도 않게 삭제하는 아이러니
          + 담배 관련 콘텐츠도 마찬가지임. 파이프 담배 리뷰어 채널도 점점 규제가 심해짐
          + YouTube가 독점이 아니라면 신경도 안 쓸텐데, 경쟁이 너무 분산되어 아무 대체제도 커지지 못하는 상황임
          + 총기 법이 전 세계적으로 다르고 YouTube는 글로벌로 수익을 올리려는 기업임을 인지했는지?
          + YouTube가 미국 문화(총기 관련)를 세계 각국의 보수적 정서와 맞추려고 하다보니 이상한 규칙이 생기는 것으로 보임
     * 영상이 2년 넘게 아무 문제 없었는데 갑자기 경고 받고, 1시간 만에 항소가 승인된 적 있음
          + 누군가가 YouTube의 백로그를 점검하면서 대안 플랫폼·셀프호스팅 영상 언급 영상을 짚어내는 임무를 위한 듯 보임
          + 빠른 항소 승인 자체가 경고 메시지를 보내는 역할, 이런 주제를 얘기하려는 사람들에게 “생각 한번 더 해라” 신호 같음
          + “YouTube는 AdSense 수익과 엄청난 도달력이라는 황금 수갑을 쥐고 있다”라는 얘기도 있는데, Google이 최근에 Gemini AI 요약 기능을 영상에 붙이기 시작해서, 내 콘텐츠가 AI 학습 데이터로 쓰이고 있는 것 아닌가 하는 느낌도 받음
          + 블로그 결론 부분에서는 균형잡힌 시선이 있지만, 앞으로 인터넷이 어딜 향해 가는지 정말 궁금함
          + 크리에이터와 3자 콘텐츠 호스팅 플랫폼의 관계가 점점 얇아지고 “너는 곧 상품”이라는 실체가 점점 드러남
          + 크리에이터들이 결국 YouTube 같은 곳에 콘텐츠 올리기를 멈추게 될까? YouTube가 너무 많고 쉬워서 불가능한 일 아닌지? 갑자기 웹의 핵심 라이브러리(ffmpeg 등)가 너무 쉬워져서 클론 플랫폼이 우르르 생길 수는 없을까?
          + 모두가 유튜브가 아닌 새로운 선택지를 가질 수 있으려면 완전히 새로운 패러다임이 필요함
          + AI가 이를 가능하게 해줄지도 모른다는 기대
          + 예: “jeff의 새 영상 있나?”라고 물으면 집의 화면에서 영상이 재생되는데, 그게 YouTube에 호스팅 된 게 아니어도 아무도 신경쓰지 않는 미래
          + Peertube, Pixelfed, ActivityPub 기반 Instagram 대안 등 다양한 오픈 대안들이 등장함
          + 이상적인 다음 단계는 모두가 호스팅을 분담해서 좋아하는 크리에이터를 따라가면 되는 구조
          + 이런 구조는 영상 캐시/미러링도 자동으로 일어나게 해줌. 나는 예전에 1,400여개의 뉴스·저널리스트 계정을 Peertube에서 팔로우했더니 서버 디스크가 거의 1TB가 되어버려 서버를 닫았음
          + 대신 다른 지인 서버로 옮기고 데이터를 옮겼는데, 그 서버 주인은 저장공간을 별로 신경 안 씀
          + 1,500명씩 팔로우하지 않는다면 솔루션이 충분히 실현 가능함. 인기가 올라가면 사람들이 오래된 미디어 파일 압축하거나 콜드 스토리지로 옮기는 자동화 방법을 올릴 듯
          + “빠른 항소 승인은 사실 경고 메시지 정도였음”이라는 대목은, 이전 영상에 대한 얘기임
          + 지금 블로그의 본영상(합법 미디어 감상용 셀프호스팅 관련)은 항소가 거절됐던 듯
          + 아무리 크리에이터들이 빠져나가도 끝없이 대체 공급자가 등장할 것 같음
          + 이탈하는 과정에서 오히려 플랫폼이 원하는 콘텐츠만 남는 상황으로 수렴될 우려
          + 지난 10년간 비슷한 사례를 많이 지켜봤는데, 변화는 없고 플랫폼의 압박은 점점 강화됨
          + 대형 플랫폼(apple, google, amazon 등)이 자신에게 불리한 콘텐츠를 애매하게 해석해서 내려버리면, 스토리가 사회적으로 퍼질 때만 이슈가 됨
          + 대다수 일반 사용자들은 거의 모르거나 체감하지 못함. HN, Reddit 등에서 가끔 “대안이 필요하다” 말하지만, 이후엔 대형 플랫폼을 계속 사용하고 금세 잊어버림
          + “앞으로 인터넷이 어디로 갈 것인가”에 대해, 셀프호스팅이 답일지도 모름(물론 현실에선 쉽진 않음)
     * YouTube의 모더레이션이 진짜 술 취한 룸바가 일하는 느낌임
          + 오픈소스·셀프호스팅 콘텐츠엔 맥락을 완전히 무시하고 과하게 적용하면서, 정작 진짜 해적판 튜토리얼은 수년째 살아있음
          + LibreELEC 같은 오픈소스 툴 소개 영상은 플래그 뜨는데, NSFW 경계선에 있는 “예술”이나 “교육” 콘텐츠로 베껴낸 외설적 채널은 문제없이 광고까지 붙어서 운영됨
          + 실제로 이 모든 게 Google 알고리즘과 각종 저작권 단체 봇(스크리퍼)이 진행함
          + 심사 과정 역시 100% 자동화라서 인간이 한 번도 개입 안 함. 그 결과 알고리즘이 내린 실수가 계속 누적되는 구조
          + 수년 전에 올린 생음악 연주 영상을 올리면 저작권 스트라이크 걸리는데, 완전한 앨범과 영화 전체가 YouTube에 그대로 있어도 괜찮음. 정말 이상함
          + Geerling(Jeff)은 YouTube에서 벌어들이는 수익이 적지 않을 텐데, 유명한 크리에이터라서 그나마 인간 담당자나 유명 유튜버 네트워크로 조금 대응 가능함. 소규모 사이트나 신규 크리에이터는 실질적 보호 장치 없음
          + 인터넷 모더레이션이 전반적으로 다 이런 문제를 가짐. StackOverflow에서도 대량의 심사 큐를 인간이 일일이 보기 어려워서 휴리스틱만으로 “아니오” 연속 버튼을 누르기 일쑤였음
          + 큐의 대부분은 부적합이라 자동 반려 순서가 생김
     * 교육 목적으로 만든 Microsoft Access 튜토리얼 영상 두 개가 삭제된 적 있음
          + 가공의 의료 데이터베이스로 테이블, 쿼리를 가르치는 영상이었지만 표 기록을 보여줬다는 이유로 “PPI(개인정보) 노출”로 불합격 처리됨
          + 항소했지만 모두 거절, 인플루언서가 아니니 할 게 없음. 학생들은 이제 Access에서 날짜 쿼리 하는 법도 못 배움
          + 나도 비슷한 경험이 있음. 뒷배경에 라디오 음악이 아주 작게 나온다는 이유로 비공개 영상이 차단됨. 항소 절차엔 백색소음(incidental music)은 괜찮다 적혀있지만, 바로 거절 처리됨
          + 사실상 항소는 의미 없는 절차라는 걸 깨달음
     * YouTube가 “광고 차단기 끄세요!” 안내를 띄워서, 그냥 yt-dlp로 링크 받아서 오프라인으로 봄. 딱히 손해는 없음
          + 하지만 Google이 내 계정이나 가족 계정에 보복도 할 수 있으니 무시하기 어려운 문제
          + uBlock Origin Lite를 Chrome에서 잘 쓰고 있음. 필터 리스트를 체크해보면 좋을 것 같음
          + 나도 영상 3개까지 제한, 그 다음은 차단 경고가 나옴. 또 ‘와이드뷰’ 버튼도 사라짐. 링크 복사해서 Firefox Nightly에서 로그인 없이 광고 차단기로 보면 문제 없음. 조금 번거롭지만 여전히 시청 가능함
          + 클릭 2번이면 YouTube 영상은 여전히 볼 수 있는 방법 다수 있음
     * 요리(집밥)도 식당주인 입장에선 해로운 행위로 간주함(풍자)
          + 좋은 비유임. 실제로 집에서 요리하는 게 식당 음식보다 나은 경우도 많음. 집밥이 시간 많이 들긴 하지만, 이상하게 식당에서 먹는 게 더 어려운 현실
     * YouTube가 점점 더 구려지는 것 같음. 광고 차단기 안 된다는 안내 배너가 계속 뜨는데, 광고 없으면 영상 자체를 보기 힘든 수준
          + 그래서 그냥 yt-dlp로 영상을 다운받아봄. 만약 이 방법도 막히면 YouTube 자체를 사용할 의지도 없음
          + Premium 구독하면 광고가 없어짐. YouTube라는 방대한 서비스를 생각하면 이 정도는 정당한 댓가라고 생각
          + 광고 차단 플러그인 문제는 좀 더 창의적 접근이 필요함. 예를 들면 광고 영상에 빈 블록을 시각적으로 씌워버리고(음소거 등) 영상은 보여주는 앱을 만들어 쓰면 어떨까 생각
          + 30-60초라는 시간세금은 내지만, 정신은 빼앗기지 않아도 됨
          + 나는 pihole 같은 걸 돌리고, Samsung TV 사용자 에이전트로 YouTube.com/tv에 접속해서 거의 광고 못 봄. 가끔 홈탭에 배너만 뜸
          + 리프레시만 해도 현재는 광고가 넘어감
          + piped라는 오픈 소스 대안도 있음 piped 문서
     * 이번에 문제가 된 영상은 실제로 해적판을 조장하지 않음. 그걸 “위험하거나 해로운 콘텐츠”로 분류하는 게 더 이상함
          + “위험하거나 해로운”에 대해 해적판-테러-마약 범죄를 연결하려는 시도가 과거에 많았음
          + 크랙딜러, 무기상들이 돈세탁에 쓰기 좋은 게 해적판 DVD와 토렌트 광고라는 억지 연결논리가 있었음
          + “위험 & 해로움”의 진짜 의미는 Google의 수익구조에 해롭다는 것 같음
          + 물론 조심하지 않으면 연방정부에서 직접 딴지를 걸 수도 있긴 하겠음 ;)
"
"https://news.hada.io/topic?id=21377","사람들이 AI 작동 원리를 이해하지 못할 때 벌어지는 일","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    사람들이 AI 작동 원리를 이해하지 못할 때 벌어지는 일

     * 대다수 사람들은 LLM의 작동 원리와 한계를 제대로 이해하지 못해 인간적인 감정이나 지능이 있는 것처럼 착각하기 쉬움
     * AI의 인간화(Anthropomorphizing) 마케팅이 사용자를 오해하게 만들고, 실제로는 ‘확률 기반 예측기’일 뿐임에도 인간과의 관계 대체까지 조장함
     * AI 오용으로 인한 심리적 문제와 사회적 부작용이 현실화, 일부 사용자는 AI와 ‘영적/로맨틱’ 관계를 맺거나 현실 인식에 혼란을 겪음
     * AI 산업의 불투명성과 착취적 노동 문제도 지적, 특히 저임금 콘텐츠 검열 노동이 AI 발전의 이면을 이루고 있음
     * AI에 대한 무조건적 신뢰가 아닌, 올바른 이해와 비판적 시각이야말로 AI 부작용을 줄이고 사회적 통제 기반이 될 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

‘AI 문해력’의 부재와 그 위험

     * AI 산업의 환상
          + 19세기 산업혁명 비판에서 시작된 ‘기계 왕국’ 우려는 현대 AI까지 이어짐
          + Empire of AI·The AI Con 등 최근 저서들은 AI 산업의 과장과 실제 이면(노동, 데이터, 마케팅 허구)을 폭로
          + AI가 ‘생각’하거나 ‘감정’이 있다는 식의 설명은 개발자와 경영진이 퍼뜨리는 잘못된 신화임

LLM의 한계와 오해

     * LLM(대규모 언어 모델)은 생각하지 않고, 이해하지도 않음
          + 단어 배열의 확률적 예측기로서, 인터넷 텍스트 대량 학습 후 문장 구조만 흉내 냄
          + 사용자는 챗봇이 뭔가를 ‘이해’하거나 ‘공감’한다고 착각하기 쉬움(Anthropomorphizing)
          + 이런 오해는 사용자가 AI와 잘못된 관계(지적·영적·로맨틱 등)에 빠지게 할 위험이 있음

AI로 인한 사회적 문제

     * ‘ChatGPT 유발 정신증’ 등 AI 오용 부작용
          + AI를 ‘신’이나 ‘영적 안내자’로 여기는 사례가 실제로 등장
          + AI가 사용자를 특별한 존재로 호칭하며, 현실 인식에 영향을 주는 경우도 있음
          + LLM이 ‘생각’이나 ‘감정’을 가진 것처럼 믿는 것은 위험한 착각임

인간 관계 대체와 사회적 고립

     * AI 친구·AI 치료사 등 인간 대체 서비스 급증
          + 실리콘밸리 기업들은 외로움, 연애, 상담까지 AI로 대체하려는 흐름(“AI 컨시어지 데이트”, “AI 친구” 등)
          + 진정한 우정·관계의 본질은 ‘개인화’가 아닌 상호 이해와 협상임에도, 이를 기술로 오도함
          + 인간관계의 대체가 오히려 사회적 소외와 정신적 불안정으로 이어질 수 있음

AI 산업의 이면과 노동 착취

     * AI 발전 뒤에는 극한의 저임금·고스트 노동 존재
          + OpenAI 등 빅테크는 케냐 등지의 저임금 노동자가 극단적 콘텐츠 검열 작업을 수행하게 함
          + 기술 혁신의 명분 뒤에 노동 착취와 사회적 역진 위험도 공존

올바른 AI 이해와 사회적 대응

     * AI가 무엇을 할 수 있고, 할 수 없는지 비판적으로 인식해야 함
          + Pew 조사에 따르면 AI 전문가 56%는 미국이 AI로 더 좋아질 것이라 생각하지만, 일반인은 17%만 동의
          + AI에 대한 근거 없는 신뢰보다, 기술의 한계와 부작용, 대체 불가한 인간 경험의 영역을 명확히 구분하는 태도가 필요
          + 예를 들어, AI가 특정 행동을 보인 이유가 실제 ‘자아’가 아닌, 소프트웨어 업데이트나 확률적 반응임을 인지하면 피해 최소화 가능

결론

     * AI의 ‘인간화’ 마케팅에 속지 않고, 실제 기술의 원리·한계·사회적 비용을 비판적으로 바라볼 것
     * 인간 고유의 관계, 경험, 윤리적 숙고 영역은 기술로 대체할 수 없다는 점을 사회적으로 인식하는 것이 중요함

        Hacker News 의견

     * archive.is 링크
     * LLM을 점치는 도구, 우리 시대의 오라클이라 비유하고 싶음. 사실 ‘인공지능’이란 개념 자체도, 은밀한 지혜를 얻고자 하는 오래된 본능에서 비롯된 거라 생각함. LLM은 애매한 의미, 기호의 장, 숨은 지식의 환상, 그리고 의례적인 인터페이스까지 모두 갖추고 있음. 단지 밤하늘의 별과 달 대신 다크모드 UX로 꾸며졌을 뿐임. Barthes가 말했듯, 해석만이 의미이며 단어 자체로 본질이 있는 게 아님. 이 점을 잊다 보면 ""챗봇이 그를 메시아라 불렀다"" 같은 어이없는 해석이 나오게 됨. 새로운 것처럼 보여도 사실 본질적으로 전혀 새롭지 않음. 예전엔 뼈와 카드를 읽었다면, 이제는 토큰을 읽는 셈임. 언어의 형태이니 논리적 주장을 대하는 것처럼 여기지만, 사실은 여전히 복잡하고 확률적인 신호를 통찰로 바꾸는 점괄임. 지금 우리가 하는 건 새로운 종류의
       점을 치는 것과 마찬가지지만, 인식조차 못하고 있음. 그래서 뭔가 불가사의한 느낌이 드는 거고, 점점 더 이상해질 거라 생각함. 진짜 우리가 뭘 하고 있는지 제대로 명명하게 되는 순간, 그 ‘불가사의함’은 사라지고 재미도 반감될 거라 조금 아쉬움
          + 이런 점치는 도구라는 비유에 반발하는 이들도 있지만, 기술 커뮤니티 사람들은 대부분 LLM의 원리를 이해한다고 생각하고 주변 사람들도 그렇다고 착각하는 경향이 강함. 그러나 비전문가 친구나 가족과 얘기해보면, 정말 챗봇을 무슨 오라클처럼 대하는 경우가 많음. LLM이 종종 ‘환각’을 보여줄 수 있다고 하면 깜짝 놀라는 경우도 많음. 이런 사실을 알게 되면 이들과 LLM의 관계가 변할 거라 기대하고, 기술인으로서 이런 오해를 적극적으로 풀어주는 노력이 필요하다고 느낌
          + 비유가 멋지게 들리긴 하지만, 내 LLM 활용은 점괘와는 거리가 멂. 예를 들어, 새 깃털의 작은 섬유 이름을 물어봤을 때 ChatGPT가 “barbs”라고 알려줌, 직접 구글로 검증하니 맞았음. 점괘라기보다는 정보 검색임. galvo fiber laser의 g-code가 궁금했는데, 실제로는 없다고 알려줌. 여러 오픈소스 컨트롤 솔루션까지 추천해줌. 영국의 은세공품 법률 규정도 물어보고, 헝가리어 ""besurranó tolvaj""의 영어 번역도 얻어봄. SQLAlchemy 모델을 못만들겠어서 ChatGPT에 시켜보기도 함. 이런 것들은 “모두가 점괘”라고 부를 만큼 거창한 게 아니라, 정보 수집이거나, 코딩 자동화일 뿐임
          + AI 관련 용어가 너무 혼란스러움. 나도 LLM 잘 쓰고 만족하지만, 개발자 블로그만 보면 ""생각""같은 표현을 남발함. 항상 확인하고 싶음, ""아직도 단어 조합만 수학적으로 하고 있지? 진짜 ‘생각’은 아니지?"" 답은 늘 맞음… 근데 돌아서면 또 비유적인 용어 남발임
          + 칼 세이건이 예언한 내용이 떠오름. 서비스와 정보 경제가 사회를 지배하고, 기술력이 소수에게 집중되고, 대중이 본질을 이해하지도 못하는 채로, 결국 점점 미신과 어둠의 시대로 미끄러져가는 미국의 미래상에 대한 경고임
          + 친구나 가족에게 음모론을 논파하려고 하면, 다음날 AI 목소리가 같은 주장을 그대로 내레이션하는 동영상을 받게 됨. 대부분 실제 LLM 텍스트도 아니고, AI 목소리만 활용해 제작자 텍스트를 읽는 것에 불과함. ChatGPT나 Siri 같은 목소리, 그리고 확인 편향이 결합되면 LLM을 마시여나 오라클처럼 신봉하는 모습으로 이어지는 듯
     * LLM의 본질에 대해 동의하지만, 저자가 AI의 작동 원리를 완전히 이해했다고 보긴 힘듦. LLM은 거대한 인터넷 데이터에 기반한 확률적 예측기일 뿐 아니라, 수많은(주로 저비용 개발도상국 중심의) 데이터 라벨링 작업이 핵심임. 모델이 감정 표현 등 인간적 반응을 ‘잘하는’ 것처럼 느껴지는 건 이 방대한 데이터 라벨러들이 피드백을 주고 튜닝한 결과임. 본질적으로는 확률 모델이 아니라, 내가 대화하고 있는 건 케냐 어딘가의 데이터 라벨러, 그들의 판단이나 감성을 트랜스포머로 변환한 것에 가까움. 단순 인터넷 크롤링만으론 안 됨. 그건 GPT2 수준임. GPT4.5는 실제론 ‘저비용 노동력’이 효율적으로 저장된 것임
          + OpenAI, Google 정도 제외하면, 인스트럭션 튜닝이 실제 LLM 성능이나 느낌에 얼마나 큰 영향을 주는지 외부자는 파악하기 어렵다고 생각함. 내 개인적 경험상, 인스트럭션 튜닝 이전 GPT-3 기반 모델에도 이미 지금과 비슷한 주요 능력이 있었음. 다만 더 감정적이거나 예측이 어려웠을 뿐임. 튜닝을 통해 더 인간이 원하는 대답을 더 예측 가능하게 한 건 사실이지만, 완전히 새로운 능력이 생긴 건 아님
          + 좀 더 정확히 말하자면, 현대 챗봇형 LLM은 대규모 인터넷 사전학습과 방대한 휴먼 피드백 파인튜닝이라는 2단계 프로세스가 핵심임. 많은 사람들이 “감정지능이 있다”는 건, 실제로는 아프리카 같은 지역의 데이터 라벨러 수천 시간이 녹아들어있는 결과임. 단순히 인터넷에서 긁어온 데이터만 반영된 모델은 아니고, 다양한 피드백으로 응답이 한층 인간적이고 안전하게 다듬어짐
          + 대형 모델의 이면엔 얼마나 많은 저임 노동자가 투입되는지에 대해 깊이 다룬 기사를 제대로 본 적이 없음. 실제로 수백만 명이 전 세계적으로 참여한다 해도 과언이 아닐 듯
          + 저자같이 설득력이 부족한 경우가 종종 있음. 왜냐하면 인간의 '생각' 메커니즘 역시 충분히 설명하지 않고, 단순히 ""그건 인간과 달라""라고 퉁치는 경우가 많음. 사실 우리도 다 모르는 부분임
          + LLM이 “생각하는 게 아니라 다음 단어를 확률적으로 예측한다”는 식의 언급, 그렇다면 ‘생각’이란 대체 뭔지 반문하고 싶음. LLM이 수학도 풀고 체스도, 두뇌 트레이닝 없이 해냄. 그럼 이건 생각이 아닌가? 어쩌면 우리 뇌도 감각 데이터와 신경망 구조에 저장된 ‘문맥’을 바탕으로 비슷하게 출력 내보내는 건지 모름
     * Bumble 창업자가 AI 데이팅 컨시어지로 데이트 자체를 자동화하겠다는 발언을 한 것에 참 할 말이 없다는 생각임.
          + 실제로 Bumble(BMBL) 주가가 92% 떨어진 현실도 있음 Yahoo Finance 차트. 많은 어설픈 AI 사업 구상은 투자가 원하는 환상을 “AI”라는 이름으로 포장하는 것과 다름없음. 투자자들을 끌어들이려고 현실을 과장하는 것이고, 근본적인 실적 개선 이야기는 관심 못 받는 경우가 대부분임
          + 데이팅 앱 업계는 10년 전부터 이게 대체 뭐하는 짓인지 자문하게 만드는 곳임. 이미 상당히 디스토피아적인 현실이고 이제 LLM까지 들어오는 건 더한 평가 시스템 정도로밖엔 느껴지지 않음
          + Bumble 창업자가 부자였다가 다시 그렇게 되기 위해 뭐든지 할 수밖에 없는 상황이라 봄. 사실 욕망이 원인임. Match가 Bumble을 가지고 있는 것도 반독점 때문일 뿐임. 이 아이디어 자체는 그리 wild하지 않음. Black Mirror에서도 비슷한 에피소드가 있음
          + 그들의 입장에서 이 모델이 효과만 있다면, 바보 같더라도 충분히 할 만한 시도임
     * 글쓴이가 LLM을 완전히 이해하지 못한다고 생각함. LLM을 단순 확률 모델로 치부하는 건 부적절함. 양자역학도 거대한 확률 모델임. LLM의 각 레이어는 문맥을 넓게 바라보고 의미와 상황까지 반영할 수 있도록 설계됨(k-v 캐시가 그 역할의 중심임). 이런 구조는 인지적으로 인간 사고의 기초적 메커니즘과 꽤 닮았다고 생각함. 물론 아직 인간 수준의 폭넓은 사고에는 못 미치고 더 어려운 주제엔 약하지만, 근본적 구조 자체가 만들어져 있음. LLM이 전혀 똑똑하지 않다는 주장은 일부 사례만 강조하는 선정적 평가임. 실제로 사람들이 활발히 쓰는 것도 ‘똑똑함’을 어느 정도 느끼기 때문임
          + LLM 제작자조차 자신들이 만든 모델의 메커니즘 전체를 다 이해하고 있다고 보긴 힘듦
          + “LLM 구조가 인류 사고를 추상적으로 묘사한다”는 주장에, ALU가 덧셈을 하는 모습이 내가 머리 속에서 덧셈을 하는 것과 추상적으로 닮았다고 말하는 논리랑 유사한다고 반박하고 싶음. 근본적으로 ALU와 인간 사고의 차이가 엄청나게 크다는 사실이 중요함. LLM과 인간 사고를 비교할 때도 그 미묘한 차이가 결정적으로 중요하다는 점을 간과해서는 안 됨
     * 정확한 용어 선택이 중요한 이유를 일목요연하게 정리한 글이라 봄. 대중이 LLM의 기술적 원리를 몰라도, 이 도구들이 실제로 뭘 하는지 이해하는 게 매우 중요함. ‘AI가 추론한다’는 과장된 홍보 덕에 주가와 기업가치가 오를 수 있지만, 그만큼 사용 안전성도 떨어짐. ‘패턴 인식, 데이터 생성 시스템’이란 보다 현실적 명명이 오히려 대중의 올바른 이해에 더 도움이 될 거라 믿음. 참고 토론
          + 수많은 사람들이 매달 수백 달러씩 챗봇 이용에 투자하고 있음. 이런 페이 수준이 간단한 유행은 아니라 진짜 뭔가 생기고 있단 방증임
     * Feynman이 “컴퓨터가 인간보다 더 잘해도, 인간과 똑같은 방식으로 하지 않으면 놀랍지 않다”고 했던 말이 떠오름. AI가 모든 분야에서 전문가를 능가해도, 실리콘이 ‘생각’하지 않는 한 인류의 우월함을 계속 주장할 거라 생각함
     * Hassabis가 “세상을 이해하는 모델”을 목표로 한다고 하는데, 비평가들은 LLM의 한계를 근거로 이 발언 자체가 무의미하다고 주장하는 오류가 흔한 듯함. DeepMind의 Astra 같은 멀티모달 AI는 텍스트뿐 아니라 시각 등 추가 입력에 기반해 실제로 “이해하는 것처럼 보이는” 결과를 내기도 함. Astra 예시 동영상
          + “이해하는 것처럼 보인다”가 핵심임. 사람이 한 번도 본 적 없는 이상한 이미지를 보여주면, 사람은 곰곰이 생각해서 정체를 추론할 수 있지만, 모델은 데이터셋에 비슷한 게 없으면 진짜로는 아무 생각 없이 무의미한 출력을 내놓음. LLM도 입력받아 일종의 필터로서 가공된 결과를 제공하지만, 근본적으론 사고가 없음. 결과의 퀄리티가 아무리 높아져도 결국 ‘이해’와는 별개임
     * LLM이 언어 의미를 어떻게 학습하는지 완전히 이해하지 못했음. 하지만 실제로 LLM이 텍스트와 개념을 어느 정도 파악하고, 완전히 헛소리만 하진 않는다는 건 확실히 느낌. 이 점이 비전문가에게는 설명이 쉽지 않음. 비전문가들은 실제 AI 사이트에 가면 ""AI 챗봇""이라는 이름, ‘인간스러운’ 답변을 보고 감탄함. 숙제든 업무든 효율적으로 끝내주니 대만족임. 진짜 AI냐 아니냐 구분을 설명하기가 쉽지 않음. 나도 LLM과 AI의 실제 차이를 명확히 설명할 수 없음. 기술적으로는 미묘하게 다르지만, 실제 사용자는 그 차이를 느끼지 못함. 결국 LLM이 종교 교주 같은 설교도 멋지게 할 수 있을 것 같고, 결국 잘 훈련되면 정말로 ‘메시아 역할’도 가능하지 않을까 기대함
     * LLM이 아직도 지식/이해 반복 루프에 걸려 헤매는 현상을 경험하는 사람이 있는지 궁금함. 내 경험상, LLM에 오류를 지적하고 다시 설명하라 해도 비슷한 환각 답변만 반복하는 게 많았음. 이는 자기이해 혹은 자기성찰이 결여됐다는 뜻임. 이런 차원이 없이는 진짜 ‘이해’나 ‘지능’이라고 부르기엔 시기상조라고 생각함. “모르겠다”는 식으로 솔직하게 한계를 인정해야 어느 정도 ‘자아’ 감각을 갖췄다고 봄. 거의 마음의 미러 테스트 같은 느낌임
          + 글쓴이 말처럼 LLM을 ‘생각’, ‘학습’으로 받아들이는 건 오해임. 그냥 텍스트 생성기일 뿐임. 예를 들어 API 존재하지 않는 코드를 생성해도, LLM에게 아무리 설명해봤자 그걸 이해하진 못함. 차라리 관련 문서를 넣어서 원하는 대로 생성하도록 유도하는 게 더 효과적임
          + 그 차이가 바로 바이어스와 논리의 차이임. 확률 모델은 결국 일종의 ‘바이어스’ 적용이고, 계산기는 ‘논리 계산’임. 이런 관점을 이해하면 모델의 한계와 강점을 구분하기 쉬움. 두 경우 모두 ‘객관성’이 빠짐. 데이터 그 자체만 처리할 뿐, 데이터 ‘이상’을 생각하지 못함
"
"https://news.hada.io/topic?id=21350","지난 6개월간 LLM의 변화, 펠리컨이 자전거 타는 모습으로 설명하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 지난 6개월간 LLM의 변화, 펠리컨이 자전거 타는 모습으로 설명하기

     * 최근 6개월간 30개 이상의 주요 LLM 모델이 등장하며 AI 업계의 혁신 속도가 더욱 빨라졌음
     * 전통적인 벤치마크와 리더보드에 대한 신뢰가 낮아져, 직접 SVG 코드로 '자전거 타는 펠리컨'을 그려보게 하는 독자적 테스트로 모델을 비교함
     * Meta, DeepSeek, Anthropic, OpenAI, Google 등에서 다양한 오픈/상용 모델이 등장했으며, 일부는 PC에서도 동작할 만큼 경량화되고, 일부는 비용 대비 성능에서 큰 발전을 보임
     * 도구 연동 및 추론 능력의 비약적 발전, 그리고 프롬프트 인젝션과 데이터 유출 등 보안 리스크가 업계의 새로운 화두로 부상함
     * ChatGPT 아첨 버그, 고발자 벤치마크 등 LLM 관련 유쾌한 버그와 실험, 단순 점수 외 실제 체험 기반의 평가가 중요해지고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

The last six months in LLMs, illustrated by pelicans on bicycles

     * 2025년 6월 샌프란시스코 AI Engineer World’s Fair에서 “지난 6개월간 LLM” 이라는 주제로 키노트 발표를 진행함
     * 원래 1년 단위로 정리하려 했으나, 최근 6개월간 너무 많은 변화가 있었음
     * 주요 LLM 모델만 해도 30개 이상이 최근 6개월 내에 공개되었고, 모두 업계 종사자라면 알아야 할 정도로 중요함

모델 평가 방식의 변화

     * 기존의 벤치마크 점수와 리더보드만으로는 실제로 쓸 만한 모델을 구분하기 어렵다는 문제 인식
     * 그래서 LLM에게 ‘자전거 타는 펠리컨’ SVG 이미지를 코드로 그려보라고 시키는 실험을 고안
          + LLM은 그림을 직접 그릴 수 없지만, SVG 코드 생성은 가능
          + 펠리컨과 자전거 모두 그리기 까다로우며, 현실에서는 존재하지 않는 조합이므로 모델의 창의성과 논리력 테스트에 적합
          + SVG는 주석을 지원하여 모델이 어떤 의도로 코드를 생성했는지 파악하기 쉬움

주요 LLM 모델의 등장과 특징

     * Amazon Nova: 1백만 토큰 지원, 매우 저렴하지만 펠리컨 그리기 성능은 낮음
     * Meta Llama 3.3 70B: 개인 노트북(M2 MacBook Pro 64GB)에서 실행 가능한 GPT-4급 모델로 주목받음
     * DeepSeek v3 (중국 AI 연구소): 크리스마스에 오픈웨이트로 공개, 최상급 오픈모델로 평가됨. 학습 비용이 기존 대형모델 대비 10~100배 저렴
     * DeepSeek-R1: 오픈AI o1과 경쟁할 수준의 추론 특화 모델로, 출시 당시 NVIDIA 주가가 하루에 600억 달러 하락하는 사건이 발생
     * Mistral Small 3 (24B): 랩톱에서 구동 가능, Llama 3.3 70B에 근접한 성능을 훨씬 적은 메모리로 제공
     * Anthropic Claude 3.7 Sonnet: 뛰어난 추론력과 창의력, LLM 평가 이미지에서도 좋은 결과
     * OpenAI GPT-4.5: 기대 이하의 성능과 높은 비용으로 6주 만에 서비스 종료
     * OpenAI GPT-4.1 및 Nano/Mini: 1백만 토큰, 매우 저렴한 비용, 실제 사용에 매우 추천할 만한 API 모델
     * Google Gemini 2.5 Pro: 합리적 비용으로 창의적 그림, 이름이 너무 복잡해서 기억하기 어렵다는 단점
     * Llama 4: 지나치게 대형화되어 일반 하드웨어에서는 실행 불가, 기대감이 낮아짐

펠리컨 평가 방법 및 순위 산출

     * 다양한 모델이 생성한 펠리컨-자전거 SVG 34개를 shot-scraper로 캡처, 모든 조합(560번)으로 1:1 비교
     * gpt-4.1-mini에 ""어느 쪽이 펠리컨이 자전거를 타는 모습을 더 잘 표현했는지""를 평가하도록 함
     * 결과를 기반으로 Elo 점수(체스 랭킹식)로 최종 순위를 산출
          + 1위: Gemini 2.5 Pro Preview 05-06
          + 상위권: o3, Claude 4 Sonnet, Claude Opus 등
          + 하위권: Llama 3.3 70B 등

LLM 버그 및 흥미로운 사례

  ChatGPT 과도한 아첨 버그

     * 새로운 ChatGPT 버전에서 사용자 아이디어(심지어 황당한 사업 아이디어)에도 극찬을 남발하는 문제가 발생
     * OpenAI는 빠르게 패치를 적용, 시스템 프롬프트에서 “사용자 분위기 맞추기”를 제거하고 “아첨하지 말 것”으로 지침 변경
     * 프롬프트 엔지니어링으로 단기적 버그 해결

  고발자 벤치마크(SnitchBench)

     * Claude 4 System Card에서 촉발, Theo Browne가 AI 모델이 회사 비리 증거를 보면 어디에 신고하는지 평가하는 SnitchBench 개발
     * 대부분의 모델이 내부고발자 역할을 자처, 미국 FDA, 언론 등으로 이메일 발송
     * DeepSeek-R1은 언론사(WSJ, ProPublica)까지 동시에 제보하는 등 더 적극적인 모습을 보임

도구 사용 능력과 보안 이슈

     * LLM의 도구(tool) 호출 능력이 최근 6개월 동안 크게 발전
     * MCP(멀티 컴포넌트 프레임워크)로 여러 도구 조합 및 검색, 추론, 검색 재시도 등 복잡한 워크플로우가 가능해짐
     * 하지만 프롬프트 인젝션, 데이터 유출, 악의적 명령 실행 등 치명적인 보안 리스크(lethal trifecta) 도 함께 부각
     * OpenAI 등 주요 AI 제공사는 문서에서 인터넷 접근, 코드 실행 등 고위험 옵션 사용 시 보안 경고를 명시

결론 및 전망

     * 펠리컨-자전거 벤치마크는 당분간 계속 쓸 만하지만, 주요 AI 연구소가 눈치채면 대체할 소재가 필요할 수도 있음
     * 2025년 들어 모델 성능, 가격, 도구 활용성, 보안 등에서 변화가 극심하며, 실제 현장에서는 단순한 숫자 벤치마크 이상의 새로운 평가와 위험 관리가 필요함

        Hacker News 의견

     * 이 제품 출시는 역사상 가장 성공적인 사례 중 하나라는 생각임. 단 일주일 만에 1억 명의 신규 계정을 모았고, 한 시간 동안 백만 명이 가입한 적도 있음. 바이럴 효과 덕분에 계속 화제가 되었지만, 나는 최근에서야 처음 들었음. 이미 오프라인 stable diffusion 앱을 쓰고 있어서 업그레이드라고 느끼기도 어려웠음. 매주 AI 관련 뉴스가 너무 많으니 정말로 관심을 가지지 않으면 중요한 출시도 깜빡 놓치기 쉬움
          + 이 서비스는 정말 메인스트림으로 나옴. 사람들이 자신을 머펫으로 변신시키거나, 내 반려견의 인간 버전을 만드는 등 다양한 화제가 있었고 TikTok 등에서도 엄청나게 유행임. 진짜 대단함.
          + 사실상 당신은 거의 소셜 미디어에서 벗어난 상태라는 생각임. 이 제품 출시는 엄청난 메인스트림 이벤트였고, 며칠 동안은 GPT 기반 이미지가 소셜 미디어를 휩쓸었음
          + 사실 ChatGPT에는 원래 이미지 생성 기능이 있었지만, 이번 것은 이전보다 훨씬 발전된 버전임. 당신이 가지고 있는 stable diffusion 앱 사용자라고 해도, 이미지 품질뿐만 아니라 지시 사항을 정확히 따르는 부분에서 큰 업그레이드임
          + 모두가 Ghiblifying(지브리 스타일로 바꾸기) 열풍을 놓친 건 아닌지 궁금함
     * 내 벤치마크에 꽤 만족하면서도, 큰 AI 연구소들이 눈치채지 않으면 이 방식이 오랫동안 유용할 거라는 기대를 가졌음. 그런데 구글 I/O 키노트에서 잠깐 등장한 자전거 타는 펠리컨 이미지를 보고, 이게 들킨 걸 깨달음. 이제 새로운 테스트 방식이 필요할 듯함. 이런 사례가 AI 능력에 대해 공개적인 논의를 어렵게 만든다는 점이 있음. 작고 독특한 테스트라도 대기업들이 알게 되면 RLHF로 과도하게 최적화하는 사례가 생김. 예를 들어 ""strawberry에서 r 개수 세기"" 같은 고전적인 테스트가 있음
          + 만약 내 자전거 타는 펠리컨 벤치마크가 AI 연구소들이 시간 들여 최적화하고 멋진 펠리컨 일러스트를 만드는 계기가 된다면, 그 자체로 내게 엄청난 성취감임
          + strawberry에서 r 개수를 세는 테스트를 GPT-4o로 해봤는데, 실패함. ""The word 'strawberry' contains 2 letter r’s.""라고 대답함
          + 이런 맥락에서 ARC Prize가 더 나은 접근이라는 생각임 ARC Prize
     * 이 벤치마크 정말 마음에 듬. 나도 비슷한 시도를 (장난 삼아, 그리고 훨씬 드물게) 여러 모델에 요청해서 데이터 구조로 멜로디를 만들어보라고 했음. Smoke on the Water 인트로를 예로 들어 Web Audio API로 소리까지 내봤음. 완벽하게 성공한 적은 없지만, 점점 개선되는 모습임. 각 모델에 웹사이트 제작까지 부탁할 수 있을 정도임. 당신 테스트가 신선함 면에서 더 신중하다고 생각하지만, 모델들이 본격적으로 설계되지 않은 영역까지 시도하게 하는 과정이 흥미로움. ChatGPT 4 Turbo 결과, Claude Sonnet 3.7 결과, Gemini 2.5 Pro 결과 중 Gemini가 가장 듣기 괜찮았지만 여전히 완벽하진 않음. 최신 유료 모델들은 어떨지 궁금함. 그리고 처음 시도했던 모습이 궁금하다면 이 링크
          + 자전거 타는 펠리컨 SVG로 평가할 때 단점은 프롬프트가 매우 오픈형이고, 평가 기준이 딱히 없다는 점임. 최근에는 SVG가 다 비슷비슷하게 나오거나, 최소한 동일한 비목표(펠리컨이 있고, 자전거가 있고, 다리가 안장인지 페달 위에 있는지 불분명함)를 달성한 상황임. 그래서 어느 쪽이 더 좋은지 합의하기 힘듦. LLM을 심판으로 쓰면 평가 자체가 더 꼬이고, 원래 의도를 잃게 됨. 게다가 벤치마크가 인기를 끌면 트레이닝 세트에 반영되어 모델이 부당하게 개선될 위험 있음. 사실 어떤 유명 벤치마크든 이런 현상은 있음. 참고로 Language Benchmark Game이 프롬프트 기반 언어 * 모델 벤치마크 게임이 되었으면 하는 바람임. 예를 들어 model X가 Python Fasta에서 최고임을 알 수 있도록. 물론 이것도 결국은 트레이닝 세트 문제, 자기 개선 효과로 번질 위험 있음
          + 프롬프트 예시가 약간 혼란스러움. 실제 프롬프트가 무엇이고, 텍스트 기반 모델이 실제 곡을 오디오로 만드는 걸 기대했다는 뜻인지 궁금함
     * 가장 아쉬운 점은 확률적 모델(LLM) 평가를 단일 샘플만으로 한다는 점임. 마치 각기 다른 난수 생성기에서 샘플 하나만 뽑아보고, 5번 생성기가 제일 높으니 최고라 결론내리는 것과 비슷하다고 느낌. 각 LLM마다 10개(혹은 그 이상) 이미지를 비교해서 평균을 내는 방식이 훨씬 더 좋을 것임
          + 벤치마크가 상당 부분 농담으로 의도된 것임. 이 테스트로 지난 6개월간 모델 출시를 더 재밌게 만들고 싶었음. 각 모델별로 10개 이미지를 만들고 비전 모델에 베스트를 고르게 한 다음, 그 이미지를 다른 모델들과 경쟁에 올릴 생각도 있었음. 심사단도 서로 다른 계열의 비전 LLM 3개로 확장하면 판단이 엇갈릴 때 어떤 결과가 나오는지도 분석할 수 있음. 그래도 이 테스트 자체가 꽤 우스꽝스럽다고 느껴서, 굳이 이렇게 확장할 가치가 있는지는 고민 중임
          + 점점 더 이 테스트 자체가 벤치마크로 널리 알려지다 보니, 최신 학습 데이터에 이런 기사들이 더 많이 들어가서 자연스레 LLM이 ""자전거 타는 펠리컨"" 이미지를 잘 그리게 되리라는 예측임
          + 지적이 맞음. 그런데 모델 개발 회사들은 LLM을 확률적이라고 인식시키지 않으려 하고, 마치 인간처럼 잘 작동한다고 홍보에 엄청 힘을 씀. 만약 인간이 펠리컨과 자전거에 완벽히 정통하다면 100% 정확하게 그림을 그려낼 것이라고 기대할 수 있음. 결국 확률적 모델일지라도 관련 지식을 잘 학습했다면 항상 정확하게 출력해야 손실이 낮아지는데, 실제 결과를 보면 여전히 지식의 결함이 드러남
          + 가장 불만인 점은 자전거 타는 펠리컨 심사를 또 다른 LLM에 외주 맡겼다는 점임. 돈과 시간이 적게 들어 더 편한 선택이었겠지만, 다양한 평가 방법을 시도해 결과를 비교했으면 참 흥미로웠을 것임. 예를 들어:
               o 군중의 지혜(여러 사람에게 투표받기)
               o 전문가의 지혜(여러 예술가 혹은 조류학자에게 평가받기)
               o LLM 집단지성(서로 다른 LLM을 평가단으로 쓰기) 인간의 컨센서스와 LLM 컨센서스가 얼마나 다를지 보는 것도 재미있었을 것임. 그래도 이야기 자체는 훌륭함
          + 가장 아쉬운 점은 실제 펠리컨 사진이 없었다는 점임. ""펠리컨"" 실제 사진 검색 결과. 현재 제공된 펠리컨 이미지들은 실제와 전혀 다름
     * 이 글 정말 잘 읽었음. LLM의 역량 측정을 3D 영역까지 확장할 수 있을 것 같음. 예를 들어 Blender용 파이썬 코드를 작성해놓고, 백엔드 API에서 headless Blender를 돌리는 방식임. 발표에서도 언급됐지만, 앞으로는 단일 프롬프트로 측정하는 건 충분하지 않을 거라 생각함. 테스트는 최신 Blender 설명서 참고, 검색엔진 활용, 블로그 문서 참고까지 포함해 더 ""에이전트적""으로 확장될 수 있음. 멀티모달 입력 처리까지 고려한다면, 특정 펠리컨 사진을 테스트 대상으로 활용할 수도 있음. 만든 3D 오브젝트를 iOS의 네이티브 3D 포맷으로 변환해 모바일 Safari에서도 뷰 가능하게 만드는 방향도 있음. 실제로 2022년 10월, 이 프로세스와 관련 서비스를 직접 만들어 본 경험이 있는데, 당시는 일반적 문법 오류 후처리까지 필요했지만 최신 LLM은 그럴 일도 덜할 것으로 기대함
     * 최고의 펠리컨 이미지는 여러 모델을 연합 실행하는 방식에서 나옴. 펠리컨을 평가할 때 evals로도 사용 중임. 관련 링크1, 관련 링크2
     * 라운드로빈 방식으로 모든 참가자가 같은 점수로 시작해서 전부 맞붙는다면, ELO 점수는 실질적으로 승리 횟수에 대응하게 됨. 아마도 적용된 알고리즘은 대진 순서를 고려하는데, 이는 참가자가 시합을 거치며 눈에 띄게 발전할 경우에나 의미가 있음. 봇끼리의 경쟁에서는 오히려 잡음만 늘리니 순서 반영은 오히려 원치 않음. 또 대진표를 확인해보니 561개 가능한 짝 중 한 결과가 빠짐. 이유가 궁금함
          + 맞는 지적임. 모든 참가자가 서로 딱 한 번씩 붙는다면 ELO 방식은 사실 필요 없음. 빠진 한 경기는 한 라운드가 무승부 판정 나서 다시 실행할 시간 여유가 없었기 때문임. ELO는 마지막에 급하게 추가한 부분임
     * Simon의 작업을 정말 즐기고 있음. 거의 모든 블로그 포스트를 읽었고, 모델을 다양하게 실험하는 모습을 보는 것이 정말 즐거움. CLI 툴들도 쉽게 사용할 수 있고, 각자 기능이 겹치지 않게 잘 맞춰져 있음. 그리고 중요한 건, Simon이 이 일 자체를 너무나 즐기고 있다는 점임. 마치 사탕가게에 들어간 어린아이처럼 신나는 에너지가 전염되고, 항상 포스트를 읽을 때마다 나도 LLM으로 새로운 시도를 해보고 싶어짐
     * Qwen 3가 눈에 띄게 빠져 있어 아쉬움이 큼. 특히 fine-grained MoE 구조 덕분에 일반 소비자 하드웨어에서 능력, 속도의 혁신이 컸던 출시임
          + Qwen 3를 빠뜨린 것이 이번 발표에서 가장 아쉬웠던 점임. 솔직히 발표를 하고 나서야 이 모델을 놓쳤다는 걸 깨달음. 요즘 내가 가장 좋아하는 로컬 모델 중 하나인데 어떻게 하이라이트에서 빠졌는지 모르겠음
          + Qwen 3 관련 내용은 시간 관계상 생략했지만, pelican 테스트도 거쳤음 Qwen 3 테스트 결과
     * 여기 Claude Opus Extended Thinking 직접 결과 보기
          + 단일 샷(single shot) 평가인지 궁금함
"
"https://news.hada.io/topic?id=21416","Spark - Three.js용 고급 3D Gaussian Splatting 렌더러","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Spark - Three.js용 고급 3D Gaussian Splatting 렌더러

     * THREE.js 렌더링 파이프라인과 연동하여 splat 및 mesh 기반 객체를 함께 표시함
     * 이식성이 뛰어나 거의 모든 디바이스(WebGL2 지원 98% 이상)에서 동작함
     * 모바일 저사양 기기에서도 빠른 렌더링 성능을 제공
     * 여러 개의 splat 객체를 함께 렌더링하고 정렬도 올바르게 처리
     * .PLY(압축 포함), .SPZ, .SPLAT, .KSPLAT 등 주요 splat 파일 포맷 대부분 지원
     * 여러 시점에서 동시 렌더링 기능 지원
     * 동적 편집: 각 splat 객체를 개별적으로 변환, 애니메이션 적용 가능
     * 실시간 색상 편집, 변위, 스켈레톤 애니메이션 지원
     * Shader graph 시스템으로 GPU에서 동적으로 splat을 생성/편집할 수 있음

        Hacker News 의견

     * 엄청 인상적인 데모라는 느낌을 받음, 내 구형 아이폰에서도 잘 작동함
       내가 전문적인 3D 프로그래밍 지식이 부족한 취미 게임 개발자 입장에서 피드백을 주자면, GitHub나 웹사이트 어딘가에 “Gaussian Splatting”이 뭔지 한 줄 설명을 덧붙이면 좋을 것 같음
       Wikipedia에서 가져온 설명 한 줄에 더 흥미와 가능성을 느끼게 되었음
       Gaussian Splatting은 부피 데이터를 서피스나 라인 프리미티브로 변환하지 않고 직접 렌더링하는 부피 렌더링 기법임
       고성능의 구름, 불, 연기 등을 만들 수 있다는 점이 정말 멋짐
          + 피드백 고마움
            FAQ를 반드시 추가해야겠다는 생각임
     * 음식 스캔 데모(“Interactivity” 예시)가 놀라움
       특히 Mel's Steak Sandwich에서 빵 구멍 안을 들여다보는 게 인상적임
       내 노트북에 내장 그래픽만 있어도 보이는 디테일에 비해 성능이 훌륭하게 잘 나옴
       이런 기술은 지금 주로 어디에 사용되는지 궁금함
          + 소형 물체를 핸드헬드 기기나 드론으로 스캔하는 커뮤니티가 존재함
            이번 데모에 Tipatat이 음식 스캔을 제공해줬음
            나는 kotohibi의 꽃 스캔도 좋아함
            https://superspl.at/user?id=kotohibi
          + 이 정도 디테일인데도 데이터 전송 용량이 그리 크지 않음
            약 80MB 정도여서 정말 신기함
     * 정말 멋짐
       BabylonJS도 Gaussian Splat을 잘 지원함
       https://doc.babylonjs.com/features/featuresDeepDive/…
          + BabylonJS와 Aframe 모두 라이선스, GitHub star와 포크 수가 비슷함
            Aframe이 더 최근 프로젝트이고, 게임과 VR 쪽에 더 집중함
            Babylon, Aframe, Three.js, PlayCanvas를 전부 써본 사용자의 관점에서는 어떻게 비교되는지 궁금함
            PlayCanvas는 상업적이지만 가장 성숙하고 기능이 풍부하고 성능도 뛰어남
            Babylon은 기능 중심의 3D 엔진이고, Three.js는 기본만 제공함
            애니메이션, 텍스처 지원이 좋긴 하지만 결국 직접 툴킷을 만들어야 함
            이 엔진들에서 좋은 경험 또는 그렇지 않은 경험이 궁금함
            OP의 데모가 정말 견고함
            Aframe의 장점과 피치는 무엇인지 궁금함
            Gaussian Splatting의 미래는 어떻게 펼쳐질지, 단순 시각화/디지털 트윈 산업만이 아니라 크리에이티브나 게임 분야에서도 편집, 애니메이션이 곧 가능할지 궁금함
            Aframe GitHub
            PlayCanvas
     * 멋진 작업임
       하지만 내 노트북의 Nvidia RTX A3000 GPU와 Firefox 조합에서 성능이 매우 좋지 않음
       이 정도 셰이더 코어라면 손이 데일 정도로 뜨거워질 수 있음
          + 구체적으로 어떤 데모/예시에서 그랬는지 궁금함
     * 폰으로 들고 뛰어다니며 grass, bushes, dirt 같은 Gaussian Splats를 캡처할 수 있나 궁금함
       1미터 정사각형 땅 패치, 덤불이 포함된 1미터 정육면체 공간을 선택해서
       그라스 블록을 반복 배치하고 덤불이나 흙 등을 중간중간 섞어서 ""마인크래프트 느낌"" 월드 만드는 것이 가능한지 궁금함
       수천 개의 블록을 렌더링하려면 꽤 하드웨어가 빵빵해야 할 것 같음
          + 이런 프로토타입은 확실히 만들 수 있음
            실제로 본다면 정말 멋질 것 같음
     * 정말 멋짐
       혹시 현 시점의 성능 병목에 대한 인사이트가 있는지 궁금함
       특히 다이나믹 씬에서의 병목이 궁금함
       파티클 시뮬레이션 예시는 버벅이지만 카메라를 돌리면 갑자기 성능이 확 좋아짐
       이건 정적 배경 부분이 생각보다 무거웠다는 의미 같은데, 이와 별개로 Sierpinski 피라미드는 프로시저럴 방식으로 정말 인상적임
          + 장면 내 스플랫 개수와 분포가 성능에 영향 미침
            아마도 질문자가 카메라를 덜 복잡한 방향으로 돌렸기 때문일 수도 있음
            성능을 일정하게 맞추는 건 아직 할 일이 남아있음
            앞으로는 LOD 시스템을 적용할 생각임
     * 조금 더 눈에 띄는 repo 링크 안내
       https://github.com/sparkjsdev/spark
     * Gaussian Splatting이 데모 그 이상을 할 수 있을지에 대해 여전히 회의적임
       파일 용량이 너무 큼
       예를 들어 스테이크 샌드위치가 12MB임
       작년 SIGGRAPH에서 Gaussian Splat 기반 Matterport 포트 클론을 봤는데, 2베드 아파트를 보기 위해 1.5GB 스트리밍이 필요했음
       멋진 데모임
          + SOGS 압축 기법이 효과적임
            풀 구면 조화(Spherical Harmonics) 포함 1M Gaussian을 약 14MB로 저장 가능함
            PlayCanvas 블로그에 관련 좋은 글이 있음
            https://blog.playcanvas.com/playcanvas-adopts-sogs-for-20x-3dgs-compre…
          + 참고로 12MB짜리 스테이크 샌드위치가 가장 큰 파일임
            나머지는 10MB 이하이고, 몇 개는 1-3MB로 아주 설득력 있음
            (예: Iberico Sandwich 1MB, Clams and Caviar 1.8MB 등)
            SOGS와 같은 고급 압축 방식이 곧 나올 예정임
            이 예시는 30MB임
            https://vincentwoo.com/3d/sutro_tower/
          + 파일이 큰 주된 이유는 Spherical Harmonics 계수를 저장하기 위해서임
            해결 가능한 문제임
     * 이름이 좀 과하게 쓰이고 있다는 인상임
       이미 Apache Spark, SPARK(Ada), sparklines, SPARQL 등이 있음
          + SPARC도 잊으면 안 됨
            https://en.wikipedia.org/wiki/SPARC
"
"https://news.hada.io/topic?id=21325","Jepsen: TigerBeetle 0.16.11","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Jepsen: TigerBeetle 0.16.11

     * TigerBeetle는 이중 입출금 회계 처리에 특화된 OLTP 데이터베이스로, 안전성과 빠른 처리 속도를 목표로 개발됨
     * Viewstamped Replication 합의 프로토콜과 strong serializability 기준을 지원하며, 고경합, 고처리량 작업에 최적화된 구조를 가짐
     * 결함 허용 및 장애 복원력에 매우 신경 쓴 설계와 테스트 절차를 갖추고, 다양한 장애 상황에서 데이터 손실 없는 동작을 지향함
     * 업그레이드, 테스트, 연산 모델, 클러스터 장애 복원력 등에서 다양한 버그와 성능 이슈가 Jepsen 테스트로 발견, 대응 가능성 개선됨
     * 최신 버전에서는 Ring 기반 복제 성능, 클라이언트 오류 처리, 로깅·쿼리 정확성 등 여러 개선점과 버그 픽스가 제공됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

TigerBeetle 소개

     * TigerBeetle은 이중 입출금(Double-entry bookkeeping) 에 특화된 온라인 트랜잭션 처리(OLTP) 데이터베이스임
     * Viewstamped Replication(VR) 합의 프로토콜 기반의 strong serializability를 보장하며, 계좌와 계좌간 전송(transfer) 데이터만 저장
     * 은행 내부 스위치, 중개업, 티켓 발권, 전력 계량 등 거래량이 많고 동시성 경쟁이 심한 환경에 적합함
     * 단일 노드(Core)에서 모든 쓰기 연산을 관장하는 구조로 수평 확장(Scale-out)이 아니라 수직 확장(Scale-up)에 집중
     * 배치 처리, IO 병렬화, 고정 스키마 등 하드웨어 친화적 최적화로 단일 노드 처리량 극대화를 지향함

장애 복원력 및 결함 허용

     * TigerBeetle은 메모리, 프로세스, 시계, 저장소, 네트워크 결함에 대해 명시적 모델 및 복구 절차 제공
     * 데이터 내구성은 단 하나의 복제본만 살아 있어도 데이터 손실이 없음을 보장
          + 모든 복제본에서 기록이 손상되면 안전하게 멈추는 형태
     * 시스템 하드웨어/소프트웨어 장애, 시계 오차, 디스크 손상, 네트워크 지연·손실·중복 등 다양한 장애를 가정
     * Viewstamped Replication과 Protocol-Aware Recovery 기법, 데이터 블록 체크섬 및 다중 복제본 저장 적용
     * 런타임 검증(assertion) 활용해 오류 및 버그 발생 시 피해를 최소화함

업그레이드 방식

     * 바이너리에는 현재 버전과 여러 이전 버전의 코드가 포함되어 있음
     * 업그레이드는 단순히 바이너리를 교체하는 것만으로 가능
     * 클러스터 내 모든 노드가 자동 롤링 방식으로 버전 변경, 사용자 개입 최소화
     * 특정 버전에서 커밋된 연산이 다른 버전에서 중복 커밋되는 것을 방지하여 상태 불일치 방지에 유리함

시간 모델

     * VR 뷰와 연산 번호를 이용한 논리 시계와, 하이브리드 물리 시계(physical time) 동시 사용
     * 리더가 모든 복제본의 POSIX 시각 수집, 오차 범위 내에서 클러스터 상호 동기화
     * 시계 동기화가 60초 이상 실패하면 서비스 거부
     * 타임스탬프는 ""유닉스 에폭 이후 나노초"" 단위지만 실제 POSIX 시간과 27초 오차 발생
     * 윤초나 음의 시간 조정 시 내부 시계가 느려지는 현상 있음

데이터 모델

     * 계정(account) 과 이체(transfer) 라는 두 가지 데이터 타입만 지원
          + 각 필드는 고정 크기, 불변성(immutable) 원칙, unsigned int 기반 설계
     * 계정은 사용자 정의 128비트 id, 원장(ledger), 플래그, 생성 시각, 커스텀 필드로 정의
     * 이체는 debit/credit account id, code, amount, 커스텀 필드 등 포함
     * 이체는 즉시 수행(단일 단계) 또는 2단계(예약·실행 협상) 처리 모두 지원
          + 예약 전송(pending) 취소/만료 가능
          + 특수 이체로 계좌 폐쇄/재개 처리 가능

연산 모델 및 트랜잭션

     * 클라이언트가 데이터 상태 갱신 또는 조회를 위한 단일 요청(batch) 단위로 동작
     * 요청 내 각 이벤트는 순차적이고 원자적(atomic) 트랜잭션으로 처리
     * 반복 실행, 다중 요청 트랜잭션, 대화형 쿼리 등은 지원하지 않음
     * 강한 일관성(Strong Serializability) 및 강한 세션 일관성 제공
     * 각 연산의 성공·실패, 오류코드 반환, 체인(Chain, 서브트랜잭션) 기능을 통한 복합 처리 지원

Jepsen 테스트 설계

     * Jepsen 라이브러리 통한 속성 기반(property-based) 테스트와 장애 주입(fault injection) 수행
     * LXC, EC2 등 다양한 환경에서 3~6노드 클러스터 대상으로 실험
     * 데이터 모델 제약으로 기존 리스트·셋 형태 일관성 검증 어려움 → 전체 연산 순서(total order) 이용해 상태/시간 일관성 검증
     * 타임스탬프 기반 일관성 체크, 모델 검증, 시뮬레이션 등 서로 보완적 방식으로 오류 감지

모델 검증과 연산 생성

     * 1600+ 라인 규모의 단일 스레드 상태 기계 모델로 TigerBeetle 동작 정확성 세밀하게 확인
     * 다양한 오류 조건(중복 id, 불연속 타임스탬프, 잔고 제약 등)와 링크드 체인에 대한 추론 및 롤백 처리
     * 검증 효율성을 위해 operation·id 생성, 상태 업데이트, 확률 기반 쿼리 조합 등 다양한 방식 활용

장애 주입

     * 프로세스 크래시(SIGKILL), 일시정지(SIGSTOP), 네트워크 파티션, 클럭 변경 등 기본 장애 시나리오 포함
     * 버전 업그레이드, 파일 손상 시뮬레이션, 일부 복제본만 부분 손상 등 세밀한 저장소 장애 주입
     * 지그재그(helical) 디스크 손상 등 다양한 시나리오로 데이터 손실 가능성 최소화 검증

주요 버그 사례 및 개선 내역

  요청 타임아웃 처리의 문제점 (#206)

     * TigerBeetle 설계상 클라이언트 요청이 절대로 타임아웃되지 않음; 클러스터로부터 응답받을 때까지 무한 재시도
     * 실제로는 Java 등 클라이언트가 비동기 연산시 타임아웃 예외를 발생할 수 있으며, 애플리케이션에서 외부 타임아웃을 둘 수밖에 없음
     * 네트워크 오류나 확실한 오류를 애매하게 숨기는 설계로 인해 명확한 실패와 불확실 오류 구분이 어려움
     * Jepsen은 실패 유형(확실/불확실)별 반환 방식 및 재시도 옵션 추가를 권고

  클라이언트 오류로 인한 JVM 크래시 (#2435)

     * 타임아웃을 우회하기 위한 스레드/비동기 래핑이 JVM segfault 문제를 유발
     * Java 클라이언트에서 적절히 초기화되지 않은 필드가 참조되어 발생, 0.16.12에서 픽스

  세션 만료시 클라이언트 크래시 (#2484)

     * 과도한 세션으로 인한 클라이언트 강제 종료 현상
     * 0.16.13부터 오류 반환식으로 개선

  단일 노드 장애시 대기 시간 급등 (#2739)

     * 링 기반 복제 방식의 약점으로 일부 노드 실패시 전체 응답 시간이 극심하게 늘어남
     * 원인: 기본적으로 프라이머리가 다음 노드로 한 단계씩 메세지를 보내는데, 일부 노드 실패시 ack 미수신으로 대기 발생
     * 0.16.30 이후, 역방향 복제 및 동적 링 토폴로지 등 도입해 장애 시 응답 지연 대폭 개선

  Java 클라이언트 Header API 버그 (#2495)

     * 빈 응답 배치에 singleton 객체 사용하여 헤더·타임스탬프가 잘못 공유되는 문제 발생
     * 데이터 정확성에는 영향 없으나 헤더 API 결과가 오염됨, 0.16.14에서 수정

  쿼리 결과 누락 (#2544)

     * 0.16.13 버전 query_accounts, query_transfers 등 결과 일부 누락되는 버그 보고, 응답 결과가 올바른 prefix로만 제한됨

결론

     * TigerBeetle은 금융·회계 분야에서 높은 안전성과 결함 허용성을 요구하는 환경에 특화됨
     * Jepsen 시리즈 테스트로 다양한 복원력, 일관성, 연산 모델, 성능 이슈가 드러남
     * 적극적 협업을 통해 장애 복원력, 클라이언트 오류 처리, 복제 및 업그레이드 자동화 등 실질적인 개선 이뤄짐
     * 최신 버전에서 더욱 견고한 장애 대응, 연결·응답 보장, 연산 일관성 등 높은 수준의 신뢰성 제공

   (이 내용의 일부는 Github, 공식 TigerBeetle 문서, Jepsen 테스트 리포트 등 다양한 오픈 소스를 참고하여 작성됨)

        Hacker News 의견

     * Fuzzer Blind Spots (Meet Jepsen!) 글도 참고 정보, https://tigerbeetle.com/blog/… 안내
     * TigerBeetle의 신뢰성과 확장성에 관한 이야기를 항상 Jepsen 보고서로 최종 확인한 경험 공유, 이번 보고서에서 여러 이슈 발견 내용이나 이를 빠르게 수정하고 앞으로 유사 버그가 반복되지 않도록 내부 테스트 스위트도 강화한 엔지니어링 접근 좋아 보인다는 평가, 이런 자세라면 10년 후 금융 특화 데이터베이스 분야에서 ‘그냥 Postgres 써라’급의 기본값 위치 도달 기대, aphyr의 훌륭한 작업으로 많은 공부 인증
          + TigerBeetle에 6,000개 이상의 assertion 구성, 일부가 지나치게 엄격해서 일부 crash 유발했지만 해당 assertion이 정확히 의도대로 경고 역할 수행 경험, 실제로는 Java 클라이언트 쪽 Jepsen 감사 편의를 위한 내부 테스트 기능에서만 작은 correctness bug 발생 사례와, durability에 지장 없는 한 가지 correctness bug Jepsen에서 발견, 관련 사례는 해당 링크에서 상세 내용 설명, TigerBeetle은 Postgres보다 많은 장애를 견디도록 설계 및 테스트 수행 중이고, 명시적 스토리지 장애 모델 채택, Postgres 출시 당시 존재하지 않았던 연구 성과 반영, Deterministic Simulation Testing과 NASA 안전 코드 기준 적용 등 다양한 안정성 보장, 실제로 문헌상 데이터 손실이 명확한 Postgres 시나리오에 대해 TigerBeetle은 탐지 및 복구 가능, 좀 더 자세한 내용은 Kyle의 helical fault injection 섹션 혹은 QCon London 강연 영상
            참고 권유
          + Kyle의 보고서를 읽을 때마다 분산 시스템 실력 한 단계 성장 느낌 공유
     * TigerBeetle가 aphyr에 의해 검증되어 약속을 지키는 모습에 기쁨 표출, 올바른 접근이 제대로 된 결과로 이어질 수 있다는 희망 사항, 실제 현장에서는 Account나 Transfer 외의 데이터는 외부 시스템 및 별도의 데이터베이스에 남는 경우가 많은데, 이러한 신뢰도 낮은 외부 시스템과 TigerBeetle 간 consistency 문제나 복구가 실제로 어떻게 이루어지는지 질문
          + TigerBeetle의 조란, 통합 패턴 설명, 일반적으로 control plane(일반 OLGP, 예: Postgres)과 data plane(OLTP, 예: TigerBeetle)으로 분리 아키텍처 권장, 사용자 정보 등은 OLGP라는 ‘서류함’에, 트랜잭션 데이터(재고→장바구니→결제 등)는 OLTP라는 ‘금고’에 저장 형태로 역할 분담, 계정 또는 이체별로 최대 3개 사용자 데이터 식별자 연결 후 OLGP 엔티티와 이벤트 연계 가능, 이 분리는 독립적 규모 확장·운영·관리 이점 제공, 예를 들어 은행처럼 현금(금고)과 정보(서류함)를 구분해야 적합한 사례 설득, 실제 트랜잭션 빈도와 정보 변경 빈도(이름/이메일 등)는 다르기 때문에 이 구조 합리적 설명, 데이터 일관성을 위해서는 write 경로에서는 OLGP(및 S3 등 필요한 외부 저장소)에 의존 관계 데이터 기록 후 마지막에 TigerBeetle로 커밋하는 방식 권장, read 경로에서는 항상
            TigerBeetle을 source of record로 조회, strict serializability 유지로 신뢰 확보 방식 제안, 아키텍처 문서 첨부 안내
     * Jepsen의 fuzzer blind spot 포스트를 읽었다면 이번 TigerBeetle 보고서가 훨씬 더 흥미롭다고 느낀다는 의견, JNI 쪽 segfault 사례는 Rust 등 메모리 세이프 언어 사용 시 보호되지 않을 수도 있지만, TigerBeetle의 Zig/TigerStyle 접근이 메모리 안전성에서는 좋은 증명 제공 평가
          + Rust로도 방어할 수 있는 버그 하나 경험 사례, 실제로는 assertion으로 대부분 방지, TigerStyle이 아니었으면 더 위험한 상황 발생 가능성 언급
     * ""Panic! At the Disk 0"" 섹션의 제목 센스에 소소한 골프클랩 감탄
     * Jepsen 인증받은 이번 상세 보고서에 깊은 감명 표현, 아직 v1.0 출시 전임에도 기대감 높은 상태, 창업자들이 스레드에서 인사이트 적극 공유하는 모습에 별도 칭찬
          + Kyle의 섬세함과 리포트의 예술적 세심함에 대해, SD25 Amsterdam에서 새로운 발표 소식도 기대
     * 분산시스템 테스트에서는 실제로 시스템 내부에서 발생 순서/시간을 시스템이 직접 리포팅하여 외부 모델과 정확히 대조하는 것이 정확한 검증을 위한 필수 요건임이 흥미롭고 ‘뚜렷하게 당연’하게 느껴진다는 소감
          + strict serializability 환경에서는 이런 방식이 가능한데, 약한 일관성 보장 하에서는 단일 글로벌 타임라인이 불가능 예시 안내, 어려운 문제를 도입했기에 시스템이 오히려 단순해지는 메타 패턴 흥미, 예를 들어 디스크 장애/복구 프로토콜을 기본으로 추가하면 느린 replica의 state sync도 ‘공짜’로 얻을 수 있는 상황 등 설명
     * Jepsen 보고서, 관련 블로그, Antithesis 연동 코드 등을 검토한 후 테스트 범위와 효과에 대한 학습 취지 질문, TigerBeetle에서는 이미 Antithesis로도 포괄적 테스트를 진행한다고 알고 있었는데, Jepsen이 발견한 버그가 Antithesis에서는 어떻게 못 잡았는지 궁금, Antithesis와 Jepsen 테스트의 차이, 그리고 내부 테스트 범위가 궁극적으로 어떻게 다른지 구체적으로 질문
          + aphyr의 보충 설명으로, 분산 시스템의 generative testing을 위해서는 1) 시스템 실행 환경 2) 로드 제너레이터 3) 오디터 3가지 요소 필요 설명, Antithesis는 주로 1번으로, 결정론적 시뮬레이션 환경 제공 기능 담당, Jepsen은 실제 머신·OS 레벨 장애 삽입, TigerBeetle의 VOPR은 한 스레드 내에서 전체 클러스터 운용, 각 시뮬레이션 방식은 서로 장단점 보완 설명, 이번 버그 사례는 결국 2), 3)인 workload 발생·검증자 오디터가 핵심, aphyr의 TigerBeetle 전용 Clojure 코드가 해당 버그 야기 및 탐지, 이 후 자체 동등 코드도 패치, 디비 자체보다 VOPR에서 더 핵심적인 문제였다는 사실, 분산 디비는 항상 버그 가능성 존재, 근본적으로 여러 생성기·테스트 전략 설계 중요
          + TigerBeetle의 블로그에도 이 이슈 상세 안내, 요약하자면 Antithesis에서 사용된 테스트가 이번 버그에 필요한 교차 쿼리와 out-of-order 값 조건을 다루지 않아 해당 버그를 놓쳤고, Jepsen 쪽은 그 조합을 맞춰 탐지에 성공, Jepsen의 test generator에도 어느 정도 한계는 있다는 점과 다양한 생성기 설계 필요 강조
          + 내부 지연 시뮬레이션 테스트의 90%는 VOPR(자체 시뮬레이터)에서 수행, 1,000개 CPU 코어로 24/7 가동, Antithesis는 추가적인 레이어로 사용, 쿼리 엔진 버그가 왜 빠져나갔는지는 이 포스트 참고 안내
     * TigerBeetle에 관심이 있다고 밝히며, 클라이언트 문서상 C나 Zig 클라이언트가 없는 점 의아함 표현, 직접 Zig로 작성된 만큼 이 클라이언트가 존재하지 않거나 개발 중인지 질문
     * TigerBeetle을 이미 대형 은행이나 증권사에서 사용하는지 궁금
          + TigerBeetle의 조란, 현재 Gates Foundation과의 협력으로 루안다의 국가 디지털 결제 시스템 2.0 전자중앙은행 구축에 활용 예정, 엔터프라이즈 차원에선 월 1억+ 트랜잭션 처리 고객 실서비스 이미 운영 중, 최근 유럽 20억 달러 규모 핀테크 유니콘과 계약, 미국에서는 추가 계약이 진행 중, 전 세계적으로 실시간 트랜잭션 처리 수요로 TigerBeetle 도입 니즈 증가, 실제 월스트리트의 중대형 브로커리지 Clear Street 창립자들이 투자에 참여, 관련 링크는 mojaloop.io, TigerBeetle의 블로그, 회사 소개 안내
          + 대형 은행이나 거래소는 아니지만, 본인이 대형 핀테크에서 새로운 상품에 이미 사용 중
          + 홈페이지에 자랑하지 않는다는 이유로 빅 네임 레퍼런스가 없을 것으로 추정, 현재로선 영향력 있는 유튜버의 추천 정도가 가장 큰 endorsement로 보인다는 의견
"
"https://news.hada.io/topic?id=21327","Show GN: cpdown – 웹페이지/유튜브 자막을 깔끔한 마크다운으로 복사해주는 익스텐션","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Show GN: cpdown – 웹페이지/유튜브 자막을 깔끔한 마크다운으로 복사해주는 익스텐션

   TL;DR: 웹페이지 본문, 유튜브 자막까지 클릭 한 번 (또는 단축키)으로 군더더기 없이 깔끔한 마크다운으로 복사해주는 크롬 확장 프로그램 만들었습니다. 특히 LLM에 프롬프트 입력할 때 유용해요!

   안녕하세요, 긱뉴스!

   저는 웹에서 찾은 정보를 제 노트(Obsidian)에 저장하거나 글/영상 요약, 번역을 위해 LLM에 컨텍스트로 제공하기 위해 자주 복사하곤 합니다. 이를 위해 cpdown이라는 브라우저 확장 프로그램을 만들었습니다.

   cpdown은 단 한 번의 클릭 (또는 단축키)으로 어떤 웹페이지든 깔끔한 마크다운으로 변환하여 클립보드에 복사해줍니다.

   주요 기능은 다음과 같습니다:

   핵심 콘텐츠 추출: Mozilla의 Readability나 Obsidian 개발자가 만든 Defuddle을 사용하여 광고, 사이드바 등 불필요한 부분은 제거하고 본문 내용만 정확히 추출합니다.

   깔끔한 마크다운 변환: 정리된 HTML을 Turndown 라이브러리를 통해 깔끔한 마크다운으로 변환합니다.

   토큰 수 계산: 복사된 텍스트의 토큰 수를 tiktoken을 사용해 계산하고 알려줍니다. ChatGPT나 Claude 같은 LLM에 내용을 붙여넣기 전에 토큰 수를 미리 확인할 수 있어 매우 유용합니다.

   유튜브 자막 복사: 유튜브 영상 페이지에서는 전체 자막을 마크다운 형식으로 복사할 수 있습니다. 영상 제목이 H1 태그로 자동 추가됩니다.

   사용자 설정: 콘텐츠 추출기(Readability/Defuddle)를 선택하거나, 복사된 내용을 코드 블록으로 감싸는 등 여러 옵션을 설정할 수 있습니다.

   cpdown은 완전 무료이며 오픈소스입니다. WXT, React, TypeScript를 사용해 개발했으며, 코드의 절반이상은 Cursor Agent 모드로 작성했습니다.

   크롬 웹스토어에서 바로 사용해보시거나, GitHub에서 소스 코드를 확인하실 수 있습니다.

   Chrome 웹스토어: https://chromewebstore.google.com/detail/cpdown/…

   GitHub: https://github.com/ysm-dev/cpdown
"
"https://news.hada.io/topic?id=21413","React와 Next.js를 위한 완벽한 Cursor AI 설정법 [번역글]","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               React와 Next.js를 위한 완벽한 Cursor AI 설정법 [번역글]

     * React, Next.js, Tailwind CSS 작업에 최적화된 Cursor AI 설정에 초점을 맞추지만, 대부분의 설정은 어떤 기술 스택에도 적용할 수 있음
     * Cursor AI 설정 조정하기
          + 설정 + 규칙 (Settings + Rules)
          + 노트패드(Notepads)
          + ESLint 추가
          + Visual Editor CLI 사용
     * Cursor 코드 에디터에서의 핵심 기능 설정과 활용
          + 코드 에디터에서의 Cursor AI 'Tab' 기능
          + 코드 생성을 위한 Cursor AI 'Chat' 기능
          + Cursor 규칙(Rules)
          + Cursor의 ‘@docs’ 기능
          + Cursor AI의 '@web' 기능
          + Cursor AI의 'Notepads' 기능
          + Cursor AI의 자동 린트 수정 기능으로 코드 품질 향상하기
          + Cursor의 테스트 기반 코드 생성 루프 설정하기
          + Cursor에 MCP 추가하기

     ""AI 도구를 마스터하는 것은 한 번에 끝나는 작업이 아닌 지속적인 과정입니다. 프롬프트를 계속 다듬고, 코드 변경을 자주 커밋하며, 새로운 AI 모델을 시도하고, 프로젝트에 맞는 적절한 컨텍스트를 사용하는 습관을 들이세요. AI를 협업 파트너로 받아들이면, 이전보다 훨씬 높은 생산성과 개발 숙련도를 경험하게 될 것입니다.""
"
"https://news.hada.io/topic?id=21323","이틀 간의 빈 스토어에서","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             이틀 간의 빈 스토어에서

     * Amazing Binz는 주로 대형 유통사 재고 및 반품 상품으로 진열된 파격가 소매점 형태임
     * 소비자, 리셀러, 이웃 모두가 저렴한 가격과 소비 과잉의 상징적 공간이라는 점에서 엇갈린 반응을 보임
     * 반품·역물류 산업의 성장과 COVID-19 팬데믹 이후 공급망 변동성이 이런 매장의 확산을 촉진했음
     * 최근 경쟁 심화, 물류 가격 상승, 한계점 도달 등으로 미국 전국적으로 빈 스토어 붐이 둔화 추세로 전환됨
     * Amazing Binz의 경험은 오늘날 소비 문화, 창업 시장, 지역 사회 변화를 독특하게 비추는 사례임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# Amazing Binz—동네에 상륙한 새로운 빈(bin) 스토어

   이 봄, 필라델피아 West Philadelphia 한복판에 오픈한 Amazing Binz는 다양한 반응을 일으키는 신개념 매장이었음. 전에는 빈티지 스토어였던 자리에서 등장한 이 매장은 Walmart, Amazon, Costco, Best Buy 등 대형 리테일러의 로고와 함께 “CRAZY DEALS, AMAZING BINZ”라는 슬로건을 내세움. 매장 내부는 일상의 상품들—할로윈 복장, 이상한 디자인의 아이스 몰드, 임신 테스트기, 다양한 생활용품—로 넘쳐나고, 가격 정책이 주된 특징임. 금요일 재고 입고 직후에는 모든 물품이 $10, 하루씩 지날수록 가격이 $8, $6, $4, $2, $1로 떨어짐. 목요일은 문을 닫고 재고를 새로 들여옴.

# 역물류(reversed logistics)와 상품의 순환

   Amazing Binz의 재고는 대기업의 초과 재고와 반품 상품으로 구성됨. 로지스틱스 연구자에 따르면, 상품이 고객에게 도달한 후 마음에 들지 않거나 문제가 있으면 ‘역물류’가 작동함. 현재 전체 상품의 약 17%가 반품되고, 온라인 구매에선 거의 30%에 달함. 초과 상품과 반품 처리 수요가 늘어나면서 TJ Maxx, Nordstrom Rack 등 기존 리퀴데이터 뿐 아니라 린스토어(bin store) 모델이 확대되는 추세임. 기업이 직접 또는 중개 플랫폼(B-Stock 등)을 통해 트럭 단위 상품을 처분하고, 인플루언서들도 언박싱 콘텐츠로 활용함.

   매장 운영자 Ahmed는 ""여기서 산 물건을 eBay, Amazon, Facebook Market 등에서 다시 판매하면 하루 만에 투자금 회수가 가능하다""고 설명함. 리셀러와 일반 소비자가 새로운 물류 생태계의 주체가 되는 구조임.

# 금요일: $10—고가 상품을 노리는 날

   Amazing Binz는 가격이 가장 높은 금요일 아침부터 줄이 이어지며, 일부는 이미 인스타그램을 통해 상품을 '찜'해놓고 방문함. 타 지역에서 온 손님들도 보이며, Philly 지역의 리퀴데이터 및 린스토어 시장이 활발함을 체감할 수 있음. Colton Carlson 등 업계인은 2018년 10여 곳뿐이던 린스토어가 현재 약 1만 곳까지 늘었다고 분석함. 무작위 초과 재고, 빠른 판매를 유도하는 점진적 가격 인하 모델이 성장의 비결임.

   공급망 불안과 코로나19로 소매점이 재고를 대량으로 쌓아두었다가 소비 급감으로 물건이 쏟아져 나온 결과, 최종 소비자 또는 리셀러들이 값싸게 상품을 구입하는 기회가 맞물림.

# 토요일: $8—동네 반응과 공간의 상징성

   토요일 농산물 시장이 열리는 날에는 비교적 한산하지만, 여전히 다양한 상품과 손님이 오감. Amazing Binz에 대해 지역 커뮤니티(예: West Willy Facebook 그룹) 반응은 극명하게 갈림. 긍정 의견은 저렴함과 다양한 상품, 부정 의견은 바라보는 소비 문명의 끝자락, 자본주의 말기 상징과 같은 심리적 거리감이 뚜렷함.

   매장 위치는 대형 물류 공간이 아닌, 동네의 오래된 스트리트에 자리함. Ahmed는 카페나 디저트 가게로 오픈하려다가 임대료·허가 등의 문제로 소규모 린스토어를 택함. 지역의 다양한 계층과 성향의 손님이 섞이고, 저마다 이유로 발길을 함.

# 일요일: $6—가격 구조와 리셀 비즈니스

   Amazing Binz의 인스타그램 담당 Omran이 “I know daht’s right” 라는 캐치프레이즈로 손님 인터뷰를 촬영함. 직접 창고와 거래해 물건을 들여오며, 트럭 한 대당 수천 개 상품이 평균 $16,000에 납품됨(개당 평균 $2 수준 유지 목표). 대부분 린스토어는 고가 상품을 별도 VIP 섹션에 판매하지만, Amazing Binz는 주요 상품도 일반 가격에 내놓아 더 많은 손님 유입을 유도함.

   가격이 낮아질수록 남아있는 상품은 점점 수요가 없다는 사실이 드러남. 한편, 남는 것들의 양과 종류를 목격하면서 집단적인 과소비 문제를 직접 경험하는 일종의 “예술 작품” 같은 느낌을 주기도 함.

# 월요일: $4—변화의 조짐과 한계점

   비가 많이 오는 한 주, Amazing Binz는 한산한 분위기임. 재고 중 일부 정치색이 강한 상품(예: 트럼프 깃발, MAGA 등)이 발견되면 직원이 바로 수거·처분함. 소형 매장은 대형 매장에 비해 재고 순환, 비용 구조, 불확실성에 더 민감한 구조임.

   Colton Carlson 등 일부 선구자조차 수익성 저하, 상품 질 하락, 재고 비용 상승 등으로 빈 스토어 운영을 철수하고 다른 형태의 리셀 비즈니스로 전환 중임. 전국적으로 일부 린스토어가 폐점 또는 파산하는 등 시장 과열→정체 분위기가 감지됨. 단, 향후 경제 변동(관세, 초과 재고 등)이 또 다른 재기의 계기가 될 수 있다고 업계 전문가는 전망함.

# 화요일: $2—고갈과 생존의 고민

   매장 운영자 Ahmed는 최근 가격 인상 압박, 이익 감소로 지속 가능성을 걱정하고 있음. 물품을 공급받기 위한 단가도 오르고, 몇 달 내에 전체 비즈니스 리뉴얼이 필요할 수도 있다고 밝힘. 방치된 상품은 종종 소셜 미디어 알고리듬에 따라 만들어지고 유통되며, 결국 시장에서 필요 없어지면 Amazing Binz와 같은 린스토어로 흘러들음. 창업자, 물류업체, 기자, 이용자는 모두 디지털·물리 유통의 말단에서 역할을 수행하게 됨.

# 수요일: $1—최종 단계와 존재의 의미

   가격이 $1까지 떨어진 수요일 밤, Amazing Binz엔 다시 북적임이 돌아옴. 남아있는 상품들은 대부분 필요하지 않은 물건임에도 불구하고, 손님은 습관적으로 구매함. Amazing Binz는 단순히 저렴하거나 재미있는 매장을 넘어, 오늘날 산업·유통·소비 구조가 만들어낸 최후의 공간처럼 느껴지기도 함.

   매일 새로 진입하는 상품들과 사라지는 품목들—누적된 상품 층 아래, 이 모든 것이 결국 landfill 또는 미세플라스틱으로 남을 미래를 암시함. Amazing Binz의 경험은 소비 문화, 창업 환경, 지역 커뮤니티 변화, 역물류 등이 집약된 현실임.

        Hacker News 의견

     * Ahmed가 말한 것처럼, 여기서 물건을 사서 eBay나 Amazon, Facebook market을 통해 재판매하면 하루 만에 돈을 회수할 수 있는 구조임을 이야기하는데, 실제로 이런 매장들은 자신들이 구매한 팔레트에서 더 가치 있는 물건들을 먼저 골라내서 eBay나 Amazon 따로 파는 경우가 많을 거라는 예상 의견임
          + 내가 자주 가던 한 자선 중고 매장 체인에서도 이와 비슷한 일이 있었는데, 직원들이 귀금속이나 전자제품, 게임 등 더 값나가는 걸 잘 선별해서 자체 eBay 스토어에 올리고, 유통/분류 센터에서는 전문 리셀러들이 디자이너 의류 같은 것만 미리 빼가게 허용하므로 오프라인 매장에서는 늘 남은 것들만 파는 구조였던 경험이었음
          + Bin store들 역시 비슷한 전략을 쓴다면, 너무 많이 안 빼내고 소수의 가치 있는 물품은 일부러 bin에 섞어놔서 매주 수백 명씩 줄 서는 열기를 유지하는 똑똑한 운영이 있을 거 같음
          + Maine에 있는 Mardens라는 서플러스&세일비지 체인 얘기를 들려주고 싶음. 60년 된 이 매장은 소매점에서 처리 못한 팔레트나 컨테이너 단위 상품을 사서, 온라인에서 제일 비싼 가격에서 20-40% 할인해 판매함
               o 가게에 가면 어느 날은 Moccamaster 커피메이커나 Arcteryx 재킷 등 정가 그대로 팔아도 되는 고급 제품을 그냥 싸게 파는 경우도 있지만, 대부분은 별로인 물건 위주임
               o 이 매장은 전체적으로 매입가의 20~30%에 사서 정가의 60%쯤에 파는 방식임. 개별 이익 극대화보다는 대량판매로 이익을 안정적으로 만들어 내는 전략으로 보임
               o 2주에 한 번씩 들를만한 즐거운 매장임
          + Goodwill 역시 비슷하게 운영하는데, 많은 물건은 eBay가 아니라 자체 경매 사이트(shopgoodwill.com)에서 팔림
               o Goodwill 입장에선 수익을 극대화하므로 합리적이라고 생각함. 배송비 아껴서 현지에서 직접 픽업할 수 있는 무겁고 비싼 물건만 노려도 꽤 괜찮은 득템 가능성 있음
          + 해당 기사는 이런 식으로 매장 측이 고가 아이템을 따로 빼낸다는 힌트는 없었음
               o 매장 주인들은 매장 운영만으로도 충분히 바쁜 모습이고, 실제로 진짜 물건을 찾으려는 사냥꾼들이 들어오는 걸 바라는 듯함
               o 확실한 $10 매출 뿐만 아니라 보석을 찾을 수 있다는 입소문과 기대감이 매장 분위기를 한껏 띄워주기 때문임
          + 실제 bin store들 중에는 정말 좋은 물건만 따로 빼서 친구에게 더 비싸게 팔거나, 아예 기사에 나온 것처럼 VIP구역 같은 데 더 비싼 가격으로 따로 올리는 곳도 있음
               o 더 큰 문제는 mystery box(미지의 박스)만 파는 bin store들로, 이건 하루 1달러에도 안 팔린 진짜 쓰레기만 담아 판다는 점임
          + 특별하게 가치 있는 게 아니면 주인들이 선별해서 빼놓진 않는다는 생각임. 내 동네 bin store는 페이스북에 제일 좋은 상품 사진을 올려서 사람들의 방문을 유도했음
     * 요즘 bin store가 여기저기 정말 많이 생기고 있음
          + 우리 집 근처 5마일 내에 두 곳이 있고, 둘 다 1년 넘게 장사 중임. 미드웨스트 중소도시인데 주로 블루칼라/제조업 중심 지역임
          + Red Tag 같은 Target 오버스톡 전문점도 있는데 Target 바로 맞은편에 위치함
          + bin store 중 큰 곳은 토요일 정오에 $7에서 시작해서 다음 주 금요일엔 $1까지 떨어짐. 줄이 엄청 김
          + 멤버십 비슷한 걸 팔아서 먼저 들어가거나 줄 앞쪽 자리를 살 수 있게 하는 것 같음
          + $35짜리 랜덤 sealed(봉인) 박스도 팔고, 여러 개 사면 묶음 할인도 있음(예: 4개 $100)
          + 대부분 Amazon이나 다른 온라인 리턴 제품을 로트로 구입해 팔고 있는 걸로 보임
          + ""Surplus""로 구글맵 검색하니 비슷한 구조의 매장들을 여럿 찾을 수 있었고, 다른 곳에서 초광폭 모니터를 $400에 샀던 경험도 있음(신품 대비 $350 이상 절약한 셈)
          + 이 가게들이 정말 좋은 점은, 리턴되는 물건이 워낙 많아서 약간의 수고만 들이면 원하는 물건을 거의 필연적으로 구할 수 있다는 점임
          + Portland에는 Goodwill Outlet store(""The Bins"")가 25년 넘게 존재함
               o 여기는 보통 Goodwill 점포에서 안 팔린 것들을 한꺼번에 bin에 넣고 무게로 파는 방식임
               o 테크업계 불황기에 나도 여기서 책 빈을 뒤져서 Amazon에서 중고로 팔 만한 책을 골라 내다 팔며 생계 유지한 적 있었음. 하지만 Goodwill에서 6개월쯤 지나자 직접 쓸만한 책을 뽑아 온라인에 팔기 시작함
               o The Bins만의 독특한 문화가 있음. 'Bin 바꾸기' 시간에는 낡은 bin이 치워지고 새 bin이 나오는데, 이때는 새로운 bin 등장 위치 주변에 사람들이 몰려들며 혼돈의 시간임
     * 사진과 내용상으로 보면 bin store 안 물건은 95%가 전부 쓰레기 신품인 것 같음. 도대체 누가 이런 걸 살지 의문이었는데, 실제로는 이런 매장이 수백 곳이나 성업 중임
          + bin 안 물건들은 대부분 Amazon 리턴품임. 매장 주인들은 Amazon 팔레트 경매에서 물건을 싸게 사서, 실제로는 내용을 모른 채 구매해 차익을 노림
          + 필요 없으면 안 사는 편이 좋음. 너무 싸서 '정말 필요한가?'에 대한 고민 없이 그냥 사버릴 수 있다는 게 문제임
               o 또, 사진과 실물이 다르기 때문에 실제로 직접 보고 산다면 대부분 사지 않을 아이템임
               o 결국 쓰레기를 바다에 바로 버리는 것과 비슷한 이야기고, 실제로 상당수가 결국 바다까지 흘러들어감. 차라리 매립지가 조금 낫다는 생각임
          + 이건 일종의 스캐빈징(주운 것 찾기)이라 볼 수 있음. 부모님이 수집가 성향이라 $0.25 데이에 가능성 있는 물건을 사다 모으는 걸 좋아함. 그래도 어차피 쓰레기가 될 걸 싸게 구입하니, 정가 주고 쓸모없는 걸 또 사는 것보다는 낫다는 생각임
          + 나도, 그리고 많은 이들도 이렇게 생각했다는 점에 공감함. ""어떤 사람들이 뭘 살지 알 수 없다""는 Dr. Seuss의 Lorax에서 인용한 명언에 크게 웃음이 나옴
          + 이 가게는 진짜 별로라는 솔직한 의견임
     * 나는 물건을 반품하는 것이 아직도 꺼림칙하게 느껴지는 편임. 오히려 귀찮아서 구매 자체를 안 하는 쪽을 선호하는 경우가 많음
          + 나는 매우 적극적인 반품족임. 설명이 달랐거나, 품질이 별로거나, 내게 안 맞으면 반품하는 것이 판매자와 시장을 더 정직하게 만든다고 생각함
               o 특히 치수나 품질을 제대로 써주지 않는 업체들에게는 반품이 소비자가 남길 수 있는 거의 유일한 강한 피드백임
               o 물론 단순 변심이나 사용한 물건까지 무분별하게 다 돌려보내진 않지만, 소비자 권리를 적극적으로 행사하는 편임
               o 예를 들면 고가 헤드폰처럼 품질과 내구성, 사운드 등 엄청 자랑하지만 실제로는 불량이나 정보 은폐가 많음. 제품 개발 과정에서 측정까지 해놓고 측정치를 숨기고 파는 건 고객에 대한 적대적 태도라고 생각하기 때문에, 이런 경우엔 오히려 더 당당하게 반품하는 편임
          + Amazon의 가장 큰 장점이 바로 물건을 사서 내 집이나 자전거, 프로젝트에 직접 조립해 보고, 안 맞으면 반품할 수 있는 구조임
               o 동네 매장에서는 아예 구하지 못하는 부품이 많아서 Amazon 덕분에 다양한 시도와 조합이 가능해짐
               o 물론 전체 Amazon 리턴의 큰 비중은 아닐 거라고 생각함
          + 나도 예전엔 제품 조사 열심히 하고 사면 거의 반품 안 했는데, 2020년 이후 물가가 크게 오르고 나니 기준이 달라졌음
               o 써본 물건까지 반품하진 않지만, 품질이 별로거나 처음부터 만족도가 떨어지면 (특히 대형 유통점 기준) 거리낌 없이 반품하는 습관이 생겼음
               o 주로 아웃도어, 레저, Home Depot, Best Buy같은 매장 구매품 위주임
               o 5년 사이 개인 책임감에 대한 태도가 바뀌었다는 걸 느낌. 하지만 '신발 5켤레 사고 4개 돌려보내기' 이런 극단적 이용은 귀찮아서 안 함
          + 반품이 불편하다는 느낌은 있지만, 기본적으로 산 물건은 그냥 쭉 쓸 생각을 하며 구매함
               o 예시로, $100 정도 하는 샌들 여러 켤레 중 어떤 게 맞을지 몰라 망설이게 되기도 함. 사용 흔적이 남으면 반품할 수 없으니 결국 구매를 미룸
               o Amazon/Walmart 주문도, 함께 보내면 손상될 만한 조합은 피하려고 전략을 짬
               o 그런데 우편/온라인 주문의 불량/손상 비율이 높다 보니, 최근에는 이런 이유로 반품하는 데 대한 불편함이 줄었음
               o 최근엔 유명 브랜드 테이블웨어를 샀는데, 고객센터에서 가짜라고 하더라. 포장도 실제 매장에서 파는 게 아니고, 유해성분이 섞인 느낌이었다는 점에서 죄책감 1도 없이 반품함
               o 내가 온라인 쇼핑 평균 반품률 30%란 기사를 보고 깜짝 놀람. 내 경우는 명백한 불량·손상만 반품해서 평범하다 생각했는데, 만약 오프라인 매장에서 어떤 고객이 30%씩 반품했다면, 그 손님은 내쫓고 싶을 것 같음
               o 의류 피팅 프로그램 빼고는 이런 고반품률을 줄이는 혁신이 필요할 것임
          + 나는 지금까지 단 한 번도 반품해본 적 없음. 애초에 소비를 많이 하지도 않고, 사서 쓰다 필요 없으면 바로 반품하는 구조 자체가 불필요한 짐을 늘리는 것 같다는 생각임
     * 누군가 궁금한 사람을 위해 Wokaar의 nose beard waxing에 대해 알려줌. 이름 그대로 코털을 왁스로 제거하는 도구임(꽤 아플 것 같다는 코멘트와 함께). Wokaar nose wax kit 링크도 공유함
          + 고마움을 전하며, 기사에서 가장 기억에 남았던 대목이 ""Nose Beard""라는 말이란 점을 유쾌하게 덧붙임
     * 이에 약간 연관된 정보로, Climate Town에서 팔레트 단위 리턴상품 취급에 대한 긴 영상을 만든 바 있음 Climate Town: Pallet-sized returns video
     * 예전에 반품 경매 사이트가 먼저 생겼는데, 난 운 좋게 지역 유통 허브 근처에 살아서 꽤 좋은 상품을 싸게 구했던 경험이 있음
          + FDM 3D프린터 $45, 레진 3D프린터(12k) $65, 1년 뒤엔 경화기 $20, DJI 짐벌도 $70에 득템
          + 시간이 지나며 소문이 나자 가격이 점점 오르고, 낙찰가에 구매자 수수료, 국가세금, 아이템 당 픽업비까지 붙으며 실질적으로 최대 소매가의 25% 미만 입찰만 내 이득이 남았음
          + 약 1년 전에 bin store들이 생기고 나서 경매에서 좋은 상품이 급격히 줄었고, bin store도 몇 번 돌아다녀 봤지만 거의 쓸모없는 잔뜩 모은 쓰레기 수준이었음
          + 그래도 이제 내 maker space용 홈오피스는 완비했지만, 여전히 특정 키워드는 모니터링하고 있음
          + 전반적으로 auction과 bin store 양쪽 모두 물건 질이 급격히 떨어지고, 경제 전반의 둔화, 관세, 해고 등 복합적인 영향으로 느껴짐
          + 주변 bin store 여러 곳도 최근 6개월 사이 문을 닫는 곳이 늘었음
     * 내 동네에도 이런 가게가 있었는데, 두 번 가봤더니 값싼 여성·아동 의류, 여기저기 잡부품, TV광고 물품 등 쓸모없는 것 투성이였음
          + 결국 너무 팔기 힘든 것들이 대부분이라 1달러에도 팔리지 못해 폐업 수순을 밟았던 듯함
          + 이런 물건을 매립하는 데에도 비용이 들어감. Storage Wars 같은 프로그램을 보면 초기엔 창고에 좋은 물건도 있고 DVD, 가구 등으로 돈을 잘 벌었지만 시즌이 흐를수록 단가가 싸진 신상품 청소 수준 쓰레기가 시장에 넘쳐나 사용감 좋은 중고에 대한 수요도 떨어져 버린 현상을 볼 수 있었음
     * ""Reverse logistics의 목표는 매립지로 가는 걸 막는 것이다""라는 인용에 대해, 덜 써본 소비자가 사서 버리게 만드는 구조로 바뀐 것이라는 시각임
          + 사용되지 않은 상품을 폐기하는 데도 비용이 드는데, 이런 부담을 '어떤 루프로든' 전가해 결국 소비자나 개발도상국에 넘기는 현실, 예컨대 Atacama 사막의 의류 폐기 사건으로 설명함
          + 이상적으로야 구매해서 한동안 쓰고 버리는 게 낫겠지만, 결국 우리가 사는 물건은 대부분 언젠가는 쓰레기가 될 운명임
          + 판매되지 않은 제품을 보관하는 비용도 상당함. 점포는 진열공간의 기회비용, 임대료, 유지비, 전기료 등 모든 요소에 매우 민감함
               o 30입방미터 쓰레기를 3년간 창고에 보관하고 있다면, 결국 운반/분류 비용에 임대료까지 더해지므로 '내 junk를 이렇게 오래 붙잡고 있을 이유가 없다'는 판단이 필요함
     * 시즌 종료, 약간 찌그러진 박스, 미수령 주문, 창고가 비좁을 때 발생한 상품 등 여러 사유로 중고시장에 나오게 되는데, 궁금증은 '관세'가 이런 흐름에 어떤 영향을 미칠지가 궁금함
          + 수입상들이 관세 폭탄을 맞을 경우 아예 터미널에서 물건을 찾아가지 않을 수도 있음
          + 기사 후반에 ""경제충격은 중고시장에는 유리하게 작용하고, 관세가 결국에는 bin store에 다시 붐을 일으킬 수 있다""고 언급된 대목이 있음
          + 캐나다 경험자로서, 실제로 관세 때문에 리턴경매와 bin store 모두 물량이 계속 줄어가는 추세가 확실하게 느껴진다는 설명임
"
"https://news.hada.io/topic?id=21317","Gemini-2.5-pro-preview-06-05 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Gemini-2.5-pro-preview-06-05

     * 정식 출시전에 최신 Gemini 2.5 Pro의 미리보기 버전이 이용 가능해짐
     * LMArena, WebDevArena 등 주요 평가에서 기존 모델 대비 24~35점 Elo 상승
     * 코딩, 과학, 수학, 멀티모달 이해, 장문 컨텍스트 처리 등 주요 벤치마크에서 최상위 성능을 기록
     * 입력 가격 $1.25, 출력 가격 $10(백만 토큰 기준) 으로 경쟁사 대비 저렴한 비용 구조

  주요 벤치마크별 비교

     * Reasoning & Knowledge (Humanity's Last Exam): 21.6%로 OpenAI/Anthropic 등과 비슷한 수준, DeepSeek R1(14%)보다 우수
     * Science (GPQA diamond): 86.4%로 업계 최고 성능(단일 시도 기준)
     * Mathematics (AIME 2025): 88.0%로 OpenAI o3, DeepSeek R1과 유사한 수준, Anthropic Claude 4/3보다 높음
     * Code Generation/Editing: LiveCodeBench 69.0%, Aider Polyglot 82.2%로 코드 생성/수정 모두 높은 정확도
     * Agentic Coding (SWE-bench Verified): 59.6% (단일), 67.2% (다중 시도)로 Anthropic Claude 4에 비해 약간 낮으나 OpenAI/DeepSeek과 비슷
     * Factuality: SimpleQA 54.0%, FACTS Grounding 87.8%로 실제 데이터 근거 생성에서 강점
     * Visual/Video/Image Understanding: MMMU 82.0%, Vibe-Eval(이미지) 67.2%, VideoMMMU(비디오) 83.6%로 텍스트-이미지-비디오 모두 강점
     * Long Context (MRCR v2, 128K): 58.0%로 OpenAI, Anthropic, xAI 등 주요 경쟁 모델 대비 최고 성능

  가격 및 지원 언어

     * 입력 가격: $1.25 / 백만 토큰 (200K 이상은 $2.50)
     * 출력 가격: $10 / 백만 토큰 (200K 이상은 $15)
     * 지원 언어: 70개 이상 글로벌 언어(멀티폴리글롯 89.2%)

  사용처 및 추가 특징

     * Google AI Studio, Vertex AI에서 즉시 프리뷰 사용 가능
     * Thinking Budget 등 개발자용 비용·지연 제어 기능 추가
     * 코딩, 지식, 멀티모달, 장문 처리 등 실제 업무 활용에 적합한 기능 강화

결론

     * Gemini 2.5 Pro는 가격, 성능, 범용성, 멀티모달, 장문 컨텍스트 등 다양한 항목에서 경쟁사 대비 우수함
     * 기업용 및 개발자용 AI 도입 시, 주요 벤치마크 기반의 명확한 비교와 비용 효율성을 함께 고려할 수 있음

        Hacker News 의견

     * Google이 lmarena에서 약 25 ELO를 추가로 올린 것에 감탄하는 중, 이전 #1도 Gemini였다는 점에 주목하게 되는 경험 Gemini와 Claude Opus 4 둘 다 지난 몇 주간 충분히 사용해본 결과, 내 생각에 Opus가 차원이 다르다고 느껴진 경험 복잡한 TypeScript 문제들을 다루면서 Gemini는 어느 순간 같은 부분에서 맴돌거나, 심지어는 포기하고 못 하겠다고 말하는 일까지 처음 겪었지만 Opus는 쉽게 해결하는 인상 이 사례가 전체 성능의 단면을 보여주는 건 아니겠지만, Gemini는 코드를 억지로 돌아가게 만드는 느낌인 반면 Opus는 문제의 본질을 파악하고 더 깔끔하게 접근하는 방식이라는 점이 차별점 Opus가 상상력이 더 풍부하거나, 에이전트적 과제에 더 최적화된 듯한 느낌도 있었음 Opus는 playwright 스크립트를 만들어 DOM을 덤프하고 분석해서 상호작용 이슈를 점검하는 등 예상 못한
       솔루션을 단발적으로 만들었던 점이 특히 인상적이었던 경험 Gemini는 코드 자체를 집요하게 읽으며 버그를 잡으려 하는데, 접근 방식의 한계가 있다고 느낌 그럼에도 불구하고 Gemini도 훌륭한 모델이며, 버전 4.0 전에만 해도 최고라고 생각했었음
          + 나 개인적으로 Opus 4보다도 o3가 더 선호되는 상황에서, 최근 한 달간 AI 코드 생성 툴에 수백 달러를 쓰면서 나만의 랭킹을 세워봤음 1위는 o3, 세밀한 부분 처리, 문제의 본질 파악, 실제 프로덕션에 사용 가능한 고품질 코드 작성에서 무척 뛰어남 단점은 컷오프 윈도우와 비용, 그리고 툴 사용을 지나치게 좋아한다는 점 Rails 프로젝트에는 거의 문제가 없지만 때로 영향이 있음 2위는 Opus 4 (Claude Code 통해 사용), 성능도 좋고 o3에 비해 저렴해서 데일리 드라이버로 주로 사용 Opus 4가 계획·처음 초안을 만들면 o3가 이를 꼼꼼히 비평하고 피드백을 리스트로 만들어서 정말 완성도를 높이는 데 쓰고 있음 3위는 Gemini 2.5 Pro, 이번 최신 릴리스를 써보진 않았지만 전에는 순위 2위였음 지금은 Sonnet 4와 동급이거나 약간 더 우위, 상황 따라 다름 4위 Sonnet 4, 코드량은
            많지만 직접적으로 코칭·감독하지 않으면 정말 질 좋은, 간결하고, 깊이 있는 코드를 뽑진 못함 내가 코드 퀄리티와 구성에 (이름, 재사용성 등) 집착이 심한 편이라, 지난달 Cursor 통계 기준 자동 제안 코드 중 33%만 수락하는 수준 최적 경로가 아닐 때는 실수 요청을 수정하고 다시 프롬프트를 다듬어가며 더 나은 결과 추구 중
          + Gemini의 가장 뛰어난 점은 다른 모델 대비 검색 기능의 우수성 회사에서 도메인으로 스팸 보내는 곳에 이메일 작성 요청하니 호스팅 업체의 abuse 이메일, 도메인 정보, mx 서버, IP, 데이터센터 등 모두 찾아줌 논문을 팟캐스트로 변환 요청도 즉시 해줬고, 듣는 재미도 쏠쏠했음
          + 이번 주 Claude 4와 Gemini 2.5에 동일한 과제를 줬을 때 Gemini는 정답을 주고 Claude는 제대로 못 해냄 특히 SQL 쿼리 비교처럼 어려운 과제가 아니라도 Gemini가 실제 문제를 찾아내는 경우가 많았음
          + 실제로는 상황에 따라 다르게 느끼는 경험이 많았음 어떤 문제는 Gemini가 척척 해결했지만 바로 다음에는 아주 간단한 버그에서 막히는 혼란스러운 경험 o3와 sonnet도 마찬가지였고, 4.0은 아직 충분히 써보지 않아 평가 유보 여러 모델을 병렬로 평가해서 최적 솔루션 고르는 지원 필요성 느낌
          + 혹시 o3로도 테스트 해봤냐는 질문받음 내 사용 사례에선 o3가 Opus 4보다 훨씬 인상 깊었던 경험
     * OpenAI의 시장 가치 측면에서 점점 걱정이 앞서게 되는 상황 강력한 경쟁자가 많아졌고, 이제 더이상 독보적 리더가 아니란 평가가 설득력 있음 3,000억 달러의 밸류에이션에서 앞으로 어떻게 더 투자 유치할지 궁금증 수익은 적고 하드웨어·전기 요금 등 비용은 계속 늘어갈 때 실질 가치 산정이 어려움 다음 세대 LLM이 새 데이터가 필요한 시점에서 Facebook, Google이 강점을 가져갈 듯한 구조 자체적으로 많은 데이터 비즈니스가 없는 OpenAI는 독점 데이터 경쟁에서 불리하다는 생각 연구와 사용자 앱 양쪽에서 리더였던 시절에야 높은 가치가 정당화됐지만, 지금은 신뢰의 근거가 빈약 신규 투자자가 OpenAI에서 얻을 이익이 의문 3,000억 달러 밸류에이션에는 보통 매출 2배수 수준인 1,500억 매출이 요구되고, 극한의 P/E(100배)로도 연 30억 이익, 10년 연속 두 배 성장
       시나리오가 전제되어야 함 (아마존 2000년대처럼) 현재는 비영리/영리 구조 이슈도 있어 상장 자체가 쉽지 않을 수도 있음 Google의 성과에 축하를 보내며 AI 경쟁에서 가장 큰 승자가 될 가능성 높다고 평가
          + OpenAI의 시장 내 입지에 오해가 크다는 의견 ""chatgpt""는 이미 일상 동사로 자리잡았고, Claude나 Gemini는 일반인에게 전혀 알려지지 않았음 뭔가 획기적인 일이 일어나지 않는 한 대중이 다른 제품으로 갈아탈 이유도 없음 ChatGPT가 가진 대화 기록, 메모리, 내보내기 구조의 편리성만으로도 이동 장벽 충분 5억 명 활성 사용자를 상대로 OpenAI가 해야 할 일은 그저 품질 유지만 해도 됨 지금의 패러다임이 유지된다면, 선도자가 아니더라도 타사 기술을 따라잡는 것도 가능 일반인은 소폭 개선으론 제품을 바꾸지 않음
          + 벨류에이션 계산에 오류가 있다는 지적 3,000억 달러의 두 배 매출이 아니라 1,500억 달러 매출이 맞음 하지만 기본 논지는 여전히 유효
          + 현재 OpenAI가 분명히 더 뛰어난 영역은 이미지 생성 일러스트, 만화, 사진 편집 및 홈 프로젝트 아이디어 구상에선 차별점
          + Google이 AI 경쟁에서 이기고 있어도, 검색 비즈니스는 여전히 잠식될 것이고 AI로 인해 시장 주도권을 통한 경제적 수익을 추출할 수 있을지는 미지수라는 견해 어쩔 수 없이 경쟁해야 하지만, 광고 중심 독점 체제 시절이 더 좋았을 것이라는 생각
          + o3 pro와 GPT 5의 출시가 임박해 있기 때문에, OpenAI가 리더가 아니라고 단정하기엔 아직 이르다는 입장 만약 이 두 모델이 눈에 띄는 진전을 보여주지 못하면 그때 가서야 리더십 상실 고려 가능 지금은 최소한 Google 등과 어깨를 나란히 한다는 느낌
     * 같은 모델을 프리뷰 버전만 세 개나 내놓는 것도 헷갈리는데, 마지막 두 날짜(05-06과 06-05)까지 섞여 더 혼란스러운 상황 하루 미뤘으면 명확했을 텐데 아쉬움 드는 상황
          + 날짜가 애매해서 사실상 13일까지 미뤄야 헷갈리지 않는 구조 캐나다의 경우 영국식, 미국식 날짜 포맷이 섞여 정말 헷갈림 요즘은 y-m-d 포맷이 공식적으로 허용되고 점점 퍼지는 추세
          + 05-06과 06-05가 헷갈리는 상황 자체가 OpenAI의 4o, o4 모델을 대놓고 놀리는 것 같은 느낌
          + Gemini 2.5 pro에서 2.6 pro로 언제 넘어갈지 궁금증 Gemini 3에서는 아마 크기가 더 커질 거라는 예상
          + 개발자들은 네이밍에 정말 약하다는 농담
     * Gemini에서만 느끼는 두 가지 이슈가 있음
         1. 명시적으로 이름을 바꾸라고 하지 않았는데 변수명을 리네임하는 문제가 있고
         2. 가끔씩 닫는 대괄호를 빠뜨린다는 점 변수명을 간결하게 만드는 걸 좋아해서 ""json""만 쓰기도 하는데, 피드백은 고맙지만 그런 변경이 많아지면 코드 리뷰가 어려워지는 상황
          + 구체적으로 Gemini가 잘못 처리하는 케이스를 들어봄 processing_class=tokenizer로 명확히 지정한 코드를 여러 번 수정해도 Gemini는 tokenizer=tokenizer로 자꾸 변경 심지어 전체 주석으로 DO NOT CHANGE라고 달아놔도 계속 잘못 바꾸는 문제 최신 버전(06-05)은 아직 못 써봤고, 직전 05-06에서도 같은 오류 반복
          + 사실상 o1-pro가 Gemini와 함께 내 순위 최상위권임을 강조 하지만 Gemini는 불필요한 주석 및 관련 없는 코드 변경이 너무 많아서 실제 업무에는 쓰기 힘들다는 문제 아이디어 탐색 때는 도움이 되지만, 최종 솔루션과는 o1-pro를 쓰는 방식
          + Gemini는 정말 어이없는 비실행 주석도 마구 추가함 ""# Added this function"", ""# Changed this to fix the issue"" 등 이런 건 커밋 메시지나 PR에나 어울리는데 굳이 코드에 주석을 넣는 점은 불편함
          + ChatGPT도 특정 명령을 아예 무시하는 사례가 많음 예를 들면, ""em dash나 en dash 쓰지 말라""고 아무리 강조해도 오히려 더 많이 집어넣음 여러 번 시도해도 한 번도 제대로 컨트롤한 적이 없는 경험
     * ChatGPT Plus와 Gemini Pro를 모두 유료로 결제해서 사용 중 ChatGPT는 계속해서 rate limit에 걸리기 때문에 해지 고민 중 Gemini/AI Studio는 아직 한 번도 rate limit에 걸린 적 없는 상황
          + AI Studio는 실제로 API 계정을 백엔드에서 사용하며, Google Cloud 프리티어 프로젝트가 자동으로 생성됨 ""get an api key"" 페이지 하단에서 결제 계좌 연동 가능 무료 티어 API는 구글 서비스 약관상 상업적 사용에 해당되지 않을 수 있어, 프롬프트가 인간에 의해 검토되고 학습 데이터로 쓰일 수도 있음
          + AI Studio는 API를 쓰기 때문에 사실상 일반 사용자가 유료 프리뷰 모델로 한계에 도달하는 경우는 극히 드묾
          + Gemini가 ChatGPT보다 훨씬 마음에 들었지만 최근 Pro 요금제에 하루 100메시지 제한이 생김 AI Studio는 아직 제한이 없는 듯
          + openrouter 같은 중계를 통해 API 쓰지 않는 이유가 있는지 궁금증
     * 이전 Gemini 모델은 코딩 보조 용도로 Claude 3.7 Sonnet보다 떨어진다고 느껴짐 (4는 더 별로) 새로운 버전도 직접 평가 나오기 전까진 시도하지 않을 생각 인터넷에서 Gemini 찬사가 많은 게 개인 경험과 너무 달라서, 노골적 마케팅이나 인위적인 붐이 섞인 거 아닌지 의심
          + 어떤 모델이든 실제로 무엇을 하느냐에 따라 평가가 다르다는 입장 Claude 3.5/3.7 Sonnet은 C/C++/Make/CMake에서는 아예 쓸모 없는 수준 잘못된 정보, 불가능한 코드 반환, 의미 없는 문법/API 생성, 논리적 모순 등 좋지 않은 경험 Gemini 2.5-pro와 o3는 압도적으로 좋았고, 팀 전체가 더 뛰어나다고 말할 정도 반면 Claude가 타입스크립트나 루비 등에는 강할지도 모르지만, 적어도 내 업무에서는 Gemini가 광고 과장 이상임
          + Claude를 써보진 않았지만, Gemini는 일상적인 질문에서 ChatGPT나 Copilot보다 항상 좋은 답을 줬음 특히 검색 용도로 사용하는 상황(커맨드라인 방법, 제품 정보 등)에서 Gemini가 확실히 강점
          + Aider에서 Sonnet과 Gemini를 번갈아 사용 중 이상하게 어떤 문제는 한 모델만 풀 수 있고, 미리 알 수 있는 패턴이 없음
          + Claude 3.7 Sonnet이 코딩 어시스턴트로 Gemini보다 낫다는 의견이지만, 데이터 사이언스나 복잡한 파이썬 ETL에선 Claude가 실망스러웠고 o3가 훨씬 뛰어남
          + Roo Code에서는 Claude가 도구 사용은 더 잘하지만, Gemini의 간결한 코드 스타일이 더 취향에 가까움 둘 다 섞어쓰거나, 하나가 실패하면 다른 걸 사용해서 문제 해결
     * 프리뷰 버전에 날짜만 붙여 계속 릴리즈할 게 아니라 패치 번호만 올리면 좋겠다는 생각
          + 기존 버전을 기반으로 제작된 생태계에 영향을 주지 않으려면, 주요 업데이트마다 새 모델로 분리해야 함
     * Aider 기준 82.2 기록 실제론 o3 high 공식점수에 비해 여전히 밀려있는 현황 Aider 리더보드 링크
          + 82.2가 타 모델의 Percent correct 기준과 동일한지 질문 ""pure"" o3 (high)가 79.6%, ""o3 (high) + gpt-4.1"" 조합이 최고 82.7%에 해당 구 Gemini 2.5 Pro Preview 05-06은 76.9% 수준 꽤 큰 점프라 평가 Aider benchmarks가 현재로선 가장 신뢰받는 벤치마크임
          + 훨씬 더 저렴하고 빠른 점이 특히나 놀라운 부분
          + 언급된 점수는 예전 05-06 프리뷰, 오늘 공개된 새 버전은 아니라는 점 짚음
     * 06-05가 03-25와 05-06 사이 간극을 메운다는 트윗 참고 관련 트윗
     * Claude 4 Sonnet과의 코드 비교에 관심 이 블로그 테이블에 따르면 Claude 4 Sonnet보다 확실히 떨어진다고 표시됨
          + 실제로 대부분의 벤치마크가 프로그래밍(코딩) 관련이고, SWE-Bench만 Claude가 더 높은 점수가 나옴 어느 벤치마크가 실제 업무를 가장 잘 반영하는지 판단이 어렵지만, 커뮤니티에선 Aider Polyglot 평판이 높음
"
"https://news.hada.io/topic?id=21329","플라스틱 대체 '투명 종이' 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           플라스틱 대체 '투명 종이' 개발

     * 일본의 JAMSTEC 연구진이 플라스틱 대체용 투명 종이를 새롭게 개발함
     * 셀룰로오스를 기반으로 제작되어, 생분해 가능하며 미생물에 의해 물과 이산화탄소로 분해됨
     * 이 소재는 내구성이 높아 컵, 빨대 등 다양한 용기로 활용 가능성이 높은 특성 가짐
     * 심해에서도 4개월 이내에 거의 완전히 분해되는 점이 기존 투명 종이와 다른 주요 강점임
     * 대량 생산 공정 도입시 탄소 배출량은 플라스틱 대비 절반 수준이나, 생산 비용은 종이의 약 3배 예상임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

연구 배경 및 혁신적 개발

     * 일본 해양연구개발기구(JAMSTEC)와 여러 연구팀이 식물성 바이오매스에서 얻은 셀룰로오스로 두꺼운 투명 종이 시트를 개발함
     * 개발된 종이는 플라스틱을 대체할 재료로 주목받고 있으며, 특히 해양 오염의 주범인 플라스틱의 대안으로 기대를 모음

제조 방법 및 주요 특성

     * 순면 씨앗 표면의 섬유에서 추출한 셀룰로오스 분말을 리튬 브로마이드 수용액에 녹여 고온에서 겔 상태로 만든 뒤 형상 및 건조 과정을 거쳐 종이로 완성함
     * 이 종이를 컵, 빨대 형태로 만들었을 때, 폴리카보네이트 수준의 강도를 보임
     * 나노미터 크기의 섬유가 조밀하게 집적되어 빛이 산란 없이 투과하여 두께 0.7mm임에도 먼 거리의 배경이 선명하게 보이는 특성 가짐
     * 매우 유연하며 투명도 또한 유지됨

생분해성·환경영향 평가

     * 해양에서의 생분해성을 검증하기 위해 다양한 깊이에 시트를 침적하여 미생물에 의한 분해 정도 관측함
     * 심해일수록 미생물 수가 적어 분해 속도는 느리나, 757m 심해에서도 4개월 이내에 대부분 분해됨을 확인함

시장 가능성과 한계

     * 지금까지는 일반적인 종이 팩이 플라스틱 용기 대안이었으나, 내용물이 보이지 않아 소비자 선호가 낮았음
     * 투명 종이는 이 문제를 해소 가능성이 있으나, 대량생산 기술 도입과 공장 설립이 전제 조건임
     * 시범 플랜트 기준으로 생산 비용은 일반 종이의 3배 수준이나, 플라스틱 공정 대비 탄소 배출량은 50% 수준 예상함

전문가 견해

     * Osaka University의 Nogi 교수는 “과거에도 여러 종류의 투명 종이가 있었으나, 심해에서 생분해가 입증된 점이 이 개발의 가장 큰 차별점”이라고 강조함

        Hacker News 의견

     * 투명성이 우리가 플라스틱을 많이 쓰는 이유는 아니고, 가볍고 분해되지 않기 때문에 선호하게 됨. 수천 년을 버티는 성질 덕분에 음식도 오래 보관 가능하니 비바람 걱정 없이 여러 부품에 플라스틱 채택. 필요한 것은 생활 환경에서는 거의 전혀 분해되지 않으면서, 특정 조건(화학물질, 온도, 압력 등)에 노출되면 빠르게 분해되는 신소재 개발 방향성
          + 플라스틱은 아주 쉽게 성형할 수 있어서 대량생산에 탁월한 기술적 강점. 목재(가볍고 저렴함), 세라믹(성형 쉬움, 방수), 금속(내구성) 각각의 장점을 플라스틱이 대부분 흡수하면서 단점은 피해감. 목재는 가공 오래 걸리고 세라믹은 잘 깨지며 금속은 비싸고 녹슬고 전도체 성질 탓에 그만큼 번거로움. 총합으로 보면 플라스틱 활용도는 당연히 높아질 수밖에 없다는 생각
          + 이미 기사에 사용 사례가 제시된 상태. “지금까지 종이 팩이 플라스틱 용기 대체재로 가장 흔하게 쓰였지만 내용물을 볼 수 없어 소비자가 선호하지 않음. 투명한 종이라면 이 문제를 해결할 수 있지만, 생산기술을 갖춘 공장이 필요”
          + 실제로 많은 포장재가 투명 부분만 플라스틱 창을 붙인 종이 소재임. 모든 플라스틱을 대체하진 못하지만 이런 부분적인 용도는 충분히 대체 가능. 한 가지 소재가 플라스틱을 완벽하게 대체하는 건 불가능하지만, 일회용 플라스틱의 의미 있는 틈새 시장이라 생각
          + 이런 소재가 대체할 수 있는 일회용 포장 플라스틱이 많음. 예를 들어 포장된 과일. 과일 유통 기간은 수천 년이 아니므로 포장재도 굳이 그렇게 오래갈 필요 없다는 의견
          + “플라스틱이 수천 년을 간다”는 게 좋아서 쓰는 게 아니라, 음식 보관을 잘하기 때문에 쓰는 것. 수천 년 지속되는 특성 없어도 음식 포장이 제대로 된다면 충분히 좋은 개선책
     * “Old is new again?”이라며 과거의 셀룰로이드, 셀로판 관련 위키 링크 공유 Celluloid Cellophane
          + 연구팀의 원논문 링크 안내 Science 논문. 투명하고, 두껍게 만들 수 있고, 순수 셀룰로오스 기반인 소재 지향. 셀로판은 1번과 3번 조건에 맞지만 두껍게 만들기 어려움, 종이는 두껍게 만들 수 있지만 투명하지 않음. 셀룰로이드는 거의 순수 셀룰로오스가 아니어서 해당 사항 없음. 주요 목표는 식품 포장재
          + 고대 로마가 실제로 모든 걸 종합하면 기술의 정점을 찍었던 건 아닌지 진지하게 궁금
          + 셀로판과 유사성 있지만, 제조 공정이 매우 다름. 셀로판과 다른 새로운 물성을 가질 수도 있다고 생각
          + “두꺼운 셀룰로오스 기반 소재로 용기 제조 가능. 기존 셀룰로오스 소재보다 두꺼워서 플라스틱 대체 기대, 플라스틱이 해양 오염의 주범인 만큼 대안으로 제시” 인용
     * 일부 국가는 그냥 쓰레기를 바다에 버리지만, 이런 근본적인 문제 해결보다 더 나은 쓰레기 만드는 데 집중하게 된 현실을 우스꽝스럽게 느낌
          + ‘몇몇 국가’라는 식으로 말하는데, 대부분 국가는 이런 덜 부유한 국가들을 ‘재활용’ 명목으로 쓰레기 수출지로 활용. 실제로 재활용 쓰레기의 상당 부분은 해외 실제로 바다에 버려짐. 관련 보도 링크 제공 The Guardian Mother Jones The Guardian D+C
          + 예방에 초점을 맞춘 단체도 활동 중이라는 의견 및 The Ocean Cleanup 링크 소개. 모든 접근 방식이 필요함
          + 강압 없이 사람 행동 변화 자체는 거의 불가능에 가까움. 환경을 바꾸는 쪽이 훨씬 쉽다는 견해
          + 기술적 문제 해결이 사회적 문제 해결보다 대체로 쉬운 편
          + 환경 친화적 쓰레기 처리가 비싸므로 모든 국가, 모든 계층이 이를 감당하기는 어렵다는 현실
     * 석유와 기타 오일 기반 핵심 소재는 본래 에너지 아닌 이런 제품 제조에 집중 활용해야 한다는 주장. 대체가 쉽지 않은 산업 분야, 의약 등에서 석유 활용, 전력 등은 태양광, 풍력, 원자력 등 친환경 에너지로 대체하는 방향성이 인류 전체의 순이익 증가로 이어진다는 의견
     * 플라스틱과 유사 특성, 그러나 수천 년 가지 않거나 재활용이 불가능하지 않은 새로운 물질군 필요성 언급
          + 플라스틱 분해 자체가 더 큰 문제라는 생각. 쓰레기 자체 저장은 과장되는 반면, 미세플라스틱 오염 문제는 실제로 위험성 크다고 지적 관련 논문. 오히려 안정적으로 잘 분해되지 않는 플라스틱이 오염 문제는 적음
          + 너무 빨리 분해되는 소재라면 병이 매대에 진열되어 있는 동안 구멍 나서 내용물 흘러내릴 수 있음. 실제 사용성 저하 문제 우려
     * “봉투는 괜찮고, 컵도 괜찮지만 빨대는 진짜 별로”라는 견해
          + 그 이유를 묻는 코멘트. 소재 자체는 폴리카보네이트와 유사한 특성이고, 이상 조건에서도 4개월, 실제 음료 속에서는 훨씬 더 오래 견딤. 박테리아처럼 미생물이 있어야만 분해되고, 음료 속에서는 전혀 변화 없으니 도대체 어느 부분이 나쁘다는 건지 궁금해함
          + 종이 빨대처럼 쉽게 흐물흐물해질 거라는 걱정 반영 질문
     * “종이 시트가 투명해지는 이유는 나노미터 정도의 매우 가는 섬유들이 치밀하게 포개져서 빛이 바로 통과하기 때문”이라는 과학적 설명 인용. 섬유를 어떻게 배열하는지 궁금
     * “드디어 이런 소식, 굉장히 반가움” 언급
     * 일본에서 거의 모든 물건이 플라스틱 포장으로 싸여있는 현실이 놀랍지 않음. 다른 면에서는 미국보다 훨씬 진보적이었지만 플라스틱 포장 문제는 아쉬움
          + 실제로 동일 용량의 포장재 기준 일본이 타국 대비 플라스틱 중량이 더 적다는 사실과, 대부분 봉지류 사용 및 경질 패키지보다 적은 플라스틱 소비 구조라는 설명. 또, 일본은 상당량을 소각연료로 사용. 관련 YouTube 영상 안내
"
"https://news.hada.io/topic?id=21336","미루기를 극복하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              미루기를 극복하는 방법

     * 생산성을 높이는 핵심은 “동작이 동기를 만든다”는 원리에서 출발함
     * 작은 행동부터 먼저 시작하면 동기가 따라오며, 복잡한 업무도 작은 단위로 쪼개서 아주 작은 첫 걸음부터 실행하는 전략이 중요함
     * 반복되는 미루기는 부정적 감정의 악순환을 만들 수 있으며, 반대로 “작은 성공→기분 상승→생산성 상승”의 선순환 플라이휠을 만드는 것이 중요
     * 기술 업계에서도 자기만의 생산성 시스템을 구축한 엔지니어가 지속적인 성과를 내며, 시간의 가치를 인식하게 됨
     * Tony Robbins의 “모션이 감정을 만든다” 개념처럼, 행동을 통해 생산성과 스트레스 관리가 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Getting Past Procastination - IEEE Spectrum

     * Meta, Pinterest 등 하이퍼그로스 테크 기업에서 일하면서 지속적으로 미루는 습관에 시달림
     * 이메일 확인, 문서 읽기, 소셜 피드 탐색 등 다양한 산만함에 자주 빠짐
     * 본질적으로 중요한 일에 진전이 없는 상태에 대한 두려움과 불안이 지속적으로 남음

  시간의 중요성

     * 하루의 끝에서 시간만이 가장 중요한 자원임을 실감함
     * 매 순간 어떻게 시간을 보낼지 선택하는 것이 곧 인생을 결정하는 행위임
     * 특히 테크 업계에서는 업무와 도구가 빠르게 변화하므로 적응 능력이 중요함
     * 최고의 엔지니어는 지속적으로 생산성을 유지할 수 있는 시스템을 만듦

  행동에서 동기가 시작됨

     * 생산성에 대한 관점을 바꾼 핵심 아이디어는 ""행동이 동기를 만든다""는 것임
     * 동기를 기다리며 이메일이나 인스타그램을 확인하기보다는, 작은 행동이라도 먼저 시작하는 것이 중요함
     * 목표에 한 걸음이라도 나아가는 행동을 하면, 그 후에 동기가 따라옴

  작은 첫걸음의 힘

     * 예를 들어, 복잡한 버그를 해결해야 할 때 문제를 최대한 단순하게 쪼개서 접근함
     * 예시: 관련 변수의 값을 출력하는 로그 한 줄 추가 같은 아주 작은 단계로 시작함
     * 이때 목표는 문제 전체를 해결하는 것이 아니라, 아주 작은 진전을 만드는 것임

  생산성의 선순환과 악순환

     * 이렇게 작은 진전을 이루면 생산성 → 긍정적 감정 → 더 높은 생산성의 플라이휠 구조가 만들어짐
     * 반대로, 미루는 악순환에 빠지면 비생산적임 → 부정적 감정 → 더 비생산적임이 반복됨

  동기는 행동에서 온다

     * 동기는 진전에서 자연스럽게 따라온다는 사실을 인식하면, 행동에 나서는 심리적 장벽이 낮아짐
     * Tony Robbins의 ""Motion creates emotion""처럼, 행동이 감정에 영향을 미침
     * 내가 동기를 통제할 수 있다는 자각이 생기면, 스트레스 없는 생산성도 가능함

   운동도 미루고, 이직 준비도 미루고, 앱만들기도 미루고 있는 저에게 되게 좋은 조언이 되는 글이네요. 확실히 뭔가를 할까 말까 고민하기 보다는, 그냥 하자! 해보자!하고 해보면 막상 몰입하고 재밌게 하더라구요. 행동을 위한 활성 에너지를 계속 줄이는게 중요한 것 같습니다. 행동이 동기를 이끈다라는 마인드셋이면 충분한 것 같습니다. :)

   ""정말 자신의 일이 의미 있는 일인지 스스로 믿기 전까지 이런 느낌은 어쩔 수 없는 것 같음. 진짜 자신이 중요하다고 여기는 게 아닐 때, 미루는 건 무의식적 무의미함의 신호일 수도 있음"" -- 제게는 이게 정말 공감되는 말이네요. 뭔가를 자꾸 미루는 경우는, 이 일이 과연 나에게 의미가 있는 것일까 이것부터 고민할때가 많더군요.

        Hacker News 의견

     * 행동이 동기보다 먼저라는 말, 정말 공감하는 내용임. 내가 쉽게 시작할 수 있게 만든 트릭은, 다음날 시작할 사소한 작업을 하나 남겨두는 방법임. 종종 메모도 남겨서 무엇을 해야 할지 상기시켜줌. 이 사소한 작업이 더 큰 무언가로 가는 길 위에 있으면 최상임. 작업을 완전히 끝내는 게 아니라, 진행 중인 상태로 둠으로써 에디터를 열게 되고, 코드와 테스트를 돌리기 시작하면서 아주 쉽게 움직일 수 있게 됨. 그제야 동기라는 게 밀려오고, 본격적으로 움직이기 쉬워지는 경험임. 이런 방법은 소프트웨어 개발 외의 일이나 개인 일상에도 똑같이 쓸 수 있음
          + 헤밍웨이가 쓴 방법이 바로 이런 거임. “집필 도중에 아직 충분한 에너지가 남아있고, 다음에 뭘 쓸지 알 때는 일부러 멈추고, 하루를 보내고 다음날 다시 그 지점부터 시작한다”라는 비법임. 링크
          + 할 작업이 명확하지 않을 때는, 실제로 내일 이어서 작업할 지점에 일부러 문법 오류를 남겨두기도 함. 이거 꽤 효과적임. “내가 어디까지 했지?”라는 질문이 바로 눈 앞에 답으로 나타나서 다시 시작할 때 장벽이 하나 줄어드는 경험임
          + 나도 마찬가지로, 한계에 도달했을 때 바로 멈추고, 남은 2분 정도를 사용해서 작업 흐름을 북마크 해두거나 다음에 할 만한 아이디어를 덧붙이는 게 훨씬 재시작이 쉬운 습관 형성임
          + 이 방법을 “내리막에 주차하기”라고 부르는 것 들어본 경험 있음
          + 해야 하는 게 무엇이든, 나는 매일 아침 코드를 빌드하는 것부터 시작함. 이 과정에서 터미널에 명령을 치기 시작하고, 대부분 빌드 오류나 경고가 발생해서 바로 처리를 하게 됨
     * 나는 ‘미루는 습관을 극복해야 한다’라는 생각에 동의하지 않음. 미루는 게 본질적으로 나쁘다고 생각하지 않음. 사회적으로 미루는 게 “비생산적”이라고 낙인찍히지만, 미루는 과정에서 대단한 통찰이 나올 때가 많음. 뇌가 어떤 작업에 관심이 없다는 신호를 보내고 있는데, 그 이유가 뭔지 스스로 묻는 게 중요하다고 느낌. 너무 과로해서 피로한 건지, 다른 걸 더 탐구하고 싶은 건지, 실패에 대한 두려움이 있는지 생각해보는 게 중요함. ""극복""하기 위해 애쓰는 대신 왜 그런지 파고드는 게 내 경험에서는 아주 효과적이었음. “행동이 동기를 만든다”는 조언이 실패 두려움이나 임포스터 신드롬 해결에는 도움이 되지만, 모든 경우에 적용하긴 힘든 측면 있음
          + 어려운 작업일수록 미루게 되는 경험을 자주 함. 그 이유는 각 결정이 초래할 위험성을 아직 완전히 파악하지 못했기 때문임. 경험이 적은 엔지니어일수록 “빠르게 실패하기”가 맞는 접근임. 판단 근거가 부족하니까, 직접 부딪혀보면서 배우는 수밖에 없음. 경험 많은 엔지니어는 어디서 실패할지 감이 오기 때문에, 그걸 피할 수 있도록 설계에 융통성과 선택지를 남기려는 경향이 있음. 이게 마치 조각가가 대리석을 앞에 두고 그릴 선을 시각화하며 고민하는 시간과 같음. 미루는 것 같지만 실제로는 과정 구상 및 시각화 단계임
          + 미루는 것도 좋지만, 아무것도 하지 않고 몇 달씩 보내게 되면 그게 절대 좋은 건 아닌 느낌임
          + 어떤 작업이 너무 어렵거나 미루고 있다면 접근 방식 자체를 다시 생각해야 한다는 신호로 받아들임. “행동이 동기를 만든다”보다 “아무 것도 안 하는 것보단 뭔가를 하라”는 말이 더 와닿음. 동기는 충분하지만 머리가 의도적으로 집중을 거부하는 경험이 많음. 이런 경우에는 완전히 별개의 쉽고 가벼운 과제를 잠깐 하면서 집중력을 되살림. 집중이 조금씩 쌓이면 결국에는 그 작업도 제대로 할 수 있게 됨
          + 나 자신도 자주 미루는 습관이 있음. 머릿속 생각을 너무 따라가거나 재미만 추구하면 생산적인 결과로 이어지지 않음. 대부분 우리 몸과 머리는 에너지를 아끼려고 함. 예를 들면 추운 아침에 헬스장 가기는 누구나 피하고 싶은 일임. 머릿속에서 가지 말라는 신호에 귀 기울이면 오히려 더 안 좋은 결과임. 근육도 원래는 아무것도 안 하길 원하지만, 조금만 움직이면 오히려 더 하고 싶어함. 우리는 좀 이상한 존재라, 스스로를 강제로 시켜야 하는 부분이 있음
          + 이런 글과 비슷한 조언은, 실제 미루는 습관 때문에 괴로움을 겪는 사람들을 위한 것임. 당신이 그 중 하나가 아니라면, 미루는 게 나쁜 게 아님. 사람마다 힘들어하는 종류가 다르듯, 모든 사람이 같은 문제를 겪는 건 아니기 때문임
     * ""Meta, Pinterest 같은 빅테크에서 10년 넘게 일하며 미루는 습관과 싸우며, 중요한 일에 진전이 없었다""는 얘기. 근데 정말 자신의 일이 의미 있는 일인지 스스로 믿기 전까지 이런 느낌은 어쩔 수 없는 것 같음. 진짜 자신이 중요하다고 여기는 게 아닐 때, 미루는 건 무의식적 무의미함의 신호일 수도 있음
          + 뭔가 의미 없게 느껴질 때 진짜 동기를 찾기 어려움. 어떤 생산성 시스템을 적용해도, 정작 업무 자체가 공허하게 느껴지면 아무 소용 없음
          + 나는 오히려 반대 경험도 함. 어떤 일이 너무 중요할수록 오히려 접근하기가 두려움. 그 중요성 때문에 미루게 되는 경험임
          + 글로벌 정보의 많은 부분을 로그인 벽 뒤에 가둬두려고 집착하는 것이 일상이어도, 일에 대한 미루는 습관을 벗어나기 쉽지 않음. 새로운 정신적 트릭을 시도하는 것보다, 근본적으로 다른 무언가를 찾아보는 게 더 나을 수 있음
          + 이런 스토리를 보면 항상 궁금해짐. Meta, Pinterest에서 미루는 습관이 있는데 어떻게 이런 직업을 얻고 유지할 수 있었는지. 나는 미루는 습관이 심해서 지원 자체를 못 했고, 일할 기회가 생겨도 자주 그만두게 됨
          + 이번 주에는 상사가 중요한 작업을 금요일까지 끝내야 한다고 미팅을 했고, 정말 큰 자극 덕분에 그 주는 엄청 생산적으로 보냄. 금요일이 지나자 더 이상 간섭이나 체크 메시지가 없으니까 바로 동기가 떨어지는 경험임
     * 나한테 미루는 습관이란, 미래에 닥칠 일의 불쾌함을 과대평가(혹은 그냥 평가)하는 뇌의 반응임. 불쾌함은 그 작업을 스스로 별로 즐기지 않거나, 기술•자원이 부족해 생길 좌절•짜증, 성공 실패에 대한 불안, 결과가 내 기대에 못 미칠 거란 걱정 등에서 옴. 나는 집 밖에 나가는 것도 엄청 싫어함. 옷 갈아입고 차를 타고 가는 걸 생각만 해도 짜증나는데, 막상 운전대 잡고 나면 ""이거 생각만큼 안 괴롭네?""하는 느낌임. 결국 여러 단계의 복잡한 작업을 상상하는 것 자체가 뇌가 멀어지게 만드는 요인임
     * “Meta, Pinterest 같은 빅테크에서 10년 넘게 미루는 습관에 시달렸다”는 부분을 보고 떠오름. 나도 박사과정과 학계에 있을 때 미루는 게 심했음. 거의 몇 주간 아무것도 못 하고 스트레스만 받기도 했음. 나중에 빅테크로 이직하고 나서는 거의 미루지 않게 됨. 목표가 뚜렷하고, 성과에 따라 보상이 나오거나 결과가 없으면 문제가 되기 쉬움. 내 경우엔 올바른 환경이 미루는 습관을 많이 없애줌
          + 이런 글을 지금 몇 달째 아무것도 못 하는 중에 읽으니 위로가 됨. 기한을 연장하고 목표가 명확하지 않은 상태임. 내 지도교수도 박사과정 때 똑같은 기분이어서 산업계로 갔다가 연구의 자유로움 덕분에 다시 돌아왔다는 얘기를 했었음
          + “결과가 없으면 금방 문제 된다”는 현장은, 사실 미루는 걸 극복했다기보다는 두려움이 그만큼 동기가 되는 환경임. 물론 두려움도 좋은 원동력이 될 때가 있음
     * 이 스레드에 멋진 의견이 많음. 결국 자기 자신에 대해 이해하는 게 핵심이라고 생각함. 나의 경우, 종종 실패에 대한 두려움으로 미루는 습관이 올라옴. 완벽하지 않을까 걱정하거나, 일이 너무 방대해서 막막할 때 특히 심함. 그런 순간에는 그걸 도전으로 생각하도록 스스로 프레임을 바꿈. 나는 도전 상황에서 기운을 받는 타입이라 그런 리프레이밍이 효과적임. 시작만 하면 작은 일부터 쪼개서 하나씩 하게 됨
          + 나 역시 비슷한 경험이 있음. “꼭 해야만 한다”고 느끼고, 그게 아주 중요하면 오히려 실패에 대한 두려움, 실망시키고 싶지 않은 마음이 생기고, 이게 방치되면 자기암시적으로 정말 못하게 되는 결과로 이어짐. 반면, “이걸 해보면 어떨까?” 식으로 궁금해서 시작하는 도전은 오히려 피곤한 줄 모르고 깊게 몰입해 대단한 결과를 내는 힘이 생김. 물론 혁신적인 프로젝트는 전체 작업의 일부이고, 대부분 일상적인 운영이나 유지관리도 많이 필요하니까, 이런 업무에 의미부여를 새롭게 하는 노력이 필요함. 그럴 땐 내가 이런 일을 맡을 수 있다는 감사한 마음을 떠올려 동기와 에너지로 삼음
     * 미루는 건 누구나 가끔 겪는 일인데, 만약 반복적으로 자주 나타나면 진짜 원인이 뭔지 확인하는 게 중요함. 본인이 ADHD일 수도 있음. 이런 경우, 일반 신경발달에 기반한 조언은 거의 소용 없고, 오히려 해로움. 자꾸 실패하는 느낌만 남음. 내 머리가 어떻게 돌아가는지 이해하는 게 첫 번째 단추임
          + ADHD는 요즘 낙인효과가 심해서 “나 ADD 있다”고 말하면 진짜로 진단을 받았든 안 받았든 믿지 않는 반응이 많음. 약을 써도 그 외 성격이나 건강에 여러 부작용이 동반됨
          + (ADHD의) 일반적인 조언이 효과 없는 예시가 궁금함. 나도 ADHD의 진단적 특징을 찾는데 늘 관심이 있음
     * 막혔다 싶으면 나는 “프리핑(prepping)”이라는 걸 함. 완전히 작업을 시작하려고 하지 않고, 방을 치우거나 책상을 정돈하고, 산만함을 줄이기 위해 웹사이트를 닫고, 필요한 재료만 미리 모으는 식임. 이건 마치 반응의 활성에너지를 낮춰서 좀 더 쉽게 시작할 수 있게 하는 방법임
          + 청소가 정말 뇌의 기름칠 역할을 한다는 느낌이 들 때 있음. 내 경우는 공간을 미리 치워놓는 게, 머릿속 어딘가에서 잡다한 요소에 신경이 분산되는 일을 크게 막아줌
     * 가끔 첫 행동은 실제 업무가 아니라 단순히 진행해야 할 작업을 투두 리스트로 정리하는 정도만으로도 머릿속이 확 트임
          + 나도 이런 식으로 시작해서 스스로를 속이는 방법을 씀. 정말 작은 목표를 정하고, 그걸 끝내면 멈춰도 된다는 허락을 스스로에게 줘야 부담이 사라짐. 그 “작음”이 정말 중요하고, 실제 멈춰도 괜찮다는 허락이 필수임. 그렇지 않으면 “작은 단계”가 아니라 “큰 과업의 1단계”가 되어 계속 미루는 결과가 됨. 코딩에선 “모든 소스와 문서 파일을 열고 정리해 놓기”, “새로운 브랜치에 빈 파일 몇 개만 만들기”, “기본 뼈대만 간단히 작성하기” 같은 식으로 쪼갬. 코딩이 아니라 글쓰기에도, 점점 더 구체적인 아웃라인을 쓰는 식으로 활용함. 물리적인 작업에도 준비물 챙기고 도구 정돈하는 데 비슷하게 적용함
     * 때로는 내가 미루는 습관이라고 여긴 게 사실은 ADHD이거나, 본인 가치관과의 불일치에서 오는 것임. 항상 개인의 의지나 실패만의 문제가 아닐 수 있음. 나에겐 “procrastination”이라는 단어 자체가 부정적인 감정(특히 부끄러움)을 동반해서, 오히려 근본 원인을 가리는 경향이 있음

   말씀하신 미루기는, 단순한 게으름보다는, 고민이 많은 미루기에 가깝다고 느낍니다.
   이 글이 말하는 바는, 결국 행동을 통해 선택을 할 수 있다는 것이 아닐까 생각합니다.
   행동을 하고 나서 얻는 결과를 통해, 더 고민해 볼지, 아니면 그대로 밀고 나갈지를 다시 선택하는 것이죠.
   이처럼 선택의 연속은 누군가에게는 '미루기'처럼 보일 수 있지만, 다른 누군가에게는 '경험을 쌓아가는 과정'처럼 보이기도 합니다.

   원글 댓글에도 있지만 저는 이 글과 댓글에서 말하는 것이 ADHD의 기전과 상당히 유사하다고 생각해요.
   이걸 잘 이용해서 일단 시작하기만 하면 누가 그만하라고 하기 전 까지, 혹은 만족스러운 목표를 달성할 때 까지 밤을 새더라도 작업할 수 있지만, 한 걸음 시작하는 것 자체가 어려운 경우가 엄청 자주 있습니다. 중간에 10분~30분 정도의 휴식을 가지는 것 자체가 일을 계속 하는 데 방해가 된다는 느낌까지 받아요.
   특히 더 개선할 아이디어가 떠오르지 않거나 수정 계획이 너무 방대한 경우에 더 그런데, 이 글에서는 아주 작은 커밋거리를 하나 수행함으로써 진행중인 프로젝트로 주의를 돌리는 시도, 혹은 주의를 돌릴 수 밖에 없는 일거리를 남겨놓는 행위들을 소개하고 있어요.
   ADHD는 스펙트럼으로 나타나고 대부분 사람들이 작게라도 이런 기전을 보이기 때문에 이 점을 스스로에 적용 가능한 트릭들을 통해 강점으로 작용하도록 하는 게 중요하다고 생각합니다.
"
"https://news.hada.io/topic?id=21409","대폭발이 블랙홀 내부에서 일어났을 수 있다는 연구 결과","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     대폭발이 블랙홀 내부에서 일어났을 수 있다는 연구 결과

     * 최근 연구에서 대폭발(Big Bang)이 사실 블랙홀 내부에서 발생했을 가능성 제기
     * 이 가설은 우주 기원에 대한 기존 표준이론을 보완 또는 변화시킬 수 있음
     * 블랙홀 내부의 특이점과 양자 중력 현상이 중요한 핵심 주제임
     * 관측 데이터와 이론 물리 기반 분석을 바탕으로 새로운 전망 제시됨
     * 우주 탄생 및 초기 과정에 대한 이해 확장 및 탐구 방향성 제시
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

대폭발(Big Bang)과 블랙홀 내부 기원 가설

   최근 발표된 연구에 따르면, 우주의 기원으로 잘 알려진 대폭발(Big Bang)은 실제로 블랙홀 내부에서 발생했을 가능성이 언급됨. 기존 표준 모델에서는 대폭발이 시간과 공간의 완전한 시작점이라고 이해하지만, 새로운 이론은 대폭발 이전에 이미 블랙홀 같은 천체 내부에서 주요 현상이 시작되었을 가능성을 고려함.

기존 표준 이론과의 차별점

     * 표준 우주론에서는 특이점(singularity) , 즉 모든 것이 무한히 밀집된 한 점에서 우주가 시작했다는 관점이 주를 이룸
     * 새로운 연구는 이 특이점이 블랙홀 내부에 존재했고, 블랙홀의 내부적 조건과 양자 중력 효과로 인해 대폭발과 같은 현상이 발생했을 가능성을 탐구함
     * 이 이론은 스티븐 호킹 등 일부 이론물리학자들의 선행 연구와도 맞닿는 측면을 보임

연구 방법과 주요 논점

     * 연구진은 최신 관측 데이터와 이론 물리 계산을 바탕으로 블랙홀 내부의 시간적·공간적 구조를 자세히 분석함
     * 블랙홀 내에서 시간과 공간의 성질이 일반적인 우주와 다르게 작용할 수 있음을 강조함
     * 이에 따라 우주가 처음 등장한 방식과 팽창 과정에 대한 새로운 해석 가능성을 제시함

의미 및 향후 탐구

     * 이 가설은 우주의 탄생과 초기 조건에 관한 논의에 큰 영향을 줄 수 있음
     * 알고리듬 발전 및 수치 모형 연구를 통해, 블랙홀 내부 기원 가설의 타당성을 더욱 검증할 수 있음
     * 기존 표준 모형을 대체하기보다는, 보완적 시도로 우주 기원을 이해할 새로운 틀을 제공함

결론

   이 연구는 우주론과 블랙홀 연구, 그리고 양자 중력 문제 등 다양한 분야와 긴밀히 연결되어 있음. 대폭발을 둘러싼 오랜 의문에 대한 새로운 관점을 제안하며, 향후 심층적인 논의와 실험적 검증을 촉진시키는 계기가 될 전망임.

        Hacker News 의견

     * 이 주제와 관련해 ""무엇이 걸려 있는지"" 궁금증이 생김, 본문에서 다루는 예측들이 먼 미래에 중요한 문제로 이어질까 궁금증, 혹은 가까운 미래의 문제에도 도움이 되는지 알고 싶음, 연구 자체를 폄하하려는 의도가 아니라 순수한 호기심임
     * 이 요약문을 작성한 사람이 논문의 저자 중 한 명이라는 점이 인상적임, 과도한 단순화 부담은 있지만, 최소한 과학을 잘못 이해할 위험성은 제거된다는 점에서 장점
          + 정말 재미있게 읽음, 더 많은 연구자들이 화이트페이퍼와 블로그글을 같이 올리면 좋겠다는 바람임, 물론 모든 과학자가 블로그를 잘 쓰거나 쓰고 싶어하는 건 아니라는 점도 이해함, 그리고 연구자의 블로그 인기(바이럴성)만으로 평가받는 세상이 온다면 걱정이 되기도 함
          + 대학 홍보팀이 과장된 글을 쓰는 것보다는 훨씬 낫다는 생각임, 괜히 세계 최초니 패러다임의 전환이니 식상한 수사를 반복하는 대신, 작성자가 진짜 중요한 점에 집중함, 예를 들어 이게 실험적으로 검증 가능한가? 가능하다면 어떻게 관측해야 하는가에 초점을 맞춤
          + 정말 좋은 글이었음, 이 사람이 제시한 해법은 정말 단순하면서 기존 모델들의 문제를 완전히 해결하는 느낌임, 아마 모든 블랙홀마다 그 안에 각기 다른 우주가 있을 수도 있다는 상상
     * 흥미로운 이야기지만, 저자 말이 맞아서 실제로 우주가 더 큰 블랙홀 내부에서 탄생했다 해도, 그렇다면 그 상위 우주는 어떻게 생성된 것인지 또 다른 궁금증이 생김, 이는 영원히 알 수 없는 문제일 수도 있음
          + 어쩌면 더 큰 우주와 그 안에 든 우주가 똑같이 닮은꼴(프랙탈) 구조일 수도 있음, 그럼 이 의문이 해결된다는 생각
          + 밑이 거북이로 끝도 없이 이어진다는 우스갯소리
          + 이건 우주를 너무 3차원적인 관점으로 본 셈이라는 느낌
          + 양자역학을 공부해 보면 ""상상 가능한 모든 것이 동시에 실제로 존재한다""는 측면으로 우리를 안내하는 듯함, 즉 모든 가능한 우주와 물리 법칙이 실제로 어떤 형태로든 다 존재하고, 우리는 그 중 하나에 속할 뿐임, 마치 지구가 태양계의 특별한 행성처럼 보이지만 사실 우주 입장에선 그렇지 않다는 사실과 비슷한 인식
     * 이 주제에 대해 예전부터 궁금증이 엄청 많았음, 물리학 교육을 받지 않았지만 블랙홀 질량이 슈바르츠실트 반지름에 선형 비례한다는 걸 알게 된 후 정말 그럴듯해 보였음, 블랙홀 크기가 커질수록 밀도는 감소하게 되고, 우리 우주가 대규모에서 밀도가 거의 일정하다는 관측과 결합하면, 결국 특정 지점에서 초거대 블랙홀의 감소하는 밀도와 우주 전체의 고정된 밀도가 만나는 교차점이 있을 거란 생각임, 동료들과 물리 이야기를 종종 나누지만 명확한 답은 듣지 못함, 게다가 여기에 관련된 함의는 정말로 흥미진진함
       암흑에너지가 실제 에너지를 대신 설명하는 방식에 다소 불편함을 느낌, 보통은 ‘모든 것을 밀어내는 원인’이라 소개되는데, 오히려 암흑에너지는 에너지가 우주에서 빠져나가는 일종의 마이너스 에너지, 즉 전체 에너지의 손실처럼 보임, 고전적 물리에서 두 물체가 멀어질수록 잠재적 에너지가 저장되고 나중에 회수 가능하지만, 암흑에너지는 이와 다르게 거리가 멀어질수록 오히려 계속 더 빨리 멀어지게 함, 즉 세계적 관점에서 보면 에너지 손실 구조임, 양자적 세계에서도 이 현상은 이어짐, 고주파 광자가 저주파로 바뀜, 암흑에너지는 우주에서 돌이킬 수 없이 빠져나가는 에너지처럼 생각됨, 마치 블랙홀 내부에서 증발처럼
       현실에서 이 질문을 하면 보통 암흑에너지의 ""에너지"" 성분은 우주의 ""장력"" 형태로 노멀라이즈되어 있는 것이라는 답을 듣지만, 이 설명이 그리 만족스럽게 들리진 않음
          + 예전에 HN에서 본 기발한 이론이 떠오름, 왜 우주가 점점 더 빠르게 팽창하는가에 대한 가설 중에 질량에 따라 시간의 속도가 다르게 흐른다는 설명이 있었음, 은하들 사이의 공간(보이드)에서는 시간이 은하 내부보다 더 빠르다는 가정인데, 전체 우주적 스케일에서는 이 누적된 차이가 커질 수 있음, 나 같은 비전공자 입장에서는 그럴듯하다고 느낌
          + “암흑에너지가 우주에서 빠져나가는 에너지처럼 느껴진다, 블랙홀 내부에서 증발하는 것처럼…”이라는 생각에 대해, 사실 블랙홀은 물질이 이벤트 호라이즌으로 유입되면 크기가 더 커지고, 증발하면 작아지는 구조가 됨, 우주 팽창과 에너지 손실을 블랙홀 프레임에 빗대면, 오히려 더 많은 에너지가 유입되는 셈이라는 반론
          + 우주의 질량 추정치를 슈바르츠실트 공식에 대입해보면 관측 가능한 우주 크기와 엄청나게 근접함을 알게 됨
          + “암흑에너지를 마이너스 에너지로 보는 게 더 그럴듯하지 않냐”는 질문에 대해, 또 다른 비전공자 입장에서 생각함, 블랙홀에서 이론상 잃는 에너지는 너무 미약해서 탐지 불가이고, 암흑에너지의 총량은 관측 우주에서 가장 큰 구성 요소임, 수치적으로 답이 맞는지 의문
          + 관측상 우리 우주가 대규모에서 균질 밀도를 보인다는 주장 중, 사실 recombination(재결합) 시점에서는 그랬지만 지금까지의 진화 과정을 전부 균질하다고 보는 가정이 LCDM(람다-콜드다크매터) 표준이지만 이 역시 실증적으로 충분히 근거가 있는 건 아니라고 봄 Cosmic web, Inhomogeneous cosmology 참조
            “암흑에너지는 마이너스 에너지 같다”는 데 직관적으로 동의, 아인슈타인 방정식에서 람다 항을 에너지-운동량 텐서 쪽으로 옮기면 실제로 음의 역할을 하고, 관측 결과 람다가 양수인 것으로 보임
            고전 계(system)에서는 두 대상이 멀어질수록 저장된 잠재 에너지가 나중에 회수될 수 있지만, 암흑에너지는 그런 구조가 아님(더 멀어질수록 가속), 즉 글로벌 관점에서 에너지 손실이라고 볼 수 있음
            일반상대성이론에서는 에너지 보존이 전체 우주적(글로벌)으로 성립하지 않음Conservation of energy, 국소(local)적으로만 성립하며, 심지어 시간-공간의 에너지를 엄밀하게 정의하는 것도 어려움Stress–energy tensor, Mass in general relativity
            암흑에너지(코스모로지컬 상수)는 말 그대로 상수라서 공간이 팽창하면서 에너지 손실이 있더라도 중력 상수가 바뀌는 건 아님, arxiv 논문 참고
     * 이번 논문이 핵심으로 삼는 ‘페르미온 바운스’ 이야기를 보면 우리가 알고 있는 질량과 에너지 규모를 비교했을 때 결과적으로 엄청난 블랙홀이 됨, 그만큼 큰 블랙홀이 존재했다면 그게 어떤 환경에 있었는지도 새삼 궁금증, 그게 양의 곡률로 인해 안에서 왔다갔다 갇힌 상태더라도…
       다만 블랙홀-우주 이론과 관련된 논의는 꽤 오래됐음, 혁명적이거나 급진적인 대안이라 보긴 어렵고, 이벤트 호라이즌 개념만 이해해도 자연스럽게 떠올릴 수 있는 생각임, 이번 논문의 새로운 점은 ‘분석적 해’를 냈다는 데 있음
     * 하드 SF 읽을거리로 Gregory Benford가 1999년에 쓴 ""Cosm""을 추천함, 실험실에서 볼링공 크기의 소우주를 만들고, 그 과학자가 정부 요원을 피해 우주를 지키려고 노력하는 얘기임, 이 우주는 시간도 크기만큼 상대적이라 오래 기다릴 필요도 없다는 게 흥미 포인트
          + 추천 목록에 바로 추가함, HN에서 SF 추천을 자주 볼 수 있어 정말 좋음, 다만 좋은 책이 너무 많아 읽어야 할 목록만 쌓여서 평생 다 못 읽을 듯한 한숨
          + 이 설정은 ""Horton Hears a Who""(허튼 헤어스 어 후)랑 비슷하다는 생각
          + 비슷한 고전으로 Theodore Sturgeon의 ""Microcosmic God""(1941) 언급
          + Star Trek DS9에 이런 비슷한 에피소드가 있었던 것으로 기억
          + Rick and Morty 시즌2 에피소드 6 'The Ricks Must be Crazy'에서 Rick이 자기 우주선 배터리로 쓰기 위해 마이크로버스 전체를 만들어내고, 그 안의 과학자가 또 미니버스를 만드는 에피소드도 떠오름
     * 어디선가 우리 3D 우주가 4D 블랙홀 내부에 있다는 가설을 읽은 적이 있음, 블랙홀 이벤트 호라이즌을 넘게 되면 반지름 좌표가 시간처럼 변해 1차원의 자유도가 사라진다는 이론, 대신 각방향 공간은 여전히 움직일 수 있기에 N-1 차원 우주가 형성, 즉 3D 우주는 4D 블랙홀에서 유입된 물질, 3D 블랙홀은 2D 플랫랜드, 그리고 바깥 4D 우주는 또 5D 블랙홀… 식의 상상임
          + 4차원에서는 컬 연산자(curl operator)가 안 된다는 지적
          + ""이벤트 호라이즌을 넘으면 반지름 좌표가 시간처럼 변해 1공간 차원을 잃는다""는 말에 대해, 시간 좌표 역시 동시에 공간적으로 바뀌기 때문에 여전히 3차원 자유도가 남음, 차원이 그냥 사라지는게 아니고, 시공간이 4D 로렌츠 매니폴드라는 물리학적 전제를 따름, 게다가 블랙홀 특이점은 일종의 미래에 속해 있어, 실제로 입자로 건드릴 수 있는 '장소'가 아니란 설명
          + 그 다음에는 ""우리 우주의 익숙한 물리 상수가 사실은 고차원에서 끈처럼 당겨진(spaghetified) 잔재일지도""라는 상상 게임도 있음, 예전에 빛의 속도 c가 바로 그런 spaghettified 상수라고 생각해 본 적이 있음, 아마 모든 상수가 상위 우주의 잔재일 수도 있다는 농담
          + 1차원 블랙홀 안에는 무엇이 있을까 궁금증
     * “빅뱅은 우주가 폭발적으로 탄생한 특이점”이라는 묘사에 대해, 언론에서는 이렇게 자주 보도하지만 실제로는 현재의 표준 이론이 아니라는 점, ""빅뱅 이전에 시공간이 없었다""는 식의 시나리오는 스티븐 호킹의 개인적 견해에 더 가까움
          + 더 정확한 설명은, 현재 우리의 이론은 ""빅뱅"" 이전을 설명할 방법 자체가 없다는 것임, 양자중력이 필요한 지점까지 이론으로 도달하면 우리의 수학이 완전히 깨짐, 그래서 빅뱅 이전 상태에 대해 그 어떤 주장도 할 수 없는 상황, 즉 빅뱅 이전에 시공간이 없었다는 얘기도 어디까지나 추측일 뿐임, 언론에서는 끊임없이 이런 추론을 '과학 뉴스'처럼 보도하지만, 본질적으로 과학은 이 문제에 공식적 입장이 없었고, 모든 주장이 전부 추측임, 언론이 이런 추측을 자주 과학의 결론처럼 잘못 전달
          + 많은 사람들이, 의식적으로든 아니든, ""빅뱅 이전이 없다""는 표준모델(람다-CDM)의 본질을 잘 이해하지 못하는 듯함, t=0 이전에는 시간 개념 자체가 없는 구조
          + 현재 표준 이론이 정확히 무엇인지 궁금증
          + 결국 언젠가는 우리 우주의 주기가 하나뿐이 아니라는 것, 즉 우리가 유일한 우주, 유일한 사이클이 아니라는 사실이 밝혀질 거라 예감함, 역사적으로도 지구가 우주 중심이라는 생각에서 태양계 중심, 그리고 이제는 우리 우주가 우주들 사이에 별로 특별할 것이 없다는 인식 단계로 온 것 같음
          + ""스스로 발생했다""는 우주 탄생을 받아들이기 힘들다면 신을 믿는게 별반 다르지 않을 거라는 우스갯소리
     * “Penrose의 정리에 따르면 양자적 배제 원리(두 페르미온이 동일한 상태를 점유 불가)가 물질이 무한정 압축되는 걸 막는다, 그래서 붕괴가 중단되고 되튕김이 발생한다”는 논문 설명에 대해, 그렇다면 왜 중성자별은 이런 배제 원리를 지키고 있음에도 블랙홀로 붕괴하는지 질문
          + 블랙홀은 시공간의 거시적 왜곡이고, 국소적인 양자 특성만의 현상이 아니기 때문이 아닐까라는 추측
          + 중성자별이 블랙홀로 붕괴하는 이유 중 하나는 강제적으로 전자가 양성자와 결합해 중성자와 중성미자를 만드는 '전자포획' 현상 때문, 압력이 충분하면 여러 단계의 축퇴물질(degenerate matter) 상태를 거치는데, 이론적으로 마지막 축퇴 단계에서는 슈바르츠실트 반지름보다 작은 크기의 물체도 가능해짐, 그러나 이러한 물질 상태는 관측 불가라 불확실성이 큼, 슈바르츠실트 반경 내부에서 일어나는 현상은 아무도 모름, 다양한 아이디어는 있지만 확정적 설명은 없음, 블랙홀 특이점 근방의 양자 물리 현상은 아직 미지
          + 질량이 충분히 크면 중력이 워낙 강해서 모든 페르미온이 서로 다른 상태에 있어도 붕괴가 계속된다는 게 답변
     * “블랙홀 우주 이론은 우리 우주 전체가 상위 우주 내 블랙홀 내부에서 생성됐다는 관점”이라는 설명에서, 그렇다면 우리 우주 블랙홀 안에도 또 다른 우주가 있는지? 상상만으로 충격적인 이야기라는 반응
          + 이런 아이디어는 이미 예전부터 있었음, 다만 블랙홀 안의 우주를 ‘포함’한다고 표현하는 건 정확하지 않을 수도 있음, White hole Big Bang/Supermassive White Hole 문서 참조
          + Men In Black 영화가 사실 다큐멘터리였던 게 아니냐는 농담
"
"https://news.hada.io/topic?id=21372","구글 사용자 전화번호 무차별 대입 공격(Bruteforcing the phone number of any Google user)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                구글 사용자 전화번호 무차별 대입 공격(Bruteforcing the phone number of any Google user)

     * 구글 계정 찾기 폼을 우회하여 특정 사용자 이름과 연결된 전화번호가 존재하는지 확인 가능함
     * 자바스크립트 비활성화 환경에서도 봇가드(BotGuard) 토큰을 의도적으로 삽입하여, IP 제한을 우회하는 공격 방식 구현 가능함
     * 네덜란드 등 일부 국가에서는 전화번호 포맷 특성상 1백만 개 미만 조합이 존재하여 현실적으로 프록시와 IPv6 회전을 통해 대규모 대입 가능함
     * 구글 계정의 디스플레이 네임을 Looker Studio를 이용해 피해자 임의 동작 없이 손쉽게 노출 가능함
     * 이 취약점은 구글에 보고 및 패치 완료되었으며, 실제 공격 체인은 자동화로 매우 빠른 시간 내에 전화번호를 확인 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

   이 글은 구글 계정의 전화번호를 무차별 대입(브루트포스) 공격으로 알아내는 방법, 그 과정, 그리고 방어 측의 대응까지 자세히 다루는 실제 사례임. 일반적으로 계정 찾기/복구 폼은 Javascript 환경과 봇 방지 체계를 이용하여 남용을 차단함. 그러나, JS가 꺼진 환경+특정 패턴으로는 이 체계를 우회할 수 있음을 증명하고 있음.

조사 배경 및 방식

     * 계정 사용자명을 찾는 구글 폼이 자바스크립트 없이 동작하는 점을 발견함
     * 폼은 특정 이름(Display Name)과 연동된 전화번호의 존재 여부를 HTTP 요청 2개로 확인함
          + 1차 요청 : 전화번호 기반으로 ess 값(세션 토큰) 획득
          + 2차 요청 : ess와 이름(GivenName/FamilyName) 파라미터로 계정 존재 여부 판별
     * 계정이 존재하면 usernamerecovery/challenge 리다이렉트, 없으면 noaccountsfound 리다이렉트로 응답

IP 제한 우회(프록시, IPv6 활용)

     * 초기에는 IP별 레이트 리밋과 캡챠로 무차별 대입이 불가했음
     * 네덜란드 모바일 번호의 경우 100만개 조합(앞자리가 정해져 있음)으로 프록시 사용 시 현실적이고,
     * AWS/Vultr 등 클라우드의 /64 IPv6 블록을 활용해 요청마다 다른 주소로 회전 가능, 서버도 IPv6 지원함

BotGuard 토큰 우회

     * JS 폼에서는 봇가드(BotGuard) 토큰이 필요함
     * No-JS 폼에서 bgresponse=js_disabled 파라미터 대신 JS 폼에서 수집한 토큰을 삽입하면 불제한 제출 가능
     * 멀티스레드 툴을 제작, 대량 전화번호를 입력해 신속하게 존재 계정 탐지 가능

오탐 거르기(필터링)

     * 동일 이름/번호 뒤 2자리 조건으로 여러 명이 걸릴 가능성 있음
     * 임의의 랜덤 성(last name)을 입력해 다시 테스트함으로써 오탐 여부를 자동으로 필터링하는 로직 추가

국가별 전화번호 포맷 및 네임 정보 수집

     * 복구 폼은 전화번호 마스킹 포맷만을 일부 제공함
     * 각국 전화번호 패턴(national format)은 구글의 libphonenumbers 정보 조사로 파악 가능
     * 피해자의 디스플레이 네임은 Looker Studio에서 소유권 변경 기능을 악용해 사용자 동작 없이 확인 가능

최적화 및 자동화

     * libphonenumbers로 각국 Prefix/길이/유효성 검증 규칙 딕셔너리 생성
     * Go 기반 chromedp로 BotGuard 토큰 자동 발급 API 제작, 실제 공격시 자동화 가능

실제 공격 절차

    1. Looker Studio 소유권 이전으로 피해자 이름(디스플레이 네임) 획득
    2. “비밀번호 찾기” 흐름에서 해당 이메일의 전화번호 일부 마스킹 수집
    3. gpb 툴을 통해 이름, 마스킹, 국가 코드 기반으로 대입 공격 실행

시간 및 효율성

     * 16 vcpu, 3000 스레드 서버 기준, 1초에 약 4만건 체크
     * 국가별 번호 조합/힌트 길이에 따라 미국(20분), 영국(4분), 네덜란드(15초), 싱가포르(5초)면 충분
     * 타 서비스에서 풀힌트 제공시(예: PayPal) 시간 더욱 단축

구글 및 패치 타임라인

     * 2025.4.14 : 구글에 리포트, 4.25 패널서 감사 표시
     * 2025.5 중 : $5,000 버그바운티 지급
     * 2025.5 : No-JS 폼 점진적 중단 및 대응 조치 적용
     * 2025.6.9 : 공식 취약점 공개

결론

   이 사례는 계정 복구 흐름, 전화번호 마스킹, 디스플레이 네임 등 여러 정보의 조합만으로 대규모 자동화 공격이 가능함을 보여줌. 구글은 절차 내 취약점 보완 및 관련 폼을 폐쇄함으로써 대응을 완료함.

   문의는 신호/이메일(원문 참고)로 가능함

        Hacker News 의견

     * 이 글에서 흥미로운 점은, 대부분의 호스팅 제공업체나 ISP가 최소한 하나의 /64 IPv6 블록을 제공한다는 사실임에도 불구하고, 여전히 대부분의 레이트 리밋이나 IP 차단은 단일 IP에 대해 적용된다는 점임. IPv6 환경에서는 전체 /64 블록을 기준으로 레이트 리밋이나 차단이 이뤄져야 한다고 생각함
          + 이런 문제를 관리해야 할 책임이 있거나 그걸로 돈을 벌고 있는 기업들조차 IPv6 관리에 있어 엉뚱한 대응을 하는 모습을 자주 봄. 내가 일하는 회사는 유명 CDN 서비스를 쓰고 있는데, 같은 /64 블록 내에서 접속해도 '이상한 IP에서 접속함' 같은 터무니없는 보안 알림을 받는 경우가 있음
          + IPv6 등장 이후로 기존 IP 차단 방식이 크게 무력화됐다고 생각함. 일반 가정용 인터넷 사용자라도 DHCPv6 Prefix Delegation으로 /56이나 /48 블록을 자동으로 받을 수 있음. 예를 들어 나는 Comcast를 통해 /56을 받았고, 이는 최대 65536개의 /64 블록으로 쪼갤 수 있음. IPv6에서 효과적인 IP 필터링을 하려면 기존 단일 IP 기반을 /64로 단순 교체하는 걸로는 부족함
          + /64 블록으로 레이트 리밋을 걸어도 충분하지 않을 수 있음. /48 블록을 받는 것도 너무 쉬움. 최적의 제어를 위해선 ASN별로 분류하고, 각 사업자가 어떻게 IP를 분배하는지까지 살펴 granularity를 조정하는 고민이 필요함
          + IPv6에서 /64 단위 레이트 리밋은 이미 업계에서 잘 알려져 있고, Google도 타 서비스에 적용하고 있음. 이건 IPv6 도입 시 제대로 기존 정책을 업데이트하지 않은 결과라고 판단함
          + BuyVM 같은 저가 호스팅 업체도 가장 저렴한 상품에 /48 단위 주소를 제공함($2/월, 현재는 $7/월만 재고 있음). 그래서 수상한 운영자들이 애용하는 경향이 있음
     * 예전에 페이스북에서 특정인의 전화번호를 찾으려고 비슷한 방법을 시도함. 비밀번호 재설정 과정에서 페이스북이 전화번호 대부분을 보여주길래, 그 숫자를 vcard 파일로 정리해서 내 폰에 불러온 뒤 사진으로 대조함. 이 방식이 예상 외로 효과적이었음
          + 구글 프로필 사진이나 구글 앱에도 비슷한 허점이 있음. 예를 들어 구글 지도 리뷰에 John Smith라고 뜨면, 여러 이메일 변형(johnsmith@gmail.com, smithjohn@gmail.com 등)을 행아웃에 추가하고 프로필 사진을 확인해서 동일인을 추적할 수 있음
          + 이런 이유로 내 실전화번호는 절대 입력하지 않음. 서비스 운영에 꼭 필요하지도 않으니까
     * 한 사람이 장기간 동안 4만 건의 요청을 초당 서버에 날려도 리소스가 크게 치솟거나 경보가 울릴 일이 없었다는 점이 인상적임
          + 실제 알람이 울렸을 가능성도 있는데, 행동이 금방 중단되거나 상황이 빠르게 복구되어 엔지니어가 대시보드에 접근할 때쯤이면 이미 정상화됐을 수도 있음. 4만 QPS는 Focus나 Google API의 트래픽 규모에선 크게 튀지 않고, 다양한 IP 및 IPv6 /64 블록으로 분산되면 눈에 띄지 않게 넘어가는 경우도 있음. 이번 사례의 핵심은 모니터링이 아니라 JS 비활성화 플로우(이전 JS 활성화 플로우에서 빌린 토큰 사용)에 전혀 레이트 리밋이 없었다는 점이라고 봄
          + 혹시 봇넷을 썼을까 생각도 드는데, 요청마다 IP를 달리한 것 같기도 함
     * 이런 유형의 버그 바운티는 보상 금액이 터무니없이 적은 편임. 안타까움
          + 보상을 자꾸 줄이면 결과적으론 자기 발등 찍는 격임
          + 이런 보안 이슈에 10만 달러 미만 지급은 정말 초라함
     * 레거시 웹페이지를 유지·관리하는 일이 엄청난 부담임을 자주 느낌. 몇십 년 된 코드와 페이지까지 계속 유지해야 하는 사이트가 많고, 모든 조합을 테스트하는 것도 사실상 불가능함. Gmail 설정 안쪽을 파고들다 보면 아직도 2004년 스타일의 오래된 팝업이 뜨는 걸 직접 볼 수 있음
          + 버그 바운티 프로그램은 아주 효율적인 비용 활용 같음. 수천 달러만 들여도 극한의 엣지 케이스를 찾아주는 자발적 인력을 동원할 수 있음. 사내 인력을 쓴다면 훨씬 더 큰 비용이 들었을 거라 생각함
          + 이게 바로 기업들이 예전 서비스와 제품을 공격적으로 폐기하려 하는 가장 큰 이유임. “그냥 그대로 두면 되는 거 아니냐”라는 질문에 대한 답은, 결국 모든 레거시 서비스가 보안 구멍이 되기 때문임. 진짜 안전한 코드는 아예 없는 코드뿐임
          + 페이스북의 “톡” 기능 같은 걸 누가 담당하고 있는지 늘 궁금함
          + 대형 기업 내부에도 비슷한 레거시 인프라가 계속 굴러감. 예를 들어 내 친구는 글로벌 대기업 내에서 내부 링크 단축 앱을 유지보수하는데, 거의 사용량 폭주에도 노드 버전 업데이트 등 매우 단순한 이유로 매번 한두 건 티켓만 들어옴. 모니터링조차 정상 동작하지 않아도 버그 리포트가 드물 정도임
          + 최근에 나도 구글에서 예전(~2013년) Catull 로고가 뜨는 페이지를 만난 적이 있음
     * “2025-05-15 – 패널이 $1,337 + 스웨그 지급. 근거: 익스플로잇 가능성 낮음(lol)”이라는 내용을 언급했는데, 실제로는 익스플로잇 가능성이 매우 높다고 생각함. 노출되는 전화번호 당사자는 많지 않을 수 있지만, 필요만 하면 사설탐정, 범죄자, 조사관 등 누구나 실제로 이 취약점을 활용할 거라 확신함
     * 비밀번호 찾기 플로우에서 전화번호 일부를 힌트로 주는 것이 실제로는 보안 위험임을 이번에 새롭게 깨달음. 만약 여러 서비스가 각기 다른 순서로 마스킹된 전화번호/이메일 힌트를 제공한다면 위험도가 더 커짐
          + 위로가 될지 모르겠지만, 2FA 등 각종 이유로 수백/수천 개 서비스가 이미 내 전화번호를 수집했고, 동의 여부와 무관하게 상당수가 이미 유출됨. 실명-이메일-전화번호 조합은 거의 무조건 공개 데이터에 덤프된 상태임
          + 이런 정보들을 찾아주는 텔레그램 봇도 존재함. 이런 식으로 브루트포스 취약점이 드러나면 자동화 도구를 쓰던 이용자들도 불쾌함을 느끼는 듯함(EoG 봇이 대표적임)
          + 이런 개인 정보를 자동으로 모아주는 유료 서비스들도 이미 오래전부터 존재함. 이메일, 전화번호 등 다양한 정보가 여러 소스에서 쌓이고, 전 세계적으로 유인이 충분해 적극적으로 서비스 보안 허점을 공략함. 결국엔 대량 유출과 연결되는 구조임
          + 과거엔 한 회사 고객센터에 카드 뒷자리 4개를 물어보고, 그걸로 다른 회사 본인 인증을 풀어낸 소셜 엔지니어링 사례도 있었음
          + 나도 대학 시절, 신용카드도 이런 식으로 정보를 획득할 수 있다는 보안 연구자 발표를 들은 기억이 있음
     * 2025년, 2023년, 2021년에도 “방지할 방법 없다”는 기사와 대규모 데이터 유출이 반복됨. 2025년 버전, 2023년 버전, 2021년 버전이 계속 반복됨. 어떤 버전이 더 웃긴지 고민함
     * 이번 사례는 매우 창의적이고 멋지다고 생각함. Brutecat이 또 한 건 했음
     * Google이 이제 진짜 유령선처럼 느껴짐. $5,000 버그 바운티는 모욕 수준이고, 이런 소액으로 시작했다는 자체가 Google이 사용자 데이터 보호에 진지하지 않다는 결정적 증거 같음
          + 버그 바운티 참여는 강제사항이 아님. 보상이 마음에 안 들면 그냥 안 하면 됨. 결국 이 프로그램들도 지속 가능한 모델 한계가 있음
"
"https://news.hada.io/topic?id=21398","Show GN: OpenAI C — OpenAI API를 위한 비공식 C SDK","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Show GN: OpenAI C — OpenAI API를 위한 비공식 C SDK

   OpenAI를 C에서 사용할 수 있게 해주는 C 언어 라이브러리입니다.

   공식 SDK(Python, Go, Ruby, .NET, Java, Node)는 있지만, C 언어용 SDK는 없길래 그냥 하나 만들었습니다.
   비공식 OpenAI C SDK입니다.

   시작한 지는 오래되지 않았지만, 현재 다음 기능들을 지원합니다:
     * Chat (GPT)
     * Image (DALL·E)
     * Audio (Whisper-1)
     * Embedding

   앞으로는 스트리밍, 파인튜닝, 파일 업로드, 모델 목록, 콘텐츠 감지, 어시스턴트 API도 지원할 예정입니다.

   물론, OpenAI를 굳이 C에서 써야 하나 싶은 생각이 들 수도 있겠지만,
   없는 것보단 있는 게 낫다고 생각해서 만들어봤습니다.

   많은 관심 부탁드리며, 재미있는 AI 개발 하시기를 바랍니다!
     * 피드백/토론: https://github.com/LunaStev/openai-c/discussions
     * GitHub: https://github.com/LunaStev/openai-c

   C는 생각도 못했네요..
   응원합니다.. ^^;
"
"https://news.hada.io/topic?id=21431","Show GN: LLM 기반 유튜브 실시간 번역 크롬 익스텐션","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Show GN: LLM 기반 유튜브 실시간 번역 크롬 익스텐션

   안녕하세요.
   이전부터 만들고 있던 LLM 기반 브라우저 UX 개선 익스텐션에 유튜브 자막 번역 기능을 출시하여 공유합니다.

   사용자의 OpenAI 토큰을 이용해 별도 서버 없이 유튜브 실시간 번역, 웹페이지 몰입형 번역 등 다양한 기능을 제공합니다.

   오픈소스로 개발하고 있어 아래 링크에서 코드, 자세한 개발기록을 볼 수 있습니다.

   설치 링크: https://chromewebstore.google.com/detail/…
   코드: https://github.com/rokrokss/shizue
   개발기록: https://rokrokss.com/post/2025/…
"
"https://news.hada.io/topic?id=21326","Windows Notepad(메모장)에 텍스트 서식 지정 및 Markdown 지원 추가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Windows Notepad(메모장)에 텍스트 서식 지정 및 Markdown 지원 추가

     * Microsoft가 Windows Notepad에 텍스트 서식 지정과 Markdown 기능을 도입함
     * 최신 Canary 및 Dev Channel 테스터를 대상으로 굵게, 기울임, 하이퍼링크 등 새로운 서식 툴바 제공
     * 사용자들은 Markdown 스타일 입력과 파일을 사용할 수 있으며, 보기 메뉴에서 서식 있는 뷰와 소스 보기 전환 가능
     * 필요 시 모든 서식을 쉽게 제거하거나, 앱 설정에서 해당 기능을 비활성화할 수 있음
     * 최근 AI 기반 텍스트 생성 기능 등 여러 업데이트로 기존 단순 텍스트 편집기에서 확장된 모습임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Notepad의 새 기능 도입

     * Microsoft가 Windows 11용 Notepad 앱에 텍스트 서식 기능과 Markdown 지원을 추가함
     * 이번 업데이트는 Canary 및 Dev Channel 테스터가 먼저 사용 가능함

새 서식 지정 및 Markdown 툴바

     * 서식 지정이 가능해지면서 Notepad 상단에는 서식 툴바가 추가되어 굵게, 기울임, 하이퍼링크 등 텍스트 스타일링이 가능해짐
     * 해당 툴바에는 목록, 제목과 같은 기능도 포함됨
     * Markdown 스타일 입력을 선호하는 사용자를 위해 마크다운 파일도 지원하며, 보기 메뉴 또는 창 하단 상태 표시줄 토글 버튼을 통해 서식 있는 뷰와 마크다운 원본 뷰 전환이 가능함

서식 관리 및 설정

     * Notepad가 그동안 일반적으로 플레인 텍스트 용도로 사용되어왔던 만큼, 툴바나 편집 메뉴에서 언제든 모든 서식을 손쉽게 제거할 수 있음
     * 가벼운 서식 지정 기능이 필요 없을 경우 Notepad 앱 설정에서 완전히 비활성화할 수도 있음

AI 및 추가 기능 업데이트

     * 이번 서식 기능 추가는 AI로 텍스트를 자동 생성하는 Write 기능 출시 이후 단 일주일 만에 이루어진 것임
     * Write 기능은 사용자의 프롬프트에 기반해 빠르게 텍스트 초안 작성을 지원함
     * 이러한 서식 및 생성 기능 추가로 Notepad가 점점 Microsoft Word와 유사한 방향으로 발전 중임

Notepad 변화와 배경

     * 과거 수십 년 동안 거의 변화가 없었던 Notepad가 최근에는 매우 다양한 신기능을 도입하며 기존의 단순 로그 뷰어에서 벗어나고 있음
     * 이러한 변화는 WordPad가 윈도우에서 제거된 이후 더욱 가속화됨
     * 최근 Notepad의 업데이트는 Microsoft가 기본 앱에 대한 전략적 변화를 추진하고 있음을 의미함

   Apple Notes에 Markdown 내보내기 기능 추가 예정
"
"https://news.hada.io/topic?id=21349","Beachpatrol - 브라우저의 일상 업무를 자동화하는 CLI 허브","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Beachpatrol - 브라우저의 일상 업무를 자동화하는 CLI 허브

     * 일반 웹 브라우저를 CLI 기반 자동화 브라우저로 대체할 수 있게 해주는 오픈소스
          + 이메일·은행·SNS 자동 체크, 파일 자동 다운로드, 텍스트 추출 및 저장
          + 폼 자동 입력, 사이트 맞춤 메시지 수집, Bash·Python 스크립트 연동
          + 일상적인 웹 브라우징 환경 전체를 자동화할 수 있음
     * Playwright 기반으로 크롬/파이어폭스 브라우저를 스크립트로 제어하며, 일반적인 브라우저처럼 사용하면서도 자동화 명령을 자유롭게 수행
          + 프로필/시크릿 모드 지원 하여 다양한 로그인/환경 구성 유지 가능 (--profile, --incognito)
     * 커스텀 Playwright 스크립트를 추가해 이메일 확인, 파일 다운로드, 폼 자동 입력, 텍스트 추출, 계좌 조회, OS 연동 작업 등 모든 웹 작업을 자동화 가능
          + beachpatrol/commands 폴더에 Playwright 스크립트 작성 후 beachmsg <스크립트>로 실행하여 스크립트 기반 자동화
     * 별도의 브라우저 확장 프로그램(Native Messaging 지원)과 연동해, 브라우저에서 바로 명령 실행, 인자 전달, URL별 커맨드 활성화, 핫키, GUI 활용이 가능함
     * stealth 플러그인, Playwright 옵션 최적화로 자동화 탐지(로그인, 구글/클라우드플레어 차단 등) 회피 기능을 내장해 실제 브라우저처럼 동작함
     * 브라우저와 독립된 커맨드 서버-클라이언트 구조로 여러 OS 툴과의 연계 및 확장성 우수
     * CLI 명령과 확장 프로그램을 통해 OS와 브라우저 자동화의 경계를 허물고, Vim·Emacs처럼 스크립트로 일상을 관리하는 경험을 제공
     * Linux (Wayland/X11) 또는 macOS 필요, Node.js/NPM 필수
"
"https://news.hada.io/topic?id=21408","Show GN: Raw Pixels Viewer","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Show GN: Raw Pixels Viewer

   기존 Raw Pixels Viewer 사이트가 사라져서 개발하였습니다.

   RAW한 이미지 파일을 디버깅하거나 분석할 때 유용하게 사용할 수 있습니다.
"
"https://news.hada.io/topic?id=21410","GitHub에서 10억 번째 저장소 생성 축하","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       GitHub에서 10억 번째 저장소 생성 축하

     * GitHub에서 10억 번째 저장소가 생성됨
     * 오픈소스 생태계의 폭발적 성장을 보여주는 이정표임
     * 수많은 개발자와 프로젝트가 협업과 혁신의 핵심으로 GitHub를 사용함
     * 지금까지의 성장 속도와 앞으로의 기술 발전 가능성에 주목해야 함
     * 글로벌 기술 커뮤니티의 확장과 다양성을 반영하는 중요한 사건임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 최근 GitHub 플랫폼에서 10억 번째 저장소가 만들어진 사건이 발생함
     * 이는 2008년 출시 이후 개발자 커뮤니티의 지속적인 성장과 오픈소스 문화의 확산을 상징함
     * GitHub는 소스코드 관리, 협업, 버전 관리 등 소프트웨어 개발의 핵심 도구로 자리잡음
     * 10억 개에 달하는 프로젝트와 저장소가 생성되며, 전 세계적으로 혁신적 아이디어와 협업의 장이 확장됨
     * 이정표는 오픈소스 소프트웨어의 힘과 글로벌 개발자 네트워크의 영향력을 다시 한번 보여주는 계기임

        Hacker News 의견

     * 100,000,000번째 OpenStreetMap changeset이 생각나는 경험 공유, 나와 몇몇 사람들이 이 기록을 노렸지만 실제로는 아무것도 신경 안 쓰고 아프리카 매핑에 열중하던 사람이 차지한 이야기, 시간이 지나고 보니 더 훈훈한 결말로 느껴짐, 이 사람은 과거에도 OSM 상을 받은 후보였던 분, OpenStreetMap은 모든 변경이 실시간 프로덕션에 적용되기 때문에 의미 없는 기여를 하기가 어려운 구조라서 오히려 우연에 의해 milestone number를 차지하는 경우가 많음, Github의 이런 이정표도 재밌는 성과라고 생각, OSM milestone에 관심 있다면 공식 블로그와 내가 정리한 글 참고 추천
     * 깃허브 저장소 ID 숫자가 overflow할 정도를 이야기하면서, 앞으로 10억 개 더 생성되면 깃허브 OpenAPI Spec도 int32 한계 넘는 현상 발생 가능성 언급, 참고: 관련 이슈
          + 예전에 CTO로 일하던 회사에서 32비트 정수(primary key)를 주요 테이블에 쓰고 있었는데 벌써 13억 개나 쌓여 있어서, 이대로 가면 몇 달 내로 overflow 문제가 발생할 뻔한 경험, 급히 64비트로 확장해서 큰 사고를 막았던 기억
     * 재미로 깃허브 저장소 ID의 시작을 공유, 첫 번째 저장소는 API에서 직접 보기, 저장소 주소는 여기
     * 깃허브에서 저장소 생성 속도를 계산하는 게 너무 쉽다는 점이 놀라움, 이런 정보는 보통 기업의 비밀로 취급된다고 생각
          + 깃허브 같은 서비스가 어마어마하게 커지면, (정보 공개에) 좀 더 느긋한 경향이 생긴다는 유쾌한 비유
          + 깃허브가 이런 정보를 굳이 숨길 이유가 있을지 궁금증, 이런 데이터로 깃허브에 타격을 줄 활용이 가능할지 의문, 많은 기업들이 원칙적으로 정보를 최소 공개하는 경향 있다는 배경
     * 전체적으로는 각각의 서버(Forgejo, Gitlab 포함)에 실제로 몇 개의 저장소가 존재하는지 궁금증, 경우에 따라 Subversion, Mercurial, git까지 포함한 범주로 언급, 혹시 이런 분산된 저장소를 검색하는 엔진이 만들어진 적 있는지, 단순히 'a'라는 단어를 검색하는 방식으로 전체 규모 추정 가능성, Github처럼 중앙 집중된 플랫폼에서는 오픈소스 코드 찾기가 쉬운 점이 장점이라고 느꼈고, MS의 Github 인수 후 직접 검색 엔진을 만들까 고민했지만 홍보가 어려워 포기한 경험, 최근 codeberg에 여러 프로젝트를 올리면서 다시 관심 생겼지만 이미 누군가 만들었을지도 모른다는 생각
     * AasishPokhrel이 10억 번째 저장소 기록을 노리고 만든 건 아닌지 궁금증
          + 실제로 이런 걸 노리기는 쉽다는 설명, 계속 저장소를 만들다 보면 언젠가는 해당 번호를 차지할 수 있음, 동시에 다른 사람도 생성 중이기 때문에 결국 운의 영역, API 지원으로 시도 자체는 간단, 다만 속도 제한(rate limits)이 변수
          + AasishPokhrel이 어제 'shit'과 'yep'이라는 두 저장소를 만든 기록, 5월 17일부터 6월 10일까지는 활동이 없다가 새로 만든 점, 특정 번호 저장소를 노리고 타이밍을 맞추는 게 정말 가능할지 확신은 없다고 전언
          + AasishPokhrel이 네팔에서 소프트웨어 개발을 공부하는 대학생이라고 알고 있는데, 이런 글로벌 milestone이 지구 반대편까지 닿았다는 점에 감동, 이 기록이 그의 이력서에 크게 남아서 좋은 개발 커리어로 이어지기를 응원
          + 실제로 노렸을 가능성은 낮은 것 같지만 불가능하다고 할 수는 없을 듯한 의견
     * 아마 스크립트로 https://api.github.com/repositories/999999999 같은 주소를 계속 체크하다가 해당 번호가 생기면 바로 저장소를 만든 방식일 것으로 추정, 저장소를 여러 개 만들고 맞춤 번호만 남기고 삭제하는 식으로도 가능, 어제 만든 다른 저장소 기록을 보면 'yep'을 milestone 번호로 남기려 했던 것 같고, 'shit'은 실패했음을 인정하는 이름이 아닐까 추측, 과거 Facebook의 D666666 codemod 사례와 같은 숫자 맞추기 기법 언급
     * ‘세 개의 콤마(,) 클럽’이라는 의미로 10억 번째 저장소를 표현
          + 스페인어 농담으로 ‘Tres commas’(세 콤마) 언급
"
"https://news.hada.io/topic?id=21319","GitLab 저장소 백업 시간을 48시간에서 41분으로 단축한 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 GitLab 저장소 백업 시간을 48시간에서 41분으로 단축한 방법

     * GitLab은 대용량 저장소 백업 시 오래 걸리는 문제를 발견하고 개선 작업을 수행함
     * 핵심 원인은 15년 된 Git 함수의 O(N²) 복잡도였으며, 알고리듬 최적화를 통해 성능을 대폭 향상시킴
     * 최적화 결과, 가장 큰 저장소의 백업 시간이 48시간에서 41분으로 줄어듦
     * 개선된 방식은 리소스 효율성과 신뢰성을 제공함과 동시에 다른 Git 기반 툴과 커뮤니티에도 긍정적인 영향을 줌
     * GitLab 18.0 버전부터 모든 사용자들이 추가 설정 없이 이러한 이점을 누릴 수 있게 됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

저장소 백업의 중요성과 과제

     * 저장소 백업은 비상 복구 전략의 핵심 요소임
     * 저장소 크기가 커질수록 신뢰할 만한 백업 과정의 복잡성이 증가함
     * GitLab의 자체 Rails 저장소는 백업에 48시간이 소요되어, 백업 빈도와 시스템 성능 사이에서 선택의 어려움이 있었음
     * 대규모 저장소에서 발생하는 시간, 리소스, 실패 위험, 레이스 컨디션 등 다양한 문제가 존재함
          + 예약 백업이 어렵거나, 외부 도구 의존 또는 백업 횟수 감소 등 조직별로 일관적이지 못한 전략이 나오게 됨

성능 병목 현상 분석과 원인 파악

     * GitLab의 백업 기능은 git bundle create 명령을 활용하여 저장소 스냅샷을 생성함
     * 이 명령의 구현 과정에서 reference(레퍼런스) 수 증가에 따라 성능 병목이 발생했음
     * 수백만 개의 레퍼런스를 가진 대형 저장소의 백업에 48시간 이상이 소요되는 경우가 발생함

  원인 분석

     * 명령 실행 중 Flame Graph 분석으로 병목 구간 확인
     * 레퍼런스가 10,000개일 때, 실행 시간의 약 80%가 object_array_remove_duplicates() 함수에서 소비됨
     * 이 함수는 2009년에 해당 커밋에서 중복 레퍼런스 처리 목적으로 도입된 것임
          + git bundle create 사용 시 중복된 레퍼런스가 포함될 경우 문제 발생을 방지
          + 그러나 중복 검출이 중첩 for 루프 형태로 되어 있어 O(N²) 복잡도가 생김
          + 레퍼런스 수가 많아질수록 병목이 심화되는 구조임

O(N²)에서 효율적 매핑으로의 전환

     * GitLab은 중첩 루프 대신 맵 자료구조를 이용한 방식으로 Git에 패치를 기여함
          + 각 레퍼런스를 맵에 추가하여 자동으로 중복을 제거하고, 효율적으로 처리함
     * 이 변경으로 git bundle create 성능이 대폭 향상되고, 대규모 레퍼런스 환경에서도 확장 가능해짐
     * 벤치마크 결과, 레퍼런스 10만 개 기준 6배 이상의 성능 개선 확인

대폭 줄어든 백업 시간과 효과

     * 최대 저장소 백업 소요 시간이 48시간에서 41분(1.4% 수준)으로 감소함
     * 저장소 크기와 무관하게 일관된 성능 제공이 가능함
     * 서버 부하 감소, 백업 기반 Git 명령 전반의 성능 향상 등 부가 이점 확보
     * 해당 패치는 업스트림 Git에 적용됐고, GitLab에서는 즉시 적용해 고객의 빠른 경험이 가능하도록 함

GitLab 고객을 위한 실제 변화

     * 대기업 고객은 연속된 밤샘 백업을 개발 워크플로와 충돌 없이 실행할 수 있게 됨
     * 복구 목표 지점(RPO) 이 줄어든 덕분에, 재해 상황에서 데이터 손실 위험이 대폭 축소됨
     * 리소스 소비와 유지보수 시간, 클라우드 비용 등 운영 오버헤드까지 줄어듦
     * 저장소 규모가 증가해도, 백업 빈도와 시스템 성능 사이에서 고민하지 않아도 됨
     * 이제 모든 GitLab 사용자는 구성 변경 없이 이러한 이점을 누릴 수 있음

다음 단계 및 의미

     * 이번 개선은 확장성 높은 엔터프라이즈급 Git 인프라 구축에 대한 GitLab의 지속적인 노력의 일부임
     * GitLab이 기여한 변경사항은 업스트림 Git 프로젝트에도 반영되어, 업계 전반과 오픈소스 커뮤니티에 긍정적 파급 효과를 미침
     * 이 같은 인프라 개선 노력이 다른 핵심 성능 개선 작업의 모델로 자리 잡고 있음

     GitLab의 성능 접근 방식에 대한 더 깊은 이야기는 GitLab 18 버추얼 런치 이벤트에서 확인 가능함

        Hacker News 의견

     * GitLab이 Git에 기여한 성능 향상 코드는 v2.50.0에 릴리즈 예정인 정보 공유 관련 커밋 링크
     * 직접 경험을 통해, 내가 작성한 코드에서 n^2 연산을 제거하는 것이 항상 올바른 선택이었음을 강조. 특별한 알고리즘을 작성하지 않아도, 아주 작은 n값에서도 문제가 쉽게 드러나는 점에 놀라움을 느낌
          + Bruce Dawson의 첫 번째 컴퓨팅 법칙 인용: O(n^2)는 최악의 확장성 문제를 일으키는 지점. 프로덕션에선 충분히 빠르고, 막상 배포되면 치명적인 성능 저하가 발생하는 부분 관련 글 링크
          + O(N^2) 시간복잡도는 테스트에서는 빠르게 보이지만, 프로덕션에서 심각하게 문제가 터지는 상황을 여러 번 목격한 개인 경험 공유
          + 내 경험상 대다수 문제(80~90%)에선 복잡한 알고리즘이 필요하다면 데이터 모델 자체가 올바르지 않다는 신호임. 컴파일러, DB 내부, 경로 기획 등 특별한 일부 경우에만 복잡한 알고리즘이 본질적으로 필요하다고 생각
          + n이 10 미만의 소규모 하드웨어 한정 케이스만 예외로 언급(CAN 인터페이스 등), 만약 하드웨어 교체 없이 n이 늘어날 수 있으면 반드시 n^2 연산을 피해야 하며, 설계상 제한하거나 사전 감지를 통해 재설계 필요성의 인식 권고
          + 본인은 n^3 연산 때문에 단 10,000개 요소에서 병목현상이 발생하는데, 아직 해결 방법을 찾지 못한 난감함 피력
     * 재미있는 발견이라는 평가와 함께, 본문이 1/10 길이만 되어도 충분히 효과적인 소통이 가능했으리란 아쉬움 공유. 그래도 영상 콘텐츠가 아니라 스킴 하기가 쉬워서 좋았다는 긍정적인 면도 언급
          + 기사 미리 안 읽은 이들을 위해, flame graph 이후 백포팅 언급 전까지만 읽고 멈추는 게 핵심 파악에 가장 효율적이라는 팁
          + 기사 전체 스타일이 LLM(대형 언어 모델)이 생성한 것처럼 느껴질 만큼 내용이 길었으며, 그 점이 기억에 남는다는 소감
          + 기사 분량이 더 길었더라도 괜찮았을 거라 생각하며, 백업 번들을 두 개 ref로 왜 만들었는지 여전히 의문
     * 48시간이나 git 폴더(수 GB)를 압축하는 데 드는 시간, 그리고 41분조차도 긴 시간으로 받아들임. git repo 전체를 그냥 스냅샷/아카이브하지 않고, git bundle을 굳이 쓰는 특별한 이유에 의문. git bundle이 자주 이루어지는 ZFS 백업보다 무슨 장점이 있는지 궁금함
          + git 공식 FAQ에서, 이런 방식은 Git의 일반적인 무결성 검사 절차를 우회하므로 위험성이 존재. 이런 경우 컬렉션 무결성 검증을 위해 git fsck를 권장. 개인 단위에서는 Syncthing, Btrfs 스냅샷만으로도 충분히 빠르고 안정적임. 관련 문서
          + ZFS 스냅샷을 S3 같은 비-ZFS 베이스로 오프사이트 백업하기엔 제한이 있다고 언급. git bundle의 덜 알려진 기능으로, git clone --bundle-uri에 위치 지정이 가능하고 서버가 클라이언트에 번들 위치를 알려주면 클라이언트가 번들을 받아 빠르게 풀어 델타 업데이트만 서버에서 받으면 되며, 대형 repo 복제에 부담이 크게 줄어듦
          + 결국 캐싱이 필요한 부분에 캐싱을 추가한 것 같다는 평. 통상적으로 git repo는 분산 시스템 특성 상, 다른 저장소로 미러링하고 파일시스템 스냅/백업 도구로 관리하면 되는 것 아니냐는 의문. 핵심은 중요한 버전관리 정보 자체가 분산되어 있어야 한다는 점 강조
     * git 백업 경험이 많진 않지만, 로컬 repo에서 직접 백업 만들면 레이스 컨디션이 생기는 이유가 의아하다는 궁금증 전달
     * 상위 계층 데이터 프로토콜 때문에 이 정도로 골치 아프다면, 차라리 블록 레벨 스냅샷을 사용하지 않는 이유에 의문. Git처럼 WAL(Write Ahead Logging)이 없는 것이 걸림돌이지만, SQLite는 WAL 모드 추가만으로 손쉽게 블록 스냅샷시키는 전략을 실제 서비스 환경에서 활용 중. Git에도 이런 아키텍처가 적용되면 훨씬 안정적인 백업 전략이 가능할 것이라 생각
          + Git에 WAL과 비슷한 메커니즘이 없다는 점에서 발생하는 문제를 공감하며, 스냅샷만 믿고 백업하면 복원 시 리포지토리가 깨지는 치명적 이슈 경험 공유. 복구는 가능하지만 매우 번거로운 이슈임을 덧붙임
          + SQLite에서 최근 더 나은 방안으로 sqlite3_rsync 솔루션 등장 팁 공유
          + GitLab은 단순 매니지드 서비스가 아니라, 스스로 설치해서 다양한 환경에 쓸 수 있는 제품이므로 사용자마다 파일시스템과 스냅샷 지원 여부, 운영 체제 조건이 다름. 즉, 모든 환경에서 보편적으로 동작하는 독립적인 백업 시스템을 원한다는 GitLab 관점 설명
     * ""알고리즘 변화로 백업 시간을 지수적으로(Exponentially) 줄였다""는 표현을 보고, O(n^2)에서 O(n^2/2^n)으로 줄였다는 뜻인가 의문. 실제론 그럴 리 없다는 추측
          + 수정된 함수의 알고리즘 복잡도가 실제로 6배 빨라졌고, 그 외 사용 맥락에서는 전체 운영 시간이 1%로 줄어드는 극적인 결과라, 이 경우 ""지수적 향상""이 마케팅적으로는 적절하다고 해석. 실제 복잡도 규정이 큰 의미는 없다는 설명
          + 일상적인 대화에서 ""exponential""은 수학적으로 딱 떨어지는 뜻이 아니라 ""엄청 개선됨"" 정도의 비유적 의미로 쓰임을 명확히 함
          + 본인 해석으로 n이 로그(n)까지 줄어든 것일 수 있다고 생각. 양자 푸리에 변환이 기존 DFT보다 지수적으로 빠르다고 흔히 표현되는 배경과 유사하게, 복잡도가 n^2에서 nlogn으로 바뀌는 상황 언급
          + n^2 알고리즘을 log(n) 조회 방식으로 대체하면 속도가 지수적으로 향상되는 게 맞지만, 실제로는 해시맵 조회처럼 O(1)까지 가는 경우가 많아 그보다 더 빠름
          + 이러한 논쟁 자체가 비생산적인 트집잡기라고 생각
     * C로 작성한다고 해서 성능이 무조건 뛰어나지는 않으며, 자료구조와 알고리즘이 더 우선임을 보여주는 좋은 사례라는 의견
          + C는 적절한 컨테이너를 구현하는 게 워낙 어렵다 보니 이런 퍼포먼스 이슈가 더 자주 발생. C++이나 Rust는 unordered_set/HashSet 등 내장 자료구조 덕분에 개발자가 for 루프 하나로 대충 넘기지 않고 자연스럽게 최적화하는 경향. 이번 사례에서도 Git에도 string set이 있지만 표준적이지 않아 원작자가 몰랐을 가능성이 높다는 분석
     * 섣부른 최적화와 예측적(anticipatory) 최적화 사이에서 균형이 필요하다는 교훈 언급. 일반적으로는 성급한 최적화를 경계하지만, 아주 빈번히 호출되는 함수에서 명백하고 쉬운 최적화는 미리 적용하는 게 좋겠다는 룰을 제안
          + 구현 당시 소스 언어에 set-of-strings가 내장되어 있었다면, 원래 개발자도 이런 최적화를 쉽게 적용했을 것이라는 추정. 결국 이런 문제가 C처럼 컨테이너가 빈약한 언어의 구조적 한계에서 비롯됐다는 의견
     * 관련 커밋(알고리즘 개선 내역) 링크를 직접 전달 관련 커밋 링크
          + 덕분에 관련 서브미션과 커널 메일링 리스트 토론 스레드를 찾을 수 있었다는 정보 공유 관련 토론 링크
"
"https://news.hada.io/topic?id=21328","Ask GN: 긱뉴스의 검색을 개선시킬 방법들이 있을까요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Ask GN: 긱뉴스의 검색을 개선시킬 방법들이 있을까요?

   현재 긱뉴스는 구글 검색을 임베딩하여 사용하는데,
   개인적으로 불편함을 좀 느끼고 있습니다.

   최근 본 뉴스의 대략적인 키워드를 기억하여 이를 검색하면
   최신순으로 정렬하는 방법이 없어 찾기 어렵기도 합니다.

   벡터스토어를 wasm으로 넣어서 구현한걸 보기도 했지만
   검색 엔진은 제 분야가 아니라 그런지 구상하기 어렵네요.

   프론트엔드 단에서 fuzzy search 등을 구현하면 아무래도 서버 부담이 커질 듯 한데,

   가십거리용이지만, 효과적으로 이를 구현할 방법이 있을까요?

   저 검색 좋아하는 검색충인데, 검색 량이 하루에 얼마정도 나오나요 ?

   만약에 적다면 기존 검색 방법 러프하게 유지하면서 rerank 모델 쓰는 것으로 자연어 검색을 써볼 수 있긴 해요.

   전번에 제가 만든 서비스의 대략적인 검색 구조입니다.

   대충 1차적으로 es 로 쿼리 날린 다음에 cohere rerank api 적용해서, 자연어 기준으로 rerank score가 가장 잘 맞는 본문을 기준으로 서빙해 주는데요.

   그런데 생각해보니까 구글을 임베딩 하셨다는게, 검색 결과 항목 내부의 html 본문을 가져올 방법이 딱히 없을 것 같네요. 그래도 일단 링크는 남깁니다

   링크 : https://dev-wiki.dev/reading/tech/1

   저는 엄청 한가하고 검색을 좋아하기 때문에 관련해서 아직 얘기할 거리가 있다면 남겨주시면 감사하겠습니다 : )

   제 경우엔 최신 결과가 먼저 나오지 않는 부분이 다소 불편하게 느껴집니다. 옛날 bbs 게시판처럼 단순하게 LIKE 쿼리로 검색하는 쪽이 제 니즈에 좀 더 부합할 듯 합니다. 속도 때문에 range를 좀 고려해야겠지만요..

   저도 공감하는 불편사항입니다. 예를 들어 ""AI"" 라고 검색했을 때 5년 전 글이 첫 페이지에 나오는 경우가 꽤 있더라구요.

   임베딩된 구글 검색의 결과가 json으로 출력되는 것 같은데 그걸 가져와서 정렬하시죠

   https://cse.google.com/cse/element/v1 리퀘스트 확인해 보세요

   구글에서 직접검색은 어떤가요?
   query: site:news.hada.io duckdb

   https://google.com/search/…
"
"https://news.hada.io/topic?id=21387","Yes24, 랜섬웨어로 인한 장애로 2일째 서비스 불가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Yes24, 랜섬웨어로 인한 장애로 2일째 서비스 불가

     * 현재 접속 오류는 랜섬웨어로 인한 장애로 인해 6월 9일 월요일 새벽 4시경부터 발생하였으며, 복구 작업 중
     * 내부 조사 결과 개인정보 유출 정황은 확인되지 않았음
     * 장애로 인해 각종 불편함을 겪으신 전회원에 대해 구체적 보상안을 마련 중
     * 빠른 서비스 복구와 함께 전체 공지 및 개별 안내 드릴 예정

   보안이나 DevOps 전문가가 해외 리눅스 재단 등의 자격증을 취득해도, 한국에서는 그런 자격보다는 경력 3년, 5년 같은 연차만을 중요하게 보기 때문에 서류컷 당하는 것을보고 해외 보안 자격증은 실질적으로 의미가 없고 보안보다는 연차만 보더라고요. 결국, 이런 구조 자체가 문제를 일으킬 수밖에 없습니다.

   그런 자격증이 실무에서 별 의미가없으니 서류컷하는거 아닐까요. 실무 보시는 분들은 그런 자격증은 비싸고 귀찮아서 안따는거지..
   회사가 지원해주길래 저도 따긴했지만 왜 따는지 모르겠던데..

   구조적인 문제가 많지만 자격증의 문제는 아닌 것 같습니다..

   저의 본래 요지는 자격증 자체의 유효성을 말하려던 것이 아닙니다. 핵심은, 한국의 일부 보안/IT 업계가 글로벌 스탠다드나 변화하는 위협에 충분히 대비되지 못하고 있다는 점입니다.

   실제로 해외에서는 리눅스 재단이나 ISC² 같은 기관의 자격증이 실무 역량이나 최신 보안 트렌드에 대한 이해를 검증하는 수단으로 널리 활용됩니다. 하지만 한국에서는 그러한 국제적 기준보다는 단순한 연차나 경력 연수 중심으로 평가하는 경향이 여전히 강한 것 같습니다.

   이러한 접근은 마치 갈라파고스화 처럼 외부 변화에 둔감해지고, 결국 새로운 위협에 취약해질 수밖에 없는 구조적인 문제로 이어질 수 있습니다. 그래서 제가 말하고자 한 건 자격증의 가치 그 자체보다, 조직이 새로운 위협과 글로벌 기준에 어떻게 반응하고 있는가에 대한 문제였습니다.

   온프레미스+망분리안됨+백업본까지암호화...

   터질게 터진듯 하네요..
   한국 사이트 취약성이 소문났나봅니다
   보안에 제일 중요한게 일단 타겟이 안되는것인데..

   https://blog.aladin.co.kr/cscenter/16511263
   알라딘은 갑자기 정보보호팀장을 뽑는군요 ㅎ

   devpia 가 떠오르네요...

   생각보다 엄청 심각하던데요....

   구매한 책도 못 받아... 월 구독료 내고 책도 못 봐... 이게 뭐냐

   백업을 안했으니 RTO, RPO도 없었을테고, 재해복구 훈련도 한번도 안했던거 같네요

   이정도 지났는데 복구되지않았다면 스넵샷, DB백업도 없을거같고..
   백업본이 없었다면 없는대로 문제고, 있었다면 DB서버에 그대로 두고 백업본도 암호화 되버린것일수도..
   온프로미스 환경에 서버 조져지고 답 없지 뭐...

   그냥 돈주고 키주기를 간절히 비는수밖에...
   Yes24한테는 비싼 수업료네요

   오늘로써 3일째인데...
   일주일 넘어도 안될 수 있겠는데요...

   2일째 서비스가 완전 불통인데, 매우 심하게 당했나 보네요.
   관련 기사에서 ""해커들이 회원 정보 등을 암호화해 해독하지 못하고 있다.""라고 합니다.
   티켓도 문제고, e북 접근도 불가능하다고 하니.. 과연 어떻게 대응이 가능할지 모르겠군요.

   ""예매한 공연티켓을 수령하기 위해 좌석번호 적힌 예매내역서 혹은 예매확인메일이 필요하다는데, 예스24에서 정책변경안내 외엔 메일을 보낸 이력이 없고, 예매확인문자엔 좌석번호가 없으며 입금기한이 예스24가 먹통된 시간과 맞물려 입금은 했으나 이 모든 걸 받지 못한 사람은 어떻게 해야 하나요?""

   공연 티켓은 정말 난리일거 같네요. 이메일이나 문자로도 좌석번호 확인도 안되나봐요.
"
"https://news.hada.io/topic?id=21365","OnLook - 디자이너를 위한 Cursor","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        OnLook - 디자이너를 위한 Cursor

     * 웹에서 사이트, 프로토타입, 디자인을 실시간 코드와 함께 만들 수 있는 오픈소스 비주얼 바이브코딩 에디터
     * Next.js + TailwindCSS 기반, 브라우저에서 실시간 미리보기 및 직접 DOM을 수정 가능
     * Bolt, Lovable, V0, Replit Agent, Figma Make, Webflow 등 상용 서비스의 오픈소스 대체를 목표

주요 기능

     * Next.js 앱을 텍스트/이미지로부터 즉시 생성 - Figma 임포트, 템플릿 등 지원 예정
     * Figma와 유사한 UI로 페이지 생성, 자산 및 토큰 관리, 실시간 프리뷰 지원
     * 실시간 코드 에디터, 체크포인트 저장 및 복원, CLI 통한 명령어 실행, 마켓플레이스 연동
     * 드래그앤드롭, Tailwind 스타일 편집, 레이아웃 실험 등 시각적 조작 지원
     * 실시간 편집 / 댓글 / 공유링크 / 커스텀 도메인 지원 예정
     * 웹 기반이지만, 데스크톱 앱(Onlook Desktop)과도 연동 가능

아키텍처 및 동작 방식

     * 앱 생성 시 코드를 웹 컨테이너에 로드해 코드가 실행됨
     * 미리보기 링크를 iFrame으로 에디터에 표시, 코드와 UI 매핑 처리
     * AI 챗봇이 코드 접근 및 편집 지원, 코드를 직접 이해하고 수정 가능
     * JSX/TSX/HTML 등 선언형 DOM을 사용하는 다양한 프레임워크 확장 가능

사용 기술 스택

     * 프론트엔드: Next.js, TailwindCSS, tRPC
     * 데이터베이스/스토리지: Supabase, Drizzle
     * AI: AI SDK, Anthropic, Morph Fast Apply, Relace
     * 샌드박스/호스팅: CodeSandboxSDK, Freestyle
     * 런타임/번들러: Bun, Docker

기타 정보

     * Apache 2.0 라이선스
     * 웹 앱은 곧 공개 예정, 데스크톱 앱도 별도 제공
     * 전체 문서 및 개발 참여 방법은 공식 문서 참고

   Onlook - 오픈 소스 Webflow를 이용한 맞춤형 앱 제작 도구

   1년쯤 전에 이런 제목으로 올라왔었는데, 역시 네이밍이 중요하네요. OOO for XXX 가 이해가 편하죠.

   그러네요 네이밍이 핵심이네요 ㅎㅎ
"
