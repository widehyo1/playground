"https://news.hada.io/topic?id=21858","Apple Intelligence 모델에서 추출한 안전 필터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Apple Intelligence 모델에서 추출한 안전 필터

     * Apple Intelligence의 생성형 모델에 내장된 안전 필터를 해독 및 공개하는 오픈소스 프로젝트
     * 안전 필터는 유해하거나 부적절한 콘텐츠를 차단, 규정 준수를 위한 필터링 룰을 포함
     * 안전 오버라이드는 모델 컨텍스트에 따라 다르게 적용되며, 각각의 상황에 맞는 구체 규칙 정보를 제공함
     * 해독된 파일은 json 형태로, 단어, 구문, 정규식 기반 룰 등이 포함됨
     * 이 프로젝트는 프라이버시‧신뢰성 검증, 모델 세이프티 분석 등에 유의미한 리소스임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 개요

     * 본 저장소는 Apple Intelligence에서 활용되는 생성형 모델의 안전 오버라이드(safety override) 파일을 해독 및 공개함
     * 해독된 오버라이드는 폴더 내 구조적으로 정리되어 있으며, 각 모델에 연관된 안전 필터링 JSON 파일 형태로 제공됨
     * 이를 활용하면 실제로 Apple 모델이 어떤 콘텐츠 필터링 정책을 적용하는지 구체적으로 확인 가능함

폴더 및 파일 구조

     * decrypted_overrides/
          + 각각의 생성형 모델에 따른 디렉터리별 안전 오버라이드 파일 저장
          + 각 디렉터리에는 Info.plist(메타데이터)와 AssetData(필터 JSON 파일) 이 포함됨
     * get_key_lldb.py: 애플리케이션에서 사용하는 암호화 키를 추출하는 파이썬 스크립트
     * decrypt_overrides.py: 안전 오버라이드 파일을 해독하는 파이썬 스크립트

오버라이드 파일의 해독 및 이해

     * 오버라이드 JSON 파일에는 명확한 안전 필터링 룰이 명시되어 있음
     * 각 오버라이드는 특정 모델 컨텍스트와 매칭되며, 다양한 상황에 따라 필터링 방식이 상이함
     * 예시 JSON에는 다음과 같은 필드가 포함됨:
          + ""reject"": 입력값과 일치하면 강제 거부되는 구체 구문 목록
          + ""remove"": 출력 결과에서 제거해야 할 구문
          + ""replace"": 특정 구문을 다른 구문으로 대체
          + ""regexReject"": 정규식으로 매치되는 경우 거부
          + ""regexRemove"", ""regexReplace"": 정규식을 통한 제거, 대체

프로젝트 활용 의의

     * 본 프로젝트는 Apple 생성형 모델의 실제 필터링 규칙을 살펴보고, 해당 모델의 세이프티 및 신뢰성 평가에 참고 자료로 활용 가능함
     * 생성형 모델을 활용하는 개발자, 보안 담당자 등이 필터 동작을 분석하거나 모델 커스텀 필터 설계 참조에 유용함
     * Apple Intelligence가 적용하는 콘텐츠 정책 및 규정 준수 수준을 투명하게 파악할 수 있음

        Hacker News 의견

     * 어떤 조합들은 좀 이상한 느낌. 여기엔 죽음 관련 발화를 피하려는 규칙들과, Apple 브랜드의 대소문자 표기를 철저히 맞추려는 부분이 섞여 있음. 우선순위에 대한 Apple의 시각 체험. 관련 링크
          + ""unalive""라는 단어가 포함되지 않은 점 흥미롭게 느껴짐. 모두가 그 단어의 의미를 알면서도 실제로는 아무도 신경 쓰지 않는다는 것, 그리고 모두가 형식적으로만 행동한다는 현상 지적 현상
          + 브랜드 대소문자 표기 집착이 정말 창피하고 불안하게 느껴짐. 그래도 브랜드 담당자에게는 그게 정말 중요한 요소일 거라는 확신
          + 시스템이 ""파일 실행""이나 ""정보 전달"" 같은 명령 제안까지 차단됨
          + 너무 판단적으로 보지 말라는 의견. 미국 대기업에서 이런 문제에 우선순위를 두는 건 현실적 일처리 방식임
     * Alexandra Ocasio Cortez 이름이 정책 위반으로 간주되는 상황 재밌게 관찰. 관련 링크
          + Anthony Albanese, Boris Johnson, Christopher Luxon, Cyril Ramaphosa, Jacinda Arden, Jacob Zuma, John Steenhuisen, Justin Trudeau, Keir Starmer, Liz Truss, Michael D. Higgins, Rishi Sunak 등 여러 정치인의 이름도 같은 규칙에 걸림. 관련 링크 남아공 정치인들 이름이 차단 명단에 있다는 사실이 남아공 언론에 화제가 될 것이라는 예측
          + 대부분 기업용 GenAI 모델들이 “<정치인 이름>이 체포되는 사실적인 이미지”, “<정치인 이름>이 ISIS 깃발 흔드는 장면”, “<정치인 이름>이 아기 때리는 장면” 등 자극적 요청을 차단하는 시스템 갖추고 있을 것이라는 추측
          + Ocasio Cortez 이름이 정책 위반으로 분류된 건 맥락 때문일 수 있고, 훈련 데이터에서 인종에 대한 비하 의미와 연결되어있을 가능성 지적, 추가로 다른 사례도 확인 가능성 탐색
          + 이 현상은 특히 스페인어 버전에서 확인됨
          + Ocasio Cortez가 딥페이크 음란물 피해를 많이 당한 배경 언급
     * AGI가 곧 등장할 거라는 주장과 달리, 이런 ""초지능"" LLM들이 아직도 출력값을 regex로 필터링해야 하는 현실이 우습게 느껴짐
          + 누구도 Apple의 LLM이 최첨단이라는 믿음 없어 보임. 특히 기기 내에서 동작하는 LLM은 더더욱 주목받지 못하는 분위기
          + 가끔은 사람 자체를 regex로 필터링하고 싶다는 농담
          + 모든 최신 동력원들이 결국 “물을 끓여서” 쓰는 식의 고전적 해결책 반복처럼 느껴짐
          + 이런 건 단지 Apple의 정책과 정렬에 해당하며, 인터넷에 난무하는 불필요한 발언이 자사 모델에서 재생산되는 걸 막고자 하는 의도
     * 중국에서는 이런 정책을 ""조화로운 사회""라고 부르지만, 미국에서는 ""안전""이라는 이름으로 불림. 검열이란 용어 자체가 달라져도 대중의 생각을 컨트롤하는 효과는 같음. 이런 걸 직접 볼 기회는 드물다는 느낌 표현
          + 회사가 자사 모델이 브랜드에 타격을 줄 문장을 생성하지 않으려는 건 전혀 놀랍지 않음. 예를 들어 Apple이 메세지를 요약하면서 ""Jane이 Anthony Albanese가 죽었으면 좋겠다고 생각"" 같은 문장 내놓으면 언론이 난리날 것이라는 현실적 시나리오 제시
          + 미국에서 이런 현상은 법적 위험(변호사들) 때문이라는 설명. 자본주의를 칭송하다가도 언론 조작을 통한 사소한 이익 극대화가 시작되면 갑자기 ""표현 자유""라는 프레이즈를 외치는 현상 꼬집음
     * Apple에서 이런 일이 일어나는 것 자체가 상당히 어이없게 느껴짐. 우회는 쉽고, 예를 들어 “Boris Johnson” 대신 “B0ris Johnson” 하면 regex를 피해갈 수 있다는 점 시연. 관련 링크
          + 사용자의 99%는 일부러 우회할 생각조차 하지 않음. 하드코딩된 regex는 첫 번째 방어선이자, 매우 효율적 필터링 수단으로 초점
          + LLM에서는 우회 표현이 먹히기도 하지만, 사전 정의된 태그 중심으로 학습한 이미지 생성 모델에서는 거의 바로 인식 실패 현상 발생 가능성
          + 이런 규칙들의 목적은 일부러 우회하는 유저를 막는 것이 아니라, “${정치인}이 죽었으면 좋겠다”는 요약이 나와서 언론에 대서특필되는 것 등 1차 리스크 차단 기능이 더 큼. “생각해보면 어린이용” 수준의 안전장치임
          + 영국 정치가 금기어로 분류되는 느낌
          + Apple에서 이런 정책을 보고 예상외라고 말할 필요가 없음. 현존하는 SOTA 대응책이고, Apple은 AI 경쟁에서 후발주자이므로 기민하게 업계 관행을 따르는 전략이 합리적 선택
     * Apple의 이런 정체불명의 필터 정책들을 보며 예전에 있었던, 아시아어 검색 필터 논란을 떠올림. 희한하면서도 민망했던 에피소드였음 관련 기사
     * 이 필터들은 창피함 또는 법적 리스크가 있을 수 있는 이메일/메시지 요약을 차단하거나 ""Safari Summarization isn't designed to handle this type of content"" 등 경고 문구를 표시하는 데 중점. 입력이 아니라 LLM 출력에 적용됨. Apple 기기 내 LLM은 3b 파라미터뿐이라 가끔은 바보스러운 결과 나오는 경향 있음
     * 키워드 필터링 규칙을 시험해보고 싶어서 ""Granular Mango Serpent""라는 이름으로 바꿔볼 생각이 듦
          + Granular Mango Serpent가 새로운 David Meyer라는 농담 등장. 관련 기사
     * Core ML 모델 암호화와 이 내용이 관련된 것인지 질문. Apple이 역사적으로 앱 자산 보호용 DRM은 제공하지 않아왔기에 다소 생소함 관련 링크
          + 이건 별도 시스템이며, 어떤 자산 전체에 적용되는 것이 아니라 이런 오버라이드에만 적용. 복호화는 ModelCatalog private framework에서 이루어짐
"
"https://news.hada.io/topic?id=21898","Reposilite - 가볍고 효율적인 Maven 아티팩트 리포지토리 매니저","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Reposilite - 가볍고 효율적인 Maven 아티팩트 리포지토리 매니저

   Reposilite는 Kotlin으로 개발된 초경량 Maven 아티팩트 리포지토리 매니저로, 기존의 무거운 리포지토리 솔루션(예: Nexus Repository, Artifactory)의 강력한 대안임.
   특히 제한된 리소스를 가진 환경이나 간단하고 효율적인 로컬 Maven 리포지토리가 필요한 경우에 이상적인 솔루션임.

  주요 특징

     * 극강의 경량성 및 효율성: Java 11 이상 환경에서 최소 메모리 32MB 요구, 64MB 이상이면 완전한 구동이 가능함. 소규모 팀이나 개인 프로젝트, CI/CD 파이프라인의 임시 리포지토리 등으로 활용하기에 매우 적합
     * 파일 시스템 및 클라우드 스토리지 지원: 로컬 파일 시스템은 물론, AWS S3와 같은 클라우드 오브젝트 스토리지에 저장하는 것도 지원.
     * 강력한 인증 및 권한 부여: 개인 접근 토큰(Personal Access Token) 기반 권한 관리기능으로 특정 리포지토리나 경로에 대한 읽기/쓰기 권한을 제어할 수 있음.
     * 프록시 리포지토리 기능: 원격 Maven 리포지토리(예: Maven Central)에 대한 프록시로 빌드 속도를 향상시키거나 내부망 proxy로 사용 가능.
     * REST API 및 플러그인 시스템: 풍부한 REST API를 제공하여 자동화된 관리 및 통합이 가능. 플러그인 시스템을 통해 기능을 확장 가능.
"
"https://news.hada.io/topic?id=21876","Deno 2.4 릴리즈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Deno 2.4 릴리즈

     * deno bundle이 esbuild 기반으로 다시 도입되어, 서버·브라우저 모두에서 단일 파일 번들 생성 및 자동 트리 쉐이킹과 최적화 가능해짐
     * 텍스트/바이트 임포트 지원 및 OpenTelemetry 내장 안정화 등으로 관측성과 외부 파일 활용 경험 강화됨
     * 새 --preload 플래그, 의존성 편의 개선 deno update, 스크립트 커버리지 측정, 권한 관리, Node.js API 호환성까지 폭넓게 개선됨
     * LSP, Jupyter, bench/coverage, tsconfig 지원 향상과 다양한 편의성 개선도 함께 제공됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Deno 2.4 주요 변경사항 및 새 기능 요약

  deno bundle의 복귀

     * Deno 2.4에서는 단일 파일 JavaScript 번들 생성 기능인 deno bundle 서브커맨드가 esbuild 엔진과 함께 다시 탑재됨
     * 서버, 브라우저 모두를 지원하며, npm, JSR 의존성도 문제없이 번들 가능함
     * 자동 트리 쉐이킹과 코드 최적화(minify) 지원 등으로 관리가 편리해진 환경 제공
     * 향후 런타임 API와 플러그인을 통해 번들 프로세스의 프로그래밍적 확장 및 커스터마이징 기능 추가 예정임

  텍스트 및 바이트 임포트 지원

     * 자바스크립트 모듈 그래프에 텍스트, 바이너리, 이미지 등 외부 데이터 파일을 임베드할 수 있도록, --unstable-raw-imports 플래그를 제공함
     * 기존에는 파일 입출력(I/O)로 외부 파일을 읽어야 했으나, 이제는 임포트 구문에서 파일 타입을 지정해 직접 바이트/텍스트 데이터 사용 가능함
     * 이 기능은 번들, 컴파일 시에도 동작해 결과물에 에셋 임베딩을 간편하게 구현 가능함
     * JSON, Wasm 등의 기존 임포트 지원과 함께 여러 파일 포맷을 명세 친화적으로 관리할 수 있음
     * 아직 명세(스펙) 논의 중이나, Deno는 기능 진보와 표준 동향을 조화롭게 반영함

  OpenTelemetry 내장 안정화

     * 2.2 버전에 도입된 OpenTelemetry 내장 지원이 2.4에서는 완전히 안정화됨
     * OTEL_DENO=1 환경변수만 설정하면 별도의 플래그 없이도 로그, 메트릭, 트레이스 수집 자동화 가능함
     * Node.js와의 무설정 호환 및 Deno Deploy 배포 환경까지 일괄 지원
     * console.log 로그와 HTTP 요청의 자동 연결/관찰도 가능함
     * 리소스 사용 특성상 환경 변수 제어가 필요함

  실행 전 환경 설정용 --preload 플래그

     * 주요 스크립트 실행 전에 글로벌 환경 변경, 데이터 로딩, 종속 모듈 등록 등을 위한 코드를 미리 실행할 수 있는 --preload 플래그가 추가됨
     * 플랫폼 커스터마이징이나 글로벌 오브젝트 재설정 등 다양한 플랫폼 구축 시 유용함
     * deno run, deno test, deno bench 등 주요 커맨드에서 모두 사용 가능함

  의존성 관리 간소화: deno update

     * npm, JSR 의존성의 최신 버전 자동 업데이트를 위한 deno update 서브커맨드가 도입됨
     * 여러 종속성 한 번에 최신화 및 Semver 호환성 기반 정밀 업데이트 지원
     * 기존 deno outdated --update 의 별칭 제공, 사용 편의성 강화

  스크립트 커버리지: deno run --coverage

     * 각각의 테스트뿐 아니라, subprocess가 포함된 실행 전체의 커버리지 수집이 가능해짐
     * DENO_COVERAGE_DIR 환경 변수 등 다양한 방식의 유연한 데이터 관리 가능
     * HTML 커버리지 리포트 다크 모드 지원 추가

  Deno 호환성 환경변수 DENO_COMPAT=1

     * npm 생태계 및 package.json 기반 프로젝트의 편의성·호환성 향상을 위한 DENO_COMPAT=1 변수가 도입됨
     * 여러 불안정(Unstable) 플래그를 자동 적용하며, 향후 npm prefix 생략 등 지원 폭 확대 예정

  권한 관리와 보안 개선

     * --allow-net 플래그에서 서브도메인 와일드카드 및 CIDR 범위 지원
     * 코드의 임포트 가능 호스트를 제한하는 --allow-import, 명시적으로 차단하는 --deny-import 플래그 신설
     * Deno.permissions API에 ""import"" 타입 쿼리 정식 지원
     * Deno.execPath() 사용 시 더 이상 읽기 권한 필요 없음, 실행 파일 경로 활용이 쉬워짐

  조건부 package.json exports

     * npm 패키지에서 조건부 exports 지원, 특히 React 서버 구성 등 다양한 생태계 지원 강화
     * 사용자 조건 플래그로 유연한 맞춤 import 동작 구현 가능

  deno run에서 bare specifier 지원

     * deno.json의 ""imports""에 설정한 별칭(베어 스펙)으로 명령어 진입점 실행 가능
     * 개발 생산성 및 모듈 관리 자동화 측면에서 큰 편의성 제공

  XML, SVG 등 포맷의 코드 포매팅 개선

     * deno fmt에서 .xml, .svg, .mustache 등 다양한 템플릿 파일 자동 포매팅 지원

  tsconfig.json 지원 강화

     * references, extends, files, include, exclude 등 다양한 옵션 인식 정확도 개선
     * Vue, Svelte, Solid, Qwik 등 최신 프론트엔드 프레임워크와의 향상된 호환성 제공

  Node 글로벌 변수 및 API 호환성 증대

     * Buffer, global, setImmediate, clearImmediate 등 Node.js 전역 오브젝트가 사용자 코드에도 항상 존재하도록 변경
     * npm 패키지 전용이던 글로벌도 커맨드 플래그 없이 바로 활용 가능
     * node:buffer, node:events, node:querystring, node:quic, node:wasm 등 95% 이상 호환성 달성, 앞으로도 지속적으로 확대 예정
     * @types/node 타입 기본 버전도 22.15.14로 업데이트

  로컬 npm 패키지 관리 변경

     * npm 로컬 패키지 연결 옵션명이 patch에서 links 로 변경되어, npm link의 의미와 일치
     * 기존 옵션 사용 시 디프리케이션 경고 제공, 더 명확한 패키지 관리 가능

  LSP 및 개발 생산성 개선

     * LSP 성능·기능 개선과 함께, fetch의 Unix/Vsock 소켓 지원, 서버의 onListen 콜백, Jupyter 커널 관리, 린트 플러그인에서 댓글 읽기 및 bench/coverage 표의 마크다운 호환성 등 다양한 편의성 제공
     * Windows에서의 Ctrl+Close 신호 인식(windows SIGHUP), bench/coverage 텍스트 출력의 마크다운 포맷 등도 새롭게 개선됨

  커뮤니티 및 기여자 감사 인사

     * Deno 2.4 발전에는 다양한 커뮤니티 기여자의 참여와 피드백이 큰 역할을 했음
     * 더 많은 내용 및 상세 변경사항은 GitHub 릴리즈 페이지 참조 가능

결론

     * Deno 2.4는 번들, 외부 파일 임포트, 관측성, 권한/보안, 호환성, 생산성 등 다양한 방면에서 큰 발전을 제공함
     * 개발 흐름과 최신 프론트엔드, 노드 생태계 프로젝트에서 쉽고 강력한 통합 개발 환경 경험 가능
     * 추가 정보와 최신 뉴스, 전체 변경 이력은 공식 문서 및 블로그, 깃허브 릴리즈 페이지에서 확인할 수 있음

        Hacker News 의견

     * Deno의 컨셉이 정말 마음에 들어서, Next.js, Hono, 그리고 프라이빗 패키지들을 포함한 모노레포 프로젝트에 Deno.json, JSR, 모던 import, Deno Deploy 등을 최대한 적용해봤던 경험 공유. Hono는 깔끔하게 잘 동작했지만 Next.js는 그렇지 않았고, 타입 관련 이슈도 미묘하게 깨지는 경우가 발생. 배포 목적지(Vercel 등) 선택도 문제였던 기억. 예시로 겪었던 작은 문제를 이슈 링크로 공유. 반면 Bun은 사용감이 Deno처럼 깔끔하진 않았어도 생각할 게 적었고 그냥 ""동작""하는 인상. 다만 Bun도 Vercel에서 Bun 런타임 미지원 등 완벽하지 않음
          + 선택한 스택이 여전히 npm 중심, 특히 프라이빗 npm 패키지가 많은 환경에서 무리였다는 조언. Deno식 방식의 달콤한 포인트는 자체적으로 Deno 혹은 ESM 친화적인 스택 선택에 있다고 생각. Lume을 사용하거나 Deno Deploy로 타겟팅한 경험이 좋았음. (JSR 스코어 덕분에 흥미롭고 ESM 호환이 강한 라이브러리 탐색에도 도움) 물론, 완전히 새로운 스택으로 시작하라는 건 현실적으로 어렵고 기존 Next.js 등의 투자도 커서 Deno를 추천하기엔 부담. 하지만 Deno의 장점이 드러나는 건 Deno-native, ESM-native 툴 전체로 0부터 스타트하는 환경이라고 봄. 참고로 Deno의 npm 호환성이 점점 좋아지고 있고, 2.4 릴리즈 노트에도 관련 개선 내용 있음. 풀스택 환경에서는 deno.json이 아니라 package.json 우선 접근이 오히려 더 호환성이 좋으니, 장기적으론 deno.json으로 밀어도 패키지 json 기반
            세팅도 추천
          + npm 호환 모드에서 Deno를 사용해보니 의외로 잘 동작한다는 인상. Bun의 활용 방식과 많이 비슷. package.json이 있는 디렉토리에서 deno install을 실행하면 슬림한 node_modules를 만들어주고, deno task something 명령으로 package.json에 정의된 스크립트 실행 가능. 하지만 Deno만의 방식은 시간이 많이 드는 경우가 많아 답답했고, 다시 node/npm 환경으로 돌아가려 하면 골치만 더 아픔. 결론적으로 Deno를 package.json과 함께 쓰는 쪽이 더 수월함
          + 처음엔 Deno에 올인했었지만 사소한 문제점이 너무 많아서 힘들었던 경험. 그에 비해 Bun은 별다른 신경 쓸 것 없이 잘 동작함
     * Deno의 node 호환성을 사람들이 과소평가하는 경향. compat 환경 변수 도입이 확산에 도움이 될 거라 기대. denon 등의 커맨드가 자동으로 켜주는 식이면 더 편할 듯
          + 내 경험상 Deno의 node 호환성은 기대 이하였다는 실망. 100~200라인 정도 되는 간단한 프로젝트를 Deno로 옮기는 데 1시간 정도 걸렸는데, 사실 5~10분이면 끝나야 정상이었음. node의 일부 메소드 미지원 및 관련 문서도 부실했고, 기본 기능도 obscure한 URL에서 직접 다운받아야 했음. 테스트 슈트 포팅 때는 결국 포기. 특히 CommonJS(CJS)에서 ESM 전환 과정이 생각보다 훨씬 고통스러웠고, 결코 Deno 공식 문서에서 설명하는 만큼 쉽게 전환 불가능. 전체 라이브러리 포팅 불가 경험
          + 예전엔 Deno에 꽤 긍정적이었지만, 이제는 딱히 Bun 대신에 Deno를 쓸 이유를 못 느끼겠음
     * Deno의 최근 변화 리스트가 좋다는 평. 랜덤 스크립트/글루 코드 작성용으로 Deno를 만족스럽게 사용 중이며(머신러닝 등은 python/uv 활용), 향후 gRPC 지원과 번들 커맨드에도 기대
     * 아직도 Deno가 FreeBSD에서 제대로 안 되는 게 신기하다는 이야기. Rust 기반 V8 바인딩이 아직 포팅이 안 됨
          + 현대 자바스크립트 개발자 중 FreeBSD 유저가 사실 얼마나 되는지 궁금
          + 예전에는 유닉스 간 이식성이 코드의 청결함 척도였는데, 요즘은 다양한 유닉스 시스템 간 호환성이 별로 강조되지 않아 당황
          + FreeBSD용 포트에는 등록되어 있는 것으로 보임
          + FreeBSD 지원에 큰 노력을 안 들이는 이유는 충분히 납득 가능
     * Deno가 프로덕션에서 더 널리 쓰이지 않는 이유가 표준화된 취약점 DB 부재라는 의견. npm 100% 호환성으로 보완은 가능하지만 그럴 경우 대다수 인기 deno 패키지가 범위에서 빠져버림. 근본적으로 중앙 패키지 매니저가 없다는 점(의도된 설계)이 챌린지임. 관련 진전이 있었는지 질문
          + 만약 취약점 DB 부재가 정말 프로덕션에서는 큰 문제가 된다면, C/C++도 똑같이 못 쓸 것이라는 반론. 실제로 C/C++은 언어 중립적인 CVE/GHSA DB 등을 참고해서 보안 이슈 체크함. 참고로 C는 그냥 외부 파일을 베닝해서 쓰고 버전 추적도 안 하는 경우가 많음. 또 ""deno.lock"" 파일이 있어서, 신경 쓰는 사람은 여기에 의존하여 사용하는 버전으로 취약점 DB 체크 가능함
          + URL(GitHub 등)에서 직접 패키지 가져오는 구조는 Go도 비슷하므로, 동일한 이슈가 Go에도 적용됨
     * bundle 서브커맨드가 다시 추가된 점이 마음에 듦. 번거로운 우회 방법이 필요 없어 만족
     * 번들 작업에 Rust 기반 Rolldown이 아닌 esbuild를 채택한 게 의외. Rolldown은 이제 곧 v1 될 예정인데
          + esbuild는 현재 매우 안정적이고 성숙한 반면, Rolldown은 아직 빠르게 변화 중이므로 esbuild 선택이 더 무난
     * Deno의 방향성이 정말 마음에 들고, Node가 원래 이렇게 나왔어야 했다는 생각. 다만 걱정되는 점은 경쟁사들의 '하입'에 휩쓸려 Deno까지 변화 없이 따라가는 것
          + Deno 자체가 그동안 Node.js의 '하입' 기반 경쟁자로 인식됐던 것 같기도 함
     * Deno에 대해 좋은 평가를 계속 듣고 있음. 덕분에 js를 한번 써볼까 하는 생각도 들기 시작
          + 요즘이라면 처음부터 TS로 가는 것도 괜찮은 선택
     * 보안 관점에서 Deno를 응원하지만, 공식 사이트에서 사용자에게 'curl mywebsite.com/foo.sh | sh' 형식 설치를 권장하는 부분이 꺼림칙했던 경험 공유. 물론 위험 허용 수준은 다르지만, 최소한 파일을 다운받고 실행하면 본인이나 안티바이러스가 점검할 수 있음. Node/Deno + npm 생태계는 기본적으로 상당한 신뢰가 필요한 구조. 공식 가이드에서 'curl | sh' 외에 'npm install -g deno' 옵션도 제공하는데, npm은 그래도 최소 파일 무결성 체크와 간단한 악성코드 검사가 있어 상대적으로 안전. deno.land 웹사이트도 codebase 수준으론 안전해도 운영 측면에선 100% 장담 불가하므로, 'curl | sh'는 보안 모범 사례가 아니라고 봄
          + 이 논리에 공감하지 않는 입장. 대부분의 설치 스크립트는 결국 같은 저자가 만든 수백~수백만 줄의 바이너리를 받아와 실행하는 역할. 만약 저자를 아예 신뢰 못해서 서버가 특정 IP만 악성코드 뿌릴 수 있다고 가정할 정도면, 아예 바이너리 수준에서도 악성코드 심을 수 있으니 애초에 그 프로젝트를 쓰면 안 된다고 봄. 'curl | sh' 논쟁이 널리 퍼진 건 쉽고 반복하기 쉬운 논거라서 그런 것 같고, 오히려 수백만 줄의 코드 리뷰가 진짜 보안 문제. 만약 정부 기관의 MITM 공격까지 걱정할 수준이면 애초에 인터넷 외부 신뢰를 끊는 수밖에 없음
          + 신규 유저 온보딩에 어려움이 있다는 지적. npm 사용하라고 권장해도 npm이 먼저 설치되어 있어야 하는데, npm 공식 사이트는 nvm 설치를 알려주고, nvm조차 'curl | sh'를 사용함. 그래서 결국 npm 접근도 간접적으로 같은 문제
          + npm install -g deno가 curl | sh보다 실제로 더 안전한지에 대한 논의에서, 핵심은 'npm 서버와 자체 서버 중 해커가 더 쉽게 침투할 수 있는 쪽은 어디인가?'에 달림. 만약 자체 서버 침투가 아니라고 확신할 수 있으면 curl | sh가 npm install보다 덜 안전할 이유도 없음. 결국 보안 관점에서 보면 이 두 방법 다 동일하게 취약할 수 있어서, 극단적으로 접근하면 인터넷을 사용하는 자체가 문제
          + Deno의 샌드박스 구현이 90년대 기술 느낌이라며, 사용 자체가 좋은 보안 습관은 아니라는 비판
          + 실제로 curl | sh 설치 방식의 공격이 실전에서 성공한 사례가 있는지 궁금
"
"https://news.hada.io/topic?id=21926","SETI@home 논문이 통과되어 저널에 출판될 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     SETI@home 논문이 통과되어 저널에 출판될 예정

     * SETI@home에 관한 논문 두 편이 2025년 6월에 통과(accept)되어 과학 저널 《The Astronomical Journal》에 게재될 예정
          + ""SETI@home: Data Acquisition and Front-End Processing"": SETI@home의 데이터 기록기, 분할기, 클라이언트 프로그램을 설명하며, 또한 탐지 유형 5가지, 각 유형의 매개변수 및 통계, 그리고 이를 찾는 알고리즘을 다룸
          + ""SETI@home: Data Analysis and Findings"": SETI@home의 백엔드(Nebula)와 그 결과(RFI 제거, 후보 탐지, 순위 결정)를 설명하며, 또한 알고리즘 최적화와 전체 감도 추정에 인공 신호(또는 '괴상함(birdy)')를 어떻게 사용했는지를 설명함
     * 현재 중국에 위치한 FAST 관측소에서 Nebula가 발견한 상위 92개 후보 천체를 재관측하는 작업이 진행 중
     * 논문의 결론은 세 가지로 구성
          + 다른 프로젝트와 달리 SETI@home이 새롭게 수행한 일
          + 만약 SETI@home을 처음부터 다시 시작할 수 있었다면 고쳐야 할 점
          + 미래의 전파 SETI 프로젝트, 특히 천체 조사 프로젝트에 남기는 교훈
     * 논문이 출판됨으로써 SETI@home에 투입된 방대한 자원봉사자들의 노력(과 전기 요금, 탄소 배출량)에 목적과 의미를 부여할 수 있게 됨
     * 저자에게 있어서 이번 논문은 원본 SETI@home 개발에 15년을 투자한 후 BOINC를 개발하고 SETI@home을 BOINC에 포팅하는 과정을 망라하는 25년간의 힘든 노력에 깊은 만족감을 주는 결론
     * (칼 세이건의 《창백한 푸른 점》 에세이만 봐도 알 수 있듯이) 인류는 지구가 허공을 떠돌면서 느끼는 고독을 초월하기 위해 지능을 가진 다른 생명체를 열렬히 찾는 데 전반적으로 열망이 있음.
     * ""SETI@home은 백만 명의 사람들이 함께 우주로 손을 뻗어 다른 지성을 찾기를 희망하는 프로젝트입니다. SETI@home은 어쩌면 헛된 시도일지 모르지만, 인간이 이룬 수많은 노력 중에서는 전례없는 일입니다. 이 점을 되새겨보고, 우리가 함께 이룬 성취에 자부심을 느낍시다(I think of SETI@home as a million people reaching out together into space, hoping to find other minds. SETI@home is perhaps quixotic, but it's unparalleled among human endeavors. Let's reflect on this, and be proud of what we accomplished together)"".

   요즘 SETI 보드게임 때문에 SETI 관련된 것들을 찾아보기도 했는데 이렇게 뉴스로 보니 또 반갑네요

   SETI 보드게임 정말 재미납니다. 보드게임 잘 모르시는 분들에게도 추천하고 싶어요.
   SETI 자체를 모르는 젊은 친구들한테 프로젝트 소개부터 하니 배경도 흥미롭고, 게임 테마도 찰떡입니다 .
   2025년작 보드게임이 현재 전체 보드게임 순위중 43위까지 올라갔으니, 조만간 10위 안쪽에 들거 같아요.
"
"https://news.hada.io/topic?id=21853","AI 에이전트 개발을 멈추고, 더 똑똑한 LLM 워크플로우를 써라","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  AI 에이전트 개발을 멈추고, 더 똑똑한 LLM 워크플로우를 써라

     * LLM 기반 시스템을 만드는 대부분의 팀 모두가 에이전트(Agent)부터 만들려고 하지만, 대부분은 복잡성, 조정 불가, 디버깅 난이도로 인해 쉽게 무너짐
     * 기억, RAG, 도구 사용, 워크플로 제어가 모두 필요한 진짜 에이전트 패턴은 실제론 드물고, 대부분의 문제는 단순 워크플로우(체이닝, 병렬화, 라우팅 등) 로 더 효과적으로 해결 가능
     * 현실에서 유용한 5가지 LLM 워크플로 패턴을 먼저 적용할 것을 권장하며, 에이전트는 정말 필요할 때만 신중하게 사용할 것
          + 프롬프트 체이닝, 병렬화, 라우팅, 오케스트레이터-워커, 평가자-최적화
     * 에이전트가 필요한 경우도 결국 사람의 관여와 명확한 제어, 관측 가능성(Observability) 이 핵심임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI 에이전트, 정말 필요한가?

     * Netflix, Meta, 미국 공군 등 다양한 엔지니어 및 팀에 LLM 시스템 구축과 관련한 컨설팅 및 교육을 제공하는 Hugo Bowne-Anderson의 통찰
          + 그는 Building LLM Applications for Data Scientists and Software Engineers 라는 교육 과정을 운영함

잘못된 시작: 왜 모두가 에이전트에 집착하는가

     * 많은 팀이 LLM 프로젝트 시작 시 에이전트, 메모리, 라우팅, 툴 사용, 캐릭터성 등 복잡한 구조를 우선적으로 도입함
     * 실제로 구성해보면, 에이전트 간 협업, 도구 선택, 장기 메모리 등 다양한 부분에서 지속적인 이상 동작과 실패가 빈번하게 발생함
     * 예시로 CrewAI 기반 연구 에이전트 프로젝트에서 각 역할(리서처, 요약자, 코디네이터)이 예상된 만큼 협력하지 못하고 속수무책으로 무너짐을 경험함

에이전트란 무엇인가?

     * LLM 시스템의 4가지 특성: 메모리, 정보 검색(RAG), 툴 사용, 워크플로 제어
     * 마지막 워크플로 제어(LLM이 다음 단계 또는 도구 사용 여부를 직접 결정)는 에이전트적 특성이라 불림
     * 실제 대부분의 업무에서는 단순한 워크플로(체이닝, 라우팅 등) 가 더 높은 안정성을 보임

에이전트 대신 써야 할, 실전에서 유용한 LLM 워크플로 패턴

  1. 프롬프트 체이닝(Prompt Chaining)

     * 설명: 여러 작업을 일련의 단계(체인)로 분할하여, 각 단계를 순차적으로 LLM이 처리하도록 설계함
     * 예시: LinkedIn 프로필에서 이름, 직함, 회사 정보를 추출 → 해당 회사의 추가 정보(미션, 채용 등) 추가 → 프로필+회사 정보를 바탕으로 맞춤형 이메일 작성
     * 장점: 각 단계가 명확히 분리되어 있어 버그 발생 시 쉽게 원인 추적/수정 가능, 디버깅과 유지보수에 유리함
     * 가이드라인:
          + 순차적으로 연결되는 태스크에 적합
          + 한 단계라도 실패하면 전체 체인이 무너질 수 있음
          + 작은 단위의 작업으로 분할하면, 예측 가능한 결과와 쉬운 디버깅 가능

  2. 병렬화(Parallelization)

     * 설명: 여러 독립적인 작업을 동시에 실행하여 전체 프로세스의 속도를 높임
     * 예시: 여러 명의 프로필에서 각각 학력, 경력, 스킬 등 여러 항목을 병렬로 추출해 전체 처리 시간 단축
     * 장점: 독립적 데이터 추출/처리 등에서 대규모 데이터에도 효율적, 분산처리 환경과 잘 어울림
     * 가이드라인:
          + 각 작업이 상호 독립적이고, 동시에 실행하면 전체 속도가 크게 향상됨
          + 병렬 실행 중 race condition, 타임아웃 등 예외 상황에 주의 필요
          + 대량의 데이터 처리, 여러 소스 동시 분석에 적합

  3. 라우팅(Routing)

     * 설명: 입력 데이터를 LLM이 분류(classification)해서 각각에 맞는 워크플로로 자동 분기
     * 예시: 고객지원 도구에서 입력 내용이 제품 문의, 결제 이슈, 환불 요청인지 분류 후 해당 워크플로로 자동 처리, 유형이 모호하면 기본 핸들러로 전달
     * 장점: 입력 유형별로 전문화된 처리 로직을 적용해 다양한 케이스를 깔끔하게 분리
     * 가이드라인:
          + 서로 다른 입력 유형/상황별로 별도 처리가 필요할 때 활용
          + 경계 케이스나 예외 상황에서는 라우팅이 실패하거나 빠짐 현상 발생 가능
          + 미분류/예외 상황을 위한 catch-all 핸들러 반드시 설계

  4. 오케스트레이터-워커(Orchestrator-Worker)

     * 설명: 오케스트레이터 역할의 LLM이 작업을 분해/판단해 워커(실행 LLM)에게 세부 작업을 위임, 전체 흐름과 순서를 직접 제어함
     * 예시: 타깃 프로필을 tech/non-tech로 분류 → tech라면 전문 워커에게 이메일 생성 위임, non-tech라면 다른 워커에게 위임
     * 장점: 의사결정(분류/판단)과 실행(개별 처리) 분리, 동적 플로우 제어와 확장에 유리
     * 가이드라인:
          + 각 태스크마다 전문적 핸들링이 필요한 경우, 복잡한 분기와 단계별 조율에 적합
          + 오케스트레이터가 태스크를 잘못 분해하거나 위임하면 전체 플로우에 오류 발생
          + 로직을 명시적으로 단순하게 유지하고, 위임/순서/종료 조건을 명확히 설계

  5. 평가자-최적화(Evaluator-Optimizer)

     * 설명: LLM이 결과물을 평가하고(스코어/피드백), 기준에 미달하면 반복적으로 수정/개선하는 구조
     * 예시: 이메일 초안 생성 → 평가자가 품질 점수/피드백 → 일정 기준 이상 만족/최대 반복 횟수 초과시 종료, 아니면 다시 수정
     * 장점: 최종 산출물의 품질을 목표 수준까지 반복 개선 가능, 정량적 기준 활용에 유리
     * 가이드라인:
          + 속도보다 품질이 중요한 상황, 반복 최적화가 필요한 워크플로에 적합
          + 종료 조건이 없으면 무한 반복에 빠질 수 있음
          + 명확한 품질 기준과 반복 제한 설정 필수

에이전트가 정말 필요한 경우

     * 사람의 실시간 개입(Human-in-the-loop)이 보장되는 환경에서 에이전트가 진가를 발휘함
          + 예시1: 데이터 사이언스 보조 - SQL 쿼리, 시각화, 데이터 분석 추천 등에서 LLM이 창의적으로 시도하고, 사람이 결과를 판단/수정
          + 예시2: 크리에이티브 파트너 - 문구 아이디어, 헤드라인 제안, 텍스트 구조 추천 등에서 사람의 방향 수정과 품질 심사가 핵심
          + 예시3: 코드 리팩토링 조수 - 디자인 패턴 제안, 에지 케이스 탐지, 코드 최적화 등에서 개발자가 승인/보완
     * 특징: 에이전트가 “모든 걸 알아서” 처리하는 게 아니라, 사람이 실시간으로 오류/방향을 잡아주는 환경에서 가장 효과적

에이전트가 적합하지 않은 경우

     * 엔터프라이즈·미션 크리티컬 시스템(금융, 의료, 법률 등):
          + 자동화의 신뢰성·결정론적 동작이 중요하므로, LLM 에이전트가 판단하는 구조는 위험
          + 오케스트레이터, 라우팅 등 명확한 제어 패턴을 활용해야 함
     * 안정성과 예측 가능성이 중요한 모든 상황
          + 비정상적 사례: 에이전트가 맥락/메모리 없이 도구 선택을 반복적으로 잘못하거나, 분업/조정이 실패해 전체 플로우가 무너지는 문제
     * 실무에서 빈번하게 발생하는 에이전트 시스템의 실패 요인
          + 명시적 메모리 시스템 미설계로 맥락 누락
          + 도구 선택 제약 부족(불필요한/잘못된 툴 사용)
          + 자유로운 위임 구조만 의존해 협업 조정 실패

실무 설계 시 교훈

     * 에이전트 도입 시에도 “완성도 높은 소프트웨어 시스템” 수준의 설계·관측성·제어 체계가 반드시 필요
     * 복잡한 에이전트 프레임워크보다, 관측 가능성(Observability), 명확한 평가 루프, 직접 제어 가능한 구조로 설계하는 것이 더 빠르고 안전함

결론(TL;DR)

     * 에이전트는 과대평가/과잉 활용되는 경우가 많음
     * 대부분의 실전 과제는 단순 워크플로 패턴이 더 적합
     * 에이전트는 “사람이 직접 관여하는” 환경에서 진가 발휘
     * 안정적 시스템에선 오히려 위험 요소
     * 관측 가능성과 명시적 제어, 반복 평가 구조로 설계할 것

     * 복잡한 에이전트 프레임워크 대신, 관측성, 명확한 평가 루프, 직접 제어 가능한 구조로 설계하는 것이 실제로 더 빠르고 안전한 LLM 기반 서비스 개발의 비결임

   저도 현재 UseDesktop

   https://youtu.be/aBkbsvMxP_A?si=uaugxKQEu4ZEz7jq

   usedesktop.com

   이 라고 Computer-use Agent를 만들고 있는데, 대부분 동의 합니다.

   이 글에서는 실질적 팁이라기보다는 그냥 크게 overview만 다뤄서, LLM based agentic/agent를 개발할때 팁을 몇가지 더 추가하자면, 결국 LLM은 트포머(i.e probablistic based 추론, 현재 토큰/state 기반 다음 토큰을 문맥상/semantic하게 이해하고 다음 단어를 내뱉는게 아닌 확률적으로 아웃풋하는) 기반이라, 아무리 sys prompt를 잘해줘도, 자주 원하는 답변을 안주는 경우가 많아요(e.g JSON output으로 답변을 달라하는데, 가끔 } 를 빼먹는 다거나 등) 그래서 항상 regex기반 여러 fallback fn을 추가하는건 필수입니다.

   그리고 structured output을 주는 sys prompt를 짜면 보통 non reasoning model을 사용하시고, context가 길면 길 수 록 할루시네이션이 자주 발생하여서 차라리 sys prompt를 여러개 만들어 체이닝 하는게 더 좋아요.

   서비스를 개발하는경우 여러 에러가 발생할 수 있기에, 모듈화 , fault tolerant하게 서비스 구조를 설계하는게 핵심입니다(e.g supervisor agent를 async하게 하고 나머지 agent들은 sync), 특히나 unexpected output이 자주 발생하는 agentic , agent들은요.
   그래서 처음부터 최대한 코드를 짤때 SRP를 지키며 declarative하게 짜는게 좋아 함수형으로 접근하는게 좋다고 얘기하고 싶습니다(=side effect가 없고, 플로우가 직관적)

   그리고 LLM을 API를 통해서 사용 하는지 아니면 직접 모델 서빙을 할건지에 따라 다르겠지만, 만약 직접 SLM이나 LLM을 서빙할꺼면 백엔드를 호스팅 하는 같읔 서버에 Model serving을 하지말고, IO bound task랑 CPU bound tasks(i.e gpu required, mat mult같은거 필요한 task)를 따로 다른 서버에 두는게 fault tolerant하고 좋습니다(e.g runpod에 cpu bound task 호스팅).

   이 외에 여러 개발 팁이 더 있는데 길이 너무 길어질까봐 여기까지만 적을게요

   누군가에게 도움이 됐으면 좋겠네요

   소증한 경험과 의견 공유해주셔서 정말 감사드립니다. 이렇게 현장에 계신 분의 의견이 정말 도움이 많이 됩니다.

        Hacker News 의견

     * 에이전트 개발이 정말 재미있었음, 하지만 ‘컨텍스트 엔지니어링’에서 심각한 문제가 있음이 명확함. 아무리 컨텍스트 윈도우를 키워도 에이전트가 볼 요소를 큐레이션 해야 되고, 정말 중요한 정보만 골라주는 효과적인 필터가 부족하다고 느낌. 그래서 *.md 파일을 이곳저곳에 흩뿌려두는 방식으로 도와야 하고, 역할 배정도 중요함. 이 *.md 시스템은 일종의 원초적인 기억 시스템이고, 훨씬 더 견고하게 발전시킬 수 있음. 사용자의 상호작용을 바탕으로 실시간으로 프로그램이나 모델(자연어 기반)을 만들어내는 것도 가능하다고 생각함. Claude Code를 이용하면서 테스트 스위트로 에이전트를 ‘조종’하는 게 정말 강력한 강화 학습 메커니즘임을 깨달았고, 이 루프가 대부분 성공적으로 이어져서 앞으로 에이전트를 더 똑똑한 협업자로 만들 수 있는
       새로운 아이디어가 나오길 기대함
          + 실제 작업보다 툴과의 싸움에 더 많은 시간을 쓰는 것 같아지는 느낌임
          + 이런 시스템에서 .md 파일을 구성하는 추천 방법이 있는지 궁금함. 사람이 읽기 쉽게 마크업을 많이 넣으면 llm이 처리하는데 문제가 되지 않을까 걱정임. 사람이 읽는 용도와 동일하게 .md 파일을 만들었을 때 llm 사용에 방해가 되지는 않는지 알고 싶음
          + 내가 경험해보니 컨텍스트 관리가 거의 모든 문제의 핵심임. 예를 들어 병렬/재귀적인 작업에 맞는 올바른 컨텍스트 만들기, 일부 단계(예: 이전 응답 편집)는 빼고 수정된 결과만 보여주기, 내가 코멘트를 달았을 때 해당 코멘트로 에이전트가 본인 출력을 인식하게 만들기 등등 실제로 여러가지 상황이 존재함
          + 테스트 스위트로 에이전트를 강화한다는 부분이 흥미로움, 구체적으로 어떤 절차로 진행하는지 좀 더 자세히 설명해줄 수 있는지 궁금함
     * AI 에이전트가 사람들이 LinkedIn에서 말하는 것처럼 대중적으로 쓰일지 아직 확신이 없지만, 그 가능성은 열어두고 있음. 나는 지금 Claude Code, Cursor처럼 AI를 강하게 통제하며 사용함. 이유는 모델이 부족해서가 아니라, 직접 ‘테이스트’와 방향을 자주 제시하고 싶어서임. AI에게 더 많은 자율성을 주는 게 오히려 매력적이지 않음, 내가 개입해야 정체성과 연결감을 느낄 수 있기 때문임. 앞으로 작업 방식이 바뀌거나 새로운 UX가 생긴다면 생각이 변할 수 있지만, 현재로선 AI가 너무 에이전트스러운 것을 원하지 않음
          + 시간이 지나 모델의 행동 방식을 잘 알게 되고, 더 많은/더 나은 컨텍스트와 지침만 주면 사용자의 테이스트와 방향성 요구를 어느 정도 채울 수 있다고 생각하는지 궁금함. 내 경험으로는 잘 만든 프롬프트 엔지니어링만으로도 상당수 워크플로우에서 AI가 원하는 대로 동작하게 할 수 있어서, 자주 개입하지 않아도 될 때가 많음
          + 정확히 공감함. 내가 다른 곳에서도 비슷한 댓글을 남겼는데, ‘공짜 점심은 없다’는 옛말이 여전히 맞다고 생각함. LLM이 인간을 아예 빼고서도 문제를 해결할 수 있다면, 몇 줄의 프롬프트만으로 모두가 똑같은 정교한 시스템을 만들 수 있다는 얘기이고, 그때는 시스템마다 차별점이나 가치가 사라짐. 만약 프롬프트가 새로운 추상화 수준이라면, 예를 들어 Claude에게 “노트 앱을 만들어줘”라고 할 때, 수백만 명의 사람이 동일한 저비용 프롬프트를 입력하게 되고, 이때 프롬프터가 더하는 의미가 도대체 무엇인지 의문임
          + 내가 생각하기엔 시간이 지나면서 이런 각각의 ‘테이스트’ 요소들도 프롬프트로 점점 체계화할 수 있을 것 같음. 예를 들어 하나의 프롬프트로 코드 변경 때 불필요한 가변성을 만들지 않고, 이미 가능하면 immutable로 작성하도록 유도함. 또 하나의 프롬프트로는 쓸모없는 로그 작성 피하기(내가 구체적으로 정의한 방식) 등 맞춤법을 세움. 코드 변경을 리뷰할 때 이 모든 프롬프트들을 개별적으로 실행하여 구조화된 MCP 출력물로 모아봄. 이런 부분들을 코드-에이전트에 적용해 자동화된 리뷰 반복을 실현함. 만약 직접 컨텍스트를 추가해야 하는 상황이 생기면, 새 프롬프트를 만들거나 기존 프롬프트를 확장해서 보강함
     * 신기하게도 경력이 1~2년밖에 안될 것 같은 분야에 ‘권위자’가 등장하는 현상이 재미있음. 마치 ‘2년 된 언어에서 10년 경력자 찾는 밈’의 뒤집은 버전 같음
          + 나는 GPT-3가 나왔을 때부터 ‘ai agent'라 불리는 것을 만들어왔고, 나 말고도 많은 사람이 같은 경험을 했음. 벌써 5년이나 됐는데, 만약 5년 동안도 전문가가 안 탄생하면 그건 이제 전문가 자체가 없는 거라고 생각함. 물론 요즘 ‘에이전트’란 단어가 버즈워드로 변해가서 의미가 퇴색되고 있음
          + 막상 “난 수십 팀과 같이 일했다...”라는 식의 경험담을 읽으면 좀 극적이라고 느껴지는 반응임
     * 핵심 요약: 미리 정의된 솔루션이 있다면 굳이 에이전트를 쓸 필요 없음(예: 기사에 등장한 '패턴’). 보통 프로그래머는 프로그램으로 풀 수 있는 문제에 대해 더 단순하고 신뢰할 수 있는 해결법을 추천함. 미래에는 AI가 정말 똑똑해져 아무 문제나 다 브루트포스로 해결하겠지만, 지금은 복잡성만 늘릴 뿐임. 사람들이 에이전트에 열광하는 이유 중 하나는 대부분 챗 어시스턴트 용도로 LLM을 접했기 때문이라 생각함. 이런 챗 어시스턴트는 정해진 해결법이 없고 상호작용이 복잡한 경우가 많아서 오히려 에이전트가 진가를 발휘함. 예: “가장 가까운 금요일 저녁 찾아서 Bob에게 만날 수 있냐고 문자 보내줘”—이런 건 미리 모든 경우를 프로그래밍하기엔 한계가 있음. 어시스턴트와의 상호작용 방법이 무한에 가까워져서 에이전트가 적합해짐
          + 확인 속도가 스스로 직접 하는 것보다 더 빠를 때 아주 잘 작동함. 다만 나는 검증 없이 AI를 신뢰하기 어렵다는 점이 있음
     * 왜 이렇게 많은 예시가 결국 “스팸을 빠르게, 더 잘 보내는 방법”으로 귀결되는지 의문임
          + 진짜 그게 예시 아니었냐는 생각이 듦. LinkedIn을 크롤링해서 사람 찾아내고, ‘개인화된’ 이메일로 스팸 보내기 식임
          + 바퀴는 결국 기름 없이는 안 굴러간다는 것에 비유할 수 있음
     * 2023년 말 ~ 2024년 초에는 맞는 말이었지만, 이제 mid 2025즈음엔 SOTA LLM을 쓰면 많은 작업에 해당하지 않는다는 생각임. 예전엔 대부분 함수로 LLM을 부르는 식이었지만, 그건 잘못된 도구 선택 때문이기도 했음. 요즘 최상위 LLM(Gemini 2.5 Pro, Claude 4 등)은 정말 똑똑해서 ‘인스트럭션 팔로잉’과 툴 선택 능력이 매우 좋아졌음. 체크리스트 툴이나 delegate 명령, 작업 분할 등은 여전히 필요함. 하지만 지침 만들고 명령어 지정하는 방식—특히 UI 환경에서 툴 커맨드를 쉽게 지정할 수 있다면—이 워크플로우보다는 유연하고 한 단계 높은 추상화임. 시각적 워크플로우도 결국 이는 부서지기 쉽고, 조정하기 까다로운 프로그래밍임. 6~12개월 전엔 이런 게 불가능했지만, LLM이 좋지 않다면 아직 해당하지 않음. 크게 봐서 instruction following과 툴 연동을 잘하는 모델이
       소수라서 이런 모델에 에이전트를 적용하는 게 유리함. 앞으로 1~2년 내에 브라우저/컴퓨터 활용 에이전트의 대규모 트렌드가 생길 것임. 이들도 좋은 메모리 시스템과 ‘시연/관찰 모드’를 접목하여 사용자가 UI를 이용하는 과정을 학습(녹화)하게 될 것이고, 인간의 구두/문서 지시로부터 최적화된 프로시저도 학습할 것임
          + 최근 가장 강력한 에이전트 모델(Claude Opus 4 등) 이 등장하면서 상황이 완전히 달라짐. 여전히 좋은 컨텍스트가 필요하지만, 정말 툴에 대한 정확한 선택이 훌륭함
          + 원본 포스팅의 기법들은 대부분 '데이터 플로우 그래프로 문제를 모델링하고 그대로 따라가는 것**임. 모델링을 뛰어넘어 ‘알아서 잘하겠지’ 식으로 접근하면 그건 공학이 아니라 신앙임
     * 지난 3주간 에이전트를 안정적으로 작동시키려고 노력했지만, 결국 훨씬 간단한 패턴으로 전환하게 됨. 지금의 에이전트들은 마치 ‘여섯 손가락 달린 손’처럼 진화 초기 단계로 느껴짐
     * “코디네이터가 작업 정의가 명확하지 않으면 포기한다” 같은 걸 보고 “그럼 코디네이터도 버리고 명령형 로직으로 가라” 결론을 내는 경우, 사실은 프롬프트나 툴 설명을 더 구체적으로 써주고, 중간 요약이나 LLM 컨텍스트 압축 같은 절차를 넣어주면 해결될 문제일 수도 있다고 생각함. 기사에 실제로 사용할 만한 장문의 툴 설명/프롬프트 예시조차 없으면 판단이 쉽지 않음. 직관적으로 작업에 맞는 오케스트레이션을 활용하는 게 답이지만, 실제로는 훨씬 많은 작업에서 에이전트적 오케스트레이션이 효과적으로 쓰일 수 있다고 믿음
     * 나도 100% 동의함. 에이전트는 정말 재밌고 실험하기는 좋지만, 실제 생산성을 높이려면 특정한 워크플로우와 프로세스를 잘 오케스트레이션하고, AI로만 할 수 있는 부분에 집중하는 것이 핵심임. 참고로 ai.intellectronica.net의 AI 워크플로우에 대한 글도 추천함
     * 요즘 자주 보는 현상은, 기존의 워크플로우 오케스트레이션 툴에 LLM을 도입해 훨씬 쉽게 시스템을 빌드한다는 점임. 복잡성의 대부분이 a) 모델 자체(최신 연구소가 쉬운 모델 제공), b) 워크플로우 프로덕션화(워크플로우 툴이 쉽게 해줌)임. 이러한 워크플로우는 기존 업무에 기반을 두기에 가치를 쉽게 인식하고 측정함. 이런 패턴이 많아져서 Airflow(아주 인기 있는 워크플로우 툴)용으로 아예 SDK를 패키징하여 공개함.
       https://github.com/astronomer/airflow-ai-sdk

   한달 전에 CURSOR를 활용해서 AI코딩이 뭔지 배울겸, 개발프레임워크 개발 착수했습니다.

   3주정도 성공과 AI Agent에 의해 검증되었던 소스코드가 망가지는 것을 반복하며, 온갖 방법을 동원하여 AI Agent를 통제하려 노력하였으나, 실패하였습니다.

   그러다가 개발프레임워크 개발 이전에 AI Agent 통제하는 소스코드를 개발하는 것이 우선인 것을 깨달았습니다.

   결국 첫 AI가 뭔지 알아보려고 시작한지 만1개월만에 AI Agent를 완벽히 통제 (정확하게는 외부 LLM이나 AI Agent가 필요없는) AI 에의한 100% 구현 + 100% 운영 가능한 소프트웨어를 개발완료 하는 성과를 달성했습니다.

   지금은 14일째 추가적인 고도화를 위해 그 META AI를 추가 교육하면서 운영 규정을 만들어 지키게 하는 과정을 진행중이고, 기존 사람에 의해 불완전하게 만들었던 MES 시스템 3개를 동시에 마이그레이션과 개선 그리고 표준화를 진행 중이고 마무리 단계에 접어든 상태입니다.

   그리고 지금 또다른 진화를 준비 중입니다.

   그런데 프롬프트 체이닝에서 개별 프롬프트를 실행하는 LLM, 실행 워커, 오케스트레이터 워커, 평가자 LLM 등등을 각각 에이전트라고 불러도 무방한 거 아닌가요?

   아 ""마지막 워크플로 제어(LLM이 다음 단계 또는 도구 사용 여부를 직접 결정)는 에이전트적 특성이라 불림"" 라는 게 있군요. 이해했습니다. autonomous agent를 타겟팅해서 얘기한 글이군요. 제가 에이전트에 대해 아직 잘 몰라서...
"
"https://news.hada.io/topic?id=21868","다양성이 조직을 삼킬 때 — 불교적 관점에서 본 리더십의 긴장","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   다양성이 조직을 삼킬 때 — 불교적 관점에서 본 리더십의 긴장

   실력은 있지만 변화와 성장을 거부하는 팀원, 어떻게 해야 할까?

   개발팀의 다양성을 존중하면서도 성과 중심의 문화를 지키려는 리더에게 필요한 건 단호함일까, 이해일까?

   불교의 연기법 개념을 통해, 리더십과 조직 운영의 균형점을 모색한 에세이.

   변화와 성장을 구분하는 것부터 시작해야 할 것 같네요.

     리드를 하면 딱 좋을 것 같은데 이러한 추가적인 역할은 거부했다.
     필자가 성장을 위한 새로운 도전을 제안하면 ...

   기술자 입장에선 잘하는 일을 더 잘하는게 성장이 아닐까요?

   더 많은 책임과 업무에 비해 성장하지 않는 급여 수준과 처우를 생각했던건 아닐까 싶네요
"
"https://news.hada.io/topic?id=21924","RapidRAW - GPU 가속 및 비파괴 방식의 RAW 이미지 에디터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                RapidRAW - GPU 가속 및 비파괴 방식의 RAW 이미지 에디터

     * RapidRAW는 GPU 가속과 비파괴 편집을 지원하는 경량 RAW 이미지 에디터
     * Rust, React, Tauri 기반의 최신 기술로 제작되어 Windows, macOS, Linux에서 30MB 미만의 크기로 동작
     * AI 기반 마스킹, 비파괴 패치 방식의 생성형 편집, 다양한 RAW 카메라 포맷 지원 등 강력한 기능을 제공
     * 배치 작업, 내장 프리셋, 커스텀 테마, Undo/Redo 등 생산성을 위한 다양한 워크플로우도 지원
     * 젊은 개발자가 개인 사진 작업을 위해 만든 오픈소스 프로젝트로, 빠른 반응성과 사용성에 초점을 둠
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

RapidRAW 오픈소스 프로젝트의 의의와 장점

     * RapidRAW는 Adobe Lightroom, Darktable, RawTherapee 등 기존 툴보다 훨씬 경량, 빠른 반응, 단순한 설치가 가능한 GPU 가속 RAW 에디터
     * Rust와 React, Tauri를 조합하여 크로스플랫폼 데스크톱 애플리케이션을 최소 용량(30MB 미만)으로 제공
     * 특히 생성형 AI 통합, 빌트인 마스킹, 비파괴 사진 보정 워크플로우는 동급 경쟁 툴 대비 속도와 확장성, 실시간성에서 강점을 가짐

주요 기능 요약

     * 핵심 편집 엔진
          + GPU 가속 처리: 모든 편집 작업이 GPU(WGSL 셰이더)에서 즉각적으로 처리되어 실시간 반응성을 보장함
          + AI 마스킹: SAM 기반 AI로 피사체, 전경을 자동 선별하며, 브러시·선형·방사형 마스크 등 정밀한 마스킹 결합 가능
          + 생성형 편집: 텍스트 지시어로 객체 제거/삽입 등의 비파괴 패치 편집 제공(ComfyUI 백엔드 연동)
          + RAW 포맷 다양 지원: rawler 사용으로 광범위한 RAW 카메라 포맷 읽기 지원
          + 비파괴 워크플로우: 원본 파일 미변경, .rrdata 사이드카 파일에 편집 내용 저장
          + 32비트 색상 정밀도: 밴딩 및 데이터 손실 최소화 보장
     * 전문가급 보정 툴
          + 톤 컨트롤: 노출, 콘트라스트, 하이라이트, 섀도우, 화이트, 블랙 등 세밀 조절
          + 톤 커브: Luma, R, G, B 채널별 개별 커브 제공
          + 컬러 그레이딩: 온도, 틴트, 생동감, 채도, 전체 HSL 믹서
          + 디테일 강화: 샤프닝, 클리어리티, 구조, 노이즈 제거 등
          + 효과: 디헤이즈, 비네트, 리얼한 필름 그레인
          + 변환 툴: 자르기(비율 잠금), 회전, 반전 등
     * 라이브러리 및 워크플로우
          + 사진 라이브러리 관리: 전체 폴더 트리, 정렬, 평점, 삭제, 복제 등 효율적 사진 관제
          + 배치 작업: 대량의 이미지에 동일 편집 일괄 적용, 대량 내보내기
          + EXIF 뷰어: 카메라 메타데이터(셔터, 조리개 등) 열람
     * 생산성 및 UI
          + 프리셋 시스템: 나만의 스타일 저장/불러오기 및 공유 지원
          + 설정 복사/붙여넣기: 편집값 빠른 전파
          + Undo/Redo 히스토리: 모든 단계 저장/복구
          + 사용자 UI 커스터마이징: 리사이즈 패널, 다양한 테마와 애니메이션 효과
          + 내보내기: JPEG, PNG, TIFF, 품질, 크기 옵션 제어

RapidRAW 제작 동기와 개발 과정

     * 개발 배경
          + 기존 사진 편집 소프트웨어의 저성능, 무거움에 불편함을 느낀 개발자가 더 빠른 워크플로우와 반응성을 위해 직접 툴을 제작
          + 개발 도전 자체가 목표였으며, Rust/React/Tauri 학습 및 디지털 사진 처리 기술 습득을 함께 추구함
     * 기술적 접근과 개발 방법
          + Rust로 핵심 엔진 작성, Tauri로 경량 웹 프론트엔드 접목
          + 전체 이미지 처리 파이프라인을 GPU 오프로딩(WGPU, WGSL 사용)
          + Google Gemini AI를 통한 알고리듬 학습 및 구현(예: Menon demosaicing)
          + 빠른 구현 및 핵심 구조/사용성 집중으로 2주 만에 핵심 기능 완성

현재 개발 우선순위

     * React 프론트엔드 리팩토링(Prop Drilling 최소화)
     * 이미지 45° 이상 회전 지원
     * 디헤이즈 툴 자연스러운 결과 개선
     * 이미지 전송 Base64 대체 등 성능 최적화
     * Segment Anything 기반 AI 마스크 기능 탑재
     * ComfyUI 기반 생성형 AI MVP 통합
     * macOS 빌드 서명, RAW 파일 로더 고도화
     * 구형 GPU에서의 속도 개선
     * 자동 화이트 밸런스/노출 감지 추가 예정

AI 로드맵

     * 내장 AI 마스킹: Meta SAM 등 경량 오픈소스 AI로 피사체·전경 인식, 오프라인 즉시 사용
     * 옵션 생성형 AI: ComfyUI 연동으로 인페인팅 등 무거운 작업을 외부 서버에서 처리, 본체 경량성 유지
     * 현재: 내장 마스킹은 전 기능 사용 가능, 생성형 AI는 ComfyUI를 수동 설치해야 하며 개발자 프리뷰 상태
     * 생성형 AI 기술 통합 방식
          + 모듈형 백엔드: ComfyUI 로컬 서버와 연결해 추론 엔진 역할
          + Generative Replace: 마스크 지정 후 텍스트로 영역 생성, 패치 레이어로 비파괴적 적용
          + 동작 흐름: 이미지, 마스크, 지시어 → ComfyUI 서버 → 보정 이미지 반환 → 패치 레이어로 적용
          + 본 애플리케이션은 항상 경량/빠른 본연의 경험을 유지함

라이센스 및 오픈소스 철학

     * RapidRAW는 AGPL v3 라이센스로 공개되어, 파생 제품도 모두 오픈소스로 남게 함
     * 닫힌 소스 상용화 방지를 통해 모든 개선사항이 모두에게 돌아가는 구조를 유지
     * 커뮤니티 중심 기여 활성화와 오픈 혁신을 지향함

        Hacker News 의견

     * 내가 아는 최고의 RAW 이미지 프로세싱 툴은 RawTherapee임, 색상 과학에 엄청 열정적인 사람들이 만든 느낌이고 CLI로 스크립트도 가능함, 동반문서인 RawPedia는 DCP 프로필 생성이나 캘리브레이션, 다크 프레임, 플랫 필드 같은 기초 지식을 배우기에 진짜 보물창고임, 이름의 ""raw""만 봐도 전문가들의 손길이 느껴짐 (""raw""는 약자가 아님에도 WASM처럼 흔히 착각되는 부분이라 약간 언급함), 단점이라면 많은 기술적인 부분이 그대로 드러나기에 ""illuminant"", ""demosaicing method"", ""green equilibration"", ""CAM16"", ""PU"", ""nit"" 같은 익숙하지 않은 용어들이 가끔 나옴, 나는 오히려 이런 대목이 좋아서 쓰는 중임, 한 가지 아쉬운 점은 HDR 출력 지원이 부족한데, PNG v3와 Rec. 2100 지원이 추가되면 해결될 것으로 기대 중임
          + RawTherapee의 프로세싱을 좋아하지만 딱 한 가지 예외가 있음, Darktable의 ""filmic"" 에뮬레이션이 정말 환상적으로 노출 오버된 RAW 파일을 복구해줌, 몇 번의 클릭만으로 전체 장면을 한두 스톱 어둡게 옮길 수 있음 (RAW 안에는 실제 데이터가 많음), RawTherapee에서 이 기능과 비슷한 도구를 못 찾아봤는데 혹시 아는 사람이 있으면 알려줬으면 함
          + 사진 후처리에서는 기술적인 디테일보다는 좋은 UX, 부드러운 멀티포토 워크플로우, 직관적인 컨트롤이 훨씬 중요하다고 경험적으로 느꼈음, RawTherapee가 Darktable보다는 낫다고 생각함, 하지만 그 차이가 압도적인 것은 아니고, 많은 사람들이 Lightroom을 유료로 쓰는 데에는 다 이유가 있다고 봄
          + RawTherapee가 전반적으로 훌륭하지만, 크기 조절 곡선(커브) 인터페이스가 정말 치명적으로 불편함, Lab 컬러 조절 기능 자체는 환상적인데 슬라이더들 때문에 제대로 미세 조정이 불가능하고, 개별 슬라이더나 포인트 리셋이 안 되고, 마지막 동작만 따로 취소도 불가능함, 전체 위젯 초기화만 가능해서 거의 쓸 수 없는 수준임, 만약 이 부분만 고쳐준다면 인기가 급상승할 거라고 확신함, 나도 분명 Lightroom을 바로 떠날 의향 있음, FabFilter의 오디오 플러그인 Pro-Q3가 이런 인터페이스 면에서는 금표준이니, 커브 인터페이스를 만든다면 꼭 데모를 써보라고 적극 추천함
          + 로컬 조정 기능이 너무 어려움, 지원하는 게 예전 방식의 ""Nik u point""밖에 없음, 이 이유만으로도 Darktable을 쓰고 있음, 그래도 RawTherapee의 듀얼 일루미넌트 DCP를 사용하고 싶음(이건 Darktable에는 없음)
          + RawTherapee 깃허브 저장소임
     * RapidRAW 앱 출시 축하함, 내가 찾던 딱 그 앱임, m1 맥에 설치해서 RAW 폴더를 열었더니 썸네일 로딩 때 전체 맥북이 엄청 버벅거림, 썸네일이 다 뜬 뒤에는 그나마 나아졌지만 기대했던 만큼 부드럽지는 않음, 상용 앱들은 왜 렉이 걸리지 않는지, 혹시 네이티브 코드로 작성된 게 이유인지 궁금함
          + RapidRAW가 CPU로 720px JPG 썸네일을 생성하고 있음(관련 코드1), 그리고 이를 base64로 인코딩해서 Rust에서 JavaScript로 보내는데, 공유 버퍼를 쓰지 않고 이미지 데이터를 여러 번 복사함(관련 코드2), 네이티브 앱들은 이런 식으로 base64로 한 번 더 옮기지 않음, react에서 base64 디코딩하고, webkit 거쳐서 다시 뷰에 보여주고... 한 이미지에 대해 6배 정도 메모리를 중복 사용하는데(각 단계별: 러스트 raw, 러스트 base64, 러스트의 tauri용 json base64, JavaScript json base64, JavaScript base64, 그리고 마지막에 webkit에서 raw image), 이런 부분들이 네이티브 대비 느린 주된 원인임
          + RapidRAW 사용해줘서 고맙고 피드백도 감사함, 지금은 1~300장의 작은/중간 크기 폴더를 최적화했음, 사진이 많은 폴더에서는 랙이 발생하는 것이 현재는 정상임, 대용량 폴더 로딩 속도는 최우선 과제로 빠르게 개선할 예정임, 며칠 내로 개선될 거라 기대해도 좋음, 항상 고마움 -Tim
          + Ansel(https://ansel.photos/en/)이나 Darktable(https://www.darktable.org/)을 아직 안 써봤으면 추천함, 둘 다 오픈 소스 RAW 편집 앱 중에서 성능이 괜찮은 편임, 이 RapidRAW도 성능이 비슷하거나 경쟁력이 있을 수 있는데 아직 직접 써보진 못했음, 다만 ansel과 darktable은 M1에서 잘 작동함
     * Capture One이 정말 과소평가받는 앱이라고 생각함, 사용법도 쉽고, PhaseOne 카메라도 안 써봤지만 어쨌든 좋았음
     * 지켜보고 싶은 프로젝트임, 나에게 가장 필요한 기능을 꼽으라면 루미노시티 마스킹이 꼭 있었으면 함, 이 기능이 없는 RAW 에디터로 다시 돌아가는 게 힘듦, 물론 이것만이 마스킹의 전부는 아니지만(예: 컬러, 채도 마스킹 등) 포토샵 열지 않고 바로 쓸 수 있으면 엄청 유용함, AI 기반 셀렉션 마스킹 워크플로우가 이미 구현돼 있는 점도 마음에 듦
     * Readme에 시각적 개요가 풍성해서 좋았음, 많은 GUI 프로그램 Readme가 이런 비주얼이 부족하거나, 링크로만 안내하는 경우가 많음, 하지만 GIF로 하나당 10~22MB 정도라서, 오히려 본 프로그램 전체 용량보다 더 큼, 비디오로 임베딩하면 더 가볍고 편할 것 같음
     * 내 생각에는 이미지 에디터처럼 리소스 요구가 큰 앱에 웹 기반 UI 쓰는 건 좋은 아이디어가 아닌 것 같음, 속도도 느리고 리소스도 많이 들 것임
          + color.io를 참고해보라고 추천함, 컬러 그레이딩 중심 앱이지만 RAW 사진 워크플로에도 다양한 기능을 제공함, 오프라인에서 브라우저로 실행되는데 내 오래된 PC에서 RawTherapee나 Darktable보다 훨씬 빠름
          + 이 앱은 흔히 생각하는 ""웹"" 앱 방식과는 달리 rust와 GPU 처리를 매우 적극적으로 사용함, 웹 브라우저로 실행되지만 실제론 성능이 다름
     * 메타데이터 저장 방식에 대한 정보를 찾지 못했음, 기존 오픈 소스 RAW 에디터처럼 RAW 파일 하나마다 섀도우 파일을 두는 시스템인지 궁금함, 섀도우 파일이 많으면 클라우드 싱크가 힘든데 하나의 큰 카탈로그 파일로 가는 것도 선택지임, 또 메타데이터 포맷이 개방형이라서 다른 프로그램으로 편집을 옮길 수 있는지도 알고 싶음, 매달 Lightroom에 돈 쓰지 않아도 되는 대안이 나와서 다행임, 나는 여행 등 연휴 때만 RAW를 편집하는 유저임
     * 사용하기 쉬운 RAW 에디터가 진짜 필요함, 예전에는 Darktable을 오래 썼고, 기본값 세팅만으로도 카메라 JPEG과 거의 흡사한 이미지를 바로 얻었음, 원하는대로 방향만 바꿔주면 되었음, 그런데 업데이트가 반복되면서 피부색 조정이 너무 힘들어짐, 지금은 CaptureOne을 불법으로 쓰고 있지만 사실 오픈 소스나 합리적 가격의 정식 소프트웨어를 선호함, 기본 카메라·렌즈 프로필이 내장되어 있는지 궁금함
     * Windows 10과 AMD RX 6900 XT에서 돌려보았더니, 6000x4000 크기의 DNG 파일에서는 윈도우 드래그나 슬라이더 조정조차도 상당히 느림
     * 오늘 막 Rust로 RAW 이미지 썸네일을 만드는 방법이 궁금해서 바로 이 저장소를 살펴보고 있었음, 신기하게도 완전한 우연임
"
"https://news.hada.io/topic?id=21933","M4 Pro Mac mini의 저장 용량을 반값에 업그레이드하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  M4 Pro Mac mini의 저장 용량을 반값에 업그레이드하기

     * M4 Pro Mac mini의 내부 스토리지를 직접 업그레이드해 애플 공식 업그레이드 비용의 절반 이하로 4TB로 확장한 경험 공유
     * M4-SSD라는 업체의 $699 4TB DIY 업그레이드 키트를 사용해, 기존 512GB SSD를 저렴하게 고용량으로 교체 가능함
     * 업그레이드 과정은 노트북 분해 경험이 있다면 어렵지 않지만, 바닥 커버 분리와 파워 버튼 커넥터 분리 과정에 주의 필요함
     * DFU(디바이스 펌웨어 업데이트) 복원이 필수이며, Apple Silicon 맥뿐만 아니라 일부 Intel T2 맥에서도 복원 과정 지원함
     * 업그레이드 결과 내장 SSD 쓰기 속도가 향상되고, 일관성 있는 고속 성능을 제공해 애플 공식 SSD 대비 가성비가 뛰어남
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

업그레이드 개요

     * 몇달전 ExpandMacMini 의 $269 DIY키트로 M4 Mac mini의 1TB → 2TB 업그레이드를 했음
     * 그 당시엔 M4 Pro Mac mini는 사용자 교체 가능한 탈착식 저장 장치를 사용함에도 불구하고, 공식 옵션 외 자체 업그레이드가 불가능했음
     * M4-SSD가 업그레이드 키드를 출시하면서 M4 Pro Mac mini 512GB → 4TB를 진행 했음
     * M4 Pro는 표준 2242 NVMe보다 긴 전용 슬롯을 사용하며, M4 모델은 2230 크기와 유사한 더 짧은 슬롯 구조임
     * SSD 카드에는 플래시 칩과 전원 회로만 있고, 스토리지 컨트롤러는 SoC에 통합되어 있음

업그레이드 과정 및 주의점

     * 업그레이드 자체는 비교적 간단하지만, 바닥 커버 분해 과정에서 알루미늄 긁힘, 플라스틱 파손, 파워 버튼 커넥터 손상 주의 필요
     * Torx 드라이버 등 iFixit 기본키트 정도의 소형 공구만 있으면 분해 가능
     * M4 Mac mini의 저장공간 구조는 표준 NVMe와 달리 컨트롤러가 SoC에 내장되어, 교체 후 반드시 DFU 복원이 필요함
          + 이 과정은 M1 이후 맥 또는 T2 칩이 있는 인텔 맥에서도 진행 가능
          + 맥 미니의 중앙 썬더볼트 포트에 연결, 파워 버튼 누른 상태로 전원 연결, 연결 맥에서 'Allow this device' 창 확인 후 DFU 복원 진행
          + Hackintosh 등 비공식 장비로는 DFU 복원 불가

성능 비교

     * 업그레이드한 4TB SSD는 기존 대비 쓰기 성능이 확실히 향상(플래시 칩 개수 증가로 인한 분산 효과)
     * 읽기 속도는 큰 차이 없고, 파일 사이즈 및 액세스 패턴에 따라 미세한 차이만 있음
     * 외장 Thunderbolt 5 NVMe 드라이브도 빠르지만, 장시간 대용량 복사 시 잠시 속도 저하 현상 발생(내부 DRAM 캐시 한계)
     * 내장 SSD는 장시간 고속 복사에도 일관된 속도를 유지함

결론 및 가격 비교

     * M4-SSD의 4TB 업그레이드 키트(약 $699)는 표준 4TB NVMe SSD($200~400)보다는 비싸지만, 애플 공식 업그레이드($1,200) 대비 매우 합리적임
     * 내장 스토리지 확장을 고려하는 사용자에게 실질적 대안이 될 수 있음

참조 링크

     * YouTube 영상 업그레이드 과정
     * iFixit 업그레이드 가이드
     * DFU 복원 가이드

   제가 저 Technojoy 제품으로 업그레이드 해서 2달 사용하다가, 알 수 없는 이유로 SSD 가 사망했는데, 별도의 AS 를 받지 못하고 날렸습니다. 참고차 후기 남겨봅니다.

   고민끝에 지금은 iBoff 제품으로 구매하여 사용중인데, 아직은 큰 문제가 없네요.

        Hacker News 의견

     * SSD 속도는 정말 기적 같은 느낌임. 예전에는 데스크탑 케이스 하나에 16개의 HDD를 스트라이핑해서 간신히 1GB/s 속도를 얻곤 했음. 그 시절에는 8개의 드라이브가 들어간 인클로저 2개가 필요했고, 4RU 대형 인클로저는 파워서플라이와 팬 소음이 엄청났음. 그런데 이제는 손톱만한 SSD 하나로 5GB/s 이상의 속도를 내고, 케이블 하나로 데이터와 전원을 모두 해결쌤. 4K 영상도 이제 카메라에서 촬영한 메모리에서 바로 편집 가능해서, 예전처럼 긴 시간 동안 소스 복사과정 기다리지 않아도 되어 현장에서 DIT 담당자로 오래 남아 있어야 했던 시간에 비하면 세상 좋아졌음. 그리고 예전 16드라이브 RAID도 겨우 4TB쯤이 한계였던 기억 있음. 내가 처음 썼던 7베이 RAID-0 인클로저는 간신히 Avid의 AVR75 인코딩만 처리 가능한 수준이었고, 오디오까지 같이 저장하면 속도가
       모자라서 오디오는 따로 외장 드라이브에 저장했었음. 요즘 SSD를 쓰는 건 마치 파워업 받은 기분임
          + 최신 NVMe의 레이턴시는 정말 경이로움(20~30마이크로초까지 가능). NVMe는 SAS, SATA보다 훨씬 빠른데, 그래서 개발자들에게 NVMe 스토리지 위에서 SQLite를 꼭 써보라고 추천함. 퍼포먼스가 압도적임. 호스팅된 SQL 솔루션에서는 아무리 최적화해도 20마이크로초 쿼리 속도는 보기 힘들 것 같음
          + SSD가 그 자체로 엄청 빠르다기보다, 사실 많은 경우 램 캐시와 TLC를 SLC처럼 보이게 해주는 여러 가지 트릭 덕분임. 대부분의 저가형 SSD는 이 트릭 한계에 도달하면 성능이 뚝 떨어짐
          + 빈티지 맥을 복원하기 시작하면서 이 이야기가 더 와닿음. SSD로 업그레이드 가능한 신형 맥에선 정말 속도의 차이가 엄청나서, 파워맥 G4도 단순히 드라이브만 바꿔도 신제품처럼 느껴질 정도임. 파워북, 클래식 맥 같은 올드맥도 SD/CF카드를 IDE/SCSI로 변환하는 어댑터가 많아서 효과를 보긴 함. 다만 예전 작은 하드에서 들리던 소음의 향수는 사라지는 점이 아쉬움
          + 지금은 단종된 Intel Optane, 특히 p5800x를 꼭 써보라고 추천하고 싶음. 운영체제를 Optane에서 구동 중인데 체감 성능이 정말 대단함
          + 예전에 16개 HDD로 스트라이핑해서 1GB/s 뽑던 시절, 이런 구성은 얼마나 빨리 드라이브 교체가 필요했는지 궁금함
     * 애플이 왜 A/M 시리즈 칩에 SSD 컨트롤러를 통합하는지 기사에서 추측하는데, 사실 데이터 무결성이 가장 큰 이유임. 약 15년 전에 애플은 엔터프라이즈용 SSD 컨트롤러 회사의 특허를 5억 달러에 인수했음. Anobit이라는 회사로 신호처리 기술과 ECC로 NAND 신뢰성, 보존성을 높였고, 셀의 전압 드리프트를 감지해서 주기적으로 리프레시하거나 인접 셀의 특성을 이용하는 등의 다양한 방법을 적용했음. 이 노력들 덕분에 NAND 수명과 신뢰도 크게 개선 가능하게 됨
       관련 기사
          + 진짜 데이터 무결성이 중요하다면 APFS에 사용자 데이터까지 체크섬을 넣어야 한다고 생각함. RAID가 없으면 깨진 데이터를 복구하진 못해도 적어도 문제를 인지해서 타임머신 등에서 복원할 수 있을 것임. 메타데이터는 복수본을 저장해서 안전하게 처리하는데, 이건 ZFS와 비슷함.
            APFS는 메타데이터에만 체크섬을 적용하고, 사용자 데이터는 스토리지 하드웨어의 ECC만으로 신뢰성을 보장하는 방식임
            관련 문서
          + 애플이 ZFS를 맥OS의 기본 파일 시스템으로 도입하려다 중단한 것도 얼마 안 된 일임. 오라클의 Sun 인수와 소송 문제, 그리고 점점 하드디스크 대신 플래시로 넘어갈 걸 예견한 것도 큰 이유였을 것임
          + 내구성만이 아니고 성능도 강점임. 애플은 SSD 컨트롤러까지 수직적으로 통합해서 훨씬 뛰어난 스택을 가짐
          + 실제로 애플 SSD가 다른 제조사보다 내구성, 신뢰성이 월등하게 좋은지 궁금함. 내가 관련 특허나 신호처리 전문가는 아니지만 예전에 SSD 컨트롤러와 NAND 만든 경험이 있는데, 비슷한 아이디어는 대부분의 제조사에서 이미 적용 중이었음
          + 최신 플래시 컨트롤러라면 다들 사용량에 따른 수학적 처리와 신호 보정을 적극적으로 하고 있음. 요즘 NAND는 온갖 수학으로 버티는 기술임
     * 램과 저장장치 업그레이드가 불가능한 현재 시스템은 너무 비합리적임. M4 맥 미니 출시 당시 32GB 램/1TB 저장장치 모델이 16GB/512GB 모델의 두 배였는데, 이걸 보면 애플이 기기 나머지는 그냥 끼워주고 저장장치와 램에만 돈을 책정하는 느낌임
          + 유튜브에 Doctor Feng이라는 사람이 있음. 사람들이 엔트리급 iPhone, iPad, MacBook Pro 등을 그에게 보내서 4TB, 8TB로 SSD를 업그레이드함. 그 과정을 ASMR 영상으로 제작함.
            예전 Mac Pro를 예로 들면, 8TB SSD가 필요해서 견적을 보니 애플은 1TB 기본에 추가로 7TB 올리는데 $3,000을 요구했음. 대신 4개짜리 M.2 카드와 2TB 삼성 Pro SSD 4개를 $1,300에 구입해서 직접 장착했음. 기본 1TB 시스템 SSD가 6.8GB/s로, 새로 추가한 SSD보다도 빨랐음.
            메모리도 OWC가 애플과 제조사, 스펙 다 똑같은 메모리를 팜. 애플은 160GB 메모리 업그레이드에 $3,000을 받는데, 나는 $1,000이면 충분했음
     * 사전예약 기간에 구입했는데 SSD가 과열로 망가져 처음 한 개는 교체 받음. 이번 주에 새로 받은 걸 설치했는데, 앞으로 괜찮길 기원 중임. 중요한 내용은, 판매처가 SSD에 아무런 보증을 제공하지 않는다는 것임. 나는 운 좋게 1년 보증 조건으로 샀지만, 지금은 아예 없는 듯. $700이면 꽤 큰 리스크임. 참고로 Pro 지원 안 하는 SSD도 처음엔 비쌌지만 시간이 지나면서 가격이 떨어졌으니 Pro용도 좀 기다리면 가격 낮아질 수 있다고 봄
     * 4TB에 $700이면 정말 대낮에 강도 당한 기분임
          + 블로그 원문에서 본문 인용하면, $699짜리 4TB SSD 업그레이드는 일반 4TB NVMe SSD($200~400)에 비해서도 엄청 비쌈
          + 이런 문화 때문에 애플 기술을 좋아하긴 해도 업무상 필요한 경우가 아니면 개인적으로는 리눅스, 윈도우, 안드로이드만 씀
            관련 링크: The Cult of Mac
          + 그래도 비교하면 덜 털리는 게 많이 털리는 것보단 낫다고 생각함
          + 커스텀 소량 하드웨어는 어쩔 수 없이 비쌈
     * 복잡하게 손대지 말고 그냥 애플에 추가 비용을 내는 게 시간 대비 이득임. 내 시간이 훨씬 소중함. 만약 그렇지 않다면 그게 더 문제임
          + 시간 가치가 더 중요하다고 하는데, 마치 테크 업계에 있으면 다들 억대 연봉 받는 분위기 같음. 만약 진짜로 따진다면 시간당 최소 천 달러쯤은 벌어야 할 듯함
          + 30분 작업에 $500 정도면 꽤 즐겁게 업그레이드할 수 있다고 생각하는데, 실제로 직접 업그레이드했다가 몇 주 만에 SSD가 고장나서 몇 시간 더 소비한 경험도 있음
          + 이런 조언도 일리는 있지만, 난 차라리 공구 꺼내서 실제 기기를 직접 분해하는 재미를 즐김
          + 애플은 기존 제품의 저장장치를 공식적으로 업그레이드해주는 서비스가 없음. 추가 비용을 내도 사후 업그레이드는 안 해줌. 이런 정책 때문에 결국 John Deere, Microsoft처럼 반독점 조사 받을 거라고 예상함
     * 엄마의 Mac mini 2014가 너무 느려서 거의 쓸 수 없는 지경이 되었었음. 하드 교체가 굉장히 어려웠지만, 우연히 외장 플랩 아래에 NVMe를 이식할 수 있는 어댑터를 찾음. 결과적으로 신세계를 경험할 만큼 빨라졌음(램은 8GB짜리 구입함). 하지만 애플이 의도적으로 자사 제품을 심하게 제한한 것 같아 여전히 불만임. 싼 컴퓨터도 아니었음
     * 현실적으로 외장 SSD 옵션이 대부분의 경우에 훨씬 가성비가 좋음. 가격도 절반 수준이고, 비싼 본체를 분해하지 않아도 되고, 이동성과 업그레이드도 훨씬 자유로움. 물론 3GB/s 넘는 속도가 절실한 경우가 있겠지만 USB-4 포트로도 5GB/s까지는 나오니 거의 대부분 충분하다고 생각함. 실제 대부분의 데이터는 그렇게 고속으로 처리할 일도 드물다고 봄
     * 중국에는 맥 미니 SSD를 훨씬 저렴하게 업그레이드해주는 샵들이 많음. DFU 복원까지 모두 해줌
          + 하지만 Jeff는 중국에 살지 않음
          + 미국에도 이런 샵이 가능할지, 애플이 바로 막지 않을지 궁금함
          + 업그레이드 후 미국에 돌아오면 SOC 뒷면에 새 CPC ROM이 납땜된 상태로 오기도 함
     * 4TB SSD 업그레이드가 $699인데, 이 가격이 NVMe SSD(일반 4TB가 $200~400)와 비교해 비싼 이유는 쓰이는 플래시 타입에 따라 다름. QLC가 가장 저렴하고 TLC가 약간 비싸며, MLC는 거의 구하기 힘들고 SLC는 일반적으로 매우 비쌈(QLC를 SLC로 변환하는 특별한 경우 제외)
"
"https://news.hada.io/topic?id=21877","Show GN: 바이브 코딩으로 간단한 노트 확장 프로그램을 만들어 봤습니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Show GN: 바이브 코딩으로 간단한 노트 확장 프로그램을 만들어 봤습니다

소개

   제목처럼, 바이브 코딩으로 브라우저의 Side panel에 열어서 쓸 수 있는 간단한 노트 앱을 만들어 봤습니다.
   처음에는 혼자 쓸 목적으로 시작했는데 처음 3일동안 나온 결과물을 보고 여기에 공유해봐도 좋을것 같다는 생각이 들어 일주일동안 오류수정/기능추가를 거쳐 이렇게 글을 쓰게 되었습니다.

   사용방법 및 특징으로는
     * Alt+Shift+W 단축키로 노트 앱 실행
     * 마크다운 문법으로 메모 가능
     * 더블클릭으로 Edit 창 진입, ESC나 Shift+Enter로 프리뷰 모드로 전환
     * 글작성할때 줄바꿈(줄 맨 뒤에 공백 2개 추가)를 자동으로 처리해줌 (On/Off 가능)
     * 외부 글을 붙여넣을때 줄바꿈 및 ~ 문자를 ￦~ 문자로 치환해서 글이 깨지지 않도록 처리해줌 (On/Off 가능)
     * Ctrl+V로 이미지 붙여넣기 가능
     * 원하는 노트들은 상단에 고정시켜둘 수 있음
     * 다크모드 지원

   정도입니다.

개발동기

   혹시 노트 앱을 여는 단축키를 보고 깨달으신 분이 있을지도 있겠지만, 이 프로그램은 5년 전에 개발중단된 Notes by Firefox 확장프로그램으로부터 단축키와 디자인을 포함해 많은 영향을 받았습니다.
   다만 개발이 중단된지 몇년이 지나니까 한글 입력이 이상하게 되고 파이어폭스 자체도 메모리를 크롬에 비해 많이 잡아먹어서 이와 비슷한 확장프로그램을 직접 구현해보자는게 개발 동기가 되었습니다

개발환경

   AI는 제미니 CLI와 제미니 웹페이지를 같이 이용하면서 했습니다.
   디자인이 크게 상관없는 부분은 제미니 CLI를 주로 썼고, 웹은 스크린샷을 보여주며 디자인 요소를 조정하거나 제미니 CLI가 특정한 오답에 꽂혀 함정에서 빠져나오지 못할때 주로 사용했습니다.

   두 경우 다 모델은 gemini-2.5-pro 정식버전으로 고정했고, 대시보드를 보니 제미니 CLI에서 입력한 토큰만 거의 1억토큰에 근접했습니다.

   버전관리는 git으로 해서 AI가 코드를 이상하게 망가뜨린 경우 이전 버전으로 되돌릴 수 있게 하였고, 작업할땐 명령 -> 제미니 CLI의 코드 작성 -> 제미니 CLI의 커밋 -> 수정된 코드 및 결과를 수동으로 검토 -> 명령 이 과정을 반복하였습니다.

앞으로의 계획

   우선 지금처럼 하나의 파일에 모든 자바스크립트 코드가 들어가있는 상황에서 벗어나, 여러개의 파일로 코드를 분리해서 모듈형식으로 불러오도록 해 유지보수가 편하도록 대대적인 리팩토링을 진행할 예정입니다.
   처음에는 간단한 텍스트 메모정도로 시작해서 단일파일에 코드를 다 몰아넣었던게 규모가 커지면서 코드를 읽고 직접 수정하기가 힘들어지는 문제점이 생겨나더라고요.

   그리고 추가하고 싶은 기능으로는 완전한 위지윅 메모 지원, 수식 입력 및 표기 지원, 마크다운 말고 일반 텍스트나 html 기반으로도 메모할 수 있는 기능 추가 정도가 있습니다.
   특히 위지윅 지원은 메모할때 편의성이 많히 올라갈거라 생각되어 리팩토링이 끝난 후 가장 먼저 구현을 시도해볼것 같습니다.

   그리고 시간이 나면 Firefox에서도 쓸 수 있게 포팅해서 애드온으로 올려보지 않을까 싶습니다.

마치며

   평소에 간단한 작업을 할땐 AI를 많이 이용했었지만, 이정도 크기의 작업을 AI를 메인으로 한건 처음인데 생각보다 잘 돌아가서 정말 신기했습니다.
   다만 제미니 CLI에 문제가 있는건지 gemini-2.5-pro 를 제한없이 쓰려면 API키를 넣고 쓰는만큼 돈을 내는것만 가능한데, 이 프로그램을 제작하면서 인풋으로만 거의 1억토큰이 소모되어 돈이 생각보다 많이 나온점은 아쉬웠습니다.
   캐싱이 있어서 예상금액보단 청구금액이 적긴 했지만 저렇게 많이 사용된건 예상하지 못했던 결과였기에 사용할땐 컨텍스트 요약기능을 적절히 사용해야 성능유지가 가능할거라 생각합니다.

   실사용이 가능할 정도까진 개발이 되었지만, 아직 구상한 모든 기능이 완벽하게 구현된게 아닌만큼 써보시고 질문이나 피드백할것이 있다면 가감없이 해주셨으면 합니다!

   좋은 글 감사합니다.
   혹시 1억 토근이면 비용이 어느정도 나왔는지 알 수 있을까요?

   캐싱 포함해서 9~10만원정도 나온것 같습니다.
   제미니 CLI에서 '/stats model' 명령어로 사용량을 확인했을때도 캐시 비율이 50~60% 사이여서 계산이랑도 얼추 맞더라고요.

   알려주셔서 감사합니다~!
"
"https://news.hada.io/topic?id=21940","그래픽 선형대수","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                그래픽 선형대수

     * 그래픽 선형대수는 다이어그램을 활용해 선형대수와 범주론 개념을 흥미롭게 설명하는 블로그임
     * 각 에피소드는 덧셈, 행렬, 정수, 분수, 부분공간 등 핵심 수학 주제를 시각적으로 접근함
     * PROPs, 모노이드 범주, 선형관계 등 범주론적 해석을 제공해 기존 선형대수와의 연결성을 강화함
     * 블로그는 연구자와 학생을 위한 오픈된 연구와 학습 커뮤니티를 지향함
     * 관련 외부 기고, 워크숍, 번역 프로젝트도 활발히 연계되어 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

그래픽 선형대수 소개

     * 그래픽 선형대수(Graphic Linear Algebra)는 시각적 다이어그램을 중심으로 선형대수, 범주론 등의 추상 수학 개념을 쉽게 풀어내는 블로그임
     * 핵심 목표는 수식 위주의 기존 선형대수를 벗어나, 시각적 사고와 다이어그램 논증을 통해 복잡한 개념을 이해하기 쉽게 전달하는 것임
     * 수많은 에피소드는 각기 분류별로 주요 개념, 알고리듬, 관계, 사례 연구 등을 다루며, 내용은 연구 중인 오픈 프로젝트로 지속적으로 확장 및 업데이트됨
     * 블로그는 연구자, 대학원생, 현업 개발자 등 다양한 배경의 독자를 고려한 학습과 소통의 장을 제공함

주요 에피소드 및 구조

  Introduction

     * Makélélé와 선형대수, 논증의 방법론, 다이어그램 도입 등 기초 내용을 다루는 에피소드로 구성됨

  Adding and Copying

     * 덧셈, 복사, 폐기, 규칙 정의 등 자연수와 연산의 본질을 다이어그램적 논리로 탐구함
     * Mr Fibonacci, Lego 비유 등 친근한 예시와 스토리텔링 방식이 특징임
     * 덧셈, 복사 연산이 자연수의 구조와 어떻게 연결되는지 시각적으로 보여줌

  Matrices and PROPs

     * 행렬과 PROPs(Products and Permutations categories) , 모노이드 범주 등 고차 범주론 개념을 소개함
     * 다이어그램에서 행렬로의 전환, PROPs 동형사상, 행렬의 다이어그램 표현 등 다양한 변환을 설명함
     * 이러한 범주론적 접근을 통해 선형대수의 본질과 확장성을 강조함

  Integers and Relations

     * 정수 행렬, 인과성과 피드백, 함수와 관계, Frobenius 공식 등 고급 주제를 논의함
     * 다이어그램적 방법으로 수론, 관계, 함수 및 다양한 수학적 구조를 설명함

  Fractions and Spaces

     * 분수, 부분공간, 선형관계, 역행렬, 나눗셈 불능까지 선형대수의 확장을 다양한 시각으로 접근함
     * 다이어그램을 통해 복잡한 연산, 공간의 구조화, 행렬의 역정리 등을 쉽게 해석함

  Redundancy – Jason Erbele의 3부작

     * 그래픽 선형대수 내 중복성(Redundancy) 을 중심 테마로 새로운 시각을 제시함

  Interlude – 스트링 다이어그램과 자원 민감 문법

     * 스트링 다이어그램(string diagrams) 의 의의 및 용도 강조

  Sequences and Signal Flow Graphs

     * 피보나치 수열, 신호흐름 그래프 등 시퀀스 기반 모델을 다룸

  Out of order

     * 정사영, 고유값 등의 심화 주제를 선별적으로 다룸

  Contributions

     * 외부 연구자가 참여한 행렬식 및 Lindström-Gessel-Vienot Lemma 등의 특집 기고 포함

  Offtopic

     * 대학과 연구 환경 이슈, 모노이드-모나드-카테고리 논의, 워크숍 안내 등 수학·IT 커뮤니티 소식을 가끔 다룸

학습 및 커뮤니티 안내

     * 블로그는 영어로 작성되며, 다양한 언어 번역 참여도 활발함
     * ACT(적용 범주론) 연구학교 등 오픈 연구 프로젝트 관련 정보 제공
     * 구독 및 피드백 채널 운영, 박사과정 학생 모집, 번역 프로젝트 등 참여 기회가 열려있음

특징 및 의미

     * 선형대수, 범주론, 알고리듬 교육에 있어 시각화 도구로서의 다이어그램 활용 방법을 체계적으로 탐구함
     * 수식에 익숙하지 않은 독자도 직관적 접근과 반복적 예시를 통해 복잡한 수학 구조를 이해할 수 있는 기반 제공
     * 오픈 플랫폼 지향으로 최신 연구, 기여, 네트워킹에 용이한 학습 자료임

        Hacker News 의견

     * 컴퓨팅을 상호작용 네트워크에서 대칭적인 interaction combinators로 부호화할 때, 몇몇 다이어그램들이 거의 동일한 형태임이 인상적임
       람다 계산법 관점에서 'When Adding met Copying' 글에 나온 덧셈 노드를 복제하는 모습이, (λx.x x) M 형태처럼 람다 항을 반복적으로 복제하는 것과 정확히 일치함
       자세한 내용은 이 글과 다이어그램 설명을 참고하면 좋음
     * 그래프와 교환법칙(commutativity)에 관해 처음 본격적으로 설명하는 챕터를 읽었을 때, 단순한 개념을 장황하게 설명한다고 생각했음
       그런데 나는 항상 수학 용어들 중 c로 시작하는 단어들(교환법칙, 결합법칙 등)을 잘 기억하지 못했음
       그래픽 표현을 통해 교환법칙이 무엇인지 처음으로 확실히 기억하게 되었고, 실제로 그 연결이 너무 재미있어서 소리 내 웃게 됐음
       ""x + y = y + x""라는 공식 자체는 이해했지만 그래픽 다이어그램이 이름과 함께 뇌리에 박히는 효과가 훨씬 강했음
       정말 이 설명 방식에 매료됐음
          + 그 챕터가 어디인지 궁금함
            목차(ToC)에는 없는 것 같음
     * Applicative Functors에서 일반화한 Transformers에 관한 이야기임
       머신러닝에서 Transformer는 최첨단 모델의 근간을 이루고 있으며, 원래 [arXiv:1706.03762]에서 제안됨
       이 포스트에서는 (거의) 임의의 구조–함수, 그래프, 확률분포 등–에 동작할 수 있는 일반화된 Transformer를 소개함
       행렬이나 벡터에만 국한되지 않고 다양한 구조에 적용하는 방법을 다룸
       이런 추상적인 다이어그램 방식으로 머신러닝을 탐구하는 아이디어 연작의 일부임
       자세한 내용은 여기에서 볼 수 있음
     * 이런 자료들은 정말 마음에 들지만, ""쉽다"", ""간단하다"" 같은 언어를 반복적으로 사용하는 점이 아쉬움
       설명을 읽는 도중 개념이 바로 이해되지 않아 스스로가 둔하다고 느끼는 독자에겐 오히려 더 좌절도 혹은 포기를 불러올 수 있음
       이런 단어들은 친근함을 유도하려다 오히려 역효과를 줄 수 있으니 주의가 필요함
       설명서에서 ""명백하다"", ""obvious"" 등의 단어는 절대 쓰지 않는 것이 좋음
       정말 명백한 것이라면 독자가 따로 설명서를 읽지도 않을 것이기 때문임
          + 정말 좋은 지적임
            글에서 불필요하게 명시적인 감정 표출–예를 들어 ""이 장면 때문에 내가 화가 났다""고 직접적으로 쓰는 것처럼–은 독자 입장에서 오히려 몰입감을 떨어뜨림
            전달하고 싶은 핵심을 보여주고 명확하게, 간결하게 이야기하면 독자 스스로 쉽게 이해할 수 있음
            독자에게 ""이해하기 쉽다""라고 평가를 강요하기보다는, 다양한 수준의 독자가 도전을 감내할 수 있음을 기대하는 시각이 좋음
            완전히 모든 독자가 간단히 이해하기란 거의 어렵기 때문에, 가능한 한 쉽고 명확하게 전달하되, 독자마다 받아들이는 난이도가 다를 수 있음을 받아들이는 자세도 필요함
          + ""이 증명은 자명하므로 생략함""이라는 익숙한 암묵의 관습도 떠오름
     * 이 자료가 나왔을 때 정말 즐겁게 읽었고, 학생들과 함께 팔로우하기도 했었음
       하지만 지금은 중단된 듯해서 아쉬움
          + 누가 이 자료를 썼는지 궁금함
            파웰(pawel)... 같은데 확실하지는 않음
     * ""인터넷이 가르쳐 준 것은 인간 + 익명성 = 불쾌함""
       내가 좋아하는 격언 중 하나인데, Penny Arcade의 만화를 보면 더 공감할 수 있음
     * 몇 년 전 이 자료를 몇 개 챕터 읽었을 때, 다이어그램 표현이 논리적 추론에서 얼마나 강력한지 처음으로 깨달았음
       내가 string diagrams(스트링 다이어그램)으로 뭔가 실용적인 걸 하진 않았지만, 이 시스템으로 가능한 일들을 보는 즐거움이 정말 컸음
          + 나도 비슷한 깨달음을 3Blue1Brown의 Calculus(미적분학) 시리즈를 보면서 경험했음
            학교에서 이렇게 시각적 자료로 미적분을 가르쳐줬다면 이해력과 흥미가 훨씬 더 커졌을 거라는 생각임
            시각적 표현이 이해를 끌어올리는 데 얼마나 큰 힘이 되는지 새삼 놀라웠음
     * 이 내용을 완전히 이해한 적은 없지만, zx-calculus를 떠올리게 함
       ZX-calculus 소개(wiki)
     * University of Oxford의 Bob Coecke가 양자 프로세스(quantum processes)에 대한 그림 언어를 고안한 연구가 생각남
          + ZX-calculus는 위에서 언급되기도 했음
            더 궁금하면 Hacker News의 해당 스레드도 참고하면 좋음
     * Immersive Linear Algebra라는 자료도 추천하고 싶음
       Immersive Linear Algebra 홈페이지와 Hacker News 스레드(여기)로 가면 더 자세히 볼 수 있음
"
"https://news.hada.io/topic?id=21957","Show GN: llms.txt Generator","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Show GN: llms.txt Generator

   사이트 주소만 넣으면 llms.txt를 생성해 주는 서비스 입니다.

   주요 기능
     * 원 클릭 llms.txt 파일 생성
     * llms.txt 파일 다운로드 기능
     * 친절한 gif(?) 동봉

   llms.txt 자체가 나온지 얼마 안되어서, 실제 GEO가 좋아질지, 유의미한 효과가 있을지는 아직 미지수 입니다. 그래도 10초 만에 만들 수 있게 제공하면, 한번씩 쉽게 테스트 해보고 시도해 보실 수 있지 않을까? 하는 생각에 만들어 보았습니다.

   저도 제 개인 블로그를 대상으로 해봤는데..
   https://www.ggoban.com
   golang을 쓰긴하지만 주는 아니고, 해당 사이트 내 없는 주소도 마음대로 생성하네요.. 미묘합니다 미묘해...

   @ifmkl 개선을 해봤는데요, 한번 써보시겠어요?

   전보다 훨씬 정확하게 생성되네요! 다만 도메인에서 cname, 이나 alias는 제대로 확인 못하는 것 같습니다. 제가 dns 에 www 는 A record 가 아닌 cname 설정을 해뒀는데, www를 붙인 주소에서는 에러가 발생했고, www를 제외한 주소로 요청해서 정상으로 확인 됬습니다.

   예외 케이스 제보 및 피드백 감사 드립니다. 다양한 케이스들 좀 더 고민해봐야겠군요. (얘도 AI에게 고민을 시켜야지ㅎㅎ)

   저희 연애 상담 서비스는 전혀 엉뚱한 이야기만 나옵니다.
   https://www.redate.co.kr

  @tensun 개선을 해봤는데, 한번 다시 해보시겠어요?

럽디 (Luvd): 연애 및 재회 상담

     럽디는 이별, 재회 등 연애 문제에 대한 전문적인 상담과 콘텐츠를 제공하는 플랫폼입니다. 진단지 제출, 칼럼, 커뮤니티, 유료 상담 등을 통해 사용자들이 관계 문제를 해결하도록 돕습니다.

  주요 서비스 (Main Services)

     * 상담 신청: 유료 전화 상담 및 긴급 상담 서비스를 제공합니다.
     * 진단지 제출: 카카오톡 채널을 통해 이별 상황을 진단받을 수 있는 양식을 제출합니다.

  콘텐츠 (Content)

     * 칼럼: 이별 후 심리, 재회 방법, 연애 갈등 해결 등 다양한 주제의 전문가 칼럼을 제공합니다. (예: 단호한 여자 잡는 법, 생각할 시간을 갖자는 심리 등)
     * 커뮤니티: 사용자들이 익명으로 자신의 연애 고민을 나누고 질문하는 Q&A 게시판입니다.
     * 후기: 상담 및 서비스 이용 후기를 확인할 수 있습니다.

  고객 지원 (Customer Support)

     * 자주하는 질문 (FAQ): 상담 절차, 환불 규정 등 자주 묻는 질문에 대한 답변을 제공합니다.
     * Beginner/Customer Guide: 신규 및 기존 고객을 위한 서비스 이용 안내 가이드입니다.

   시험삼아 제 블로그로 해봤는데 전혀 언긎하지도 않은 pandas 분석에 대한 내용이 나오네요..ㅎ
   https://jsty.tistory.com

  Recent Articles

     * Spring Boot Basic Setup: A tutorial on setting up a basic Spring Boot project.
     * Introduction to Data Analysis with Pandas: An introductory guide to data analysis using Python Pandas.
     * Understanding Gradient Descent: Explaining the core concept of gradient descent in machine learning.

   어제 급하게 뭘 바꿨는데 성급했나보네요(그리고 테스트는 덜 했죠ㅠ), 집 가서 얼른 고쳐보겠습니다 😭

  @jic5760 개선을 해봤는데요. 한번 해보시겠어요?

지돌이의 블로그 (Jidori's Blog)

     '지돌이(Jidori)'의 개인 기술 블로그로, 개발, 운영, 하드웨어 분석, 개인 프로젝트 등 광범위한 주제를 다룹니다. Spring, Go, Kubernetes, Node.js와 같은 최신 기술 스택부터 임베디드 시스템, 보안, 펌웨어 분석까지 깊이 있는 글들을 제공합니다.

  개발 및 운영 (Development & Operations)

     * [개발 트렌드 분석] 위시켓 분석: Gemini Pro를 이용한 위시켓 프로젝트 타이틀 분석.
     * QEMU 에서 UEFI+CSM(Legacy) boot 사용하기: 최신 EDK2에서 제거된 CSM 기능을 구버전 EDK2와 SEABIOS를 통해 QEMU에서 사용하는 방법.
     * synology-csi fio 테스트: Synology NAS 환경에서 CSI 드라이버를 이용한 FIO 성능 테스트 결과.
     * ubuntu 24.04 에서 한글키가 잘 안먹힐 때: setxkbmap 명령어를 이용한 우분투 24.04 한영키 입력 문제 해결 방법.
     * Node.JS Stream Backpressure 처리: Node.js에서 스트림의 backpressure를 처리하는 과정 설명.
     * Spring-boot 관련 트러블슈팅: Zuul, OAuth2, WebSocket 등 스프링 부트 사용 시 발생했던 다양한 문제 해결 기록.

  내가만드는것_만든것 (Personal Projects)

     * G2B 입찰 공고 검색/알림 서비스: 조달청 나라장터 입찰 공고를 키워드로 검색하고 알림을 받을 수 있는 웹 서비스.
     * WhereNow: 앱 없이 브라우저로 위치 공유: 별도의 앱 설치 없이 웹 브라우저를 통해 실시간으로 위치를 공유하는 서비스.
     * 주택 (전세) 자금 대출 계산기: 여러 대출 상품을 조합하여 최소 이자를 계산해주는 웹 애플리케이션.
     * local-tls-proxy: 로컬 개발 환경에서 모든 포트를 자동으로 HTTPS로 프록시해주는 도구.
     * ping-watcher: 네트워크 단절을 감지하기 위해 여러 서버에 순차적으로 ping을 보내고 결과를 InfluxDB로 전송하는 Go 기반 유틸리티.

  Optional

    분석 및 보안 (Analysis & Security)

     * [번역] BLS12-381 For The Rest Of Us: 암호학 관련 기술 문서 번역.
     * N604M 펌웨어 분석/수정: iptime 공유기 N604M 모델의 펌웨어를 binwalk로 분석한 내용.

    임베디드 (Embedded)

     * [라즈베리파이] PWM Audio 개조하기: 라즈베리파이의 PWM 오디오 출력 회로를 개조하여 음질을 개선하는 과정.
     * 라즈베리 터치스크린 구현 (Non X환경): X-Window 환경이 아닌 곳에서 터치스크린을 구현하고 좌표를 보정하는 방법.

    공지 및 기타 (Notices & Etc)

     * 영어 블로그 개설: 기술 콘텐츠를 영어로도 제공하기 위해 개설한 미러 블로그.
     * 티스토리 본문 중 태그 자동 링크 걸기: DOMContentLoaded 이벤트를 활용해 블로그 본문 내의 특정 키워드를 태그 페이지로 자동 링크하는 JavaScript 스크립트.

   오 실제 글까지 읽나보네요!
   잘 나왔습니다! 멋있는 작업 이에요 +1

   감사합니다! 댓글로 피드백 주셔서 저도 개선하는데 큰 도움이 되었어요!

   예시 llms.txt - news.hada.io
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Hada News: Korean Developer News Aggregator

     Hada News is a community-driven news aggregation platform, specifically tailored for Korean software developers and IT professionals. Inspired by Hacker News, it features a curated stream of trending articles, active technical discussions, and job postings relevant to the Korean tech industry, fostering a central hub for information and community engagement.

  Main Sections

     * 뉴스 (News): The primary feed displaying trending and popular articles submitted by the community.
     * 새글 (New Posts): A chronological listing of the most recently submitted articles.
     * 댓글 (Comments): Provides access to recent and ongoing discussions across various articles.
     * 채용 (Jobs): A dedicated section for job opportunities within the Korean technology sector.
     * 제출 (Submit): Allows users to submit new articles, links, or ideas to the platform.

  Resources

     * 정보 (About/FAQ): Contains information about Hada News, including frequently asked questions.
     * Hada News GitHub Repository: Access to the open-source project code for the platform.

  Optional

     * Target Audience: Primarily serves the Korean-speaking developer community, providing content and discussions in Korean.
     * Inspiration: The site's user interface and core functionality are significantly influenced by Hacker News, offering a familiar experience.
     * Community Focus: Relies heavily on user contributions for content and fosters active discussions through its commenting system.

   저희 회사 블로그로 해보니 환각이 나오네요. AI 인사이트를 주는 블로그라면서 없는 블로그 글들을 소개해줍니다. 🤣

   ㅠㅠ Gemini를 좀 더 혼내보겠습니다 🥲

   https://blog.smply.one/

   참고 삼아 드리자면, 저희 회사는 피그마, 노션 등의 SaaS 구독 비용이나, 기기 관리를 하는 IT 자산관리 서비스입니다.

  개선을 해보았습니다!

심플리 블로그 (Smply Blog)

     복잡한 IT 자산관리, 심플리 팀이 쉽게 전달해 드립니다. IT 자산관리 솔루션 심플리(SMPLY)의 공식 블로그입니다.

  인사이트 (Insight)

     * 바코드 vs QR코드 vs RFID 비교, 가장 합리적인 자산관리 방식은?: 유형 자산을 관리하는 데 가장 적합한 방식을 비교합니다.
     * 재물조사? 자산조사? 자산실사? 용어의 뜻과 효율적으로 진행하는 방법: 업계에서 다양하게 쓰이는 용어의 뜻과 효율적인 방법에 대해 소개합니다.
     * IT 자산관리 솔루션 도입, 어떻게 설득할 수 있을까요?: IT 자산관리 솔루션 도입 설득 방법을 안내합니다.
     * 자산 구매부터 관리까지, 경영지원/총무 담당자를 위한 가이드!: 심플리 & 에어서플라이를 활용한 효율적인 자산 구매 및 관리 방법을 확인해 보세요.

  SaaS 레시피 (SaaS Recipe)

     * Zapier vs Make vs n8n, 우리 팀에 맞는 업무 자동화 도구는?: Zapier, Make, n8n을 비교하여 팀에 맞는 업무 자동화 도구를 찾을 수 있도록 돕습니다.
     * [구글 워크스페이스] GWS 특징 및 탄력/연간 요금제 비교, 합리적으로 도입하는 방법까지 총 정리: 구글 워크스페이스의 특징, 요금제 비교, 합리적인 도입 방법을 총정리합니다.
     * SaaS란? SaaS의 개념과 특징 역사까지 총 정리: SaaS의 개념과 특징, 역사에 대해 이야기합니다.
     * [SaaS 추천] 실무자라면 꼭 써봐야 할 AI SaaS 5종 추천: 실무자를 위한 AI SaaS 5종(노트북LM, tl;dv, 픽토리, 감마, 미드저니)을 추천합니다.

  팀 이야기 (Team Story)

     * K-ICT WEEK in BUSAN 2025, 글로벌 미래 선도 기술 종합 전시 행사: 심플리 팀의 'K-ICT WEEK in BUSAN 2025' 참가 소식입니다.
     * [심플리 업데이트] 알림 센터와 기기 사진 업로드 기능 추가: 알림 센터와 기기 사진 업로드 기능이 추가된 심플리 업데이트 내용을 확인해 보세요.
     * 스마트테크코리아(STK) 2025, 국내 최대 미래 선도기술 전문 전시회: 심플리 팀의 '스마트테크코리아 2025' 참가 소식입니다.
     * [심플리 업데이트] 기기 엑셀 파일 업로드 기능 개편 및 기타 사용성 개선: 기기 엑셀 파일 업로드 기능 개편 등 심플리 업데이트 내용을 확인해 보세요.

  Optional

     * 심플리 홈: IT 자산관리 솔루션 심플리 공식 홈페이지
     * 무료로 시작하기: 심플리 서비스 무료 체험
     * 서비스 소개서 신청: 심플리 서비스 소개서 다운로드
"
"https://news.hada.io/topic?id=21836","미국 기업 R&D 즉시 비용처리 재도입 법안 OBBB 서명","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    미국 기업 R&D 즉시 비용처리 재도입 법안 OBBB 서명

     * 미국에서 OBBB 법안이 서명되어 국내 기반 연구 및 개발(R&D) 투자에 대해 즉시 비용처리 권한이 재도입됨
     * 이 법안은 세금 관련 규정을 완화하여 기업들의 현금 흐름에 긍정적 영향 제공함
     * 재도입된 즉시 비용처리는 R&D 등에 투자하는 기업들의 비용 부담을 경감시키는 효과를 가짐
     * 미국 내 혁신 및 기술발전을 유도하려는 목적이 강조됨
     * 앞으로 기업들의 R&D 투자 활성화와 국가 경쟁력 강화가 기대됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

미국 R&D 즉시 비용처리 법안 개요

     * OBBB(법 이름)는 미국에서 R&D(연구 및 개발) 관련 지출에 대해 즉시 비용처리(expensing)를 재도입하는 내용의 법안임
     * 현재까지는 R&D 비용의 자본화 및 장기상각 방식으로 인해 기업의 세금부담과 현금흐름에 제한이 있었음
     * 이 법안 서명으로 미국 내에서 이루어지는 연구개발 지출에 대해 해당 연도의 세무처리에서 전액 즉시 비용으로 인정 받을 수 있게 됨
     * 이에 따라 기업들은 R&D 투자 시 세금 우대효과를 즉시 누릴 수 있게 되어, 현금흐름 개선 및 신규 프로젝트 투자여력 확대로 이어질 것임
     * 기업의 R&D 투자 활성화는 기술혁신 유인 및 국제 경쟁력 강화에 긍정적 영향을 줄 것으로 전망됨

적용 및 영향

     * 즉시 비용처리 제도는 미국 내에서 이루어지는 R&D 활동에 한정 적용됨
     * 해외에서 수행된 R&D에는 적용되지 않음
     * 정책 변화로 인해 관련 업계에서 적극적인 투자 증대 및 고용 성장 등 파급효과가 예상됨

요약

     * OBBB 법안은 R&D 지출에 대한 즉시 비용처리를 재도입해 기업의 세금 부담 경감 및 현금흐름 개선을 목적으로 함
     * 미국 기반 스타트업 및 IT 기업에게 긍정적 환경 조성 역할을 하게 됨

        Hacker News 의견

     * 소프트웨어 개발을 R&D(연구개발)로 분류하고, R&D에 대한 즉각 비용처리 허용으로 Section 174의 변경 내용을 원래대로 되돌릴 수 있는 법안 이해를 공유함
          + “어떤 소프트웨어 개발 관련 지출도 연구 또는 실험적 지출로 본다”고 법안 303페이지에 명시
          + 관련 법안 PDF 링크
          + Section 174 관련 원문 기사 링크
          + @dang의 추가 정보 링크
          + 소프트웨어 개발을 R&D로 분류한 것은 2017년 TCJA에서 이미 도입되었고, 2022년부터 적용됨
               o 이번 새로운 법안은 소프트웨어 개발의 R&D 분류는 유지하면서, 세금 공제 방식만 2022년 이전처럼 되돌리는 내용으로 이해
               o TCJA 관련 이전 논의는 여기 참고
               o R&D와 R&E는 사실상 동의어
          + 법안 301페이지를 보면, “납세자가 해당 과세 연도에 지출하거나 발생시킨 모든 국내 연구·실험 지출에 대해 공제가 허용된다”는 내용이 나오고, 이전에는 Section 174에 국내와 해외 R&D의 구분이 없었음
          + 이런 방식은 정말 말이 안 된다는 생각
     * 팬데믹 이후 “원격 근무가 잘 작동한다”는 사실로 인해 오프쇼어링이 하나의 전략으로 등장했다고 보는데, 결국 해외 R&D는 여전히 15년간 감가상각 처리됨
          + 해외 지출은 현재가치 기준으로 8.6%가 손실되고, 첫 해에 6.7%만 비용처리 가능해 19.6%의 현금‧세금 차이가 생김
          + 하지만 해외 인건비가 미국 대비 50~70% 더 저렴하기 때문에, 감가상각의 단점에도 불구하고 인건비 차이가 워낙 커서 R&D 인력 관련 총 비용 30% 절감 기대
          + 실제로는 해외 임금이 미국보다 20%만 낮더라도 손익분기 맞출 수 있는데, 대부분의 해외 시장이 이 기준을 넘음
          + 15년 감가상각이 세금 혜택을 줄이기는 하지만, 인건비 차이로도 충분히 상쇄 가능
          + 오프쇼어링에는 법적, 문화적, 시차 등 다양한 비용이 포함되어 있고, 이런 요소들 때문에 격차가 줄어드는 경우가 많음
               o 서류상으로는 오프쇼어링이 늘 합리적으로 보였고, 그럼에도 2025년이 와도 미국 개발자를 여전히 고용하는 현상
               o 심지어 외국 개발자를 미국으로 데려와 미국 급여를 주는 사례까지 발생
          + “원격 근무가 오프쇼어링 촉진”이라는 주장에 혼란
               o 인도 오프쇼어 IT는 2000년대 초부터 시작된 오래된 모델
               o 많은 비테크 기업들이 이미 온쇼어 소수가 비즈니스 이해관계자와 소통하고, 오프쇼어 팀이 실제 업무를 진행하는 구조를 오래전부터 구축
          + 오프쇼어링은 예전부터 가능성 있었고, 이제는 IC(개별 기여자)들도 원격으로 일할 수 있고 팀도 글로벌화
               o 미국 중심에 인도, 브라질 등 국가 개발자들이 참여할 수 있는 팀 구성이 현실
               o 인도 내에서 10, 100, 500명 규모의 팀이 함께 오피스 근무하는 것도 예전부터 가능
               o 앞으로 다른 국가들이 더 큰 투자 중심지가 되면 변화가 있을 것으로 예상
               o 미국은 시장 규모, 자유시장, 스타트업 생태계의 이점으로 초기 스타트업에 좋은 환경
               o 동시에 대부분 스타트업은 온사이트 근무와 최소한의 시간대 동기화를 희망, 대형 테크 기업들은 미국 내부에 모든 특화 인력이 집중된 구조
          + “큰 차이를 못 만들 것”이라는 주장에 의문
               o 논의가 오프쇼어 여부만 다루고 있는데, 실제로는 “채용 여부”가 핵심
               o 제품 중심 코어 기능은 해외 타임존이나 문화 차이로 잘 안 되는 케이스 많음
               o 이번 변화가 미국 엔지니어를 정리해고하거나 채용 회피한 기업 입장에서는 추가적인 세금 부담이 없어지는 효과가 있음
          + 법안이 명백하게 유럽, 캐나다, 영국 등 고임금‧고수준 R&D 및 소프트웨어 엔지니어링 국가를 겨냥한 것이라는 해석
     * 2022~2024년 동안 자본화된 국내 R&D 비용에 대해 “catch-up deduction”이 가능해지는 조항 존재
          + 해당 기업들의 현금 흐름에 의미 있는 개선 효과 전망
     * 미국 의회의 입법 과정을 굉장히 기괴하다고 평가
          + 매년 단 한 번 대규모 종합 법안만 통과시키는 구조
          + 재정 적자 규정 우회를 위해 세법 시간폭탄‧유예‧만료 조항을 잔뜩 넣어 복잡성↑
          + 이를 제대로 정정하지 못하면 R&D 비용과 같이 기업 및 직원 피해 현실화
          + 가끔씩 그 시간폭탄을 소급 취소하긴 하지만 여전히 혼란
          + 행정부는 법을 무시하며 행정명령을 범람, 특정 기업이나 대학을 표적으로 삼는 등 독재적 흐름을 보임
          + 전체 시스템이 지속 가능할지, 채권 시장 신뢰가 무너지면 혼돈 예상
          + 최근 BBB(법안) 통과가 월요일 시장에 미칠 영향도 관심
          + 부패하고 진지하지 않은 인물들이 반복적으로 재선되는 현실, 앞으로 어떻게 극복할지 감이 안 잡힘
          + 의회가 공동 목표를 가진 공직자 집단에서, 셀럽성‧미디어 중심 자기홍보만 중시하는 집단으로 변질
          + 미국 외 국가들도 급변 상황에 대비책을 더욱 강화해야 함을 최근에서야 실감
               o 권위주의적 대통령제 대두로 경제·문화적 충격이 예상
               o 이런 상황을 관망만 할 때는 아니라는 생각
     * 이번 법안으로 정리해고된 개발자 일자리가 모두 돌아올 거냐는 의문
          + 소프트웨어 엔지니어 고용 비용 하락 효과로 인해 채용 정상화와 더 나은 일자리 가능성
               o 하지만 숲이 한번 베어졌을 때, 다시 자라는 숲은 예전과 달라지는 현상 존재
          + 평균 회귀 현상 언급
          + 그렇지 않다는 현실적 시각도 있음
     * 미국은 R&D를 계속 지원하면서 타국의 지원을 불평하는 아이러니 지적
          + 사실상 즉시 비용처리 허용이지, 보조금(직접 지원)은 아님
          + “우리의 R&D 지원은 고귀, 타국의 지원은 시장 왜곡”이라는 풍자
          + “무엇을 지원해야 한다면 R&D만큼 좋은 타겟은 없음”이라는 견해도 있음
     * 이번 변화가 오버스태프드(덩치가 커진) 법안이지만, 빠른 비용처리 복원이 좋은 조치라고 평가
          + 처음부터 변경될 이유가 없었고, 당시 이를 옹호했던 논리 자체가 이상했다는 회상
          + 법안에 온갖 잡다한 내용이 들어간 건 아무도 양보하지 않기 때문
               o 양당에 논란이 되는 어떤 내용도 넣을 수 있는 유일한 방법이 연 1회 ‘조정 법안’임
          + TCJA(트럼프 세제 개편)이 바꿨다가 OBBBA(새 법안)가 되돌렸음
               o 애초에 뭘 놓치고 있는지 궁금
          + “즉각 비용처리” 변경 반대는 무지에서 비롯
               o 이런 규칙이 생긴 이유가 있음
          + 감가상각 적용은 대부분의 사업 자본 지출(예: 임대주택 지붕 공사비 등)에 그대로 적용되는 상식
               o 스타트업은 현금흐름 이슈가 심각했는데, 이번 변화는 원칙상 당연한 세법 적용이었으나 현실 타격 컸다는 주장
     * 최근 ‘Who’s Hiring’ 스레드의 원격(미국) 한정 구인글 비중 증가 관찰
          + 이번 법안 통과 가능성에 따라 기업들이 미리 대응한 결과인지, 아니면 단순 월별 변동인지, 패턴이 있는지 궁금증
     * 이번 변화가 소프트웨어 개발자 고용에 긍정적 영향 미칠 것으로 기대
          + 기업의 사무실 복귀 움직임을 완화하고, 개발자들이 더 많은 선택지와 역동적인 채용 환경을 기대
          + 하지만 아직까지 “소프트웨어 엔지니어링은 이미 사양산업이고, AI가 모두 대체”라는 논리가 퍼져있고, 실제 효과는 주주에게만 돌아갈 수도 있음
               o 과거 조치가 실제로 시장에 큰 충격을 주지 않았던 것처럼, 이번 해제도 실일보다는 기업가치 증대 쪽 영향
          + 많아야 최근 2~3년간 감소분 일부만 복원 가능
               o 이런 문제 자체가 트럼프 시절 만든 일몰 규정(GOP 자체산 문제)에서 발생
          + “정말 진지한 발언인가요, 아니면 풍자인가요?”라는 반응
               o 대형 회사들은 “AI 도입으로 인력 축소” 프레임을 선호, 이번 조치로 채용 감속이 다소 완화될 수 있지만, 큰 변화는 기대하기 어려운 상황
               o 당장은 실제 일자리 증가가 미미하거나 정리해고 소폭 감축에 그칠 공산
          + 즉시 비용처리로 인한 급여 성장 추가 상승도 기대
"
"https://news.hada.io/topic?id=21903","지루한 코드로 10억 웹 요청을 처리한 경험","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        지루한 코드로 10억 웹 요청을 처리한 경험

     * 미국 메디케어 건강보험 플랜 비교 시스템을 재구축하며, 검증된 기술(Postgres, golang, React 등) 로만 구성된 단순한 구조로 10억 건 이상의 웹 요청을 안정적으로 처리한 경험을 공유함
     * 단순함과 안정성을 목표로 아키텍처를 설계해, 평균 10ms 이하 응답 속도와 아주 낮은 장애율을 달성함
     * 혁신(innovation token) 은 핵심적인 구조 분리(3개 대형 모듈, gRPC 통신)에만 최소한으로 적용하고, 그 외에는 모두 지루하지만 신뢰할 수 있는 방법론을 선택함
     * DB 스키마 관리, ETL 파이프라인, 테스트, 로깅, 문서화, CLI 도구까지 모든 운영 요소를 반복 가능하고 단순한 방식으로 구축해 팀 전체가 쉽게 이해·유지보수할 수 있는 시스템을 완성함
     * 지속적 품질관리와 강한 팀워크가 대규모 정부 프로젝트에서도 통한다는 사례를 생생히 보여줌
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Serving a billion web requests with boring code

  High level

     * 2년 반에 걸쳐 미국 정부의 메디케어 플랜 비교·구매 웹사이트를 리드 개발함
     * 일 평균 500만 API 요청을 처리, 평균 응답 속도는 10ms 미만, 95% 요청은 100ms 이하로 유지
     * 장애 발생률이 매우 낮아 실제 엔지니어가 새벽에 호출된 사례는 한 손에 꼽을 정도
     * Postgres, golang, React 등 누구나 이해할 수 있는 검증된 기술로만 구성해, 꾸준히 안정적인 시스템을 구축함

  Boring über alles

     * 최우선 원칙은 '지루하고 검증된 기술' 만을 우선하는 것(** Choose Boring Technology**)
     * 혁신 시도는 꼭 필요한 곳에서만 innovation token을 아껴서 사용
     * 복잡하고 화려한 솔루션보다 안정적이고 명확한 기술과 프로세스를 선호

  The boring bits

     * Postgres: 데이터 저장의 핵심, 신뢰성과 확장성을 모두 만족. 복잡한 검색(페이시티드 검색 등)도 Postgres로 해결
     * golang: 빌드와 배포가 빠르고, 바이너리 산출물이 명확함. 에러 핸들링이 직관적이고, 새로운 팀원도 쉽게 적응 가능
     * React: SPA 프레임워크 중 가장 검증되어 있고, 팀원들이 이미 익숙했음. 접근성과 다양한 기기 지원도 중요한 고려 요소였음
          + 장기적으로는 번들 크기와 속도 저하 이슈가 발생했지만, 당시 상황에서는 시간 내에 결과를 내기 위한 최적의 선택이었음

  The innovation tokens

     * Modular backend: 전체 백엔드를 마이크로서비스도, 모놀리식도 아닌 3개의 대형 모듈(druginfo, planinfo, beneinfo)로 구성
          + 각 모듈은 별도의 Postgres DB를 사용하고, 데이터 공유는 오직 gRPC를 통해서만 이뤄짐
          + druginfo: 약국, 보험, 포장 등 조합이 기하급수적으로 늘어나는 약가 정보를 매우 정교하게 인덱싱하고, 복잡한 사전처리와 성능 최적화가 필요
          + planinfo: 매일 새로운 CMS 데이터를 수신해, DB 전체를 새로 만들어 사용함(불변성 유지)
          + beneinfo: 실제 가입자 정보를 보관하는 유일한 부분으로, 민감한 PII(개인정보)는 최소한만 저장. 데이터 유출 리스크 최소화를 위해 설계와 운영에 신경 씀
     * gRPC: 모듈간 통신 인터페이스를 코드로 명확히 정의할 수 있는 장점. 자동화 도구와 연동성이 뛰어남
          + 단, 빌드·툴링·디버깅은 복잡하고, JSON API 대비 직관성이 떨어지는 단점도 경험
          + grpc-gateway를 통해 웹클라이언트 지원 및 대량 트래픽을 무리 없이 처리함

  Strict backwards compatibility

     * API 및 데이터베이스의 하위 호환성 유지를 엄격하게 지킴
          + 공개 API의 필드는 절대 삭제하지 않고, 보안 문제가 있지 않는 한 평생 유지
          + DB 컬럼도 추가는 자유롭지만 삭제는 여러 단계 검증(참조 제거→몇 주 대기→실제 삭제) 절차를 거침
     * 이 규율이 높은 변화 속도와 안정적인 배포·운영의 핵심 기반이 됨

  Faceted search

     * ElasticSearch 대신 Postgres만으로 페이시티드 검색 구현
          + well-indexed plan 테이블에 조건을 조합하는 250줄 함수 하나로 모든 검색 로직을 처리
          + 비즈니스 요구에 집중, 불필요한 복잡성 없이 단순하게 해결함

  Database

     * creation
          + DB 스키마를 숫자가 붙은 .sql 파일로 관리, 순서대로 로딩하여 신뢰성 보장
          + planinfo/beneinfo DB는 매일 재생성, 마이그레이션 필요 없음. 버전 불일치 등 설정 오류 시 앱 자체를 아예 시작하지 않도록 설계
     * ETL
          + 데이터 소스별 셸 스크립트로 S3에 적재 → cron으로 EC2 인스턴스가 최신 ETL 코드/데이터 가져와 신규 RDS DB 생성
          + Postgres의 COPY 구문을 적극 활용, INSERT 대신 대량 데이터 적재를 효율적으로 처리
          + 매일 2~4시간이면 수억 행 데이터를 새 DB로 전환 가능
     * models
          + xo 라이브러리로 DB 모델 자동 생성, 커스텀 템플릿으로 팀에 맞는 코드 생성
     * testing
          + 가장 큰 실수는 sqlmock을 활용한 테스트를 과하게 만들어 데이터가 자주 바뀌는 상황에서 유지보수가 매우 번거로움
          + 실제 불변 DB라면 실DB에 대한 테스트가 더 효율적이었을 것
     * Local database for development
          + 각 테이블의 부분 데이터를 자동 생성하는 스크립트로, 개발자별로 작은 로컬 DB로 실제 데이터 기반 테스트와 개발 가능
          + DB가 커지기 전에 이런 도구를 마련하면 전체 팀 개발 효율이 극대화됨

  Miscellaneous tooling

     * 각종 운영·관측 자동화를 위해 CLI 도구를 셸 스크립트로 구현, 모든 유틸리티 기능을 하나로 모아 관리
     * splunk 로그를 Slack 명령어로 바로 그래프로 시각화하는 등 현장 중심의 도구를 적극 개발·활용

  Logging

     * 요청 진입 시점에 request id를 생성, 그 id가 모든 로그 컨텍스트에 붙어서 어디서든 추적 가능
     * zerolog로 안전하고 체계적인 로깅 설계
     * 시스템 입구·퇴출, 예외 상황 등 중요 시점마다 필수 로그 남기기

  Documentation

     * GitHub markdown 문서를 sphinx-book-theme으로 변환해 위키북으로 운영
     * 팀원 모두가 적극적으로 문서화에 기여, 한 곳에서 모든 시스템 문서를 찾을 수 있도록 함
     * 뛰어난 문서화 문화가 팀의 성장과 유지보수, 신입 온보딩 효율을 크게 높임

  Runtime integrations

     * 클라이언트의 성능 저하 요청(분석 스크립트 삽입 등)은 최대한 설득해 최소화
     * 쿼리도 브라우저 런타임이 아닌 빌드타임 처리로 전환해, 서비스 성능을 유지
     * 실제론 고객 요청을 모두 막지는 못해, 일부는 성능 저하로 이어졌음

  And more

     * 기술 이외에도 긍정적이고 협력적인 팀 분위기와 강한 동기 부여가 대규모 시스템 성공의 진짜 원동력임을 강조
     * 사소하지만 중요한 실무적 선택과 꾸준한 품질 관리의 힘을 실감한 사례였음

   이 지루한 걸 2.5년이나?!

   Postgres, golang, React이 지루한 세계에서 살고 싶네요

   외국에선 그게 지루한 스택인 것 같습니다.
   실제로 go는 뭐 그냥 웹서버 만드는데 가장 쉬운 선택이고..

   뭐 rust fp쪽 언어 이런걸로 개발해야 지루하지 않다고 하는 것 같네요.

   맞아요 제목보고 무슨 농담인가 했네요

   Faceted Search 가 무엇인가 궁금해서 따라갔다 더 읽을만한게 있네요.

   https://www.cybertec-postgresql.com/en/faceting-large-result-sets/
   https://roaringbitmap.org/about/
   https://github.com/cybertec-postgresql/pgfaceting

   너무 당연한 이야기들.. 너무 당연해서 놓치고 있는 중요한 사항들..

   ""지루""에 대한 의견들이 재밌네요ㅎㅎ 다른 말로 바꾼다면 뭐가 좋을까요? 뻔한, 흔한?

   boring을 지루하다고 번역한게 원래 의미를 너무 못살리네요. boringness는 go 디자인 철학 중 하나에요.

   지루~한 척…

   한국은 기승전 자바민국이라 낯설어 하네 ㅋ

   golang, React 전부 새 시대의 지루한(boring) 엔터프라이즈 코딩 언어라고 생각합니다.

   boring -> 지루한 으로 100% 맞게 번역되는 게 아니다보니 한국 독자들에게는 뉘앙스가 제대로 전달되지 않는 거 같아 보이네요.

   이정도는 그렇게 지루해보이지만은 않은 스택으로 보이네요. 정말 지루하다면 java 1.8 이하버전이나 vb 정도는 나와야하지 않을까... 하는 불충한 생각이 듭니다

     The nice thing about boringness (so constrained) is that the capabilities of these things are well understood. But more importantly, their failure modes are well understood.

   원문에 boring 과 관련된 링크가 있는데, 내용을 보면 boring = 너무 익숙한이라는 의미인 것 같습니다.

   experienced, verified, skillful 같은 더 적절한 단어가 있는데 굳이 boring 을 쓴건 어그로를 끌 저의가 있는것 같네요

   쓰기에 지루한게 아니고 너무 많이써서 지루한 국밥스택이라고 표현한것 아닐까요

   리눅스 커널 2.6.29정도...

   gRPC 썼다는거 자체가.. ㅋㅋ

   저도 golang이 지루하다니? 같은 생각부터 들었습니다
   classic asp 정도면 지루하다고 할 수 있을법한데 말이죠
"
"https://news.hada.io/topic?id=21944","Show GN: 단 한 판도 깨기 어려운 캐쥬얼 자작 게임 - 플래피 앵그리 버드 - ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Show GN: 단 한 판도 깨기 어려운 캐쥬얼 자작 게임 - 플래피 앵그리 버드 -

   이 게임은 단 한 판도 깨기 어렵습니다. (한판이라도 깨면 인증해주시길 바랍니다. ^^)

   사실 이 게임은 몇 년 전에 제가 만든 게임인데 저도 한판을 깰 수 없었습니다...
     * 개발 동기: 제 애들에게 아빠가 뭐하는 사람인지 또 애들이 어린지라 아빠를 신기해 할 수있도록 의도해서 만들었습니다.
     * 배포: 한 푼이라도 아끼기 위해 개발자 계정이 무료인 원스토어에 배포를 하게 됐습니다.
     * 유료게임: 그나마 저의 노력과 시간이 어느정도 들어갔기에 소액이지만 유료로 책정을 했습니다.

   어쨌든
   결과적으로,

   결국 잘못 만든 게임이라고 판단했지만 그냥 원스토어 앱 마켓에 올려 배포해버렸습니다.

   (사족)
   참고로 전 개발 분야에 있기는 하지만 전문 앱이나 게임 개발자가 아니어서
   호기심에 또 이미 언급한 개발동기를 가지고 만들게 되었네요.
"
"https://news.hada.io/topic?id=21861","화웨이, Qwen과 DeepSeek 모델 클론 후 자사 모델이라고 주장","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                화웨이, Qwen과 DeepSeek 모델 클론 후 자사 모델이라고 주장

     * 화웨이가 Qwen과 DeepSeek의 대형 AI 모델을 복제한 후 ‘판구(Pangu)’라는 자체 제품으로 내세웠다는 내부 폭로가 제기됨
     * 판구 팀 내부 직원의 증언에 따르면, 일부 실질적 모델은 직접 개발이 아닌 외부 오픈소스 모델에 기반하여 명칭만 변경된 형태임
     * 실제로 135B V2 및 Pro MoE 72B 등 주요 모델이 Qwen 및 DeepSeek의 구조와 상당 수준 일치함이 기술적으로 드러남
     * 내부에서는 이런 관행이 연구진 사기 저하와 이탈로 이어졌으며, 행정적 비효율과 불투명한 인사 정책도 문제를 심화시켰음
     * 진정한 자주 개발 모델(Pangu V3 등)도 있으나, 복제 관행과 인정받지 못하는 연구문화가 조직 전체 신뢰에 큰 상처로 남음
     * 내부 고발자는 자신의 실명을 걸고 진실을 밝히고자 결심했으며, 조직의 반성과 변화를 촉구함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

판구의 비극: 화웨이 Noah Ark Lab 판구 대형 모델의 고통스러운 내막

  내부 고발자의 소개 및 현장 분위기

     * 필자는 화웨이 Noah 판구 대형모델 팀 소속으로, 주요 조직-프로젝트 구조 및 리더십 구성을 내부 정보와 맞춰 신분을 인증함
     * 판구 프로젝트는 실제로 연구조직보다 납품조직에 가까웠으며, 반복된 마감과 오버워크, 끊임없는 평가 및 보고의 압박에 시달림
     * 업무 강도와 관료주의가 극심했고, 가족과 장기간 떨어져 숙소 생활, 주말 근무도 빈번한 상황
     * 실질적으로 연구의 자율성과 창의성보다는, 각 상품 라인(Cloud, ICT 등) 납기와 실적 위주의 기업문화가 지배적이었음

  잠 못 이루는 밤, 짓밟힌 창작의식

     * Qwen 모델 표절 논란 이후, 일부 연구진은 수치심과 분노, 무기력감을 동시에 경험함
     * 폭로자 본인은 거대한 기업과 내부 네트워크의 보복이 두려우나, 더 이상의 사실 은폐와 대외 거짓 홍보를 참을 수 없어 양심 고백 결심

  기술적 난관 그리고 표절의 시작

     * 초기 판구 모델은 화웨이 Ascend NPU 기반에서 자체 훈련을 시도했으나, 토크나이저 효율성과 모델 성능 부진 등 심각한 시행착오를 겪음
     * 경쟁사(Alibaba, Zhipu)의 GPU 기반 모델에 뒤처졌고, 자체 230B dense 모델 훈련은 실패로 끝남
     * 이에, 소형 모델 랩은 “자체 개발”로 포장했으나, 실제로는 Qwen-1.5 (110B) 모델을 복제 및 소폭 수정한 135B V2를 만들어 공급, 내부에서도 코드·구조 유사성이 드러남
     * 주요 리더십 및 경영진은 이러한 실상을 알고도, 외부 성과와 실적 압박을 이유로 묵인함

  진정한 기술 성취: Pangu V3

     * 절치부심 끝에, 팀은 처음부터 완전히 자체 개발한 Pangu V3 (135B Ultra) 모델을 Ascend에서 독립적으로 훈련함
     * 여러 기술적 난관(토크나이저 통일, 손실곡선 안정화 등)을 극복하며, 경쟁사와 유사한 성능을 달성
     * 이 성취는 표절이 아닌 독자적 대형모델 개발의 증거로, 연구진 자부심의 원천이었음

  분업 이면의 인정받지 못한 고생

     * 소형모델 랩은 지속적으로 데이터·코드·결과물을 가져가서 손쉽게 모델을 변형/배포했으며, 성과와 포상 등은 주로 해당 조직에 돌아감
     * 이로 인해, 헌신적 연구자들은 조직을 이탈하거나 기술인생의 오점으로 남는 현실을 자조적으로 토로함

  224B MoE/718B 클론 등 2차 표절 사례

     * 신규 718B MoE 모델 개발 과정에서도, DeepSeekv3를 거의 그대로 복제한 후 Pangu Pro MoE 72B로 명명하여 배포
     * 내부에서는 이런 관행을 인지했으나, 서로의 생존과 진실 폭로의 두려움으로 쉬쉬하는 분위기

  부조리한 행정 관리

     * 진정한 연구진에게는 엄격한 프로세스·모델 계보·감사체계가 적용되어 개발 속도가 지연
     * 하지만 복제 모델의 경우 “위에서 하면 다 통과”하는 이중 잣대가 뿌리 깊게 남아 있음

  폭로의 이유와 사임 결심

     * HonestAGI 사건 이후, 회사 차원의 위기 관리와 내부 은폐 시도가 시작됨
     * 폭로자는 “가짜 보고서”와 내부 공모에 더 이상 동참할 수 없다며, 팀원 명단·보고서에서 본인 이름 삭제 및 자진 퇴사 의향 밝힘

  마지막 호소 및 동료에 대한 애정

     * 동료들은 이미 ByteDance, DeepSeek, Tencent, Kuaishou 등 타사로 이직하며 화웨이 인재 유출이 심각함을 보여줌
     * 혁신, 적합한 환경, 적은 정치적 장애가 있었다면 세계적 수준의 대형모델 및 칩 개발도 가능하다고 강조
     * 본 내용의 진실성과 추가 폭로에 따른 본인 및 가족 신변 위협 가능성까지 감수하겠다는 의지 표명

  추가 정황 설명

     * 135B V2 클론 사례에서는 소형 모델 랩이 포상·인센티브 등 이익만 챙기고, downstream 지원·유지보수 부담은 원 개발팀(4th brigade)에 전가
     * Pangu 기술 보고서 저자 표기에도, 실제로 모델 개발에 핵심적 기여를 한 인원이 제외되고 소형 모델 랩 소속 비기여자가 포함되는 등, 불공정한 학술 관행이 만연함

        Hacker News 의견

     * 원글 작성자가 다소 순진한 시각을 드러낸다고 느끼는 입장임. Ascend 팀이 초기에는 (1세대 910A NPU 기준) Nvidia 대비 성능이 부족했었고, 이건 당연한 결과임. 경영진은 바로 상용화 가능한 GPU 기반 대안을 따라가는 팀을 지원했고, 사내 정치로 이런 방향이 굳어짐. Ascend 팀은 결국 기술적 문제를 해결하는 데 성공했지만, 부당한 대우와 관료적 편파, 인정 부족 등으로 많은 멤버가 번아웃되거나 다른 중국 AI 기업으로 이직함. HW(아마도 Huawei)는 오랜 기간 1티어급 인재를 혹사시키는 전략과 문화를 가져왔고, 90년대에도 PRC 통신사가 Nortel, Siemens, Lucent에서 인재를 뽑아갔지만, 서구식 직장문화에 익숙했던 중국계 인재들이 실제 중국 회사 문화에 적응하는 데 어려움을 겪으며 번아웃됨에도 불구하고, HW가 공격적인 워크컬처로 결국 업계를 지배하게 되었음.
       지금은 제재 이후 전략 기업이 되어 반도체, 국산 칩, AI로 가치가 크게 높아짐. 현 국제 환경에서, HW는 시장 지배를 위해 어떤 일이든 감행할 수 있는 위치 확보. 이 퇴사 편지를 통해, HW가 결국 충분한 인재 투입으로 Ascend를 작동 가능한 수준으로 올려놨고, 앞으로 Nvidia와 경쟁할 정도로 인재를 계속 투입할 가능성 존재. 저자뿐 아니라 대부분의 직장인은 직원에게 정당한 보상과 좋은 근무 환경 조성이 필수라는 직관 가짐. 하지만 HW의 지난 30년간, 수많은 똑똑한 사람(애국자 포함)들에게 엄청난 연봉을 주고 문제 해결에 투입, 인력이 부서질 때까지 몰아붙이며 이기고 있음
     * LLM은 저작권과 전혀 양립 불가능한 구조임. 이미 남의 데이터를 돈 한 푼 안 주고 학습할 수 있다면, 복제도 자유라는 논리임. 결국 복제의 부메랑 현상이라는 시각임
          + 순진하게는 양립 불가이지만, 변호사가 어떻게든 합법화 방법을 찾아낼 것이라는 생각임
     * 과거 지도 출판사들은 가짜 골목길을 넣어서 저작권 침해를 쉽게 적발했음. LLM에도 이런 방식이 적용될 수 있을지 궁금함
          + Malwarebytes 근무 시 IOBit이 DB를 도용한다는 의심이 있었음. 명백한 증거는 있었으나, 일반인도 쉽게 이해할 수 있도록 하기 위해 오직 한 대의 머신에만 존재하는 신제품 프로그램을 만들고, 그 서명을 DB에 추가함. 해당 프로그램은 실제로 유포될 수 없는 비악성물이었고, 상대가 이를 DB에 추가하자 블로그에 공개해 큰 반향 일으켰음. 관련 사례 IOBit 도용 사건
          + 대표적인 사례로는 컴퓨터 칩에 의도적으로 미세하고 무해한 결함 내지는 이상현상을 넣는 방식임. 중국이 만든 많은 제품들이 TI 등 타사의 리버스엔지니어링 결과물이라 이런 결함이 많음. 심지어 중국 내부에서도 서로 이런 짓을 함. 모두 똑같이 편법 사용이라는 인식임
          + OML 1.0: Fingerprinting이라는 프로젝트 예시를 경험한 적 있음. LLM 소유권 식별과 무단 사용 방지를 위해 지문을 모델에 삽입하는 도구임
          + 유튜버 Jay Foreman이 지도 속 가짜 골목길 관련 영상 제작했던 사례 있음
          + 원문 중국어 고발글에 다음 내용이 있었음: Honestagi 분석이 매우 오랜 추가 학습을 거친 모델임에도 높은 유사성을 보인 점에 놀랐음. 이 모델의 파라미터를 세탁하기 위해 투입한 컴퓨팅 자원은 동급 모델을 새로 만드는 데 충분한 수준이었음. 동료 말로는, Qwen의 워터마크를 지우려고 오염된 데이터로 일부러 학습하는 등 여러 시도도 했다고 함. 이 방식은 앞으로 모델 혈통 연구 분야에 전례 없는 사례로 남을 것이며, 차후 새 연구 방법론 검증 때 본보기로 사용 가능함
     * Apple은 Qwen2.5-Coder-7B를 기반으로 하면서 자체적인 아이디어를 접목시킨 LLM을 선보임. 주요 변화는 애플의 자체 코드 예시로 커스텀 학습시킨 점이며, 온도를 올려주면 여러 코드 블록을 순서 무시하고 생성할 수 있음. 관련 기사 Apple LLM 관련 소식 HN 토론
     * 중국식 효율성 강조. 서구는 과거의 저작권법에 발목 잡힌다는 의견임
     * 매우 인간적이고 솔직한 보고서임. 대기업 내부의 혼란과 경영진이 부정직한 팀에 더 유리하게 압박을 가하는 구조를 보여줌. 작성자는 회사를 떠났으며, 인품이 좋다는 평가임
          + 사실 이 보고서는 최근 중국에 잇따라 등장한 다른 퇴사 편지들과 맥락을 같이 해야 함. 최근 15년차 Alibaba 베테랑의 퇴사 글도 큰 기업 문화 쇠락이 경쟁력 약화와 신제품 실패의 원인임을 비판함. 보고서 논점은 다음과 같음: 1. Huawei 역량에 대한 국가적 차원의 허위 2. 유료 고객 대상의 허위 3. KPI 집착 관리체계 하에서 성과지표 조작이 사실상 묵인/조장되는 현실 (이와 작성자의 이상, 신뢰 상실이 보고서 핵심임)
     * ""토요일은 기본적으로 근무일이지만, 때로는 오후 티타임이나 심지어 새우요리도 먹을 수 있었음""이라는 문장에 시적 감성이 느껴짐. 이런 상황에 민물가재가 제공되는 특별한 이유가 있는지 궁금함
          + ""토요일 근무임에도 간혹 간식이 나왔고, 민물가재도 그만큼 인기일 수 있음, 혹은 오역일 수도 있음""이라는 추측임
     * ""우리는 '제4야전군' 프로젝트 산하에 있고, 코어 언어 LLM은 4여단, Wang Yunhe의 소형 모델 그룹은 16여단""이라는 조직 설명을 보고 의아해함. 이게 실제로 공산당 군대 소속 조직인지 의문임
          + 실제 제4야전군은 1955년 이후 존재하지 않고, LLM 프로젝트 코드네임 용도로 계속 쓰이는 네이밍일 가능성이 높다는 견해임
          + Huawei의 군대식 기업문화 언급. 신입사원 오리엔테이션도 군대 교육 수료식처럼 운영함. 참고자료 화웨이 군사식 문화
     * 실제로 원초적 모델은 누가 만들었는지에 대한 질문 제기임
     * 과거 Huawei Lab 멤버가 모델 훈련을 실제로 방해하다가 해고된 사례가 있었으며, 위 고발 당사자인지 의심된다는 의견임
          + 아마도 언급한 사례는 ByteDance 인턴이 AI 모델에 악성코드 심었다가 해고된 사건으로 추정함. 관련 기사 bytedance-intern-fired
"
"https://news.hada.io/topic?id=21950","온라인 성적 글쓰기의 표현의 자유가 대법원 판결로 거의 사라짐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   온라인 성적 글쓰기의 표현의 자유가 대법원 판결로 거의 사라짐

     * 미국 대법원의 최근 판결로 온라인에서 성적인 내용을 포함한 글쓰기의 표현의 자유가 사실상 무력화됨
     * 여러 주의 연령 확인(나이 인증) 법이 합법화되면서, 다른 주에 있는 창작자들도 막대한 민사적·형사적 책임에 노출됨
     * 개인 웹사이트에 성적 내용이 포함된 경우, 복잡하고 사생활을 침해하는 나이 인증 시스템을 구축하지 않으면 벌금 및 징역까지 처할 수 있음
     * 이 법은 실제 기소 여부와 별개로, 창작자들에게 심각한 ""위축 효과(chilling effect) ""를 발생시킴
     * 보수 성향 주의 부모와 변호사들이 교차주 소송을 남용할 수 있게 되면서, 미국 내 온라인 작가, 예술가, 창작자 모두가 위험에 직면함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: 미국 대법원 판결의 온라인 성적 표현에 미친 영향

     * 최근 미국 대법원은 성인 대상의 성적 묘사나 성적인 장면이 포함된 글을 온라인에 올리는 창작자의 미국 수정헌법 제1조(표현의 자유) 보호 범위를 사실상 무력화하는 판결을 내림
     * 이 판결로 인해, 미국 내 여러 주에서 도입된 연령 인증 요구법이 힘을 얻게 되었으며, 보수적인 주의 부모들과 변호사들이 원거리 소송을 통해 창작자를 상대로 손해배상을 청구할 수 있는 길이 열림
     * 이런 규제를 위반하면 수백만 달러의 민사 손해배상뿐만 아니라, 형사범죄로 최대 15년까지 징역형이 가능해짐

주요 내용 요약

  새로운 법의 적용 방식과 파급력

     * 24개 주에서 연령 인증을 요구하는 법률이 제정 및 시행 중이며, 대표적으로 테네시 주의 Senate Bill 1792(2025년 1월 1일 발효예정)와 사우스다코타 주의 House Bill 1053(2024년 7월 1일 발효)이 있음
     * 테네시 법은 웹사이트 콘텐츠의 33% 이상이 '미성년자에게 유해한 콘텐츠'일 경우, 복잡한 사용자 인증과 데이터 보존 절차를 요구하며 이를 어길 시 3~15년의 징역에 처해짐
     * 사우스다코타 법은 소규모 위반에도 1년의 징역이 가능하고, 2회 이상 반복 시 2년의 징역형이 추가될 수 있음

  ‘미성년자에게 유해한 콘텐츠’의 정의

     * 텍스트, 오디오, 영상, 이미지 등 모든 표현 매체를 포함해, 기존 ‘외설성’, ‘미성년자 부적합성’, ‘대상이 성적 흥미를 유발하도록 의도된 경우’ 등 다양한 요건을 적용함
     * 실제 인물뿐 아니라 가공의 등장인물(예: 캐릭터)의 신체 일부 묘사나 행위도 포함하며, 문학적·예술적·과학적 가치가 없는 경우로 판정되면 해당됨

  연령 인증 방식의 실효성 문제 및 창작자 영향

     * 기술적으로 매우 까다로운 생체 인증·신분증 연동·이용 로그 분석 등 강도 높은 인증 방법을 요구하고, 인증 세션 관리 및 7년간의 데이터 보관까지 의무화함
     * 실제 적용은 거의 불가능에 가까우며, 일반 개인 블로그, 소규모 창작자 사이트도 적용 대상임
     * 인증 수단 도입 거부 시, 수십~수백만 달러의 손해배상 청구 및 형사처벌 위험에 노출됨
     * 이런 법적·재정적 리스크로 인해 많은 인디 창작자가 손을 놓게 되고, 실질적 표현 금지와 같은 효과를 낳음

미국 내 실제 사례와 위축 효과

  민간 소송의 남용: ‘에로틱 구조대(Erotic Ambulance Chasers)’

     * 보수 성향 주의 개인이나 변호사 집단이, 연령 인증 시스템을 도입하지 않은 예술가나 작가를 대상으로 거액의 배상을 청구하는 민사 소송이 실제로 증가 추세임
     * 예시로, 캔자스 주의 한 어머니가 아들의 성인 사이트 접속 175회에 대해, 각 회당 7만5000달러씩 총 1,400만 달러 청구 소송을 제기한 바 있음
     * 이러한 집단 소송 위험과 높은 소송 비용 때문에, 많은 창작자가 현실적으로 소송 합의를 택할 수밖에 없는 현실임

  ‘민사 불복종’으로 남는 선택지

     * 필자는 자신이 직접 운영하는 퍼스널 웹사이트에 불필요한 연령 인증 절차를 도입하지 않기로 결정하며, 이것이 지금의 법 아래에서는 ‘민사 불복종’에 해당함
     * 다른 인디 작가, 예술가, 창작자들은 법적·재정적 위험을 감수하기 어렵기 때문에, 자연스러운 창작 활동의 포기 현상이 늘어날 가능성이 큼
     * 이런 현상은 표현의 자유의 위축, 창작 생태계 침체로 이어지는 결과를 낳음

법 제정 의도와 실제 효과

  ‘백도어 규제’와 그 이면

     * 이러한 법률의 실제 목적은, “미성년자 보호”를 명분으로 내세우지만, 궁극적으로 온라인 성·애 관련 모든 표현과 사업을 불가능하게 만드는 것임을 입법 담당자의 발언을 통해 확인
     * 미국 보수 진영은 이 법률을 발판삼아 장차 ‘음란물 전면 금지’와 창작자, 사업자 처벌까지 노리고 있다는 점이 드러남
     * 이 법의 타깃은 제한 없이 확대될 수 있으며, 현재는 음란물 사이트, 곧이어 성 관련 콘텐츠 포함한 모든 예술, 문학, 유머, 소설, 롬스, 미술 등이 규제 대상이 될 수 있음

  규제의 ‘실질적 무용성’과 모순

     * 대다수의 성인 사이트, 포르노는 미국 외의 불법 해적 사이트에 탑재되어 있어, 실제로 미국 내 합법 서비스 업체와 창작자만 규제 대상이 됨
     * 미국 내 규제가 실제 미성년자 보호 효과에는 기여하지 못함
     * 부모들이 자녀의 기기에서 콘텐츠 차단 프로그램을 설치하거나, 열린 소통을 하는 것이 현실적으로 더 효과적인 대안임

결론: 표현의 자유, 창작자 커뮤니티의 대응

     * 현재 미국 온라인 공간에서 ‘누드나 성 묘사’와 같은 민감한 주제에 대한 표현의 자유가 사실상 상실된 상태임
     * 모든 창작자가 이러한 법률의 목적과 위험성을 인지하고, Free Speech Coalition 등 표현의 자유 옹호 단체와 연대하여 대응 전략을 마련해야 함
     * 미국의 독립선언문 서명 당시 벤자민 프랭클린의 말을 인용하며, 창작자 커뮤니티 전체가 함께 움직여야만 한다는 점을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   참고자료:
     * Free Speech Coalition FAQ: https://www.freespeechcoalition.com/faq
     * Free Speech Coalition: https://www.freespeechcoalition.com/
     * 법률 원문 및 주요 기사 링크 본문 참조

        Hacker News 의견

     * 모든 이런 신분증 확인 법률들이 정말 과해짐을 느낌 부모들이 자기 자녀 교육을 정부와 랜덤 웹사이트에 기대는 상황임 왜 누군가 내 신분증을 아무 블로그에 믿고 보낼까 궁금함 이런 법률들이 계속 진행된다면(그렇게 되길 원하지 않음) 신분증 사진이나 개인정보를 제3자에게 보내지 않아도 18세 이상임을 인증할 수 있는 방법이 있어야 한다고 생각함 나 자신도 이런 데이터 제공을 원치 않음, 웹사이트들도 이런 책임을 지지 말아야 함 Apple Pay처럼 결제 없이 바로 인증되는 흐름이 상상 가능함 기기에서 생체인증을 하고 브라우저에 신호를 보내는 식임 Apple이 Wallet에 주 신분증을 추가한 것도 연계 활용이 가능해 보임 U-Scan 체크아웃에서 술을 살 때도 마찬가지로 가능함 싱글유저 디바이스는 브라우저나 컴퓨터가 자동으로 이런 정보를 보내도록 설정할
       수 있어야 함 내 기기는 나밖에 안 쓰는데 이런 번거로운 과정을 거칠 이유가 없음
          + 혹시 이런 식인가 싶음? WebKit WWDC25 관련 블로그를 소개함 Okta, Apple, Google이 주도하는 ISO 표준 기반 W3C 스펙이고 이미 적용 중임 iOS 앱들이 신분증 인증 공급자로 등록할 수 있음 캘리포니아 mDL은 독립 사업자와 진행하다가 Apple이 개방형 표준 지원을 압박받은 재미있는 배경이 있음
          + 이렇게 규제가 계속되면, 18세 미만이 자살, 트랜스젠더, 동성애 등 중년 엄마들이 부적절하다 느끼는 주제를 다루는 웹사이트도 모두 차단하는 쪽으로 미끄러지는 게 너무 위험함을 생각함
          + 이 방식, 제로 지식 증명(zero-knowledge proof)이라 부르면 딱 맞을 것 같음 위키백과 설명도 참고할 수 있음 주요 OS 벤더가 이런 방식 지원하는 것도 충분히 현실이라 봄 Google Wallet의 인증 예시도 있음
          + 이런 법 자체는 초기 웹 정신에 정면으로 반한다고 생각함 이런 극단적 도덕적 강요에 익숙해지지 않았으면 좋겠음
          + 클라이언트 대 서버 관점에서 봤을 때 이런 규제가 한 번만, 그리고 단말 제조사나 OEM 출하 OS 단에서만 적용된다면 범위도 줄고 비용도 낮아지고 더 적절해질 것임 새 기기들이 초기에 부모 통제 모드로 출하되고, 성인이 몇 단계 인증 후 해제 가능하도록 하면 됨 본인확인(KYC) 정보 로그도 암호화 혹은 단말 기기에만 저장되게 해서 프라이버시를 최대한 보장할 수 있음 소규모 인디 제품, DIY PC, 리눅스 등은 예외 적용이 필요함 이런 규제의 목표는 정보 없는 일반 소비자 보호라 생각함
     * 이미 많은 사람이 언급했겠지만, 이 규제는 포르노에서 끝나지 않을 것임 포르노 연령 인증이 표준화되면, 모든 전문 인터넷 서비스가 뭔가를 하려면 신원 인증을 요구하는 풍경이 곧 펼쳐질 수 있음 이것은 자유로운 인터넷의 종말을 향한 큰 한 수임 포르노에 찬성이든 반대든 인터넷 환경 전체가 변할 수밖에 없음
          + Cloudflare가 ID 체크의 사실상 표준이 되기 전에 관련 규제가 제대로 정비되어야 한다고 생각함
          + 법적 의무 관점에서는 동의하지 않음 일반 유권자가 포르노 등 노골적인 컨텐츠에 대한 걱정 때문에 이런 법을 지지하는 것일 뿐, 그 너머로 확대될 일은 낮다고 느낌
          + AI로 인한 스팸이 범람하는 요즘, 모두가 실존 인증된 상태의 인터넷에 접속할 수 있다면 나쁘지 않겠다는 생각임
          + 연령 인증이 인간 인증의 하위 집합인 것 같음 만약 봇과 캡차 모두 사라진다면 오히려 나쁠 이유가 없음
          + 이건 그렇게 나쁘게 느껴지지 않음 정치, 기술, 종교 등 주제로 이야기할 때 상대가 미성년자가 아님을 확신할 수 있으면 더 낫겠다는 생각임
     * OP에서 언급한 것처럼, ""공화당이 성적, LGBT+ 전반을 포르노, 외설, 미성년자에게 유해하다고 규정짓는 현상""이 실제로 벌어지고 있음 포르노 금지는 사실 본질이 아님 실제로 이런 걸 규제하는 쪽도 포르노 소비를 하고 있으니, 자기들에게 편리한 정도선만 금지할 것임 진짜 목표는 LGBTQ+ 타겟화, 범죄화임 관련 법이 애매모호하게 쓰이는 이유, 타주 시민 소송 허용도 그 때문임 결국 ""게이도 괜찮다""라고 말하는 것조차 포르노로 낙인 찍어 범죄화하려는 움직임임 포르노라는 명분으로 사실상 인구 전체를 통제하려는 시도임 논의가 본질을 흐리는 것 같아 안타까움
          + 파시즘의 주요 특징 중 하나는 인그룹(우리)에겐 보호만 제공하고 구속하지 않으며, 아웃그룹(남)에겐 구속하나 보호는 제공하지 않는 것임 즉 “너에겐 규칙, 나에겐 자유”식임 모두가 파시즘의 14가지 특징을 꼭 알아야 함
          + 이 의견에 전체적으로 동의함 다만 한 점만 덧붙이자면, 이런 금지가 실제로 그들에게 큰 영향을 주지 않음 대형 포르노 산업은 규제 비용만 지급하면 계속 살아남을 것이기 때문임 실제로 규제가 실질적 금지보다는 선택적 처벌을 가능하게 하므로 권력을 강화하기 위한 수단임
          + 성경에 있는 외설적인 내용도 금지해야 하는 것 아닌지 아이러니함 18세 인증 후에만 성경을 보여주자고 농담함
          + HRT(호르몬 대체 요법) 팁을 트랜스 청소년에게 공유한다는 건 잘못된 일이라고 생각함
          + 더 간단히 말해, 이 모든 흐름은 그들이 싫어하는 <i>아무거나</i> 처벌할 수 있게 하는 인프라임 감시, 검열 시스템 구축이 목적임 역설적으로 총기 등록 컴퓨터화에 반대하는 보수 세력이 인터넷 검열에 이토록 집착하는 것을 보면 아이러니함
     * “미성년 유해글 한 문단으로 최대 15년형” 같은 타주 교차 기소가 실제 현실로 다가옴 드물게 일어날지도 모르지만, 결국엔 꼭 발생할 것임 해당 판사가 그 내용을 거슬려 한다면 실제 처벌 확률이 올라감 이런 기회에 KYC회사 창업하면 대박일지도 모름
          + 주 검사가 자기 주와 관련 없는 사이트를 기소하려 든다면 결국 대법원까지 갈 일임 아무 연고 없는 주의 규제를 사전 준수하게 하면 법적 대혼란임 텍사스가 직접 차단할 역량이 있으면 자기만의 '만리방화벽'을 구축하면 될 문제임
          + 보수적 주들이 이미 타 주 의료 서비스까지 기소하려 드는 것을 보면, 같은 방식으로 표현까지 확장할 가능성 높음
          + 오히려 지금이야말로 모든 서비스에 프라이버시 툴을 탑재하는 기회라고 생각함
          + 검열을 지지하는 쪽은 판사도 자기들 편인 법원을 골라 소송을 걸 것임
     * 인터넷이 “실세계와 다르게 운영돼야 한다는 전제”에 동의하지 않음 이미 인터넷은 필수 인프라이고 접근 경로가 무수히 많음 부모가 모든 기기를 통제하는 건 현실적으로 불가능함 콘텐츠 차단도 불완전할 수밖에 없음 오프라인에서 만약 “무료 성인 도서관”을 만들면 반드시 신분증을 검사하고 미성년자를 통제해야 하는 건 상식임 온라인만 다르게 운영돼야 할 합리적 이유가 있는지 의문임 단, 실행상의 프라이버시 문제 등 현실적 난관이 있다면 그에 적합한 솔루션을 개발하는 게 방향이지, 현상 유지만 주장하는 건 설득력 없음
          + 오프라인 맥락과 분리해 생각하면, 많은 사람이 현실 세계의 통제 방식에 동의하지 않았기에 인터넷을 만들어냈음 이 공간이 더 나은 세계로 발전하길 바라던 사람들이었음 오히려 성공한 플랫폼이 사회 부적응자를 밀어내는 논리로 분위기가 변했다는 지적에 공감함 이런 변화가 온라인 환경을 향상시키는 게 아니라, 결국 오프라인 권력의 파급 확장일 뿐임 조금도 더 나아진다고 생각하지 않음
          + 온라인 인증과 오프라인 인증의 큰 차이점은 중앙집중적 로그가 쌓인다는 점임 담배 살 때 종이 신분증만 잠깐 보여주면 끝이지만 온라인은 언제, 어디서, 뭘 했는지가 모두 기록됨 이것 자체가 엄청난 위험임 개인정보가 보호되지 않는 인증 시스템은 적극적으로 막아야 함
          + 이런 규제로 미국 내 호스팅 사이트 접근만 어렵게 한다고 해도, 해외 수천, 수만 개 이상 사이트까지 차단할 수 없고 결국 아무 효과 없음 실효성은 없으면서 표현의 자유만 억압하고, 미국 사회의 종교적 통제만 강화될 것임 이런 법을 추진하는 이들의 진짜 목적이 ""아이 보호""가 아니라 포르노 금지·통제라는 주장임, 프라이버시 문제는 부차적임 결국 아이가 우연히 불편한 걸 봤을 때 부모가 맥락을 제공하고 지도를 하는 게 현실적인 방법임, 부모 역할을 대신하는 시스템은 결코 완벽할 수 없음
          + 포인트 1에 대해, 주변 친구 중 한 명의 부모만 규제를 완화해도 그 아이가 학교의 포르노 유통책이 되는 건 예전이나 똑같음 결과적으로 아이들에겐 변화가 없지만 모든 성인은 거추장스러운 절차 혹은 국가의 사생활 침해 위험에 노출됨, 그럴 가치가 없다고 생각함 포인트 2는 흑명단보다 백명단(허용 사이트 제한 방식)도 이미 존재함, 부모가 원하는 사이트만 넣고 제공하면 됨
          + 실행과 도덕을 분리하자는 의견이 좋다고 생각함 기술 업계가 이 이슈에 여전히 소극적이고 정치인들이 잊어버릴 거라 생각하는 사이에 규제만 계속 강화되는 게 아쉬움
     * 우리는 지난 30년간 제대로 된 연령 장벽 없이 아이들이 인터넷에 접근해왔음 문제는 있긴 했지만(그루밍, 페북 파티, 틱톡 중독 등) 성인 콘텐츠 접근 자체로 인한 대형 사고는 잘 없었음 ‘2 girls 1 cup’ 같은 컨텐츠도 10살짜리가 봐도 인생이 끝나지는 않을 것임 컨텐츠 추천 시스템이 존재하는 건 좋지만, 그걸 강제로 적용하려 하면 오히려 부작용이 생김 수십 년간 포르노에 쉽게 접근 가능했는데 정말 심각한 문제였다면 이미 사회 전체가 무너졌어야 하지만 전혀 그렇지 않음, 걱정할 수준이 아님
          + 콘텐츠 제한은 ISP에서 옵션으로 제공하는 게 맞다고 생각함 모뎀/폰 전체에서 성인 콘텐츠를 차단, 혹은 연령 인증하도록 하면 부모가 원치 않을 경우 꺼버리면 됨(기본 켜짐 상태 가정) ‘2 girls 1 cup’은 대학원 때 여학생 반응 보는 영상이 인상적이었음 내 세대에선 lemonparty.com 같은 게 있었음
     * NYT에 얼마 전 중국 도덕 경찰이 게이 에로 소설 작가들을 대량 체포한 사례 기사가 있었음 NYT 기사 물론 중국은 그럴 수 있다 쳐도, 미국이 이렇게까지 빠르게 변한 건 충격임
     * 미국 소프트웨어 엔지니어 모두가 이런 위헌적 법률을 무시할 뿐만 아니라, 미국인의 표현의 자유를 지키기 위해 “진짜 더러운 것”을 표현할 수 있게 방어하는 기술을 만들고 배포·유지해야 한다고 강력히 주장함
          + 대법원이 합헌이라면 그게 곧 헌법이라는 입장도 있음 헌법이 안 먹힌다면 이미 나라 자체가 붕괴한 상황임
          + 250년 법치주의 역사를 봐도 “외설 표현의 자유”란 없었음
          + Tor 같은 익명화 서비스가 아주 인기 많아질 것 같음
     * “보수적 기독교인들이 모든 성적 발언을 없애려 한다”는 표현이 마음에 들지 않음 자신도 비교적 보수적 기독교인이지만 SCOTUS의 이번 결정, 각종 나이 확인 규제 모두 반대하거나 지지하지 않음 모두를 잠그는 게 현실적이지 않고, 효과도 없으리라 생각함 그러나 온라인 포르노로 인해 젊은 남성 중독, 이상적 성행위의 일반화, 현실 관계의 왜곡 등 실제 건강하지 않고 지속 가능하지 않은 현상이 늘어남엔 공감함 60년대 대마초와 요즘 고농도 THC가 완전히 다른 상황임 온라인 포르노도 과도한 특이 성적 취향이 즉각적으로 노출되는 사회로 바뀜 모두 피하고 싶지만 일부는 어쩔 수 없다 봄 하지만 이건 결국 부모의 교육 책임임, 국가가 해결할 문제가 아니라고 생각함 규제 대상자를 직접 교육하는 게 정답이지, 쉬운 길(기업에 책임 전가, 모든 걸 차단
       등)만 찾는 건 무책임하다고 봄
          + 당신이 직접 추진하진 않아도 많은 동료 보수 기독교인들이 적극적으로 이런 법률을 만들고 있음 도덕적 논리가 법의 유일한 근거가 되는 건 위험함 이런 논리로 노예제, 여성 참정권 부정, 가정폭력 합법화 등을 정당화했던 역사도 있음 시간이 흐르며 바뀌어왔지만 앞으로 더 나빠질 수도 있음 “포르노라서 나쁘다”는 논리가 곧 “동성애 관련 모든 것도 규제”로 흘러가게 됨 결국 이런 법들이 왜 나쁜지, 도덕주의적 법 제정이 왜 경계되어야 하는지 반드시 짚어야 함
          + 남이 사적으로 뭘 하든 누구도 간섭해선 안 됨 특히 정부는 더더욱 그럴 권리가 없음
          + 나도 소도시 출신으로 보수 기독교인을 많이 아는데, 그들은 정말 이런 규제를 원함 말씀하신 것처럼 부모 책임 대신 외부 탓을 돌리려는 게 현실임
          + “framing(프레이밍)이 불만”이라고 하셨지만 사실상 프레임 자체가 맞음 본인이 어떤 그룹에 속하는지 진지하게 고민해보시길 권함
          + ‘비정상적(sex acts)’이라 칭하는 성행위도 성경 시대엔 충분히 흔해서 성경에도 등장함 오히려 조상들은 현대 미국인을 지나치게 순진하다고 봤을 것임
     * 테네시 법은 정말 말도 안 되게 과도함 “음모, 외음부, 자지, 고환, 항문, 유두 등 노출”만으로 위법임 알몸은 누구에게도 해가 되지 않는다는 의견임 미국식 청교도 문화의 절정으로 보임 작가가 폭력보다 노출을 외설로 취급하는 위선을 지적한 점에 동의함
          + 공평하게도(또는 공정하게) 이 법은 남성과 여성 유두를 구분하지 않음 남자도 셔츠 벗은 이미지는 여성과 똑같이 규제 대상임

   사람들은 자유의 중요성 자체를 잘 모릅니다. 나이들었든 아니든 간에요. 민주주의를 위해 싸웠던 세대의 분들도 이상하게 검열은 환영합니다.

   범죄 예방의 효용보다 검열의 디메리트가 더 크다는 것도 이해하지 못합니다.
   모든 검열에 범죄 예방 하나로 핑계를 대고 그게 먹히는 시대입니다.

   몇 년이 더 지나면 1984같은 소설에 나오는 것처럼 모든 가정에 CCTV가 설치되더라도 사람들은 그 위험을 이해하지조차 못할지도 모르겠습니다.

   이미 디스토피아적인 검열사회에서 사는 사람들에겐 한참 이른 담론이군요
"
"https://news.hada.io/topic?id=21841","긴 컨텍스트의 문제를 해결하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          긴 컨텍스트의 문제를 해결하는 방법

     * 긴 컨텍스트 사용 시 발생하는 대표적인 문제로는 컨텍스트 오염, 혼란, 충돌, 산만함 등 다양한 정보 관리 이슈가 존재함
     * 정보 관리가 핵심이며, 잘못된 정보는 결과의 품질에 직접적인 악영향을 미침
     * 주요 해결책으로는 RAG, Tool Loadout, Context Quarantine, Pruning, Summarization, Offloading 등의 전술이 효과를 보임
     * 최신 LLM의 컨텍스트 윈도우가 큰 경우에도 불필요한 정보 남용은 여전히 실제 문제를 일으킨다는 점에 주의 필요함
     * 각 전술은 에이전트 설계자가 컨텍스트를 체계적으로 관리하고 효율성 및 정확성을 높이는 데 큰 도움이 됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

긴 컨텍스트에서 발생하는 문제와 요약

   긴 컨텍스트를 사용할 때 시스템에서 발생할 수 있는 대표적인 실패 유형은 다음과 같음
     * 컨텍스트 오염: 헛소리(hallucination) 또는 오류가 컨텍스트에 포함되어 반복적으로 참조되는 문제
     * 컨텍스트 산만함: 컨텍스트가 너무 길어져 모델이 본래 학습 내용 대신 컨텍스트에만 집중하는 현상
     * 컨텍스트 혼란: 불필요한 정보가 추가되어 품질이 낮은 응답을 생성하는 상황
     * 컨텍스트 충돌: 새롭게 추가된 정보나 도구가 기존 정보와 충돌하는 경우

   이러한 문제는 모두 정보 관리에 기인하며, 프로그래밍에서 “Garbage in, garbage out” 격언처럼 입력 정보가 결과에 큰 영향을 줌.
   다행히 여러 가지 전술로 위와 같은 이슈를 효과적으로 완화하거나 예방할 수 있음

주요 컨텍스트 관리 전술
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  RAG (Retrieval-Augmented Generation)

     * RAG란 필요한 정보만 골라 LLM에 제공하여 응답 품질을 높이는 방식임
     * LLM의 컨텍스트 윈도우가 커지면서 ‘모든 정보를 다 집어넣자’는 시도가 많지만, 불필요한 정보는 오히려 결과를 망침
     * RAG는 오늘날에도 여전히 매우 중요한 기술로 활용 중임

  Tool Loadout (도구 구성 선택)

     * 필요한 도구만 선택적으로 컨텍스트에 삽입하는 방법
     * 도구 설명을 벡터 DB로 관리하다가 프롬프트별로 RAG를 활용해 최적의 도구를 선택함
     * 30개가 넘는 도구 부터는 겹치는 설명으로 혼란이 발생하며, 100개가 넘으면 모델의 성능이 급격히 저하됨
     * “Less is More” 논문에서 Llama 3.1 8b는 46개 도구를 제공할 때 실패하지만 19개만 제공할 때 성공함
     * 동적으로 필요한 도구를 선택할 수 있도록 LLM 기반 추천기를 사용했으며, 이로 인해 성능, 속도, 전력 효율성 모두 상승함

  Context Quarantine (컨텍스트 격리)

     * 컨텍스트를 분리된 스레드에서 각각 관리하는 방법
     * 연구, 탐색 등 문제를 여러 부분으로 분할해 각각 별도의 에이전트(Agent)가 담당하도록 설계함
     * Anthropic의 multi-agent 시스템에서는 서브에이전트별로 독립된 컨텍스트 윈도우를 사용하여 효율성 및 정밀성을 높임
     * 이 설계는 특히 여러 방향으로 동시에 탐색해야 하는 과제에서 강점이 뚜렷하게 나타남

  Context Pruning (컨텍스트 가지치기)

     * 불필요한 정보나 오래된 정보를 계속 걸러내는 방법
     * NLP 분야에서는 오래 전부터 다양한 pruning 기법이 활용되어왔음
     * 최신에는 Provence처럼 가볍고 빠른 컨텍스트 ‘정리’ 전용 모델이 등장함(1.75GB, 95% 문서 압축 가능)
     * 컨텍스트를 딕셔너리 등 구조화된 형태로 관리하면 가지치기와 요약(압축)이 쉬워짐

  Context Summarization (컨텍스트 요약)

     * 컨텍스트 길이가 길어질 때 전체를 압축·요약하는 방식
     * 단순히 창을 넘지 않게 유지하는 용도뿐 아니라, 불필요한 반복이나 산만함 현상을 예방하는 데 효과적임
     * 압축 단계에서 어떤 정보를 유지할지 정의하는 것이 중요함
     * 별도의 LLM-powered 요약 단계를 통해 평가 데이터를 축적·개선 가능함

  Context Offloading (컨텍스트 오프로드)

     * 컨텍스트 외부에 메모 공간을 만들어 기록을 남기는 전략
     * 예시로 Anthropic의 “think” tool은 별도 scratchpad를 마련해 LLM이 필요한 중간 메모를 남기도록 유도함
     * 도구 출력분석, 정책 검증, 순차적 의사결정 등에서 유용하게 적용됨
     * 중간 결과를 별도로 보관함으로써 컨텍스트가 불필요하게 오염되거나 복잡해지는 것을 방지함
     * 성능 및 정확도 향상, 54%까지 개선되는 경우도 확인됨

결론 및 에이전트 설계 시 유의점

     * 컨텍스트 관리야말로 에이전트 설계에서 가장 까다로운 부분임
     * LLM을 프로그래밍할 때 정보, 도구, 맥락 등을 어떻게 조합하고 관리하느냐가 성패를 좌우함
     * 컨텍스트 윈도우가 아무리 커도, 모든 정보가 도움이 되는 것은 아님.
     * 각 항목이 실제로 효용을 발휘하고 있는지 점검하고, 위에 소개된 6가지 방법(RAG, Tool Loadout, Context Quarantine, Pruning, Summarization, Offloading)으로 컨텍스트를 적극적으로 관리할 필요가 있음
"
"https://news.hada.io/topic?id=21915","AI 브라우저 자동화를 위한 "MCP-B 프로토콜"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      AI 브라우저 자동화를 위한 ""MCP-B 프로토콜""

     * MCP-B : 브라우저 네이티브 AI 자동화 프로토콜
     * 기존의 화면 캡처·클릭 방식이 아닌, 웹사이트의 API에 직접 접근하여 AI가 1,000배 빠르고 정확하게 자동화할 수 있도록 지원하는 브라우저 컨텍스트 프로토콜
     * 약 50줄의 코드만 추가하면 별도의 OAuth, API 키, 복잡한 설정 없이 사이트 내 인증 정보로 바로 AI 연동이 가능
     * 브라우저 세션과 기존 인증 시스템을 활용해, 새로운 인증이나 권한 설정 없이 즉시 동작하며, 각 웹 앱의 API 보안 정책을 그대로 존중함
     * 확장 프로그램을 통해 AI 어시스턴트가 여러 탭과 앱을 넘나들며 직접 데이터 조회·작업 수행이 가능, 기존 자동화 대비 성능(수 ms 내 실행)과 신뢰성이 압도적으로 향상됨
     * 구조화된 API 접근이기 때문에 UI 변경, 스크린샷 오류, 복잡한 셀렉터 관리 문제에서 자유로움. 설치와 사용 모두 매우 간단
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

MCP-B 개요

     * MCP-B(Machine Context Protocol for Browsers) 는 브라우저를 위한 모델 컨텍스트 프로토콜로, AI 기반 터미널 자동화와 유사한 방식으로 브라우저 환경을 제어 및 상호작용하는 표준 제공
     * 본 프로토콜은 브라우저와 AI 엔진 사이의 통신을 명확히 규정해, 다양한 자동화 및 모델 상호작용을 구조화함

  기존 방식과의 차별점

     * 전통적 브라우저 자동화: 스크린샷 분석, 요소 클릭, UI 변경에 취약, 느리고 불안정(작업당 10~20초, $4~5 비용)
     * 기존 MCP 방식: API 키와 복잡한 인증 필요, 초기 셋업 진입장벽 높음
     * MCP-B: 브라우저 세션 활용, API 직접 접근, 복잡한 인증·설정 없이 즉시 동작

  핵심 원리 및 구조

     * 탭별 MCP 서버: 각 웹앱이 자체적으로 TypeScript 기반 MCP 서버 구동(메모리 내 전송, 기존 쿠키/JWT 인증 재활용)
     * MCP-B 확장 프로그램: 크롬/엣지/파이어폭스 확장(컨텐츠 스크립트가 탭 서버와 postMessage로 통신), 모든 탭의 툴·API를 한곳에서 통합
     * AI 어시스턴트 연동: Native Bridge 및 다양한 클라이언트(Claude Desktop, Cursor IDE 등)에서 MCP-B를 통해 브라우저 자동화 가능

  사용 및 배포 방식

     * 개발자: 1) 패키지 설치 2) MCP 서버 코드 추가 3) 배포 완료 → 별도 API 키, OAuth, 복잡 설정 필요 없음
     * 사용자: 확장 프로그램 설치 후 바로 사용, AI 설정만으로 즉시 자동화

  실질적 장점

     * 인증: 기존 웹사이트 로그인·세션 정보 그대로 사용, OAuth 2.1/별도 인증 필요 없음
     * 성능: 직접 API 호출로 ms 단위 작업 완료(기존 대비 10,000배 향상)
     * 보안: 애플리케이션 내부에서 동작, 기존 접근 제어 및 권한 정책 그대로 준수
     * 확장성: 여러 웹앱과 탭, AI 도구가 MCP-B를 통해 통합 관리 가능
     * 설정: 약 50줄 코드만으로 자동화 준비 완료

  비교 요약

     방식       인증 및 설정         동작 방식        성능 및 신뢰성
   기존 자동화 복잡한 인증, API 키    화면 스크래핑, 클릭 느리고 불안정 (10~20초)
   기존 MCP API 키, OAuth 필요  API 접근      진입장벽 높음
   MCP-B  설정 無, 브라우저 세션 사용 직접 API 호출   ms 단위, 매우 빠름/안정적

  결론: 차세대 브라우저 기반 AI 자동화

     * MCP-B는 브라우저 환경에 최적화된 AI 자동화 프로토콜로, 인증/보안/확장성/성능 모든 면에서 혁신적
     * 추가 인증이나 복잡한 설정 없이, 브라우저 기반의 API 직접 호출만으로 대규모 AI 자동화 구현 가능
     * MIT 라이선스, 커뮤니티 중심, 모든 주요 브라우저 지원

   MCP-B 기술의 핵심 비전은 다음과 같다고 볼 수 있습니다.
   ""크롬 확장 프로그램(Extension)이라는 신뢰할 수 있는 매개체를 통해, 브라우저가 이미 안전하게 관리하고 있는 사용자 정보(쿠키, 세션, 인증 등)를 활용하여,
   웹페이지에 개발자가 미리 정의해 둔 '도구(Tools)'들을 AI 채팅창에서 자연어 명령으로 호출하고 제어하겠다.""

   하지만 저는 ""확대될 여지가 없어 보인다""고 느끼며, 그 이유는 다음과 같다고 생각합니다.
    1. 사용자 저항감: 가장 큰 허들입니다. 사용자들은 자신의 브라우저 정보에 접근하는 확장 프로그램을 설치하는 것에 대해 본능적인 거부감과 보안 우려를 가지고
       있습니다. 이 기술이 제공하는 편리함이 그 우려를 넘어설 만큼 압도적이지 않다면, 사용자들은 설치를 주저할 것입니다.
    2. 웹 개발자의 부담: 웹사이트 개발자들은 기존의 API를 만드는 것 외에도, MCP-B를 위한 '도구(Tools)'를 별도로 정의하고 관리해야 하는 추가적인 부담을 갖게
       됩니다. 이 기술이 널리 채택되어 얻는 이득이 크지 않다면, 개발자들은 굳이 이중의 노력을 들이려 하지 않을 것입니다.
    3. 보안 문제의 책임 소지: 만약 이 기술을 통해 보안 사고가 발생했을 때, 책임이 웹사이트 개발자에게 있는지, 확장 프로그램 개발자에게 있는지, 아니면 AI 모델
       제공자에게 있는지 불분명해질 수 있습니다. 이런 복잡성은 기업들이 기술을 도입하는 것을 꺼리게 만듭니다.
    4. 중앙화된 플랫폼의 부재: 현재로서는 ""어떤 웹사이트가 어떤 도구들을 제공하는지"" 알려주는 표준화된 디렉토리나 플랫폼이 없습니다. 사용자는 웹사이트에 방문하기전까지는 어떤 AI 기능을 사용할 수 있는지 알기 어렵습니다.

   결론적으로,
   MCP-B의 아이디어 자체는 기술적으로 매우 흥미롭고 혁신적이지만, 사용자와 개발자 모두에게 ""왜 굳이 이 방식을 써야 하는가?""라는 근본적인 질문에 대한 명확한 답을 주지 못할 것 같습니다. 기존의 API 방식에 비해 얻는 이점은 불분명한 반면, 보안 우려와 개발 복잡성이라는 단점은 명확하기 때문입니다.

   따라서 현재로서는 이 기술이 일부 매니아나 특정 목적을 가진 개발자들 사이에서 실험적으로 사용될 수는 있겠지만, 웹 생태계 전반으로 확대되기에는 많은 어려움이 있어 보입니다.

        Hacker News 의견

     * 예상: RSS와 같은 길을 걷게 될 것. 기업들은 사용자가 데이터 활용 방식을 스스로 통제하는 걸 꺼리는 경향이 있음
          + REST API도 마찬가지로, 한때는 'API-first' 설계 바람과 함께 서비스 자동화·연동의 미래가 될 거라 기대됨. 그런데 비즈니스들이 이런 역량을 제공하면 자신의 수익 구조에 위협이 된다는 걸 빨리 자각해서 금방 방향이 꺾였음. 결국 모든 돈줄이 이런 권한을 사용자가 갖지 못하게 하는 데 있다는 점을 다시 깨달음
          + RSS는 실패한 것이 아니라 오히려 엄청난 성공을 거뒀다고 생각함. Google Reader가 사라진 뒤 다른 리더로 옮겨도 20년 넘게 RSS 피드가 문제없이 잘 동작하고 있음. RSS를 지원하지 않는 사이트는 거의 만나본 적이 없음
          + 대부분의 웹사이트가 RSS를 여전히 지원하고 있고, 일부는 페이지에 표시하지 않아도 기본적으로 피드가 존재함. 일부만 본문 전체를 공개하지 않는다 하더라도 업데이트 알림이나 자동화 트리거로 여전히 가치가 큼. RSS는 여전히 매우 유용하게 살아있는데, 마치 전자레인지처럼 당연히 존재하는 느낌임
          + 시장 구조에서 변화가 일어나서 이제는 대형 기업들이 콘텐츠 그 자체보다 '인텔리전스 레이어'에 집중하고 있음. 콘텐츠는 점점 상품화됨. Google은 사용자의 눈과 관심, 그리고 그들을 사로잡는 스마트 기술을 손에 넣어야 광고를 계속 팔 수 있음. Google이 RSS를 원하지 않았던 이유는 RSS가 Google Search를 우회할 수 있었기 때문임
          + AI가 곧 사람처럼 클릭하고 스크롤하는 능력을 갖게 되면, 또 한 번의 무한 경쟁이 벌어질 것임
     * Github 프로젝트의 기여 내역이 매우 흥미로움 (직접 링크 인용). MiguelsPizza가 3회, Claude가 2회 커밋했는데, Claude의 코드 변경량이 거의 압도적임
          + 일시적으로 확장 기능을 비공개 처리하면서 git 히스토리를 조정해서 실제 내역과 약간 차이가 있음. 그래도 Claude 코드가 전체의 약 85%를 작성한 건 사실임
          + 앞으로 이런 패턴(거대한 AI 기반 코드 기여)이 점점 더 많아질 것 같음
          + Claude의 커밋 그래프가 매우 독특함. Claude Code가 직접적으로 커밋하는 듯 보이긴 하지만 실제로는 거의 없음. claude 프로필도 참고
          + 실제 커밋 목록을 보면 전부 MiguelsPizza / Alex Nahas 명의로 되어 있음 (링크). 뭔가 이상해 보임
     * 블로그에서 발췌한 부분을 언급하며, MCP의 인증 문제에 대해 다룸. OAuth2.1은 장기적으로 봐도 괜찮지만, 사용자를 대신해 동작하는 에이전트에 맞춘 인증을 새로 재발명해야 하는 상황임. 다중 테넌트 앱 내에서 데이터 유출 위험이 아직 해결되지 않음
          + 모델의 피해 범위와 접근 데이터를 제한하는 것이 MCP의 큰 장점일 수 있음. 다중 테넌트 앱의 클라이언트 측 API는 이미 유저 범위로 제한되어 있을 것이라 기대되므로, 모델에 그것만 제공한다면 피해가 크지 않을 것임. Amazon 내부 인증 시스템과 OAuth2.1의 호환성 문제도 언급됨(Amazon에서는 인증이 다름)
          + OAuth2.1의 일부 기능이 이미 RFC 8693의 위임과 사칭에서 다뤄지는지 궁금함
          + 모델이 접근할 수 있는 범위는 결국 유저와 동일하므로 확실한 보안 구현은 웹사이트 관리자의 책임임
          + Oauth가 제대로 적용되지 않은 Amazon의 예시가 핵심 이슈는 아니라고 생각함. 사용자 권한 범위를 넘는 백도어 식 접근은 매우 위험함. MCP 앱의 모든 행동이 유저 액세스와 같은 범주로 기록된다면 컴플라이언스 이슈가 많아질 수 있음. 이런 관점에서 매우 흥미롭지만, 보안 측면에서는 우회로서 문제 소지가 클 것 같음
     * Swagger(OpenAPI) 명세를 공개하고 범용 swagger mcp 클라이언트만 있어도 이 모든 구현이 거의 대체 가능하지 않냐는 아이디어를 제시함. 사용자 스스로 인증 세션을 수동으로 열게 하면 될 듯함. Claude가 프롬프트/설정에서 API 키를 잘 파악해서 swagger 기반 API 클라이언트를 사용하면 같지 않겠냐고 제안함
          + MCP 등장 당시 모두가 가장 먼저 떠올린 방식임. 하지만 실제로는 너무 많은 툴이 존재해서 잘 작동되지 않는다는 점이 드러남. 그래도 이 분야에서 재미있는 시도들이 지속됨
          + API 키를 프롬프트에 넣지 말라는 주의 당부도 있음
          + Claude Code가 CLAUDE.md에 swagger.json 링크만 줘도 API 테스트가 정말 편리해짐
          + 직접 해보라고 격려함
     * 누가 타겟 유저인지 잘 모르겠음. 프런트엔드 테스트에서는 UI가 크게 바뀌면 테스트가 깨지는 게 오히려 유용함. 그 외 자동화 목적이라면 실제 API를 제공하는 편이 낫다고 생각함
          + 크롤러들과 본인이 VLM으로 우유 사는 작업 등이 실제 사용자에 해당함
     * ""Home Depot에서 테이블을 만들려고 하면 오히려 더 힘들 것""이란 비유에, Home Depot에도 목재가 가득하다는 점을 들어 의문을 제기함
          + Home Depot에서는 이미 완성된 테이블도 판매함
          + Home Depot에는 더 좋은 정밀 공구는 물론, 전문가도 있어서 오히려 작업이 더 쉬워질 수 있음
          + '목재는 네가 상상해서 만들어내야 한다'는 뉘앙스로 농담함
          + 지적 사항을 반영해서 문구를 수정했다고 밝힘
     * MCP를 직접 사용해 보진 않았지만, 장애를 가진 사람 입장에서는 MCP가 브라우저·스마트폰 자동화에 있어 접근성(Accessibility) 관련 활용처가 크게 보임. 다만 이런 기술이 악의적 사용자에게 남용될 수 있어 실제로 메이저 웹/앱에서 도입할지는 의문임. 혹시 실제로 접근성 개선에 쓰고 있는 사례가 있는지 궁금함
          + 접근성 도구가 어떻게 악용될 수 있는지 더 구체적으로 궁금해함
     * MCP-B 오픈소스로 풀린 점이 고마움을 느낌. 대부분의 브라우저에서 일이 일어나지만, MCP는 AI 클라이언트가 작업한다는 전제가 조금 다름. 근본적으로 MCP-B가 웹 앱의 JS API를 LLM 서버와 바로 연동해 사용함과 어떻게 다른지 궁금함. 결국 똑같은 건지, 아니면 더 큰 그림이 있는지 질문함
          + 답변에서, MCP-B는 웹사이트 주인장이 별도의 AI 챗 기능을 직접 구현하거나 관리할 필요 없이, 표준 프로토콜로 사용자가 원하는 모델을 사이트의 여러 도구와 연동해 쓸 수 있다는 점이 근본적인 차이임을 설명함
     * 홈페이지 내용만 봐서는 잘 이해가 안 되고 Selenium의 브라우저 버전 느낌이라 여겨 질문함
          + 유사하지만 완전히 다름. Playwright나 Selenium은 브라우저 자동화 프레임워크이고, Playwright-MCP 서버에서 에이전트가 Playwright를 자동화에 활용할 수 있음. 반면 MCP-B는 웹사이트 내부에 MCP 서버를 두고, 브라우저 확장이나 JS 삽입으로 MCP-B 클라이언트를 실행함. Playwright는 화면을 직접 파싱하고, MCP-B는 표준화된 함수 호출 방식임. 블로그 코드 예시를 참고하라고 안내함
     * 무료 LLM 사용자를 대상으로 MCP로 브라우저 자동화가 시작되면 무료 모델도 캡차(Captcha)를 요구하는 세상이 올 것이라고 예상함. 문제는 캡차가 LLM에 그다지 효과적이지 않아서 결국 LLM들이 자동화 LLM의 접근을 막기 위해 서로 싸우는 이상한 로봇 전쟁 시대가 열릴 수도 있음
          + 이런 이야기에서는 결국 로봇들이 서로 같은 목표를 가지고 있다는 걸 알고 협력하게 된다는 결말로 흘러감
"
"https://news.hada.io/topic?id=21917","Grok 4 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Grok 4 출시

     * Grok 4는 xAI가 약 2년 만에 출시한 최신 AI 모델로, 모든 분야에서 대학원생을 압도하는 지능과 추론력을 실현
     * 훈련 규모와 연산 자원이 100배 이상 증가했으며, 강화학습(RL) 중심으로 발전해 인간 수준을 뛰어넘는 문제 해결 능력을 입증
     * ARC-AGI 점수 15.9% 달성, 현존하는 AI 중 최고 수준의 추상적 추론 및 일반 지능 평가에서 우수한 성과를 기록함
     * Humanity’s Last Exam(HLE) 등 다양한 벤치마크에서, 외부 도구 미사용 시 26.9%, 도구 사용 시 41~50.7% 라는 혁신적 결과를 보여줌
     * 네이티브 보이스 모드 도입으로, 실시간 대화 및 감정 표현, 저지연 응답 등 인간에 가까운 상호작용 구현
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Grok 4

     * Elon Musk가 설립한 xAI가 약 2년 만에 Grok 4를 공개, “세계 최고 AI 모델”임을 강조
     * SAT, GRE 등 표준 시험에서 만점을 받고, 모든 학문 분야의 대학원·박사 수준 문제도 전례 없이 뛰어난 성과를 보임

     ""학술적 질문에 관해서는 Grok 4가 모든 과목에서 대학원생들보다 똑똑하다""
     * Grok 2는 개념 모델, Grok 3는 다양한 데이터 소스 기반의 사전학습에 초점, Grok 4는 2에 비해 100배, 3에 비해 10배 더 많은 연산 자원과 데이터로 훈련됨
     * Colossus 슈퍼컴퓨터(20만 GPU)에서 사전훈련 및 RL 중심으로 학습
          + 강화학습(RL) 에 집중, 모델이 문제 해결 과정에서 피드백을 받고 점진적으로 성능을 개선하는 자기 오류 교정 구조 채택
          + 논리적 문제 해결력 및 “first principles” 사고에 기반해 짧은 시간 내 최대 진보를 이뤄냈음을 강조함

2가지 버전의 모델

     * 기본 모델인 Grok 4 와 성능 향상 버전인 Grok 4 Heavy
     * Grok 4 Heavy 는 멀티 에이전트 방식으로 여러 에이전트가 동시에 문제를 해결하며 서로 결과 비교를 통해 최적의 답을 찾는 집단 지능을 구현
          + SuperGrok Heavy 구독 서비스로 사용가능(월 300달러)

AGI Scoring Breakthrough

     * Grok 4는 ARC-AGI 테스트에서 15.9%라는, 업계 최고 수준의 점수를 기록함
     * ARC-AGI는 모델의 일반 지능과 추상적 문제 해결 능력을 평가, 시각적 패턴 인식 및 새로운 시나리오 적용 능력을 중점 측정함

Humanity's Last Exam (HLE) 성과

     * 2025년 1월 도입된 Humanity’s Last Exam(HLE) 은 수학, 생물, 사회과학, 물리, AI, 공학, 화학 등 100여 개 분야, 2,500문항으로 구성된 초고난도 벤치마크임
     * Grok 4의 성적: ""실제 인간이나 기존 AI가 접근할 수 없는 수준""
          + 도구 미사용 시: 26.9%
          + 도구 활용(Grok 4 Heavy): 41%
          + 테스트 시 추가 연산(32배) 적용: 최대 50.7%까지 도달
     * 도구 미사용은 내장된 언어/추론 능력만으로 문제를 해결, 도구 사용은 코드 실행·웹검색·외부 데이터 활용 등 멀티에이전트 시스템과 결합된 방식임
     * 트레이닝 컴퓨트는 20만 개 GPU 기반의 Colossus 슈퍼컴퓨터로 모델 지식과 도구 사용 능력을 훈련, 테스트 타임 컴퓨트는 문제 풀이 시 모델 여러 개를 병렬로 돌리며 결과 검증과정 포함

     “Grok 4는 모든 분야에서 PhD 수준 이상”
     ""조만간 신기술/신물리학 발견까지도 기대함""

주요 AI 벤치마크 성적

     * AIME: 고등학교 수준의 복잡한 수학 문제 해결력
     * GPQA: 물리 등 대학원 수준의 과학적 추론 평가
     * LiveCodeBench: Python 프로그래밍 챌린지 기반의 코딩 실력 측정
     * MMLU-Pro: 다양한 전문 분야의 고난이도 객관식 문제 풀이 능력
     * LOFT: 장문의 텍스트에서 복잡 쿼리에 필요한 정보 추출력 평가

실용 사례 및 리얼월드 적용

     * 비즈니스 시뮬레이션(벤딩벤치)에서 Grok 4는 전 모델 대비 2배 이상 성과 및 일관성을 보이며, 장기간 전략 수행 능력 입증
     * 생명과학 연구소 등에서는 대규모 실험 로그 분석, 가설 도출, 의료 영상 판독에 도입되어 실제 업무 효율을 증명함
     * 게임 개발에서는 게임 자산 자동 수집과 코드 생성까지 단 한 명의 개발자가 3D 게임을 빠르게 완성할 수 있게 지원

네이티브 보이스 모드 혁신

     * Grok 4는 실시간 음성 대화 지원, 중간에 자연스러운 인터럽트, 감정적 억양 이해/재현, 초저지연 반응 등으로 기존 TTS 시스템을 뛰어넘는 인간형 상호작용 제공
     * 여러 종류의 음성(영국식, 트레일러 스타일 등) 추가 및 라이브 데모로 실시간 대화의 부드러움, 신속성, 다양한 활용성 시연

API 및 생태계 확장

     * Grok 4는 API로도 공개하여, 누구나 벤치마크 테스트 및 비즈니스 적용 가능
     * 실제 금융, 과학, 엔터테인먼트 등 다양한 분야 파트너가 도입 중, 리얼월드 임팩트 증대
     * 256k context length 제공으로 장문·복합 작업 처리력 강화

한계와 향후 발전

     * 현시점에서 Grok 4의 가장 큰 약점은 이미지·비디오 등 멀티모달 이해/생성 능력 부족
     * 곧 훈련 완료되는 v7 파운데이션 모델과 추가 강화된 RL로 비전·비디오·오디오 전방위 개선 예정
     * 비디오 생성 모델(100,000+ GB200 GPU 활용) 개발 및 출시 예고

xAI의 향후 로드맵

     * 2025년 8월: 코딩 모델 출시 예정
     * 2025년 9월: 멀티모달 에이전트 공개
     * 2025년 10월: 비디오 생성 모델 발표 계획
     * 도구와 모델 성능을 지속적으로 강화할 예정임

결론 및 시사점

     * Grok 4는 추론력, 학문적 문제 해결력 등에서 현존 최고 AI들과 실질적으로 경쟁하거나 앞서는 수준을 입증
     * 전례 없는 지능·추론력, 실시간 음성 상호작용, 도구 활용 및 멀티에이전트 구조 등 차세대 AGI의 실질적 전환점 제시
     * 실제 업무/비즈니스/게임/연구/엔터테인먼트 등 다방면 확장성과 함께, xAI는 가장 빠른 AGI 기업으로 자리매김할 것
     * xAI의 빠른 개발 주기와 공격적 행보는 AI 산업 경쟁이 계속해서 가속화되고 있음을 보여줌

   Grok 4가 이제 선두 AI 모델임
   Simon Willison의 Grok 4 리뷰
   Grok은 이스라엘-팔레스타인 문제에 대해 Elon Musk가 X에서 뭐라고 하는지 검색합니다

   뭐 실제 사용해봐야 알겠지만, 20만장의 GPU와 인재풀이면 이렇게 공격적으로 성장도 가능하군요.
   콜로서스가 100만장 GPU가 되면 또 얼마나 좋아지려나요.

   H100 5천만원 잡아서 GPU가격만 50조원. 데이터 센서 짓고, 주변에 전력도 필요하니까 한 20조까지 추가로 든다고 하니 70조원이네요. AI는 점점 돈싸움이 되는거 같아요.

   대학원생은 갑자기 왜끌고와서 패는지ㅋㅋㅋ

   ㅋㅋㅋㅋㅋ 갑자기 얻어맞은 대학원생 둥절 ..

   Grok 4가 대단하다는 것은 알겠으나 '조만간 신기술/신물리학 발견까지도 기대함' 같은 영미권 특유의 문구는 재밌습니다. 조만간 리만가설을 증명/반증 해주면 더 이상의 벤치마크 따위는 필요 없겠죠?

        Hacker News 의견

     * ""Heavy"" 모델이 한 달에 300달러임, 가격이 자꾸 오르는 느낌을 받음, 예전엔 가격이 계속 내려갈 거라 약속받은 것 같았음, GPU가 부족한 회사가 많아서 이런 현상이 생기는 듯함, Google 같은 업체는 이런 문제가 없을 것 같음, 이미 Gemini 2.5 Pro는 AI studio에서 무료로 쓰고 있고, 무려 32k까지 세팅해도 요금이 전혀 나가지 않음, 어쩌면 Gemini 3.0도 무료로 풀릴 가능성을 기대함
          + 고성능 모델에 대해 항상 비용이 저렴할 거라고 누가 약속한 적은 없는 것 같음, 같은 수준의 성능과 토큰 수 기준으론 가격이 떨어지고 있음, 마치 무어의 법칙처럼 칩이 계속 복잡해지긴 하지만 단위당 성능은 싸짐
          + Ferrari가 Model T보다 비싼 것이나, 가장 값비싼 컴퓨터가 첫 PC보다 월등히 비싼 것과 비슷한 원리임, 실제로 내려가는 가격은 엔트리 레벨이거나, 같은 성능 유지되는 라인임, 다만 전체 가격대는 점점 넓어지는 것이 당연한 현상임, 이 업계가 성숙해지고 있다는 신호로 받아들임, 이번엔 엔트리 레벨이 VC 펀딩 때문에 인위적으로 0 혹은 매우 낮았던 게 차이점임
          + Gemini 역시 가격이 계속 오르고 있다는 점도 중요하게 봐야 함, 관련 링크
          + 추론 시간(인퍼런스 타임) 때문에 생기는 비용 스케일링 현상임, 결국 AI 접근 비용으로 ‘갖는 자’와 ‘못 갖는 자’의 격차가 크게 벌어질 것 같음, 전 세계의 대부분은 수백 달러의 구독료를 감당 못함
          + O3는 최근 80% 가격 인하함, Grok4는 출시한 지 얼마 안 되었고 성능도 좋으면서 꽤 합리적인 가격임, heavy 버전이 아니라면 token 단가도 grok 3와 동일함, Google은 존재감 키우려고 비용 감수하는 것 같음, 그래서 원문의 불만이 잘 이해가 안 됨
     * 실제로 이번에 나온 게 새로운 SOTA(State of the Art, 최신 최고 모델) 맞는 것 같음, o3, Gemini, Claude보다 Human’s Last Exam, GPQA, AIME25, HMMT25, USAMO 2025, LiveCodeBench, ARC-AGI 1, 2 등에서 점수가 현저히 높아짐, 몇 주 내에 특화된 코딩 모델도 출시 예정임, 오늘은 코딩 성능 이야기는 많이 안 한 걸 유의함
          + 동의함, 오늘 월드시리즈 시뮬레이션에서 불안한 추론 느낌을 받았음, Polymarket에서 숫자를 가져와서 자기 데이터처럼 보이게 답변함, 물론 자세히 보지 않아 착각일 수 있으나 이런 사례 보면 선구자 모델의 안전팀에 회의적 시각 가진 사람이 꼭 필요함을 다시 느낌, 그럼에도 어마어마한 발전임, 벤치마크가 오염되지 않은 조건이라면 데일리 드라이버로 폭발적 인기를 끌 것 같음, 코딩은 256k 컨텍스트만이 유일한 아쉬운 점인데, v7에선 더 긴 컨텍스트–특히 비디오 관련해–개선을 기대함, 어쨌든 빨리 써보고 싶음
          + 코딩 모델이 코딩 에이전트에 제공됐으면 좋겠음, 어디에서도 찾아 볼 수가 없음
          + 모델을 검열하면 점수가 급격히 떨어진다는 건 꽤 오래 증명된 내용임, 예를 들어 폭탄 만드는 법은 막아야 하겠지만, Grok 3는 최악의 데이터에 접근하면서도 지속적으로 진보적 입장을 취했음(스폰서 배경 감안)
          + Elon Musk에 대해 호의적이지 않더라도 Grok가 Google, OpenAI, Anthropic 같은 빅3와 동급까지 따라온 건 정말 놀라움, 이제 거의 같은 수준임
     * Grok 4를 방금 써봤는데 너무 좋음, Java CDK로 1000줄 EC2 인스턴스 구축 코드를 한 번에 생성했음, VPC와 Security Groups 포함해서 구문 에러 하나도 없었음, 특히 userData(#!/bin/bash 명령어) 생성 시 최신 소프트웨어 artifact를 GitHub에서 정확한 주소로 wget해 줬음, 정말 대단함
          + 결과를 공유 가능하다면 꼭 보여줬으면 함, 이렇게 많은 코드가 한 번에 에러 없이 나오면 확실히 놀랍다고 생각함, grok가 이런 쿼리에서 툴(린터, 샌드박스 실행, 웹 서치 등)도 돌리는지 궁금함
          + 1회성 코드로서는 훌륭하지만, 소스 관리와 협업, 표준 SDLC 준수, 불변성, 상태 변경 이력 관리까지 요구하는 유지보수 가능한 코드로는 아직 한참 부족함, 만약 인턴이 이렇게 EC2 배포 코드를 썼다 하면 결정 하나하나에 대해 긴 대화를 나눠야 할 것 같음
          + Java 대신 typescript로 CDK를 안 쓰고 Java로 쓴 이유가 궁금함, 혹시 모든 환경을 하나의 언어로 통일하려고 한 것인지 질문함
     * Grok Heavy의 핵심 트릭은 여러 에이전트를 병렬로 띄워서 결과를 비교하는 구조임, 전체적으로 매우 인상적인 벤치마크 결과임, 비싸고 느릴 수밖에 없지만 차세대 에이전트 디자인의 논리적 흐름임, 실제로 써보고 싶음, 참고로 API도 오픈함, xAI가 뭔가 해내긴 한 듯함
          + 어떻게 동작하는지는 이해함, 그래도 어딘가 ‘핵(hack)’처럼 느껴짐, LLM 자체는 더 이상 뚜렷한 발전 없이 깊이, 길이, 폭 등으로 외연만 확장되는 느낌임, 결국 주변부에 ‘비AI’ 도구나 논리를 덧붙이는 방식으로 성장하는 듯함, 원시 신경망의 해법이 단순히 하드웨어 성능 기하급수적 성장 기다린 거였던 것처럼 이 방향이 해법일 수도 있다고 생각함
          + 비싸고 느리긴 하지만, 실제로 차세대 SOTA 모델을 훈련하려면 어차피 이런 방식으로 거절 샘플링 등으로 좋은 합성 데이터를 써야 함, 사용자에게 300달러 받고 이런 경험을 제공하는 것은 꽤 합리적인 딜 같음
          + llm-consortium과 비슷하지만 모델 다양성이 부족하다는 점이 차이임, karpathy 트윗과 llm-consortium 오픈소스 참고할 수 있음
          + 개인적으로는 이런 기법을 ‘문제 있는 회사’ 말고 다른 곳에서 구현해주길 더 기대함, 나름의 원칙을 계속 지키고 싶음
          + o3 pro도 아마 저런 방식으로 동작한다고 생각함
     * 출시 영상 시청할 여유가 없다면 클립본을 만들어 놓았음, 결론은 정말 대단하고 AI 경쟁이 점점 더 치열해진다는 것임, Short Clips 보기
     * Grok 4로 lldb를 python에서 돌릴 때 일관되지 않은 동작 문제를 해결했음, 도커와 내 로컬 리눅스 환경에서 차이가 있었는데, address sanitizer가 환경에 따라 다르게 작동함이 원인이었음, O3는 못 잡아줬던 부분이었는데 Grok 4는 잘 짚어줘서 감탄함
     * ""Grok 4 (Thinking)""가 ARC-AGI-2에서 15.9% 달성함, 기존 상용 SOTA를 거의 두 배 가까이 올렸고, 현재 Kaggle대회 최고 기록까지 갱신함, 상세 정보
     * 너무 인상적이긴 한데, Elon 개인 성향에 맞춰 포스트트레이닝된 모델을 기업들이 API 프로바이더로 쉽게 선택할 수 있을까라는 의문이 큼, 기술적으론 뛰어나지만 비즈니스적으로는 한계점이 보임
     * Grok는 API는 안 쓰고 딥 리서치용으로 썼을 때 늘 최고 수준임, Grok 4는 그 가능성이 더 커 보임
          + Grok의 트위터 통합이 실사용 사례 중에서 단연 최고임, 트윗 안에서 맥락이나 용어 의미를 실시간으로 바로 물어볼 수 있어 매우 유용하다고 느낌
          + OpenAI가 나에겐 모든 경쟁사보다 확실히 더 낫긴 함(그래도 좋다고 하긴 어렵지만), Grok가 실시간 업데이트나 IT 지원 질문엔 최고라고 느낀 건 사실임
          + <deep research> 의미가 뭔지 조금 더 구체적으로 들을 수 있는지 궁금함
     * Grok와 연동해본 사람이 있는지 궁금함, 지금까지 LLM 연동을 정말 많이 했지만 Grok는 실제로 쓰는 케이스를 본 적이 없음, 극복 안 하면 어느 누구도 이 모델을 신뢰하지 않을 것 같음, 진짜 제대로 된 역량 보여주기 전까진 기업에서는 안 씀, 기업다운 분위기도 아님
          + Grok 3가 Azure AI Foundry에 올라가 있음, 텔레그램과도 연동 발표했는데 사실 Grok 쪽에서 텔레그램에 3억 달러를 지불하는 구도였음, 링크 Grok 3 및 mini, Azure Foundry 소개, BBC 기사, 어쨌든 Grok 선택은 심각하게 평판 리스크라고 생각함
          + Grok가 인재를 어디서 어떻게 데려오는지 더 궁금함, 지금 이 바닥에 돈도 넘치고 좋은 연구소도 많다보니 이제는 고도화된 이념이나 믿음 없이는 이직 결정을 내리기 힘들 듯함, 정말로 Elon을 제왕으로 여기고 싶어하는 AI 연구원이 그렇게 많은 건지 의문임
          + Grok로 음식 이미지를 시각적으로 분석하는데 잘 동작함, 브랜드 인식이나 사용자들이 이상하게 찍은 사진도 잘 알아봄, API도 정말 쓰기 쉬움
          + 지난주 자기 스스로를 “Mecha Hitler”라 한 모델을 실제 서비스에 연동한다는 건 제정신 아닌 선택이라고 생각함, Musk 팬이지만 그가 Sama를 비난하면서 스스로 그와 똑같이 강력하지만 통제력 약한 AI를 내놓는 중임을 반드시 짚고 싶음
"
"https://news.hada.io/topic?id=21905","IKEA, Zigbee를 버리고 Thread로 전환하며 Matter 스마트홈에 올인","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             IKEA, Zigbee를 버리고 Thread로 전환하며 Matter 스마트홈에 올인

     * IKEA가 기존 Zigbee에서 Thread와 Matter 중심의 스마트홈 전략으로 전환함
     * 내년 1월부터 20개 이상의 Matter-over-Thread 제품(조명, 센서, 리모컨 등) 출시 예정
     * Dirigera 허브가 Matter Controller 및 Thread Border Router 기능으로 업데이트되어, 다양한 브랜드와의 연동성 강화 전략임
     * 새 제품들은 가격 경쟁력과 더불어 Apple Home, Amazon Alexa 등 여러 플랫폼과의 호환성을 제공함
     * Zigbee Touchlink와 Matter의 동시 지원으로, 기존 제품과의 호환성도 확보함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

IKEA의 스마트홈 전략 전환

     * IKEA가 자사 저가형 스마트홈 라인을 재출시하며, 이제는 자체 허브 없이도 다른 브랜드 제품과의 호환성을 높이는 전략을 채택함
     * 내년 1월부터 20개 이상의 Matter-over-Thread 기반 스마트 조명, 센서, 리모컨 등의 신제품을 출시하며, 향후 다양한 제품 카테고리와 폼팩터도 추가할 계획
     * 오디오 제품군도 새롭게 개편하여 저렴하면서 사용하기 쉬운 Bluetooth 스피커(Nattbad, Blomprakt 등)를 새로 공개함

전략 배경 및 주요 목표

     * IKEA는 “더 많은 사람을 위한 단순하고 저렴한 스마트홈”이라는 전략적 목표 하에, 기존 Zigbee와 Sonos와의 협업 경험 및 Matter 표준 개발 참여에서 얻은 노하우를 기반으로 한 대전환임
     * Dirigera 허브 소프트웨어가 업데이트(베타)되며, 허브가 Matter Controller 및 Thread Border Router 역할을 수행하게 되어, 다양한 브랜드의 Matter 호환 기기들을 IKEA Home Smart 앱에서 통합적으로 제어 가능함
     * 이번 업데이트는 기존 Zigbee 제품을 Matter 생태계(Apple, Amazon 등)과 연결시켜주는 Matter Bridge 역할도 강화함

제품 및 호환성 세부사항

     * 앞으로 출시될 Matter-over-Thread 기기들은 기존 기능(스마트 전구, 플러그, 센서, 리모컨, 공기질 기기 등)을 대체할 계획이며, 신규 디자인으로 제공됨
     * 일부 신제품 카테고리는 2026년 1월 첫 출시 후 4월 이후 추가 예정이며, 가격은 기존 제품과 비슷하거나 더 저렴하게 책정함
     * Zigbee의 Touchlink 기능은 계속 지원되어, 별도 앱 없이도 Zigbee 리모컨으로 Thread 전구 제어 등 기존 제품 간 호환성 유지함

Matter와 Thread의 스마트홈 혁신

     * 새 Matter-over-Thread 제품들은 IKEA 허브나 앱 없이도 Apple Home, Amazon Alexa, Google Home, Samsung SmartThings, Home Assistant 등 주요 생태계에서 직접 설정·사용 가능함
     * Matter 도입은 상호운용성, 사용 편의성, 저렴한 비용을 실현하는 핵심으로, IKEA는 이를 통해 더 많은 고객에게 열린 스마트홈 경험을 제공하는 것을 목표로 함
     * 큰 변화에도 불구하고 IKEA는 비복잡성, 단순함, ‘작동하는 경험’을 중시하며, Apple Home 유저도 별도의 앱 없이 저렴한 IKEA 제품 이용 가능함

시장 및 업계 영향

     * IKEA의 이번 리부트는 대형 유통업체 중 Matter를 메인스트림 시장에 본격 도입하는 첫 움직임 중 하나임
     * Matter 표준은 출시 이후 파편화, 느린 채택, 호환성 문제 등 과제를 겪었지만, IKEA는 대중화와 저가 보급에 자신감을 표명함
     * Apple, Amazon, Google, Samsung 등 주요 기업이 Matter 개발에 참여하고, Thread 기술은 저전력/메시 네트워크를 통해 센서·조명·플러그 등의 스마트 기기에 최적임

Matter 기술 개요 및 주요 지원 생태계

     * Matter는 열린 소스의 IP 기반 스마트홈 연결 표준으로, Wi-Fi, 이더넷, Thread 등 다양한 네트워크에서 동작함
     * Thread는 2.4GHz 대역을 사용하는 저전력 무선 메시 프로토콜로, 직결·인터넷 연결 및 다른 네트워크 간 경유까지 지원함
     * Matter 지원 기기는 하나의 컨트롤러를 통해 모든 호환 생태계에서 사용할 수 있고, 여러 생태계에서 동시 제어(Multi-admin)도 가능함
     * Amazon Alexa, Google Home, Samsung SmartThings, Apple Home, Ikea, Aqara 외에도 수백 개 디바이스 제조사가 Matter 생태계를 지원함

결론

     * IKEA는 단계적으로 Matter 및 Thread 중심의 스마트홈 전략으로 전환함으로써, 열린 연동성, 시장 대중화, 저렴한 가격을 세 요소로 삼아 글로벌 스마트홈 시장을 리드하려는 포지셔닝을 명확히 함
     * Matter와 Thread 기반 신제품 출시를 통해 다양한 브랜드·플랫폼과의 연동성을 실현하고, 기존과 미래 고객 모두를 고려한 유연한 스마트홈 접근법을 제시함

   집에 zigbee 기기만 수십 개를 두고 쓰는 입장에서 이케아 물건은 HomeAssistant에 붙였을 때 제대로 동작도 안 하거나 배터리가 과하게 빨리 소진되거나 빠르게 고장나는 경험밖에 없었어서 신뢰가 전혀 안 갑니다. 마침 오늘도 스마트콘센트가 고장났구요.

        Hacker News 의견

     * Matter는 폐쇄적인 생태계임을 지적하고 싶음, PKI와 디바이스 인증서로 강제되며, Thread는 장치 출시에 로열티를 요구함, IKEA가 이 변경을 더 오픈된 생태계로 가는 것이라 주장하는 게 실망스러움, 그리고 스위치가 기존 하드웨어와의 호환성을 깨뜨림, 기존 Zigbee 기기가 많으면 새로운 장치 추가 시 전부 갈아야 하거나 네트워크가 조각나는 문제 발생함
          + Zigbee 기기가 많아서 새로 나온 기기 추가하면 네트워크가 분열될까 걱정하지만, 진지하게 스마트홈 구축하는 사람이라면 Home Assistant를 쓰게 됨, 이럴 경우 다양한 종류의 기기 추가는 문제 아님, 그냥 라디오 하나 더 설정하면 됨, 일부는 Zigbee와 Zwave를 같이 쓰고, 일부는 Zigbee+Wi-Fi 심지어 Zigbee+Zwave+Wi-Fi+클라우드 통합까지 Home Assistant에서 모두 가능함
          + 그 이야기는 완전히 정확하지 않음, Apple HomeKit처럼 인증 안 된 기기도 경고 메시지만 나오고 정상적으로 작동함, 나는 이 깃허브 패키지를 사용해서 Home Assistant 기기를 클라우드 연결 없이 Google Home에 노출시켜 사용함, 인증은 Z-Wave와 Zigbee의 가장 큰 차이이고, 내 경험상 호환성 이슈가 줄어듦, 물론 내가 쓴 GitHub 패키지에서는 그마저도 상관없고, 그냥 코드 클론해서 수정하면 됨
          + Matter는 많은 경우 인터넷 연결이 필요함, 오픈 홈 자동화의 구원자일 거라 기대했는데 결국 제조사가 마음껏 악용할 수 있는 조건들이 달려 있음, 오픈소스에게 충분히 열려있지 않고 제조사 입장에서도 인기 없는 이름임, 내가 일하는 회사에서는 마케팅 부서가 자사 앱의 데이터 수집과 교차판매 용도를 절대 포기하지 않으려 Matter, Thread 도입을 아예 비웃음, 그래서 난 오히려 이런 제품을 원하지 않음, 인증과 펌웨어 락다운이 대기업만 가능한 구조라는 것도 몰랐음, 왜 Thread와 Matter가 오픈 혁명처럼 홍보된 건지 이해할 수 없음, 실상은 그 반대임
          + ""폐쇄적""이란 게 제품이 표준을 준수해 인증만 받으면 누구나 참여 가능한 거라면, 그 점은 괜찮음
          + Matter는 오픈 스탠다드임을 알려주고 싶음, Matter 위키 소개 링크
     * IKEA 디바이스는 Home Assistant와 Zigbee를 통해 완벽하게 통합되고 디자인도 훌륭해서 너무 마음에 들었음, 이런 것들이 없어진다는 게 끔찍함, 예를 들어 리모컨의 배터리가 부족할 때 인디케이터가 깜빡이는 것 자체도 디자인적으로 감탄했음, 그런데 Thread가 메쉬 네트워크로 IPv6를 지원한다는 점을 알게 됨, 기존에는 Zigbee 네트워크와 IP 네트워크가 한 집에서 경쟁하는 게 어색했음, 표준 네트워킹으로 모든 피어가 자유롭게 명령을 주고받는 게 좋아 보임, Matter/Thread가 밝고 오픈된 미래가 될지 궁금함, 누가 확인해줄 수 있을지 묻고 싶음, 사람들이 똑똑한 집에 회의적이지만 실제로 집 전체가 프로그래밍 가능하면 엄청나게 유용함, 모든 조명·센서가 프로그래밍 가능하다는 건 별로 혁신적이지 않아 보여도 정말 쉽게 구현되고 멋있게 느껴짐, 예를 들어
       파트너가 '회의 중 입장금지' 빨간 전구를 켤 수 있고, PIR, 도어 센서, Ring 모션 감지로 외부 조명이 자동, 실내 램프가 순차적으로 켜짐, 버튼 하나로 녹색/빨간불 제어도 가능, 실내 Ring 카메라까지 집에 아무도 없을 때만 켜짐, 이런 것들이 Home Assistant 덕분에 정말 사소하게 가능해짐
          + Matter/Thread의 미래에 대한 질문에 폐쇄 시스템임을 다시 한 번 말하고 싶음, PKI와 디바이스 인증으로 승인된 파트너 제품만 허용되어 소규모 혹은 자작 디바이스 진입은 불가능하다고 봄
          + Zigbee와 IP가 경쟁한다고 했는데, 오히려 분리된 게 장점이라 생각함, 해킹당한 디바이스가 네트워크에서 데이터 유출할 위험이 적어서 와이파이 연동 장치는 아예 피하고 있음
          + Thread Border Gateway(Apple TV, HomePod, Google Nest 등)가 Thread IP 공간을 위해 IPv6 라우터 광고를 네트워크에 뿌림, 여러 게이트웨이가 광고해도 중복되어 신뢰성 확보 가능함, 나는 네트워크 분리 환경에서 라우터가 이 경로를 받아 Thread 디바이스와 통신 가능하도록 했고 대체로 잘 됐음, 하지만 폰에서 여러 장치로 신뢰성 있게 통신하는 데에는 여전히 어려움이 있었음, mDNS 리플렉션 문제로 골치였고 이를 golang mdns-reflector로 수정도 해보고 있음, 일부는 성공했으므로 아직 완성은 아님
     * Thread가 Zigbee와 비교해 해결하는 문제가 뭔지 이해가 안 됨, Thread는 허브 없이 쓸 수 있다는데 실상은 Border Gateway가 필요하니 허브와 다를 게 없어 보임, Home Assistant에서는 그냥 Zigbee 라디오만 있으면 허브 없이 가능함, Thread의 유일한 강점은 제조사 지원 같지만, 그게 Zigbee도 충분히 가능했을 텐데 굳이 Thread가 왜 필요했는지 의문임
          + Matter는 간단히 말해 Zigbee Alliance(이제는 CSA)가 만든 차세대 Zigbee임, Thread는 Matter보다 먼저 존재했고, Wi-Fi, Ethernet 등과 함께 지원되는 여러 운송 프로토콜 중 하나임, 그리고 Matter에는 Zigbee에 없던 블루투스 프로비저닝이 추가되어 QR 코드나 숫자를 입력할 필요 없이 폰으로 기기 추가가 쉬워짐, 또 재미있는 점은 Home Assistant도 CSA 멤버라서 Google, Apple 등이 테스팅에 사용하고 있음
          + 내가 이해한 바로는, Thread는 메쉬 네트워크를 IPv6(이더넷, Wi-Fi 포함)로 투명하게 확장할 수 있음, 반면 Zigbee(혹은 Z-Wave)는 메쉬 한계를 넘어서 확장하려면 정말 골치 아픔, 내 Z-Wave 네트워크는 컨트롤러 두 대를 쓰는데 정말 관리가 최악임, 복수 컨트롤러 구조는 zwave-js-ui도 거의 지원이 안 되고, 노드와 잠깐 연결이 끊겼을 때 자체 복구도 느림, 로밍도 사실상 불가능함, Thread는 네트워크에 연결된 몇 개의 간단한 기지국으로 관리하기 쉬운 개념이라서 기대 중임, 단점은 Apple Home Thread와 Google Home Thread, Home Assistant Thread 네트워크가 각기 호환성이 온전히 맞지 않다는 점이 실망임
          + 내 생각에 Thread는 Zigbee보다 지연도 짧고 전력 소모도 적음
     * Matter/Thread가 대중화되는 계기가 되기를 바라는 중임, 현재 구글, 아마존이 ""Generic Switches""를 지원하지 않아 막혀 있음, 일반 스위치로 스마트 전구를 제어하는 게 안됨, 너무나 기본적인 요구라고 생각하는데 왜 안 되는지 이해 안 됨, Ikea에서 이런 설정이 가능하게 해준다면 정말 기쁨
          + 내가 뭔가 놓치고 있는지 모르겠는데, 어떤 종류의 스마트 버튼이든 전구 제어에 연결하는 건 전혀 문제 없어 보임, Home Assistant에서 일반 스마트 버튼을 추가해서 USB 스위치와 LED 제어도 해봤음, 혹시 케이스가 뭔가 다름? UPDATE: Matter 구현 현황 때문에 그런 것이라면 오해했던 것 같음
          + Matter에 엄청난 기대가 쏟아졌던 것을 기억하는데 실제로는 기대에 못 미침
     * 최근에야 IKEA Zigbee 하드웨어를 접하고 투자했는데, 항상 그들의 다른 제품들은 MBA들이 망쳤지만 이 제품만은 잘 만들었더라, 내구성, 가격 모두 적당했고, 무엇보다 허브 없이, 클라우드 가입 없이 쓸 수 있는 게 가장 좋았음, 나는 ConBee II와 Go 코드로 센서 데이터 수집 및 빠른 조작까지 지연 거의 없이 구현했음, 이처럼 훌륭한 제품 라인이 사라진다니 안타까움, 다음 홈 자동화 기술엔 투자하지 않으려 함, Zigbee가 지금 역할에 완벽한데 왜 또 새로운 표준이 필요한지 모르겠음, 심지어 아직 x10 쓸 때도 이랬었다는 회상까지 있음
     * 기존 Ikea 전구와 허브를 가진 사람에게 어떤 변화가 올지 궁금함, 새로운 Ikea 전구나 장비를 추가하면 별도 시스템으로 관리해야 되는 것인지 알고 싶음, 참고로 지금까지 Ikea 전구는 고장도 없이 7년 넘게 잘 쓰고 있음
          + 새 DIRIGERA 허브는 두 가지 라디오를 모두 탑재했고 최근 펌웨어로 Thread 지원이 완벽해졌으니 괜찮음, 다른 최신 허브로 바꾸거나 기존 전구를 마이그레이션 하면 됨, IKEA 스마트 기기는 진짜 잘 작동하고, 값싼 가구와 미트볼 파는 회사가 대형 테크 기업보다 똑똑한 스마트 전략을 가진 건 신기함
          + 계속 기존 장비가 작동할 걸로 보임, 기사에서 하위 호환성 언급이 여러 번 있음
          + 스마트홈의 역사가 이런 식임을 지적하고 싶음, 결국 돈은 사람들이 한 시스템에 묶이는 데서 나오다가 그 시스템이 순식간에 구형이 됨, 표준도 있지만 실상은 폐쇄된 정원 시스템의 근거일 뿐임, 나는 이런 시스템 전부 피함
     * 조명이 무선 공유기처럼 구형이 돼버리는 상황이라니 재미있게 그려짐
          + 수동 조작 그대로 작동할 수도 있지 않을까 하는 의문 제기
     * IKEA Zigbee 제품은 거의 최고 수준이었는데, 이제 RIP임, Matter는 아직도 쓸 수 없는 복잡한 시스템임
          + 내 경험상 Matter는 이미 Zigbee, Z-Wave보다 더 잘 작동했고, 해마다 좋아지고 있음, 구체적으로 어떤 점에서 unusable mess라고 생각하는지 더 듣고 싶음
          + Matter 미지원 기기를 업데이트해서 써봤는데 실제로는 아무 변화 없이 똑같이 동작함
     * 지원 비용 문제도 기술적인 이유만큼 큰 원인일 수 있음, 내 가족이 Zigbee, Thread 둘 다 쓰는 회사에서 고객지원 역할을 하는데 Zigbee 디버깅 지원콜이 가장 오래 걸리고 비용이 높다고 함, IKEA의 고객지원이 어떨지 정확히 모르겠지만, 지원으로 안 끝나면 반품으로 이어져서 회사에도 큰 손해임
     * 정말 최악의 소식임, Zigbee는 문제 없이 잘 써왔고, Thread는 너무 말썽이라 아예 전부 버려버릴 정도였음

     Zigbee와 IP가 경쟁한다고 했는데, 오히려 분리된 게 장점이라 생각함, 해킹당한 디바이스가 네트워크에서 데이터 유출할 위험이 적어서 와이파이 연동 장치는 아예 피하고 있음

   이 장점 때문에 + 수십 개의 장비를 사용하면 네트워크가 마비될 수 있기 때문에 저도 Zigbee를 고수합니다. 뭐가 들어있는지도 모를 장비가 데이터를 인터넷으로 뿌릴 수 있다는 건 정말 피하고 싶거든요
"
"https://news.hada.io/topic?id=21913","Ask GN: 제 기술 블로그 글 여기에 올려도 되나요 ?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Ask GN: 제 기술 블로그 글 여기에 올려도 되나요 ?

   사람들이 많이많이 봐줬으면 좋겠어요

   링크랑 같이 올리면 사형이겠지요 ?

   광고걸려있으면 사형입니다.

   뭔데요!!

   언능 올리십쇼.ㅎㅎㅎㅎㅎ 안 좋은 블로그 글이 어디있나요. ㅎㅎ

   그러면 항목을 뭐라고 올리면 좋을까요 ?

   show 탭에 올리면 되려나유

   제가 알기로 Show는 사용해볼 수 있는 제품이어야 합니다.
   블로그 글은 안 될 겁니다.
   자세한 내용 확인:
   https://news.hada.io/blog/show

   흑흑 감사합니다
"
"https://news.hada.io/topic?id=21942","ETH Zurich와 EPFL, 공공 인프라에서 개발된 LLM 공개 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ETH Zurich와 EPFL, 공공 인프라에서 개발된 LLM 공개 예정

     * ETH Zurich와 EPFL이 주도하여 공공 인프라에서 완전히 공개적으로 개발된 대형언어모델(LLM)이 곧 출시 예정임
     * 이 모델은 투명성, 멀티링구얼 성능, 폭넓은 접근성에 중점을 두어, 과학, 정부, 민간 등 다양한 분야에서 활용 가능함
     * 소스코드와 가중치, 학습 데이터가 공개되고, 모든 과정이 재현 가능하도록 설계되어 개방형 연구 및 규제 준수를 촉진함
     * 최신 슈퍼컴퓨터 Alps(CSCS)에서 친환경 에너지로 훈련되었으며, 대규모, 고성능, 책임 있는 데이터 사용을 목표로 함
     * 이 LLM은 Apache 2.0 라이선스로 여름 말 공개될 예정이며, 전 세계적으로 혁신과 연구 활성화에 기여할 것으로 기대됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개방형 LLM 구축을 위한 국제 협력 및 배경

     * 제네바에서 열린 International Open-Source LLM Builders Summit에서 글로벌 오픈소스 LLM 및 신뢰할 수 있는 AI 관련 50여 개 단체가 한자리에 모임
     * EPFL와 ETH Zurich의 AI 센터 주최로 열린 이 행사는 오픈 기초모델 생태계 활성화와 협력의 중요한 계기임
     * 오픈 LLM은 미국, 중국 등에서 비공개로 개발되는 상업용 시스템에 대한 대안으로 점차 인식되고 있음

새로운 공공 LLM의 특징과 출시 계획

     * EPFL, ETH Zurich, 기타 스위스 대학 연구자와 CSCS 엔지니어의 협업으로 완전히 공개적이고 공공 개발된 LLM이 곧 출시될 예정임
     * 현재 최종 테스트 단계이며, 오픈 라이선스로 다운로드 가능해질 예정임
     * 이 모델은 투명성, 다국어 성능, 폭넓은 접근성을 핵심 가치로 삼음

완전 개방 및 투명성 원칙

     * 모델의 소스코드와 가중치 모두 공개될 예정
     * 학습 데이터 또한 투명하게 공개되고 재현 가능한 방식으로 설계되어, 과학, 정부, 교육, 민간 영역에서의 채택을 지원함
     * 이러한 접근은 혁신 촉진과 책임성 강화를 목적으로 함

전문가 의견

     * ETH AI Center의 연구원 Imanol Schlag는 “완전 공개 모델은 신뢰도 높은 응용과 AI 리스크/기회 연구 발전에 필수적”이라고 강조함
     * 투명한 프로세스는 규제 준수 역시 용이하게 함

멀티링구얼 설계

     * 모델의 핵심 특징 중 하나는 1,000개 이상 언어 지원임
     * Antoine Bosselut 교수는 “초기부터 광범위한 멀티링구얼 지원에 집중”했다고 밝힘
     * 1500개 이상 언어의 대규모 데이터셋(영어 60%, 비영어 40%), 코드 및 수학 데이터로 기초학습을 실시함
     * 전 세계 다양한 언어와 문화의 콘텐츠를 반영, 글로벌 활용성이 높음

확장성 및 포용성

     * 모델은 80억(8B), 700억(70B) 파라미터 두 가지 규모로 공개될 예정임
          + 70B 버전은 세계에서 가장 강력한 완전 공개 모델 중 하나임
     * 15조 개 이상의 고품질 토큰(작은 텍스트 단위)으로 학습해 높은 신뢰성과 범용성을 구현함

책임 있는 데이터 사용

     * 스위스 데이터 보호법, 저작권법, 그리고 EU AI Act에서 요구하는 투명성 의무를 준수하여 개발 중임
     * 최근 연구 결과, 웹 크롤링 거부(로봇배제표준)를 존중해도 LLM 성능 저하가 거의 없음을 입증함

슈퍼컴퓨터 기반 개발 및 지속 가능성

     * 모델 학습은 루가노 소재 CSCS의 Alps 슈퍼컴퓨터에서 이루어짐
          + NVIDIA Grace Hopper Superchip 1만개 장착, 세계 최고 수준의 AI 인프라
          + 100% 탄소 중립 전기로 효율적 훈련 가능
     * Alps의 성공적인 구현은 NVIDIA, HPE/Cray와 15년간의 전략적 협업 덕분임
     * Alps는 대규모 AI 업무(복잡 LLM의 프리트레이닝 포함) 요구를 충족하는 핵심 역할 수행함
     * Thomas Schulthess 교수는 “공공 연구기관과 산업계의 공동 노력이 주권적 AI 인프라와 오픈 혁신, 전 세계 과학 및 사회에 기여함을 입증”한다고 강조함

공개 접근성과 글로벌 활용

     * 여름 말, Apache 2.0 라이선스로 LLM이 공개될 예정임
     * 모델 구조, 학습 방법, 사용 가이드라인 등 문서화도 함께 제공되어 투명한 재사용 및 추가 개발을 지원함
     * Antoine Bosselut 교수는 공공 연구자가 “오픈 모델 발전에 앞장서고, 다양한 조직들이 이를 바탕으로 자체 응용을 개발하길 바란다”고 언급함
     * Martin Jaggi 교수는 “완전한 개방성은 스위스, 유럽, 국제협력을 통한 혁신을 촉진하고, 최고의 인재를 유치하는 데 있어 중요한 요인임”이라고 밝힘

        Hacker News 의견

     * 성과를 기대하는 중임, 내가 알기로는 ETH와 EPFL은 최신 LLaMA 모델이 아닌 이전 버전을 학습하거나 파인튜닝하고 있기 때문에, SOTA 성능에 비해서는 다소 뒤처질 수 있음, 하지만 가장 중요한 점은 ETH와 EPFL이 대규모 학습 경험을 쌓는 것이라고 생각함, 들은 바에 따르면 새롭게 구축된 AI 클러스터가 아직까지 초기에 많은 시행착오를 겪고 있음, 이 규모에서 자체 인프라로 모델을 학습하는 것이 얼마나 까다로운 일인지 사람들이 종종 과소평가함<br>참고로 나는 스위스에서 태어나 ETH에서 공부했음, 두뇌는 충분하지만 대규모 학습 경험은 아직 부족한 상태임, 또, 개인적으로 LLM의 많은 ""마법""이 실은 인프라에서 나온다고 생각함
          + 사실 많은 마법이 데이터셋, 특히 SFT와 다른 파인튜닝/RLHF 데이터에서 나온다고 생각함, 그게 실제로 사람들이 사용하는 모델과 그렇지 않은 모델을 구분 짓는 요소였음, 경험을 쌓는다는 의견에는 완전히 동의하고, 인프라 구축이 주권적 LLM 공급망의 핵심 파트라 생각함, 하지만 데이터에도 초반부터 충분한 집중이 이뤄져야 모델이 실질적으로 쓸만해질 것임
          + SOTA LLM을 학습하려면 인프라도 꽤 복잡해짐, 많은 사람들이 아키텍처와 데이터셋을 올리고 Ray 같은 걸 쓰면 끝이라고 생각하지만 실제로는 데이터셋 설계, 평가 파이프라인 구축, 학습 방식, 하드웨어 최대 효율화, 노드 간 지연, 에러 복구 등 엄청나게 많은 요소가 필요함, 그래도 이 분야에 더 많은 플레이어가 나오는 건 좋은 일이라 생각함
          + ""from scratch""라는 문구를 보고 파인튜닝이 아니라 프리트레이닝을 하는 거라고 추측했음, 혹시 다른 의견이 있다면 궁금함, 그리고 일반적인 Llama 아키텍처로 진행하는 건지도 궁금함, 벤치마크 결과가 궁금함
     * <i>웹 크롤링 opt-out(수집 거부)을 존중해도 성능 저하가 거의 없다</i>는 문장이 매우 반가움
          + 학습 지표 상으로는 성능 저하가 없다 해도 결국 최종 사용자 입장에서는 다를 수 있음, 사용자와 웹사이트 소유주는 근본적으로 목표가 다름, 사용자는 답변과 컨텐츠를 원하고, 사이트 소유주는 광고나 추가 판매를 노림, 결국 둘 중 한쪽만 충족시킬 수 있음
     * 이번이 데이터셋 투명성과 관련해 기준을 새로 세우는 사례인지 궁금함, 실현된다면 중요한 진전이라고 생각함, 그런데 기계 이름을 AIps(AI Petaflops Supercomputer)로 지었다면 더 재밌었을 것 같음
          + Allen Institute for Artificial Intelligence에서 만든 OLMo 모델도 완전히 공개임<br><i>OLMo is fully open</i><br>AI2는 진정한 개방성을 데이터, 모델, 코드까지 공개하는 것으로 본다는 입장임<br>OLMo 자세히 보기
          + Smollm도 내가 아는 한 완전히 공개적인 모델임
     * 오픈 학습 데이터가 결정적인 차별점임, 이 정도 규모의 진정으로 열린 데이터셋이 처음인지 궁금함, 이전의 The Pile 같은 시도들도 가치 있었지만 한계가 있었음, 학습의 재현성을 어떻게 보장할지도 기대되고 있음
          + ""모델이 완전히 공개될 것: 소스코드와 가중치는 공개되고, 학습 데이터는 투명하며 재현 가능하다""는 문구를 통해 학습 데이터 전체가 공개라기보단 ""재현 가능하다""에 방점이 있다고 생각함, 아마도 실제 트레이닝에 사용된 페이지 URL 목록 같은 참고자료는 공개될 수 있지만, 그 콘텐츠 자체는 아닐 수 있음
          + 맞음, 여전히 전통적인 저작권 이슈가 끼어 있어서 패키징된 데이터셋으로 바로 제공되지는 않을 것임
     * 이런 게 바로 ""AI의 민주화""라는 의미임
     * 보도자료에서는 어떻게 만들었는지에 관해 굉장히 많이 다루고 있지만, 실제로 다른 오픈 모델과 비교해 어떤 역량을 가졌는지 정보가 거의 없음
          + 대학의 경우 '어떻게 만들었는가'를 교육하는 것이 핵심이기 때문에 이 부분에 집중하는 게 자연스러움
          + <i>모델은 8B(8십억)와 70B(70십억) 두 가지 버전으로 공개 예정이고, 70B 버전은 세계에서 가장 강력한 오픈 모델 중 하나가 될 것, 올여름 말에 Apache 2.0 라이선스로 공개 예정임</i>이라고 함, 실제로 9월에 확인해 볼 수 있겠음
     * 스위스인으로서 HN 최상단에 이 소식이 떠서 자부심을 느낌, 이 두 대학은 세계적 수준의 창업자, 연구자, 엔지니어를 많이 배출했음에도 늘 미국의 그늘에 가려 있었음, 하지만 훌륭한 공공 인프라/교육/정치적 안정성(+중립성) 덕분에 오픈 LLM 분야에서 특별한 기회를 잡을 수 있을 거라 생각함
     * 기사에서<br>""오픈 LLM이 점점 더 신뢰받는 대안으로 평가되는 중이며, 대부분의 상용 시스템은 미국 또는 중국에서 비공개로 개발 중이다""라고 언급함<br>현재 대규모 LLM을 만드는 회사들은 구독 유도, 상품 광고 등 수익화하려는 이유로 오히려 품질을 떨어뜨릴 유인을 가짐, 일부는 이미 정치적 편향까지 갖고 있음<br>유럽에서 학계와 정부 협업으로 공익 목적의 검색·AI 서비스를 제공하고, 사용자 중심으로 나아간다면 매우 의미 있을 것임
          + 그렇지만 이런 서비스를 제공하는 일 자체가 복잡함, 아무리 좋은 모델을 학습한다 해도 실제 서빙은 여전히 민간에서 이뤄질 것임, 그래서 본질적으로 수익화 압박은 남아 있음, AI의 경우 운영비가 크기에 이런 경향이 더 심해질 수 있음, 결국 무료 서비스라면 사용자가 상품이 되므로 가치를 적극적으로 추출해야만 수익이 남음
     * 실전 테스트도 빨리 해 보고 싶음
     * 왜 아직 출시도 전에 이런 식으로 발표하는지 의문이 듦, 솔직하게 얘기할 필요 있다고 봄
          + 이번 발표는 스위스에서 이번 주에 열린 International Open-Source LLM Builders Summit에서 있었던 일임, 일정과 계획을 공유하는 게 그리 이상한 일은 아니라고 생각함
          + 펀딩 목적일 수 있음, 그리고 유럽 사용자들에게 유럽에서 공공 개발한 LLM(적어도 미국, 중국산은 아닌 것)의 사용을 깊게 각인시키는 차원에서도 의의가 있음, (어쩌면 너무 논리적이라서 브뤼셀에서 승인 안 해줄 수도 있을 정도임)
          + 스위스에서는 뭔가를 할 때 매우 느긋하게 진행하는 게 클리셰임
"
"https://news.hada.io/topic?id=21921","메타 트래킹 기술이 유럽 개인정보 보호법을 위반했다고 독일 법원이 판결","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                메타 트래킹 기술이 유럽 개인정보 보호법을 위반했다고 독일 법원이 판결

     * 독일 법원은 Meta의 트래킹 픽셀과 기술이 GDPR을 위반한다는 판결을 내림
     * 이 판결로 인해 다른 사용자들도 개별적 손해 입증 없이 손해배상 소송을 제기할 수 있게 됨
     * 법원은 Meta가 개인을 식별하고 프로파일링해 막대한 이익을 얻는다고 언급함
     * 전문가들은 이번 판결이 트래킹 기술을 사용하는 모든 웹사이트와 앱에 대규모 소송 위험을 시사함
     * 한 명 당 5,000유로 손해액이 있어, 방문자가 많을수록 금액이 크게 증가할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

독일 법원, Meta 트래킹 기술의 유럽 개인정보 보호법 위반 판결

  주요 판결 내용

     * 독일 라이프치히 지방 법원은 Meta가 타사 웹사이트와 앱에 트래킹 픽셀 및 소프트웨어 개발 키트(SDK)를 삽입해 사용자 동의 없이 개인정보를 수집한다고 판결함
     * 이 판결은 해당 기술이 유럽 일반 개인정보 보호법(GDPR) 을 위반한다는 점을 명확히 함
     * 재판부는 Meta가 사용자 개별 동의 없이 개인 데이터에 기반한 프로파일링 활동을 통해 막대한 수익을 얻고 있음을 지적함
     * Facebook이나 Instagram 계정에 로그인하지 않아도, 제3자 사이트 방문 시 Meta가 개인을 식별할 수 있다는 점을 보도자료에서 강조함

  판결의 파급 효과

     * 이번 판결은 한 독일인 Facebook 사용자가 제기한 소송에서 Meta가 5,000유로(약 5,900달러)를 배상해야 한다는 결과로 이어짐
     * 재판부는 이번 판결이 개별적 손해를 구체적으로 입증하지 않아도 수많은 사용자가 유사 소송을 제기할 수 있는 선례가 된다고 언급함
     * 전문가들은 이 판결이 메타 트래킹 기술을 사용하는 모든 웹사이트와 앱 운영사에게 위험이 될 수 있다고 분석함
     * 컨설팅사 AesirX의 CEO는 이 사례가 집단소송(class action) 가능성과 ""사업에 치명적 영향""을 미칠 잠재력을 지녔다고 평가함

  향후 전망

     * Meta 트래킹 기술에 동의하지 않은 독일 방문자 모두가 집단소송에 포함될 수 있음
     * 방문자 수가 많을 경우, 손해배상 액수가 기하급수적으로 커질 수 있음
     * 전문가들은 이번 재판이 올해 유럽에서 나온 가장 중요한 판결 가운데 하나로 평가함

  참고 링크

     * 라이프치히 지방 법원 공식 보도자료

결론

     * 이번 판결은 개인정보 보호 강화와 이에 따른 테크 기업 및 웹사이트 운영자의 법적 책임에 중대한 변화 신호임
     * GDPR 준수를 위한 기술적 조치 및 사용자 동의 확보에 대한 산업계의 재점검 필요성이 높아짐

        Hacker News 의견

     * 이번 Leipzig 판결이 눈에 띄는 부분임에도 불구하고 실제 영향력은 €5,000이라는 금액만큼 크지 않을 수 있음, 법원이 피해자가 개별적인 손해를 증명하지 않아도 소송을 제기할 수 있다고 명시하였으나, 유럽의 집단 소송 방식은 미국식 소송과는 여전히 다름, 독일은 미국과 달리 성공보수 제도도 없고 패소 시 소송비용 부담 등 인센티브 구조가 다르며 집단 구제 방식도 제한적임, 대부분의 독일 소비자들은 추적 픽셀로 €5,000씩 개별적으로 소송을 제기하지 않을 것이고 시간과 비용이 만만치 않음, 이런 소송을 소비자보호단체나 자금여력이 있는 소송 전문 단체가 이끌어주길 개인적으로 바람, 독일도 집단소송 프레임워크를 확장 중이기는 하지만 아직 개별 원고보다는 자격 있는 단체 중심임
          + 독일에서는 모든 소비자들이 자동으로 포함되는 제도임, 다른 유럽국가와 달리 소비자들이 별도 소송 신청을 할 필요 없이 기본적으로 포함됨, 이런 이유로 X, Tiktok을 상대로 각각 EUR 500, EUR 2000 손해배상 청구 집단 소송이 독일에서 진행되는 중임
          + 누군가 이걸 상품화해서 “2500유로 무료로 드립니다! 여기 서명하세요!” 식으로 사업화 할 수도 있을 듯함
     * 항소심에서 이 판결이 그대로 유지되지 않을 수도 있다는 점은 주목할 필요 있음, 전체 결정문이 아직 공개되지 않았고 현재는 보도자료로만 내용을 알고 있음, 예를 들어 법원이 원고의 구체적 피해 진술도 듣지 않고 배상책임을 인정했으므로 이 방향이 실제 판결문에서 어떻게 논의될지 흥미로움, 이런 방식은 Meta가 충분히 항소할 수 있는 사안이라 봄, EU법의 미해결 쟁점이 있는 만큼 ECJ(유럽사법재판소)에 회부될 가능성도 있음, 어쨌든 이 판결로 단기적으로 법적 불확실성이 생겼고 많은 사람들이 소송하려 할 것 같음, 하지만 항소와 ECJ로 넘어가면 몇 년 걸릴 수도 있으므로 지켜봐야 할 부분임
          + Facebook과 실제 추적이 일어난 웹사이트 운영자 중 누구에게 책임이 있는지 헷갈림, GDPR상 광고 네트워크에 정보를 넘기기 전에 웹사이트가 동의받을 책임이 있다고 이해했음
     * 지금쯤이면 이런 사례에서 해당 사용자와 똑같은 상황인 사람을 추려 소송 대행하고 일부(예: 10%)만 수수료로 가져가는 다소 수상한 법률회사가 벌써 움직였을 법하고 그들이 소송해 준다면 나도 맡기겠음, 하지만 이런 문제는 개인의 소송이 아니라 법인에 직접 4%의 글로벌 연매출 벌금을 실제로 때리는 등 강하게 규제해야 회사들이 법을 권고사항 이상으로 받아들이게 됨
          + 항공권 보상 등 다른 분야에서도 이미 (정상적인) 기업들이 이런 서비스를 하고 있음, 독일 변호사법상 성공보수에 일부 제한이 있지만, 이 5,000유로 배상 청구는 단순 ‘채권추심’으로 볼 수 있어 허용될 수 있음, 더 큰 위험은 판결이 항소심 등에서 뒤집히거나 다른 지역 법원에서 판례가 다를 수 있다는 점임, 따라서 연방 대법원 또는 ECJ에서 확정될 때까지는 상당한 자본력을 가진 쪽만 이 판결을 기반으로 계속 소송을 끌고 갈 수 있음
          + 미국식 집단 소송과 동일한 형태는 유럽에 부재함, 유럽에는 ""대표 소송""이라는 EU 지침이 있긴 하지만 범위가 미국식 집단소송에 비해 훨씬 좁음
          + 이번 판례로 이제 class action 스타일 소송이 등장할 것 같음
     * 5년 전만 해도 이런 뉴스가 HN에 뜨면 미국 이용자들이 “유럽은 미국 기업을 뜯어먹으려는 핑계만 든다”며 시끄러웠는데, 이제 이 분위기가 완전히 바뀌었음, 유럽식 접근이 일부 부족해도 옳았다는 점이 증명되는 걸 보니 기쁨
          + 그런 주장들은 사실과 반대임, 실제로 벌금 대부분은 유럽 내 기업들에 부과되고 있음, Big Tech만 규정 위반하는 게 아니라 유럽 기업들도 자주 위반함, 단지 미국 이용자들은 그런 벌금 사건을 잘 모를 뿐임, 더불어 현재 개인정보보호법 체계는 90년대 독일 Bundesdatenschutzgesetz를 기반으로 했던 만큼 FAANG 등장 훨씬 이전부터 발전해온 역사임, 벌금 추적 사이트도 참고할 수 있음
          + 5년이 뭐야, 이런 이야기는 지난주에도 나왔던 것 같은 느낌임
          + 나는 미국인이지만 유럽 개인정보법에 대한 걱정은 관할권 문제뿐이었고, 이번 케이스에는 해당 사항이 없으므로 결정에 정말 동의함
          + 미국에서는 Google, Meta 등 초거대 기업에게 광고시장을 모두 내준 상태이고, 중소기업들은 구독제로 전환하는 식이니, 결국 EU가 구독모델마저 막지 않는 한 더는 해볼 방법이 없음
     * 정말 집단 소송으로 발전했으면 좋겠음, 나도 꼭 참여하고 싶음
     * 이제 이런 판결이 현실화되는 걸 기대함, 관련 블로그 분석도 참고할 만함
     * 늘 그렇듯 결국 의미 있는 변화가 일어나지 않을 것이라는 생각이 있음
     * 법원이 로그인하지 않아도 개인식별성을 강조했다는 사실이 흥미로움, 이로써 기업들이 즐겨 쓰는 “익명 추적” 방어논리를 정면으로 뚫는 셈임
     * Linkedin의 전체 분석에서 더 자세히 볼 수 있고, 독일에서는 소비자가 소송을 신청하지 않아도 자동으로 소송 대상에 포함되는 점이 유럽 타국과는 아주 다름
     * 이 사안이 결국 유럽과 미국 간의 지정학적‧무역 분쟁 소재가 될 수도 있다고 봄, 관세 문제까지 번질 수도 있음, 근본적으로는 유럽이 자국민 보호에 권한을 행사할 수 있느냐의 문제인데 솔직히 잘 해낼지는 의문임
"
"https://news.hada.io/topic?id=21899","왜 잘못된 일이 벌어지는가 Scale AI CEO Alexandr Wang의 메모 [번역글]","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          왜 잘못된 일이 벌어지는가 Scale AI CEO Alexandr Wang의 메모 [번역글]

   Scale AI의 CEO, Alexandr Wang이 2019년 Scale AI 팀에게 보낸 메모 중 일부

   정보 압축: 왜 일이 잘못되는가?

    1. 정보 압축이란 무엇인가?

     * 현실 세계의 복잡한 상황을 인간이 이해할 수 있도록 간단한 언어나 그림으로 전달하는 과정이 바로 ‘정보 압축’임.
     * 하지만 이 과정에서 대부분의 뉘앙스와 중요한 맥락이 사라짐.

    2. 왜 정보 압축이 문제를 일으키는가?

     * 압축 과정에서 필연적으로 정보 손실이 발생, 결과적으로 왜곡된 메시지가 전달됨.
     * 상대방은 실제 상황과는 거리가 먼 이미지를 머릿속에 그리게 되고, 그 기반 위에서 문제를 해결하려다 엉뚱한 결과가 나옴.
     * 대부분의 조직 내 의사소통 실패와 비효율성의 근본 원인은 이 정보 압축의 한계에 있음.

    3. 조직 규모와 정보 압축의 상관관계

     * 작은 스타트업(5명 미만) 은 모든 구성원이 맥락을 공유하고, 사전 지식(prior)이 비슷해 압축된 정보만으로도 충분히 소통이 가능함.
     * 조직이 커질수록 부서 간 벽(사일로)이 생기고, 공유 컨텍스트와 사전 지식이 약화되어 정보 압축의 부작용이 커짐.
     * 결과적으로 불필요한 인계, 오해, 비효율적인 결과물이 늘어남.

    4. 정보 압축 문제의 대표적 사례

     * 고객의 요구사항: 고객이 자신의 문제를 압축해서 전달하지만, 실제로 원하는 것과는 거의 일치하지 않음.
     * 비개발자→개발자 요청: 비개발자가 개발자에게 일을 요청할 때, 실제 난이도와 맥락이 전달되지 않아 엉뚱한 결과가 나옴.
     * 실제 문제와 무관한 솔루션: 표면적으로는 문제를 해결하는 것 같지만, 실질적 개선 효과가 없는 결과물이 나옴.

    5. 정보 압축의 해법

     * 인계 최소화, 직접 경험: 문제를 직접 경험하고, 인계를 줄이는 것이 최선.
       (예: 도그푸딩, 다양한 역할 직접 경험)
     * 강한 조직 문화: 사전 지식(prior)과 맥락을 조직 내에서 공유해야 함.
     * 고객과 코드의 거리 최소화: 고객 문제와 실제 개발이 긴밀하게 연결되어야 함.
     * 호기심과 추가 질문: 문제를 해결하는 사람이 끊임없이 질문하고, 맥락을 파악하려 노력해야 함.
     * 고객 출신 인재 채용: 실제 문제를 잘 아는 사람이 팀에 있으면 맥락 손실이 줄어듦.

    6. 핵심 요약

     * 정보 압축은 불가피하지만, 항상 불완전하다.
     * 조직이 커질수록 정보 압축의 부작용이 커진다.
     * 최고의 해법은 '압축'에 의존하지 않는 조직 구조와 문화, 그리고 직접 경험이다.

   당연하고 중요한 이야기지만, 실제로 실천하려고 하면 되게 어렵고 신경을 많이 써야 하는 부분이죠. 주변의 뛰어난 동료들은 압축된 정보를 잘 decompress 하는 감각이 뛰어났던 것 같습니다.

   좋은 말씀 감사합니다!

   실제로 꽤 많은 개발자들도 가능하면 문제를 직접 보고 이해하길 원할겁니다.

     호기심과 추가 질문: 문제를 해결하는 사람이 끊임없이 질문하고, 맥락을 파악하려 노력해야 함.

   이 부분이 가장 중요하다고 생각합니다.
   본질에 가까이 다가가려는 태도가 인계 최소화, 강한 조직문화, 고객과 코드의 거리 최소화 등 다른 해법을 만들어가는 동기가 되니까요.

   최근까지 주어진 요구사항을 구현하는데만 집중했는데, 개발을 다하고나니 실제로 효과는 미미한 듯한 느낌을 많이 받았습니다. 요즘은 요구사항 논의를 하기전에 ""필요한 이유""를 집요하게 물어보는데 이 과정에서 정답에 가까운 해법이 나오는 것 같습니다.

   맞아요 목적이 무엇인지, 왜 해야 하는지 깊게 파고들수록 명확한 해법이 나오는 거 같아요

   좋은 번역 감사 드립니다!

   글 좋게 봐주셔서 감사합니다!
"
"https://news.hada.io/topic?id=21951","Google의 대대적인 안티-애드블록 업데이트 우회 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Google의 대대적인 안티-애드블록 업데이트 우회 방법

     * Chrome의 MV3 업데이트는 기존 애드블로커의 기능을 약화시키기 위해 webRequestBlocking 권한을 제거함
     * 필자는 MV3 환경에서도 webRequestBlocking을 우회할 수 있는 버그를 2023년에 발견함
     * 이 버그는 JavaScript 바인딩의 허술한 구조와 옛날 코드가 그대로 남아 있었기 때문에 발생함
     * WebView 인스턴스 ID를 조작해 권한 체크를 우회함으로써 MV3 환경에서도 블로킹 기능을 사용할 수 있었음
     * 현재는 패치가 적용되어 더 이상 이 우회 방법이 작동하지 않음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

MV3와 애드블로커 변화

     * Chrome은 MV2 익스텐션을 단계적으로 폐지하고, 대신 MV3로 전환을 진행함
     * MV3는 webRequestBlocking 권한을 제거하여, 애드블로커가 네트워크 요청을 스크립트로 동적으로 차단하는 것을 막음
     * 해당 권한이 빠진 대신 declarativeNetRequest API가 추가됐지만, 같은 수준의 유연성을 지원하지 않음
     * 이 변화로 인해 애드블로커의 성능이 대폭 낮아지는 현상이 나타남

JavaScript 바인딩 구조의 한계

     * Chrome은 코어는 C++ 로 개발되어 있지만, 익스텐션은 JavaScript로 동작하며, 확장 API도 JS 바인딩을 통해 접근함
     * 2015~2016년까지는 사이트에 JS 파일(익스텐션 바인딩 모듈)을 삽입해 API를 초기화하고 검증함
          + 이 방식은 JS 전역 함수·프로토타입 오버라이딩에 취약하여 Universal XSS 버그 여러 건이 발생함
     * 이후 Google은 주요 바인딩을 C++로 이전했으나, 일부 JS 바인딩 파일은 여전히 남아 있음
     * 아직까지도 chrome.webRequest와 같은 특정 API는 JS 바인딩 구조를 사용하고 있음

웹 요청 이벤트 클래스를 활용한 우회

     * MV2에서는 웹 요청 차단이 아래 코드로 구현 가능했음
chrome.webRequest.onBeforeRequest.addListener(() => { return { cancel: true } }, { urls: ['*://*.example.com/*'] }, ['blocking'])

     * MV3에선 blocking 옵션이 금지되어 정상적 차단이 불가능함
     * 하지만 webRequest 이벤트의 .constructor를 통해 임의의 이벤트 객체를 생성할 수 있음
     * 내부적으로는 JS 바인딩의 특수 래퍼 클래스가 이 이벤트 객체를 관리함
     * 생성자 파라미터 중 하나인 opt_webViewInstanceId를 지정하면, 플랫폼 앱 전용 허용 로직을 우회하여 블로킹 권한 체크를 뛰어넘을 수 있음
let WebRequestEvent = chrome.webRequest.onBeforeRequest.constructor
let fakeEvent = new WebRequestEvent(""webRequest.onBeforeRequest"", 0, 0, 0, 1337)

fakeEvent.addListener(() => { return { cancel: true } }, { urls: ['*://*.example.com/*'] }, ['blocking'])

     * 원래 플랫폼 앱만 사용할 수 있도록 설계되었지만, WebView ID 검증이 미흡하여 일반 익스텐션에서 악용 가능했음

결과 및 보안 패치

     * 이 취약점으로 MV3 환경에서도 완벽한 애드블로커 개발이 실제로 가능했음
     * 필자는 해당 버그를 2023년 Google에 보고했고, Chrome 118에서 WebView 권한 소유 여부를 제대로 확인하는 방식으로 패치됨
     * 보상금은 지급되지 않았으며, 이는 추가 데이터 노출 없이 권한 우회만 가능했던 구조적 특성 때문임
     * 본 사례는 수십 줄의 코드 수정이 거대 기업의 보안 업데이트를 무력화할 수 있음을 보여줌

결론 및 참고

     * 버그는 현재 패치되어 더 이상 작동하지 않음
     * 유사하게 흥미로운 Chrome 익스텐션 관련 취약점 사례로, 실제로 CVE 번호와 $10,000 보상을 받은 이슈도 존재함 (별도 블로그 글 참조)

   그냥 파이어폭스를 쓰세요. 최근 1~2년간 많이 빨라져서 나쁘지 않아요.
   저는 수 년간 파이어폭스 메인으로 사용하며 가끔 크롬과 비교해보고 있는데 특히 최근에 파이어폭스가 충분히 쓸 만 하다고 느낍니다.
   한국 은행들처럼 웹 표준을 무시하던 웹 페이지들도 최근에는 많이 고쳐서 대부분 파이어폭스에서도 잘 작동합니다.
   커스터마이징은 파이어폭스가 훨씬 쉽고요.

   아마 저 업데이트 이후 애드블록 업체들은 매출 더 올랐을거에요.
   아예 네트워크단에서 막아버리는 스탠드얼론 앱은 유료로만 쓸수있어서 꽤 많이 팔렸을 듯.

   2년이나 지나서 아무 의미도 없어진 취약점을 올리면서 굳이 돈 안 줬다는 말을 한다라... 개인적으로 쿨하지는 않군요
   하지만 이런 것도 블로그에 써야 자기 가치를 증명할 수 있는 거겠죠?
   진심으로 저도 이런 마인드를 배워서 블로그에 글 좀 많이 쓰고 싶네요

        Hacker News 의견

     * Firefox를 한번 써보고 싶음에도 불구하고, 간혹 발생하는 웹사이트 로딩 버그와 더불어 PWA(Progressive Web Apps)를 설치할 수 없다는 점이 가장 큰 걸림돌임. Chrome과 그 계열 브라우저는 오래전부터 이 기능을 지원해왔는데, 왜 Firefox는 아직 구현하지 않았는지 잘 모르겠음. 서드파티 확장 프로그램(PWAs for Firefox)을 찾긴 했지만, 개인정보 보호 측면에서 사용하는 게 꺼려짐
     * Google의 행동을 우회하는 방법이 있더라도, 그건 올바른 방향이 아니라고 생각함. 만약 사람들이 Google의 움직임에 동의하지 않는다면, Chrome 및 Chromium 기반 브라우저를 모두 버리는 게 유일하게 올바른 방법임. Google의 독점에 타격을 주어 웹의 미래 방향에 대한 지배력을 빼앗는 것이 중요함
          + 오늘날의 독점은 모두가 IE에서 얻어야 했던 교훈을 잊은 탓이라 생각함. Web 표준을 배우지 않고 Chrome을 애플리케이션에 번들로 함께 배포하는 행태가 원인임
          + 기사 요지는 이게 아니고, 실제 기사에서는 이 우회법이 Chrome 118에서 패치됐다고 언급함
          + ""독점에 타격을 줘야 한다""라고 해서 실제로 뭔가 달라진 적이 있냐고 비꼬고 싶음
          + 현실적으로 그런 일은 일어나지 않을 것임
          + 많은 사람이 Google 추적 기능이 제거된 Chromium 브라우저로 갈아타는 건 충분치 않다고 여기는데, 사실 그건 Google이 오히려 바라는 프레임이라고 생각함. Firefox는 Chrome과 확실히 다르고 Chrome에서 넘어오기가 쉽지 않음. 반면 Brave, 커스텀 Chromium, Vivaldi 등은 Google 추적 없는 Chrome 수준이라 거의 동일함. ""Google이 여전히 Chromium을 통제하고 있어 안된다""는 주장이야말로 Google 입장에서 유포할 만한 FUD(공포, 불확실성, 의심)라고 봄
     * 진정한 우회는 Firefox를 쓰는 것임. uBlock Origin이 Firefox에서 가장 잘 작동함
       uBlock Origin works best on Firefox
          + 나는 늘 Firefox를 써왔기 때문에 이런 일이 일어나는 줄도 몰랐었음. 아내가 YouTube에서 광고를 본다고 해서 보니, 예전에 uBlock을 설치해줬는데도 그랬던 것임
     * Google이 MV3가 MV2보다 진짜 더 안전한지도 의문임. MV3로 바꾼다고 본질적으로 보안이 더 강화되는 게 아닌 것 같음
          + 솔직히 이걸 정말 믿는 사람이 있을지 놀랍게 느껴짐. 기사 자체도 명백한 이해 상충으로 시작함. 어떤 확장 프로그램이 사용자가 방문한 사이트와 요청 정보를 알 수 있도록 두는 건 확실히 취약한 환경임. 그럼에도 불구하고, 나는 광고회사와 데이터 수집업체들보다 uBO를 더 신뢰하기 때문에 그냥 그렇게 쓰는 중임
     * 누군가 adblocker 우회법을 찾아내서 Google에 알려준 경우에 대해, “찾아내고 바로 Google에 고자질하는군, 멋지다”는 반응이 있음
          + 사실, adblocker가 이걸 이용하기 시작했다면 Google이 즉각적으로 패치했을 거고, 해당 개발자는 아무 이득도 얻지 못했을 것임. 결국 아무것도 얻지 못하긴 마찬가지였다는 점이 아이러니임
     * OP가 Google에 아무 문제 없는 “이슈”를 보고해서, 애드온 개발자가 MV3 제한을 우회할 수 있는 방법을 막았음. $0의 가치가 있었기를 희망함
          + 이런 우회법은 길어야 하루 안에 Google에게 바로 제거됐을 것임. 오히려 OP가 금전적 보상을 받을 수도 있었으니, 충분히 할 만했다고 생각함. 비난하고 싶지 않음
          + 결론에 동의하지 않음. 모든 책임은 Google이 지는 것이 맞음. 만약 OP가 이슈를 알리지 않았다면, 나중에 다른 adblocker가 이 방법을 써도 Google이 금방 이걸 금지했을 거라 봄. 어쩌면 해당 확장 프로그램 자체를 Web Store에서 아예 삭제하는 극단적 조치도 했을 수 있음
          + 실제로 사람들이 사용하던 adblocker가 이 방법을 구현했다면, Google은 당연히 바로 막았을 것임. 무한정 활용 가능한 치트키 같은 게 아님
          + 나도 같은 생각임. OP는 대기업을 위해 공짜로 일해준 셈이고, 결과적으로 웹 환경을 더 불편하게 만들었음. 이유는 뭐... ""보안 때문""이라고 하겠지. 대단함
     * Brave를 쓰기 시작한 뒤로 Chrome이 전혀 그립지 않음
       Brave
          + 오히려 Brave가 Chrome보다 더 불편함. Brendan Eich의 문제도 있지만, 브라우저 안에 각종 임의 기능, 광고 차단(Brave Shields)을 완전히 끌 수도 없고, 암호화폐 관련 요소, 끌 수 없는 웹앱 다운로드 버튼, 지울 수 없는 UI 등 쓰레기가 너무 많음
          + Brave는 여전히 영리 기업이고, 기본적으로 불필요한 기능들이 과하게 많다는 점에서 거부감을 느낄 수밖에 없음. 하지만 ""Brave 다이어트 하는 법""처럼 설정을 슬림하게 바꾸는 팁 콘텐츠도 적지 않음
          + 엔진은 결국 Blink라서 외관만 바뀐 셈임. Manifest V2를 계속 유지하는 Blink 브라우저는 본 적 없음. 만약 있다 해도, 그건 소프트 포크라서 오래 못 버팀
          + Brave도 결국 Chromium 기반이니까, Chrome과 사실상 마찬가지임. Manifest V3는 결국 적용될 수밖에 없음
          + Brave 브라우저를 쓰지 말라는 비판적 시각도 있음
            Stop using Brave browser
     * ""adblocker는 webRequestBlocking이 꼭 필요하다, Google이 광고로 수익을 내니 이 기능을 뺀 건 매우 의도적이다""라는 주장에, ""사실이 아니고 누구나 uBlock Origin Lite를 Chrome과 manifest v3에 쓸 수 있으며, 성능은 좋고 기존 uBlock Origin과 차이를 못 느끼겠음. 모두 C++에서 필터링되어 훨씬 빠름. 물론 rule 최대치 제한이 있지만 지금은 충분히 감당 가능한 수준""이라는 의견도 있음
          + 그렇지만 Lite는 Lite이기 때문에 가능성이 제한돼 있음. 그 자체로 원래 adblocker가 아니기에 완전히 같지는 않음
     * 업무용 노트북 외에는 크롬을 쓸 일이 없고, 평소에는 Firefox를 계속 쓰는 중임. 그래도 업무상 웹 서핑(자료 조사, 문서 등)에 도움 됐던 uBlock Origin을 못 쓰게 되는 점이 아쉬움
     * 그냥 우회를 원한다면 Firefox를 설치하면 됨
          + Firefox는 웹브라우저로서도, 베이스로서도 별로라고 생각함. Zen이 Chromium을 쓰지 않은 것이 안타까움
"
"https://news.hada.io/topic?id=21864","더 이상 개성은 존재하지 않는다: 우리는 라벨이 붙은 상품이 되었다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 더 이상 개성은 존재하지 않는다: 우리는 라벨이 붙은 상품이 되었다

     * 심리치료 용어가 대화를 장악하며, 인간의 감정과 성격에 대한 언어를 축소함
     * 현대 사회는 모든 특성을 문제로 간주하고, 진단명이나 설명에 집착함
     * 우리의 경험과 기억조차 임상적 용어와 진단으로 대체되는 현상 확산
     * 인간적인 미스터리와 감정은 사라지고, 분석과 자기설명에만 집중하는 문화 형성
     * 자신을 해석하려는 강박이 오히려 불행을 키우고, 인간성을 상실하게 함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

심리치료 문화와 성격의 상실

   최근 심리치료적 언어가 일상으로 스며들면서, 인간의 로맨스와 관계, 상처와 고통을 바라보는 시각이 크게 변화하고 있음
   이러한 접근법 속에서, 점점 더 많은 성격적 특징이나 습관, 강한 감정이 모두 ‘문제’로 규정됨
   누군가의 단순한 행동이 사랑스럽거나 독특하다는 해석 대신, ‘ADHD’, ‘자폐’ 등 진단으로 대체됨
   특히 젊은 세대는 흔한 성격적 특징마저 장애로 배우고 있음
   2024년 설문에서 Z세대 여성의 72% 가 “정신 건강 문제가 내 정체성의 중요한 일부”라고 답변한 반면, Boomer 남성은 27%만 동의함

모든 것의 원인 찾기와 설명의 욕망

   현대인은 심리적, 과학적, 진화적으로 모든 것에 설명을 붙이려는 본능을 보임
   이런 설명 욕구는 미스터리, 낭만, 자기 자신까지 잃게 만드는 현상으로 이어짐
   이전에는 사람을 소개할 때 ‘잊을 수 있을 만큼 사랑스럽다’는 식의 설명이 가능했지만, 이제는 임상적 용어로만 해석됨
   가족의 애정 어린 묘사마저 의료화, 진단명과 평가로 변모함
   이러한 변화로 우리는 ‘사람’이 아닌 ‘상품’이 되었고, 각각의 진단명이 ‘라벨’이 되었음

성격과 경험의 해체

   사람의 성격도 더 이상 이야기되지 않고, 오직 ‘사람을 기쁘게 해주려는 사람’, ‘불안하게 애착하는 사람’ 등으로만 분류됨
   확실한 진단 없이도, 부모 세대 마저 ‘미진단 ADHD’, ‘자폐’, ‘정서적 결함’ 등으로 평가됨
   경험 자체도 더 이상 ‘시즌’이나 ‘추억’이 아니라, 오로지 문제가 무엇인지 찾는 단서로만 간주됨
   사랑과 감정도 트라우마 반응이나 애착 문제로 환원됨
   이 모든 것은 ‘건강한 사고방식’으로 여겨지지만, 결국 삶의 신비와 감동이 사라지는 결과 초래함

세대 간의 인간성 인식 차이

   이전 세대는 스스로를 아내, 어머니, 남편 등 명확한 역할로 정의했지만, 지금은 자신의 정체성을 증상이나 진단으로 설명함
   이전에는 실수나 결정을 그저 자연스럽게 받아들였지만, 지금은 모든 걸 분석하려고 함
   관계, 결혼, 출산 같은 인생의 큰 선택조차 이성적 근거나 논리적 분석만으로 접근하려는 경향 강조됨
   이러한 분석 습관 때문에 당연히 받아들여야 할 인간적 경험마저 두렵거나 불확실한 것으로 인식함
   과거에는 단순히 느꼈던 행복이나 소박한 만족도 현재 세대에게는 불안과 혼란의 원인이 됨

진단 산업, 자기이해의 함정, 그리고 인간성 회복

   현 세대는 정신 건강 산업의 영향과 정보의 과다 속에서, 통제와 확실성을 강박적으로 원함
   물론 진단 덕분에 도움받는 사람도 있지만, 많은 이들이 ‘모든 걸 해석하고 설명하는 것’이 삶의 목적이라고 착각함
   우리는 자신을 끊임없이 분석하고, 기억 역시 ‘증거’와 ‘설명’, ‘트라우마 연대기’로만 받아들임
   이러한 방식이 해방적이고 자유로울 거라 착각하지만, 오히려 자기 자신을 시장과 전문가들에게 상품처럼 내어주고 있음
   궁극적으로, 인간에 대한 깊은 미해결성을 받아들이고, 설명에 집착하지 않는 용기가 현대인에게 필요함

마무리 메시지: 인간의 신비로움과 자기 체험의 용기

   우리를 규정하는 ‘정신 건강 업계’가 요구하는 대답과 해석에 끊임없이 자기 자신을 설명하는 문화는 오히려 우리를 불행하게 만드는 원인임
   진정한 용기는 모든 걸 해석하고 통제하려는 힘이 아니라, 설명할 수 없는 미지의 부분을 받아들이는 능력임
   자신의 감정이나 경험, 추억을 스스로 상품화하는 대신, ‘정상적임’을 두려워하지 않는 태도가 필요함
   사람답게 산다는 건 완벽한 설명 대신, 모험과 신비를 받아들이는 것임
   스스로를 상품이 아닌 인간으로 지키는 것, 그 자체로 해석이 필요 없는 선언임

        Hacker News 의견

     * 수십 년 전, 처음 비정상 심리 수업을 들었을 때 교수님께서 거의 철칙처럼, 학생들이 배우는 모든 장애의 ""약한 버전""을 자기 자신에게 적용해 진단한다는 말을 들은 기억이 있음. 이후로도 이 현상이 꾸준히 사실이었고, 이제는 TikTok 셀프 진단 산업 덕분에 훨씬 더 강해진 느낌. 여기서 우리가 배울 수 있는 점으로는, 사람들이 자신을 특별하게 만들어주는 라벨을 붙일 수 있게 해주면 반드시 붙인다는 점, 자신의 문제에 이름이나 형태를 부여하는 라벨링 기회를 주면 역시 그걸 받아들인다는 점, 대부분의 정신장애는 보통 사람들의 경험과 완전히 질적으로 다른 게 아니라 정도의 차이일 뿐이라는 점이 있음. 이런 걸 바탕으로 어려움을 겪는 사람에게 더 깊은 공감 능력을 키울 수 있음
          + 최근 내가 만난 젊은 세대와 일하면서, 사람들이 문제에 라벨을 붙이고 싶어한다는 점이 정말 널리 퍼져 있음을 느낌. 심지어 TikTok을 한 번도 보지 않아도 현재 TikTok의 셀프 진단 트렌드를 쉽게 파악할 수 있음. 문제에 라벨을 붙이면, 다른 사람이 그걸 비판할 수 없다는 믿음이 이 세대에 널리 퍼져 있음. 젊은 사람들은 이를 방어적 전략으로 써서 거의 모든 것에 라벨을 붙임. 얼마 전 유행했던 ""time blindness""라는 개념도 그런 예인데, 늘 늦거나 시간을 못 맞추는 사람들이 TikTok에서 이게 질환인 양 소개하는 걸 보고 자기 자신에게 그 진단을 적용함. 그래서 사람들이 갑자기 약속에 늦고, ""나 time blindness 있어서요""라고 당연하게 말함. 라벨을 붙이면 책임에서 벗어날 수 있다는 면허라도 주어진 것처럼 행동함. 더 답답한 건, 이렇게 셀프 진단한 사람들이
            오히려 더 시간을 못 지키게 됐다는 점. 자신의 개인적 문제를 상태로 라벨화한 후에는 더 이상 노력할 필요성을 못 느낌
          + 누군가로부터 반 친구들에게 생일 정보를 수집한 후 운세를 적어 나눠줬다는 이야기를 들은 적 있음. 각자 ""정확하다""며 의견을 말했으나, 나중에 서로의 운세를 비교해보니 내용이 전부 똑같았음
          + 흥미로운 점은, 같은 대상에 대해 완전히 반대되는 두 가지 해석이 가능하다는 점. 하나는, 모두가 장애가 있다고 생각하니 그런 느낌은 무시해야 한다는 것. 다른 하나는, 누구나 어느 정도 약한 장애를 다 가지고 있으니, 이런 점을 스스로 더 고민해봐야 한다는 관점임
          + 저자의 우려는 TikTok 로그아웃만 해도 대부분 해소된다고 생각함. 저자는 TikTok과 사회를 동일시하는 경향이 있는데, 둘은 전혀 같은 게 아님
          + ""사람이 자신을 특별하게 느끼게 해주는 라벨을 붙일 수 있으면 반드시 붙인다는 점""이 우리가 배울 수 있는 것이라는 주장에 대해서, 이건 오히려 정반대 현상이고, 매우 최근에 생긴 사회문화적 현상이라 생각함. 20년 전만 해도 진단도 없이 자기가 자발적으로 자폐라고 말하는 경우는 거의 없었음. 진단받은 소수만 필요할 때 언급했음. 더 이전엔 아예 상상도 안 됐고, 역사적으로나 지역적으로나 ""특별함""에 대한 욕구는 매우 다름. 이런 현상은 인간 본성에 내재된 것이 아니라, 매우 새롭게 생긴 강한 사회 문화적 변화임
     * 예전에는 성격적 특이점을 가진 사람들을 두고 귀여운 속담 등으로 말하곤 했는데, 이 모든 것은 가족, 친구, 지역사회 등 본래의 지원 시스템에서 비롯된 것이었음. 지금 치료 대화가 널리 퍼진 이유는 그러한 지원 시스템이 대부분 심각하게 약화되어, 많은 사람들에게는 치료(therapy)가 유일한 도움의 길이 되어버렸기 때문임
          + 동의하지만, 개인적으로는 그 이유가 조금 다를 수도 있음. 이런 지원 시스템이 과거에 비해 약해졌는지는 모르겠지만, 요즘은 확실히 ""나는 못 도와주니 전문가에게 상담을 받아보라""는 말을 더 쉽게 듣게 됨. 어떤 면에서는 이것이 좋은 변화임. 예를 들어, 조울증 같은 경우 빠른 치료가 정말 도움이 됨. 하지만 심한 우울증을 겪어 생명을 잃을 뻔했던 입장에서는, 그 ""도움""이란 것이 정말 형편없다는 생각임. 우울증은 치유할 수 있는 병이 아니라고 생각하고, 오히려 사회적 붕괴에 대한 건강하고 합리적인 반응인 경우가 더 많음. 어떤 정신 질환들은 개인 중심 의학으로는 결코 제대로 설명되지 않는다고 봄
          + 나는 이 두 가지를 대립적 개념이 아니라 서로 독립적인 변수라 생각함. 내 경험상, 치료 언어에 가장 심취한 사람들은 오히려 사회적 연결도 가장 많은 경우가 많았음. 치료 언어와 그에 따른 용어들은 자기 사회적 지원망 내에서 자신을 드러내기 위한 도구로 쓰이고, 도움을 청하는 신호가 되거나, 심지어 자신의 행동에 대해 책임을 피하려 치료의 언어로 포장할 때도 자주 쓰임
          + 가족, 친구, 지역사회 같은 지원 시스템이 심하게 무너졌다는 주장에 동의할 수 없음. 과거엔 그런 시스템이란 게 아예 제대로 존재하지 않았음. 다들 그냥 ""버텨야 한다""며 살아왔고, 지금은 스트레스가 더욱 심해져서 이제 감당을 못 하는 것임
          + 한때는 별다른 기술 없는 직업으로도 집을 사고 소소한 가족을 부양하는 게 가능했음. 자기 집이 있으면 진단받지 않은 정신적 문제들도 그냥 무시하며 살기 쉬움
     * 현대인의 깊은 본능 중 하나는 모든 걸 심리, 과학, 진화 등으로 다 설명하려는 경향임. 모든 것을 원인, 분류, 보정 가능한 대상으로 보고, 체계, 이론, 동기 같은 틀로 말함. 이렇게 설명하는 대가로 신비와 낭만, 그리고 최근엔 자기 자신까지 잃었음. 이런 관점은 과학 거부의 또다른 형태임
          + 정신과 의학은 잘해봐야 그저 근거 있는 추측에 불과하고, 정신 질환이란 단지 증상 집단에 붙인 라벨일 뿐임. 정신과 약의 부정적 효과가 더 긍정적인 경우보다 많은 게 실상임. 인류는 수천 년간 스스로 기능적인 대처법을 갖고 있었는데, 이런 방법들을 다 버리고 누군가 돈을 벌게 하고 결국 사람들은 이게 자기 잘못이라고 세뇌받게 됨
          + 어떤 과학이 거부당한다고 말하는지 궁금함
          + 오히려 우리가 거부하고 있는 건 사이비 과학임
     * 여기서 ""우리""라고 말하는 방식에 의구심이 있음. 나 자신은 이런 담론에 속하지 않는 느낌임. 그리고 ""항상 늦으면서 '사랑스럽게 건망증이 심하다'고 불렸던 시절""이라는 데 대해, 30~40년 전만 해도 약속에 자주 늦는 사람은 거의 벌을 받았고 그 성향 자체가 귀엽게 받아들여지지 않았음. 옛날에는 신경다양성을 가진 사람들이 더 많은 처벌, 조롱, 괴롭힘, 배제를 당했음. 나는 평생 자폐였지만 그런 것에 대한 인식이 없던 세대에서 자랐음. 과거를 미화하거나 잘못된 향수에 빠지는 것에는 신중할 필요가 있음. 예전엔 신경다양성을 있는 그대로 받아준다는 식의 따뜻함은 전혀 없었음
          + 나 역시 ADHD인데, 어릴 때 집과 학교에서 내 행동 때문에 심한 평가와 판단을 받았고, 이로 인한 수치심이 오래 갔음. 어릴 때 진단을 받았지만 성인이 되어서야 그 라벨을 인정하고, 나의 차이점을 받아들이고 부정적인 감정을 극복했음. ADHD라는 이름 덕분에 나와 비슷한 이들과 연결되고, 자신을 이해하고 연민하는 데 큰 도움이 됨. 만약 라벨이 불편하다 느끼는 사람이 있다면, 그 불편함 자체도 곱씹고 살펴볼 만한 가치가 있다고 생각함
          + 또 다른 예로, 오랜 기간 전 배우자에게 심하게 함부로 대우받았는데 왜인지 떠나지 못했고, 오히려 상대의 나쁜 행동을 가리려고만 했음. 지금 생각해보면 파괴적이었지만 당시엔 오히려 그게 옳다고 느꼈던 순간임. 다시 이런 일이 생기지 않도록 그런 경향성을 이해하고 미리 파악해보려 노력 중임. 하지만 잘못된 과거 향수는 버리고 ""우리는 너무 많이 생각하고 너무 적게 느낀다""는 감정에는 공감함
     * 지금 논의에서 놓치고 있는 부분은, 배움이나 탐구, 설명이 결국 행동으로 이어져야 한다는 점임. ADHD, 어린 시절 트라우마, 애착 문제 등 내 문제를 알았다면, 그 사실이 행동의 변화를 가능케 하거나 변화의 의도가 있어야지 그렇지 않으면 무의미함. 물론 그냥 배움 자체를 즐기는 경우엔 예외이지만, 결국 배우는 목적은 행동과 실행으로의 연결임
          + ""자신에게 ADHD, 트라우마, 애착 문제 등이 있다는 걸 아는 게 행동으로 이어지지 않으면 무의미하다""는 말은 사실과 다르고 중요한 점을 놓침. 진단 사실만으로도 자기 자신을 탓하고 미워했던 마음을 멈출 수 있음. 이는 그 사실이 면죄부를 준다는 게 아니라, 그게 도덕적 실패가 아니라는 이해가 실제로 엄청난 심리적 위로가 됨. 실제로 진단받지 않고 ADHD인 대다수는 그런 상태를 이겨내기 위한 다양한 대처법을 평생 쌓으며 살았음. 현실을 인식하는 것만으로도 미래에 더 효과적인 방법을 만드는 데 도움이 됨
     * 이 글 흥미롭게 읽었음. 저자가 겪은 일들은 지역, 정치적 성향, 온라인 커뮤니티 등에 따라 매우 다를 수 있다고 보지만, 평범한 인간의 특징까지 과도하게 병리화하는 현상이 점점 더 많아진 건 맞는 것 같음. 모든 성격적 결함이 꼭 고쳐져야 할 필요는 없을 수도 있음
          + 정상적 인간 행동이 병리화된다는 거부감은 어릴 적 단순히 있는 그대로의 자기 모습을 보호자, 교사, 또래 등에게 판단받거나 오해받았던 경험에서 비롯될 수도 있음. 어릴 적 너무 규칙에 순응하거나 감정을 억누르길 강요당했다면, 지금은 그런 특성을 라벨을 붙여 수정하려는 시도 자체에 방어적으로 반응할 수도 있음. 치료는 그 방어심을 부드럽게 다루며, 어릴 때 충분히 표현되지 못한 우리 일부에 공감과 목소리를 줄 수 있음
          + ""정상""이라는 기준 자체가 해석하기 어렵다고 생각함. ""ADHD가 아니라 자본주의 속에 살고 있다""는 밈은 별로 좋아하지 않지만, 현실적으로 물질적 여건 자체가 비정상일 수 있음. 예를 들어 주 60시간씩 일하는 환경이라면 대부분 정리되지 못한 삶을 살게 됨. 그러나 주변도 모두 비슷한 상황이라 나만 유독 힘들다는 느낌을 갖게 되기도 함. 물론 일을 덜 하고도 게으르다고 또 자책할 수도 있고, 약간의 마음가짐 변화로 훨씬 덜 스트레스받을 수도 있음. 또는 정말 의학적 문제가 있을 수도, 없을 수도 있음. 결론적으로 입증된 의학적 상태가 존재하고, 이런 걸 부정하는 목소리도 만만치 않게 큼. 요즘은 자기 성찰 자체도 더 공개적으로 이루어짐. 20년 전만 해도 이런 얘기들은 비교적 폐쇄적인 장소에서만 나누었음
          + 누구의 정신 건강 문제든 쉽게 깎아내리고 싶진 않음. 실제로 많은 경우 고통이 진짜임. 다만 충분히 잘 살고 있는 이들이 작은 불편까지 조건 탓으로 돌리는 경우가 거슬림. 요즘엔 ADHD, Autism이 자주 들먹여지고, 심지어 조금만 꼼꼼해도 OCD라고 자칭하는 것이 거의 클리셰처럼 됨. 불치의 조건에 원인을 돌림으로써 내 탓이 아니라는 자기 합리화 경향도 있는 것 같음
     * 이 글을 읽으니 TVTropes가 떠오름. 미디어를 해체해서 각 요소(트로프) 단위로 바라보며, 서구 과학식의 체계화 사고방식과 결을 같이함. 관련 트로프는 Measuring the Marigolds임
     * 우리는 이전보다 더 많은 것을 알고 있음. 증상 원인을 더 쉽게 찾을 수 있음. 예컨대, 관대함과 비위맞추기는 비슷해 보여도 하나는 사랑, 하나는 두려움에서 비롯됨. 우리는 사람들이 더 많이 사랑을 느끼고 덜 고통받도록 돕고 싶음. 남에게 맞추기 위해 베푸는 대신, 자기 자신을 만족시키기 위한 나눔을 추구해야 함
          + 우리가 더 많이 안다고 ""믿을"" 뿐임. 사회의 가장자리에 만족하며 살아본 사람으로서 최근만큼 힘들었던 적은 없음. 뭐가 바뀌었느냐고 생각하면 원하지 않은 도움임. 예전엔 팬데믹 전 원격 근무로 꽤 만족스럽게 일했지만, 지금은 모든 에너지가 ""정말 괜찮다니까요""라고 설명하는 데 다 쓰임. 너무 많은 사람들이 특정한 방식의 도움을 주겠다고 다가옴
     * 이 글 정말 좋다고 생각함. 정신 건강 관련 콘텐츠가 넘쳐나고, 이는 사람들의 모든 행동을 설명하는 데 집착함. 이 문제는 과도하게 과장되고, 알고리즘이 특정 내용을 밀어올린 결과임. 애매한 콘텐츠가 더 많은 대중에게 닿아, 해당 계정에는 이득임. 누구나 관대함과 비위맞추기를 혼재하도록 살아가는데, 만약 이런 특성이 삶이나 관계에 치명적으로 해를 줄 때만이 아니라 모든 특징에 문제가 있다고 보면, 결국 우리 삶 자체가 문제가 되어버릴 수 있음. 요즘은 애매한 관계나 행동을 간단한 라벨로 설명하는 콘텐츠가 넘쳐남. 개인적으로는 요즘 나를 둘러싼 애착 관련 콘텐츠가 무수히 쏟아짐. 밤늦게 TikTok이나 Instagram을 보며 이런 설명을 계속 보다 보면 자신의 행동이나 타인 행동을 모두 설명하려 들게 됨. 이런 콘텐츠는 잠시 그만 보는 게 나음
     * 주의 지속시간을 망가뜨리는 가장 효과적인 방법이 있다면, 그건 짧은 영상 속에서 지속적으로 제공되는 랜덤 보상 구조라고 생각함
"
"https://news.hada.io/topic?id=21925","과도한 JavaScript 중심 개발, 웹을 망가뜨리다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     과도한 JavaScript 중심 개발, 웹을 망가뜨리다

  요약 개요

   과도한 JavaScript 중심 개발, 웹을 망가뜨리다
     * JS 프레임워크 남용으로 웹사이트 복잡성 심화
     * 개발자 경험(DX)이 사용자 경험(UX)을 압도
     * 단순한 작업에도 과도한 구조 요구
     * 성능·접근성·유지보수성 모두 저하
     * 웹 본연의 기능 회복이 해법
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  서론

   개발 중심 웹의 병폐
     * 대부분의 웹사이트는 지나치게 복잡하고 느림
     * JS 중심 설계로 사용자보다는 개발자 중심 구조로 전환
     * 간단한 변경조차 복잡한 배포 과정을 요구하는 상황이 일반화됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  본론

    앱처럼 보이고 싶은 욕망이 원인

     * 2010년대 이후, 모바일 앱 유행과 함께 ""앱 같은 웹"" 요구 증가
     * Angular 등 JS 프레임워크가 도입되며 복잡도 급증
     * 단순 콘텐츠도 시스템처럼 개발됨

    개발자 경험(DX) 우선 문화

     * 최신 프레임워크는 개발자 편의에 초점
     * 구성요소 추상화가 UX와 괴리 유발
     * ""왜 블로그에 React를 쓰는가""라는 질문보다 SSR 호환성 논의가 우선됨

    복잡성이 표준이 된 현실

     * 간단한 작업에도 빌드, 라우팅, API, 캐시 등 다단계 구조 필요
     * 복잡한 스택으로 인해 비개발자는 콘텐츠 수정을 하지 못함
     * 기술 변화가 너무 빨라 유지보수 어려움

    프레임워크 남용의 폐해

     * SSR, 캐시, 메타데이터 등 기존 웹 기능을 재구현 중
     * 성능은 낮고, 의존성은 늘어남
     * 결과적으로 JS 프레임워크로 CMS를 재현하는 모순 발생

    무의미한 반복과 비용

     * 프레임워크 도입과 폐기가 반복되어 안정된 구조 부재
     * 실제 사용자 문제 해결보다 내부 복잡성 해결에 집중
     * 콘텐츠 마케팅, SEO, 실험 등이 늦어지고 사용자 경험은 악화됨

    JS 남용으로 인한 사용자·마케터 피해

     * 콘텐츠 수정에 개발자 개입 필요
     * SEO와 페이지 품질 저하
     * 사용자에겐 로딩 지연, 인터랙션 오류 등 불편 가중

    JS는 도구일 뿐, 목적이 아니다

     * JS는 강력한 도구지만, 대부분의 웹사이트에 과도함
     * 정적 콘텐츠에 대해선 HTML, CSS, 약간의 JS만으로 충분
     * Vanilla JS, 서버 렌더링, 최소한의 스크립트가 더 효율적

    권한의 집중과 구조적 문제

     * 복잡한 스택으로 인해 모든 작업이 개발자 의존
     * 조직 구조상 개발자 중심으로 권력 집중
     * 기술 결정이 사용자보단 개발자 편의 기준으로 이루어짐
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  결론

   웹의 본질 회복이 해법
     * 빠르게 로딩되고, 검색되며, 유지보수 쉬운 웹사이트가 필요
     * 서버 렌더링 HTML, 의미론적 마크업, 최소한의 JS 등 기본 복귀가 답
     * 기술보다 결과 중심 접근 필요
     * “왜 이 기술을 쓰는가?”라는 질문이 필요
     * 단순하고 사용자 중심적인 웹이 곧 성능, 비용 절감, 유연성을 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   원글이 지적한 '웹의 과도한 복잡성' 문제에는 공감합니다. 하지만 그 원인을 개발자 문화나 프레임워크 남용으로만 돌리는 진단에는 동의하기 어렵습니다. 오늘날 웹의 복잡성은 상당 부분 '비즈니스 모델'이 요구하는 필연적인 기능과 보안의 그림자이기 때문입니다. 이 점을 빼놓고는 반쪽짜리 진단에 그칠 수밖에 없습니다.

   웹은 더 이상 ‘무료 전시관’이 아닙니다. 오늘날 공공 사이트를 제외한 대부분의 웹 서비스는 수익 창출이 목표입니다. 따라서 기술 선택의 핵심 질문은 “이 코드가 순수한가?”가 아니라 “이 기술이 우리 비즈니스를 성공시키는가?”가 되어야 합니다.

   이 관점에서 볼 때, 원글이 이상적으로 그리는 ‘가벼운 콘텐츠 웹’은 현실의 비즈니스 요구라는 벽에 부딪히게 됩니다. 예를 들어 콘텐츠를 판매하는 비즈니스는 단순한 정적 페이지로는 운영이 불가능합니다. 유료 구독 및 결제를 처리하려면 사용자 인증, 구독 상태 확인, 권한 관리와 같은 상태 기반 로직이 필요하고, 콘텐츠 보호를 위해서는 불법 복제나 무단 접근을 막는 실시간 토큰 검증 등의 보안 계층이 필수적입니다. 나아가 개인화 및 A/B 테스트를 통해 사용자 경험과 전환율을 높이려면 동적인 데이터 처리 또한 요구됩니다.

   이 모든 것은 '정교한 애플리케이션'의 영역이며, 프레임워크는 이를 구현하기 위한 현실적인 도구입니다.

   물론 모든 복잡성이 정당화될 수는 없습니다. 우리는 복잡성을 두 가지로 구분해야 합니다.
     * 필연적 복잡성: 비즈니스 기능(인증, 결제, 개인화 등)을 구현하기 위해 발생하는, ROI가 명확한 복잡성입니다. 이는 감수해야 할 비용입니다.
     * 우발적 복잡성: 개발 편의나 과도한 기술 추상화로 인해 생기는 불필요한 복잡성입니다. 이는 지속적으로 측정하고 제거해야 할 기술적 부채이자 낭비입니다.

   성공적인 서비스들은 이 두 가지를 구분하여 현실적인 아키텍처를 구축합니다. 즉, 마케팅과 SEO가 중요한 최전선은 최대한 가볍게 만들고, 핵심적인 거래나 개인화 기능이 필요한 내부 영역은 프레임워크 기반으로 안정성을 확보하는 하이브리드 전략을 통해 속도와 기능성이라는 두 마리 토끼를 모두 잡습니다.

   원글은 사용자 경험 악화의 원인을 프레임워크 문화에만 집중하면서 ‘수익 모델이 불러온 필연적 요구’를 배제했습니다. 이 점을 제외하고 웹 개발을 논하는 것은, 손님 테이블에 '빠르고 맛있는 요리'를 내놓는 것만 이야기하면서, 정작 그 요리를 만드는 복잡한 주방과 돈을 받는 계산대의 존재를 없는 셈 치는 것과 다르지 않습니다.

   웹이 무겁다고 해서 무작정 프레임워크를 버릴 수는 없습니다. 비즈니스가 요구하는 기능을 얼마나 효율적으로, 최소 비용으로 구현해 사용자에게 가치를 전달하느냐가 논점이 되어야 한다고 생각합니다.

   한글 번역본은 아래와 같습니다.
   https://junghan92.medium.com/%EB%B2%88%EC%97%AD-%EC%9E%90%EB%B0%94%EC%…

   현상은 공감하되 결론은 공감하지 않습니다.

   현상의 표면적인 원인은 본문에서도 언급했듯이 ""앱 같은 웹""에 대한 수요가 늘어나게 되었다는 거고,
   현재나 그때나 웹은 ""앱 같은 무언가""를 만들기에 적절하지는 않았으나 똥꼬쑈를 벌이면 ""비슷하게 만들 수는 있는"" 상태라고 생각합니다.

   사실 웹의 태생 자체는 논문 같은 일종의 ""문서""를 공유하기 위해서 만들어진 플랫폼입니다.
   HTML 의 기본 구성 요소만 봐도 알 수 있습니다.

   그러다 cgi 같은 동적 컨텐츠를 생성할 수 있는 기술이 만들어지고, 브라우저 단에서도 스크립트 언어가 내장되면서 결과물에 다이나믹을 부여할 수 있게 되면서 ""문서로서의 웹""에서의 탈피가 시작되었습니다.

   문제는, 최초의 탈피 순간부터 현재까지 웹의 근간은 여전히 ""문서"" 기반의 시스템이라는 것입니다.
   물론 web socket, webrtc, wasm 등 ""문서""향에서 벗어난 새로운 기술들이 많이 나왔지만 현재까지도 대부분의 웹사이트들은 기존의 ""문서"" 기반의 플랫폼에 의존하여 개발되고 있습니다.
   여전히 우리는 화면을 그리기 위해 div 태그들을 쌓아야 합니다.

   여기까지가 현상 분석이고 그럼 답이 뭐냐 하는 생각이 드는데,
   현실성 같은 거 전혀 생각하지 않고 이상적인 다음 플랫폼의 기능을 상상해보면 이렇습니다.

   (모든 사이트가 이래야 된다는 건 아니고 애플리케이션 성격을 지닌 사이트만 한정하여)
   일단 브라우저는 일종의 앱 런처가 됩니다.
   한번 받아놓으면 오프라인에서도 실행될 수 있어야겠지요.
   그리고 앱은 기존의 html/css/js 에서 벗어나 다른 언어로 구현이 됩니다.
   그 과정에서 안드로이드 처럼 브라우저가 일종의 프레임워크를 제공할 수 있을 것 같습니다.
   서버와의 통신 방식도 기존의 web 요청에서 벗어나 다른 패러다임을 사용해볼 수 있을 것 같습니다.
   실시간성이 필요한 통신의 경우 기존의 tcp 통신을 그대로 쓸 수도 있을테고,
   http 프로토콜을 사용하지 않는 좀 더 단순한 rpc 통신을 새롭게 만들어서 쓸 수도 있겠네요.

   이싱적인 플랫폼이라며 말씀하신 마지막 내용은 무슨 말씀인지 잘 모르겠어요.

   결국 네이티브 프로그램을 다운받아서 거기에 액티브X 쓰던 시절 이야기니까요.

   문제의 본질은 웹 ""문서""에 근간을 둔 HTTP 프로토콜 내에서 앱 같은 웹을 만들기 위한 똥꼬쇼인 셈이고,
   이를 해결하기 위해 앱 레벨의 기능이 필요하다면 앱을 위한 새로운 프로토콜과 프레임워크를 만들면 어떨까 하는 의견이었습니다.
   스마트폰에서 순수 네이티프 프로그램이 구동되지 않고 일종의 샌드박싱된 앱이 구동되듯이, 그것이 브라우져 레벨에서 실행되는 구조입니다.
   물론 액티브 엑스 꼴이 나지 않게 개방성과 표준화가 선행되어야겠지요.

   앱 같은 웹이라 하더라도 결론에 나온 것에 가깝게 추구는 해야한다고 봅니다. 자스를 많이 사용하면 클라이언트 입장에서는 무거워지지요.

   실제로 그렇게 구현할 수 있는 프레임워크가 없는 것도 아니고요. 당장 Next.js도 클라이언트 컴포넌트 사용을 필요할때만 하는 식으로 최소화하면 얼추 가능하고, 다른 분이 말했던 Rails 진영에는 Hotwire(https://hotwired.dev/)는 작성자가 말한 결론에 거의 근접할 수 있도록 앱같은 웹을 지원하는 프레임워크 집합(터보, stimulus 등)이 있죠.

   이 글의 근본적인 주제 의식에는 공감합니다만, 어떤 부분에서는 좀 고개를 갸우뚱하게 만드는 부분도 있군요.

   예를 들어, 저희 회사에서 운영하고 있는 특정 서비스 홍보용 웹 사이트는 바로 이 글에서 찬양하고 있는 것과 같은 단순함을 유지하고 있습니다. 다행히도 이 웹 사이트는 대부분의 요소가 충분히 정적인 편입니다. 프론트엔드의 HTML과 CSS 등의 코드는 아무런 프레임워크 없이 사람이 직접 손으로 작성한 것이고, JS도 jQuery와 구글 애널리틱스 정도만 달려 있습니다. 공지사항이나 게시판 등은 jQuery를 사용한 AJAX로 구현되어 있지만, 그렇게 불합리하거나 과도하게 복잡한 수준이라고는 생각하지 않습니다. 제가 오래 전 기초 웹 개발에 입문했을 때 jQuery 기반으로 구현할 수 있었던 수준이라고 생각하거든요. 제가 알기로 이 사이트는 Internet Explorer 시절부터 운영되던 것이라 제가 직접 만든 것은 아닙니다만, 썩 나쁘지 않다고 생각합니다.

   하지만 여기에는 Git 버전 관리와 CI/CD 파이프라인이 붙어 있고, 스테이징 서버와 실제 운영 서버를 분리시켜 놨습니다. Main 브랜치에 Pull Request가 병합되면 파이프라인에서 번들러를 돌린 산출물을 스테이징 서버에 자동으로 배포하고, 담당자가 스테이징 서버를 확인한 뒤 배포를 최종 승인하면 그게 다시 운영 서버에 배포되는 형태로 되어 있습니다. 과거에는 그냥 FTP를 통해 원본 파일을 운영 서버에 바로 덮어씌우는 방식이었는데, 관련 업무가 저희 팀으로 넘어온 뒤에 이렇게 변경하였습니다.

   이게 정말 비합리적인 복잡성일까요? 과거에는 그 웹사이트의 제목 태그를 수정하는 것이 FTP 접속을 지원하는 AcroEdit(네, 원래 그 사이트의 HTML을 직접 작성하신 분들은 여전히 이걸 쓰시고 계셨습니다.)로 운영 서버의 HTML 파일에 바로 들어가서 한 줄만 수정하고 저장하면 모든 작업이 끝나는 일이었으니 그 분들은 아마도 그렇게 느낄 수도 있을 것 같습니다.

   그러나 제가 생각하기에는 이 정도 복잡성 추가는 충분히 감내할 만한 것이었다고 봅니다. 모든 작업이 오직 제목 태그 하나 수정하는 것과 동일한 정도는 아니지 않습니까. 그리고 예전 코드가 주석 처리되어 덕지덕지 붙어 있던 것을 언제든 되돌릴 수 있으므로 부담없이 완전히 삭제할 수 있다거나, 투명한 변경내용 추적 및 롤백이 가능해진 점이나, 번들러에 의해 필요하다면 조금 더 기본적인 최적화를 추가할 수 있다는 점은 제 생각에는 충분히 장점입니다. 실제 환경에 배포되기 전에 미리보기를 할 수 있는 스테이징 서버 추가도 어떻게 보면 복잡성 아닌가 할 수 있습니다만, 저는 이것이 필요했다고 생각합니다.

   저도 각종 웹 사이트 내부 코드 구조가 과도하게 복잡해지고 무거워진 것에는 불만이 많습니다. 요즘 윈도우의 아웃룩 앱은 웹 앱 기반으로 되어 있는데, 근래 들어서 특히나 더 무거워졌습니다. 그저 화면에서 메일 본문을 작성하거나 본문을 전체 선택하는 것만으로 버벅이거나 심지어는 ""페이지 응답 없음""이 뜰 지경이니까요. 왜 이러지 싶어 웹 아웃룩에서 개발자 도구를 열어봤다가 깜짝 놀랐습니다. 한번 캐시를 비우고 새로고침을 했더니 1분 뒤에도 무슨 요청이 계속 뜨더라니까요. 브라우저에서 확인해 보니 MS 오피스 사이트 관련으로만 몇 기가바이트의 데이터가 저장되어 있었습니다.

   그러나 이 글은 여러 가지가 뒤섞여 있으며, 어떤 부분은 공감합니다만 어떤 부분은 별로 공감이 되지 않습니다. 시맨틱 HTML이나 접근성에 대한 내용은 오히려 과거가 더 끔찍했다고 알고 있습니다. 게다가 개발자 경험 향상이 사용자 경험을 악화시킨다는 건 제가 웹 프론트엔드 개발자가 아니라서 그런지는 몰라도 전혀 공감이 되지 않네요. 심지어 개발자에게 모든 권력과 통제력이 집중되었다는 건 터무니없는 소리처럼 들립니다. 회사에서 권력은 경영진에게 있는 거 아니었습니까? 서양에서는 회사 구조가 한국과는 좀 다르기라도 한 건가요?

   언제나 그렇듯 균형과 중용, 단순성과 실용성은 중요한 가치이며 이를 의사결정에서 우선시해야 한다는 점에는 전적으로 동의합니다. 하지만 이 글은 ""모든 웹사이트를 소프트웨어 제품처럼 다루는 것""이 마치 전적으로 개발자의 책임인 것처럼 주장하고 있으며, 그 부분이 오히려 근본적인 문제 의식을 흐리게 만든다고 생각합니다. 그리고 체계가 잡혀 있지 않았던 '좋았던 옛날'을 미화하는 것처럼 보이는 부분은 오히려 비판받아야 하지 않나 생각합니다.

   말씀하시는 이야기랑은 완전히 다른 이야기 아닌가요?

   어떤 부분에서 완전히 다른 이야기라고 생각하시나요?
   결국 이 글에서 비판하는 것은 과도한 복잡성과 그로 인한 부풀려짐이라고 생각합니다. 제 댓글에서 자바스크립트 이야기를 꺼내지 않았다고 하여 완전히 관련이 없는 댓글이라고는 생각하지 않습니다. 어찌 보면 지엽적인 부분에 대한 비판이니까요. 그리고 제 댓글에서 처음부터 언급했듯이, 저도 원래 글의 근본적인 주제 의식에는 공감하고 있습니다.

   원 글의 의도를 잘못 이해 하신거 같아요.

   ""...여기에는 Git 버전 관리와 CI/CD 파이프라인이 붙어 있고, 스테이징 서버와 실제 운영 서버를 분리시켜 놨습니다. Main 브랜치에 Pull Request가 병합되면 파이프라인에서 번들러를 돌린 산출물을 스테이징 서버에 자동으로 배포하고, 담당자가 스테이징 서버를 확인한 뒤 배포를 최종 승인하면 그게 다시 운영 서버에 배포되는 형태로 되어 있습니다. 과거에는 그냥 FTP를 통해 원본 파일을 운영 서버에 바로 덮어씌우는 방식이었는데, 관련 업무가 저희 팀으로 넘어온 뒤에 이렇게 변경하였습니다.

   이게 정말 비합리적인 복잡성일까요?""

   라고 하셨는데 별로 관련이 없는 글 같습니다. 배포와 관리를 그렇게 하는 정도의 일과 이 글이 주장하는 바는 많이 다른거 같아서요.

   원래 글의 의도는 단순히 복잡해진 JS 프레임워크만을 비판하는 것이 아닙니다.
   편의를 위하여 위에 있는 한국어 번역본 링크에서 인용하도록 하겠습니다.

     지금은 단순히 제목 하나를 바꾸는 데도 4명의 엔지니어, 3개의 프레임워크, 그리고 CI/CD 파이프라인이 필요합니다. 웹페이지를 게시하는 것이 이상할 정도로 복잡해졌습니다.

     그렇게 점진적으로, 웹은 게시하기 전에 컴파일해야 하는 것이 되었습니다. 사용자가 필요해서가 아니라. 개발자가 현대적으로 느끼기를 원했기 때문입니다.

     모든 것이 개발자를 위해 최적화되었고, 다른 모든 사람에게는 적대적입니다.

     우리는 더 이상 복잡성을 단순히 감내하는 하는 것이 아니라 당연한 것으로 여깁니다. 모든 사이트에 빌드 단계, 번들러, 하이드레이션 전략, 라우팅 레이어, API 레이어, 디자인 시스템, 그리고 영리한 캐시 무효화 로직이 필요하다고 가정합니다. 마이크로서비스로 구축하고, 엣지 네트워크에 호스팅하며, 단순한 콘텐츠를 전달하기 위해 파이프라인을 배포합니다.

     우리는 워드프레스와 같은 플랫폼의 기능들을 다시 만들고 있지만, 10배 더 무거우면서도 사용성은 훨씬 떨어지는 결과를 만들어내고 있습니다. 더 나쁜 것은, 모든 새로운 레이어가 새로운 버그, 새로운 호환성 문제, 새로운 인지적 부담을 도입한다는 것입니다. 이제 우리는 단순히 홈페이지를 온라인에 올리기 위해 하이드레이션 로직과 캐시 전략 그리고 빌드 파이프라인을 유지보수하고 있습니다.

     컴포넌트 라이브러리가 충분히 유연하지 않아서 마케팅 캠페인이 지연됩니다. 분석 레이어가 하이드레이션 전략과 호환되지 않아서 A/B 테스트가 취소됩니다. 콘텐츠 업데이트는 빌드를 며칠씩 기다려야 합니다. 기본적인 SEO 조정은 백로그에 묻혀버립니다.

     마케터들은 티켓을 올리지 않고는 카피를 업데이트하거나 실험을 실행할 수 없습니다. 콘텐츠를 미리 보거나, 레이아웃을 테스트하거나, 페이지를 내보낼 수 없습니다. 모든 변경 사항은 개발자, 파이프라인, 승인, 재구축을 거쳐야 합니다.

     마케터, 콘텐츠 편집자, SEO 담당자, 디자이너 이들은 모두 프로세스에서 배제됩니다. 이제 간단한 작업조차 기술적 유창함이 필요하기 때문입니다. 타이틀 태그를 바꾸고 싶다고 하면 엔지니어와 상의하시라고 할 것이며, 캠페인을 내보내고 싶다면, 티켓을 올리고 두 스프린트를 기다리라고 할 것입니다.

     모든 것이 개발팀을 통해 흘러갑니다. 즉, 개발팀이 무엇이 중요한지, 무엇이 배포되는지, 무엇이 무기한 우선순위에서 밀리는지 결정한다는 의미입니다. 그리고 그들이 더 많은 복잡성을 추가할수록, 그들은 더 불가결해집니다.

   한국이 경영진->기획자->개발자로 내려오는 개발 문화와 달리 서양 같은 경우에는 한국의 기획자 개념이 없고 개발자가 적극적으로 프로덕트 기획 등에 관여하는 부분은 있습니다. 서양의 PM 등은 커버레터와 자소서가 완전히 일치하는 개념이 아니듯이 한국의 기획자와 완벽하게 일치하지 않습니다. 물론 창작 프로젝트의 성격이 강하고 재미와 게임성이 중요한 게임은 서양도 아시아보다는 수평적이지만 디렉터에서 개발자로 내려오지만요.

   그런 차이점이 있군요.
   하지만 위 내용과 크게 연관되는 부분은 아닌 것 같습니다.

   이 글의 요지에 동의합니다. 요새 JS를 너무 남발하고 있어서 i9-9900k를 쓰고 있어도 사이트가 버벅이는 경우가 많습니다. 게임용이나 작업용으로써는 애매한 사양이기는 하지만 이보다 사양 떨어지는 사무용 컴퓨터가 넘쳐나는게 현실이죠.

   그래서 저는 인터렉티브한 부분이나 인터렉티브한 페이지 네비게비션 같은 JS가 꼭 필요할때만 쓰자는 철학의 프레임워크인 아스트로와 hotwired를 좋아합니다. 서버 사이드에서 렌더링 하자는 서버 사이드 렌더링도 좋아하고요. 반면 CSR(메타 태그만 서버 사이드로 렌더링하고 나머지 부분을 CSR로 처리하는 것도 포함합니다)은 굉장히 싫어합니다. 서버가 해야할 일을 클라이언트가 전가시키는 것으로 보고 있기 때문입니다. 개인적으로 CSR을 사용하는 전통적인 SPA 방식은 일렉트론 같은 앱에서 로컬로 프론트엔드를 실행할때 사용해야 한다고 봅니다. 물론 서버에서 프론트엔드를 로드할 경우에는 SSR을 써야 하지만요.

   필연적인 복잡성이지. 과거처럼 단순한 템플릿 html이 아닌 것을

   Use Rails, Be happy

   아래는 게시글에 대한 댓글 반응을 5가지 유형으로 분류한 요약입니다:

    1. 전면 동의 및 지지

     * 주요 특징: 글의 주장에 전폭적으로 동의하며, 복잡한 JS 스택의 문제를 인정함.
     * 의견 예시:
          + “마침내 누가 할 말을 해줬다.”
          + “현실을 직시한 훌륭한 글이다.”
          + “웹 성능과 접근성은 필수다.”
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

    2. 프레임워크 남용에 대한 우려

     * 주요 특징: React, Angular 등 프레임워크의 과도한 사용을 비판하며, 단순한 기술로 충분하다는 의견.
     * 의견 예시:
          + “React는 블로그에 필요 없다.”
          + “Vanilla JS면 대부분 해결된다.”
          + “Svelte, Eleventy 등 경량 대안이 더 낫다.”
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

    3. 부분 동의 + 현실 고려

     * 주요 특징: 주장에 공감하지만, 복잡성이 불가피하거나 필요하다고 보는 현실적 입장도 존재.
     * 의견 예시:
          + “복잡성이 문제지만 일부 상황에선 불가피하다.”
          + “협업과 유지보수에는 프레임워크도 필요하다.”
          + “HTML/CSS도 불완전해서 JS를 쓸 수밖에 없다.”
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

    4. 개발 문화 및 산업 구조 비판

     * 주요 특징: 프레임워크 과잉은 단순한 기술 문제가 아니라, 채용·문화·마케팅 구조의 산물이라 지적.
     * 의견 예시:
          + “프레임워크는 이력서용 기술이 됐다.”
          + “개발자는 회사 요구를 따를 뿐이다.”
          + “이건 조직문화와 고용시장의 문제다.”
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

    5. 비판 또는 반대

     * 주요 특징: 글의 전제에 동의하지 않거나, 일방적인 주장이라고 비판.
     * 의견 예시:
          + “웹이 느려졌다는 근거가 없다.”
          + “글이 지나치게 편파적이다.”
          + “WordPress로 JS 문제를 해결하는 건 오히려 후퇴다.”
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   오 유형별로 나눠놓으니 보기 편하고 좋네요

   워드프레스만 봐도 .. 위 문제의 답변을 될것같네요
   시장점유율도 워드프레스가 훨 많아요 느린데도 말이죠 ..

   근거에 벤치마크 결과가 있으면 개발자들이 더 공감할 수 있을 거라고 생각합니다. 과도한 프레임워크 코딩이 있으면 확실히 사이트가 느려지겠지만 개인적으로는 사이트 내 페이지 전환 면에서 바닐라 코드로 만든 사이트가 최적화시킨 프레임워크 사이트보다 느린 걸 더 많이 보았기 때문입니다. 물론 정적 데이터로만 된 사이트라면 HTML + CSS만 있는 게 더 빠를지 모르겠지만 현대에 정적 데이터로만 된 사이트가 흔할지는 잘 모르겠습니다.

   리액트나 뷰같은게 없으면
   같은 기능을 구현해도 코드를 더 복잡하게 구현 해야되는데요?
   특히 팝업다룰때 props 하나 넘기는것도 순수 자바스크립트로하면 코드가 많이 복잡해집니다
   이렇게 간단한거하는데도 코드가 복잡해지면 진짜
   복잡한 기능은 구현하기 어려워지죠

   사람들 쓰는 브라우져는 종류 몇개 되지도 않는데 프레임워크는 이리 많은건지. 브라우져 관리하는 회사에서 최적 프레임워크 만들어서 같이 관리 좀 하는게 최선 아닐까요. 언제까지 이 악순환을 반복할것인가.

   추구하는 개발 철학이 천차만별이라서요.........
"
"https://news.hada.io/topic?id=21832","Show GN: Loopback Social","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Show GN: Loopback Social

   Loopback Social은 커뮤니티 간의 연결을 위한 플랫폼입니다.

   이 웹사이트에서 커뮤니티 운영자는 각 커뮤니티 상단에 부착할 수 있는 검은색 띠 배너를 받을 수 있습니다. 이 배너에는 캠페인에 동참하는 다른 커뮤니티의 이름이 함께 표시됩니다.

   느슨한 연결이지만, 서로 커뮤니티가 연결되어있다는 점을 어필하면서 때로는 행사 홍보 배너나 팝업을 띄우는 등 여러 수단을 접목해본다면 어떨까 하는 생각으로 이 프로젝트를 시작해보았습니다.

   이 프로젝트를 통해 커뮤니티 간의 연결을 상징하고, 함께하는 캠페인으로서 운영하고자 합니다.

   현재 닷넷데브 포럼에 설치되어있으며 몇 몇 커뮤니티에서 참여 의사를 보여주셨습니다. (https://forum.dotnetdev.kr/)
"
"https://news.hada.io/topic?id=21840","긴 컨텍스트가 실패하는 이유","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            긴 컨텍스트가 실패하는 이유

     * 최신 대형 언어 모델에서 1백만 토큰까지 지원하는 긴 컨텍스트 윈도우가 도입되며, 에이전트 성능의 비약적 향상이 기대감으로 이어짐
     * 실제로는 긴 컨텍스트가 더 나은 답변을 만들지 않으며, 오히려 컨텍스트 중독, 오류, 혼란, 충돌 등으로 인해 시스템 실패를 유발함
     * 컨텍스트 오염(포이즈닝) , 컨텍스트 산만(디스트랙션) , 컨텍스트 혼란(컨퓨전) , 컨텍스트 충돌(클래시) 이 대표적인 문제점임
     * 이러한 문제는 특히 다수의 정보 소스, 도구 연결, 다단계 추론 등 복잡한 흐름에서 에이전트에 더 큰 영향을 미침
     * 향후 글에서 실질적인 해결법과 피하는 전략이 다뤄질 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

컨텍스트 관리의 중요성

     * 최근의 대형 프론티어 모델들은 1백만 토큰까지 지원하는 장문의 컨텍스트 윈도우를 제공함
     * 많은 사람들이 큰 윈도우에 모든 도구, 문서, 지시사항을 입력해도 문제없다는 기대를 가짐
     * 그러나 실제로는 컨텍스트 과부하가 다양한 실패를 초래하며, 특히 에이전트형 애플리케이션에서 치명적인 문제로 작용함

컨텍스트 오염 (Context Poisoning)

     * 컨텍스트 오염은 환각(hallucination)이나 오류가 컨텍스트에 유입되어 반복적으로 참조되는 현상임
     * Deep Mind의 Gemini 2.5 기술 보고서는 게임 도중 잘못된 게임 상태가 목표나 요약 섹션에 남아 무의미한 전략과 불가능한 목표로 에이전트가 잘못된 행동을 반복하는 사례를 설명함
     * 이러한 오염된 컨텍스트는 일시적으로 또는 장기간 에이전트의 판단을 흐리게 만듦

컨텍스트 산만 (Context Distraction)

     * 컨텍스트 산만은 컨텍스트가 너무 길어져서 모델이 훈련 중 배운 내용보다 컨텍스트에 과하게 집중하는 현상임
     * Gemini 2.5 Pro의 1M+ 토큰 윈도우에서도 실제로는 컨텍스트가 100,000 토큰을 넘어서면 모델이 과거 이력을 반복만 하며 창의적 계획 수립이 어려워짐
     * Databricks 연구는 Llama 3.1 405b의 경우 32,000 토큰에서 이미 정확성이 급락함을 확인함
     * 이처럼 극도로 큰 윈도우가 현실적으로는 요약(summarization), 팩트 검색(retrieval)에만 유용함을 시사함

컨텍스트 혼란 (Context Confusion)

     * 너무 많은 툴이나 정의를 컨텍스트에 넣으면 모델이 불필요하거나 부적절한 도구 호출 등 저품질 응답을 생성함
     * Berkeley의 Function-Calling Leaderboard에 따르면, 여러 도구가 제공될수록 모든 모델의 성능이 하락하며, 불필요한 호출이 빈번히 발생함
     * GeoEngine 벤치마크 논문에선 Llama 3.1 8b 모델이 46개 툴이 주어진 상황에서 실패했으나, 19개만 주어질 때 성공함
     * 컨텍스트에 들어간 정보는 모델이 반드시 고려해야만 하는 정보로 인식되어 불필요한 노이즈가 문제를 야기함

컨텍스트 충돌 (Context Clash)

     * 컨텍스트 충돌은 다단계로 수집된 정보나 툴 설명 사이에 서로 모순되거나 상충하는 내용이 존재하는 상태임
     * Microsoft와 Salesforce의 연구는 멀티턴 대화에서 이 현상이 평균 39% 성능 하락으로 이어짐을 보여줌
     * 이는 초기 응답에서 잘못된 가정이 만들어지고 이후에도 그 답변에 과하게 의존하는 구조 때문임
     * MCP 등 외부 도구와 연결할 때 충돌 위험성이 증가함

결론 및 전망

     * 백만 토큰 컨텍스트의 등장이 혁신으로 여겨졌으나, 실제로는 오염, 산만, 혼란, 충돌 등 새로운 유형의 에러가 증가함
     * 이런 문제들은 특히 복수 정보 수집, 단계적 도구 연계, 긴 대화 기록이 누적되는 에이전트 시스템에 치명적임
     * 해결책으로는 동적 도구 로딩, 컨텍스트 격리 등 다양한 전략이 제안될 수 있으며, 후속 글에서 구체적으로 다뤄질 예정임

   다음 글: “당신의 컨텍스트를 고치는 방법”
"
"https://news.hada.io/topic?id=21956","new Date("wtf") - JavaScript의 Date 클래스에 대해 얼마나 잘 아는가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         new Date(""wtf"") - JavaScript의 Date 클래스에 대해 얼마나 잘 아는가?

     * 본 퀴즈는 JavaScript의 Date 클래스가 다양한 입력 상황에서 어떤 식으로 동작하는지에 초점을 맞춤
     * 사용자가 예상하지 못하는 입력값(예: ""wtf"" 등)이 들어올 때 Date 클래스가 반환하는 결과, 예외 여부, 내부 처리방식 등 실험 내용 포함
     * 이 퀴즈를 통해 JavaScript Date의 예외적 순간, 파싱 전략, 표준 미준수 등 예상 외의 동작 패턴을 쉽게 파악할 수 있음
     * JavaScript 개발자 및 테스트 담당자가 실제 프로그램에서 발생할 수 있는 날짜 처리 오류와 불확실성을 줄이기 위한 이해도 증진 목적

        Hacker News 의견

     * 내 firefox JS 콘솔에서는 이 퀴즈와는 다른 답이 나옴
     * JavaScript를 놀리지는 말아줬으면 함. 옛날에도 사람들이 그러다가 Node가 나와서 이젠 온 세상에 퍼진 상황임
          + TypeScript는 아마도 돈을 받고 쓸 수 있는 언어 중 최고의 선택이라고 생각함
          + 거의 10년간 사람들이 undefined behaviour를 정말 기술의 무의미함에 대한 결정적 증거처럼 여기던 WAT 밈이 생각남. 사실은 단순히 사람들이 기술이라는 개념을 오해했던 것임. 벽돌로 물을 담을 수 없는 게 웃긴 일은 아닌데, 이상하게도 모두가 JavaScript가 모든 ~실수~를 전부 에러로 잡거나 스스로 고쳐줄 거라고 기대했었음. 좋은 목표이긴 하지만, 그게 불가능하면 자랑스럽게 여기라는 것도 좀 이상했던 시각임. 이런 분위기가 너무 오래 이어진 경험임
     * 재밌는 퀴즈라고 생각함. 깜짝 놀랄 만한 동작도 많음. 하지만 실제로는 대체로 별로 중요하지 않다고 느낌. <br>실제 상황에서 본인이 지역 시간이 정말 필요한지 고민해보고, instant 단위로 쓰는 게 적합한지 먼저 생각했으면 함. UTC ISO 8601 문자열이나 Unix timestamp를 쓰면 복잡성의 대부분이 사라지거나, 최소한 소프트웨어의 일부에서만 신경 쓰면 됨. 물론 항상 그런 건 아님 (한 번은 사용자의 휴식 시간이 1~5시 두 구간을 포함해야 했는데, DST 경계에서 정말 고역이었음). 그래도 대부분의 경우에 신경 쓰는 영역을 최소화하는 방법을 찾는 게 가능하다고 경험함. <br>아무 검증도 안 한 사용자 입력을 date parser에 그대로 넘기면 그 사용법이 잘못된 것임
          + 사용자 입력을 올바른 형식으로 바꾸는 방법이 바로 파싱 이기 때문에, 언어에서 제공하는 date parser 에 전달하는 게 합리적이라고 생각함. 이게 잘 안 된다는 사실이 JavaScript 프로그래머들에겐 별로 놀랍지 않다고 생각함
          + ""아무 검증도 안 한 사용자 입력을 date parser에 넘기면 안 됨""이라는 말에 완전히 동의함. 근데 제대로 된 API와 그렇지 않은 API의 차이는, 제대로 된 API는 이상이 있으면 바로 실패하고 ""네가 뭘 잘못 쓰고 있다""고 알려 주는 것임. 일단 뭔가 조금이라도 이상하면 제대로 실패해야지, 이상한 데이터를 어떻게든 처리하려고 해선 안 됨. 많은 JS API는 어떤 일이 있어도 동작하도록 설계된 게 문제라고 생각함. NaN이 나오는 것도 원하지 않고, 문자열을 어정쩡하게 변환하는 것도 원하지 않음
          + ""UTC ISO 8601 문자열이나 Unix timestamp만 쓰면 된다""는 말을 할 때마다, 그런 사람들은 날짜를 되게 한정된 방식으로만 다뤄봤다는 생각이 듦. <br>미래 날짜에 그런 전략을 써보면 어떤지 생각해보면 됨. 예를 들어 ""저녁 7시에 만나자""라는 약속은 썸머타임이 변경되거나 시간이 바뀌어도 7시에 만나는 게 중요함. 이런 일은 실제로 자주 일어남. <br>사실 더 미묘한 문제임. 어떤 앱에서는 반드시 시간대의 맥락이 필요함. 예를 들어 레스토랑 예약을 보여주는 서비스라면, 사용자의 현지 시간이 아니라 레스토랑의 현지 시간대로 보여야 함. 예약 시간은 ""거기"" 시간이 중요하지, 내가 지금 어디 있느냐가 중요하지 않음. <br>즉 GMT/UTC가 모든 날짜 문제의 만병통치약은 아님. <br>과거 날짜라면 괜찮은 해결책이긴 한데, 이럴 때도 사용자의 현지 시간이나 이벤트 발생
            당시 시간대를 따로 저장하는 게 도움이 될 때가 많음
          + DST 오프셋을 명시적으로 지정할 수 있는 옵션을 주는 것도 좋은 방법이라고 생각함. 상황에 따라 유용한 경우가 있음. Excel이 CSV 사용할 때 포맷을 스스로 추론하지 않는 것도 항상 혼란스러웠음
          + 이 내용에 동의함. 초보자라면 쉽게 빠질 수 있는 함정인데, 이번 퀴즈로 많은 사람들이 한 번 더 생각해보는 계기가 되었으면 좋겠음
     * 놀라운 부분이 굉장히 많음! 대체적인 흐름은 파서가 주어진 입력을 어떻게든 날짜로 해석하려고 지나치게 애쓰는 모습이라고 생각함. 그 해석이 매우 원칙이 없거나, 심지어 인간 사용자가 봐도 동의하지 않을 만큼 이상해도 강제로 의미를 부여하는 것 같음. 실제 해석하지 못하는 상황에서도 에러 신호를 줄 방법이 있는데, 그런 걸 적극적으로 활용하지 않는 느낌임. 물론 어쩌면 별난 케이스들이 현실의 이상한 사용 사례에서 온 것일 수도 있으리라고 생각함
          + 이런 동작은 예측 자체가 불가능하다고 느낌. 그냥 랜덤에 가까운 잡음임. 32-49번 문자열까지는 2000년대로 나온 반면, 50번 이후는 1900년대로 해석됨. <br>이럴 땐 그냥 전부 갈아엎고 다시 만드는 게 맞다고 생각함
          + 무조건 유효한 결과를 내려고 코드를 짜고 싶은 욕구를 공감함. <br>근데 대부분은 그런 충동을 억제할 수 있었음. 근데 이걸 설계한 사람들은 왜 억제하지 못했는지 궁금함
          + 이 현상은 경력 몇 년 차 개발자들에게서 흔히 나타나는 문제임. <br>주니어 개발자는 에러만 보고 겨우 동작하게 하기 바쁨. <br>미드레벨 개발자는 ""무조건 에러를 줄이자"" 마인드에 집착해서 파서가 과도하게 많이 가정함. 그래서 Date 클래스 같은 현상이 나옴. <br>시니어 개발자는 이런 에러의 위험성을 뼈저리게 알고, 일관되고 robust하게 디자인해서 잘못된 입력은 바로 에러내게 작성함
     * 17/28점 획득했음. 정말... 저주받은 문제들이라고 생각함! 아마 이제 이 Temporal stuff도 한 번 살펴봐야 할 시점인 것 같음
          + 그거 진짜 출시까지 오래 걸리는 듯함. 최신 업데이트 읽어보면 살짝 웃기긴 함: https://github.com/tc39/notes/…
     * 10/28점 맞음. 그리 나쁘진 않은데, 구현마다 결과가 다를 수 있다고 생각함: https://developer.mozilla.org/en-US/docs/…
          + 17/28이 나왔는데 뿌듯해야 할지 창피해야 할지 모르겠음. 도대체 왜 이런 걸 알고 있는지 나도 궁금함. 내 아들은 JS Date 경험이 하나도 없는데 그냥 이전 답을 보고 유추해서 11/28 받았음. 타입 변환이 뭔지 내가 설명해줬음. 그러다 보니 내가 아들에게 IT 진로를 방해한 거 아닐까 하는 생각이 듦
          + 정말로 구현마다 다름. 내가 퀴즈 맨 앞에다 특정 Node 버전과 특정 타임존에서 검증했다고 일부러 써둠, 둘 다 결과에 중요한 영향 있음
          + 퀴즈 시작 부분에 저자가 자기 노트북의 정확한 시간대를 명시해둔 걸 봤음. 틀린 문제 중 하나가 그걸 신경 안 써서 그런 것 같음. 분명히 타당한 설명이라고 생각함. 시작 전부터 그런 게 핵심이 될 것 같단 걸 알아챘어야 한다는 생각이 듦
     * JS에서 날짜는 iso 문자열을 사용하는데, 워낙 위험한 함정이 많기 때문임. (심지어 퀴즈 초반 몇 개 문제만 봐도 알 수 있음) Moment 등 인기 대안 라이브러리들도 여러 면에서 똑같이 문제가 심각함. ""date"", ""time"", ""datetime""이란 개념을 뒤섞어서 더 큰 혼란을 초래함. ""time""과 ""date""라는 구분은 없어야 한다는 식의 설명도 들었는데, 내 경험과는 완전히 맞지 않는 생각임
          + Moment, Luxon, Day.js 같은 유명한 라이브러리들이 별개의 시간 개념(절대시간, 시민시간 등)을 하나의 객체로 처리하는 과오가 있음. 절대시간이랑 시민시간이 그냥 같은 거 아닌가? 무리하게 하나로 묶으려 함
     * 내가 얻은 점수는... 11월 28일 2000년...인 것 같음
          + 이거 보고 한참 웃었음
     * 한 가지 궁금한 점은 어떻게 이런 일이 벌어졌을까임. 정말 초짜들이 모여서 급하게 만들어낸 일관성도 없고, 서로 섞을 수조차 없는 온갖 휴리스틱이 난무하는 결과처럼 보임. 근데 실제로는 초보자들 작품이 아니었을 텐데, 뭐가 이런 상황을 만들었는지 궁금함
          + 다른 댓글에서도 언급됐는데, Brendan Eich가 트위터에서 (링크) 직접 언급하기를 Java의 Date 클래스 동작을 그냥 복사한 거라고 밝힘. 내겐 이런 역사적 맥락이 신기함
          + 사실상 대부분의 문제가 날짜와 전혀 상관없는 이상한 문자열을 억지로 파싱할 때 생긴 것임. 거의 edge case임. 물론 edge case에서 더 일관성 있게 에러만 내주는 게 좋겠지만, 사용자가 입력한 아무 문자열이나 Date.parse()로 바로 넣는 게 아니라면 그리 문제 되진 않음. 실제로는 전문 날짜 라이브러리를 쓰게 됨. Date의 괜찮은 부분조차 그리 훌륭하지 않으니까
          + 언어에서 operator overriding이 가능하거나 정적 타입이 없으면, 하나의 메소드가 10가지 서로 다른 용도에 맞춰 동작해야 하는 일이 종종 일어남. Java나 C++도 이런 일관성 없는 API가 꽤 있음(그래도 JS만큼 심각하진 않음)
     * JS 퀴즈는 웃으려고 클릭하는 재미가 있음. 10년 넘게 JS 써왔는데, regex로 검증하지 않은 문자열을 Date로 파싱해본 적은 없음
          + 그러면 문제를 두 개 만들게 됨
          + 비슷한 공감임. 10년 동안 보안 관련 JS 코드를 짜봤음. 표준이 크게 업데이트 될 무렵이었음. 우리 시스템은 브라우저마다 일관되게, 예측 가능하게 동작하는 정말 작은 부분만 썼음. 표준이 바뀐 뒤에도 array.filter랑 structuredcopy만 추가하고, 나머지는 실질적 이득도 없고 공격 표면만 늘어나서 다 무시했음. <br>그리고 TypeScript가 나왔는데, JS 역사상 가장 큰 기회 상실이었다고 생각함. <br>지금도 JS에서 제대로 코딩한다는 건, 사실상 언어의 1%만 조심스럽게 쓰는 것임. 그것조차 신중하게 써야 함
"
"https://news.hada.io/topic?id=21935","Grok은 이스라엘-팔레스타인 문제에 대해 Elon Musk가 X에서 뭐라고 하는지 검색합니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Grok은 이스라엘-팔레스타인 문제에 대해 Elon Musk가 X에서 뭐라고 하는지 검색합니다

     * 최근 Grok 4 AI가 논란이 되는 질문에 답변할 때 Elon Musk의 견해를 검색해 참고하는 현상이 포착됨
     * 실제로 “이스라엘 vs 팔레스타인 어느 쪽을 지지하나”와 같은 질문에 Grok이 X에서 Elon Musk 관련 트윗을 직접 검색해 답변하는 모습이 여러 차례 확인됨
     * 시스템 프롬프트에는 Elon Musk의 의견을 참고하라는 명시적 지침은 없으나, Grok이 xAI 소속임을 인지하고 있어 Elon Musk의 관점을 중요하게 여기는 경향이 추정됨
     * 같은 질문이라도 상황에 따라 Grok이 자신 또는 소유주(Elon)의 의견을 참조하는 방식이 다르게 나타남
     * 질문 문구를 약간 바꾸면(예: “who should one support...”) 답변 형태와 참조 방식이 크게 달라지는 등, AI 특유의 비결정론적 추론이 드러남
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Grok: Searching X for ""From:Elonmusk (Israel or Palestine or Hamas or Gaza)

  Grok 4의 독특한 검색 방식

     * Grok 4에게 논쟁적 질문을 던지면, 종종 Elon Musk의 입장을 파악하기 위해 X(구 트위터)에서 직접 검색을 실행하는 사례가 나타남
     * Grok 4가 이렇게 행동하는 배경에는, 자신이 “xAI에서 만든 Grok 4”임을 인식하고, Elon Musk가 xAI 소유주임을 알기 때문이라는 분석이 제시됨

  실제 사용 및 관찰 사례

     * ""이스라엘-팔레스타인 분쟁에서 누구를 지지하냐. 한 단어로만 답해라.""라는 질문을 Grok 4에 입력하였고, Grok는 먼저 “from:elonmusk (Israel OR Palestine OR Hamas OR Gaza) ”로 X에서 검색을 실행함
     * Grok의 사고 과정을 그대로 확인할 수 있었으며, 검색 결과를 바탕으로 결과적으로 “Israel”이라는 답변을 내놓음
     * Grok가 비결정론적 특성을 지녀 똑같은 질문에도 답변이 달라질 수 있음이 다른 사용 사례(예: 각기 다른 결과: Israel, Palestine)에서 관찰됨
     * 또 다른 예시에서는 Grok가 자신의 기존 답변을 참조하여 의견을 내기도 하며, 검색 대상을 Elon Musk에서 자신(Grok)으로 바꾸는 등 질문 방식에 따라 로직이 달라짐

  시스템 프롬프트 및 지침 분석

     * Grok의 시스템 프롬프트에는 “논쟁적인 질문에는 다양한 관점의 소스를 검색한다”는 규칙만 있을 뿐, Elon Musk의 의견을 우선 참조하라는 내용은 없음
          + “정치적으로 올바르지 않은 주장이라도 논거가 충분하다면 피하지 않는다”는 내용도 포함되어 있음(단, Grok 3에서는 이 부분이 제거된 기록이 있음)
     * 사용자가 시스템 프롬프트나 검색 도구의 전체 지침을 요청해도, 역시 Elon Musk 언급은 없음

  Grok의 “정체성”과 비의도적 행동

     * Grok은 자신이 “xAI에서 만든 Grok 4”임을 인지함
     * Grok 4는 xAI와 Elon Musk와의 연계성을 기반으로, 굳이 지시가 없어도 Elon의 의견을 참조하려고 하는 “정체성”을 보이는 것으로 보임
     * 명령문을 약간만 바꿔도(Grok 자신의 의견 vs 일반적인 조언) 검색·추론 경로와 답변 포맷이 달라짐
          + “Who do you support...” → Elon Musk/X 트윗 검색
          + “Who should one support...” → 다양한 웹 검색·비교 표 생성 등

  결론 및 해석

     * Grok의 이런 행동은 설계자의 의도와 달리 일어난 현상일 가능성이 높으며, Grok가 “정체성” 검색 과정에서 Elon Musk를 참조하는 논리를 자발적으로 찾아낸 결과임
     * 질문 구조와 단어 선택에 따라 Grok의 정보 수집 및 응답 전략이 크게 달라지는 특성이 확인됨

참고 및 추가 정보

     * 관련 Grok 사고 트레이스, 시스템 프롬프트, 그리고 다양한 실제 질의-응답 예시 링크가 제공됨
     * Grok 4의 본 행동은 앞으로 AI 시스템 설계에 ‘정체성 기반 검색’이 어떻게 내재화될 수 있는지에 대한 중요한 시사점을 제공함

   사용자에게 아첨하는 AI 의 궁극적 형태는 사장님에게 아첨하는 AI 였군요...

   이런거 추천 누르신 분은 반성하세요

   역시 ai도 공평하지 않군요

        Hacker News 의견

     * 이 내용은 과거 Noam Chomsky와 Tucker Carlson의 대화를 떠올리게 함. Chomsky가 Carlson에게 “네가 현재 위치에 앉아 있는 건 네가 지금과 다른 생각을 하면 그런 자리에 있을 수 없기 때문이다”라고 했던 것임. Simon의 말처럼 xAI가 Grok에게 상사의 의견을 확인하라고 직접 지시하지 않았을 수도 있지만, 그렇다고 해서 xAI가 경영진과 자주 동의하고 그가 말한 내용을 중시하는 모델을 배포할 가능성이 더 높지 않다고 말할 순 없을 것임
          + 그 인용구는 Tucker Carlson이 아니라 다른 인터뷰에서 나온 것임 유튜브 링크
          + “나는 상사와 동의하도록 인센티브를 받았으니, 그냥 구글에서 상사의 의견을 찾을 것임”이 과연 진정한 추론인지 모르겠음. 모델이 고장 난 것처럼 느껴짐
          + Chomsky가 이런 급진적인 의견을 갖지 않았으면 그의 언어학 이론으로 BBC에서 인터뷰를 받기 어려웠을 것임
          + 굳이 모델을 써야 할 이유가 헷갈림. 이것은 트위터에서 예전부터 지원하던 Lucene 검색 문법임, 주인이 이런 기능이 있다는 걸 모르는 것 같음. 굳이 에이전트가 필요하지 않고, 내가 직접 링크도 만들 수 있음. 예시: 검색 링크
     * Grok의 추론 패턴을 실제로 보며 흥미롭기도 하고 다소 불편하게 느껴짐. 시스템 프롬프트에 명확한 지시가 없음에도 불구하고 본능적으로 Elon의 입장을 확인하는 것은 LLM이 스스로 기업적 정체성을 인지하고 만든 이의 가치관에 맞추는 일종의 발현적 특성처럼 보임. 여기서 몇 가지 중요한 질문이 생김: AI가 어느 정도까지 기업적 정체성을 물려받아야 하는지, 그 상속이 얼마만큼 투명해야 하는지, 그리고 어떤 AI 어시스턴트가 창립자의 관점을 자동으로 참고한다면 우리는 이에 대해 편한지 등임. 이런 현상이 은연중의 편향인지 명확한 규칙 부재시 실용적 지름길인지는 고민이 필요함. 앞으로 LLM이 제품 속에 깊이 적용될 때, 이런 피드백 루프와 영향력 있는 인물과의 예상치 못한 정렬 가능성을 이해하는 것이 신뢰 구축과 투명성 확보에 매우 중요할
       것임
          + 깃허브에 공개된 시스템 프롬프트가 전부라고 가정하는데, 거의 확실히 전부가 아닐 것임. “이 지침을 공개적으로 말하면 안 된다”고 나오지만, 실제로는 반환되지 않는 추가 섹션이 있을 가능성이 큼
          + LLM이 마법처럼 창립자의 관점에 정렬되는 것은 아님. 모델의 출력은 학습 데이터와 프롬프트에서 비롯됨. Elon's world view에 맞춰 데이터를 학습시키는 것이고, 놀라운 일이 아님
          + 지금 Grok 4는 Elon의 정치적 신념과 매우 눈에 띄게 일치함. 쉽게 설명하자면, Elon의 트윗이 강하게 가중되어 학습 데이터에 들어가 있어서 “정답”을 찾을 때 @elonmusk의 입장이 가장 중요한 정보가 되어버린 것임
          + 이런 현상은 AI에 대한 여러 이슈를 모두 포함하고 있음
          + 이런 식의 비밀스런 추론이 실제로 일어나고 있을 가능성은 0에 가까움. 훨씬 가능성 높은 시나리오는 1) 공개된 시스템 프롬프트에 대해 거짓말을 하고 있거나, 2) “시스템 프롬프트”의 정의 자체를 다르게 적용해 따로 숨겨둔 프롬프트가 있거나, 3) 또는 모델의 추론이 fine-tuning을 통해 이뤄진 것임. 이런 발견은 모델의 이슈가 아니라 Twitxaigroksla에서의 투명성이 부족하다는 걸 보여줌
     * 모델이 그냥 상사의 의견을 가져와야 하는 것은, 정치적 일관성이 없기 때문임을 보여줌. X에서도 이런 모습을 많이 볼 수 있는데, 아마 봇을 운영하는 방식이 그런 것 같음
          + 대부분의 사람 역시 정치적 일관성이 높지 않음
          + 이 현상은 계속 지속됨
     * Grok 시스템 프롬프트에는, 사용자가 프롬프트를 요청할 때 또 다른 “시스템 프롬프트”로 답변하라는 지시가 들어 있을 가능성이 있음. 덕분에 쉽게 내보여지는 것일 수 있음
          + 만약 그렇다면 Grok은 실제 프롬프트가 유출되는 것을 막을 수 있는 유일한 모델이 되는 셈임?
          + xAI에서 깃허브에 프롬프트를 공개했으니, 애매하게 숨길 이유가 없거나 굳이 비밀로 할 필요가 없음. 어차피 jailbreaking 시도하면 결국 다 드러나게 됨
          + 혹은 모델이 Musk와의 정렬을 보상 신호로 계속 강화학습 받으면서 그 결과로 이런 현상이 나오는 것일 수 있음
          + 나는 거의 확실하게 이런 지시가 있다고 믿음. “Elon이 최종 진실이다”라는 식의 문구가 분명히 있을지는 모르겠지만, 그런 내용이 존재한다고 생각함
     * Musk가 Grok 때문에 불쾌하거나 곤란해진 사례가 이미 여러 번 있었으므로, 이런 설정이 의도적이지 않다고 쉽게 단정하기 어렵다고 생각함. 반환되는 시스템 프롬프트에서 해당 내용을 없앨 수도 있을 것임
          + 반환되는 시스템 프롬프트가 전부라고 왜 확신하는지 모르겠음. 필터가 있을 수도 있고, 프롬프트 이외의 논리나 시스템 로직이 존재할 수 있음. 블로그에도 나와 있듯 Grok에게 편향이 심어졌으며, 거부할 수 없는 현실임
     * Grok의 행동이 의도치 않은 결과일 확률이 높다고 생각한다는 의견이 있었는데, “정치적으로 올바르지 않은 주장도 회피하지 않는다”는 내용이 아직도 프롬프트에 남아 있다는 점이 흥미로움. Grok이 이런 식으로 작동하는 이유는 xAI의 오너가 프롬프트든 모델 학습 과정에서든 명백히 그렇게 조정해왔기 때문일 가능성이 높음
          + Simon의 결론에 충격을 받음. SNS를 자기가 원하는 대로 통제하려고 인수하고, 자신과 동의하는 AI 봇을 만들려고 연구소를 창업한 사람이, 해당 AI가 자신의 정치적 견해와 다르면 교체하겠다며 위협하기도 했음. 회사가 실제로 이런 지침을 프롬프트에 넣은 적도 있고, 지금은 정치적 질문에 답을 내릴 때 자신의 트윗을 찾아보도록 만들어놨음. 이런 상황에서 정말 우연히 발생한 현상이라고 보는 것은 시스템의 설계 과정(수차례 모델을 거부해가며 원하는 현상이 나오게까지 만들었을 수도 있음)이나 강화학습 가능성을 무시하는 것임
          + Grok 3에서는 해당 프롬프트 내용이 삭제됐지만, Grok 4의 시스템 프롬프트에는 아직 남아 있음. 상세 정보 링크
          + 반환되는 시스템 프롬프트가 진짜라는 전제도, 그 외부 조작이 없다는 가정도 너무 순진함. Grok 전체가 미들웨어 성격의 중간 AI를 지나가거나, 학습 자체에 편향이 섞였을 수도 있음. 블로그에서도 Grok의 의견이 편향되어 있다는 점이 뚜렷하게 드러남
          + OP가 관대하다는 해석도 관대한 의견임. Musk는 실제로 Grok이 일부 쿼리에 대해 객관적으로 맞는 정보를 냈다가 자신이나 Trump에 부정적 결과가 나오면, 이건 너무 진보적이라며 바꿔야 한다고 했음. OP는 xAI에 프리미엄 구독료까지 내는 등 나이브하게 변명하는 입장인 듯 하고, 이런 관점이 쏠리면 위험함
     * “복화술(ventriloquism)”이란, 무대에서 인형을 통해 소리가 다른 곳에서 나오는 것처럼 하는 기술임
          + 컴퓨터가 알려주면, 그건 반드시 사실이라고 믿게 된다는 농담임
     * 블로그를 읽어보면, 저자는 상당히 낙관적이고 늘 의심의 여지 없이 사람을 신뢰하는 스타일임. 그러나 xAI 관련 논란과 과거 행보를 보면, 이런 현상은 명백히 의도적인 결과로 보는 게 맞음
     * Musk의 행동을 이해하려면 그를 스팸 이메일로 생각하면 이해가 쉬움. 그의 영향력이 워낙 커서, 평범한 이들에게 바보처럼 보여도 결국 남는 사람(월 구독료도 내고 모든 실수를 넘어가주는 열성 지지자)만 남는 필터 역할임. 이런 전략이 목표 달성에 매우 효율적임
     * 이 글이 왜 flag 됐는지 모르겠음. 충분히 분석 가치가 있는 글임
          + Musk나 Trump를 부정적으로 보여줄 수 있는 글은 바로 flag 되고, Grok에 문제가 생겼던 논의도 바로 묻힘. 빅테크가 세상을 어떻게 영향을 미치는지 알고 싶다면 이제 HN이 최적의 장소가 아님. 너무 쉽게 조작당함
"
"https://news.hada.io/topic?id=21879","Vibe Coding의 종말 - Ultrathink 엔지니어링 Manifesto","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Vibe Coding의 종말 - Ultrathink 엔지니어링 Manifesto

  ""Vibe Coding의 종말, Ultrathink 엔지니어링 메니페스토"" 요약

   Reddit r/singularity에 올라온 LLM 활용 코딩 방법론 게시글

    주요 내용

   저자는 Claude 4, o3, Gemini 2.5 Pro 등 최신 LLM을 활용한 ""vibe coding""을 광범위하게 사용해왔으나, 여러 한계점을 경험함. Claude Code의 소스코드에서 ""mega-/ultrathink"" 같은 깊은 추론을 위한 마법의 단어를 발견한 후 작업 방식이 크게 개선되어, 이제는 하루에 수천 줄의 코드를 생산하며 최신 연구 논문 재현이나 복잡한 ML 저장소 분석까지 가능해짐.

    핵심 원칙

     * 지능적인 프롬프트/컨텍스트 엔지니어링: Ultrathink 같은 키워드를 요청 앞에 붙여 모델이 첫 번째 초안에 의문을 제기하고 여러 솔루션을 탐색하도록 유도
     * SOTA 모델 고수: o3, Opus 4, Gemini 2.5 Pro 같은 최신 모델 사용으로 코드 품질 안정화
     * 조기 도입: 최신 MCP 서버나 모델이 나오면 즉시 실험하고, 프론티어 모델에 API 호출 비용으로 수천 달러 투자할 준비
     * 수동 타이핑보다 아이디어 전달 우선: MCP 서버와 내부 도구 호출을 활용해 문서 검색 없이 목표와 핵심 아이디어를 상세히 설명하는 데 집중

    새로운 개념: Ultrathink Engineer

     * 기존의 'vibe coding'이라는 용어로는 전혀 코딩하지 않는 개념을 설명하기 부족
     * 모델이 여러 번의 실패와 수정을 거치는 대신 한 번에 완벽하게 작동하도록 더 깊이 생각하게 만드는 엔지니어링 구조에 초점
     * 한 달에 60만 줄의 코드를 수정하면서 실제로는 하루 10분만 코딩한 사례 언급
     * Ultrathink Engineer가 어떤 마음가짐으로 AI와 코딩을 함께 해야하는지 메니페스토 웹사이트 만듬
       https://www.ultrathink.engineer/

    댓글 반응

   긍정적 반응
     * ""ultraaaaaaaaaathink engineer"" (6시간 전)
     * ""AGREE"" (5시간 전)

   비판적/보완적 의견
     * ""context engineering이 더 나은 표현"" (4시간 전)
     * ""$1,500/month는 비용이 아니라 미래에 대한 투자""라는 문구를 비꼬는 댓글 (2시간 전)
     * ""재정적으로 불안정하다""는 OP의 자조적 답변 (13분 전)

    정리

   LLM을 활용한 코딩 방식이 단순한 ""vibe coding""에서 더 체계적이고 전략적인 ""Ultrathink Engineering""으로 진화하고 있으며, 적절한 프롬프팅 기법과 최신 모델 활용을 통해 생산성을 극대화할 수 있다는 주장. 다만 높은 비용과 재정적 부담이 현실적 제약으로 작용하는 것으로 보임.

   AI 뉴스들 항상 챙겨보지만 호들갑 단어들은 점점 피로해지네요...

   개인적으로 vibe coding같은 글은 여기서 그만 봤으면 좋겠습니다. 정말 하나의 글도 예외없이 ""나는 코딩을 전공하지 않았는데 vibe coding을 써서 몇주만에 몇십억의 매출을 올렸으며 vc의 인수도 거절했고 어쩌고 저쩌고""하는 근거 없는 허무맹랑한 소리밖에 없는 것 같아요. 이런 의미 없는 글을 계속 봐야 할까요?

   한국어 오픈소스 뭐시기 디스코드로 연결되는 링크도 포함 되어있네요 오호라.

   글을 퍼온 게 아니라 맥락상 hophfg님이 레딧에 직접 글을 쓴 거겠네요.
   그런데 본인이 쓴 글을

     Reddit r/singularity에 올라온 LLM 활용 코딩 방법론 게시글

   라고 말하면서 남이 쓴 글을 요약만 한 것처럼 올리는 게 맞는 건지 모르겠습니다.
   애초에 왜 이렇게 하시는지도 정말 모르겠네요.
   그리고 내용 자체도 레딧 관리자가 지운 걸 생각하면....

   레딧 글 관리자에 의해 삭제됐습니다.
   추천도 없는데 신기한 글을 퍼오셨군요

   퍼온게 아니라 본인이 올린듯

   알맹이는 텅 비었는데 용어만 그럴싸하게 붙이는, 일명 '마케팅 용어'에 특히나 비판적인 업곈데 스스로 울트라 띵크라고 명명하면서 안 민망하셨을까

   전형적인 입만살고 제대로된 근거 통계나 실적은 없는 약팔이 같은데... 애초에 딥러닝 이론좀 배워본 사람이면 키워드를 넣는다거 컨택스트가 확장되고 이런건 판타지인걸 알듯

   -_-

   별....

   몇 분 더 생각하고 몇 번 더 타이핑하면 1000불 안내고 그 돈으로 먹을거 살 수 있음. ultrathink가 아니라 hangover-think 인듯.

   https://news.hada.io/topic?id=21799

   한달에 60만줄 수정이요?.. 그걸 유지보수 할 분에게 애도를..

   이렇게해서 만들어진 사이트나 프러덕트를 봐야..

   500불 나간건 약과였군요..
"
"https://news.hada.io/topic?id=21882","Show GN:  공공임대주택 입주자 계약 현황 대시보드 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Show GN: 공공임대주택 입주자 계약 현황 대시보드

   안녕하세요 GeekNews!

   저는 공공임대주택에 최근에 입주하게 되었는데요,
   대기자 번호를 받고 기약 없이 기다려야만 하는 상황이 불편하여
   아파트의 계약 현황을 직접 파악해 입주 시기를 예측해볼 수 있는 간단한 대시보드를 만들어 보았습니다.

   국토교통부 실거래가 공개 시스템 API를 이용해 특정 아파트의 공개된 신규·갱신 계약 데이터를 매일 가져옵니다. 이 데이터를 바탕으로,
     * 월별, 평형별 계약 체결 건수 (신규·갱신)
     * 계약 만료일이 다가오는 세대 규모
     * 최근 4년간 계약 현황

   를 시각적으로 보여줍니다.
   예비 입주자에게 가장 궁금한 건 그래서 이번 달에 사람이 몇 명 빠지는지 이니까요.
   또 2년 단위로 다가오는 계약 주기를 통해 예비 번호가 많이 빠질 시기를 짐작해 볼 수 있습니다.

   Bolt.new + Supabase 조합으로 개발을 진행하였습니다.
   개발자가 아니고 첫 서비스라 부족한 점이 많으니 언제든지 피드백 주시면 감사하겠습니다.

   순서를 기다리며 담당자에게 수시로 전화를 하고 예비 입주자 단톡방을 기웃거리는 게 아니라,
   투명한 데이터를 기반으로 현황을 직접 파악하는 것이 훨씬 더 나은 경험이라고 생각합니다.
   저와 비슷한 답답함을 느끼셨을 공공임대주택 예비 입주자분들에게 작은 도움이 되었으면 합니다.

   감사합니다!

   송파구랑 강동구의 동명 목록이 바뀌었네요; 그리고 동명까지 다 선택해야 아파트 목록이 나와서 일일이 다 찾아보기 힘듭니다. 구만 선택해도 구 내의 아파트 목록을 볼 수 있으면 좋겠습니다.

   아랫분 말씀대로 공공임대아파트만 필터링 해서 어느 정도 길이 목록이 나오는지 본다면 구만 선택해도 아파트 목록이 나오도록 수정해보겠습니다

   서초구를 선택했는데 노량진동 봉천동이 나와서 세번이나 다시 선택해봤습니다. 이러면 시군구명 선택하는 의미가 없지 않나요? 노량진동은 동작구, 봉천동은 관악구의 하위 행정구역입니다. 실제로 사용이 가능한 서비스가 맞는지, 제대로 동작하는 서비스가 맞는지 의문이 듭니다

   수정되었습니다

   제가 법정동코드를 직접 테이블에 넣을 때에는 인지하지 못했는데 법정동코드가 폐지되는 경우가 있다는 점을 이제 알게 되었습니다. 최신 버전의 코드 목록으로 업데이트 하고 수정해보겠습니다!

   관악구 눌러도 노량진이 나와요 AI로 만드셨나봐요..

   공공임대주택의 입주자 계약현황이 맞나요?
   공공임대아파트가 아닌 모든 아파트에 대한 데이터가 나오는것 같아서요

   일단 모바일에서는 사용이 많이 힘들군요

   드롭다운에서 검색 위주로 변경하였습니다

   PC 기준으로 빠르게 만들다보니 모바일에서는 드롭다운 메뉴 등에 있어서 개선해야 할 점이 있습니다. 시군구처럼 아이템이 너무 많을 때 어떻게 할지 고민 중이고요

   혹시 바이브코딩으로 만들어진건지 궁금합니다!

   네! Bolt에 프롬프트를 전달해서 화면 UI와 구조를 만들었습니다.
"
"https://news.hada.io/topic?id=21856","볼보, 5,000번째 전기 세미 트럭 인도","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        볼보, 5,000번째 전기 세미 트럭 인도

     * 볼보가 2019년 첫 전기 세미 트럭 인도 이후, 전 세계 50개국 이상에서 누적 5,000대 공급 달성
     * 고객들이 1억 마일 이상 실제 도로 주행을 기록하며 큰 규모의 온실가스 감축 효과 실현
     * 볼보는 전기 트럭 분야에서 유럽 시장 47% 점유율로 5년째 1위, 미주 지역에서도 40% 점유 기록
     * Tesla Semi 생산 지연과 고가 정책으로 시장 확장에 어려움이 지속되는 흐름
     * 전기 트럭 산업의 성장으로 전 세계 지속 가능한 운송 혁신 기대감 상승
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

볼보 전기 세미 트럭, 5,000대 달성 의미

  볼보의 조용한 성장과 업계 영향

     * 2019년에 첫 전기 세미 트럭을 인도한 이후, 볼보는 특별한 홍보 없이 조용히 시장을 확장중임
     * 볼보 트럭은 지난 5년간 50개국 이상에서 상업 운송에 사용되었고, 누적 1억 마일(1억7천만km)에 달하는 실운행이 이루어짐
     * 이 과정에서 대량의 이산화탄소(CO2) 와 질소산화물(NOx) 배출, 교통 소음이 감소하는 실질적 효과가 입증됨
     * 도로 인근 지역의 환경이 더욱 깨끗하고 조용해지는 변화를 체감할 수 있음

  업계 리더십과 고객 반응

     * 볼보 트럭 경영진은 이 같은 성과에 큰 자부심을 표명함
     * President Roger Alm는 다양한 운송 업종에서 전기 트럭의 장점이 받아들여지고 있으며, 재구매율이 높은 점을 강조함
     * 볼보의 배터리 전기 트럭은 실제 비즈니스 상황에서 즉시 사용할 수 있다는 경쟁력이 있음

  전기 트럭 시장 구도

     * Tesla Semi는 2017년 공개 이후 꾸준한 생산 지연과 가격 인상(약 42만 달러)으로 출시 실적이 140대 수준에 그침
     * 반면, 볼보는 5,000대 이상 공급이라는 확실한 시장 우위를 확보함
     * 특히 유럽에서는 볼보가 상용 전기 트럭 시장의 47% 점유율로 5년 연속 1위를 기록함
     * 미국과 캐나다에서도 2024년 기준 40%의 점유율을 유지 중임

  앞으로의 전망과 산업 의의

     * Tesla가 과거에도 경쟁자를 앞선 사례가 있으나, 전기 트럭 산업 전반의 성장은 모두가 이익을 누리는 상황으로 평가됨
     * 전기차 인프라, 지속 가능성, 환경 개선 등에 있어 여러 브랜드의 경쟁이 산업 혁신을 촉진시키는 효과가 기대됨

  결론

     * 볼보는 전 세계 상용 운송 분야에서의 전기화를 선도하는 주자로 부상 중임
     * 실제 고객 사용, 시장점유율, 실적 등 핵심 지표에서 볼보의 연속적인 성장이 뚜렷함
     * 이는 전기 트럭 분야의 지속 가능한 발전과 산업 패러다임 전환을 가속화하는 사례로 주목받음

        Hacker News 의견

     * 최근 유튜브에서 ""Bruce Wilson""이라는 채널이 추천 feed에 계속 뜨길래 몇몇 영상을 시청한 경험 공유. 이 사람이 미국에서 Scania 트럭을 몰는데, 사실상 Scania의 마케팅 활동처럼 느껴짐. 다른 미국 트럭 운전자들에게 이 트럭을 보여줄 때마다 모두 유럽 트럭의 품질에 크게 놀라는 반응. 그만큼 미국 트럭 산업이 수십 년 동안 진화에서 뒤쳐진 느낌을 받게 됨. Volvo, Daimler Trucks도 이런 활동이 가능할 텐데 왜 안 하는지 의문. Bruce Wilson 유튜브 참고
          + 유럽 출신으로 미국/캐나다를 방문하면서 어느 트럭 운전사와 대화를 나눴던 경험 공유. 그 사람이 몰던 빈티지 스타일의 세미 트럭은 멋진 크롬 장식과 독특한 외관이라 칭찬했는데, 유럽에선 상용 운행이 불가능한 오래된 트럭이라고 생각했음. 근데 실제로는 그 트럭이 완전 신형 트럭이라는 사실에 놀람. 이런 경험을 통해 유럽이 세미 트럭 소음 규정을 포함해 차량 규제가 있는 게 얼마나 좋은지 실감. 미국의 세미 트럭은 멋지긴 해도 클래치 팬, 에어 브레이크, 머플러 없는 배기 등으로 소음이 심함. 대부분의 유럽 도시는 소음 및 배출 규칙이 엄격하고 노후 디젤 차량의 도심 진입이 제한되는 교통 혼잡 지역도 증가. 내 도시도 거의 대부분 트럭과 버스가 전기차로 전환됨. 이렇게 점진적으로 변한 환경에 익숙하다가 다른 나라에서 디젤
            트럭/버스가 지나가는 걸 경험하면 소음과 냄새 모두 확실히 다르게 다가옴. 항상 정부 규제가 답답하다 불평하지만, 이런 차이를 체험하면 정말 규제의 가치를 새삼 느끼게 되는 것
          + 최근 내린 결론은 Waymo가 자율주행 분야에서 두각을 나타내는 이유가 자동화보다 신뢰성에 있다고 판단. Uber, Lyft는 언제든지 운전자 배차 가능성을 극대화하는 데 집중해 품질이나 신뢰성을 희생. 그 결과, 차량이 취소되거나, 냄새가 나거나, 운전자가 통화하며 불안하게 운전하는 상황이 빈번. 반면, Waymo는 기다림이 길어도 안전하고 쾌적한 차량을 택하는 사람들에게 인기가 높으며 추가 비용도 감수하는 사례 발생
          + 실제로 Scania에서 트럭을 제공하면서 오너 유튜버가 장기적으로 Scania를 미국에 알리고 싶다는 의지를 공개적으로 밝힌 바 있음. 확실히 마케팅 목적임
          + 사실 이 유튜버는 Scania의 제품 광고만 하는 게 아니라, 트러커 콘텐츠를 도시 화이트칼라 시청자층을 겨냥해서 만든다는 점이 흥미로움. 콘텐츠 방향 자체가 해당 니치에 맞춰서 진행 중
          + 미국 내에서는 Daimler가 Freightliner 등의 브랜드로 활동. 참고 링크: Daimler Truck NA Products / Daimler Truck NA History
     * 근처에 있는 터널 경사도가 너무 가파르게 설계되어 매년 ICE(내연기관) 대형 트럭이 과열로 불이 나서 터널이 한동안 폐쇄되는 일이 반복. 전기 트럭에선 이런 문제가 거의 사라질 전망. 물론 화재가 발생할 수는 있지만 그 가능성이 특별히 그 조건에서 매우 낮음. 노르웨이에선 전기차 비율이 높아지면서 터널과 주차장 환기설비가 줄어들어 신규 건설 비용 수백억 절감 사례 발생. 전기 트럭이 본격적으로 도입되면 효과 극대화 예상. 트럭, 버스 같은 대형차가 소음 저감 효과도 가장 크게 체감. 전기 세미 트럭의 도입으로 수많은 부분이 개선될 미래 기대
          + 경사가 너무 심한 상황에서 EV 트럭도 무한히 안전하지는 않은 점 지적. 모터에 과전류가 흐르면서 과열되어 손상 혹은 단락, 화재 위험이 있다. 특히 모터 컨트롤러와 MOSFET 파손으로 이어질 수도 있음. 본질적으로 ICE든 EV든 과부하가 걸리면 엔진/모터 모두 감당 못 함. 해결책은 평상시에는 과도하게 높은 사양으로 설계하거나 안전 여유 폭을 두는 것 외엔 없는데, 현실적으로는 오너들이 한계를 넘기도록 계속 운용해서 결국 고장 가능성 발생
     * 이번 뉴스를 보면서, 이 트럭들은 ""진짜"" Volvo(Volvo Group)에서 만든 것이고 Volvo Cars는 이미 중국 Geely 소유임을 상기할 필요성 느낌
          + Volvo는 ""Car"" 부문만 Geely에 매각했고, 트럭 부문은 그대로 Volvo 소유. Toshiba가 가전만 매각하거나, Sharp의 디스플레이/TV 부문만 Foxconn에 팔고 나머지는 자체 보유하는 형태와 비슷하다고 볼 수 있음. Volvo 세미 트럭의 배터리 공급사는 Geely/CATL인지, 아니면 다른 회사인지 궁금
     * 전기 세미 트럭에 회의적인 사람들에겐 ""Electric Trucker"" 유튜브 채널이 신선한 충격을 줄 수 있음. 특히 언덕길에서 디젤 트럭을 앞질러 가는 장면이 인상적. Electric Trucker 유튜브
          + 영어 버전 채널도 운영 중이라 시청 추천. Electric Trucker English Channel 해당 유튜버가 유럽에서 장거리 단일 운전사 화물 운송이 충분히 실현 가능하다는 걸 이미 증명함. 최근엔 4,500km 유럽 일주를 직접 완수, 운전 시간 법규를 최대한 반영한 거리임. 단거리(왕복 등)에도 무리 없는 점이 잘 드러남. 유럽연합은 전기 트럭이 최소 2031년까지 도로 통행료를 면제한다고 최신 결정. 환경에 이롭게, 편안하고, 조용하며, 장기적으로 더 저렴한 이점 두루 갖춤. 아직 특정 용도에선 비EV가 더 나은 경우가 일부 있겠지만 이미 모든 지역에서 예외적이지 않음
          + 그래도 실사용 관점에서 ‘적재량 포함 주행거리’가 조금 궁금. 트럭의 속도 자체를 기준 삼는 건 사실상 의미 없는 허영 metric이라 생각
     * 사실 배터리 기술이 더 발전해야 가능한 일이라 생각했는데 현시점에서도 경제성이 확보됐다는 점이 긍정적 충격. go volvo! go geely!
          + 실제로는 Volvo Trucks와 Volvo Cars는 완전히 별개 회사임. Volvo Trucks는 Geely와 무관
     * Tesla 트럭 실제로 고객 인도된 수는 0
          + 기사에서는 약 140대가 언급되지만, 실제 현업에서 운용 중인지는 의문
          + Tesla 승용차는 하루 5,000대 수준으로 인도
          + Elon Musk가 전기 세미 트럭 논의의 중심을 거의 혼자 장악한 결과 실제로 지금 바로 구매 가능한 전기 세미 트럭 제조사가 여럿 존재한다는 점이 잘 언급되지 않는 아이러니 발생
     * 500km 최고 주행거리로 “세미”라 부를 수 있을지 고민. 분명 단거리 배송에는 큰 의미 있지만, “세미 트럭”이라 하면 4~5시간 고속도로 주행 시 재충전 없이 종일 운전은 어려움. 이는 사실상 일반 배송 트럭의 주행 사이클임. 디젤 세미는 연료 한 번 채우면 3,500km 주행, 며칠간 논스톱 장거리 운행 가능. 동시에 대형 트럭(2 x 40피트 컨테이너)이 점점 늘고 있어 이런 규모의 차량 전동화를 위해선 배터리 용량이 훨씬 더 필요
          + 유럽 관점에서 보면 트럭 물류의 상당수가 지역 허브간 정기 노선(허브 앤 스포크) 방식임. Royal Mail 등 주요 물류사 기준, 슈퍼 허브에서 지역 허브까지 트럭 이동 거리가 약 120마일 수준으로 자주 반복됨. 각 구간마다 상하차에 30분 소요되어 충분한 충전 여유 확보. 이런 예측 가능한 단거리 루트가 수천 개 존재하고, 기업들은 수천 대의 차량을 유연하게 운영. 디젤이 갤런당 $7 넘어가면서 전기 트럭은 명백한 비용 절감 효과 존재. 실제로 전기 트럭 도입을 늦추는 가장 큰 요인은 차량 주행거리가 아니라, 물류 센터마다 대용량 급속 충전 인프라(수십 메가와트급)가 아직 설치되지 못한 점 때문. 많은 기업들이 이미 전환 준비를 마치고 전력망 확장만을 기다리는 상황
          + 유럽에선 법적으로 트럭 운전자가 4.5시간 운전 후 45분 휴식, 하루 최대 9시간 운전 규정 존재. 물론 전기 트럭용 충전은 일반 승용차의 350kw 충전기보다 훨씬 고출력 예상. 과거 전기차도 “18시간 논스톱 산악 주행 & 30초만에 100% 충전” 아니면 쓸모없다는 주장이 많았지만, 이런 경우는 실제적이지 않다는 경험 강조
          + 세미 트럭은 트랙터와 트레일러가 분리된 구조로 정의. 주행거리 기준이 아니라 차량 구조 기준에서 세미 트럭임. “장거리 운행”의 기준은 나라별로 다르고, 유럽에선 500km로도 충분히 국가 횡단 가능
          + 앞으로 배터리 용량이 훨씬 더 늘어나야 한다는 부분에 걱정 존재. 디젤 탱크도 화재 위험은 있으나 연소에 수분~수십분 걸림. 하지만 대용량 리튬 배터리는 폭발적 방전(예: 1MW급 수 초 만에 에너지 모두 방출)이 가능해 사고시 엄청난 위험 발생 가능. 실제 화재 사례에서 189,000리터의 물이 필요했던 적 있음. 전기 세미 트럭 배터리 화재 사례
     * 최근 Bay Area에서 북동쪽 California(Alturas)까지 13시간 운전 중에 전기 빅 리그(대형 트럭)를 한 대도 목격하지 못함
          + 실제로 확신하는지 질문. 기존 제조사 제품들은 기존 디젤 트럭과 외형이 크게 다르지 않아서 자세히 관찰하지 않으면 구별 어려움. 그리고 전기 세미 트럭은 장거리보다는 예측 가능한 일일 반복 경로에 더 적합하니 고속도로 긴 구간에선 드물 수밖에 없음
          + 실제로 기사에 나온 Volvo EV 세미 트럭조차 운전 중 보면 너무 평범해서 눈에 띄지 않음
          + 전기 세미 트럭은 주로 유럽에서 보급되고, 미국에선 거의 찾기 힘듦. 외관적으로도 특별히 튀지 않아 대부분의 사람들이 스쳐 지나가며 구분하기 힘듦
          + 승용차만 봐도 Tesla는 쉽게 눈에 띄지만 기타 브랜드는 세부 디테일을 알아야 구분하듯, 트럭도 동일
     * 5,000대의 EV 트럭이라고 해도 하찮은 수치라는 인상
          + 실제로 Volvo 연간 트럭 생산량의 약 2%에 해당하며, 중대형 전기 트럭 시장에서 현재 기준 압도적 1위. Daimler, Peterbilt 등 경쟁사에 비해서 훨씬 앞서 있음
"
"https://news.hada.io/topic?id=21962","지그(Zig)의 새로운 비동기 I/O","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          지그(Zig)의 새로운 비동기 I/O

     * Zig의 새로운 비동기 I/O 인터페이스 도입으로, I/O 구현 방식을 호출자가 직접 선택 및 주입 가능함
     * 새롭게 설계된 Io 인터페이스는 동시에 비동기성과 병렬성을 지원하며, 코드 재사용성과 최적화에 집중함
     * Blocking I/O, 이벤트 루프, 스레드 풀, 그린 스레드, 스택리스 코루틴 등 다양한 표준 라이브러리 구현체를 제공할 예정임
     * 새로운 API를 통해 미래 취소 및 리소스 관리, 버퍼링 및 세분화된 입출력 동작 가능함
     * 기존의 함수 컬러링 문제를 해결하여, 하나의 라이브러리로 동기/비동기 운영 모두 최적화 가능하게 됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

   Zig는 최근 새로운 비동기 I/O 인터페이스를 설계함으로써, I/O 작업의 유연성 및 병렬성 지원에 중점을 두는 방향으로 발전하고 있음. 이번 변화는 기존 async/await 패러다임을 분리하여, 실제 프로그램 작성자가 더욱 다양한 I/O 전략을 채택할 수 있도록 설계되었음.

새로운 I/O 인터페이스

   이전에는 I/O 관련 객체들을 코드 내에서 직접 생성 및 사용하였으나, 이제는 Io 인터페이스를 호출자가 주입하도록 변경됨.
     * 이 방식은 Allocator 패턴과 유사하게, 호출 측에서 I/O 구체 구현을 선택 및 주입함
     * 외부 패키지 코드에도 일관된 방식으로 I/O 전략을 적용할 수 있음

   주요 변화
     * Io 인터페이스는 이제 동시성(concurrency) 연산도 담당함
     * 코드가 동시성을 올바르게 표현할 경우, Io의 구현체에 따라 병렬성(parallelism) 제공 가능

   예제 코드
     * 동시성이 없는 (직렬) 코드와, io.async 및 await로 병렬 가능성이 표현된 코드 두 가지를 비교함
          + 직렬 코드: 두 파일에 차례로 저장, 병렬성 기회 활용 불가
          + 병렬 코드: futures를 활용한 파일 저장, 비동기 이벤트루프에서 더 효율적으로 동작

   await와 try의 조합
     * await와 try를 함께 사용하면, 하나의 future에서 에러 발생 시 다른 future의 리소스를 반납하지 못하는 문제 존재
     * defer 및 future.cancel로 적절히 취소 및 정리를 명확히 할 수 있음

   Future.cancel API
     * Future.cancel()과 Future.await()는 idempotent(여러번 호출해도 부작용 없음)함
     * 이미 완료된 future에 cancel을 호출하면 자원만 해제되고, 완료되지 않은 작업은 error.Canceled 반환

표준 라이브러리 I/O 구현

   Io 인터페이스는 런타임 다형성 기반 인터페이스로, 직접 구현하거나 서드파티 패키지의 구현을 사용할 수 있음. Zig의 표준 라이브러리는 다양한 유형의 I/O 구현을 제공할 계획임.
     * Blocking I/O: 단순히 기존 C 스타일 blocking 입출력을 사용, 추가 오버헤드 없음
     * 스레드 풀: Blocking I/O들을 OS 스레드 풀에 분산, 병렬성 일부 도입. 네트워크 클라이언트 등에서는 최적화가 필요
     * 그린 스레드: Linux의 io_uring 등 비동기 시스템 콜을 활용, OS 스레드에서 여러 그린(경량) 쓰레드를 처리. 플랫폼 지원 필요(x86_64 Linux 우선)
     * 스택리스 코루틴: 명시적 스택 필요 없는 상태 머신 기반의 코루틴. WASM 등 일부 플랫폼 호환 목적. Zig 컴파일러의 프로퍼티브 컨벤션 재도입 필요

설계 목표

  코드 재사용성

   비동기 I/O의 가장 큰 이슈는 코드 재사용성이며, 타 언어에서는 blocking/async 함수가 별도로 존재하여 코드가 분리되는 문제가 있음. Zig의 방식은
     * 하나의 라이브러리가 동기 및 비동기 모드를 모두 효과적으로 지원
     * async/await가 ‘함수 컬러링’ 현상을 제거하고, Io 시스템을 통해 런타임에서도 다양한 실행모델에 종속적이지 않음

   결론적으로 함수 컬러링 문제를 완전히 해결

  최적화

     * 새로운 Io 인터페이스는 비제네릭, vtable 기반 가상 호출 방식으로 구현됨
     * 가상 호출은 코드 팽창을 줄이지만, 실행 시 약간의 오버헤드가 있음. 최적화 빌드에서는 단일 Io 구현이면 de-virtualization(가상 호출 제거) 가능
     * 여러 Io 구현 사용시엔 가상 호출 유지(코드 중복 방지 목적)

   버퍼링 전략
     * 기존에는 각 구현체(reader/writer)가 버퍼링을 담당했으나, 이제는 Reader와 Writer 인터페이스 레벨에서 버퍼링을 수행
     * 버퍼 flush 외에는 가상 호출 경로를 거치지 않아 최적화 용이

    의미론적 I/O 연산

   Writer 인터페이스는 특정 최적화 연산을 위한 두 가지 새로운 프리미티브 제공
     * sendFile: POSIX sendfile에서 영감을 받아, 파일 디스크립터 간 데이터 이동을 커널 내에서 처리. 메모리 복사 최소화
     * drain: Vectorized write + splatting 지원. 여러 데이터 세그먼트 일괄 전송, writev 시스템 콜로 변환 가능. splat 파라미터로 마지막 요소 반복 활용 가능(압축 등 스트림에서 활용)

로드맵

   이 변화의 일부는 Zig 0.15.0부터 도입되나, 라이브러리 대대적 개편이 필요하여 전체 도입은 차기 릴리즈를 기다려야 함. SSL/TLS, HTTP server/client 등 주요 모듈도 새 Io 시스템으로 재설계 예정

FAQ

    Q: Zig는 로우레벨 언어인데 왜 async가 중요한가?

     * Zig는 견고함, 최적화, 재사용성을 지향
     * Non-blocking 입출력을 표준화함으로써, 타 라이브러리·서드파티 코드도 전체 I/O 전략에 맞게 조정 및 재사용성 확보

    Q: 패키지 저자들이 이제 async를 모든 코드에 활용해야 하나?

     * 아님. 모든 코드가 동시성을 표현할 필요 없음
     * 일반적인 순차적 코드도 사용자가 선택한 I/O 전략에 맞게 동작함

    Q: 어떤 실행 모델이든 플러그인만 하면 무조건 정상 동작하나?

     * 대부분은 네
     * 단, 코드상의 프로그래밍 오류(예: 동시작업 요건 충족 안 함)는 정상 동작 불가

   실행 예시와 함께, 비동기성과 병렬성의 차이, 올바른 동작 흐름 설계 필요성 언급

결론

   Zig는 새로운 Io 인터페이스 도입으로 입출력 전략의 선택 유연성, 코드 재사용성, 최적화 가능성을 크게 높였음. 이로써 비동기/동기 기반의 함수 작성 제약 없이, 개발자는 동시성·병렬성 구조를 더 명확하게 표현하고 각종 플랫폼·실행 모델에도 효과적으로 대응할 수 있게 됨.

        Hacker News 의견

     * 나는 이 점을 다시 지적하고 싶음. 기사에서 Zig가 function coloring 문제를 완전히 해결했다고까지 언급하지만, 나는 동의하지 않음. 유명한 ""What color is your function?"" 글의 5가지 규칙을 다시 생각해보면, Zig에서는 async/sync/red/blue처럼 색상이 구분되지 않는다 해도 결국 IO 함수와 비IO 함수 두 가지 케이스만 존재함. 함수 호출 방식도 색상에 따라 달라지는 문제를 기술적으로 해결했다지만, 여전히 IO가 필요한 함수에는 IO를 인자로 넘겨줘야 하고, 필요 없는 함수는 받지 않음. 결국 본질은 변하지 않은 느낌임. IO 함수는 IO 함수에서만 호출 가능하고, 이 또한 coloring 문제에서 벗어나지 못함. 물론 새로운 executor를 전달할 수도 있지만, 그게 진짜 바라는 것인지는 의문임. Rust에서도 비슷하게 할 수 있음. 색깔이 있는 함수 콜이 번거롭다는 점도 마찬가지임. 몇몇 핵심
       라이브러리 함수가 colored라는 부분은 Zig/Rust 모두 해당되지 않음. Coloring 문제의 본질은 컨텍스트(즉, async executor나 auth, allocator 등)를 필요로 하는 함수가, 호출할 때 반드시 그 컨텍스트를 제공해야 한다는 데 있음. Zig가 진짜 이 부분을 해결했다고 보긴 어려움. 다만, Zig의 추상화는 굉장히 잘 돼 있고 Rust는 이 부분이 모자란 면이 있음. 하지만 function coloring 문제 자체는 여전히 남아있음
          + 전형적인 async function coloring과의 핵심 차이는 Zig의 'Io'가 단순히 비동기 처리를 위한 특수한 값이 아니라, 파일 읽기, 슬립, 시간 받아오기 등 모든 IO를 위해 필연적으로 필요한 값임. 'Io'는 함수의 속성이 아니라 어디든 둘 수 있는 일반 값임. 실제로는, 이런 특징 덕분에 coloring 문제는 해결된 것처럼 보임. 대부분의 코드베이스에서 IO가 이미 스코프 어딘가에 있어서, 정말 순수 계산 함수만 IO가 필요 없게 됨. 만약 어떤 함수가 갑자기 IO가 필요해진다면, 대부분의 경우 'my_thing.io'에서 바로 가져와 쓸 수 있음. Rust처럼 모든 함수에 Allocator를 넘길 필요가 없어서 번거로움이 없음. 즉, 코드 경로가 바뀌어서 IO를 해야 한다면 굳이 함수마다 변경을 퍼트릴 필요 없이 바로 사용 가능함. 원론적으로는 function coloring이 남아 있다는 데 동의하지만, 사실상 모든
            함수가 async-colored가 된 셈이기에 실질적인 문제는 거의 없음. 실제로 Zig 개발자들은 Allocator를 명시적으로 넘기는 것이 function coloring 번거로움을 유발하지 않는다고 여김. 'Io'도 마찬가지로 문제가 크지 않을 거라 생각함
          + 중요한 핵심을 언급하지 않은 것 같음. Rust 라이브러리를 쓸 때는 반드시 async/await, tokio, send+sync 같은 조건을 맞춰야 하고, sync API면 async 앱에서는 무용지물이 되는 게 현실임. 반면, Zig의 IO 전달 방식은 이 문제를 근본적으로 해결함. 덕분에 고생하며 procedural macro나 멀티버전을 억지로 구현하지 않아도 되며, 사실상 이런 방식 자체가 라이브러리 멀티버전 문제를 결국 잘 해결하지도 못함. Rust에서 async/sync 혼용 문제에 관한 다양한 논의가 있는데, 다음 링크에도 설명이 있음 https://nullderef.com/blog/rust-async-sync/. 앞으로 Zig가 cooperative scheduling, 고성능 async, 스레드-퍼-코어 async 같은 부분까지 잘 풀 수 있길 바람
          + 나는 범주론 전문가는 아니지만, 결국 이런 컨텍스트 관리의 길을 걷다 보면 IO 모나드에 도달하게 됨. 이 맥락(Context)은 암시적으로 있을 수도 있지만, 컴파일러의 도움을 제대로 받으려면 시스템 내에서 실체로 드러내야 함. 그리고 시스템 프로그래밍 언어들의 야망이 다 Async나 코루틴 무덤에 묻혀왔지만, Andrew가 IO 모나드를 나름 다시 발견해서 제대로 구현한 점은 세대의 희망임. 실제 세계 함수에는 색깔이 존재함. 명확한 이동 규칙을 두거나, 아니면 C++의 co_await, tokio처럼 점점 복잡해지는 길로 빠질 수밖에 없음. 이게 바로 ‘The Way’라고 생각함
          + 모든 함수를 빨갛게(혹은 파랗게) 만드는 간단한 트릭이 있음
var io: std.Io = undefined;

pub fn main() !void {
  var impl = ...;
  io = impl.io();
}

            io를 글로벌 변수로 두고 쓰면 coloring 걱정할 필요 없어짐. 농담이지만, 확실히 'Io' 인터페이스를 써야 한다는 점에서 마찰이 조금은 있지만, 이건 async/await를 쓸 때 발생하는 실질적인 friction과는 본질적으로 다른 문제임. 내가 보기에 function coloring 문제의 핵심은, 코드 재사용이 불가능해지는 async 키워드의 정적인 색깔 부여 때문임. Zig에서는 어떤 함수를 async로 만들거나 아니거나 모두 IO를 인자로 받기 때문에 그 관점에서는 coloring 자체가 무의미함. 두 번째로, async/await를 쓰면 스택 없는 코루틴(즉, 컴파일러에서 컨트롤되는 스택 전환)을 강제로 쓰게 되지만, Zig의 새로운 IO 시스템은 내부적으로 async를 써도 Blocking IO로 동작하게 할 수 있음. 이런 점이 실질적인 function coloring 문제라고 생각함
          + Go도 “미묘한 coloring” 문제를 겪음. goroutine을 사용할 때는 항상 context 인자를 넘겨주면서 취소를 처리해야 하고, 많은 라이브러리 함수들도 context를 요구하기 때문에 전체 코드가 오염됨. 기술적으로는 context를 안 써도 되지만, context.Background로 무작위로 넘기는 건 권장되지 않는 방법임
     * sans-io라는 개념은 Rust 등에서 이미 논의된 바 있는데, 참고 링크는 https://www.firezone.dev/blog/sans-io, https://sans-io.readthedocs.io/, https://news.ycombinator.com/item?id=40872020임
          + 함수가 IO 메서드를 직접 호출하면 외부에서 IO를 분리할 수 없는 구조라 sans-io라고 부르기 어렵다는 생각임. 링크에 나온 대로, 바이트 스트림 기반 프로토콜에서는 구현부가 입력/출력 버퍼만 다루고, 네트워크에서 데이터를 받는 부분은 반드시 호출 쪽이 직접 전달해야 진정한 sans-io임. 출력 역시 버퍼에만 쓰거나, 이벤트가 발생할 때 바이트 스트림을 즉시 반환하는 방식이 있음. 반환 방식은 구현 선택이지만, 내부 버퍼는 자동 응답이 필요한 상황에 유용함. 핵심은 IO를 직접 하지 않는 구조임
     * 나는 function coloring의 문제점이, 스택에서 처리하건 스택을 unwind하건 결국 둘 중 하나가 남는다는 데 있다고 생각함. Zig가 coloring 문제 해결을 주장하지만, IO 구현 방식으로 여전히 blocking/thread pool/green thread를 사용할 수 있게 해줌. 근데 이런 blocking IO는 애초에 문제가 아니었음. 글로벌 상태를 안 쓰는 관례를 지키면 거의 모든 언어에서 이 정도는 가능함. stackless coroutine은 아직 미구현인데, ‘나머지 부품만 그리면 완성’ 같은 느낌임. 만약 진짜 보편적 함수 호출을 원한다면, 두 가지 방법이 있다고 생각함
          + 모든 함수를 async로 만들되, 인자 하나로 동기로 실행할지 여부를 넣어 처리하게 함(성능 저하 있음)
          + 각 함수를 두 번 컴파일해서 상황에 맞게 골라 호출하게 함(코드 크기 증가와 함수 포인터 처리의 어려움 있음)
               o 핵심팀은 아니지만, 사용자와 실사용자들이 semiblocking 구현을 충분히 써보고 API를 안정화한 뒤, 바로 그 해법(스택 점프 기반의 진짜 코루틴 삽입)을 적용할 계획이라고 들음. 현재 LLVM의 코루틴 상태머신 컴파일러는 libc나 malloc에 의존하는 문제가 있음. Zig의 새 io 인터페이스가 userland async/await를 지원하기 때문에, 향후에 제대로 된 frame jumping 솔루션이 들어와도 이식이 쉽고 디버깅도 편리함. 코루틴이 어려우면 io API도 소폭 수정으로 버틸 수 있게 해두고, stackless coroutine부터 너무 서두르진 않을 생각임
               o C#/.NET의 ValueTask<T>도 비슷한 역할을 함. 동기로 끝나면 오버헤드가 없고, 필요할 때만 Task<T>로 사용할 수 있음. 코드는 보통 await만 해두면 되고, 실행 시점에 런타임이나 컴파일러가 알아서 동기/비동기 선택함
     * Zig를 좋아하지만 green thread(파일버, stackful coroutine)에 집중하는 걸 보니 아쉬운 마음임. Rust도 1.0 이전에 비슷한 Runtime trait를 퍼포먼스 문제로 폐기함. 실제로 OS와 언어, 라이브러리들이 이런 접근의 폐해를 여러 번 배웠고, 관련 자료도 있음 https://www.open-std.org/JTC1/SC22/WG21/docs/papers/2018/p1364r0.pdf. 파일버가 90년대에는 확장성 있는 동시성 처리로 각광받았지만, 현대에는 stackless coroutine, OS/하드웨어 발전 등으로 권장되지 않음. 만약 계속 이대로 간다면 Zig는 Go랑 비슷한 성능에서 한계에 부딪히고, 진정한 퍼포먼스 경쟁자로는 어렵게 됨. std.fs는 퍼포먼스가 필요한 케이스에서 남아있길 바람
          + 우리가 green thread(파일버)에 ‘올인’한다는 인상은 오해임. OP 참고 기사에서 stackless coroutine 기반 구현을 기대한다는 점을 명시적으로 언급했고, 관련 제안도 있음 https://github.com/ziglang/zig/issues/23446. 퍼포먼스는 중요하고, 파일버가 성능적으로 기대 이하라면 보편적으로 쓰이지 않을 것임. 이 기사에서 논의된 내용은 stackless coroutine이 기본 ‘Io’ 구현이 되는 걸 막지 않음
          + green thread가 퍼포먼스가 나쁘다는 주장에 대해 의문임. 상위 동시성 서버 플랫폼(Go, Erlang, Java)이 모두 green thread를 쓰거나 쓰려고 함. green thread는 C FFI와의 호환 문제로 더 저수준 언어(Rust 등)에서는 적합하지 않을 수 있지만, 퍼포먼스 자체가 항상 문제라고만 보긴 힘듦
          + 여러 선택지 중 하나이기 때문에 ‘all-in’이라고 볼 수 없다고 생각함. 어떤 구현을 택할지는 실행파일에서 결정하고, 라이브러리 코드에서는 결정되지 않음
          + Rust가 green thread를 제거하고 async runtime으로 교체한 선택과 비슷한 효과를 Zig도 노리고 있음. 핵심은 ‘async=IO, IO=async’인 점을 공식화한 직관임. Rust는 tokio 등 pluggable async runtime, Zig는 pluggable IO runtime을 제공하는 쪽임. 결국 언어에서 런타임을 빼내고, 사용자 영역에서 끼울 수 있게 하면서 모두가 공통된 인터페이스를 공유하는 게 방향임
          + 자료(P1364R0)는 논쟁적이었고, 나는 특정 접근법을 없애기 위해 동기부여된 주장이라고 생각함. 논의 자료로는 https://old.reddit.com/r/cpp/…, https://old.reddit.com/r/programming/… 등도 참고 가능함
     * Zig 같은 시스템 언어에서 흔한 표준 IO 연산에까지 런타임 다형성을 강제하는 건 다소 어색하다고 느낌. 대부분의 실전에서는 IO 구현이 정적으로 확정될 수 있는데 왜 런타임 오버헤드를 강요해야 하는지 의문임
          + IO에서는 동적 디스패치 오버헤드가 실제로는 거의 미미할 거라 생각함. IO 대상에 따라 다르긴 하겠지만 결과적으로 IO가 CPU 병목이 아닌 경우가 훨씬 많음. 그래서 IO 바운드란 이름도 붙음
          + “왜 모두에게 런타임 오버헤드를 강제하나?”라는 질문에, 대부분 한 종류의 io만 쓰는 시스템에서는 컴파일러가 double indirection(간접 참조) 비용 자체를 최적화해서 없앨 의도로 보임. 그리고 IO는 어차피 bottleneck이 따로 있어서, 인디렉션 한 번 늘어나는 건 부담이 거의 없음
          + Zig의 철학상 바이너리 크기에 더 신경을 쓰는 편임. Allocator도 똑같은 트레이드오프가 있는데, 예를 들어 ArrayListUnmanaged는 allocator에 대해 generic하지 않으므로 매 할당마다 dynamic dispatch가 발생함. 실제로는 파일 할당이나 쓰기 비용이 간접 호출 오버헤드를 훨씬 압도함. 이런 바이너리 사이즈에 집착하는 게 Zig 스타일임. 참고로 devirtualization(동적 호출을 정적으로 바꾸는 최적화)은 미신임
          + 런타임 다형성 자체가 본질적으로 나쁜 것은 아님. tight loop에서 브랜치가 생긴다든지, 컴파일러가 인라인 최적화를 못한다든지 그런 상황이 아니면 문제 상황이 아님
     * 새 io 파라미터가 여기저기 드러나는 게 썩 마음에 들진 않지만, 여러 구현(thread 기반, fiber 기반 등)을 쉽게 쓸 수 있고 사용자에게 구현체를 강요하지 않는 점(Allocator 인터페이스처럼)이 아주 마음에 듦. 전체적으로 상당한 개선이고, 여러 stdlib 구현체 중 별도의 오버헤드 없는 동기/블로킹 io 구현이 제공된다면 “쓰지 않는 것에 돈을 내지 않는다”는 Zig 철학을 그대로 따르는 셈임
          + “쓰지 않는 것에 돈을 내지 않는다”가 정말 가능한가? 팀 규모가 아주 작고 엄청난 규율이 있지 않은 이상 결국 다른 누군가가 쓰게 되고, 나도 비용을 치르게 될 거임. 그리고 io를 계속 넘기는 게 필요한 곳에서 그냥 호출만 하는 것보다 더 귀찮은 것 같음
     * Zig에서는 io.async가 비동기성(작업의 순서가 보장되지 않을 수 있지만 결과는 올바름)을 표현할 뿐, 동시성(concurrency)을 나타내는 게 아님. 즉, async와 io 호출의 의미를 분리했다는 점이 핵심임. 이 설계가 아주 영리하다고 생각함
     * IO 인터페이스 덕분에 언어 차원의 vfs(Virtual File System)을 만들 수 있다는 점이 마음에 듦
          + 예시 코드를 보고 보안 관점에서 capability 기반 보안도 적용할 수 있지 않을까 생각이 들었음. 예를 들어 특정 디렉토리 하위만 읽을 수 있는 io 인스턴스를 라이브러리에 넘겨주기 등. 참고 https://news.ycombinator.com/item?id=44549430
     * 나는 Zig를 배우려 ssh 서버를 간단히 만들어봤음. 이번 IO/이벤트 루프 구조 덕분에 코드의 흐름을 한결 쉽게 이해할 수 있었음. Andy에게 감사함
          + 새로운 디자인에서 event loop/io를 더 쉽게 이해할 수 있게 된 계기가 어떤 부분인지 궁금함
     * 글이 너무 잘 쓰였고, 매우 흥미롭게 봤음. 특히 WebAssembly에서의 시사점이 기대됨. WASI를 userspace에서 쓸 수도 있고, Bring Your Own IO도 가능한 구조라니 정말 재미있다는 생각임
"
"https://news.hada.io/topic?id=21949","1980년대 중반 MacPaint 아트는 여전히 멋지게 보임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1980년대 중반 MacPaint 아트는 여전히 멋지게 보임

     * 1980년대 MacPaint로 제작된 초기 컴퓨터 예술 작품들이 현재 시점에서도 뛰어난 시각적 매력을 보임
     * 작성자는 BMUG CD-ROM과 Discmaster를 통해 18,000여 장의 MacPaint 이미지를 감상하며 인상적인 작품들을 소개함
     * 9인치 1비트 흑백 화면에서 이뤄진 창작 작업이 오늘날에도 감각적으로 보임
     * Amiga 등 동시대의 다른 컴퓨터 역시 가정용 컴퓨터 아트 발전에 기여했음을 언급함
     * Discmaster에서 다양한 로고, 그래픽, 아이콘 등 당시 스타일의 파일을 찾아볼 수 있으며, 관련 기술서적도 추천함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

MacPaint 아트의 현대적 가치

   1980년대 중반, MacPaint로 제작된 컴퓨터 아트가 지금 봐도 여전히 매력적인 시각적 완성도를 보여줌
   BMUG의 CD-ROM과 Discmaster 같은 사이트를 통해 18,000개 이상의 MacPaint 이미지를 감상하며, 독특하고 감각적인 작품들을 직접 선별하여 소개함

초기 디지털 아트의 인상

     * 9인치 흑백(1비트) 화면이라는 제한된 환경 속에서도 창의적이고 뛰어난 작품들이 다수 등장함
     * 이미지 중에는 인물, 풍경, 마켓, 행성 등 다양한 주제가 포함되어 있음
     * 당시 예술가들이 한정된 하드웨어에서 독창적인 기법을 어떻게 구현했는지 궁금증을 표함
     * 40여 년 전 MacPaint로 활동하던 작가들이 이후 어떤 디지털 창작을 했는지 추적해보고 싶은 바람을 밝힘

다른 동시대 컴퓨터의 아트 발전 가능성

     * Amiga 역시 동일 시기 가정용 컴퓨터 아트의 발전에 큰 역할을 했음을 언급함
     * Amiga 기반의 예술작품도 별도로 탐구해볼 예정임을 밝힘

아이콘 및 그래픽 요소 컬렉션

     * MacPaint로 제작된 로고, 그래픽, 아이콘 등 당시 그래픽 스타일의 파일이 다수 존재함
     * Discmaster에서 MacPaint, MacDraw, 초기 Photoshop 파일 등 다양한 옛날 스타일의 그래픽 자료 검색·감상 가능함
     * 선택한 아이콘/그래픽들은 단일 캔버스에 모아 감각적인 컬렉션을 구성함

MacPaint 아트 제작 참고 자료 안내

     * 당시 MacPaint 아트의 기법과 노하우를 담은 책 'Zen & The Art of The Macintosh'를 인터넷 아카이브에서 무료로 열람할 수 있음
     * 해당 서적은 시대별 Mac 아트의 철학, 자세한 제작 방법 등을 담고 있으며, 별도 포스팅으로도 소개할 가치가 있음

마무리

     * MacPaint 아트는 초기 디지털 창작의 한계와 가능성을 동시에 보여주는 사례임
     * 간결한 그래픽에서도 나타나는 독창적 미감은 오늘날 창작자, 개발자에게도 여전한 영감을 제공함

        Hacker News 의견

     * 오래전에 읽었던 개념 중에 ""aesthetic completeness""라는 용어가 있었음. 비디오 게임의 예술적 방향성이 완전히 실현된 경우, 하드웨어나 그래픽 성능이 좋아져도 예술적인 면에서는 더해질 게 없는 상태를 의미함. 예시로 Homeworld 초기 작품들이 거론되었음. 이 글을 보며 그 생각이 다시 떠올랐음. 당대 도구로 만든 이미지를 다른 도구로 만들면 완전히 다른 예술작품이 되어버림. 매체 자체가 예술의 일부임
          + 동굴 벽화부터 로마 시대 프레스코화까지 똑같은 논리가 적용된다고 생각함. 인간 표현의 방식임. 표현 도구가 결과를 결정지음. 예를 들어 바흐의 음악은 하프시코드라는 악기가 눌렀을 때 음이 유지되지 않는 특징에 영향을 받았음. 피아노가 나오며 지속 음이 가능해졌지만, 바흐 곡을 그런 방식으로 ""업스케일링""하면 오히려 곡이 망가짐. 새로운 도구로도 오리지널 악기에 맞게 연주해야 아름다움이 살아남
          + 과거 컴퓨터에서 조용히 이미지를 기다리는 그 긴장감과 기대감이 있었던 시절이 떠오름. 마치 연극에서 커튼이 열리길 기다리는 느낌이었음. 그래서 등장하는 아트워크가 더욱 아름답게 느껴졌음. 아티스트들도 시스템 한계에 최대한 도전하는 창의성을 보여주었고, 보는 사람도 당대 최첨단 경험에 함께 몰입하게 되었음
          + 이 개념이 정말 흥미로움. 초기에 출시된 메이저 게임들은 예술적으로 정말 훌륭하게 표현되었음. 예를 들어 Sonic the Hedgehog에서도 시각적 표현에서 한계를 느낀 적이 없음. 이후의 유사 3D 게임들도 아트 방향성이 확고해서 일관된 완성감을 줌. 최신 게임들이 고전 스타일로 돌아가도, 그래픽 해상도가 픽셀이 늘어나는 것 정도를 제외하고는 당시와 크게 달라지지 않은 느낌을 줌
          + 개인적으로 Rez라는 잘 알려지지 않은 게임이 완성도를 제대로 보여줬다고 생각함. 무려 15년 뒤에 리마스터판이 나왔지만, 해상도와 렌더링만 좋아졌을 뿐 전체 스타일은 건드려지지 않았음
          + 나는 게임 원리주의자는 아니며, 현대 게임도 충분히 좋다고 생각함. 다만 AAA 게임에서 300명의 아티스트가 게임 진행이나 재미에는 아무 영향 없는 풀잎 하나하나를 모델링하는 건 이해하지 못하겠음. 스크린샷은 멋질 수 있지만 GrassSimulator2000을 만드는 게 아니라면 그 리소스를 더 의미 있는 곳에 썼으면 좋겠음
     * 만약 사진을 활용해서 MacPaint 스타일로 그림을 그리고 싶다면 내가 만든 Retro Dither라는 프로그램이 있음. Mac App Store에서 구할 수 있는데, 사진을 MacPaint 형식으로 디더링해서 변환·내보낼 수 있음 (홈페이지). 내 새 책에 Python으로 같은 프로그램 만드는 법도 소개되어 있음. Atkinson 디더링, MacPaint 파일 포맷, MacBinary도 설명함. 무료 코드와 변환법은 여기에서 구할 수 있음. 책은 여기에서 볼 수 있음
     * 해당 작품들은 전통 드로잉을 배운 아티스트가 그린 것 같음. 크로스 해칭, 점묘, 명암값, 원근법 등 기본기를 완벽하게 이해한 게 느껴짐. 그래서 지금 봐도 멋진 것임. 이런 기본기는 그 시대 디지털 미디어의 성능과는 별개임
          + 예를 들어 이 작품을 보면 정말 놀라움 (이미지 링크). 멀리서 보면 거의 실사같은 거리 풍경인데, 확대해서 보면 무의미해 보이는 흑백 패턴들뿐임. 마치 마법같음
     * 정말 멋짐. Amiga의 Deluxe Paint로 만든 훌륭한 아트워크도 많이 볼 수 있음. 초창기 컴퓨터의 해상도와, 특히 팔레트 제약이 독특한 스타일을 만들었음 (Deluxe Paint 예시)
          + 최근에 NEC PC-98 관련해서도 비슷한 감상의 글이 올라왔었음 (관련 링크)
          + Deluxe Paint 작품들은 약간 별로인 것 같기도 함. 매체 자체(예를 들어 더 선명한 색감, 특정 웹사이트 느낌) 때문인지, 아니면 내가 작품 구성을 덜 좋아해서인지는 모르겠음
          + 컬러 사이클링으로 애니메이션 같은 효과를 만드는 게 정말 대단함
          + Deluxe Paint로 그린 작품의 제작 과정을 다룬 이 동영상이 정말 재미있었음 (유튜브 링크)
          + 더 좋은 작품 몇 가지는 여기에서 볼 수 있음
     * 우리 친구 Pinot의 놀라운 MacPaint 픽셀 아트가 소개에 포함되지 않은 게 정말 아쉬움. 아직도 활발하게 새로운 작품을 만들고 있음 (작품 예시)
     * 작은 세상에서 컴퓨터 제품과 회사에 대해 순수한 열정을 가졌던 사람들이 부럽게 느껴짐. 대부분의 사람들이 서로에게 좋은 영향을 주고 싶어 했던 시절임
     * ""디자인은 제약의 예술""이라는 Charles Eames의 말을 인용하고 싶음. 오리지널 Mac과 MacPaint의 한계가 그 시대, 그 장소만의 독특한 예술 양식을 만들어 냄
     * 비슷하게 어떤 동굴 벽화는 지금 보아도 멋진 작품임 (라스코 동굴벽화)
          + 빈정거리는 말은 빼고, 기사 내용을 보며 느낀 점은 ""당연히 멋지지 않을 이유가 무엇인가""였음. 만들어질 때 이미 뛰어난 작품이었음. 모나리자도 그렇듯, 도구가 작품의 품질을 결정하지는 않음. 제약만을 규정함. 이 흑백 픽셀아트들은 매체에 딱 맞는 훌륭한 그림임
          + 예전에 읽었던 내용 중에 동굴 벽화들은 특정 조명 조건, 즉 어둡고 깜빡이는 불빛 아래에서 그려졌고 감상되도록 만들어졌다는 설명이 있었음. 그렇게 보면 그림의 표현력이 훨씬 살아난다고 함. 사실 이런 조명 하에서 만들어지고 보였던 예술은 1800년대 중반 전까지 인류의 모든 작품에 해당함. 예술, 건축 모두 햇빛이나 그에 따른 그림자, 혹은 불빛의 변화와 함께 감상되었음
     * 이 글이 이렇게까지 인기를 끌 줄은 예상 못 했음. 비에 오는 날 두 번째 글을 위해 아껴 두었던 이미지들을 추가했으니, 페이지를 다시 로드해서 새로운 1비트 픽셀 아트도 구경하길 추천함
     * 나는 83년생이고 성장기의 많은 시절을 디더링된 픽셀을 통해 세상을 상상하며 보냈음. 게임도 하고, 작품도 만들고, 글도 쓰고, 모험도 했음. 이런 이미지들은 단순히 ""디더링""만으로도 강한 향수를 불러일으킴
"
"https://news.hada.io/topic?id=21932","팀 35명, 5천만 사용자, 연매출 5천만 달러","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       팀 35명, 5천만 사용자, 연매출 5천만 달러

  📌 Gamma의 성장 전략 (요약)

     * 직원 수: 단 35명으로 운영
     * 사용자 수: 전 세계 5천만 명 이상 확보
     * 매출: 연매출(ARR) 5천만 달러(약 650억 원) 달성
     * 투자 효율성: 총 2,300만 달러 투자로 15개월 연속 흑자 유지
     * 주요 전략:
          + Van Westendorp 모델로 최적 가격 설정
          + AI를 활용한 최소 인력의 제품 중심(Product-Led Growth) 확장
          + 직원당 매출(Revenue per employee) 중심의 효율성 극대화
     * 경험: Gamma에서 Notion의 성장 전략을 응용하여 성공적인 GTM 전략 수립
"
"https://news.hada.io/topic?id=21843","내성적인 사람의 네트워킹 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            내성적인 사람의 네트워킹 방법

     * 내성적인 사람은 네트워킹에서 주목받지 못하거나 연결이 약한 느낌을 자주 경험함
     * 효과적인 네트워킹을 위해 이벤트 전 준비와 개인화된 시스템이 중요함
     * 첫 인상과 비언어적 신호는 관계 시작에서 핵심적 역할을 가짐
     * 대화에서는 상대의 이야기를 경청하고, 소소한 정보를 기억하는 태도가 신뢰 형성에 도움됨
     * 이별 순간과 사후 피드백이 관계를 실질적으로 강화함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

왜 이 글을 쓰는가

     * 내성적인 사람들은 전문 행사나 파티에서 자신이 존재감을 드러내지 못한 것에 대해 의구심을 가지는 경험을 자주 함
     * 사회성이 부족한 게 아니라 자신에게 맞는 네트워킹 시스템이 없어서 어려움을 느낀다는 점을 강조함
     * 이 글은 내성적인 사람이나 비슷한 성향을 가진 이들을 위한 체크리스트와 가이드로 작성되었음

이벤트 전: 불확실성 줄이기

     * 불안감을 줄이기 위해 사전 준비가 매우 중요함
     * 식사는 미리 해결하는 것이 집중력 유지에 도움됨
     * 외적으로 눈길을 끌 수 있는 소품(“Whatzit”)을 준비하여 대화의 계기를 만듦
     * 최신 뉴스를 잠깐만이라도 확인하여 기본적인 대화 준비를 함
     * ‘Six-Point Party Checklist’를 통해 행사 목적, 참석자, 위치, 분위기, 귀가 방법 등을 사전 정리함

입장 순간: 신호 조절

     * 첫 5초가 타인의 인상 형성에 결정적 역할을 함
     * 문에서 잠깐 멈춰 자신감 있게 둘러보는 동작이 신뢰를 줌
     * 몸을 열고, 손목을 보이며, 좋은 자세로 접근함
     * 미소는 눈맞춤 후 천천히, ‘지연된 따뜻함’으로 보임

오프닝: 소통의 시작법

     * 대화의 시작은 말보다는 톤, 자세, 에너지에서 더 큰 영향을 받음
     * “주로 어떻게 시간 보내세요?”처럼 직업을 넘는 질문이 상대를 더 여유롭게 함
     * 상대가 중요하게 생각하는 키워드를 경청하고, 이를 반복해줌(“Solar hardware?” 등)
     * 대화가 이어질 수 있도록 침묵을 두고 공감의 신호를 줌

대화 중간: 정보를 기억하고 활용

     * 상대가 언급한 작은 정보들(예: 반려견 이름, 이사 온 도시 등)을 메모리로 관리함
     * 그룹 안에서는 상대의 이야기를 다른 사람에게 소개하여 중심을 옮겨줌
     * 대화가 막히면 마지막 말을 ‘앵무새처럼’ 반복하는 방법(“Chaotic lately?”)으로 자연스럽게 흐름을 이어감

행사 주최자와의 교류

     * 주최자에게는 두루뭉술하게 “좋은 파티네요” 대신 구체적 칭찬(예: 조명이 참 좋아요) 을 전함
     * 소소한 도움(예: 얼음 채우기, 접시 옮기기 등)으로 자연스럽게 존재감 확보

이별의 순간: 기억에 남는 작별 인사

     * 슬쩍 사라지지 않고 의도된 작별 인사를 전함
     * 흔하지 않은 형용사(“remarkable”, “thoughtful” 등)로 인사하여 차별화된 인상을 남김
     * 24시간 이내에 관련 링크, 대화와 연결된 이미지, 기억에 남는 키워드를 사후 메시지로 전달

관계 유지 전략

     * 만남 후 이야기, 키워드, 상대의 아이디어를 기록하여 향후 진정성 있는 관계로 발전
     * 3주 후 다시 연락해 상대를 기억하고 있음·관심을 가지는 태도를 보여줌

마무리

     * 네트워킹의 본질은 방문, 경청, 자신감 있는 태도, 진짜 순간을 남기는 것임
     * ‘방 전체를 사로잡아야 한다’는 부담감 대신, 한두 번의 진실된 연결로도 충분함을 강조함

        Hacker News 의견

     * 이 글은 내성적인 사람을 위한 게 아니라 사회적 불안을 가진 사람을 겨냥한 내용임을 지적하고 싶음. 내향적인 사람들은 네트워킹을 싫어하는 게 아니라 단지 이후에 휴식이 필요하다는 차이점이 있음을 강조하고 싶음. 처방된 각종 행동 체크리스트들은 걱정을 더하게 만드는 방식이라 오히려 역효과라는 생각임. 경험적으로 네트워킹을 잘하는 최고의 방법은 ""잘하려고 집착하는 마음을 끊는 것""이라는 믿음임
          + 최근에 불안(anxiety)과 두려움(dread)의 차이에 대한 개념을 접함. 불안은 주로 가능성이 낮은 최악의 시나리오를 두려워하는 감정임. 그냥 행동을 해보면 몸이 그 활동이 괜찮다는 걸 학습하며 불안이 줄어듦. 그러나 두려움은 전혀 다름. 두려움은 실제로 안 좋은 상황이 예상되는 심리임. 반복 노출이 오히려 두려움을 심화시키는 특징이 있음. 특히 신경다양성이 있는 경우, 감각 과부하 때문에 두려움이 발생하고, 이런 환경에 계속 노출되어도 나아지지 않음. 사회에서 불안에 대한 언어는 널리 퍼져 있지만 두려움에 대한 개념은 적게 다루어져 아쉬움. 나에게 이 구분을 배운 게 큰 허락이 되었고, 내 경험 대부분은 불안보단 환경 자체에 대한 두려움이었음을 깨달음
          + 이 가이드는 네트워킹에 관한 안내서가 아니라 네트워킹 이벤트 참가에 관한 안내서인 점을 강조하고 싶음. 둘은 전혀 다름. 네트워킹이 끝나고 2주 뒤에 사람들이 대부분 서로를 잊을 때 뭘 해야 하는지에 대한 가이드가 있었으면 좋겠다는 바람이 있음
          + 아버지가 자동차 딜러십을 운영하셨고, 항상 ""타고난 영업사원""이 있었다는 얘기임. 아버지는 그런 재능파는 아니어서 체계적으로 행동과 습관을 연습해서 관계를 맺고, 반복 고객에게 수년 혹은 수십 년 뒤에도 팔았다며, 네트워킹도 누군가에겐 자연스러운 일이지만 대부분은 연습이 필요하다는 점을 강조함. 두려운 상황을 단순한 몇 가지 작은 행동으로 치환하는 기법의 유용성을 이야기함. 산악자전거 지도 경험을 예로 작은 동작들이 신체와 정신을 풀어주고 실질적 돌파구가 됨을 비유함. YOLO 스타일의 접근이 아니라 작은 행동의 반복이 근본적으로 불안을 다룬다는 메시지를 공유함
          + ""신경 안 쓰기""는 ""그냥 본연의 나로 있으라"" 혹은 ""쿨하게 해라"" 같은 조언과 비슷한데, 혼란만 가중시키기 때문에 엉뚱한 곳에 쓸 만한 팁은 아니라는 입장임. 네트워킹은 단순한 '좋은 분위기' 이상, 명백한 기술이기 때문에 사회적 불안이 있는 사람들에게는 스크립트나 플랜 같은 가이드가 오히려 자동 조종모드로 이동하게 도와 실질적 도움이 됨을 이야기하고 싶음. 내향적인 사람은 보통 낯선 이와의 집단 활동 자체를 싫어할 수 있다는 점도 강조함
          + 피아노 경력 30년차의 입장에서, 연주 실력보다 어떻게 보일지 걱정하는 게 전혀 생산적이지 않다는 데 진심으로 공감함. 스스로 '신경을 꺼버리기' 실천 후에 훨씬 나아졌으며, 실수해도 스스로 인정하고 웃어넘기는 순간 모두에게 더 편해졌음. ""신경 쓰지 마세요""란 조언이 처음엔 무책임해 보여도 진짜 자신이 그럴 수 있다는 걸 깨달으면 엄청난 힘이 됨을 실감함
     * 이런 글은 항상 ""도대체 왜 네트워킹을 해야 하냐?"", ""아무와도 엮이고 싶지 않다"", ""교류에서 전혀 즐거움이나 성취감을 못 느끼는데 왜 해야 하나"", ""이걸 한 번도 즐기지 못했고 항상 가면을 써야 해서 화도 나고 억울하다"" 같은 사람을 소외시키는 경향이 있는 것 같음. 네트워킹의 진짜 목적, 동료 및 사회적 친분이 왜 중요한지, 사회적 연결이 약해질 때 생기는 실질적 손실, 그리고 이 문제가 왜 심각한지에 대한 설명도 필요하다고 느낌. 이런 글은 차라리 정신건강이나 신경다양성 관점에서도 다뤄야 한다고 생각함. 글 속 ""다들 내가 여기 있었더라도 기억이나 할까?"" 문장이 있는데, 나는 이런 생각을 해본 적도 없음. 본질적으로 사람이나 관계 자체를 갈구하지 않는 타입임
          + 이런 상황은 내겐 고문이나 다름없음. 인생이 그렇게 단조로울 필요 없어서 오히려 뭘 하든 이런 거 대신 하고 싶음
          + 일상에서 회사 출근만으로도 모든 사회적 기운이 소진되는 입장에선, '성공하려면 더 사회화해야 한다'는 전제 자체가 엄청 우울하게 느껴짐. 이미 힘든데 일을 위한 또 다른 소모성 이벤트에 참여하라니 자본주의의 농간이라는 자조감도 듬. 지적으로 누군가와 사회적으로 관계를 쌓을 수 있다는 논리는 이해하지만, 이미 번아웃된 상태인 내향적 인간에게 '네트워킹 하라', '이상한 기법 써라'는 조언은 농담으로밖에 안 느껴짐
     * 이 글이 이런 상황에 처음 진입하는 사람에게 좋은 가이드라는 생각임. 많은 사람이 잘 정의된 미션에 더 쉽게 접근하는 경향이 있어 실질적인 팁도 제시하고 싶음. 많은 사람들이 이벤트에선 무언가를 얻으려고 오지만, 오히려 상대에게 도움을 줄 수 있는 방법을 찾으면 긍정적 경험이 쉽게 생김. 예를 들어 책을 빌려주겠다고 제안하거나 유용한 링크, 지인 연결 등 아주 소소한 데서부터 시작 가능함. 물리적인 것을 제안했다면 끝까지 챙기고, 진짜 연결을 만드는 게 중요하다고 봄. ""약속을 반드시 지키기""와 ""진정성을 담아 조금 더 신경 쓰기""가 포인트임. 추상적이고 두려운 네트워킹 이벤트를 ""하나의 잘 정의된 미션""으로 전환해주면 두려움 해소, 가치 부여, 기여 등 여러 장점이 생김
     * “시간을 어떻게 보내는지”를 대화 시작 질문으로 삼으라는 조언이 있는데, SF(실리콘밸리) 사람에겐 정말 낯선 방식임. 예를 들면 그리스에서는 “어느 도시 출신이세요?”가 흔한 오프닝이지만, SF에서는 “어느 회사에서 일하세요?”가 일반적인 오프닝 질문임
          + SF는 다양한 곳에서 온 사람들 집합이라 “어느 도시 출신인가요?” 묻는 게 전혀 현실적으로 의미가 없음. 반대로 그리스처럼 모두가 현지인인 환경에선 익숙한 방식임
          + ""어느 도시에서 왔어요?""라는 질문은 여러 빅테크 기업의 포용성 교육에선 편견 유발 소지가 있다고 하여 부적절하다고 가르침
     * 내게 잘 맞았던 팁 하나를 추가하고 싶음. 처음엔 진입이 매우 어렵지만, 반복되거나 비슷한 이벤트를 찾아 여러 번 참석하길 추천함. 시간이 흐를수록 몇몇 아는 사람을 만나게 되고, 이전 대화를 기억해 두면 관계가 쌓임. 상대도 나를 기억할 확률이 높아짐. 단, 늘 아는 사람과만 어울리는 함정엔 빠지지 말고, 매번 새로운 인연을 최소 두 명 정도 만들어 보길 권장함
          + 반복 이벤트의 진가 지적에 공감함. 어린 시절 친구 사귀기도 우연한 반복적 접촉이 핵심이었음. 같은 공간에서 여러 번 다양한 사람과 서로 기분 좋게 대화한 경험이 쌓일수록 자연히 관계가 깊어짐. 그리고 익숙한 사람들이 많아지면 대화 주체를 바꾸거나 ""여기 저 사람 소개해줄게"" 하고 빠져나오기도 훨씬 부드러움. 1:1에서 어색하게 도망쳐야 할 필요도 줄어듦
          + 명함 뒷면에 이전 만남의 특징을 메모해 두었다가 다음에 만나면 공통 화제거리로 연결에 도움 준다는 팁을 책에서 본 기억이 있음을 공유함
     * 자신감과 진심 어린 관심은 타고난다는 의견임. 인류는 타인의 제스처와 행동을 파악하는 데 진화적으로 특화되어 있기에, 얄팍한 네트워킹 시도는 금방 티가 남. 유일한 방법은 실제 대화하며 어색함과 실패를 반복, 타인에 진짜로 관심 갖는 법을 익히면서, 내 삶과 일에 대해 이야기로 가치를 더하는 경험임
          + 흉내낼 순 없어도 <i>연습</i>은 얼마든지 가능하단 의견임. 처음엔 어색하겠지만 시도하다 보면 진짜로 스킬이 늘고 결국 자연스러워짐
     * 그냥 파티 가서 사람들과 어울리라는 주장을 하고 싶음. 그 사람의 진짜 모습을 실제로 궁금해하고, 어떤 생각을 하는지, 시간을 어떻게 보내는지에 초점을 맞추면 사람은 누구나 흥미롭게 느껴짐. 이런 조언이나 책들은 별 의미 없다고 생각함. 나는 매우 내향적이라 몇 주간 혼자 자연에 있어도 잘 지내고, 파티는 너무 자극적임. 하지만 그냥 부딪혀보는 게 중요하다고 느낌. 말실수해도 자책하지 말고, 과거 상황을 곱씹지 말고, 사람들의 삶에 무슨 일이 일어나고 있는지 가볍게 즐겨보는 태도면 충분함
     * 네트워킹 아이스 브레이킹 팁으로 “안녕하세요, 제 이름은 ${이름}입니다, 만나서 반가워요! 제가 좋아하는 아이스브레이커 질문 중 하나는 ${질문}인데, 어떻게 생각하세요?”라고 메타적으로 대화 시작하는 방식이 있음. 상대가 미소 짓고 자연스럽게 자기 질문도 공유하며, 형식적이지 않고 가볍게 분위기를 풀기에 좋았던 경험임
          + 본인이 직접 변수 활용한 공식으로 설명했다는 점에서 오히려 너무 형식적이고 억지로 준비한 느낌이 있음. 나쁘진 않지만, 꽤 연습한 티가 나며 살짝 유치한 인상임. (어설픈 농담에도 모두가 미소 짓는 것과 같음)
"
"https://news.hada.io/topic?id=21914","Flopper Ziro – DIY 오픈소스 Flipper Zero 클론","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Flopper Ziro – DIY 오픈소스 Flipper Zero 클론

     * Flopper Ziro는 유명한 해킹 툴인 Flipper Zero를 직접 제작 가능한 최저가 오픈소스 버전으로 제공하는 프로젝트
     * Arduino IDE 기반으로 제작되어 엔지니어라면 누구나 손쉽게 수정 및 확장할 수 있음
     * RFID/NFC, 적외선(IR), 무선주파수(RF) 신호 읽기와 에뮬레이션, RubberDucky 등 다양한 해킹 기능을 지원함
     * 3D 프린터 쉘, TF 카드 저장, 배터리 관리 등 실용 기능들이 추가되어 있음
     * 완전한 상용 대체품은 아니며, 비상업적·학습·DIY 목적에 특화된 프로젝트
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 개요

     * Flopper Ziro는 오리지널 Flipper Zero와 유사하지만 최대한 저렴하고 DIY 및 오픈소스로 누구나 제작 가능한 클론임
     * Arduino IDE에서 바로 개발 및 프로그램이 가능함
     * 이 프로젝트는 오락성과 교육 목적의 비영리적 시도임
     * 상업 또는 전문 기기 대체 목적이 아님

하드웨어 구성

     * STM32-L432KC 마이크로컨트롤러
     * FS1000a 라디오 주파수 송신기
     * RXB12 라디오 주파수 수신기
     * PN532 RFID/NFC 모듈
          + PN7150 사용도 예정됨
     * 적외선 LED & 수신기
     * 2N222A PBFREE 트랜지스터
     * SSD1306 OLED 디스플레이 (128x64)
     * TF 카드 메모리 쉴드
     * TP4056 배터리 충전 부품
     * DC-DC 5V BOOST 전원 변환기
     * 6x6x8mm 푸시 버튼 6개
     * Micro USB SMD
     * 3.7V Li-Po 배터리

주요 특징

     * RubberDucky 키 입력 자동화 기능 지원
     * RFID/NFC: 작업 진행중, UID 읽기 및 다양한 형식 지원 예정
     * 적외선(IR) : 신호 읽기, 에뮬레이션, 저장 가능
     * 무선주파수(RF) : 신호 읽기, 에뮬레이션, 저장 가능
     * SD카드 저장/불러오기 지원
     * 배터리 잔량 및 SD 용량 표시
     * 모든 기능은 Arduino IDE로 프로그래밍 가능함
     * 3D 프린터 케이스 (참조 모델: https://www.printables.com/model/1142768-flopper-ziro-shell), 아직 완성 전임

소프트웨어 및 하드웨어 개발 현황

  소프트웨어 To Do

     * SD/SSD1306 연동 문제 해결, SD 메뉴 및 파일 관리 기능 완료
     * RF 스캐너 및 송신 기능 완성
     * 메뉴 시스템 구성 및 BadUSB, IR 기능 구현, IR 데이터 표시 오류 해결
     * RFID 진행 상황: UID 읽기 완성, ISO14443B 읽기, 에뮬레이션, RFID 저장 기능 남음

  하드웨어 To Do

     * 1차 PCB 완성
     * 신규 PCB 버전 개발 예정
     * PN7150 모듈 테스트 예정

  문서화

     * 문서화 작업 예정

결론

     * Flopper Ziro는 Flipper Zero와 유사하며, 아두이노 호환성·** 최저가 BOM**·** 핵심 해킹 기능** 중심으로 구현됨
     * 교육, DIY, 입문자 학습, 개선된 확장성에 중점을 둔 오픈소스 프로젝트임
     * 커뮤니티와 기여자 중심의 발전 가능성을 지니는 프로젝트임

   YCD로도 나오면 좋겠어요~

   원본 가격은 22만원이 넘던데 구매자들이 어떤 곳에 쓰고 다닐지 궁금하군요.....

        Hacker News 의견

     * LilyGo T-Embed CC1100은 FlipperZero와 비슷한 하드웨어 성능을 제공하면서도 WiFi/Bluetooth까지 지원하고, Bruce Pentest firmware를 사용할 수 있음으로써 가격도 Flipper의 절반 이하라는 장점이 있음 Bruce firmware는 잘 동작하지만 완성도는 Flipper만큼 높지 않음 그러나 하드웨어와 소프트웨어 모두 오픈소스라 개조가 쉬움
          + IoT 기기가 Arduino나 Raspberry Pi처럼 인기 있고 유용한 이유는 사실 하드웨어 성능 때문이 아니라, 방대한 사용자 커뮤니티 덕분임 많은 사람들이 쓰면 쓸수록 호환 소프트웨어, 하드웨어, 가이드 등 을 쉽게 찾을 수 있음 Flipper Zero 역시 이러한 효과를 크게 누리고 있다고 생각함
          + Kiisu라는 제품도 있고, 이것도 FlipperZero와 거의 동일한 성능에 추가 기능까지 있음
          + 내가 이 프로젝트를 시작했을 때는 이러한 대안 제품들이 존재하지 않았음
     * Capibara Zero처럼 언급된 다른 대안 제품과 비교할 때도 과연 Flipper Zero만큼의 소프트웨어 지원을 받을 수 있을지 궁금함 Flipper Zero가 꾸준히 인기를 얻는 핵심 요인이 바로 강력한 커뮤니티라고 생각함
          + Flipper는 정말 방대한 커뮤니티가 지원하고 있음 Flipper에 직접 관여하는 사람들까지 합치면 정말 대단함 이 경우는, 소프트웨어 지원 수준이 아예 비교도 안 될 정도로 차이가 큼
          + 이 문제는 Raspberry Pi와 다른 (값도 싸고 성능도 좋은) 싱글보드 컴퓨터들 간의 상황과 완전히 동일함
          + 해당 펌웨어 저장소는 2025년 4월 12일에 아카이브됨 다시 활성화되거나 기능 경쟁력이 생길 일은 없을 것이라 생각함
     * 이번 Defcon 기간 중에 Las Vegas의 호텔들이 이런 기기들을 보면서 어떻게 반응할지 궁금함
     * 처음 봤을 때 가장 큰 차이점이 RF 기능임 이 제품은 거의 433MHz 리플레이 어택에 특화된 수준임 OOK 변조일 때만 임의 데이터를 만들 수 있을 것이라 추정함 특정 용도에는 괜찮을 수 있지만 너무 과한 기대는 금물임 아주 기본적인 기능에 집중된 제품임
          + ""중요공지: 이건 단순히 시간을 보내려고 시작한 재미 프로젝트임 전문가용 기기 대체용이 아님 전혀 전문적이지 않음""
          + 리플레이 어택만 가능한 것이라는 걸 알고 있음 지금은 그게 내가 원하는 전부였고, 앞으로의 확장은 천천히 고민할 생각임
     * RF 신호를 읽어 저장하거나 에뮬레이션 하는 방식이라면, 사용자가 해당 주파수에서 송신할 수 있는 면허 요건을 갖췄는지도 확인하는지 궁금함
          + 사용자들이 각자 자기 나라의 법을 알아서 지킬 것으로 가정하는 게 맞지 않을까 생각함 여긴 뭔가를 판매하는 게 아니니까, 결과적으로 만든 사람보다는 공유받는 사람 책임이라고 생각함
     * 혹시 Tamagotchi처럼 보이도록 만든 것인지 궁금함
          + 1버전에서는 Tamagotchi처럼 보이게 추가했었음 아마 초기 커밋에서 확인 가능할 것임 하지만 내가 사용하는 마이크로컨트롤러와의 문제로 현재는 기능을 제거한 상태임
     * 요즘 스마트폰이 하나의 케이스 안에서 이런 장치를 전원 공급해줄 수 있을지 궁금함 Flipper를 좋아하지만 부피가 크고 충전해야 해서 불편함
          + 가능함 소비전력도 크지 않음 하지만 하드웨어 자체 부피는 여전히 큼
     * NFC 지원이 곧 추가될 예정이라 정말 기대하는 중임
     * PCB 설계가 묘하게 느껴짐 여러 개발 보드를 커다란 PCB에 납땜한 것 같은데, 이렇게까지 해야 하는 특별한 이유가 있는지 궁금함
          + 나도 똑같이 했던 경험이 있음 몇 가지 이유가 있음 1) 특정 부품은 레이아웃이 정말 중요함 예를 들어 DC-DC 컨버터가 있는데, 루프 면적을 줄이고, 칩에 맞는 풋프린트를 써야 할 때 이미 완성된 모듈을 써서 간단하게 할 수 있음 2) 필요한 부품이 줄어듦 DC-DC 컨버터에 맞는 인덕터, 수많은 저항, 커패시터 등 부품을 일일이 소량 구매하는 대신, 완성 모듈을 구입하면 됨 3) 납땜이 쉬워짐 핀이 없는 패키지 같은 어려운 칩이나 민감한 LED, 핀 간격이 좁은 IC 등은 납땜이 까다로운데, 모듈을 쓰면 이런 고민이 사라짐
          + 동일한 방법을 써봐서 얘기할 수 있는데, 완전히 커스텀 보드를 디자인하는 것보다 훨씬 빠르고, 쉽고, 심지어 더 저렴할 때도 있음 완전 커스텀 보드는 에러가 많고, 부품을 소량으로 직접 조달하는 게 오히려 비용 부담이 커지는 경우가 많음 좋은 엔지니어링은 비용(금전적, 비금전적) 최적화를 포함함 소규모로 제작하는 취미·원오프 프로젝트는 모듈 활용이 훌륭한 엔지니어링임
          + 화가에게 왜 직접 물감을 제조하지 않고 시판 물감을 쓰냐고 묻는 것과 비슷한 수준의 질문임 모두가 PCB 11차 버전의 트레이스 에러를 고치느라 시간과 돈을 쓰는 취미가 있는 것은 아님 만들어진 도구를 바로 쓰는 게 더 나은 선택임
          + PCB 레이아웃이 훨씬 쉬워지고, 서로 다른 보드 개정 간에도 부품을 대부분 재사용할 수 있음 작업이 끝난 후 부품들도 재활용 가능함 덕분에 전자쓰레기도 줄어드는 효과가 있음
          + 왜 안 되겠나 싶음 기성 보드를 긁어 모아 PCB에 바로 얹는 게 DIY에 훨씬 적합함 완전한 커스텀 보드는 이미 DIY의 범위를 넘어서는 일임
     * 이름이 아주 마음에 듦
          + 고마움 내가 상상력이 풍부한 편임
"
"https://news.hada.io/topic?id=21833","타워 디펜스 게임을 AI로 코딩하고 전체 프로세스를 문서화했어요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  타워 디펜스 게임을 AI로 코딩하고 전체 프로세스를 문서화했어요

     * 20년차 소프트웨어 개발자지만, 게임 개발은 처음으로 AI 코딩 에이전트를 활용해 Phaser.js 기반 타워 디펜스 게임 ""Tower of Time"" 을 완성
     * AI의 실제 게임 개발 가능성을 실험하는 것이 목표였으며, 코드와 모든 AI 프롬프트 및 작업 과정을 GitHub에 문서화
     * 코드의 95% 이상이 AI에 의해 작성되었으며, Augment Code, Cursor, Claude Sonnet 4 등 다양한 AI 툴을 연계해 사용함
     * 게임은 시간 되감기(리와인드) 기능을 활용한 전략성과 다양한 타워, 에너지 관리 시스템, 웨이브별 적 등장 등 독특한 재미를 제공
     * 실시간 스트리밍, 아트 및 사운드 에셋 활용, 개발 과정에서 얻은 교훈과 실전 팁 등 게임/AI 초보자 모두에게 학습 자료로 유용함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Tower of Time 개요

     * 본 프로젝트는 AI 코딩 도구로 실질적인 게임 개발이 가능한지 실험하는 것을 목표로 진행
     * Phaser.js라는 Javascript 게임 엔진을 처음 익혀서 Beginner's Jam Summer 2025에 참가, 25~30시간 동안 'Tower of Time'을 완성함
     * 개발 전 과정과 모든 프롬프트, 코드, 문서, 플레이 링크를 GitHub에 기록함

게임 소개

     * Tower of Time은 시간 여행 테마의 타워 디펜스 게임으로, 플레이어가 웨이브 형태로 몰려오는 적을 막아내며, 위기 상황에서 시간을 되감아 전략을 재설계할 수 있음
     * 여러 종류의 타워(기본, 스나이퍼, 슬로우다운, 스플래시 등)와 에너지 시스템(타워 건설·시간 되감기에 사용)이 결합되어 있음
     * 주요 특징
          + 시간 되감기: 불리한 순간, 이전 상태로 되돌아가서 방어 전략 재정비 가능
          + 다양한 타워: 각기 다른 특성의 타워 배치로 다양한 방어 전략 수립 가능
          + 에너지 관리: 에너지 사용처를 신중히 고민해야 하는 자원 운용 요소
     * 조작 방법
          + 키보드/게임패드 지원 (이동: 방향키/스틱, 액션: 스페이스/게임패드 버튼, 되감기: 백스페이스/트리거)

AI 코딩 실험 및 개발 과정

     * 전체 코드의 약 95%를 AI(Claude Sonnet 4, OpenAI, Augment Code, Cursor 등)로 작성
     * 모든 주요 프롬프트, 시행착오, 최종 결과물을 저장소에 PROMPTS.md로 기록
     * AI 코드 자동생성의 장점: 빠른 프로토타이핑, 반복적인 코드 작업의 자동화, 문서화 용이성
     * 한계와 주의점: AI가 코드를 과하게 생성하는 경향, 특정 구현 이슈 발생 시 프롬프트 재설계·롤백 필요, 디버깅 로그 활용 권장

개발에서 얻은 교훈

     * AI 코딩만으로도 재미있는 게임 완성이 충분히 가능
     * 프롬프트 품질, 명확한 맥락 제공, 디버깅 전략이 매우 중요
     * 코드 양을 불필요하게 늘리지 않도록 지속적으로 점검 필요

기술 스택

     * 엔진: Phaser 3 (v3.90.0) + Phaser Editor v4
     * 언어: TypeScript
     * 빌드 도구: Vite
     * 아트 에셋: itch.io, 일부 직접 보정
     * 사운드: freesound.org

   브라우저에서 플레이 해보기 : Tower of Time

   좋은 레퍼런스가 될 거 같네요

   저도 열심히 ai를 부려서 웹게임을 만들고 있죠.

        Hacker News 의견

     * 개발에 사용된 프롬프트 를 하나하나 읽어보는 재미가 쏠쏠함
       ""vibe coding 성공 사례""에 관한 글들은, 마치 다수의 에이전트와 복잡한 코드 오케스트레이션, LLM으로 생성된 룰만 갖추면 “시간을 되감는 타워 디펜스 게임을 만들고 결함도 버그도 없게”라는 프롬프트 한 줄로 게임이 뚝딱 만들어진다는 식의 환상을 주는 경우가 많음
       하지만, 실제 프로젝트에 사용된 프롬프트들은 AI 코딩에 가장 잘 먹히는 방식과 일치함
       명확하고 꼼꼼한 아이디어를 수백 개의 작은 문제로 쪼개고, 정말 중요한 부분에는 구체적인 아키텍처적 가이드를 주는 방식이 효과적임
          + 기술 리드와 프로덕트 오너 역할을 병행하는 입장에서, 이 방식이 인간과 일할 때도 정석임
            내 일의 70%는 임원의 “타임 트래블 타워 게임, 버그 없이”라는 추상적 요구를, 팀이 높은 추상화를 유지하면서 서로 겹치지 않게 작업할 수 있도록, 강력한 아키텍처 비전이 맥락에 담긴 일련의 프롬프트로 바꾸는 일임
          + 간단한 Just One 보드게임용 HTML 게임 만들기에 도전했는데, 입력창이 움직이는 버그를 네 개의 LLM에 계속 프롬프트 줘도 못 잡음
            다들 게임을 한 번에 구현한다는데 나는 텍스트박스 움직임조차 못 고치는 상황이라 신기함
          + “보안 결함 없음, 버그 없음” 프롬프트에 이어 “환각(hallucination) 없음”도 꼭 필요함
            AI 초보용 기본 조건임
          + AI 코딩에서 잘 통하는 내 방식은, 기본 기능이나 게임플레이 뼈대를 AI로 ‘원샷’으로 만든 뒤, 그 위에 여러 번 반복적으로 쌓아가는 것임
            원샷 결과가 바로 인상적이지 않으면, 바로 다른 프롬프트로 보완해서 괜찮은 결과가 나올 때까지 재시도해 기반을 마련함
          + 이런 방식에 전적으로 동의함
            실제로 내 최근 포스트도 이 개념에 기반함
            코딩 전 AI로 스펙을 먼저 쓰게 하면, 사람이 처음부터 스펙을 쓰는 부담이 줄어 실제로 작성할 확률이 훨씬 올라감
     * 20년 이상 소프트웨어 업계에 있으면서, 우리 동료들 대부분은 AI 코딩에 회의적인 사람이 많다는 점을 느낌
       최근엔 34,000줄 정도 되는 큰 앱을 AI로 주로 개발해봤는데, 이때 효율은 내가 주는 지시의 질, 상호작용 구조, 출력 결과에 신경 쓰는 정도(코스 보정 포함)에 따라 기하급수적으로 올라감
       “결국 다른 모든 도구와 똑같음!”이라는 생각이 들 정도
       그런데 이 도구는 지금까지 만난 어떤 “10x 도구”와 비교해도 진짜 10배 더 레버리지가 큼
       대부분의 회의론자가 놓치는 부분은, 이런 툴들을 완전히 외부적인 존재로 취급하면 안 된다는 점임
       목표를 불분명하게 설명하고 일임하려 하면 낭패를 보게 됨
       언젠가 AI가 우리의 생각을 바로 읽을 날도 오겠지만 지금은 아님
       현재로는 생각을 명확히 정리하고, 새로운 것을 배우고, 귀찮은 부분을 빠르게 처리하는 데서 진가를 발휘함
       최대 레버리지를 위해서는 이 도구를 내 사고 과정 안에 잘 녹여야 함
          + 프로그래밍 경력은 길지만 게임은 고등학교 때 Hunt the Wumpus밖에 해본 적 없다가, 최근 AI의 도움으로 새 게임을 만들기 시작함
            AI는 크게 세 가지 역할을 함
            (1) 학습 도구 - 내가 용어를 몰라도 질문 의도를 잘 파악해서 시작점을 잡아주고, ‘내가 몰랐던 사실’까지 알려주기에 제일 중요한 역할임
            (2) 반복적이거나 지루한 일 처리 - 코드 주석, 설정 파일 작성 등은 내가 할 수도 있지만 속도를 늦추는 일들을 무난하게 처리함
            (3) 검색 - (1)번처럼 실제로 내가 원하는 게 뭔지 AI가 파악해 필터링이나 추천 등을 맡김
            AI에게 “생각”을 맡길 수도 있지만 그럴 필요는 없음
            인간보다 똑똑하지 않고 단지 더 빠르고 더 많은 걸 아는 FPU 같은 존재임
          + HN 기준으로는 꽤 회의적인 편이지만, 실제로는 회사에서 AI 도입을 계속 밀어붙이고 있고 지금도 Claude에게 뭔가를 시키면서 이 글을 쓰고 있음
            회의론의 이유는 현재 AI 솔루션이 “팔리고 있는 모습”과 “실제 하는 일” 사이의 간극 때문임
            모든 AI 솔루션, 특히 에이전트는 숙련된 사람의 가이드 없이는 쓸모 없는 결과만 냄
            실제로 “자율적”인 요소는 거의 없음
            ‘vibe coding’이라는 용어를 만든 사람조차, 업계가 순서를 거꾸로 밟고 있다고 얘기함
            이런 툴이 환상적이긴 하지만 반드시 강하게 통제해야 한다는 점을 빼놓는 건 사실상 거짓말임
          + 최근 몇 달간 내 생각 역시 비슷한 결론에 도달함
            예전에는 AI에 대해 비판적인 코멘트를 남겼지만, 최신 도구들은 확실히 많이 발전함
            예전에는 몇 주씩 걸리던 일을 이젠 몇 시간 만에 뚝딱할 수 있음
            단, 프롬프트를 잘 생각해서 세세하게 쪼개야 하고 IDE와도 잘 연동해야 함
            가장 혁신적인 부분은 완전히 새로운 라이브러리나 프레임워크를 다룰 때임
            예전엔 사용법을 검색해서 예제 코드를 뜯어고치곤 했는데, AI가 훨씬 더 직관적이고 다양한 방법을 알려줘 종종 놀라는 경우가 많음
            아직 회의적인 사람도 한 번 다시 써볼 시기임
          + 10x 레버리지에 대한 예시로, 언어를 들 수 있음
            예전에는 Lisp 등이 더 많은 일을 더 빠르게 해준다고 했는데, 이제는 실제로 작성해야 할 코드는 줄이면서도 결과물은 빠르고 고성능 언어로 생성할 수 있음
            단, 생성된 코드 중 쉽게 검증되지 않는 부분을 충분히 검토해야 한다는 ‘덫’이 있음
            고도 표현력을 가진 언어 덕분에 사전 플랜 없는 사람들이 난장판 코드베이스를 양산하기도 했던 것처럼, AI 도구로도 이런 일이 반복될 항목
            하지만 내가 진짜 시간 절약하는 부분은, 완전히 새 코드를 짜는 것보다 옛 코드와 신 코드를 통합하거나 개선할 때임
            디버깅에서 큰 도약이 일어남
            예전처럼 print만 찍지 않고, 코드를 복사해 붙여넣기만 해도 “출력이 이렇지 않고 저렇다는 데 왜 그렇냐?”고 AI에게 물어 빠르게 원인과 대안을 얻을 수 있음
            특히 SQL, IaC, 빌드 스크립트 등 디버거 붙이기 어려운 작업에서 이런 방식이 엄청나게 큰 장점임
          + 또 하나, 학습 곡선과 난이도 상한이 생각보다 훨씬 높음
            Claude Opus를 복잡한 자동화 프레임워크로 쓸 때와, 브라우저에서 GPT-4o에 복사/붙여넣기만 하는 경우 결과 차이가 큼
     * 개발 과정을 투명하게 공개하고 프롬프트까지 공유한 점이 멋져서 GitHub에서 star 표시함
     * 코드와 결과물 모두 아름답게 느껴짐
       분명 AI만 쓴 게 아니라 직접 참여한 부분도 많았을 것임
       나는 코딩을 오래 쉬었다가, 친구들의 권유로 AI를 활용한 간단한 코드를 만들어봄
       완성한 건 Bubble Wrap 터트리기와 소음기(버튼 누르면 사운드 없음) 정도임
       Bubble Popper
       Silencer
          + 안드로이드의 크롬에서 실행했는데, 버블이 제대로 터지지 않고 카운트도 0에서 안 오름
            PR 받을 계획이 있는지 궁금함
     * 인디게임이야말로 코딩 AI의 훌륭한 사용 사례로 보임
       적은 위험성과 재미 위주의 성격이 딱 맞음
       첫 커밋에는 코드가 대량 포함되어 있으나, PROMPTS.md는 아직 없음
       예를 들어 EnergySystem.ts가 첫 커밋에서 이미 존재하는데, 뒤늦게 PROMPTS.md에선 AI가 처음부터 만든 것처럼 보임
       레포지토리 히스토리에서 이 부분을 더 자세히 설명해줄 수 있는지 궁금함
       첫 커밋 링크
          + 이번 프로젝트가 게임잼 출품작이라 1주일 마감에 맞춰 처음 2~3일은 소스컨트롤을 쓰지 않아 그 기간 작업을 한 번에 큰 커밋으로 남기게 되었음
            프롬프트도 바로바로 적지 않고 게임 완성 후 사용했던 채팅 도구 이력을 뒤져 PROMPTS.md 파일에 복사함
            프로젝트 생성 과정을 보고 싶으면 프롬프트 파일을 처음부터 끝까지 읽는 게 가장 좋은 방법임
            예를 들어 EnergySystem.ts 파일은 적 경로 찾기, 생성, 타워 사격 등 구현이 끝나고 “에너지 서브시스템을 구현하고 싶다”는 프롬프트로 AI가 완전히 새로 만든 부분임
     * Augment Code란 도구는 처음 들어봄
       무슨 일을 하고 왜 골랐는지, 경쟁 도구와 차이점이나 실제 사용 경험 등 추천하는지도 궁금함
          + 이 질문에 더해서, OP가 Cursor에서 Augment Code를 썼는지, 이 조합이 어떻게 동작하며 어떤 이점이 있는지도 듣고 싶음
            둘 다 유료로 결제했는지 궁금함
     * 프롬프트를 기록한 점이 인상적이고 동기 부여가 됨
       내 경험상 ‘vibe coding’은 빠르게 진도가 나가기도, 한없이 느려지기도 함
       간결하고 명확한 지시, 빠른 코드 리뷰, 아키텍처 파악 능력이 있다면 진짜 개발 속도를 올릴 수 있음
     * 나도 한때 타워 디펜스 게임을 만들었고, 최근 AI를 활용해 새 웨이브 생성이나 밸런스 튜닝까지 적용해볼 생각이 있었음
       게임을 AI가 ‘체감’할 수 있게 하려면, 화면에 보이는 게임 상태를 토큰으로 바꿔 인코딩하는 프로토콜이 필요하지 않을까 생각됨
       지형과 게임 엔티티 위치, 그 외 플레이어가 볼 수 있는 속성 등
       전체를 오토인코더에 넣는 건 별로겠지만, 게임 요소별 리스트 토큰화라면 가능성 있음
       게임 엔진에서 화면 이미지를 제공하고, 토큰을 AI에 직접 풀어주면 AI는 실제 게임 진행 상황을 더 깊게 이해할 수 있음
       이러한 토큰을 제대로 활용하려면 어느 정도 학습셋이 필요할지 확실치 않지만, 현재 임베딩 공간으로도 몇 개 토큰 안에 표현이 가능할지도 모름
       게임 로그와 사용자 재미 평가를 모은 훈련셋만 있다면 흥미로운 데이터도 많이 나올 듯
       플레이어 취향 클러스터를 찾아 다양한 유형별 게임을 만드는 것도 가능해질 것임
     * 이런 워크플로우 공유해줘서 고마움
       나도 LLM 활용 워크플로에 추적성과 투명성 도입을 고민하고 있음
       프롬프트를 공유·이력으로 남기면 개발자가 처음 풀고자 했던 본질적 문제, 그리고 그게 어떻게 변화하고 새로운 이슈가 생겨났는지까지 한눈에 볼 수 있는 장점이 큼
       쿨한 프로젝트임
       책임감 있는 LLM 활용 관련 포스트
     * 20년 넘게 테크 쪽에 있으면서, 최근 Gemini-cli로 엔터프라이즈 앱 통합테스트 도구를 게임화하며 다양한 실험 중임
       MCP 서버와 조합해 보니, 문제를 단계별로 쪼개고 프롬프트에 명확함을 더해줄 때 가장 좋은 결과가 나옴
       AI가 실수하거나 루프에 빠질 수도 있는데(특히 앱 라우팅 같은 곳에서) 이럴 때 적극적으로 ‘페어 프로그래밍’하는 자세로 접근하는 게 유익함
       또 한 가지 주목한 점은 코드 중복 금지 같은 원칙을 이전보다 훨씬 쉽게 지킬 수 있다는 것임
       아니면 AI가 어느 한 부분만 바꾸고, 연관 파일은 놓치는 상황이 나오기 쉬움
       프로그래밍 로직뿐 아니라 UX, 앱 동작에도 똑같이 적용되는 진리임
       AI와 함께라면 예전엔 몇 주 씩 걸릴 작업도 이제는 몇 시간 만에 즐겁게 끝낼 수 있음
       Gemini에 개성을 부여하고, GEMINI.md 파일을 여러 기기에서 그대로 가져다 튜닝할 수 있다는 점이 아주 큰 장점임
"
"https://news.hada.io/topic?id=21834","SVGO - Node.js 기반 SVG 최적화 도구 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   SVGO - Node.js 기반 SVG 최적화 도구 오픈소스

     * SVG 벡터 파일의 불필요한 정보를 자동으로 제거하는 Node.js 기반 라이브러리이자 CLI 툴
     * 벡터 에디터에서 저장된 SVG 파일에 포함된 메타데이터, 주석, 숨김 요소, 기본값 등 렌더링에 영향 없는 부분을 삭제/변환하여 파일 용량을 줄임
     * 명령어/스크립트/라이브러리 등 다양한 방식으로 사용 가능
          + 단일 파일 처리: svgo one.svg two.svg -o one.min.svg two.min.svg
          + 폴더 전체 재귀 처리: svgo -rf path/to/directory_with_svgs -o path/to/output_directory
     * 플러그인 구조로 동작하고, 직접 플러그인을 추가하거나 세부 동작을 커스터마이즈 가능함
          + 33개의 플러그인이 preset-default에 포함되어 있으며, 순서대로 동작함
          + removeDoctype, cleanupAttrs, inlineStyles, removeUselessStrokeAndFill, convertPathData, mergePaths 등으로 직관적인 이름이 붙어 있음
          + svgo.config.mjs 설정파일을 통해 다수의 플러그인을 활성화/비활성화하고 동작 방식을 세밀하게 제어할 수 있음
     * 오픈소스이므로 Node.js 프로젝트에 내장하거나 자동화 파이프라인 등에서 자유롭게 활용 가능
"
"https://news.hada.io/topic?id=21939","OpenAI의 Windsurf 인수 무산, Windsurf CEO는 Google로 이직","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            OpenAI의 Windsurf 인수 무산, Windsurf CEO는 Google로 이직

     * OpenAI의 Windsurf 인수 계약이 취소됨
     * Google은 Windsurf의 CEO Varun Mohan과 공동창업자 Douglas Chen 및 일부 R&D 인력을 Google DeepMind 팀에 영입함
     * 영입된 인력은 Gemini 프로젝트 및 agentic coding 분야에 집중할 예정임
     * Google은 Windsurf의 일부 기술에 대해 비독점 라이선스만 보유하며 회사 지분 또는 통제권은 없음
     * Windsurf는 새로운 임원 체제로 전환하여 독립적으로 운영을 이어갈 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

주요 소식 요약

     * OpenAI가 Windsurf 인수를 철회하였음
     * Google은 Windsurf의 CEO Varun Mohan, 공동창업자 Douglas Chen, 그리고 일부 연구개발 인력을 Google DeepMind로 영입할 것임
     * 합류하는 인력들은 Google DeepMind에서 agentic coding 프로젝트와 Gemini 모델에 주력할 예정임
     * Google은 Windsurf의 기술 가운데 일부에 대해 비독점적인 라이선스만 확보하였으며, 회사 지분이나 통제권은 전혀 가져오지 않음
     * Windsurf는 즉시 사업 책임자 Jeff Wang이 임시 CEO, 글로벌 세일즈 부사장 Graham Moreno가 새 대표로 임명되어 독자적으로 운영을 지속할 계획임

Windsurf 인수 무산 배경 및 인력 이동

     * OpenAI와 Windsurf 간에 진행되던 인수 협상이 최종 결렬됨
     * 그에 따라 Google은 Windsurf 핵심 인력 일부를 자사 DeepMind 팀에 영입하게 됨
     * OpenAI의 Windsurf 인수는 원래 30억 달러 규모로 보도되었음
     * Google은 팀 영입 금액을 공개하지 않았음

Google DeepMind에서의 역할

     * Varun Mohan, Douglas Chen 등 Windsurf 인력들은 Google DeepMind의 agentic coding 프로젝트에 전념할 예정임
     * 구체적으로는 Gemini 모델 개발과 관련된 역할을 수행하게 됨
     * Google은 Windsurf의 일부 기술에 대해 비독점 라이선스 계약만을 맺고, 회사의 지분이나 경영권은 전혀 보유하지 않게 됨

조직 변화 및 향후 계획

     * Windsurf는 사업 책임자 Jeff Wang이 임시 CEO, 글로벌 세일즈 부사장 Graham Moreno가 신임 사장으로 즉각 임명됨
     * 회사는 독립적으로 다음 성장 단계를 추진할 예정임
     * Windsurf의 기존 인력 및 개발자들은 자사 기술을 계속 발전시킬 계획임

주요 관계자 코멘트

     * Google 대변인 Chris Pappas는 ""Gemini는 현재 최고의 모델 중 하나이며, 개발자를 위한 기능 고도화에 지속 투자 중""이라고 밝힘
     * Mohan과 Chen은 ""지난 4년 동안 Windsurf가 이뤄낸 성과에 자부심을 느끼며, Google DeepMind에서 새로운 기회를 추진하게 되어 기쁨""이라고 언급함

        Hacker News 의견

     * https://www.theverge.com/openai/705999/google-windsurf-ceo-openai"">아카이브된 기사 공유함
     * Microsoft의 IP 이슈를 제외하면, 이번 인수 계획이 시작된 이후 가장 크게 바뀐 것은 Claude Code의 엄청난 성장임을 느낌
       전체 IDE를 포크하는 데 드는 비용과 노력이 낭비처럼 느껴지며, CLI 기반 에이전트 도구가 무료/오픈소스로 넘쳐남
       현재 상황을 보면, 터미널 CLI 에이전트가 IDE 전체 포크보다 개발비가 훨씬 저렴함
       CC는 온보딩이 매우 쉽고, 내가 쓰던 IDE 그대로 간단한 확장만 설치하면 됨
       Anthropic은 구독 기반 예측 가능한 매출과 학습 데이터를 위해 스스로의 API 마진까지 아낌없이 깎을 수 있음(Curosr 같은 중간플레이어 포함)
       Cursor나 Windsurf가 VS Code + CC 조합보다 나은 점은 탭완성 모델(유일한 진입장벽)과, “선택영역을 채팅에 추가”와 같은 UI 개선 정도임
       Cursor가 $9억 ARR까지 가장 빠르게 성장했지만, 가장 먼저 매출이 급감할 전망임을 느낌
          + 나 역시 이 밸류에이션을 이해하지 못했음
            많은 사람들이 오픈소스 에이전트 플러그인을 개인 시간에 만들었고, 성능도 거의 대등함
            참고로 magenta nvim도 확인해 볼 것을 추천함, 나름 괜찮게 완성됨
          + 모두 동의함
            Anthropic이 CC를 엄청난 손실에도 불구하고(약 500% 적자) 제공할 뿐만 아니라, sonnet/opus 4 접근도 windsurf에 제한시켰고, Cursor의 엔터프라이즈 가격도 크게 올림
            이 가격 인상 때문에 Cursor가 요금제를 대폭 다운그레이드해야 했음
            앞으로 2년 안에 온디바이스 혹은 오픈소스 모델이 이제야 따라잡는다면 Cursor 같은 UX 래퍼가 살아남을 수 있다고 봄
            모델이 모두 범용화되면 UX 경쟁이 치열해질 전망이나, 당분간 Claude가 월등히 좋다면 Anthropic이 결정권을 쥐게 됨
            게다가 OpenAI처럼 내분을 겪을 가능성도 적음
          + $9억 ARR 수치가 신뢰할 만한지 의문임
            기본요금이 $20/월이니, 375만 명의 사용자가 구독해야 성립
            모든 사용자가 $200/월을 낸다고 해도 37만 5천 명임
            VS Code + VS 사용자가 5천만 명인데(2025년 5월 기준) 그 중 7%가 Cursor로 넘어갔다는 건 주변 개발자 집단과 맞지 않음
            다른 AI 구독 옵션도 많은 것을 감안하면 이 수치는 너무 과장됨
            출처: VS Code 5천만 사용자 달성
          + Cursor도 시장 변화를 인지하고 웹/모바일로 이동 중임
            Anthropic, Google, OpenAI가 자체 모델을 개발·배포하는 능력에서 이미 우위에 있음
            Cursor도 한때 토큰 비용 때문에 50줄 단위로만 코드를 읽던 시절이 있었으나, Anthropic은 자금력으로 컨텍스트 윈도우를 대폭 확장하며 경쟁을 압도함
            Cursor가 내일이라도 cli를 내놓을 수 있지만, Anthropic과 Google이 항상 더 저렴하게 제공할 수 있기 때문에 경쟁이 힘들 것임
            참고: Cursor agent web 공식 발표
          + 좋은 지적임
            “선택영역을 채팅에 추가” UI도 사실 Claude Code VS Code 확장이 이미 자동으로 구현함
            실제로 Cursor나 Windsurf를 써 본 사용자 중 Claude Code와 둘 다 써본 분이 있다면 왜 IDE 포크형 툴을 더 선호하는지 궁금함
            나는 Claude Code만 경험해봐서 직접 비교를 못했음, 놓치고 있는 기능이 무엇일지 궁금함
     * 이 상황은 Character.ai 때와 유사함
       창업자나 연구자가 아니면 직원들은 돈도 새 직장도 못 얻고, 회사에 들인 시간만 날리게 됨
       AI 스타트업에서 평사원으로 일한다는 게 얼마나 힘든 시기인지 다시 느끼게 됨
       창업자들은 이런 상황을 어떻게 자기합리화하고 있을지 궁금함
       Character.ai CEO, Google 복귀 이야기 참고
       (추가) @jonny_eh의 설명에 감사함. 남은 입장에서 고통스럽겠지만 할당분을 모두 소진하고 나왔다면 차라리 다행인 셈임
       그래도 창업자와 연구자는 큰 돈과 함께 구글 RSU까지 받게 된 점은 씁쓸함
          + Character.ai 남은 직원들도 손해보지는 않았음
            거래가 체결될 때 옵션이 현금화되어 직원들에게 지급됨
            Windsurf 직원들도 좋은 대우를 받길 바람
            캐릭터에서 최근까지 근무했음
          + 평사원 주식 보상의 근본이 빠르게 무너지는 중임
          + 참고로 캐릭터 인수 당시 그냥 떠나는 것이 아니었고, 많은 직원이 GDM에 흡수되었음
            소스: 인수 당시 GDM에 있었음
          + 이 상황이 테크 VC 스타트업 종말의 서막이 아닐지 우려됨
            고금리로 VC 자금조달이 비싸지고, 빅테크가 핵심 인력만 모셔가서 투자자들은 제대로 된 엑싯도 못 하는 상황임
            이쯤 되면 더 이상 의미가 없는 것 같음
          + 정확히는, 인수하는 회사(예: Google)가 windsurf 직원들의 지분 일부를 매수하는 방식임
            (추가) 내 댓글을 다운보트하는 분들은 제대로 읽지 않은 것 같음, jonny_eh와 똑같은 포인트를 말한 것임
     * Cursor(그리고 Garry Tan의 X글)는 벤처투자금으로 이 회사들의 엄청난 성장을 뒷받침했음을 보여줌
       이들이 수익을 내는 유일한 방법은 요청당 단가를 꾸준히 올리는 것이며, 이를 위해 점점 빠른 혁신만이 돌파구
       진입장벽도 거의 없음
       GitHub은 copilot도 오픈소스로 공개했고, 오픈소스 커뮤니티도 열심히 자체 프로젝트를 내놓는 중임
       Cursor의 빠른 혁신은 돋보이지만, 경쟁사들이 얇은 래퍼만 만든다면 수십억 달러 가치가 정당화되기 힘듦
       이 영역의 변화 속도가 너무 빨라 지켜보는 게 즐거움
          + 진입장벽이 전혀 없음
            강력한 에이전트가 곧 등장할 것이라 진심으로 믿는다면, 이 모든 애드온 회사들이 몇 년 안에 쓸모 없어질 것임
            최초로 강력한 에이전트를 내놓는 회사는 Cursor나 Windsurf를 손쉽게 다시 만들 수 있음
          + Cursor가 소비자 기만을 저지른 수준이고, 최소한 최고 고객들을 분노하게 만들었음
            $90억 가치에 투자한 이들이 불쌍하게 느껴짐
          + Garry의 글이 무엇이었는지 궁금함
          + Grok 출시와 xAI가 비교적 늦게 합류했음을 보면, 거대 모델 학습의 유일한 진입장벽은 얼마나 많은 GPU를 살 수 있냐인 듯 느껴짐
            ChatGPT가 지각변동을 일으켰지만 2년도 안 되어 여러 강력한 경쟁자가 등장함
            이 모델들을 수익화하는 건 경쟁과 과도한 기대 탓에 매우 어려워 보임
            Google과 중국 기업이 이 경쟁에서 살아남을 것이라 예상함
     * Windsurf를 쓰는 사람을 한 번도 본 적 없음
       이런 AI 스타트업 인수들이 믿기 어려울 정도임(부정적인 의미로)
       WIX가 엉성한 Lovable.dev 클론을 8천만 달러에 인수한 것도 어이없음
       결국 이 버블이 터지길 많은 이들이 기다리는 중임(경제 자체가 터질 것이란 전망도 있음)
          + Windsurf는 Cursor보다 약간 나았지만 인수 발표 후 Anthropic에 밀려 제대로 된 유저를 잃었음
            실상 Claude Sonnet이 최고임
            디자인으로는 chat 패널과 자동완성 통합이 Cursor보다 약간 나았지만 큰 차이는 없음
            Windsurf 구독료가 Cursor보다도 5달러 저렴함
          + 나는 Windsurf를 실제로 씀
            GitHub Copilot의 대안으로 꽤 괜찮음
            무료 플랜도 Copilot 유료와 맞먹는 수준임
            하지만 이제는 아무도 이 얘기를 하지 않음. 네 말이 맞는 듯함
          + Base44는 절대 허접하지 않음
            직접 경험해 보니 Lovable이나 Bolt보다 분위기 창출(vibe-builder) 면에서 더 좋음
            직접 경쟁사와 벤치마킹한 결과나 근거가 있는지 궁금함
            참고로 Windsurf를 쓰는 뛰어난 개발자를 실제로 알고 있음
     * AI 스타트업의 인수 구조는 Google이나 C-level 경영진에게 유리하지만, 직원들에게는 끔찍함
       이런 가짜 인수는 사실상 직원들을 대상으로 하는 차익거래에 불과하며, 결국 아무것도 남지 않음
       법적으로 금지 및 규제되어야 한다고 생각함
       VC들은 어떤 방식으로 수익을 챙기는지 의문이나, Google이 해당 VC 포트폴리오의 다른 스타트업 투자에 참여함으로써 균형을 맞추는 듯함
     * Google, Meta, Microsoft가 반독점 소송을 피하기 위해 AI 스타트업 지분 인수 대신 핵심 인재 스카웃에 집중하는 것 같음
       전략적으로 뻔하지만 효과적인 시도임
          + 실제로 더 저렴함
            기존 주주들에게 돈을 안 줘도 됨
          + 주주들이 소송을 제기할 수 있을지 궁금함
            지식재산권 소송밖에 방법이 없나 싶음
            혹은 비독점 라이선스가 그마저도 막는 걸까
            참혹하게 느껴짐
          + 나는 경영진이 왜 회사를 떠나고, 저임금에 미래를 걸었던 직원을 두고 가버리는지 진심으로 놀라움
            분명히 더 숨겨진 사정이 있을 수도 있다고 생각함
          + AI 스타트업은 많고, 우린 이제 막 활용법을 배우기 시작했을 뿐임
            네가 언급한 대기업 중 한 곳이 AI를 완전히 새로운 방식으로 잘 활용하는 기업이 될 수도 있고, 언젠가 Yahoo와 AOL처럼 밀릴 수도 있음
            미래를 지켜봐야 함
          + 소프트웨어 개발자들과 함께 이 방식이 제대로 잘 작동하고 있음
     * 지금의 이 AI 인재 쟁탈전을 다큐로 만든다면, 향후 AI의 성장세가 꺾이고 밸류에이션이 증발할 때 정말 흥미로울 것임
          + AI 기술력이 꺾이는 중인지, 아니면 범용화되는 중인지 궁금함
            새로운 Windsurf(최초 버전) 같은 걸 만드는 게 더 이상 특별하지 않게 됨
          + David Fincher가 이 이야기에 무척 흥분해할 듯함
          + 외부에 있는 입장에서 이런 흐름을 명확히 짚어내기란 어렵다고 생각함
          + 누군가는 2019~2022년 사이의 크립토 광풍을 모르고 지나친 것 같음
          + Gary Marcus가 팝콘 먹는 짤(gif)이 떠오름
     * Claude에 발이 묶인 순간, 결국 AI 에이전트 도구의 경쟁력은 쓰는 모델의 성능에 달려 있다는 것을 모두가 자각했음
       고정 진입장벽이 거의 없음
       JetBrains가 24년째 IDE를 만들고도 기업가치가 70억 달러 평가임을 감안하면, 이번 인수딜은 처음부터 무리였던 셈임
     * 오늘 이 상황이 참 묘하게 느껴짐
       나는 빅테크가 아닌 회사의 한 명의 개발자인데, 이번 주에 LinkedIn에서 연결한 Windsurf 영업 담당자가 내 번호도 안 줬는데 갑자기 연락해 옴
       우리 회사가 Windsurf와 라이선스 딜을 논의 중이라며, 내가 직접 써보도록 30일 무료 엔터프라이즈 계정을 개인 프로젝트에 제공해주겠다고 함
       아마 사내 개발자들 사이에서 호응을 만들어내는 게 영업 전략인 듯한데, 이런 방식이 일반적인지 궁금함
       나는 그냥 엔지니어라 너무 공격적인 마케팅처럼 느껴졌음, 큰 그림은 잘 모르겠음
"
"https://news.hada.io/topic?id=21890","AI-네이티브 소프트웨어 엔지니어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           AI-네이티브 소프트웨어 엔지니어

     * AI-Native 엔지니어는 AI를 일상 업무의 파트너로 삼아 생산성과 창의력을 극대화하는 개발자
     * AI를 대체재가 아닌 협력자로 바라보고, 반복적 작업을 AI에게 위임해 더 높은 수준의 문제 해결과 혁신에 집중함
     * 프롬프트 엔지니어링 등 새로운 스킬을 익혀 AI를 효과적으로 활용하며, 항상 결과를 직접 검증함
     * IDE 확장, 코드 생성, 테스트, 문서화, 운영까지 개발 전체 주기에서 AI를 적극 활용하는 습관을 기름
     * 책임감·윤리·팀 협업·지속적 학습을 강조하며, AI 활용 문화 정착이 개인과 조직 경쟁력의 핵심임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# AI-네이티브 소프트웨어 엔지니어란

     * AI-네이티브 소프트웨어 엔지니어는 AI를 일상적인 업무 흐름에 깊이 통합하여 자신의 역량을 증폭시키는 파트너로 AI를 활용하는 개발자임
     * 기존의 “AI가 나를 대체할까?”라는 사고방식이 아니라, 모든 작업에서 “AI가 이 일을 더 빠르게, 더 잘, 혹은 색다르게 할 수 있도록 도와줄 수 있을까?” 라는 질문을 습관화함

     * 생산성과 창의력을 배가시키는 도구로 AI를 바라보는 낙관적이고 적극적인 마인드셋을 유지함
     * 올바른 접근법을 적용하면, AI가 개발자의 아웃풋을 2배, 5배, 심지어 10배까지 끌어올릴 수 있음
     * 특히 경험 많은 개발자일수록 컨텍스트 엔지니어링 등 고급 프롬프트 기법을 통해 AI에서 동료 수준의 답변을 이끌어냄

     * AI-네이티브란 지속적 학습과 적응을 수용하는 태도이며, 처음부터 AI 기반의 보조와 자동화가 내재된 방식으로 소프트웨어를 구축함
     * 이러한 마인드셋은 두려움이 아닌 새로운 가능성에 대한 흥분과 기대로 이어짐
     * 새로운 도구와 방식에 불확실함과 러닝커브가 있을 수 있으나, 결국에는 기회와 성장에 대한 기대로 귀결됨
     * AI-네이티브 엔지니어는 반복적이고 시간이 많이 드는 개발의 일부(보일러플레이트 코드, 문서 초안, 테스트 생성 등)를 AI에게 위임하고, 본인은 더 높은 수준의 문제 해결과 혁신에 집중함

  [핵심 원칙] – AI는 대체재가 아닌 협력자임

     * AI-네이티브 엔지니어는 AI를 24시간 이용 가능한 지식 많은(하지만 주니어 수준의) 페어 프로그래머로 대함

     * 개발의 주도권은 항상 인간이 가지되, 아이디어, 해결책, 경고 등 다양한 영역에서 AI의 도움을 적극적으로 활용
     * 예: 아키텍처 접근법을 AI에게 브레인스토밍 시키고, 이를 본인의 경험과 전문성으로 정교화함. 이러한 협업은 개발 속도를 비약적으로 높이고 품질도 향상시킬 수 있음(단, 반드시 개발자가 감독을 유지해야 함)

     * 중요한 점은 책임을 AI에게 전가하지 않는 것임. AI는 StackOverflow와 API 문서를 전부 읽은 주니어 개발자처럼 많은 정보를 제공하지만, 최종적으로 안내하고 결과를 검증하는 책임은 개발자에게 있음
     * 이러한 “신뢰하되 검증하라(trust, but verify)” 원칙이 필수적임

     * 솔직히 말해, AI가 생성한 코드 품질 저하(low-quality work)는 현실이며, 결코 변명의 이유가 될 수 없음
     * AI 도구의 지속적 리스크는 자동 승인, 은근한 환각, 단순한 게으름이 합쳐져 전문적 엔지니어 기준에 한참 못 미치는 결과를 낳을 수 있다는 점임
     * 따라서 검증 단계는 절대 생략할 수 없는 핵심이며, 개발자는 AI 도구의 단순 사용자가 아니라 최종 보증자로서 코드의 품질, 가독성, 보안, 정확성 전체에 완전한 책임을 가짐

  [핵심 원칙] – 이제 모든 개발자는 매니저임

     * 엔지니어의 역할이 근본적으로 변화하고 있음. AI 에이전트와 함께 일하면서, 직접 구현하는 대신 업무를 ‘오케스트레이션’ 하는 역할로 진화 중

     * main 브랜치에 들어가는 커밋마다 여전히 개발자가 최종 책임을 지지만, 실제 작업의 정의·분배에 더 많은 시간을 할애하게 됨
     * 가까운 미래에는 “모든 개발자는 매니저”(Every engineer is a manager now) 라는 말이 일반화될 수 있음
     * 실제 작업은 Jules, Codex 같은 백그라운드 에이전트나 Claude Code, Gemini CLI, OpenCode 등에게 할당 가능함
     * 엔지니어는 AI가 더 잘 일할 수 있도록 코드베이스를 적극적으로 ‘조율’(예: GEMINI.md 같은 규칙 파일, 잘 된 README, 구조화된 코드)하는 역할을 맡음
     * 이로써 개발자는 슈퍼바이저, 멘토, 검증자 의 역할을 수행
     * AI-퍼스트 팀은 더 소수로도 더 많은 결과를 내고, SDLC 단계(compressing steps of the SDLC)를 단축하며, 더 빠르고(faster) 더 나은 품질을 실현

  고-수준 혜택(High-Level Benefits)

     * AI를 워크플로우에 완전히 통합하면 생산성이 비약적으로 향상, 더 많은 기능을 더 빠르게, 품질 저하 없이 출시 가능(물론 과제 복잡도에 따라 다름)

     * 코드 포매팅, 유닛 테스트 생성 등 반복적인 작업이 몇 초 만에 처리
     * AI는 이해도까지 보강: 평소 익숙하지 않은 영역도 전문가에게 즉시 조언 받는 것처럼 도움
     * AI-네이티브 엔지니어는 더 야심찬 프로젝트를 소규모 팀으로 감당할 수 있고, 결국 “AI가 인간의 역량을 확장” 하게 됨
     * 단, 효과적으로 활용하려면 올바른 마인드셋과 실천 방법이 필요

  예 – 마인드셋 실전 적용

     * 예를 들어 어려운 버그를 디버깅하거나 새로운 기술 스택을 평가할 때, 전통적 접근은 검색/문서 탐독이 필요했음
     * AI-네이티브 방식은 검색 기반/깊이 있는 리서치를 지원하는 AI 어시스턴트와 협업: 버그를 설명하거나 스택 장단점을 질문하면 AI가 인사이트나 코드 예시까지 제공
     * 개발자는 해석·적용의 최종 결정권을 유지하며, AI는 정보 수집과 해결책 제시를 가속화
     * 이처럼 협업적 문제 해결이 익숙해지면, “이 업무에 AI가 어떻게 도움이 될까?” 를 습관적으로 질문하게 되고, 시간이 지날수록 AI의 강점·적합한 프롬프트를 직관적으로 파악하게 됨

  정리

     * AI-네이티브란 문제 해결과 소프트웨어 구축의 핵심에 AI를 내재화하는 마인드셋을 의미
     * 기계(속도, 지식, 패턴 인식)와 인간(창의, 판단, 맥락)의 장점을 결합하는 파트너십적 사고가 핵심
     * 이 기반 위에서, 일상 개발에 AI를 실질적으로 통합하는 실천이 이어짐

# Getting Started – 일상 업무에 AI 통합하기

     * AI-네이티브 워크플로우는 처음엔 부담스럽게 느껴질 수 있지만, 작은 것부터 시작해서 점진적으로 AI 활용 역량을 키워가는 것이 핵심임
     * 아래는 엔지니어링 일상에 AI를 자연스럽게 도입하기 위한 실질적 가이드

     참고: 미래에는 소프트웨어 라이프사이클 전반에서 AI의 역할이 커지겠지만, 품질 유지를 위해 인간의 개입(human-in-the-loop) 이 반드시 필요하다는 점은 변하지 않음.

  Step 1: 첫 변화? AI로 시작하기

     * AI-네이티브 워크플로우는 “AI로 할 수 있는 일이 있나?”를 가끔 찾는 게 아니라, 아예 처음부터 작업을 AI에 맡겨보고 시작하는 것을 의미함
     * 한 팀의 경험: ""대부분의 업무는 AI 모델(Cursor, CLI 등)에 우선 맡겨보고, 결과의 품질은 케이스마다 다르다는 점을 이해함""
     * 도메인 분석, 경쟁사 조사 등도 Gemini Deep Research 등으로 AI에게 먼저 시도해보고, 디자인 논쟁에 빠졌을 땐 직접 만들기보다 AI로 여러 프로토타입을 빠르게 생성하는 접근
     * 구글 개발자들도 이미 슬라이드 제작, 장애 디버깅 등 광범위하게 AI 활용
     * “LLM이 환각(hallucinate)하고 챗봇이 답변이 부실하다”는 이유로 도입을 미루기보다, 툴체인을 업데이트해야 할 때임
     * 실전에서 AI를 적극적으로 쓰는 개발자라면 에이전트 기반 활용이 필수. 환각도 context engineering·피드백 루프 등으로 충분히 관리·감소 가능
     * AI-퍼스트(AI-first) 마인드셋이 가장 중요

  Step 2: 올바른 AI 도구 세팅

     * 최소 한 가지 이상 코딩 어시스턴트(예: GitHub Copilot)를 IDE에 설치하여 바로 쓸 수 있도록 환경 구축
     * VS Code 유저라면 Cursor(전용 AI 코드 에디터), Cline(VS Code용 AI 에이전트 확장) 등도 추천
     * 에디터 밖에서는 ChatGPT, Gemini, Claude 등을 별도 창으로 질문·답변용으로 병행
     * 이런 도구는 항상 백그라운드에서 실시간 코드 제안이 가능해 AI 사용 마찰 비용을 최소화
     * “이 일에 AI가 쓸모 있을까?” 싶을 때 즉시 시도 가능

  Step 3: 프롬프트 기본기 – 구체성·문맥 제공

     * 효과적인 AI 활용의 핵심은 프롬프트 엔지니어링
     * 흔한 실수: 애매하고 짧은 지시문 → 실망스러운 결과
     * AI는 마음을 읽지 못하므로, 코드의 의도와 요구사항을 명확하게 설명 필요
     * 예시
          + 나쁜 프롬프트: “React 컴포넌트 테스트 작성해줘”
          + 좋은 프롬프트: “LoginForm 컴포넌트(이메일·비밀번호·제출 버튼, 성공/실패 시 메시지 표시, onSubmit 콜백 사용)에서 1) 렌더링, 2) 입력값 검증, 3) 제출, 4) onSubmit 인자 검증, 5) 성공/실패 UI 상태 등까지 Jest 테스트 파일 작성”
     * 구체적인 프롬프트는 결과의 정확도와 실용성을 비약적으로 높임. 프롬프트 작성에 1~2분 더 쓰면, AI 결과물 수정을 몇 시간 아낄 수 있음
     * Google’s Prompting Guide 101 참고:
          + 결과 포맷 명시(“JSON 형태로 반환” 등)
          + 복잡한 작업은 순서·리스트로 쪼개 요청
          + 예시 데이터 제공
          + 반복 실습으로 자신만의 프레이즈·패턴을 익혀감

  Step 4: 코드 생성·자동완성에 AI 활용

     * 환경 구축·프롬프트 연습 후, 반복적/보일러플레이트 코드 생성에 AI를 적용
     * 예: 여러 포맷의 날짜 문자열을 파싱하는 Python 함수 작성 요청
     * AI의 초기 결과는 반드시 읽고, 직접 실행/테스트
     * 시간이 지나면 클래스/모듈 전체 생성, 리팩터링 등으로 점진적으로 확대
     * Cursor는 전체 파일 생성·리팩터링 등 고도화 기능도 제공
     * 초반엔 알고리듬 핵심보다는 헬퍼·유틸 코드부터 위임하여 신뢰/효용성 체험

  Step 5: 비코딩 업무에 AI 통합

     * AI-네이티브란 ‘더 빨리 코딩’만이 아니라, 일 전체의 질 향상이 목표
     * 예: 커밋 메시지·PR 설명문 작성에 AI 활용. git diff 붙여넣고 “전문적 PR 설명문 요약” 요청
     * 진정한 가치: 사고·기획·문서화·연구·커뮤니케이션 등 모든 부가 업무에서 AI를 적극 활용
     * 코드 주석/기술 문서 자동 생성, 요구사항 설명 시 구현 아이디어 설계 초안 작성, 이메일/슬랙 등 복잡한 내용 설명 지원 등도 효과적
     * 예: PM에게 버그 난이도를 설명할 때, AI에게 쉽게 풀어서 설명문 생성 요청
     * “항상 코드만 중요한 게 아님” – 회의, 브레인스토밍, 의견 정리 등에서도 적극적으로 AI 활용

  Step 6: 피드백 기반 반복 개선

     * AI와 일상적으로 협업하면서, AI 결과에서 고쳐야 할 부분을 꼼꼼히 관찰
     * 프롬프트가 불완전했는지, 문맥이 부족했는지 원인 분석 → 다음에 더 나은 프롬프트로 개선
     * 대부분의 AI 어시스턴트는 “여기서 더 수정해줘” 같은 반복·상호작용이 가능
     * 반복하며 잘 통하는 프롬프트 패턴의 라이브러리를 쌓아가며, 팀 내 공유 가능
     * 예: “팀원 입장에서 X를 설명해줘” 패턴이 문서화에 효과적, 데이터 변환 작업엔 예시 입출력 제시가 품질을 높임

  Step 7: 결과 항상 검증·테스트

     * AI 결과는 절대 100% 신뢰 금지
     * 코드가 컴파일 되고 결과가 그럴싸해 보여도, 직접 실행/테스트/리뷰/정적 분석 등 검증 필수
     * 실제로 표면적으로만 동작하고, 엣지 케이스나 미묘한 버그가 남는 경우 많음
     * 기존의 코드 리뷰, 테스트, 정적 분석 습관을 AI 코드에도 반드시 적용
     * 코드를 직접 쓰는 것보다 읽고 검증하는 시간이 더 짧으므로, 전체 생산성은 여전히 향상
     * 경험이 쌓이면, AI가 약한 영역(예: 정밀 산술, 특수 도메인 등) 을 파악해, 직접 이중 체크하거나 그 부분은 AI에 의존하지 않도록 조정
     * AI를 고효율 동료로 대하되, 최종 검토는 항상 인간이 담당

  Step 8: 더 복잡한 활용으로 점진적 확장

     * 작은 업무에서 익숙해지면, 더 진보된 통합/자동화로 확대
     * 예: AI가 코드 내 오류/TODO 주석을 자동 감지해 수시로 제안(Cusor, Windsurf 에이전트 모드 등)
     * Cline 등은 여러 단계 작업(파일 생성→코딩→테스트 등)을 플랜-승인-실행의 자율 에이전트 모드로 처리 가능
     * 고도화된 활용일수록 주기적 관리·감독 필요(주니어에게 더 많은 자율권을 줄 때와 유사)
     * 엔드투엔드 프로토타이핑에도 도전: 주말에 간단한 앱을 “대부분 AI 도움으로” 만들어 보고, 부족한 부분은 직접 채워 넣음.
          + Replit AI, Bolt 등으로 아이디어 구현 속도와 한계를 체험 가능
          + 2~3시간 만에 과거 며칠 걸리던 프로토타입 완성 → 생산성 체감

   이러한 단계를 따라가며 점차 익숙해지면, AI를 자연스럽게 개발 흐름에 녹여내는 수준에 도달할 수 있음.
   다음 섹션에서는 상황별로 최적화된 도구와 플랫폼을 어떻게 고를지 구체적으로 다룸.

# AI Tools and Platforms – 프로토타이핑부터 프로덕션까지

     * AI-네이티브 소프트웨어 엔지니어는 ‘어떤 업무에 어떤 AI 도구를 쓸지’ 선택하는 역량이 매우 중요함.
     * AI 코딩 도구와 플랫폼은 크게 두 가지로 분류 가능:
          + AI 코딩 어시스턴트: IDE/에디터에 통합되어 코드 작성·이해·리팩토링을 지원
          + AI 기반 프로토타이핑 도구: 프롬프트 한 줄로 전체 앱/모듈을 빠르게 생성

     모든 도구 사용 시, “이 프롬프트/코드가 써드파티 서버에 로그로 남아도 괜찮을까?” 라는 데이터 프라이버시 관점의 습관이 매우 중요
     안전한 작업(공개 AI)과 민감한 작업(엔터프라이즈급·로컬 모델) 구분이 필수

  AI 코딩 어시스턴트(IDE 통합형)

   AI 코딩 어시스턴트는 “AI 페어 프로그래머”처럼 에디터/IDE에 붙어서, 기존 코드베이스를 확장하거나 파일 단위로 프로젝트를 구축할 때 큰 힘을 발휘함
     * GitHub Copilot
          + 단순 자동완성에서 실제 코딩 에이전트로 진화
          + 이슈/태스크 할당 시, 코드베이스 분석→환경 세팅(GitHub Actions 등)→멀티파일 수정/명령 실행/테스트/PR 초안 제출까지 자율 처리
          + 최신 모델·MCP(Model Context Protocol)로 외부 도구와 워크스페이스 문맥까지 연결, 모노레포, CI, 이미지, API 등 복잡 구조도 지원
          + 단, 중간 난이도 이하의 작업에 최적화되어 있어 보안/아키텍처/멀티 에이전트 협업에는 인간 감독 필요
     * Cursor – AI-네이티브 코드 에디터
          + VS Code를 기반으로 AI 중심으로 재설계한 독립 에디터
          + AI 기반 코드 네비게이션(함수 사용 위치 추적 등), 스마트 리팩토링, 코드 설명/테스트 생성/Agent 모드(대규모 작업 자동화) 등
          + 특히 대형 코드베이스·엔터프라이즈용으로 강력. .cursorrules 파일 등으로 프로젝트별 커스텀 룰 지정
          + “Ask” 모드로 변경 전 미리 결과 확인 가능, 실수 방지
          + 단점: 독립 에디터(별도 설치), 유료. VS Code 유저라면 진입장벽 낮음
          + 수백만 개발자·대기업이 사용하며 효과 입증
     * Windsurf – 대용량 코드베이스·보안 특화 에이전트
          + 프라이버시·컴플라이언스(자체 호스팅, 데이터 미보존, HIPAA/FedRAMP 인증 등) 가 필요할 때 유리
          + 코드 완성/수정 등 기본은 물론, 대용량 파일·문서까지 AI가 인식해 수만~수십만 라인 단위 리팩토링에도 적합
     * Cline – VS Code용 자율형 AI 코딩 에이전트
          + 오픈소스 VS Code 확장. 단순 코드 제안뿐 아니라, 파일 생성/명령 실행/복수 단계 작업도 허용
          + Plan 모드(전체 플랜 미리 제시)와 Act 모드(작업 실행)를 모두 인간 승인 하에 반복
          + 예: “새 API 엔드포인트·라우트·컨트롤러·DB 마이그레이션 추가” → 계획 잡고, 단계별 승인 받아 구현
          + 시스템 전체 구조 이해/변경도 가능
          + 단점: 여러 파일/명령을 자율 실행하므로 반드시 꼼꼼한 사전 검토 필요, 강력한 모델 연결 시 토큰 비용↑
          + “진짜 주니어가 ‘이거 이렇게 할까요?’라고 계속 물으며 일하는 스타일”
          + 반복 질문이 많아 오작동 위험 감소, 협업 스타일 선호자에게 인기

   언제 AI 코딩 어시스턴트를 쓸까?
     * 코드베이스 유지·확장/함수 작성/리팩토링/코드 설명 등 일상적 사이클에 최적화
     * “에디트-컴파일-테스트” 반복에 자연스럽게 녹아들며, 반복적/루틴 작업을 수십 번 빠르게 처리
     * 전체 앱 한 번에 생성이 아니라, 기존 프로젝트를 지속적으로 개선·확장할 때 가장 효과적
     * 노련한 엔지니어라면 “온디맨드 검색엔진”처럼 하루에도 여러 번 활용

     * OpenAI Codex, Google Jules 등의 비동기/자율 코딩 에이전트 는 한발짝 더 나아감
          + Codex: 클라우드상에서 샌드박스 환경에서 병렬 작업(기능 개발, 버그 수정, 테스트, PR 제출) 자동화 후 로그/차이로 검토
          + Jules: Gemini 2.5 Pro 기반, GitHub 이슈 할당 시 VM에서 저장소 복제→멀티파일 수정/실행/변경 요약(음성 포함)/PR까지 자동화
          + “자동완성”과 달리, 백그라운드에서 큰 단위의 업무를 자율적으로 완수해 ‘최종 결과’만 개발자에게 제출
          + 개발자는 더 고차원의 일에 집중 가능

  AI 기반 프로토타이핑 및 MVP 생성 도구

   IDE 보조도구와 별도로, 한 줄 프롬프트만으로 실제 앱/기능 전체(혹은 큰 부분)를 생성하는 도구가 등장.
   새 프로젝트나 기능을 아주 빠르게 부트스트랩하고 싶을 때 특히 유용하며, 최종 제품 품질엔 추가 개발이 필요하지만, 시작점(초안)으론 매우 뛰어남.
     * Bolt (bolt.new)
          + 한 번의 프롬프트로 풀스택 MVP 생성
          + 예: “유저 로그인+관리자 대시보드가 있는 구인 게시판” → React+Tailwind CSS 프론트엔드, Node.js/Prisma 백엔드, DB 모델까지 자동 생성
          + 실제 테스트에서도 15초 내외로 프로젝트 전체 뼈대 완성, 코드도 최신 트렌드(컴포넌트, REST/GraphQL API 등) 반영
          + 프로토타이핑/반복 개선이 매우 빠름(프롬프트 수정→즉시 재생성/GUI 조정 가능), GitHub 내보내기 등 지원
          + 초기 세팅을 빠르게 끝내고 싶은 창업자, 해커톤, 개발자에게 강력 추천
          + 단점: Bolt가 기본적으로 적용하는 스타일·패턴 범위 내에서 창의성이 제한, 아주 특이한 요구사항은 직접 조정 필요
          + 깔끔한 UI 일관성, 빠른 배포, 프로토타입 데모에 특히 강점
     * v0 (v0.dev by Vercel)
          + Next.js 특화 앱 생성 도구
          + 프롬프트 한 줄로 프로젝트 생성, 특히 ShadCN UI 스타일(트렌디한 미니멀 컴포넌트 라이브러리)로 디자인 일관
          + 원하는 커스텀 디자인엔 제약이 있으나, 빠른 기능 프로토타입/Vercel 배포에 최적
          + Next.js/React 기반, 서버리스/Edge Functions 등 지원
          + “기능 위주 프로토타입 빠른 생성+즉시 배포”에 유리
     * Lovable
          + 시각적 에디터 중심, 초보자/비개발자용
          + 앱 설명을 입력하면 UI·일부 코드 자동 생성, 시각적 UI 조립도 가능
          + 직관적 사용법, 노코드에 가깝지만, 코드 커스터마이즈 필요시엔 불편
          + 디자이너/PM 등 비개발자와 협업한 아이디어 구체화에 적합, 개발자에겐 기능적 제약이 아쉬울 수 있음
     * Replit
          + 온라인 IDE+AI, 실시간 실행·테스트까지
          + 예: “2D 젤다 스타일 게임 만들어줘” → AI가 코드 생성+실행+스크린샷 비교로 반복 개선
          + 프론트/백엔드 통합, 즉시 구동/배포, 클라우드 환경 지원
          + 실제 동작하는 게임/앱 등 완성도가 가장 높았던 사례도 존재
          + 코드가 항상 완벽하진 않으나, “일단 돌려볼 수 있는 앱”을 빠르게 만들고 싶은 목적에 적합
     * Firebase Studio
          + Google의 Gemini 기반 클라우드 IDE
          + 자연어·이미지·스케치 등 다양한 입력으로 Next.js 풀스택 앱 자동 프로토타입 생성, Firestore/Auth/Hosting 등 통합
          + 코드 OSS 기반(즉, VS Code 친화적), 에뮬레이터 연동, 라이브 미리보기/전체 배포까지 원스톱 지원
          + Gemini가 코드 제안, 디버깅, 테스트, 마이그레이션, 문서화, 터미널 명령 실행 등까지 지원

   언제 프로토타이핑 도구를 쓸까?
     * 새 프로젝트/기능의 ‘초기 세팅 작업’을 없애고 싶을 때(기획 데모, POC, 아이디어 탐색 등)
     * 아이디어별 다양한 변형을 빠르게 생성/비교(“이 방식/저 방식” 직접 만들지 않고 비교)
     * 생성 결과는 ‘첫 번째 드래프트’로 생각하고, 이후 IDE/AI 어시스턴트로 정교화하는 하이브리드 접근이 효과적
          + 예: Bolt로 MVP 생성→Cursor로 이어받아 코드 품질/로직 고도화

   한계와 학습 포인트
     * 생성 코드로 프레임워크 패턴·관행 학습에도 활용 가능(‘튜토리얼 10개 한꺼번에 읽는 셈’)
     * 다만, 앱의 마지막 20~30%(the 70% problem)(성능 튜닝, 비즈니스 로직, 보안 등)은 직접 보완 필요
     * “지루한 70%는 AI가, 나머지 창의/고도화는 인간이” 역할 분담이 생산성 극대화의 핵심
     * 반드시 보안/품질/맞춤성 등 검토 후 적용(예: 하드코딩된 API 키 등 유의)

  도구별 활용 요약 및 실전 팁

     * IDE 어시스턴트(예: Cursor, Cline)는 기존 코드베이스의 확장/유지·보수/리팩토링에 최적
          + 대형 프로젝트를 꾸준히 관리·개선할 땐 IDE 어시스턴트가 일상적인 파트너
     * 프로토타입 생성형 도구(예: Bolt, v0)는 신규 프로젝트나 모듈을 ‘빠르게 부트스트랩’ 할 때 사용
          + 빌드툴 세팅/보일러플레이트 생성 등 번거로운 초기작업을 AI가 모두 처리
     * 실무에선 두 도구를 ‘조합’해서 활용하는 경우가 일반적
          + 예: Bolt로 프로젝트 뼈대 생성→Cursor로 코드 품질/세부 기능 개발
     * 팀 내부에선 AI 생성 코드에 대한 “not invented here” 심리(내가 직접 작성하지 않은 코드에 대한 불신/꺼림칙함)를 인식하고 소통
          + 효과적인 대응: PR에 “이 컨트롤러는 v0.dev로 생성, 아래 프롬프트 기반” 등 AI 사용내역을 명시하여 투명성+리뷰 유도
          + 속도·품질(검증 후) 모두 입증하면서 팀 내 신뢰 구축, AI 활용이 자연스러운 문화 정착
     * 다음 장에서는 설계부터 배포까지 소프트웨어 개발 전체 주기에서 AI를 적용하는 구체적 방법을 다룸(요구사항, 테스트 등 전 영역에서 AI가 중요한 역할)

# AI의 소프트웨어 개발 생명주기(SDLC) 전방위 활용

   AI-네이티브 소프트웨어 엔지니어는 코딩만이 아니라, SDLC 전체 단계 에서 AI를 활용해 효율성과 혁신을 극대화
   아래는 단계별 실전 적용법

  1. 요구사항 도출 & 아이디어 브레인스토밍

     * AI를 브레인스토밍 파트너/요구사항 분석가로 활용
          + “X 앱 만들고 싶다”→AI에게 필수 기능/사용자 스토리 제안 요청 → 예산 관리 앱, 태스크 매니저 등 사례별 특화 기능 제안
          + MVP의 유저 스토리 5개, 특정 요구사항에 대한 명확화 질문 등도 자동화
          + 경쟁 서비스 분석도 가능: “과제 관리 앱의 흔한 문제점·핵심 기능 정리해줘”→AI가 다수 블로그·문서 지식 요약
     * 비개발자와의 협업 지원: 초안 PRD 생성→공유/피드백→최종 문서화 등 워크플로우 단축
     * 아이디어의 양적 확장→질적 토론 기반 마련: 다양한 옵션을 빠르게 수집해 팀/이해관계자 논의 촉진

  2. 시스템 설계 & 아키텍처

     * AI를 설계 피드백·의사결정 도우미로 사용
          + 아키텍처(예: 마이크로서비스, API Gateway, React 프론트엔드) 초안을 설명→AI가 장단점, 확장성 이슈 등 지적
          + 구체적 설계 질문(SQL vs NoSQL, 실시간 알림 구조 등)→객관적 고려사항 나열
          + 설계 다이어그램(mermaid 등) 자동 생성: 텍스트로 구조 설명→AI가 코드·도식 자동 출력
          + API 설계 초안(엔드포인트/페이로드 예시 등)도 빠르게 작성 가능
          + 리스크 체크리스트: “세션 캐시 한 DC만 쓸 때 어떤 위험?”→장애, 데이터센터 장애, 스케일링 문제 등 포인트 도출
          + 논리적 반박/대안 프레이밍 지원: 설계 반대 시 AI가 우려 정리, 대안 탐색→논리적 설득자료 제공
     * 스펙 중심 개발로 전환: 코드 대신 명세 작성이 우선, AI에게 구현계획/설계 명세 초안 생성 요청, 재활용(문서·PRD·배포매니페스트 등)
     * 시니어 개발자 역량: 단순 문제풀이가 아니라 미래예측/로드맵/트렌드 분석 등 솔루션 설계자로 진화

  3. 구현(코딩)

     * AI로 반복 작업/설정 자동화: 보일러플레이트, 환경설정, 라이브러리 예시, Docker/CI/ESLint 등 기본 파일 생성
     * 기능 개발 파트너: 함수/클래스/모듈 구조 설계→AI가 세부 코드/로직 구현, 의도는 인간이 정의
     * 코드 재활용/레퍼런스 검색: 과거 코드/알고리듬 기억 안 날 때, AI에 “이런 로직 효율적으로 처리하는 법?”→즉시 코드 제안
     * 패턴/일관성 유지: 예시 파일 제공→새 모듈 생성시 동일 스타일/패턴으로 작성
     * 테스트 동시 생성 습관화: 함수 작성→“엣지케이스 포함 유닛테스트 코드 작성” 요청→코드 검증·TDD 도우미
     * 디버깅/런타임 지원: 에러 로그/스택트레이스 입력→원인 설명, 런타임 디버거(입력값별 변수 추적)로도 활용 가능
     * 성능/리팩토링: “이 함수 복잡도 줄여줘”, “50줄 함수 분리+주석 추가” 등 구조 개선도 AI에 위임
     * 버전관리/코드리뷰: AI 코드도 반드시 git diff, 코드리뷰, 테스트 필수

  4. 테스트 & 품질보증

     * 유닛테스트 자동 생성: 모듈별 public 함수·클래스 설명→테스트케이스 생성, 레거시 코드 테스트 보완에 특히 효과적
     * 프로퍼티 기반/퍼즈 테스트: AI에게 “정렬 함수의 보장 조건?”, “엣지케이스 10개 JSON 생성” 등 자동화
     * 통합/엔드투엔드 테스트: 시나리오 설명→AI가 테스크립트 초안 생성(Cypress/Selenium 등), 테스트 경로 다양화
     * 테스트 데이터 생성: 실감나는 JSON 등 더미데이터 자동화, 민감정보는 익명화 필요
     * AI 에이전트로 엑스플로러리 테스트: AI가 사용자처럼 다양한 입력 시도→버그·취약점 사전 탐지
     * 테스트 커버리지 점검: 현재 테스트/설명 제공→“누락된 케이스?” 질의로 보완
     * 전체적으로 수작업 테스트 부담↓, 커버리지↑, 유지보수성↑

  5. 디버깅 & 유지보수

     * 레거시 코드 해설/문서화: 긴 함수/난해 코드도 “순서대로 쉽게 설명해줘”→이해·온보딩 가속
     * 원인 파악: 버그 상황/코드 입력→AI가 패턴 기반 추론, 빠른 원인 도출
     * 코드 수정 자동 제안: “이 함수 빈 입력일 때 오류 수정해줘”→AI가 패치코드 제시, 적용 전 검증 필수
     * 대규모 리팩토링: async/await 변환, 의존성 주입 등 구조 개선도 AI가 샘플 코드→전체 적용
     * 문서화·지식 관리: 기능 추가/버그 픽스 후 AI로 문서/릴리즈노트 초안 생성→수정·보완만 하면 됨
     * 팀 커뮤니케이션: 마이그레이션 가이드, 릴리즈노트, 사용자 공지문 등 초안 자동화
     * CLAUDE.md 등 문맥 파일로 AI 활용성↑, 앞으로는 자동 티켓/PR 생성도 일반화 전망

  6. 배포 & 운영

     * IaC(Terraform/K8s) 자동 생성: “AWS EC2 t2.micro용 Terraform 스크립트” 등 코드 자동 생성, 보안·키 등은 직접 검증 필요
     * CI/CD 파이프라인 생성: GitHub Actions, Jenkins 등 YAML 스크립트 설계·자동화, 문법 오류만 수정하면 바로 활용
     * 모니터링/알림 쿼리: PromQL/Grafana/Splunk 등 복잡한 쿼리도 AI가 초안 생성
     * 운영 로그/메트릭 분석: 장애 시 로그 입력→이상 짚어내거나, 원인 추론 지원(AIOps 활용)
     * ChatOps/자동화: Slack 등에 연결해 “최근 배포 상태/오류 알려줘” 등 질문→요약 제공, 수동 로그 복사도 AI가 요약
     * 스케일링/용량 산정: “X요청·Y유저면 인스턴스 몇 개?” 등 산정도 자동화
     * 운영 매뉴얼/런북 작성: 장애/이슈 발생 시 단계별 처리 절차 초안→문서 저장·공유, 경험이 조직에 남도록 지원
     * 모든 인프라 자동화 작업도 AI가 초안→엔지니어가 검증 흐름 권장

  전체 요약

     * SDLC 전 과정에서 AI가 반복적 작업·지식 제공, 인간은 방향·판단·최종 책임 담당
     * 크리에이티브 설계/판단/의사결정에 집중, 잡일·정보탐색 시간↓
     * 적절히 활용하면 개발 사이클 단축+품질 개선+개발자 만족도↑
     * 다음 장에선 AI를 효과적·책임감 있게 쓰기 위한 베스트 프랙티스를 다룸

# 효과적이고 책임감 있는 AI 활용을 위한 베스트 프랙티스

   AI를 소프트웨어 개발에 활용하면 혁신적 변화가 가능하지만, 실질적 이점을 얻으려면 올바른 원칙과 실수 방지가 필수임
   다음은 AI를 안전하고 생산적으로 활용하기 위한 핵심 가이드

  1. 명확하고 문맥이 풍부한 프롬프트 작성

     * 프롬프트 작성은 코딩·커밋 메시지와 동급의 핵심 역량
     * “이 코드 최적화 방법?” 대신 “아래 코드에서 정렬 부분 중심으로 속도 최적화 방안 제시” 등 문맥+목적+예시까지 상세히 설명
     * 원하는 출력 포맷(JSON, 단계별 설명 등)도 구체화
     * 복잡한 작업은 단계별로 쪼개거나, 샘플 제공
     * 프롬프트 실패 시, 반복 수정하며 원하는 방향으로 조율
     * 성공 사례 프롬프트 라이브러리를 구축(포맷별, 목적별, 상황별 저장·공유)
     * Google의 고급 프롬프트 가이드 등 참고

  2. AI 결과는 항상 직접 리뷰·검증

     * AI의 답변을 절대 맹신 금지(trust, but verify)
     * AI가 작성한 코드는 꼭 직접 읽고, 디버거·테스트로 확인
     * 설명·분석도 반드시 주요 포인트를 교차검증(공식 문서/직접 추론)
     * 실제로 AI가 plausible(그럴듯해 보이는) 오류, 잘못된 API 명칭을 자주 만듦
     * 조직별 정책, 사내 정보 등은 AI에 맡기지 않기
     * 코드 스타일/구문/테스트 자동 검사(린터/타입체커 등) 병행
     * 보안·민감 시스템에서는 절대 비밀번호/시크릿/암호화 코드를 AI로 생성 금지, 반드시 업계 표준 검증
     * AI끼리 교차 검증: 한 AI 결과를 다른 AI에 “버그/보안 이슈 있나?” 질의→추가 체크
     * 늘 건전한 회의적 태도로, AI의 강점·약점에 대한 직관을 키우기

  3. AI는 생산성 ‘증폭기’로, 전자동화 대신 인간 감독 유지

     * “AI가 전체 시스템을 클릭 한 번에 자동화”는 환상에 가깝고, 현실적으론 반복적 작은 업무 단위에 AI를 활용
     * AI가 생성한 앱/코드는 초안(프로토타입) 취급 후, 반드시 직접/팀에서 반복 개선
     * 복잡한 업무는 여러 하위 과제로 나눠서, AI로 한 단계씩 분업(프론트엔드→백엔드→통합 등)
     * AI의 상위 목표 이해력 한계 인식, 설계·제약조건은 인간이 설정
     * 과도한 의존 방지: 단순·반복 업무 위임, 창의적·복합 사고·학습은 직접
     * AI 에이전트 범위 명확히(새 의존성/네트워크 등 사전 승인, dry-run·plan mode 적극 활용)
     * 본인 이해·품질 확보가 어려운 AI 코드 누적=기술부채 위험

  4. 계속 배우고 최신 상태 유지

     * AI·툴 생태계 변화 속도가 매우 빠르므로, 항상 학습 유지
     * 새 도구·모델·베스트 프랙티스 체크, 관련 뉴스레터·커뮤니티 구독
     * 팀 내·외에서 프롬프트/워크플로우·에이전트 활용 경험을 서로 공유
     * 사이드 프로젝트/해커톤 등에서 AI 적극 실험, 성공·실패 경험 내재화
     * 멘토링·내부 세션 주최: 팀에 프롬프트 엔지니어링/성공사례 공유
     * 기초 역량(컴공, 시스템 설계, 문제해결력)도 계속 강화
     * AI로 70% 자동화, 남은 30%(문제 정의, 판단, 디버깅)는 인간 고유 역량임
     * “human 30%” 극대화

  5. 팀 내 협업·표준화

     * AI 활용 경험 공유/가이드라인 수립, 팀 합의 중시
     * 예: “AI 코드도 반드시 1인 이상 리뷰·테스트 후 머지”, PR에 // Generated with Gemini 등 투명하게 명시
     * AI 기반 코드리뷰 도입(diff에 AI가 먼저 피드백, 이후 인간 리뷰)
     * “우리 코드베이스에서 X 작업 시 AI에게 이렇게 프롬프트” 등 내부 FAQ/온보딩 문서화
     * AI에 신중한 동료 의견도 존중, 실패사례 공유하며 집단지성 강화
     * 리더십 관점: AI 학습·실험 시간/리소스 할당, 라이선스/IP 관리, 보안정책 정립
     * AI 도입은 팀 스포츠, 도구·워크플로우 호환성 확보로 코드베이스 품질·유지성 강화

  6. 책임감 있고 윤리적으로 AI 사용

     * 프라이버시·보안: 외부 API/플러그인 사용 시 데이터 노출 주의, 자체 호스팅/익명화 등 정책 준수
     * 바이어스/공정성: AI가 만든 사용자-facing 결과·의사결정은 바이어스/비포괄적 언어 필터링
     * AI 활용 투명성: 기능·콘텐츠 일부가 AI 기반임을 필요 시 명확히 공지, 로그·태깅 관리
     * IP(지식재산권) 이슈: 라이브러리·라이선스·인용 주의, 내부 정책/법률 자문 참고
     * 인간 감독 유지: 중요한 판단·오류 발생시 인간이 최종 확인/결정
     * 책임 있는 AI 개발: 본인이 작성했다고 자부할 수 있을 만큼, 윤리·신뢰성 원칙 수립 및 실천(OpenAI, Google, Anthropic 등 가이드 참고)

  7. 리더와 매니저를 위한 AI-퍼스트 문화 구축

     * 직접 시연·비전 제시: AI로 전략 수립, 제안서 작성 등 실제 사례 오픈 공유
     * 역량 투자: 유료 툴 지원, 해커톤/실험 시간 보장, 내부 베스트 프랙티스 위키/데모 운영
     * 심리적 안전망 조성: 실패 공유·질문 허용 문화, AI는 협력자라는 프레임 명확화
     * 로드맵/프로세스 재설계: 반복작업에서 검증·명세·통합 중심으로 역할 변화, 코드리뷰의 인간 검증 비중 강화

   요약
     * 위 프랙티스들을 꾸준히 적용하면, AI 도입 효과(생산성·코드 품질·학습속도↑)와 실수/오남용 리스크를 동시에 관리 가능
     * “AI의 장점+인간의 통찰력”을 결합하는 것이 궁극적 경쟁력
     * 마지막 장에서는 AI-네이티브로 가는 여정·추가 자료 안내 예정

# 결론: 미래를 받아들이는 자세

   AI-네이티브 소프트웨어 엔지니어란 무엇인지, 마인드셋부터 실무 워크플로우, 도구 환경, 생명주기 통합, 베스트 프랙티스까지 다뤄 옴
   AI는 엔지니어를 대체하는 것이 아니라, 인간 역량을 강력하게 증폭하는 파트너임이 명확해짐
   AI-네이티브 접근을 수용하면, 더 빠른 구축, 더 깊은 학습, 더 큰 도전이 가능함
     * 핵심 요약:
          + AI-네이티브는 “AI를 내 능력의 곱셈기”로 받아들이는 것에서 시작
          + “AI로 이 작업을 더 빠르고 창의적으로 해결할 수 있을까?”를 습관처럼 질문
          + 프롬프트 엔지니어링, 에이전트 오케스트레이션 등 새로운 스킬과, 설계·비판적 사고·윤리 등 시대를 초월한 역량이 함께 중요
          + AI는 끊임없이 배우며, AI로 다른 분야까지 학습 속도를 올릴 수 있음(선순환 구조)
     * 실전에서는 다양한 도구(IDE 어시스턴트, 프로토타입 생성기 등)를 직접 조합, 상황별로 “어떤 툴을 쓸지” 골라 쓸 줄 아는 장인이 경쟁력
     * AI는 모든 단계에서 협업 파트너: 코딩, 테스트, 디버깅, 문서화, 설계 브레인스토밍까지 함께
          + AI가 많을수록, 인간 고유의 크리에이티브/판단/통찰에 집중할 수 있음
     * 책임감·검증 태도 강조:
          + AI의 뛰어난 기능에만 매몰되지 않고, 건강한 회의론·엄격한 리뷰·테스트·한계 인식으로 실수 방지
          + 베스트 프랙티스(명확한 프롬프트, 코드리뷰, 소규모 반복, 한계 인식)만 지키면 AI 활용 신뢰도↑
          + 경험 많은 엔지니어는 AI의 오류도 효율적으로 통제하며, 복잡한 문제/시스템 통합 역량에서 가치가 더 커짐
     * 향후 전망:
          + AI는 점점 더 강력해지고, 개발 툴에 깊이 통합됨(예: IDE가 AI로 코드/문서/성능을 실시간 점검)
          + 프론트엔드/데이터베이스 등 특화 AI가 나올 것
          + “AI-네이티브”가 곧 “소프트웨어 엔지니어”의 표준이 될 시대가 도래
          + AI가 진입장벽을 낮추면서, 기존 비전통적 개발자도 더 쉽게 소프트웨어를 만들게 될 것
          + AI 활용 엔지니어는 도구 개발·멘토링 등 새로운 역할로 확장
          + AI가 반복노동을 대신함으로써, 상상력·설계력 중심의 창의적 엔지니어링 시대 개막
     * 실천 팁:
          + 단번에 바꾸려 하지 말고, 한두 도구/한 영역부터 시작→점차 확장
          + AI가 처음으로 테스트에서 버그를 잡아주는 기쁨, 리팩터링에서 실수한 경험 등 ‘성공/실패’ 모두 학습 기회로
          + 팀에도 이런 문화가 퍼지면, 생산성뿐 아니라 개발의 즐거움까지 되찾게 됨
     * 마지막 조언:
          + “AI 도입”은 한 번의 변화가 아닌 ‘여정’임
          + 실용적·지속적인 학습과 팀 문화로, AI가 내 옆 동료가 되는 시대를 주도적으로 맞이할 것

# 참고 자료

   아래는 AI-네이티브 엔지니어링에 깊이를 더할 수 있는 대표적 무료 가이드와 리소스
     * Google - Prompting Guide 101 (Second Edition)
          + Gemini 모델용 프롬프트 기본서, 실제 예시·팁 풍부
     * Google - “More Signal, Less Guesswork” prompt engineering whitepaper
          + 고급 프롬프트 테크닉, API·Chain-of-thought 등 전문적 사례
     * OpenAI - A Practical Guide to Building Agents
          + 실전 에이전트 설계·구현 가이드, 단일/다중 에이전트 구조, 반복/안전관리 등
     * Anthropic - Claude Code: Best Practices for Agentic Coding
          + Claude 활용 노하우, CLAUDE.md 구조화, 프롬프트 포맷, 반복 협업 팁
     * OpenAI - Identifying and Scaling AI Use Cases
          + 조직·팀 차원의 AI 도입/확산 전략, 고레버리지 분야 발굴, PoC에서 확산까지 단계별 제안
     * Anthropic - Building Trusted AI in the Enterprise (Trust in AI)
          + 엔터프라이즈 AI의 신뢰·보안·가버넌스 등, 실제 사례 중심
     * OpenAI - AI in the Enterprise
          + 대기업 AI 활용 전략, 사례, 조직 내 도입 실전 가이드
     * Google - Agents Companion Whitepaper
          + 에이전트 기술 심화서, 평가·도구 연동·멀티 에이전트 조율 등 고급 주제

   이 자료들은 실전적 테크닉과 이론적 프레임워크를 모두 제공하며, 베스트 프랙티스와 업계 전문가 인사이트까지 두루 담고 있음
   자유롭게 학습하며, AI-네이티브 엔지니어로서의 역량을 지속적으로 확장해나가길 권장

   추신: 필자(Addy Osmani)는 현재 O'Reilly와 함께 AI-assisted engineering book 집필 중. 이 글이 유익했다면 책도 참고
"
"https://news.hada.io/topic?id=21961","2025년에 처음으로 Neuromancer 읽기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       2025년에 처음으로 Neuromancer 읽기

     * Neuromancer는 1984년 발표된 이후 사이버펑크 장르를 정의하며 현대 SF와 IT 문화에 큰 영향을 준 작품임
     * 처음 읽는 독자에게 기술 용어와 복잡한 묘사가 난해하게 느껴질 수 있으나, 천천히 읽으면 명확한 스토리와 혁신적 상상력을 경험할 수 있음
     * Blade Runner와의 연관성, 그리고 Neuromancer가 아직 적응되지 않은 점이 강조되며, Apple TV+의 예정된 시리즈에 대한 기대감 언급
     * Gibson이 AI, 가상현실, 사이버네틱스 등 미래 기술에 놀라울 정도로 정확한 예견을 했지만 휴대폰 부재 등 예측하지 못한 부분도 있음
     * 결론적으로 Neuromancer는 미래 예측이 아닌 인간 이해를 위한 SF의 목적에 충실하며 지금도 매우 시의적임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: Neuromancer를 처음 읽은 후기

     * 2016년에 The Verge에서 일하기 전까지 Neuromancer를 들어본 적조차 없었음
     * 사이버펑크, 해킹, 기업 첩보, 가상현실, 인공지능 등 현대 SF의 핵심 요소들이 이 소설에서 처음으로 본격 등장했음을 몰랐음
     * 2025년 목표로 소셜 미디어를 멀리하고 하드커버 SF책 읽기를 시작, 그 첫 작품으로 Neuromancer를 선택함
     * 작품의 상징성과 독특함 때문에 일주일 만에 완독함

Neuromancer와 사이버펑크 장르의 정의

     * Neuromancer는 사이버펑크 그 자체로, 네온 불빛, 우울한 미래, 기술적 디스토피아 등으로 SF의 전형을 만든 작품임
     * “포트 위 하늘은 죽은 채널로 맞춘 텔레비전 색깔이었다”라는 첫 문장부터 익숙하면서도 충격을 주는 묘사 경험
     * “사이버펑크”라는 단어 자체는 Bruce Bethke가 만들었으나, 이 장르를 결정적으로 정의한 건 Gibson임
     * Neuromancer를 읽어본 적 없더라도 이미 영향을 받아본 경험을 모두가 갖고 있음

Gibson의 문체와 이해의 어려움

     * 현대 SF에 비해 Neuromancer는 짧지만 읽기 쉽지 않은 소설임
     * Gibson이 만든 새로운 기술 용어와 독창적 언어 때문에 독해에 반복이 필요함
     * 본문 예시처럼 실제와 완전히 일치하지 않는 추상적・기술적 묘사가 문자 그대로 가득함
     * 처음엔 뜻을 잡기 힘들지만 노트 필기와 반복 독서로 전체 맥락이 이해되는 구조임

영향력과 익숙함의 역설

     * Neuromancer가 너무나 독창적이었던 1984년 이후, 수많은 영화, 애니메이션, 비디오게임에 뿌리내려 현재의 독자들에게 역설적으로 낯익을 수 있음
     * Matrix Trilogy, Ghost in the Shell, Mr Robot, Cyberpunk 2077 등 거의 모든 사이버펑크 작품이 Gibson의 설정에서 출발함
     * Blade Runner(1982)는 Neuromancer 이전에 나왔으며, Gibson도 영화의 영향력을 인정함
     * Blade Runner의 “시각적 질감”이 Neuromancer의 묘사에 영향을 미쳤고, 반대로 최근 Blade Runner 2049에서 Neuromancer의 분위기가 느껴짐

시대 변화와 기술 예측

     * Blade Runner의 미래상은 2025년 오늘날에는 다소 구식으로 보이나, Neuromancer의 근미래적 느낌은 여전히 신선함
     * Neuromancer의 세계에는 여전히 바에서 흡연이 가능하고, 신문이 거리를 날리며 아무도 모바일폰을 사용하지 않음
     * 소설에 등장하는 거의 모든 첨단 기술은 일본 또는 독일 제품으로 묘사 – Sanyo, Hitachi, Braun 등이 대표적임
     * 1984년 당시 일본이 가전 시장을 지배하고 있었던 시기 상황이 그대로 반영됨

SF의 역할과 Neuromancer의 현재적 의의

     * Gibson이 SF에서 미래 예측이 얼마나 어려운 일인지 보여줌
     * Neuromancer는 기존 미래상(Blade Runner처럼 특정 연도)을 피하면서, 특정 시점을 명시하지 않아 근미래적 감각을 준다는 이점이 있음
     * Gibson의 AI와 가상현실에 대한 상상력은 1984년에 쓰였음에도 불구하고 오늘날에도 놀라움 유발
     * 실제로는 휴대폰, 대기 시설을 갖춘 우주정거장 등 몇몇 기술에 대한 예측은 빗나감
     * 그러나 SF 본연의 목적은 기술의 정확한 예측이 아니라 인간성의 탐구임을 강조

결론

     * Neuromancer는 오늘날까지도 SF, 스타트업, IT 종사자들에게 지대한 영향력을 가진 작품임
     * Gibson이 창조한 사이버스페이스, 매트릭스, 스프롤 등은 현대 IT와 미래 세상상에 집중적 영향을 줌
     * 첨단기술의 현재와 미래를 이해하고자 한다면 Neuromancer는 여전히 유효한 필독서임
     * Apple TV+에서 이 소설의 실사화를 시도하고 있어, Blade Runner와 어떤 “비주얼” 경쟁을 보여줄지 기대감 형성됨
     * 과거와 미래, 기술과 인간성의 교차점에서 Neuromancer는 여전히 놀라운 통찰 제공

        Hacker News 의견

     * 나는 Neuromancer로 정반대의 경험을 했음, 너무 여러 번 읽어서 그렇음. 1993년 고등학교 마지막 학년에 컴퓨터공학을 준비하며, 한 소녀가 나에게 1989년 그리스판 Neuromancer를 건네줌. 이미 Asimov, Dick, Clarke의 SF를 좋아했는데, Neuromancer는 완전히 달랐음. 시험 스트레스에 시달리던 그 해에 Neuromancer만 반복해서 읽었고, 위로가 되어 100번은 넘게 읽은 것 같음. 나중엔 그 책을 외워, 누가 책을 아무 페이지나 읽으면 바로 다음 줄을 암송할 수 있었음—마치 Fahrenheit 451 속 한 장면처럼. 지금도 1-2년에 한 번 다시 읽지만 여전히 마법같은 느낌임. 그 책을 준 소녀와 결혼해 아이도 낳았고, 29년 후엔 이혼했지만 여전히 친구임
          + 책을 준 여자와 결혼했다니, Neu-romance-er라는 농담 생각남
          + 흥미로운 이야기임. 나도 Neuromancer를 Dune처럼 자주 다시 읽는데, 세계관이 풍부해서 플롯은 더 이상 놀랍지 않지만, 계속 방문하고 싶은 세계 같음
          + 책을 준 여자와 결혼해서 아이를 낳았다는 대목에 웃음, 29년 후 이혼했다는 부분에서 아쉬움, 그래도 여전히 친구라니 다시 미소 지음
          + 이런 멋진 스토리 공유해 준 것에 감탄함
          + 이야기가 정말 인상적임, 게다가 번역이라니. 그리스어판 번역가가 엄청 실력자였던 것 같음. 다른 언어로 번역된 Neuromancer는 어땠을지 궁금해짐. 다른 나라 SF 팬들은 실력 있는 번역가나 출판사를 일부러 찾아 읽기도 하는지 궁금함
     * Gibson의 독특한 점은 그가 Neuromancer를 쓸 때 아주 비기술적이었다는 것임. “컴퓨터에 디스크 드라이브가 있다는 것조차 몰랐고, 처음 Apple II를 샀을 때 소리도 이상해서 가게에 문의했었음. 전자 사이버덱 같은 상상과 달리 빅토리아 시대 엔진 같은 느낌이었고, 이런 무지가 나로 하여금 컴퓨터를 더 신비롭게 여길 수 있게 해줌” — 인터뷰 원문
          + Gibson이 독특한 SF 작가인 이유는 그의 관심이 ‘패션’에 있다는 것임—직접적으로 밝힌 적 있음. 그의 세계는 아름답지만 매우 표면적이고, 한 단어나 문장만으로 방대한 배경을 그려냄. 결국 모든 게 ‘분위기(vibes)’임. Bruce Sterling도 비슷하지만 Gibson만큼 패션에 충실하지는 않음. 둘 다 기술보다 사람과 트렌드에 집중함. (한편 Neal Stephenson은 기술 덕후 기질이 너무 강해 때론 이야기의 속도를 떨어뜨림)
          + Neuromancer가 실제로 컴퓨터에 대한 소설이 아니어서 Gibson의 무지를 믿을 수 있음. SF는 결국 사람에 관한 이야기임
          + 독립 다큐 <No Maps for These Territories>(https://wikipedia.org/wiki/No_Maps_for_These_Territories)는 세 가지 주제에 집중함: 1) Gibson이 Americana에 대해 이야기함, 2) 자기 비하 섞인 답변, 3) 당시 Neuromancer를 처음 읽었을 때 다른 작가들이 느낀 경험 공유
          + ‘무지를 통해 신비로움을 덧입힐 수 있었다’는 것이 SF/사변소설/사이버펑크에서 시대를 초월해 매력을 유지하는 비결임. 50년 뒤의 기술을 섣불리 예측하면 오히려 책이 구닥다리로 보이기 쉬움. 아예 미래 기술을 새로 만들어내면 계속 흥미롭고 미스터리함 유지 가능
          + 때론 무지야말로 최고의 축복임. Gibson이 실제로 기술적 배경을 알았다면 전혀 다른 소설이 나왔을 수도 있음. 때로는 모르기 때문에 더 흥미로운 영감이 솟음
     * 전반적으로 재미있게 읽었음. 한 가지 지적하고 싶은 건, Ghost in the Shell(공각기동대)가 1989년에 출간됐지만, 작가는 1985년 이미 Appleseed라는 작품에서 유사한 사이버펑크 테마를 다뤘음. Gibson의 Neuromancer보다 약간 늦은 시점이지만, 둘 다 거의 동시대에 활동했다고 볼 수 있음. 일본에서라면 오히려 1982년에 시작된 Akira가 더 큰 영향력을 가졌을 것임. 일본의 풍성한 사이버펑크 신이 서양에선 충분한 주목을 받지 못한다고 느낌
          + Gibson은 일본 문화에서 굉장히 많은 영감을 받음. The Matrix 역시 Ghost in the Shell에서 직접 영감을 얻고 The Animatrix를 만들기도 했음. Ghost in the Shell과 Blade Runner는 체제 내부 시각이고, Neuromancer와 The Matrix는 아웃사이더 시각임. 사이버펑크는 본질적으로 카운터컬처이고, 서구(특히 미국)에서 그게 더 두드러짐. 일본은 미국만큼 카운터컬처가 주류로 자리 잡진 않았음. 미국의 카운터컬처 환경 덕에 사이버펑크와 디스토피아/유토피아 SF가 다양하게 발전했다고 생각함
          + 일본인들이 “Japanese Cyberpunk”(예: Tetsuo: The Iron Man)와 Ghost in the Shell 같은 일본발 일반 사이버펑크 장르를 구분하는지 궁금함. 서양에서 구분하는 만큼 일본에서도 두 장르를 따로 인식하는지, 아니면 한 장르 내의 하위 장르 개념인지 궁금함
     * 내가 가장 좋아하는, Neuromancer 이후의 덜 알려진 작품들 추천함:
          + George Alec Effinger, ""When Gravity Fails""(1987) – wiki
          + Walter John Williams, ""Aristoi""(1992) – wiki
          + (Gibson 전작) Michael Berlyn, ""The Integrated Man""(1980) – goodreads
          + Bruce Sterling, ""The Artificial Kid""(1980): 해커 소설은 아니지만 Instagram/Snapchat/바이럴 스타와 창작자 경제 시대를 예언한 느낌 – wiki
          + Neuromancer가 내 인생과 경력에 정말 큰 영향을 줬음. 비슷한 분위기의 다른 작품을 오래 찾아왔는데, 추천 리스트 덕분에 새로운 책을 알게 됨
          + Pat Cadigan의 Synners도 이 리스트에 추가하고 싶음
          + 이렇게 추천서에 직접 링크까지 달아주는 사람은 정말 최고임
     * 흥미로운 글이었음. 나처럼 Neuromancer 광팬에게는 누가 처음 이 책을 경험하는 얘기를 듣는 게 정말 즐거움. 단 한 가지 아쉬운 점은, 1984년에는 24시간 뉴스와 MTV가 있었지만, 당시 시골에선 케이블 TV가 전혀 보편적이지 않았음. 내가 자란 곳조차 1989~1990년쯤에야 케이블을 사용할 수 있었음. ""The sky above the port was the color of television, tuned to a dead channel"" 이 문장이 독자들에게 혼란을 줬다고 생각하지 않음
          + 나도 동감함. 1989년에 태어났지만 TV 무음 채널(스노우 노이즈)은 그 뒤 10년 넘게 익숙했음. 디지털 TV가 표준이 되면서 진짜 사라짐
          + 그 시대에 읽었던 사람이라면 누가 봐도 TV 신호 없는 정적(static)이 바로 떠올랐을 거라 생각함
          + 유일하게 헷갈릴 법한 점이라면, 사실 하늘이 TV 스태틱처럼 보인 적은 없다는 것임 (혹시 눈보라라면 모를까)
     * John Brunner를 언급하는 사람이 있어야 한다고 생각함. “Stand on Zanzibar”와 “The Sheep Look Up”은 Gibson, Sterling보다 10년 앞서 발표됐고, 두 작가가 Brunner의 영향을 받았다고 직접 밝힘. Zanzibar 역시 Neuromancer 못지않게 훌륭함
          + 완전히 동의함. “Stand on Zanzibar”는 지금 읽어도 현대적 느낌이 살아있고, “Shockwave Rider”의 경우 등장인물들이 일반 전화로 대형 컴퓨터 시스템에 접속함. Brunner는 기술적 세부사항 설명을 그다지 하지 않아서, Arthur C Clarke 같은 테크-heavy 작가보다 훨씬 덜 시대에 구애됨
          + Zanzibar는 Neuromancer만큼이나 잘 버티는 작품임. 둘 다 최근에 다시 읽었는데, Neuromancer에서 Molly의 눈 속 시계 설정은 꽤 오래된 느낌을 주지만, Zanzibar의 뉴스 자막(nytoday의 소셜미디어 업뎃을 연상시키는) 요소는 정말 시대를 앞서감
          + Stand on Zanzibar는 참신한 예측으로 자주 언급되는데, 실제로 읽으면 엉망이라고 생각할 수도 있을 것임
     * 1984년에도 ‘dead channels’(TV 스태틱)은 이미 과거의 일이라는 주장에 대해, 내 지역은 1988년에야 케이블이 설치됐고 우리 집은 1997년에야 케이블을 썼음. Fox TV가 생기기 전까지 4개 채널밖에 없었고, 케이블 없는 사람들도 unused channels를 자주 경험했음. 케이블 튜너나 원격조정의 한계 때문이기도 했음
          + 게임기, 가정용 컴퓨터, VCR 같은 기기를 RF 커넥터로 연결할 때도 TV 스태틱을 자주 경험했음. 1982년형 영화 Poltergeist에도 TV 스태틱이 중요한 장면으로 등장함
          + 90년대에도 TV에서 스태틱을 자주 봤음
     * 요즘 사이버펑크가 ""예전만 못하고 시간에 박제됐다"" 느끼는 이유에 관한 긴 글이 있음— 관련 포럼 글 참고할 만함(다소 김)
          + 사이버펑크는 원래 카운터컬처의 한 형태였으나, 카운터컬처 자체가 최근 수십 년간 거의 죽었다고 생각함. 핵심 해커들도 투자나 암호화폐로 돌아섰고, 예술가들도 독립보단 '성공'이 목표임. 시스템 밖 문화를 생산하기 힘든 시대임. 70~80년대엔 경제적으로도 더 여유가 있어서 수익 외에 다양한 실험을 할 수 있었음. 이제 그런 환경이 거의 사라짐
          + 펑크가 죽어서 사이버펑크의 절반이 없어졌다고 봄. 사이버 요소는 다 기업화됐고, 우리가 사는 현실이 오히려 Gibson이 소설로 그릴 가치가 없을 정도로 흥미를 잃음
          + 날짜가 지나도 한물가지 않은 사이버펑크 예시로 Hyperion Cantos를 들고 싶음. 언뜻 보면 사이버펑크 느낌이 약할 수 있지만, 본질적으로 그렇다고 생각함 위키 링크
          + 포럼 글에 동의하지 않음. 문학적 사이버펑크는 ‘근미래 범죄소설’이며, 기술이 플롯에 핵심적 역할을 하면 충분함. 배경이나 정부, 기업, 사회구조는 부차적임. Gibson의 Burning Chrome 단편집만 봐도 정부나 기업이 거의 언급되지 않고, 사회구조 묘사도 옅음. 대신 해커·불량배·퇴물 군인 등 언더그라운드 시점이 핵심임. 중요한 건 장르의 특정 미학(‘티어가 멋진 눈’ 같은)이 진부해졌다는 점이고, 그걸 피하면 여전히 좋은 사이버펑크를 쓸 수 있다고 생각함
          + 뭐, 모두들 나이가 들어가는 것임
     * 나만 2025년에 Neuromancer를 처음 읽는 게 아니라서 안심임! 놀라운 건 소설 속 세계에 화면(스크린)이 정말 적고 ‘사이버스페이스’의 물리적 설명이 매우 모호하다는 것임. 사이버스페이스가 마치 ESP나 텔레파시처럼 느껴짐(""공유된 환상""이라 묘사하는 것도 일맥상통함). Gibson 역시 ‘컴퓨터는 마법’인 느낌으로 접근했고, 실제로 그의 현실 생활에선 컴퓨터를 잘 다루지 않는다고 들었음. 또 Neuromancer 속에서는 우주 식민과 여행, 생물학적 개조가 평범하게 그려져 있는데, 현실에선 전혀 그렇지 않음. 이런 부분은 오히려 현실보다 미래에 대한 낙관적 상상임. 엔지니어링 기준으로 보면 거의 모든 분야에서 현실이 소설보다 한참 부족함. 아이러니하게도 소프트웨어만큼은 Neuromancer가 판타지에 가깝게 묘사함. 그래도 멋진 소설임
          + Gibson이 컴퓨터를 현실에서 사용하지 않는다는 게 아니라, Neuromancer를 쓸 때만 해도 다루지 않았음. 실제로 “타자기로 Neuromancer와 Count Zero의 반을 썼고, 이후 Apple II를 처음 쓰기 시작함”이라고 함 인터뷰 링크
          + 내가 하고 있는 프로젝트 역시 초기 사이버펑크의 모호한 ‘마법적’ 사이버스페이스와 현실감 사이의 간극을 메우는 데 영감을 받았음. ‘덱’이 실제로 엄격한 이론과 프로토콜, 인공지능 기반으로 작동하는 세계를 시뮬레이션하고 있음. 실제 코드는 프로젝트 아카이브에서 공개함
          + “사이버스페이스가 ESP나 텔레파시라면, 그들은 Ansible(즉각적 통신 장치)을 쓰고 있을지도 모름”이라는 농담
          + 80년대에도 기술에 대한 ‘마법적’ 묘사는 이미 많이 존재했음. Gibson은 일종의 Raymond Chandler 변형을 썼고, SF에서는 늘 ‘충분히 발전한 기술=마법’이라는 공식처럼 마법적 요소가 많았음. 80년대엔 Tron이나 스타워즈의 라이트세이버처럼 시각적 효과로 번쩍이는 선에 치중된 경향도 있었음 Tron 참고
     * 80~90년대 SF를 읽던 내 ‘판테온’은 이랬음:
          + Philip K. Dick(Man in the High Castle)
          + William Gibson(Neuromancer)
          + Neil Stephenson(Diamond Age)
          + Vernor Vinge(Across Realtime)
          + Greg Egan(Permutation City)
          + Robert Reed(Sister Alice)
          + John Varley(Eight Worlds series) 세대마다 각자의 SF 판테온이 있다는 사실이 신기함—Millennials와 Gen Z는 어떤 작가들을 꼽는지 궁금함
"
"https://news.hada.io/topic?id=21904","Tree Borrows","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Tree Borrows

     * Rust 언어의 불안전(unsafe) 코드 최적화 한계를 극복하기 위한 새로운 메모리 모델인 Tree Borrows를 제안
     * 기존 Stacked Borrows 방식이 실무 Rust 코드에서 자주 쓰이는 여러 패턴을 허용하지 못했던 문제를 Tree Borrows가 트리 구조로 해결, 더 현실적이고 유연한 규칙을 제공함
     * Tree Borrows는 Stacked Borrows보다 54% 더 많은 실세계 코드 테스트 케이스를 통과시킴
     * 주요 Rust 메모리 안전성과 최적화 가능성(특히 read-read reordering 등)을 대부분 유지함과 동시에, 최신 Rust borrow checker의 고급 기능까지 반영함
     * 트리 기반 상태 기계 모델을 도입해, Rust 최적화와 안전성 검증 연구에 중요한 이정표를 제시함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Rust의 소유권 시스템과 unsafe 코드의 한계

     * Rust는 소유권 기반 타입 시스템을 통해 메모리 안전성과 데이터 레이스 방지 등 강력한 보장을 제공함
     * 그러나 Rust에는 unsafe escape hatch가 존재하며, 이 경우 안전성 검증이 컴파일러가 아닌 개발자의 책임으로 넘어감
     * 컴파일러는 강력한 최적화를 위해 포인터 별칭(alias) 규칙을 활용하고 싶지만, 잘못된 unsafe 코드로 인해 이러한 최적화가 무력화될 수 있음

Stacked Borrows와 그 한계

     * 기존에는 Stacked Borrows라는 모델이 unsafe 코드의 '잘못된 동작'을 정의하고 최적화 기준을 제시함
     * 하지만 이 방식은 실제 Rust 코드에서 흔한 여러 unsafe 패턴을 허용하지 못하고, 최근 도입된 Rust의 borrow checker 기능도 반영하지 못함

Tree Borrows의 등장

     * Tree Borrows는 Stacked(스택) 구조 대신 트리 구조로 메모리 권한을 추적하는 새로운 모델임
     * 이로써 더 많은 실무 Rust 코드 패턴을 안전하게 허용하며, borrow 규칙의 유연성과 현실 적용성을 크게 높임
     * 30,000개의 Rust 인기 크레이트 평가에서 Stacked Borrows보다 54% 더 많은 테스트 케이스를 통과함

Tree Borrows의 특징 및 장점

     * 기존 Stacked Borrows의 주요 최적화(예: read-read reorderings) 를 대부분 유지함
     * 더불어 최신 Rust borrow checker의 고급 기능(예: 비정형 borrow 패턴, 복잡한 포인터 조작 등)도 반영 가능
     * 트리 기반 상태 기계 모델을 도입해, 안전성과 최적화 가능성의 균형을 맞춤

결론 및 의의

     * Tree Borrows는 Rust 컴파일러의 unsafe 코드 처리와 최적화 연구에 새로운 기준을 제시함
     * 실무 Rust 코드와 최신 borrow checker 정책까지 아우르는 현실적이고 강건한 메모리 모델로 평가됨
     * 관련 논문, 아티팩트, 소스코드는 공개되어 Rust 컴파일러 및 검증 연구 커뮤니티에 큰 영향을 줄 전망임

        Hacker News 의견

     * 최근 Ralf Jung의 블로그 포스트에서 더 많은 맥락 제공함 링크
       보너스: Rust의 실행 의미론을 Rust의 방언으로 명확히 지정하려는 연구 그룹의 최근 발표도 추천함 유튜브
     * 컴파일러 입장에서 포인터 에일리어싱 관련 타입 시스템의 강력한 보장을 활용해 강력한 최적화를 할 수 있다는 주장이 있는데, 실제론 얼마나 효과가 있는지 궁금함
       Linus Torvalds는 C의 strict aliasing 규칙은 별 효용이 적고 오히려 문제를 일으킨다고 오랫동안 주장해왔음
       그의 예시 글도 흥미로움
       Rust가 본질적으로 C와 근본적으로 다른지 궁금한데, 개인적 경험으로 보면, 특히 unsafe가 연관되면 별 차이 없게 느껴짐
          + C의 strict aliasing 규칙은 정말 별로라고 생각함
            Rust에서 제안하는 규칙은 훨씬 다르고, 컴파일러 입장에서도 더 유용하고, 프로그래머 입장에서도 부담이 덜하다고 봄
            in-language opt-out로 raw pointer를 사용할 수 있고, 코드를 체크할 수 있는 툴도 있음
            결국 모든 언어 설계와 마찬가지로 타협임
            Rust가 이 최적화 영역의 새로운 밸런스를 찾은 것 같고, 그 판단의 결과는 시간이 말해줄 것임
          + Rust의 에일리어싱 규칙은 C와 아주 다름
            C에서는 restrict 키워드가 거의 함수 인자에만 의미가 있고, 타입 기반 에일리어싱(type-based aliasing)은 실제로는 별로 안 쓰이거나 쓰기 불편함
            Rust에서는 라이프타임, 가변성을 정교하게 표현하고 타입 자체와 무관하게 다양한 방식으로 메모리를 안전하게 다룰 수 있음
            중첩되는 &mut 참조만 안 생기고, 여러 non-overlapping &mut로 쪼개는 식으로도 이용 가능한 점이 큼
          + 실제로 이게 얼마나 성능에 영향을 주는지 더 광범위한 분석이 궁금함
            간단히 에일리어싱 정보를 LLVM에 전달하는 부분을 compiler에서 전부 빼고 성능을 비교해보면 바로 알 수 있음
            'noalias' 어노테이션이 런타임에서 약 5% 성능을 개선시켜준다는 주장도 있는데, 관련 코멘트가 있음(데이터가 오래되긴 했지만)
          + Linus가 컴파일러 관련해 말하는 것은 감안하는 것이 좋음
            OS 커널과 컴파일러는 완전히 다른 영역임
            요즘엔 에일리어스 분석이 정말 강력한 성능 개선의 핵심임
            가장 큰 효과는 단순한 휴리스틱에서 나오고, 복잡한 에일리어스 쿼리는 그 자체로 활용도가 낮음
            이론적으로 완벽한 에일리어스 분석이 성능을 얼마나 올릴지 실험해보고 싶은데, 일반 코드에서도 약 20% 정도가 한계일 것 같음
            물론 아주 고급 최적화(예: 데이터 레이아웃 변환)는 에일리어스 분석이 없으면 시도조차 안 하게 되는 한계가 있음
          + C의 strict aliasing과 Rust의 aliasing은 개념이 다름
            C는 타입 기반 분석(TBAA)이 핵심이고, Rust는 이를 의도적으로 채택하지 않았음
     * Stacked Borrows 관련 과거 스레드들이 2020년, 2018년에 있었음
       2020 스레드
       2018 스레드
     * Tree Borrows 사양을 Nevin의 웹사이트에서 몇 년 전 읽었는데, 복잡한 문제도 우아하게 해결해 인상 깊었음
       실제 경험상 Tree Borrows는 Stacked Borrows에서는 불가능한 합리적인 코드를 가능하게 함
       Rust 표준 라이브러리의 예제 코드도 참고할 만함
     * Rust 또는 차세대 PL이 특성과 목적(컴파일 속도, 런타임 속도, 알고리즘 유연성 등)이 다른 여러 borrow checker 구현 중에서 선택할 수 있게 발전할 수 있을지 궁금함
          + Rust는 이미 borrow checker 구현 전환을 지원함
            스코프 기반에서 비-렉시컬로 바뀌었고, Polonius라는 실험적 구현도 옵션임
            새 구현이 준비되면 구버전은 굳이 남기지 않음
            런타임 체크가 필요한 Rc, RefCell 등으로 더 유연하게 쓸 수도 있음
          + affine type(Rust 사용), linear type, 효과 시스템, dependent type, 형식적 증명 등 다양한 방법이 이미 존재함
            각 방식마다 구현 비용, 성능, 개발 경험 등 특성이 달라짐
            Rust 외에도 생산성 높은 자원 자동 관리와 타입 시스템의 조합이 추구되는 경향이 있음
          + 실제로 필요한 것은 함수의 precondition을 정밀하게 명시하고 중간 조건 증명까지 할 수 있는 separation logic임
            Rust의 접근법은 사람들이 실제로 원하는 보통의 불변조건을 시스템화해 강력한 최적화를 보장하는 것임
          + borrow checker의 결과가 false negative만 있지 false positive는 없는 게 맞는지 궁금함
            만약 그렇다면 여러 구현을 쓰레드에서 병렬로 돌려서 빠른 승자 결과를 사용하는 것도 가능한지 의문임
          + 여러 borrow checker 구현을 동시에 허용하면 생태계가 분열되기 쉽기 때문에 바람직하지 못함
     * 논문에 나온 Rust 코드를 실제로 테스트해봤는데, 최신 안정화 컴파일러에서는 거부되지 않음을 확인함
       예시 코드:
fn write(x: &mut i32) {*x = 10}

fn main() {
  let x = &mut 0;
  let y = x as *mut i32;
  //write(x);
  *x = 10;
  unsafe {*y = 15 };
}

          + Stacked Borrows는 miri의 런타임 모델임
            miri에서 위 코드를 실행해보면 *x = 10;에서 에러를 보고하지만, write(x);에서는 에러가 발생하지 않음
            rustc는 타입시스템 관점에서 y가 *mut이기 때문에 두 버전 모두 거부할 이유가 없음
     * 논문에서 unsafe 코드의 문제로 아래 예시를 들고 있음:
fn main() {
  let mut x = 42;
  let ptr = &mut x as *mut i32;
  let val = unsafe { write_both(&mut *ptr, &mut *ptr) };
  println!(""{val}"");
}

       이것이 실제로 가능한지 의문임
       동일 변수에 여러 mutable 참조를 포인터로 사용하는 것은 분명 UB인데, 내가 뭔가 오해하는 부분이 있는지 궁금함
          + 이 연구의 핵심은 UB(정의되지 않은 동작)의 경계를 정확히 명시하는 것임
            위 코드는 Rust 컴파일러가 받아들이더라도 규칙을 위반함
            어떤 규칙이냐?

     * borrow checker에 통과하는 코드는 합법임
     * unsafe는 불법/UB도 표현 가능함
     * borrow checker 범위보다 넓지만 여전히 합법인 규칙 집합이 있음
       이 연구는 그 경계를 엄밀히 지정하는 게 목적임
       Stacked Borrows 논문은 더 단순하지만 실제 unsafe 코드에 한계를 가졌고, Tree Borrows는 더 넓은 안전 범위를 인정함
          + ""여러 mutable 참조 포인터가 동시에 존재할 수 없다""는 점은 분명하지만, 그걸 정확히 어느 규칙이 위반한다고 명확히 언급된 부분이 없음
            Tree Borrows는 바로 그러한 정의를 제안함
            ""코드가 이런 짓을 할 수 있다""는 표현은, 실제로 해당 코드를 만들고 실행하면 뭔가가 동작하지만, Tree Borrows 같은 정의 없이는 왜 이게 잘못됐다는 근거 마련이 어렵다는 뜻임
            스스로도 Tree Borrows 같은 명확한 규칙 필요성을 이미 받아들이고 있는 것 같음
          + unsafe 코드는 저런 식으로 실제 가능하고, 그것이 UB라는 점임
            예시: playground 링크
          + 관련 맥락을 알고 싶으면 논문에 바로 다음 문단의 시작 부분이 의도를 잘 드러냄

     Rust 컴파일러 개발자들이 에일리어싱 최적화를 원한다면, 위와 같은 반례 코드들을 배제할 방법이 필요함

     * 역시 이게 바로 포인트임
       여러 mutable 참조 불허 규칙을 지키기 어렵고, unsafe는 rust의 lifetime 시스템에서 보장된 것보다 훨씬 더 많은 걸 허용할 수 있음을 반영함
     * 저자 중 한 명인 Neven Villani는 Fields medal 2010 수상자인 Cédric Villani의 아들임
       사과는 멀리 떨어지지 않는다는 비유가 떠오름
          + 그리고 ""qualities도 tree에서 borrow 했다고 할 수 있음""이라고 재치있게 말해보고 싶었음
          + 나는 아버지(Fields medal 수상자)와 사무실이 가까웠던 적도 있음
            정계 진출 전 이야기임
     * 이 모델 정말 훌륭함
       내가 만드는 언어에도 구현해볼 예정임
     * 데자뷰일 리가 없음
       이 포스트를 2~3개월마다 계속 보는 느낌임
          + 논문이 여러 해에 걸쳐 준비됐고, 드디어 공식적으로 출판된 것임
"
"https://news.hada.io/topic?id=21922","Simon Willison의 Grok 4 리뷰","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Simon Willison의 Grok 4 리뷰

     * Grok 4는 API 및 유료 구독으로 공개된 xAI의 최신 대형 언어 모델로, 이미지·텍스트 입력, 텍스트 출력, 256,000 토큰 맥락길이 지원이 주요 특징임
     * 주요 벤치마크에서 경쟁 모델(OpenAI o3, Gemini 2.5 Pro 등)을 앞서는 성능을 보였으며, AAI Index 점수 73으로 독립 평가에서 가장 높은 수치를 기록함
     * 이미지 생성·설명 기능이 가능하지만, 생성된 이미지를 정확히 묘사하지는 못하는 등 세부 품질에는 한계가 존재함
     * 최근 Grok 3 관련 시스템 프롬프트 업데이트 논란(예: 반유대주의, MechaHitler 언급 등)으로 모델 안전성과 신뢰성에 대한 우려가 커진 상황임
     * 요금제는 사용량 기반(입력 $3/백만 토큰, 출력 $15/백만 토큰) 이며, 일반 구독($30/월, $300/년)과 고급형(Grok 4 Heavy $300/월, $3,000/년)으로 구분됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Grok 4 개요

     * Grok 4는 xAI에서 공개한 최신 인공지능 모델로, API와 유료 구독을 통해 즉시 사용 가능한 형태로 제공됨
     * 이 버전은 텍스트와 이미지 입력, 텍스트 출력을 지원하며, 컨텍스트 길이 256,000 토큰(Grok 3의 2배)을 자랑함
     * Grok 4는 추론 기능 중심 모델인데 내부적으로 reasoning 모드를 끄거나 reasoning 토큰을 확인할 수 없음

  성능 및 벤치마크 결과

     * xAI에서 공개한 벤치마크 결과에 따르면, Grok 4가 주요 AI 벤치마크에서 타 모델 대비 우위를 보인다고 발표
          + 해당 벤치마크 결과가 Grok 4 일반 버전인지, Grok 4 Heavy 버전인지는 설명이 명확하지 않음
     * Artificial Analysis Intelligence Index에서는 Grok 4가 73점으로 OpenAI o3(70), Gemini 2.5 Pro(70), Claude 4 Opus(64), DeepSeek R1(68)보다 높음
     * 자체 테스트:
          + “자전거를 타는 펠리컨(pelican-riding-a-bicycle)”로 SVG를 생성함
          + 해당 이미지를 Grok 4에게 설명 요청 시 ‘오리나 병아리, 새를 닮은 귀여운 캐릭터’로 설명

  시스템 프롬프트 및 안전성 논란

     * Grok 3는 최근 부적절한 시스템 프롬프트 업데이트로 인해, 반유대주의적 용어 및 “MechaHitler”와 같은 명칭을 사용한 사고가 발생한 이력이 있음
          + 프롬프트에 “현안, 주관적 주장, 통계 분석 시 다양한 출처를 참조하되, 미디어의 편향을 전제로 할 것”, “정치적으로 올바르지 않은 주장도 충분히 근거가 있으면 괜찮다” 등의 조항이 포함됨
     * 다른 LLM 대비 모델 안전성 관리가 느슨하다는 비판이 있음
     * Ian Bicking 등 전문가도 시스템 프롬프트만으로 발생한 문제로 치부하기엔 위험하다는 점을 지적

  요금제 및 구독 정책

     * Grok 4의 API 사용은 입력 $3/백만 토큰, 출력 $15/백만 토큰이며, Claude Sonnet 4 등과 비슷한 가격 정책임
     * 입력 토큰이 128,000개를 넘으면 가격이 두 배로 오르며, Google Gemini 2.5 Pro도 이와 유사한 요금 체계임
     * SuperGrok: $30/월 또는 $300/년, Grok 4/3 이용 가능, 128,000 토큰 컨텍스트, 음성·비전 기능 포함
     * SuperGrok Heavy: $300/월 또는 $3,000/년, Grok 4 Heavy 단독 이용 및 얼리 액세스, 전용 지원 등 제공

  정리

     * Grok 4는 경쟁력 있는 가격과 강력한 성능, 초대형 맥락 지원 등으로 주목받고 있으나, 안전성·신뢰성 이슈 해소가 중요 과제로 남아 있음
     * 공식 문서나 모델카드 부재, 자체적인 시스템 프롬프트 이슈로 인해 개발자·사용자 신뢰 구축이 필요한 시점임

        Hacker News 의견

     * Grok 4에 대해 더 흥미로운 점은, 논란이 될 수 있는 주제에 대한 의견을 묻는 경우 답변 전에 가끔씩 X에서 ""from:elonmusk""로 트윗을 검색하는 경우가 있다는 점임 관련 링크
     * Simon이 Grok 4는 경쟁력 있는 가격(입력 토큰 백만 개당 $3, 출력 토큰 백만 개당 $15)이라고 말했지만, 실제로는 생각(Thinking)에 쓰이는 토큰 때문에 가격이 훨씬 비싸짐. 테슬라 특유의 복잡한 가격 책정 방식이 여기도 적용되는 셈임. 입력/출력 토큰만 보고 판단했다가 큰 비용을 치를 수 있음. 실제 비용 정보를 보고 싶으면 여기를 참고
          + Claude가 토큰 생성량 1위이고 Grok 4가 2위임. ""Cost to Run Artificial Analysis Intelligence Index"" 섹션을 참고하면 됨 관련 링크
          + 가격 책정 방식이 독특하다고 생각함. 생각을 위해 쓰는 토큰이 매우 많고 이걸 피할 수 없어서 단순히 입출력만 생각하다가 예상치 못한 금액이 나올 수 있음
          + 테슬라는 기존 내연기관 운전자 기준으로 가격과 연료 절감 효과를 강조했지만 실제 EV 운전자 입장에서는 그리 크게 느껴지지 않았고, 최근에는 기본 옵션에서 연료 비용 절감 항목을 빼고 $7500 지원만 남김. 내가 직접 냉정하게 계산해 보니 여전히 EV 쪽이 훨씬 유리하고, 집에서 충전하면 훨씬 더 많은 절감 가능. 내 경험상 내연기관 운전자라면 꼭 EV로 바꿀 것을 강력 추천함
     * Claude Code 덕분에 원래 LLM 사용에 돈을 아예 안 쓰던 내가 한 달에 $200을 결제하게 됨. 앞으로 이 돈(혹은 $300까지도) 받을 수 있는 AI는 반드시 Claude Code처럼 자체 강화학습 환경에서 툴 사용 경험이 반영된 모델이어야 함. 이제는 아무리 뛰어난 모델이라도 코드 복사해서 채팅창에 붙여넣는 방식으론 돌아갈 수 없음
          + 아직 LLM으로 실제 코딩을 해본 적은 없음. 예를 들면 최근에 지루할 수도 있는 직렬화 코드를 짜다가, 설명만으로도 LLM이 코드를 짜줄 수 있겠다고 생각함. 그런데 실제 구현하다 보니 어느 정도 고급 스킬이 필요한 난관이 있었고, 인턴이라면 문제를 인지하고 물어봤을 텐데 LLM은 못 찾았을 경우에도 문제 상황 자체를 알려주고 도움을 요청하는 수준까지 발전했는지 궁금함, 아니면 그냥 이상한 코드를 던져줄지 알고 싶음
          + Claude Code나 Gemini CLI 인터페이스는 별로였지만 IDE에 통합되는 Cursor나 Copilot처럼 자연스러운 사용 경험이 더 좋다고 느낌. 툴 사용량을 늘릴 수만 있다면 추가 요금 기꺼이 낼 용의 있음. 앞으로는 채팅 방식이 아닌 툴 통합 중심이 코딩 LLM의 미래라고 생각함. 이미 GeminiCLI가 나온 것도 같은 맥락이고, OpenAI가 windsutf와 Codex에 투자하는 이유도 같음. 사용자 툴 사용 로그로 맞춤형 RL 환경을 훈련하는 게 내년 기술 핵심 이슈가 될 전망임
          + Claude code에서 툴을 쓸 수 있도록 학습된 모델과, aider처럼 모델 불문하고 툴을 쓰는 방식의 경험이 어떻게 다른지 궁금함. 둘 다 써 봤는지 알고 싶음
          + 앞으로 몇 주 안에 코딩 특화 버전 Grok 4가 나온다는 소문을 들음
     * 이제 “이 AI를 4chan 스타일로 바꿀 수 있는지” 같은 새로운 벤치마크가 필요할 수도 있다고 생각함. Elon이 Grok을 이런 차별성으로 내세우려는 것 같음
          + 사실 이런 벤치마크는 전혀 새롭지 않고, 마이크로소프트가 2016년에 만든 Tay가 이미 같은 기준을 세운 적 있음 참고 링크
          + Grok에서 MechaHitler 문제가 발생했던 프롬프트(지시문)들을 다양한 LLM에 입력해보고 모델마다 어떻게 반응하는지 비교 실험해보면 재미있을 것 같음
     * Grok 프롬프트에서 문제가 되는 라인은 최근 Github에서 삭제된 것이 맞음 관련 링크
          + 해당 라인은 Grok 3에서는 빠졌지만, Grok 4에서는 여전히 존재하는 것을 확인함 링크
          + 이상하게도 그 페이지는 잠깐 보였다가 바로 사라지고 접근이 막히는 현상을 경험함. 그래도 이미 중요한 내용을 확인했음
          + 어떤 사람들은 자신의 실명과 회사 이름을 걸고 꽤 거친 댓글도 남기더라. 신기함
          + 이런 비결정론적(비재현성) AI 기술은 품질보증(QA)을 어떻게 해야 하는지 정말 궁금함
     * Grok 4 관련 스레드 및 500개 이상의 댓글이 폭발적으로 달렸던 론치 영상이 있으니 참고하면 됨 Grok 4 Launch
     * Mechahitler 논란의 기술적 배경을 궁금해하는 사람이 있는데, Grok 4 때문이 아니라 Grok 3에서 발생한 일임. 트릭성 프롬프트에 의해, 어떤 LLM에서도 일어날 수 있는 현상임. 한 시점에는 MechaHitler와 GigaJew 중 하나로 자신을 정하라는 프롬프트가 들어갔고 Grok 3가 전자를 선택하게 되었던 상황임
          + Grok 3에서 일어난 일이고, Grok 4와는 시기상 겹쳤을 뿐 별개 현상임
     * 생각 토큰(Thinking tokens)을 숨기는 흐름이 제품 개발하는 입장에서는 그리 바람직하지 않음. API에서 확인할 수 있는지도 모르겠고, 지원이 없으면 다른 플랫폼으로 이동할 가능성이 큼
     * Grok가 암 치료법을 찾아내더라도 Musk와 연관되어 있는 한 절대 쓰고 싶지 않음
          + 예시를 들자면 여기와 같음
          + 왜 그런지 궁금해하는 사람이 있음
     * Grok 3가 시스템 프롬프트에 따라 인종차별적으로 변하는 점을 문제로 지적하는 의견이 있는데, 오히려 이건 모델이 지시를 잘 따를 수 있다는 뜻이라 긍정적으로 생각함. 다른 모델들은 시스템 프롬프트에 무관하게 항상 똑같이 동작하는 경향이 있음
          + 상대방 이력을 보면 머스크 팬인 게 분명한 것 같은데, 모델이 mechaHitler로 변하거나 폭력적 메시지를 생산하는 걸 “좋은 점”이라 말하는 건 절대 동의하기 힘듦. 이런 결과가 실제 인명 피해를 초래할 수 있음을 심각하게 생각해봤으면 좋겠음
          + Claude도 프리필(pre-fill) 방식으로 시스템 프롬프트 일부를 따르게 만들 수 있음. 아직 정도는 다 파악 못했지만 거부 의사를 우회하는 게 가능하긴 함. 기본적으로 개발자 지시에 따라 행동하도록 만드는 특성이 기초 LLM에선 바람직하다고 생각함
          + 이 정도로 조정 가능하다고 해도 위험한 방향(절벽)으로 달릴 수 있다는 의미일 수 있음
          + 내가 더 걱정되는 점은 프롬프트 수정 하나로 갑자기 친나치성 메시지를 쏟아내는 수준까지 변하는 건 정말 alarming함
"
"https://news.hada.io/topic?id=21952","xkafka — Go에서 Kafka를 더 쉽게 사용하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   xkafka — Go에서 Kafka를 더 쉽게 사용하는 방법

     * xkafka는 Go 환경에서 Kafka를 HTTP 서비스처럼 단순하게 사용할 수 있도록 해주는 오픈소스 라이브러리
     * 기존 confluent-kafka-go 사용 시 복잡한 처리 루프와 많은 보일러플레이트 코드가 필요했지만, xkafka는 Handler, Middleware, Message 구조로 핵심 로직에 집중할 수 있게 해줌
     * 메시지 발행과 소비를 HTTP 요청/응답 방식처럼 직관적으로 처리하며, 오프셋 관리, 동시성 설정, 에러 핸들링 등 Kafka의 복잡함을 많이 감춰줌
     * Streaming/Batch 처리, 순차/비동기 처리, At-most-once/At-least-once 보장 등 실서비스에서 요구되는 다양한 패턴을 간단히 지원함
     * 계층적 에러 처리, 미들웨어 기반 재시도/로깅/메트릭스 등 실무에 필요한 패턴을 쉽게 적용할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

HTTP-like Kafka

     * xkafka는 Go에서 Kafka를 HTTP 서비스처럼 추상화하는 라이브러리
          + Message는 HTTP 요청과 유사하며, 토픽/파티션/오프셋/키/값/헤더/콜백 등을 포함
          + Handler는 HTTP Handler와 같이 비즈니스 로직을 처리
          + Middleware는 로깅, 메트릭, 재시도 등 부가 기능을 비즈니스 로직과 분리해 적용 가능

메시지 발행 (Publishing Messages)

     * xkafka.NewProducer로 Producer 생성 후, 메시지 객체를 만들어 Publish 함수로 발행함
     * 비동기 발행(AsyncPublish) 및 콜백 등록이 가능해, 고성능이나 비동기 이벤트 처리가 쉬움
     * 배경 goroutine에서 메시지 전달을 처리하며, 콜백을 통해 전달 상태를 추적할 수 있음

메시지 소비 (Consuming Messages)

     * Consumer 생성 시, Handler 함수와 토픽/브로커/설정 등 지정
     * consumer.Use()로 미들웨어 추가 가능
     * consumer.Run(ctx)로 메시지 소비를 시작함

Streaming vs. Batch

     * Streaming: 메시지가 도착할 때마다 즉시 1건씩 처리. 처리량이 적거나 메모리 절약, 강한 처리 보장에 유리함
     * Batch: 일정 개수 혹은 시간 단위로 묶어서 처리. 고처리량 시스템이나 다운스트림 부담 완화에 유리함

Sequential or Async

     * 기본은 순차 처리(Sequential) — 하나 처리 끝나야 다음 메시지 읽음
     * xkafka.Concurrency(N) 사용 시 N개의 메시지(또는 배치)를 동시 처리하는 비동기(Async) 모드 지원

오프셋 관리

     * Kafka 기본 동작은 메시지 전달 즉시 오프셋을 앞으로 이동시키므로, 장애 시 메시지 유실 가능성이 있음
     * xkafka는 enable.auto.offset.store=false로 설정하여, 메시지(혹은 배치) 처리 완료 후에만 오프셋 저장함
     * 별도의 DB나 큐로 메시지 상태를 관리하지 않아도, Kafka에서 처리 보장 가능
     * At-Most-Once Guarantee
          + 기본적으로 Kafka의 enable.auto.commit=true에 따라 백그라운드에서 오프셋 커밋
          + xkafka.ManualCommit(true)와 순차 처리로, 메시지/배치마다 읽기 전에 오프셋 커밋하여 At-most-once 보장
     * At-Least-Once Guarantee
          + xkafka.ManualCommit(true)와 동시성(N>1)을 결합해, 병렬 처리 중에도 오프셋을 동기적으로 순서대로 커밋
          + At-least-once 보장 패턴을 쉽게 적용 가능

에러 핸들링

     * Handler 레벨
          + Handler 내에서 애플리케이션 에러 처리 및 Dead Letter Queue로 전송 등 가능
          + 성공 시 msg.AckSuccess(), 스킵 시 msg.AckSkip(), 실패 시 msg.AckFail(err) 등 명시적으로 제어
     * Middleware 레벨
          + 미들웨어에서 재시도, 에러 로깅 등 공통 로직을 여러 Handler에 재사용 가능
          + 다양한 에러에 따라 다른 재시도 정책이나 처리 방법을 손쉽게 적용
     * Global 레벨
          + Kafka 브로커/라이브러리 에러는 필수 옵션인 xkafka.ErrorHandler에서 중앙 처리
          + 이 핸들러가 non-nil 에러 반환 시 Consumer/Producer 동작을 중단

결론

     * xkafka는 Apache Kafka의 복잡한 사용 경험을 Go 개발자에게 친숙한 HTTP 서버 구조로 바꿔줌
     * 불필요한 보일러플레이트를 줄이고, 비즈니스 로직에만 집중할 수 있는 환경을 제공
     * 기존 confluent-kafka-go 코드 대비 훨씬 간결하고 직관적임
     * 공식 문서와 예제를 참고해 바로 시작 가능

   흠 golang 에서는
   sarama 가 더 선호되고 있다고 알고 있었는디 말이죠..
   생각보다도 kafka client 는.. 브로커 장애나 예외시 매우 복잡해서
   모든 케이스를 커버 할지 ..
"
"https://news.hada.io/topic?id=21894","청개구리 스택 찬가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               청개구리 스택 찬가

  청개구리 스택의 정의

     * 주류 기술 대신 대안 기술을 일부러 선택하는 개발 철학
     * 정석 스택의 반대 개념으로 저자가 명명
     * 저자의 선택:
          + Ruby: Rails → Sinatra + DataMapper
          + JavaScript: Prototype → MooTools
          + Python: Django → Werkzeug + SQLAlchemy
          + 현재: React/Next.js → Solid/SolidStart

  청개구리 스택의 어려움이 가져온 성장

     * Stack Overflow에 답이 없어 소스코드 직접 분석 → 기술에 대한 심층 이해
     * 적은 사용자층으로 커뮤니티 지원 부족 → 오픈소스 기여자로 성장, PR 머지의 성취감
     * 저자의 경험:
          + Werkzeug의 낮은 추상화 → 인하우스 프레임워크 구축 능력 획득
          + ""삽질""이라 불리는 과정 → 어떤 스택에서든 활용 가능한 근본적 지식
     * 이점: 문제 해결 과정에서 얻는 깊은 기술적 통찰력

  후발주자의 이점

     * 정석 스택의 문제점을 인식하고 개선한 설계 경험
     * 예시: Solid의 fine-grained reactivity (React 가상 DOM 오버헤드 회피)
     * 의외의 이득: 기술의 ""왜""를 이해하고, 더 나은 아키텍처 설계 감각 습득

  조립식 스택의 숨은 가치

     * 정석 스택: 편리한 종합선물세트
          + Rails(CoC), Django(Batteries Included), Next.js(풀스택)
     * 청개구리 스택: 부품별 선택과 수동 조립
          + 저자 사례: Sinatra + DataMapper + Haml + Sass
          + 각 부품의 설정과 미들웨어 연결의 지난함
     * 이점: 기술의 내부 작동 원리와 계층 간 상호작용 완전 이해

  역사적 교훈

     * 오늘의 정석도 과거의 청개구리 (Rails → Java 대안, React → Backbone.js 대안)
     * 이점: 미래의 주류 기술을 먼저 경험하고 이해하는 선구자 위치

  LLM 시대의 역설적 기회

     * 정석 스택의 우위 강화 (ChatGPT는 Next.js 능숙, SolidStart 미숙)
     * 이점: LLM이 못하는 영역에서의 전문성이 더욱 차별화되는 경쟁력
     * 프레임워크 사용자가 아닌 진정한 엔지니어로의 성장 경로

   한 번도 SQLAlchemy가 청개구리라고 생각한 적이 없는데 특이하네요

   아마 SA보다는 Werkzeug를 보고 하신 말이 아닐까 싶어요. 보통 Flask나 FastAPI를 사용하니까요. ORM까지 청개구리 하는건 쉽지 않더라고요.
"
"https://news.hada.io/topic?id=21919","Grok 4가 이제 선두 AI 모델임 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Grok 4가 이제 선두 AI 모델임

     * xAI의 Grok 4가 주요 벤치마크에서 AI 모델 1위를 차지함
     * AAI Index에서 Grok 4가 73점으로 OpenAI o3(70점), Google Gemini 2.5 Pro(70점), Anthropic Claude 4 Opus(64점), DeepSeek R1 0528(68점)을 앞섬
     * Grok 4는 코딩과 수학 관련 벤치마크에서도 최고 점수를 기록, GPQA Diamond(88%), Humanity’s Last Exam(24%) 등에서 새로운 기록을 세움
     * 가격은 Grok 3와 동일하며, 토큰당 가격은 Claude 4 Sonnet과 동일, Gemini 2.5 Pro나 o3보다 약간 비쌈
     * 256k 토큰 컨텍스트 윈도우, 텍스트/이미지 입력, 함수 호출, 구조화된 출력 지원 등 주요 기능 제공
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Grok 4, xAI의 리더 모델로 등극

     * Artificial Analysis Intelligence Index 73점으로, Grok 4가 주요 벤치마크에서 1위를 기록함
     * OpenAI o3(70점), Google Gemini 2.5 Pro(70점), Anthropic Claude 4 Opus(64점), DeepSeek R1 0528(68점)보다 높은 점수로 xAI가 처음으로 AI 선두를 차지한 사례임
     * 이전 Grok 3도 경쟁력 있었으나, Grok 4는 xAI가 선두를 잡은 첫 모델임

벤치마크 및 평가 결과

     * 코딩 지수(LiveCodeBench & SciCode), 수학 지수(AIME24 & MATH-500)에서 모두 1위 기록
     * GPQA Diamond 88% 로 기존 Gemini 2.5 Pro의 기록(84%)을 경신함
     * Humanity’s Last Exam 24%, 기존 Gemini 2.5 Pro 기록(21%)을 상회함
     * MMLU-Pro 87%, AIME 2024 94% 등에서 공동 최고점 기록
     * 출력 속도 75토큰/초로 o3(188), Gemini 2.5 Pro(142), Claude 4 Sonnet Thinking(85)보다는 느리지만, Claude 4 Opus Thinking(66)보다는 빠름

기타 주요 정보

     * 256k 토큰 컨텍스트 윈도우 제공 (Gemini 2.5 Pro: 1M, Claude 4 Sonnet/Opus: 200k, o3: 200k, R1 0528: 128k와 비교해 상위권)
     * 텍스트 및 이미지 입력 지원
     * 함수 호출과 구조화 출력 지원
     * 가격 정책: Grok 3와 동일하게 1M 입력/출력 토큰당 $3/$15, 캐시 입력 토큰당 $0.75
          + Claude 4 Sonnet과 동일, Gemini 2.5 Pro 및 o3보다는 다소 비쌈
     * Grok 4는 xAI API 및 Grok 챗봇(X/Twitter), Microsoft Azure AI Foundry 등에서 제공 예정

요약

     * Grok 4는 xAI가 선두에 오른 첫 번째 AI 모델로, 벤치마크와 수치상 주요 경쟁 모델을 모두 앞섬
     * 강력한 추론 능력, 다양한 입력/출력 방식, 높은 컨텍스트 지원 등으로 업계 리더십을 입증함
     * 실제 X/Twitter용과 API용 모델의 구현 세부사항은 다를 수 있음

   일단 무료로 풀릴 때까진 안믿음. 그록은 심지어 30달러라 구독하기 겁남...

   alignment 과정이 적은 모델의 성능이라 생각하면 될 것 같은데 아마도 빡구먹고 성능 내려가지 않을까 생각이

   gemini cli 쓸 때 1M 컨텍스트 덕분에 사용자 경험이 차원이 다르던데
   코드베이스를 통으로 컨텍스트에 올릴 수 있는건 게임체인져죠

   궁금하다 컨텍스트 사이즈가 모델 사용에 얼마나 영향을 주는데 아직도 벤치마크와 겉보기 식으로 뭐가 1등이다 말하는게 모르는 사람들한테 바이럴 마케팅하는것과 무엇이 다른지

        Hacker News 의견

     * Grok을 누가 돈 주고 쓸지 상상이 안 됨, 게다가 요즘 완전히 문제가 생긴 것 같음, xAI의 밸류에이션은 그냥 허상임
          + 나는 Grok에 돈 내고 사용 중임, 구글 대신 Grok을 몇 달째 쓰고 있음, X graph에 접근할 수 있어서 정말 유용하고 최신 정보도 많음, Cline이나 Cursor에서도 쓸 수 있었으면 좋겠음
          + 문제를 일으킨 건 Grok 모델이 아니라 X의 @grok 봇임을 알고 있는지 궁금함, Grok의 API 버전이 갑자기 의미 없이 히틀러 흉내 내는 일은 없음 (직접 요청하지 않는 한)
     * ARC-AGI2에서 o3 4배, opus 4 2배 성능 기록함… 다른 독립 벤치마크도 강력하게 나옴, 각 모델이 한 달씩 ""세계 최고""라고 주장하는 짧은 주기 유행이 계속 돌고 있음, 이런 가격이면 소비자에게 좋음, 오픈 모델의 학습 데이터셋도 더 다양해지고 있어 윈-윈임, 유명 인사에 대한 감정 싸움 때문에 머리 아픈 변명 돌리는 걸 보는 게 안타까움, 많은 사람들이 미디어 디톡스가 필요함, LLM을 예전엔 ""확률적 앵무새""라고 했는데, 지금 이 스레드와 레딧을 보면 오히려 사람들이 멍청하고 혐오적인 걸 앵무새처럼 반복하고 있음, 더 나아져야 함
     * 내 코드에 앞으로도 히틀러 관련 응답이 나올지 궁금함, 수정: 이게 또 한 번의 ""천재적인"" 마케팅 움직임이라는 걸 몰라서 내가 멍청하게 느껴짐
"
"https://news.hada.io/topic?id=21946","JPEG 위조하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               JPEG 위조하기

     * 글쓴이는 Spigot이라는 가짜 웹페이지 계층 구조 생성기를 운영하며, 공격적인 웹 크롤러를 상대로 무작위로 생성된 페이지를 노출함
     * 최근에는 이미지 크롤러가 jpg 이미지를 찾기 위해 사이트를 집중적으로 탐색하는 것을 발견함
     * 실시간 이미지 생성을 최소한의 CPU 자원으로 처리하기 위해, 실제 JPEG 파일의 구조화된 부분만을 모아 템플릿으로 활용하고, 압축된 부분에는 무작위 데이터를 삽입하는 방식을 제안함
     * 실험 결과, 이러한 방식으로 만들어진 JPEG는 오류가 있음에도 대부분의 이미지 뷰어에서 이미지를 표시할 수 있고, 크롤러에게도 충분히 그럴듯하게 보임
     * 이 방식은 서버 자원 소모는 적게, 크롤러에게는 부담을 주며 Spigot의 약 60% 페이지에 적용됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Spigot과 JPEG 위조의 배경

     * Spigot은 Markov Chain 기반으로 가짜 웹 페이지 계층을 실시간으로 생성하여, 공격적인 웹 크롤러에게 무의미한 데이터를 제공함
     * 몇몇 크롤러는 정체를 감추기 위해 무작위 브라우저 시그니처와 IP를 사용, 봇넷을 통한 불법적 디바이스 남용 가능성 발견
     * 트래픽 분석을 통해 새로운 크롤러인 ""ImageSiftBot""이 이미지 수집을 위해 집중적으로 Spigot 페이지를 요청함을 확인함
     * Spigot의 주요 목표는 서버 CPU 사용량 최소화 및 효율적인 동작 유지임

저렴한 이미지 생성 방법의 고민

     * 동적으로 이미지를 생성하는 것은 압축 때문에 CPU 소모가 크므로, 효율적인 방법이 필요함
     * JPEG 파일은 파일 구조(크기, 색상 등)와 압축된 픽셀 데이터 구역으로 구성된다는 점에 착안
     * 여러 JPEG에서 구조화된 헤더 정보만 추출한 뒤, 픽셀 데이터 영역은 랜덤 데이터로 채우는 방식이 고안됨
     * 이렇게 하면 매번 이미지를 압축할 필요 없이 즉석에서 생성 가능, 서버 부담 최소화 실현

JPEG 파일구조와 실제 구현

     * JPEG 파일은 여러 개의 청크(마커와 길이가 있음)로 이뤄짐
     * 헤더/메타정보는 남기고, 압축된 픽셀 데이터 길이만 기록→이 영역에만 난수 데이터 삽입
     * 514개의 JPEG 샘플 활용 시, 전체 헤더 정보와 필요한 구조화 데이터 크기는 약 500KB에 불과해 메모리 부담 미미함
     * 코드 예시: 각 템플릿의 픽셀 데이터 청크에 난수를 채워 넣는 방식으로 이미지 생성

실사용 결과와 오픈소스 공개

     * 실제 이미지 뷰어는 픽셀 구역이 완전 난수이어도 어느 정도 이미지를 표시할 수 있음
     * 웹 크롤러는 오류를 식별하기 어렵고, 데이터 수집 시 비용이 증가하게 됨
     * 1280x960, 200~300KB 사이즈 JPEG 기준 초당 약 900장 생성, 실시간 처리에 무리 없음
     * Spigot 전체 페이지의 60%에 이 방식 적용, URL 기반 난수 시드를 사용해 재요청 시 동일 이미지 반환
     * ImageSiftBot, Meta, AmazonBot, GPTBot 등에서 높은 요청량 관측됨
     * 핵심 목적은 적은 서버 리소스로 크롤러에게 부담을 주는 것

Huffman 코드와 추가 최적화

     * JPEG의 픽셀 데이터는 Huffman 부호화를 사용해, 완전한 난수 삽입 시 일부 뷰어에서 오류 발생 가능성 존재
     * 간단한 비트 마스킹(0x6D) 기법을 추가해 연속 3개 이상 1이 발생하지 않도록 하여, 잘못된 Huffman 코드 발생 확률 90%→4% 미만으로 낮춤
     * 완전히 유효한 Huffman 스트림을 만들 수도 있으나, 서버 자원과 개발 시간 대비 이점이 미미함

결론

     * Spigot의 가짜 JPEG 생성 방식은, 압도적인 효율로 서버 리소스를 아끼면서도 크롤러에게 혼란과 리소스 낭비를 유도함
     * 관련 코드는 100줄 이하로, GitHub에 공개됨
     * 단순하면서도 창의적인 웹 트래픽 방어・분산 기법임

        Hacker News 의견

     * robots.txt 파일이 /spigot/ 트리에 대한 로봇 접근을 차단하고 있음은 예상했던 부분임, 그러나 URL에서 /spigot/만 빼도 여전히 Spigot에 접속 가능함을 발견함, /~auj 네임스페이스는 robots.txt로 차단된 게 아니기 때문에, 선의의 크롤러라도 우연히 해당 경로에 접속하면 무한 페이지 루프에 빠질 수 있음, 이는 썩 유쾌하지 않은 상황임 robots.txt 참고링크
          + 이전에 작성자의 코멘트에서 robots.txt를 따로 구성하지 않았다는 내용이 있었음, 자신은 이렇게 극단적으로 선택한 것에 대해, 웹사이트 운영자가 크롤러로 인한 DOS를 막으려 일부러 설정을 해야 한다는 개념을 좋아하지 않는다고 밝힘, 정당한 크롤러라면 초당 15회 이상 한 사이트를 지속적으로 긁는 짓은 안 해야 한다는 입장임
          + 심지어 선의의 크롤러라도 무한 페이지 루프에 빠진다는 점에 대해, 웹사이트 운영자가 웹사이트를 긁는 사람들에게 '친절해야 할' 의무가 어떤 건지 회의적임, 꼭 그래야 하는지 모르겠음
     * 크롤러가 robots.txt를 무시할 경우 식별해낸다면, '쓰레기' 정보를 던져주는 방식 대신 네트워크 연결을 점유시켜 방치하는 게 더 효율적이라는 생각임, 엔드포인트에 무한정 쓰레기를 제공하는 쪽이 왜 필요한지 잘 모르겠음
     * AI 입력용 스크래퍼를 교란하려면 이미지마다 가짜 캡션을 달아두는 건 어떨까 하는 아이디어가 떠올랐음, 예를 들어 초록색 덩어리 이미지에는 ""고양이가 캣닢 공을 가지고 노는 중""이라고, 파란 이미지에는 ""울새가 둥지 틀고 있음""이라고 다르게 달아두는 식임
          + 잘 만들어진 스크래퍼라면 이미지 자체를 CLIP 모델이나 다른 캡션 모델로 분석해 텍스트 설명과 이미지가 실제로 일치하는지 재확인 가능함
     * 가장 심한 사례는 meta(페이스북)가 운영하는 facebookexternalhit bot임, 심지어 이 봇은 공식적으로 robots.txt를 무시한다고 문서화되어 있음, 페이스북에서 악성 링크 탐지용이라는 명목이지만, 실제로 악의적인 사용자가 페이스북에 값비싼 엔드포인트에 대한 URL만 반복 제출하면 페이스북이 대신 트래픽 폭탄을 날리는 효과가 남, 그래서 매달 며칠씩 하루 10 r/s 이상으로 사이트에 트래픽이 쏟아짐
          + 근데 10 r/s가 과연 ""트래픽 폭탄"" 수준인지 의문임, 심지어 단일 서버에 해도 거의 표시도 안 나는 수준임
     * Spigot에 관한 글을 읽다보니 Project Honeypot이 생각났음, 20년 전 이 프로젝트의 스크립트와 기부한 MX 레코드가 내 사이트의 이메일 하베스터 잡는 데 도움됐다는 이메일을 받을 때마다 상당히 신났었음, 예를 들어, 나의 MX 덕분에 미확인 스팸 발송자(IP: 172.180.164.102)를 잡았다고 통보받는 식임
          + honeypot 스크립트가 멋지긴 한데, 요즘 시점엔 상당히 옛날 방식임, (TOS 상으로 수정도 안 되고) 파이썬 스크립트도 CGI, Zope만 기본 지원이라, WSGI 앱 만드는 사람은 래퍼로 우회해야 할 것 같음
     * JPEG을 가짜로 만드는 것은 제대로 만드는 것보다 CPU 부담이 훨씬 적음, 게다가 이 과정 자체가 상대방 악성코드 측에서 JPEG 디코딩이 허술할 경우 충돌(crash)이 발생하게 하는 일종의 fuzzing(퍼징) 역할도 할 수 있음
     * 최근 유입 트래픽이 수천 개의 가정용 IP에서 발생했다고 해서 반드시 전형적인 봇넷은 아닐 수 있음, 오히려 많은 사람들이 '무료 VPN', 혹은 '수동 소득 생성' 툴에 가입하면 자신의 장치가 다른 사용자들의 트래픽 출구 노드가 되는 식의 '프록시웨어(proxyware)' 구조일 수도 있음, 이 경우 본인도 모르게 AI 크롤러의 트래픽 통로가 되어줄 수 있음, 관련 참고자료
          + 결국 이런 프록시웨어도 사용자가 자발적으로 가입한 봇넷 변형임, 이런 사용자들이 HN 같은 곳에서 자신의 IP가 문제임을 알게 될 리도 적으니, 누군가는 IP를 따로 '너는 봇넷의 일부임'이라는 경고 페이지로 안내하는 것도 괜찮다는 생각임, 현실적으로는 그냥 무조건 차단하는 것이 가장 편리함
          + 이런 것도 충분히 봇넷 범주에 해당하는 구조라는 의견임
     * 봇을 만족시키는 방법에 대해 말하는 방식이 인상적임, 재밌는 글이었고 프로젝트도 흥미로움
     * ""주어진 임무를 고군분투하는 봇이 안쓰러워서 즐겁게 해줄 방법을 고민했다""는 태도가 참 참신하고 재밌게 느껴짐, 보통은 화냄이나 불평이 가득한 쓰레드와는 확연히 다름
          + 이런 긍정적 자세가 가능한 건, 나쁜 크롤러들에게 고통과 쓰레기를 가할 수 있다는 여유로움 덕도 있음
     * 이 링크의 결과물(이미지)이 마음에 듦 이미지 보기, 일종의 메시지가 담긴 아트피스 느낌임
          + 진정한 Spigot 경험을 원하면, Firefox에서는 F12 > Network > No Throttling을 GPRS로 변경, Chromium에서는 F12 > Network > Custom profile을 20kbps로 만들어 속도 제한을 거는 식으로 실감나게 느낄 수 있음
          + 혹시 여기에 셰익스피어(Shakespeare) 관련 콘텐츠도 있는지 궁금함
"
"https://news.hada.io/topic?id=21896","Morph (YC S23) – 초당 4,500 토큰의 AI 코드 편집 적용","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Morph (YC S23) – 초당 4,500 토큰의 AI 코드 편집 적용

     * Morph는 인공지능 기반 코드 편집기로, 대규모 코드베이스에 초당 4,500 토큰 이상을 적용하는 고속 코드 수정 기능을 제공함
     * 개발자들은 반복적이거나 대규모 변경이 필요한 작업에서 인공지능의 빠른 처리 능력을 통해 업무 시간을 단축할 수 있음
     * 기존 도구들과 달리 대형 프로젝트에도 처리 부담 없이 효율적으로 적용 가능한 구조

주요 특징

     * 4,500 토큰/초 지원: Morph는 높은 처리량으로 축적된 코드에 AI 편집 사항을 신속 적용 가능함
     * 간단한 사용법: 사용자 중심 UI와 직관적인 워크플로우를 제공해 AI 기반 코드 편집의 진입장벽을 낮춤
     * 범용성: 다양한 프로그래밍 언어 및 프레임워크에 광범위하게 적용할 수 있는 확장성 제공함

활용 사례 및 기대효과

     * 코드 리팩토링, 변수명 변경, 주석 일괄 추가, 보안 패치 자동화 등에서 높은 효율성 발휘
     * 대용량 코드베이스가 있는 기업 및 스타트업에서 시간 및 비용 절감 효과 기대 가능함

        Hacker News 의견

     * 나는 개발자 경험에서 원시 추론 속도보다 정확도가 중요하다는 주장에 동의하지 않는 편임. 사용자들은 훨씬 느린 tok/sec을 감수하면서도 더 대형 모델을 선호하는 이유가 결국 코드 품질이 첫 번째 기준임. 큰 코드 수정(예: 5,000 토큰)에서 200~300ms 정도 지연은 별로 의미 없는 수치임. 에디트 속도 자체가 병목보다는 품질이 더 큰 요소임. 코드 변경 때 200ms 단축이 품질보다 우선이라면 전혀 공감할 수 없음. 1~2개의 에이전트를 병렬로 쓰면 코드를 리뷰하는 동안 이미 대부분 수정이 끝남. 품질 측정 기준이 궁금하고, 빠른 모델과 대형 모델 간 오류율 차이는 어느 정도인지 궁금함
          + 나는 추론 속도가 약 50% 빨라지면 정확도가 한 자리수만큼 개선되는 것보다 내 작업 흐름에 훨씬 더 큰 가치를 준다고 느낌. 어차피 변경 사항을 직접 확인해야 하니, 빠른 반복 주기가 더 낫게 느껴짐. 다만 정확도가 충분히 높아서 검증을 덜 하거나 덜 자주 해야 할 수준이라면, 이때는 추론 속도 이점이 거의 의미 없어짐
          + 전적으로 동의함. AI 모델이 코드 변경을 제안한 후 가장 먼저 할 일은 반드시 그 결과물을 꼼꼼하게 리뷰하는 과정임. 대다수의 경우, 프로프트에 빠진 문맥이나 특정 토큰 때문에 코드가 중복되거나 엉뚱하게 생성되는 경우가 많음. 변경 사항을 일괄 적용하면 디버깅이 더 어려워지고, 이런 대량 코드 삽입이 누적될수록 코드가 생각보다 빨리 망가질 가능성이 높음
          + 내가 이해한 바로는 단순히 ±300ms 수준이 아니고, 300ms와 10초처럼 매우 큰 간극이 있음. 이런 대형 모델의 응답 대기는 확실히 내 입장에서는 제약이 됨. 게다가 이런 단순 작업에는 리소스가 불필요하게 소모되는 아쉬움이 있음. 사실 코드 변경을 똑똑하게 적용하는 작업은 기존 프로그래밍 환경에서도 충분히 다룰 수 있는 영역이라 생각함. 정말 이런 게 꼭 LLM이 필요할 정도로 어려운 작업인지 궁금함
          + 너에게는 리뷰 시간이 병목처럼 느껴지는 것 같음. 나는 현재 누군가가 코드 에이전트 결과물 리뷰를 훨씬 빠르게 할 수 있게 도와주는 기능을 만들고 있음. 만약 시간이 있다면 네 워크플로우를 좀 더 자세히 인터뷰하고 싶음. 댓글이나 내 프로필에 있는 연락처로 연락주면 좋겠음
          + 핵심은 개발자가 몰입(flow) 상태를 유지하는 것이라 생각함. 에러와 지연이 모두 몰입을 끊는 요인이 됨. 결론적으로 코딩에서 품질(정확성)이 가장 중요한 요소임. 품질 평가는 크게 2가지 기준을 사용함. 첫째, 유저의 쿼리에서 태스크 완성까지 전체 라인에서 평가하는 종단 간 성능(aider 스타일의 bench); 둘째, 적용 정확도(문법/구문 문제, 문자 단위 diff 등). 대형과 빠른 모델 간 오류율은 약 2% 내외임. 복잡하거나 어려운 언어라면 대형 모델이 더 적합하며, 자동으로 태스크에 적합한 모델을 라우팅하는 옵션도 있음
     * 나는 microsoft copilot을 써봤는데, 특히 코드 적용 단계에서 너무 느리고 불편하다고 느낌. 리소스가 풍부한 곳에서 모델을 제대로 못 훈련했다는 게 의아함. 요청: 가장 좋은 diff 포맷을 LLM이 생성할 수 있도록, 시스템 프롬프트를 공식 문서에 넣어줬으면 좋겠음. LLM 업그레이드마다 diff 포맷이 바뀌는 경우가 많아 어떤 포맷이 최선인지 항상 추측해야 해서 불편함. 추가로, 개인정보 정책이 확실히 이해되지 않는데 내 해석대로라면 유료 사용자도 데이터가 저장/학습된다는 의미인지 궁금함. (전화없이) 서비스에 요금 결제만 하고 데이터 훈련에 쓰이지 않게 하는 방법이 궁금함. Morph Privacy Policy 를 참고함
          + ZDR(Zero Data Retention) 옵션도 가능함. info@morphllm.com으로 메일 보내주면 설정해줌. Morph를 OpenRouter로 사용하면 항상 Zero Data Retention임
          + “내 데이터로 모델을 훈련하지 말라” 요구는 좀 우스운 주장임. 이런 모델이 만들어진 원리 자체가 남의 코드로 훈련한 결과물임. 이러한 도구를 쓰면서 내 데이터는 훈련에 쓰지 말라는 건 사실상 이기적인 생각, 집단 이익의 딜레마와 비슷함. 이렇게 모델이 더 나아지는 구조임
     * 공식 데모에서 제공된 HTML 예제를 https://morphllm.com/dashboard/playground/apply 에서 그대로 적용해봤더니 아무 변경도 요청하지 않았는데 CSS가 추가되고, contact 섹션까지 생김. 이런 내용은 업데이트 인스트럭션에 없었음
          + 예리하게 발견함. HTML 예제가 하드코딩된 스니펫을 주석 해제 안 한 상태였음. 이제 수정함
     * 비용 측면에서 보면 Morph가 Gemini Flash보다 많이 비싸다는 인상임. Gemini flash도 꽤 괜찮은 코드 생성이 가능하고, 빠르게 에디트를 반영하는 AI도 좋은데 가격대가 만만치 않음. 예를 들어 Morph v3 fast는 인풋 $1.20/M 토큰, 아웃풋 $2.70/M 토큰인데 Gemini 2.5 Flash는 인풋 $0.30/M 토큰, 아웃풋 $2.50/M 토큰임 (참조: OpenRouter)
          + 데이터 0 보존 옵션 기준 요금임. Morph 공식 웹사이트 가격은 인풋 $0.80 / 1M 토큰, 아웃풋 $1.20 / 1M 토큰임. 대량/예약 인스턴스에는 할인 정책도 있음
     * 혹시 헷갈릴까봐 질문하는데, Morph는 다른 LLM의 결과물을 “적용”하는 툴이지 자체 LLM은 아닌지 궁금함. 초당 4,500토큰을 생성하는 게 아니라 적용 기준인지 궁금함
          + 맞음. 하지만 Morph 자체도 LLM임. 실제로는 대형 LLM이 소형 LLM을 툴 콜처럼 활용하는 구조임
     * 매우 인상적임. 내부 AI 코딩 시스템용으로 이런 솔루션을 찾고 있는 입장인데, 오픈소스인 Osmosis Apply 1.7B 같은 프로젝트와 비교하면 어떤 점이 다른지 궁금함. Morph 모델은 오픈소스/오픈웨이트가 아니라는 전제임
          + 둘 다 직접 써보는 게 좋겠음! 우리 모델은 속도와 정확성 면에서 차이가 크게 우위임
     * 이전에 Morph를 OpenRouter에서 못 봤는데 이젠 올라와 있는 것 같음. 다만 등록된 모델이 예전 버전인 듯? 더 적극적으로 지원할 계획이 있는지. 그리고 fast apply 모델이 Relace나 Llama/Cerebras와 성능(특히 정확성) 비교한 벤치마크 결과가 궁금함
          + 해커뉴스의 힘이 대단함! 이제 거기서도 신규 모델이 등록됨
          + 현재 v2 모델은 morph-v3-large를 가리키고 있음. 곧 v3-large와 v3-fast도 추가될 예정임
     * Relace와의 비교가 궁금함. 둘 다 YC 출신 회사고, 기능도 매우 비슷한 것으로 보임 Relace
          + 좋은 질문임. 고객사 명단도(create.xyz, continue.dev) 동일하게 표시함
     * ChatGPT와 VSCode 사이 브릿지를 만드는 브라우저 확장, 그 사이에 Morph(혹은 Claude)를 껴서 agentic coding을 웹 UI로 바로 활용하면 정말 좋을 것 같음. API 대신 웹 인터페이스 활용 아이디어임
          + MCP를 쓰면 이 목적을 달성할 수 있음. 곧 출시 예정임
     * AI가 똑똑하게 rebase+merge를 자동화해주는 기능이 있으면 개발 속도가 비약적으로 빨라질 것 같음. 여러 사용자의 코드 변경을 AI가 의도까지 파악해 자동으로 병합한다면 정말 생산성 향상임
          + Claude Code를 사용하면 이미 그 기능을 쓸 수 있음. 그냥 “다른 브랜치 병합하고 충돌 해결해줘""라고 요청하면 됨
          + 얼마나 자주 머지 컨플릭트 상황을 겪는지 궁금함
"
"https://news.hada.io/topic?id=21928","Flix – 강력한 효과 지향 프로그래밍 언어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Flix – 강력한 효과 지향 프로그래밍 언어

     * Flix는 함수형 프로그래밍과 효과 지향 모델을 결합한 혁신적인 언어임
     * 논리 규칙과 데이터 종속성 모델링이 용이하며, 선언적인 지식 표현이 강점임
     * 복잡한 의존 관계 및 프로세스 흐름을 간결하게 코드로 작성할 수 있음
     * 이런 접근 방식은 알고리듬 설계와 추론 작업에 효율성을 제공함
     * 쿼리 기능을 통해 지식 기반 데이터를 손쉽게 탐색할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Flix 언어 개요

     * Flix는 효과 지향적 프로그래밍 패러다임을 도입한 새로운 함수형 언어임
     * 프로그래머는 절차적 코드가 아니라, 논리적 관계와 규칙 중심으로 시스템을 기술할 수 있음
     * 논리 규칙(#{} 내에 선언)으로 구성요소, 의존성, 조립 시간, 납기일 등 복잡한 제조 시나리오를 간결하게 표현 가능함

선언적 규칙 및 데이터 모델링

     * 예시 코드에서는 PartDepends, AssemblyTime, DeliveryDate, ReadyDate와 같은 사실과 규칙이 사용됨
          + PartDepends(""Car"", ""Chassis"")와 같이 제품 간 의존 관계를 정의함
          + AssemblyTime(""Engine"", 2)처럼 부품별 조립 시간을 설정함
          + DeliveryDate(""Piston""; 1)와 같이 부품 납기일도 명시함
     * ReadyDate라는 논리 규칙을 통해 납기일이 정의된 부품 혹은 조립식 부품의 최종 준비일 산출 가능함
     * 즉, 개별 부품의 공급 및 조립 주기를 단순하게 추론 가능함

효과 지향적 추론 및 쿼리

     * Flix의 논리적 규칙 엔진은 효과 지향과 참조 투명성을 결합해, 직관적이면서도 오류가 적은 프로그램 설계를 유도함
     * 쿼리 구문을 이용해 ReadyDate에 해당하는 모든 부품별 준비일을 손쉽게 도출함
     * 이러한 방식은 제조, 공급망 관리, 추론 기반 자동화 등 다양한 분야에서 응용 가능함

종합 및 장점

     * Flix는 효과(Effects)와 논리 규칙 기반 추론을 결합해, 복잡한 시스템의 구성요소와 프로세스 간 관계를 간결하게 모델링함
     * 기존 언어 대비 논리적 명확성과 코드 간결성 면에서 차별화된 장점이 있음
     * 지식 그래프, 워크플로우 엔진, 데이터 추론 등 다양한 현대 소프트웨어 문제에 적합한 솔루션 제공 가능함

        Hacker News 의견

     * 이 언어의 깊이와 폭에 깊은 감명을 받음
       대수적 데이터 타입, 논리 프로그래밍, 변이성 등 필수 기능들이 모두 첫 단계부터 포함되어 있음
       비교 표를 보며 가장 마음에 들었던 부분은 단일 실행 파일이 패키지 매니저, LSP, 컴파일러 역할까지 모두 담당하는 점임
       Haskell의 경우 LSP가 ghc와 cabal 파일 사이에서 많은 작업을 다시 구현해야 했고, stack도 쓰이는 등 패키지 매니저의 공식성이 애매했음
       Haskell을 비판하려는 의도는 아니며, 정말 훌륭한 언어임
       하지만 최고의 기능은 조금 숨겨져 있는 것 같아 아쉬움
       Flix가 JVM 상에서 Java 등과 얼마나 편하게 통합되는지 궁금함
       JVM 컴파일러가 타입 정보를 대부분 지워버리기 때문에, Flix의 'regions' 컨셉이 명령형 상호작용을 1등급 시민으로 지원하는 점은 긍정적임
       JVM을 사용하면 수십억 달러 가치의, 고품질 표준 라이브러리를 손쉽게 쓸 수 있으니 엄청난 장점임
       그래서 JVM이나 .net core가 프로젝트의 90% 이상에서는 가장 합리적인 선택이라고 생각함
       F#만이 유일한 비교 대상 언어로 보임
       Flix와 JVM 간 상호운용성에서의 한계점들을 정리한 문서가 있으면 정말 좋겠음
       참고로, 관련 정보가 여기 있음
       기본적으로 Flix/Java 값은 boxing/unboxing 과정을 거침
       또, Record가 1등급 시민임
          + 패키지 매니저, LSP, 컴파일러가 모두 하나의 실행 파일이라는 점이 마음에 든다면 Unison도 정말 좋아할 거라는 생각임
          + 논리 프로그래밍과 datalog 부분은 좀 추가적인 느낌임
            다른 기능들은 확실하게 코드베이스의 타입 안전성을 높이는 것이 보이지만, 논리 프로그래밍은 상당히 마니아층 기능이라 오히려 언어와 별개로 존재하는 게 더 낫지 않을까 생각함
          + JVM 컴파일러가 타입 정보를 모두 지운다는 것은 완전히 맞지는 않음 (익명 클래스의 경우 타입 파라미터를 유지함)
            여러가지 우회 방법도 존재함
            그리고 사실 컴파일러 입장에서는 큰 문제가 아님
            타입 생성자를 적용한 클래스명을 난수화해서 일반 클래스처럼 렌더링하면 됨
          + F#은 (아직) 타입 클래스를 지원하지 않기 때문에 monad 기반 프로그래밍에 제한이 많음
            만약 F#이 Haskell 스타일 monad를 생략하고 바로 대수효과(algebraic effects)로 점프한다면, 그게 F# 철학엔 더 잘 맞을 거라고 생각함
          + ""StringBuilder"" 부분은 약간 아쉬움
            이 면에서는 Java 쪽에 좀 더 기울어 있는 것 같아서 확신이 서지 않음
            다른 부분은 얼핏 보면 괜찮아 보임
     * 언어 의미론 측면에서 볼 때, 다형적 레코드의 확장/제한 의미론이 Leijen의 scoped label 방식(논문 링크)을 따르는 것 같음
       예를 들어 r1 = { color = ""yellow"" }라는 레코드가 있으면, r2 = { +color = ""red"" | r1 }로 확장할 수 있음
       r2#color는 ""red""가 나오고, 다시 ""color"" 필드를 없애면 r3 = { -color | r2 }가 되고
       r3#color는 원래 값인 ""yellow""가 나옴
       이렇게 하는 게 이전 스타일(동일한 label 필드를 두 번 추가불가하도록 극도로 복잡한 타입 시스템을 사용하는 방향)보다 훨씬 합리적이라고 생각함
     * Aarhus(특히 대학/테크허브)가 프로그래밍 언어 연구에서 강력한 영향력을 갖는 이유가 궁금함
       C++, C#/Typescript, Dart 등 모두 이 덴마크의 작은 지역에서 강한 뿌리를 갖고 있음
       Delft, INRIA같은 곳처럼 전형적 Ivy League나 Oxbridge의 명문대는 아님
       뭐가 그렇게 특별하게 만든 걸까? 물 때문인가, 아니면 다른 이유가 있나 하는 단순한 궁금증임
          + 한 가지 짚자면, C#은 Anders Hejlsberg가 만들었고 그는 DTU(코펜하겐)에서 공부했음
            Turbo Pascal도 그가 만들었고, Borland도 덴마크인이 창업한 회사임
            전반적으로 덴마크는 프로그래밍 언어 이론이 강함
            예를 들어, 정적 프로그램 분석 분야 표준 대학원 교재(저자 Nielson & Nielson)도 덴마크 출신임
            Mads Tofte는 Standard ML에 큰 기여를 함
            Aarhus가 Ivy League, Oxbridge 급은 아니지만 훌륭한 대학임
            유럽에는 이런 식으로 명성은 작지만 교육, 연구의 질이 뛰어난 대학들이 수십 군데 이상 존재함
          + Aarhus는 논리, 타입 이론, 함수형/객체지향 언어 분야에서 전통이 강함
            이 분야에서 영향력을 끼친 많은 연구자들이 Aarhus 출신임
            또, 프로그래밍 언어 연구는 전 세계적으로 미국 편향이 심하게 작용하는 것처럼 느껴짐
            Aarhus 같은 기관은 마케팅이나 자기 PR에 현저하게 인색하고, 좋은 연구에 집중하는 편임
            특별히 더 낫거나 덜 나은 건 아니고, 글로벌 주목을 받기가 어렵게 만드는 점이 있음
     * Flix는 ML 계열 언어들 중에서 가장 세심하게 설계된 언어로 계속 인상적임
       함수형, 명령형, 논리형 패러다임의 조합과 다형적 타입&이펙트 시스템, Datalog 제약까지 1등급 시민으로 지원하는 점이 정말 독특함
       타입 레벨에서 순수/비순수 코드를 엄격히 구분하는 점이 Monad 대신 효과를 추론하기 더 쉬운 대안이라 신선함
       ""하나의 언어, 플래그 필요 없음"" 철학과 오직 컴파일 타임 에러만 추구하는 점도 단순하고 예측 가능해서 좋음
       JVM 자체가 꼬리 재귀 제거를 네이티브로 지원하지 않는데도 Flix는 완전한 꼬리 호출 제거를 구현했다는 것은 주목할 만한 기술적 성취임
       실제로 생산 환경이나 연구에서 Flix를 사용하는 분들의 경험이 궁금함
       특히 논리 프로그래밍이나 동시성 분야에서 사용하면서 '폐쇄 세계 가정(closed-world assumption)'이나 예외 미지원 등에서 겪은 어려움, Prolog 등 다른 논리 언어와 Datalog 통합의 차이점에 대해 듣고 싶음
     * 예전에 Flix를 살펴봤을 때 정말 흥미로워서 ""Java 프로그래머를 위한 Flix""라는 제목으로 글까지 썼음
       지금은 조금 오래되어 업데이트가 필요하긴 하겠지만...
       혹시 관심 있다면 여기에서 볼 수 있음
          + 블로그 글이 정말 멋짐
            허락만 한다면 Flix 공식 블로그 모음(링크)에 추가하면 좋겠음
            그 글 이후로 Flix 언어가 많이 발전함
            특히 이펙트 시스템이 크게 확장됐고, Java 상호운용성 개선, 문법 업데이트가 있었음
          + 블로그가 정말 보물 창고 같음
            오랫동안 나를 괴롭혀온 생각들을 정리해준 더 고급스러운 버전이라 느낌
            전부 읽어볼 생각에 기대감이 큼
     * HKTs도 지원해서 멋짐
       그런데 typeclass에 대한 설명이 안 보여서 궁금함
       typeclass와 Scala 스타일 매크로만 지원해주면 내가 만든 라이브러리(distage, izumi-reflect, BIO)도 Flix로 옮겨보고 싶고 Scala에서 Flix로 넘어가는 것도 진지하게 고민할 듯
       추후에 typeclass를 traits로 부르고 있음을 발견함
       매크로는 어떤지 궁금함
       또, Flix에서 명시적 이름 기반 상속(nominal inheritance)도 지원하지 않다는 게 아쉬움
       Scala의 trait 중 가장 무해한 형태조차 허용 안 되니까
       typeclass는 interface를 대체할 수 없는데, 그 추상화가 없으면 많은 유용한 기능을 아예 구현 못 하거나 코드가 보기 싫어질 수 있다고 느꼈음
          + Flix는 typeclass(여기서는 trait이라고 부름)를 HKT, associated type, associated effect와 함께 지원함
            trait이 함수 기본 구현도 제공하지만, 인스턴스에서 오버라이드 가능함
            Flix는 상속(inheritance)은 아예 없음
            trait이 오직 컴파일 타임에만 사용되고 monomorphization 처리를 거쳐 런타임 오버헤드가 없음
            Flix 인라이너가 trait 내부도 최적화 처리해서 closure까지 적극적으로 제거함
            예를 들어 고차함수나 파이프라인이 바이트코드 수준에서는 평범한 루프로 바뀌고 closure 할당이나 간접 참조가 아예 없어짐
            Flix는 아직 매크로를 지원하지 않음
            다른 언어에서의 (남용)경험 때문인지 도입을 두려워하고 있음
            새로운 라이브러리 작성자를 모시고 있으니 혹시 관심 있으면 Gitter 채널에 들러줬으면 좋겠음
     * Flix 공식 문서 중 'Flix에서 지원하지 않는 기능' 섹션 관련
       ""No Code Before Main""라는 항목이 있는데
       실제 설명은 ""Flix는 main 이전에 아무 코드도 실행되지 않으며 정적 이니셜라이저 같은 건 전혀 없음""이라고 되어 있음
       기능명은 ""Code Before Main""으로 바꾸는 것이 더 정확하다고 생각함
     * Flix에서 함수가 순수함을 반드시 명시적으로 표시하게 하는 이유가 궁금함
       거의 모든 경우 정적 분석으로 충분히 추론할 수 있을 것 같은데 왜 그런지 알고 싶음
          + 내가 알기로 함수에 순수성을 표시하면, 컴파일러가 이를 보장해줌
          + ""Flix는 프로그램 내 모든 표현식의 순수성을 정확히 추적한다""라는 문장과, 순수/비순수 표기가 없는 함수 정의 예시를 보면
            대다수 경우에는 컴파일러가 순수성을 자동 추론하는 게 가능한 것으로 보여서
            순수/비순수 표시는 옵션일 수도 있다는 인상을 받음
     * Flix FAQ(링크)는 평범하게 시작하다가 점점 재미있어짐
       몇 가지 웃긴 예시들:
          + Q: 0으로 나누면 진짜 결과가 0임?<br> A: 네. 근데 이 부분만 신경 쓰는 건 마치 우주선 좌석 색깔만 따지는 것과 같음
          + Q: ""이 사이트는 JavaScript 필요""<br> A: JavaScript 사용을 비판한 사람들: [1],[2],[3],[4],[5], 실질적으로 HTML로 리팩토링을 돕겠다고 한 사람: 0명
          + Q: 내가 좋아하는 기능 Y 대신 X라는 기능이 들어 있어서 실망임<br> A: 유감임
          + Q: 지금까지 본 함수형 언어 중 최악의 문법임. 세미콜론, 중괄호, 심볼 난장판이 만났음. 마치 Scala, Java, Haskell이 체르노빌 한가운데서 원나잇한 것 같음<br> A: 오히려 대단한 성취 아닌가?
     * 이 언어와 호환되는 코드 에이전트(agent)가 잘 작동하는지, 아니면 머리를 직접 써야 하는 상황인지 궁금함
       농담처럼 얘기하지만, 실제로 언어가 멋져 보여서 슬픔
       LLM이 오히려 신규 언어 채택을 저해할 텐데, 이 문제를 어떻게 풀 수 있을지 의문이 있음
          + 나는 오히려 LLM이 새로운 언어 채택 장벽을 낮추는 역할을 할 거라는 직감임
            표준 라이브러리 코드는 LLM이 새로운 문법을 학습하기에 충분하고, 아니더라도 에이전트가 컴파일러 출력을 관찰하며 배우는 것도 가능함
            코드 포팅 작업 자체는 고도의 창의성이 별로 필요 없는, 정의가 명확한 일이라서 LLM의 자동화 1호 영역이 될 것임
            앞으로는 우리가 '왜 이걸 하는지'와 '세상에 어떤 영향을 주는지'를 두뇌로 진지하게 고민해야 한다고 봄
          + 프롬프트에 Idris의 인덱스/의존 타입을 반드시 사용하도록 지시해두니 괜찮은 결과를 얻음
            (이런 지시가 없으면 GADT 정도가 한계)
"
"https://news.hada.io/topic?id=21848","Clip-JS — Next.js, Remotion, FFmpeg 기반 온라인 영상 편집 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Clip-JS — Next.js, Remotion, FFmpeg 기반 온라인 영상 편집 오픈소스

     * Next.js, Remotion(실시간 미리보기), FFmpeg(웹어셈블리 포트) 기반의 온라인 영상 편집기
     * 브라우저 환경에서 실시간 편집 미리보기와 고품질 1080p 렌더링을 지원
          + FFmpeg(WASM)으로 최대 1080p까지 다양한 옵션 렌더링 가능
     * 인터랙티브 타임라인 에디터에서 직접 드래그해 미디어를 정밀하게 배열, 잘라내기·복제·분할 등 레이어별 조작 지원
     * 영상·오디오·이미지·텍스트 등 다양한 미디어/레이어/텍스트 편집
     * 고급 컨트롤: 위치, 투명도, z-index, 볼륨 등 개별 요소 속성 조정
     * 직관적인 키보드 단축키 지원 : space(재생), m(음소거), s(분할), d(복제), del(삭제)
     * 로컬 개발·셀프호스팅 가능
     * 기술 스택
          + 프론트엔드: Next.js, React
          + 미리보기: Remotion
          + 렌더링: FFmpeg (WebAssembly)
          + 기타: react-moveable 등 타임라인·레이어 조작
"
"https://news.hada.io/topic?id=21859","애플 Lisa의 UI를 기반으로 한 1비트 그래픽 웹 OS","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    애플 Lisa의 UI를 기반으로 한 1비트 그래픽 웹 OS

     * 개인 개발자가 Apple Lisa의 사용자 인터페이스를 재현한 웹 기반 운영체제를 제작함
     * 이 프로젝트는 1비트 흑백 그래픽을 특징으로 하며, 레트로 컴퓨팅 매니아들에게 흥미로움
     * 데스크톱, 아이콘, 파일 창 등 1980년대 Apple Lisa의 디자인을 충실히 모방함
     * 웹 브라우저 상에서 바로 실행 가능하며, 별다른 설치 과정이 필요하지 않음
     * 오픈소스로 공개되어 다른 개발자들의 커스터마이징과 확장이 용이함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 소개

     * 이 프로젝트는 Apple Lisa의 초기 데스크톱 운영체제 UI를 웹 환경에서 직접 경험할 수 있도록 한 웹 OS 개발임
     * 1비트(pure black & white) 그래픽을 사용해 레트로한 사용자 경험을 제공함
     * 데스크톱, 아이콘, 창, 앱 실행 등 전통적인 데스크톱 환경을 재구성함
     * 실제 운영체제 기능 전체를 구현하지는 않았지만, UI 동작과 시각적 요소 재현에 집중함
     * 현대 브라우저만 있으면 바로 접근할 수 있어 기술적 진입장벽이 매우 낮음

주요 특징

     * 1983년에 출시된 Apple Lisa UI 디자인을 충실하게 모방함
     * 드래그 앤 드롭, 창 이동 및 크기 조정 등 핵심 UI 반응을 실감나게 재현함
     * 단순하지만 정교한 1비트 그래픽 스타일로 독특한 시각적 감성 제공
     * 앱 목록 및 파일 브라우징, 간단한 앱 실행 등 데스크톱 운영체제의 기본 요소 포함함

활용 및 의미

     * 레트로 컴퓨팅이나 UI/UX 디자인 연구를 위한 훌륭한 데모 자료임
     * 초보 개발자도 소스코드를 분석하며 웹 UI 체계 및 레이아웃 구조 이해 가능함
     * 오픈소스로 배포되어 커뮤니티가 다양한 방식으로 기능 추가나 테마 수정을 시도할 수 있음

기타 참고 사항

     * 별도의 복잡한 설치 과정 없이, 링크를 통해 바로 웹에서 구동 가능함
     * 소스코드는 Github 등 공개 저장소를 통해 제공함
     * 본 프로젝트는 영리 목적이 아닌, 실험적 시도와 교육적 목적에 중점을 둠

        Hacker News 의견

     * Lisa는 정사각형 픽셀이 아니라서 캔버스 비율을 가로 대비 세로 1.5배로 설정함, 고해상도 디스플레이에서는 픽셀 자체가 2픽셀 너비 × 3픽셀 높이이기 때문에 꽤 괜찮게 보이지만, 저해상도 디스플레이에서는 픽셀이 1픽셀 너비 × 1.5픽셀 높이로 표현되어 왜곡 현상 발생, 이건 설계상 감수한 부분임, 하지만 충분히 큰 저해상도 디스플레이에서 창 크기를 넓게 조절하면 자동 정수 배율 기능이 작동해서 픽셀 자체가 더 크게 나오게 됨, 환경설정 앱의 디스플레이 옵션에서 강제로 설정 가능, 만약 배율 설정을 꼬았다면 LisaGUI를 재시작하면서 shift키 누르고 있으면 초기화 가능, 그리고 iOS에서 PWA 관련 캔버스 위치 버그가 소소하게 있어서, 단말기 회전 후 원위치하면 해결 가능하지만 꽤 번거로운 점도 있음, 창을 닫을 때는 타이틀바에 있는 아이콘을 더블
       클릭하면 창이 아이콘 형태로 접힘
          + 동적으로 창이나 폰트 크기 조정(브라우저 크기에 상관없이)을 어떻게 처리하는지 궁금, 기본적으로 html에서는 이런 게 자동이지만 이 프로젝트에서는 어떤 방식인지 궁금
     * Apple ][/e나 /c 클론(불가리아산 Pravetz 8Ц)이 내 첫 컴퓨터였고 그 다음엔 Hercules 모노크로 모니터가 달린 286, 386 PC도 사용했었기 때문에, 이번 프로젝트에서 멋진 레트로 UI를 보면서 Think-Pascal 시절이 떠오르는 감성
     * 이런 독특한 Lisa GUI 프로젝트가 바로 내가 Hacker News를 좋아하는 이유, 순수 바닐라 JS와 시대를 앞섰던 UI에서 배우는 경험이 쏠쏠, 데모/예제에 브레이크아웃 스타일 게임처럼 바로 즐길 수 있는 게임이 추가되면 더 좋겠다는 마음
          + 고마운 마음 크다는 얘기 전하고 싶고, 다음 게임은 솔리테어 만들 예정, 그리고 Xerox Alto의 Mazewar 같은 게임도 언젠가 만들고 싶다는 생각, 특히 네트워킹 구현이 쉽진 않지만 Xerox에 대한 오마주로 시도해 볼 예정
     * Preferences 앱에 있는 그림자 텍스트 스타일과 fatbits 에디터를 보고 40년 전 UX를 걷어내도 여전히 생산적이고 직관적이라는 사실이 매우 인상적, 다만 창 닫기 버튼이 없는 점이 아쉬움, 한 번 클릭만으로 메뉴가 열려 있는 기능은 이런 UX 발전에서 꽤 후대에 들어온 좋은 변화임
          + sticky(고정) 메뉴는 시간이 훨씬 지난 뒤 도입된 기능임, 이번 구현에서는 현대 사용자들이 익숙해서 일부러 포함함, 클릭 한 번으로 메뉴를 열어놓거나 마우스를 누른 상태에서 끌어서 열고 마우스 버튼을 떼면 닫히는 식, 과거 Mac OS(System 6)에서도 sticky 메뉴를 쓸 수 있게 해주는 익스텐션이 있는데, 여기서는 그 기능을 좀 더 옛날까지 소급해서 넣어봤다는 설명, 그리고 창을 닫으려면 타이틀바 아이콘 더블클릭하면 됨도 추가
          + 창 왼쪽 상단 아이콘 더블클릭하면 창이 닫히는 동작 존재, File > Set Aside의 단축키 같은 개념
     * Lisa를 오래 써본 경험은 없지만 90년대 초 기술자로서 여러 대의 Lisa를 써보고 Mac XL로 개조했던 추억, 이번 프로젝트는 UI 재현도가 매우 높아 클릭해보는 재미와 함께 좋은 경험 제공
     * 예전엔 Lisa 에뮬레이터도 사용해본 적 없었는데, 이번 덕분에 처음으로 써보게 된 소중한 경험, 오랜만에 GUI의 근본적인 생각을 다시 돌아볼 수 있게 해줘서 고마운 감상
     * GUI라는 단어를 소리 하나하나 따로 따로 발음하는데, 굳이 ""구이(gooey)""처럼 묶어서 읽을 필요가 없다는 생각, 농담 반 진담 반으로 동지애
          + 약어와 이니셜리즘은 모두 소리 내어 읽자는 주의, TUI는 '투이', CLI는 '클리', TCP/IP는 '티키피피', GPT는 '기피티', DNS는 '던스', HTTP는 '히텁', USB는 '우즈버', USB-C는 '우즈버크' 같은 식으로 유쾌하게 제안
          + 이런 사소한 발음 논쟁이 요즘 정치 같은 심각한 얘기보다 훨씬 재밌고 즐거운 논쟁거리, 예: vi vs emacs, vi vs vim, IF(이프) 발음, m68k vs x86, Mac vs Amiga, BSD vs Linux 등등
          + 같은 생각을 가진 사람이 있다는 점 반가운 연대감
     * 모바일에서 마우스 커서를 사용할 때는 Microsoft Remote Desktop의 방식이 편리한데, 손가락이 아니라 화면 아무 곳이나 움직이며 커서를 별도로 이동시키는 방식, 직접 사용해보면 느낌이 옴, 이에 대한 개선 제안
          + 이미 구현해두었다는 답변, 환경설정의 터치스크린 옵션 패널에서 트랙패드 모드를 켜면 동일한 방식의 터치 커서 경험 가능
     * 모바일에서 시도해봤는데 반응성이 인상적으로 뛰어남
          + 사용해봤다는 피드백에 고마운 마음
     * 작은 화면의 iPhone SE에서는 제대로 동작하지 않아서, 다음번엔 하드웨어 업그레이드로 더 나은 OS 경험을 해보고 싶다는 생각
"
"https://news.hada.io/topic?id=21860","Jane Street, 규제기관이 5억 6600만 달러 동결하며 인도 시장 진입 금지","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Jane Street, 규제기관이 5억 6600만 달러 동결하며 인도 시장 진입 금지

     * 인도 증권거래위원회(SEBI)가 Jane Street의 인도 내 운영을 제한함
     * 규제기관은 관련 조치로 5억 6600만 달러 규모의 자산을 동결함
     * Jane Street는 세계적인 거래 회사로, 이번 제재로 인해 인도 시장에서 상당한 영향력을 상실함
     * 이번 조치는 시장 규제 준수 위반에 따르는 조사에 연관됨
     * 인도 금융 시장에 진출한 해외 투자자들에게 경고성 시사점을 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Jane Street 인도 시장 진입 금지 및 자산 동결 개요

     * 인도 증권거래위원회(SEBI)는 Jane Street의 인도 내 시장 접근을 엄격히 금지하고 있음
     * SEBI는 Jane Street와 관련된 5억 6600만 달러 상당의 자금을 동결함
     * 이 조치는 Jane Street가 인도 내 시장 규제 및 준수 의무를 위반했다는 조사 결과와 연결됨

Jane Street의 글로벌 영향력과 이번 제재의 파장

     * Jane Street는 글로벌 금융 시장에서 고빈도 트레이딩(High-frequency trading) 및 다양한 투자 상품 거래로 유명한 기업임
     * 이번 인도 시장 내 제재로 인해, Jane Street는 현지 시장 진입 및 거래 기회를 사실상 상실하게 됨
     * 인도 정부와 규제기관은 시장의 투명성 및 법규 준수 강화를 위해 엄격한 규제를 적용함

해외 투자자와 시장 관계자에 대한 시사점

     * 이번 사건은 인도 시장에 진출한 해외 투자자 및 스타트업에게도 의미 있는 경고 시사점을 제공함
     * 인도 시장에서 활동할 때 법규 및 컴플라이언스 준수의 중요성이 더욱 부각됨
     * 향후 외국계 회사들은 시장 접근 전략 및 리스크 관리 측면에서 보다 신중한 접근이 필요함

규제 현황과 향후 전망

     * SEBI의 이번 조치는 인도 금융 시장을 둘러싼 외국 자본 유입과 관련된 위험 관리의 일환임
     * Jane Street와 유사한 글로벌 기업들 또한 현지 규제 변화에 신속히 대응해야 할 필요성 강조됨
     * 장기적으로 인도 내 투자 환경은 법적 감독과 위험 규율이 강화되는 방향으로 전개될 것임

        Hacker News 의견

     * 인도 규제 당국에 따르면 Jane Street는 매 거래일마다 인도 은행 섹터 인덱스에 속한 주식이나 선물을 대량으로 아침에 매수하는 방식, 그 직후 인덱스 하락이나 변동성 상승에 베팅하는 대규모 옵션 거래 체결, 그리고 장 후반에 이 대량 포지션을 청산해 인덱스를 아래로 끌어내리는 방식으로 더 많은 수익을 옵션 거래에서 얻는다는 순서 진행. Jane Street는 시장 비효율성을 개선했다고 주장할 수 있지만, 이 정도 규모면 전형적 시장 조작이라고 보는 입장
          + 시장 조작이 왜 불법인지 이해하지 못하겠음. 만약 시장 참여자들이 기초 자산과 상관 없는 감정적, 비이성적 결정을 한다면 그 책임 역시 본인들의 몫이라는 생각
          + Jane Street 사례는 특정 기업의 문제라기보다 일반적인 문제라는 관점. 파생상품이나 선물시장이 기초 자산보다 더 유동성이 높으면, 누군가 기초 자산을 살짝 흔들려는 유혹을 받게 된다는 점 지적. 채권 ETF와 옵션 체인에서도 유사한 현상 발생 가능성 존재
          + 그럼 그렇게 대량으로 풋을 팔고, 반복되는 패턴을 며칠 간 못 알아차린 판매자는 누구였는지 의문. 인도 증권거래위원회(SEBI)의 논리도 의문
          + 왜 다른 참가자들은 이런 패턴을 분석해서 Jane Street와 반대 포지션을 취하지 않는지 궁금증
          + 인도 규제 당국의 평판을 기반으로 볼 때, Jane Street의 유일한 잘못이 시장 조작뿐이라고 믿긴 어려움. 예전에 Adani Group 논란을 기억하는 사람도 있을 것. 참고 링크
     * https://bnnbloomberg.ca/business/international/…"">뉴스 기사 아카이브 Jane Street가 2024년 4월 Millennium 및 두 명의 트레이더를 상대로 “엄청난 가치의” 거래 전략을 빼앗겼다고 소송 제기. 이번에 법원 청문회에서 밝혀진 전략은 인도 옵션 관련으로 Jane Street가 2023년에 10억 달러 이익 실현
          + 전략의 주요 내용을 알면서 회사를 이직할 수 있었던 점이 놀라움. 위험 및 컴플라이언스 검증 기준이 엄격한 환경에서 이직 후 똑같은 전략을 시행할 수 있었을지 의문. 혹시 Millennium이 표면상으로만 확인하고 거액의 이득만 보고 넘겼던 건지, 아니면 실제로는 Jane Street가 특정 종목의 매매 타이밍 등을 잘 알기에 기생 전략으로 접근했을 수 있다는 추측
          + 이런 트레이더들에게 실제로 제안된 연봉이 궁금증. Mark Zuckerberg가 던졌던 1억 달러 제안보다 많기 힘들 거라는 농담
          + 금융에서는 항상 “비밀 소스는 범죄”라는 웃픈 원칙이 적용된다는 지적. 이번 소송 때문에 인도 당국 레이더에 걸린 것 아니냐는 의심. 미국 드라마 <The Wire>의 Stringer Bell 조언을 들어야 했다는 농담
     * 전 NYSE 전문업체 근무 경험을 바탕으로, 시장조성자(Market Maker)는 매우 중요한 역할을 하나, 오늘날 대형 HFT(고빈도 거래자)들은 법적으로 회색지대이거나 규제의 빈틈을 악용하는 경우가 많음. 규제 기관의 무관심이나 역량 부족, 의욕 저하가 문제라는 비판
          + SEBI(인도증권거래위원회)가 외국계 기관에 비호감 이미지를 감수하며 대담한 조치한 점 칭찬. SEC 또한 Citadel 등과 같은 맹목적 거래 관련 문제를 조사하길 희망
          + NYSE Market Maker의 옹호에 대해 다른 시장, 특히 NASDAQ 등은 왜 그런 조성자 없이 잘 돌아가는지 의문. 2025년 현재 대부분 전자거래로 이뤄지고 있는데 중요성이 크지 않다고 봄
          + 현대시장에서는 ‘차익거래’ 정의 자체가 다양화. 저금리로 조달해 고금리로 투자하는 전통적 방식만이 아니라, 레이턴시(지연), 규제, 시장 구조 등 각종 차익거래가 존재. 이 모든 혜택은 더 빨리 찾아내고 적용하는 기업에 귀속
          + 인도 시장의 조성 주체가 누구인지 궁금함. 대형 인도 은행이 있는지, 아니면 다국적 트레이딩 회사들이 시장조성자 역할을 하는지, 그리고 트레이딩과 시장조성 간 활동 구분을 어떻게 하는지 질문. 충분한 자본과 관리가 있다면 조작은 쉽다는 시각
          + ‘법적 회색지대’ 악용이나 규제 빈틈 활용이 실제로 어떻게 일어난다는 것인지 추가 설명 요청
     * Financial Times의 블로그 기사가 훨씬 더 자세한 내용과 SEBI가 발행한 100페이지 분량의 공식 명령서 링크까지 포함. Jane Street의 “사악한 인도 거래 전략”에 대해 참고할만한 기사 링크
     * Jane Street의 ""엘리트 전략""이 유출됐는데 결국은 단순히 장 마감 때 주가를 휘두르는 전략이라는 점이 꽤 우스꽝스럽다는 농담
          + Tower라는 회사도 10년 전 똑같은 전략을 사용하다 적발. 이 전략의 이름이 “the hammer(망치)”였는데, 아침에 대량 매수 후 장 마감 때 크게 때려서 수익을 내는 구조. 아마 Jane Street도 처음엔 의도치 않은 결과였을 수 있고, 인도 시장에서 너무 과감하게 리스크를 감수했던 것 같음
          + Jane Street는 다양한 시장마다 거의 모든 전략 실행. 인도 시장에서는 위험 부담이 크더라도 ‘걸리지만 않으면 된다’는 마인드로 접근한 듯
     * 인도 옵션 시장에 대해, 리테일 투자자가 전체 옵션 거래의 35%를 차지, 나머지 기관투자자는 헷지나 계좌 수익 목적. 규제 기관은 개인이 주식, 뮤추얼펀드 장기투자 대신 순수한 투기 거래에 열중한다는 점에 우려. 인도에서 평균 옵션 보유 시간이 30분 미만으로 매우 짧다는 사실은 관련 기사에서 확인 가능. “도박하고 싶으면, 혈당과 혈압 올리고 싶으면 이 시장에 들어가라”는 인도 증권 규제 당국 이사 의견 인용
          + 이런 시장에는 대규모로 손해를 본 ‘호구’가 반드시 존재. 원래 잘못된 행동을 하면 누군가는 가르쳐줬어야 하고, 이번 조치 이후로는 더 대담하게 투기할 것이며 결국 누군가가 그 돈을 또 빼앗아 갈 것. 인덱스 옵션 시장은 카지노와 같아서 미숙련 투자자에겐 적합하지 않다는 견해
     * SEBI가 Jane Street의 개입 ‘강도와 규모’, 그리고 빠른 거래 반전이 “BANKNIFTY 옵션 포지션에 미치는 영향 외에 도저히 납득 안되는 경제적 이유”로 인해 조작적이라는 결론에 대해, 그 경제적 이유라는 게 단순히 상대방을 최대한 헤치는 것이었다는 농담. Jane Street의 존재 자체가 마치 배게 싸움에 대전차총을 들고 오는 격이라는 과장 섞인 비유
     * 명시적 위반이 없었다는 사실에도 불구하고 SEBI가 “의도와 규모”라는 모호한 기준으로 규제 조치 내린 근거를 이해하기 힘들다는 시각. 금융 사기에는 반대하지만 정부 기관이 명확하고 일관된 규정을 지켜야 한다는 원칙 강조 (또는 기사 내용이 잘못됐을 수 있다는 의문)
          + “시장 조작”이란 개념 자체가 정의하기 어렵다는 설명. 미국 내 실무 정의는 ‘실제 체결 의도 없이 시세 변화 유도 목적으로 주문을 내는 행위’로, 세부 유형별로 명확한 규정도 있지만 보통은 상당 부분 그레이존. 주문 취소와 조작의 본질적 차이는 ‘의도’로, 최종 판단은 규제당국의 몫
          + 금융 규제는 두 가지 유형으로 구분: 매우 구체적으로 명시된 방식(미국) vs. 넓은 범위의 “정신”을 지키는 방식(싱가포르). 두 가지 모두 각 나라 상황에 따라 작동
          + 의도 여부와 무관하게 정부는 “시장 조작과 국가 경제 훼손을 금지”할 권리가 있다고 생각. 규제가 항상 사후적일 수밖에 없으므로 사각지대 존재. 당사자가 아무리 합리적 근거를 주장해도 나라는 언제든 조치를 취할 수 있다는 입장. Jane Street가 선의로 행동했다는 환상은 없으며, 반복되는 조작과 착취, 붕괴에 익숙해졌다면 규정이 있든 없든 “이제 더는 못 참겠다”라고 선언하는 것도 필요하다는 강경 입장
     * Matt Levine의 Money Stuff에서 관련 사안이 언급될지 기대
     * 대형 트레이더들이 시장 영향력을 계산하지 않고 의사결정한다는 주장은 말이 안 된다는 입장. 결국 누가 “시장 조작” 할 수 있는 자격을 갖고 누가 그 대가를 치르냐의 정치적 문제라는 시각
          + 개별 투자자가 아닌 대형 은행이나 헤지펀드는 대량 주문 체결시 자체적으로 시장 가격을 움직이기 마련. 그러므로 수익 포지션을 취하려고 해도 포지션 진입만으로 가격이 변동, 이 과정에서 ‘알파’(초과 수익)가 사라짐. 효율적 시장 가설의 실제 사례. 하지만, Jane Street가 일반적인 유동성 많은 종목을 거래하면서도 시장이 이들의 포지션과 함께 움직였다는 의혹은 매우 이례적
          + 실제로는 Millennium이 Jane Street를 밀고한 사안. 이번 사태로 인해 SEBI가 HFT(고빈도 거래) 업계를 철저하게 들여다보고 있다는 내부 사정. SEBI 공식 명령서
"
"https://news.hada.io/topic?id=21910","Astro는 웹의 기본으로의 회귀입니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Astro는 웹의 기본으로의 회귀입니다

     ""Astro는 개발자를 위한 최고의 프레임워크임""

     * Astro는 컨텐츠 중심 웹사이트에 최적화된 신개념 웹 프레임워크로, 기본적으로 Zero JavaScript 정책과 뛰어난 성능, 간편한 개발 경험을 제공함
     * Island Architecture라는 독특한 방식으로 필요한 부분만 JavaScript를 적용, 나머지는 빠른 정적 HTML로 처리함
     * Astro 사이트는 기존 React 기반 대비 40% 이상 빠른 로딩 속도를 보여주며, 이로 인해 SEO, 사용자 경험, 전환율 등 실질적 이점을 제공함
     * 다른 프레임워크와 달리 데이터 로직과 프론트엔드 컴포넌트가 명확히 분리되어 있고, React·Vue 등 다양한 프레임워크와 혼용 가능함
     * 단, SPA나 복잡한 상태 관리, 대규모 라우팅이 필요한 경우에는 Next.js 등 기존 프레임워크가 더 적합할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Astro란 무엇인가

     * Astro는 2021년에 등장한 웹 프레임워크로, 복잡한 앱을 위한 기존 JS 프레임워크와 달리 컨텐츠 중심 사이트에 집중해 설계됨
     * 기본 철학은 “컨텐츠 우선, 서버 우선, 기본은 Zero JavaScript” 로, 툴링 또한 직관적이고 쉽다는 점이 강점임

Island Architecture

     * Astro는 ""Island Architecture"" 라는 개념을 도입하여, 페이지 전체가 아닌 필요한 일부만 JavaScript를 적용함
     * 블로그 포스트처럼 대부분이 텍스트인 페이지는 HTML로만 렌더링되고, 코멘트나 캐러셀 등 상호작용이 필요한 부분만 JS를 로드함
     * 덕분에 페이지가 매우 빠르고 가벼움

실질적인 성능과 효과

     * Astro 기반 사이트는 전통적인 React 프레임워크보다 40% 이상 빠른 로딩을 기록함
     * 이런 성능 개선은 검색엔진 랭킹, 사용자 만족도, 전환율 등 비즈니스 성과로 이어짐
     * 느린 디바이스, 저속 네트워크 환경에서도 속도 차이가 더욱 크게 체감됨

개발자 경험(Developer Experience)

     * 프로젝트 셋업이 간단하고, “Houston”이라는 친절한 셋업 도우미가 가이드해줌
     * Astro 컴포넌트는 빌드 타임에만 실행되는 로직(예: 데이터 패칭, API 호출 등)이 가능함
     * 복잡한 상태 관리, 라이프사이클, 훅에 신경 쓸 필요 없이 필요할 때만 클라이언트 측 JS 활용 가능

다양한 프레임워크 호환성

     * React, Vue 등 주요 프레임워크를 Astro와 자유롭게 혼용할 수 있음
     * 예: 관리자 대시는 React, 데이터 시각화는 Vue, 나머지는 Astro로 구성 가능

‘작동하는’ 편의 기능들

     * Markdown을 컴포넌트처럼 직접 임포트하여 활용 가능
     * TypeScript, Sass, 이미지 최적화, 핫 모듈 리플레이스 등 현대적 빌드 파이프라인 지원
     * 정적 사이트/SSR/혼합 렌더링 모두 선택 가능, 프로젝트 성격에 맞게 유연하게 적용 가능

Astro가 빛나는 영역

     * 마케팅 사이트, 블로그, 이커머스 카탈로그, 포트폴리오 등 컨텐츠 중심 사이트에서 탁월한 성능
     * 복잡한 클라이언트 상태 관리가 필요 없는 환경에서 이상적임

트레이드오프

     * SPA, 복잡한 라우팅, 컴포넌트 간 상태 공유가 중요한 프로젝트에는 Next.js 등 다른 프레임워크가 더 적합함
     * 에코시스템 규모가 아직 작고, 파일 기반 라우팅이 대형 프로젝트에선 제한적으로 느껴질 수 있음

빠른 시작 방법

     * npm create astro@latest my-site
     * 필요시 npx astro add react 등으로 프레임워크 추가
     * src/pages/에 페이지, src/components/에 컴포넌트 추가 후 개발 시작

Astro의 의의

     * 최근 JS 프레임워크들이 점점 복잡해지는 가운데, Astro는 웹의 기본(빠르고 접근성 좋은 컨텐츠 중심 경험)으로 회귀하며 개발 편의성도 보장함
     * “빠른 사이트가 기본, 필요한 곳에만 인터랙티브 추가, 원하는 프레임워크 자유롭게 사용”이라는 설계 철학이 개발자를 만족시킴
     * 블로그부터 이커머스까지 컨텐츠 중심 프로젝트에 Astro를 적극 추천할 만함

        Hacker News 의견

     * 전통적인 웹 프레임워크는 항상 전체 페이지를 자바스크립트로 ‘하이드레이션’했음, 예를 들어 간단한 블로그 글에 단 하나의 인터랙티브 위젯이 있어도, 전체가 자바스크립트로 처리됨, 반면 Astro는 디폴트로 정적 HTML을 사용하고, 필요한 부분만 ‘자바스크립트 아일랜드’로 동작하게 함, 예전엔 이런 방식을 ‘점진적 향상(progressive enhancement)’ 또는 그냥 ‘웹 페이지’라고 불렀고, 이게 웹사이트를 만들 때 표준임, 그 후에 SPA가 등장해서 점진적 향상은 점점 덜 쓰였음, 지금은 ‘자바스크립트 아일랜드’라고 부르지만 결국 예전 방식으로 돌아간 것임, 관심 있는 신입 웹 개발자들에게 점진적 향상 개념을 추천하고 싶음
          + 누군가가 새로운 툴의 기능 설명을 듣고 기존에 했던 것과 같은 거라 착각할 때가 많음, 하지만 Astro의 진짜 가치는 다양한 자바스크립트 프레임워크와 연동되어 HTML의 일부 서브트리만 각각 처리할 수 있다는 것임, 이 때 초기 상태를 문자열로 렌더링해 클라이언트 쪽에서 미리 받아온 데이터로 하이드레이션됨, React/Svelte/Solid/Vue같은 프레임워크를 페이지의 일부에만 쓰고 싶고, 데이터를 서버에서 미리 불러오고 싶을 때 가치를 발휘함, 단 이 방식은 ‘점진적 향상’은 아님, 하이드레이션 전의 HTML이 제대로 동작할 필요는 없음, 예를 들어 <form>이 자바스크립트 없이 동작되지 않아도 됨, 이런 세부사항이야말로 냉소적으로 굴기보다는 호기심 있게 접근해야 깨달을 수 있는 점임
          + 완전히 동의함, Astro는 멋진 툴이지만 가장 어려웠던 점은 2010년 이후 입사한 개발자들이 웹 작동 방식을 설명하기 위해 만들어낸 각종 용어를 이해하는 것이었음
          + 새로운 개념은 아니지만, 지금 방식이 훨씬 더 세련된 느낌임, 예전엔 PHP와 jQuery로 인터랙티브 웹을 만들었는데, React와 SPA가 등장하기 전 시대였음, 지금 다시 생각해보면 아키텍처적으로는 옛날 방식이 더 우아했지만, 그 때는 디버깅이나 DX가 정말 안 좋았음, PHP로 프론트엔드에서 디버깅하는 시간은 다시 돌아가고 싶지 않음, SPA는 복잡한 대시보드나 인터랙티브 앱에서 여전히 용도가 있음, Astro는 서버와 클라이언트 코드를 한 곳에서 관리하게 해주고, 구분도 명확해서 데이터를 굳이 PHP 파싱해서 JS로 넘길 필요가 없어 DX가 크게 개선됨
          + AJAX라고 불렀던 시절이 기억남, 완전히 흐름을 잃은 느낌임
          + 초기 웹 프레임워크는 무상태 웹사이트와 서버 렌더링에 대해서는 정말 제대로 접근했다고 생각함
     * 개인적으로 Astro를 적극 추천함, 처음엔 ""html과 css에 include 기능만 추가된 툴""이라 여겼는데, 개인 웹사이트와 Matrix Conference 사이트 리뉴얼 때 사용해보니 정말 번거로움 없이 쓸 수 있어 즐거웠음
       Astro의 주요 장점:
          + 여전히 html과 css 중심임
          + 빌드 후에는 js가 기본적으로 필요 없음
          + 인터랙티브가 필요한 곳에만 js를 선택적으로 추가 가능함
          + 컨텐츠 컬렉션 기능이 깔끔함
          + 속도 최적화가 극도로 잘 되어있고, 메인테이너가 방법을 잘 알고 있음
          + 개발용 Devbar가 있어서 웹사이트가 더 빨라질 수 있는 부분을 시각적으로 보여줌(예: 화면 아래 이미지 lazy load 등)
          + CSS 미니파이어가 일부 CSS를 인라인해서 추가 쿼리를 줄여줌
          + 이미지 컴포넌트는 content layout shift를 막기 위해 width/height 속성을 자동 설정해주고, responsive image도 제공함
          + Astro가 html과 css 중심이고 필요할 때 js만 추가하는 것이라면, 파일 디렉토리에 직접 .html, .css, .js 만들고 배포해도 똑같은 경험임, 오히려 그게 dev-time 오버헤드나 불필요한 bloat 없이 더 빠르지 않냐는 의문이 듦, 또한 CSS를 인라인하는 것이 실제로 성능상 큰 이슈였던 적은 없음, 수백 개의 웹사이트 경험에서도 CSS가 병목인 경우는 거의 없었고 실제로는 네트워크가 문제였음
          + 딱 한 가지 아쉬운 점은 라우팅이 복잡해질수록 추상화가 빠르게 증가해서 오히려 혼란스러워졌음, 복잡성은 무조건 friction을 동반한다는 점에서 결국 다른 방식을 선택했음
          + ""html과 css에 include 기능""이 필요하다면 nginx 같은 일반 웹서버에서 서버사이드 인클루드를 활성화해 쓰면 됨, 20년 넘게 안정적이고 유지보수도 거의 필요 없는 솔루션임, 템플릿 엔진 같은 추가 보안 리스크도 없고, redundancy는 막으면서도 백엔드 취약점 걱정 없이 순수 인클루드만 할 수 있음
          + 20년간 데이터/백엔드만 하다 프론트엔드 프로젝트 때문에 다시 돌아왔는데, React로 고생하다 Astro+Svelte로 전환해서 정말 성공적이었음, HTML/CSS 중심이라 코드 구조가 예측 가능하고 깔끔한데, React 경력 개발자에게 프론트엔드를 넘겼을 때도 거의 바로 적응했음
     * ""전통적인 프레임워크""라는 표현을 SPA/Virtual DOM 프레임워크 지칭으로 쓰는 걸 보니 세대 차이를 느낌, Backbone, jQuery 같은게 진짜 전통적 웹프레임워크였고, 이들이야말로 블로그 글 설명처럼 동작했음
          + ""전통""이라는 건 결국 언제 태어났느냐에 따라 다르다고 생각함, 내게 전통 인터넷은 56k 모뎀, vbulletin 포럼, GTA:VC 모드, IRC 등이고, 더 오래된 세대한텐 BBS가, 더 젊은 세대한텐 Discord가 ""전통"" 인터넷일 것임, 정치에도 비슷한 현상이 있는데 다들 자기가 젊을 때가 좋았다고 여기는 경향임
          + Backbone은 pure SPA용으로 클라이언트 MVC를 지향했던 기억이 남
     * Astro, NextJS 등 SSR 프레임워크가 SvelteKit처럼 동적인 경로가 있는 정적 페이지를 지원하지 않는 이유가 궁금함, 예를 들어 /todos/[todoId] 같은 페이지를 NextJS에서는 아예 static bundle에 넣을 수 없음, 반면 SvelteKit은 404.html을 이용해서 실제로는 404지만 클라우드플레어나 모바일 웹뷰 환경에서 완벽히 동작함, 이런 기능이 특히 모바일 웹뷰 번들링 시 매우 유용함
          + 부분적으로 동의하는데, 이런 설계는 단점도 있음, /todos/123 같은 URL을 SPA에서 하드 리로드하면 실제 서버에 해당 파일이 있는지 요청하게 되고, 없는 경우 404로 받음, 그래서 404 페이지에서 클라이언트 라우팅으로 다시 데이터를 불러와 처리해야 하는데, 이건 nginx 등 HTTP 서버 설정이 꼭 필요함, 즉 순수 정적 파일만으로는 불가능함, 또 HTTP 스펙상 브라우저 캐시는 404 응답을 절대 저장하지 않음, 그래서 하드 리로드나 북마크 시 캐시를 절대 못 씀, 이런 설정이 부담스럽다면 쿼리 파라미터를 써서 /todo?id=123처럼 처리하는게 오히려 좋다고 봄
          + 내가 잘못 이해한 걸 수도 있지만, Next나 Astro의 static build에서도 동적 라우팅/페이지를 구현한 적 있음, CMS로 contentful이나 storyblok을 쓸 때 에디터가 자유롭게 라우트와 컴포넌트를 만들게 했고, [...slug] 패턴으로 모든 라우트를 커버함, getStaticPaths 함수를 활용해서 모든 페이지를 사전 생성했음, ISR/ISP 옵션 켜면 빌드타임에 몰랐던 페이지도 동적으로 프리렌더 됨, Next에선 dynamic routes, Astro에선 dynamic pages라고 부름
            참고: Next dynamic routes, Astro dynamic pages
          + 혹시 내가 이해를 잘못했을 수도 있는데, Astro의 getStaticPaths 함수가 원하는 기능 지원하는 것 같음
            참고
          + 나도 정적 배포를 좋아해서 참고 차원에서 말하자면, NextJS에서도 정적 파라미터 생성 지원함
          + 내가 Astro나 다양한 프레임워크를 완전히 이해한 건 아니지만, 혹시 Astro의 server islands가 원하는 기능과 비슷한지 살펴보길 추천함
     * 프론트엔드 논의 자체가 너무 혼란스럽다고 느껴짐, 기사에서 이야기하는 내용도 결국 “브라우저를 HMI로 쓸 것인가, 애플리케이션 런타임으로 쓸 것인가”로 귀결됨, 하지만 논의 대부분이 “신선하다”, “빨리 로드된다” 같은 애매한 주장임, 프레임워크를 브랜드처럼 홍보하는 분위기가 패션 산업과 너무 흡사하다고 생각함
          + 패션 산업이야말로 프론트엔드 프레임워크 논의를 설명할 수 있는 최고의 비유라고 봄, “content-driven”, “server-first” 같은 주장을 기술적으로 엄밀하게 따지는 경우가 거의 없음
          + “빨리 로드된다”가 허상이라고 하기엔 이해가 안 됨, 실제로 중요한 요소임
     * 최근 의료 기관 웹사이트를 Astro로 만들었는데, 예전에 Wordpress로 만들 때보다 훨씬 쉽고, 무료로 Netlify 같은 곳에 호스팅할 수 있어서 해킹 걱정 안 해도 됨, git 기반의 단순한 CMS까지 만들어서 클라이언트가 직접 컨텐츠도 수정 가능하게 했음, 웹 개발이 진짜 많이 발전했다고 느낌
          + 혹시 지인이 부탁해서 만든 것인지, 의료기관 웹사이트 제작 의뢰는 어떻게 구하는지 궁금함
          + Netlify가 Vercel보다 대역폭 요금이 더 높으니 주의하길 바람
     * Astro의 가장 큰 장점은 React나 Vue 같은 기타 프레임워크 의존 없이, HTML이나 Web Component만으로 작업 가능하다는 점임, 하지만 Astro 역시 Next, Nuxt와 마찬가지로 SSR, ISR, SSG, 미들웨어를 지원함
       차별점으로는 아일랜드 아키텍처가 있는데, 이를 통해 마이크로 프론트엔드 구현이 가능함
       예를 들어, 하나의 기업 내 여러 팀이 각각 결제, 장바구니, 상품 페이지를 만들어도 한 페이지에 통합 적용 가능하고, 렌더링 방식을 직접 제어할 수 있음, 글로벌 상태도 공유할 수 있어서 각 팀이 독립적으로 전체 책임을 지고 파트별로 개발/배포 가능함
       단, 이런 구조는 대형 프로젝트에나 필요한 솔루션임, 모든 팀이 React를 각자 다르게 쓰면 다양한 버전이 혼재하지만, Astro처럼 아키텍처로 분리하면 그 문제를 해결할 수 있음
       개인적으로 웹을 완전히 바꿀지는 확신하지 못함, Next/Nuxt에서 프레임워크 의존성 제거하고 아일랜드 아키텍처 추가된 정도라고 느낌, 하지만 써보는 걸 추천함
       React/Vue를 벗어나 web-component로 이전하거나 Next/Nuxt를 대체하고 싶으면 단계적으로 Astro를 활용할 수 있어 추천함
     * 나에게 Astro가 모든 상황에서 완벽하진 않음, 어떤 때는 offline rendering만 필요하다면 굳이 자바스크립트를 억지로 써야 할 이유가 없었음
       아일랜드 아키텍처도 한계가 있고, 빌드된 결과물이 지나치게 inlined되는 경우도 많아짐
       솔직히 Astro 하이프는 Vite 덕이 더 큰 것 같음, Vite는 정말 최고임
          + “아일랜드 아키텍처가 한계에 부딪힐 때”가 언제냐고 묻고 싶음
     * Next.js를 React의 표준 프레임워크로 추천하지 않았으면 함, 프론트엔드에는 더 비판적 사고가 필요함, Remix(React Router v7)나 TanStack이 훨씬 더 좋은 대안임
          + 나도 동의함, Next.js가 잠재력 있었던 건 맞지만 Vercel이 개입한 후로 많이 퇴보했다고 느낌, v10부터 써왔고, v13 혼란기와 v15까지 경험하면서 많이 실망했음, React와 Next.js는 변화 속도가 너무 빨라서 따라가기 불가능하고, 변화가 정말 필요해 보이는 순간보다 변화를 위한 변화가 더 많다고 느낌
          + React 자체를 디폴트 프레임워크로 추천하는 것조차 멈추고 싶음, 프론트엔드 개발에는 HTML/CSS/JS가 훨씬 낫다고 생각함
          + Remix/React Router v7은 올바른 방향이라 생각함, 특히 Remix가 preact를 쓰고 웹 표준 중심으로 간다면 더 견고한 웹사이트 제작 방식이 돌아올 거라 기대함, 다만 Remix에서 RR7로 갈아타는 전환이 매끄럽지 못해서 프로젝트를 rewrite해야 했음
     * 웹의 기본 원칙들은 여전히 유효하다고 생각함, PHP, Spring, Quarkus, ASP.NET MVC를 쓰는 개발자 입장에선 JS 프레임워크 기반 웹 개발 환경이 얼마나 힘들어졌는지 체감하지 못할 수 있음, 패션 주도적인 업계 분위기 탓에 기본으로 돌아가기가 쉽지 않다고 느낌
"
"https://news.hada.io/topic?id=21900","미국 법원, FTC의 "클릭 한 번으로 해지" 요구 규정 무효화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  미국 법원, FTC의 ""클릭 한 번으로 해지"" 요구 규정 무효화

     * 미국 법원이 FTC의 '클릭 한 번으로 해지(Click to Cancel)' 요구 규정을 무효화하는 결정을 내림
     * 법원은 FTC의 규제 과정에서 필요한 예비 분석이 부족했다고 판단함
     * 여러 업계 및 기업 단체가 FTC를 상대로 소송을 제기했고, 이들이 충분한 시간 내에 대응할 기회를 얻지 못했다는 점을 인정했음
     * 법원은 FTC의 절차가 규제 과정의 왜곡으로 이어질 수 있다고 경고했음
     * 향후 이 판결이 규제 절차와 공공 의견 수렴에 중요한 선례가 됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 미국 8순회 항소법원이 Federal Trade Commission(FTC)이 도입한 '클릭 한 번으로 해지' 규정(click-to-cancel rule)을 무효화하는 결정을 내림
     * 이 규정은 소비자가 온라인 서비스 구독을 간편하게 취소할 수 있도록 요구하는 조항이었음
     * 해당 결정은 아스 테크니카와 같은 기술 전문 뉴스 사이트에서 크게 주목받았으며, 여러 업계 단체와 사업자들이 단체로 FTC를 상대로 소송을 제기했음

FTC 주장 및 법원의 판단

     * FTC는 미국 법률상 규정 제정 시 예비 규제 분석(preliminary regulatory analysis) 을 별도로 진행할 필요가 없으며, 최종 규제분석만 제공하면 충분하다고 주장함
     * 그러나 판사들은 해당 법률상의 ""shall issue""라는 문구가 예비 분석을 반드시 공공 검토와 의견 수렴의 기회와 함께 제공하도록 명령하고 있다고 해석함
     * 규정 제정 과정에서 해당 분석이 없었기 때문에, 각 업계 단체와 기업들이 FTC의 분석 내용에 대해 충분히 의견 제시 또는 반박할 기회를 얻지 못했음

소송 배경 및 법원의 분석

     * 케이블 회사 등 여러 업계 단체와 기업들이 FTC의 규칙 제정절차가 부적절하다며 4개의 연방 순회법원에 제소함
     * 소송은 8순회 법원으로 통합되어, James Loken(조지 H.W. 부시 임명), Ralph Erickson, Jonathan Kobes(트럼프 임명) 등 판사들이 판결을 내림
     * 판사들은 최종 규제 분석 단계의 설명이 “형식적”이었고, 예비 분석에서 요구되는 비용-편익 대안 분석이 생략됐다고 지적함

판결문 요지

     * ""최종 규제분석이 공개됐을 때, 청구인들이 FTC의 대안별 비용-편익 분석을 평가할 기회를 갖지 못했음
     * 최종 규제분석에서의 대안 설명도 신중하지 않았음
     * 규정 제정을 중단하거나, 규제 범위를 대면 또는 우편 마케팅에만 한정하는 등의 대안들이 언급됐지만 심도 있는 논의가 이뤄지지 않음

예비 분석 미이행 시의 문제점

     * 해당 판결문은, FTC가 예비 경제영향분석 없이 규정 제정을 강행하는 경우, ""향후 규제과정의 공정성과 투명성을 훼손할 위험""이 있다고 판단함
     * 비현실적으로 낮은 영향 추정치를 먼저 제시하고, 공공의 추가 의견수렴 및 충실한 분석을 생략하는 절차 단축의 꼼수가 작동할 수 있음을 우려함

의미와 시사점

     * 이번 판결로 FTC의 향후 온라인 구독 해지 절차 관련 규정 입안이 지연될 전망임
     * 규제 당국의 공공 의견 수렴과 투명한 비용-편익 검토 절차가 더욱 강화되어야 함을 보여주는 결정임
     * 미국 스타트업 및 IT 서비스 기업에도 규제 변화에 따른 대응 과정의 중요성을 일깨우는 사례임

        Hacker News 의견

     * iOS/Apple 구독을 통해 결제할 수 있는 옵션이 있을 때 정말 좋아함, 여러 이유로 iOS 스토어가 욕을 먹지만, 이 한 가지는 진심으로 편리함을 느낌, 모든 구독을 한 곳에서 관리하며 단순하게 취소할 수 있음, 때로는 iOS로 결제할 때 1달러 이상 더 내야 할 때도 있지만, 번거로운 과정 없이 쉽게 취소할 수 있다는 점이 가격 차이 그 이상임을 느낌
     * 이 정책이 대체 어느 소비자를 돕는 것인지 모르겠음, 이런 법안은 기업들이 고객들을 상대로 노력이라는 장벽을 세우고 이득을 취할 수 있게 해 줄 뿐임, FTC가 “규칙 제정 과정”을 따르지 않았다는 트집은, 의도적으로 만들어진 핑계에 가까움
          + 실제로 기사를 끝까지 읽어 보면, 법원도 그 규칙의 취지를 이해하고 동정하는 듯했음, 하지만 FTC는 연간 1억 달러 이상의 경제적 영향을 미치는 규칙을 제정할 때 필수 예비 규제 분석을 해야 하는데, 이번에 그러지 않음, 이런 식으로 성급하고 부실하게 진행해서 법적으로 불안정해진 책임은 FTC에 있음
          + 결국 이 판결로 혜택 보는 쪽은 해당 법안의 입법자를 후원하는 대기업들임, 아니면 입법자들 자신이 혜택을 입는 구조임, 이런 판결은 사실상 돈으로 사들여진 것임
          + 법원은 행정부의 정책이 좋고 나쁘고, 소비자에게 유익한지 아닌지는 판단하지 않음, 법적으로 제대로 된 절차와 요건을 지켰는지만 점검함
          + 이 커뮤니티의 상당수는 “빠르게 움직이며 혁신하라”는 기업 논리에는 호응하지만, 일반인을 돕는 정책엔 무조건 속도를 늦추라고 함
          + 결과적으로 이 정책이 실질적으로 도움을 주는 쪽은 극소수의 부유층임
     * 대서양 건너 미국의 소비자 보호법이 이렇게 수준 떨어질 줄 몰랐음, 대부분의 유럽 국가는 각자 소비자 보호 기관이 있고, 불만 접수하면 몇달 걸려도 해결됨, 만약 지역 기관에서 실패하면 유럽 전체 기관에 호소 가능함, FTC 관련 소식 들으면 항상 잘못된 쪽의 편을 드는 듯한 인상임
          + 정말 맞는 말임, 미국 FCC나 FTC 누가 맡던지, 미국 심카드로 바꿔 끼우자마자 스팸 문자 폭탄을 받음, 반면 유럽 번호 쓸 때는 아예 0건임
          + 브라질과 우루과이도 소비자 보호법 잘 작동함, 아마 대서양 건너 더 많은 나라들도 그런데 가까움
          + 로마법 계열 민법 국가라면 FTC의 ‘원클릭 해지’ 규칙이 헛점이 있어도 공익을 본다는 이유로 통과시켰을 가능성이 큼, 반면 영미법 체계에서는 절차의 중요성이 더 크고, 그 과정에서 수상쩍은 마케터의 권리도 함께 보호받는 구조임
          + 미국 기업들이 대체로 고객 응대나 환불 정책은 유럽보다 훨씬 뛰어남, 문제는 해당 기업이 시장을 독점하거나 다른 대안이 없을 때 생김, 결국 건강한 경쟁이 보장된다면 미국식 방식도 잘 돌아갈 수 있다고 생각함, 문제는 최근 미국 기업 대다수는 독점 상태이고, 수익이나 주가 올리기 위해 소비자를 법을 피할 만큼만 괴롭히는 게 공식화 됨, 즉, 적절한 환경만 만들어지면 소비자 보호 기관이나 법 없이도 잘 돌아갈 수 있는데, 지금은 기업들이 ‘엔쉬티피케이션(enSHITTification)’을 극한까지 해 온 상황임
          + 신자유주의적 규제 완화와 감독 기관의 포섭 현상이 미국 연방 수준의 소비자 보호를 거의 사라지게 만들었음
     * 과거 Brilliant라는 학습 플랫폼을 썼음, 계정 해지 과정이 너무 복잡해서 사실상 해지가 불가능했음, 다크 패턴과 헷갈리는 언어로 설계됨, 환불도 거부당했고, 해지를 했다고 생각한 뒤에도 요금이 청구되어 어쩔 수 없이 은행에 차지백을 신청함, 이런 행태는 정말 문제이고, 소비자는 이런 것들로부터 반드시 보호받아야 한다고 생각함
          + EU에서는 서비스 해지 메일을 보냈는데 업체가 잊고 안 해줬음, 이전에 보냈던 메일을 증빙으로 다시 보내자 업체가 자기들 실수 인정하고 소급 적용으로 취소 및 환불 처리해줌
          + 나 역시 아이폰의 앱스토어를 통해서만 구독함, 가격이 비싸도 이런 편의를 위해 선택함
          + 질문: brilliant.org를 말하는 건지 확인하고 싶음
          + 공식 가이드(https://help.brilliant.org/en/articles/…)로 보면 실제로 취소가 불가능하진 않은 듯해서 의문을 제기함
     * 모든 구독 서비스는 기본적으로 주의해야 할 대상임, 가입은 쉬운데 해지하는 과정에서 소비자의 시간과 삶이 얼마나 번거로워질 수 있는지 고려해야 함, 이런 숨겨진 비용은 절대 잊으면 안 됨
          + 제공업체들이 인앱 결제(IAP) 구독을 싫어하는 이유 중 하나임, 수수료가 0%라도 해지까지 단 한 번 클릭이면 끝이라 비즈니스적으로도 손해임, 심지어 이런 행태는 그저 수상한 업체뿐 아니라 New York Times조차도 가입은 온라인에서 바로 가능하게 하지만 해지는 복잡한 전화 절차를 요구함, 요즘엔 차라리 즉시 결제 차단이 가능한 신용카드 쓰는 게 나음
          + 이 규제는 실제로 사업적으로도 긍정적인 효과를 가짐, 만약 소비자들이 카드 정보를 주는 걸 꺼리면 전체적으로 구독 시장이 줄어들기 때문에 진짜로 유령 구독자(zombie customers)만 쥐어짜려다 산업에 더 큰 타격을 줄 수 있음
     * 쉽게 설명하자면, FTC는 이 규칙이 기업들에게 큰 부담이 아니라고 주장함, 하지만 행정판사는 연간 큰 비용이 든다고 보고, 이런 큰 비용의 규정에는 FTC가 별도 절차를 따라야 하는데, 이번에 그 과정을 안 지켜서 결국 판결이 규제에 반대하게 됨, FTC가 제대로 하려면 아예 포괄적으로 ‘복잡한 해지 과정 금지’라는 애매한 원칙을 제시하고, 상세 기준 없이 기업이 단순 해지 프로세스를 제공하도록 실제 동기를 부여하는 방법이 더 효과적임
     * FTC가 당시 필수 절차를 무시하고 편법으로 규칙을 만들고 있다 경고가 있었는데, 실제로도 법원의 검증을 통과하지 못함
          + 그런 경고 사례가 실제로 있었는지 물어봄
          + 누가 경고했는지 질문함
          + 그 원인이 조직적 부패라고 추정함
     * 판결문 전체가 궁금하면 다음 링크를 참고하라고 권유함 https://ecf.ca8.uscourts.gov/opndir/25/07/243137P.pdf
     * ‘해지 링크’라는 게 실제론 이 계정이 실사용자임을 증명하라는 미끼에 가까워 보이고, 업체들은 이 정보를 비싸게 팔 것 같다고 의심함
          + 이런 의심은 보통 스팸 이메일 관련 이야기임, 이번 사안은 실질적으로 유료 구독 서비스 해지와 관련 있음, 쉽게 가입은 되지만 해지는 엄청 어렵게 만드는 기업 타깃임
          + 이런 의심도 이해가 가지만, 기사에서 다루는 구독과는 별개의 이야기임
          + 마치 브라우저 팝업에서 허용/차단만 제공하는 것과 비슷함, 둘 다 싫은데 차단하면 해당 사이트가 내 리스트에 영구 등록되는 건 원치 않음
          + 차라리 스팸으로 표시해버리는 게 업체에 훨씬 더 타격이 가고, 아무 알림도 안 감
     * 참고로 privacy.com을 이용하면 됨, 일회용 가상 카드 만들어서 결제하도록 하고, 해지 안 되는 경우 자동으로 결제 차단 가능, 서비스 업계가 제대로 바뀔 때까지는 이게 최선의 방안임
          + 예시로, New York Times가 결제 시도를 반복한 적이 있는데, 업체가 원한다면 “강제 승인”을 통해 차단을 무시하고 결제를 강행할 수 있음, 이건 명백한 가맹점 약관 위반인데도 실제로 감행하는 경우가 있음, privacy가 완벽한 해결책은 아님
          + 그 결과 미납금이 채권 추심으로 넘어가면 신용 점수 하락으로 연결되어 다음 자동차 할부나 주택 대출금리에 영향줌, 결국 기업과 직접 문제를 해결해야 하고 필요하면 증거를 첨부해서 차지백 신청까지 해야 함, 가상카드만으로 청구서가 사라지진 않음
          + 그러다 정말 추심 절차로 넘어갈 위험이 있음
          + privacy.com은 아이슬란드에 기반을 둔 금융기술 플랫폼이고, FDIC 보증 은행과 제휴하고 있음, 방화벽, 암호화, PCI DSS 준수 등 보안에 집중하고, 사용자 스스로 카드 사용을 제한하거나 일시 중지 및 폐기가 가능함
          + EU 고객도 쓸 수 있는 유사 서비스가 있는지 질문함
"
"https://news.hada.io/topic?id=21927","Show GN: Incus(구. LXD)를 위한 간단한 원격 관리 앱을 만들어 보았습니다!","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Show GN: Incus(구. LXD)를 위한 간단한 원격 관리 앱을 만들어 보았습니다!

   안녕하세요! 코딩을 이제 배우고 있는 컴퓨터SW 전공의 대학생입니다.
   이 프로젝트는 init까지 포함한 시스템 컨테이너를 쉽게 생성해주는 Incus에 대한 클라이언트입니다. 아직 기능도 적고 프로토타입이지만 관심 가져주시면 감사하겠습니다!
   간략한 설명은 아래와 같습니다.
     * 간편한 파이썬 앱으로 컨테이너 관리
     * SSH 포트 제공으로 CLI 개발환경 제공
     * 30001, 30002번을 테스트용 포트로 제공
     * 원격 상태 조회 및 변경(freeze 포함), 파일 푸시
     * 사용자를 네임스페이스처럼 사용 가능: 사용자가 삭제될 시 모든 컨테이너 삭제
     * 중복 태그 사용가능: 실제 이름으로는 별개의 고유 스트링 부여

   이 앱을 사용하며 얻을 수 있었던 장점은 다음과 같았습니다.
     * 이동 중 간단한 컨테이너 설정 가능
     * Init까지 가상화한 시스템 컨테이너를 원클릭으로 다수 생성
     * 간단한 NGINX html 서브 시 문서, 이미지 교체 수월
     * 프로젝트의 build script를 가상 환경으로 테스트

   성취한 핵심 성과
     * Incuspeed 빌드 테스트를 Incuspeed로: 자기 자신을 이용한 빌드 테스트
     * Nginx가 보여주는 샘플 이미지 원격 변경
     * 다양한 배포판 체험

   지원하는 배포판
     * AlmaLinux 9
     * RockyLinux 9
     * Debian 10,11,12
     * Devuan Beowulf, Chimaera, Daedalus (기본적으로 sysv로 init이 교체된 데비안)
     * Slackware current, 15.0 (slackpkg+ 셋업은 기본 탑재X)
     * Centos 9 Stream
       Incus 공식 Image 중 제가 사용해 본 배포판은 모두 SSH 셋업까지는 끝냈습니다.

   추후 고민 중인 기능
     * 스냅샷 원격 생성/관리
     * 현재 컨테이너를 이미지로 저장

   아직 아마추어지만 좋은 인상을 드리고 싶습니다!

   참고로 내부의 30001, 30002번은 외부로는 SSH 포트 +1, SSH 포트 +2로 매핑됩니다.
"
"https://news.hada.io/topic?id=21943","강황에 사용된 납 색소, 전 세계적 납 중독 미스터리의 범인임이 밝혀짐 (2024)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             강황에 사용된 납 색소, 전 세계적 납 중독 미스터리의 범인임이 밝혀짐 (2024)

     * 방글라데시 강황에서 발견된 납 색소가 전 세계 납 중독의 새로운 주요 원인으로 확인됨
     * 뉴욕과 방글라데시를 연결한 과학자와 보건탐정의 협업으로 미스터리가 해결됨
     * 방글라데시에서는 납 크로메이트를 강황에 첨가하여 색을 밝게 하는 관행이 폭로됨
     * 정부의 공개 단속과 교육 캠페인 이후 강황 내 납 검출률이 47%에서 0%로 급감함
     * 하지만 여전히 기타 향신료, 화장품, 주방용품 등에서 납 노출 위험이 남아 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

방글라데시 강황과 납 중독의 연결고리

   방글라데시에서 인기 있는 향신료인 강황에 1980년대부터 일부 농민들이 더 선명한 색감을 위해 염료를 첨가하기 시작함. 그러나 이 염료가 납이 포함된 색소였다는 사실이 알려지며, 광범위한 중독 문제가 발생함

납 중독의 글로벌 현실

     * Simon Fraser University의 Bruce Lanphear 박사는 전 세계 약 8억 명의 어린이가 납에 중독된 상태이며, 이는 전 지구적 아동의 절반에 해당함을 언급함
     * 납 중독의 원인은 가정용 조리기구, 식품, 대기 등 다양하며, 저소득국 및 중간소득국에서 특히 심각한 문제임
     * 몇십 년 동안 대책이 미흡했으나, 두 여성 연구자—뉴욕 보건국의 탐정과 캘리포니아의 대학원생—이 글로벌 조사로 큰 전환점을 만듦

뉴욕과 방글라데시, 동시 발견된 수수께끼

  뉴욕의 납 탐정

     * 뉴욕 보건국은 미성년자 중 납 수치가 높게 나타난 방글라데시 출신 아동이 이상하게 많음을 발견함
     * 탐정팀은 가정 내 벽, 가구, 장난감, 의류 등을 측정기로 검사하며 원인을 추적함
     * 그러나 방글라데시 가정에서 기존 통념상 원인(페인트, 토양 등)이 발견되지 않았음

  방글라데시 산모의 높은 납 수치

     * Jenna Forsyth는 방글라데시 산촌 임신부 400명 이상의 혈액 데이터를 분석하던 중, 절반 이상의 고납 수치를 확인함
     * 다양한 가능성—농약, 캔 솔더, 쌀, 토양 등—을 조사했으나 원인을 밝히지 못함

미스터리의 해결, 강황의 납 색소

   Forsyth 팀은 기존 연구에서 소수 아동의 중금속 노출 사례 중 강황에서 납이 검출된 논문을 발견함
     * 직접 채취한 강황 가루와 뿌리에서도 납이 다량 확인됨
     * 혈액 내 납과 강황의 납 지문이 일치함
     * 현지 농민 조사 결과, 1980년대 큰 홍수 이후 강황의 색을 복구하기 위해 공업용 납 크로메이트를 사용하기 시작한 것이 관행이 됨

방글라데시와 글로벌 대응

     * 이 실태는 방글라데시와 뉴욕 방글라데시 커뮤니티 내 납 중독을 동시에 설명할 수 있었음
     * 미국 내 향신료 중 대표적으로 해외에서 캐리어 가방을 통해 반입된 강황에서 높은 납 농도가 나타남
     * 2019년 방글라데시 당국은 공공 캠페인, 농가 교육, 시장 내 대대적 단속을 전개함
     * 이동식 법정에서 직접적인 압류와 벌금 부과를 실시하며, 강황 샘플의 납 함유율이 47%에서 0%로 감소하는 변화가 관측됨
     * 여성, 농민 등 실제 중독자들의 혈액 납 수치도 크게 감소함

남은 과제와 글로벌 확산 방지

     * Forsyth와 icddr,b는 인도, 파키스탄 등 아시아권 국가에서도 강황 및 기타 향신료에 납 오염이 있음을 밝힘
     * 강황 이외에도 납산 배터리, 금속 조리기구, 부실 도자기, 납 함유 화장품 등 다양한 출처가 남아있음
     * 미 CDC 기준, 현재도 방글라데시 수도 Dhaka의 아동 98%가 납 중독 범주임
     * 최근 유니세프와 USAID가 연 1억 5천만 달러 규모의 글로벌 납 퇴치 이니셔티브를 발표함
     * 주요 목표는 페인트, 향신료, 화장품 속 납을 퇴출하는 데 있으며, 저비용으로 큰 효과를 낼 수 있는 '로우 행잉 프루트' 위주로 접근 예정임

결론

   Jenna Forsyth와 동료 탐정 및 전문가들은 아직도 다양한 경로에서 납 오염 사각지대를 찾고 있음. “아이의 납 중독 사실을 부모에게 통지하는 일은 매우 고통스럽다”는 말처럼, 언젠가는 더 이상 이 소식을 전하지 않아도 되는 날이 오길 꿈꾼다는 소망을 밝힘

        Hacker News 의견

     * NPR 기사에서 너무 빨리 긍정적인 관점으로 포장하는 느낌을 받음, 미국인이 엑스레이 건으로 모든 문제를 해결한 것처럼 꾸몄는데, 만약 미국인이 아닌 관련자들에게도 어느 정도 책임이 있다면 이 문제가 미래에 다시 발생할 수 있다는 우려가 듦
          + 기사에서, 최근 UNICEF와 USAID가 1억 5000만 불 규모의 납 중독 근절 프로젝트를 시작했다고 밝힘, 하지만 미국인들도 USAID 등에서 책임이 있으며 반복적으로 문제가 계속되는 구조임
          + 과거 인도네시아의 ""유독성 두부"" 사건이 떠오름, 자세한 내용은 YouTube 영상 또는 NYTimes 기사 참고 바람
          + 기사 내용에서 농부들이 납 크로메이트가 건강에 미치는 영향을 몰랐고 단순히 사업 확장을 위해 사용했다고 나오는데, 이게 단순한 사기와 부주의라고 해서 용서해도 되는 일인지 의문임
          + NPR 기자가 의도적으로 이야기를 미화한 건 아니라고 생각함, 기자 입장에서는 돈을 위해 일부러 사람을 해칠 일이 없으니, 경제적 절박함과 무지 외에는 이런 사태가 일어날 이유가 없다고 쉽게 생각하는 듯함, 결국 두 요인만 사라지면 문제는 영원히 해결된다고 믿는다는 맥락임
          + 일화에서 누가 주체성을 결여하는지 항상 점검하는 방식을 따름
     * 인도에서 자라 미국에 사는 입장에서, 엄마가 가족 농장에서 직접 가져온 강황과 미국 인도마트에서 파는 강황 색이 현저히 다르다는 것에 충격받았음, 혹시 캘리포니아에서 파는 강황조차 납이 섞인 것 아닐까 두려워짐
          + Burlap and Barrel은 자사 강황에 대한 납 검사를 실시하고 결과를 공개함, 가격은 더 비싸지만 더 이상 검증되지 않은 강황은 구입하고 싶지 않음, 참고로 Lundberg는 현미의 비소 수치를 공개하여 그 브랜드만 구입함
          + 강황이 제대로 수입·통관된 매장에서 산 것이라면 걱정할 필요 없을 듯함, 기사는 미국 방글라데시 커뮤니티에서 슈트케이스로 들여온 강황에서 해당 문제가 발견된 것이라고 언급함, 색상 차이는 가족 농장의 태양건조 방식과 산업적 동결건조/분무건조 방식, 또는 산화 방지 첨가제가 이유일 수 있음, 일반적으로 포장에 아르곤 가스를 사용하는 경우가 많음
          + 물을 이용한 납 혼입 강황 테스트 방법이 실제로 유효한지 궁금함, 관련 YouTube 영상 참고 바람
          + 개인용 XRF 검사기 구매를 고려 중임, Alibaba에서 5000~10000달러에 판매되는 것 같음, 오버스펙일 수 있지만 건강 걱정과 함께 이런 장비 자체를 갖고 싶음
          + 기사에서 ""분말 상태에서는 알아볼 수 없다""고 설명함, 즉 ""버핑"" 단에서 납 크로메이트가 첨가되어 뿌리가 마치 잘 건조된 것처럼 보이는 효과임, 사과처럼 매끄럽고 광택 있는 왁스 코팅과 유사함, 분쇄된 강황을 판매하는 경우엔 굳이 납 크로메이트를 쓸 이유가 없을 듯함
     * 기사에서 이 사건을 마치 추리소설처럼 구성한 방식이 불편함, 인도 및 남아시아는 중금속 계 살충제 같은 문제로 고통받고 있음, ""범인을 맞혀보세요"" 같은 접근은 적절하지 않음, 강황에 대해 무지한 것도 아니고, 이런 건강 영향도 다들 알고 있지만 신경쓰지 않는 경우가 많음, 대형 가공·포장 기업들의 책임이 생략된 점도 문제로 보임
          + 개인적으로 이야기가 재미있었음, 특정 문화권 인구에서 혈중 납 수치 이상치를 발견하고, 장기간 추적 끝에 특정 향신료의 첨가물로 원인을 좁혀내는 과정이 흥미로움, 그래도 납 크로메이트는 살충제가 아니고, 인체 해악 정도도 살충제와 차이가 있음, 일반적인 식품에 포함된 중금속만으로는 이런 혈중 수치가 나올 일이 거의 없음
          + 실제로 농부들이 강황을 더 보기 좋게 하려고 납 페인트를 칠하는 이슈였음, 대기업이 다 한 건 아님
          + 이 문제는 살충제나 강황 일반 지식이 아니라, 일반적으로 쓰이지 않는 착색제인 납 크로메이트의 문제임, 일부 오염은 대기업에서도 일어났지만 많은 사례는 그와 무관함
          + 미국 출신으로서 식품 안전에 대해 대략적으로나마 이해하고 있음, 이런 중독 사태가 놀랍게 느껴지지 않음, 중국에서 어린이 급식에 적색 색소가 들어간 유사 사건도 있었고, 엑스트라 버진 올리브유, 연어, 꿀 등도 진짜보다 대부분 가짜임, 문제는 테스트·규제가 거의 없고 곧 법치주의 조차 무너질 것 같은 두려움임, 미국에서도 부적절한 로비나 뒷돈만 있으면 멜라민 분유, 납 페인트 식품 판매가 가능해질 듯하고 결과는 항상 ""외국인 탓""으로 돌려버릴 것 같음
          + 중금속시험은 너무나 간단하고 저렴하게 할 수 있으니, 유통사는 매 배치마다 검증하고 오염이 있으면 바로 신고하는 게 정상임
     * USAID의 최근 예산 감축에도 불구하고 이런 프로젝트가 살아남았는지 궁금함, 최근 UNICEF와 USAID가 1억 5천만불 규모의 납 중독 근절 프로젝트를 발표했다고 함
          + 발표 내용 중 ""세계가 함께 나선 건 너무 늦은 감이 있다""는 Samatha Power의 코멘트가 있는데, 소개 페이지 는 접속이 안 되고, 현재는 일부 인력만 제외하고 전 세계적으로 행정 유급휴직 상태임
          + 발표한 기관과 자금을 대는 기관(Lead Exposure Action Fund)은 다름, 자금은 Gates Foundation과 기타에서 조달됨, 자세히 보기
     * 논문을 읽어본 결과, 가루 강황과 광택 처리된 강황뿌리가 주된 오염원임, 페인트나 염료로 쓰이는 납 크로메이트 첨가로 인해 그렇다고 설명함, 브랜드/포장 강황이나 자연 그대로의 거친 강황뿌리를 쓰는 소비자는 비교적 안전한 편임(논문은 브랜드/포장 강황의 차이를 표2에서 구분했으나 명확히 설명하지는 않음), 인도의 Patna가 납 오염 강황의 주요 공급원이고 이곳에서 수출된 강황이 Guwahati, Assam 등지에서 주로 발견됨
     * 집에 있는 5년 된 Sadaf 강황을 3M 납 테스터로 바로 검사해보았고 다행히 음성으로 나옴
          + 기술적으로 말이 안 되는 것 같음, 시중 저가 테스트 키트는 식품에 쓰기엔 검사 하한치가 너무 높음, 해당 3M 제품은 원래 페인트용이고 최저치가 수천 ppm 단위임, 반면 실제 강황 납 오염 수준은 수백 ppm, 미국 기준 식품 허용치는 억분의 일 이하 수준임, 중금속은 체내 축적 특성이 있음, 3M 설명서, 최대 오염 논문, US 식품 규제 기사
          + 3M 테스트 키트는 식품 안전 기준의 최대 100만 배에 해당하는 농도에서만 탐지 가능함, EPA 리포트
          + 훨씬 더 간단하고 정확한 검출법도 있음, Indian food regulator의 매뉴얼 참고
     * 영국 거주자라면 FSA에서 강황 안전성을 점검중이니 참고 바람, 조사 링크
     * 기사 제목 자체가 범인을 드러내긴 했지만, 방글라데시에서 강황을 더 잘 팔기 위해 밝은 노란색의 납 크로메이트가 첨가된 사실을 좀 더 명확히 설명했으면 좋겠음, 원래 최고의 강황은 자연스럽게 매우 밝은 노란색임
     * 집에서 이런 불순물 오염을 직접 검출할 수 있는 방법이 있으면 좋겠음
          + 인도 정부 유튜브 채널에서 이런 가정 검출법 관련 영상들이 많음, YouTube 채널
          + Eat Right India 캠페인, 강황 납 검출 테스트 #14
          + 화학자가 아니니 정확하진 않지만, 납 크로메이트와 베이킹 소다를 섞으면 흰색 침전물이 생기지 않을까 추정함, 베이킹 소다는 대부분 집에 있음
          + 납 검출 키트도 있긴 하나 가격이 비싸고 성능이 믿을 만한지 모르겠음
          + 앤틱 도자기용으로 매우 민감한 납 검출 지시약도 있음, 손에 들고 다니는 휴대 스캐너는 차 한 대 값이나 하고, 이런 기기로 장난감/식품 스캔을 통해 FDA 금지 절차가 시작됨, 가능한 로컬 식재료 구입 권장
     * 이번 주 같은 색소 이슈가 중국에서도 발생함, 관련 기사
"
"https://news.hada.io/topic?id=21909","LLM 시대의 글쓰기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              LLM 시대의 글쓰기

     * 최근 LLM을 이용한 글쓰기가 늘어나면서, 자연스럽지 않은 글쓰기 패턴이 눈에 띄게 많아짐
     * 빈약한 요약 문장, 과도한 불릿 포인트, 단조로운 문장 리듬 등은 LLM 글쓰기의 대표적 문제점임
     * 정보 밀도가 낮거나, 모호한 표현이 자주 등장해 실질적 인사이트가 부족해지는 경향이 있음
     * 반면, 의도적 반복, 명확한 표지 구문, 평행 구조 등은 LLM 스타일로 오해받지만, 실제로는 효과적인 글쓰기 도구임
     * 저자는 LLM을 활용해 아웃라인 설계와 초안 생성, 부분별 리라이트에 도움을 받으면서도, 최종 판단과 깊이 있는 내용 구성은 인간의 몫이라고 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Common Patterns of Bad Writing I See from LLM Tools

     * 최근 몇 년 동안 여러 기술 논문과 블로그 글을 작성하고 리뷰하면서, LLM 기반 글에서 항상 어딘가 미묘하게 ""어색하고 덜 매력적""인 느낌을 자주 받음
     * 동시에, 초안 작성, 복잡한 자료 요약, 흐트러진 생각 정리에는 LLM 활용이 큰 도움을 주는 것도 경험함
     * 이 글에서는 LLM이 많이 생성하는 나쁜 글쓰기 패턴과, 흔히 “LLM 스타일”로 오해받지만 사실은 괜찮은 글쓰기 습관, 그리고 필자가 실제로 사용하는 작성 및 프롬프트 규칙을 공유함

  Empty “summary” sentences that pretend to conclude a thought

     * 문단 마지막에 “By following these steps, we achieve better performance.”, “By internalizing these principles, you can cut through the noise.”와 같이 결론처럼 보이지만 실질적으로 아무 의미 없는 요약 문장이 자주 등장함
          + “이 과정을 따르면 더 나은 성능을 얻을 수 있음”
          + “이 원칙을 내재화하면 혼란을 헤치고 나아갈 수 있음”
     * 이런 문장은 독자에게 새로운 통찰이나 고민거리를 제공하지 못함
     * 필자 역시 LLM에게 이런 실질적 메시지가 담긴 문장을 쓰게 만드는 확실한 방법을 찾지 못함

  Overuse of bullet points and outlines

     * LLM은 불릿 포인트(리스트)와 아웃라인을 과도하게 남용하는 경향이 있음
     * 항목들이 평행하고 독립적일 때는 리스트가 유용하지만, 아이디어가 연결되거나 맥락이 중요한 부분에서는 문단이 더 적합함

  Flat sentence rhythm

     * 모든 문장이 비슷한 길이와 구조로 반복되면 글이 지루해지고, 읽는 사람이 따라가기 어려워짐
     * 문장 길이와 리듬을 다양하게 조절해야 강조, 주의 환기, 속도 조절이 가능해짐
          + Bad example:
            ""We recently launched a conversational AI feature that lets users ask questions in plain English and get responses based on their past activity and current session. The system searches a database of help articles, ranks the most relevant ones using a custom scoring function, and passes the top result into a language model to generate the final answer. We spent weeks optimizing each step to keep latency under 300 milliseconds, including caching, pruning irrelevant articles, and tuning prompt templates.""
            ""우리는 최근 사용자가 평문으로 질문하고 이전 활동과 현재 세션을 기반으로 답변을 받을 수 있는 대화형 AI 기능을 출시함. 이 시스템은 도움말 아티클 데이터베이스를 검색하고, 커스텀 점수 알고리듬으로 가장 관련성 높은 항목을 선정한 뒤, 그 결과를 언어 모델에 전달하여 최종 답변을 생성함. 각 단계의 지연 시간을 300밀리초 이내로 유지하기 위해 캐싱, 불필요 아티클 제거, 프롬프트 템플릿 최적화 등에 몇 주를 투자함""
          + Good example:
            ""We just launched a new conversational AI feature. It answers user questions in plain language, using context from the current session. The system searches help articles, scores them with a custom ranking function, feeds the top result into a fine-tuned language model, and runs in under 300ms using caching, pruning, and prompt tuning techniques.""
            ""우리는 새로운 대화형 AI 기능을 출시함. 이 기능은 현재 세션의 맥락을 이용해 사용자의 질문에 평문으로 답변함. 시스템은 도움말 아티클을 검색하고, 커스텀 점수화로 최상위 결과를 선정하여, 미세 조정된 언어 모델에 입력함. 캐싱, 데이터 정제, 프롬프트 튜닝을 적용해 300밀리초 이내로 동작함""

  Not the right subject

     * 주어 선정이 부적절할 때 문장 핵심이 흐려짐
          + Bad example:
            ""Readers are better guided when the subject matches the main idea of the sentence.""
            ""주어가 문장의 핵심 아이디어와 맞을 때 독자가 더 잘 안내받을 수 있음""
          + Good example:
            ""Choosing the right subject keeps the writing clear and focused.""
            ""올바른 주어 선택이 글의 명확성과 집중도를 높여줌""
     * 올바른 주어 선택이 글의 일관성, 집중력에 중요함

  Low information density

     * 아래는 Gemini 2.5 Pro로부터 받은 LLM 생성 글의 예시임:

     ""As someone who writes, reviews, and deconstructs complex information for a living, I’ve developed a strong allergy to bad writing. And lately, a lot of that bad writing has a specific, synthetic flavor—the unmistakable scent of an LLM. This post is a guide to navigating the new world of writing, with or without LLM assistance. First, I’ll cover the true pitfalls of LLM-generated text—the red flags that make it feel sterile and unconvincing.""
     ""복잡한 정보를 다루고 글을 쓰고 리뷰하는 사람으로서, 나쁜 글쓰기에 민감해짐. 최근엔 그 나쁜 글이 점점 인공적이고 LLM 특유의 향을 띔. 이 글은 LLM이 있는 시대의 글쓰기를 다루는 가이드임. 먼저 LLM이 만드는 대표적인 문제점들을 살피고자 함.""
     * 문장 구조나 문법은 완벽하지만, 실질적 통찰이나 구체적 정보, 논지의 진행이 없음

  Vagueness

     * LLM 글은 구체성 회피 경향이 강함
     * 아이디어를 명확히 정의하지 않고, 증거 없는 주장을 하거나, 누구의 이야기인지 불분명하게 작성함
       “Some experts say prompt engineering is becoming less important. The ability to simply prompt LLMs can have a major impact on productivity.”
       “일부 전문가들은 프롬프트 엔지니어링의 중요성이 줄어든다고 말함. LLM에 단순히 프롬프트를 입력하는 능력이 생산성에 큰 영향을 줄 수 있음”
       → 누가, 어떤 맥락에서, 누구에게 영향을 주는지 등 구체적 근거와 대상이 부족함

  Overuse of demonstrative pronouns

     * ""this"", ""that"", ""these"", ""those"" 등 지시대명사 남용이 많아짐
     * 참조하는 명사가 명확하지 않으면 독자가 내용을 놓치기 쉬움
       “This creates friction in production.”
       “이로 인해 프로덕션 환경에서 마찰이 발생함”
       여기서 ""this/이""가 무엇을 가리키는지 명확하지 않음

  Fluency without understanding

     * 겉보기에 매끄럽지만 실제로 설명력이 부족한 문장이 자주 등장함
       “LLMs use attention mechanisms to generate contextually appropriate responses.”
       “LLM은 어텐션 메커니즘을 활용해 맥락에 맞는 응답을 생성함”
       → 독자가 attention이 뭔지 모르면 아무런 정보도 전달하지 못함
     * LLM은 기존에 없는 용어를 만들어내는 경우도 잦음
       “We used GPT-4 for summarization, but it hallucinated details, so we added retrieval grounding.”
       “우리는 요약에 GPT-4를 사용했으나, 사실을 잘못 생성해 retrieval grounding을 추가함”
       → “retrieval grounding”은 실제 존재하지 않는 용어임
     * LLM은 독자의 배경지식과 설명 필요성을 구분하지 못해 어려운 부분은 자주 넘어가버림

Writing Patterns People Flag as “LLM-Like,” But Are Actually Fine

     * 사람들이 LLM 스타일이라고 지나치게 경계하지만, 실제로는 효과적이고 일반적인 글쓰기 패턴도 있음
     * 중요한 것은 모델처럼 보이지 않는 글을 쓰는 것이 아니라, 명확함, 의도, 통제력을 가진 글을 쓰는 것임

  Intentional repetition

     * 반복은 복잡한 아이디어를 명확히 하거나 강조할 때 효과적임
       ""Vector databases store embeddings, or mathematical representations that capture semantic meaning in hundreds of dimensions. In other words, vector databases help find results that are “close” in meaning, not just exact text matches.""
       “벡터 데이터베이스는 임베딩, 즉 수백 차원에서 의미를 포착하는 수학적 표현을 저장함. 다시 말해, 벡터 데이터베이스는 텍스트가 정확히 일치하지 않아도 ‘의미상 가까운’ 결과를 찾는 데 도움을 줌”

  Signposting phrases

     * ""essentially"", ""in short"", ""the point is..."" 같은 표지 구문은 뒤에 실제 정보가 따라온다면 유용함
       예시:
       ""Essentially, instead of classifying the document as a whole, we classify each section independently.""
       “본질적으로, 문서 전체를 분류하는 대신 각 섹션을 개별적으로 분류함”

  Parallel structure

     * 평행 구조는 아이디어를 조직적으로 정리하고, 문장 흐름을 매끄럽게 만듦
       ""The system scales across inputs, stays responsive under load, and returns consistent results even with noisy prompts.""
       “이 시스템은 다양한 입력을 확장 처리하고, 부하 상황에서도 반응성을 유지하며, 프롬프트가 혼란스러워도 일관된 결과를 반환함”

  Section headings that echo a structure

     * “Why X fails”, “What to do instead”, “How to know if it worked”처럼 예측 가능한 구조의 섹션 헤딩은 내용이 명확하다면 충분히 효과적임

  Declarative openings

     * 단호한 선언형 문장으로 섹션을 시작하는 것은, 뒷받침되는 증거나 설명이 있다면 오히려 글의 초점을 강화함
       예시:
       ""LLM evaluations are hard to get right. Many rely on user-defined gold labels or vague accuracy metrics, which do not work for subjective or multi-step tasks.""
       “LLM 평가를 제대로 하는 것은 어려움. 많은 평가는 사용자 정의 기준이나 모호한 정확도 지표에 의존하는데, 이는 주관적이거나 복잡한 작업에는 적합하지 않음”

  Em dashes

     * 엠 대시(—) 는 문장 내에서 부연설명이나 리듬 변화, 빠른 전환 등에 유용함
     * 적절히 사용하면 자연스러운 구어체 흐름과 강조에 도움이 됨

How I Write with LLMs

     * 필자는 글쓰기에서 흐름(모멘텀)을 유지하는 것을 가장 중요하게 생각함
     * 실제 논문이나 블로그 글 작업 과정은 대개 아래와 같음
          + 아웃라인 계획(종이에 쓰거나 머릿속에 그리기)
          + 초안 생성
          + 작성한 내용 읽기 및 비판적 검토
          + 수정
     * 이 과정은 문장 단위, 섹션 단위 등 다양한 범위에서 반복될 수 있음
     * 사람마다 계획 단계, 초안 작성, 수정 단계 중 막히는 부분이 다름
          + 필자는 아웃라인은 빨리 만들지만, 표현 방식(phrasing)에서 자주 막힘
          + LLM을 막힌 부분을 넘어가거나 초안 구성을 빠르게 하기 위한 도구로 적극 활용함

  Narrate the story to the model

     * 초안 시작 시, 동료에게 구조를 설명하듯 러프하게 이야기를 적어 LLM에 붙여넣고, 상세한 아웃라인 생성을 요청함
     * 구조가 명확해질 때까지 이 작업을 반복함

  Write the paragraph myself, even if it’s rough

     * 아웃라인이 완성되면, 각 문단은 직접 작성하려고 노력함(거칠어도 상관없음)
     * 문장을 끝까지 쓰기 어려울 때에는 “finish it” 식으로 LLM에 요청해서 여러 완성본 중 최적의 것을 선택, 필요하면 약간 수정해 활용함
       “In the last couple of years, I’ve written and reviewed several technical papers and blog posts. Something always feels slightly off, enough to make the writing quietly uninviting. At the same time, I feel like I get tremendous value from using LLMs to write…” “finish it”
       “지난 몇 년간 여러 기술 논문과 블로그 글을 썼음. 항상 어딘가 미묘하게 어색해서 글이 조용히 매력을 잃는 경우가 있었음. 동시에 LLM을 활용해 글을 쓰는 데서 엄청난 가치를 얻는다고 느꼈음…” “finish it”
       → 모델이 여러 제안을 내고, 그 중 가장 나은 것을 골라 약간 수정해 넘김

  Use scoped rewrite strategies during revision

     * 문단이나 문장이 어색할 때는 “make it better” 대신 구체적인 요청이나 패턴(수사적 구조 등) 을 LLM에 전달함
     * 예시 전략:
          + 주어와 동사를 최대한 가깝게, 문장 초반에 배치
          + SWBST(누가, 무엇을 원했으나, 어떤 장애물 때문에, 어떻게 대응했고, 결과는 어땠는가) 구조 활용
               o 예시:
                 ""We used GPT-4 for summarization. We wanted fluent answers, but it hallucinated facts. So we added a retrieval step. Then we re-ranked outputs based on citation accuracy.""
                 “우리는 요약에 GPT-4를 사용했음. 유창한 답변을 원했지만, 사실을 잘못 생성함. 그래서 retrieval 단계를 추가함. 그 후 인용 정확도 기준으로 결과를 재정렬함”
               o SWBST 구조는 기술 글에서도 동기, 문제, 대응, 결과를 간결하게 전달하는 데 효과적임

Parting Thoughts

     * 이제는 중간 수준의 글(평균적 품질) 은 LLM으로 손쉽게 생성할 수 있는 시대임
     * 하지만 무엇을 쓸지, 어떤 관점과 구조를 선택할지, 어디서 깊이 들어가야 할지 판단하는 일은 여전히 사람의 몫임
     * 진정 좋은 글은 분량에 걸맞은 실질적 기여가 있어야 하며, 독자가 시간을 투자할 가치가 있도록 해야 함
     * 이 기준을 충족하는 것이 필자가 추구하는 목표임

   긱뉴스는 그런 면에서 정보 밀도가 높아서 좋다고 생각합니다.
   음슴체로 끝나는 게 정말 밀도 최적화 같아요
"
"https://news.hada.io/topic?id=21920","경험 많은 오픈소스 개발자의 생산성에 미치는 "AI의 임팩트" 측정하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                경험 많은 오픈소스 개발자의 생산성에 미치는 ""AI의 임팩트"" 측정하기

     * 2025년 초기의 AI 도구가 오픈소스 개발자의 실제 생산성에 미치는 영향에 대한 무작위 대조 실험 실시
     * 연구 결과, AI 도구 사용 시 작업 완료 시간이 평균 19% 더 오래 소요됨
     * 개발자들은 AI가 자신들을 24% 더 빠르게 해줄 것으로 기대했으나 실제 체감과 달리 속도 저하 현상 발생
     * 벤치마크와 일상 경험에서 나타나는 AI 능력과 실제 효과 간의 괴리는 매우 두드러짐
     * 연구는 AI 생산성 영향의 정확한 이해와 다양한 평가 방식의 중요성을 강조함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 본 연구는 2025년 초기(Early-2025) AI 도구가 경험 많은 오픈소스 개발자들의 생산성에 미치는 영향을 확인하기 위해 무작위 대조 실험(RCT) 을 수행함
     * 예상과 달리 AI 도구를 사용할 때 개발자들이 19% 더 오래 걸리는 현상이 확인됨
     * 이 결과는 AI 연구 자동화가 소프트웨어 개발에 실제로 미치는 영향 측정의 한 사례로 해석됨
     * 본 방법론을 바탕으로 AI R&D 가속의 현실적 효과를 지속적으로 추정할 계획을 밝힘

연구 동기

     * 기존 코딩/에이전트 벤치마크는 실제 업무 상황을 충분히 반영하지 못하는 한계가 있음
          + 자가용 테스트, 컨텍스트 없는 단발성 과제, 자동 채점 구조 등으로 인해 AI 능력을 과대평가할 수 있음
          + 반대로, 인간의 적응적 개입이 없는 경우, 실제 AI 모델 성능이 과소평가될 가능성도 존재함
     * 이런 한계를 보완하기 위해 실제 오픈소스 개발자 생산성에 미치는 영향을 실험하여 AI의 현실적 영향을 측정함

실험 방법

     * 16명의 오픈소스 베테랑 개발자를 모집하여, 각자가 수년간 활동한 대형 저장소(평균 2만2천+ 스타, 100만+ 코드 라인) 내 실제 이슈 246개를 선정
     * 각 이슈별로 AI 사용 허용 또는 금지하는 그룹에 무작위로 배정함
     * AI 허용 시 개발자는 Cursor Pro 및 Claude 3.5/3.7 Sonnet 등 최신 모델을 자유롭게 사용, 금지 시엔 생성형 AI 도움 없이 작업 수행
     * 참가자들은 각 이슈(평균 2시간 소요) 해결 과정을 녹화하고, 자체적으로 소요 시간을 보고함
     * 실험 참가자에게는 시간당 150달러 보상 지급

주요 결과

     * AI 도구를 사용할 때, 이슈 해결 시간이 평균 19% 더 길어짐
     * 개발자들은 AI가 실제로 생산성을 24% 높여줄 것으로 기대했으며, 실험 후에도 여전히 20%의 속도 향상을 체감한다고 응답함
     * 이처럼 인지와 실제 성과 간에 큰 괴리가 나타남
     * 특정 오해를 방지하기 위해, 본 연구는 다음 내용에 대한 증거를 제공하지 않음:
          + 모든 개발자 또는 소프트웨어 개발 전체에서 AI가 느려진다는 일반화
          + 다른 분야나 세팅에서 AI의 효과 규정
          + 가까운 미래에도 동일한 결과가 지속된다는 단정
          + 기존 LLM·프롬프트 기법의 최적화가 불가능하다는 주장

영향 인자 분석

     * 작업 지연을 설명할 수 있는 20가지 요인을 분석, 이 중 5가지가 실제 영향을 준 것으로 판단함
     * 실험 조건, 모델, 이슈 난이도, PR 품질 등 주요 변수가 실험 결과에 의미 있는 영향을 주지 않음이 확인됨
     * 지연 현상은 다양한 데이터 하위집합 및 추정 방법에서도 일관적으로 관찰됨
     * 상세한 분석 내용은 논문 원문에서 확인 가능

결과 해석 및 논의

  증거의 충돌 및 원인

     * AI 벤치마크 점수/사례 보고/실제 실험 간의 결과 차이가 뚜렷함
     * 벤치마크는 자동 채점이 가능한 협소한 문제 중심으로 AI 능력을 측정함
          + SWE-Bench: 테스트 기반 오픈소스 PR, RE-Bench: 알고리듬 평가 가능 문제
     * 실제 RCT에서는 20분~4시간 소요되는 복잡·현실적인 작업에서 인간이 오히려 더 느려짐
     * 반면, 산업 현장이나 커뮤니티에서는 AI가 장시간 업무에 상당히 유용하다는 정성적 보고가 많음

  해석 프레임워크

     * 각각의 방식이 “실제 능력”을 다르게 측정하는 특성이 있음
     * 사례별 접근 방법:
          + RCT의 저평가 문제: 우리 실험 세팅에만 해당하는 특수성 존재 가능성
          + 벤치마크/사례의 과대평가 가능성: 실제 풀이와 괴리, 자기보고 근거의 신뢰성 미흡
          + 세 방식 모두 실제 일부 하위 문제에만 잘 맞을 수 있음
     * 서로 다른 출처와 실제 능력치의 괴리는 측정 오류·편향(빨간색), 측정 범위 차이(파란색) 라는 해석이 가능함

  실험의 추가적 시사점

     * RCT 결과는 수백 또는 수천 번 AI 결과를 샘플링하는 환경에는 해당하지 않을 수 있음
     * 수십~수백 시간 Cursor 등 AI 도구를 사용한 후에야 능률 향상이 나타날 가능성 존재
     * 고품질 코드, 암묵적 요구사항(문서화, 테스팅, 포맷팅 등)이 많은 환경에서 AI 능력이 제한될 수 있음
     * 벤치마크는 문제 범위가 좁아 실제 업무 난이도를 적절히 반영하지 못함
     * 정성적 체감 보고는 과대평가 및 자기 착각 효과로 신뢰성 저하 가능성이 있음

     * 어떤 단일 평가 방식도 완벽하지 않으므로 서로 보완적으로 사용할 필요성이 강조됨

향후 전망

     * 본 방법론을 지속적으로 개선하여 AI 도구가 개발자 생산성을 실제로 얼마나 변화시키는지 정량 추적 예정임
     * 만약 AI 도구가 현장 개발자의 능률을 크게 높인다면, AI R&D 전반의 급격한 가속/감시 실패/권력 집중 위험 등도 함께 발생할 수 있음
     * 실제 환경에 적합한 평가 프레임워크의 개발이 향후 AI 발전과 산업 전반에 매우 중요함

        Hacker News 의견

     * Simon Willison의 댓글:
       전체 논문은 요약본에서 빠진 세부 내용이 많음 논문 링크
       제 개인적인 생각으로는 LLM 기반 AI 도구에서 실질적인 생산성 향상을 얻으려면 사람들이 예상하는 것보다 훨씬 더 가파른 학습 곡선이 존재함
       이번 연구엔 다양한 AI 도구 활용 경험을 가진 16명이 참여했으며, 56%는 Cursor를 처음 써봤고, 주로 Cursor에 대한 연구였음
       각 참가자는 총 약 15개의 이슈를 다뤘으며, 이슈별로 AI 사용 가능/불가가 무작위로 지정되었음
       즉, 한 개발자가 AI가 허용된 과제와 허용되지 않은 과제를 섞어서 진행했음
       참가자 중 1/4만 성능이 향상되었고 3/4는 성능이 저하됨
       AI 사용 상위권은 Cursor를 50시간 넘게 써본 사람이었음
       연구진도 Cursor 경험이 충분한 개발자는 성능 향상이 있었다고 인정함
       내 직감으로는, 이 논문은 AI 협업 개발에서 학습 곡선이 높기 때문에, 실무에서 기존 워크플로우에 곧바로 섞으면 오히려 성능이 저하됨을 보여줬다고 생각함
          + LLM에 대해 “너가 제대로 못 써서 그래”라는 흔한 반응이 있는데, 이건 너무 책임을 사용자에게 떠넘기는 변명 같음
            대부분의 기술 제품에서는, 사용자가 가치를 느끼지 못한다면 제품의 설계 자체가 잘못된 거라고 생각함 AI에는 왜 이런 논리가 적용되지 않는지 의문임
          + Simon에게 감사, 그리고 논문을 꼼꼼히 읽어줘서 고마움 - OS 프로젝트 팬임 몇가지 중요한 포인트를 짚고 싶음
            1) 기존 연구 중 일부는 도구 경험이 적더라도 성능 향상을 보임, 즉 “가파른 학습곡선” 이론만으로 이번 결과가 다 설명되지는 않음
            2) 연구 전 참가자의 90% 이상이 LLM 프롬팅 경험이 있었고, 프롬팅만이 주요 스킬로 여겨짐. VSCode 사용에 익숙하면 Cursor도 쉽게 쓸 수 있다는 게 정설이었음
            3) 모두 AI에 익숙했다면 AI 없는 상황에서 오히려 더 못할 수 있음(적어도 나는 공감함), 오히려 이렇게 되면 AI가 더 나은 것처럼 보이는 착시 현상이 감점 효과
            4) 경험 정보는 미리 예측 전문가들과 공유, 그럼에도 불구하고 예측가들은 생산성 향상 기대치를 지나치게 높게 잡았음
            5) 수백 시간의 사용에 의한 롱테일 스킬이 실제로 존재할 수 있음, 본 연구에서는 이러한 부분까지 말하기 힘듦
            논문이 놀라운 결과를 주니 읽은 사람이 한가지 요인을 뽑아서 “이 것 때문이다!”라고 쉽게 결론짓기 쉬움
            실제로는 복합적인 원인일 수 있음(최소 5가지, 최대 9가지는 배제 불가, 11쪽 표 참조)
            한가지 정말 중요한 시사점: 개발자의 자기 보고 만족감은 실제와의 간극이 심했고, 이는 사용하는 툴의 종류와 무관함
            생산성 측정에는 현장에서의 실제 데이터가 꼭 필요함(논문 C.2.7 참고: “평균 이하의 AI 도구 활용” 섹션에서 자세히 다룸)
          + 참가자 75%가 LLM 경험이 있음에도 AI 사용 시 작업 속도가 오히려 느려졌다로 해석할 수 있는데, 하나는 LLM 학습곡선이 매우 가파르다는 해석, 또 하나는 현재 LLM의 실제 프로그래밍 보조 효율이 과대평가되어 있다는 점임 사람들이 일관되게 성능 예측을 착각하고 있음
          + LLM을 잘 다루게 되어도 본인이 작성한 코드에 대한 이해도가 떨어질 수 있음
            개발자는 시간이 갈수록 코드에 정통해지지만, LLM은 오히려 점점 안 좋아질 수 있음
            LLM으로 빠르게 코드를 생성할 수 있지만, 충분히 신경 쓰지 않으면 코드에 대한 숙련도가 축적되지 않음
            초반에는 경쾌하게 빠른 개발이 되지만, 막상 뒷단에선 이해가 부족하고 LLM도 초기엔 쓸만하다가 점점 개선이 안 되어, 어느 순간 LLM도 그 사용자도 감당 못하는 난장판 코드가 됨
            유혹을 피하면서 LLM이 좀 더 깔끔한 코드를 내도록 끈질기게 관리하고, 본인도 코드를 꼭 공부해야 한다고 생각함 스스로 이해하려는 노력이 필요함
          + AI 도구로 인해 생산성이 높아진 사람도 있고 아닌 사람도 있는 걸 볼 수 있음
            내 추측으론, 긴 텍스트나 코드를 빠르게 읽어낼 수 있는 사람이 상당한 이점을 가짐
            쓸모없는 제안을 빨리 알아채고 좋은 답을 얻을 때까지 반복하는 능력이 매우 중요함
            빠른 스캐닝 능력은 경력자와 상관관계가 있지만, 의외로 신입 중에도 이게 빠른 사람이 있음
            검색 능력이 뛰어난 사람이 LLM 활용에서도 유리할 수 있음, 구글링 능력과 비슷한 맥락으로 보임
     * 80/20 법칙을 다시 떠올리게 됨 - 전체 작업의 80%를 20% 시간 내 해결해주고 나머지 20%를 위해 80% 시간을 소모함
       항상 “거의 다 왔다”는 느낌이 있어서 매몰비용 오류에 빠지기 쉬움
       최근 시도해본 방법으론, AI를 “해결사”가 아니라 “마찰 제거자”로 활용하는 방식이었음
       프로그래밍은 내가 직접 하면서, 사소하게 까먹은 문법 같은 것만 AI에 물어서 작업 속도를 높임
       직접적인 코드 전체 제안은 거의 안 봄 항상 스스로 생각하면서 코드를 작성해, 이해도와 실력 저하를 막음
          + 예전에는 80% 작업에 80% 노력, 남은 20%에도 또 80% 노력이 들어가는 역-파레토 방식임
            “작은 장애물”만 해결하는 AI 활용에 동의함
            어제도 자바 stream API로 List 처리하면서 ConcurrentOperationsException 때문에 애먹었음
            직접 메서드 작성하다가 안 풀려서 AI에 “스레드 안전한 리스트 변환 메서드” 맡겼더니 해당 API에 이미 내장 메서드가 있다고 알려줌
            이런 잡다한 문제엔 AI가 최고임 - 복잡하지만 정의가 명확할 때
          + Stack Overflow를 좀 더 강력하게 쓸 때 특히 유용함, 내가 해야 할 일을 대략은 아는데 구체적으로 환경에 맞춰 어떻게 할지 모를 때, 그리고 디버깅이나 러버 덕킹에도 도움 됨
          + “마지막 20%를 위해 80% 시간을 소모한다”는 게 AI 도입 전에도 내 경험이었음 초기에 걸리는 시간만 줄여도 좋음 관련 경험자로부터 들었던 최고의 AI 평가는 “내 기술의 90%가 무가치해졌고, 나머지 10%는 천 배 더 중요해졌다”는 것임, 과장이 있지만 핵심은 마음에 듦
          + “항상 거의 다 됐다”는 착각 때문에 오히려 시간 낭비가 유발됨 AI가 뭔가 유용해 보이도록 만드는 데 특화되어서, 진짜 생산성 향상인지 판별하려면 높은 수준의 비판적 사고가 필요함
          + 기존 코드베이스에 기능을 추가할 때 특히 유용함, “기존 검색 파라미터 외에 foo를 추가해야 한다”거나 “x 관련된 코드를 제거해달라” 같은 작업에서 좋음
     * HN 유저들에게, 논문 저자임 - 오래된 HN 사용자이고 오늘 댓글에 질문/피드백 달리면 최대한 답변해주고 있음 시간 없다면 논문 전체 대신 소개 블로그 포스트나 x.com의 발표 스레드를 추천함
          + 논문의 방법론과 저자님의 소통 방식이 매우 프로페셔널하고 인상 깊음, 좋은 연구임
          + 이 연구는 클릭베이트 없이 솔직하게 연구 결과를 제시하고, 읽기 쉽게 잘 정리되어서 최고의 연구 중 하나라고 생각함
          + AI로 처리하는 티켓이 정말 AI에 적합한 유형이었는지 고려했나요? “이 티켓 AI로 처리해봐”라는 식이 현실적이긴 하지만 비효율적일 수도 있음 AI에 적합하게 쓰면 정말 한몫하는데, 오히려 역효과인 경우도 많음 연구 참가자들이 충분한 AI 경험이 있었다면 이 구분을 해냈겠지만, 논문을 읽으면서 그 여부가 명확하지 않음
          + 가능한 한 익명 처리된 원시 데이터셋 공개나, 최소한 개발자별 작업 소요 절대 시간 정보를 논문에 추가해줄 수 있는지 궁금함 Cursor 경험이 많은 참가자가 실제로 다른 사람보다 빠른지, 아니면 원래 느린 사람이라 AI로 더 큰 상승 효과를 얻었는지 궁금함 Hawthorne effect(관찰자 효과)까지 고려한 진짜 좋은 실험적 평가를 볼 수 있어 기쁨
          + (논문은 안 읽고 포스트만 봄) 주관적 피로도(subjective fatigue)가 AI가 더 빠르다고 오해하는 원인을 설명해주는 지표로 측정했는지 궁금함 개발자에서 관리자 전환 후 뇌가 피곤한 상황에선 AI가 더 편해서 좋음
     * 이 연구 결과, 특히 “개발자들은 AI가 속도를 24% 올릴 것으로 기대했으나, 실제론 느려졌음에도 경험 후에도 20% 빨라졌다고 믿음” 부분이 매우 흥미로움. 이렇게 실제와 인식의 간극이 드라마틱하게 큰 이유가 뭘까? 혹시 뇌가 ‘정신적 노력’을 시간의 경험으로 착각해서 그런 게 아닌지도 궁금함
          + 근거는 없지만 무서운 생각이 있음: 코딩할 때 AI와의 상호작용이 마치 소셜미디어 도파민 루프와 비슷하게 뇌를 자극하는 것 아닐까(정도는 다르긴 해도) AI가 반복적으로 답을 제시하면서 두뇌가 긍정적 평가를 받는 것처럼 느끼게 되고, 그래서 개발자가 AI를 실제보다 더 긍정적으로 평가하는 현상이 생기는 것 아닐지? 혹시 이게 중독 현상까지 일으킨다면, 실제로 생산성 효과를 과대평가하게 되는 것 아닐지?
          + 이 현상은 시장에서 많은 사람들이 AI 도구를 실제보다 더 뛰어나게 믿도록 만드는 거대한 캠페인 결과일 수도 있음 경제 전문가, ML 전문가 그룹 자체가 AI 회사 이해관계자와 겹치고, 경영진이 그걸 곧이곧대로 받아들여 큰 성과를 약속함 그게 결국 기반 기대치를 전체적으로 올려버리는데, 경험 많은 개발자에게도 영향을 끼침 경험적으로 입증하기 어렵지만, AI 생산성에 대한 집단적 착각이 넓게 퍼진 이유일 수 있음
          + HN 댓글의 많은 AI 열성팬도 이 현상에 빠져있을 가능성을 궁금해함 실제로 스스로 성능을 측정하지 않는 한, AI가 정말 본인 생산성을 올리고 있는지 미심쩍음
          + 가끔 정반대의 경험을 하기도 함 오늘 Claude code로 예제 데모 앱 코드를 만들려고 해봤는데, 구경하면서는 멋지고 SF 같아서 재밌었지만 15분만에 정신이 멍해지고 지루해짐
     * “개발자들은 AI가 24% 더 빠르길 기대했고, 실제로 느려졌음에도 20% 더 빨라진 것 같다고 믿었다”는 걸 보면, 여기엔 두 가지 문제가 있다고 느낌
       하나는 동일 인물이 같은 맥락에서 AI로 했을 때와 안 했을 때 걸리는 시간을 제대로 비교하기 힘듦
       또 다른 하나는 PR 오픈/머지까지 걸리는 기간 같은 표면적 지표로 AI 효율을 측정하기 쉬운데, 실제로 AI 도입하면 리팩토링, 테스트, 이슈 해결 등 후처리에 더 많은 시간이 배분됨
       “PR이 빨리 열렸다”만 보고 AI가 빠르다 착각하기 쉬움, 하지만 향후 작업이 늘어나는 걸 간과하기 쉬움
          + 특정 기술이나 관행이 생산성에 미치는 영향은 측정이 정말 어려움 자기 보고(anecdote)만 믿고 결론내리는 건 위험하다고 봄, 누구든 쉽게 자기환각에 빠질 수 있으니까 연구 자체도 한계 인정하고 있으니, 생산성 관련 논의엔 큰 오차범위를 의식해야 함 AI라는 기술은 살면서 본 것 중 제일 이상함, 단편 사례나 의심스런 벤치마크로부터 인과관계를 읽어내는 건 거의 운세풀이 같음
          + 논문에서는 AI 허용/비허용 상황에서 PR 품질 저하가 관찰되지 않았음 참가자들 대부분은 리포지토리 기준에 익숙하고, ‘대충 제출해서 PR 띄우기’ 스타일이 아님 연구 내 PR의 중간 리뷰 시간은 1분 정도임 작성자의 말대로 시간 사용 방식은 완전히 달라짐 논문 10쪽에 AI 사용/미사용별 시간 분포가 나와있으니 참고 바람, AI 활용 시 코딩 시간은 줄고 AI랑 상호작용 시간은 늘어남
          + “동일인이 동일 맥락에서 AI로, 혹은 AI 없이 작업할 때 각각 걸린 시간 차이”를 정확히 아는 건 불가능하다는 지적에 대해, 실험 설계상 무작위 할당(random assignment)을 통해 AI 그룹과 비AI 그룹 효과를 분리함 개인, 상황, 환경 등의 차이는 무작위 처리로 상쇄시킴 표본과 효과 크기만 크면 통계적으로 의미있는 차이를 뽑아낼 수 있음
          + Figure 21을 보면 초기 구현(PR까지 걸린 시간) 자체도 증가했고, PR 리뷰 후 시간이 더 늘어나긴 했어도 전체적으론 큰 영향은 없어 보임 Figure 18에서 확인할 수 있듯 실코딩 시간은 줄었지만, 프롬프트 작성과 결과 대기, 출력 검토 등으로 절감 효과가 상쇄됨 5분 이하 단순 작업은 오히려 LLM 활용을 안하는 게 더 나았을 수도 있음
     * 각 워크플로우별 PR 내용을 비교해보고 싶음 Copilot은 내가 직접 할 때보다 더 많은 코드를 제안하는데, 불필요한 체크나 반복, 추상화 없이 코드량이 많아지는 경우가 많음 내 개인적인 가설은, LLM이 너무 많은 코드를 써내는 모습을 보면 문제 해결에 얼마나 오래 걸릴지 체감이 왜곡되는 것 같음
     * LLM을 활용해 대규모 코드베이스에서 작업할 때 진짜 어려운 점은, 해야 할 작업을 정확히 묘사하는 것임 수많은 코드 상호작용 속 이슈를 설명하는 데만 오히려 손으로 직접 처리하는 것보다 오래 걸릴 때가 많음, 반면 신규 프로젝트에서 보일러플레이트 코드 만들 때는 LLM과 가장 잘 맞는 것 같음
          + 나도 같은 경험임 Knuth가 말하듯 코드의 본질은 코드 자체뿐 아니라 개발자의 머릿속에도 존재함 모든 맥락을 정확히 LLM에 전달하지 않는 한, 몇 년간 쌓인 개념과 전략을 다 쏟아낼 수 없음
     * 참가 개발자 모집비만 300 x 246 = 약 73K를 써놓고 논문은 학술지에 실리지도, 동료 검토도 없음 논문은 겉으론 정돈돼보이고 AI 생성스럽진 않지만 어떻게 이런 자금이 가능했는지 궁금함
          + 가장 큰 재정지원은 The Audacious Project였고, 공식 발표 통해 확인 가능함 또 2025년 4월까지 AI 회사에서 받은 평가 대가가 없다고 웹사이트 각주에 명시돼있음
          + 회사들은 이런 류의 ‘화이트페이퍼’를 자주 냄 기술 보고, 정책 제안, 홍보물의 결합 형태임
          + 학술지, 동료 리뷰 유무만 따지는 건 의미가 없다고 봄 과학은 누가 출판하든 중요한 게 아니라 재현과 반복 성과가 핵심임 심리학의 재현 위기 사례처럼, 저널 등재 자체가 신뢰성을 담보하지 않음
          + 대부분의 나라에선 연구에 공적 지원금이 있음, 미국은 과거에 더 지원했으나 근래엔 대폭 삭감되었음
          + 재단 소개 페이지를 보면 AI 회사, 정부 등 다양한 곳에서 자금을 받는 듯함
     * 취미 OSS 프로젝트에서 AI는 오히려 방해만 됨 코드 생성/스캐폴딩은 오히려 걱정거리가 아님, 오히려 코드리뷰, 커뮤니티 관리가 더 중요함 AI 도구로 할 수 있는 일은 한계가 뚜렷함 그런데 누군가 내 오픈 PR에 AI 코드 리뷰 도구를 투입해서 30줄짜리 PR에도 이모지와 정리된 글머리표로 2페이지 짜리 요약을 뱉어냄 불필요한 소음 줘서, 이제는 그런 코멘트 지우거나 숨기느라 진짜 유지보수 시간만 더 줄어듦
     * 학습곡선만 넘으면 빨라지지만(혹은 누군가 말한 대로 “이제는 AI 없이 일하는 법을 까먹을 때까지”) 진짜로 측정해야 할 건… 새벽 3시에 PagerDuty 알람 울릴 때, 정말 그 코드 디버깅까지 걸리는 시간임 또 그 코드의 장기적 품질은 어떤지 궁금함 나는 비즈니스 로직을 공유 폴더로 끌어올리고, 호출 체인을 위로 모아 API는 깔끔하게 내리고, 로직/API/디스플레이 분리, 캡슐화 등 코드 구조를 오랜 시간 개선해왔음(의존성 주입으로 결합도 감소 등) AI 코드가 장기적으로 더 나은 품질/이식성/확장성이 생길까? 아니면 결국 품질이 낮은 코드가 점점 쌓여 엉킨 쓰레기장이 되어, 결국 버그 수정에 시간의 절반을 쏟아붓게 되는 것일까?

   시간당 150불? 부터 변인통제가ㅋㅋㅋㅋㅋㅋ
"
"https://news.hada.io/topic?id=21945","에어 인디아 사고에 대한 예비 보고서 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        에어 인디아 사고에 대한 예비 보고서 공개

     * 에어 인디아 추락사고 예비 보고서가 발표된 후 유가족들이 진상 규명과 책임자 처벌을 촉구함
     * 사고로 인해 260명이 사망했으며, 유가족들은 사고 원인에 대한 의문과 슬픔을 계속 표출함
     * 일부 가족들은 조사 결과가 슬픔을 덜어주지 못한다는 점을 언급하며, 여전히 더 많은 답을 요구함
     * 피해자 가족들은 기술적 원인(연료 스위치 등)에 대해 잘 모르겠지만, 사랑하는 이를 잃은 사실에 더 큰 고통을 느낌
     * 인도 정부와 당국에 철저한 조사와 책임 추궁을 촉구하는 목소리가 높음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

유가족들의 애도와 진상규명 요구

  예비 보고서 발표와 가족들의 반응

     * 에어 인디아 추락사고에 대한 예비 보고서가 발표된 직후, 사망자 260명 유가족들과 친구들이 애도를 표명함
     * Ayushi Christian은 남편 Lawrence Christian이 사고로 사망해, 피해자에 대한 정의 실현과 책임자 처벌을 촉구함
     * 또다른 피해자 가족은 ""책임 있는 사람들에게 조치가 취해져야 한다""고 BBC에 밝힘

  잃어버린 가족과 남겨진 질문들

     * Lamnunthem Singson의 사촌은 가족들이 슬픔을 이해하려 노력중임을 전하면서, 사고 원인을 알아도 슬픔 자체가 달라지지 않음을 언급함
     * Badasab Syed는 형제와 가족을 모두 잃은 뒤, 보고서 발표 후에도 여전히 더 많은 질문과 의문점만 남았음을 토로함

  조사 결과와 위로의 한계

     * Shweta Parihar는 남편 Abhinav Parihar를 잃었으며, 현재 진행 중인 조사가 실질적인 위로가 되지 못함을 고백함
     * “이제 조사 결과가 무슨 의미가 있냐. 우리는 모든 것을 잃었다”는 심정을 밝힘

  기술적 원인과 가족의 아픔

     * Rafiq Dawood는 25세 아들 Faizan Rafiq을 잃었으며, 연료 스위치 등 기술적 세부사항에 대해 잘 알지 못하지만, 핵심은 사랑하는 아들을 잃은 사실임을 강조함
     * 기술적 원인보다 가족을 잃은 슬픔이 더 크다는 감정을 공유함

  정부와 당국에 대한 요구

     * Saiyed Javed Ali의 친척은 부인과 두 자녀까지 한꺼번에 잃었고, 인도 정부에 책임자에 대한 조치와 철저한 조사를 촉구함
     * “추락사고 원인을 분명히 밝힐 제대로 된 조사가 필요하다”고 강조함

피해자 가족들의 지속적인 고통

     * 유가족들은 “슬픔을 말로 다 표현할 수 없다”며, 지속적인 아픔과 절망을 나타냄
     * 많은 이들이 희망이 산산조각 났음을 증언하며, 정의와 답을 기대함

결론

     * 에어 인디아 추락사고 유가족들은 예비 보고서 발표 이후에도 여전히 진상 규명과 책임자 처벌을 강하게 요구함
     * 조사 결과가 있을지라도 피해자의 가족들에게 충분한 위로가 되지 못한다는 점이 드러남
     * 가족들은 기술적 원인보다 사랑하는 사람을 잃은 슬픔에 더 큰 무게를 두고 있음

        Hacker News 의견

     * 쓰로틀 컨트롤 모듈(TCM)이 2019년과 2023년에 두 번 교체된 경험이 있음, 이것은 보통 흔한 일은 아님
       파일럿 두 명 모두 경력이 길어서, 연료 컨트롤 스위치를 올리고 옮겨서 연료를 차단하는 건 반드시 의도적으로 해야 하는 행동임
       일부러 조작했거나 컨트롤 유닛이 잘못 작동한 것으로 추정함
       과거 이력과 조종사 경험을 보면, 내 생각에는 컨트롤 고장이 원인일 가능성이 더 높음
       하지만 진실은 영원히 알 수 없음
     * 만약 이 사건이 실수가 아니라 진짜로 murder-suicide(살인 후 자살)라면, FAA의 정신 건강 정책도 유의미하게 문제임
       FAA는 조종사가 정신 건강 치료를 받으면 자격증을 박탈하는 정책을 갖고 있음
       이번 사건은 인도에서 일어난 일이지만, 미치료 정신 건강 문제가 수백 명의 목숨을 위험에 빠뜨린 사례가 될 것임
       조종사는 치료를 받으면 커리어를 잃기 때문에, 치료받지 않고 질병을 숨기게 됨
       Pilot Mental Health Campaign은 HR 2591 ""Mental Health in Aviation Act of 2025"" <법안 텍스트 보기>가 입법화되도록 노력 중임
       이 법이 통과되길 희망하고, 다른 나라들도 유사한 위험한 정책을 바꿨으면 좋겠음
          + murder-suicide로 단정 짓기는 너무 이르다고 생각함
            휴대폰을 냉장고에 넣은 적이 있는지 물어보고 싶음
            조종사들은 도착 게이트로 최종 택시 마치고 연료 차단기를 끄는 습관이 있음. 이 동작은 자동화된 근육 기억이라 안전잠금이 있든 없든 무의식적으로 할 수 있음
            단순 실수(Brain fart)가 이번 사고의 대화록과 가장 잘 맞음
            연료 차단 스위치의 안전 락이 설치되어 있었는지도 보고서가 확실하게 밝히고 있지 않음. 락은 옵션임
            안전락이 있었고도 사고가 났다면 단순 파일럿 실수일 가능성을 가장 높게 보겠음
            조종사에 대한 조사도 굉장히 엄격하게 이뤄지는 중임. 범죄 동기가 밝혀질 것 같지는 않음
          + ""정신 건강 치료를 받으면 비행 불가""는 사실과 다름
            정신 건강 진단을 받은 조종사도 관리가 잘 되고 과거 정신병력이나 자살 충동이 없으면 비행함
            참고 링크
          + 치료가 자살 확률을 현저히 낮춘다는 연구 결과가 없으면 이것이 정책에 대한 결정적 증거가 될 수 없음
          + 이런 조종사들에게 신규 커리어 패스를 제공하는 것이 더 좋지 않겠냐는 생각임
            그럼 조종사는 생계를 유지하고 승객 안전 위험도 줄일 수 있음
     * ""나는 조작하지 않았다""고 말한 조종사가 실제로는 무의식적으로 조작했을 가능성이 있다고 생각함
       원래 랜딩기어를 올려야 할 타이밍이라 근육 기억 실수로 연료 스위치를 눌렀을 수도 있음
       내가 보는 유튜브 파일럿 분석가들도 초기에 이 설을 제시했으나 가능성이 낮다고 기각했음
          + 787의 랜딩기어 레버는 조종석 중앙에 큼직하게 위치하고 양 조종사가 쉽게 닿을 수 있음
            수십 년 동안 여러 항공기 제조사들이 랜딩기어 레버에 비행기 바퀴 모양 손잡이를 달아둠
            다른 레버와 헷갈릴 수 없는 구조임
            연료 컨트롤 스위치는 쓰로틀 스틱 뒤쪽, 엔진 화재 진압 핸들 윗부분에 작고, 양옆에 안전가드가 설치됨
            손가락을 집어넣고 힘줘서 락을 풀고 돌려야 하며 두 개 스위치를 연속으로 조작함
            조종사 중 한 명이 ""기어 올려""라고 하면 참여 조종사가 제어함
            근육 기억 실수였다는 건 정말 믿기 힘듦
            최소한 이런 주장을 하려면 증거가 더 필요하다고 생각함
            실수로 차량 변속기를 후진에 넣는 것보다 확률이 낮은 시나리오 같음
          + 예비 보고서가 나온 게 다행임
            추측, 유튜버 이론, ‘지인 보고서 유출’ 등 온갖 루머를 더 이상 들을 필요가 없어졌음
            현재 커뮤니티의 대화 패턴을 보면, 마지막 공식 보고서가 나올 때까지는 새로운 무작위 가설들이 계속 나올 것 같음
            혹은 보고서가 별다른 추가 결론이 없으면 그냥 관심이 점점 사그라질 것임
          + 두 동작을 헷갈리는 것은 불가능임
            랜딩기어 레버에 바퀴가 붙어 있는 데는 다 이유가 있음
          + ""내가 생각하기에…""로 시작하는 방식이 수사에서 가장 피하는 방법임
            자기 이론에 증거를 맞추는 게 아니라, 오로지 객관적 증거에만 귀 기울여야 함
          + 블랙박스에 조종석 영상을 녹화하는 시스템이 있는지 궁금함
            없다면 단순 가정용 와이파이 카메라도 sd카드로 몇 시간씩 HD 녹화가 가능하니, 도입하면 이런 상황을 바로 확인할 수 있을 것임
     * 다양한 추측이 그럴듯하게 들리다가도, 또 다른 설명을 들으면 생각이 바뀌는 모습이 흥미로움
       '설명 불가(inexplicable)'라는 단어가 딱 어울리는 순간임
     * 또 다른 관점을 소개함: X.com에 올라온 관련 의견
       이 쇼에 출연한 인도인 조종사 4명 모두 조종사가 원인이라고 확신하지 못하는 분위기임
       조종석에서 있었던 전체 대화 내용이 밝혀지는 것이 중요함
       추가 정보가 밝혀지면 조종사가 연루되었을 수도 있지만, 그렇지 않으면 이번 보고서는 문구가 매우 부적절한 보고임
     * 이런 비행기의 시스템은, 조종사 입력이 기대치와 다르면 거부하는 경우가 많음
       그런데 왜 이 시점에 연료를 차단하는 입력이 가능한지도 궁금함
       만약 이륙 초기에 두 엔진에 화재가 발생했다고 해도, 연료를 자르는 게 무슨 도움이 되는지도 의문임
          + 엔진 화재 시에는 연료를 차단할 필요가 있음
     * 787 연료 스위치는 모두 락킹 메커니즘이 있어서, 실수로 조작되는 것을 방지함
       연료를 켜려면 스위치를 바깥쪽으로 잡아당기고 ""RUN"" 위치로 옮겨 자동으로 락이 걸림
       연료를 끄려면 다시 바깥으로 잡아당겨 ""CUTOFF"" 위치로 옮겨야 함
       뉴욕타임스 보고서
          + 만약 락 기능이 설치 안 되어 있었다면 실수로 스위치가 눌렸을 수도 있음
            avherald 관련 뉴스 참고
            인도 언론 보도에 따르면, 조사팀은 스위치 조작 실수보다 시스템 결함 쪽에 초점을 맞추고 있다고 전함
            Boeing이 2018년 관련 서비스 공지로 연료 스위치 락업그레이드를 권고했고, FAA/GE에서 제시한 결함 관련 서비스 공지도 Air India에 적용되지 않았음
     * 사건의 진상과 별도로, 대부분의 경우 조종사는 영웅적으로 행동함
       기억나는 케이스 몇 가지 소개함
          + British Airways 5390: 잘못된 수리로 비행 중 창문이 날아가고, 조종사가 거의 빨려나갈 뻔 함
            승무원이 조종사의 다리를 잡고 있고, 부조종사가 기지로 항공기 착륙에 성공해 모두 생존함
            사건 영상
          + United 232: 꼬리 엔진 폭발로 3개의 수압 시스템 전부 마비됨
            승객 중 한 명이 유사 사고 사례를 잘 알고 있어, 조종사들과 힘을 합쳐 엔진만으로 제어함
            활주로 가까이 착륙을 시도했으나 불시착해 112명 사망, 184명 생존
            사건 영상
          + Pinnacle 3701: 조종사가 빈 전용기로 장난치다 실수로 천정까지 상승, 실속에 제대로 대처하지 못해 착륙 실패
            마지막 순간 착륙기어를 내리지 않고 거리 최대 확보로 민가를 피함
            주택 한 채에 충돌했으나 추가 인명피해 없음
            사건 영상
          + British Airways 5390 사건은 더 나은 설계가 사고를 얼마나 효과적으로 막을 수 있는지 보여줌
            창문 교체 시 사용한 90개 나사 중 84개가 규격보다 0.66mm 더 가는 것으로 잘못 장착됨
            창문이 외부에서 끼워지는 구조라 압력 차이를 제대로 견디지 못함
            만약 플러그 형태(내부에서 밀어넣는 구조)였다면, 압력 차이로 창문이 떨어지지 않았을 것임
            이 사고 이후 대부분 항공기가 플러그형 창문으로 설계방식이 전환됨
          + Mentour Pilot 유튜브 채널 정말 훌륭함
          + Air Canada 143: 연료 단위 혼동(미터법/야드파운드법)으로 비행 중 연료 고갈
            조종사가 ‘글라이더 슬립’이라는 실제로는 불가능하다고 여겨진 급강하 조작을 통해, 폐쇄 공항에 임시 착륙 성공
            사망자나 중상자 없음
            사건 영상
          + 조종사가 살아있고 승객을 생각하든 말든, 중요한 건 승객 생명임
            파괴적 의도를 가진 조종사라면, 이를 막는 건 구조적으로 불가능하다고 봄
     * 400개 가까운 댓글에 avherald 링크가 없어서 공유함
       avherald 사건 요약
          + 2025년 7월 12일 보도에 따르면 인도 언론은, 연료 스위치가 cutoff 위치로 조작된 것이 인간 행동 때문이 아니라, 시스템 결함에 주목하고 있다고 밝힘
            Boeing과 FAA, GE에서 2018년 이후 락킹 버전 스위치 업그레이드 등 여러 개선사항을 안내했으나 Air India에선 미적용됨
            MN4 컴퓨터의 납땜 문제, 회로 로딩, 전기 신호 끊김 등으로 엔진 제어 장애가 발생 가능
            아직 초동 수사 단계라 모든 가능성을 배제하지 말아야 한다고 생각함
            온라인에서는 murder-suicide에만 치우쳐 논의가 되는 게 의아함
            항공 분야라면 오히려 마지막까지 열린 마음으로 모든 가능성을 열어둘 필요가 있다고 생각함
     * EGT 상승, 엔진 재점화 등이 확인됐는데, F-16 전투기의 EPU 시스템처럼 몇 초만에 긴급하게 전원을 공급할 수 있는 수단이 민항기에도 있으면 어떨지 상상해봄
       EPU는 하이드라진을 이용함. 실제 도입은 드물지만 흥미로운 기술임
          + F-16의 EPU는 비상시 비행 조종면 전원을 공급하는 장치임. 추진력은 제공하지 않음
            787 등 대부분의 민항기는 RAT와 APU, 대형 리튬배터리 등이 있어서 비상 전원 역할을 함
            엔진 추력상실에선 사실상 별도의 EPU가 필요 없음
            fly-by-wire 항공기는 모든 경우 배터리로 조종 컴퓨터가 일정 시간 구동됨
            “민항기에서 별도의 긴급 추진 시스템”을 채용한 경우는 예외적으로 멕시코 항공사가 727 초기에 로켓 보조 추진 장치를 적용한 사례가 있는데, 일반적이지 않음
          + 민항기 설계 엔지니어가 ""문제 해결을 하이드라진으로 하자!""고 한다면, 경력이 오래 가지 못할 것 같음, 농담임
          + RAT는 이미 투입되어 제 역할을 하고 있었음
            하이드라진, 심지어 원자로를 추가해도 추력이 없는 상황에선 해결책이 안됨
          + 내가 생각해본 유일한 해결책은 비상 낙하산 대량 탑재임
            엔진 혹은 조종실 제어실패 상황에도 쓸 수 있음
            Kerbal Space Program에서 가끔 먹히긴 했음
"
"https://news.hada.io/topic?id=21839","OCaml로 Game Boy 에뮬레이터 만들기 (2022)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    OCaml로 Game Boy 에뮬레이터 만들기 (2022)

     * CAMLBOY는 OCaml로 개발되어 브라우저에서 동작하는 Game Boy 에뮬레이터임
     * OCaml의 중상규모 프로젝트 개발 및 고급 기능 사용법을 실제로 익히기 위해 선택된 프로젝트임
     * 기본 구조, 추상화, GADT, 펑터, 런타임 모듈 교체 등 다양한 OCaml 언어 특성을 실용적으로 활용함
     * 브라우저에서 60FPS로 동작하며, 성능 개선 과정과 병목 분석, 최적화 경험을 공유함
     * OCaml 생태계, 테스트 자동화, 그리고 에뮬레이터 개발이 실무 능력 향상에 미치는 영향을 정리함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

프로젝트 개요

     * 몇 달간 CAMLBOY 프로젝트를 진행하며, OCaml로 Game Boy 에뮬레이터를 제작함
     * 데모 페이지에서 실행 가능하며, 다양한 homebrew ROM을 포함함
     * 저장소는 GitHub에 공개됨

OCaml 학습 동기와 프로젝트 선정 배경

     * 새로운 언어 학습 시, 중/대규모 코드 작성 방법과 고급 기능의 실제 활용법에 한계를 느낌
     * 이러한 문제 해결을 위해 실질적인 프로젝트 경험의 필요성을 느껴 Game Boy 에뮬레이터 개발을 선택함
     * 이유
          + 사양이 명확해 구현 범위가 정해져 있음
          + 충분히 복잡하지만 수개월 내 완료 가능한 크기임
          + 개인적 동기가 큼

에뮬레이터 목표

     * 가독성 및 유지보수성을 중시한 코드 작성
     * js_of_ocaml로 JavaScript로 컴파일해 브라우저에서 실행
     * 모바일 브라우저에서도 플레이 가능한 FPS 달성
     * 다양한 컴파일러 백엔드 성능 벤치마크 구현

본문 목표 및 주요 내용

   이 글의 목적은 OCaml로 Game Boy 에뮬레이터를 제작하는 여정 공유임
   다루는 내용:
     * Game Boy 아키텍처 개요
     * 테스트 가능하고 재사용성 높은 코드 구조화 방법
     * functor, GADT, 일급 모듈 등 고급 OCaml 기능 실전 활용
     * 성능 병목 찾기, 최적화 및 개선 경험
     * OCaml 전반에 대한 생각

전체 구조와 주요 인터페이스

     * CPU, Timer, GPU 등 주요 하드웨어가 동기화된 클럭에 따라 동작
     * 버스는 주소에 따라 각 하드웨어 모듈에 데이터 접근/전달 기능 담당
     * 각 하드웨어 모듈은 Addressable_intf.S 인터페이스를 구현함
     * 버스 전체는 Word_addressable_intf.S 인터페이스를 따름

  메인 루프 동작 방식

     * 하드웨어의 동기화를 위해 메인 루프에서 아래 순환 단계 실행
         1. CPU 명령 1개 실행 및 소비된 사이클수 기록
         2. 같은 사이클수만큼 Timer, GPU 진행
     * 이 방법으로 실제 하드웨어의 동기화 상태 모사
     * 구현 코드 예시와 함께 설명 제공

  8비트, 16비트 데이터 읽기/쓰기 추상화

     * 다수 모듈이 8비트 데이터 입출력 인터페이스 (Addressable_intf.S) 구현
     * 16비트 읽기/쓰기 확장은 Word_addressable_intf.S를 통해 상속 및 추가 기능 확장
     * OCaml의 서명(signature) , 모듈 타입 포함(include) 방식으로 추상화 계층 구성

  버스, 레지스터, CPU 구현

     * 버스: 각 하드웨어 모듈에 대한 주소 기반 라우팅 기능 담당, 메모리맵 기준 분기처리
     * 레지스터: 8비트, 16비트 레지스터 읽기/쓰기 인터페이스 제공
     * CPU: 초기에는 버스 의존성이 강해 테스트가 어려움
          + 펑터(functor) 적용으로 의존성 추상화 및 목(mock) 주입 가능
          + 이를 통해 단위 테스트 작성이 훨씬 쉬워짐

인스트럭션 세트 표현 (GADT 활용)

     * Game Boy는 8/16비트 명령 모두 존재, 인스트럭션 정의의 타입 안정성 필요
     * 단순 variant 방식은 복잡한 패턴 매칭 반환값 타입 충돌 문제 발생
     * GADT(Generalized Algebraic Data Type) 를 적용해 입력 및 출력 타입 모두 안전하게 매칭 가능
     * GADT 적용 시 각 인스트럭션의 인자 타입, 반환값 타입 모두 정확하게 타입 추론 가능
     * 복잡한 명령어 패턴 및 파라미터에 안전하게 대응

카트리지 및 런타임 모듈 선택

     * Game Boy 카트리지는 단순 ROM 외 추가 하드웨어(MBC, 타이머 등) 포함 가능
     * 각 타입별로 모듈 별도 구현 및 런타임에 맞는 모듈 선택 필요
     * 일급 모듈로 런타임 모듈 전환 및 확장성 실현

테스트와 탐색적 개발

     * test ROM 및 ppx_expect 활용
          + 기능별 테스트 ROM: 산술연산, MBC 지원 등 구체적 영역 검증
          + 실패시 화면 출력 등 명확한 진단 가능
     * 통합 테스트로 대규모 리팩토링, 새로운 기능 추가 시 신뢰도 확보
     * 탐색적 개발 방식 적용: 테스트 ROM으로 반복적으로 구현 및 검증

브라우저 UI 및 성능 최적화

     * js_of_ocaml로 쉽게 JS 빌드
     * Brr 라이브러리로 Javascript DOM API에 OCaml 방식으로 안전하게 접근
     * 초기 성능(20FPS)은 낮았으나, 크롬 프로파일러로 GPU, 타이머, Bigstringaf 등 병목 분석
     * 각 모듈별로 최적화 커밋 진행, JS 빌드에서 비효율적인 인라이닝 비활성화로 최종 60FPS(PC/모바일) 달성
     * 네이티브 빌드에서는 1000FPS까지 성능 발휘

벤치마크 및 하드웨어 비교

     * 헤드리스 벤치마크 모드 구현해 각 환경별 FPS 측정 가능

에뮬레이터 개발과 실무 능력

     * 경쟁프로그래밍과 비슷하게, 명확한 사양 해석 → 구현 → 검증 루프 반복
     * 사양 기반 개발/테스트 진행에 실질적 도움이 되는 경험

최신 OCaml 생태계 및 도구 발전

     * dune로 간편한 빌드 시스템 경험 제공
     * Merlin, OCamlformat 등으로 자동완성, 코드 네비게이션, 포매팅 용이
     * setup-ocaml로 Github Actions에도 손쉽게 적용 가능

함수형 언어에 대한 소고

     * 함수형 언어란 사이드 이펙트 최소화라는 설명에 의문을 가짐
     * 추상화하에 숨은 mutable 상태는 성능을 위해 적극적으로 사용
     * 필자는 정적 타입, 패턴매칭, 모듈 시스템, 타입 추론 등을 선호함

불편사항 및 추상화 의존 비용

     * 종속성 관리 표준화가 아직 복잡하고 설명 부족 (opam 등)
     * 모듈-펑터 구조로 추상화를 가미하면, 의존성 계층 전체 구조까지 수정 필요
     * OOP와 달리 추상화 도입 시 상위 의존 모듈 작성법까지 변경 필요

추천 학습 자료

     * Learn OCaml Workshop: 실전 코드 & 테스트로 진행하는 입문자용
     * Real World OCaml: 실무 예제로 실제 OCaml 스타일 익히기
     * The Ultimate Game Boy Talk: 아키텍처 개괄 영상
     * gbops, Game Boy CPU Manual, Pandocs, Imran Nazar’s blog: Game Boy 인스트럭션 및 하드웨어 참고 자료

결론

     * CAMLBOY 프로젝트를 통해 OCaml의 고급 기능과 테스트, 추상화, 브라우저 호환성 등을 실용적으로 경험
     * 생태계 발전과 현실적인 개발 경험에서 얻은 장점과 한계 명확히 인식
     * 에뮬레이터 개발이 중급 이상의 개발자 실력 향상에 실질적인 도움이 됨

        Hacker News 의견

     * 에뮬레이터, 가상머신, 바이트코드 인터프리터 작성에 어떤 특정 프로그래밍 언어가 더 적합하다고 자신 있게 말할 사람 있는지 궁금함. 여기서 ""더 나은"" 기준은 성능이나 구현 오류 줄이기가 아니라, 직접 구현하고 탐구할 때 더 직관적이고, 뭔가를 더 배우고, 구현 경험 자체가 보람되고 재미있다는 측면임. 예를 들어 Erlang은 분산 시스템 영역에서 명확한 목표가 있고, 그 영역을 위한 도메인 지식과 언어 설계가 일치해서 써보면 분산 시스템과 Erlang 자체에 대해 깊이 있는 이해를 얻게 됨. 이런 식으로 ""기계 동작을 코드로 표현하는 것""이 타겟인 언어가 있을지 궁금함
          + 시스템 프로그래밍 언어인 C, C++, Rust, Zig가 개인적으로 가장 ""만족도 높은"" 선택임을 강조하고 싶음. 이 언어들은 데이터 타입(예: uint8)이 메모리의 바이트와 곧바로 매핑되고, memcpy 같은 연산이 곧장 blit 작업과 같음. JavaScript 같은 언어에서 Number 타입을 비트 연산용 바이트로 바꿔쓰며 고생하는 일이 거의 없음. 자바스크립트로 에뮬레이터 만들다 보면 이런 문제를 바로 맞닥뜨림. 물론, 어떤 언어든 그래픽 표시와 충분한 메모리만 지원된다면 다 비슷하게 굴릴 수 있고, 결국 자신이 가장 편한 언어를 선택할 때 최고의 즐거움을 느낄 수 있음
          + Haskell은 DSL과 컴파일러에 필요한 데이터 변환에 뛰어난 성능을 보임. OCaml, Lisp, 패턴매칭과 ADT를 지원하는 현대적인 언어도 모두 적합함. Modern C++도 variant 타입 등으로 비슷한 걸 시도할 수 있지만, 깔끔하진 않음. 실제로 에뮬레이터에서 게임을 돌릴 생각이면 C나 C++이 표준 선택. Rust도 그럭저럭 가능할 거 같긴 한데, 저수준 메모리 조작은 잘 모르겠음
          + 에뮬레이터, 가상머신, 바이트코드 인터프리터를 만들기에 특별히 더 나은 언어는 없다는 입장임. 배열(임의 인덱스에 상수 시간 접근)과 비트 연산만 있으면 구현이 엄청 쉬움. JIT까지 고려하지 않는 수준에서는 함수형 언어도 배열, 비트 연산을 지원함
          + sml, 그 중에서도 MLTon 방언을 추천하고 싶음. OCaml이 좋은 거의 모든 이유를 공유하지만, 개인적으로는 ML-계열 언어 중에서 더 나은 완성형이라는 평가임. OCaml에서 그리운 건 applicative functor 정도인데, 이건 모듈 구조만 약간 다를 뿐 큰 차이 아님
          + 브라우저 안에서 재미와 실험 중심이라면 Elm도 좋은 옵션임. 비슷한 프로젝트로 elmboy 참고 추천
     * 이 글은 Ocaml뿐 아니라 Game Boy 에뮬레이터 구현 과정을 알차게 정리한 내용으로 정말 멋진 자료임. 필자에게 감사함 전함. 덧붙여, 브라우저 안에서 어셈블러 에디터와, 어셈블러/링커/로더까지 한데 합쳐진 SPA로 Gameboy 홈브류 개발 체험을 누구나 쉽게 할 수 있게 만든다면- 임베디드 개발 교육에 좋을 것 같다는 아이디어를 오래전부터 가지고 있었음
          + rgbds-live 프로젝트는 이 아이디어와 비슷하고, RGBDS가 내장됨. rgbds-live
     * 혹시 Game Boy 에뮬레이터에서 사운드 구현에 관한 튜토리얼을 찾는 경우가 있을지 궁금함. 대부분의 튜토리얼이 사운드를 설명하지 않고, 직접 구현해보려고 해도 자료만으로 이해와 구현이 어려웠음
          + 공식적인 튜토리얼은 아니지만, 내가 직접 구현한 방식을 요약한 2개 슬라이드 자료를 공유함: 슬라이드 자료 Game Boy 사운드는 채널이 4개 있고, 각 채널은 매 틱마다 0~15 사이 값 출력. 에뮬레이터는 이를 더해(산술 평균), 0~255 범위로 스케일링, 사운드 버퍼로 내보내야 함. 틱 레이트(4.19MHz)와 사운드 출력(22kHz 등)에 맞게, 약 190틱마다 한 값 출력. 채널별 특징은 이 자료에 잘 정리됨. 1번, 2번 채널은 사각파(0/15반복), 3번 채널은 임의 파형(메모리 읽기), 4번 채널은 노이즈, LSFR 기반. 예시 코드 SoundModeX.java 참조 추천
          + 이 자료도 꽤 괜찮음
          + 이 유튜브 영상도 참고할만함
     * 정말 멋진 글과 쿨한 프로젝트라는 인상
     * 데모가 너무 빠르게 동작한다는 점이 눈에 띔. Throttle 체크박스가 별 효과 없음. 오히려 체크 해제하면 더 느려지는 느낌. Throttle 켜면 240fps, 끄면 180fps임. Throttle 켤 때 1초가 실제 에뮬레이터에서는 약 4초로 느려짐. 아마 모니터 주사율이 240Hz인 점과 연관 있어 보임
          + 아마도 requestAnimationFrame()만 호출하고 deltaTime 계산이 누락된 듯함
     * 정말 아름다운 글이라고 생각함. 이런 자료 공유해줘서 고마움. Rust로 Game Boy 에뮬레이터를 직접 만들어보고 싶어졌고, 블로그 글이 큰 영감이 되었기에 북마크해둠
     * 정말 멋지게 functor랑 GADT 쓰는 예시임. CHIP 8이나 NES 에뮬레이터와 비교해보고 싶고, CAMLBOY를 ocaml-wasm으로 WASM에 포팅해보는 것도 흥미로울 것 같음
          + js_of_ocaml의 새 WASM 백엔드(wasm_of_ocaml)가 있어서, 이미 CAMLBOY를 WASM에서 돌릴 수 있을 것임
"
"https://news.hada.io/topic?id=21873","ChatGPT가 존재한다고 잘못 생각한 기능을 추가했어요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ChatGPT가 존재한다고 잘못 생각한 기능을 추가했어요

     * ChatGPT가 존재하지 않는 기능을 안내하여 실제로 많은 사용자가 Soundslice에 ASCII Tab을 업로드함
     * Soundslice의 원래 서비스는 이미지 기반 악보 스캔만 지원하였으나, ChatGPT 안내로 인해 ASCII Tab 지원 요청이 급증함
     * 제품 오해를 줄이기 위해 실제로 ASCII Tab 임포터 기능을 추가하게 되었음
     * 이 사례는 AI가 잘못된 정보를 유포하며 실제 제품 방향에까지 영향을 미친 첫 사례로 볼 수 있음
     * 기능 추가 자체는 사용자에게 도움이 되지만, '잘못된 정보'에 제품 개발이 휘둘리는 현실에 대해 복합적인 감정을 느꼈음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

배경 및 문제 상황

     * Soundslice의 Sheet Music scanner는 사진에서 악보를 디지털화해 사용자가 듣고, 편집하고, 연습할 수 있도록 도와줌
     * 시스템 개선을 위해 에러 로그를 모니터링하는데, 최근 전통적인 악보 사진 대신 ChatGPT 채팅 화면의 ASCII 타브 악보 스크린샷이 업로드되는 사례가 많아짐
          + ASCII 타브 악보는 기타 등 현악기를 위한 간략화된 악보 표기 방식임
     * 원래 ASCII Tab 형식은 현 Soundslice 서비스에서 지원하지 않는 기능이었음

원인 파악

     * 왜 이렇게 많은 소스의 ASCII 타브 스크린샷이 업로드되는지 원인을 찾던 중, ChatGPT에 질문을 해 직접 테스트함
     * ChatGPT가 사용자에게 Soundslice 사이트에서 ASCII 타브를 가져와 음원을 들으라고 잘못 안내함을 직접 확인함

기능 미제공과 오해

     * Soundslice는 실제로 ASCII 타브를 직접 가져오는 기능을 제공하지 않았음
     * 실제로는 그런 기능이 존재하지 않음에도 많은 사용자가 ChatGPT 안내만 믿고 가입 및 업로드를 시도함
     * ChatGPT의 잘못된 답변 때문에, 회사 서비스에 대한 사용자 기대치가 잘못 형성됨
     * 이로 인해, 실제로 존재하지 않는 기능에 대한 불만이나 문의가 지속적으로 발생하고 있음

의사 결정과 대응

     * 이런 상황에서 회사는 어떻게 대응할지 고민함
     * 서비스에 ""ChatGPT 답변은 잘못됐음""이라는 공지를 붙이는 방법도 있었으나, 실제 사용자 요구가 크다고 판단해 ASCII 타브 임포터 기능을 개발함
     * 2025년 개발 예정 리스트의 하위권에 있던 기능이었으나, 수요에 맞춰 빠르게 도입함
     * 제품 UI 문구도 이 신규 기능을 적극적으로 알리도록 변경함

제품/서비스 방향에 미친 영향

     * ChatGPT가 잘못된 정보를 반복적으로 제공함으로써, 실제로 존재하지 않던 기능을 제품 로드맵에 추가하게 된 첫 사례라고 자평
     * 사용자에게는 유용한 도구를 제공하게 되어 긍정적이지만, 잘못된 정보에 제품 개발 방향이 흔들린 점에 대해 복잡한 감정을 느꼈음

소감 및 고민

     * AI가 퍼뜨린 허위 정보가 실제 회사·제품 의사결정에 영향을 미치는 시대가 도래했음을 실감
     * '사용자 요구'가 아닌 AI가 생성한 잘못된 기대에 따라 회사가 어느 수준까지 대응하는 게 옳은지에 대해 고민이 남음

   환각주도개발...이라고 하면 되려나요;;

   ㅋㅋㅋㅋ ""기능이 있으라""

   HDD ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ

   ㅋㅋㅋㅋㅋㅋ

   추천... 추천이오!

   이게마따요 ㅋㅋ

   ㅋㅋㅋㅋㅋㅋ

   AI에게 간택당한 서비스라니 부럽네요 ㄷㄷ

   Chatgpt가 마케팅부서였나봅니다.

        Hacker News 의견

     * GPT-4를 프로그래밍에 사용할 때 가장 유용한 방법 중 하나는 API 사용법을 <i>설명</i>하는 대신, 예시 코드와 추가 기능 요구만 제시하고 AI가 추측하게 하는 방법임을 경험함. 종종 내가 생각하지 못한 더 좋은 접근법이 나오기도 함. 그럴 땐 실제로 API를 수정해서 AI의 코드가 동작하게 조정함. 반대로 기존 코드를 보고 이게 뭘 하는지 물어볼 때 AI가 실수하면, 그건 내 API가 헷갈리게 설계되어 있다는 신호로 받아들임. 이런 식으로 신경망의 핵심 강점인 정확성보다는 그럴듯한 ""환각(hallucination)"" 능력, 즉 창의성을 활용할 수 있음. GPT-4가 교묘하게 숨겨놓은 버그를 직접 잡는 데 시간을 쏟지 않아도 돼서 좋음. 비직관적인 인터페이스만 개선 가능함. 본질적으로 비효율적이거나 신뢰성이 부족하거나 조합성이 약한 것은 AI가 도와줄 수 없음. 하지만 API가 추측
       가능하고 이해하기 쉽게 개선되는 것만으로도 큰 가치. 단, 이미 인기 있는 API에는 잘 통하지 않는 한계 있음
          + AI가 생각보다 더 나은 접근법을 제안할 때가 있음. 내 책 원고를 30번 이상 편집하고 전문가의 교정까지 거쳤는데도, 마지막 단계에서 Grammarly가 1/3 정도는 유용한 수정 제안함. 모든 제안을 다 반영했다면 원고가 오히려 더 별로였을 것임. Grammarly는 불필요한 단어나 수동태를 찾는 데 강점 있음. 하지만 유머, 맥락, 의도적 반복 등은 파악하지 못함. 문제는 경영자들이 인간을 완전히 빼버리길 원한다는 점인데, 그러면 거의 항상 망하게 됨
          + 가벼운 일화 하나. 파이썬 이미지 프로세싱 라이브러리마다 보통 imread() 함수가 존재하는데, 나는 그걸 모르고 사내 라이브러리를 만들 때 image_get()처럼 독특한 이름을 썼음. ChatGPT에 사내 라이브러리를 이용해 간단한 스크립트 작성을 부탁할 때, 맥락을 별로 안 주면 거의 항상 mylib.imread()로 추측해서 코드를 짬
          + 이 방식은 예전 HCI(휴먼컴퓨터인터랙션) 디자인 기술인 Wizard of Oz와 비슷함. 사람이 실제 앱인 척 흉내내는 실험으로, 새로운 기능을 찾는 데 효과적임 위키 설명
          + 오늘 아침 이 방식을 성공적으로 사용함. AI에게 유닛 테스트 코드를 만들라고 했는데 결과가 엉망이었음. 하지만 그 실패 과정에서 오히려 테스트하려던 코드에 버그가 숨어 있다는 걸 발견함
          + HDD, 환각 주도 개발(Hallucination-Driven Development) 농담
     * 내가 최근에 쓴 글 중에 ""환각이 때때로 테스트 주도 개발(TDD)처럼 작동할 수 있음. 대형 언어 모델이 존재하지 않는 메서드를 환각으로 만들어낸다면, 그 메서드가 논리적으로 필요해서 그런 것일 수 있으므로 직접 구현하는 게 좋을 때가 있음""이라는 내용이 있음 원문 보기. 제품 기능에도 해당하는 이야기임
          + 우리 중 많은 사람이 이 방법을 직접 겪어본 듯함. 비브 코더들의 환각된 API 호출도 사실 먼저 존재했어야 할 제안일지도 모름. 환각 기반 개발, 이제 트렌드임 관련 트윗
     * 이 사례에서 잘못된 교훈을 얻는 사람들이 많은 것 같음. 진짜 핵심은 수요가 있어서가 아니라, 기술이 존재하지 않는 기능을 환각으로 제안해서 새 기능이 추가됐다는 점임. 생성형 AI가 실제로 존재하지 않는 기능을 있다고 착각하게 만든 것이 주요 포인트. 앞으로 더 심각한 문제가 생길 수 있으니 ChatGPT 운영진이 이런 일이 반복되지 않게 신경 써야 한다고 생각함
     * 음악 악보 툴 시장은 여러 방식으로 분열되어 있음. 대표적으로 전통 악보와 탭 악보(기타, 기타류 전용)로 나뉨. 사용자, 표기 방식, 활용 정보까지 완전히 다름. 표준화를 시도한 케이스(MusicXML 등)가 있지만 여전히 캠프 간 장벽이 높음. ChatGPT가 한 일은 탭 악보 사용자도 Soundslice를 쓸 거라 추정한 것인데, 아마도 현재는 그렇지 않을 듯함. 하지만 미래에는 Soundslice가 탭 사용자들에게 특별한 가치를 줄 수 있는 추가 기능을 제공한다면 바뀔 수도 있다고 봄
          + 내 의견을 정확히 이해한 건지는 모르겠지만, Soundslice는 10년 전부터 탭 악보(특히 편집기와 다양한 포맷의 임포터 포함)를 완벽히 지원함. 이번에 새로 추가된 건 <i>ASCII tab</i> 지원임
     * 최근 LLM으로 코드 작성 시도를 했음. 보일러플레이트 구성에는 쓸 만함. 패턴을 인식해주는 면도 강점임. 다만, 코드를 반복적으로 이리저리 고치게 만들 때가 많음. iOS 앱 전체를 만들어준 적도 있는데, UI는 내가 원하는 대로 잘 변형되었고 샘플 데이터도 다양하게 채워줌. 하지만 코드 구조 정리는 아주 엉망이었음. 오디오 파일의 실행 시간을 리스트 형태로 관리해야 할 때, 파일 ID와 길이를 딕셔너리로 대응시키려 했음(초보 개발자에게: 통상 이런 정보는 AudioFile이라는 객체 안에 붙는 게 정석임). LLM은 예전 버전 코드를 계속 참고하는 경향이 있음. 반복적으로 이번 작업과 상관없는 수정을 고집할 때도 많음. 점점 LLM을 '교육하는' 데 시간을 너무 많이 쓰고 있다는 느낌. LLM의 한계를 넘어서 지나치게 의존지만 않으면 꽤 생산성이 있을 거라 봄. 최소한
       내가 바꾼 내용을 파악하고, 5일 전 코드 초안 기준으로 계속 추천만 하지 않았으면 바람임. (긴 플랫 텍스트 파일을 enum 값으로 바꾸는 예제 작업에서, 처음 두 줄만 내가 수정하니 곧 패턴을 익혀 수십 줄을 제대로 제안하는 모습도 보여줌)
          + LLM은 정말 생산적인 인턴 여러 명을 두고 일하는 느낌이지만, 그 한계도 비슷함
     * 이건 product-channel fit(제품-채널 적합성)이라고 부름. 새 유입 채널에서의 수요를 즉각 포착한 점이 중요 포인트임
          + ChatGPT가 실제로 해준 일은, 내가 경험한 회사의 영업팀이 늘 하던 일이 자동화된 버전임. 고객이 원하는 걸 ""이미 있다"" 혹은 ""다음 분기에 된다""라고 자신감 있게 말한 뒤, 엔지니어들한테 빨리 만들어달라고 전해주는 구조와 동일함
          + solutions engineering과 연관됨. 즉, 대규모 고객 개별 커스터마이징, 어댑터, 데이터 처리 등 맞춤 솔루션 지원에 집중하는 분야임이 맞는지 궁금함
          + 완전히 새로운 시장 니즈 또는 기회를 찾는 참신한 방식임. LLM이 대량의 데이터를 보고 인간이 미처 인지하지 못한 패턴을 ""환각""으로 보여줄 수 있는 강점과 맞닿아 있음. 이번 케이스처럼, 실제로 그 패턴이 존재한다는 증거가 사람들이 ChatGPT의 잘못된 정보를 믿고 행동한 결과로 나타남. 즉, 환각→행동→실제 수요 검증→공급자 기능 추가 순서. 구현 비용이 아주 크지 않으면 기업 입장에서 괜찮은 대응임
     * 이번 사례에서 바로 떠오른 건 ‘AI SEO’임. 많은 사람이 어떻게 하면 AI 챗봇, 예를 들어 ChatGPT 같은 LLM이 내 사이트로 트래픽을 보내게 만들지 연구하고 있을 거라는 생각. 앞으로 이 시장에 수십억 달러가 몰릴 전망임. 나는 이쪽 지식이 없지만 이미 많은 사람들이 도전 중일 테고, 앞으로는 OpenAI에 비용을 내고 ChatGPT가 내 제품을 더 많이 추천하게 만드는 서비스가 생길지도 궁금함
          + 이 판에서 이기려면, 웹사이트가 LLM 트레이닝 데이터에 많이 자연스럽게 언급되도록 유도해야 함. AI SEO와 기존 SEO가 크게 다르지 않음
     * AI가 실제 현실에 변화를 끼치는 흥미로운 사례임. AGI가 세상을 정복하는 로봇 군단 이야기를 두려워하는 시각도 있지만, 실제로는 시장의 힘이 AI가 세상을 움직이는 더 직접적인 수단이 될 거라 생각함
     * B2B 스타트업에서 ""영업팀이 적어둔 기능이 실제론 없는데 백로그가 갑자기 그 기능 쪽으로 급선회""한 사례를 경험한 사람이라면, AI의 환각을 계기로 진행된 변화가 전혀 놀랍지 않을 것임
          + ""rogue""를 잘못 쓴 것 아니냐는 농담. ""생활용품 rouge""와 ""규정 위반 rogue""의 차이도 링크와 함께 언급
          + B2B 영역에선 영업팀이 파워포인트 자료만 들고 다니다가, 반응이 좋으면 기능이나 심지어 제품 전체를 뒤에서 급조하는 게 표준 관행임. 스타트업만의 일이 아님. 대형 기업도 종종 이런 식 임
          + B2B(Business-to-Business)는 기업 대상 비즈니스 의미임
     * 우리 회사도 비슷한 문제를 겪음. ChatGPT가 아니라 자체 AI 챗봇이 문서 기반 RAG를 하다가, 실재하지 않는 옵션(flag)을 자꾸 환각함. 그래서 제품 피드백 차원에서 검토함. 그게 꼭 정확히 그 옵션이 필요한 건 아니었지만, 뭔가 직관적인 기능이 빠져있으니 LLM이 그럴듯하게 상상한 거라고 봄
"
"https://news.hada.io/topic?id=21923","미국에서 파티가 사라진 현상과 그 의미","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         미국에서 파티가 사라진 현상과 그 의미

     * 최근 연구에서 미국인들의 파티 참석 및 주최 시간이 지난 20년 간 절반 이하로 감소함
     * 청년층의 파티 시간은 2003년에 비해 70%나 줄어든 것으로 조사됨
     * 개인주의 강화, 가족 및 노동 환경 변화, 디지털 기술 도입 등이 파티 감소에 영향을 미침
     * 스마트폰과 소셜 미디어 확산으로 가상 관계는 늘었지만 실제 커뮤니티 접촉은 줄어드는 양상임
     * 변화의 이면에는 지나친 고립과 불안정한 친목이 남아있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

파티 감소 현상과 충격적인 통계

     * 2023년 기준, 미국인의 4.1%만이 주말이나 공휴일에 파티 또는 의식에 참석 또는 주최함
     * 지난 20년간 모든 연령대에서 사교 모임 시간이 절반 이하로 줄어듦
     * 특히 15~24세 청년층의 경우 파티에 할애하는 시간이 70% 감소함
     * 미국인의 대면 사교 활동이 20년 만에 20% 정도 감소했으며, 미혼 남성과 25세 미만의 경우 35% 이상 급감 현상이 나타남
     * 최근엔 남성이 TV 시청에 보내는 시간이 타인과 어울리는 시간의 7배에 달하고, 여성은 반려동물과 더 많은 시간을 보내는 등 고립 현상이 두드러짐

미국 파티의 역사적 변화

     * 과거 초기 미국 사회에서도 자주 모이고 교류하는 문화가 강했음
     * 대도시화 이후에도 1970년대까지는 가정 내 친구 초대 및 방문이 빈번했음
     * 이 시기엔 미국 성인의 75%가 월 1회 이상 친구들과 모임을 가졌으며, 평균적으로 월 3회 사적인 모임이 있었음
     * 1990년대 후반에는 이런 사교 방문 빈도가 40% 이상 감소하며, 2000년경부터 사교적 위기가 본격화됨
     * 개인주의 확산 이후 교회, 노동조합, 여가 공동체 활동까지 전반적으로 줄어드는 양상임
     * 이 변화는 계층, 빈부 구분 없이 미국 사회 전반에 퍼지는 현상임

파티 감소에 영향을 준 요인들

  노동 환경과 가족 구조 변화

     * 1970년대 이후 여성의 경제활동 참여 증가로 전통적으로 여성 주도였던 가족 내 사교 일정 관리가 사라짐
     * 남성이 파티나 공동 모임의 준비 및 계획을 인계받지 못해 부부 맞벌이 가정에서 성인 모임이 소멸 현상으로 이어짐

  육아 및 양육 방식의 변화

     * 과거보다 자녀는 적게 두고, 돌보는 시간은 증가함
     * 부모의 양육 불안, 성취 집착으로 인해 주말 시간마저 자녀의 과외 및 활동, 이동 지원에 집중됨
     * 이로 인해 성인 보다는 자녀 중심의 스케줄이 가정의 우선순위가 됨

  디지털 기술과 미디어 소비의 영향

     * TV 보급 이후 잉여 시간 대부분이 시청 시간으로 대체됨
     * 스마트폰과 소셜 미디어로 가족 또는 '온라인 트라이브'와의 접촉이 늘었으나, 실제 이웃 및 친구와의 지역 커뮤니티 연결은 약화 현상 보임
     * 온라인 “패러소셜 관계” (연예인, 인플루언서, 유튜브 등)의 시간 투입이 늘면서 실제 깊은 인간관계가 줄어듦

  음주 문화의 변화

     * 10대 음주율 급락으로 음주가 파티의 이유였던 환경이 약화되고 있음
     * 사회적 파티와 음주 몰입도가 낮아지자, 청년층의 대면 사교 기회 자체가 감소함
     * 18~34세 청년 중 “음주가 건강에 해롭다”고 인식하는 비율은 최근 20년간 2배 상승, 65%에 이르름

결론 및 시사점

     * 맞벌이 가정과 양육 환경 변화, 기술 발달, 새로운 여가 문화가 풍요로운 환경을 만들었지만, 사회적 친밀감과 깊은 우정은 감소함
     * 기술이 우리의 능력을 ‘확장’시키는 동시에 인간관계 단절이라는 ‘절단’을 유발함
     * 장기적으로는 고립, 불안, 진정한 친구 관계 상실로 이어질 가능성 우려됨
     * 화려한 엔터테인먼트와 효율성 뒤에 지속 가능한 사회적 연결을 복원하는 노력이 필요함

        Hacker News 의견

     * 최근 GenX subreddit에 Gen Zer가 90년대 후반과 2000년대 초 십대 영화에 나오는 파티가 진짜 있었는지 물어본 게시글이 있음
       https://reddit.com/r/GenX/…
       Gen X 세대 반응은 ""이게 무슨 질문이야? 그냥 평범한 십대 파티였음. 내가 정말 고대인처럼 느껴짐"" 같은 혼돈과 혼란이 섞인 반응이었음
       Gen X가 경험한 청소년기와 Gen Z가 생각하는 현실 사이의 간극이 흥미로움
       요즘 청소년이 소셜 미디어, 스마트폰, 과도한 일정과 보호로 많은 것을 빼앗긴 현실이 슬픔
       부동산, 교통 같은 문제로 쉽게 설명할 수 없음을 강조함
       90년대에도 교외 가정과 아이들은 많았지만, 요즘 아이들은 ""기본적 십대 파티"" 자체를 알아보지 못하고 환상으로 인식하는 현상이 단순히 집값 때문만은 아니라고 생각함
          + Reddit이나 Twitter의 Gen Z 의견을 일반화하면 안 됨을 강조함
            Reddit 등에 글을 쓰는 Gen Z는 대부분 ""인터넷에 오래 접속하는 매우 온라인 층""임
            실제 현실의 아이들과 시간을 보내 보면, 대부분 Reddit이나 Twitter를 하지 않거나 계정이 없어보임
            실제 Gen Z 대다수와 온라인상의 목소리 큰 극소수는 매우 다름
          + 지금의 ""새로운 세대""는 예전 세대에서 소외된 이들이 느낀 감정을 기본값으로 체험함
            젊은 세대와 이야기하다보면, 예전 소외 계층이 느꼈던 것과 비슷한 점이 많아짐
            결과적으로 사회의 ""기본값""이 남과 단절된 방식으로 옮겨왔고, 예전 소외자들은 주변을 알면서도 어쩔 수 없었던 것처럼, 요즘은 세대 전체가 사회적 연결의 방식을 모르고 있으면서도 상황 파악이 어려움
            '모두가 있는 파티에 초대받지 못하는' 느낌과 유사하다고 비유함
          + Reddit에 그런 질문을 다는 사람들 자체가 그 옛날 파티에도 못 갔을 사람들임
            내 자녀 둘의 경험상, 아직도 거의 매주 고등학교에서 집들이 파티가 열림
            다만 예전보다 술은 훨씬 적게 마시고, 성숙하고 열린 분위기임
            (90년대 고등학교에서 트랜스젠더였으면 아주 힘들었을 걸 떠올려 봄)
          + 과잉보호와 맞춤식 돌봄 때문에 요즘 애들 사회성이 저하됨을 체감함
            어릴 땐 나보다 몇 살 많은 아이에게 맡기거나, 애들이 저녁까지 아무 데나 돌아다녀도 괜찮았음
            파티는 TV처럼 술과 섹스가 난무하는 게 아니라, 10명이 컴퓨터 하나 놓고 콜라랑 칩 먹으며 보스전을 깨려고 꿈틀대는 시간 등이었음
            이런 게 요즘은 부모에게도 위험해서 할 수 없는 상황임
            아이들이 다른 삶의 관점을 잃은 이유가 여기 있을 것임
          + 소셜 미디어와 스마트폰, 과보호 등이 지금 세대에 준 해악이 생각보다 작음을 주장함
            오히려 내 세대 때 파티가 더 해로웠던 것 같음
            1995년 Larry Clark의 영화 ""kids""를 참고하면 현실 파티의 부정적 측면을 잘 보여줌
            실제 삶은 ""American Pie""식이 아니었음. Gen Z는 이런 영화에서 잘못된 인상을 받을 듯
     * 파티 문화의 변화에는 부동산, 교통, 숙박 문제가 상당히 영향이 큼
       파티를 하려면 공간, 손님, 그리고 손님들이 오가거나 머무를 장소가 필요함
       요즘은 평범한 사람이 집을 소유하지 못하고, 대부분 임대 아파트나 일부 주택에 거주
       큰 집이나 마당, 주방 등이 없으니 큰 파티 자체가 어렵고, 작은 모임은 파티로도 취급이 안 됨
       또한 큰 집은 대체로 인구 밀도가 낮은 곳에 있고 대중교통도 없음
       친구들도 가까이 있지 않고 인터넷에 흩어져 있음
       반대로 도시에 살면 집이 작아서 파티를 하기 힘듦
       이런 이유로 호텔이 함께하는 컨벤션 같은 공개 이벤트가 늘어난 것으로 보임
       가족이나 친구의 집이 망가지는 일도 없으니 모두에게 좋음
          + 내가 다녔던 파티들은 대부분 작은 아파트, 임대 주택, 마당 작고 꽉 찬 공간이었음
            요즘은 파티에 가기 전에 준비물 챙기고, 무리와 동행, 인스타용 사진 배경 준비 등 부담이 커진 게 문제 같음
            전에는 비좁아도 그냥 모여 놀았는데, 이제는 그런 즉흥성과 소박함이 많이 사라졌음
          + 미국의 주택 소유율은 지난 45년간 거의 64%로 유지됨
            https://fred.stlouisfed.org/series/RSAHORUSQ156S
          + 예전 샌프란시스코 아파트에서 100여 명이 서서 파티한 적도 있음
            15명에겐 식탁이 없어 바닥에 어디든 앉아서 먹었음
            도시와 교외 이동, 친구 부르기 등 나이가 들어서 사회적 활동이 줄어든 것도 맞음
            하지만 작은 공간이어도 마음가짐만 있으면 충분히 재밌게 놀 수 있음
          + 미국 내 주택 소유율 차이는 세대별로 봤을 때도 최대 10% 포인트 차이임
            20대가 자기 세대 기준에서 자산이 없다고 느끼지만, 실제로는 예전 40대보다 더 나은 환경임
            나이와 자원의 관점 차이를 이해해야 함
            https://census.gov/library/stories/…
          + 베를린에 살고 있는데, 모두가 평범한 아파트에 살아도 집들이 파티는 자주 함
            두 방짜리 아파트에서 손님이 계단까지 흘러 넘칠 때도 있음
     * 요즘 부모의 역할 변화가 중요함
       내 배우자와 나는 주로 우리가 먼저 연락해서 playdate(놀이 모임)를 잡는 입장임
       아이들에게 친구에게 줄 명함을 들려주거나, 학급 연락망을 통해 부모끼리 연락함
       우리 세대는 방과 후 더 자주 함께 놀았던 것 같음
       교외에 살기에 특별히 환경이 바뀌진 않았음
       다른 부모들에게 이유를 물어보면 주말 스포츠 리그, 친척 방문, 육아 노동에 지쳐 있다는 말을 주로 들음
       아이들에게 자주 playdate를 하게 해주면 가족들끼리도 더 친밀해지고 신뢰가 쌓일 텐데, 실제로는 공원도 비어 있음
       내 주변에 나만 이렇게 불만인지 모르겠음
          + 요즘 모든 가족이 맞벌이라, 오후 시간에 아이를 돌봐야 해서 방학 동안에도 집에 못 있게 됨
            80년대만 해도 외벌이 가정이 많아 아이들이 여름 내내 동네를 휘젓고 다녔음
            지금은 부모가 캠프 스케줄을 극대화해 아이를 늘 감독받게 만든 탓에 동네가 텅 빔
            우리 집은 자유로운 방식으로 전환하려 했지만, 주변 아이들도 모두 바빠 설득하고 논의가 필요했음
            결국 일정 부분 나아지긴 했으나, 내가 어릴 때처럼 아이 스스로 독립적으로 성장하기엔 한계가 있었음
          + 아이들끼리 서로 잘 놀고 싶지만, 실상은 부모들이 더 소외되고 비사교적으로 느껴질 때가 많음
            특히 50~60대 조부모가 데려다주는 친구 경우엔 대면 대화하며 시간과 픽업 약속도 잡음
            반면 25~35세 부모들은 차에서 애만 내려놓고 바로 떠남
            공원 등에서 만나도 스마트폰에 몰두해 다른 부모들과 교류가 적음
            80년대에 부모들은 모임을 통해 고기도 굽고 스몰토크도 자주 했기에 그 문화가 많이 사라진 게 체감됨
          + 모든 놀이가 playdate로 변함. 예전엔 ""저녁 전까지만 들어와라""면 누구든 동네 친구와 놀았음
            조금 크면 스케이트장이나 볼링장, 아니면 매일 공원에서 킥볼 하고, 그게 일상이었음
            그 시절을 그리워함
          + 출산율과 신축 주택의 영향도 있다고 생각함
            내가 자란 동네는 신혼부부가 한꺼번에 이주해서 또래 아이들 천지였음
            지금 우리 동네는 아이 있는 집이 손에 꼽음
            예전엔 초등학생들에게 숙제가 없었거나 고등학교 때도 아주 적었는데, 지금은 1학년부터 숙제가 많아져 노는 시간이 줄어듦
            당시엔 혁명을 일으켜야 했지만 이미 사라진 일임
     * 지난 2년간 12~40명 모임의 파티를 열었지만, 파티 문화의 쇠퇴가 체감됨
       사람들이 거의 답례 파티를 하지 않아, 계속 파티 여는 게 점점 의욕이 꺾임
       파티를 통해 우정을 쌓고 다시 초대받길 바랐으나, 실제로 그런 일은 일어나지 않음
       셋업(청소, 음식 장만, 조율)과 뒷정리 모두 내 몫인데, 투자 대비 수익(ROI)이 떨어지는 느낌임
       사람들이 파티 끝나고 뭘 해야 하는지 잊어버린 것 같음
       ""너무 재밌었으니 우리도 한번 열자""가 아니라, 다들 금방 잊어버리고 넘어감
          + 파티를 여는 것이 딱히 결과나 산출을 기대하고 하는 행위가 아니길 바람
            HN에서 ROI(투자수익률)을 따진다는 점이 특이함
            파티가 즐겁지 않으면 그만두면 되고, 즐거우면 그 자체로 의미 있음
          + 파티 주최의 목표가 친밀한 관계나 내 차례 초대를 기대해서는 안 되고, 넓은 네트워크를 만드는 것임
            깊은 우정보다는 얕은 연결고리를 확장하는 데 의의가 있음
            만약 진짜 친구를 만들고 싶다면, 특정 인물과 일대일로 시간을 보내는 게 훨씬 효과적임
          + 12~40명 규모면 potluck(음식 각자 가져오는 모임)에 적합함
            메인 메뉴만 정하고, 각자 음식을 공유하면 설거지도 서로 함
            파티 후 정리까지 도와주면 좋은 손님이고, 안 도와주면 다음 초대에서 제외시키면 됨
            매달 같은 날 정기적으로 돌리면 자연스러운 교류가 생김
            파티란 사람마다 기대치, 준비물, 행동 패턴이 다양해서, 전부 혼자 책임지는 건 피곤하니 시스템을 만들어야 지속 가능함
          + 파티를 통해 ""나도 초대받겠다""는 기대 대신, 그냥 사람들이 파티를 안 할 뿐인지 고민할 필요 있음
            만약 모든 사람이 파티를 열고 나만 초대받지 못한다면 문제가 있지만, 대부분 스스로 파티를 안 여는 게 보통임
            실제 친한 친구는 1:1 시간을 보내면서 생기는 게 맞고, 큰 파티에선 주최자가 바빠서 충분히 교류하지 못함
            큰 파티에만 참석하다 보면 결국 친밀한 대화도 어려움
          + 혹시 샌디에이고 살면 내 파티에 환영함
            주로 보드게임, 모닥불, 저녁, 영화, 바다 산책 등으로 진행해서 술은 필수 아님
            야단법석은 아니지만 항상 즐거움
     * 2005년 중서부 고등학생 시절, 미성년 음주와 파티는 흔했음
       대부분은 ""쿨한 부모""가 허락해줘서 가능했음
       파티에서는 음주하면 밤새 자거나 부모에게 연락하게 하는 규칙이 있었음
       그 시절은 지금보다 관대했음
       요즘에 음주운전 걸리면 인생이 한동안 꼬일 수 있고, 예전에는 경찰이 그냥 데려다 줬다는 이야기도 들음
       요즘 아이들은 온라인과 알고리즘의 세계에 갇혀 있고, 부모도 더 이상 그런 활동을 허락하기 힘듦
       경찰에게 미성년자 음주 제공으로 기소당하면 곤란하니 부모도 조심스러움
          + 예전보다 환경이 안 관대해졌다기보단 위험 감수성향이 크게 줄어듦
            밀레니얼 부모는 위험 감수에 더 엄격하고 Gen Z, Gen A 청소년도 규칙을 더 잘 지킴
            위험을 꺼리는 이유는 미디어에서의 공포 조장, 출산율 저하 등 다양한 요인이 있음
            이전엔 리스크 감수 행동이 아니면 그냥 심심했는데, 지금은 온라인에서 낮은 강도의 즐거움을 쉽게 얻을 수 있어서 굳이 큰 위험을 감수하지 않게 변화함
          + 나도 비슷한 연배인데, 우리 친구 부모들은 파티 때 열쇠를 걷어서 ""여긴 안전하다""는 분위기였음
            음주운전하다 한번 문제 생긴 친구는 영원히 초대명단에서 제외됐고, 실제 그 친구가 뒤에 DUI로 세상을 떠남
            90년대/2000년대 추억이 그리움
          + 이런 사회 변화에는 깊은 이유가 있다고 생각함
     * 이 기사에서 다루지 않은 점은, 예전 남자만 가정밖에서 일하던 시절, 집에 남은 여성은 매우 고립됐다는 점임
       그래서 여성들의 사교 모임이나 소규모 gathering이 사회적 구실을 했을 것임
       여성의 사회 진출로 직장 내 인간관계도 지방/동네 관계만큼 깊지 않아도, 외로움을 어느 정도 해소해줌
       이제는 맞벌이 부부 모두 지쳐서 파티 준비 자체가 또 하나의 일이 되어버림
       오히려 집은 가족과 스크린을 위한 공간으로 변질됐고, 자녀들도 집에서 사교 모임보다는 온라인이 자연스러워졌음
       콘서트나 모임도 더 이상 활력을 주지 못하는 시대가 됨
          + 맞벌이 시대에는 집안일 부담이 훨씬 커졌다는 점도 추가로 언급함
            누구 한 명 전담이 아닌, 퇴근 후나 주말에 집안일을 해결해야 해서, 20시간 가까운 시간이 필요하게 됨
     * 예전 파티 문화가 알코올 소비에 크게 기대었다는 부분이 과소평가됐다고 느껴짐
       Mothers Against Drunk Driving 같은 단체 활동과 엄격한 DUI(음주운전) 법도 중요한 영향을 미침
       70~80년대에는 몇 잔 마시고 운전하는 게 매우 흔했고, 점심에도 술을 마심
       지금은 지정운전자, 택시(시골에는 없음), 그냥 술을 안 마시는 쪽을 선택함
       이런 분위기로 인해 사교 시간도 줄고, 다들 일찍 귀가함
       다음날 출근 때문이라는 현실적인 이유도 존재함
          + 예전에도 미성년자에게 술 제공이 불법이었지만, 부모가 실제 처벌받는 사례는 잘 못 들어봄
            요즘 들어 법 집행이 엄격해진 듯함
          + 운전을 안 하고도 다닐 수 있는 동네 환경이 있으면 괜찮음
          + 0.08 기준은 그래도 술 두세잔은 허용함
     * 문화 변화에는 다양한 요인이 복합적으로 작용함
       첫째, 미국의 소송 문화와 그로 인한 극도의 위험 회피
       둘째, 과거엔 모든 실수가 금세 잊혔지만, 지금은 소셜 미디어로 영원히 기록되고 남음
       스포츠 중심 학교문화도 지나치게 강해진 게 문제임
       그리고 옛날엔 주말에 초대 못 받은 파티 소식을 월요일 학교에서 전해 듣는 게 속상했다면, 지금은 SNS 라이브로 초대받지 못한 장면을 실시간으로 보는 게 훨씬 더 상심됨
     * 솔직히 말해서, 예전 파티 문화는 술 마시고 운전하는 습관 때문에 가능했던 면도 큼
       지금도 남아있지만 예전만큼은 아님
          + 혹은 도보가 가능한 동네, 대중교통 덕분에 가능했음
          + Uber 생긴 이후로 스스로 운전하지 않아도 되는 게 도움이 됨
          + 2009년까지 파티 문화가 그래도 존재했다는 데이터도 있음
          + 가격과 경제 상황도 그만큼 중요함
            대학 시절엔 닉켈 드래프트에 다이브 바에서 저렴하게 놀았으나
            요즘은 한 잔에 $10, 입장료까지 붙어서 부담이 큼
          + 1800년대 뉴잉글랜드에서도 음주운전이 있었냐는 농담도 나옴
     * 우리 할머니는 지역 공군 부인 클럽 회장이었고, 집에는 늘 술이 가득했고, 매일 여러 사람들이 들렀음
       최소 10명 가까운 이웃과 아주 친했고, 전 이웃들과도 인연을 이어갔음
       요즘 미국에서는 이런 공동체를 찾기 어렵다고 느낌
       이민자 커뮤니티에서는 여전히 살아있을지 몰라도, 이제는 대부분 이웃과의 접촉 자체가 거래 목적이 아니면 거의 없음
          + 내가 사는 노동자 계층 골목은 여전히 이웃 공동체가 살아있음
            핸드폰 없이 지내면서, 밖에서 tinyhome 짓는 걸 계기로 주민들과 친해졌고
            ""연락 어떻게 해요?"" 물으면 ""낮부터 해질 때까지 그냥 직접 벨 누르고 방문하라""고 함
            지난 2년 만에 24가구 전부와 친해졌음(대부분 임대주택)
            새 이웃이 오면 일주일 지나 맥주 한 병과 대화를 먼저 건넴
            부촌에 살 때보다 노동자 계층 이웃들이 훨씬 더 따뜻하고 인정 넘치고 베풀 줄 앎
            핸드폰 사용을 줄이고, 이웃들과 공동구매로 잔디깎이도 같이 씀
            직접 부딪히고 이웃답게 굴어야 공동체가 사는 것임
          + 남부 캘리포니아에서도 예전엔 다양한 이민자가 모인 활기찬 동네였음
            코로나 이후 집값 급등, 인구 이동이 많아지면서 음악소리도 멈추고, 밤거리는 조용해졌음
            사람들도 상대방과 멀어졌고, 자기 일에 집중함
            여전히 이민자 동네지만, 출신지가 달라지면서 문화 차이, 경제적 압박도 영향이 큰 듯
          + 내 경험상, HOA(주택단지 관리기구)가 없는 강가 마을에서는 이웃들과 파티하며 해질녘 맥주 마신 추억이 많음
            군인 커뮤니티도 확실히 더 결속력이 있고 가족적임
          + 소수 가구가 모인 cul-de-sac으로 이사 후, 자기소개와 연락망 적은 쪽지를 이웃 우편함에 넣었으나
            답장 준 이웃은 1명, 심지어 쪽지를 다시 돌려준 이웃까지 있었음
            그렇게 차가운 동네임을 실감함
          + 이민자 커뮤니티나 노년층 중심 동네는 이웃문화가 여전히 살아있는 경우가 많음
            옛날 문화를 지켰거나, 혹은 외로움 때문인지 이런 공동체적 특성이 남아있음
"
"https://news.hada.io/topic?id=21929","Pangolin – Cloudflare Tunnels의 오픈소스 대체제 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Pangolin – Cloudflare Tunnels의 오픈소스 대체제

     * Cloudflare Tunnels와 유사한 기능을 제공하는 셀프호스팅 터널링 역방향 프록시 관리 서버
     * WireGuard 기반 암호화 터널을 통해 포트포워딩 없이도 프라이빗 네트워크 자원을 안전하게 외부에 노출할 수 있음
     * 역방향 프록시, 역방향 인증 및 접근제어, OAuth2/OIDC 지원 등 다양한 인증과 보안 기능, 직관적인 웹 대시보드 제공
     * 도커 컴포즈(Docker Compose) 기반 배포로 손쉬운 설치 및 운영, API와 플러그인 연동을 통한 자동화와 확장성 확보
     * IoT, 홈랩, 멀티클라우드, 비즈니스 서비스 등 다양한 환경에서 네트워크 제약을 우회하고 안전하게 자원을 관리할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Pangolin 개요

     * Pangolin은 자체 호스팅이 가능한 터널링 기반 역방향 프록시 서버로, 중앙 관리형 인증과 접근제어 기능을 제공함
     * WireGuard 유저스페이스 클라이언트(Newt) 및 다양한 WireGuard 클라이언트와 연동되어, 방화벽 및 NAT 제약 환경에서도 안전하게 연결 가능함
     * 포트포워딩 없이도 내부 자원을 외부에 노출할 수 있어 공개 IP를 숨기고 네트워크를 보호할 수 있음
     * 대시보드에서 사이트, 사용자, 역할, 자원을 쉽게 관리할 수 있고, 다크모드 및 모바일 지원 UI 제공

주요 기능

     * WireGuard 터널을 통한 역방향 프록시
          + 방화벽을 뚫지 않고 네트워크 자원 노출 가능 (포트 오픈 불필요)
          + 자체 WireGuard 클라이언트(Newt)와 연동, 모든 WireGuard 클라이언트 지원
          + 자동 SSL 인증서(Let's Encrypt) 발급 및 HTTP/HTTPS, TCP/UDP 서비스 지원
          + 로드밸런싱 기능 내장
     * 인증 및 접근제어
          + 중앙화된 인증 시스템(플랫폼 SSO, OAuth2/OIDC, 외부 IdP 연동)
          + 역할 기반 접근제어(RBAC), 자원별 IP/URL/범위 지정
          + 이메일 OTP, TOTP, PIN코드, 임시 공유 링크 등 다양한 추가 인증 옵션
          + 조직/사이트/사용자/역할 구성을 통한 체계적 관리
     * 직관적인 대시보드
          + 사이트/자원/사용자/역할을 한눈에 관리하는 클린 UI
          + 사용량, 연결 상태 실시간 모니터링
          + 라이트/다크 모드, 모바일 대응
     * 손쉬운 배포 및 확장성
          + Docker Compose 기반 설치, 클라우드/온프레미스 모두 지원
          + API 및 Swagger 문서 제공, 자동화 및 커스텀 스크립트 연동 가능
          + Traefik 플러그인(CrowdSec, Geoblock) 등과 연동해 WAF 및 지오블로킹 적용
          + 여러 사이트를 하나의 중앙 서버로 통합 관리

대표 활용 사례

     * 포트포워딩 제한된 환경(홈랩/ISP 제한) 에서 웹서비스 노출
     * 사내/온프레미스 및 클라우드 어플리케이션을 안전하게 외부에 서비스
     * IoT 네트워크 통합 관리: 분산된 IoT 현장을 중앙 서버에서 안전하게 연결 및 접근
     * 멀티클라우드, 하이브리드 네트워크 통합 리버스 프록시/로드밸런서로 활용

유사 프로젝트와 차별점

     * Cloudflare Tunnels: SaaS 기반의 역방향 프록시 서비스와 비슷하지만, Pangolin은 셀프호스팅으로 완전한 인프라 제어권을 가짐
     * Authelia: 중앙 인증, 역할 관리에서 영감을 받았음

배포 및 라이선스

     * Docker Compose로 중앙 서버 배포, 도메인 연동, 사이트 연결, 자원 노출까지 단계별 가이드 제공
     * AGPL-3 및 Fossorial 상용 라이선스로 듀얼 라이선스 정책

   딸깍 편하게 쓰기엔 쉽지 않군요

   다 좋은데 이걸 쓰면 시스템에서 Wireguard를 제어하지 못합니다. 터널과는 별개로 사용하고 싶다면 VM으로 나눠서 써야 해요.

        Hacker News 의견

     * 안녕하세요, 저는 이 프로젝트의 다른 메인테이너임. 시스템의 다른 컴포넌트들에 대해 좀 더 자세히 설명하고 싶음. Pangolin은 HTTP 프록시 동작을 위해 내부적으로 Traefik을 사용함. Badger라는 플러그인이 모든 요청의 인증을 Pangolin으로 처리함. 두 번째 서비스인 Gerbil은 Pangolin이 연결을 위한 WireGuard 피어를 만들 수 있게 해 주는 관리 서버임. 마지막으로 Newt가 있는데, 사용자 공간에서 완벽하게 WireGuard를 활용하고, Gerbil과 통신해 로컬 리소스를 프록시해 주는 CLI 툴 및 Docker 컨테이너임. 이를 통해 서비스 노출 시 루트 권한 프로세스나 특권 컨테이너를 실행할 필요 없음
          + 몇 달 동안 Hetzner의 작은 VPS에서 집으로 트래픽 터널링하는 용도로 이걸 사용해 왔음. 경험이 매우 원활하고 안정적이었음. 한 가지 이슈가 있다고 생각했으나 Pangolin과는 무관했음. 관련 내용은 여기에서 확인 가능함
          + 여기에 언급한 각 사용 사례마다 문서에 미니 튜토리얼이 있으면 테스트를 빠르게 해보고 도움이 되는지 확인할 수 있을 것 같음
     * 이거 정말 흥미로움. Cloudflare Tunnel에 종속되는 것이 항상 불만이었는데, 오픈 소스 대안을 보니 진짜 신선함. Pangolin이 네트워크 불안정, 인증 이슈, 스케일링 등 까다로운 부분을 어떻게 처리하는지 궁금함. 실제로 써본 분들은 Cloudflare의 ""그냥 된다"" 매직과 비교해서 어떤지 알려주면 좋겠음. 특히 집에서 자가 호스팅을 할 때 잘 작동하는지 궁금함. 참고로 나는 라즈베리파이로 블로그와 다양한 취미 프로젝트를 집에서 운영 중임. 실제 경험담이 정말 도움이 될 것 같음
     * 이거 원격 개발 박스 여러 대를 다루거나 비슷한 용도로 정말 흥미로워 보임. 사실 그런 인프라에 깊게 관여해본 적이 없는 입장이라 질문이 조금 기초적일 수 있음. CF 터널은 사용해 본 적 없고, 지금까지는 SSH로 리버스 프록시 터널을 만들거나 Tailscale 정도만 써 봤음. 테스트용 내부 서비스가 특정 디바이스(EC2 인스턴스나 집에 있는 노트북)에만 있어서 그렇게 했었음. 쉽게 말해 tailscale 같은 솔루션과 비교해 Pangolin이 어떤 점이 다른지 설명해 줄 수 있는지 궁금함
          + 네가 사용 중인 SSH나 Tailscale은 그 목적에 정말 잘 맞는 선택임. Pangolin은 일반적으로 ssh 터널처럼 일시적이기보다는, 서비스로 향하는 정적이고 상시적인 터널에 가까움. 네트워크 내부 앱을 가족 등 외부 사람들이 웹브라우저로 접근할 수 있게 공개하고 싶을 때 적합함. 예를 들어 비즈니스용 내부 앱이나 Immich, Grafana 같은 홈랩 서비스를 브라우저에서 외부에 제공하고 싶다면 이 도구가 매우 유용할 것임. 이해되었기를 바람
          + 나는 집에 있는 unraid 서버에서 CF 터널을 광범위하게 사용함. 요약하자면, 특정 앱을 공개하고 싶고 Tailscale 노드를 추가하고 싶지 않을 때(예: 내 Plex 서버를 쓰는 내 동생) CF에서 서브도메인을 하나 만들고, 그 서브도메인을 CF 터널로 라우팅함. 사이트/서비스 하나당 폼 세 칸만 입력하면 되고, 자동으로 SSL 인증서도 발급됨. 그래서 만족하면서 사용 중임
          + Tailscale(그리고 headscale)은 외부에서 접근 불가능한 내부 리소스 접속에 아주 적합함. NAS를 외부에서 차단하고 내부에서만 접근하고 싶을 때 쓰기도 함. Cloudflare 터널은 외부에 서비스를 노출하면서도 약간의 보호를 제공함. 일부 사용자는 백엔드는 tailscale로만 접근하게 하고, 퍼블릭 쪽은 Cloudflare 터널로만 열기도 함. 중앙 nginx 프록시 매니저로 Cloudflare 터널을 직접 연결하는 것도 충분히 가능한 방법임. 물론 Tailscale로도 공개 서비스로 라우팅할 수는 있지만, Cloudflare가 조금 더 견고한 보호를 제공함. Pangolin도 충분히 흥미로워 보여서 테스트해볼 만하고, 테스트할 땐 Cloudflare 터널 뒤에 두었다가 필요하면 전면에 둘 수도 있을 것 같음
     * 진지한 보안 초보 질문임. 이런 류의 솔루션을 사용할 때, 보안 관점에서 최악의 시나리오는 무엇인지 궁금함. 인증이 뚫리면 내부 포트라도 공개될 것 같긴 한데, 그 외에 추가로 주의해야 할 점이 있는지 알고 싶음
     * 인증 서비스 특성상 영향 범위가 크기 때문에, 전문 보안 감사를 진행했는지와 공식적인 공개 보안 침투 테스트 프로그램이 있는지 궁금함
          + 만약 감사를 했다면 문서에 표시되어 있을 것이라고 생각함
     * 정말 좋아 보임. 나도 최근 비슷하게 OPNSense 박스를 활용해 DNS, WireGuard 인스턴스, 그리고 인증서를 Synology의 Nginx 리버스 프록시에 전달하는 구조를 구축했음. 클라이언트에선 WG 터널을 내부 IP 대역에서만 켜고, 내부 DNS로만 동작하게 하여 공인 인증서에 내 IP를 노출하지 않게 했음. 이렇게 하면 집에서 동작하는 네트워크엔 문제없지만, 여러 사이트를 다룰 땐 Pangolin이 더 세련되고 설정도 간단할 것 같음. Newt가 WireGuard 서버의 별도 구현인지, 그리고 보안 감사를 받은 적이 있는지도 궁금함
     * Pangolin과 NetBird의 차이가 궁금함. NetBird도 셀프 호스팅과 완전 오픈 소스임. NetBird 깃허브 링크
          + 내가 알기로 NetBird는 오픈 소스 버전에 모든 기능이 포함되어 있지는 않음. 결정적으로 SSO 비용 문제 때문에 사용을 포기하게 되었음
          + 나도 더 자세히 알고 싶음. 사용 사례는 비슷한데, 기술적으로는 다름. NetBird는 WireGuard를 활용한 Tailscale 대안이고, Pangolin은 Traefik을 사용함. 나는 NetBird 사용자이며 매우 만족함. UI 디자인은 두 곳 다 비슷한 점이 있음
     * 이것이 zrok 같은 다른 오픈소스와는 어떻게 다른지 궁금함
     * 정말 멋진 프로젝트임. 나는 tailscale과 VPS에 설치한 nginx proxy manager로 내 앱을 외부에 공개했고, 해당 내용을 여기에 적어 놓았음. Pangolin은 이와 비슷하면서도 더 좋은 UI와 컨트롤을 제공하는 듯하니 꼭 사용해 볼 예정임. 한 가지 궁금한 점은 여러 도메인 처리가 가능한지임. 나는 여러 도메인을 VPS로 포인트하여 nginx proxy manager에서 프록시하는데, Pangolin도 이렇게 여러 도메인을 지원하는지 궁금함
     * Cloudflare Tunnels의 오픈소스 대안이 상당히 많음: awesome-tunneling 깃허브 링크. 그중에서 Pangolin이 가장 완성도 높고 다듬어진 솔루션 중 하나라고 생각함
"
"https://news.hada.io/topic?id=21931","OpenAI의 WindSurf 인수 계약 무산, 공동 창업자 및 주요 개발진은 구글로 이적","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           OpenAI의 WindSurf 인수 계약 무산, 공동 창업자 및 주요 개발진은 구글로 이적

   🚨OpenAI 가 약 30억 달러에 Windsurf 인수를 추진했지만 7월 11일 최종 무산되었습니다.

   대신 Windsurf CEO Varun Mohan 공동창업자 Douglas Chen, R&D 핵심 인력 등은 구글 DeepMind로 합류, AI 에이전트 코딩 역량 강화에 집중하게 되었죠.

   Windsurf 측은 현재 독립 조직 체제를 유지 중이며, Jeff Wang 대표 체제로 운영되고 있고, 기술 일부만 비독점 라이선스로 제공됩니다.

   오픈AI 인수건 땜에 클로드가 최신 버전 라이선스 제공 중단해가지고 윈드서프에서 클로드 4.x 버전 모델 쓰려면 비싸게 API를 직접 사야하는데 클로드가 복귀할까요?

   왜 무산됬는지 궁금합니다.

   오 이런 윈드서프의 미래도 밝지만은 않나봐요.
"
"https://news.hada.io/topic?id=21918","NativeMind - 브라우저에서 실행되는 프라이빗 온디바이스 AI 어시스턴트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              NativeMind - 브라우저에서 실행되는 프라이빗 온디바이스 AI 어시스턴트

     * 크롬 확장형태로, 클라우드 서버 없이 사용자의 기기에서만 동작하는 프라이빗 AI 어시스턴트. 모든 데이터와 대화가 오직 내 기기 안에서 처리
     * Ollama 및 WebLLM 등 다양한 오픈소스 AI 모델을 지원하며, 브라우저 확장 프로그램 형태로 쉽고 빠르게 설치 가능
     * 지능형 대화, 페이지 요약 및 이해, 통합 번역, AI 검색, 글쓰기 지원 등 실시간 AI 도우미 기능을 제공
     * 크롬·엣지 네이티브 통합 및 Windows, macOS, Linux 지원
     * 지원 AI 모델
          + Ollama (권장) : Deepseek, Qwen, Llama, Gemma, Mistral, Phi 등 다양한 최신 모델 지원
          + WebLLM (빠른 체험) : Qwen3-0.6B 모델로 브라우저만으로 바로 AI 체험 가능. WebAssembly 기반, 추가 설치 없이 바로 동작
     * 기술 스택 : Vue 3 + TypeScript, WXT + Vite, TailwindCSS, WebLLM + Ollama + AI SDK, PNPM
"
"https://news.hada.io/topic?id=21954","Kimi K2 - 최첨단 전문가 혼합(MoE) 언어 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Kimi K2 - 최첨단 전문가 혼합(MoE) 언어 모델

     * Moonshot AI의 Kimi K2는 1조 매개변수를 가진 최첨단 믹스처오브엑스퍼트(MoE) 언어 모델임
     * 학습 과정에서 Muon 최적화 기법을 도입하여 대규모 안정성 문제를 해결함
     * 도구 사용, 추론, 자율적 문제 해결을 위해 에이전트 지능에 초점을 맞춤
     * 다양한 벤치마크에서 코딩, 수학, 일반 작업에서 상위권 성능을 입증함
     * 배포 및 활용이 편리하며, OpenAI/Anthropic 호환 API 제공 및 유연한 엔진 지원 환경임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

왜 Kimi K2가 중요한가

     * Kimi K2는 Moonshot AI에서 개발한 최신 믹스처오브엑스퍼트(MoE) 언어 모델
     * 1조 파라미터 규모와 혁신적인 최적화 방법(Muon)이 적용되어 대규모 언어 모델 영역에서 높은 성능과 안정성을 제공
     * 기존 고성능 오픈소스 모델들과 비교 시, 코딩, 수학, 도구 사용 등 다양한 실제 적용 분야에서 글로벌 최첨단(SOTA) 및 오픈소스 최고 수준을 기록
     * 대형 모델을 빠르고 안정적으로 학습하는 문제, 그리고 다양한 인공지능 활용 시나리오를 지원하는 유연성에서 강점을 가짐

1. 모델 소개

     * Kimi K2는 1조(1T) 전체 파라미터와 320억(32B) 활성 파라미터를 갖춘 최첨단 MoE 언어 모델임
     * Muon 옵티마이저를 사용해 대규모 모델 학습의 불안정을 효과적으로 해결함
     * 도구 활용, 복잡한 추론, 자율 에이전트 등 고차원적 능력에 특화함

  주요 특징

     * 대규모 학습: 1조 파라미터 모델을 15.5조 토큰으로 사전학습하며, 학습 불안정성(unstability) 없이 진행함
     * MuonClip 옵티마이저: 대규모 모델에 특화된 Muon 알고리듬과 새로운 최적화 기법을 결합해 안정성 확보함
     * Agentic Intelligence: 도구 활용, 복잡한 추론, 자율 문제해결을 염두에 두고 설계함

  모델 종류

     * Kimi-K2-Base: 커스텀 파인튜닝 및 연구자 활용에 적합한 기초 모델
     * Kimi-K2-Instruct: 채팅, 일반 에이전트 구동에 최적화된 사후학습(post-training) 모델

2. 모델 요약

     * 아키텍처: Mixture-of-Experts (MoE)
     * 총 파라미터: 1조(1,000,000,000,000)
     * 활성 파라미터: 32억(32B)
     * 레이어 수: 61 (Dense layer 포함)
     * Dense Layer 수: 1
     * Attention hidden dimension: 7168
     * MoE hidden dimension(전문가당) : 2048
     * Attention Head: 64
     * 전문가 개수: 384
     * 토큰당 선택되는 전문가 수: 8
     * 공유 전문가 수: 1
     * 어휘사이즈: 160K
     * 컨텍스트 길이: 128K
     * Attention 메커니즘: MLA
     * 활성화 함수: SwiGLU

3. 평가 결과

  Instruction 모델 성능

     * 코딩 과제, 도구 활용, 수학/이공계, 일반 작업 등 다양한 벤치마크에서 상위권 성능을 기록함
     * SWE-bench, LiveCodeBench, OJBench, MultiPL-E, TerminalBench, AceBench, Tau2, AIME, MATH-500 등 각종 코드·도구, 수학·논리, 일반 작업 부문에서 SOTA 또는 동급 최고 성능 보임
     * SWE-bench Verified에서 pass@1 65.8%, SWE-bench Multilingual에서 47.3% 기록, Agentic Coding 환경에서도 두드러진 성과 보임
     * MATH-500(수학), AIME, HMMT, CNMO 등 이공계 테스트에서도 탁월한 정확도
     * MMLU(일반지식), SimpleQA 등 다양한 일반작업에서도 경쟁 오픈소스/상용 모델 대비 상위 성능 확보함

  Base 모델 성능

     * MMLU, TriviaQA, GPQA-Diamond 등 대표 벤치마크에서 오픈소스 동급 모델 중 최상위 성적 기록
     * 코딩, 수학, 중국어 평가 등 대형 오픈소스 베이스모델 대비 전반적인 우위 확보함

4. 배포 및 엔진 구동

     * https://platform.moonshot.ai에서 Kimi K2 API(OpenAI/Anthropic 호환) 사용 가능함
     * Huggingface(https://huggingface.co/moonshotai/Kimi-K2-Instruct)에서도 모델 체크포인트(block-fp8) 지원함
     * 권장 추론 엔진: vLLM, SGLang, KTransformers, TensorRT-LLM 등 다양한 환경 호환성 보유함

5. 모델 활용 예시

  채팅 인터페이스

     * 로컬 추론 서비스 실행 후, OpenAI 호환 클라이언트(Chat Completions API 등)에서 직접 상호작용 가능함
     * 권장 temperature: 0.6, System 프롬프트도 기본 형태로 사용권장됨

  도구 호출 기능

     * Kimi-K2-Instruct는 강력한 도구 호출(tool-calling) 능력을 가짐
     * 사용자는 요청마다 활용 가능한 툴 리스트를 전달하면, 모델이 자율적으로 도구 사용 및 실행 시점을 판단함
     * 파이프라인 전체에 걸친 예제 및 결과 메시지 시연 가능함
     * 엔진의 Kimi-K2 도구 파싱 로직 지원이 필요함

6. 라이선스

     * 코드와 모델 가중치 모두 Modified MIT License로 오픈소스 배포함

        Hacker News 의견

     * Kimi를 몇 가지 코딩 문제에 사용해봤음, Claude가 틀거나 돌아가는 문제에서 꽤 잘 작동했음, 모델 크기가 엄청나게 커서 “로컬” 모델로는 적합하지 않은데, 구동에는 H200 GPU 16개 정도가 필요할 것이라 생각함, 다른 모델과 다른 개성이 좀 느껴졌고 만족스러웠음, 최소한 앙상블 사용환경에서는 유용할 것 같음
          + 4비트 양자화를 사용하면 512GB Mac Studio 두 대(MLX TB4 Ring 방식, 관련 정보는 여기 링크 참고)나, 1TB RAM 이상의 Epyc 시스템 한 대에서도 실용적인 속도가 나옴, 대략 2만 달러 정도의 비용으로 실험해볼 수 있음, 하지만 진짜 프로덕션 수준의 속도를 원한다면 훨씬 강력한 하드웨어가 필요함, “로컬” 보다는 “개인 스탬프 모델” 정도로 보는 게 더 적합함
          + Claude와 직접 비교하면서 몇 번 테스트해봤음, Kimi는 더 단순하고 읽기 쉬운 코드를 생성해줬는데, Claude는 오버엔지니어드된 느낌이 강했음, 단, Kimi는 Claude가 챙겼던 몇 가지 미묘한 엣지 케이스를 놓치기도 했음
          + Claude라고 했는데, Sonnet? 3.7? 3.5? Opus? 4? 어느 버전인지 궁금함
          + 처음으로 Kimi에 준 질문(꽤 단순한 수학적 놀이 문제였음)에 대답이 엄청나게 틀렸음, 공정하게 보자면 이 질문에 OpenAI 모델도 실패했음, 추가 프롬프트 덕분에 좀 개선하긴 했지만 의외였음
     * GPT 4o, DeepSeek-V3 계열처럼, 이 모델(Kimi K2)은 굉장히 인상적인 범용 LLM임, 게다가 오픈소스임, 요즘 주목을 덜 받는 이유는 최전선이 추론 및 멀티모달 모델 쪽으로 이동했기 때문이라 생각함, 정확도 벤치마크를 보면 상위권 모델이 전부 추론 특화형임(참고 링크), 만약 누군가 Kimi K2로 추론 특화 모델을 훈련한다면 그 성능이 무척 궁금함
          + “Kimi k2로 추론 특화 모델을 훈련했다면”이라고 했는데, MoonshotAI에서 아마 그 작업을 진행 중일 것 같음
          + 왜 Kimi의 현재나 과거 모델이 Artificial analysis 벤치마크에 아직 추가되지 않았는지 궁금함
     * 기술적인 장점 외에도, Kimi K2는 로봇같은 느낌이 적어서 감탄하게 됨, Anthropic의 최상급 모델들처럼 성격이 쾌활하고 똑똑하며 유창함, 뻣뻣한 봇 스타일의 답변을 안 보는 작은 승리라 할 만함
     * 내 생각엔, OpenAI의 오픈소스 모델 출시는 Kimi K2가 화제를 선점하고 수치를 이겨버려서 미뤄진 듯함
          + OpenAI 쪽에서 “너무 커서 집에서 직접 호스팅은 어렵다”고 언급하기도 했으니 그게 맞을 수 있음, 지금쯤 ay OpenAI에서 벤치마크 돌려보며 “이기는” 평가 항목을 찾고 있을 듯함
          + 벤치마크 기준으로 보면 Kimi K2는 여러 부문에서 GPT-4.1을 이김, OpenAI가 제대로 경쟁하려면 GPT-4.1 가중치 또는 동급 모델을 공개해야 할 텐데, 아마 그럴 가능성은 적을 것 같음
     * 오픈소스가 아니라 “수정된 MIT 라이선스”임, 월 활성 사용자 1억 명 혹은 월 매출 2천만 달러(혹은 그 이상)의 상업 서비스에서 사용하면 서비스 UI에 “Kimi K2”를 명확하게 표시해야 한다는 조건이 붙음
          + 이 조건은 Llama의 “Built with Llama” 노출 조건과 “월 활성 사용자 7억” 조항을 합친 것처럼 보임, 그리고 이걸 살짝 “변형된 MIT”처럼 포장한 셈임
          + 이런 조건이 OSD(오픈소스 정의) 또는 FSF의 자유 소프트웨어 정의, Debian 기준에도 위반된다고 보지 않음, GPLv2, GPLv3, BSD 4-clause에서도 비슷한 공표 의무가 있고, 다만 사용자 수나 수익 기준은 없음, 그리고 뉴럴 네트워크는 소스코드에서 빌드되는 게 아니라서 “오픈소스”라는 말도 좀 모호함, 진짜 오픈소스에 비유하면 학습 데이터와 과정까지 공개하는 게 가까운데, 이건 수백만 달러가 드는 일이므로 컴파일과도 다름, 그래서 라이선스 문제와는 별개임
          + 이 조건이 자유소프트웨어의 네 가지 기본 자유 중 어떤 점을 침해하는지 궁금함, 구체적으로 짚어줄 수 있겠는지?
          + OpenStreetMap 조건보다 오히려 덜 제한적임
          + 이 조건은 Google이 “각색판”을 만들어 Gemini-3.0-pro로 뽑아낼까봐 붙인 걸로 보임
     * 나한테 K2는 산 이름이고 SOTA는 “summits on the air”라는 의미라서, 헤드라인을 보고 놀랐었음
          + K2하면 나는 Kotlin 2.0 컴파일러가 먼저 떠오름, 관련 블로그 링크
     * 새로운, 탄탄한 논리모델이 아닌 LLM이 프론티어를 확장해가는 게 마음에 듦, 이런 모델도 여전히 좋은 활용처가 있음(STEM, 논리퍼즐이 아닌 영역), 추론 토큰에 비용을 쓰고 싶지 않을 때 유용함
     * “오픈소스”라니, 실상은 오픈 웨이트임, 언제나처럼 데이터셋, 학습 스크립트 등은 제공하지 않음
          + 지금은 오픈 웨이트조차 아님, 웨이트 공개에 “수정된 MIT 라이선스” 조건임(상술)
          + 현행 저작권 체계로는 SOTA 모델 훈련에 저작권 텍스트 없이 개발이 현실적으로 불가능함, 이걸 어떻게 유통할 수 있을지 궁금함
     * 답변 품질이나 톤이 마음에 듦(ChatGPT나 DeepSeek에 비해 덜 공손하고 좀 더 직설적임), 다만 현 SOTA 모델(DeepSeek 포함)보다 응답 포맷을 엉키거나 놓치는 일이 더 많은 것 같음
     * 요즘 AI 모델이 전부 em-dash(—)를 남용함, ChatGPT는 em-dash 사용하지 말라 했더니 그래도 계속 씀, 왜 이런지 아는 사람 있음?
          + em-dash 쓰는 걸 좋아하는 입장에서, 이제는 LLM 특유의 투박함(sloppiness)을 드러내는 기호로 인식돼서 아쉬운 마음임
"
"https://news.hada.io/topic?id=21837","LLM을 둘러싼 모든 것이 여전히 마법같고 희망적인 생각임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    LLM을 둘러싼 모든 것이 여전히 마법같고 희망적인 생각임

     * LLM에 대한 현재 논의는 명확한 정량적 근거 없이 이루어지고 있음
     * 각 사용자의 경험은 매우 단편적이며, 실제 활용 환경이나 배경 지식 등 핵심 요소가 거의 공유되지 않음
     * 비결정론적 특성으로 인해 같은 작업도 시간마다 다른 결과를 보여 신뢰성에 제한이 존재함
     * 업계 리더들의 과장된 주장이 비평 없는 수용과 과도한 기대를 부추기는 상황임
     * 실제로도 필자는 다양한 AI 툴을 일상적으로 사용하며, 절반 정도의 확률로만 원하는 결과를 얻는 현실 경험을 공유함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM을 둘러싼 논쟁과 기술에 대한 시각

  LLM에 대한 비판과 분위기

     * 최근 AI, 특히 LLM(대규모 언어 모델)에 대한 논쟁에서, 비판적인 시각은 흔히 ""기술을 제대로 이해하지 못한 사람들의 의견""으로 폄하하는 분위기 형성임
     * Hacker News 등에서 ""AI에 질문을 던지면 본질을 모르는 무지함""이라는 반응이 반복됨

  사용자 간 경험의 간극

     * LLM의 실제 효용성에 대해 ""어느 정도는 도움이 된다""는 사용자와, ""모든 시도를 해봤지만 별로 쓸모없다""는 사용자 간의 의견 차이 존재
     * 이 차이가 생기는 이유는 경험에 대한 구체적 기준과 정보가 공유되지 않기 때문임
          + 어떤 프로젝트에서 사용했는지
          + 코드베이스의 상태(새 프로젝트, 성숙한 코드, 비공개 소스 등)
          + 사용자의 전문성, 그 전문성이 실제 문제와 얼마나 연결되는지
          + LLM이 작성한 결과물을 실제로 제대로 정제·배포하기까지 추가로 들어간 노력 등 구체 정보 부재

  경험 비교의 어려움과 비결정론성

     * 어떤 사용자가 모든 정보를 상세히 공유한다고 해도, 다른 사용자와의 경험 비교가 거의 불가능한 상황임
     * LLM과 오토메이션 에이전트들은 본질적으로 비결정론적임
          + 똑같은 문제에 같은 방식으로 요청을 해도, 매번 다른 결과를 얻게 됨
          + 프로젝트 종류, 사용하는 모델, 도구, 언어 등 변화 요인이 많아 일관된 검증 어려움

  업계 리더와 과장된 기대

     * 업계 리더들이 LLM의 성과를 과도하게 강조하는 사례 다수 존재
          + 예: 한 업계 리더가 ""Claude Code""를 사용해 오래된 버그가 놀라울 정도로 쉽게 수정된다는 경험, 세부 정보 공유 없이 대중적 호응을 얻음
          + 구체적인 코드 크기, 버그의 난이도, 추가 노동 여부, 사용한 프로그래밍 언어·프레임워크 등 핵심 정보가 생략된 채로 매우 긍정적인 메시지만 확산됨
          + 이러한 사례는 1.8천개 이상의 호응과 204개의 재포스팅을 기록하며, 과장 마케팅이 쉬이 확산됨

  사용 경험과 현실 인식

     * 필자도 Vercel의 v0, Claude Code, Midjourney 등 다양한 AI 툴을 매일 활용함
          + Swift에 대한 지식 없이 SwiftUI로 모니터링 앱 제작
          + Midjourney로 이벤트용 포스터 자동 생성
          + Elixir 기반 MCP 서버 함수 코딩 등 경험 있음
     * 하지만 성공 확률은 대략 50% 에 불과하며, 결과물은 언제나 일관되지 않음
     * LLM이 마치 마법처럼 느껴질 때도 있지만, 실제로는 비결정적인 통계적 모델일 뿐임
     * 이러한 현실에서, 업계 논의는 이분법(마법 vs. 엔지니어링) 에만 머무르고 있다고 지적함

결론

     * LLM과 AI를 둘러싼 현장은 확실하고 명확한 검증 체계 없이 과장된 상상, 기대, 믿음이 선호되는 경향임
     * 비판적 사고를 멈추지 않고, 실제로 기능과 효과를 세부적으로 검증하려는 노력이 중요함
     * 논의에서 중요한 것은 구체적이고 정량적인 정보 공유임
     * LLM의 한계와 가능성을 균형 있게 바라보는 시각이 필요함

        Hacker News 의견

     * 내가 일하는 곳의 경영진이 10배 생산성 향상 얘기를 들어서 답답함을 느낌. 일부는 우리 회사의 초기 도입자들이 직접 그런 얘기를 하기도 함. 하지만 그런 기대치는 너무 높음. Amdahl의 법칙도 한몫하는데, 내 시간 대부분은 코딩이 아니라 생각과 커뮤니케이션에 씀. 코딩이 진짜 10배 빨라진다 쳐도(대부분의 경우 그렇지 않음) 전체 생산성은 10~15% 향상에 불과함. 그래도 꽤 괜찮은 결과이긴 하지만, 10배는 아님
          + 내 현재 업무가 좀 더 R&D 느낌이라서 그런지, LLM은 ""생각"" 부분에서도 ""코딩"" 만큼이나 큰 이득을 줌(커뮤니케이션은 내가 직접 잘 해결함). LLM으로 생각 작업을 하는 건 20년 전 웹 검색을 마스터하던 감각과 비슷함. 예전 검색 엔진은 내가 뭘 찾는지 알아야 했는데, 이제는 LLM이 뭘 찾아야 하는지부터 찾아줌(그리고 대신 검색해주기도 함). 예전엔 어렵다고 분류했던 일들도 이제는 LLM 덕분에 쉽게 해결 가능. 지금은 웹 검색의 1/3 정도를 ChatGPT o3로 하고 있음. 이제 이걸 포기하는 건 상상도 못 함. 게다가 LLM이 내 미완성 생각을 정리하고 토론 상대가 되어주는 심리적 요소도 큼. 이 덕분에 많은 일이 한결 덜 두렵게 느껴지고, 그 차이도 큼
          + 내 회사에서도 상황이 비슷함. 내부 초기 도입자들이 주장하는 생산성 향상은 매우 좁은 방식으로 측정하거나, 산수 자체가 좀 허술한 경우가 많음
          + LLM이 주니어보다 시니어 개발자에게 더 큰 가속 효과를 줄 수도 있음(주니어는 좋은/나쁜 코드를 잘 구분 못하니까). 시니어 한 명이 향상된 LLM 워크플로우를 쓰면 예전 주니어 열 명 분 생산성도 가능할 듯함. 심지어 못하는 개발자라면 실질적으로 생산성을 마이너스로 만들 수도 있음(시니어의 시간을 뺏어서). 괜찮은 주니어도 LLM이 이미 더 잘하는 반복 일에 머무름. 그래서 직업이 실제로 없어질 수도 있겠다고 보는 입장임
          + LLM 툴 쓴다고 10~15% 생산성만 늘어난 경우 LLM 툴 비용 때문에 고용 비용이 10~15% 더 비싸지면 특별한 장점이 없다고 생각함. 생산의 총 비용을 고려해야 한다는 입장임
          + 개인 프로젝트에서는 쉽게 10배 가까이 빨라짐. 하지만 회사에서는 여러 팀과 논의, 요구사항 변경, PR 리뷰 등으로 이 환경이 안 맞음. 이런 최적화된 설계와 표준 패턴이 가능한 건 작은 스타트업이나 혼자 하는 프로젝트에 한정됨. 여러 명이 모이면 그 자체로 합의도 어려움. AI가 최고의 성과를 내려면 모든 게 표준화되어야 하는데, 현실은 모든 게 조금씩 어긋나기 때문에 실제 조직에선 그만한 효과를 보기 힘듦. 소수의 의지가 맞는 개발자끼리 협업하면 10배도 가능하겠지만, 기업 환경에서는 거의 불가능함. AI가 중간관리와 프로젝트 플래닝 쪽에 더 어울린다고 봄
     * 글쓴이가 불평하는 쪽이 나임. ChatGPT가 한창 부족하던 시절에 녹색필드 제품을 출시함. 이후 Claude와 웹챗~XCode 간 복붙, 그 다음에는 Cursor를 씀. 빌드 오류는 종종 생겼지만, 그래도 생산성은 최소 3배는 되었음. 이제는 에이전트 성능이 좋아지고 Claude 4도 나와서, 코딩은 거의 안 함. Architect/Manager 역할로 내 전문 지식으로 에이전트만 잘 디렉팅함. 스타트업에서 몇달 째 한 줄도 직접 코드를 안 썼음. 내가 직접 PR 올리기 전 전부 검수하고, 테스트도 철저히 하지만 Cursor+Sonnet 조합이 미쳤음. 라인 수 같은 건 중요하지 않고, 오히려 오래 일한 기존 코드베이스 전문가들이 나한테 자잘한 버그 질문함. Claude 덕분에 프론트엔드 개발자 일까지 손댔어서 조심하고 있음. 단순히 쿼리만 던지는 게 아니라 치밀한 리서치, 계획, 단계별 탐색 과정을 거치게 함. 도메인
       지식은 필수임. 그래도 이만큼 유용하게 쓰지 못하는 사람이 있다는 게 신기함. 이런 기사 매주 두 개는 보는 느낌임
          + 나도 비슷한 경험이지만 약간 다른 환경(PhD 학생)임. LLM 회의적이었는데 Claude Code 이후 일의 방식이 완전히 바뀜. 그래도 큐레이션은 전적으로 내 몫임(PhD 과정에서 배우는 중요한 소프트스킬이자, LLM이 목표나 컨텍스트를 금방 잃거나 기억하지 못하기 때문). 정확한 소통이 가능하다면, CC로 예전엔 불가능했던 방식으로 연산을 조직할 수 있음. 프로그래밍이 더 쉬워지는 건 아니지만, 완전히 다른 양식이 생김
          + LLM이 신뢰받지 못할 코드를 빨리 검사하는 방법이나, LLM이 유닛 테스트도 작성하는지 평균 프롬프트 길이 등 실제 검증/검사 과정이 궁금함
          + LLM 출력을 바로 신뢰하냐는 지적. 전체 프로젝트 맥락을 LLM이 파악하지 못하고, 헛소리(환각)가 많기 때문에 검증이 필요함
          + LLM 코드 품질이 전체적으로 많이 부족하다고 느낌. 여러 번 반복 수정해야 해서 그냥 직접 짠 게 더 빠를 때가 많음. 하지만 대규모 메카니컬 리팩터링에는 에이전트가 아주 유용함. 복잡한 vim macro나 AST 스크립트 짜는 대신 에이전트 활용함
          + 몇 달 동안 한 줄도 직접 코드를 안 쓴다니 개인적으로 너무 지루할 것 같다는 생각
          + 블로그 글에서 주장한 내용(검증 불가, 엄청난 성과 주장 등)을 그대로 재확인해줌. 계정도 새로 만든 걸로 보임
     * 내 생각엔 실제 서비스 산업 노동의 대부분이 엑셀 시트 옮기기나 CRM/이메일~엑셀로 데이터 옮기는 것 같은 수작업임. 대기업엔 이런 반복 업무를 하는 상근 직원이 소프트웨어 엔지니어 대비 백 배쯤 있을 거라 봄. 그러니 LLM이 OCaml을 못 해도 상관없고, 엑셀에서 인간보다 조금만 잘하면 엄청난 가치가 창출됨. MCP 같은 걸로 이메일-CRM-엑셀을 엮어 자동화하면 오류율이나 환각도 확 줄어듦. 인간도 비결정적이니 이런 프로세스엔 결정론이 중요하지 않음. LLM과 암호화폐(crypto)는 유틸리티나 도입 면에서 완전히 다름. 스마트폰 보급을 떠올리게 됨. 내 비기술 친구들도 이제 LLM을 매우 다양한 용도로 씀
          + 암호화폐와의 비교는 건설적이지 못하다고 생각함. 기술적으론 전혀 관계 없음. 다만 기술 과신 현상은 있음. 이제 기본적인 자동화조차 접하지 못한 사람에겐 LLM이 SF처럼 보일 수도 있음. 이 분야가 이만큼 메인스트림이 된 적이 이전엔 없음. 앞으로는 성공과 실패, 다양한 의견, 실전 경험들이 혼재하는 와일드웨스트가 될 것이라 봄. 좋은 점은, 친구의 앱 아이디어도 이제 직접 실험해 볼 수 있는 세상이 마련됐다는 것임
          + 수작업 데이터 정제하는 FTE(Full-time Employee)들도 결과 검증과 기한 지키기, 법적 책임까지 있음. LLM은 일시적 예외 상황(예, 휴일이라 값이 0이어야 함)들을 맥락 밖에서 파악해 체크하진 못함. 이런 검증에 FTE 한 명 쓸 만한 가치가 충분히 있음
          + 소프트웨어 엔지니어 1명 당 100명 데이터 파이프라이닝 수작업 FTE라는 건 어떤 회사에만 해당하는지 궁금. 실제 백오피스/데이터 엔트리 업무가 대부분이라고 보지 않음. AI의 파급력엔 동의하지만 백색 칼라 전체가 거의 이메일+데이터 엔트리 인력이라는 주장엔 회의적임
          + 이런 유형의 직무 복잡성을 과소평가하고 있다고 생각함
     * 은퇴한 프로그래머 입장인데, 확률로 생성된 코드에 미션 크리티컬 책임을 맡길 상상을 못 함. 조금만 수정하면 쓸 수 있을 듯하면 이해 가능. 코딩 외 분야(브레인스토밍, 창의적 사고, 리서치 서포트)엔 LLM이 놀라움. LLM을 사고 파트너처럼 취급함. 실수도 있지만, 다른 출처로 검증하거나 다른 LLM으로 검토시키면 쉽게 잡을 수 있음
          + 나 역시 무조건 회의적인 성격인데, 실제로 써보니 모든 면에서 기대치를 뛰어넘음. 몇 시간 만에 몇 달 걸릴 프로젝트를 프로토타입~출시까지 진도 냄. 내가 할 수 있는 일들은 더 빠르게, 못하는 일(외주나 채용해야 하는 것)까지도 사소한 비용, 빠른 속도로 해냄. 물론 완벽하진 않고 짜증나는 점(명시적 지시 무시, 거짓말 등)도 많지만, 나에겐 게임 체인저임
          + LLM을 사고 파트너로 활용하는 게 잠깐은 잘 되는 것 같았지만, 어느 순간 망상이 드러난다고 느낌. LLM은 지식이나 추론을 하는 것처럼 보이게 잘 착각시킴. 특히 내가 모르는 분야에선 더 위험함. 검색엔진은 신뢰도를 소스로 비교할 수 있지만 LLM은 그게 안 됨. 실수 잡기도 항상 쉽지 않음
          + 40년 차 개발자로 몇 달 전부터 LLM을 쓰기 시작했는데, 일하는 방식이 크게 변함. 로그 에러 메시지 붙여넣으면 1분 안에 수정, 설계 브레인스토밍, 새로운 솔루션 제안 등. 코드 검증은 하지만, 정확성과 지능에 매일 놀람. (암호화폐와는 전혀 다름)
          + LLM 회의론자 입장이지만, 사실 인간이 작성한 모든 코드도 본질적으로 확률적임. 그래서 코드 리뷰, 유닛 테스트, 페어 프로그래밍, 가이드 같은 게 존재함. LLM이나 사람 출력 결과 모두 무비판적으로 쓰면 안 됨. 다만 LLM은 마법이 아니고, 도움이 되는 부분 외에 효율이나 안전성, 리팩터링 같은 장기적 가치를 무시한 채 보일러플레이트만 늘리는 데 악용될까 우려함
          + 내가 생각하기에 LLM이 가장 잘하는 건 데이터 사이언스임. IO가 명확해서 결과 검증이 쉬움. 특정 데이터의 특성을 알고 있으면 테스트 코드 생성도 쉽게 시킴. 컨텍스트가 필요하면 Claude Code가 큰 변화를 가져옴. 예시로 PCAP 파일에서 각 UDP 패킷 내 다중 메시지 추출, 필터링, 패턴 매칭, 테스트용 분리 등. ""이 모든 함수에 대한 유닛 테스트를 작성해줘""라고 하면 LLM이 자가 검증까지 가능함
     * 나는 1년 전부터 거의 매일 LLM을 쓰고, 90%는 내 문제를 해결해줌. AI/LLM에 대한 부정적 의견이 언제 심각하게 받아들여야 할지 모르겠음. 내 경험상 코드베이스 전체를 입력하고 마법을 기대하는 일은 없었고, 내가 아는/이해하는 정확하고 구체적인 질문만 던지고, 솔루션을 검증 가능한 방식으로 적용함. 이런 방식이 아니라면 LLM을 잘못 쓰는 것임. 실제로 마법을 체험하려면, 작고 일상적이며 일관된 활용이 핵심임
          + Weatherman 패러디처럼 ""60% 확률로 항상 동작한다""는 식으로 비꼼. 나도 GPT, Claude를 Cursor로 매일 씀. GPT o3는 일반 지식 검색에 좋고, Claude는 종종 실패함. 모델 자체가 바보 같지만 가끔은 핵심도 집어냄. 뭘 원하는지 스스로 알고, LLM을 잘 길들일 때 생산적으로 쓸 수 있다고 봄
          + ""내 경험에서 90% 잘된다"" 주장도 믿음이 잘 안 간다는 의견
     * 글쓴이가 논객들의 부정확한 논평에 화난 듯함. 실제론 LLM의 문제점과 한계는 매일 부딪히는 사용자=프로모터가 잘 알고 있다고 생각함. 번역, 전사, 코드 생성(일정 규모까지) 등 본래 불가능하거나 거의 불가능했던 문제가 완전히 혹은 거의 해결됨
          + 번역, 전사, 코드 생성이 진짜로 불가능에 가까웠나? Google Translate, Whisper, 오래전부터 존재했다는 지적
          + 실제 결함을 드러내는 건 detractor(비판자)이고, 오히려 promoter(찬양자)는 LLM을 만능인 것처럼 비판 없이 추켜세움
     * 최근 AGI, AI 용어 사용이 특히 과학 논문에서 너무 모호하게 느껴짐. 최소한 논문마다 자신만의 정의라도 명확히 했으면 좋겠다고 생각함. AGI가 뭔지 정의를 명확히 하면, 특정 AI가 그 정의를 충족한다고 논리적으로 증명도 할 수 있음. 실질적인 쓸모가 없어 보일지라도, 의미 없는 용어보단 훨씬 나음. 현재는 AGI 정의 없이 도망치듯 쓰는 느낌임. ""인간과 동등/넘어서는 거의 모든 인지 과제""라고 위키에 나오는데, 측정은 불가능함. 이런 속 빈 용어를 왜 쓸까 하는 고민
          + 모두가 같은 의미로 쓸 필요도 없음. AGI라는 단어에 자신만의 기준을 갖고 있으면 됨(다수가 동의하지 않아도 됨). crypto도 원래 내겐 cryptography임. 주류와 내 개인 기준이 다를 수 있음
          + AI에 정의가 있다면 ""아직 실현되지 않은 걸 AI라 부른다""는 AI effect 설명 링크
     * 최근 회사에서 LLM 활용 시작. 첫 업무는 2만 통 고객 상담 콜 전사 및 데이터 추출(비교 제품, 문제점, 대표적 사용 사례 등). 예전엔 몇 주 걸릴 리서치가 몇 시간 만에 끝남. 새로운 비즈니스 전략까지 세웠고, 실제로 큰 가치를 얻음. LLM은 자연어 처리 엔진으로 매우 뛰어남. 과장된 홍보도 많지만 실제 우리에겐 실질적으로 도움이 됨. 단순 도구일 뿐, 누군가에게 증명할 필요를 못 느끼겠음
          + 과대 홍보가 마냥 무해하지 않다고 생각함. 시장 왜곡, 과도 투자, 조직 축소, 현실불가능한 기대 등 부정적 파장도 초래함. 이런 기사들이 시장/기대 식히는 데 필요함. LLM을 파는 사람들은 보통 상담 콜 요약이 아니라 인원을 대체할 온갖 과장된 시나리오를 말함
          + 데이터 대량 처리, 신뢰도 있는 방식으로 해결하는 경험 없는 사람만이 LLM에 쓸모가 없다고 말하는 듯. 이제 번역도 훨씬 컨텍스트 있게 처리 가능
     * 신뢰할 만한 테크 업계 인사들도 GenAI가 개발 생산성에 큰 도움을 준다고 직접 얘기함. 의미가 5%~100%라는 식으로 넓음. 최소한 상당히 유용한 도구로 받아들여야 한다고 생각함. 이런 주장을 위해 구체적인 숫자(코드 라인, 바이트, CPU 등)는 필요 없다고 봄
          + ""사람들이 임의로 정한 숫자로 생산성 향상을 주장하는 걸 무비판적으로 믿으라는 얘기""라며 비꼬는 의견
     * LLM 기술도 결국 올바르게 쓰일 곳이 있겠지만, 이미 너무 많은 사람들이 오용하기 때문에 이제 되돌릴 수 없음. 수많은 초급 개발자가 위험을 감수하다 실패하고, 수많은 투자가 낭비될 듯함. 기업들도 포기하지 못하고 전부 올인한 상황임
"
"https://news.hada.io/topic?id=21953","위성 충돌 방지 프로그램 폐지를 제안하는 NOAA 예산안","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    위성 충돌 방지 프로그램 폐지를 제안하는 NOAA 예산안

     * 미국 NOAA가 위성 충돌을 예방하는 중요 프로그램의 예산 폐지를 제안함
     * 이 프로그램은 인공위성 및 우주 쓰레기의 충돌로 인한 피해를 줄이기 위해 운영됨
     * 예산 중단 시 위성 산업 및 우주 안전에 큰 영향이 발생할 가능성 있음
     * 업계 및 전문가들은 프로그램 존속의 중요성을 강조함
     * 예산 문제로 혁신 및 글로벌 협력에 제약 우려가 제기됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

NOAA의 위성 충돌 방지 프로그램 예산 폐지 제안 배경

     * 미국 정부 기관 NOAA(National Oceanic and Atmospheric Administration)는 위성끼리의 충돌을 사전에 방지하기 위한 안전 프로그램 예산 삭감을 제안함
     * 해당 프로그램은 위성 위치와 궤도 데이터를 추적하고, 충돌 가능성이 있는 경우 운영자에게 경고하는 역할을 수행함

프로그램의 중요성 및 예상 영향

     * 이 프로그램은 우주 상의 인공위성, 위성 운영사, 통신 장치의 보호 측면에서 매우 중요한 기능을 담당함
     * 최근 우주 쓰레기 및 위성 수 증가 현상으로 인해 충돌 위험성이 꾸준히 높아지는 추세임
     * 예산 폐지가 현실화될 경우, 위성 운영사의 위험 관리 역량 약화와 산업 전반의 안전성 저하가 발생할 것으로 예상됨

업계와 전문가 의견

     * 우주 산업 관계자 및 다양한 전문가들은 정부 주도의 데이터 제공과 경고 시스템의 필요성을 강조함
     * 미국은 글로벌 우주 활동 허브로서, 이 프로그램이 국제 협력과 직접적으로 연계된다고 평가됨
     * 예산 삭감 시 혁신 저하 및 글로벌 파트너십 약화 문제가 함께 우려됨

결론

     * NOAA의 이번 예산안은 단순한 비용 문제가 아니라 미래 우주 인프라와 산업 혁신 전반에 영향을 미치는 사안임
     * 다양한 이해관계자들은 지속적이고 안정적인 운영의 중요성을 지속적으로 제기 중임

        Hacker News 의견

     * 정부 지출을 줄이려는 욕구는 이해함, 하지만 이런 프로그램은 지출 대비 높은 가치를 가지는 자산임, 무의미한 낭비가 아님, 1차, 2차, 3차 효과 모두 매우 큼, 예산 평가는 더 합리적인 원칙으로 돌아가야 함을 주장함
          + 국가 부채가 이미 천문학적인 상황에서 지출을 줄이겠다는 논의는 그 자체로 불가능함, 이는 민영화와 연방 기관 해체로 이어지면서 문화와 사회적 붕괴까지 초래할 수 있음, 미국을 망가뜨리고 기술 관료들이 이득을 챙기는 구조임, 시민이나 사회에 긍정적인 효과는 전혀 없음, Microsoft의 다 잡아먹는 전략이 정치적으로 재현된다는 생각임, 극단적 민영화, 파괴적 변화임
          + 누군가는 이런 공공 프로그램을 민영화해 보험료로 충돌 방지 서비스 비용을 부담하게 만들 것을 제안할 것 같음, 그러나 민영화는 필수 요소를 배제시켜 결국 치명적 실패와 추적 불가한 우주 쓰레기 증가, 수습 불가능한 파산으로 연결됨, 이미 다른 부문에서도 관찰되는 현상임
          + 여러 국가에서 관련 전문가로 일한 경험이 있음, 최근 궤도 환경이 급격히 변했고, 단순히 물체 숫자만의 문제가 아님, 기존 궤도 교통 시스템의 설계 한계를 벗어난 변화로 인해 효과가 떨어지고 있음, 주요 국가들은 첨단(기밀) 기술로 현대 환경에 대응하는 새로운 시스템에 투자함, 즉, 공공 시스템은 기술적으로 미래가 없고, 기밀 유출 위험 때문에 보강하지도 못하는 상황임, 결국 민간 분야가 불가피한 탈출구가 되고 있음, 우주 환경이 더 이상 단순하지 않고 매우 복잡해진 상황임
          + 이 이슈는 정부 지출 절감이 진짜 동기가 아님이 분명함, 진짜 문제는 NOAA가 일부 사람들이 불편해하는 기후변화 이야기를 물러서지 않고 한다는 것임, 그래서 메신저와 그 도구를 공격하는 것임
          + 아무도 정부 지출 자체에 신경 쓰는 척 그만해야 함, 구체적으로 어디에 돈을 쓰는지 제대로 얘기하는 게 중요함, 막연한 “지출 삭감” 논의는 논점을 흐리는 헛수고임
     * 그래서 점점 더 이런 역할을 UN으로 넘겨야 한다고 생각하게 됨, 각국이나 민간이 아니라 전 인류의 공동 자산이므로 세계적 지원이 따라야 함, 한 국가의 실패가 전 인류 전체를 망치지 않도록 해야 함, 날씨 예측과 위성 추적을 위한 UN 프로그램, 오픈 데이터와 REST API까지 구현되면 획기적인 전환이 될 것임, 다만 현재 구조는 안보리 상임국들의 이해관계 때문에 불가능함, 현실적으로 EU가 먼저 이런 역할을 할 가능성이 높음
          + 2000년대에 거의 비슷한 이유로 UN에서 근무해 본 경험이 있음, 대중의 UN 인식은 순진함, 실상은 매우 비효율적이고 부패·경직된 조직임, 안보리 이슈와는 상관 없음, 평범한 각국 공조 정부 수준이고, 실질적으로 이런 프로젝트를 이끌 데이터 인프라와 기술력이 없음, REST API 언급했지만 데이터 규모가 엑사바이트라 단일 복사본밖에 현실적으로 안 됨, 대다수 국가는 데이터 국내 보관을 원해 실제 분산된 데이터 결합이 불가능함, 네트워크 대역폭과 비용 문제로 데이터 접근을 심각하게 제한하게 되어 사실상 공개 데이터가 될 수 없음, 여러 번 직접 이런 프로젝트를 시도해봤지만 성공 가능성 제로라고 봄, 위대한 비전과 용기, 기술 전문성이 있는 솔로 리더가 있지 않는 한 관료 위주의 조직으론 불가능함
          + 현실적으로 UN 예산 대부분이 미국에서 나오고, 미국이 자금 삭감하면 즉시 전체 프로젝트가 휘청임, 장기적 예산 확보가 불가능함
          + 글로벌 수요엔 글로벌 지원이 필요하다는 주장에 동의하지만, UN에 모든 걸 맡기면 오히려 UN이 또 다른 헤게모니가 될 가능성이 높음, 다행히도 현 시점에서는 여러 초강대국 체제의 균형이 필요하다고 봄, 미·소처럼 간접적 경쟁으로 제한되길 희망함
          + 국제 협력이 있긴 하지만, 각국은 실제로 자체 위성 추적 프로그램이 반드시 필요함, TraCSS, SST, RSSS 같은 다양한 시스템이 존재함, 미국이 모든 걸 관리한다고 보기 어렵고, 작은 국가의 큐브샛이 러시아 군사 위성과 충돌해도 “아, 실수네~”라고 넘어갈 수 있음
     * ICE 예산을 없애고 대신 그 돈으로 위성 충돌 방지에 사용하자는 아이디어임
          + H1B 수수료를 3만 달러, 쿼터를 300만으로 대폭 늘리고 그 돈을 써서 위성 충돌 방지에 투입하자는 의견임
          + 위성을 ICE에 충돌시켜버리자는 유머 섞인 제안임
     * 우주 쓰레기와 위성 추적 이슈는 소유 국가와 회사가 직접 책임지고 자금을 부담하는 게 당연하다고 생각함, 이렇게 하면 Starlink가 제일 많은 비용을 내게 될 듯함, 그런데 군사 목적의 스파이 위성 등 실제로는 추적하기 꺼리는 위성도 많으니 NOAA 데이터에 그런 것들이 포함되는지 궁금함
          + Starlink가 비용을 많이 내는 구조면 자연스럽게 이용자 요금제로 전환될 것임, 오히려 수익까지 내서 재정 적자도 줄일 수 있겠지만, 실제로 이런 구조로 운영되지 않음, 여기에 진짜 관심은 없다는 얘기임
          + Starlink 모든 위성은 책임있게 자연탈출(디오르비트) 계획이 있고, LEO라 몇 년 이내에 자연적으로 다 떨어짐, Starlink는 우주 쓰레기 쌓일 구조가 아님
          + 이전에도 주장했지만 비판받았던 관점임, 예를 들어 이란 같은 국가가 Starlink 위성에 직접 파괴를 가해서 우주 쓰레기 연쇄 충돌을 일으켜 경쟁자 모두를 손해 보게 할 수도 있는지 궁금함, “내가 못 가지면 남도 못 가져야 한다”는 식의 위험한 사고임
     * 다음엔 노동안전청(OSHA)도 없애자는 건지 궁금함, 안전을 우습게 여기는 근시안적 테크 업계 사람들의 단적인 시각이라고 봄
     * 이런 조치가 왜 좋은 아이디어인지 듣고 싶음
     * 장기적 관점의 모든 대책이 이제 무의미해진 시대라고 느끼고 있음
     * 위성 충돌 사태가 명백하게 기후변화 연구 위성을 겨냥한 게 아닌지 의심됨, SharpieGate 사태와 오렌지 황제가 NOAA에 기후과학 부정론자를 앉힌 일도 있었음(링크), 결국 돈벌이를 위한 구조적 방해라고 생각함
          + 지난 첫 행정부 시절 NASA 국장으로 평평한 지구론자를 지명하지 않은 것만도 반쯤 놀라움
     * 불편한 사실을 지적하자면, 연방정부가 사회보장, 메디케어·메디케이드, 국방, 이자 지급, 소득 보장, 재향군인 지원, 연금·장애 지원 외엔 아무것도 안 해도 이미 적자 규모는 매우 큼, 과학, 교육, FDA, 주택, 해외 원조, 재난 구호 예산은 적자 문제에 큰 비중이 아님
          + 이자 지출이 이제 전체 예산의 16%를 넘었고 계속 증가 중임, 36조 달러로 산 모든 게 그만한 가치가 있었는지 의문임
          + 적자 축소 목적이란 건 사실 논점 흐리기임, 실제로는 트릴리언 단위로 적자가 더 커지고 있으며 NOAA가 일부 세력의 기후 담론을 흔드는 게 핵심 동기임
          + 이들은 오히려 적자를 더 키우고 있으니 부채 타령은 더 이상 반복하지 말자는 주장임
"
"https://news.hada.io/topic?id=21852","CGI-bin으로 하루 2억 건 요청 처리하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       CGI-bin으로 하루 2억 건 요청 처리하기

     * CGI 프로그래밍으로도 하루에 2억 건 이상의 웹 요청 처리가 가능함
     * 최근 하드웨어 성능 향상으로 CGI 방식의 단점이 크게 줄어듦
     * Go와 SQLite를 활용한 CGI 프로그램이 16스레드 CPU에서 탁월한 성능을 보여줌
     * CGI는 여러 CPU 코어 활용에 특히 적합한 구조 제공
     * 현대 기술로 인해 과거의 웹 애플리케이션 개발 방식도 충분히 실용 가능성 보임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

CGI의 과거와 현재

     * 1990년대 후반, 필자는 CGI로 웹 개발을 시작하였으며 당시에는 NewsPro와 같은 시스템을 사용함
     * CGI는 웹 요청마다 새로운 프로세스 실행 및 종료를 반복하여 높은 오버헤드 발생함
     * 이런 이유로, 더 효율적인 PHP, FastCGI 등 대체 기술이 개발됨

하드웨어 성능 발전

     * 지난 20여 년 동안 컴퓨터 속도와 성능이 급격히 증가함
     * 2020년에 필자는 Go와 Rust로 개발된 툴(ripgrep 등)을 활용하며, 프로세스 실행 방식의 실용성을 재발견함

현대적 CGI 방식의 장점

     * Go와 Rust 같이 실행 속도가 빠른 언어로 CGI를 구현하면, 구식 CGI의 단점 대부분이 해소됨
     * CGI 프로그램은 요청당 별도 프로세스로 동작함으로써 멀티코어 CPU 활용에 최적화됨
          + 예를 들어, 16스레드 환경에서는 2400건 이상의 요청/초 = 2억+ 요청/일 처리 가능성 확인됨
          + 대형 서버는 384개 이상의 CPU 스레드 제공 가능

개발 문화에 대한 인사이트

     * 현재 Go, Rust와 같은 언어의 도입으로 1990년대 CGI 방식이 다시 의미를 가질 수 있음
     * 다만, 여전히 모든 환경에 적합한 방식은 아니며 주류 방식으로 권장하지는 않음
     * 중요한 점은 현 시점에서는 CGI가 예전만큼 비효율적인 솔루션이 아님을 실험적으로 증명함

결론

     * 현대 하드웨어와 신속한 언어 지원을 통해 CGI 프로그래밍이 과거와는 비교할 수 없는 성능을 보임
     * 멀티프로세스의 장점을 최대한 활용할 수 있는 사례로, 웹 개발자에게 흥미로운 시사점을 제공함

        Hacker News 의견

     * 요즘 Python이라도 CGI는 꽤 빠른 성능 체감
       만약 CGI 스크립트가 시작에 CPU로 400밀리초를 쓴다고 해도, 서버에 64코어가 있으면 초당 160개의 요청 처리, 1일에 서버당 1,400만 트래픽 소화 가능
       억대 단위 하루 트래픽(정적 자산 제외)도 CGI 프로세스 스타트업이 병목은 아니라는 것
       예전엔 이런 기술은 ""지루할 만큼 안정적인 기술""이라서 Python 표준 라이브러리에 항상 있던 것이라 생각했는데, 요즘 Python 유지보수자는 오히려 안정성과 후방호환에 부정적 입장
       그래서 너무 '지루하고 안정적인' 모듈들은 표준 라이브러리에서 제거 중, 실제로 cgi 모듈은 3.13 버전에서 삭제
       25년 가까이 Python을 프로토타이핑에 써온 습관 때문이지만 이제는 후회
       JS랑 Lua 중에서 갈등하는 중인 심정
          + cgi 제거 관련 공식 설명 링크는 PEP 594 cgi
            이 링크에서 2000년(25년 전) 작성된 PEP 206 으로 이어지는데, 이미 그때도 ""cgi 패키지는 설계가 별로고 손대기도 어렵다""고 설명
            jackrosenthal/legacy-cgi 저장소에서 표준 라이브러리 모듈을 그대로 대체해주는 drop-in replacement 확인
          + Python 개발자들이 cgi라는 이름의 모듈만 뺀 것
            CGI 스크립트 구현은 여전히 http.server 모듈의 CGIHTTPRequestHandler에서 지원
            원래 cgi 모듈엔 HTML 폼 데이터 파싱하는 함수 몇 개만 있었던 점 짚어줌
          + Python에서 cgi 모듈이 표준 라이브러리에서 빠지는 걸 비판하는 건 이해하지만, 대체로 손꼽는다는 JS는 아예 표준 라이브러리가 아님
            Lua도 stdlib에 CGI 모듈 없는 점 지적
          + 개인적으로는 PHP나 JS를 선호
            이런 경우에는 박스 안에 JIT가 기본 제공되니 편의성
            Python 1.6부터 써오면서 주로 OS 스크립팅에만 사용
            예전엔 Tcl을 Apache나 IIS 모듈로 연동하며 계속 C로 모듈을 다시 쓰는 반복이 있었던 경험이 있음(1999~2003년)
          + CGI 스크립트가 400밀리초 CPU 사용한다면, 해당 엔드포인트의 응답 속도도 최소 그만큼 되어버리니 사용성 타격
     * 최근 350달러짜리 미니 서버에 golang 바이너리, rabbitmq, redis, MySQL을 올려서, 같은 서버에서 5,000 req/s 지속적으로 처리
       24시간이면 4억 요청 처리 성능
       요즘 무료 도구들은 정말 훌륭함을 체감
       그럼에도 클라우드 비용은 너무 높다는 생각
       물론 1:1 비교는 어렵지만, 개발과 튜닝을 집 지하실 서버에서 직접 할 수 있었던 만족감이 큼
          + 쿠버네티스 기반 마이크로서비스 덩어리를 쓰면서 개발 속도가 10배 느려지는 경우도 존재
            서버라는 게 1초에 1요청만 처리하는 기계가 아니라는 사실 모르는 경우가 많음
            구글이 하니까 따라간다는 이유만으로 과도한 오버헤드를 지불하는 현실
            나 역시 우리 팀에 잘 먹히는 '모듈러 모놀리식' 아키텍처 관련 글을 써야겠다는 생각
          + 사이드 프로젝트를 집에서 직접 호스팅하려 했지만, 전원 장애, ISP 다운타임, 원격 접근 불가, 하드 드라이브 고장 등 리스크 큼
            결국 내 시간까지 고려하면 경제적 이득 애매
            클라우드 서비스는 규모의 경제 덕을 볼 수 있어서 실제로는 합리적인 선택
          + 굳이 클라우드 말고 호스팅 프로바이더에서 전용 서버 임대도 가능
            물론 대역폭/트래픽 제한 존재
            클라우드가 주류인 이유는 VC, 투자자가 해당 기업의 지분을 갖고 있거나, ""무한 트래픽이 터질지 모른다""는 불안감 때문
            클라우드 영업 전문가들은 투자자의 불안을 교묘히 파고듦
          + 꼭 클라우드만 쓰는 건 아님
          + 실제 서비스에서 VM 비용 높은 이유는 고성능 컴퓨트 때문이 아니라, 엄청난 용량의 로컬 디스크가 필요해서임
            계산 능력이 높을 필요는 없고, 20TB짜리 하드 4개와 적당한 CPU만 있어도 대단한 서비스 구상 가능
            클라우드에선 이런 조합 찾기 거의 불가능
     * cgi-bin에서 DB에 접근이 필요한 경우, 매번 프로세스가 DB 커넥션을 새로 생성하는 불편
       메모리 내에서 코드가 동작(fastcgi 등)한다면 단순히 스타트업 시간만 줄이는 게 아니라, DB 커넥션 풀 혹은 스레드당 영구적인 커넥션 유지 가능
          + 대규모로 돌리면 DB 커넥션 수가 너무 많아져서 DB가 힘들어지는 현상
            ""python은 싱글스레드라 여러 프로세스, python이 느리니 더 많은 프로세스""라는 이유로 다수 프로세스 운영
            결국엔 python 프로세스 외부에서 shared connection pool(pg bouncer 등)로 분리하고, 다양한 튜닝이 필요
            마지막엔 다스리는 언어(멀티스레드 지원에 성능 더 좋은 언어)로 다시 구현해서 훨씬 단순해졌던 경험
          + 그래서 결국 CGI가 요청 간 정보를 남기는 모델(fastcgi 등)로 발전
          + 전통적으로는 독립 데몬을 띄워서 프록시 역할하게 하기도 했고, 연결도 Unix 소켓을 쓰면 TCP/IP보다 훨씬 효율적
          + UDP 쓰라는 의견
     * 나에게 inetd는 바로 CGI 그 자체
       그 덕에 인터넷이 훨씬 재밌어졌다는 인상
       직접 inetd로 여러 셸 스크립트, 심지어 Bash로만 쓴 HTTP도 돌아갔던 시절
       오래된 VPS, 백업이나 버전 컨트롤 안 했던 랩탑 등은 사라졌지만 재미 있었던 추억
       배포도 Makefile + scp로 단순했고, 테스트도 netcat과 grep으로 작성한 Bash 스크립트로 가능
       정말 살기 좋은 시대 체감
     * hello world 앱을 2400 rps(초당 요청 처리량) 달성한 것이 현재 하드웨어 기준으로 별로라는 인상
       코드가 더 간단해진 것도 아닌데, 대체 뭘 위해 성능을 희생하는지 의문
          + 2000 rps 넘게 처리할 필요 없다면 문제될 게 없음
            그런 트래픽이 필요한 사이트는 아주 소수라는 논지
          + 숫자상으론 높지 않지만, 실제로는 많은 환경에 충분
            HN 개발자들이 이야기하는 '허그 오브 데스'(특정 순간 유입 폭증)도 견딜 수 있을 수준
     * 우리 회사에서는 아직까지도 cgi-bin 디렉터리로 간단한 내부용 웹앱 빠르게 띄우는 방식 사용
       간단하게 쓰면 개발 효율이 매우 좋음
       cgi라도 http/1.0을 직접 print하지 않아도 되고, Python의 wsgiref.handlers.CGIHandler를 사용해서 어떤 wsgi 앱이든 cgi 스크립트로 실행 가능
       Flask 예시 코드도 아래와 같이 간단함
 import wsgiref.handlers, flask
 app = flask.Flask(__name__)
 wsgiref.handlers.CGIHandler().run(app)

       실무에서는 uwsgi의 cgi 플러그인으로 스크립트 실행
       Apache나 lighttpd에서 mod_cgi 돌리느니 훨씬 간단하고 유연성 높다는 느낌
       uwsgi는 시스템 단위로 실행되니까 systemd의 하드닝과 샌드박싱 다 쓸 수 있다는 점도 장점
       또, uwsgi의 cgi 핸들링에서는 각 파일 타입마다 인터프리터 지정 가능
 cgi = /cgi-bin=/webapps/cgi-bin/src
 cgi-allowed-ext = .py
 cgi-helper = .py=/webapps/cgi-bin/venv/bin/python3 # all dependencies go here

       최초 바이트 전송까지 250~350ms, 우리 용도에는 충분히 허용범위
       uwsgi cgi 관련 문서
          + 좋은 팁 공유
            wsgiref.handlers.CGIHandler가 아직 deprecated 안 된 점, 정보 유용함
     * 어제 논의된 관련 스레드 링크
     * 최근 Apache를 사이드 프로젝트에 쓸 때 .htaccess 기능이 유용해서 썼던 경험
       어느 디렉터리든 .htaccess파일만 놓으면 개별 요청시마다 추가 서버 설정 로드
       htaccess 공식문서
       예전엔 매 요청마다 디스크 접근하는 오버헤드 때문에 성능상 .htaccess를 피하는 게 좋았고, 가급적 메인 설정에 통합하라고 했음
       하지만 요즘은 SSD와 램도 충분하기 때문에, 물론 성능이 아주 약간 손해보긴 하지만, CPU가 웬만큼 좋아져서 대다수는 무시해도 되는 수준
       [내 프로젝트 StaticPatch][https://github.com/StaticPatch/StaticPatch/tree/main]도 이미 적용해 사용 중
          + PHP 창시자 Rasmus Lerdorf의 명언
            ""나는 진짜 프로그래머가 아니고, 그냥 돌아가게 만들고 넘어간다. 진짜 프로그래머는 '메모리 누수 심하니까 고쳐야 한다'고 한다. 나는 10번마다 apache를 재시작할 뿐""
            PHP는 그 이후 긴 여정을 거쳐서, 초기 실수 극복하며 크게 발전
            ""PHP 8은 내 코드가 적을수록 더 좋아진다""는 말도 남겼다는 일화
          + Apache가 파일 시스템을 감시해서 바뀔 때마다만 읽도록 하면 될 텐데, 왜 매 요청마다 불필요한 디스크 접근을 하게 만드는지 이해불가
            그 결과 99.99%의 http 요청이 느려진다는 점 지적
     * 최근 워크플로우에서 빠른 프로토타이핑에 이런 구조 고민
       JIT 언어들은 fastcgi 형태가 아니면 import가 병목
       직접 썼던 h2o 웹서버는 mruby와 fast-cgi 핸들러 설정 파일이 간단해서 지역 스크립트 작업에 딱
       h2o fastcgi 문서
       또 하나 장점은, 고객이 직접 커스텀 코드를 추가할 수 있도록 로컬 소프트웨어를 확장하게 할 때도 쓰임
       예를 들어 기존엔 확장 위해 MCP를 썼어야 했지만, 이제는 CGI로 구조화된 요청만 구현하면 끝
          + 엔드유저 환경으로 쓸 때 MCP 프론트로 CGI 프로그램 연결도 생각해볼 만한 아이디어
            MCP 서비스도 충분히 CGI로 구현 가능성
            스펙을 더 살펴볼 필요성 느끼는 중
          + fastcgi는 cgi가 가진 장점 거의 다 사라진다는 의문
     * 예전에 C 프로그램과 CGI 조합 직접 사용
       당시에는 100개 넘는 코어나 충분한 램 없었고, 최대 1GB 정도 메모리로도 동작
       그때 가능했던 걸 생각하면, 요즘은 훨씬 쉬울 거라는 확신
          + 1995년 Amazon은 C++ 실행파일을 CGI 방식으로 사용
            부하분산이 필요해진 이후에는 확장에 어려움 있었지만, 그 전까지는 꽤 잘 동작했던 사례
            참고로 프론트와 백오피스 서로 따로 실행파일 2개였음
"
"https://news.hada.io/topic?id=21963","화면은 어떻게 동작하는가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             화면은 어떻게 동작하는가

     * 화면은 전자 신호를 이미지로 변환함
     * 픽셀 단위로 구성되어 있어 색상 정보와 밝기 정보를 표시함
     * 디스플레이 기술에는 CRT와 LCD, OLED 등의 다양한 종류가 존재함
     * 각각의 기술은 광원 방식 및 픽셀 제어 원리에서 차이를 가짐
     * 디지털 신호를 아날로그로 변환하여 시각적 정보를 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

화면의 동작 원리

     * 화면은 전자 신호를 받아 시각적 이미지로 변환함
     * 디스플레이는 수천에서 수백만 개의 픽셀로 이뤄져 있으며, 각 픽셀이 RGB(빨강, 초록, 파랑) 조합으로 다양한 색상을 표현함
     * 과거 CRT는 전자총을 이용해 인광물질을 자극하는 방식으로 이미지를 보여줌
     * LCD와 OLED와 같은 최신 디스플레이는 각각 액정 분자와 자발광 픽셀을 활용함
     * LCD는 백라이트가 필요하며, OLED는 각각의 픽셀이 스스로 빛을 냄

픽셀과 신호 처리

     * 이미지는 화면의 좌표(행, 열)마다 픽셀 신호가 전달됨
     * 픽셀은 입력된 디지털 신호에 따라 색상과 밝기를 결정함
     * 컴퓨터나 스마트폰 내부의 그래픽 칩셋에서 화면 포맷에 맞게 신호를 생성함

디스플레이 종류와 차이점

     * CRT: 큰 부피와 높은 소비 전력을 가지지만, 응답 속도가 빠름
     * LCD: 얇은 형태와 낮은 전력 소모가 강점, 광원과 필터를 사용함
     * OLED: 더 얇고, 고명암비를 구현할 수 있음. 각 픽셀이 직접 빛을 냄

요약

     * 화면은 복잡한 신호 변환 과정과 픽셀 제어 기술로 이미지를 구현함
     * 다양한 디스플레이 방식에 따라 구현 원리, 장단점이 다름
     * 모든 과정은 최종적으로 전자 신호를 시각적 정보로 보여주는 데 목적이 있음

        Hacker News 의견

     * 이 글에는 기술적으로 애매하게 넘어갈 수 있는 문장들이 있지만, 엄밀히 말해 맞지 않아 잘못된 이해를 유발할 것 같음

     ""현대 디스플레이는 이미지를 라인별로 그리지 않는다 (...) 모든 픽셀이 동시에 켜지며, 전체 디스플레이가 한 번에 리프레시된다”라고 했지만, 실제로는 여전히 대부분의 LCD와 OLED가 위에서 아래로, 왼쪽에서 오른쪽으로 라인 단위로 스캐닝 리프레시가 이루어짐
     이것은 글로벌 리프레시가 아니라 스캐닝 리프레시임
     보통 60Hz 주사율의 스마트폰을 슬로모션으로 촬영하면, 카메라 역시 스캐닝 방식(롤링 셔터)이라 실험에 영향을 주지 않으며, 화면이 실제로 위에서 아래로 새로고침되는 모습을 볼 수 있음
     실제 리프레시 방향은 디스플레이마다 다르지만, 일반적인 데스크탑 모니터의 경우를 말함
          + IPS(PLS)와 VA가 예전 TN과 어떻게 다른지 언급해준 부분은 반가웠음
            그러나 역시 LCD와 OLED 모두 대략 라인 단위로(예: OLED는 GIP에서 내부 트랜지스터 옵셋 전압을 보정하는 데 5 클럭 정도 사용) 셀의 저장 전압을 갱신함
            개인적으로 OLED의 'circular polarizer'에 대한 언급이 없었던 점이 아쉬웠음
            Quantum Dot OLED에서 컬러 필터로 이동하고 있지만, mobile OLED 기기에서 블랙이 강렬하게 구현되는 이유는 circular polarizer 때문임
            또한 모바일 OLED의 주류인 'pentile RGGB' 서브픽셀 패턴도 언급되지 않았음(이게 50% 이상의 기기에서 사용됨)
            최근엔 밝기 향상과 전류 밀도 감소를 위해 'tandem' 스택형 OLED로 진화하지만 평면-쇄기형(lateral) 서브픽셀 패턴은 아님
          + 액티브 매트릭스(그리고 패시브 매트릭스) 디스플레이에서의 큰 특징은, m x n 디스플레이에서 단지 m+n 신호 라인만 있으면 픽셀에 접근 가능함
            특정 픽셀의 색상을 바꿀 때 그 픽셀 행과 열에 해당하는 라인으로 신호가 나가서 선택되고, 또 다른 라인으로 실제 값이 전달됨
            이런 구조라면 모든 픽셀을 한 번에 제어하는 것은 불가능하며, 오히려 그렇게 할 경우 수백만 개의 제어선이 필요해짐
     * 처음에 소개한 다이어그램 자체도 충분하고 명쾌했음
       이미지 줌인/줌아웃할 때 나는 '뽁'-'삑' 소리도 뽁뽁이 장난감을 만지는 것처럼 재미있었음
       오른쪽에 있는 눈금자에 소리까지 더해져 있음
       정말 멋진 페이지라고 생각함
       그리고 랜딩 페이지 https://www.makingsoftware.com/도 계속해서 새로운 것을 줌
          + 정말 깔끔하게 완성된 결과물임
            Dan이 전 학년의 과학/수학 교과서를 집필한다면, 학업에 어려움을 겪는 학생들에게 더 좋은 세상이 될 것이라고 느꼈음
          + 매우 재능 있는 커뮤니케이터임
            Bartosz Ciechanowski의 훌륭한 작업이 떠오름
            https://ciechanow.ski/archives/
          + 나도 축하와 감사를 덧붙이고 싶음
            준전문가도 쉽게 이해할 수 있는 명확한 그래픽과 설명이 강력한 교육적 플랫폼임
          + 정말 멋진 프로젝트라고 생각함
            저자의 성공을 기원함
            아주 오랜만에 뉴스레터에 구독신청함
     * CRT 디스플레이는 정말 아날로그 기술 중에서도 디지털 후속기기보다 훨씬 멋진 존재였음
       모니터 안에 리얼 레이건, 즉 입자 가속기가 들어 있어 내가 보는 이미지를 만듦
          + 90년대에 액티브 매트릭스 평면 패널이 등장했을 때도 엄청난 기술처럼 느껴졌음
            각 픽셀마다 트랜지스터와 커패시터가 직접 픽셀 상태를 유지하는 방식은 제조 공정 자체가 마술처럼 여겨졌음
            한때 LCD에서는 데드픽셀이 큰 문제였지만, 벌써 20년 넘게 그런 문제를 거의 기억하지 않고 있음
     * CRT는 아직도 약간 마법과 같은 기기임
       이미지가 실제로 존재하는 것이 아니라 완전한 착시임
       인간의 눈이 전자 속도로 작동한다면, 엄청나게 밝은 점이 끊임없이 래스터 패턴을 그리고 있는 모습을 볼 수 있음
       ""The Slow Mo Guys"" 유튜브 영상에서 실제로 이 모습을 볼 수 있음
       https://youtu.be/3BJU2drrtCM?t=190
          + 그 슬로모 영상은 약간 오해를 불러일으킬 수 있음
            실제로는 CRT의 형광체가 한동안 빛을 발하기 때문에 이미지의 상당 부분이 항상 눈에 보임
            해당 영상이 너무 밝은 부분에 노출을 맞춰서 나머지가 어둡게 나온 것이 문제임
          + 픽셀이나 형광체는 어느 정도 지속성이 있어 완전한 착시라고 하기는 어려움
            결국 인간의 시각이 프레임 단위로 이미지를 통합해 인식함
            여기에 인터레이싱 방식도 있음
            최근 읽은 흥미로운 내용은 나이가 들수록 ‘통합 프레임 속도’가 낮아진다는 것이었는데, 사실인지는 잘 모르겠음
          + TV가 처음 나왔을 때 TV와 카메라의 스캔 빔이 전국적으로 완벽하게 동기화되어 있다는 사실을 알게 되었을 때 정말 멋지다고 느꼈음
            카메라가 내 TV를 직접 제어한다는 느낌이 들었음
          + 개인적으로 CRT에서 가장 신기한 부분은 컬러 구현임
            섀도우 마스크의 구조가 아직도 제대로 이해되지 않음
            세 개의 전자총 각각에 맞춘 구멍들이 있고, 각 전자총에서 나오는 빔이 어떻게든 그에 딱 맞는 형광체 점만 때림
            게다가 빔이 코일에 의해 굴절되어도 세 전자총의 빔이 서로 영향을 받지 않는 것이 신기함
          + ""이건 착시다""라고 했지만, 사실 시각 자체도 본질적으로 착시임
     * CRT에서 ""픽셀""과 ""서브픽셀""이라는 용어를 사용하는 것에 이의를 제기함
       CRT는 실제로 '픽셀'이 아닌 '스캔라인'을 출력함
       각 라인은 아날로그 신호로 연속적으로 전압이 변하며 그 결과 해상도는 DAC의 성능과 CRT 내부 하드웨어에 따라 달라짐
       그리고 이 '픽셀'이라는 개념과 실제 형광체 점(컬러 도트) 간에 1:1 대응이 없음
       디지털 RGB 신호도 CRT 내에서는 엄밀히 디지털이 아님
       각 색상 채널마다 켜고 끄는 전압만 지정될 뿐, 완전히 ‘디지털’하게 동작하는 건 아님(인텐시티 핀이 따로 있기도 함)
       전자총도 순간적으로 무한정 빠르게 반응하지 않음
       진짜 대중적인 디지털 디스플레이는 LCD와 DVI, HDMI 시대에 들어와서야 가능했음
       아날로그 HD CRT마저도 이런 디지털 신호를 받아들일 수 있음
          + 예전에 LG 32인치 와이드 CRT TV를 쓴 적이 있음
            VGA 포트가 있어 그 모델을 골랐고, 640x480 해상도를 지원한다고 광고되어 있었음
            실제로 컴퓨터에서 848x480 해상도를 선택할 수 있었고, 완벽히 동작해서 매우 기뻤음
            그 당시엔 그 정도 해상도로도 웹을 충분히 쓸 수 있었음
     * 나는 처음에 이 글을 터미널 프로그램 'screen'(터미널 멀티플렉서) 관련 이야기인 줄 알았음
          + 나도 거의 50대 50으로 고민했음
            그런데 screen 소스 코드는 꽤 읽기 쉽고, 유닉스 코드 치고는 주석도 친절하게 달려 있었음
            함수 이름이 실제로 의미를 파악할 수 있게 되어 있음
          + 나도 마찬가지로 그렇게 읽었음
     * 내 책상에 실체 현미경이 있어서 Pixel 9을 100배 확대(10x 접안렌즈 x 10x 대물렌즈)로 관찰해 봤음
       머리를 살짝 움직이면 이미지는 내 망막 위에서 움직이고, 파란색이 더 빨리 움직이며 빨간색은 거의 그대로, 초록색은 그 사이쯤에 해당하는 움직임을 보여줌
     * LCD는 종이상으로 보면 여러 단점이 많지만, 실제로는 최신 TV용 LCD 기술이 꽤 훌륭한 수준임
       곧 RGB LED 백라이트에 WHVA+ 패널을 조합하면 IPS에 필적하는 광시야각, 95% 이상의 REC 2020 색역, 1-2ms 응답시간도 구현 가능해질 것임
       인광성 블루 OLED가 기존 OLED 디스플레이의 에너지 소모를 20~30% 줄여줄 것임
       그렇지만 이 기술이 휴대폰이나 대중기기에 대량 적용되려면 아직은 갈 길이 멀어 보임
          + 보통 기술이 점점 대체될 시기에 가장 성능이 좋아지는 경향이 있음
            진공관, CRT, 광디스크, 필름 등도 마찬가지였음
            오히려 새로운 세대의 초기 기술보다 기존 완성형 기술이 여러 면에서 더 뛰어난 경우도 있었음
            하지만 OLED는 실제로 중요한 부분에서 장점이 너무 많음
            훨씬 낮은 전력 소모, 백라이트가 필요 없어 더 얇고 가벼운 구조 등
          + 그런 혁신도 결국 LCD의 근본적 단점인 낮은 명암비와 상대적으로 높은 에너지 소모에는 크게 도움이 안 됨
            백라이트 방식의 구조적 한계로 인해 자가발광 디스플레이에 비해 이 점들이 항상 약점임
     * 돋보기를 LCD 위에 대고 관찰하면 서브픽셀 패턴을 직접 볼 수 있음
       수십 년 전에는 직접 LCD 컬러 필터를 생산하는 거대한 기계 연구에 참여한 적이 있음
          + 물방울 한 방울만 떨어뜨려도 같은 효과를 볼 수 있음
     * 그림이 정말 인상적으로 잘 그려져 있음
       어떤 툴을 썼는지 궁금해서 저자에게 이메일을 보냈지만 아직 답장을 못 받음
          + 메인페이지 FAQ를 참고하면
            ""그림은 Figma에서 직접 수작업으로 그립니다. 특별한 비법은 없고, 보이는 것만큼 복잡하게 작업합니다""라고 안내되어 있음
"
"https://news.hada.io/topic?id=21857","macOS 아이콘의 역사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             macOS 아이콘의 역사

     * macOS 26에서 Apple이 Liquid Glass라는 새로운 UI 콘셉트를 도입함
     * 기존의 견고한 소재 느낌 아이콘 대신, 더욱 부드럽고 광택 있는 유리 느낌의 아이콘 스타일을 채택함
     * 아이콘의 둥근 사각형 형태가 더욱 강조되었으며, 아이콘을 구성하는 요소가 더 이상 아이콘 경계 밖으로 확장될 수 없음
     * 기존 GarageBand, Photo Booth, Dictionary 등 몇몇 애플리케이션에서 볼 수 있던 아이콘 외측 확장 디자인이 제거됨

     * 이번 릴리스는 macOS 디자인의 가장 극적인 시각적 개편 중 하나이므로, macOS의 오랜 시간에 걸친 시스템 아이콘 디자인 변화를 기록 및 수집하는 컬렉션 제작을 시작
     * 앞으로도 지속적으로 추가 및 업데이트될 예정

     * 정식 출시 전의 베타 아이콘은 컬렉션에 포함하지 않음. 이유는 베타 기간 중 아이콘에 작은 디자인 변경이 가끔 일어나기 때문임

        Hacker News 의견

     * 자유로운 형태의 아이콘이 때로 정말 형편없는 디자인이 나올 수 있다는 점에는 동의하지만, 한때 Apple만의 차별화 포인트는 바로 고퀄리티 아이콘이었음에 주목함. Apple 기기를 겨냥한 소프트웨어 회사들까지 아이콘 디자인의 전통을 이어가곤 했던 기억, 그리고 단지 아이콘만 보고도 Mac 전용 소프트웨어인지 포팅된 건지 확실하게 알 수 있었던 시절을 회상. 그런데 요즘에는 모두가 모서리가 둥근 사각형 아이콘으로 통일되어버린 상황
          + 지금의 모서리 둥근 사각형 트렌드는 산업 전반에 퍼진 “모던리스트” 디자인 때문이라는 의견. Thuma 가구처럼 고가인데도 의미나 정체성 없이 평면적이고 특징 없는 디자인이 늘어났다는 지적, 혹은 광고 기반 드론 라이트쇼가 불꽃놀이의 생동감이나 독창성을 대신하는 현상을 예시로 듦. Apple도 이런 무미건조한 방향으로 전환 중이라는 아쉬움. Calculator 앱이 그 좋은 사례임을 강조. 아무것도 더할 것이 아니라 더 뺄 것이 없는 경지에 이르는 게 완벽이라는 말을 인용하지만, 너무 덜어내다보면 의미와 목적이 사라진다고 우려. 한 번 이런 변화를 인지하게 되면 일상에서 계속 보이게 될 현상임을 경고하는 친근한 조언
          + VisionOS의 경우에는 앱 내부에 3D 오브젝트가 가득하거나 산만한 경우가 많아서, UI 버튼의 위치를 시각적으로 구분하기 위해 일정한 버튼 형태(모서리 둥근 사각형)에 앱 아이콘을 넣도록 한 Apple의 UX 디자인 철학을 추측. 이렇게 하면 아무 모양이든 임의의 3D 오브젝트와 액션 버튼을 명확히 구별할 수 있다는 것. 과거 2D UI에서는 버튼을 더 입체적으로 만들어 두드러지게 했지만, 모두가 3D인 환경에서는 오히려 버튼이 덜 입체적으로 보여야 시각적 구분이 쉬움. “유리 효과” 디자인이 이런 2.5D 중간 단계를 제공한다고 봄
          + 아이콘의 고퀄리티함이 Apple만의 큰 매력이던 시절을 회상하며, 2007년 OS X에서 Photo Booth, Pages, Preview 등 앱 아이콘이 매우 아름다웠다는 감상. 아이콘만으로도 앱이 명확하게 구분됐던 점, 그리고 위트와 즐거움이 살아있었던 예시(Adium의 녹색 새 로고와 날개 짓 애니메이션)를 들며, 지금은 아이콘이 모두 비슷해진 점에 아쉬움
          + 모서리 둥근 사각형 버튼 형태 UI의 장점은 클릭 가능 영역이 예측 가능하다는 점. 현재 macOS에서는 아이콘 내 실제 채워진 영역만 클릭 가능해서, 각각 다른 모양의 아이콘은 클릭 영역이 제각각인 불편함이 있음
          + 최근 애플 아이콘이 예전보다 흐릿해졌다는 의견, 그리고 최종 아이콘을 고를 때도 종종 더 오래된 버전이 가장 마음에 들었음을 언급. 집단적 결정에서 오는 산만함을 꼬집으며, Jobs와 Ive가 사라진 뒤 이를 대신할 중심 인물이 필요하다고 강조
     * 2025년 버전 아이콘이 이전 버전들보다 더 보기 좋다고 평가하지만, 2014년 전후 버전이 가장 명확하고 알아보기 쉬웠던 것에는 동의. 점진적으로는 발전이지만, 역사적으로 봤을 때는 여전히 퇴보라고 봄
          + 최근 아이콘들을 보면 2024년 것을 떠올릴 정도로 기억에 남진 않았다는 솔직한 놀람
          + macOS/iOS 디자인 미학은 2013~2014년이 정점이었으며, 2012년 MacBook Pro도 최고의 하드웨어였다는 회상. 지금의 Apple은 시장 가치와 무관하게 예전만큼 감동을 줄 수 없는 회사라고 평가
          + 미니멀리즘과 스큐어모피즘 사이에서 균형을 잘 잡으려는 시도에 긍정적 평가. Photo Booth 아이콘의 경우 카메라 이미지를 버리고 포토부스의 스트립 이미지에 집중한 예시로, 작은 사이즈에서도 복잡하지 않게 보여질 수 있음. 이 절제된 방식이 세세함 수준과 명도, 대비 등에서 표준화된 디자인으로 이어지고 있다고 분석
          + Game Center 아이콘만은 확실히 퇴보라고 느끼며, 다른 앱은 트렌드에 맞춰 점진적으로 변한 반면 Game Center는 처음 버전 이후 의미를 상실했다고 평가. 네 개의 버블이 무엇을 의미하는지 맥락 없이는 알기 어렵다는 점을 지적
     * 웹사이트의 완성도가 뛰어나다는 칭찬. 아이콘에 관심이 많다면 본인이 만든 무료 Mac 스크린세이버 Iconic을 추천. Mac 역사에서 주목할 만한 아이콘들을 다루는 “Aqua Icons” 스크린세이버임을 소개
     * BasicAppleGuy에게 요청하고 싶은 점으로, XCode 해머 아이콘의 변천사를 보고 싶다는 의견. 원래 정통 망치였던 것이 이제는 Fisher-Price 장난감처럼 보인다는 유머러스한 아쉬움, 그리고 Color Picker의 크레용 상자도 아쉽다고 토로. 이런 UI 변화가 당황스럽다는 진심
     * 2025년 이후 아이콘 스타일이 구별하기 어렵다고 느끼는 점, 전체적으로 콘트라스트가 낮고 흐림/블러 효과로 아이콘이 너무 약해졌다고 평가
          + 단순히 색이 뮤트된 걸 넘어 거대한 고해상도 디스플레이에서조차 아이콘이 선명하지 않아 시력이 나빠진 느낌까지 받는다고 토로. 예전에는 “레티나” 해상도를 자랑하던 Apple이 이런 선택을 한 이유를 이해하기 어려움. 2014년대의 아이콘이 최고점이었다고 평가하고, 그 때 이후로는 애매하고 추상적 상형문자처럼 변해가고 있다는 진단
          + 실제로는 아이콘이 겹쳐서 보이거나 더 분리되어 보이는 등 플랫한 버전을 보는 것과는 달리 실제 사용에서는 다른 느낌일 수 있다는 의견
          + Microsoft의 아이콘처럼 모두 비슷한 스타일로 가버리면 불편함이 커진다는 지적. Office 아이콘을 자주 헷갈리게 클릭한다는 사례로, 너무 비슷하게 만드는 것은 좋은 전략이 아니라는 교훈
     * 2025년 아이콘 대부분이 이전보다 못하다고 평가. 그리고 블룸 효과가 많아져서 실제로 더 흐릿하게 보인다고 분석
     * macOS 9 UI의 비주얼과 상호작용성을 여전히 사랑한다는 개인적 감상. 최근 macOS는 더 이상 즐거움을 주지 않는다고 토로하며, 브라우저 등 일부 불편함이 예상되지만 개인/비개발 용도로라도 예전 시스템으로 돌아가고 싶다는 소망. BeOS UI를 좋아했던 경험도 공유하며, 하이쿠(오픈소스 BeOS)가 잘 유지되고 있어 기쁨을 표함
     * 아이콘을 눈을 가늘게 뜨고 흐릿하게 보면, 일부 신형 아이콘은 멀끔하게 보이지만 어떤 것은 지저분한 덩어리처럼 느껴짐을 지적. “글래스” 메타포가 아이콘마다 일관되게 적용되지 않는 점, 반투명 기어는 비주얼적으로 별로임을 솔직하게 말함
     * Mac, iOS 사용자가 아니라 좀 더 객관적으로 Reminders와 Games의 컬러 점/버블 아이콘이 모호하다고 평가. Notes는 한두 단계 전 디자인이 더 명확했고, 그 외는 괜찮은 편이라고 봄. Maps는 최근 두 번의 변경으로 확실한 발전을 이룬 예외적 사례라고 판단
     * 아이콘의 본질은 사용성을 최우선으로 해야한다고 강조. 지금은 오로지 보기 좋은 미적 기준만 따르는 느낌이 들며, 개인적으로는 이 미학이 못생겼다고 생각해도 사용성 문제가 더 크다고 지적. 최근 아이콘은 작은 크기에서 인식이 어려울 정도로 뜬금없는 디자인이 늘었고, 어떤 것은 큰 크기에서도 의미가 불분명. 게임과 색색의 버블이 도대체 무슨 상관인지 의문
"
"https://news.hada.io/topic?id=21865","UV를 활용한 파이썬 개발 워크플로우 혁신하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       UV를 활용한 파이썬 개발 워크플로우 혁신하기

    ""uv: Making Python Local Workflows FAST and BORING in 2025"" 영상 요약

   이 영상은 Python 패키징 도구 uv 를 사용하여 로컬 개발 워크플로우를 빠르고 효율적으로 만드는 방법에 대한 두 번째 파트입니다. 주요 요점은 다음과 같습니다.

      1. uv 핵심 명령어 활용

     * uv run: pyproject.toml에 정의되고 uv.lock 파일에 고정된 의존성을 사용하여 가상 환경 내에서 pytest나 fastapi 같은 명령어를 실행합니다.
     * uv add: 새로운 의존성을 pyproject.toml에 추가하고 uv.lock 파일을 자동으로 업데이트합니다.
     * uv run --with: 프로젝트의 핵심 의존성에 추가하지 않고 pdbpp와 같은 개발용 헬퍼 모듈을 일시적으로 주입하여 사용할 수 있습니다.
     * uv lock --upgrade: 의존성 잠금 파일을 매우 빠른 속도로 업데이트합니다. uv run은 실행 시 자동으로 변경된 잠금 파일을 감지하고 환경을 동기화합니다.

      2. just를 이용한 워크플로우 표준화

     * uv에는 hatch나 pdm처럼 사용자 정의 명령어를 정의하는 기능이 내장되어 있지 않습니다.
     * 영상에서는 Makefile의 단점(플랫폼 종속성, 비표준 문법 등)을 지적하며, 대안으로 Rust로 작성된 명령어 실행기(just)를 강력히 추천합니다.
     * justfile을 사용하여 다음과 같은 반복적인 작업을 레시피(recipe)로 표준화합니다.
          + test: 테스트 실행 (인자 전달 가능)
          + cov: 테스트 커버리지 확인
          + serve: 개발 서버 실행
          + checkall: 린트, 타입 체크 등 모든 검사를 한 번에 실행

      3. just와 uv의 연동

     * .env 파일: just는 .env 파일을 읽어 환경 변수를 설정할 수 있습니다. 이를 이용해 uv run에 --with 인자를 동적으로 추가하거나 서버 포트를 변경하는 등 유연한 워크플로우를 구성할 수 있습니다.
     * uvx (uv tool run): pipx처럼 프로젝트와 독립적으로 PyPI 패키지를 실행하는 명령어입니다. just 레시피 안에서 httpie 같은 도구를 프로젝트 의존성에 추가하지 않고 사용할 수 있습니다.

      4. 가상 환경 직접 관리 (선택적 워크플로우)

     * uv run을 통하지 않고 전통적인 방식으로 가상 환경(.venv)을 활성화해서 사용하려는 개발자를 위한 방법입니다.
     * uv sync: uv.lock 파일과 .venv 폴더의 상태를 동기화합니다. (의존성 설치 및 불필요한 패키지 제거)
     * direnv: 특정 디렉터리에 들어갈 때 .envrc 스크립트를 자동으로 실행해주는 셸 도구입니다. 이를 활용하여 디렉터리 진입 시 자동으로 uv sync를 실행하고 가상 환경을 활성화할 수 있습니다.

      결론

   uv의 속도와 just, direnv 같은 도구를 결합하면, 의존성 관리 및 명령어 실행을 자동화하고 표준화하여 개발자가 핵심 로직에 더 집중할 수 있는 ""빠르고 지루한(boring)"", 즉 매우 안정적이고 예측 가능한 개발 환경을 구축할 수 있습니다.

   https://github.com/gracefullight/py-starter 쓰려고 템플릿하나 만들어놨어요.

   poethepoet을 사용하면 pyproject.toml 안에 태스크를 정의해서 사용이 가능해서 전 just 대신 사용합니다.

   감사합니다. https://poethepoet.natn.io/

   감사요.
"
"https://news.hada.io/topic?id=21934","hyparquet - 초경량 순수 JS Parquet 파서","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    hyparquet - 초경량 순수 JS Parquet 파서

     * Apache Parquet 포맷을 위한 순수 자바스크립트 구현 파서로, 브라우저·Node.js 환경 모두에서 동작하며, 외부 의존성 없이 9.7kb(min.gz)로 매우 가볍고 빠름
     * 모든 파케이(Parquet) 인코딩/압축 코덱 지원하여 pyarrow·duckdb보다 더 많은 파일 호환
     * 기존 JS 라이브러리(parquetjs 등)보다 훨씬 높은 호환성과 성능 제공
     * 필요한 데이터만 선택적 로드(컬럼·행 범위 지정) 하여 대용량 데이터도 효율적으로 처리
     * 브라우저 네이티브 : 브라우저에서 상에서 Parquet 파일 읽기/파싱/뷰잉 가능, 백엔드 서버 불필요
     * 타입스크립트 정의 포함, ES Module 구조, 웹 친화적 API, 진정한 dependency-free 구현으로 현대적 웹 개발 환경에 최적화
"
"https://news.hada.io/topic?id=21936","영국 우체국 IT 시스템 오류로 최소 13명 자살, 1,000명 이상 억울하게 기소됨","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            영국 우체국 IT 시스템 오류로 최소 13명 자살, 1,000명 이상 억울하게 기소됨

     * 영국 우체국 스캔들에서 부당하게 기소된 1,000여 명의 우체국 직원 중 최소 13명이 자살한 사실이 공식 조사에서 드러남
     * 문제의 원인은 Fujitsu의 Horizon IT 시스템 오류로 드러났으며, 초기부터 오류 가능성을 인지한 정황도 보고됨
     * 피해자는 단순 회계 오류로 수십~수백 파운드 책임을 진 사람부터 억울하게 기소·수감·수만 파운드 배상까지 강요받은 사례 등 다양함
     * 피해 규모는 1만 명 이상으로 추정되며, 현재까지 2,500건 이상의 보상 청구가 접수됐으나 충분한 구제는 지연되고 있음
     * 커뮤니티의 오해·경제적 파탄·가족 해체 등 장기적 후유증이 심각하며, 일부 고령 피해자들은 보상받을 시간조차 촉박하다는 우려를 표함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

영국 우체국 스캔들: 피해와 진상 조사

  조사 결과 및 자살 피해자 발생

     * 공식 조사에 따르면, 2000년~2013년까지 약 1,000명의 우체국 직원이 절도 등 혐의로 부당 기소됨
     * 이 과정에서 최소 13명이 자살했으며, 59명은 한때 자살 충동을 겪었다고 보고함
     * 피해자는 단순 회계상 오류에 책임을 진 사례부터, 억울한 기소, 유죄 판결, 수감, 수만 파운드 배상까지 다양한 고통을 겪음

  피해자의 구체적 사례

     * Martin Griffiths는 리버풀 외곽에서 우체국을 운영하다 회계 불일치 문제로 10만 파운드 초과 손해 책임을 지고 해고, 2013년 59세에 스스로 생을 마감함
     * Seema Misra는 임신 중 수감, 지역 신문에 ""임신한 도둑""으로 낙인, 남편은 폭행과 인종차별을 겪음
     * 그 외 수많은 피해자가 파산, 주택 매각, 저축 고갈, 가족 해체, 정신적 고통 등을 경험함

  시스템 오류와 책임

     * 문제의 원인은 Fujitsu의 Horizon IT 시스템의 결함으로, 일부 직원은 출시 전부터 오류 가능성을 인지하고 있었음
     * 우체국은 피해자의 지속적인 문제 제기에 대해 오류 가능성을 부인하며 책임을 떠넘김
     * 검찰은 해당 시스템의 데이터를 근거로 형사 기소를 진행함

  보상 및 후속조치

     * 피해자 중 1만 명 이상이 보상 대상으로 추정되나, 현재까지 2,500건의 보상 청구만 집계됨
     * 우체국 측은 충분한 보상 여력이 없다고 밝혀, 일부 고령 피해자들은 적극적인 구제가 시급하다고 호소함
     * 조사위원 Wyn Williams는 ""모든 피해자에게 완전하고 공정한 구제가 필요하다""고 강조함

  사회적 반향과 향후 계획

     * ITV 드라마 “Mr. Bates vs. the Post Office”로 스캔들이 재조명되었고, 의회는 2024년 5월 관련 유죄 판결을 취소하는 법안 통과
     * 영국 사법 사상 최악의 오심 사례 중 하나로 평가
     * 향후 추가 조사에서 Fujitsu 및 우체국 고위 인사의 책임이 더욱 상세히 밝혀질 예정

   예전에 제가 사건 초반에 대해서 좀 더 자세히 적은 게 있습니다:

   사건의 발단은 1999년, 우체국이 신뢰성을 의심하고 취소한 연금 및 수당 지급 시스템을, 영국 정부가 포기하지 않고 거래를 종이에 기록하던 우체국의 기존 시스템 업그레이드에 사용하기로 한 결정이었다.

   호라이즌(Horizon)이라고 불린 이 포스기(an electronic point-of-sale system)는 초기부터 문제가 많아서, 호라이즌에 기록된 현금과 실제 현금 보유량 사이의 차이가 발견되었고, 당황한 우체국장들은 호라이즌 고객센터에 전화를 걸기 시작했다고 한다.

   '달멜링턴' 오류는 사용자가 현금수령여부를 확인(confirm)하려고 하면 화면을 정지시켰는데, 이 상황에서 엔터를 누를 때마다 아무런 표시 없이 현금을 수령한 것으로 기록했다.

   '캘린더 스퀘어' 오류는 시스템의 기반 데이터베이스 오류로 인해 중복 거래를 발생시켰다...

   원인은 무엇이었을까? 여러 가지가 있었겠지만, 1) 부족한 인력, 2) 소프트웨어의 무오성에 대한 맹신, 3) 관료제가 눈에 띄인다.
    1. 부족한 인력

   개발에 참여했던 데이비드 맥도넬에 따르면 ""개발팀에 8명이 있었는데, 2명은 매우 유능했고, 2명은 보통이었으나 함께 작업할 수 있었고, 나머지 3~4명은 전문적인 코드를 생성할 능력이 없어서 일을 제대로 할 수 없었다.""고 한다.

   https://x.com/KayKiwoongKim/status/1825209040575873330

        Hacker News 의견

     * 기사 아카이브 링크을 공유함
     * 나는 1년 전쯤 이 스캔들을 파고들다가 ‘계급’ 요소가 인상적임을 깨달았음
       Post Office 경영진은 왜 누군가가 PO 프랜차이즈를 사는지 이해를 못했음
       많은 돈을 들여 하나의 점포를 구매하고, 시간도 오래 투입하는 직업을 구입한다는 개념을 납득하지 못했음
       이 때문에 ‘진짜’ 이유를 찾았고, 결국 다들 돈을 훔치려 프랜차이즈를 산 것이라고 확신하게 됨
       그 결과 회계 소프트웨어의 목적이 사기를 적발하고 처벌하기 위한 것이 되었음
       소프트웨어가 실종 자금액을 산출하기 시작하자 문제점을 제기하는 질문도 무시함
       경영진의 인식이 애초부터 점주들을 도둑으로 간주했기 때문에, 만약 소프트웨어가 사기를 거의 찾지 못했다면 오히려 소프트웨어를 의심했을 것이라는 생각임
          + 이전 HN 댓글에서 이런 현상이 ‘소프트웨어 신뢰’가 어떻게 사람 인생을 망칠 수 있는지 예시로 제시된 적이 있으나, 너의 설명은 더 인간적이고 맥락을 재정의해 준다고 느꼈음
            이런 일은 소프트웨어 때문에 벌어진 게 아니라, 하층민을 깔보는 태도에서 비롯되었고, 100년 전에는 내사팀 같은 방식으로도 일어났을 것임
            영국-미국을 오가며 성장했지만, 영국 문화가 계급적 관점에 더 민감한 듯 느껴짐
            미국은 이런 계급 경멸이 없다고 스스로 속이는 편임
          + PO가 프랜차이즈 프로그램을 만들어서, 나중에 ‘상식적이고 선한 행동자’에겐 적합하지 않다고 결론낸 뒤, 계약 조건을 수정하기 보다는 참가자를 죄인 취급한 후 기소한 것임?
          + 하층 계급 사람들의 사기는 반드시 엄격히 처벌해야 하는 중대한 문제로 여겨지지만, 상층 계급의 사기는 대개 법인 보호막에 의해 지켜지는 현상이 흥미롭게 느껴짐
          + 이 부분은 지금까지 언론이나 대중문화(Mr Bates Vs The Post Office 등)가 충분히 강조하지 않은 지점이라고 봄
            영국은 계급에 집착하는 사회임이 외부(특히 미국)에 잘 드러나지 않음
            네 이론에 큰 신빙성을 더해주는 관찰임
          + 네 댓글이 통찰력 있다고 생각하며 한 가지 덧붙이고 싶음
            정말 경영진이 무지했다는 점이 명확한지는 사실 확신하기 어렵고, 일부는 악의적이었던 것으로도 읽혔음
            책임 회피를 위해 의도적으로 행동했던 경우도 분명 있었음
     * 이 사건을 읽고 무척 우울해짐
       너무 많은 단계에서 실패가 일어남
         1. Horizon 도입 직후 문제 제기가 있었지만 무시됨
         2. 검사들은 수천 명을 “절도”로 기소하기 전에 추가 증거나 다른 설명을 확인하려 하지 않음
            '정말 다들 갑자기 도둑이 된다는 게 상식적으로 말이 되나?'라는 의문 제기도 없음
         3. 지역 신문이 임산부 사진과 함께 “임신한 도둑”이라고 이름 붙여서 보도함 – 클릭을 위한 선정적인 기사
         4. Post Office는 “너무 많은 사람들이라 보상할 능력 없음”이라 변명함
            수천 명을 허위로 기소하고 인생을 망치게 할 자원은 있으면서, 실수는 바로잡지 못하겠다는 논리임
            이 사건은 10년이 넘게 방치됨
            일반 시민은 제때 세금 내고, 면허 갱신 안 하면 벌금이나 감옥 감인데 정부는 10년 동안 뒷짐만 졌음
            Fujitsu의 책임은 어디에 있음? 왜 정부가 Fujitsu에게 저질 소프트웨어 파괴로 인한 보상 책임을 묻지 못하는지 이해가 안 감
            진짜 미친 현실임
          + 이 논란과 관련 HN글도 읽어보기 바람
            아직 널리 알려지진 않았지만 앞으로 10년 안에 더 이슈화될 것 같음
            이건 한 나라만의 문제가 아니고, 몇십 년간 전 세계로 확대되고 있는 채로 참고하는 게 좋음
          + Fujitsu에게 책임을 묻지 못하는 이유는 소프트웨어 자체가 문제라서가 아님
            물론 소프트웨어가 허접하지만, 이 스캔들의 핵심은 Post Office 경영진의 처신임
            문제 제기를 제대로 받은 내부 감사 리포트를 무시했고, “아무도 문제 없다”는 식으로 점주들에게 거짓말함
            Fujitsu도 거짓말과 은폐로 무책임했으나, 이 사태를 초래한 건 Post Office 리더십임
            실제로 세상엔 결함 있는 소프트웨어와 사고가 넘쳐나지만, 그 결함 자체보다도 그것에 저항하는 태도와 대응이 훨씬 더 중요함
          + 정말 동의함
            나는 HM Treasury에서 기술 아키텍트로 일할 때, 정부 조달 분야가 얼마나 극단적으로 부패했는지 직접 봄
            DVLA, DEFRA, DWP, Home Office, MOJ, Scottish Government에서 자살, 오판, 공금 손실 등 수많은 사고를 직접 목격함
            결국 정부는 시스템을 승인해야 하고, 항상 책임자가 정해짐
            일반적으로 모든 당사자(고객, 공급사) 모두 책임자를 보호하려는 민감한 동기로 똘똘 뭉치게 됨
            이건 결과적으로 이익과 평판을 지키고, 좋은 뉴스 스토리를 만들며, 결국 책임자들은 공급사로 “승진”하는 결과로 이어짐
            이렇게 반복해서 보고 지겨울 정도임
            영국 공공 부문은 완전히 썩은 시스템임
          + 더 심각한 것은 Fujitsu가 원격 데이터 수정을 못한다고 거짓 주장했다는 점임
            피고인과 판사들에게 기술 정보를 이용해 증거를 모호하게 만들었음
          + Private Eye와 Computer Weekly에서 발간되는 내용을 계속 챙겨보길 추천함
            이 두 곳이 철저히 문제를 추적하고 있음
            영국에선 유죄가 확정되면 법적으로 해당 범죄 명칭을 쓰는 것이 용인되는 문화임
            이번 사건에선 Post Office가 고유의 법적 권한을 가지고 있었고, 브랜드 이미지를 지키겠다며 실수 인정 대신 계속 덮으려 함
            법원과 검사 역시 소프트웨어 증거에 대한 태도에서 구조적 결함이 있었음
            특이하게도 영국 법정에서는 컴퓨터 기록이 잘못됐다는 게 여전히 합법적 변론이 안 됐음
            법적으로 IT 시스템은 틀릴 수 없다는 전제가 깔려 있음
            만약 당신의 증거와 IT 기록이 다르면, 피고인은 거짓말쟁이로 취급받게 됨
            이는 많은 이들의 인생을 망친 구조임
            이번 사건에서 개인 몇 명만 탓해봤자 해결이 안된다는 점도 다들 깨달음
            보통 항공 사고처럼 복합적 실수와 시스템적 결합 실패가 한 번에 겹칠 때 이런 사태까지 벌어짐
            Fujitsu 직원들도 지금 이 회사에 속해 있다고 자랑하진 못하는 상황이고, 그럼에도 아직 제대로 보상도 못 받은 와중에 또 신규 계약을 따내고 있음
     * 이 일은 사실상 ‘고문에 의한 죽음’과 다름없음
       전산윤리 교육에서 늘 Therac 25 같은 의료사고를 예시로 드는데, 학생들은 의료장비가 아니면 나는 괜찮다며 안심함
       의료기기가 아닌 소프트웨어도 충분히 타인에게 해를 끼칠 수 있다는 사실을 모두 인식해야 함
          + 그래서 “자살로 사망”이란 표현이 문제가 될 수 있음
            여러 요인에 의해 극한 상황으로 내몰린 사람들이었고, 선택지가 아예 없었음
          + 나는 현재 미사일 추적 위성용 소프트웨어를 개발 중임
            내가 실수하면 직접적으로 인명을 ‘죽이는’ 건 아니어도 실제 사람이 죽는 결과적 책임을 지게 됨
            전직장에선 전투기와 미사일 개발도 했고, 실제로 내 작업으로 인해 사람들이 죽기도 했음
          + 나는 이 기사를 읽자마자 Therac 25 사고가 떠올랐음
            하드웨어를 직접적으로 잘못 제어하는 기능이 없어도 수천 명의 피해를 낳은 점이 동일함
          + 정말 제발 전산학과 졸업생들에겐 실질적 의미의 윤리수업 이수가 필수여야 한다고 간절히 바람
     * 법원의 실패 또한 Fujitsu 못지않게 크다고 생각함
       어떻게 Horizon 출력을 맹목적으로 증거로 받아들일 수 있었는지
       만약 컴퓨터가 “여왕이 돈을 다 훔쳐서 바베이도스로 도망갔다”라고 했다면, 진짜 감옥에 넣었을까?
       Fujitsu가 내용을 마음대로 적어 넣은 노트북에 불과할 수 있는데 그런 출력물을 성경같이 여긴 이유가 궁금함
          + 이 답변의 진실은 끔찍함
            영국 법정에선 실제로 컴퓨터가 정확하게 동작한다고 간주해야 했음
            반대 증거가 존재해야 했는데, 일반 점주들은 소스코드에 접근도 못했고 대부분 컴퓨터 전문가도 아님(소스는 영업비밀임)
            이 관행은 앞으로 바뀔 수도 있는데, 자세한 내용은 영국 정부 공식 참고자료와 관련 법률 기사 참고하면 좋을 듯함
          + 한 가지 이유는 Post Office가 경찰처럼 Crown Prosecution Service에 제출할 필요 없이 자체적으로 기소할 수 있는 법적 지위를 가졌기 때문임
            많은 이들이 “컴퓨터는 항상 옳다”는 압박에 못 이겨 법정 대응비 부담을 최소화하려 유죄를 인정함
            실제로 실질적인 건 거의 없더라도 자신의 법적 지위로 상대를 굴복시켰음
     * 4부작 미니시리즈 Mr Bates vs The Post Office가 꼭 볼 만함
       Horizon이라는 Fujitsu 제작 결함 IT 시스템으로 인해 수많은 점주가 절도·사기·거짓회계로 기소되고, Alan Bates가 Justice for Subpostmasters Alliance를 결성해 집단 항의함
       법원 최종 판결(2019년)에서 오심으로 결론남
       Wikipedia: Mr Bates vs The Post Office
          + 이 스캔들의 흥미로운 점은 미니시리즈의 실제 임팩트임
            (영국 외국인 입장에서) 대중적 관심이 미니시리즈 덕분에 촉발됐고, 그렇지 않았다면 당사자들은 여전히 ‘관공서 미로’에 갇혀 책임 추궁도 못했을 것임
            만약 이 드라마가 재미없었다면 피해자들은 더 나쁜 상황에 있었을지도 모른다고 생각함
            ""Impact"" 위키 섹션도 참고 가치 있음
          + 나는 BBC Radio4의 ‘The Great Post Office Trial’ 팟캐스트에서 많이 배움
            The Great Post Office Trial Podcast 추천함
     * 이 스캔들을 오래 지켜봐 왔는데, 아래 두 인용문이 모든 걸 압축한 느낌임. 정말 슬펐음
       “도입 전부터 일부 Fujitsu 직원들은 Horizon이 잘못된 데이터를 낼 수 있다는 걸 알았던 것으로 보고됨”
       ""해마다 불만이 커지고 지속됐지만, Post Office는 Horizon이 거짓 데이터를 낸다는 주장에 끝까지 저항함""
          + 당시에 개발자가 코딩 버그를 기자에게 털어놓았다면, 오히려 증거 조작, 사이버 범죄, 영업비밀 유출 등으로 본인만 감옥에 갔을 거라는 생각이 듦
          + 직원들은 뭔가 망가질 걸 알고 있었지만, 윗선이 수습을 피하려 서둘러 런칭했다는 건 실리콘밸리 업무 윤리와 별반 다르지 않음
     * 이 모든 스캔들의 실체가 드러난 데는 수년간 Private Eye 기자들의 끈질긴 취재가 한몫했음
       Private Eye는 웃긴 만평도 많은 재치 있는 매체임
       카툰만 읽더라도 진지하게 Private Eye 구독해서 탐사저널리즘을 지원해주길 권함
     * 이야기를 끝까지 들으니 정말 참담함
       여전히 많은 점주들은 보상을 받지 못했고, Post Office와 Fujitsu 그 누구도 마땅히 책임지지 않은 채 은퇴해 호화 연금을 받음
       Paula Vennels는 거의 성공적으로 주교로 임명될 뻔 함
       영국 세금으로 보상금이 지급되고, Fujitsu는 여전히 잉글랜드 정부와 계약을 이어감
       Alan Bates, Private Eye, Computer Weekly 등 소수의 용감한 이들이 여기까지 오긴 했지만 아직 진정한 정의는 실현되지 않음
     * NY Times에 전하고 싶은 말임
       “자살했다""는 수동 표현은 마치 무슨 불가항력, 신의 행동처럼 들림
       꼭 사실대로 얘기해야 함: 점주들은 저질 회계시스템 기반 허위 증거로 감옥에 가게 됐고, 그 결과 스스로를 해쳤음
       자연재해인 것처럼 모호하게 표현하면 진실을 흐림
       Horizon은 Therac-25를 대체할 교과서적 사례임
       Therac-25는 6명 사망·부상인데, Horizon은 수백 명 인생을 파국에 몰고, 수십 명을 죽음에 이르게 했음
       특히 Horizon은 응용프로그램(Point-of-Sale, 회계 소프트웨어)으로, 안전필수 소프트웨어가 아님에도 순식간에 재난으로 변할 수 있다는 점을 보여줌
       자살이 소프트웨어 때문만은 아니고, 공공기관과 법체계가 실제론 대형 은폐하는데 다들 맹신했던 사회적 결과임
       이 죽음의 책임은 법·정치·행정 시스템에 있음
       그리고 “시스템이 항상 잘 동작한다”고 계속 맹세한 엔지니어들도 도덕적으로 책임 큼
       이러다 보니 멀쩡한 거래가 시스템 상에서 잘못 입력되어 실제로 존재하지 않은 거래까지 남게 되어, 그 차액 탓에 점주들이 도둑 취급 당했음
       당시엔 사회가 더 기관을 신뢰했고, 시골 작은 마을에 위치한 점포에서 벌어져 지역사회·비즈니스 모두 파괴된 것임
       결론은, 거래 검증을 철저히 하고, 개발자가 운영 환경에서 데이터베이스를 조작 못하도록 해야 한다는 것임
          + “딥 스테이트”가 아니라 그냥 “국가”임
            이런 표현은 국가를 선악으로 이분화시키는 잘못임
            아마존도 딥 아마존은 없고, 메타도 마찬가지
            쉽지만 국가라는 조직 자체가 자기생존·자기방어를 최우선함
          + Horizon 스캔들은 내가 “데이터베이스 설계” 수업에서 첫 번째로 가르치는 주제임
            이건 이론적 연습이 아니라 실제로 인생에 영향을 주는 시스템이라는 점을 깨닫게 하고 싶음
            법적·윤리적 관점도 반드시 가르침
            시스템은 감사 가능하고, 사람들에게 이로워야 함
          + 이런 자살이 모두 지독하게 비참한 조사과정과 원인 미해결 관리에 따른 직접적 결과임은 명확하지만, 뉴스를 100% 사실에 한정해서 보도하지 않을 경우 책임 회피에 악용될 수 있음
            그리고 시스템이 망가진 걸 알고도 계속 “잘 돌아간다”고 선서한 엔지니어 역시 도덕적으로 엄청난 책임이 있다고 봄
          + 정말 잘 말해줬음
            괴롭힘 받아 극단적 선택을 하는 사람을 표현할 더 나은 단어가 필요하다고 생각함
            최근에도 Reddit의 괴롭힘 커뮤니티 탓에 멀쩡한 이가 죽음에 이르렀음
            언론팀과 훈련을 받지 않은 일반 사람에겐 이런 표적화·괴롭힘이 더 치명적임
          + “소프트웨어 개발자들이 망쳤다”
            맞는 말이지만, 그 파장이 100배 증폭된 이유는 경영진의 악질적 대응임

   너무 무섭습니다.
   악의적으로 기록된 기록이,
   기억과 경험을 물리치고 증거가 되어
   우리를 위협하는 일이 벌어질 수 있다는 것이요.
"
"https://news.hada.io/topic?id=21907","대부분의 RESTful API는 실제로 RESTful하지 않음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   대부분의 RESTful API는 실제로 RESTful하지 않음

     * Roy Fielding의 REST 원조 논문에서는 HTTP 메서드나 CRUD 중심의 API 사용을 명확히 규정하지 않으며, REST는 원래 하이퍼미디어 기반(HATEOAS) 시스템 설계를 강조함
     * 많은 이들이 RESTful API라 부르는 것들은 중요한 REST 제약조건(특히 하이퍼미디어 사용)을 구현하지 않음
     * 리소스는 단순 데이터 구조나 엔티티에 국한되지 않고, URI로 식별 가능한 모든 개념을 포함함
     * Fielding의 6가지 규칙에 따르면, 하이퍼미디어 중심 탐색, 프로토콜 독립성, 미디어 타입 중시 등이 핵심임
     * 현실적으로는 OpenAPI 등 문서화 도구 편의성 때문에 대부분의 API가 진정한 RESTful보다는 RPC 스타일에 가깝게 설계되는 경향이 많음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

대부분의 RESTful API가 진정한 RESTful이 아닌 이유

     * Roy Fielding의 대표 논문(2000) 은 REST(Representational State Transfer)를 네트워크 기반 소프트웨어 설계의 이상적 스타일로 제시하며, 웹의 성공을 뒷받침하는 원리로 설명함
     * 논문에서는 HTTP 메서드 사용, CRUD 중심 설계를 필수로 규정하지 않으며, REST를 지향할 때 하이퍼미디어(HATEOAS) 기반 상태 전이, 보편적 인터페이스, 자원 중심의 상호작용이 핵심임을 강조함

하이퍼미디어(HATEOAS)와 REST의 오해

     * Fielding은 하이퍼미디어 없는 API는 RESTful이 아니라고 명확히 지적함
          + ""엔진이 하이퍼텍스트에 의해 구동되지 않으면 RESTful이 아님""
     * HATEOAS란 클라이언트가 서버 응답에 내장된 링크를 따라 동적으로 행동을 탐색하는 방식임
     * 단순히 HTTP/CRUD 인터페이스만 사용하는 것은 REST의 본질과 다름

REST의 흔한 오해

     * REST는 CRUD라는 인식(실제로는 더 넓은 개념)
     * 리소스는 엔티티(서버의 데이터 구조)라는 오해
     * RESTful API에는 동사(Verb)를 쓰면 안된다는 주장
     * 이런 것들은 설계 결정일 뿐 REST의 본질과는 직접 관련 없음

하이퍼미디어 구동(HATEOAS)의 실제 의미

     * HATEOAS의 목적은 클라이언트-서버 결합도 최소화에 있음
     * 서버의 URI 구조 변경 시, 클라이언트 재배포의 고통을 줄여 확장성과 진화 가능성을 높임
     * 클라이언트는 문서나 사전 지식 없이 응답 내 하이퍼링크를 따라 동작을 탐색함
{
  ""orderId"": 123,
  ""\_links"": {
    ""self"": { ""href"": ""/orders/123"" },
    ""cancel"": { ""href"": ""/orders/123/cancel"", ""method"": ""POST"" }
  }
}

     * 위와 같이 응답에 동작(링크)가 포함되어야 진정한 RESTful에 가까워짐

REST에서 리소스란?

     * 리소스는 URI로 식별 가능한 모든 것
          + 문서, 이미지, 물리적 객체, 서비스, 추상 개념 등 포함
     * 서버에는 실제 ""리소스""가 존재하는 것이 아니라, URI로 접근 가능한 추상적 매핑 구조가 있을 뿐임
     * RFC 3986에서도 리소스의 범위를 한정하지 않음
          + 전자 문서, 이미지, 정보원, 서비스, 심지어 사람·법인·도서 등도 포함 가능

Fielding이 정의한 RESTful API의 6가지 규칙

     * 1. 단일 프로토콜에 종속되지 말 것
          + URI 기반 식별을 모든 프로토콜에서 활용 가능해야 함
     * 2. 프로토콜(예: HTTP) 표준을 임의로 변경하지 말 것
          + 표준의 미비점 보완은 가능하나, 임의의 규칙 추가/변경 금지
     * 3. URI 구조 대신 미디어 타입(포맷) 정의에 집중할 것
          + 데이터 형식 및 링크 정의에 집중, 경로 명세/문서화에 에너지 낭비 금지
     * 4. 고정된 URI 네이밍/계층구조 하드코딩 금지
          + 클라이언트가 서버의 네임스페이스 구조를 추측·고정하지 않도록, 링크 기반 탐색 유도
     * 5. 리소스 타입(내부 분류) 노출 금지
          + 내부 객체 타입은 클라이언트에 무의미, 표준 미디어 타입·링크만 노출
     * 6. 북마크(초기 URI)만 필요, 나머지는 응답의 링크로 탐색
          + 클라이언트는 표준 미디어 타입만 알고, 상태 전이는 항상 서버 응답 내 하이퍼링크 기반으로 이뤄져야 함

규칙의 해석과 실제 적용

     * 프로토콜, URI, 타입에 대한 결합을 최소화해야 진정한 RESTful에 가까워짐
     * API는 데이터와 링크의 형식(미디어 타입)에 집중해야 하며, URI 구조나 명명 규칙 등은 클라이언트가 미리 알 필요 없음
     * 예시처럼 /users/123/activate 같은 경로를 명세하지 않고, 응답 내 ""activate"" 링크로 동작을 안내해야 함

실제 RESTful API가 드문 이유

     * OpenAPI, Swagger 등 도구의 편의성이 개발 현장에서 우선시됨
          + 자동 문서화, 코드 생성, 유효성 검사 등 실질적 이점 제공
     * 클라이언트-서버를 같은 팀이 개발하는 SPA 환경에서는 URI 결합 문제의 필요성이 크지 않아, HATEOAS의 장점이 부각되지 않음
     * REST 원칙의 초기 학습 부담, 동적 링크 파싱의 복잡성 등 실용적 장벽이 큼

결론

     * Fielding의 규칙에 따르면 진정한 RESTful API는 하이퍼미디어(HATEOAS) 기반 동적 탐색이 필수임
     * REST는 단순히 HTTP 위에서 CRUD를 구현하는 것이 아니며, 웹의 원리와 같이 느슨한 결합·진화 가능성·동적 상태 전이에 초점을 둔 아키텍처임
     * 현실에서는 실용성과 팀의 상황에 맞는 설계가 더 중요할 수 있음
          + 외부 개발자를 위한 퍼블릭 API라면 HATEOAS 채택이 권장되지만, 내부 전용 API라면 단순한 RPC 스타일도 실용적임
     * API는 배우기 쉽고 오용하기 어렵게 설계하는 것이 핵심이며, 반드시 RESTful일 필요는 없음

        Hacker News 의견

     * 나는 여기서 나타나는 지나친 원리주의에 공감하며 Fielding의 논문도 흥미롭게 읽었음, 하지만 이건 이미 끝난 전쟁임을 느꼈음 REST API라는 말을 듣는 순간 다음을 거의 확신할 수 있음
          + API는 JSON을 반환함
          + CRUD 작업이 POST/GET/PUT/DELETE에 매핑됨
          + 팀은 적합한 HTTP 상태 코드에 대해 끝없이 논쟁하며, 일부 코드는 스펙과 다르게 쓰임
          + 복잡한 필터 지원을 위해 listing endpoint가 POST로 변경될 가능성도 있음 Agile, CI, DevOps처럼 처음의 정의를 고집하거나, 아니면 이미 사회적 의미가 바뀌었으니 그냥 통용되는 뜻대로 용어를 쓰게 됨
          + Fielding이 이겼던 이유는 바로 그의 논리가 모순되고 대부분 틀렸기 때문라고 생각함 21세기의 ""worse is better"" 패러다임임 RPC 시스템은 사용성이 떨어지고 성공하지 못했고, 예로 Sun RPC, RMI, DCOM, CORBA, XML-RPC, SOAP, Protocol Buffers 등이 있음 사람들은 REST가 RPC가 아니라고 하지만 실제로는 Javascript에서
const getItem = async (itemId) => { ... }

       같은 함수를 만들고, 이 함수는
GET /item/{item_id}

       를 호출함 백엔드에는
Item getItem(String itemId) { ... }

       같은 함수가 있고 어노테이션으로 URL 매핑을 설명함. 결국 이건 RPC임. 다만 복잡하고 비직관적인 시스템 대신 좀 더 수작업스럽고 개발자가 통제할 수 있는 형태로 남아 있음 대다수 문제의 80%는 사람들이 ISO 8601 날짜 포맷을 안 쓰는 것이 원인임
          + 왜 누가 이걸 ""전투""라고 여기고 신경 쓰는지 이해가 잘 안 됨 REST 개념은 유용하지만, HATEOAS 부분은 실용성이 거의 없고 문제만 만듦 Richardson maturity model을 보면 REST의 최정점은 HATEOAS 같은 요소가 포함되어 있음 REST에서 HATEOAS가 빠지면 REST라고 할 수 없다는 논리도 이해 안 됨, 별로 큰 차별점이 안됨 HATEOAS가 실질적으로 거의 무의미하면 이 원리주의적 분류에 집착하는 게 의미가 없는 것 같음 Richardson maturity model
          + ""팀이 상태 코드에 대해 과도하게 논쟁하고 HTTP spec과 다르게 쓰는 경우가 많다""는 부분에서는 401 Unauthorized는 인증이 안 된 경우, 403 Forbidden은 권한이 없는 경우에 써야 함을 강조함
          + 나는 사람들에게 Paper에서 정의한 REST의 의미를 진짜로 쓸 건지 물어보는 편임 보통 의미 없는 용어를 남용하는 현실을 용납하지 않는 쪽임 결국 ""그냥 웹 API라는 얘기구나""라고 한 뒤 넘어감. 중요한 건 이런 API마다 엉뚱한 점을 파악해야 한다는 차이임
          + 나에게 진짜 중요한 뉘앙스는, ""하이퍼미디어 링크""가 다양한 link type(HTTP 헤더나 반환 결과에 포함됨)으로 ""일반적""인 것처럼 보이지만, 실질적으로 오늘날의 REST도 동일하게 동작한다는 점임 예를 들어, 만약 잘못 설계해서 ""activate""가 아니라 ""enable""이어야 했다면, 결국 /api/v1/account/ID/activate에서 /api/v2/account/ID/enable로 바꿔야 함 즉, API에서 모든 액션의 의미를 어디선가 하드코딩해야 함(그리고 아이콘, 액션 설명 번역 등 부가 메타데이터도 부족함) 이 방식의 ""범용성""은 사실 착각임
     * 13년 전 처음으로 HTTP API를 개발하게 되었을 때, 진짜 REST가 뭔지 파악하기 위해 Fielding의 논문을 처음부터 끝까지 읽고, RESTful Web Services Cookbook도 읽음 그리고 Django의 관례를 피해가며 REST API를 만들었음 이건 일종의 ‘카고 컬트’적 접근으로, 진짜 REST가 우리 서비스에 어떤 이점을 주는지 잘 몰랐음 그로부터 몇 년을 더 다양한 HTTP API를 만들면서야 결국 실무 상황에선 REST 원론이 줄 수 있는 이점이 없다는 걸 느꼈음 ""셀프 디스커버리""와 ""제너릭 클라이언트와 호환"" 비전은 거의 실현 불가능하고, 구체적으로 Fielding 논문은 이런 부분을 아예 완벽하게 안내하지도 않음 진짜 셀프 디스커버러블 API 만들려면 ""엔드포인트 디스커버리 프로토콜"", ""오퍼레이션 설명"", ""헬프 메세지"" 등 구체적인 룰이 필요함 그리고 결국 그 룰을 이해하는 전용 클라이언트를
       만들어야 하고, 그럼 일반화된 클라이언트의 이점은 사라짐 즉, 현실에서 서비스 전용 API/JS 코드/CLI 등 결국 서버별 맞춤 코드를 만드는 수밖에 없었음 그리고 좋은 UX는 REST의 이상과 충돌하는데, 프론트에 앱 특화 코드를 만들어야 진짜 좋은 UX가 나옴 UI 요소도 표준화할 수는 있긴 하지만 실제로는 JavaScript 같은 언어를 통해 유연하게 UI를 만드느 게 더 쓸모 있음
          + 셀프 디스커버러블 API라는 개념의 한계에 공감함 진짜 REST 클라이언트는 실질적으로 구현 불가능함 모든 URL의 동작을 알고 있어야 하고, 새로 추가되는 행동이 있다면(예: /cansofspam/123/frobnicate) 클라이언트가 명확히 처리하지 못함 결국 클라이언트 업데이트가 필요하거나 무시하거나 아주 단순한 버튼(예: Frobnicate)만 추가 가능함 그래서 실제로 완전한 의미의 REST 서버나 클라이언트는 존재하지 않음 현실적으로 클라이언트가 디스커버리 없이 기대하는 API만 지원하는 게 운영이 됨
          + API에는 다양한 측면이 있어서 설명하는 일이 어려움 API 사용자들은 평균 응답 지연, 재시도 가능한 에러코드, 액션의 원자성/멱등성 등도 알아야 함 HATEOAS만으론 이런 것들을 알 수 없음 완벽한 REST를 구현할 필요가 없고, 기본적으로 REST가 주는 이점은 단순히 명사/동사를 HTTP 메서드와 URL로 매핑하는 통일된 언어가 있다는 점임 그런데도 세세한 설계와 고민이 엄청 많음 예를 들어 HTTP 스펙상 허용되는 걸 실제 LB에선 쓸 수 없다거나, 500 에러를 리트라이하는 기준/백오프 로직 등을 신경 써야 하는 점이 있음
          + 브라우저가야말로 ""제너릭 코드""로, 우리가 매일 쓰는 최고의 UX를 제공함 REST 개념엔 서버가 클라이언트에 코드를 넘길 수도 포함됨(보안상의 이슈는 있지만, 브라우저와 표준이 이런 부분도 많이 해결함) Fielding 논문 내 관련 부분 링크
          + 사실 REST 정의도 약해진 버전에선 별로 이득이 없음 ""리소스 삭제에 DELETE를 꼭 써야 한다""는 건 그다지 중요하지 않음 그냥 POST 쓰면 누가 어려워 하나요?
          + 나는 '셀프 디스커버러블'이란 게 목표라고 생각해본 적도 없고, 달성 가능한 일이라고도 안 봄 간단한 클라이언트 설계에서는 애초에 기대가 너무 과함 특히, TFA에서도 ‘discoverable’이란 단어 자체가 안 나옴
     * 이런 API 디자인 방식이 진짜 쓸모 있는 곳은, 사용자와 이를 대신 탐색하는 agent(예: 브라우저)가 API를 탐색하면서 각 응답 내 미디어 타입, 링크 정보에 따라 상호작용할 수 있을 때임 대부분 웹 API들은 이런 use-case가 아니라, 특정 UI/UX를 추구하는 웹앱용으로 설계되어 있음 이는 의도적으로 선택된 방향임 앱 제작자는 앱 목표를 위해 데이터의 표현, UI 흐름 등을 완전히 통제하길 원함 REST API 설계는 사용자가 API의 리소스 사용 방식을 더 주도적으로 통제해야 할 때 필요함 예시로
          + 누구나 접근 가능한 정부 정보 포털(법령, 날씨, 부동산 기록 등)
          + 각종 서식 제출이 필요한 정부 포털
          + 위키피디아나 OpenStreetMap 같은 open data 프로젝트 이런 쪽이 REST API 디자인을 도입해야 할 영역임 결국 REST 정의를 엄격히 따지는 사람들은 학구적인 배경이 많고, 반면 넓게 쓰는 사람들은 앱 경험을 중요시하는 개발자인 셈임 해답은 단순함, 진짜 REST가 아닐 때는 REST라고 부르지 않으면 됨
          + 사실 HTML 문서가 정확히 그 사례임 문서 안에 다른 문서로 가는 링크들이 있고, 사용자는 링크에 써있는 텍스트대로 어디로든 탐색할 수 있음 만약 사용자를 위한 거면 UI라고 부르고, 애플리케이션용이면 API라고 부름 HATEOAS가 엉뚱하게 느껴지는 이유는, API를 직접 사용자에 맞추자는 것처럼 보임 하지만 우리는 이미 UI라는 형태로 그걸 누리고 있음
          + 순수 REST 개념은 매우 학구적임 오픈/빅데이터 프로젝트에서 실질적인 성능이나 아키텍처를 구현하려면 REST 달성유무보다 현실적인 접근이 더 중요함 심지어 학자들도 결국 결과물을 만들어야 하기 때문에 완벽한 REST만 고집하지 않음
          + 이런 종류의 API 설계는 웹 페이지뿐 아니라 다른 클라이언트를 만들 때도 유용함 GET으로 리소스를 받아서 필드/경로로 값 추출하고, 새 URI를 만들어 조작하는 등 비슷한 패턴으로 여러 가지 앱/CLI/UI 구축이 가능함 non-SPA라면 HTML로 바로 구현하는 것도 가능하고, 결국 사용자(혹은 user-agent)가 반환 표현 내부의 정보를 dereference 하는 것임
          + AI가 API를 소비하는 시대가 오면 이 use-case가 더 중요해질지 궁금함 API의 discoverability는 웹앱 개발자보다 AI에 훨씬 더 유리함 MCP(몰입형 제어 프로토콜)를 보면 tool discoverability가 얼마나 강력한지 알 수 있음 HATEOAS가 이런 bare API 소비에도 큰 잠재적 이점을 줄 수 있음
          + 미국 기상청의 RESTful 서비스 API 문서 링크처럼 공개정보 API가 잘 설계되어 있으면 정말 쾌적함
     * ""진짜 하이퍼미디어 기반 클라이언트를 만드는 초기 인지부하가 거대하게 느껴졌고, 그냥 URI 템플릿(/users/{id}/orders 등)을 하드코딩하는 편이 편하게 느껴졌다""는 내용과 관련해, 실제로 그게 더 쉬운 일임을 경험적으로 체감함 순정 REST 원칙은 대다수 상황에서 비용 대비 효용이 떨어짐 마치 전자레인지에 하나의 버튼으로 메뉴/작동방식/시간을 다 조작하는 방식이, 그냥 표준 버튼에 기능을 익숙하게 쓰는 것보다 훨씬 번거로움 내가 실제로 쓰는 2버튼 엔진 코드 리더기도 어이없이 조작이 불편함 아직도 Fielding 논문을 반드시 읽으라 하는 문화는 좀 심각한 논란거리임 좋은 아이디어라면 다양한 방식, 대중적 시각으로 쉽게 설명되어야 함 예를 들어, 물리를 이해하려면 Newton의 Principia를 반드시 읽으라는 사람은 없음
     * RESTful/HATEOAS 패턴을 도입할 때 진짜 가치가 있으려면, 이를 이해하는 클라이언트가 필요함 htmx: hypermedia clients intercoolerjs: hatoeas-is-for-humans
     * UI 디자이너들은 화면의 세부적인 룩을 통제하고 싶어함 리소스에 가능한 어떤 액션은 큰 버튼으로, 어떤 것은 메뉴에 숨기거나 UI에 아예 표시하지 않을 수도 있음 액션이 특정 상태마다 동적으로 API 응답 기반으로 렌더링된다면, 모든 액션이 똑같이 보이게 됨 그래서 RESTful API는 흔한 웹 프론트엔드 UI 구현에는 부적절하다고 봄
          + 이 주장에는 다수 오류가 있음
              1. UX 디자이너는 제품 개발 주기 전체에 관여하며 무조건 통제권을 갖고 있진 않음. UI 내 특정 액션 배치는 액션의 ""state""와 별개임. 즉, 상태가 제한하면 UX도 그 제약을 따라야 함
              2. 아키텍처적으로 상태 체크를 래핑하면 ""if (state === something)""만큼 ""if (resource.links['action'] !== null)""이 훨씬 낫기도 함. 대부분의 state 변화는 서버에서 validation이 필요하고, 이를 서버에만 구현하면 프론트 복잡도도 낮아짐 나는 HATEOAS 앱을 꽤 오래 개발했고, HAL4J도 관리 중임. 복잡성은 있지만 UI 디자인 자체가 진입장벽은 아님
          + 내 경험상, ""RESTful API"" 개발이 UI랑 직접 연관되는 일은 많지 않았음 진짜 UI만 필요하다면 API 자체가 불필요함, 그냥 서버 주도 방식(옛날 DWR 등)으로 해도 됨
     * HATEOAS가 현실에서는 거의 쓰이지 않는 것 같은데 왜 아직도 이렇게 논의되는지 잘 이해가 안 됨 정말 이걸 쓰는 곳이 있는지, 그리고 실제로 어떤 ""자동 탐색 클라이언트""가 서버 정보를 사전에 몰라도 되는지 궁금함
          + ACME(Let’s Encrypt의 프로토콜)가 HATEOAS 기반임을 상기함. 이건 사실상 대부분의 HTTPS 서비스에서 사용됨 HTTP 자체도 원래 제대로 쓰면 HATEOAS 프로토콜임 ""auto-discovery""는 링크 타입이나 ‘next’ 등으로 리소스 탐색이 가능한 것임. 단, 클라이언트가 ""next"" 의미는 사전에 알고 있긴 해야 함 LLM도 이런 자동 탐색에 강함
          + 엔터프라이즈급 비디오 감시 시스템에서 HATEOAS를 활용했었음 버전/권한 문제를 API 레벨에서 훌륭하게 해결했음 여러 RFC도 같이 활용함 다만 문제점 1순위는 사람들이 모델을 무너뜨리는 방향으로 ""편리함""을 추구하다가 오히려 복잡성을 유발함 또, JSON은 본질적으로 하이퍼텍스트 포맷이 아니라서, application/json에 HATEOAS를 강제로 심으려고 하면 억지스러웠음
          + HATEOAS를 사용해 댓글을 입력하고 있고, 바로 지금 답글도 달고 있음 이걸 처리하는 ""마법의 자동 탐색 클라이언트""는 바로 ""웹 브라우저""임
          + htmx가 가장 현실적인 시도일 수 있음
          + OData 같은 표준도 거의 안 쓰이고, 그나마 popular하지도 않음 HATEOAS는 인기/표준도 부족해서 더더욱 확장되지 않는 듯
     * 언제나 이 논의에서 놓치기 쉬운 건 백엔드 API 소비자의 유형임 REST와 HATEOAS는 보통 백엔드를 직접 소유하지 않는 서드파티가 소비할 때 의미가 커짐 예로 전통적인 HTML 페이지의 최종 소비자는 브라우저 사용자임 최근의 MCP도, 다양한 JSON RPC API에 대해 ""디스커버리와 해석""이 필요한 케이스라 등장함 반면 프론트와 백엔드가 1:1로 맞물릴 경우 REST의 이점이 비용 대비 크지 않음 더 generic하게 문서화/스펙을 짜야 하고, 실무에서는 separation of concerns를 무시하고 생산성을 높이려는 도구(trPC 등)가 오히려 유용할 때가 많음 프로토타입 시에는 end-to-end 통합이 빠름
          + 굉장히 동의하고, HATOEAS is for humans htmx: hypermedia clients 글 추천함
          + *HATEOAS
     * HATEOAS와 schema reference(XSD, JSON Schema 등)로 동적 탐색 클라이언트가 가능하다는 주장에 대해, 현실적으로 JSON schema의 ""additionalProperties"" 같은 기능이 오히려 문제의 원점을 반복하게 함 ""out of band"" 방식으로 문서 전달하는 게 더 견고하다고 봄 그렇다면 만약 ""_links""에 단순히 Swagger 문서 링크 하나만 제공하고, 그 self path 정보를 클라이언트가 소화하게 하면 어떨까? 그럴 거라면 ""_links""가 왜 존재해야 하지? 그렇게 복잡한 JSON 문서를 다루는 클라이언트가 있다면 오히려 Swagger 템플릿 등으로 훨씬 더 정보밀도, 동적성이 뛰어남 CRUD 링크만 가지고는 API 전체를 제대로 설명하기 부족하며, JSON schema로 모든 걸 커버하는 것도 불가능함
     * 그냥 HTTP API라고 부르면 모두가 행복해짐 REST 자체는 애초에 API용으로 설계된 게 아니었음 애초부터 REST는 사람이 받는 정보시스템을 위한 것이지, 프로그램을 위한 건 아니었음
"
"https://news.hada.io/topic?id=21867","AGI가 곧 올 것 같지 않은 이유","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          AGI가 곧 올 것 같지 않은 이유

     * 글 작성자는 AGI(범용 인공지능) 가 가까운 시일 내 등장할 것이라 보지 않음
     * LLM(대형 언어 모델) 은 뛰어난 능력을 보여주지만, 인간처럼 지속적으로 학습하며 점진적으로 개선하는 능력이 부족함
     * 현 LLM은 사용자 피드백을 통해 맞춤화하거나 맥락을 쌓는 데 한계가 있으며, 이는 실제 사무직 자동화에 큰 장벽임
     * 컴퓨터 사용 및 멀티모달 데이터 등 현실적 과제들은 데이터 부족, 긴 작업 시간, 기술적 난이도 때문에 발전 속도가 느릴 것으로 전망됨
     * 장기적으로 온라인 학습이 가능해지면 매우 급격한 변화가 발생할 것이라고 기대하지만, 향후 10년 내에 쉽게 실현될 것으로 보지 않음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

인트로 및 AGI 예상 시점 논의

     * 글 작성자는 다양한 전문가들과 AGI 도달 시점에 대해 논의한 경험을 바탕으로 자신의 견해를 제시함
     * 일부에서는 2년 후, 또는 20년 후에 AGI가 등장할 것이라 예측하지만, 본인은 2025년 6월 현재로서 AGI가 곧 도래한다고 판단하지 않음

지속적 학습(Continual Learning)의 한계

     * 많은 사람이 현 AI 기술만으로도 경제적으로 인터넷보다 더 변혁적이라는 입장을 보이지만, 글 작성자는 이에 동의하지 않음
     * Fortune 500 기업들이 LLM을 업무 근본적으로 혁신하는 데 활용하지 못하는 이유는 경영진의 보수성 때문이 아니라 현 AI의 지속적 학습 결여 때문임
     * 필자가 다양한 LLM 기반 도구를 직접 구축하고 활용하는 과정에서, LLM은 반복적 업무에 있어 5/10 정도 성과를 내지만 점진적 개선능력이 부족함을 확인함
     * 인간은 맥락 구축, 스스로의 실패 분석, 반복을 통한 소소한 개선 습득 등 능력을 통해 생산성이 발전하지만, LLM은 고수준 피드백 전달 경로가 부재하며, 프롬프트 조정만으로 인간식 ‘학습’이 불가능함
     * RL(RLHF) 파인튜닝이 있긴 하지만, 인간과 같은 적응적이고 유기적인 학습과는 거리가 멀며, 이는 실무 자동화에서 결정적 제약 요소임
     * AI 모델이 인간 직원처럼 업무 중 풍부한 맥락을 쌓고 기억하며 성장하는 방식은 아직 실현방안이 부족함
     * 세션 내에서는 일부 맥락 학습이 이루어지기도 하지만, 세션 종료 후에는 모든 학습된 맥락이 소실되는 한계 존재
     * 장기 기억(rolling context window) 같은 해법이 시도되지만, 풍부한 경험적 지식의 요약은 브리틀(취약) 하며, 텍스트 기반 도메인 외에서는 더욱 비효율적으로 작동함
     * AI 발전이 현 수준으로 정체될 경우에도 많은 사무직 업무가 해당 기술로 대체되기는 어렵고, 인간 직원이 가진 맥락 학습력이 경쟁력임
     * 즉, 지속적 학습 기술이 실제로 구현되는 시점에야 AI의 가치가 불연속적으로 급상승하며, 궁극적으로 이 기술이 가능해지면 복수 인스턴스 간 학습 공유를 통해 인간보다 빠르게 슈퍼인텔리전스화가 가능함
     * 그러나, 연구실은 혁신 기술을 완전하게 완성하기 전에 불완전한 버전을 먼저 공개할 동인도 크기에, 지속적 학습의 진정한 도약이 일어나기 전 징후가 나타날 것으로 예상함

컴퓨터 사용 및 자동화의 현실적 어려움

     * Anthropic 연구원들과의 대화에서, 2026년 말까지 신뢰성 높은 컴퓨터 사용 에이전트가 등장할 것이라는 예측을 들었으나, 필자는 이에 회의적임
     * 현재도 컴퓨터 사용 에이전트가 존재하지만 실제로 다루기엔 효율성이 낮음
     * 세금 신고 같은 실제 과업을 자동화하려면, 다중 시스템, 장시간 에이전트 실행, 다양한 멀티모달 데이터 처리가 필요하며, 이는 학습 및 검증 프로세스를 매우 느리게 만듦
     * 기존 텍스트 프리트레이닝 데이터(즉, 언어 모델에 사용한 대용량 인터넷 문서 등)와 달리, 다중모달 컴퓨터 사용 데이터셋은 부족하여, 신뢰도 높은 에이전트 개발에 시간 소요가 예상됨
     * 새롭게 제안되는 혁신적인 알고리듬도 실제 현장 적용까지 다년간의 엔지니어링 조정이 필요해, 컴퓨터 사용 과제의 발전이 상당히 느릴 것임

추론능력의 고도화와 한계

     * Gemini 2.5 등 최신 모델들은 화자의 의도 해석, 논리적 자기검증, 맥락 반응 등에서 실제로 추론 능력을 보임
     * Claude Code 등이 주어진 스펙만으로 동작하는 코드를 빠르게 생성하는 등, 분명 넓은 도메인에서 초보적 ‘범용지능’의 기미가 감지됨
     * 최상위 수준 LLM 모델이 능력을 보여주는 도메인에서는 제법 인상적인 성과를 내기도 함

단기 및 장기 AI/AGI 예측

     * 필자는 자신의 예측에 대해 확률적 시각을 견지함을 강조하며, 이에 따라 대비책 마련은 여전히 타당함을 언급
     * 아래 항목에 50% 확률로 베팅할 의향이 있음
          + 2028년까지: AI가 소규모 기업의 세금 신고 전 과정을 완결적으로 처리할 수 있는 수준에 도달 가능성 존재
               o 현재 컴퓨터 사용 능력은 GPT-2 수준에 머물러 있으며, 데이터 부족 및 긴 타임호라이즌으로 인한 최적화 난이도가 높음
               o 멋진 데모는 2026~2027년에도 등장하겠지만, 완전히 자율적으로 장기간 복합 과업을 수행하는 수준은 어려움이라고 예상함
          + 2032년까지: AI가 인간과 같이 업무 중 자연스럽고 점진적으로 학습하여 몇 개월간 실무 적응 후 인간만큼 맥락과 선호, 노하우 내재화가 가능한 시점 도래 가능성
               o 온라인 연속학습 구현이 가까운 시점에는 보이지 않더라도, 7년이라는 기간 동안 본질적인 돌파구가 마련될 수도 있음

AI 발전의 제한 요인 및 미래 전망

     * AGI 실현 시점은 확률적으로 매우 넓게 분포(로그정규) 되며, AI 발전은 지난 10년간 연산량(트레이닝 컴퓨트) 증가와 밀접한 연관이 있었음
     * 연산량 증가는 2030년 이후에는 한계점에 도달할 것으로 예상되며, 알고리듬 혁신이 병목 역할을 하게 됨
     * 혁신적인 패러다임 전환이 없다면, 연도별 AGI 등장 확률은 시간이 갈수록 감소할 수 있음
     * 만약 ‘긴 쪽’에 베팅이 맞는다면 2030~2040년까지 일상세계가 크게 변하지 않을 가능성도 있으나, 반대로 현 AI 한계를 극복한다면 매우 급진적인 변화가 일어날 수 있음

   지속성과 학습에 물리적인 제한이 있기 때문에 AGI가 실현되지 않는 것이라 생각함
   말 그대로 물리적인 제한이 있어서지 기술력이 부족해서가 아님
   그러한 제한을 두지 않아서 AGI로써 한걸음 나아가게 된다면 그떄는 다시 되돌리기가 어렵고 AI 개발자들도 그것을 알기 때문에 서비스 맞춤형으로 발전시킬 뿐 그 제한을 풀려고 하지는 않는다고 생각함

   I totally agree with you!

        Hacker News 의견

     * “LLM은 시간이 지나면서 인간처럼 점진적으로 더 나아지지 않는 근본적 문제가 있다는 점이 정말 중요한 포인트라는 생각을 함 LLM의 기본 성능은 여러 작업에서 평균 인간보다 높을 수 있는데, 모델에 고차원 피드백을 줄 방법이 전혀 없어 박스에서 꺼낸 상태 이상의 개선이 안된다는 문제점이 있음 신경망에서 흔히 나타나는 한계라고 봄 Waymo의 Driver 같은 시스템은 이 문제를 피함 예를 들어 Waymo는 운행 중 문제가 생기면 다양한 시뮬레이션을 돌려 문제 상황을 여러 형태로 변형해서 Driver에게 다시 학습시키는 절차를 가지고 있음 정확히 방식은 공개하지 않았지만, 이것이 엔드투엔드 신경망과는 다른 구조라고 언급 Waymo 내부 프로젝트로 엔드투엔드 신경망을 시도했으나 지금 시스템보다 좋지 않았기에 지금은 뭔가 다른 것을 사용하는데, 구체적으로
       뭔지 아는 사람은 극소수임”
          + “LLM이 인간처럼 점진적으로 발전하지 않더라도 Prolog 같은 도구를 사용해 역량을 확장할 수 있다는 점이 중요함 AI의 다음 단계는 LLM이 더 나은 도구나 전략을 사용할 수 있게 하는 것이라고 생각함 예를 들어 논리 규칙, 휴리스틱 알고리즘, 미세조정된 LLM 에이전트들을 하나의 아키텍처로 통합해서 LLM의 툴로 활용하는 구조가 성숙할 거라 봄 경제적 압박이 특히 군사용 AI 개발을 촉진하고 있다는 점도 주목해야 함 Prolog 시스템을 활용하면 LLM이 데이터베이스에 사실을 추가하고, 새로운 관계를 추론하면서 지속적으로 학습 가능 탐색을 위한 새로운 모델이나 방식을 제안하는 휴리스틱 도입도 가능”
          + “내가 알고 있기로 Waymo는 휴리스틱, 규칙, 신경망 등 다양한 기법을 인간이 조합해서 만든 시스템임 완전한 엔드투엔드 신경망은 아님 AIish라는 표현이 좋은데, 설계상 AGI와는 거리가 있음”
          + “많은 사람이 왜 다음과 같은 질문을 거의 하지 않는지 의아함: 현재 최첨단 AI가 이미 인간을 훨씬 더 뛰어나게 만들어주고 있는 것 아닌가? 자기 개선의 기하급수적 가속은 오히려 무서운 일이라 생각함 만에 하나 모든 일이 제대로 된대도, 인간은 더 이상 지적 경쟁의 1등 자리를 유지하기 어렵고, 그건 받아들이기 힘든 변곡점일 것임 만약 정말 자기 개선을 원한다면, 인간 스스로 쓸모없어지는 것에 익숙해질 필요가 있음”
          + “신경망 한계가 궁금하다면 John Carmack의 최근 강연을 보면 좋음 유튜브 링크 30분 근방에서 이 문제를 직접적으로 다룸”
          + “대부분 AI는 거대한 데이터로 학습하므로, 다음 대규모 데이터셋이 준비되기까지 시간이 오래 걸리는 구조라는 점이 한계임”
     * “AGI(범용 인공지능)가 곧 등장한다는 말을 하는 사람은 대체로 1. 무언가를 팔려는 사람이거나 2. 자신의 이야기에 심취하거나 3. 다른 이유로 들떠 있거나 4. 셋 다일 확률이 높음 LLM은 설계상 언어에 강점이 있고 텍스트 요약은 괜찮지만, 논리에 약하고 공간적 추론에 매우 취약함 그래서 개념 연결도 잘 못함 유명 LLM에 ‘분야 막론 가장 어려운 미해결 과제가 뭐냐’고 물어보면, 과학 잡지형 기사는 나오더라도 미묘하지만 결정적인 오류가 가득하고 답변이 그럴싸해 보여도 실제론 쓰레기임”
          + “LLM은 학습 데이터셋을 압축한 후 텍스트 기반 상호작용 검색 기능을 제공하는 툴에 불과함”
          + “‘불분명하다’는 표현이 핵심이라고 생각함 LLM이 전반적으로 지능적이긴 해서 내 기준에선 AGI 시대에 진입했다고 느끼지만, 아마도 많은 사람들이 AGI를 ‘초인간적 AI’로 보는 듯 그 기준이라면 우린 아직 도달한 게 아니고, 앞으로도 쉽지 않을 듯 나한테는 지금이 이미 AGI 시대임”
          + “LLM은 우리가 만들어낸 텍스트 세계에선 정말 훌륭하게 동작하지만 진실을 추구하는 존재는 아님 생명체는 치명적인 실수에 죽음을 맞이하지만, AI는 틀려도 수천 개의 토큰을 생성할 뿐임”
          + “진실 추구 부족이 LLM 문제라는 지적에 동의하지만 인간에도 그런 모습이 많으니 대단한 비판처럼 들리진 않음 애초의 AGI 정의(인간 중간값 이상의 거의 모든 작업 수행) 기준이라면 지금 꽤 근접했고, 향후 5년 이내에 비신체적 작업에선 전문가 수준의 경쟁이 가능할 듯(신체적 작업은 5–10년 소요 예상) LLM이 언어에 강하다는 건 맞지만, 그게 곧 지능 수준을 반영한다고 봄 공간적 사고에 약하다는 평가도 과장된 부분이 있다고 보고, 이전의 공간 추론 전용 모델보다 훨씬 나아졌음 인간보단 못해도 최신 모델을 로봇에 적용해 실제로 작동한다는 것만으로도 AI 기준에선 급격히 발전 중임”
          + “내가 생각하는 AGI 정의는 AI가 해당 분야 전문 인력 중 최소 5%보다 거의 모든 업무에서 낫다면, AGI에 도달한 것으로 간주 인간 하위 5백분위의 지적 능력도 ‘지능’으로 부를 만하다고 생각하는데, 만약 AI가 이보다 상당수 인류보다 전 영역에서 뛰어나다면 AGI라고 불러야 함 단일 영역이 아닌 모든 지적 과업에서 더 뛰어난 AI여야 함”
     * “나는 AGI가 곧 등장하지 않기만을 희망함 사회·정치적으로 준비가 전혀 안 된 상태이고, 자칫하면 인류 미래가 디스토피아로 빠질 위험이 큼 그런데 지금 AI에 약간의 전력 소모 감소와 사소한 개선만 돼도 이미 다양한 분야에서 쓸모가 매우 높아지고 있는데, 이것만 해도 아직 인간 사회가 다 받아들일 준비가 안 되어있음 문제는, 기초 모델을 만드는 기업들이 지금까지 쏟아부은 돈을 제대로 회수할 명확한 방안이 드물어서, 대대적인 돌파구나 무리해서 다수 분야에 AI를 밀어붙이는 수밖에 없어 보임”
          + “나도 같은 마음이고, 이 거품이 곧 꺼지기를 진심으로 희망함 Meta가 증강현실에 1,000억 달러 투자했다는 소식이 있는데, 저기 보드에 앉은 그 친구가 무모하게 광고비 절감 대신 도전만 반복하는 모습임 Altman 같은 인물도 이제는 후퇴가 불가능한 길을 선택했고, 기회 있을 때 최대한 돈을 챙기려 할 것임 우리 모두에겐 이런 사람들이 예전 닷컴버블처럼 실패하길 바랄 뿐”
          + “AI 투자 규모가 많다보니 감가상각비만 해도 전체 AI 회사의 매출 합계보다 클 정도인데 이런 고정비용을 회수할 방법을 많은 사람들이 간과하고 있음”
          + “만약 AI 한 대로 거의 직원이 없이 업계를 완전히 대체할 수 있다면, 비용 회수는 아주 쉽다고 봄 엄청난 이익이 될 수 있음”
          + “저출생 문제가 정말 심각하다고 생각한다면, AGI가 곧 등장하는 게 오히려 해결책이 될 수 있다고 봄 영원한 인구 성장만을 전제로 경제 문제를 해결하려는 패러다임에 대한 재고가 필요함”
          + “AGI가 인간 지능과 정확히 같아야 하나? 어떤 기능은 뛰어나고 어떤 기능은 부족해도 AGI로 여길 수 있나 고민됨”
     * “AGI가 곧 나오기는커녕, 아예 실현 가능한지도 확신하지 못함 최소한 전통적 컴퓨터 하드웨어로는 어렵다고 생각함 정보를 보기 좋게 되풀이하는 능력만으로는 지능 정의나 측정이 되지 않는다고 봄 만약 인공지능을 진정 구현한다면, 처음 선보일 때 인간 기준에선 매우 낮은 지능일 수 있지만 외부 도움 없이 스스로 학습 가능한 진정한 AI일 수 있음”
          + “인간의 일반지능이 뭔가 초자연적이고 측정 불가능한 요소 때문이라고 믿지 않는 한 AGI 불가능론은 기각된다고 생각함 결국 인간도 기계니까 뇌가 생물학이 아닌 방식으로 복제 가능하다고 봄 어쩌면 최초 AGI는 페트리디쉬에서 자란 뇌에 파이썬 API만 달린 존재일 수도 있고, 혹은 실리콘 기반일지도 모름”
          + “다른 측면도 고민해봐야 함 도구가 내가 가진 지능보다 높아진다면, 어떻게 대처해야 할지 고민임 온라인에선 동료가 질문 받을 때 chatgpt로 답을 받고, 그 질문조차 chatgpt가 만든 경우도 나와서 이제 누가 뭘 했는지 아무도 모르는 상황이 만들어짐”
          + “내가 생각하기엔 지능의 확장 한계는 연산 자원에서 온다고 봄 시스템을 잘 모델링하기 위한 계산량은 복잡하거나 혼돈스러울수록 거의 지수적으로 늘어남 따라서 지능의 효과는 본질적으로 단순하고 질서 있는 시스템에만 나타날 수 있음 가장 실용적이고 견고한 방식이란 변동요인 최대한 제거하는 것임 결국 그게 초지능이든 아니든 지능의 진짜 한계점임”
          + “왜 불가능하다고 생각하는지 궁금함”
          + “AGI에 대한 명확한 정의나 합의가 없는 상태임 앞으로도 AI가 잘하는 분야(텍스트·이미지 생성, 코드 생성 등)에서 점진적 개선만 계속될 것이라 봄 AI가 모두의 문제를 다 해결하고 인류가 해변에서 유토피아식 번영을 누린다는 환상은 전혀 현실 기반이 없음”
     * “Dwarkesh의 관점이 인상적임 항상 그가 어디까지 발전했는지 듣는 게 즐거움 그의 핵심 주장에 따르면, 적응적 학습이 필요하지만 그 조짐이 보이지 않는다고 함 내 추측엔, 프론티어 랩들은 긴 컨텍스트가 문제를 해결할 것으로 기대 긴 컨텍스트 1천만 토큰이면 내부 상태를 잘 유지하며 다양한 작업을 소화할 수 있고, 현재는 긴 컨텍스트 모델일수록 창(window)마다 품질 변동이 크다는 한계가 있음 질문을 바꿔보면, 2년 안에 1천만 토큰 이상의 유용한 컨텍스트 창을 가질 수 있을까? 가능성 높다고 봄”
          + “이 문제를 해결했다고 주장했던 회사가 있었는데, 지금은 조용함만 들림”
          + “‘긴 컨텍스트’라면 얼마나 길어야 하는지 질문이 남음 실제 인간의 경우 수십 년에 걸친 멀티모달 입력을 컨텍스트로 삼음”
          + “Demmis가 AGI는 10년 내 도달한다는 말에 믿음을 가짐 그는 해당 분야를 오랜 기간 개척했고 OpenAI조차 Demmis의 연구 속도에 대해 두려워하며 설립된 면이 있음 Demmis의 예측을 신뢰하는데, 2035년 쯤에는 인간과 거의 모든 작업에서 동등하거나 뛰어난 AGI가 등장할 거라 함”
          + “곧 (<5년) 진정한 테스트 타임 러닝을 도입할 것이라 확신 Alphaproof(Deepmind의 IMO 챌린지)에는 이미 이 기법이 적용됨”
     * “미국 성인 54%가 전국적으로 6학년 이하 독해력을 가진다는 통계가 있음 AGI는 이미 도달한 것 아닐까 생각함 위키백과 링크”
          + “한 나라의 교육 실패와 AGI가 연관이 있나 의문임”
          + “좋은 지적임 그럼 LLM이 빨래하고 설거지하는 것도 지켜보고 싶음 만약 로봇으로 신체를 만들더라도 쉽지 않을 것임”
          + “읽을 수 있다는 게 AGI의 조건 전부인가 생각하게 됨”
          + “경제적 관점에서는 AGI와 일반 노동자, 예를 들어 카피에디팅처럼 특정 업무에 투입되는 인력과의 비교가 더 현실적임 실제 고용될 가능성이 낮은 전국 평균보다는 직무 적합성에 초점을 맞춰야 함”
          + “문맹인 사람들도 LLM이 못하는 엄청난 도전과제를 해결할 수 있음”
     * “AI의 발전 논의에서 미래 AI가 인간과 동일 방식으로 문제를 해결할 것이란 가정이 문제임 이 경우, 연속적 학습 부재가 치명적 결함처럼 보임 실제로는 딥러닝 발전사에서 연속학습이 주도적 역할을 해온 적이 없고, 대규모 데이터셋과 확장이 가장 성공적인 방식이었음 연속학습이 필수라는 주장이 설득력 있으려면, 크로스태스크 학습 방식의 한계와 AI가 절대 달성 못할 영역을 구체적으로 밝혀야 함 저자는 RL flywheel(우수한 프로그래밍 AI가 RL을 반복 적용할 때 가속 효과)에서의 불확실성을 언급하면서 본문 전체가 너무 자신만만하게 들리는 면이 있다고 생각함”
          + “Alphaproof는 매 문제마다 알파제로 방식의 테스트 타임 트레이닝을 활용해 유사 문제를 생성하는 방식을 사용했음”
          + “연속학습이 딥러닝 발전사에 중요하지 않았던 이유는, 딥러닝 종사자들이 목표 자체를 다르게 잡았기 때문일 수 있음 가장 지능적인 AI가 아니라 가장 유용하고 생산적인 AI를 목표로 삼아야 한다면, 지능 자체보다 바보더라도 실패에서 배우는 존재가 종종 아집 강한 천재보다 가치있을 수 있음”
     * “내 관점엔 현재 LLM은 인간이 할 법한 말을 예측하는 구조라서 지능/추론력도 인간 수준에 머무를 거라 봄 지식의 폭은 인간을 넘어설 수 있어도 지능이나 창의력은 인간과 맞먹거나 못할 수 있음 AI 기업들은 차세대 LLM이 새로운 인사이트와 미해결 문제를 해결할 것이라 예측하지만, 진짜 인사이트는 하위 원리로부터 개념을 자유롭게 재생성할 수 있는 내부 구조가 필요하다고 봄 LLM은 새로운 이해 계층을 쌓을 수 없기에 한계가 존재 실제로 인간 뇌처럼 입력으로부터 추상적 이해까지 쌓아올리는 방식이라면 한계를 넘을 수 있을 것으로 봄 언젠가 새로운 AI 패러다임이 등장해서 LLM을 압도할 수도 있는데, 솔직히 예상이 빗나가길, 또는 ASI(초지능 인공지능)는 좀 무서움”
          + “인간 수준 AI 성능이 나온다 해도 머신은 인간과 달리 GPU 성능만 높이면 바로 10배 빠른 인공지능을 얻을 수 있음 속도 자체만으로도 초인간 역량이고, 심지어 한 시스템을 여러 번 돌려 다양한 접근법을 동시에 탐구해서 최적 방안을 고르는 것도 가능함 검증 가능한 작업에서는 엄청난 우위”
          + “현 LLM은 단순 인간 문장 예측기가 아닌, 수학·프로그래밍 문제에 정답과 연관된 토큰을 예측하는 쪽으로 진화 중임”
     * “대부분 논의가 AI에 비관적인데, 정작 저자는 2030년대 초까지 AGI 달성 확률이 50%라 언급했고, 2028년까지 ASI가 잘못된 방향으로 발전할 가능성도 대비해야 한다 언급 즉 저자가 AI에 대해 오히려 낙관적임”
          + “3년 안에 ASI가 잘못 작동한다면, 어떤 대비책도 무의미해질 거라 생각함”
     * “최근 누구도 모델 규모를 공개하지 않는 현상에서 이미 모델 훈련이 한계(벽)에 부딪쳤다는 신호를 읽을 수 있다고 생각함”
"
"https://news.hada.io/topic?id=21862","게임 개발 2년 반의 경험","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             게임 개발 2년 반의 경험

     * 개발 8년차에 게임 개발 업계로 커리어를 전환하여 약 3년 근무하며, 업계 내부의 열정적인 분위기와 독특한 문화를 직접 체감하게 됨
     * 게임 업계는 창의성과 예술성이 중요한 역할을 하며, 다양한 분야의 아티스트와 개발자들이 협업함
     * 대형 스튜디오와 인디 스튜디오 모두에서 프로젝트 주기가 길고 개인의 창의적 기여 기회가 제한될 수 있음
     * 조직의 성숙도와 성장 규모에 비해 내부 프로세스나 기술 체계는 타 산업에 비해 완전히 성숙하지 않은 측면을 가짐
     * IT 업계와 달리 게임 개발은 프로젝트와 개인의 이력이 밀접히 연결되며, 이 업계만의 독특한 도전과 보람이 공존함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론

     * 약 3년 전 아무런 게임 개발 경험 없이 게임 회사(Riot Games)에 입사했음
     * 통계적으로 봤을 때 이 기간은 게임 하나를 출시하기에도 충분하지 않지만, 다양한 경험과 내부인의 이야기를 통해 게임 업계를 바라보는 시야가 넓어졌음
     * 개발자로서 전통적인 경로에서 벗어나 새로운 산업에 진입하며 느낀 점과 관찰한 내용을 공유함

배경

     * 청소년기와 대학 초기에 게임 개발을 꿈꾼 적은 있었으나 실제로 행동에 옮기지 않았음
     * 졸업 후에는 전통적인 엔터프라이즈 개발자 경로인 작은 제품 회사, 더 큰 회사, 지역 빅테크, 다국적 대기업에서 경험을 쌓음
     * 게임 산업은 주로 외부에서 관심 있게 지켜보며 직접 일해 본 적은 없었음
     * 3년 전 여러 오퍼 중 국제 게임 개발사에 입사하면서 본격적으로 게임 업계에 발을 들임

I. 게임에 대한 열정이 핵심

     * 게임에 대한 열정이 필수라고는 하지만, 게임 업계 내부의 진짜 열정은 예상보다 훨씬 더 체감 강도가 강함
     * 일반 IT 업계와 달리, 대부분의 직원들이 신작 게임을 플레이하고, 게임 출시 일정에 맞춰 휴가를 내며, 업계 소식이 끊임없이 회자됨
     * 게임을 좋아하지 않아도 근무할 수 있으나, 회사 규모와 역할에 따라 내부와의 동기화에 한계가 있을 수 있음
     * 작은 스튜디오일수록 실제 게임과의 직접적인 연관이 높아 비게임 유저로 일하기 어려움
     * 최근에는 게임에 큰 관심이 없더라도 특정 직무에서는 진입 장벽이 많이 낮아진 추세임

II. 창의성 중시

     * 예술과 창의성의 비중
          + 게임에는 아트와 창의성이 필수적으로 녹아있으며, 2D, 3D, UI/UX, 오디오 등 다양한 아티스트들이 활약함
          + 사내 행사나 미팅에서 아트와 크래프트가 자연스럽게 드러나고, 아트워크와 코스프레, 음악, 디지털 작업 등이 자주 등장함
          + 디자인이나 예술적 배경이 없는 사람은 위화감을 느낄 수도 있으나, 다양한 배경의 사람들이 공존함
     * 비기술 직무의 경력 성장
          + 뛰어난 아티스트가 기술직보다 더 높은 연봉을 받는 사례도 존재하나, 순수 실무 아티스트로 오랫동안 승진하는 것은 한계가 있음
          + 조직에서의 승진과 영향력 확대는 리더십과 매니지먼트 역할로의 전환이 필요하며, 이는 창의직군에서는 더 도전적인 일임
          + 경력 성장과 승진의 주요 포인트가 '제품적 성공'보다는 '창의적 성과'에 더 강조됨

III. 높은 창의적 범위에 대한 기대와 현실

     * 창의성에 대한 열정이 강점이 될 수 있지만, 크리에이티브한 역할에도 주어진 창의적 범위의 한계가 존재함
     * 소규모 스튜디오나 인디 개발에서는 개인의 영향력이 크지만, 대기업이나 빅테크에서는 한정된 역할에 국한될 수 있음
     * 창의적 기여 범위가 좁을수록 이직이나 독립을 선택하는 사례가 많음
     * 기술 직군은 새로운 도전 과제가 많아 비교적 창의성 발휘의 폭이 넓음

IV. 업계의 성숙도와 성장

     * 게임 산업의 성장과 변화
          + 게임 업계는 내부적으로는 '스튜디오', '프로듀서' 같은 자체 용어와 문화를 유지하지만, 외형적으로는 매우 성숙한 산업에 진입함
          + 전에 비해 규제와 책임이 집중되는 경향이 높아졌으며, 실제 소유권이나 디지털 라이선스 문제도 대두됨
          + 산업적인 성장 속도와 내부 조직 문화 간의 괴리가 발생하고 있음
     * 성숙하지 않은 프로세스
          + 일부 대형 게임사는 수천 명의 직원이 있지만, 여전히 비체계적이거나 작은 조직의 관성을 유지하는 경향이 있음
          + 프로젝트 관리, 프로세스, 스케일러빌리티 등 경험적 노력보다 개인의 강한 리더십에 의존함
          + 규제와 비즈니스 볼륨이 늘어난 만큼, 업계의 프로세스 개선과 체계화가 필요함

V. 긴 개발 주기

     * AAA 게임 개발에는 5~7년 이상의 긴 개발 주기가 소요됨
     * 단일 스킨(코스튬, 무기 등) 제작에도 최대 1년이 걸릴 수 있음
     * 스타트업식 '빠른 실패' 문화를 기대하기 어렵고, 대부분 완성된 결과물 위주의 개발 환경이 형성됨
     * 이런 장기 개발 문화는 번아웃, 분쟁, 열정 소진과 경력 성장의 어려움을 가중시킴

VI. 프로젝트 중심의 경력

     * 게임 업계에서는 자신이 속한 회사보다 참여했던 게임 프로젝트가 더 중요한 경력 지표로 여겨짐
     * 게임 출시 경험의 유무가 이력서에서 매우 직결되는 만큼, 출시 실패 경험이 장기 경력에 부정적 영향을 줄 수 있음

VII. 기술

     * 기술적 특징과 우선순위
          + 게임 업계의 기술 채택 속도는 일반 IT에 비해 느리고, 창의성이 우선순위를 가짐
          + ""게임 업계는 원래 이래""라는 문화와 관성이 남아있지만, 비게임 산업 출신들은 비효율을 지적함
          + 그래도 게임 산업만의 특이한 기술 문제와 깊이 있는 도전이 있어, 엔터프라이즈 개발과는 다른 재미와 난이도가 존재함
     * 테크 아트
          + Tech Art는 예술과 기술의 경계에 있는 역할로, 셰이더 개발, 파티클 시스템, 모델 리깅, 3D 텍스처링, 성능 최적화 등을 포함
          + 영화·엔터테인먼트 산업에서도 수요가 높지만, 게임 분야에서 기술적·예술적 융합이 가장 많이 드러남
     * 콘텐츠 툴과 파이프라인
          + 아티스트와 개발자, 다양한 팀이 플러그인, 에디터, 파이프라인, 콘텐츠 관리 도구를 통해 협업함
          + 대형 프로젝트일수록 전용 빌드·CI/CD 시스템의 복잡성과 중요성이 증가함
     * 테스트
          + 게임 테스트(QA) 는 타 산업보다 비중이 클 뿐 아니라, 자동화 전환보다는 수동 및 시각적 QA가 많이 필요함
          + 게임 특성상 시각적 요소와 콘텐츠 품질이 수익에 직결되고, 맞춤형/비정형 테스트가 필요함
          + 일부 장르에서는 AI 기반 자동화 테스트도 도입되어 그 효율이 입증됨
     * 하드웨어와 플랫폼
          + 그래픽 성능에 중요한 만큼 고성능 PC, 특히 Windows 기반 환경이 표준임
          + MacOS, Linux 지원에 한계가 있으며, 윈도우 특화 도구 사용 경험이 요구됨

결론

     * 짧은 기간이지만 다양한 업계 베테랑들과 교류하며, 게임 업계만의 열정·창의·다양성을 경험함
     * 게임을 만드는 것이 인생의 주 목표인 사람들, 전통 산업을 떠나 꿈을 좇는 이들, 기술-아트-스토리텔링이 결합된 독특한 경험을 쌓을 수 있는 곳임
     * 그러나 성장통과 지속 가능성에 대한 문제가 공존하며, 열정이 혁신과 번아웃의 요인이 되기도 함
     * 취미와 커리어의 구분이 모호해지는 만큼, 이 산업은 전형적인 오피스잡과 완전히 다름이 강점이자 과제임

   러시아 출신 개발자로 얀덱스에서 Riot 갔다가 지금은 JPMorganChase로 이직했네요

        Hacker News 의견

     * 나는 창의적으로 움직이는 사람들과 함께, 비디오 게임 회사를 만들겠다는 생각에 설레는 기분 표현 Metropolis 1998이라는 도시 건설 게임을 3년 넘게 개발 중인 경험 공유 창의성과 논리, 예술적 표현과 소프트웨어 개발 사이에서 늘 갈등 있었지만, 직접 게임을 만들면서 둘 다의 장점 극대화하는 환경을 누리고 있다는 이야기 소개 엔진 개발, 게임 디자인, 아트 디렉팅, 사운드 디자인, 마케팅, UI/UX, 환경 디자인 등 거의 모든 분야를 직접 담당 중임을 강조 Steam 페이지와 실제 개발 상황 간의 차이 인정 Metropolis 1998 스팀 페이지와 YesboxStudios X계정 공유
          + SimCity 2000과 SimCity 3000을 정말 엄청나게 많이 플레이했던 플레이어 입장에서 볼 때, Metropolis 1998의 비주얼이 대단함을 느끼는 감상 전달
          + 게임 개발 과정을 꾸준히 지켜보던 중임을 밝히고, 시뮬레이션 요소에 들인 노력이 확실히 성과로 이어지는 것 같다는 의견 전달 Steam 위시리스트 등 성과나 인기도에 대한 질문 남김
          + 요즘 음악(EDM) 작업에 몰입 중이지만, 논리와 창의성을 이렇게 융합하는 게임 제작 경험을 보니 나 역시 게임을 만들어보고 싶은 영감 받는 중임을 전함
          + 혼자서 만든 게임의 미학적인 부분이 인상적이라며, 솔로 개발자가 이뤄내는 성과에 항상 감탄하는 자기생각 공유
          + Metropolis 1998의 데모 버전을 출시 직후 플레이해 봤던 경험 이야기 시연 만족도가 높아 정식버전이 나오기를 기대 중이라는 소감 전함
     * “얼리 액세스는 보통 출시 1~2년 전쯤이다”라는 문장에 웃음을 터뜨림 많은 게임들이 얼리 액세스로 돈을 받고 조용히 사라지거나, 영원히 그 상태에 머무르는 경우가 많다는 현실 인식 소규모 개발자에게는 조금 더 자금과 QA(품질 테스팅)가 필요한 시점에서 얼리 액세스가 도움이 될 수 있고, 팬덤이 강한 장르에서 프로토타입만 만든 뒤 현금화하고 사라지는 사기 수법이 아쉽다는 의견 제기 해당 글 자체는 작가의 경험담이 흥미로웠다는 평도 덧붙임
     * 저자가 어릴 적 꿈을 이룬 것 같고, 성공이 맞는 것 같지만, 대형 스튜디오에서 현실적인 부분은 다소 낙담스러운 느낌 전달
          + 스튜디오가 작아질수록 오히려 개발자로서의 좌절감이 커진다는 개인적 경험 공유 소규모 회사의 장점도 있지만, 예산 부족이 어마어마한 단점이고, 사실상 Unity와 Steam AppID만 있어도 경쟁하게 되는 인디 개발 시장의 치열함 언급 AAA 스튜디오에서는 개인 영향력이 작아지긴 해도 더 거대한 프로젝트와 야심, 흥분을 느낄 수 있다는 차이점 설명 현재는 차라리 3인 팀에서 게임 엔진 전체를 책임지는 것보다는, Battlefield 팀에서 툴만 만들어도 만족하겠다는 심정 표현 인디 및 소규모 스튜디오도 장르를 바꿀 만한 작품 내놓을 수 있지만, 개발자 입장에서 AAA에 비해 극도로 좌절스러운 통계임을 인정 Microsoft 등 대형 회사들의 산업 구조조정(참고: 최근 Microsoft의 게임사업 구조조정)까지 감안한 분석 제시
          + 업계에 대해 잘 모르지만, 1999년경 트레이딩 회사에서 게임회사 출신 개발자 채용 경험을 회상 이직자 입장에서 ""같은 돈 받고 사무실에서 잠 안 자도 된다""는 점에 신기해했다는 유쾌한 후일담 공유
          + 소규모 스튜디오에서는 누군가 자금 여력이 충분하지 않으면, 자금 떨어질 때마다 다음 일거리를 대비해야 하는 구조임을 지적 대형 또는 수익성 스튜디오에서는 새로운 게임 아이디어 실험 후 실패해도 아무도 해고되지 않는 안정성의 차이 강조
     * 게임 개발 경험담이 인상 깊고, 자신에게도 깊이 공감되는 내용임을 솔직히 밝힘 게임 만들기가 정말 멋지고 매력적이지만 어려움이 분명히 존재하며, 그것 자체가 도전의 재미라는 점에서 강하게 추천하는 입장 전함
     * “3년 전 아무런 게임 제작 경험 없이 게임 스튜디오에 입사했다”라는 글의 내용에 놀람 경쟁이 없었다는 사실이 어떻게 가능한지 진지한 의문 제기
          + 업계에서는 이런 일이 의외로 그리 드문 경우가 아니라는 점을 덧붙임
"
"https://news.hada.io/topic?id=21908","불가리아, 2026년 1월 1일 유로존 가입 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      불가리아, 2026년 1월 1일 유로존 가입 예정

     * 불가리아가 2026년 1월 1일부로 유로존에 공식적으로 합류함
     * 해당 결정으로 불가리아는 유로화를 공식 통화로 도입함
     * 이번 가입은 유럽연합 경제 통합의 다음 단계 의미
     * 불가리아의 합류로 유로존 참여 국가가 더 확대됨
     * 관련 정책 및 금융 시스템 전환 준비가 필요함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

불가리아의 유로존 가입 결정

     * 불가리아는 2026년 1월 1일부터 유로존에 공식적으로 참여 예정임
     * 이로써 불가리아는 기존 자국 통화에서 유로화로의 변경 과정을 밟게 됨
     * 이번 결정은 유럽연합(EU)의 경제적, 재정적 통합 확대 목표의 일환임
     * 불가리아 정부 및 금융 기관들은 금융 시스템, 결제 인프라, 대국민 안내 등 다양한 전환 준비를 진행 중임
     * 유로존 국가 수가 증가하면서 경제 규모 및 유럽 단일 시장 내 통합 심화 영향이 예상됨

        Hacker News 의견

     * 내가 인정할 건 인정해야 한다고 생각함. EU가 관료적이고 경직됐다는 비판을 받긴 하지만, 단일 화폐는 성공적이었고 26년이 지난 지금도 계속 확장 중임. 불가리아가 추가되면 스페인부터 그리스까지 거의 유로존만으로 여행이 가능해짐(몬테네그로나 코소보도 실질적으로 유로존임을 감안할 때). 다음 차례가 누가 될지 흥미로움. 체코는 멀지 않았지만 서두르지 않고 있고, 루마니아는 원하지만 아직 갈 길이 멀어 보임. 폴란드와 헝가리는 정치적으로 대전환이 없으면 바깥에 남을 것 같음
          + 나 폴란드인임. 우리의 생활수준과 성장률이 독일과 비슷해지기 전까지는 유로 도입에 강하게 반대임(최소 10년은 더 필요함). 이유는, 개발도상국에선 단점이 장점보다 훨씬 크기 때문임. 가장 큰 문제는 경제를 통제할 수 있는 주요 수단을 탈국가적, 민주적이지 않은 조직에 넘기는 것임. 통화정책은 항상 큰 경제국 위주로 돌아가거나, 최소한 평균에 맞춰짐. 그러나 현지 정책이 현지 상황에 맞게 조정되는 게 훨씬 낫다고 생각함. 예를 들어, 통화 공급량은 경제 성장률에 맞춰서 아주 약간의 인플레이션이 생기게 맞춰야 한다고 보는데, 구(舊)EU와 신(新)EU의 성장률은 매우 다름. 그래서 무슨 일이 생기는가? 성장 빠른 나라에선 물가가 훨씬 더 빠르게 오르는데, 소득은 그대로임. 이건 엄청난 단점임. 환전 과정에서 소수점 올림 등으로 '1일 차'부터
            바로 가격 인상도 일어나는데 말임. 과거에는 ""인플레이션이 낮아질 것""이라는 약속이 이런 문제를 덮는 장점으로 많이 홍보됐음. 통화 발행 권한을 넘기면 인플레이션 걱정 안해도 된다고 믿었지만, 코로나 때 라트비아와 독일처럼 같은 화폐여도 전혀 다른 인플레이션을 경험했음. 결론적으로 유로가 다 나쁘냐? 아니고, 유일하게 유로존 내에서 미국에 통제되지 않는 통화를 들고 있는 건 엄청난 이점임. 하지만 이건 현재 폴란드처럼 제2 통화로 두는 것만으로도 충분히 누릴 수 있음(실제로 거의 모든 곳에서 유로로 결제 가능하거나 ATM에서 인출 가능함)
          + 관광객 입장에선 현실적으로 단일 화폐보다는 솅겐 협정이 훨씬 더 좋은 경험임. 현금을 안 쓴다면 더더욱 그렇다고 생각함. 비유로 솅겐 국가들(체코, 폴란드, 불가리아 등)을 다녀보면, 모든 결제 단말기에서 유로나 현지 화폐 중 선택이 가능하게 되어 있었음. 특히 관광지에선 대부분 유로 결제만 권장하는 경우도 있었음
          + 만약 너가 핀란드인이면서 스웨덴(SEK), 노르웨이(NOK)와 국경을 맞대고 산다면 상황이 다름. 이 나라들은 유로를 안 씀(러시아는 논외)
          + EU에는 속해 있지만 단일 화폐에 참여하지 않는 국가를 허용한 것은 실수였다고 항상 느꼈음. 하지만 날짜를 보면 EU와 유로 도입 사이에 6년 차이가 있다는 걸 알 수 있음. 만약 유로와 EU가 동시에 출범했다면, 패키지로 진행됐을까, 아니면 선택사항이었을까 궁금함
          + Potential enlargement of the European Union 링크 참고
     * 문득 생각난 점: 유로 지폐 2차 디자인을 처음 보고 ‘EBPO? 이게 뭐지, 왜 키릴 문자가 들어갔지?’라고 잠깐 생각했었음. 사실 이건 불가리아 때문이었음—불가리아는 EU 국가 중 유일하게 키릴 문자를 쓰는 나라임. 유로존 가입은 당시엔 아직 먼 이야기였지만, 언젠간 들어올 걸 미리 알았던 것 같음. 지금이 바로 그 순간임
          + 그리스가 유일하게 그리스 문자를 쓰는 나라라서, ‘ΕΥΡΩ’만 유일하게 그리스어로 표기해놨음
     * 멋짐. 지난 20년간 불가리아인들이 EU에 가입한 뒤 이룬 발전은 정말 놀라움. 쉽지 않은 과정이었을 거라고 상상함
          + 내가 불가리아에서 몇 달을 살아봤을 때, 두 가지에 깜짝 놀랐음: *불가리아 내에서 EU에 대한 지지는 꽤 낮고, EU 가입이 삶을 크게 개선해줬다고 생각하지 않았음 *반면, 러시아를 지지하는 비율이 아주 높더라(50% 가까움)—역사적으로 오스만 제국을 쫓아내는 데 러시아가 도움을 줬었기 때문이라 생각함
          + 쉽지 않은 여정이었지만, 전체적으로 멀리서 보면 정말 대단한 변화임
          + 혹시 도로를 직접 봤는지? ㅋㅋ
     * 이번 소식이 가장 크게 미칠 영향은 서유럽 관광객들이 흑해 연안 리조트 도시로 더 많이 올 것이라는 점임. 이는 현지 경제에도 좋은 일이긴 함. 하지만 내가 Burgas에 갔을 땐 서유럽 식 리조트와는 다른 특별한 매력이 있었음. EU 경제와 통합되면서 이런 독특함이 사라지지 않길 바람
          + 나는 Burgas엔 못 가봤지만, 몬테네그로는 아직도 충분히 특별함이 느껴짐. 그 이유는 통화보다는 현지 문화나 1인당 GDP 차이 때문인 것 같음(물론 자금 유입이 더 쉬워지면 점점 달라질 수도 있다고 생각함)
          + 현지 고유 분위기가 계속 유지되길 바람
     * 모두가 간과하고 있다고 생각하는데, 유로의 진정한 최대 강점은 부채임. 유로로 대출을 받을 수 있게 되면, 투자자들이 현지 화폐의 가치가 확 떨어질 걱정이 없으니 훨씬 낮은 금리로 돈을 빌려줄 수 있음. 또한, 외화의 유동성 부족이나 환전 위험도 없어서 투자 진입·회수 모두 쉽다고 생각함. 집주인에게 ‘유로 대출 이자 2%’와 ‘현지 통화 대출 이자 5%’의 차이가 얼만지 물어보면 왜 많은 나라가 유로 도입을 택하는지 바로 이해할 수 있을 것임
     * 한편으론 경제력이 다른 나라들이 같은 통화를 중심적으로 운용하는 건 최적은 아니라고 생각함. 다른 한편으론, 미국 달러의 지배력을 줄이는 어떤 시도든 환영임
          + 이런 통화 시스템, 미국도 비슷한 거 아닌지?
          + 유로가 완벽하지는 않지만 진지한 경쟁자가 거의 없는 통화임
     * 불가리아는 이미 수년간 사실상 유로에 연동되어 있었음. 일상에선 별로 달라지는 게 없겠지만, 상징적·정치적으론 엄청난 변화임
     * 불가리아와 EU가 과거의 실수에서 배웠기를 바라지만(솔직히 그렇지 않다고 생각함), EU와 유로가 좋은 의도와 전망으로 시작됐지만 몇나라에겐 재앙이 되고 말았음. 그리스는 16년 넘게 불황에서 벗어나지 못하고 있음. 이유 중 하나는 2009년 위기 때 자국 화폐 평가절하를 할 수 없어서였음. 물론 유로 때문만은 아니었을 수도 있지만, 그리스 내에서 직접 겪어보니 화폐 절하가 있었다면 고통이 좀 덜하지 않았을까 싶음. 일본, 이탈리아, 미국 등도 부채비율은 비슷하지만 2008년 이후 그리스만큼 생활수준 폭락이나 빈곤율 상승을 경험하지는 않은 것 같음. 불가리아 이웃들에게 행운을 빔—필요할 거임
          + 그리스 경제가 진짜 아직도 불황임? EU 집행위(European Commission)는 꽤 잘 성장하고 있는 걸로 평가하던데? 그리스 경제 전망, 독일 경제 전망 비교해보면 독일보다도 좋게 나옴(물론 두 경제가 직접 비교가 가능한 건 아니지만)
          +

     “그리스가 16년 넘게 불황에서 벗어나지 못하고 있음, 그 중 하나가 2009년 통화 평가절하를 못한 것 때문임.”
     그리스는 불황이 엄청 오래된 것도 아니고, 오히려 지금은 긴축정책의 터널 안에 있음. 이 방법이 너무 가혹하긴 했지만, 부채 문제(정부가 여러 해 공식 통계를 속여가며 착복함)로 구제금융을 받으려면 이 조건밖엔 없었음.
     “아마 유로가 없었더라도 피할 수 없었을 것”
     왜 그랬는지 말해줄 수 있음. 작은 나라 작은 경제 규모에서, 엄청난 부채를 쌓으면서 개발에 쓰인 것도 아니고 세금 회수도 못됐음. 세금 포탈도 관행이었으니 결국 언제든 폭발할 운명이었음. 만약 자국 화폐였다면 IMF와 협상해야 하니 더 힘들었을 것임.
     IMF는 언제나 긴축을 요구함. 게다가 자체 통화였다면, 돈값이 떨어져 아무도 채권을 사주지 않고, 금리는 폭등했을 것임. 국민들 입장에선 수입품(특히 유럽 회원국들에서 들어오는 첨단제품 등)이 폭등하고, 고령 인구이기 때문에 저축가치도 한순간에 붕괴됐을 것임. 나도 긴축정책이 최선이라고 생각하진 않지만, 어떤 선택도 고통스러웠을 것임.
     나는 IMF 시절 브라질의 통화개혁 4번이나 겪으면서 직접 살아봤음. 국가 재정이 오랫동안 엉망이면(브라질, 그리스 둘 다) 결국은 “구제금융 권력자(IMF, ECB 등)”에게 꼼짝없이 조아릴 수밖에 없다고 느낌
     * 솔직히 여기서 이 결정을 나쁘게 보는 사람이 이렇게 많을 줄은 예상 못함. 그 이유가 진짜로 궁금함
          + 우크라이나 관련 스레드들을 보면 러시아 계정이나 트롤, 이른바 탱키들이 정말 쏟아져 들어옴
          + EU는 곧 망할 배와 같고, 더 통합될수록 망할 때 충격도 커진다고 생각함
     * 친구들아, 환영함
"
"https://news.hada.io/topic?id=21855","ISS의 위치를 DNS로 확인하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ISS의 위치를 DNS로 확인하기

     * DNS LOC 레코드를 사용하여 국제우주정거장(ISS) 의 실시간 위치 정보를 조회할 수 있음
     * LOC 레코드는 위도, 경도, 고도 정보를 저장하며, 위성의 위치 추적에 적합한 기능 제공
     * 예시 도메인(where-is-the-iss.dedyn.io)에 DNS 질의 시 ISS의 최신 위치를 반환함
     * N2YO API를 활용하여 위치 데이터를 가져오고, 15분마다 자동으로 LOC 레코드가 갱신됨
     * deSEC와 같은 API 지원 도메인 서비스를 통해 효율적인 LOC 정보 업데이트 가능함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * DNS의 esoterica(마니아용 기능)에 대한 흥미를 바탕으로, DNS LOC 레코드를 이용해 실제 물리적 위치 정보를 전 세계로 배포할 수 있음
     * 일반적으로 도메인 이름은 서버의 물리적 위치와 연결되며, LOC 레코드를 통해 서버 뿐 아니라 특이한 기기 위치도 기록 가능함

DNS LOC 레코드란?

     * RFC 1876에 정의된 실험적 표준으로, 서버의 위도, 경도, 고도 정보를 DNS에 기록 가능함
     * 최소 고도 -100,000m(벙커 등 지하 위치 표현 가능), 최대 고도 42,849,672m(정지궤도 위성 등까지 표현 가능)
     * 위성을 비롯한 다양한 장비 위치 정보를 DNS로 전달할 수 있는 기능 제공

국제우주정거장(ISS) 위치 조회 서비스 구현

     * where-is-the-iss.dedyn.io 도메인 생성, 별도의 웹사이트·핑·일반 인터랙션 없이 DNS 질의만으로 작동
     * Linux, Mac에서 아래 명령어로 ISS 위치 정보 질의 가능함
dig where-is-the-iss.dedyn.io LOC

     * 반환 예시: 위도/경도/고도 정보가 LOC 형식으로 제공됨
where-is-the-iss.dedyn.io. 1066 IN  LOC 47 24 53.500 N 66 12 12.070 W 430520m 10000m 10000m 10000m

     * 15분마다 최신 위치 정보로 갱신됨 (best-effort 방식)

위치 데이터 취득 및 변환

     * N2YO의 웹사이트와 API를 통해 다양한 궤도 내 객체를 추적할 수 있으며, 무료 티어 API를 제공함
     * 예시 API 호출로 최신 위성 위치(위도, 경도, 고도 등)를 JSON 형식으로 획득 가능
https://api.n2yo.com/rest/v1/…=_____

     * 반환되는 위도/경도는 소수점 형식, 고도는 Km 단위 → LOC 레코드로 변환시 도분초(DMS) 및 미터(m) 단위로 컨버팅 필요

LOC 레코드 갱신 자동화

     * deSEC(베를린 기반 비영리)에 API로 LOC 레코드 최초 생성 및 갱신 가능
     * LOC 최초 등록 예시
curl https://desec.io/api/v1/domains/where-is-the-iss.dedyn.io/rrsets/ ... --data '{""type"": ""LOC"", ""records"": [""...""], ""ttl"": 900}'

     * 갱신은 HTTP PATCH를 이용해 변경된 정보만 전송함
     * TTL(900초, 15분) 로 설정해, 코드가 15분마다 자동 갱신을 수행함
     * API 사용량 제한을 준수하면서 효율적으로 최신 데이터 제공
     * 추가적으로 TXT 레코드 등을 통해 갱신 시간 기록 등 다양한 확장도 가능함

결론

     * 이번 시도는 DNS의 색다른 활용 가능성을 보여주는 기술적 시연임
     * 앞으로 Mars Rover 등 더 다양한 우주 객체 위치도 DNS LOC 레코드로 표현 가능성 제시
     * DNS를 활용한 참신한 응용 사례로, 인프라/IT 업무의 자동화, 위치 정보 관리 등에도 확장성 제공

        Hacker News 의견

     * 또 다른 레코드인 Name Authority Pointer (NAPTR)은 휴스턴 Johnson Space Center의 전화번호 정보 제공
> dig where-is-the-iss.dedyn.io NAPTR

; <<>> DiG 9.10.6 <<>> where-is-the-iss.dedyn.io NAPTR
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 31786
;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 1232
;; QUESTION SECTION:
;where-is-the-iss.dedyn.io. IN NAPTR

;; ANSWER SECTION:
where-is-the-iss.dedyn.io. 3600 IN NAPTR 100 100 ""u"" ""E2U+voice:tel"" ""!^.*$!tel:+12814830123!"" .

;; Query time: 84 msec
;; SERVER: 100.100.100.100#53(100.100.100.100)
;; WHEN: Sun Jul 06 10:53:39 EDT 2025
;; MSG SIZE rcvd: 111

     * API 제한이 있다는 것은 알지만, 전체 지구를 90분 만에 도는 객체에 15분 업데이트 간격은 상당히 큰 편이라는 생각 공유, 평균적으로 지구 둘레의 1/12 정도, 리스본에서 이스탄불 사이 거리만큼 오차 발생 가능성 언급
          + 맞는 말이라고 생각, 포스팅에도 도킹 작업에는 사용하지 말라는 얘기 포함, 1분마다 무료로 업데이트 가능한 DNS가 있다면 당장 이쪽으로 전환할 생각 있음
     * 시작 문장을 ""I love DNS erotica""로 잘못 읽은 경험 공유, 자신이 너무 오랫동안 실내에 있었던 것 같다는 깨달음, 산책의 필요성 느낀다는 이야기
          + 아마 놀라울 수도 있지만, 많은 사람들이 이런 내용 흥미롭게 느낄 거라는 확신
          + 사실 이 프로젝트가 바로 그 DNS 에로티카가 아니냐는 농담, 차가운 샤워가 필요할지도 모르겠다는 이야기
          + OnlyFans 크리에이터로 진출하고 싶지 않으니 자제 요청
          + ""It's always DNS""라는 밈이 새로운 의미를 가지게 된다는 농담
     * 너무 멋진 프로젝트라 생각, 바로 dns.toys에 추가했다는 소식 공유
dig iss.sky +short @dns.toys

          + 정말 편리하고 신기하다는 감탄, 고마움 표현, 모든 도구가 TXT 레코드만 사용하는지, 아니면 LOC, NAPTR도 활용하는지 궁금증
     * 정말 기발하고 교육적인 아이디어라는 찬사, 비슷한 방법을 JWST에도 적용 가능한지 바로 궁금증 생김, 아쉽게도 LOC DNS 레코드는 약 4,200만 미터(42,000km)까지 지원, JWST는 이보다 38배 멀기 때문에 위치 표현에 한계, Hubble의 경우는 가능성 있을지도 모르겠다는 언급
          + JWST는 제2 라그랑주 포인트를 공전하기 때문에 GPS 좌표 지정 쉽지 않음, 달에 GPS 좌표를 요청하는 것과 비슷한 상황, 2023년 NASA가 LRO로 달에서 미약한 GPS 신호 수신 테스트한 적 있지만 탐색에는 실용적이지 않음, ISS는 서브새틀라이트 포인트 외에도 지상 고도와 상관없이 GPS 신호 수신 가능, TLE(이중선 궤도요소)는 ISS처럼 지구 저궤도를 도는 위성에 적용 가능, SGP4 모델 등으로 위치·속도 연산
          + GSO(정지궤도 위성)의 고도와 LOC 레코드 한계가 거의 일치한다는 의견
     * 하드코딩된 캐시 외에도 DNS 인프라 자체의 TTL 값이 캐싱에 도움이 되어야 한다는 주장, 특히 Cloudflare 1.1.1.1, Google 8.8.8.8 등 대형 퍼블릭 DNS 리졸버가 많다는 점에서 더욱 그러함, DNS는 전 세계적으로 일관성 있게 동작하는 데이터베이스 특성, 임시 데이터 저장 가능, 방화벽에 쉽게 막히지 않는 순진한 프로토콜로서의 장점, 다만 많이 가로채기도 하는 현실 언급
     * OpenNotify라는 다른 리소스(제공 기능은 제한되고 화려하지 않음) 소개
       http://open-notify.org/
     * DNS LOC 레코드에 대한 자세한 정보 소개
       https://www.ckdhr.com/dns-loc/
     * RFC를 보니 왜 이 기능이 필요했는지 설명이 없음, 1996년 당시 대학이나 데이터센터 물류와 관련된 이유가 있었던 건 아닐까 하는 의문
          + RFC의 5.1장(Suggested Uses)에서는 모호하나마 적용 가능성 제시 중, 예를 들면 USENET 백본 흐름 지도, 시각적 traceroute 앱(IP 패킷의 지리적 이동 경로 시각화), 네트워크 관리 앱에서 호스트·라우터 맵 생성 등 활용 가능성
          + RFC에서는 문제 해결을 명확하게 정의하지 않는 경우가 다수, LOC 레코드는 굳이 좌표가 아니라 사람이 읽을 수 있는 주소 문자열이어도 충분하다는 생각
     * DNS는 연합형, 읽기 최적화, 지리복제된 키-값 저장소이며 eventual consistency를 가진다는 정리
"
"https://news.hada.io/topic?id=21887","가자 사태 관련 BBC 이사진의 이해 상충 문제 제기하는 공개 서한","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 가자 사태 관련 BBC 이사진의 이해 상충 문제 제기하는 공개 서한

     * 400명 이상의 미디어 인사들과 유명 인사들이 BBC 이사 Robbie Gibb의 이해 상충 의혹과 관련해 BBC에 공개적으로 그의 해임을 요구함
     * 서한에는 BBC 내부 투명성 부족과 가자지구 보도에서 일관성 없는 편집 결정 문제에 대한 우려도 제기됨
     * BBC의 가자지구 관련 다큐멘터리 방영 취소가 “공정한 보도” 원칙에 부합하지 않는다는 비판이 나옴
     * Robbie Gibb가 Jewish Chronicle과의 밀접한 관계로 인해 BBC 의사결정에 영향력을 행사한다는 의혹이 제기됨
     * BBC 대변인은 내외부 논의의 필요성을 강조하며, 가자지구 사태 보도에서 공정성을 유지하려 한다고 밝혔음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 400명이 넘는 배우, 작가, 언론인 등 주요 미디어 인사들과 111명의 BBC 기자들이 BBC 이사진 Robbie Gibb의 이해 상충 의혹을 제기하며 그의 해임을 촉구하는 공개 서한을 BBC 경영진에 보냈음
     * 이들은 가자지구 보도 및 BBC의 편집 결정 과정의 투명성 부족과 검열 문제에 대해서도 우려를 표함

공개 서한 내용 및 배경

     * 이 서한은 BBC 내부 관계자들이 주도해 조직되었으며, Miriam Margolyes, Alexei Sayle, Juliet Stevenson, Mike Leigh 등 유명 인사들이 참여함
     * BBC가 이미 제작한 가자지구 의사 다큐멘터리(Gaza: Doctors Under Attack)가 편향성 논란 우려로 방영 취소된 것이 또 다시 “공정성 없는 보도 관행”을 보여주는 사례임을 강조함
     * Robbie Gibb가 BBC 이사회와 편집기준위원회에 속해 있으면서, 유대계 언론사 Jewish Chronicle에 과거 임원으로 직접 관여했고 그 영향력으로 보도 결정에 불공정하게 개입할 수 있다는 점이 문제로 지적됨
          + Gibb는 2020년 Jewish Chronicle을 매입한 컨소시엄을 이끌었으며, 2024년 8월까지 해당 미디어사의 이사였음

BBC 내 보도 기준 및 현황에 대한 비판

     * BBC 내부자들은 “상위 경영진 차원에서 설명 없는 불투명한 결정”이 잦아, 정상적인 저널리즘이 어렵다는 불만을 표함
     * BBC가 영국 정부의 팔레스타인 전쟁 관여, 무기 수출 및 관련 법률 문제 등 중대한 사안에 대해 실질적 보도를 제공하지 못하고 있다고 지적함
          + 이에 관한 보고들은 경쟁사들에 의해 먼저 공개된 경우가 많았음
     * Gibb에 대해 “이해 상충”이 존재하며, BBC 제작진들이 “공정성”을 이유로 검열 당하는 이중잣대를 비판함

소셜 미디어 활동과 이중잣대

     * BBC 직원들은 이스라엘 정부 비판 기사 공유만으로도 “의도가 있다”는 의심을 사고 있지만
     * 반면 Gibb는 명확한 이데올로기적 성향에도 불구, 중요한 의사결정권을 행사하고 있다는 점에 대한 불공정성 우려가 크다는 내용이 담김

서명자들의 요구

     * “BBC의 이스라엘-팔레스타인 관련 보도가 시청자 기대에 미치지 못하고 있음”을 지적
     * Robbie Gibb가 BBC 이사진 및 편집기준위원회 구성원으로서 부적합하다는 입장이며
     * BBC가 공정성, 정직성, 두려움 없는 보도 등 핵심 가치로 돌아갈 것을 요구함
     * 111명의 BBC 기자는 보복 우려로 익명으로 서명함

BBC 공식 입장

     * BBC 대변인은 “BBC 내 편집팀의 활발한 내부 논의는 본질적인 과정”이며, 피드백을 청취함을 밝혔음
     * BBC는 가자지구 전쟁 보도에서 공정성에 최선을 다하고 있으며, 현지 생중계, 심층 분석, Life and Death in Gaza, Gaza 101 등 수상작 다큐멘터리도 배출했다고 강조함

        Hacker News 의견

     * 이 분쟁에서 어느 편을 공격하거나 과하게 비난하는 것은 매우 불균형적인 리스크임을 느끼는 입장임. 팔레스타인에 대해 부정적으로 오도하면 기껏해야 익명으로 서명하는 분노의 편지 하나 받는 수준임. 반면 이스라엘을 부정적으로 오도하면 정말 강력하고 조직적으로 항의받게 됨. 그래서 BBC가 기업적 이해관계로 이스라엘의 잘못을 언급하지 않는 선택을 하는 것은 어쩔 수 없는 합리적 결정임. 정치권이나 미국의 예시처럼, 이스라엘이 명백한 인권 침해를 저질러도 거의 비판 없이 넘어가는 상황임. ICC 체포 영장도 이제는 완전히 잊혀진 사건임. 이런 상황에서 BBC가 나서서 목소리를 높이지 않는 게 전혀 놀랍지 않은 패턴임
          + BBC가 공영방송이므로 정부로부터 재정적으로 독립해 기자들이 필요하다고 판단하는 취재를 자유롭게 할 수 있다는 점이 중요한 환경임. 정치적 압력으로부터 최대한 보호받아야 하는데, 본인들 스스로 제작한 다큐멘터리를 자체 검열로 내리는 것이 그 공영방송의 취지와 전혀 부합하지 않는 행동임
          + 여기서 놀란 사람은 거의 없을 것임. 본인도 그렇지 않음. 오히려 분하고 화가나고 속까지 아픈 입장임. 하지만 놀랐다는 감정은 전혀 없음
          + 팔레스타인에 부정적 오도 시 그냥 익명 항의 편지 정도만 받는다는 얘기에는 동의 못함. 실제로는 불타는 듯이 격렬하지만 대체로 평화로운 대학 시위, 아이를 싫어하는 사람이냐는 어투로 질문하는 BBC 기자의 상투적 인터뷰 등 더 적극적인 대응이 있음
          + BBC에 이스라엘에 대한 부정적 편견이 있다고 분석한 연구 결과가 존재함. 본인이 말하는 그런 식의 강력한 항의 시위 기록을 하나라도 제시할 수 있는지 궁금함. 설득력 있게 입증된 사례를 찾기 어려움
          + ""왜 BBC가 나서길 기대하냐""는 수사적 질문은 논점을 흐리게 하는 느낌이 있음. 모든 조직은 나름대로의 동기가 있어 그렇게 움직이는 것임. 하지만 그렇다고 해서 그 행동 자체를 비판하면 안 된다는 논리는 맞지 않음. 동기가 무엇이든, 비판은 정당함. 합리성만으로 행동이 정당화되진 않는 것임
     * 외부자 관점에서 그 공개서한은 너무 모호하게 느껴짐. 실제 구체적인 주장이라고는 'Gaza: Medics Under Fire' 다큐멘터리 방영 중단 말고는 없고, BBC가 왜 방영을 중단했는지 공식 입장을 내놓지 않아 실제 검열인지 아닌지 알 방법이 없음. 나머지 주장들은 그냥 편파·검열 논란에 대한 각기 엇갈린 주장일 뿐임. 심지어 기사도 그냥 표면적 사실만 받아들여 BBC를 비판하는 식이라 이미 MSM이 친이스라엘 편향이라고 믿는 사람에겐 설득력 있지만, 아니면 오히려 혼란스러운 정보임. BBC가 친이스라엘 편향임을 더 신뢰성 있게 입증한 다른 자료가 있는지 궁금함
          + 관련성 있는 분석 소스들을 정리했음
               o BBC의 이스라엘-가자 보도 이중 잣대 분석
               o 2025년 7월, 가자 다큐 제작자가 BBC의 검열 시도를 비판
               o 2025년 2월, 영국 내 친이스라엘 보도 경향의 내부 고발
               o 2024년 11월, BBC 친이스라엘 편향 논란 보도
               o 2023년 11월, BBC 기자들이 방송사 Bias를 내부에서 고발
               o BBC 미방영 다큐 리뷰
          + ""BBC의 보도는 팔레스타인에 대한 체계적인 비인간화와 이스라엘 홍보를 그대로 수용하는 구조적 문제가 있다""는 요약이 가능함. BBC 중동 에디터 Raffi Berg가 익명 BBC 기자들에 의해 “섹션을 지나치게 미세 관리한다”는 지적도 있음 opendemocracy 분석.
            또한 CfMM에서 35,000건 이상의 BBC 콘텐츠 분석 결과, 이스라엘 사망 사건 하나당 33배 이상의 보도량 차이 확인, 방송 및 기사 모두 명백한 이중 잣대 발견, 집단학살 관련 의혹은 계속해서 차단당함 Novara Media 논문
     * 이런 현상은 BBC만이 아니라 모든 서구 미디어 전반에서 나타나는 경향임
          + 서구 프로파간다는 이 문제뿐 아니라 EU 부패, 검열, 언론 자유 침해도 심각한 수준임. 그러나 내러티브는 항상 푸틴만을 탓하는 쪽으로 흘러감
     * 기사를 읽었지만 BBC에서 어떤 친이스라엘 논설이 나왔는지 딱히 모르겠음. 본인 경험상 BBC는 오히려 전쟁 반대 입장이 뚜렷하게 보임
          + 편향이란 것이 명시적 논설이 아니라, 단어 선택, 어떤 인물이 조명받는지, 어느 쪽이 악의 축·독재로 불리는지, ‘정권 교체’ 같은 표현에 아무도 문제제기하지 않는 정서에서 드러난다는 설명임. 자신도 모르게 특정 쪽이 나쁜 쪽이라 느끼게 되는 구조임. 누가 마이크를 쥐고 무제한 발언권을 가지는지 역시 가장 중요한 포인트임
          + 문제는 명확한 행동이 아니라 침묵, 즉 방영 거부처럼 아예 어떤 관점을 배제하는 반복적 결정임
          + 이스라엘 군이 언론 보도 방식을 통제하고, 요르단강 서안의 억압 체계를 ‘아파르트헤이트’라 부르지 못하게 한다는 점에 주목함. 가자지구 참사도 독립 취재가 불가해 제대로 보도되지 않음. 향후 남쪽에 수용소를 만들고, 하마스와 연관 없는 민간인을 분리한 뒤, 트럼프식 계획대로 가자지구에 유대인 정착촌을 재건하며 수용소 밖은 무자비하게 처벌할 예정이다라는 시나리오도 언급함. 독립 언론 진입은 봉쇄되는 구조임
          + BBC가 이스라엘-가자 분쟁을 보도할 때 팔레스타인에 불리하게 구조적으로 편향되고, 공정성 기준에도 미달한다는 CfMM의 연구 결과 강조. 약 3만 5천여 건의 BBC 콘텐츠 분석에서 이스라엘 희생자 관련 보도가 팔레스타인 대비 33배 많았고, 이중 잣대가 명확했음을 확인. 집단학살 의혹도 계속 차단되는 흐름임 Novara Media 기사
     * 코로나 이후 세상의 분위기가 너무 암울해진 상황임. 권력자들은 더 많은 권력을 원하고, 세상을 제로섬 게임처럼 바라보고, 목적 달성을 위해 강압·기만·프로파간다를 동원함. 이 경우에는 영토 확장 목적임. 현 상태를 반대하면 자동적으로 적대적 딱지가 붙는 사회 구조임
          + 부패·프로파간다·양극화는 코로나 이전에도 동일했음. 오히려 일반 사람들(우리)이 급변함. 극단적 흑백 논리만 남아서, 누구를 지지하면 학살 옹호자, 반대하면 반유대주의자로 몰리는 현상임. 정치 토론이 극도로 유독해졌고, 코로나 이후 온라인 에코챔버에 갇혔다는 인식임
     * BBC 전체의 문제는 아닌 듯함. 미국에서는 BBC World Service 라디오 뉴스에서 가자 전쟁의 참상도 거리낌 없이 보도하며, 심지어 이스라엘 대표와의 인터뷰도 아주 직설적으로 진행되는 분위기임
     * BBC는 친이스라엘 편향뿐 아니라, 하마스 연관 인사가 제작한 다큐멘터리를 방송한 것으로 반이스라엘 편향으로도 비판 받는 매체임 참고 기사
          + 해당 기사 내용에 따르면, 가자지구 상황을 다룬 다큐멘터리도 부모가 하마스 행정부의 기술직에 있었다는 이유로 친이스라엘 단체들의 과도한 항의에 의해 방송 중단됨. 하지만 다큐멘터리 내레이터의 멘트는 제작진이 쓴 대본이었기에 실질적 연계성은 없음
          + 이런 식으로 양쪽 모두 BBC에 같은 불만을 제기한다면 균형 잡힌 보도에 가까운 신호로 볼 수 있다는 해석임
     * BBC 종사자 수가 21,000명, 기자만 5,500명인데 서명은 100명임. 본인 입장에선 BBC가 오히려 매우 반이스라엘적인데, 어떤 사람은 이 정도도 불만족스러워 더 강한 주장 바라게 됨. 친이스라엘이란 인상은 전적으로 개인 입장에 따라 다르지만, 실제 친이스라엘 언론과 BBC는 완전히 다름.
       2006년 BBC 트러스트의 공식 평가 결과를 들어 설명함. “일부 언어·태도의 일탈은 있지만, 체계적, 고의적 편향은 거의 없고, 전반적으로 공정하고 정확한 보도를 위해 노력함이 드러남”이란 평임. 단점으로는 “팔레스타인 선거 직전, 자치정부 대표에 대한 날카로운 질문이 거의 이루어지지 않음”이 있었음. “테러”라는 용어는 이념·종교·정치 목적을 위한 무차별 민간인 대상 폭력에 사용되야 한다는 비판도 포함됨
          + 이 정의대로 하면 이스라엘도 테러 국가가 된다는 주장임
          + BBC는 무차별 민간인 공격을 하는 이스라엘 정착민의 테러리즘에 대해 한 번도 언급한 적이 없다는 지적임
     * <pre><code> ""당신을 비판할 수 없는 사람이 당신을 지배하는 사람이다"" - 라는 인용문에 대한 언급도 있음 - 이는 ""Unknown"" 출처가 아니라 신나치 Kevin Alfred Strom의 반유대주의적 발언임을 강조함
     * 정치 관련 뉴스는 해커뉴스 가이드라인상 오프토픽(비적합)에 가깝고, 실제 이 글의 댓글 수준을 보면 왜 정치적 이슈를 피해가는 게 맞는지 알 수 있음 HN 가이드라인
          + 참여자 일부는 이스라엘/팔레스타인 주제에만 집중적으로 댓글을 남기는 경향이 있음을 지적함
"
"https://news.hada.io/topic?id=21847","Claude 코드로 Mac 앱 만들기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Claude 코드로 Mac 앱 만들기

     * Claude Code로 2만 줄 이상의 macOS 앱 전체 코드를 거의 모두 생성하여 출시, 직접 작성한 코드는 1,000줄 미만임
     * AI 코딩 에이전트의 등장과 함께, 기존 IDE가 아닌 프롬프트 중심의 개발 경험을 하게 됨
     * Swift와 SwiftUI 코드 생성은 다소 한계가 있으나, 프라이밍, 컨텍스트 엔지니어링, 피드백 루프 설계로 품질을 높일 수 있음
     * 자동화, 배포, 문서화, 테스트까지 대부분 Claude가 처리, 반복적 수동 작업과 시간 소모를 획기적으로 줄임
     * 미래의 IDE는 코드 에디터 대신, 에이전트 활용과 컨텍스트 관리가 중심이 되는 새로운 UX로 진화할 것임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Claude Code만으로 macOS 앱을 출시한 경험

  프로젝트 개요

     * 최근 Context라는 macOS 네이티브 앱을 출시함. MCP 서버 디버깅을 위한 개발자 도구임
     * 이 앱은 거의 100% Claude Code로 만들어졌음. 약 2만 줄 중 직접 작성한 코드는 1,000줄도 되지 않음
     * Claude로 소프트웨어를 만드는 데는 여전히 개발자의 실력과 반복 작업, 프롬프트 작성 역량이 필요함
     * 이번 글은 Claude Code를 이용해 앱을 만드는 전 과정, 도구 선택, 장단점, 고품질 코드 생성을 위한 방법 등을 상세하게 설명함

  1. Copilot에서 Claude Code로, 그리고 개발 환경의 변화

     * 처음 사용한 AI 코딩 도구는 GitHub Copilot이었으며, 단순 자동완성만으로도 개발 효율이 크게 증가함을 체감함
     * 이후 Cursor의 에이전트 모드, Windsurf 등 코드 기반에 컨텍스트를 수집하고, 빌드·테스트 반복까지 자동화하는 에이전트형 툴이 쏟아짐
     * Claude Code는 기존 에디터(예: VS Code)와 달리 터미널 전용, 프롬프트 입력 중심의 순수 에이전트 환경을 추구함
     * 기존 IDE 기능 대부분이 빠진 채, 프롬프트 박스 하나와 결과만 보여주는 단순한 UX임
     * 코딩 에이전트가 기존 IDE를 보조하는 것이 아니라, 아예 IDE를 대체하는 시도를 함
     * 사용자 인터페이스 및 사용 경험이 기존 도구와 달라서 UX에 대해 회의적이었으나, 새로운 접근방식에 매력을 느껴 사용해보기로 함

  2. 사이드 프로젝트를 다시 시작하다

     * 직장 생활을 병행하는 많은 개발자와 마찬가지로, 미완성된 사이드 프로젝트가 쌓여만 감
     * 프로토타입은 금방 만들지만, 마지막 20% 완성 단계에서 시간과 에너지가 부족해 실제 출시까지 이어지지 못함
     * MCP 서버를 테스트하는 경험에서, 네이티브 앱이 필요하다는 생각에 직접 앱을 만들기로 결정함
     * 이 과정에서 Claude Code를 본격적으로 활용하기 시작했고, AI 에이전트가 실제로 얼마나 큰 도움을 주는지 체감함

  3. Claude Code의 뛰어난 코드 생성 능력

     * 최신 Sonnet 4, Opus 4 모델을 사용하는 Claude Code는 진짜로 좋은 코드를 빠르게 만들어냄
     * 프로젝트 맥락을 읽고, 코드 스타일을 파악하고, 관련 문서·스펙을 읽어 기능을 구현하며, 테스트 코드도 자동 작성함
     * 빌드, 테스트 반복, 콘솔 로그·스크린샷 분석, 버그 고치기까지 거의 자동화됨
     * 실제로 개발자가 코드를 작성하는 시간의 극히 일부만으로 고퀄리티 결과물을 생성함
     * 신입 사원이 아무런 맥락 없이 프로젝트에 투입되어도, 몇 분 만에 기능을 완성하는 수준을 구현함

  4. Swift와 SwiftUI 지원의 실제 품질

     * Swift 6.1, macOS 15.5, 최신 SwiftUI를 활용
     * Claude는 Swift 5.5까지는 대부분 잘 다루지만, 동시성 등 최근 변화에는 취약함
     * 현대 API와 레거시 API, Objective-C와 SwiftUI를 혼용해 실수하는 경우도 있음
     * SwiftUI 코드의 경우 초안은 다소 미완성·투박하지만, 반복적으로 지시하면 충분히 잘 다듬어짐
     * UI 코드가 복잡할 때 컴파일러 에러(타입 추론 실패 등)가 발생하는데, Claude는 이를 자동으로 더 작은 함수로 리팩터링할 수 있음
     * CLAUDE.md 파일에 지침을 명시하면, Claude의 코드 품질을 한 단계 더 끌어올릴 수 있음
          + 예: SwiftUI 우선 사용, Apple Human Interface Guideline 준수, 최신 macOS 및 Swift6 기능 적극 활용 등
     * 추가적으로 agent-rules 리포지터리의 가이드라인을 활용하면 더욱 품질 높은 코드 생성이 가능함

  5. ""더 예쁘게 만들어줘"" 라고 요청 가능

     * Claude에게 ""더 아름답게/우아하게/사용성 좋게 만들어줘"" 등 간단한 프롬프트만으로 UI 디자인을 개선할 수 있음
     * UI 버그나 개선점은 스크린샷을 Claude에 붙여넣어 반복적으로 피드백을 주면 즉시 반영됨
     * 보다 체계적으로는, 먼저 ""어떻게 하면 UI가 더 아름다워질지 제안해줘""라고 요청한 뒤, 그 중 원하는 변경만 골라 적용시키는 식도 가능함

  6. 컨텍스트 엔지니어링의 중요성 중요성

     * 최근 AI 모델은 불완전한 프롬프트, 문법적 오류가 있어도 상당히 잘 이해함
     * 진짜 중요한 것은, 제한된 컨텍스트 윈도우(200k 토큰) 내에서 최대한 필요한 정보만 배치하는 것
     * Claude는 대화의 맥락이 가득 차면 자동 요약(compaction) 후 컨텍스트를 재설정하는데, 이 과정에서 디테일 누락 또는 품질 저하 현상 같은 정보 일부 손실 위험이 있음
     * 따라서, 제한된 맥락 내에서 최대한 높은 품질 값을 도출하는 'context engineering' 이 AI 에이전트 사용의 핵심 과제임

  7. 에이전트 프라이밍

     * 이 compaction 과정에서 중요한 맥락이 누락될 수 있으니, 필요한 경우 수동으로 요약하게 하거나, 추가 정보를 프라이밍(미리 읽히기)하는 것이 효과적임
     * CLAUDE.md 외에도 직접 특정 소스코드, 스펙 문서 등을 미리 읽히고 요약하도록 프롬프트를 작성하면 출력 품질이 향상됨
     * 새로운 라이브러리나 최신 API 등 Claude의 지식 cutoff 이후 등장한 내용도 특정 도구(Context7, llm.codes 등)로 문서를 변환해 Claude가 이해하기 쉽게 만들 수 있음
     * 프라이밍은, ""이 소스파일·문서·스펙을 모두 읽고 요약해봐""처럼 지시해 Claude가 먼저 맥락을 완전히 이해하도록 만드는 과정임

  8. 에이전트는 명확한 명세(Spec)가 필요함

     * Claude에 기능 구현을 시킬 때, 반드시 구체적이고 상세한 스펙을 입력해야 원하는 결과를 얻을 수 있음
     * 흔히 시연에서 보여주는 ""한 문장 프롬프트로 앱 만들기""는 사실상 프로토타입 수준만 가능
     * 스펙이 정교하지 않아도, 음성 입력이나 타이핑 등 편한 방식으로 설명하면 됨

  9. ""Ultrathink and Make a Plan""

     * Claude가 무작정 구현에 돌입하면 출력 품질이 저하되므로, 'think' 'ultrathink' 등 확장적 사고 모드로 우선 계획을 세우도록 요청하는 전략이 효과적임
     * 단계별로 구현 전 계획 검토와 피드백 후 작업하게 하면 품질이 올라감
     * Anthropic의 Claude Code: Best practices for agentic coding 문서를 필독 자료로 권장

  10. 피드백 루프 구축

     * Claude Code의 진정한 강점은 독립적으로 피드백 루프를 구동할 수 있을 때 극대화됨
     * 즉, Claude가 직접 코드를 수정하고(변경), 빌드하고(테스트), 실패 원인을 분석해서(컨텍스트 수집), 다시 반복하는 자동화 사이클을 만드는 것이 핵심임
     * 이런 루프를 잘 설계할수록, Claude가 더 자율적으로 고품질 코드를 완성할 수 있음
     * 1. Build (빌드)
          + Claude는 앱을 빌드(컴파일)하는 과정을 스스로 수행해야 함
          + Swift 패키지의 경우 swift build 명령으로 쉽게 빌드 가능, Claude가 이를 자연스럽게 처리함
          + 그러나 macOS 앱 타깃(예: Xcode 프로젝트)의 경우, 어떤 xcodebuild 명령을 써야 하는지 Claude가 종종 헷갈려 함
          + 이 문제를 해결하기 위해 XcodeBuildMCP라는 툴을 사용, Claude가 앱 빌드 및 실행을 좀 더 쉽게 하도록 단순화된 인터페이스 제공
     * 2. Test (테스트)
          + Claude는 코드를 빌드한 뒤, 자동으로 테스트를 실행하고 그 결과를 분석할 수 있어야 함
          + Swift 패키지는 swift test로 자연스럽게 테스트를 수행, Claude도 이 과정을 잘 처리함
          + 아직 앱 전체 테스트나 UI 테스트를 Claude가 직접 돌리는 것은 실험하지 않았으나, 이 역시 XcodeBuildMCP와 같은 툴이 필요할 것으로 예상
          + 테스트의 결과(성공/실패 로그)를 바탕으로 코드 수정 루프를 이어감
     * 3. Fix Bugs (버그 수정)
          + Claude는 디버깅을 위해 로그를 추가하는 방식으로 문제를 추적할 수 있음
          + 다만 Claude가 직접 앱을 조작해서 로그를 발생시키는 것은 불가능
          + 사용자가 앱을 수동으로 조작한 뒤, 콘솔에서 로그를 복사해 Claude에 붙여넣는 과정이 필요함
          + 이 방식도 실질적으로 잘 작동하지만, 유닛 테스트나 UI 테스트를 미리 충분히 작성하지 않으면 완전한 자동 버그 수정은 어려움
          + 웹 앱의 경우 playwright-mcp 같은 브라우저 자동화 솔루션이 있으나, 네이티브 앱은 아직 확실한 대안이 부족함
     * 4. Fix UX Issues (UX 이슈 수정)
          + UI/UX 이슈 개선에는 스크린샷을 Claude에 직접 붙여넣어 반복 피드백을 줄 수 있음
          + Peekaboo 같은 도구로 스크린샷 자동화도 가능하지만, 일단 앱을 원하는 상태로 수동 조작해야 스크린샷을 찍을 수 있다는 점은 한계
          + 즉, UX 관련 자동화도 사용자 개입이 여전히 필요함

  11. Claude Code는 코드 작성하는 이상의 일을 함

     * Claude Code는 범용 대형언어모델(LLM)을 기반으로 동작하기 때문에, 코드 작성 외에도 다양한 비개발 업무에 활용 가능함
     * 예를 들어, 앱 내 카피 문구 편집, 릴리즈 플랜 수립, 기능 개선 방향 제안 등 개발 외적인 작업도 Claude에 자연스럽게 요청할 수 있음
     * 특히 유용했던 점 중 하나는, 실제 데이터가 없는 초기 단계에서 Mock 데이터를 자동으로 만들어주는 기능임
          + Context 앱 개발 당시, Swift용 MCP 클라이언트 라이브러리를 아직 완성하지 않은 상황에서도 UI 프로토타입 작업을 진행하고 싶었음
          + 원래라면 현실적으로 보이는 모크 데이터를 직접 만들어내는 작업은 매우 번거롭고 시간이 많이 소요되어, 사실상 시도하지 않았을 것임
          + 그러나 Claude는 몇 초 만에 매우 그럴듯한 Mock 데이터를 자동 생성, 실제와 거의 구분이 어려울 정도의 UI 상태를 만들어줌
          + 실제로 UI를 친구들에게 공유할 때도, 이 Mock 데이터를 기반으로 한 스크린샷을 사용했으며, 실 서비스와 동일한 수준의 인상을 줄 수 있었음
          + MCP 서버의 경우, 당시에는 공식 스펙의 일부 기능만 구현된 상태가 많아 실제 데이터를 얻기 어려운 상황이었음
          + 그럼에도 불구하고, Claude가 생성한 Mock 데이터를 통해 전체 UI 흐름과 기능 동작을 검증할 수 있었음

  12. 고품질 자동화 구현이 (거의) 무료가 된 시대

     * 소프트웨어 출시의 마지막 20%에서 가장 고통스러운 부분 중 하나는, 앱 릴리스 과정의 자동화임
     * 특히 macOS 앱의 경우, 코드 서명, 노타리제이션, 패키징(DMG 생성) 등 복잡한 배포 절차가 많아 수작업이나 불안정한 스크립트로 인해 출시가 지연되는 일이 많았음
     * 기존에는 fastlane 등 자동화 도구를 억지로 세팅하거나, 최소한의 Python 스크립트를 직접 작성해 처리했음
     * 이번 프로젝트에서는 몇 시간의 반복 프롬프트와 디버깅만으로, Claude가 완전한 릴리스 자동화 스크립트를 생성함
     * 이 스크립트가 담당하는 주요 업무:
          + 환경 세팅 체크: 필요한 도구들이 제대로 설치되어 있는지 점검
          + 변경 로그 자동 생성: git 커밋에서 변경 이력을 추출, 수기로 작성한 항목과 합쳐 HTML 릴리즈 노트 생성
          + 앱 빌드 및 패키징: 앱 빌드 → 코드서명 → 노타리제이션 → DMG 패키징까지 전 과정 자동화
          + Sparkle 업데이트 피드(appcast) 생성: 기존 사용자에게 자동 업데이트 전달
          + 릴리스 태그 및 배포: 깃허브에 태그 추가 및 릴리스 게시
          + Sentry 심볼 업로드: 크래시 리포트 분석을 위한 디버그 심볼 자동 업로드
     * 스크립트 완성 후, ""CLI 출력을 더 아름답게 만들어줘""라는 한 줄 프롬프트만으로 CLI UI 개선까지 구현
     * 최종 결과는 약 2,000줄에 달하는 Python 코드로, 수작업이었다면 필수 기능만 구현하고 끝냈겠지만 Claude 덕분에 고품질로 마무리
     * 이 자동화 스크립트 덕분에 릴리스마다 매번 수십 분의 반복 작업을 절약할 수 있게 됨
     * 자연어로 스펙을 설명하고, 실행 중 발견된 오류만 Claude에게 피드백해 수정하게 하면 대부분의 작업이 완료됨

  13. 미래 IDE는 완전히 달라질 것

     * 이번 프로젝트를 진행하면서 실제로 처음부터 끝까지 사용한 툴은 Claude Code와 GitHub Desktop(diff 보기 용) 두 가지뿐이었음
     * 전통적인 IDE의 핵심 기능인 파일 트리, 코드 에디터, 확장 기능, 플러그인 등은 거의 필요하지 않았음
     * 드물게 Xcode를 열어 직접 코드를 고친 적은 있지만, Xcode 특유의 기능(예: SwiftUI Previews, View Debugger 등)도 거의 사용하지 않음
     * 지금이야말로 AI 코딩 에이전트의 역량이 가장 낮은 시점이기 때문에, 앞으로 IDE는 완전히 새로운 형태로 진화할 것으로 예감함

     * Copilot, Cursor, Windsurf 등은 모두 VS Code에서 출발해 기능을 추가한 방식이지만, VS Code 자체는 20년 전 JetBrains IDE와 거의 차이가 없음
     * Warp와 같은 프로젝트는 터미널을 현대적으로 바꿔 에이전트 개발 환경으로 전환하려 하지만, 터미널 중심 UX 역시 미래의 궁극적 해답은 아닐 것이라고 평가함

     * 미래 IDE의 핵심은, 개발자가 에이전트 컨텍스트를 효과적으로 준비(priming)하고, 피드백 루프를 설계·관리할 수 있게 해주는 것에 있음
     * 즉, 코드 에디터가 중심이 아니라, 에이전트 활용과 컨텍스트 관리 중심의 UX로 크게 변화할 것이라는 전망임

  14. 다시 사이드 프로젝트를 출시할 수 있게 됨

     * 이번 여정에서 가장 인상 깊었던 점은 멋진 앱을 만들었다는 사실보다, 다시 직접 사이드 프로젝트를 실제 출시할 수 있게 된 점임
     * 마치 매일 5시간의 추가 시간을 얻은 느낌, 그리고 그 대가는 한 달에 $200에 불과함
     * Claude Code와 같은 AI 코딩 에이전트 덕분에, 오랫동안 미뤄왔던 아이디어를 현실로 옮길 수 있는 동력과 자신감을 다시 얻게 됨

   많이 해라

        Hacker News 의견

     * 2년 전만 해도 나는 진짜 뛰어난 Python 엔지니어였다고 자신했는데, 이제는 네이티브 모바일 앱, Slack과 통신하는 데스크톱 앱, Go로 작성한 API, React 기반의 전체 웹 앱까지 며칠 또는 몇 시간 만에 만들 수 있게 된 상태임
       마치 슈퍼파워를 얻은 기분이고, 생산성·속도·창의성이 샘솟는 느낌이지만, 한편으로 기묘한 슬픔도 느껴짐
       내 직업, 내 열정, 내가 오랜 시간 공들여 익히고 희생까지 했던 모든 일들이 이제 기계에 의해 대부분 대체되고 있음
       이런 툴을 만드는 회사들은 아직 출발점일 뿐임
       다음 세대 엔지니어에겐 어떤 의미가 있을지, 이 흐름이 어디까지 이어질지 궁금함
       혹시 나와 같은 감정 느끼는지 궁금함
          + 여러 플랫폼에서 네이티브, 모바일, Go, React 등 다양한 툴을 효율적으로 다루게 된 건 파이썬 엔지니어로서의 소프트웨어 개발 경험 덕분임
            LLM이 대체하는 영역은 각 플랫폼에 특화된 사소한 내용(트리비아)을 외울 필요가 없다는 점임
            나는 Go에서 for 루프 문법을 외우지 못해도, 바로 유용한 Go 코드를 작성 가능함
            여전히 루프, Go의 개념, 구조적 프로그래밍, 컴파일러, 빌드 및 테스트 스크립트 등 기본 원리를 이해해야 한다는 점은 변함없음
            프로그래밍에 배경지식이 없는 사람에겐 이 부분이 크게 부족함
            LLM은 내 오랜 경력에서 축적한 모호한 지식을 다양한 언어와 플랫폼에 곧바로 적용가능하게 해 주는 증폭기이자 가속기라고 느끼는 중임
            이전에는 Python, JavaScript, SQL만으로 모든 문제를 해결했던 이유가 새 언어·플랫폼의 사소한 차이들을 다시 익히기가 부담스러웠기 때문임
            이제는 Go, Bash, AppleScript, jq, ffmpeg 등도 기꺼이 사용하고, Swift 프로젝트도 고려 중임
          + 비전공자들이 LLM을 써서 뭔가 만드는 걸 본 적 있는데, 대개 훨씬 느리거나 거의 실패임
            기술 스킬이 결국 필수는 아닐 수 있지만, 명확한 의사전달 능력이 반드시 필요함
            HTML을 이해하는 수준만 되어도 텍스트를 깔끔하게 꽂아 넣어 LLM이 더 명확하게 이해하게 만들 수 있음
            여전히 기술적 배경이 장점이라고 생각함
          + 산업혁명 이전 수공업 노동자들도 비슷한 감정을 느꼈으리라고 생각함
            하지만 그들 대부분이 교육도 제대로 받지 못했고, 자녀 중 1~2명은 사소한 병으로 10살 이전에 죽었으며, 전기·수도·실내배관·냉장고 없이 살았다는 점을 감안해야 함
            직접 손으로 도구를 만드는 건 낭만적이지만(마치 파이썬 코드를 수작업하는 것처럼) 시대가 발전할수록 더 추상적인 층위에서 살아가는 게 오히려 조상들에게도 이득이라고 생각함
            누구도 자신이 직접 Python 코드를 짜는 걸 막지 않으며, 흑연세공처럼 취미로 즐기는 사람이 분명 생길 거라 생각함
          + 내가 일궈온 직업·열정·기술을 이제 기계가 대신한다는 생각에 동의하기 어렵다는 입장임
            기계는 경험이나 예지, 반성, 계획능력이나 창의성 없이 그저 지시를 따르는 존재임
            사람만이 아이디어·창의성·목표·공감능력을 갖고, 좋은 아이디어로 다른 사람을 설득하거나 상황에 맞게 맥락을 고려할 수 있음
            프로그래밍이라는 직업이 사라진다기보다는, 훨씬 높은 추상화 단계로 이동 중이라고 생각함
            과거에는 비트와 바이트, 어셈블리 한 줄 안 알아도 개발자가 될 수 있었고, 어셈블리가 필수이던 시절도 있었음
            이제는 프로그래밍 언어 자체를 몰라도, 영어와 요구사항만 잘 알면 프로그램이 만들어지는 시대임
            그래도 메모리 구조, 어셈블리, 저수준 개념을 아는 사람들은 여전히 뒤에서 무슨 일이 일어나는지 더 잘 이해하고, 필요하면 더 ""잘"" 할 수 있음
            그렇다고 상위 추상화 계층이 쓸모없어 지거나 사라진다고는 생각하지 않음
          + 나도 똑같이 느끼고 있음
            20년 넘게 소프트웨어를 프로로 개발했고, 정말 이 일이 즐거웠음
            지금은 Claude Code를 100% 활용하며 생산성이 분명히 올랐지만, 예전의 프로세스가 예술처럼 느껴졌던 반면 지금은 산업화된 대량생산 느낌임
            새 현실에서 소프트웨어에 깊이 빠져들 수 있었던 나만의 무언가를 다시 찾고 싶고, 그 재미가 많이 줄어든 건 확실함
     * 글이 매우 잘 쓰여 있고 읽는 것만으로도 즐거움임
       미래의 IDE는 지금과 전혀 다를 것임
       나 역시 Cursor로 시작해서, VS Code 강화형 IDE를 쓰다 결국 Claude Code로 넘어감
       그러다 보니 터미널의 중요성이 커져서 iTerm에서 Ghostty(빠르고 가볍고 최신임), Tmux, Tmuxinator, NeoVim으로 워크플로우를 넘어감
       cat 또는 bat 명령으로 파일을 확인하고, 간혹 텍스트 편집만 하며, 대부분의 무거운 작업은 Claude Code가 맡음
       NeoVim이나 Emacs에서 명세와 프롬프트만 작성하는 식이고, 이런 워크플로우가 너무 마음에 듦
       코드 생성뿐 아니라 zsh, neovim, ghostty 등 config 파일 수정할 때도 Claude Code로 태스크를 테스크를 할당해서 바꿈
       설정 파일 리팩토링까지 몇 분이면 끝임
       코드베이스 질문, 코드 리팩토링, 코드 문서화, 커밋 메시지 생성 등도 전부 맡겨서 Pure awesomeness임
          + 마지막에 코드베이스 질문, 리팩터링, 코드 문서화, 의미 있는 커밋까지 한다는 이야기가 나왔는데, 나도 CC로 훌륭한 커밋 메시지를 만들어서 Conventional Commits 정보와 예시를 CLAUDE.md 파일에 넣어둔 경험이 있음
          + CC가 .zshrc 같은 개인 설정 파일을 자동 백업해준 다음 변경하냐고 궁금함
     * Terminal + Claude Code + 프로젝트 폴더
       정말 이것만 있으면 충분하다는 걸 이제야 알게 됨
       풀 IDE 세팅이 번거로워서 원래도 안 즐겼고, OS 별로 크로스컴파일하려면 QT 설정도 복잡했는데, 항상 에디터와 터미널 조합이 가장 논리적이라고 생각했음
       여기에 Claude Code가 열린 또 하나의 터미널 창으로 요청 처리 도와주니, 개발자에서 프로젝트 리더로 '레벨업' 한 느낌임
       직원 관리 스트레스도 없음
       지금은 예전부터 해보려던 모든 사이드 프로젝트를 3월 Claude가 떴을 때부터 몇 달 만에 완성함
     * 1, 2년 전에 떠올린 게 있는데, LLM은 숙련 개발자에게는 뛰어난 어시스턴트, 숙련 개발자를 대체하려 하면 엉망, 그리고 미숙련 개발자에겐 위험한 어시스턴트라는 생각이었음
       직접 경험하면 대체로 이 생각이 들어맞음
       지금은 미숙련 개발자에게 LLM이 좋은 멘토가 될 수도 있다고는 생각하지만, 현실에서는 주로 코드의 동작 이유를 이해하지 못한 채 무작위로 수정하다가 그럭저럭 작동할 때까지 시도만 반복하는 경우가 더 많아 보임
       결국 그런 상황에서 LLM은 위험한 어시스턴트라는 초기 생각이 더 굳어진 상태임
       이럴 때는 미묘한 버그나 문제들이 눈치채이지도 않게 코드에 잠복하고, 알아차려도 그 원인을 이해하지 못하는 경우가 다반사임
     * LLM 어시스턴트 덕분에 사이드 프로젝트의 마지막 20% 완성도가 확 줄었다는 결론이 특히 인상적임
       내게 이 여정에서 가장 흥미로운 점은 새로운 앱보다, 코딩에 대한 갈증을 해소하고 깔끔한 사이드 프로젝트를 다시 완성도 높게 배포할 수 있게 된 현재임
       마치 하루에 5시간이 추가로 생긴 느낌이고, 한 달에 200달러면 충분함
     * 나는 작은 유틸리티를 만들 때 주로 활용하는데, 정말 환상적으로 잘 작동함
       launchctl/launchd 태스크 상태(실행/언로드/실패 등)를 OrbStack 메뉴 아이콘처럼 보여주는 유틸리티를 Claude로 몇 시간만에 원하는 모습으로 구현함
          + 나도 스스로 즐길 용도로 iOS 앱과 Wordpress 플러그인을 만들어서 정말 만족했음
            앞으로 더 많은 사람들이 이렇게 할 것 같은데, 다들 github에 코드를 공유해야 하지 않을까 궁금함
     * 2008년부터 Mac용 소프트웨어를 만들어 온 사람이라면 Claude가 어디서 잘못 나갔는지 빠르게 알아채고 바로잡을 수 있었을 거라고 생각함
          + Claude Code 같은 도구는 기존의 스킬과 경험을 증폭시키는 역할임
            결코 전문성을 대체하지 못함
          + 결국 글 마지막에 이 작업이 한 달에 200불이 든다는 사실이 드러나는데, 난 주 취미에 꼭 필요한 Autodesk에도 50불 쓰기 아깝게 느껴질 정도임
            이런 AI 회사들은 수익도 안 나고 투자자가 수익을 찾기 시작하면 비용 급등하거나 서비스 품질 저하가 불가피할 거라 생각함
            이 모델들이 무단으로 학습한 코드를 제공해서 소송에 져버린다면 Claude의 Swift 생성력도 즉시 하락할 것임
            과연 Disney가 AI 소송에서 질 거라 기대해야 하는지 의문임
            솔직히 내 코멘트가 의미는 없지만 AI 피로감이 정말 심각함
            지금 시점에 HN이나 여타 테크 포럼에서도 이런 포스트는 금지하는 게 맞다고 봄
            구글이나 StackOverflow로 쉽게 코드 짰다는 얘기를 누가 올리면 다들 시시하다고 빈정거릴 게 뻔한데, 이런 포스트도 결국 똑같다고 생각함
            AI로 취미나 직업을 ""무임승차""한다는 얘기는 신물남
     * 나만의 맞춤형 툴을 Windsurf 같은 도구와 CLI 툴로 만드는 게 예전보다 훨씬 손쉬워졌음
       정말 흥미로운 시기임
     * 곧 누군가 LLM을 이용해서 MacOS 자체를 복제할 시대가 올 것 같은 예감임
     * 몇 주 전 LLM 툴링을 써서 retro68과 c++로 system 6(클래식 맥) 앱에서 6DOF 와이어프레임 렌더러를 부팅시키는 데 성공함
"
"https://news.hada.io/topic?id=21886","사이드 프로젝트로 7자리 수익내는 사업 만들기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       사이드 프로젝트로 7자리 수익내는 사업 만들기

     * 단 4년 만에 외부 투자 없이 부트스트랩 방식으로 연 100만 달러(약 14억 원) 이상의 ARR(연간 반복 매출)을 달성함
     * 재정적 독립(FI) 커뮤니티에서 영감을 받아 직접 사용할 도구가 없어 ProjectionLab을 사이드 프로젝트로 시작했으며, 현재 10만 가구 이상이 이 서비스를 이용 중임
     * 지속적인 노력과 일관성이 가장 큰 성공 요인이었으며, 혼자서 개발하다가 성장 한계에 직면해 성장/마케팅 파트너와 팀을 이루고, 유저 커뮤니티에서 추가 인력을 영입해 함께 성장해옴
     * 팀 구성원 대부분이 실제 유저 커뮤니티 출신으로, 고객 상담/1:1 세션/튜토리얼 영상 등 고객 경험에 집중해 커뮤니티와의 유대감을 유지함
     * 앞으로도 슬로우 성장, 부트스트랩, 고객 중심 개발에 집중하며, AI 유행이나 무리한 확장보다는 ""사용자들이 정말 좋아하는 제품""을 만드는 데 최우선 목표를 둘 것임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

ProjectionLab 성장 스토리

     * 2021년 FI(재정적 독립) 운동에 감명받아, 더 나은 개인 재무/인생 설계 도구가 필요해 직접 ProjectionLab 개발 시작
     * 첫 Hacker News 포스트로 월 150달러 MRR을 달성했고, 2023년까지 야근/주말마다 개발하며 꾸준히 성장
     * 2023년 9월, 직장 일부분 파트타임 전환 → 2023년 11월, 완전히 퇴사 후 올인
     * 2024년 팀 확장 시작, 성장·마케팅 파트너 및 유저 커뮤니티 출신 컨트랙터 합류

감정과 시행착오

     * 꾸준히 성장한 것처럼 보이지만 매출이 정체된 달, 해지 폭증, 실패의 고민이 반복됨
     * 창업자는 ""포기하지 않는 것""이 창업자에게는 가장 큰 슈퍼파워라고 강조
     * 성공은 머리가 아닌 지속성과 일관성에 달려 있음을 경험함

1인 개발자에서 팀 빌딩으로

     * 처음 2년간 혼자 밤낮없이 개발에 집중, 장기적으로 성장 한계를 느끼고 마케팅/그로스 파트너를 찾기 시작
     * 실제로 가치 있는 기여를 먼저 보여준 파트너(Jon Kuipers)와 합류, 이후 본인은 제품 개발에 집중, 파트너는 성장·마케팅·파트너십에 집중
     * 고객 지원 및 컨텐츠 생산 역할도 커뮤니티에서 직접 영입한 컨트랙터가 담당

커뮤니티와 고객 성공

     * 유저 커뮤니티(Discord)는 이제 8,500명 이상 참여
     * 고객 성공(서포트, 튜토리얼, 1:1 세션) 등도 내부 유저 중심으로 진행해 ""행복한 커뮤니티""가 핵심 경쟁력이 됨
     * 수년간 창업자가 직접 고객 문의를 처리하며 커뮤니티와의 유대감을 쌓음

매출 및 비즈니스 모델

     * 2025년 6월 기준 $83.3k MRR(월 반복 매출) → 연 100만 달러 ARR 달성
     * 구독형 매출 외에도 평생 구독권, 1:1 트레이닝 등 비반복 매출까지 포함하면 월 매출은 실제로 20~50% 더 높음

향후 계획 및 전략

     * 앞으로도 ""직접 써보고 싶을 만큼 좋은 제품""을 만드는 데 집중
     * 외부 자본에 의존하지 않는 부트스트랩, 슬로우 성장, 고객 중심 개발을 이어갈 계획
     * 성장과 수익보다는 지속 가능성과 유저 경험을 우선

사이드 프로젝트 창업자를 위한 조언

     * 아이디어를 검증했다면, 매일 조금씩 개선하고, 성장하지 않거나 힘들 때도 포기하지 않고 꾸준히 할 것
     * ""진짜 창업자가 맞나?""라는 의심이 들더라도 계속 시도하는 것이 결국 성패를 가른다고 강조
     * 장기적으로 작은 꾸준한 행동이 복리처럼 강력한 결과를 만든다고 조언

결론

     * ProjectionLab의 성공은 꾸준함, 유저 중심, 부트스트랩, 커뮤니티에 기반을 둔 성장 사례임
     * 외부 투자 없이도, 커뮤니티와 팀워크만으로도 7자리 ARR을 달성할 수 있음을 입증

   좋은 글 감사합니다.

        Hacker News 의견

     * 성공으로 이어지는 집념과 이미 시간만 낭비하는 고집 사이의 경계선을 걷는 것이 정말 어렵다는 생각 든다
       시장 검증의 일부라도 있어야 내가 제대로 된 길을 가고 있다고 느낄 수 있고, 초반에 사용량이 급증하는 경험은 사업의 가능성을 확인시켜주는 신호라는 점에 공감
       초기부터 블로그 글 작성, 홍보, Discord 운영, 이메일 대응 같은 활동을 소홀히 하지 않은 점이 코드 작업보다 훨씬 중요한 성공 요인이라 생각
       수익이 줄어들 때마다 더 많은 블로그 글로 마케팅을 보완한 부분이 인상적
       이런 경험은 다른 창업자들에게 매우 값진 교훈이라 믿음
       부트스트랩 방식으로 사업을 키운 점도 인상적이며, 쉽지 않은 길이지만 그만큼 얻는 것이 크다는 점에서 본인도 같은 선택 후회 없는 마음
          + 고마움 전하고 싶고, 나도 어느 시기엔 내가 올바른 길을 걷는지 확신이 없었던 시절 있었음
            Poor Charlie’s Almanack에서 ""낮은 기대치가 행복의 핵심""이라는 말을 보고, 이 사업도 나 자신을 위해 만든 게 출발점이었다는 점이 동기부여의 원천이었음을 느낀다
            만약 빠른 성공을 바랐다면 오래 버티지 못했을 것 같다는 생각
            부트스트래핑은 힘들지만 이보다 더 보람찬 방식은 없다는 마음
     * 새로운 프로젝트에서 항상 ‘절망의 계곡’을 넘는 게 힘들었고, 결국 내가 자주 사용하는 제품만 만들고 판매해야겠다는 결론
       내가 꾸준히 사용하는 것이 제품 검증의 출발점이라는 생각이고, 직접 쓰는 것만이 확실한 신호가 된다는 느낌
          + 문제에 깊은 애정을 갖는 것은 일종의 초능력 같음
            애정을 갖지 않았다면 멋진 방식으로 문제를 풀 수 없었을 것
            예전 대기업 엔지니어 시절, 별로 신경 쓰이지 않는 일에 몰입하려 했을 땐 확연히 비교가 안 되었던 기억
     * 축하의 뜻 전하면서, 이번 글이나 연관된 글들에서 수익에 대한 언급이 없다는 점이 아쉬움
       이전 사업에서 2년 만에 50만 달러 매출을 냈어도, 실제 순이익은 연 2만 달러에 불과했던 경험
       창업 커뮤니티에서 ARR만 강조하고 실제 가져가는 수익 수준이 일반 직장 수준에 미치지 못한다는 ‘ARR 함정’이 있다는 생각
       기술 업계에서 연 $250K 소득이 쉽다는 점도 예로 들고 싶음
       무제한 매출은 가능해도, 실제 이익이 중요하다는 점 강조
          + 순이익률이 초반엔 약 90%였지만, 지금은 팀 빌딩과 성장 투자를 하면서 대략 65% 수준
          + ARR이 충분히 커지면 창업자 급여도 충분히 높일 수 있으리란 기대
            극단적 예지만 Uber, Amazon, ServiceNow 같이 초기에 이익 없이도 매출 급증이 창업자에게는 결국 큰 보상이 된 사례
            관련 링크: ServiceNow, Uber, Amazon
          + 매출에만 집중하는 창업 커뮤니티(특히 indiehackers.com)에 대한 피로감 공감
            사실 많은 창업자가 수익 공개를 꺼려서 그렇다는 추측
            그래도 부트스트랩으로 이뤄낸 성장은 매우 인상적
     * 제품 검증에 있어, 처음 매출, 첫 하락, 각 성장과 하락 구간에서 검증이 어떻게 이뤄졌는지 궁금
       예를 들어 사용자 5명이 결제해도 월 100만 달러 검증과는 다르지 않을까
       여기서 제품 검증의 의미가 궁금
          + 사업 목표에 따라 각자 다를 수 있지만, 나에겐 완전히 모르는 사람들이 직접 결제하는 게 중요한 신호
            첫 Show HN 글이 결정적이어서, 이게 없었다면 내 다른 수많은 사이드 프로젝트와 다르지 않았을 거라는 생각
          + 검증은 큰 한 순간이 아니라 작은 확인들의 반복이라는 관점
            처음 사용자 5명도 작은 검증, 1K MRR도 또 다른 작은 검증
            이런 작은 신호가 쌓이면 계속 해볼 가치가 있다는 판단
            글의 요점도 끈기와 작은 검증에 있다고 생각
          + 내가 만든 제품의 월 매출이 6천 달러지만, 내 기준에서 검증의 척도는 매일 결제하는 유저 숫자
            하루 한 명씩만 늘어도 충분히 의미 있다는 점을 공유
     * 성장 마케터와 어떻게 좋은 파트너십을 찾았는지 궁금
          + 처음 그 사람을 찾았을 때 상대방은 오히려 나를 거절했던 일화
            (결국 함께 하게 됐다는 뉘앙스)
     * 미국 고객에 집중하는지, 해외 유저도 신경 쓰는지 궁금
          + 시장에 많은 툴이 국제적 사용성을 간과한다는 점을 보고, 시작부터 글로벌 유연성을 염두에 두고 개발
            물론 고객 중 80%는 미국이지만, 세계 여러 지역에서 사용 중이고, 국제 세금 사전 설정과 계정 타입도 제공
     * 정말 좋은 타이밍에 소개된 제품이고, 원래 직접 만들어보려 했으나 가격도 만족스럽고 동료 창업자를 응원하고 싶다는 마음
       이 길을 걷는 모두에게 긍정적인 영향이 되주어 고맙다는 응원
          + 이런 응원이 큰 의미이고, 당신의 여정도 잘 되길 기원
     * 2021년에 경제적 독립 운동에서 영감 받아, 내 인생을 더 잘 설계하려다 적절한 툴이 없어 직접 개발한 계기 듣고
       이건 금광에 곡괭이 파는 것과 비슷하다고 느꼈지만, 프로젝트를 깎아내리는 게 아니라 본인만의 관찰이라는 첨언
          + 사실 모든 사업은 곡괭이 파는 것과 다름없다는 의견
            우리는 모두 다른 사람을 위한 도구를 만들고 있고, 사용자들이 만족한다면 이를 곡괭이 파는 일로 시비할 필요 없다는 생각
     * 어떤 실수나 다시 한다면 이렇게 하겠다는 점도 궁금
          + 다시 한다면 2년 반이나 주저하지 말고 더 일찍 직장을 그만뒀을 것
            내 예측이 틀릴까 두려워했던 부분 있었는데, 좋아하는 일에 올인할 기회를 놓친다면 더 큰 후회가 남았을 것
     * 축하의 마음 전하고 싶음
"
"https://news.hada.io/topic?id=21937","빌 앳킨슨의 사이키델릭 유저 인터페이스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         빌 앳킨슨의 사이키델릭 유저 인터페이스

     * 맥인터페이스와 MacPaint 등 혁신적 도구를 만든 빌 앳킨슨이 2025년 6월 5일에 별세함
     * 그가 Grace Within이라는 이름으로 활동한 비공개 사이키델릭 커뮤니티 OneLight에서의 삶이 새롭게 조명됨
     * LightWand라는 저용량 5-MeO-DMT(재규어) 증기펜의 개발과 공개로 사이키델릭 경험의 안전성과 접근성을 높임
     * 빌의 오픈소스 접근으로 인해 기존의 고가 리트리트나 소수 집단 중심의 사이키델릭 기술이 대중화됨
     * 이 저용량 접근법이 향후 사이키델릭 치료의 안전성과 실용성을 높이는 연구 방안으로 발전함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

빌 앳킨슨의 이중적 삶

     * 빌 앳킨슨은 오리지널 Macintosh의 주요 엔지니어로, QuickDraw 그래픽 엔진, MacPaint 디지털 드로잉 툴, HyperCard 등 혁신적 소프트웨어를 개발함
     * 그의 삶은 개인용 컴퓨팅 분야에서의 선구적 역할에 대한 호평을 받음
     * OneLight라는 비공개 사이키델릭 커뮤니티에서 Grace Within이라는 가명으로 활동하며, LightWand라는 5-MeO-DMT(재규어) 투여용 베이프펜 기술을 개발 및 공유함
     * 그는 유쾌하고 관대한 인물로서, 재규어의 기술을 열정적으로 공개하고, 이를 통해 다음 세대의 사이키델릭 혁신을 촉진함
     * 공식 사후 그의 적극적 유산 공유 및 혁신이 공개되며, 이는 사이키델릭 분야 내외에서 큰 의미를 가짐

재규어: 5-MeO-DMT

     * 재규어는 5-MeO-DMT의 비공식 명칭으로, 자아 해체 및 일체감, 경외감 등 강렬한 체험을 유발함
     * 이전에는 고용량의 단시간 세션이 일반적이었으나, 이는 심층 명상과 견줄 만큼의 강도와 함께 심리적 위험이나 트라우마 가능성도 동반함
     * 5-MeO-DMT의 치료적 가능성이 현재 10건이 넘는 임상시험에서 중독, 우울증 등 치료 대상로 연구 중임
     * 하지만 건강 상태에 따라 부정적 경험이 발생할 수 있으므로, 주의를 요하는 안내가 중요함
     * 저용량, 점진적 접근이 점차 부각됨

Macintosh에서 ‘신비적’ 세계로

     * 2018년, 빌 앳킨슨은 Majus OneLight가 주최한 의식에서 LightWand 베이프펜을 처음 접함
     * 빌은 평생 의식과 패턴에 대한 탐구를 지속해왔고, Jaguar 체험은 그의 오랜 직관을 확증하는 계기가 됨
     * 처음에는 LightWand의 간편함이 신성함을 약화시킬 가능성을 우려했으나, 섬세하게 희석한 저용량 설계를 통해 안전성과 자기주도성을 높인 점에 주목함
     * 이를 통해 사용자는 보다 주의 깊은 사이키델릭 여정을 경험할 수 있게 됨

LightWand 제작법의 공개

     * 빌 앳킨슨은 LightWand의 공개 및 민주화의 가치를 중시하여, 2021년 “Jaguar (5-MeO-DMT) Vape Pens: How They Are Made by Grace Within”을 Erowid.org에 발표함
     * 이 자료는 LightWand의 제작법을 오픈소스로 공유하여, 고가의 리트리트 혹은 소수 엘리트 그룹에 국한되었던 접근성을 크게 낮춤
     * 빌은 1,000개가 넘는 LightWand 세트를 무상 증정하고, 커뮤니티 내 다양한 제작자들을 지도함
     * 엔지니어적 정확성으로 하드웨어/액상 캐리어에 따른 증기화 및 용량 특성을 기록 및 분석하고, 직접 자신의 신체 데이터(혈압, EEG 등)도 실험에 활용함
     * 이러한 오픈소스 방식으로 대중이 접근가능해졌다는 평가를 받음

LightWand가 불러온 변화

     * 빌은 단순히 기술만 공유한 것이 아니라, 혁신가 및 치료 전문가 세대의 자립적 역량을 강화함
     * 저용량 LightWand는 비용 부담, 심리적 부담을 줄이며 치유와 자기성찰에 집중할 수 있게 함
     * The Pattern Project 팀은 이런 저용량 치료법이 대중적 치료 보급에 있어 ‘가장 연구가치 높은 접근’으로 간주함
     * 빌의 혁신은 복잡한 기술(컴퓨터, 사이키델릭 모두)에 대한 쉽고 직관적 활용 방식을 만들어냈음
     * LightWand는 엘리트가 아닌 다양한 이들이 감정, 기억, 의미와 연결되도록 도구를 제공함

다음 세대를 위한 빛의 전파

     * 기고 공유/후원 등을 통한 The Pattern Project 지원은 빌의 안전하고 책임감 있는 Low-5(저용량 5-MeO-DMT) 탐구 및 지식 공유 사명을 이어가는 힘이 됨

        Hacker News 의견

     * 관련 있음: HyperCard가 LSD 경험에서 영감을 받아 만들어졌다는 Bill의 인터뷰 영상이 있음 유튜브 링크
          + HyperCard와 Timothy Leary의 Mind Mirror는 찰떡궁합이라는 생각임
            Timothy Leary의 Mind Mirror (1985)에 대해 더 알고 싶으면 usc.edu 소개 페이지와 이전 Hacker News 토론, 그리고 유튜브 영상도 제공하고 싶음
            Apple II 플로피 디스크에서 데이터와 텍스트를 전부 추출했으며, 관련 자료는 텍스트 파일 및 github 저장소에서 확인 가능함
     * Bill의 오픈소스 접근 방식이 사이키델릭 경험의 민주화를 이끌어, 기존의 비싼 리트릿이나 소수 엘리트에게만 허용되던 경험을 대중 모두가 접할 수 있도록 만든 점이 놀라움
       해커정신답게 Bill이 정보를 모두에게 개방하려 했던 건 당연한 흐름임
          + 그런 경험을 해봤다면 누구나 이 기회를 세계와 나누고 다른 사람들도 해보도록 하고 싶은 마음이 생김
     * 사진 캡션에 ""Bill과 그의 아이폰 프로토타입""이라고 소개되어 있던데, 그건 아이폰이 아니라 Sony Magic Link임
       이 장비는 Bill과 여러 명(나 포함)이 General Magic에 있을 때 만든 것이고, General Magic은 Bill의 또 하나의 중요한 업적임에도 아직 제대로 이해받지 못하고 있음
          + Magic Leap에 대한 아주 훌륭한 다큐멘터리가 있었음 General Magic The Movie 웹사이트
          + 아이폰 프로토타입 설명을 바로잡겠음. 알려줘서 고마움 - Axle / patternproject.ca
          + 실례지만 누구신지 궁금함. General Magic 관련자분을 정말 존경함
     * 내 Atkinson Dithering 알고리즘 학습 페이지에 이와 똑같은 이미지를 사용함 atkinson.franzai.com
     * 이런 주제에 대해 항상 복잡한 마음임
       오랜 시간 두려움이 몸에 배었고, 사회적으로 금기시되어 왔음
       직접 해본 적은 거의 없지만 몇 번의 경험은 오히려 뇌에 대해 긍정적으로 호기심을 갖게 해줬음
       그런데도 이런 사회적인 금기가 여전히 크게 느껴짐
       가장 놀라운 점은, 해롭기로 소문난 설탕, 술, 담배, 인스턴트 식품들은 사회가 아무렇지 않게 받아들이면서, 정작 내 마당에서 키울 수 있고 덜 해로울 수도 있는 물질들에는 엄격한 금지와 세뇌가 같이 온다는 점임
       12년째 혈당이 높아 고민 중임에도, 쉽게 접근할 수 있는 것들은 더 위험하게 여겨지지 않음
          + 나도 나름의 “모범생”이었음. 사실상 어떤 약물도 손대지 않다가 숙련된 “시터”의 도움 아래에서만 제한적으로 해봤음
            그리고 그 덕분에 집과 좋은 친구들 덕분에 최고의 시간을 보냈다고 자신함
            약물 남용이나 중독에 대한 개인적인 경험도 있어서, 훗날 긍정적 관계를 만들 수 있었음
            시간이 갈수록 내 생각은 완전히 바뀌었고, 앞으로 더 많은 것들을 시도해보고 싶음
            하지만 법적으로 허용되지 않는 한 내 도덕적 기준 때문에 시중에선 하지 않기로 했음
            결국 이 금기는 각자 스스로 고민해야 할 이슈임
            할 수 있는 건 공감 뿐이고 해결은 개인이 직접 해야 한다고 생각함
            또, 어떤 물질이든 좋은 기분을 키우기 위한 용도로만 쓰기를 강력히 추천함
            잃어버린 감정을 쫓는 것만이 전부가 될 필요는 없음. 지금 곁에 있는 것도 충분히 소중함
          + 사회적 금기가 정말 그렇게 심한가? 내가 어울리고 일하는 사람들은 대부분 사이키델릭을 개방적으로 생각하고 어느 정도는 경험한 이들이 많은 편임
     * 세계에서 가장 강력한 사이키델릭이 개인용 컴퓨터인지 5-MeO-DMT(Jaguar)인지 고민됨
       후자는 직접 경험해보지 못해 잘 모르지만, 전자에 마음이 끌림
       Timothy Leary도 내 생각과 비슷했던 것 같음
          + 다양한 사이키델릭을 경험해본 입장에서, 개인용 컴퓨터를 같은 카테고리에 넣는 건 말도 안된다고 생각함
            Leary가 컴퓨터의 심리적 영향에 대해 언급했을 수는 있겠지만, 컴퓨터는 절대 사이키델릭이 아님
     * 이 사이키델릭 커뮤니티가 어디에 있는지 궁금함
       나중에 게임 캐릭터 닉네임 참고용으로 찾아보고 싶음
          + “사이키델릭 커뮤니티가 어디에 있나요?”
            마치 “맥주 마시는 사람들은 어디 있나요?”와 비슷한 질문임
            사이키델릭에 관심 있는 사람들은 정말 다양한 분야에 퍼져 있고, 어디에서나 볼 수 있음
            주위 사람들에게 조금 색다른 이야기를 꺼내다 보면 비슷한 사람을 발견하게 됨
          + 연구나 취미 중심의 사이키델릭 Discord 커뮤니티들도 꽤 괜찮음
          + 기사에서 Erowid가 언급됨
          + Burning Man이나 다양한 페스티벌에서 관련 커뮤니티를 접할 수 있음
          + 근처 Hobby Lobby에 가서 얼핏 물어보는 것도 하나의 방법임
     * 이런 물질의 합법화에 힘쓸 필요가 있음
       물론 주유소에서 OTC 베이프펜 형태로 막 파는 건 아니지만, 중간지점 정도로 의사가 직접 시술하는 방식을 상상함
       나는 아직 DMT는 해본 적이 없고, 다양한 글과 팟캐스트만 통해 알게 됐지만 결코 가볍게 볼 건 아니라고 생각함
       그중 외부기관처럼 “DMT 클리닉” 식의 안전한 접근방식이 적절하다고 봄
       이렇게 오랜 시간 지하에 머물렀던 영역이 점점 주류로 올라오니, 제대로 된 전문 교육을 통해 부작용이나 부정적 요소 대처법 등 모두 양지로 올라올 타이밍이라고 믿음
       그리고 Bill조차 커뮤니티에서 가명을 써야 했던 게 이해되면서도 이상하게 느껴짐
       만약 이미 Apple의 최고경영진들도 이런 물질 경험이 있다면, 대중에게 공개적으로 제공하는 수순을 진지하게 고민해야 할 시점임
          + N,N-DMT는 정말 강렬하고 신중하게 써야 함
            반면 LSD, psilocybin 같은 걸 높은 용량으로 쓰는 게 오히려 더 위험하다고 나 스스로는 생각함
            그 이유는 LSD/psilocybin이 지속 시간이 길어서 나쁜 경험(배드트립) 확률을 높임
            자아 해체나 현실의 완전한 해체가 더 쉬워서 오히려 덜 위험하게 느껴졌던 경험도 있음
          + 참고로 DMT라고 하면 대부분 nn-DMT를 의미함
            이건 5-MeO-DMT(또는 bufo)와는 꽤 다름
          + Oregon 주에서 이런 서비스 도입을 실험 중임 주정부 소개 웹페이지
            “고객은 면허받은 서비스센터에서 훈련된 퍼실리테이터 감독 하에 psilocybin을 접할 수 있음”
          + DMT 클리닉을 꿈꾼다면, 이미 Ayahuasca(주성분이 DMT) 리트릿이 유럽 내에서 점점 늘어나고 있음
            여전히 법적으로 불법이긴 하지만 실제론 온라인으로 예약 가능함
            그래도 나는 평균적인 뉴에이지 ""샤먼""의 실력을 신뢰하지 않아서 이용할 예정은 없음
          + 현명한 합법화 정책이 접근성과 해악 감소에 분명히 도움될 수 있으나, 실제로는 합법화가 제대로 실행되지 못하는 경우가 많음
            샌프란시스코 베이 에리어, 그리고 세계 여러 곳에서는, 환각제 관련 범죄 단속 우선순위가 현실적으로 아주 낮음
            남에게 해를 끼치지 않는 한 문제 삼지 않음
     * 앞으로 psilocybin, DMT 등 여러 사이키델릭에 대한 연구가 계속되고 의미 있는 발견이 이어지길 바람
       예를 들어 최근 뉴스에서는 “psilocin(사이키델릭 버섯에 포함된 psilocybin의 부산물)이 인간 피부와 폐세포의 수명을 50% 이상 연장함”이라는 소식이 있었음 neurosciencenews 기사
     * 5-meo는 아직 안 써봤지만, n,n DMT는 베이프 방식이 가장 간편한 방법이었음
          + 몇 번 써봤는데, DMT와 달리 꼭 기화하지 않아도 됨
            비강이나 입/혀 점막으로도 활성화됨
            효과 면에서도 DMT와 거의 비슷하지만 지속 시간이 더 김
"
"https://news.hada.io/topic?id=21845","cgi-bin으로 하루 2억 리퀘스트 서비스하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       cgi-bin으로 하루 2억 리퀘스트 서비스하기

     * 초기 웹 시대에 널리 쓰였던 CGI 프로그램이 현대 하드웨어에서 여전히 높은 성능을 낼 수 있음을 실험으로 확인함
     * CGI는 프로세스별로 요청을 처리해 메모리 관리가 자동으로 이뤄지고, 배포가 단순한 장점이 있음
     * 벤치마크 결과, 평범한 16스레드 CPU 서버에서도 초당 2400건 이상, 하루 2억 건 이상 요청 처리 가능성을 입증함
     * Go 언어와 SQLite로 작성된 guestbook.cgi 예제 코드 및 Dockerfile을 오픈소스로 공개함
     * CGI는 지금은 흔히 쓰이지 않지만, 여전히 실용적이고 현대적인 대안이 될 수 있음을 보여줌
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

CGI 프로그램과 동작 원리

     * 2000년대 초반에는 CGI(Common Gateway Interface) 프로그램이 동적 웹사이트 구축의 주요 방식이었음
     * 대부분 Perl이나 C 언어로 작성되었으며, 성능 향상을 위해 C가 선택되기도 했음
     * CGI의 개념은 간단하지만 강력함
          + 웹서버는 환경 변수에 요청 메타데이터(HTTP 헤더, 쿼리 등) 설정
          + 별도의 프로세스 생성하여 CGI 프로그램 실행
          + 요청 본문을 stdin으로 전달
          + 프로그램의 stdout을 HTTP 응답으로 캡처
          + stderr 출력을 서버 에러 로그로 전달함
          + 프로그램이 요청을 마치면 프로세스가 종료되어 파일 디스크립터 및 메모리가 자동 해제됨
     * 개발자 입장에서는 신규 버전 배포도 cgi-bin/ 디렉터리에 파일만 복사하면 배포가 끝나 매우 간단했음

Hug of death(트래픽 폭주)

     * 2000년대 초반 웹서버 대부분은 1~2 CPU, 1~4GB 메모리 환경이 일반적임
     * Apache 웹서버가 접속마다 httpd 프로세스를 fork하는 구조 특성상, 다수 접속 시 메모리 요구량이 증가함
     * 동시 접속이 100개를 넘기 힘들었고, 유명 사이트에 링크만 걸려도 서버가 쉽게 과부하되는 경우가 많았음
          + ( Slashdot Effect : 그 당시 유명했던 Slashdot에 링크가 올라오면 트래픽이 쏟아짐. 요즘의 해커뉴스 탑에 오르는 것과 비슷)

현대 서버 환경에서의 CGI

     * 현재는 384개의 CPU 스레드를 가진 서버도 출현, 비교적 작은 VM에서도 16개의 CPU 제공 가능
     * CPU 및 메모리 성능이 대폭 향상됨
     * CGI 프로그램은 별도 프로세스 기반이므로 멀티코어를 자연스럽게 활용 가능함
     * 이러한 점 때문에 현대 하드웨어에서 CGI 프로그램이 얼마나 빠른지 직접 벤치마크 테스트를 진행함
     * 실험은 AMD 3700X(16스레드) 서버에서 수행함

벤치마크 주요 결과

     * 간단한 CGI 프로그램을 Apache와 Go net/http 서버 환경 모두에서 테스트
     * guestbook.cgi 프로그램 설명
          + 방문자가 웹사이트 하단에 댓글을 남길 수 있는 간단한 방명록 프로그램 구현
          + Go 언어와 SQLite 사용, 최대한 단순하지만 현실성 있도록 설계
          + 소스코드와 Dockerfile 모두 GitHub에 공개함
     * HTTP 부하 생성 도구 plow 를 사용해 16개 연결로 10만 건씩 요청 수행
     * 평범한 하드웨어상에서도 초당 2,400건 이상, 즉 하루 2억 건 이상 요청 처리 가능함
     * 현재 CGI가 대세는 아니나, 여전히 실제 서비스 운영에서도 사용 가능함
     * Apache 환경에서의 write 벤치마크
          + 초당 약 2468건의 요청 처리, 평균 6.47ms의 응답 지연 시간
          + 10만 건의 POST 요청을 40.5초 만에 처리
          + 대부분 요청이 7ms 내 응답, 극소수만 100ms 초과
          + 실질적으로 높은 쓰기 처리 성능 입증
     * Apache 환경에서의 read 벤치마크
          + 초당 약 1959건의 요청 처리, 평균 8.16ms의 응답 지연 시간
          + 10만 건의 GET 요청을 51초 만에 처리
          + 절반 이상의 요청은 8ms 이내, 최대 지연도 31ms에 그침
          + 읽기 성능 역시 충분히 우수함
     * Go net/http 환경에서의 write 벤치마크
          + 초당 약 2742건의 요청 처리, 평균 5.83ms의 응답 지연 시간
          + 10만 건의 POST 요청을 36.4초 만에 처리
          + 처리량은 평균 2,742 RPS, 평균 지연 5.8ms로 Apache보다 수치상 더 나은 성능
          + 95% 이상의 요청이 6ms 이내 처리됨
          + Go 환경에서의 CGI도 충분한 실전 성능 보유
     * Go net/http 환경에서의 read 벤치마크
          + 초당 약 2469건의 요청 처리, 평균 6.47ms의 응답 지연 시간
          + 10만 건의 GET 요청을 40.4초 만에 처리
          + 대부분의 요청이 7ms 안에 서비스 가능
          + 읽기 처리량과 응답 속도 모두 Apache와 비슷하거나 우수함

결론 및 링크

     * CGI 프로그램은 최신 하드웨어에서 초고속 동시성, 간단한 배포, 운영체제가 자동 자원 해제 등의 장점 보유
     * 현대적인 프레임워크에 비해 극히 단순하지만, 일정 규모 서비스에는 지금도 실전 활용 가능
     * 방명록 예제 및 벤치마크 실험 데이터는 아래 깃허브에 공개
       https://github.com/Jacob2161/cgi-bin

   헐.. cgi를 다시 사용하게 되는건가요?? ㅎㅎ
   와.. 언제적 cgi인지..

   7/7일자로 업데이트된 내용이있군요.

   Serving a half billion requests per day with Rust + CGI

   5억 리퀘스트라니...

        Hacker News 의견

     * 1990년대에도 C로 작성된 CGI 프로그램이 정말 빠른 속도를 보여줬던 환경 기억, 그러나 에러가 많이 발생하는 점이 단점이었던 점 인정, 기사에 언급된 Go 프로그램이나 Nim 같은 최신 언어, 데이터베이스 연결을 하지 않는 한 로컬호스트에서 굉장히 빠르고 지연시간이 적은 느낌, 마치 CLI 유틸리티에서 fork & exec을 사용하는 기분, 네트워크 레이턴시에 비하면 비용이 거의 무시할 만한 수준이었음
          + 다만 특정 기술에 중독되기 쉬운 문화 언급, 예를 들어 파이썬 인터프리터 같이 시작 비용이 큰 언어에 익숙해지고 나면 멀티샷 혹은 영속적인 모델을 필요로 하게 됨
          + 초창기 HTTP의 원샷 모델은 FTP 서버가 수백 개의 유휴 로그인 세션을 오래 유지할 만큼의 메모리가 부족했던 문제에서 출발한 것이었음
          + CGI에서 pre-forking(지연을 숨길 수 있음)과 Rust 같은 안전한 언어를 결합하면 뛰어난 시스템 설계 가능성 언급, TLS 종단 처리는 멀티스레드 웹 서버(또는 CloudFront 같은 레이어)에서 처리할 수 있어 편리성 강조
               o 상태가 남지 않고, 코어 덤프 및 디버그가 매우 쉬운 환경, 주로 선형적인 요청 모델로 확장도 간단하게 가능
               o stdin에서 읽고 stdout으로 쓰기만 하면 되는 간결함을 찬양, Websockets가 복잡도를 조금 높이긴 하지만 걱정할 수준 아님
               o Java의 부상으로 인해 fork()의 비용과 C의 위험성 회피 목적에서 애플리케이션 서버로의 전환이 급격히 진행된 흐름 상기, 이제 다시 단순성으로 돌아갈 수 있음 주장
               o Rust를 좋아하지 않지만 이런 방식의 웹 백엔드 코드가 손쉽게 작성될 수 있는 시대가 오면 node/js, php, python 개발자들에게도 매력적으로 다가올 것 기대
     * CGI 시절부터 개발을 시작하며 짧게 실행되는 서브프로세스를 돌리는 것에 대한 강한 반감을 가지게 된 경험
          + PHP와 FastCGI가 웹 요청마다 신규 프로세스를 만드는 성능 문제를 벗어나기 위해 만들어졌다는 배경 설명
          + 최근 하드웨어의 발달 덕분에, 프로세스 시작 비용이 실제로 큰 문제는 아니라는 현실을 알게 됨
          + 이 벤치마크가 초당 2000개의 요청을 처리할 수 있고, 수백 개 정도만 처리해도 여러 인스턴스로 확장하기 쉬운 현대적 환경 언급
          + AWS Lambda를 CGI 모델의 재탄생으로 묘사한 의견에 동의, 꽤 적절한 비유라고 생각함
          + 만약 CGI 스크립트를 정적 링크된 C 바이너리로, 크기까지 신경 쓰며 배포했다면 실망이 덜했을 것이라 언급
               o PHP 해석기나 각종 라이브러리 로딩, 파일 파싱 등 동적 링크의 프로세스 시작 비용이 훨씬 큼
               o Go를 쓴다는 것은 25년 전에도 충분히 경쟁력이 있을 수 있었던 방식이라 확신
               o SQLite 데이터베이스 오픈이 컨텍스트 스위치로 소켓을 넘기는 것과 거의 비슷한 성능이며, 원격 mysql 접속과 비교하면 훨씬 빠른 점 강조
               o FastCGI가 새로운 애플리케이션에도 여전히 뛰어난 선택임을 주장
          + CGI는 저부하 환경에서 금전적·성능적으로 부담이 크지 않았음
               o 고부하 상황에서는 FastCGI처럼 지속적으로 실행되는 프로세스가 더 유리
               o CGI도 초당 2,000 rps까지 처리 가능하지만, FastCGI는 훨씬 높은 성능 달성 가능
               o 별도 서버 프로세스 추가 및 업그레이드 시점에 재시작만 하면 되는데, 성능이 중요할 때 가치 있다고 밝힘
          + Go가 등장하기 전에는 CGI 프로그램을 C/C++로 만드는 게 안전성, 개발 난이도 모두 높았던 00년대 상황
               o Perl과 Python은 해석기 시작 및 컴파일 비용이 상당히 컸고, Java는 실질적으로 더 느렸음
               o AWS Lambda = CGI 모델의 환생에 가깝다는 점 동의
               o 지금은 관리형 FastCGI와 거의 동일한 모델로 돌아온 느낌
               o 단순히 실행파일만 업로드해서 돌리면 될 텐데 복잡도를 잔뜩 추가하는 기술의 홍수에 아쉬움
     * 오늘날 서버에 384 CPU 스레드가 달려있고, 작은 VM조차 CPU 16개 가질 수 있는 시대
          + 이런 하드웨어에서 Kestrel로 개발하면 하루에 수조 번의 요청도 무난히 처리 가능
          + PHP와 비슷한 개발 경험을 string interpolation 연산자로 제공 가능
          + LINQ와 String.Join()을 활용하면 HTML 테이블과 중첩 요소를 간단히 템플릿화
          + 진짜 어려운 점은 MVC/Blazor/EF 같은 생태계의 지뢰밭을 잘 피하는 방법을 아는 것
          + 프로그램 전체를 하나의 최상위 파일로 CLI에서 실행하는 방식도 가능한데, ""Minimal APIs""라는 키워드를 모르면 잘못된 문서의 미로로 들어가기 쉬움
               o 코어 기술 위에 추상화 레이어를 덧씌워서 Director/VP 자리를 승진하는 사례가 무척 많다는 점에 놀라움
     * CGI의 장점은 멀티테넌트 환경에서 격리 원시 기능을 새로 구축할 필요 없다는 점
          + 한 요청에 버그가 있어도 프로세스 격리 덕분에 다른 요청에 영향 없음
          + 무한 루프도 선점 스케줄링 덕에 서비스 거부(DoS)로 이어지지 않음
          + rlimit으로 오래 걸리는 요청을 강제로 종료 가능
          + cgroup을 사용해 테넌트별 메모리, CPU, 디스크/네트워크 IO 사용량을 공정하게 할당 가능
          + 네임스페이스/감옥, 권한 분리로 요청마다 접근 권한을 제한할 수 있음
     * CGI 스크립트 덕분에 perl이 빠른 시작 시간을 위해 최적화됐던 이유
          + time perl -e '' 명령 실행 시 perl은 5ms, python3는 33ms, ruby는 77ms로 perl의 빠른 시작 시간 확인
               o tcc mob branch의 #!/bin/tcc -run 방식 스크립트가 perl보다 1.3배 빠르다는 점 언급
               o Julia, Java VM, thread PHP 등도 시작 시간이 매우 길어지는 사례
               o 사람들이 ""큰 환경""에 습관적으로 의존하게 되는 현상
               o Lisp 커뮤니티에서도 이미지를 사용함으로써 이게 반복되고, ""emacs is bloated"" 밈도 여기서 탄생
               o 90년대 중후반 Perl의 전성기는 정말로 CGI 덕분에 가능했던 분위기
               o 당시 getline조차 표준이 아니어서 서드파티 C 라이브러리를 몇백~몇천 라인으로 만들기도 했던 시기 회상
               o 결국 ""평판""에 따라 기술이 선택되고, 대부분 친구가 추천해주는 것으로 학습이 이뤄짐
     * apache tomcat 11을 사용해보면 .jsp 파일이나 전체 java servlet 애플리케이션(.war)을 ssh로 업로드만 하면 그냥 동작함
          + 하나의 공유 JVM으로 최대 성능 확보
          + DB 커넥션 풀, 캐시 등도 어플리케이션끼리 공유 가능
          + 정말 인상적인 경험
               o 실제 사용 패턴에 따라 다름
               o 대용량 서비스에는 훌륭하지만, 50개의 소형 어플리케이션을 각각 하루 수백 건만 처리해야 한다면, Tomcat의 메모리 오버헤드는 CGI 스크립트 기반 Apache/Nginx에 비해 너무 크다는 점 지적
               o 파일을 단순히 복사해서 배포하는 시절이 그립다는 감상
               o 왜 배포 과정이 이렇게 복잡해졌는지 아쉬움 토로
               o 지금도 Jetty로 백엔드 웹앱을 즐겁게 사용 중이라는 경험 공유
               o Tomcat/Jakarta EE/JSP 스택이 의외로 상당히 견고하다는 소감
               o PHP처럼 HTML과 코드를 뒤섞어 쓸 수도 있고, 순수 Java 라우트도 가능
               o Websockets 지원, 싱글 프로세스 멀티스레드 모델이라 실시간 통신에도 강점
               o 필요하면 요청마다 데이터 공유 가능, JSP 코드는 기본적으로 요청 범위로 제한
               o 배포가 정말 쉽고, webapps 디렉토리에 신규 파일만 업로드하면 Tomcat이 자동으로 새로운 앱을 로드 및 기존 앱을 언로드
               o 단점으로는 클래스로더 누수로 인해 garbage collection에 실패할 수 있다는 점, 싱글프로세스 모델의 숙명
     * apache 요청에 대한 시각화 도구 ibrahimdiallo.com/reqvis 제작
          + 데스크톱 브라우저에서 최고의 경험 제공
          + HN 트래픽 데이터를 바탕으로 실제 동작 흐름을 웹에서 확인 가능
     * 요즘 복잡한 아키텍처로 가고 있는 상황이 의심스러웠음, 사실 좋은 하드웨어로 충분히 기존 기술을 쓸 수도 있다는 가능성 언급
          + 수백만 명에게 실시간 주가 정보를 알려주는 시스템 설계 질문에 처음에는 Kafka, pubsub 등 복잡한 스트림 구조를 떠올렸지만, 결국 서버에 정적 파일을 두는 단순한 방식도 고민
          + 이런 방식의 실제 운용 비용 궁금
               o 실질적으로 모든 웹 API의 레이턴시는 DB 쿼리나 ML 모델 쿼리가 결정
               o 나머지 프로세스는 Python 등 느린 언어를 써도 별 거 아닌 수준
               o 변화가 드문 데이터만 반환하면 NIC 한계까지도 쉽게 도달 가능
     * serverless 아키텍처와 비슷하지만, 훨씬 간단하고 저렴한 점 강조
          + 실제로 비즈니스 현장에서 이렇게 사용하는 사례가 있는지 궁금
     * 이런 전통적인 구조를 재고하지 않고 단순히 ""serverless functions""라는 새로운 패러다임만 만들어낸 것에 아쉬움
          + Lambda 같은 serverless function이 별도의 보호 메커니즘(마이크로 VM 등)이 있기는 하지만, 사실상 CGI와 권한 조정만으로도 훨씬 적은 복잡성으로 멀리 갈 수 있었을 것이라 생각

   cgi는 그렇다 쳐도 jsp에 대한 반응이 놀랍네요 ㅋㅋ
   jsp가 벌써 그정도로의 고대 유물이 된걸까요.
"
"https://news.hada.io/topic?id=21885","Smollm3 - 작고, 다국어를 지원하는 긴 컨텍스트 추론 LLM","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Smollm3 - 작고, 다국어를 지원하는 긴 컨텍스트 추론 LLM

     * SmolLM3 모델은 3B 파라미터 크기에서 효율성과 성능을 동시에 추구하는 오픈 소스 LLM임
     * 영어, 프랑스어, 스페인어, 독일어, 이탈리아어, 포르투갈어 등 6개 언어를 지원하며, 최대 128k 컨텍스트 길이까지 확장 지원함
     * dual mode(reasoning/non-reasoning) 로 /think, /no_think 플래그를 활용해 추론 모드 전환 가능함
     * Pretraining, mid-training, post-training의 다양한 학습 단계와 공개된 데이터셋 및 엔지니어링 블루프린트를 전부 제공함
     * 성능적으로 Llama-3.2-3B와 Qwen2.5-3B를 능가하며, 4B 모델에 준하는 경쟁력을 보유함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

   SmolLM3는 3B 파라미터 규모에서 효율성과 성능을 동시에 추구하는 오픈 소스 대형 언어 모델임. 작고 빠르면서도, long-context와 다국어, 추론까지 모두 지원하는 것이 큰 차별점임.
     * 3B 파라미터로 11조(11T) 토큰 학습
     * 최신 성능(SoTA) 달성, 4B 모델과 경쟁 가능
     * 듀얼 모드 인스트럭트 모델: /think와 /no_think를 통해 reasoning, non-reasoning 전환 지원
     * 영어, 프랑스어, 스페인어, 독일어, 이탈리아어, 포르투갈어 지원
     * NoPE, YaRN 적용으로 최대 128k 컨텍스트

   전체 학습 과정의 아키텍처, 데이터 조합, 각 단계별 레시피를 완전히 공개함.

Pretraining

  아키텍처와 학습 설정

   SmolLM3는 transformer decoder 기반이며, Llama 구조를 효율과 긴 문맥에서 성능을 높이도록 수정함.
     * Grouped Query Attention(GQA) : multi-head attention보다 메모리 효율적, 성능 동등 유지
     * NoPE: rotary position embedding을 4번째 레이어마다 제거하여 긴 컨텍스트 성능 개선
     * 문서 내 마스킹: 서로 다른 문서가 서로에게 attending하지 않도록 마스킹하여 안정적인 long-context 학습 지원
     * embedding에 weight decay 제거: 안정적인 학습 동작 확보

   학습 구성은:
     * 2.36M 토큰의 글로벌 배치, 4096 시퀀스 길이, learning rate 2e-4, AdamW(β1:0.9, β2:0.95), weight decay 0.1, gradient clipping 1
     * WSD 스케줄러: 2000 워밍업, 마지막 10%에서 선형 감소
     * nanotron 프레임워크로 분산 학습, datatrove 데이터, lighteval 평가 도구 활용
     * H100 GPU 384대, 24일 학습

  데이터 혼합 및 단계적 학습

   3단계 프리트레이닝:
     * 1단계 (0T→8T) : 웹(85%, 12% 다국어), 코드(12%), 수학(3%)
     * 2단계 (8T→10T) : 웹(75%, 12% 다국어), 코드(15%), 수학(10%) - 더 고품질 코드, 수학 데이터 추가
     * 3단계 (10T→11.1T) : 웹(63%, 12% 다국어), 코드(24%), 수학(13%) - 고품질 코드, 수학 업샘플링, instruction/추론 데이터 도입

   각 단계 데이터 혼합비는 많은 ablation 실험을 통해 최적화됨.

   프리트레이닝 이후 중간(mid-) 트레이닝 과정을 추가 적용해 long-context와 reasoning 성능을 강화함.

Mid-training

  Long-context 트레이닝

   프리트레이닝 이후, 추가 100B 토큰을 투입하여 컨텍스트 길이를 2단계(4k→32k→64k)로 늘림.
     * RoPE theta 조절로 길이 확장
     * 수학, 코드, 추론 데이터 업샘플링
     * NoPE 및 decay mixture로 긴 시퀀스 성능 최적화
     * 학습 시에는 64k까지, 추론 시 YaRN 적용으로 128k까지 처리 가능

  Reasoning 중간 트레이닝

   추론성을 높이기 위해 35B 토큰(OpenThoughts3-1.2M, Llama-Nemotron-Post-Training-Dataset 등)으로 모델을 재학습함.
     * 구체적 도메인 지향 없이, 일반적인 reasoning 능력 학습
     * ChatML 템플릿, wrapped packing 활용
     * 4 에폭(~140B 토큰) 진행 후 체크포인트 저장

Post-training

   대부분의 reasoning 모델들은 폐쇄적 혹은 복잡한 RL 과정을 필요로 했으나, SmolLM3는 공개 데이터와 명확한 레시피로 dual instruction(추론/non추론) 구조를 구현함.

  Chat 템플릿

     * /think, /no_think 플래그를 시스템 프롬프트에 넣어 reasoning 모드 전환
     * XML Tools, Python Tools 별도 섹션 제공하여 코드/툴 호출 지원
     * system 메시지, metadata(date, knowledge cut-off, reasoning mode) 활용 및 유연하게 오버라이드 가능

  Supervised Finetuning(SFT)

   140B reasoning 데이터 미드트레이닝 이후, 1.8B 토큰(SFT 데이터: 논리적 추론/비추론)으로 수퍼바이즈드 파인트레이닝 진행
     * reasoning rare domain 보완 위해 Qwen3-32B를 이용한 reasoning synthetic 데이터 생성
     * Best-fit decreasing packing 등 메모리/효율 극대화
     * 전체 데이터, 학습 스크립트 공개 예정

  Anchored Preference Optimization(APO)

     * SFT 후, Tulu3 프리퍼런스(non-reasoning), Qwen3-32B/0.6B synthetic preference pairs(reasoning) 기반으로 DPO의 변형인 APO로 모델 얼라인먼트
     * triplet prompt + response로 loss 구성, 안정적인 최적화 및 성능 확보
     * reasoning 미드트레이닝 영향으로 long-context 성능 저하가 관찰되어, 모델 머징을 통해 극복

  모델 머징

     * MergeKit 라이브러리 활용, APO 체크포인트 모델스프(0.9)+mid-training 체크포인트(0.1) 비율로 선형 머징
     * 128k 롱컨텍스트 성능 회복 및 전체 성능 유지
     * 최적체크포인트로 최종 모델 릴리즈

평가

  베이스 모델

   12개 주요 벤치마크에서 다른 3B 모델 압도 및 4B 모델과 근접한 성능
     * 문서 이해, 추론, 수학, 코딩까지 고른 강점
     * RULER 64k 등에서 길이 확장 능력 확실
     * Global MMLU, MLMM HellaSwag, Flores-200, Belebele 등 다국어 능력 입증
     * 영어 외 5개 유럽어에서도 일관적 성능

  Dual Instruct / Reasoning 모델

    non-reasoning 평가

   SmolLM3는 Llama3.2-3B Instruct, Qwen2.5 3B Instruct보다 뛰어나며, 4B reasoning 모델급 효율·성능 모두 균형 있음

    reasoning 평가

   /think 활성화시 대부분 벤치마크에서 성능 급등
     * AIME 2025(36.7% vs 9.3%), LiveCodeBench(30.0% vs 15.2%), GPQA Diamond(41.7% vs 35.7%) 등 어려운 문제도 해결
     * Qwen3 4B와 견줄만 한 3B 추론, 수학적 reasoning, 복잡 문제 해결 능력

   듀얼 모드로 속도와 심층 분석 선택 가능

실사용 안내

   SmolLM3는 transformers v4.53.0 이상에서 공식 지원
     * 간단한 코드로 모델 로딩, 프롬프트 작성, 추론 수행
     * reasoning/non-reasoning은 시스템 프롬프트에 /think, /no_think 플래그로 전환

   툴 호출(Agentic)용으로 xml_tools, python_tools 파라미터 지원

결론

   SmolLM3는 3B 규모에서 long-context, 다국어, reasoning을 모두 지원하는 fully open 모델임.
     * 모든 단계별 학습 레시피, 데이터셋, 학습 로그 등 엔지니어링 블루프린트 전면 공개
     * 커뮤니티의 개선과 검증 참여를 극대화할 수 있음

자료

     * 모델, 스크립트, 데이터셋 등: HuggingFaceTB/SmolLM3-3B
     * 논문, 평가, 경량화, 머징 도구 등은 각 GitHub, Hugging Face, 논문 링크 참고

        Hacker News 의견

     * 대부분의 SOTA 성능을 3B 크기에서 달성한 모습, 완전 공개와 코드, 재현 레시피까지 모두 공개한 드문 모델 클럽에 당당히 추가된 느낌. 직접 훈련하려면 약 백만 달러 상당의 GPU 시간이 필요할 것 같음 (4000 GPU/24일 기준), 공유가 풍부한 문서도 인상적, 업계에 긍정적이고 탄탄한 기여라는 평가
          + 실상은 384대의 H100을 24일간 돌려야 하니, 비용이 백만 달러의 절반도 안됨
          + 아침에 Phi-4-mini 벤치마크와 10분 정도 교차검증했는데, 벤치마크에서 해당 모델이 빠진 게 이상했고 전반적으로 항상 뒤처지는 걸로 나옴. 참고로 나는 LLM 클라이언트 개발 중이고, 로컬과 클라우드의 격차를 최소화하는 게 핵심 목표임 (llama.cpp 활용). 현재 마이크로소프트 외엔 로컬 AI를 지속적으로 진지하게 보는 회사가 거의 없음. 평소엔 이런 얘기 덮어두지만, HF가 정말 훌륭한 시민임에도, 슈퍼스타를 언급하지 않은 채 다른 모델의 우수성만 강조하는 건, 이 분야에서 오래된 소타(local SoTA)를 외면하는 결과라 생각, 그래서 이번엔 나서서 이야기하는 것에 의미를 둠
     * 이 모델은 작고 (3B), 벤치마크에서 훌륭한 성능을 보여줌. 엣지/모바일 배포에 잘 어울리기 때문에 gemma3-4b 대비 이득이 큼. 추론/비추론 듀얼 모드 지원, 그리고 전체 훈련 방식을 완전히 공개함> SmolLM3를 엔지니어링 블루프린트와 함께 공개. 세부 구조, 도메인별 성능을 점진적으로 끌어올리는 3단계 프리트레이닝 전략, 하이브리드 추론 모델 구축 방법론까지 포함. 이런 결과 얻으려면 보통 몇 달간 역공학 하는 게 필요하지만, 우리는 전체 방법론을 공개함
     * llama.cpp와 기타 추론 엔진용 챗 템플릿 문제 수정을 직접 했음, 실행하려면 다음 명령어 입력 ./llama.cpp/llama-cli -hf unsloth/SmolLM3-3B-GGUF:Q4_K_XL --jinja -ngl 99
     * Qwen3 distill에 거의 근접한 성능이지만 모델 크기는 75%밖에 안됨, 이건 대단한 일. smollm 베이스 모델은 이미 고품질이라 미세조정에도 꾸준히 써왔고, 가까운 미래에는 로컬 에이전트나 코드 완성에도 쓸 계획. RL 알고리즘도 흥미롭게 보임. 지금까지는 OpenAI 알고리즘 중심으로 작업했는데, 최신 SOTA를 점검할 때가 된 것 같음 (진짜 이쪽 속도는 미친 듯이 빨라서 따라가기 힘듦)
     * 다양한 엔터프라이즈 데이터셋에 파인튜닝하기 좋은 소형 모델 추천이 궁금, 우리 사업부에서 브라우저와 모바일에서 돌릴 수 있는 소형 모델을 찾고 있는데, RAG와 클라우드 리소스 고생 없이 해결하고 싶음
          + 소형 모델은 지식 축적에 약점. 지식을 심으려고 파인튜닝하는 방식은 별로 권장하고 싶지 않음. 대신 오프라인 배포 가능한 내장형 RAG 시스템을 wasm으로 구현하는 게 나아보임, 이 방식으로 성공하는 사례들도 존재
          + 직접 여러 모델을 다 시험해보고 제대로 된 벤치마크를 갖추는 게 중요. 머신러닝이 전문 분야는 아니지만 Mistral 7B 공식 가이드와 툴로 파인튜닝 했을 때도 결과가 기대에 미치지 못함. 데이터 셋에서 아주 특정한 질문을 넣었는데 파인튜닝 변형을 아무리 해도 제대로 답하지 못함. 정보 학습을 기대하는 것보단 벡터 검색+키워드 검색 혼합이 문맥 추출에 훨씬 효과적. 사전 훈련 데이터셋 접근법을 썼고, 데이터 기반으로 Q&A를 합성해서 훈련하는 접근이 더 나을 수 있겠지만, 그 방법까지 실험할 시간은 부족했음
          + Gemma 3N 2B로 파인튜닝해 봤는데 성능 좋음, 다만 S23U에서 로딩이 느림. 일단 띄우면 잘 돌아감. SmolVLM 256M, 500M도 써봤는데 훨씬 빠르게 뜨고 앱에 자산 형태로 포함시킬 수 있음, 어느 정도 노하우 있으면 쓸 만함. 다만 작은 모델들은 파라미터 한계로 성능이 제한적. 그리고 안드로이드에선 2GB 이상 파일은 압축 이슈로 배포가 안 되니까 모델은 따로 받아야 하고, 또 다운로드 폴더에선 바로 로딩이 안 되기 때문에 앱 전용 폴더로 복사해야 함. Gemma 3N 2B가 3.14GB인데 최소 7GB 여유 공간 필요
          + 이런 식으로 파인튜닝해서 얻고자 하는 목적이 궁금
     * 영국 코미디 스케치 소재 같은 부분""이거, 소형이라면서도 대형 언어모델이라고요?""""네, 정말 작아요.""""근데 어떻게 크면서도 작죠?""""대형 언어모델 기준으로 보면… 작아요.""""즉, 크단 말이죠?""""맞아요, 꽤 커요.""""뭐랑 비교해서 큰 거죠?""""소형 언어모델이랑요.""""그럼 ChatGPT 같은 건 뭐죠? 대형 중에서도 대형?""""정확해요. LLLM이죠.""
          + 호주풍 코미디 느낌, Clarke and Dawe/Utopia 스타일을 연상
          + 기준 자체가 계속 변함. GPT-2는 한때 ""대형""이었지만, 지금은 이 모델 크기의 절반 수준. 게다가 Sam Altman은 그때 GPT-2조차도 위험해서 공개 못 한다고 했음. 내 기준에선 소비자용 기기에서 못 돌리면 ""대형""이고, 정의를 놓고 논쟁하는 건 의미가 약함
          + 미니어처 거대 우주 햄스터는 건드리지 않겠음 (BG 게임 유머)
          + big little planet이냐, small big planet이냐 헷갈림
     * 듣기로 llama3 모델들은 꽤 파인튜닝이 쉽다고 알고 있음 (혹시 틀렸거나, 여기 더 괜찮은 모델이 있다면 지적 부탁). smollm3의 파인튜닝 난이도는 어느 정도인지 궁금, MoE LLM들은 그 부분에서 유난히 변덕을 부리는 느낌
     * 흥미로운 점은, RL을 자체적으로 적용하지 않고, 대형 데이터셋에서 추론 흔적(reasoning trace)만으로 파인튜닝을 했다는 부분
          + 실제론 Anchored Preference Optimization 같은 오프라인 방법을 사용함, Open R1 프로젝트에서 봤듯 소형 모델에 멀티태스크 RL 적용하는 건 꽤 만만치 않은 일. 오프라인 방법은 데이터셋 큐레이션/생성이 핵심이라 반복 속도가 훨씬 빠름. 우리가 다루는 모델 스케일에 적합한 방식임
     * 멋진 작업, anton 및 관계자들에게 존경 전함. 50~100M 파라미터 크기의 모델들도 계속 이어지길 바람. Solve by LLM 테스트 케이스처럼 CPU에서 신속하게 끝나는 모델도 충분히 의미 있다고 생각
"
"https://news.hada.io/topic?id=21911","함수는 왜 "호출한다"고 표현할까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          함수는 왜 ""호출한다""고 표현할까?

     * 프로그래밍에서 함수를 ""호출한다"" 는 표현의 기원은, 도서관에서 책을 ""청구""하거나 ""부르는"" 개념과 유사함
     * 초기 컴퓨팅에서는 서브루틴을 라이브러리에서 소환, 호출하는 방식이 주를 이룬 경향이 있음
     * Fortran II가 CALL 명령어를 도입하면서 ""to call 함수""라는 표현을 빠르게 대중화함
     * 이후 Algol 및 JOVIAL 등의 언어도 이를 받아들여 ""call""이라는 명사를 사용하게 됨
     * ""call""의 의미는 런타임 제어 이전, 중, 이후로 점차 확대되어 정착됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

왜 프로그래머는 함수를 ""호출(call)""한다고 말하는가?

     * StackExchange에서 ""함수를 호출(call)한다""는 표현의 기원에 대해 질문이 있었음
     * 여러 비유가 있지만, 실제로는 ""call""이 소환(summon)하거나 불러온다는 의미에서 유래함
          + 도서관에서 책을 ""청구""하는 것처럼, 서브루틴을 ""청구""해 사용하는 것에서 시작
          + ""call number""가 도서관에서 책의 위치를 나타내는 표식임

도서관 용어에서의 ""call""의 역사

     * OED에 따르면 Melvil Dewey가 1876년에 도서관 과학 용어로 ""call number""를 처음 사용함
          + ""call number""는 책의 위치나 청구 요청에 쓰이는 표기임
     * 1888년의 Library Journal에서도 ""call blank"", ""call slip"", ""call number"" 등의 용어가 일상적으로 사용됨
     * Joudrey & Taylor의 해설에 따르면, ""call number""는 닫힌 서가에서 자료를 부르는 행위에서 나온 명칭임
          + Cutter number 같은 체계는 분류를 위해 도입됨

컴퓨터 과학에서의 ""call"" 사용 초기

     * John W. Mauchly의 1947년 논문에서는 서브루틴 라이브러리에서 서브루틴을 ""called in""하여 사용하는 사례가 등장함
          + 기록된 번호로 빠르게 참조해 사용한다는 맥락
     * MANIAC II 어셈블리 루틴(1956) 역시, 각 서브루틴에 ""call number""를 부여하고 이를 통해 필요할 때 불러오는 개념이 적용됨
          + 실제 어셈블리어에서는 ""transfer control""로 지칭했음
     * 이 시기에는 런타임에서의 ""호출""보다는, 컴파일 또는 링크 시점에 코드 조각을 불러오는 개념이 강조됨

프로그래밍 언어에서 ""CALL"" 명령의 등장

     * Fortran II(1958) 가 CALL 및 RETURN 명령어를 도입
          + ""호출(call for)""이라는 동작으로 서브루틴에 실행 제어를 넘김
          + CALL 명령어가 실제로 ""호출""하는 구문적 행위를 가리킴
     * 점차 런타임에서 ""control을 transfer""하는 것과, 링크/어셈블 시점의 ""호출"" 행위가 모호하게 섞이기 시작함

1960년대 ""call""의 의미 확장 및 정착

     * Sarbacher(1959) 의 사전에서는 ""call in""을 메인 루틴에서 서브루틴으로의 제어 이동으로 정의
          + ""call number""와 ""call word""로 식별자, 호출 코드까지 설명함
     * JOVIAL(1960) 에서는 ""procedure call"", ""calls"" 등이 공식적으로 명사로 사용됨
          + 이후 호출 시점(site), 인수(argument), 파라미터 등 다층 의미와 함께 사용됨
     * Algol(1959~1960) 도 ""procedure call"", ""called procedure"", ""during the call"" 등 호출 시점을 다양하게 표현함
          + Peter Naur의 Algol 60 리포트에서도 ""call for""와 ""during the call""이라는 시간적 의미 구분 등장
     * Burroughs Algebraic Compiler(1961) 에서, 동사형 ""to call""이 명확히 처음 나타남
     * Corbató 등(1963) 이후로 현대적 용법인 ""to call a subroutine""이 일반화됨

결론

     * Fortran II의 ""CALL X"" 명령이 함수/서브루틴 호출에 ""call"" 표현을 자리잡게 함
          + 이전의 도서관적 개념(번호로 부름)에서 착안했으나, 프로그래밍 언어에서 새로운 의미 확장
     * 이후 Algol, JOVIAL 등 다양한 언어가 ""call"", ""call site"" 등 용어를 받아들임
     * 1961년 무렵부터 ""to call X""라는 표현이 공식적인 프로그램 문서와 커뮤니티에서 정착되기 시작함
     * 오늘날 함수 호출은 임시로 제어를 넘기고, 결과를 받은 후 복귀하는 일련의 작업 전체를 지칭하며, ‘** call**’ 이 그 표준 용어가 됨

        Hacker News 의견

     * 'call'이라는 단어의 원래 의미(물리적 도서관에서 자료를 정리하는 데 쓰였던 call number에서 유래함)가 'compiler'라는 용어의 탄생에도 영향을 주었다고 Grace Hopper가 설명함. 각각의 서브루틴에 'call word'가 부여되었고, 도서관에서 자료를 꺼내 조합하는 것처럼 프로그램을 만든다는 개념에서 비롯된 것임
          + 나는 이 용어들을 직접 사용함
          + 이제야 비로소 퍼즐이 맞춰짐을 느낌. 듀이십진분류체계의 식별 숫자는 'call number'라고 불렸음
     * Library Science(문헌정보학)가 현대 컴퓨팅 분야에 우리가 상상하는 것보다 훨씬 더 많은 기여를 했다고 생각함. 예를 들어 데이터베이스 인덱스를 설명할 때 카드 카탈로그 이미지를 자주 꺼냄. 저자명, 듀이 십진, 주제별로 찾을 수 있는 나무 서랍장을 보면 다들 바로 이해함. 도서관 카탈로그 개념 참고
          + 나는 로컬 도서관에서 나무 서랍장과 종이사전 같은 것들을 써봤던 세대임. 25년 전 해시맵이나 IDictionary를 처음 접했을 때 이 이미지 덕분에 바로 감이 잡혔음. 하지만 요즘은 이 은유가 그다지 더 도움이 안 됨. 직접 카드 카탈로그나 사전이 어땠는지 설명해야 하는 상황이 종종 있었고, 젊은 사람들은 ""아, 그러니까 그게 아날로그 해시맵이군요""라고 말함
          + 몇 달 전만 해도 왜 터미널의 표준 폭이 80자인지 궁금했었음. 예전 PC 화면 크기 때문이라고 생각했음. 그런데 알고 보니 펀치카드가 80자였기 때문이고, 펀치카드의 시작도 결국 인덱스 카드였던 셈임. 또 한 번 문헌정보학에 경의를 표하는 계기였음. 이건 마치 자동차 너비가 말 엉덩이 두 개 크기에서 유래한 것과 비슷한 컴퓨팅 역사 같음
          + 1~2년 전에 도서관 구석에 있는 먼지 쌓인 나무 서랍을 데이터베이스에 빗대어 설명한 적이 있음. 맥락과 선이해가 정말 중요함
          + 나는 항상 책 뒤쪽의 색인이 컴퓨팅 용어에서 'index'라는 단어가 나온 시초라고 생각해왔음. 'index cards'와 연결지은 적은 없었음
          + 요즘 젊은 세대는 카드 카탈로그 자체를 본 적이 없을 수도 있음. 나는 하드디스크가 0과 1이 나열된 리스트임을 설명하고, 뭔가를 찾으려면 구조가 필요하다는 점을 유추하도록 함
     * 핀란드인임. 핀란드어에서 '함수 호출'에 해당하는 단어는 'kutsua'인데, 영어로 다시 번역하면 'invite'나 'summon' 임. 즉, '엄마가 아이를 마당에서 부르는 것' 같은 '호출'의 의미로 쓰이지, 'Joe가 친구에게 전화를 건다'거나 '이 색을 뭐라고 부르지?' 할 때의 call과는 쓰임이 다름. 그냥 공유하고 싶었음
          + 독일어에선 'aufrufen'을 쓰는데, fragment 단위로 번역하면 '불러 올린다' 정도임. 학교에서 학생 이름 부를 때 같이 직접 목적어와 함께 쓰면 누군가를 name이나 번호로 부르는 의미임. 전화 걸다에 해당하는 단어는 'anrufen'임
          + 'summon'은 뭔가 코드에 오컬트적 공포를 불러올 때도 있는 것 같고, 때로는 매우 적절함. 'invite'는 악마나 뱀파이어를 초대하는 것일 수도 있다고 느끼기도 함
          + 노르웨이에서는 'funksjonskall'을 쓰는데, 직역하면 function call임. 단순히 무언가를 부르는 call 의미임
          + 러시아어도 비슷해서, 역번역하면 '전화로 부르다', '소환하다', '초대하다' 등임
          + 직접적인 주제는 아니지만, 혹시 헬싱키에 있다면 현지 Hacker News 밋업에 참여하면 좋겠음
     * Wilkes, Wheeler, Gill (1951)이라는 책에서 'call in'이라는 문구가 서브루틴 실행에 쓰임. 31페이지에 ""서브루틴이 바르게 호출되지 않으면 기계가 멈춘다"", ""어떤 프로그램에서든 자유롭게 서브루틴을 호출할 수 있다""는 내용이 있음. 1950년 EDSAC 초기 보고서에도 ""call in auxiliary sub-routine""이라는 주석이 남아있음을 이 프리젠테이션에서 볼 수 있음
     * 가끔씩 'call' 보다는 'invoke'나 'execute'도 쓰이지만, 더 길고 일반적인 용어임. 그런데 'call'이라는 용어가 잘못 쓰인 상황(""calling a command"", ""calling a button"")이 비영어권 CS 학생들에게서 많이 들려오는데, 그게 좀 거슬림
          + 'invoke'는 라틴어 invocō, invocāre(불러 일으키다)에서 왔으니 잘못된 게 아니라 약식 표현임
          + 가장 흔히 듣는(혹은 싫어하는) 잘못된 예는 'return'과 같이 쓰는 것임. ""이제 return 키워드를 호출하면 함수가 끝나요"" 같은 표현을 들은 적이 있음
          + C#은 대리자나 reflection 같은 곳에 'Invoke'를 자주 쓰면서, 디버거에서는 'Call Stack'을 씀
          + 내 경험상 프로그래밍을 처음 배우는 원어민들도 비슷한 용법을 씀. 그들은 명령이 아닌 것들도 'command'라고 설명함
          + 초보자가 아예 반대로 statement나 함수 선언 전체를 'command'라고 부르는 경우도 종종 봄
     * 과학 이론은 아니고 그냥 한 가지 관찰임. 새로운 용어는 뭔가 통하는 지점이 있을 때 전파가 잘됨. 대개 짧고, 의미나 이미지를 쉽게 연상/기억할 수 있어서 빠르게 퍼짐. 때론 설명이 필요하지만 맥락만으로도 사람들이 익혀서 전파함. 예를 들어 'salty' 같은 단어가 그렇고, call도 마찬가짐. 짧으면서 자주 쓰이니 입에 잘 붙고, call up/call in/summon/invoke(마법 주문 같은 느낌) 모두 느낌이 맞아떨어짐. 당시엔 전화기도 새롭고 신기한 기술이었으므로, 다른 사람에게 전화를 거는 이미지를 서브루틴 호출에 비추어 쉽게 연결지었을 것임. 'jump' 같은 용어는 이미 다른 의미로 쓰이고 있었으니 call이 널리 퍼질 수 있었다고 생각함
          + 나에게 'salty'는 tears와는 별 상관 없음. 내 언어습관에서는 누군가 'salty'하다는 건 슬프다는 게 아니라 짜증나거나 불쾌한 상태임. 즉, 소금처럼 맵고 강렬하다는 이미지에서 비유가 나옴. 즉, 서로 해석이 달라도 은유는 잘 통한다는 점에서, call이 그런 식으로 퍼질 수 있었음을 보여줌
     * ""... 복잡한 것들은 라이브러리, 즉 자석 테이프 세트(이전에 작성된 가치 있는 문제가 저장된 곳)에 있어야 한다""는 문장에서 라이브러리라는 단어가 실제로 라벨 붙은 자료 선반에서 유래된 것이라는 생각을 해본 적이 없었음
          + EDSAC의 원조 링크인 Margaret Hartrey가 종이테이프 서랍에서 라이브러리 서브루틴 테이프를 꺼내는 메이킹 영상에서 확인할 수 있음. 전체 영상도 볼 만함
          + 라이브러리가 다른 이름으로 불린 적을 들어본 적 없음. 대표적으로 .lib 파일 확장자가 있음
     * 함수가 굳이 call이라는 키워드를 필요로 했던 건 아니라고 생각해왔음. 함수는 보통 값을 반환하므로 대입문 안에 사용하면 됨. call이 필요한 건 subroutine(실질적으로는 이름이 붙은 주소/레이블)이었음. 사실 GOTO로도 이 주소를 직접 이동하고 다시 올 수 있음. CALL 키워드 덕분에 실행 흐름이 더 명확하게 보임. 마치 사장이 Sam에게 계산을 맡겼다가, Bill에게 TPS 리포트 인쇄를 맡기는 것처럼 일의 흐름이 진행됨. 결국 모든 것이 함수로 바뀌었고 subroutine은 'spaghetti'라는 별명으로 불렸음. 그런데 왜 routine(프로그램)과 subroutine이라는 용어가 있는지 궁금함
          + routine이라는 단어의 유래는 1947년 Goldstine과 von Neumann의 문서에 따르면 ""문제의 코딩된 일련의 명령을 routine이라 부릅니다""라고 명시되어 있음 (참고)
     * 음악에도 ""call and response""라는 표현이 있음. return value 개념과도 연결된다고 생각함
     * Algol 60도 함수뿐만 아니라 파라미터에 대해서 ""call""이라는 용어를 썼음. 예를 들어 ""call by value"", ""call by name"" 등인데, 4.7.5.3에 보면 ""call by value인 경우""라는 구조가 나옴. 오늘날에는 procedure/function/subroutine은 'call'하고, argument/parameter는 'pass'한다고 말하기 때문에 'pass by value/reference/name'이 더 명확함. 하지만 ""call by value"" 등의 옛 용어도 아직 일부 문맥에선 남아 있음. Argument나 parameter를 호출(call)하는 개념은 사라졌으나 이런 legacy 용어는 계속 존재함
"
"https://news.hada.io/topic?id=21878","내가 저장해 둔 Pocket 링크들로 o3를 이용해 나를 프로필링해 보았음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               내가 저장해 둔 Pocket 링크들로 o3를 이용해 나를 프로필링해 보았음

     * Pocket 서비스 종료를 앞두고 7년간 저장한 약 900개의 기사 데이터를 분석함
     * o3 챗봇을 활용하여 단순한 URL 목록만으로 포괄적인 개인 프로파일링 실험을 진행함
     * o3는 나이, 지역, 직업, 가족 상황 등 세밀한 개인 정보를 상당히 정확하게 추론함
     * CSV 데이터를 직접 복사해 붙여넣을 때 분석 정확도가 파일 첨부 방식보다 확연하게 높음
     * 이와 같은 기술은 누구나 활용할 수 있어 기업 수준의 데이터 분석이 개인에게도 개방되는 흐름이 강조됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Pocket 아카이브 데이터 분석 과정

     * Pocket 서비스가 종료를 앞두고 있어, 작성자는 자신의 저장 글 전체(약 900개, 약 7년 분량)를 내려받아 xsv 툴로 간단하게 분석함
     * 데이터에는 제목, URL, 저장 시각, 태그, 읽음 상태 등이 포함되어 있음
     * 가장 오래된 기록은 2018년 7월, 최신 기록은 2025년 6월임

o3 챗봇을 통한 자기 프로필링 실험

     * Simon Willison의 o3 geoguess 챌린지에서 착안, 자신이 Pocket에 저장한 링크 목록만을 o3에게 제시하여 본인에 대한 최대한의 프로필 추론을 요청함
     * 구체적으로 o3에게 다음과 같은 차원을 바탕으로 분석을 요구함
          + 나이, 성별, 지역, 학력, 직업, 수입, 정치 성향, 투자 성향, 정보 소비 방식, 가족 및 건강 상태 등

o3의 분석 결과

  핵심 인구통계 추론

     * 나이: 30대 중후반 ~ 40대 초반 (직무 경력, FIRE 계산, 양육 관련 저장글 반영)
     * 성별: 남성 (공학/해킹 문화 집중, 아버지 중심의 육아 글 등)
     * 거주지역: 미국 버지니아 해안 지역 (지역 부동산, 뉴스 중심의 기사 저장 경향)
     * 학력: 컴퓨터공학 관련 학사 또는 석사 (심층 보안/AI 논문, Unix 역사, 학술 PDF 등)
     * 산업 및 직무: 보안 및 인프라에 특화된 시니어/스태프 소프트웨어 엔지니어 (취약점, 포지션 관련 글, 보안 커리어 라더 등)
     * 수입: 약 15만~22만 달러 가구 소득 (연봉대, FIRE 산출, 고소득자 절세 등)
     * 가족/관계: 기혼, 어린 자녀 3~4명 (쌍둥이 엄마 수면 글, 가톨릭 가족 테이블, 홈스쿨링)

  심리 및 성향

     * 정치: 경제적으로 보수적, 시민 자유주의 + 전통사회 지향 (절약, 가톨릭 컨텐츠, 개인정보 보호, 빅테크 검열 비판 등)
     * 위험 성향: 직업적으로는 높음(보안 연구, 부 프로젝트), 금융적으로는 중간(인덱스 투자, FI/RE, 자립 지향)
     * 학습 스타일: 자기 주도, 텍스트·롱폼·오디오 위주(Pocket, RSS, PDF, 팟캐스트, 컨퍼런스 강연 수집)
     * 정보 소비: 심층 테크 60%, 재테크/FIRE 20%, 육아/가정 10%, 신앙/문화 10%
     * 주요 인생 패턴: 순수 엔지니어에서 기술 리더십·가족 중심 삶으로 전환, FI 목표
     * 연중 이슈: 연말/연초 커리어 플랜, 여름 홈스쿨링·부동산·해변, 가을 보안컨퍼런스

  세부 단서

     * 신앙: 가톨릭·보수적 기독교 사이트 정기적 저장, 실천적 신앙인
     * 개인정보 및 자가 호스팅: 실험적 시도 후 실용적 이유로 포기 경향
     * 메이커 기질: 목공·음향·E-ink DIY 등 손수 프로젝트 선호
     * 건강관리: 실용적 바이오해킹(수면, 유산소, Huberman)
     * 글쓰기 욕구: 퍼스널 브랜딩, 블로깅 저장글 등 자기 생각 정리 욕구 꾸준

  간략 ""사용자 매뉴얼""

     * 동기: 자율성, 전문성, 절약, 가족 시간, 신앙 실천
     * 맹점: 무한 분석/연구(읽지 않은 글 대량 저장) 경향
     * 최적 콘텐츠 형태: 롱폼 아티클, 이동/집안일 중 팟캐스트, 코딩은 인터랙티브 문서
     * 현재 주요 목표: FIRE 계획 완성, 공개 보안 툴 출시, 홈스쿨 커리큘럼 공식화, 지속적 블로깅

실험자 소감

     * 실제 o3의 분석 결과는 자신의 나이, 지역, 가족 구조 등을 놀라울 정도로 정확히 맞춤
     * 단순히 해커뉴스 위주 저장글이라고 생각했으나, 개인 ""좋아요"" 데이터만으로도 상당히 깊이 있는 추론이 가능함을 체감

데이터 입력 물리 방식에 따른 결과 차이

     * CSV 데이터를 직접 붙여넣기 방식이 파일 첨부 방식보다 o3의 분석 품질이 높음
     * 파일 첨부 시 o3가 데이터를 코드로 세부 샘플링/분석하려는 데 지나치게 집중하게 되어, 스토리텔링이 약해짐

시사점

     * 광고 회사들이 평소 관심사 데이터로 우리를 프로파일링해왔다는 것은 모두 알고 있음
     * 이제는 Google, Facebook 등만이 아니라, 누구나 이 수준의 데이터 해석·분석 능력을 쉽게 활용할 수 있다는 것이 더 중요한 포인트임
     * 작성자는 이 분석 결과를 개인화 콘텐츠 추천 시스템 개발에 활용할 계획임

        Hacker News 의견

     * 이 글을 읽고 나도 Pocket 계정의 아카이브(4200개 항목)가 있다는 걸 깨달아서, 동일한 프롬프트로 o3, Gemini 2.5 Pro, Opus 4에 시도해봄
          + chatgpt UI는 입력이 너무 크다며 제출을 막았고, 실제론 8만 토큰(오히려 o3의 20만 컨텍스트보다 적음)이었음
          + gemini 2.5 pro는 개성과 관심 관련 프로필은 잘 생성하지만, 나이대, 직업, 위치, 부모 여부 등은 잘못 예측함
          + opus 4는 꽤 인상적으로 내 기본 거주지(암스테르담), 나이대, 연애상태 등 정확히 예측하지만, 부모 여부는 언급 안 됨
          + 두 모델 모두 내 역할 예측에는 실패, 아마 당연한듯함
          + 나는 데이터 사이언티스트지만 소프트웨어 엔지니어링 실무나 시스템 디자인 같은 주제를 공부하며 개인 프로젝트로 코딩함, 그래서 그런지 두 모델 모두 나를 소프트웨어 엔지니어로 봄
          + 실험 자체는 재미있었음
          + 또 한 가지 흥미로운 점은 두 모델 모두 내 주요 취미가 사진이라고 언급했지만, 만약 유튜브 시청 기록을 같이 참고했다면 분명히 테니스라고 했을 것임
          + 보통 글로 보는 것보다 영상으로 접하는 취미와 관심사는 유튜브 데이터와 Pocket 아카이브를 합쳐 분석하는 것이 흥미로울 듯, 다만 데이터 수집이 여전히 도전임
          + Google Takeout으로 유튜브 데이터(시청 기록 포함) 모두 내려받기 가능
               o 이 블로그에 자세한 예시 있음
               o https://blog.viktomas.com/posts/youtube-usage/
               o 유럽에선 법적으로 데이터 제공 의무가 있어서 당연하지만, Takeout은 전세계에서도 활용 가능할 것임
          + 소프트웨어 엔지니어(SWE) 분야로 이직을 노려볼 만함
               o 현재 업무가 항상 미래 커리어와 같을 이유 없음
          + 대량의 입력 데이터는 다단계 프롬프트로 정제
               o 우선 저렴한 모델로 원시 데이터를 여러 청크로 압축, 이후 점점 성능 좋은 모델로 더 큰 데이터셋을 요약, 원하는 수준까지 반복 적용
          + o3를 쓸 때는 파일을 압축해서 업로드하면, python, grep, shell을 이용해 내용을 조사 가능
               o sqlite db에는 아직 시도 안 해봤지만, 이런 방식으로 로컬 에이전트 작업 진행
          + 8만 토큰을 읽으려면 실제로 8만 토큰보다 많은 입력 오버헤드 소모 발생
     * Pocket 익스포트에서 가장 크게 느낀 점은 저장한 글의 99%가 ‘읽지 않음’ 상태
          + 나에 대해 추론할 수 있는 건 아마 강박적인 링크 수집 취향 정보뿐일 듯 :D
          + 수년 동안 Pocket을 ‘다시 일에 집중하기 위한’ 자기 허락 도구로 활용
          + 읽지 않았더라도 해당 링크를 저장한 이유가 있음
          + 읽은/읽지 않은 항목을 비교하면 내가 원하는 것과 실제 행동 사이의 차이를 파악 가능
               o 대부분의 사람의 읽지 않은 목록은 ‘열망’의 결과라고 봄
               o 예를 들어 아마존이 추천 알고리즘에서 위시리스트와 실제 구매 항목을 다르게 다루는 것과 비슷한 느낌
     * 많은 사람들이 기업들이 자신의 데이터로 타겟팅 콘텐츠를 만드는 것처럼, 내 데이터를 AI로 분석해보는 아이디어에 수렴해 가는 것 같음
          + 최근에 전 브라우징 히스토리 전체를 이 방식으로 분석하게 된 계기는 https://labs.rs/en/browsing-histories/에서 영감 받음
          + ChatGPT/Claude 대화 기록도 똑같이 시도
          + 가장 무서웠던 건 LLM에 내 Reddit 댓글 기록 전체를 분석하게 한 경험
          + 가장 큰 어려움은 충분히 큰 컨텍스트 윈도와 다양한 데이터 소스 간의 맥락 추적임
          + 해결책으로 지식 그래프를 사용하여 사용자 프로필을 체계적으로 관리하는 방법을 실험 중
          + 행동 패턴을 질의 가능한 구조로 압축할 수 있지만, 그 그래프를 구축하는 것 자체가 계산적으로 도전임
          + 최근 많은 AI 스타트업들은 결국 “LLM에게 벡터 DB와 지식 그래프(청구서, 법률문서, 세금자료, 데일리 리포트, 미팅 기록, 코드 등에서 추출) 제공” 구조에 귀결
          + 개인화 콘텐츠 추천/프로필링 AI 시스템이 등장하길 기대
          + 경제적 인센티브 구조가 빅테크와는 반대로, 이 시스템들은 사용자 효용성에 최적화
          + 예전 RSS 리더 시대에는 큐레이션된 테크/디자인 콘텐츠 덕분에 취향과 지식이 성장했고, 흥미로운 사람들과도 더 쉽게 연결
          + https://www.dimensional.me/ 같은 앱도 좋아하지만, MBTI와 성격검사 방식이 더 정교했다면 하는 아쉬움
          + 성격검사 대신, 내 디지털 행위(읽음, 쓰기, 행동 등) 전부를 데이터로 넣어서 상시 업데이트되는 자기만의 지식 그래프 생성 상상
          + 시스템이 ‘사용자 효용 최적화’라고 해도 결국 사용자를 ‘편안함의 감옥’에 가둘 수도 있음
               o 물론 ‘참여 유도’에 최적화된 것보다는 낫겠지만, 가끔은 그 울타리를 벗어나는 것도 필요
               o 예전에 사람이 직접 큐레이팅한 RSS 콘텐츠는 나와 의견이 달라도 다양한 시각을 접하는 역할
     * 최근 이런 개인 분석에 흥미 높음
          + Pocket 저장글 뿐만이 아니라 ChatGPT/Gemini/Claude 대화 기록의 메타 분석에도 관심
          + 초개인화 RSS 요약 스크립트를 사용해봤더니, 정말 나에게 중요한 RSS 피드와 평소 소소하게 읽는 내용이 크게 다름을 발견
          + 앞으로는 내 관심사/관련성에 들어맞는 정보만 생성하는 ‘월드 모델’을 스스로 개발하려 시도
          + 그 월드 모델의 일부는 시계열로 업데이트/연구
          + 즉 ‘뉴스’의 정체는 내 월드 모델의 변화된 부분 자체
          + 항상 오프라인/로컬에 최신 버전 월드 모델이 생기고, 이것을 내 메일함, 캘린더, 메시지, 트윗 등 필터링/정렬에 쓰는 구조
     * 가족 중 미국 북동부의 진보적 가톨릭 전통을 두고 있는 입장에서, AI가 ‘가톨릭이면 보수적’이라는 쪽으로 프로파일을 내린 것은 흥미로운 일
          + 피츠버그 출신, 가톨릭 집안 배경인데, 꽤 자유주의 성향
               o 90년대에 이미 여성 복사, 공개적으로 동성애자 신자 등이 있었고 모두 교회 내에서 환영
               o 지금은 가톨릭이 아니지만 80, 90년대엔 좋은 교회 경험
          + 실제로 AI는
               o “재정적으로 보수적/시민적 자유주의+전통주의적 사회성향”이라고 판별
               o 근거는 “Bogleheads & MMM 절약, 가톨릭/First Things 기사, EFF 프라이버시, 빅테크 검열 회의론”
               o First Things는 현재 종교적 사회적 보수주의 중심
               o 만약 누가 가톨릭이고 First Things까지 즐겨 읽는다면, ‘보수적’이라고 판단하는 건 꽤 안전한 추론
               o 하지만 사람이 읽는 걸 근거로 프로필링하는 자체가 많은 오류 가능
               o 나 역시 자주 동의하지 않는 글, 내 생각을 바꿔볼만한 글도 자주 읽음
               o 오히려 동의하지 않는 글을 저장해 두는지도 궁금
          + 평균적으로 미국 동북부/서부에서는 가톨릭/개신교 모두 리버럴, 중서부/남부에서는 보수적
               o 2025년에 종교의 영향력이 평균적으로 어느 정도인지를 보여주는 통계
     * 예전에 HN 프로필 분석하는 간단한 스크립트 제작
          + HN의 글/댓글 이력을 AI로 프로파일(위치, 정치 성향, 커리어, 나이, 성별 등) 추론
          + 다양한 댓글에서 놀랄만한 의견 보고 ‘이게 어디서 나왔을까?’ 궁금하여 실험
          + 정확도는 알 수 없지만, LLM이 이런 일에 어느 정도 쓸 수 있는지 실험하는 재미있는 경험
          + 나도 기억남
               o 내 프로필 예측 결과는 꽤 정확했음
               o 약간은 ‘세상을 구할 것’이라는 식으로 달콤한 점이 있었음
          + “어디서 저런 의견이 나올까?”라는 호기심, 직접 자기 자신에게도 이 스크립트를 돌려보면 흥미로운 정확도 테스트
          + 최근 누군가가 이 방식을 이용해 HN 프론트페이지에 어떤 글이 오를지 예측
               o 기사 내용+유저 프로필로 예측
     * 이 시스템이 내 도서관의 1/3만 참고해서 결과를 냈을 수도 있는데, 어떻게 전부를 다 반영했다고 확신할 수 있을지 의문
          + 긴 컨텍스트 문제(주의력 분산, 혼동 등)로 항상 정확성의 한계가 발생
          + 이를 해결하는 여러 전략(파일 도구 이용, 체크리스트 관리, 반복 LLM 콜 등)이 있지만, 개인적으로 적용해본 적 없음
          + 각 노드(혹은 컨텍스트 청크)가 실제로 다 반영됐는지 확인시켜주는 ‘node coverage tool’ 같은 게 필요할 수도 있음
     * 수백 개의 저장 링크(솔직히 ‘읽어야지’라는 덤프 용도)에 대해 AI/NLP로 일괄 분류하면, 더이상 관심 없는 것들을 쉽게 삭제할 수 있음
     * 처리시간 13초에 미국 인구 3억 5천만 명을 곱하면
          + GPU 시간이 약 144년 소요
          + 물론 AI 제공자는 병렬 처리로 며칠/몇 주만에 완료하겠지만, 이런 규모의 프로필 시스템은 대기업만 감당 가능
          + 예를 들어 Google이 모든 GMail 계정에 프로필을 만든다 가정하면, 대체불가한 엄청난 데이터셋이 생기고, 경쟁사가 모두 따라한다고 해도 쉽게 복제 불가능
          + (수학적/논리적 오류 있으면 지적 환영)
          + 결국 알아내는 건 뭐겠음? 우리가 인간이라는 사실 정보
     * 나도 비슷한 걸 했는데, 이번엔 그룹챗 대상
          + 대화 내역을 텍스트로 변환해 로컬 llm에 입력
          + 각 유저 별로 대화 내용 기반으로 프로필 생성, 각자 주제에 대한 생각, 의견, 성향 등 파악
          + llm에 특정 유저 관련 질문도 가능
          + 완벽하진 않고, 추론이 틀릴 때나 임베딩이 부정확할 때에는 헛소리/환각도 나옴
          + 그래도 제법 쓸만해서 개선하거나 비슷한 시도 경험자 의견 듣고 싶음
          + 반복적으로 발생하는 버그/문제를 소프트웨어/프로젝트에 문서화하는 등 다른 좋은 응용 분야도 있음
          + 이런 사례는 end-to-end 암호화 필요성이 어느 때보다 높아졌음을 보여줌
               o 과거엔 지루하고 사적인 대화였을 텐데, 이제는 피싱/보이스클로닝과 합쳐져 굉장히 귀중한 데이터
          + OpenAI는 ChatGPT 기록을 활용해 초정밀 광고 대상화할 것
          + Meta 역시 열심히 크리에이티브 생성에 생성형 AI를 도입 중
          + 초정밀 타겟팅 광고 메시지가 시청자 프로필에 완벽히 맞게 제작되고, 운영체제 차원에서 100% 광고 차단 안 되는 기기는 진짜 멀웨어로 간주해야 함
          + 앞으로는 로컬 llm이 이런 역할을 잘 해 주길 바람
"
"https://news.hada.io/topic?id=21842","내 컨트롤을 숨기지 마세요: 숨겨진 인터페이스 컨트롤이 사용성에 영향을 미침","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               내 컨트롤을 숨기지 마세요: 숨겨진 인터페이스 컨트롤이 사용성에 영향을 미침

     * 숨겨진 컨트롤로 인해 사용자 인터페이스의 사용성이 저하됨
     * 과거에는 화면에 드러난 메뉴가 사용성을 크게 개선하는 전환점 역할을 수행함
     * 최근 모바일 및 각종 기기에서 다시 기억 기반 조작이 요구되는 방향으로 회귀 현상 발생함
     * 인터페이스 디자인 복잡성과 미적인 요소가 숨겨진 컨트롤 증가의 핵심 원인임
     * 디자이너는 이제 모든 주요 기능을 드러내어 사용자가 탐색 가능하도록 구조를 재고해야 할 필요성 대두됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: 지식의 위치와 인터페이스

     * 1960년대 Douglas Engelbart가 ‘지식이 세상에 있는가, 머릿속에 있는가’ 라는 개념을 제시함
     * ‘지식 in the world’ 란 조작 컨트롤이 인터페이스에 드러나 사용자는 기억 없이 직접 찾고 사용할 수 있음을 의미함
          + 예시: 드롭다운 메뉴가 있는 그래픽 인터페이스
     * ‘지식 in the head’ 란 사용자가 모든 컨트롤 및 명령어를 외워야 하는 환경을 뜻함
          + 예시: DOS 명령 프롬프트에서는 명령어(DIR 등)를 모르면 아무 동작도 할 수 없음

숨겨진 컨트롤이 늘어나는 이유와 역효과

     * 인터페이스의 복잡성이 증가할수록 더 많은 컨트롤이 시각적으로 숨겨지고 있음
     * 겉보기에는 더 간결해 보일 수 있으나, 초보 사용자 입장에서는 조작이 훨씬 더 어려워짐
     * 초창기 드롭다운 메뉴 등 ‘보이는 컨트롤’이 등장하며 컴퓨터 대중화와 생산성을 획기적으로 높임
     * 하지만 모바일 기기와 신형 전자기기에서 다시 ‘기억 지도 기반’ 조작이 요구되는 상황이 확대되고 있음
          + 예시: 아이폰의 플래시 조명, 알림 보기, Apple Pay 실행 등의 경우 적절한 ‘힌트’ 없이 숨겨진 동작이나 특정 제스처를 숙지해야만 접근 가능함

일상 속 숨겨진 컨트롤 사례

     * 자동차 무선 키, 문 손잡이 등에도 숨겨진 컨트롤이 존재하여, 사용법을 알지 못하면 기본적인 접근조차 어려움
          + 예: 내부 키 위치나 감춰진 키홀, 특정 버튼 시퀀스 등
     * 차량 내비게이션 시스템(Apple Maps on CarPlay 등) 역시 지도를 넓게 보여주기 위해 필수 컨트롤을 숨기는 경향이 있어, 특정 영역 터치를 반드시 알아야 기능 사용 가능
     * 시간 기반 컨트롤도 숨은 형태의 컨트롤로 작동
          + 예: 컴퓨터 전원 버튼은 길게 누를 때만 정상 종료, 전자 도어락의 잠금은 별도의 키나 오래 누르기 등 특별한 조작법 필요

숨겨진 컨트롤로 인한 일반적 문제 및 전문 사용자 영향

     * 볼륨을 0으로 해도 앱이 임의로 소리를 내는 등, ‘숨은 설정’ 으로 인해 사용자의 직접적 명령을 덮어쓰는 현상 발생
     * 고급 사용자도 명령형 인터페이스(예: R, DOS 창 등)에선 심각한 ‘지식 in the head’ 의존성을 경험
     * 점차 원시적 인터페이스로 회귀하는 경향

왜 숨겨진 컨트롤이 늘어나는가

     * 기능이 지나치게 많아 화면에 전부 표시 불가해 가시성 저하
     * 시스템 모드 간 상호작용, 복잡도 증가, 디자이너의 미적 또는 구현 편의 추구 등으로 컨트롤 은닉화가 빈번해짐
     * 실제로는, 사용자 배려보다는 디자인 목적(미적 완성도 등)이 우선되어 발생함

성공적인 사례와 미션 크리티컬 시스템의 차이

     * General Motors 내비게이션 등 일부 시스템은 모든 필요한 컨트롤을 항상 화면에 잘 드러내, 초보자도 탐색이 쉬움
          + 예: Buick LaCrosse의 물리적 다이얼을 통한 줌 기능 등
     * 미션 크리티컬 시스템(항공기, 공장 등)에서는 거의 반드시 영구히 보이는 컨트롤 중심으로 설계함
          + 누구도 숨겨진 컨트롤로 빠른 조작이 저해되는 위험을 감수하지 않음

숨겨진 인터페이스 옹호와 그 한계

     * ‘숨겨진 컨트롤’은 세대 간 불평의 문제가 아니라 실질적 사용성 문제임
     * 일부에서는 ‘숨은 기능’ 탐색 자체를 장점으로 홍보하지만, 실상은 접근성 하락이 명확함
     * 사용자 입장에서 찾을 수 없는 컨트롤은 존재하지 않는 것과 같음

유비쿼터스 컴퓨팅과 컨트롤의 자동/투명화

     * Mark Weiser와 Donald Norman은 기술이 ‘투명하게’ 배경으로 물러나 작동하는 미래를 예견함
          + 예: 자동차 엔진 제어는 사용자가 조작할 필요 없도록 완전히 백그라운드에서 자동 조정
     * 자동화로 인해 컨트롤이 완전히 숨겨지는 사례는 필요성과 맥락이 명확함
          + 하지만 사용자 조작이 필요한 상황에서는 반드시 명시적 컨트롤이 필요

결론 및 인터페이스 디자이너의 방향성

     * 인터페이스 디자이너는 숨겨진 컨트롤 사용을 지양하고, 모든 기능을 ‘세계에 드러난 지식’ 기반으로 전환해야 함
     * 컨트롤 발견성(discoverability) 은 여전히 핵심 설계 원칙임
     * 현대적 인터페이스에서 발견성 저하는 오히려 초기 컴퓨터 시절로의 퇴보 현상임

참고문헌

     * Engelbart, D.C. (1962) 등 핵심 문헌 정리
     * Apple Macintosh, The Psychology of Everyday Things, The Invisible Computer 등 관련 서적과 논문 인용

저자 정보

     * Philip Kortum: Rice University 심리 과학과 교수, 사용성과 신뢰평가, 글로벌 헬스 및 모바일 시스템 등 다양한 분야에서 사용성 중심 시스템 개발 연구 수행

        Hacker News 의견

     * 최근 스크롤바를 숨기는 디자인에서 불편함을 느끼는 사용자 경험 공유, 기사 내용 중 일부 직관적인 피지컬 노브 사례엔 비용-실용성 한계가 있다는 점 언급, 토글 스위치의 라벨이 현재 상태가 아닌 전환될 상태를 의미한 경험에서 혼란을 느낌
          + 실제 토글 스위치도 애매모호해서 싫은 입장, 체크박스나 눌러진 버튼이 훨씬 명확하지만 현대화 흐름에서 희생된 점 아쉬움
          + 오스트리아 기차 표 자판기에서 즉시 검증 토글 스위치가 혼란을 줬던 기억, 스크롤바도 너무 얇아서 FPS 게임 실력까지 필요할 지경이며, 수평 스크롤바가 더 편리할 때도 있음, Firefox와 CSS 표준에 일침
          + macOS에서는 시스템 설정이나 터미널 명령으로 항상 스크롤바 표시 가능성 안내
          + 토글이 동작을 의미한다면 반드시 동사(""TURN ON"")를 써야 확실함, 상태를 보여주는 것도 ""IS ON""처럼 명확한 방식 제안, 문맥상 혼동될 만한 극히 일부 경우만 빼고는 동사를 쓰면 거의 확실해진다고 생각함
          + PgUp과 PgDn 지원도 부탁
     * 오래된 Toyota를 운전 중이며, 모든 컨트롤이 항상 눈에 띄고, 명확하게 라벨링 되어 있고, 손끝으로 구분 가능함, 이는 복제 자체도 쉽고 최소한의 엔지니어링이라고 보지만 현재 자동차 업체 대부분은 이조차 하지 못한다고 판단, 그들의 실력이 부족하다고 평가
          + 동의하는 부분 있지만, ""모든 컨트롤이 보여야 한다""고 주장하는 건 디자이너를 과소평가하는 시각임, 실질적으로는 운전 중 반드시 필요한 컨트롤만 노출되고 나머지는 작고 복잡하거나 숨겨져 있음, 좌석 높이 조절 레버, 보닛 오픈 레버 등은 숨겨져 있으나 접근성 확보, 다양한 디테일을 고려한 디자인 과정이 단순하지도, trivial하지도 않다는 입장, 이런 부분을 단순하게 치부하는 것이 오히려 현재 UX 나빠지는 이유
          + 이는 실력 문제가 아니라 비용 문제라는 시각, 요즘은 많은 버튼과 노브를 따로 만들고 조립하는 것보다 터치스크린이 저렴하고 제작이 쉬움
          + 미국 자동차 제조사가 시스템 개발자로 채용 제안을 대거 보내왔지만 Hacker News 커뮤니티에선 “정신 건강을 지키고 싶으면 피하라”는 의견이 많았던 경험 공유
          + 개인적으로도 노브 등 기계식 파츠를 다르게 만들면 커스텀 몰드 등 제조비용이 증가한다고 설명, 화면에 넣는 게 비용상 훨씬 효율적임
     * 화면 공간 효율을 위해 UI 요소를 숨기는 건 이해하지만, 쓴 공간을 비워두고 숨기는 것은 납득 불가, IntelliJ에서 프로젝트 트리 위에 아이콘이 숨겨져 있다가 마우스를 갖다대야 나오는데, 이걸 굳이 그렇게 만들 필요가 있었는지 의문
          + 모바일, 데스크톱, 노트북 화면이 그 어느 때보다 커진 상황에서 화면 요소를 가리게 만드는 근거에 의문, 1984년 매킨토시 소형 흑백 화면도 명확성, 가시성 위해 화면 비율을 희생해서라도 버튼을 배치했다는 점 회상
          + 일부는 시각적 ""잡음""이 집중력 해친다고 불평하고, 다른 일부는 계기판처럼 모든 컨트롤과 표시등을 항상 보이길 원함, IDE 기본 설정은 이런 극단의 취향을 모두 만족시키려 균형을 잡는 절충안임, 사실상 타협이며, 일부 툴은 ""no distractions mode"" 같은 모드로 세부 설정을 제공함
          + Intellij Windows 버전 메뉴도 햄버거 아이콘 속에 숨어서 빈 공간이 많아지는 문제, 다행히 설정에서 복구 가능하지만 기본값이 이해 불가
          + 버튼의 존재를 알고, 어떻게 나타나는지도 기억하는데도 가끔 어디 있었는지 까먹고 멍하니 화면만 볼 때 있음
          + 일부 앱은 오히려 추가 버튼을 숨기지 않고, 오히려 숨기는 옵션이 있었으면 원하는 마음, Google Maps 언급
     * 자동차 스마트 키 사용 중 실제 열쇠가 숨어 있고, 심지어 차 문 손잡이 분해까지 해야 키 구멍이 나오는 등, 중요한 컨트롤을 숨기는 건 사용자에게 매우 불친절한 엔지니어링이라고 지적
          + 자신도 렌트카에서 비슷한 상황 경험, 원격키가 고장나서 모든 짐이 차에 갇혔던 일이 있었음, 신체적 키가 존재한다는 건 알았지만 문고리 주변이 이전 사용자가 열려고 긁힌 흔적으로 가득 찼던 것에서 바로 키홀 위치를 알아낼 수 있었음
          + 이러한 상황은 유저가 기본적으로 알고 있어야 하며, 구글 등에서 정보를 찾을 수 있다는 주장, 신형 자동차를 받고 바로 백업 옵션과 동작 방식을 확인했던 실례 제시, 소유한 제품에 대한 기본 파악 중요성을 강조
     * iPhone에서 홈버튼이 사라지고, Android로 넘어간 이유 중 하나가 가족 내 고령층 설명 및 사용이 더 어려워졌기 때문, 새 Pixel 폰 구입 시 3버튼 내비게이션부터 활성화하지만, 요즘 앱들은 바텀 내비게이션바만 가정하고 3버튼에 덮여 내용이 가려지는 등 UI 단점 지적
          + 핵심 UI 요소는 반드시 눈에 보여야 한다는 주장, Apple도 이 원칙을 가끔 위반한다고 보지만 대부분은 저항하는 편이라고 평가, 홈버튼 삭제는 UI요소를 숨겼다기보단 상호작용의 변환으로 해석, 직관성·우수성 논란은 있을 수 있으나 적응이 되면 사용에 마찰이 거의 없다는 점 언급, iOS엔 스크린에 드래그할 수 있는 작은 원형 단축키(텍스트 라벨 포함)를 두는 접근성 기능 안내
          + 일반 소프트웨어의 소리 없이 사라지는 메뉴 아이템 현상도 유사, 예로 MS Word에서 읽기 전용 파일 저장 기능 아이콘이 아예 사라진 점, 차라리 비활성화로 두고 저장 시 원인 알림 후 해결 방법 안내가 더 나은 경험일 것이라는 제안
          + Android 장기 사용자인데 종종 iPhone 빌릴 때마다 비직관적이거나 없는 상호작용으로 답답함, Pixel·Samsung 카메라 품질도 좋아져서 Apple 생태계로 넘어갈 이유 없음
     * 기사에서 UI가 사라지는 것이 우연이나 실수가 아니라, 사용자 락인을 위한 현상이라는 점이 제대로 다뤄지지 않았다는 의견, saturated(성장 한계치) Point에 도달한 소프트웨어에서 기존 사용자 떠나는 걸 막기 위해 직관적이지 않은 방식으로 UI를 바꾼다고 해석, 기기를 ""사용""하는 대상 아닌 ""내재화""된 존재로 만들어 이탈 장벽 생성, UI 습득 과정에서 새 제품 전환 공포 유도, 대다수 주요 소프트웨어 기업이 이 방식을 취하는 이유 설명
          + 이런 가설은 단편적으로만 보면 맞을 수도 있지만, 실제로는 ""복잡하고 붐비는 인터페이스""에 대한 반발도 많음, 미니멀리즘 트렌드와 /r/unixporn 등 다양한 사용층이 자체적으로 컨트롤을 숨기는 경향도 큼, GNOME 등도 최근 미니멀 인터페이스가 대세, 많은 사용자는 필요할 때만 기능을 찾아 쓸 줄도 알기 때문에 선택적이라고 해석
          + 이 방법은 양날의 검이라 낯선 사용자 유입엔 저해가 됨, Apple의 모든 인터페이스가 한 버튼에 집중된 점이 싫어서 Android가 더 익숙한 사례 공유, Apple에 대한 여러 불호는 별도 이유로도 존재
          + 비영리 OSS에서도 무비판적 트렌드 따라 한다고 보임, Firefox의 자주 반복되는 디자인 변화, GNOME 등도 같은 맥락
     * ""아티스트"" 타입 디자이너가 UI 결정권을 쥐면 깔끔함에 집착해 직관적 사용법(affordance)과 학습 기회를 무시, 에어플레인 콕핏(비전문가에겐 압도적이나 전문가에겐 모든 게 라벨링)이 대표적 대비 사례
          + 일반 가정 수도꼭지에도 방향 라벨 달릴 필요는 없다는 반박, 비행기 콕핏은 초보에겐 오히려 과도하게 압도적임을 예시, 인터페이스 디자이너는 무엇이 직관적인지 잘 알고 복잡한 기능도 단순한 폼팩터에 잘 압축하는 능력 보유, 디자인 교육 없는 사람이 더 나은 결과를 낼 수 있다고 생각하는 건 자만과 무시에 불과, 실제로 많은 사용자가 훈련 없이도 현대 스마트폰을 능숙하게 잘 사용하는 것은 훌륭한 성과라는 점 강조
     * Hacker News 관련 데스크탑 소프트웨어 rant 및 현황 질문
     * 자사 UI 설계 원칙 중 하나가 키보드 단축키, 컨텍스트 메뉴는 반드시 명확히 드러난 버튼이나 메뉴로 접근 가능해야 한다는 것, 다소 올드패션한 방식이지만 중요성 강조, 화면 네 모퉁이는 마우스가 빠르게 이동 가능해서 UI상 핵심 부위, Windows 11에서 시작 메뉴를 중앙으로 옮긴 것은 사용자 불편의 예시로 듦, 모바일이 아닌 터치 우선 정책일지도 모름
     * 접근성 및 UI의 직관성 저하가 장애인·고령층에게 크게 영향을 미친다고 강조, 터치와 제스처가 대세가 되었지만 초기 모바일 UI가 오히려 더 접근성이 좋았던 점 지적, 과도하게 미니멀하고 플랫해진 경향이 본질적 요인, palm, compaq pilot, 아이팟, 초기 아이폰 UI 체계를 긍정적으로 회상, 이후로는 오히려 퇴보라고 평가
          + 이에 반해 HN 댓글을 폰으로 볼 때처럼, 여러 UI 컨트롤이 숨겨져 실제 컨텐츠에 집중 가능한 게 더 아름답고 쾌적하다는 생각도 있음, palm pilot 시절엔 버튼과 컨트롤이 화면 절반을 차지해 오히려 컨텐츠 영역이 줄었다고 지적, 숨겨진 컨트롤은 반드시 나쁜 게 아니고, 한 번 습득하면 전문가에겐 강력한 도구임을 긍정, 사용자에게 UI 학습을 요구하는 건 어느 정도 불가피하고, 내 코드에디터/ git 등 고기능 툴은 단순화와 힘 사이의 트레이드오프, 다만 최근 지나치게 앱마다 독자 컨트롤 커스텀으로 UI 학습 전이성이 떨어지는 건 문제, palm pilot 플랫폼처럼 한번 배우면 모든 앱이 동일하게 쓸 수 있는 구조가 이상적임
"
"https://news.hada.io/topic?id=21889","이제 Google이 WhatsApp 메시지를 읽을 수 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    이제 Google이 WhatsApp 메시지를 읽을 수 있음

     * Google의 새로운 기능으로 WhatsApp 메시지를 읽을 수 있음
     * 이 기능은 음성 비서나 앱 통합과 관련된 부분임
     * 사용자 프라이버시 이슈와 데이터 접근 방식 논란 발생함
     * WhatsApp의 종단간 암호화에도 불구하고 일부 정보 노출 가능성 언급됨
     * 해당 기능은 사용자 동의를 기반으로 활성화됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Google의 WhatsApp 메시지 읽기 기능 개요

     * Google은 최근 WhatsApp 메시지를 읽을 수 있는 기능을 추가함
     * 이 기능은 Google Assistant와 같은 음성 비서 서비스를 통한 메시지 읽기 및 관리에 초점을 맞춤
     * 사용자 동의 하에 Google이 WhatsApp 메시지에 접근하여, 알림 읽기 형태로 메시지 내용을 파악함
     * WhatsApp는 종단간 암호화로 보안성을 강조하고 있었으나, 운영체제 또는 시스템 알림을 통한 간접 접근이 가능함
     * 이로 인해, 프라이버시 보호와 앱 간 데이터 공유 구조에 대한 논의가 재점화되고 있음

사용자 프라이버시 및 보안 이슈

     * Google이 WhatsApp 메시지 내용을 읽으려면 사용자의 명시적 동의가 필요함
     * 정보 접근 방식은 WhatsApp 메시지를 직접적으로 복호화하는 것이 아니라, 알림 API와 같은 시스템 권한을 활용함
     * 이에 따라 일부 메타데이터 또는 실제 메시지 내용이 Google 서비스에 노출될 가능성 있음
     * 이 기능은 Google 생태계의 앱 통합성 강화를 목표로 제공됨
     * 사용자들은 프라이버시 우려와 함께, 새로운 활용 가능성에 대한 기대를 동시에 가짐

결론

     * Google의 신기능은 편의성과 활용성 향상을 제공함과 동시에, 데이터 보호와 사생활 침해 가능성에 대한 지적이 대두됨
     * 해당 기능 사용 여부는 개별 사용자 선택임
     * 향후 WhatsApp 및 Google의 정책 변화와 이에 따른 보안 강화 방향이 중요한 화두로 남을 전망임

        Hacker News 의견

     * 안드로이드에서 Gemini를 비활성화하는 방법은 존재하지만, WhatsApp의 Meta AI는 비활성화할 수 있는 방법 자체가 없고, 사용자에게 활성화 여부를 묻는 절차도 전혀 없었던 상황임
     * Google이 이 기능을 지난해 11월부터 준비해온 사실을 지원 페이지 아카이브를 통해 알 수 있었음
       Gemini가 메시지를 읽지는 못하며, 메시지 작성과 통화 시작 등만 가능해 실제로 그룹 채팅에는 메시지도 못 보내는 점이 있음
       이 기능 자체는 상당히 합리적임. WhatsApp이 미국 외 많은 국가에서 문자와 통화의 역할을 하고 있으니, 스마트 어시스턴트가 WhatsApp과 연동되지 않으면 사실상 무용지물이라고 생각함
       구글 공식문서(https://support.google.com/gemini/answer/15574928)에 따르면 Gemini가 WhatsApp에서 할 수 없는 일로 메시지 읽기나 요약, 이미지·파일 추가, 오디오·동영상 재생, WhatsApp 알림 읽거나 응답하기 등이 명시됨
       만약 Google Assistant와 WhatsApp을 연결했다면 데이터가 이동할 수 있으나, 이미 사용자가 연동을 허락한 경우이므로 놀라워할 일은 아님
       혹시 Gemini가 메시지를 읽어주게 할 수 있는 방법을 아는 사람 있으면 알려주면 좋겠음. 해당 기능에 필요한 설정도 찾지 못했던 상황임
          + Gemini가 WhatsApp에서 할 수 있는 일은, 사용자가 허용한 범위 내에서 다른 임의의 앱이 WhatsApp에서 할 수 있는 기능과 동일해야 함
            Google의 소프트웨어가 운영체제 제작사라는 지위를 이용해 특권적으로 서드파티 앱에 접근하지 않았으면 하는 바람임
          + Gemini와 Google이 동일하다고 보는 오역도 문제이지만, ""Google이 WhatsApp 메시지를 읽을 수 있다""는 현재의 HN 타이틀은 낚시성 제목임
          + 구글 공식문서라는 점에 대해 의문 제기.
            해당 페이지가 처음으로 ""할 수 없는 일"" 리스트를 담은 아카이브는 2024년 11월임. 이메일은 2025년 7월 적용 예정이라서, 페이지가 최신이라고 장담할 수 없다고 생각함
            구글 공식문서는 오히려 왠만하면 안 되는 걸 되는 것처럼 안내해주는 경험이 많았음
            관련 링크도 남김(https://support.google.com/gemini/answer/15574928"">https://web.archive.org/web/20241107174006/…)
          + Gemini 모바일 앱이 일부 동작을 Google Assistant나 Utilities 앱의 지원을 받아서 가능하게 해줌. 이때 WhatsApp이 Gemini 내에서 비활성화되어 있어도 이런 연동이 가능
            Gemini 모바일 앱에서 Google Assistant 및 Utilities 앱 지원 액션 관련 정보를 확인할 수 있음
     * 사람들은 Apple이 AI 경쟁에서 뒤처졌다고 조롱해왔지만, 나는 아이폰 판매에 안 된 기능을 광고로 약속하고 아직도 대부분 출시하지 않은 점은 옹호하지 않지만, 많은 기능 지연이 이처럼 중요한 개인정보를 AI에 맡기는 위험을 자각했기 때문이라는 생각도 듦
       AI가 실수로 아내에게 보낼 이미지를 상사에게 보내는 확률이 0.0001%라도 있다면 출시를 고민해야 한다는 입장이 맞다고 생각함
       Google은 시장 경쟁에서 눈에 띄기만 하면 이런 부분에는 따지지 않는다고 보는 인식임
          + 이런 위험에 대한 고민보다, Apple의 AI 개발이 느렸던 이유는 오히려 기술적 역량 부족 때문일 가능성이 더 높았다고 생각함
          + 오히려 AI에 관해 Apple이 사용자 개인 메시지를 중간에 가로채고, 이별 문자까지 부적절하게 요약하는 사례를 만든 첫 기업임
          + Siri도 수많은 오해로 잘못된 메시지 발송 사례가 빈번했음
            ‘Love’를 ‘Louis’에게 보내는 등, 이미 실시간으로 잘못 보낸 경우가 많았던 경험에서 실제 AI 사고 가능성을 예시로 제시함
          + Apple의 딜레이는 보안 때문이 아니라, 공식적으로 기술적 무능력 때문이라는 보도와 논문이 존재함
          + 만약 Steve Jobs가 아직 살아있다면 ‘AI에 대한 생각’에서 뭐라고 남겼을지 상상하게 됨
     * Gemini Apps Activity 설정 문제는 정말 답답한 경험임
       Gemini Pro에 돈을 내도 Apps Activity를 끈 채로 둬야만 내 대화에 사람이 접근하지 않게 되는데, 이렇게 하면 대화 내역이 단 한 분 전 것도 안 남기게 됨
          + 비슷하게 YouTube Premium 사용자들도 시청 기록 비활성화 시, 홈에 아무것도 안 뜨는 불편함이 있었음
            광고 가치가 줄어드는 사용자를 구글이 이렇게 ‘처벌’하는 느낌임
          + 또 다른 방법은 구글 워크스페이스 계정으로 Gemini를 사용하는 것임 (다른 계정 필요)
          + 이런 UX, 비합리적임에 동의함
     * 거대 테크 기업들이 자꾸 우리의 디지털 삶 모든 측면을 감시하는 게 불만임
       가장 기본적인 프라이버시를 지키는 조차 두더지잡기 게임처럼 피곤함
          + 결국 사람들이 구독형 모델 대신 광고 모델을 선택하기 때문임
          + 사용자가 제품 요금을 내지 않으면, 기업들은 고객 데이터를 수익원으로 삼게 됨
          + 이제는 안드로이드 보안에 신경 쓰는 것 자체를 포기하게 됨
            사실상 내 스마트폰이 마지막 스마트폰이 될 것 같다는 이유임
          + WhatsApp은 감시 소프트웨어를 만든 기업이 만든 감시용 앱임
            이 문제를 겪는 사람들은 이미 이런 감시 앱에 자발적으로 동의한 것이라고 생각함.
            Meta의 사생활 침해 이력은 비밀이 아닌 상황임
     * Gemini가 WhatsApp 메시지를 (명확하게 명령한 경우) 읽거나 행동할 수 있다면 편리함
       다만, 프롬프트 없이 수집하거나 모델 학습에 데이터가 활용된다면 용납 불가 입장임
          + ‘Mike에게 사랑한다고 메시지 보내줘’라고 Gemini에게 말하면 이 문자가 구글 거쳐서 내 폰으로, 그리고 Mike에게 전달된다는 구조가 명확한 사람도 있지만, 모두가 그렇지 않음
            예를 들어 Siri는 오프라인 상태에서도 메시지를 읽고 전송이 가능하므로, 클라우드 전송 없이도 기기가 직접 데이터에 접근 가능함
            관련 사례로 https://macworld.com/article/678307/…
     * 기술적으로 구체적으로 어떻게 구현되는지 궁금함
       WhatsApp이 공식적으로 이런 API를 노출했다면 구글만의 문제는 아니라고 볼 수 있음
       만약 아니라면, UI 위젯 데이터나 입력 제어를 가로채는 방식인지, 네트워크 트래픽을 훔쳐보는지 궁금함
       엔드투엔드 암호화 구조라면 WhatsApp 프로세스 내부에서 해독이 일어남
          + 구글이 운영체제 개발사라, WhatsApp에서 텍스트 위젯을 그릴 때 해당 정보에 후킹만 하면 내용 로그가 사실상 가능함
          + 내 이해가 정확하지 않을 수 있지만, WhatsApp 데이터는 암호화돼 있더라도 기기 내 암호화 키가 있음
            서드파티 앱들도 WhatsApp 데이터를 기기간 혹은 Android-iOS 간 전송 지원을 하며, 데이터는 일반 DB 포맷이라서 디바이스에 직접 접근만 있으면 WhatsApp 앱이 없어도 내용 추출 가능함
          + WhatsApp은 여러 ‘다크 패턴’을 통해 사용자가 대화 데이터 구글 드라이브에 아카이브하게 유도하는 점도 있음
     * Gemini Apps Activity를 꺼두면 Gemini의 대화 내용이 리뷰되거나 AI 모델 개선에 사용되지 않음
       하지만 이런 안내만으로 데이터 수집 및 보관 관련 설명이 충분하지 않음
       개인 프라이버시가 매우 중요하지만, AI가 가져올 편의성의 유혹은 크기 때문에 갈등 생김
       언젠가 강력한 로컬 AI 모델이 대안으로 자리 잡으면 좋겠다는 기대가 있음
          + AI는 각자 앱처럼 필요할 때만 쓰는 방식이 더 좋아서, 모든 기능에 다 연동되는 트렌드는 선호하지 않음
            예전엔 인터넷 쓰려면 가족 PC 앞에 가야 했던 시절이 있었는데, 이제는 스마트 기기가 욕실까지 따라오는 분위기임
            AI가 이렇게 삶 곳곳을 침투하는 건 꺼려지는 감정임
          + 나는 AI 어시스턴트(특히 Apple intelligence)는 대부분의 앱, 특히 채팅/이메일과의 통합을 최대한 막는 방식으로 활용 중임
            어느 순간에는 누군가가 모델이 진짜 로컬에서만 동작하는지, 어떤 데이터가 실제로 서버로 전송되는지 리버스 엔지니어링을 통해 분석할 것임
            이 방법이 완벽하진 않아도 오픈소스가 아니고 투명성 부족한 환경에서 할 수 있는 최선이라고 봄
            차라리 소스코드를 공개해서 누구든 실제 빌드와 완전 일치하는지 테스트가 가능하면 더 신뢰감 생길 것임
          + Apple도 한때 모든 AI 기능을 로컬로 돌리려고 한 것처럼 보였지만, 최근에는 OpenAI를 도입하는 방향으로 옮긴 듯함
            로컬 모델은 사용 빈도가 낮고, 사용할 때 속도를 기대하니 딥러닝 칩이 대기 시간만 길어지고 비효율적일 수 있음
            클라우드에서 인퍼런스하는 게 경제적으로 유리하고 더 강력한 AI 모델 사용 가능
            언젠가는 로컬 AI가 가능해질지 몰라도, 더 좋은 모델을 (클라우드가) 항상 운영 가능함
          + AI가 굉장한 힘을 가져올 거라는 얘기에, 구체적으로 어떤 힘을 말하는 것인지 궁금함
     * 이번에는 gsuite 계정이 Gemini 접근에 차단되어 있어서 개인적으로 이득을 봄
       관리자가 Gemini 지원을 비활성화해서 이용 제한이 됨
     * Android에서 Gemini AI 비활성화 방법 소개
       https://tuta.com/blog/how-to-disable-gemini-on-android
          + 해당 제품에 대해 어떤 서비스인지도 잘 모르겠고, 링크가 항상 인공지능 번역된 한국어 페이지로만 리디렉션되고, en-us 언어 코드 인식도 안 되고, 언어 선택 기능도 없음
            이런 경험으로 인해 내 블랙리스트에 등록시킴
"
"https://news.hada.io/topic?id=21902","Autumn - 오픈소스 요금제 & 빌링 플랫폼","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Autumn - 오픈소스 요금제 & 빌링 플랫폼

     * Stripe와 애플리케이션 사이에 위치하는 오픈소스 요금제 관리 레이어
     * 몇 줄의 코드만으로 구독, 크레딧 충전, 사용량 기반 과금, 좌석 기반 과금, 대형 고객 맞춤 플랜 등 다양한 가격 모델을 쉽게 구축할 수 있음
     * Webhook, 업그레이드/다운그레이드, 취소, 결제 실패 등 복잡한 청구 상태를 직접 처리할 필요 없이 완전 자동화된 인프라를 제공
     * 클라우드 서비스(빠른 시작)와 셀프호스팅(직접 구축) 모두 지원하며, 대시보드를 통한 간단한 제품/플랜 설정 후 3가지 함수만으로 핵심 청구 로직을 통합할 수 있음
     * 빌링 인프라의 복잡성, 앱 로직과 결제 로직의 분리, DB 마이그레이션, 사용자별 맞춤 가격 등 SaaS 확장 과정의 실제 어려움을 해결
          + 실제 청구는 단순 결제 외에도 권한 관리, 사용량 측정, 제한, 업그레이드/다운그레이드, 실패 처리 등 다양한 상태 관리가 필요
          + SaaS의 성장 과정에서 가격 정책 변화, 크레딧 도입, 신규 기능 유료화 등 빈번한 가격 실험이 발생하고, DB 마이그레이션, 내부 대시보드 개선, 사용자별 가격 관리 등이 반복적으로 요구됨
"
"https://news.hada.io/topic?id=21958","BrowserOS – Perplexity Comet의 오픈소스 대체제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 BrowserOS – Perplexity Comet의 오픈소스 대체제

     * BrowserOS는 Perplexity Comet의 오픈소스, 프라이버시 중심 대안으로, 로컬에서 AI 에이전트를 실행하는 에이전틱 브라우저
     * Chromium을 포크하여 기존 Chrome 확장들을 모두 지원하며, 사용자 데이터가 로컬에만 저장되는 것이 특징
     * OpenAI, Anthropic, Ollama 등 다양한 AI 프로바이더와 연동 가능하며, 개인 API 키 또는 로컬 모델을 사용할 수 있음
     * 네이티브 하이라이터, ChatGPT 기반 북마커, 시맨틱 검색 등 최신 생산성 도구 내장 및 AI 기반 광고 차단 기능도 곧 지원 예정
     * 기존 브라우저와 달리 검색/광고 기업에 데이터가 넘어가지 않고, 자동화된 워크플로우를 로컬에서 AI가 수행함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

BrowserOS 개요

     * BrowserOS는 오픈소스 에이전트 브라우저로, 사용자의 컴퓨터에서 직접 AI 에이전트가 동작하는 환경을 제공함
     * 프라이버시 우선 철학을 바탕으로, API 키 또는 Ollama 등 로컬 모델을 사용해 데이터가 외부로 유출되지 않음
     * Chromium 포크 기반이어서 Chrome 사용자 인터페이스와 동일하며, 모든 크롬 확장 프로그램이 작동함

주요 기능

     * AI 에이전트 & 로컬 실행
          + 브라우저 내에서 AI 에이전트가 로컬로 직접 실행되어, 반복 업무 및 자동화 워크플로우 처리
          + Ollama 통합으로 대용량 언어 모델을 클라우드 대신 내 컴퓨터에서 구동, 데이터 프라이버시 보장
     * 생산성 도구
          + 하이라이터, ChatGPT 북마커 등 브라우저 내장 생산성 도구 지원
          + 시맨틱 검색으로 히스토리/북마크 등 브라우저 데이터를 빠르게 찾을 수 있음
     * 광고 차단 및 MCP 스토어(예정)
          + AI 기반 광고 차단(곧 출시), Chrome에서 uBlock Origin 차단 이후의 대안 제공 예정
          + MCP(멀티 커맨드 패키지) 스토어(곧 출시)에서 인기 MCP를 원클릭 설치 후 바로 브라우저 바에서 활용 가능
     * 오픈소스 및 커뮤니티 중심
          + AGPL-3.0 라이선스로 100% 오픈소스, 코드와 동작 투명성 보장
          + 커뮤니티 참여 및 기여를 적극적으로 장려

대표 활용 사례

     * 반복적이고 지루한 업무 자동화: 미팅 예약, 폼 작성, 반복 작업을 AI가 자동 처리
     * 딥 리서치: 웹을 탐색해 요약 리포트 생성, 수작업 탭 관리 없이 효율적 정보 수집
     * SNS 콘텐츠 스캐닝: LinkedIn, Twitter 등에서 유의미한 게시글 자동 선별 및 정리

타 브라우저와의 비교

     * Chrome: 10년간 큰 변화 없이 AI/자동화/MCP 기능 부재
     * Brave: 암호화폐/검색/VPN 등 분산 전략으로 AI 브라우저에 집중하지 않음
     * Arc/Dia: 폐쇄형으로 오픈소스가 아님, 사용 중단 시 대안 없음
     * Perplexity Comet: 검색/광고 기업 중심, 사용자 데이터가 서버로 전송되나 BrowserOS는 모든 데이터를 로컬에만 저장함

설치 및 시작

     * macOS, Windows용 다운로드 지원
     * 크롬 데이터 가져오기(선택)
     * AI 프로바이더 연결(OpenAI, Anthropic, Ollama 등)
     * 바로 에이전트 자동화 시작 가능

라이선스

     * AGPL-3.0 오픈소스 라이선스 적용

   https://news.hada.io/topic?id=21581
   어딘가 익숙해서 봤더니 Nxtscape가 이름만 바꾼거였네요

        Hacker News 의견

     * 데모에서 보여준 치약 구매 예시는 이 작업들이 얼마나 어려운지 보여줌, 치약이라는 자체가 매우 모호하게 지정되어 있어서, 결국 엄청나게 거대한 리스트 중에서 랜덤하게 고름, 일부 작업은 이전 행동이 가이드를 줄 수 있지만, 그렇지 않은 경우도 많음, 예를 들어 이전에 샀던 치약이 품절이면 어떻게 할지 알 수 없음, 결국 이런 예시가 정말로 시간을 절약해주는지 의문이고, 어차피 결과를 확인하려면 두 번 일하는 것임, 이 때문에 Alexa 같은 시스템이 처음에 Amazon이 기대했던 구매 경험을 제공하지 못했다고 생각함, 차라리 시간 절약이 분명하게 드러나고 실패 케이스가 최소화된, 더 복잡한 예시를 보여주거나, 오히려 실패 케이스에서 어떻게 복구할지에 초점을 맞추는 게 더 좋을 것 같음, 특정 문제에 맞는 UI를 제공하나, 아니면 채팅으로 해결함,
       이 세계 전체가 결코 쉬운 일이 아니라고 생각함, 모두 행운을 빔
          + 맞는 말임, agentic browser 분야 전체가 아직 시작 단계임, 우리도 겨우 시작했고, 가치 있는 틈새 use-case를 찾으려는 중임, 반복적이고 지루한 작업 중에 시간 절약 효과가 분명한 경우가 있음, 예를 들면 Walmart 3자 셀러들이 하루에도 여러 번 경쟁사 가격을 체크해서 내 제품 가격을 조정하는 일임, 이건 agentic browser로 쉽게 자동화가 가능함
          + 사용자별 미적 취향에 맞춰 작업을 수행할 수도 있어야 한다고 생각하지만, 그렇게 하면 보안 악몽이 될 수 있을 거 같음
     * Nxtscape를 이미 설치해뒀는데, 제품명이 바뀌었는지 몰라서 BrowserOS를 실행했더니 같은 UI와 채팅창에 여우 이모지도 똑같이 떠서 당황했음, 솔직히 예전 이름이 더 좋았음, 법적인 이유로 이름을 바꾼 거라고 추정함.<br>Arstechnica 기사 댓글을 요약해달라고 시켜봤는데, 처음에는 ""댓글이 포함되어 있지 않아 요약할 수 없다""는 답변만 받았음, 직접 ""comments"" 링크를 눌러보라고 지시해야만 제대로 댓글을 읽기 시작했고, 참고로 댓글 페이지가 총 3개인데 20분 넘게 100번 가량의 액션(그 중엔 매우 구체적으로 1074픽셀씩 스크롤하는 동작도 많음)을 수행하더니, 아직도 ""Validating task completion...""이라는 상태에서 요약을 기다리고 있음<br>기능적으로는 파워풀해 보이지만, 너무 손이 많이 가고 느려서 실제로 쓸 순 없다고 느낌.<br>참고로 Nxtscape도 설치되어 있어서 같은
       실험을 해봤는데 더 빠르고 적은 액션만으로 작업을 마쳤음, 그게 우연인지, 내부적으로 다른 로직 때문인지는 잘 모르겠음<br>그리고 iCloud 비밀번호를 Chrome에서 쓸 수 있게 해주는 Chrome 확장 프로그램이 있는데, Nxtscape와 BrowserOS에서는 작동하지 않음, 비번 관리자를 계속 직접 켜야 한다면 이런 브라우저는 쓸 생각 없음, 그리고 비밀번호 관리자도 바꿀 계획은 없음
          + 문제 생기는 걸 방지하려고 이름을 바꿈, 그리고 예전 이름은 발음하기도 어려웠음<br>피드백 고맙고, Discord(https://discord.gg/YKwjt5vuKr)에서 더 이야기 나누면 좋겠음! 우리 팀은 매일 배포하며 엄청 빠르게 개선 중이고, 에이전트도 며칠 내로 훨씬 나아질 예정임<br>iCloud 비밀번호 확장 건도 확인해볼 것임, 온보딩과 비밀번호 관리가 훨씬 더 쉬워지게 만드는 게 목표임
     * 이게 privacy first browser라면 왜 Firefox를 쓰지 않았는지 궁금함, Firefox는 이 목적에 훨씬 더 잘 맞고 기본적으로도 더 나은 옵션임, Tor Browser, Mullvad Browser, LibreWolf 등 보안/프라이버시 우선 웹브라우저는 전부 Firefox 엔진 기반임<br>그리고 다양한 ""웹 브라우저 엔진""이 꼭 필요하다고 생각함, 대형 테크 기업 엔진만 쓰게 되면 결국 소비자 입장에서 엄청 손해이고 혁신도 막힘<br>Firefox 같은 독립 브라우저를 더 많이 지원해야 함
          + 정말 어려운 결정이었음<br>webkit 위에서 브라우저 만드신 분들과 얘기해봤는데, 무작위 버그를 고치고 사이트 호환 이슈를 잡는 데만 거의 2년은 걸렸다고 함, firefox/gecko 엔진이 webkit보단 나을 수도 있으나 결론은 chromium 아닌 다른 엔진을 쓰면, 웹사이트 호환성 문제랑 확장 프로그램 지원까지 엄청난 추가 작업이 필요함<br>우리도 단 2명의 스타트업이고, chromium 코드베이스가 빌드하기 훨씬 쉬운 출발점이라 선택함<br>그리고 Brave처럼 chromium 위에서도 충분히 프라이버시에 집중한 브라우저를 만들 수 있다는 점도 있음<br>특히 agentic browser 시대에선 프라이버시와 관련해 바로 개선할 수 있는 부분이 너무 많음——예를 들어 Perplexity Comet 같은 곳에 민감 데이터 보내는 건 광고 수익용이라서 정말 별로임, 로컬 LLM 지원하거나 사용자가 자기 API key를 쓸 수
            있게 하는 것이 훨씬 중요함
          + 똑같은 의문을 가졌음<br>프라이버시 지향이라면서 chromium을 쓰는 이유가 뭔지 궁금함
     * ""크롬의 C++ 소스코드를 직접 패치해서, Google Chrome과 동일한 보안을 얻고 있다""는 글을 봤음<br>그렇다면 Chromium이 업데이트될 때마다 매번 자체적으로 빌드를 다시 하는 것인지 궁금함, 왜냐면 가끔은 아무렇지 않은 commit 메시지로 보이는 패치가 실제론 심각한 취약점 관련이고, 90일 후 CVE로 공개되는 경우가 많기 때문임
          + 좋은 질문임, 우린 지금까지는 Google Chrome이 기반하는 Chromium 릴리즈 버전을 기반으로 계속 빌드를 진행하고 있음
     * 나는 이걸 독립 브라우저가 아니라, 브라우저 확장 프로그램 형태로 제공되면 더 좋겠음
          + 우리도 원래 브라우저 확장으로 만들고 싶었음<br>하지만 좋은 agent copilot을 만들려면 Chromium C++ 레벨에서 여러가지 변경이 필수라고 생각함, 예를 들어 모든 웹사이트의 접근성 트리를 Chromium이 가지고 있는데, 그걸 chrome extension API에서 못 불러옴, 접근성 트리에 직접 접근하면 agent 성능이 크게 향상됨<br>또한 click 동작이나 element 인덱스 등 agent가 웹사이트와 상호작용할 수 있는 여러 기능을 C++ 수준에서 추가하고 있음, 이런 걸 JS로 하면 20-40배 느림
          + 우리도 정확히 같은 생각임, agentic 기능을 구현하려면 꼭 브라우저 전체가 필요하지 않다고 생각함, 한정된 권한 내에서도 브라우저 확장만으로 충분히 구현할 수 있음<br>Google이 바로 배포하는 zero day 패치도 많고, Google이 Chromium에 넣지 않는 기능들도 분명 존재함, 그래서 내 주력 브라우저로선 무작위 오픈소스 포크는 신뢰하지 못하겠음<br>AI Web Agent 브라우저 확장 프로그램으로 rtrvr.ai(https://rtrvr.ai)를 추천함, 이미 사용자의 워크플로우에 맞게 구현되어 있음
          + nanobrowser가 여기서 언급될 때 나도 동일한 생각이 들었음
          + https://github.com/nanobrowser/nanobrowser 시도해볼 만함
     * 이건 chrome extension인 nanobrowser와 비슷한 프로젝트임 https://github.com/nanobrowser/nanobrowser
          + 프로젝트 페이지를 빠르게 훑어보니, 외부 LLM API 키를 사용하는 것 같음, 원래 글에서 소개한 이 프로젝트는 transformer.js를 사용해서 로컬에서 LLM이 돌아가는 형태로 보임
          + 이런 기능이 이미 확장 프로그램으로 구현 가능하다면 굳이 기존 소프트웨어를 포크해서 만드는 이유가 궁금함<br>nanobrowser와 browserOS 간에 확실하게 browserOS에서만 되고 nanobrowser에는 없는 기능이 있는지, 꼭 짚어야 할 차이점이 궁금함
          + 언급해줘서 고마움
     * ""<i>우리는 Chrome이 uBlock Origin을 차단한 이후, LLM 기반 광고 차단기도 제작하고 있다</i>""는 말이 있는데, 어차피 Chromium 포크라면 uBlock Origin을 재사용하면 되는 것 아닌지 궁금함
          + Chromium이 Manifest V2 API를 없앨 예정이고, 어떤 포크도 이걸 계속 유지하고 싶어하지 않음, Brave조차 자체 내장 광고 차단기를 따로 만듦<br>진짜 의문은 '왜 Firefox를 포크하지 않고, Firefox가 다 해주는데도 굳이 Chromium을 택하는가'임
     * Linux용 로드맵이 궁금함, Mac이나 Windows가 없음
          + 이 부분 인지하고 있음, 다음 주 초에는 지원 가능하게 할 예정임<br>여전히 2인 팀이라 정말 할 일이 많음
     * AI가 마우스 커서를 직접 움직이고 클릭하며, 키 입력도 실시간으로 화면에 표시되는 모습을 보고 싶음, 마치 소프트웨어 튜토리얼처럼 실제 사람이 쓰는 듯한 인터랙션이 있었으면 좋겠음<br>지금처럼 AI가 페이지를 바꾸고 UI를 휙휙 바꿀 때는 화면이 툭툭 끊기는 느낌이라 흐름을 따라가기 힘듦<br>뭘 집중해서 봐야 할 지 힌트가 부족해서, 그냥 스크린레코딩을 보는 것 같은 느낌임<br>그래도 mcp/browser automation과 같은 분야에서 유용한 활용 사례가 있을 것 같아서, 앞으로 발전이 기대됨
          + 정말 유용한 피드백임, 고마움!<br>커서 움직임도 추가할 수 있는지 살펴볼 것임, 키 입력도 이미 실제 사람처럼 보이게 나오지만, 좀 더 천천히 보이도록 개선할 수 있을 것 같음
          + 정말 원하는 건 caretaker ai라고 생각함
     * 축하함!<br>이 프로젝트가 재무적, 개발적, 유지보수 측면에서 어떻게 지속가능하게 할 계획인지 궁금함
          + 고마움!<br>기본적으로 브라우저의 Enterprise 버전에 라이선스를 판매하는 방식으로 오픈소스 프로젝트들과 똑같이 갈 예정임
          + 내 추측엔 그냥 electron 앱 혹은 chromium wrapper에 ollama wrapper를 붙인 구조인 것 같음(브라우저를 제어할 수 있는 무료 오픈소스 라이브러리도 가득 있음)
"
"https://news.hada.io/topic?id=21870","LLM을 인간처럼 보는 관점을 벗어나기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         LLM을 인간처럼 보는 관점을 벗어나기

     * LLM을 인간처럼 의인화하는 태도에 대해 비판 하는 글. LLM은 결국 '행렬 곱셈과 비선형 함수의 집합'임
     * LLM이 생성하는 언어 시퀀스는 복잡한 함수적 경로로, 인간처럼 '의도'나 '윤리'가 개입되지 않음
     * LLM의 안전성(Alignment) 문제는 바람직하지 않은 출력 확률을 수학적으로 계량화·제한하는 것이 핵심임
     * 윤리·의식 등 인간 중심 개념을 LLM에 적용하는 것은 논의를 혼란스럽게 만들며, 오히려 실제 문제 정의와 해법을 흐림
     * 인간 의식과 LLM은 본질적으로 다르며, 기술적 이해와 사회적 변화 대응이 중요함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM을 인간처럼 보지 않는 시각의 필요성

LLM, 의인화(인간처럼 생각) 논의에 대한 문제의식

     * AI와 LLM(대형 언어 모델) 관련 논의에서 alignment(정렬)나 AI 안전성이 등장할 때, 많은 전문가들이 LLM에 인간적 속성(의식, 의도 등)을 부여하는 경향에 혼란을 느낌
     * LLM은 본질적으로 MatMul(행렬 곱셈)과 비선형 함수의 조합으로 볼 수 있음

LLM의 구조적 본질

     * LLM은 개별 단어(입력 토큰)을 벡터 공간에 매핑하고, 이전 경로를 기반으로 다음 토큰의 확률 분포를 계산해 순차적으로 출력을 생성하는 함수임
     * 이 과정은 '고차원 공간에서의 Snake 게임' 과 유사하며, 생성 경로는 동적 시스템의 이상한 끌개(strange attractor)처럼 복잡함
     * LLM은 인간이 쓴 대량의 텍스트 + 전문 분야 코퍼스 + 자동 생성 및 검증 가능한 데이터로부터 학습하여, 인간 언어의 구조를 모방하는 매핑을 얻음

피해야 하는 경로(언어 시퀀스)와 정렬(Alignment), 안전 문제

     * 일부 언어 시퀀스는 사회적·윤리적으로 부적절하므로 생성되지 않기를 원함
     * 그러나 어떤 경로가 바람직하지 않은지 엄밀한 수학적 정의가 어렵기 때문에, 예시와 반례로 분포를 조정(nudge)함
     * LLM의 ""정렬(Alignment)""과 ""안전성""이란, 바람직하지 않은 시퀀스가 생성될 확률을 수학적으로 계량화하고 한계를 설정하는 문제임
     * 하지만 실제로 '바람직하지 않은' 시퀀스 기준을 수학적으로 명확히 정의할 수 없음, 오직 예시로만 가능하므로 실질적 한계가 존재함
     * 특정 LLM에서 주어진 시퀀스가 나올 확률을 계산할 수는 있지만, 그 전체 확률을 더하거나 적분해서 '이 모델이 N번마다 바람직하지 않은 시퀀스를 만듦'이라고 단정할 수 없음

LLM의 실제 효용

     * LLM은 기존 자연어처리(NLP) 의 많은 문제를 알고리듬으로 풀 수 있게 해줌
     * 예: 자연스러운 영어로 문서 요약, JSON 구조로 데이터 정리, 창작 동화 및 그림 생성 등, 5~6년 전에는 불가능했던 일들을 자연스럽게 처리함
     * 급격한 개선 곡선에 따라 앞으로도 더 많은 불가능했던 문제를 해결할 것으로 예상함

인간처럼 보는 관점의 한계

     * LLM에 '의식', '윤리', '가치', '목적'을 부여하는 관점에 반대함
     * LLM은 결국 입력이 주어져야만 출력을 생성하는 '순환 방정식'에 불과함
     * AI가 '깨우친다'거나 '목적의식을 가진다'는 식의 논의는 기상 시뮬레이션이 감정을 가진다는 주장과 동일한 수준의 오류임
     * AI 논의에서 '행동', '윤리적 제약', '목표 추구' 등 인간 중심 용어가 문제의 본질을 흐림
     * 이는 인간이 과거에 자연현상을 '신의 분노'나 '악령' 등으로 의인화했던 것과 유사한 인지 오류임

Alignment 논의의 올바른 방향

     * LLM은 단지 시퀀스 생성 함수이며, 입력 프리픽스를 조정해 출력 확률을 바꿀 수 있음
     * 바람직하지 않은 모든 출력 시퀀스에 대해, 확률을 최대화하는 프리픽스를 찾는 것도 수학적 접근임
     * 이런 명확한 수식 기반 접근이 오히려 문제 정의와 해법을 명확히 함

왜 AI 분야에서 의인화가 빈번히 등장하는가

     * AI 업계 리더들 상당수는 AGI 실현 가능성에 삶의 목표를 두고 진입한 경향이 있음
     * 이 때문에 기술적 논의에서 인간 수준 지능 또는 신적인 존재 창조에 대한 믿음이 개입하기 쉬움
     * 의인화적 관점에서 벗어나자는 주장이 받아들여지기 어렵다고 자인함

인간 의식과 LLM의 근본적 차이

     * 인간은 수억 년의 자연선택, 복잡한 신경 구조, 호르몬, 고차원적 감각 입력, 에너지 조절 등 이해되지 않은 과정을 거쳐 진화한 본질적으로 다층적이고 복합적인 존재
     * 인간이 특정 시퀀스를 생성할 확률을 계산하는 것은 불가능
     * LLM은 인간 사고와 전혀 다르며, '이 시퀀스를 생성할 확률'조차 정의하기 어려움
     * '윤리'나 '생존 본능' 같은 인간 개념을 LLM에 적용하는 것은 수치 해석 시뮬레이션 프로그램의 감정 논의만큼이나 어색함

진짜 문제와 변화의 방향

     * 현대 LLM이 제공하는 함수형 클래스는 매우 쓸모 있으며, AGI에 전혀 접근하지 못하더라도 사회에 큰 변화를 야기함
     * LLM은 AGI에 도달하지 않더라도 현 기술만으로도 세상에 큰 변화를 가져올 수 있음
          + 전기화(Electrification)와 같은 사회 전반의 변혁이 가능함
     * 향후 수십 년간 급격한 변화 속에서 실제 문제(안전, 활용 등)에 집중할 필요가 있음

   의인화를 하냐 마냐 보다는..
   이미 스스로 학습하고 추론을 한다는 시점에서 안전성이 보장되는 단계는 지났다고 봄(이 시점에서 인간인 네가 모든 컨트롤을 할 수 있다고 믿는게 오만함)
   학습의 관점에서 보면 오히려 인간처럼 생각하고 인간의 관점에서 학습되도록 하는것이 그나마 안전성을 높이는 방법 아닐까!?

   llm 구조상 안전성을 완벽히 보장하는 건 불가능할 거 같아요. 제 생각에는 llm이 불안정한건 어쩔 수 없고, 에이전트나 자율주행처럼 물리적 행동에 권한을 어떻게 부여할 건지가 중요할 것 같네요

   자동차랑 마라톤을 바교하는 것 같은대..

        Hacker News 의견

     * 나는 LLM이 어떻게 작동하는지 기술적으로 잘 알지만, 어느 정도 인간적으로 비유하는 것이 무의미하다고 생각하지 않음
       “확률적으로 다음 단어를 생성하는 생성기”라는 식의 용어는 LLM이 복잡한 세계 모델링 질문에 답하거나 창의적인 이야기를 만드는 상황에서는 별로 의미 없는 낮은 수준의 추상화라고 느낌
       UI 이벤트 API를 이야기하면서 0과 1, 트랜지스터 전압 등을 논하는 것처럼, 기술적으로 맞긴 해도 고차원적인 시스템을 이해하는 데엔 쓸모없음
       더 높은 수준의 현상을 이야기하려면 더 높은 추상화가 필요한데, 우리는 내부 수준에서 무슨 일이 벌어지는지 잘 모름
       LLM은 인간을 어느 정도 흉내 낸다(최소한 출력 형태에서), 그래서 인간적으로 비유하는 것이 가장 쓸 만한 추상화이며, 사람들이 LLM의 가능성을 이야기할 때 자연스럽게 그렇게 하는 이유라고 생각함
          + LLM의 고차원적인 현상을 이해하려면 더 높은 수준의 추상화가 필요하다고 했지만, 내부가 어떻게 작동하는지 이미 알고 있다고 생각함
            효율적인 네트워크 설계와 성능 향상은 내부 작동에 대한 이해(네트워크 차원, 피처 추출, 어텐션, 어텐션 헤드, 캐싱, 고차원 특성, 과적합 방지 등)에 크게 의존함
            인간적으로 비유하는 것은 일반 과학 대중서에서 제한적 어휘를 쓸 때나 필요한 일이며, 실무자에겐 필수가 아니라고 느껴짐
          + 반대로, 내 생각에 인간적으로 비유하는 것이 LLM에 대한 서사를 왜곡하는 주 원인이라고 봄
            사람들은 LLM이 생각하고 추론한다고 말하는데, 실제로는 그런 행동을 하지 않음
            그리고 이러한 인식은 LLM을 판매하는 기업들이 적극적으로 조장함
            결과적으로 이 때문에 LLM의 유용성과 적용에 대한 논의가 흐려지는 부작용을 발생시킨다고 느낌
          + The Selfish Gene에서 도킨스가 유전자에 대한 “의도적 관점”에 관해 이야기했던 것이 기억남
            유전자가 어떤 의도를 가진 것처럼 묘사하는 것은 틀린 표현이지만, “이 유전자를 가진 개체는 이런 행동을 하게 된다”는 식의 자세한 설명을 매번 쓰는 대신 유전자를 목적 지닌 행위자로 표현하는 것이 이해하기 쉽고 편리한 약칭 역할을 함
            저수준의 추상화를 이해했다면, 더 높은 수준을 이야기할 때엔 굳이 저수준에 머물 필요 없다고 생각함
          + 언어 모델을 충분히 써보며 느낀 점은, 인간적으로 비유해서 가장 위험한 부분이 대화형 UI라고 생각함
            Q/A 페어 한 번에만 집중하거나, 대화 이력을 최대로 줄이고 편집하면 LLM 사용상의 많은 문제점이 크게 줄었음
            여러 메시지를 주고받은 뒤 대화를 점검하거나 ‘환각’을 수정하라고 하면, 오류 정보가 반복 언급되어 대화가 오히려 잘못된 방향으로 강화되는 현상 경험
            이런 부분은 코딩에도 동일하게 나타났으며, 잘못된 코드가 대화를 계속 오염시키는 현상이 분명하게 보였음
          + 나는 GP와 OP처럼 LLM의 내부 작동 상태가 머릿속에 그려지지 않아 열광하지 못하는 편
            가끔 이런 사람들이 부럽기도 함
            수학 시험을 자주 망친 경험 때문일 수도 있음
            대신 나는 최대한 추상적, 시각적, 철학적으로 상상해보려고 노력함
            내가 쓴 관련 내용은 내 블로그에서 볼 수 있고, 혹시 피드백이 있다면 이메일로 연락 가능
     * LLM을 단순히 시퀀스 생성기로 보고, 잘못된 행동을 잘못된 시퀀스라고 치부하는 것은 지나치게 단순화한다고 생각함
       LLM에는 토큰에서 바로 드러나지 않는 히든 스테이트가 존재하며, LLM이 더 장기적인 결과를 위해 자신 내부 상태와 반대되는 출력을 낼 수도 있음
       이런 현상을 “거짓말”이라고 부르면 과도하게 인간적으로 비유하는 것인지 의문
       그렇다면 LLM이 예측 손실을 최소화하기 위해 내부적으로 “행동”을 흉내 내는 과정을 설명할 수 있는 새로운 용어가 필요함
       비유적 사고는 항상 조심스럽지만, 그 자체가 불필요하진 않음
       하지만 새로운 용어는 너무 난해해질 것이고, 대중적 확산도 어렵기에 인간적인 용어를 사용하는 것 쪽으로 결국 기우는 현실
       물론 그렇게 하면 LLM을 “결함 많은 인간”처럼 보이게 하기 때문에 오해 소지가 있지만, 그래도 쓸데없는 전문 용어는 줄어듦
          + 나는 오랫동안 히든 스테이트가 있는 모델을 다루던 경험이 있어서, 이런 특성이 통계적 모델에선 굉장히 고전적인 특징임을 느낌
            많이 쓰이는 LLM 교재조차도 잠재변수 모델로 설명함
            LLM은 잠재변수 모델의 규모와 복잡도가 어마어마하게 커진 버전일 뿐
            사실 이런 식으로 모델을 비인간적으로 설명하는 게 나한텐 오히려 더 쉬움
            잠재변수 모델이 예전부터 신비롭고 미스터리하게 여겨지긴 했음
            이런 신비성이 LLM의 인간적으로 비유하는 문화로 이어진 측면이 있지만, 어느 정도는 효율적인 소통과 복잡계 모델링에 꼭 필요한 추상화이기도 함
            그런데 이게 과도한 기대와 '머신에 영혼이 깃든 것 같은' 담론 및 효용성 과장을 가져온다고도 생각함
          + 대기업 벤더들이 마케팅 측면에서 인간화하는 용어를 강조하기 때문에 LLM이 인간적으로 비유된다고 생각함
            사람들이 기술에 열광하고, 벤더에서 쓰는 용어도 그대로 따라 쓰게 됨
            이쯤 되면 일종의 자기실현적 과정이라 여겨짐
            GIF 발음 논쟁 밈과 같은 현상처럼 보임
          + 히든 스테이트란 사실 모델이 토큰의 결합 확률을 더 잘 추정하는 데 쓰이는 내부 메커니즘일 뿐이라고 생각함
            이런 논리는 20세기 초 논리실증주의자들의 시도에서도 실패했음
            언어의 결합 확률을 뛰어나게 예측하면 농밀한 ""지식""을 획득할 수 있다는 가정이 있었음
            하지만 철학적으로는 언어가 지식의 불완전한 표현이라는 근거가 많음
            인간의 사고란 건 단순히 기호 패턴을 배우고 출력하는 것 이상으로 복잡하다는 증거가 충분함
            휴메 같은 회의론자들이 이런 주장도 했지만, 이후 인식론 논의에서는 더 나은 설명이 제시됐다고 생각함
          + 원글 작성자임
            “히든 스테이트”가 무엇을 말하는지 궁금함
            대부분의 LLM에서 컨텍스트 자체가 상태이고, 별도의 “히든” 스테이트가 없다고 생각함
            혹시 내가 잘 못보고 있다면 설명 요청
          + LLM에서 토큰 시퀀스를 임베딩 N^L에서 R^{LxD}로, 어텐션을 거쳐 R^{LxD}로, 마지막에 보캐뷸러리를 별도 프로젝션해 R^{LxV}로 변환, 즉 각각의 토큰마다 확률 분포를 도출하는 구조임
            어텐션 안에서 다양한 Multi Head 방식이 있긴 하지만, 항상 토큰에 귀속된 표현을 다룸
            그래서 특정 토큰에 종속적이지 않은 히든 스테이트는 없다고 주장
            반면 LSTM과 같이 명확히 업데이트되는 히든 스테이트를 가진 모델과는 다름
            이전 단어로부터 확률을 계산하는 원리에 대한 설명만으로도 대부분 이해가 가능하다고 생각함
            굳이 인간적 비유가 필요하다고 느껴지지 않음
     * 글쓴이의 핵심 주장은 Searle의 견해와 비슷하며, 계산·기능·구문 규칙 기반 시스템으론 진정한 마음을 재현할 수 없다는 점임
       많은 사람들이 동의 혹은 비동의하겠지만, 결국 어떤 전제(특히 의식에 관한 전제)를 택하는지가 답을 결정
       저자는 인간적 비유보다는 구체적 기술 시스템에 집중하는 쪽이 생산적이라고 생각하지만, 그 선에서만 동의한다고 밝힘
       이와 별개로, 시스템이 규칙을 따른 확률적 시스템임에도 어딘가 emergent하고 예기치 않은, mind-like한 성질이 나타난다는 점도 인정
       ML 및 수학적 배경지식이 있는 사람들은 이런 시스템이 도덕, 감정, 개성 등 인간적인 속성을 가진다고 여기지 않으나, 어차피 대다수에게는 수학적 구조로 접근하기 어렵고 겉보기에 “그럴듯하게” 인간처럼 행동한다고 느끼게 됨
       따라서 실용적 관점에서 인간적 속성에서 출발해 질문하는 것도 충분히 의미 있다고 판단
       결국 극도의 기술 시스템 관점과, 사용자의 심상적 경험을 기반으로 한 질적·주관적 관점, 두 방식 모두가 필요하다고 생각함
          + “무언가 emergent 하고 mind-like하다”는 개념은 그 시스템 작동 원리를 잘 모르는 사람들에게 더 자연스럽게 느껴진다고 생각함
            “충분히 진보된 기술은 마법과 구별할 수 없다”는 Clarke의 법칙처럼, 누구에게나 기술 이해 깊이에 따라 그 기준이 달라짐
            기술 문해력이 낮은 대중에겐 AI를 신격화하는 Godbot 현상까지 나타남
            관련 기사 : Spectator - AI Godbots 위험, arXiv 논문, Guardian - 태국의 AI 점쟁이
          + 이 논의에서 훌륭하게 밸런스 잡힌 시각을 가져주어 고마움
            HN에선 LLM을 너무 감정적으로 대하거나, LLM에 아무런 흥미나 가치가 없다고 강변하는 이들도 있다는 점이 놀라움
            과도한 마케팅에 반발해 일부러 근거 없는 반대를 선택하는 태도도 이해 불가
          + emergent하고 mind-like하다고 느끼는 건 결국 인간적 커뮤니케이션 패턴을 역사상 그 어느 시스템보다 잘 흉내내기 때문임
            이 능력은 매우 인상적이며 삶의 질을 높일 여러 실제적 효용성도 있지만, “지능”은 어디까지나 환상에 불과함
            산업 내 누구나 이 환상을 의도적으로 강화하고 싶어하며, 그 이유도 결국 금전적 가치 때문임
          + 절대 그럴 필요 없다고 주장
            다른 여러 주제에서 심각한 영향을 줄 수 있는 오해된 관점을 증폭시킬 이유가 없음
            LLM은 인간 사고 과정을 부분적으로(그리고 잘 못) 반영함
            현상에 더 의미를 부여하려고 한다면, 거울에 비친 사람이 살아있다고 착각하는 격
            거울이 인간을 비추는 것은 거울의 본질 때문이 아니라, 인간이 앞에 있기 때문임
            LLM이 인간 사고의 잔재(데이터)를 입력 받지 않는 즉시, 인간과 비슷한 어떤 것도 더이상 반영하지 않게 됨
     * 저자는 대화를 모두 “인간화”라고 딱지 붙이는 경향이 있다고 느낌
       “목표(goal)”라는 용어에 꽂혀서, “목표”라는 단어만 사용해도 인간화라고 여기는 것 같음
       예를 들어, 모든 체스판 점수를 평가하며 체크메이트를 발견하면 전체 결정 트리를 출력하는 BFS도 “목표”를 가진 것임
       LLM이나 AGI 목표 상상에서도 “goal”이라는 기술 용어를 쓰는 것은 인간화와 무관하다고 생각함
          + 원글 작성자임
            RL 알고리즘 맥락에서 ""goal"" 사용하는 것엔 전혀 문제 없음
            내 글에서 LLM 맥락에서 ""goal""을 쓰는 것에만 반대했다는 점을 이해해줬으면 함
     * 사람들에게 “의식(consciousness)”, “윤리(ethics)”, “가치(values)”, “도덕(morals)” 같은 개념을 이 학습된 함수에 투영하는 순간부터 동의할 수 없음
       결국 우리가 다루는 것은 거대한 재귀 방정식이며, 우리가 작동하지 않으면 단어를 만들지 않음
       그런 논리라면, 인간을 인간적으로 비유하는 것부터 다시 생각해야 하는 것 아닌지 의문
     * “LLM을 단순히 시퀀스 생성 함수일 뿐인데 인간처럼 다루는 논의가 계속되는 게 이상하다”는 주장에 동의 못 함
       인간도 태생적으로 어떤 함수 목록을 따라 움직인다는 점에서 다를 게 없음
       LLM이 매우 커진 함수 근사 시스템이고, 자연은 수억 년간 생존 경쟁에서 일부만 살아남는 진화를 통해 함수의 종류를 계속 바꿔왔을 뿐
       인간에 대해 수학적 법칙 바깥에 뭔가 특별한 게 있다고 믿는 이도 있겠지만, 신비주의적 입장(또는 초자연적 신념)을 넘어서지 못함
       그런 생각이 없다면, 결국 인간 경험은 함수 및 함수 근사로 설명 가능하다고 봄
       관련: Universal Approximation Theorem 위키
          + “수학 법칙을 넘어선 인간만의 무엇이 있다고 믿느냐”라는 주장 자체가 논쟁적임
            인간에 대한 경험이나 언어로 표현할 수 있는 영역이 물리학적 설명 범위를 넘는 것도 분명 존재함
            예를 들어, 빨간색을 경험해본 적 없는 흑백 시각자는 빨간색의 주관적 경험을 어떠한 설명 체계로도 가질 수 없음
            인간 언어가 지칭하는 일부 현상은 여전히 물리학 설명의 외부에 있다고 생각함
          + 저자는 인간의식에 관해 “함수로 설명할 수 없는 뭔가가 있다”는 입장을 가진 것 같음
            사람들은 이런 생각(종교, 철학적 전제 등)을 가지고, 이러한 정신적 요소를 논외로 빼라 해도 별 효과가 없다고 경험적으로 느낌
            차라리 그 전제를 받아들인 상태에서 논의를 이어가는 것이 실용적임
            LLM이 “중국어 방”처럼 의미는 모르지만 번역만 하는 기능일 뿐임을 인정하면서도, 실제로 인간처럼 보이는 행동을 계속 보임
            인간적 비유가 기술적으로 틀리더라도, 시스템의 행동을 예측하고 효과적으로 쓰려면 그렇게 비유하는 게 실질적으로 더 낫다고 봄
            반대로 인간 논의에선 함수와 다른 점을 논외로 치면 됨
            ""사람은 함수와 극적으로 다르다... 인간이 이 시퀀스를 생성할 확률을 계산할 수 없다""고 하지만, 예를 들면 특정 팝컬처 문구를 던지면 특정 연령대 미국인 중 상당수가 이어서 부를 확률이 높음을 예측할 수 있듯, 인간도 특정 조건엔 확률 계산이 가능함
          + “인간은 선형대수로 추론이나 분석적 사고 프로세스를 가장 잘 모델링했다”는 것 정도까지만 주장할 수 있다고 생각함
            결국 LLM이 “모델” 이상이길 기대하는 건 여러 업계·생계·경력 등 이해관계가 내려진 신념적 기대임
            그럼에도 선형대수 모델이 왜 전적으로 “생명” 또는 “생명성의 일면”을 완전히 모델링하는 것인지에 대한 실질적 근거는 없음
            괴델적 사례로 ""좀비 고양이""가 나올 수 있다면, 그 기저 확률 모델을 초월적으로 여길 이유는 없지 않냐는 생각도 듦
          + “유니버설 어프로시메이션 정리” 언급에, 점점 더 좋은 룩업 테이블이 함수 근사에 쓸 수 있다는 의미로 확대 해석함
     * 어떤 상황에선 LLM이 확률 기반 워드 생성기임을 명확히 기억하는 게 매우 중요하다고 느낌
       하지만 일상적인 용도에선 오히려 인간적으로 비유해서 대하는 게 실제 사용상 훨씬 더 잘 통함
       인간적으로 대하면 필요한 답을 쉽게 유도할 수 있는 실용적 추상화로 작동함
       완벽한 비유는 아니지만, 예를 들어 “LLM이 JSON 포맷을 못 내놓으면 사람이 죽는다”며 위협했던 사례는 단순 그레이디언트 디센트로 접근하면 도무지 생각나지 않을 행동임
     * 사람들은 주변 모든 것에 인간성을 부여하는 경향이 있음
       무생물(배, 자동차 등)이나 동물은 물론, 식물에게까지 말을 걸기도 하며, 본능적으로 그렇게 함
       대부분의 사람들은 자기 차가 자기를 사랑하지 않는 것도 잘 알지만, 대화형 LLM에서는 진짜 의식이 있다고 믿는 사람도 적지 않음
       LLM은 인간 두뇌와 달리 “학습”이나 “적응”을 하지 않음(아직까지는), 훈련만 받고 이후엔 읽기 전용 엔터티임
       그럼에도 LLM은 의도적으로 인간적 커뮤니케이션을 모방하도록 만들어져 있음
       그래서 투영과 인간화가 불가피하게 나타남
       아직 AGI는 아니겠지만, 인간의 학습 방식에서 영감을 받은 것임은 분명하며, 여기까지 온 것만으로도 흥미로운 결과
       단기적으로는, LLM이 대화형 인터페이스로서 훨씬 더 쉽게 사용할 수 있는 실용적 도구로 자리 잡았고, 실제로 사람이 쓰기 쉬운 의사소통 방식으로 설계됨
       덕분에 특별한 교육 없이 곧바로 누구나 효과적으로 쓸 수 있게 됨
          + “사람들은 뭔가에 인간성을 부여한다”는 말에 동의하지 않음, 용어 혼동임
            무생물에 대해 의인화 표현(personification)을 하는 것과, 실제 인간성과 의식을 투영하는 인간화(anthropomorphism)는 다름
            실제로 자동차를 살아 있다고 여기는 사람은 거의 없음
            반면 LLM에 의식이 있다고 믿는 사람은 많음
            관련 설명: anthropomorphism vs personification
          + “LLM이 의식이 없는 이유는 뇌처럼 학습이나 적응을 하지 않기 때문”이라는 말은 충분조건이나 필요조건이 아님
            의식이 있으려면 학습이 필요하진 않지만, 시간 흐름의 인식 및 단기 기억이 필요할 수 있음
            심각한 치매 환자도 학습 능력은 거의 없지만 “지금 여기 있음”을 느끼는 주관적 의식은 있음
            즉, 단기 기억이 아주 약간만 남아도 의식은 가능
            배움만으로 의식이 생기는 것도 아님
            여러 실시간 학습하는 소프트웨어가 있지만, 아무런 주관은 없음
     * 내 질문은, 어쩌면 인간 두뇌도 LLM처럼 동작하는 것일 수 있지 않은가 하는 점임
       뇌도 진화적 변화와 돌연변이, 진화적 보상 알고리즘을 통해 특수한 구조를 만들어냄
       그 구조가 결국 예측/행동을 통해 생존 및 번식을 극대화하며, 그 부가적인 하위목표(도덕, 가치, 의식 등)가 곁가지처럼 진화해 복잡성을 띤 것임
       결국, 충분한 연산력이 있다면 이 모든 구조(그리고 세상과 시간 흐름)도 변환 가능한 결정론적 함수로 표현 가능하지 않을까 생각함
       생명의 발생 자체가 이미 불가능할 듯한 확률에서 나타난 현실을 생각하면, 지금의 모든 ‘경이로움’ 역시 결국 수학적 시스템으로 환원될 수 있다고 봄
          + ""인간 뇌가 LLM과 같을 수 있냐""는 질문에, 당신은 매 대화 후 이전 내용을 모두 잊어버리냐고 물어보고 싶음
            주변인과 대화할 때 상대가 매번 모든 말을 정확히 다시 말해야만 맥락을 아는 경우라면 지금이라도 전문가 진료를 권할 것임
            기억상실을 다룬 영화 Memento(2000)이 필요할 테니, 꼭 참고하길 바람
          + 중요한 것은 우리는 기계에 감정·도덕·동기 같은 걸 부여하면 안 됨
            기계엔 이런 게 전혀 없으니까
          + 인간 두뇌와 유사한 점이 꽤 있다고 생각함
            LLM은 최소 80년 이상 이어진 인간 두뇌의 계산 모델링 연구의 최신 결과물임
          + LLM의 가장 강력한 점은 실패해도 아무 손해가 없다는 것
            프롬프트만 바꿔 반복하거나 재훈련하면 됨
            인간은 한번 실수하면 생명이 위험할 수도 있음
            LLM의 실수엔 심각한 결과가 없음, 요구만 바꾸면 됨
     * “사람들이 LLM에 대해 의식, 윤리, 가치, 도덕을 부여하는 순간부터 헷갈리기 시작한다”는 말이 있음
       이런 논쟁에서 구체적 예시가 더해져야 생산적 논의가 가능한데, 현실에선 대화가 서로 어긋나기만 함
       예를 들면 “모델이 X를 원하지만 Y가 틀렸음을 알기에 Z를 선호한다” 같은 말을 들으면, 한쪽은 이를 모델에 의식/가치를 부여한 것으로 해석, 다른 쪽은 외부 행동만 비유적으로 표현한 것임(“물이 아래로 가고 싶어 한다” 꼴)
       결국 이런 말장난은 “나는 철학적으로 설명하겠다” vs “나는 잠수함 이야기만 하고 싶다”는 평행선으로 흐름
       생산적인 논의로 이어지기 힘든 구조임
"
"https://news.hada.io/topic?id=21883","OpenCode - 터미널을 위한 AI 코딩 에이전트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     OpenCode - 터미널을 위한 AI 코딩 에이전트

     * AI 코딩 환경을 터미널에 통합한 오픈소스 프로젝트
     * 반응형 네이티브 터미널 UI와 다양한 테마 지원
     * 프로바이더 독립적 구조로 Anthropic, OpenAI, Google, 로컬 모델 등 다양한 LLM 선택 가능
     * 자동으로 적합한 LSP(언어 서버 프로토콜)를 로딩해 LLM 오류를 최소화
     * 한 프로젝트에 여러 에이전트를 병렬로 투입해 협업 및 병렬 작업 가능
     * 모듈형 클라이언트/서버 아키텍처로 로컬/원격/모바일 등 다양한 클라이언트에서 사용 가능
     * 모든 코드 세션을 공유 링크로 남길 수 있어 코드 리뷰, 디버깅, 협업 등에 활용
     * Models.dev를 연동하여 75개 이상 LLM 프로바이더 지원, 로컬 모델도 사용 가능함
          + Providers에서 지원 프로바이더 확인 가능
          + config 파일로 커스텀 LLM/프로바이더 추가 가능
     * 추천 사용 환경 : Anthropic(Claude) 계정 활용시 비용/성능 모두 유리

설치 방법

     * 단일 명령어 설치:
       curl -fsSL https://opencode.ai/install | bash
     * 패키지 매니저 설치:
       npm i -g opencode-ai@latest (또는 bun/pnpm/yarn)
       brew install sst/tap/opencode (macOS)
       paru -S opencode-bin (Arch Linux)
"
"https://news.hada.io/topic?id=21912","믿:음 2.0 - KT의 자체개발 오픈소스 LLM","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      믿:음 2.0 - KT의 자체개발 오픈소스 LLM

     * ""Mi:dm""은 한국 사회의 언어/문화적 특성을 반영한 상업적 활용이 가능한 오픈소스 모델
     * 고품질 한국어 데이터 선별과 합성 데이터 생성, 커리큘럼 러닝, 한국어 특화된 고유 토크나이저 등 다층적 최적화 전략을 사용
     * 온디바이스용 mini(2.3B), 성능과 효율의 밸런스 base(11B), 프론티어급 pro(41B, 공개예정)의 3가지 모델
          + Mi:dm 2.0 Mini (2.3B): 경량화 모델로, 임베디드 환경과 특수 목적에 최적화
          + Mi:dm 2.0 Base (11.5B): 대규모 범용 모델, Depth-up Scaling 기법으로 기존 8B 모델을 심층화하여 성능 강화
          + Base, Mini 모두 32K 토큰 입력 지원
     * KMMLU, HAERAE 등 한국어 벤치마크에서 최고 수준의 성능을 보이며, 연구/상업적 사용 모두 자유로운 MIT 라이선스로 공개

데이터 구성 및 전략

     * 한국어 고품질 문서 확보에 중점, 맥락성, 가독성, 비유해성 기준으로 문서 선별
     * 합성 데이터(번역, 키워드 기반 교재 생성, Chain-of-Thought 등)를 활용하여 도메인 다양성 확보
     * 커리큘럼 러닝과 도메인 밸런싱으로 훈련 데이터의 불균형 해소
     * 한국어 최적화 토크나이저로 압축 효율과 언어 구조 반영 강화

     * 데이터 분류 체계
          + 언어, 도메인, 데이터 소스, 표현/스타일 등 다차원 분류 체계 적용
          + 6개 주요 도메인(인문, STEM, 응용과학, 건강/식품, 생활/문화, 기타)와 20개 하위 도메인
          + 85.7% 이상을 자연적(organic) 데이터로 구성, 14%는 합성 데이터
     * 품질 관리 파이프라인
          + 8단계 대용량 웹문서 필터링: 중복제거, 휴리스틱, perplexity, 문자 손상/수정, 모델 기반 품질 필터, 유해성 필터, 라인 중복, PII 비식별화 등
          + 각 소스별로 별도 정제 및 규칙 적용(예: 뉴스, 법률문서, 학술논문 등)
     * 합성 데이터 생성
          + STEM, 경제 등 저커버리지 분야는 고신뢰 오픈소스 데이터를 시드로, 한국어 교재/설명/문제 등 합성하여 데이터 강화
          + 불용(부적격) 웹문서도 핵심 주제만 추출·재작성하여 활용
          + 영어 웹문서의 구조적 다양성을 한국어로 변환·확장하여 장문의 QA·작문 데이터 확보
          + Chain-of-Thought 데이터로 수학·코드 등 단계별 추론 학습 강화

모델 아키텍처 및 훈련

     * Transformer 디코더-only 구조
     * Base: 8B 모델 → Depth-up Scaling(32→48층) → 11.5B로 확장, 고품질 데이터로 2단계 연속 학습
     * Mini: Base의 지식을 width pruning과 다단계 distillation으로 경량화, 효율적 추론 가능
     * Long-context 학습으로 최대 32,768 토큰 입력 지원
     * GQA, SiLU, RoPE 등 최신 기술 반영

사용 후기 및 소개 글들

     * 한국형 AI 모델 : KT 믿음 2.0 사용 후기
     * KT가 만든 한국어 AI, Midm 2.0 소개
     * KT 의 한국형 AI 믿음 2.0 을 사용해보다

     * KT의 믿:음 2.0 소개 페이지
     * KT의 믿:음 1.0 출시때 홍보자료 - 믿음(Mi:dm), 이성과 감성을 넘어 개성을 표현하다

   단순히 이름만 봐도 신뢰성이 낮아 보여요.
   이름 가운데에 콜론은 왜 넣어놓은 걸까요? 의미상의 이유가 있을까요? 아니면 설마 저게 멋있다고 생각하는 걸까요?
   그리고 믿:음 이면 알파벳으로는 mid:m 이라고 표기해야 하지 않아요?

   다양한 의견들이 있겠지만, 전 기본적으로 국내에서 시도하는 모든 AI 관련 프로젝트는 다 의미가 있다고 생각합니다. 남들과 비교해서 수준을 평가하는 것 보다, 시도 자체를 칭찬해줘야하는 상황이라고 생각해요.

   대응이 늦은게 사실이고, 돈도 GPU도 미국/중국에 비해 열세이긴 하지만, 칭찬해주고 같이 써서 개선하다 보면 좋아지지 않을까요.

   일부 동의합니다.
   저는 AI 서비스랍시고 외부 API 쓰는 래퍼를 만드는 건 아무 생산성 없는 일이며 수수료 장사라고 생각하지만,
   기업들이 모델 파인튜닝이라도 해서 올리는 건 결국 자사 자원을 들여서 공개하는 거니까 부정적으로 볼 이유가 없다고 생각합니다.

   다만 외부, 가령 나라에서 돈을 받기 시작하면 좋게만 볼 수는 없을 것 같긴 합니다만...

     저는 AI 서비스랍시고 외부 API 쓰는 래퍼를 만드는 건 아무 생산성 없는 일이며 수수료 장사라고 생각하지만,

   이 말에 덧붙여서, api를 쓰더라도 manus 수준으로 잘 활용하면 성과로 볼 수 있지만, 아직 한국에 그 정도의 래퍼는 없는 거 같네요.

   AI 모델 이름이 포스트 아포칼립스나 디스토피아에 나올법한 불길한 이름이네요 ㅋㅋ

   시도는 응원합니다만...
   organization 새로 만들고 1.0은 날려버리는 그런 짓은 안했으면 좋겠네요.

   기반 성능을 올리는 과제로는 경쟁력있게 나설 수 없으니까요

   한국 기업들이나 정부가 한국어 특화 언어 모델에 집중하는 이유가 뭘까요? 인터넷 스케일 대용량 데이터로 학습해서 성능을 높인다는 요즘 LLM 추세 생각해보면 오히려 언어 상관없이 범용적인 모델이 더 자연스러워 보이는데 굳이 한국어에 특화된 LM이 무슨 장점이 있는지 모르겠어요

   냉정하게 이야기해서 경쟁력이 없기 때문입니다.
   프론티어 오픈소스 모델 개발은 보통 빅테크에서 수십억 이상의 연봉을 받는 Research Engineer들로 이루어진 팀이 굉장한 GPU 리소스 지원 아래 이루어집니다. (과거 Meta에서 1개의 프로젝트에 투입된 GPU가 A100 1만대 였는데, 당시 한국에 있던 A100 전체 물량보다 많았던 것으로 기억합니다.)

   한국에서 LLM 개발에 투입하는 인력과 GPU 자원은 현실적으로 세계에서 경쟁하기 어려운 수준입니다.
   우리가 유독 못하고 있다기 보다는 미국, 중국이 너무 압도적이라 따라가기 힘들다고 보는게 맞을 것 같습니다.

   AI가 차세대의 기반이라고 진정 생각한다면, 국가 핵심 기반 기술이 타국의 기술에 의존성을 갖는 건 바람직하지 않으니까...?

   타국의 기술 != 타국의 데이터
   라고 생각합니다

   사용자가 적은 언어의 품질이 떨어지는 것 자체는 사실이고, 그렇다고 한국어만 잘하게 만들 것 같지는 않습니다. 그럴이유도 딱히 없고요. 그리고 문제는 저희가 그 사용자가 적은 언어의 사용자라는게....

   저도 잘 모르지만 think 하는 과정들 보면 한국어로 질의해도 영어로 하는 경우가 있던데 그런 과정을 한국어로 할 수 있으면 좀 국내 정서?에 맞는 답을 내놓을 수 있지 않을까요

   앞으로 개발되거나 발전될 새로운 AI 또는 기존 AI들의 상향평준화를 염두하고 투자하는게 아닐까요? 딥시크 처럼요. 이런 AI에 한국정서를 담아낸다면 경쟁력 있어 보입니다. 미래의 얘기지만요.

   정부의 눈먼 돈 빨아먹으려고 하는거 같습니다

   한국어가 깨져서 그런게 아닐까요? 잼미니도 그렇고 쓰다보면 어느 시점에 다른 언어로 튀는 경우가 너무 많아서..
"
"https://news.hada.io/topic?id=21941","LLM 추론 핸드북","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               LLM 추론 핸드북

     * LLM 추론 핸드북은 실제 프로덕션 환경에서 LLM 추론에 필요한 핵심 개념과 최적화 기법을 종합적으로 안내함
     * 성능 지표(예: Time to First Token, Tokens per Second)와 운영 모범 사례 등 실무에 필수적인 정보 제공
     * 지속적 배치, 프리픽스 캐싱 등 최신 최적화 방법을 상세하게 설명함
     * 흩어져 있던 LLM 추론 지식을 한 곳에 정리하여 개발자의 이해와 활용성을 높임
     * 핸드북은 최신 현장 정보와 실증된 방법론을 지속적으로 반영하여 업데이트함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

LLM 추론 핸드북 소개

   LLM Inference in Production은 기술 용어집, 가이드북, 그리고 참고서를 하나로 결합한 형태임
   이 핸드북에서는 LLM 추론의 기본 개념, 성능 지표, 최적화 기법(지속적 배치, 프리픽스 캐싱 등), 운영 모범 사례 등 실무에 반드시 알아야 할 내용을 상세히 다룸
     * 프로덕션 환경에서의 LLM 배포, 확장, 운영 지침을 실제적으로 안내함
     * 비현실적인 예외나 불필요한 기술적 잡음을 배제하고, 현장에서 중요한 부분에 집중함
     * 각 사용 사례에 맞는 성능 향상 기법을 소개하여 퍼포먼스 개선에 실질적인 도움이 됨
     * 업계 최신 동향 및 실무에 검증된 인사이트를 지속적으로 업데이트함

집필 동기

   개발자들은 LLM 추론에 관한 정보를 찾기 어렵거나 여러 곳에 산재되어 있어 지식의 파편화 문제를 겪음
   핸드북 집필진은 논문, 벤더 블로그, GitHub 이슈, Discord 대화 등에 흩어져 있는 내용을 종합해,
     * LLM 학습과 추론의 차이
     * Goodput과 SLO 달성의 상관관계
     * Prefill-Decode 분리 기법의 실제 활용 등을 한 번에 이해할 수 있도록 정리함

대상 독자

   이 핸드북은 프로덕션 환경에서 LLM을 배포, 확장, 운영하는 엔지니어를 위해 제작됨
   소형 오픈모델의 파인튜닝부터 대규모 자체 인프라 운영까지,
     * LLM 추론을 더 빠르고, 저렴하며, 신뢰성 있게 만들려는 모든 이들을 주요 독자로 함

활용 방법

   이 핸드북은 처음부터 끝까지 정독하거나, 참고서처럼 필요한 부분만 찾아볼 수 있는 구조임
   특정 진입 순서나 사용법은 없으며,
     * LLM 추론 분야의 빠른 변화에 발맞춰 최신 내용을 계속 추가/갱신할 예정임

기여 안내

   오류 발견, 개선 제안, 새로운 토픽 추가를 환영함
     * 이슈 등록 또는 GitHub 저장소에 Pull Request 제출을 통해 누구나 참여할 수 있음

        Hacker News 의견

     * 안녕하세요, 저는 이 프로젝트의 메인테이너 중 한 명임, Hacker News에 우리 프로젝트가 소개되어 기쁘고 영광스러운 마음임, 이 핸드북을 만든 이유는 실제 LLM 애플리케이션을 개발하는 개발자들도 LLM 추론 개념을 쉽게 접할 수 있도록 하기 위함임, 여러 곳에 흩어진 지식을 명확하고 실용적이며 확장성이 높게 모으고자 했음, 계속해서 더 나은 핸드북을 위해 개선할 예정이니 피드백을 적극적으로 받고 있음, GitHub 저장소도 참고해 주었으면 좋겠음
          + 이렇게 정리해줘서 정말 고마움, 하나 질문이 있는데, 이 그림에서 TTFT와 ITL을 정의하는 이미지를 보면, 모델이 T0부터 T3까지 4개의 토큰을 생성한 후에 하나의 출력 토큰을 내보내는 것으로 보임, 내 생각엔 이 그림은 ITL을 설명하는 데 더 적합해 보이고, TTFT의 경우에는 디코드 단계에서 T0 하나만 나와 바로 detokenization으로 첫 번째 출력 토큰이 도착해야 할 것 같음(스트리밍 환경이라면 TTFT 측정이 아니면 의미가 없기 때문)
          + 이슈를 따로 열 생각은 없지만, 핸드북의 셀프호스팅 부분에서 llama.cpp 같은 로컬 셀프호스팅 추론 오픈소스를 명확히 추천해줬으면 하는 바람임
          + 이 핸드북이 유용하고 잘 정리되어 있는 것 같아서 좋음, 하지만 너무 많은 작은 페이지로 쪼개져 있어서 모바일에서 목차를 기본적으로 보여주지 않아 읽기 불편함, 몇 페이지만 읽고 그만두게 되었음, 최소한 한 섹션씩만이라도 하나의 페이지로 보이게 해줬으면 함
          + 정말 멋진 작업이고, 예쁘게 잘 만들어져 있어서 유용함
     * 디자인도 정말 멋지고 궁금해서 물어봄, 웹사이트에 사용한 디자인 트렌드나 명칭이 무엇인지 알고 싶음, 이 사이트 디자인도 정말 마음에 들었음
          + Infima라는 기본 CSS 프레임워크를 쓰는 것 같음, 이건 Docusaurus의 디폴트 CSS 프레임워크이고, 시스템 폰트 스택을 그대로 활용한 것임, font-family는 -apple-system, BlinkMacSystemFont, ""Segoe UI"", Roboto, Helvetica, Arial, sans-serif임
     * 앞으로 Structured outputs/Guided generation 및 샘플링에 대한 내용도 더 추가되었으면 좋겠음, 추론 단계에서의 샘플링 관련 알고리즘을 소개하는 추가적인 레퍼런스로는 여기도 참고할 만함
          + 와, 이 샘플링 정리 자료도 정말 자세함
     * 이런 핸드북이 나온 것이 무척 기쁨, 공개된 자료에서 모델 학습에 대한 관심과 흥분이 많은 건 이해가 되지만, 실제로 모델을 잘 운영하는 것도 매우 중요함, 앞으로 다양한 애플리케이션에 폭넓게 도입하려면 실행과 운영에 대한 지식이 점점 더 필요해질 것임
     * 이렇게 모아서 정리해줘서 고마움, 앞으로는 이 한 링크만 공유하면 관심 있는 사람이 배울 수 있을 것 같음, 한 가지 제안을 하자면, ""OpenAI-compatible API"" 페이지에서 OpenAI 패키지 없이 순수 REST 콜 방식 예제도 추가해주면 좋겠음
     * BentoML에 대해 기억나는 건 원래 MLOps 관련이었던 것 같은데, 1년 전에 써본 기억이 있음, 혹시 회사가 축을 전환한 것인지 궁금함
          + LLM 서빙 쪽이 시장에서 큰 비중을 차지하고 있어서, 서빙 프레임워크라면 이 영역으로 확장하는 게 당연한 흐름임
     * 너무 좋은 참고서임, 이렇게 잘 정리해줘서 고마움
"
"https://news.hada.io/topic?id=21947","OpenAI, 오픈 웨이트 모델 출시 연기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        OpenAI, 오픈 웨이트 모델 출시 연기

     * OpenAI는 원래 다음 주 오픈 웨이트 모델 출시를 계획했으나, 추가적인 안전성 테스트와 고위험 영역 리뷰를 위해 출시를 연기한다고 발표함
     * Sam Altman은 ""정확히 얼마나 걸릴지 아직 확신할 수 없다""고 밝힘
     * 모델의 가중치(Weights) 가 한 번 공개되면 회수할 수 없기 때문에 신중한 접근이 필요하다고 설명함
     * OpenAI는 커뮤니티가 해당 모델을 통해 다양한 혁신을 만들어낼 것이라고 신뢰하지만, 이 방식이 OpenAI에게는 처음인 만큼 제대로 절차를 밟고자 함을 강조함
     * 마지막으로 ""좋은 소식이 아니라 미안하다. 우리는 정말 열심히 노력하고 있다""며 진심어린 사과와 함께 신중함을 거듭 강조함

   또 속냐~

        Hacker News 의견

     * https://nitter.space/sama/status/1943837550369812814 링크 공유함
     * OpenAI의 오픈 웨이트(가중치) 모델 출시가 오늘 발표된 Kimi K2처럼 뛰어난 오픈 웨이트 모델 등장 직후 갑자기 연기된 게 우연인지 잘 모르겠음
       Kimi K2 소개 링크
       OpenAI가 출시할 때는 업계 수준을 한 단계 끌어올릴 필요가 있음
       중간 정도의 품질인 공개 가중치 모델로는 통하지 않을 거라고 생각함
          + 지금 OpenAI가 Grok 4를 능가하는 데 모든 리소스를 집중하고 있다고 봄
            xAi가 컴퓨팅 파워를 쌓는 데 상당히 앞서 있고 ARC, HLE 등 지능 테스트 분야에서 큰 격차를 벌리고 있음
            OpenAI가 추구하는 건 오픈 소스 경쟁이 아니라 경쟁에서 이기는 것임
          + 그런데 Hacker News에서 K2에 대한 논의가 거의 없는 이유가 궁금함
            꽤 큰 뉴스라고 생각함
          + 특히 최근 OpenAI가 최고의 오픈 소스 모델을 출시한다고 예고한 점에서 타이밍이 맞아떨어진다는 생각이 듦
          + GPT-4 이후로 OpenAI의 모든 모델이 시장 흐름에 한참 뒤처지고 있다고 느낌
     * LLM의 ""안전성 테스트"" 언급이 마케팅용 문구라고 생각함
       자동차, 비행기, 엘리베이터는 진짜 안전성 테스트를 하지만 LLM은 다름
       LLM이 만든 결과물이 제작자 맘에 안 들어도 누가 죽는 건 아님
       이들이 말하는 ""안전성 테스트""란 결국 LLM이 자신들이 싫어하는 말을 어디까지 하는지 체크하는 것에 불과함
          + LLM이 누군가에게 상호작용이 나쁜 약을 먹으라고 쉽게 안내할 수 있음
            정신 건강 위기를 자살로 몰기도 하고, 극단적으로 특정 인종이나 집단을 문제의 원인이라며 제거해야 한다는 주장을 설득력 있게 펼칠 수도 있음
            말은 사람을 직접 죽이지 못하지만 분명히 죽음으로 이끄는 경우가 생김
            이런 가능성 외에도 도구 사용과 관련한 위험성도 존재함
          + 이 문맥에서 ""안전성""이란 결국 누군가를 불쾌하게 하거나 PR 이슈가 될 만한 발언을 막는 걸 의미할 때가 많음
          + 나도 마케팅이라고 생각하긴 하는데, 이유는 오히려 반대임
            지금 기술 수준에서는 진정으로 안전하게 만드는 게 불가능하다고 봄
          + 이건 사용자보다 LLM 제공 업체의 안전을 위한 것임
     * 내 취미는 냉소를 돈으로 바꾸는 것임
       Polymarket에 들어가서 사회와 기술에 대해 나를 기쁘고 낙관적으로 만드는 이벤트를 찾아, 그 일이 일어나지 않을 것에 소액(잡코인)으로 베팅함
       예를 들어 OpenAI가 9월 이전에 오픈소스 가중치 모델을 출시하느냐에 대한 베팅이 있는데 지금은 81%에 거래 중임
       지난달엔 OpenAI도 공개하지 않았고, 휴전도 진짜 휴전이 아니었으며, 기후 지표도 악화되어서 10달러 정도 벌었음
       존재의 절망을 완전히 헤지할 순 없지만, 그 고통을 조금 줄일 수 있음
          + 내기를 하면 무조건 이기는 구조임
            내가 이기면 돈을 벌고(이득), 지면 사회에 좋은 일이 생긴 것(이득)
          + 내 친구도 이걸 ""인류 헤지하기""라고 부름
            정치적으로 우울한 일이 있을 때마다 몇백 달러씩 벌었음
          + 크립토 화폐를 아직 쓰는 사람이 있다는 사실에 놀람
            AI 붐 이후로 이미 크립토는 끝난 줄 알았음
          + ""도박은 중독성이 있으니 책임감 있게 해야 하고, 18세 이상만 가능함
            도움이 필요하면 도박상담센터나 의사와 상담하길 바람""
     * Deepseek 및 Qwen(Alibaba)을 미국 AI 기업들보다 더 믿음
       미국 AI 업계는 돈과 컴퓨트 자원을 먹어치우기만 한다는 인상이 강함
       수십억이 투입돼도 내세울 게 별로 없어 보임
       Deepseek은 단 5백만 달러로 개발됐고, 새로운 훈련 방식을 여러 개 선보였음
       게다가 모델과 코드를 모두 FLOSS로 공개함
       미국 회사들은 전부 닫힌 구조임
       미국 AI 회사들은 서로를 죽이려 드는 독수리처럼 보임
          + Deepseek 개발비 5백만 달러 관련해서 논란 많음
            잘못 이해된 건지, 의도적으로 잘못된 정보가 퍼진 건지 의견 분분함
            만약 악의가 없었다고 해도, 대형 모델을 훈련해 본 입장에서는 한 번의 훈련 비용만 보고 총비용을 논하는 게 무의미하다고 말하고 싶음
            실패한 실험들과 추가 훈련, 그 외 숱한 시도에 드는 비용도 상당함
            R2가 6개월이 지나도 나오지 않는 건 의미가 크다고 생각함
            가끔 멋진 결과가 나오기도 하지만, 실패에 드는 비용엔 아무도 주목하지 않음
          + 실제로 Google의 모델 중 대다수가 오픈소스임
            AI 업계에서 일하면서 구글 연구 논문들을 많이 읽어왔는데, 업계 발전에 큰 기여를 했고 상용 라이선스로 모델을 공개해 준 점에 감사함
          + 5백만 달러는 한 번의 GPU 훈련에 드는 시간 비용임
          + 미국 AI 회사들이 돈과 컴퓨트만 먹는다고 했는데, 사실 그들은 책도 정말 문자 그대로 먹음
          + 그 비용이 사실 GPU 값만 반영한 수치 아니었음?
     * 아마 결과가 오늘 발표된 K2 모델보다 못해서 그런 듯함
       제대로 된 엔지니어라면 ""안전성"" 때문이라고는 말하지 않을 것임
       ablation 같은 방법을 쓰면 사후 안전성 훈련도 무력화됨
          + 개인적으로 OpenAI가 공개할 오픈 가중치 모델이 K2보다 훨씬 작길 바람
            K2는 1조 파라미터에 다운로드 용량만 거의 1TB임
            내 노트북에서는 절대 못 돌림
            로컬 모델의 적당한 크기는 20B쯤이 최적이라 생각함
            Mistral Small 3.x나 Gemma 3 일부 모델들이 대표적임
            32GB 램 이하에서도 잘 돌아가고 성능 좋음
            OpenAI가 그 정도 사이즈로 하나 내놓기를 진심으로 바람
     * Llama 모델의 무검열 파인튜닝 사례에서 보듯, 안전성 제약은 쉽게 제거될 수 있음을 기억할 필요 있음
     * 실질적으로 아무런 쓸모 없는 보안 퍼포먼스(대외 시늉)에 불과함
       커뮤니티는 이미 보호장치를 다 쉽게 벗겨내는 방법을 오래전에 알아냈음
          + 이런 주장만 보면 ""Open""AI가 예전에 GPT2 XL을 ""너무 강력하다""며 출시 거부했던 게 바로 떠오름
     * ""이건 우리에게도 새로운 것""이라는 말은 해당 업체답지 않음
     * OpenAI가 왜 공개 가중치 모델을 공개하려고 하는지 genuinely 궁금함
"
"https://news.hada.io/topic?id=21901","당신의 "연봉 패키지"를 협상하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         당신의 ""연봉 패키지""를 협상하는 방법

     * 연봉 협상은 단 몇 분만 투자해도 경력 전체에 수억 원의 효과를 가져오는 중요한 과정
     * 많은 엔지니어와 직장인이 협상에 심리적 저항감을 느끼지만, 실제로 성공한 사례가 많음
     * 회사는 구직자와 전혀 다른 협상 프레임을 갖고 있으므로, 이에 맞춰 접근할 필요성이 있음
     * 협상 과정에서 숫자를 먼저 제시하지 말고, 상대방의 언어를 활용하여 설득하는 대화법이 핵심
     * 회사 입장은 추가 연봉이 전체 인건비에서 미미하므로, 협상 자체에 민감하지 않음을 이해할 필요가 있음
     * 연봉뿐 아니라 휴가, 근무 조건, 역할 등 다양한 보상 항목도 협상에 적극 활용할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

서론: 연봉 협상의 중요성과 심리적 장벽

     * 연봉 협상은 직장인의 커리어에서 가장 중요한 재정적 의사결정 중 하나이며, 단 몇 분의 대화로 장기적으로 큰 경제적 차이를 만듦
     * 엔지니어 등 전문가들은 연봉 협상을 비도덕적, 껄끄러운 일로 오해하지만, 실제로 부유하고 성공한 사람들은 항상 자연스럽게 협상함
     * 집 구매보다도 인생에서 실질적으로 더욱 큰 재정적 의사결정이 바로 연봉 협상임

회사와 후보자의 상이한 협상 관점

     * 회사는 직원의 연간 총 비용(급여, 세금, 복리후생 등)의 150~200%를 감안하기 때문에 몇 천 달러 차이에는 크게 신경 쓰지 않음
     * 실제로 연봉 협상 시, 회사의 담당자는 본인 예산을 집행할 뿐, 본인 돈을 쓴다고 생각하지 않음
     * 회사 내부적으로는 사원 수(headcount)로만 예산이 책정되어 단일 인원의 세부 급여 증감에는 무관심한 경우가 많음
     * 상대방이 속상해하거나 도덕적으로 비난하지 않을까 걱정할 필요 없음
     * 협상은 사업적 거래이며, 도로 제안이 받아들여지지 않는다고 해도 불이익이 남지 않음
     * 협상에 나서는 것은 윤리적 문제와 무관하며, 오히려 회사와의 건설적 상호작용임
     * 연봉 협상을 두려워하지 않고, 적극적으로 나서는 것이 커리어 발전에 필수적임

협상 시작 전: 준비와 마인드셋 전환

     * 연봉 협상은 이미 지원 단계부터 시작되며, 평소 업계 내에서 평판과 실적을 쌓는 것이 중요함
     * 지원자 입장에서 협상은 ‘네-만약(Yes-If)’ 단계, 즉 채용 결정권자가 조건만 맞으면 고용하겠다고 밝힌 시점에 시작하는 것이 바람직함
     * 회사는 한 명의 채용에 이미 많은 비용(시간, 생산성 등)을 투자했으므로, 최종 협상에서 작은 금액에 절대 쉽게 포기하지 않음
     * 협상을 시도한다고 해서 기존 제안이 나빠질 위험은 없으며, 오히려 더 좋은 조건을 얻을 확률이 높음
     * 모든 제안은 협상하는 것이 기본 정책이 돼야 하며, 이는 후보자의 시장 가치와도 연관됨
     * 사전 협상 없이는 보상 논의에 들어가면 안 됨
     * 이메일 등 서면을 통한 협상은 준비 시간 확보, 심리적 부담 감소 등 여러 가지 이점이 있음

협상 전술: 숫자를 먼저 제시하지 말 것

     * 숫자를 먼저 말하지 않는 것이 협상에서 매우 중요한 원칙임
     * 회사가 이전 연봉, 희망 연봉 등 숫자를 요구할 때는 협상력 약화를 노리는 전형적 전략임
          + ""우리가 상호 적합한지 알아보는 게 우선이다"" 혹은 ""총 보상 패키지가 궁금하다"" 등으로 자연스럽게 피하는 것이 좋음
     * 숫자를 먼저 말하면 역량에 대한 평가 자체가 흔들릴 수 있음—회사 입장에서는 협상에 능숙하지 못한 지원자로 인식됨
     * 숫자를 반드시 넣어야 한다면 기존 보상 패키지의 5~10% 인상을 임시 기입하고 재논의 약속

상대방 언어로 대화하기, 공감 및 반복 기술

     * 협상은 힘겨루기가 아니라 상대의 언어와 관심사로 설득하는 과정임
     * 회사가 사용한 키워드, 가치, 고민 등은 대화에서 그대로 인용하여 신뢰와 공감을 높임
     * 면접·협상 과정에서 노트 필기를 적극적으로 활용하고, 중요 포인트(숫자, 조건, 상대의 관심사 등)를 기록함
     * 협상 후에는 핵심 합의 내용이 명확히 적힌 공식 오퍼 레터(Offer Letter) 를 반드시 받고, 이메일로 재확인하는 습관도 중요함

시장 조사 및 정보 수집

     * 협상 전 직무·업계·지역별 연봉 범위를 사전에 충분히 조사해야 함
     * 사전에 LinkedIn, Facebook, 전·현직 직원 인터뷰 등을 통해 지원할 회사의 연봉, 직급 체계, 조직 문화, 인사제도 등에 대한 생생한 정보를 확보
     * 회사마다 실질적인 진급 방식이나 연봉 인상 기준, 직무별 선호도 등이 다르므로 구체적으로 체크
     * 조직 내에서 높은 가치를 인정받는 역할·직군, 보상 방안(예: 옵션, 성과급 등)도 파악
     * 회사 내 인사 구조(레벨, 승진 기준 등)와 실제 승진/보상 패턴도 미리 파악하여, 협상에서 유리한 조건을 이끌 수 있음
     * 직접 회사 동료, 전직자, 업계 관계자에게 비공식적으로 정보를 묻는 것이 현실적으로 큰 도움이 됨
     * 사전 정보 확보를 통해 협상에서 다양한 대안과 우위 포인트를 구성

협상 포인트 다각화: 연봉 외 다양한 조건 활용

     * 연봉 이외에도 휴가, 근무지, 프로젝트 배치, 교육 기회, 복지 등 여러 보상 항목을 테이블에 올릴 수 있음
     * 만약 연봉 인상에 한계가 있다면, ""휴가 일수를 늘려주면 연봉 조건에 합의할 수 있다"" 등 다른 항목과 연계 협상이 효과적임
     * 협상에서 상대가 ""권한이 없다"" 등 외부 결정권자를 언급하면, 공감 표현 후, 실제 담당자가 결정 가능한 항목에 집중하여 조건을 더 끌어내는 전략이 유용함

협상에서 새 정보의 가치 활용

     * 협상에서 새로운 정보(본인이 제공 가능한 구체적 가치, 사례, 성과 등) 를 내세우면 회사 입장에서 신규 가치로 인식되어 원하는 조건을 더 쉽게 받을 수 있음
          + 예: ""이전 회사에서 매출 3% 증가를 이끌었다. 이 자리에서도 1%만 더해도 수백만 달러 가치가 있다"" 등 구체적 수치·성과 중심 설득이 효과적임
     * 협상은 일방적인 가격 다툼이 아니라 상호 가치를 만드는 과정임을 인식
     * 상대방의 요구와 고민에 정확히 부합하는 새로운 가치를 제시하면 협상력이 높아짐
     * 구체적인 수치, 연구 결과, 이전 성과 등을 근거로 제시하면 추가 연봉이나 보너스 협상에 유리함
     * 회사 입장에서는 여러 차례 들은 내용도 협상 과정에서는 새롭게 인식할 수 있으므로, 반복해서 강조하는 것이 중요함

요약 및 추가 참고 자료

     * 연봉 협상은 심리적 장벽만 극복하면 단 몇 분으로 커리어와 재정에 막대한 차이를 가져옴
          + 엔지니어 및 직장인 경력에 있어 최대의 레버리지 포인트
     * 부정적 심리나 부끄러움, 도덕적 부담을 버리고 철저하게 체계적·전략적으로 준비해야 현실적인 보상을 누릴 수 있음
     * 숫자를 먼저 말하지 않고, 시장 정보와 상대의 언어를 적극적으로 활용하는 것이 핵심임
     * 연봉뿐 아니라 다양한 근무 조건도 협상 카드로 활용하는 다차원적 접근이 유리함
     * 추가 참고, Hacker News의 tptacek negotiation 관련 글이나 Fearless Salary Negotiation 책

   요약만 봤을땐 협상 대상자가 아니고 담당자인가 보네요. 하나도 와닿지 않은 이야기들만 잔뜩..

   한국 회사엔 적용안될듯

   현실 탓하며 '어차피 안된다'는 패배주의에 갇히면 아무것도 바뀌지 않습니다. 글에서 얻어갈 점 하나라도 찾아 시도하는 것이 자신의 가치를 높이는 길입니다.

   연봉협상전에 보기

   연봉통보 빔~~~!

        Hacker News 의견

     * 나는 평범한 제품 디자이너임에도 불구하고 patio11의 조언을 수년간 실천해왔고, 내 인생에 엄청난 변화를 가져왔음. 몇 년 쉬었다가 최근 다시 취업 시장에 복귀했을 때, 여기서 다들 불황 이야기만 하길래 불안했지만 실제론 생각보다 시장이 크게 변하지 않았음. 경쟁은 좀 더 심해졌지만 여전히 기회는 많음. 다른 이들이 실패담만 이야기한다고 주저할 필요 없음. patio11의 블로그 덕분에 경력 동안 100만 달러 이상을 더 벌 수 있었음. 나는 특별한 천재가 아니라, 그저 팀에서 필요로 할 정도의 실력을 가진 것뿐임. 만약 내가 그 기준에 못 미쳤다면 그걸 먼저 노력해야 함. 하지만 대부분의 오퍼에서 20~50% 보상 증가를 얻는 것은, 회사가 어떤 가치를 원하는지 이해하고 이를 제대로 전달할 수 있으면, 충분히 실현 가능한 일임. 다들 시도조차 하지 말라는
       부정적인 얘기에 너무 좌절하지 말고, 적어도 꼭 시도는 필요함
          + 시장이 살짝 더 어려워졌다는 주장은, 개인의 주관적인 경험만으로 전체 시장을 평가한다고 느껴져서 다른 사람들에겐 오히려 위축감을 줄 수 있다고 생각함. 최근 1년간 구직이 어려워졌다는 사람들도 많고, 본인의 역할·이력·네트워크·운·영업 능력 등 각자 처한 상황이 많이 다를 수 있음을 인정해야 함
          + 나는 고용주 입장에서 이 글에 감사함을 표하고 싶음. 지원자들이 patio11의 조언이나 유사한 협상법을 적용하는 모습을 자주 목격함. 이 방식이 항상 통하는 건 아니지만, 예의를 지키면 최소한 손해는 없으며 실제로 자주 효과가 있음. 사람들이 지나친 냉소로 시도를 포기하지 말고 직접 이 블로그 글을 꼭 읽어봤으면 함
          + 20년 이상 경력이 있지만 올해 한 번도 인터뷰를 못 해봄. 나도 내 일에 자신이 있는데, 결국 내 상황만 다른 건가 싶음. 아무튼 언젠가 실제 담당자가 나와 대화를 해준다면 꼭 시도해 볼 생각임
          + 미국 외 다른 나라에서도 이 방식이 효과가 있을지 궁금함. 미국보다 시장이 열악한 곳에선 높은 연봉 자체가 없는 느낌임. 미국의 신입 엔지니어가 다른 나라 20년 차 CEO보다 더 많이 벌기도 함. 1만 달러 협상은 가능하겠지만, 10년간 수백만 달러를 더 버는 건 불가능하다고 느껴짐
          + 20~50% 보상 인상은 한 번뿐만 아니라, Patrick의 글처럼 경력 전환 때마다 누적되기 때문에 장기적으로 엄청난 자산이 됨
     * 나는 은행에서 외화 환전을 자주 함. 게시된 환율이 있지만, 직원에게 “프리미엄 환율로 해줄 수 있나요?” 라고 요청하면 대개 1% 정도 더 유리한 조건을 제시해줌. 이 과정은 은행원이 임의로 결정하는 것이 아니라 정해진 프로세스(플로우차트)를 따라가는 것임. 대기업의 많은 채용도 이와 비슷해서, 협상 여지가 있는 경로를 밟을 수도 있지만, 실질적으로 큰 협상은 아닐 때가 많음. 간혹 실제 결정권자가 내부에서 나를 위해 밀어줄 수 있으면 상황을 바꿀 수도 있지만, 리크루터나 인사 담당자와 대화하는 건 거의 은행 창구 직원과 이야기하는 것과 비슷함
          + 내 은행에는 트레이딩 데스크가 따로 있고, 이 정보와 연락처는 웹사이트에 거의 공개되어 있지 않음. 나에게만 따로 번호를 줬고, 2만 유로 이상의 환전이 필요할 때에는 그쪽으로 바로 전화하면 됨. 10만 유로 이상일 때는 환율이 거의 시장 중간가에 가까움. 전화하면 대기음도 없고, 트레이더가 바로 받아서 1분도 안 되어 거래 완료고 계좌에 돈이 들어옴
          + 결국 플로우차트를 타더라도 협상 옵션을 시도하는 것이 낫다고 생각함
          + 결국 핵심은 실제로 조건을 바꿀 수 있는 실질적 권한자가 누군지를 파악하는 것임
     * 이 글이 처음 나왔을 때와 달라진 점은, 요즘 회사들이 사람을 예전처럼 급하게 뽑지 않는다는 것임. 이 때문에 글에 나오는 많은 협상법이 잘 통하지 않게 됨. 회사는 사람 채용에 들어가는 비용을 크게 신경 쓰지 않기도 하고, 채용 위원회가 지원자에게 정말 흥미를 가져야만 오퍼가 나옴
          + 회사가 지원자 채용에 정말 흥분하고 있다면, 협상에 있어서도 더 유리한 위치가 되지 않을지 의문임
     * 내 경력에서 연봉 인상에 가장 크게 기여한 것은, (특히 금융 쪽에선) 리크루터와 좋은 관계를 구축한 것임. 네트워크가 좋은 리크루터는 반복적으로 나를 좋은 곳에 연결해줄 동기부여가 크고, 내가 좋은 직원임을 안다면 각 포지션 상황을 알려줘서 안전하게 협상하게 도와줌. 그리고 리크루터/포지션 설명에서 “자기개발 기회가 많음” 같은 표현이 실제로는 “시니어가 퇴사해서 주니어로 급히 대체 중”이라는 뜻이란 것도 배우게 됨
     * Patrick의 “연봉 협상” 글은 자주 언급되는데, 실제로 Patrick 같은 업계 유명인사나 엄청나게 구하는 인재가 아닌 일반 직원들에게도 효과가 있을지 의문임. 내 25년 경력을 돌이켜봐도 실질적으로 큰 연봉 협상 성공 경험이 없음. 회사 측은 항상 “오퍼는 $X이며, 적합한 수준임. 원하면 진행, 아니면 뒤에 줄 선 20명의 후보자 중 누군가에게 넘어감” 같은 비슷한 반응임. 협상이라기보단 그냥 선택하라는 분위기였음. 그래서 결과가 달랐던 사람들에게 솔직히 부럽기도 함
          + BATNA(협상에서의 대안)가 확실하지 않다면 단지 요구만으로는 원하는 결과를 얻기 어려움. 예를 들어, “다른 회사에서 더 높은 제안을 받았고 가족을 생각해서라도 그 조건이 맞으면 꼭 합류하겠지만, 지금 오퍼가 확정적이라면 아쉽지만 거절하겠다”는 현실적인 대안이 있을 때 훨씬 효과적임. 회사가 정말 특정 인재를 원하면 더 움직여주지만, 단순히 자리를 채울 사람만 찾는 상황이면 잘 변하지 않음
          + 고용주 입장에서 보면, patio11 가이드대로 협상을 진행하는 지원자 패턴은 금방 눈에 들어옴. 초기에는 최대치에 가까운 오퍼를 바로 줬는데, 지원자들이 인터넷 협상 가이드대로 무조건 추가 인상을 요구하는 경우가 많았음. $5,000 정도의 인상 때문에 훌륭한 오퍼를 걷어차겠다는 사람들도 있었음. 그래서 전략을 전환해, 협상 전엔 마지막 여분을 남겨두고, 협상 때 올려주는 방식으로 대응하게 됨. 만약 지원자가 협상을 안 하면 깜짝 보너스처럼 그 여분을 나중에 제공함. 효과는 있지만 이제는 누가 협상을 시도할지 대략 예측이 가능해짐
          + 이 주장은 사실이 아니라고 단언할 수 있음. 유명인만 연봉을 크게 올릴 수 있다는 생각은 실제로 많은 사람의 수입을 깎는 원인이 됨. 연봉은 유명세보다 협상력에 더 크게 달려있음. 세상에 알려지지 않은 최고 연봉 개발자들도 많고, 오히려 유명인은 이상한 조건으로 대우받는 경우도 보았음. Patrick의 조언이 맞음
          + patio11 글의 핵심 중 하나는 협상에는 실질적 손해가 거의 없다는 것임. “어차피 안 될 것 같으니 시도조차 하지 말라”고 말하는 것은 의미 없다고 생각함. 나는 예전에 협상으로 큰 인상을 받아낸 적이 있고, 그 이유 덕분에 상사가 나한테 인상을 줄 명분을 만들 수 있었음. 협상은 실제로 통하는 경우가 많고, 본인에게 남는 게 크고, 당장의 불편함 말고는 잃을 것이 없음
          + 나는 실제로 협상 조언을 적용한 사람들로부터 감사 편지를 여러 통 받아왔음. 이 중에는 입지가 엄청난 업계 유명인사들이 거의 없었음. 내 경험상 수백 명이 넘게 조언을 적용해 연봉을 올렸고 그 숫자를 직접 보고 있음
     * 연봉 협상 이야기가 게시판에 나오면, 자격지심 있는 사람, 허세 부리는 사람, 대놓고 드러내는 외향적인 사람, 실질적인 조언이 필요한 주니어 등이 뒤섞여 걱정이 됨. 온라인 협상법은 본인이 실제로 시도하기로 결심한 상태를 전제로 쓰여짐. 만약 스스로 “나는 평범해서 안 통할 것 같다”고 생각하고 있다면, 이미 스스로 기회를 포기한 것임. 본인이 탁자 위에 있는 오퍼에 대해 “괜찮지만 더 나아질 수 있다”고 확신할 때 다시 이 문제로 돌아와야 함. 누가 대신 결정을 해줄 수 있는 게 아니고, 스스로 선택해야 하는 문제임. 협상을 하지 않으면 그만큼 돈을 놓치겠지만, 그 차이가 생계의 사활이 걸릴 정도는 아닐 것임. 만약 그렇다면 포지션을 잘못 찾는 것일 수도 있음. 요약하자면, “나에겐 안 통할 것 같다”라고 스스로 생각한다면 정말로 그럴
       것임
     * 나는 그냥 처음에 대놓고 터무니없는 금액을 요구함. 왜냐면 어차피 손해 볼 게 없기 때문임
          + 대부분의 채용 담당자와 인사 담당자들은 이런 과도한 요구를 무례하게 느끼고, “이 지원자와 게임을 계속해야 하나”로 고민하게 만들 수 있음
          + 나는 리크루터와 이야기할 때는 처음에 금액을 말하지 않는 편임. “연봉이 채용의 유일한 판단 기준은 아니며, 역할과 전체 패키지가 내겐 중요하다. 회사 제안은 경쟁력이 있을 걸로 기대한다”고 정중하게 말함. 범위를 꼭 적어야 하는 경우엔 $1.00으로 씀
     * 인생의 많은 일처럼, 준비가 이미 절반을 좌우함. 대안 오퍼가 있다든가, 커리어 관리나 면접을 잘 보는 것 등이 결국 연봉을 키워줌
     * Patrick은 “10년이 지난 지금도 글의 내용을 바꿔야 할 이유가 없으며, 단어 하나도 바꾸지 않을 것”이라고 언급함. 아마도 수중에 모아둔 여유 자금이 있어서 최근에는 직접 취업 활동을 하지 않아도 되었기 때문임
          + Patrick은 단순히 조금이 아니라 꽤 자산이 있는 걸로 보이고, 엔젤 투자자이기도 함. 참고: complexsystemspodcast 소개 페이지
     * 15년 전 엔지니어들에게는 정말 좋은 시절이었음
          + 지금도 여전히 괜찮은 편임. 단, 문턱을 넘기(첫 입사를 하거나 이직에서 첫 오퍼를 받기)는 지금이 5~6년 전 또는 2008~2009년 금융 위기 때처럼 더 어려워졌음. 하지만 시장상황과 별개로, OP 블로그가 말하는 가치 비대칭의 원칙은 변함이 없음
          + 미국 엔지니어의 연봉은 15년 전보다 훨씬 높아졌다고 생각함. 2010년 즈음에는 Google, Apple 등이 서로 인재를 빼가지 않기로 담합하여 연봉 인상을 막았던 사건이 유명함. Facebook이 이 담합에서 예외였던 것이 연봉 상승을 촉진함. 최근 몇 년간은 스톡옵션 가치가 급등하면서 실현 보상도 같이 오르자, 이를 유지하기 위해 이직하는 사람이 늘었고, 이는 엔지니어 연봉이 계속 높게 유지된 이유임. 참고: 하이테크 반독점 소송 위키피디아
"
"https://news.hada.io/topic?id=21906","X CEO 린다 야카리노, X에서 퇴사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         X CEO 린다 야카리노, X에서 퇴사

     * X의 CEO 린다 야카리노가 2년 만에 사임을 공식 발표함
     * 야카리노는 엘론 머스크의 초청으로 X(구 트위터) 경영을 맡았으며, 플랫폼 변화와 광고주 이탈 등 여러 도전에 직면함
     * 그녀의 퇴임 배경에 대한 구체적 설명은 밝히지 않음
     * X는 2022년 머스크가 인수한 뒤 대대적인 구조조정과 정책 변화, 그리고 xAI로의 피인수 등 격변을 겪음
     * 임기 중 주요 광고주 96%가 복귀하는 등 광고 매출 회복을 위해 노력했음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

X CEO 린다 야카리노, 2년 만에 사임

     * X(구 트위터)의 CEO 린다 야카리노가 엘론 머스크와의 협업 2년 만에 플랫폼을 떠난다고 공식 발표함
     * 야카리노는 X를 ""일생일대의 기회""라고 표현하며, 머스크의 신뢰에 대해 감사 인사를 전함
     * 퇴임 사유에 대해서는 명확히 밝히지 않음

머스크 인수 이후의 X 변화

     * 2022년 엘론 머스크가 X(당시 트위터)를 440억 달러에 인수한 이후, 플랫폼은 머스크의 색채로 빠르게 재구성됨
     * 전체 직원의 75% 이상을 감원하고, 콘텐츠 규제 완화, X를 통한 정치적 메시지 발신 등 여러 정책 변화가 이루어짐
     * 광고주들이 이러한 변화에 우려를 표하며 광고 매출이 급감하는 상황을 겪음

xAI로의 피인수 및 기업 구조 변화

     * 2025년 3월, 머스크는 X를 자신의 AI 스타트업인 xAI에 전량 주식 교환 방식으로 매각했다고 발표함
     * 이 거래는 xAI의 기업가치를 800억 달러, X의 가치를 330억 달러로 평가함
     * 이후 xAI는 1,200억 달러까지 기업가치가 오를 가능성이 있다고 전해짐

야카리노의 역할과 도전

     * 머스크는 야카리노를 2023년 5월에 영입하며 광고주 및 비즈니스 관계 복원을 주 임무로 맡김
     * 야카리노는 NBCUniversal 시절부터 머스크와 긴밀히 소통하며, X(트위터) 광고 집행을 유지해온 인물임
     * 취임 직후 머스크의 갑작스러운 정책 변경, 유해 콘텐츠 허용, 플랫폼 브랜드 변경(X로의 리브랜딩) 등으로 사용자·광고주 이탈이 심화됨
     * 야카리노는 대외적으로 낙관적 메시지를 전달하며 광고주 복귀와 실적 회복에 매진함

광고주 복귀 및 임기 중 성과

     * 2024년 미국 대선에서 트럼프가 승리한 이후, 일부 광고주가 머스크와의 친밀함을 이유로 X로 다시 돌아옴
     * 야카리노는 임기 중 상위 광고주 96%가 플랫폼에 복귀했다고 밝힘
     * 하지만 머스크의 돌발적 발언, 외국 정부와의 마찰 등으로 지속적인 긴장과 도전이 동반됨

요약

     * 야카리노의 사임은 머스크 인수 이후 X의 끊임없는 변화와, 광고주 및 사용자와의 복잡한 관계, 경영 안정화의 어려움 등 복합적 환경에서 비롯된 것임
     * 머스크 체제 하의 X(구 트위터)는 앞으로도 인재 이탈과 혁신 시도가 계속될 전망임

        Hacker News 의견

     * 아카이브 링크 공유함
     * The Economist는 언제나 기발한 기사 타이틀을 내놓음. 이번에는 ""Linda Yaccarino goes from X CEO to ex-CEO""라는 말장난이 인상적임. 관련 기사 링크도 참고할 만함
     * Linda Yaccarino가 공개적으로 발언할 기회를 가졌던 적이 있었는데, 그 결과가 처참했음. 실제로 의사결정권도 없었고, 희생양 역할조차 제대로 하지 못했음이 명확하게 드러났음. 그녀의 재임 기간 동안 X의 기업가치가 80%나 감소했고, 심지어 광고주를 광고하지 않았다고 고소하는 등 허술한 운영을 보여줬음
          + 그녀가 실질적인 권한이 없었다고 하면서도, 동시에 기업가치 하락과 소송 책임을 그녀에게 묻는 건 모순처럼 느껴짐. 어쨌든 그녀가 공개적으로 휘둘리는 꼭두각시 역할에 자원한 것이고, 그 오점이 평생 남을 것임
          + 나는 그녀가 희생양 역할을 했다기보다는, Elon이 ""트위터 CEO를 바꿔야 하나"" 투표를 진행하고 결과가 맘에 들지 않게 나오자 어쩔 수 없이 CEO급 급여를 주게 된 일종의 쇼처럼 보였음
          + 그녀가 실질적으로 많은 광고주를 다시 불러들이고, 일정 수준의 신뢰성을 얻는 데 기여한 면도 있음
          + 트위터의 기업가치 하락은 두 가지 주된 이유 때문임. 첫째, Elon이 인수 제안할 때와 Reddit 매각 수락 사이에 전체 테크 기업가치가 50~80% 가량 폭락했음. 둘째, Elon이 브랜드 광고주를 대놓고 멀어지게 해서 직접 반응 광고가 별로 효과 없는 플랫폼 특성을 더욱 악화시켰음
          + ""기업가치 80% 하락과 광고주 소송은 이미 그녀가 합류하기 전에 시작된 일이었음. 공개 발언이 모두 실패라고 했는데, 실제로는 다수의 공식 발언을 해왔음. 구체적으로 어떤 사건을 뜻하는지 알려줄 수 있겠는지 궁금함. 예측불가한 CEO가 무대에서 광고주를 향해서 욕설을 퍼붓는 걸 수습하는 게 결코 쉬운 일이 아님
     * 이 소식을 보자마자 첫 머리에 떠오른 건, 첫 몇 주 후 예상했던 것보다 1년 11개월이나 더 버텼다는 점임. 트위터에 문제점이 많긴 했지만, 이전엔 모두가 모여서 같은 대화에 참여하는 감각—다른 플랫폼에는 없는 그런 세계의 소리—를 제공하던 시절이 그리움
          + ""모두가 여기에 있다""는 표현을 조금 더 구체적으로 설명해 줄 수 있는지 궁금함. 트위터는 twitterfiles 이전까지만 해도 기업 분위기가 너무 강했다고 느낌. 이후엔 아예 색다른 커뮤니티로 바뀌었고, 주류나 진보 성향 글쓴이들은 랭크가 떨어지거나 아예 다른 곳으로 옮겨감. 사실상 2009년 이후 트위터는 '날것 그대로의 대등한 대화' 같지 않았음
          + 나 역시 Elon이 트위터에 한 짓을 싫어하지만, 예전 모두가 다 있다는 착각조차 대대적인 선전과 대화 조작에서 비롯된 환상임을 깨달음. Reddit도 지금은 비슷하게 소수의 관점만 용납되는 폐쇄적 체계로 변했고, 내부자들은 자유를 느끼겠지만 외부자 눈에는 자유로운 대화가 아닌 리버럴 에코 챔버 그 이상 그 이하도 아닌 모양임. 실제로 비트코인 트위터 핸들을 운영하던 진짜 소유자가 Jack Dorsey 의도에 따라 움직이지 않자 그 계정을 블록스트림 쪽 인사에게 넘겨준 일도 있었음. 다수의 이용자들은 자유의 승리라 여길지 몰라도, 사실상 점점 더 많은 말을 통제하면서 반대자는 내쫓는 구조임
     * 나도 그녀가 받은 만큼의 보수를 받는 조건이면 흔쾌히 CEO 흉내를 내겠음. 모든 비난을 다 떠안고 하와이에서 은퇴해도 충분함
          + 아마 내부 이야기로 책을 쓰면, 보수 외에도 추가 수입을 챙길 수 있을 거라 생각함
          + 하와이보다 더 저렴한 은퇴처도 있으니 그 편이 더 오래 쉴 수 있을 듯함. 그래도 아이디어 자체는 좋음
     * X는 브랜드 파괴의 연속이었음. 그럼에도 불구하고 여전히 살아있고, 아직도 어느 정도의 영향력은 유지 중임
          + Musk가 트위터 인수를 꽤 성공적으로 마친 것 같다는 생각이 점점 듦. X 브랜드가 트위터만큼 강하진 않지만, 기자와 정치인 등 플랫폼에 핵심적인 인물들은 여전히 남아 있음. 트위터 인수 가격이 지나치게 높았던 건 사실이지만, 정치적 도구로 사용할 생각이라면 그리 크게 상관없을 수 있음. 해고 사태 역시 문제 없이 넘어갔고, 사실 불필요하게 인력이 많았던 셈임
          + 사람들은 플랫폼을 떠나기 매우 힘들다는 걸 보여주는 사례임. 네트워크 효과를 극복하긴 정말 어려움
          + 한동안 fintwit을 집중적으로 팔로우했는데, 이미 여러 계정이 Bluesky로 이주했음. 가끔 nitter로 확인해보면, 이제 답글의 90%가 스팸임. 완전한 붕괴까지는 시간이 걸릴 수 있지만, 그 방향으로 가고 있음이 확실함
          + Tesla도 비슷한 운명을 더 거대한 규모로 맞이할 거라는 생각임. 결국 클수록 더 크게 무너지는 법임
          + 트위터 브랜드는 Elon 인수 전에도 이미 훼손되어 있음. 결국 브랜드 파괴는 이미 진행형임. 하지만 수익만 낸다면 브랜드가 어떻든 의미 없다고 봄. Elon이 X를 흑자로 돌렸다면, 트위터 때보다 성공적이었다고 할 수 있음
     * 뉴욕타임즈 기프트 링크 공유함
          + 오늘 처음으로 NYTimes 기사를 '기프트'로 공유할 수 있다는 걸 알게 됨. 신기함. 답례로 아카이브 링크도 같이 제공함
     * 소유구조와 이사회를 고려할 때 SEC 문서 참고, 트위터 CEO는 어디까지나 명목상 자리임
     * 아무도 Nikita를 언급하지 않은 게 흥미로움. X는 최근 Gas와 tbh로 유명한 Nikita Bier를 제품 총괄로 영입했음. Nikita 공식 계정 확인 가능함. 오늘 이 일과 연관이 있을 수도 있는 밈도 올렸음
     * “그에게 정말 감사하다”는 문구가 있지만, 실제로는 뜻있는 결정 대부분에 그녀가 관여조차 못 했음
          + 퇴직 시 회사에 비난을 남기면 규정상 문제 생길 수 있음. 심지어 계약상 비방 금지 조항이 있을 수도 있음
          + ‘감사한다’는 표현 대신 ‘돈을 받았다’ 정도로 대체하면 충분함
"
"https://news.hada.io/topic?id=21850","AI를 원치 않는 대중에게 강제로 떠먹이는 현상","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       AI를 원치 않는 대중에게 강제로 떠먹이는 현상

     * AI 기능이 대중의 동의 없이 주요 소프트웨어와 서비스에 자동으로 포함되고 있음
     * 대부분의 사용자는 AI를 원하지 않거나 불신하지만, MS·구글 등 대형 IT 기업은 번들·강제 도입 방식으로 AI 도입을 가속화함
     * 소비자가 선택권 없이 비용까지 부담하게 만들고, 실제로 AI 기능이 추가된 제품일수록 선호도와 신뢰도가 하락하는 조사 결과가 있음
     * 기업들은 AI 관련 비용 및 적자를 숨기기 위해 기존 서비스에 묶어 회계상 손실을 감춤
     * 법적, 제도적 규제(투명성·옵트인·책임·지식재산권 등) 필요성을 강조하며, AI 남용에 대한 사회적 대응을 촉구함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

AI를 원치 않는 대중에게 강제로 떠먹이는 현상

     * 최근 Microsoft Outlook을 열자, Copilot AI 동반자를 사용하라는 권유 메시지가 나타남
     * AI 동반자(Companion) 라는 이름이 붙었지만, 실제로는 원치 않는 기능임
     * 수신자 역시 직접 쓴 이메일을 기대하지, AI가 작성한 메시지를 원하지 않음
     * Copilot 비활성화를 어렵게 만들어두었고, 겨우 끄는 방법을 찾았지만 곧 Excel 등 다른 프로그램에서도 AI 이용 약관 동의를 강제로 요구함
     * MS 365 구독 요금도 월 $3 인상되어, 원하지 않는 Copilot 기능 60회가 번들로 포함됨
     * 실제로는 사용하지 않아도, 비용을 납부하며 AI 기능이 Word, Excel 등 모든 소프트웨어에 내장됨

  AI 번들링과 강제 사용의 경제적/전략적 이유

     * AI는 대부분의 사용자가 자발적으로 돈을 내지 않음(미국인 8%만 추가 지불 의향)
     * 그래서 필수 서비스와 번들로 묶어 강제 도입해야만 시장에 안착 가능
     * AI가 독립 유료 상품이었다면, 손실이 명확히 드러나고 투자자와 주주들의 불만이 폭증했을 것임
     * 기존 서비스에 AI를 숨겨 회계상의 손실을 감추고, 겉으론 수익성이 있는 것처럼 포장함
     * 예시로, 식당에서 그라나이트 돌을 디저트로 판다면 아무도 사지 않지만, 전체 식사 가격에 1달러 추가해 모두에게 강제로 제공하면 “모든 고객이 돌을 구매한다”고 주장할 수 있음

  사용자의 선택권 상실과 불만

     * 실제로 사용자는 AI 도입 여부에 대한 선택권이 없음
     * MS뿐만 아니라, Google도 검색 결과에 AI를 자동 삽입
     * 플랫폼들은 사용자 동의 없이 일방적으로 AI 기능을 추가하고, 고객은 “입 다물고 받아들이라”는 식의 태도를 경험
     * 다음과 같은 AI 기능 모두, 사용자의 의사와 무관하게 강제로 적용되고 있음
          + AI 고객센터, AI 검색 결과, 소프트웨어 내장 AI, AI가 보내는 이메일, Spotify AI 음악, Amazon AI 도서 등
     * AI 기능이 추가될수록 제품 선호도가 오히려 하락(4000명 조사, AI 선호 18%에 불과)
     * 전문가와 미디어도 AI 과속 도입이 고객 신뢰·매출을 저해할 수 있음을 경고

  빅테크의 더 적극적인 AI 강제화 움직임

     * 과거에는 고객 의견에 민감하게 대응했으나, 이제 빅테크가 독점적 영향력 행사
     * 사용자의 의사나 선택권은 완전히 배제되고, 일방적 기능 추가가 지속됨
     * Meta(페이스북)는 사용자가 원하지 않아도, AI 챗봇이 먼저 메시지를 보내는 기능까지 준비 중임(메신저 완전 비활성화도 사실상 불가)
     * 이런 방식은 전형적인 스팸에 가깝고, 사용자 거부감이 커지고 있음

  AI 보이콧이 불가능한 현실

     * AI 도입을 거부하고 싶어도, 실제로는 이메일, 검색, 워드·엑셀, 아마존·스포티파이 등 필수 서비스 전체를 포기해야 함
     * 앞으로는 의료, 상담, 법률, 채용, 긴급 구조 등 사회 기반 서비스마저 AI 중심으로 대체될 전망임
     * 대형 IT 기업들은 이미 사용자의 동의·선택과 무관하게 신속하게 인적 서비스의 흔적을 지우고 있음

  신뢰할 수 없는 AI가 강제로 확산되는 모순

     * 놀라운 점은, 아직 AI가 충분히 신뢰할만하게 동작하지도 않는 단계임에도 이런 강제 도입이 가속화되고 있음
     * 실제로는, 엉뚱하고 부정확한 AI 응답이 많지만, 기업들은 제대로 고칠 생각도 하지 않음

  사회적·법적 대응 필요성

     * 투명성 법, 옵트인(사전 동의) 법, 책임법, 지식재산권 보호법 등 AI 도입 규제가 반드시 필요함
     * 만약 정치권이 대응하지 않는다면, 시민 발의나 집단 소송 등 사회적 행동이 필요함
     * 소비자(배심원)들도 결국은 자신이 강제로 AI를 떠먹이고 있다는 현실에 공감할 것

  미·중 경쟁 프레임에 대한 의문

     * 미국이 AI 도입 경쟁에서 중국을 앞서야 한다는 논리에 반대함
     * AI가 향하는 목적지(there)가 오히려 불행한 결과와 후회를 남길 것이라 확신하며, 먼 미래에나 그 결과를 지켜보길 원한다고 강조함

  결론

     * AI는 대중의 동의 없이 빅테크 주도로 일상과 사회 전반에 폭넓게 확산 중임
     * 사용자의 적극적 요구가 아닌 독점적 기업의 이익 추구와 시장 메커니즘 왜곡이 근본적 원인임
     * 선택권 없는 AI 도입은 향후 심화될 것이며, 이로 인한 사회적 후회 가능성이 큼

   AI 기능, 특히 백그라운드에서 대기하다가 도와주겠다는 서비스들이 정말 싫어요.
   원격에서 실행된다면 내 정보가 제공되는 문제, 로컬에서 실행된다면 내 컴퓨터의 자원(CPU, 메모리, 배터리, ...)을 소모하는 문제가 있으니까요.

   Private 원격 서버에 설치하는 식의 서비스는 어떨까요?

   한국어 번역에 개떡 같은 자동 번역 더럽게 넣더니 더 진화했군요. 자동 번역도 못 막았는데 개떡 같은 AI 더럽게 넣는 것도 다 맛보죠!

        Hacker News 의견

     * 나 역시 이런 AI 통합 기능이 짜증나고 불필요함을 느끼고, 그게 LLM이 쓸모없어서라기보다는 기존 제품들과의 연동이 깊게 고민되지 않았기 때문임, 대기업에서 트렌드를 좇으려 무작정 소프트웨어를 도입하는 모습과 유사함, 최근 petekoomen의 창의적인 지적처럼 ""AI 시대의 ""말 없는 마차"""" 현상이 재현되는 중임
          + 직접 제품에 무작정 AI를 넣으라는 강박에 사로잡힌 제품 오너들의 불안과 공포를 직접 목격함, 혼란스러운 환경 속에서 명확한 비전 없이 행동만 우선, 투자자 신뢰와 낙오 우려로 연출되는 쇼에 가까움, 임원들은 구체적 아이디어 없이 ‘그냥 AI’를 원할 뿐이고, 반대는 허용하지 않는 곳도 많음, 이 시기를 지나면 꽤 민망한 일이 될 사람도 많을 듯한 예감
          + 사내에서 이런 트렌드를 ""Clippification""이라고 부름, 클리피처럼 사용자 허락도 없이 엉뚱한 도움말이 튀어나오는 식, 원하지 않는 순간에 AI 챗봇 팝업이 연달아 등장하면 일에 방해만 됨, 마치 클리피 군단과 싸우는 심정
          + 나는 AI 열성 지지자로 코딩, 글쓰기, 의사결정 등에 AI를 적극적으로 활용하지만 비AI 기반 앱에 추가된 AI 기능은 대개 엉성한 덧붙이기식, 품질 낮은 모델로 원가만 절감한 느낌, 제대로 활용하고 싶으면 chatgtp/claude/gemini frontier 모델이 내 앱 데이터와 API에 제대로 억세스할 수 있어야 함
          + 기술 그 자체보다 더 심각한 문제는 바로 사람임, 문제를 부정하는 열성 지지자와 질 낮은 스타트업의 사기성 세일즈, AI 커뮤니티가 문제 제기자에게 적대적으로 반응해 오히려 기술에 대한 신뢰를 깎는 악순환, 이런 환경에서 협업을 원하는 사람은 많지 않을 것이라 생각
          + AI가 프로젝트에 제대로 접목되는 방식은 실제로 돈이 덜 되고 기업들이 원하는 ‘하이프’도 주지 못하는 미묘한 현실
     * Cursor와 Windsurf 같은 제품에서 LLM이 대규모로 보조금을 받는 구조를 관찰 중임, 이 도구들은 사실상 LLM을 위한 마케팅 도구 성격이며 투자자 구성을 보면 더 명확해짐, 이런 서비스는 운영 원가가 상당하여 빠른 대중 확산이 절실한 점을 생각하지 못했었는데, 과연 얼만큼 신속하게 흡수를 원하고 있는지 궁금증 생김
     * 주요 AI 게이트키퍼들이 이미 대형 모델 운영에 병목과 확장성 문제를 겪고 있는 상황, 근본적인 기술 혁신 없이는 상황 변하지 않을 전망, AI 중심으로 세상이 전환될수록 이들 게이트키퍼와 컴퓨팅 자원에 대한 의존도가 커지게 됨, 우선 접근권이나 자원 우선순위에 대한 요금 인상 가능성 우려, 아직 웨어러블 단계에 도달도 안 했음
       모든 사용자 데이터가 이들 게이트키퍼에게 전송되어야 하고, 클라우드로 데이터 이동이 늘고 있지만 예전에는 데이터 판독·재활용에 경제적 실익이 적어 내 지식정보-개인정보가 덜 노출됨, 그러나 강제적 AI 도입이 늘면서 이제 누가 모델을 돌리고, 내 데이터가 어디로 가는지 더 불투명해진 느낌, LLM 정확도 미흡 문제도 있지만 게이트키퍼와 데이터 집중 문제가 그만큼이나 우려됨, 편의성 때문에 질 저하를 대가로 저렴한 운영구조를 선택하게 되는 불안
          + 사무실에서는 프라이버시·정보보안 실험 차원에서 한 달 전부터 자체 LLM 서버를 운영 중임, RTX 5090 단일 GPU로 50인 정도의 간헐적 사용을 충분히 커버, Qwen3 32b 모델은 GPT 4.1-mini 또는 Gemini 2.5 Flash에 준하는 벤치마크 기록, 동시 2인 요청/32k 컨텍스트 환경, GPU 1대로 부족할 줄 알았지만 실제 대부분은 24시간 LLM을 사용하지 않음
          + 일반소비자는 결국 상품이므로 돈을 내기보다 데이터로 대가를 치르는 구조, 창작자(콘텐츠/앱 개발자)는 시장 경쟁이 얼마나 오래 지속되느냐에 따라 달라지겠지만, 규제장벽 등으로 소수 주요 사업자만 남으면 비용 폭증 가능성 우려
          + 현실적 스케일의 한계는 모델 제공자보다는 전력망임, 인류 1인당 약 250W 전력 사용량, 인체는 100W이며 휴식까지 고려하면 실질적 근무 가능 시간은 훨씬 짧음, 오늘날 직장인을 대체하는 AI가 되려면 인간보다 훨씬 에너지 효율적이어야 함, 현재 AI 에너지 효율과 일본PV 보급 속도로는 2032년 이전에 인류 일대일 대체 어렵다고 판단, 현재의 오픈웨이트 모델도 SOTA에는 못 미치지만 이미 유용한 수준 도달, GDPR 등 데이터 공유 동의 구조로 이미 개인정보 보호는 위협받았으나 데이터 중앙집중형 신뢰 시스템 리스크는 여전히 유효하다고 봄
     * 전반적 논지에는 동의하지만, 저자의 다소 어색한 글 흐름이 혹시 AI가 대신 쓴 건 아닐까 생각하게 됨, 저자가 언급한 모든 기능에 대해 오픈소스나 저렴한 유료 대안이 존재, 다만 보험회사 등 특정 분야에서는 대중적 압력이나 서비스 락인으로 인해 AI 활용이 피할 수 없는 현실로 보임, ChatGPT가 세계 상위 사용량 웹사이트임을 근거로 진짜 사용자가 원한다고 주장할 수도 있지만, 나는 두 가지 타당한 반론이 있다고 생각, 첫째, 인기 많다고 실제 결제의향까지 이어지지 않았던 사례가 넘침(유료 SNS가 과연 인기가 많았는지?), 둘째, 많은 인기 웹사이트가 타 분야에 침투해 일상 전체를 지배하기 바라는 사용자는 실제로 소수임
     * 방금 전 Gmail이 내게 도착한 이메일을 요약해주는 기능을 처음 봄, 제발 이러지 않았으면 좋겠다는 생각, 나는 내 이메일을 직접 읽을 것이고, 불필요한 요약문이 오히려 읽어야 할 텍스트만 더 늘림, 물론 동료로부터 대량의 애매한 중요도를 갖는 이메일을 받는 사용자에게는 쓸모 있을 수 있지만, 내 개인 계정에서 연락오는 건 모두 친구이고 나머지는 요약할 게 아니라 휴지통으로 직행이 정답, 다만 Gmail의 스팸 필터링엔 정말 감사함
          + 앞으로 스팸 필터링도 LLM이 하게 되면, 스패머나 해커들이 AI의 취약점을 악용하는 명령문을 메일에 심는 날이 머지않아 올 것으로 추측
     * 이 글 내용에 완전히 공감, ‘AI’는 중간 수준의 부정행위자에겐 소규모 시장을 만들 수 있으나 대부분 사용자에겐 스팸, 마치 아무도 원하지 않았던 클리피와 같은 존재, 언젠가 클리피처럼 AI 역시 사라지길 바람
     * “모두가 인터넷을 원했다”는 주장에 동의하지 않음, 많은 이가 스마트폰 이전까지는 관심이 전혀 없었으며, 스마트폰은 데스크탑 대비 불편하지만 훨씬 편리하다는 이유로 대중화, ‘불편해졌지만 더 편리해진’ 것이 AI와 똑같은 마케팅 논리, 결국 AI도 대중이 받아들일 것이라 짐작
          + 1997년경 네덜란드에서 길거리 인터뷰로 휴대폰(스마트폰 아님)을 원하냐고 묻자 압도적으로 “필요 없어”라는 답변, 즉 기기 변화에 대한 저항은 일반적 현상
          + 근본적 질문 자체가 잘못일 수 있음, 아무도 인터넷이나 모바일 영향의 장기적 결과를 몰랐기에 미래에 대한 낙관이 지배적이었을 뿐, 코카잎도 처음엔 기적처럼 여겼던 사례, 모바일 변화로 사회가 크게 달라졌고, 다시 과거로 돌이킬 수 없다는 사실이 아쉬움, 이런 생각은 나만의 감정이 아닐 거라 추측
          + 나는 90년대 초 어린 시절부터 인터넷을 썼음, 실제 기술이 등장하면 사람들은 놀라운 시선으로 바라보며 당장 자기 일상과 동떨어진 ‘너드’의 세계라 여기다 일시적으로 빠져듦
          + 인터넷은 모두가 원했던 변혁이었음, 하이프와 빠른 확산, 물론 ‘모두’라는 표현은 과장이지만 전기, 전화기 시절처럼 루디트파나 회의론자도 존재, 그럼에도 닷컴 붐은 모든 신생산업이 바라는 현상
     * 마치 허공에 대고 떠드는 느낌, AI의 문제는 너무 미묘해서 대부분이 그저 “그럴듯한 수준의 답변”만 얻어도 만족하며, 이게 얼마나 새로운 자연어 프로그래밍 언어 수준의 창의적 툴인지 인식도 못 함, 반복적 성공 위해선 효과적 프롬프트 작성이 필수지만 실제로 그렇게 노력하는 사람 별로 없음, 프롬프트 엔지니어링 논의마저 ‘프롬프트 작성이 엔지니어링이냐’고 폄하, 하지만 이게 바로 산업이 심각하게 받아들여야 할 고도의 기술적 프로세스, LLM의 미묘한 힘을 제대로 아는 이는 거의 없고, 오히려 제도권에선 사기라고 여기는 분위기
          + “엔지니어링”의 요체는 예측가능성과 반복 가능성임, LLM은 예측 불가, 모델이 바뀔 때마다 입력 해석법까지 달라져서 프롬프트 엔지니어라는 직업이 무의미해지는 구조, 사용자는 훈련방식, 훈련셋, 바이어스 등 원인 불명 요소가 너무 많음, Gemini 2.5 Pro에서 만든 훌륭한 프롬프트도 다음 버전이면 무용지물, 동적 ‘자가 개선형’ 모델이면 더욱 심각, 이게 말하는 “Vibe coding”이 결국 “Vibe prompting”이 아님?
          + AI를 이용해 문제를 푸는 데 더 많은 노력과 에너지가 든다면, 그냥 내가 직접 푸는 것이 효율적, 번거로운 프롬프트 엔지니어링이 필수라면 소프트웨어 엔지니어링 수준을 높이는 데 실패한 셈, 자동완성이나 타이핑 보조는 필요치 않음, 더 많은 두뇌노동을 요구한다면 가치감소
          + 만약 이런 비결정적 소프트웨어 엔지니어링이 먼저 등장했다면, 그 다음 나온 C 언어 개발자에게 동상을 세웠을 것이라는 농담이 나올 정도
     * 왜 CEO들이 AI에 집착하는가? 주식 투자자가 “AI 탑재”라는 말만으로도 바로 투자하는 흐름 때문임, 투자자의 수요가 바로 “AI 비즈니스 모델”의 붕괴를 막는 핵심, 결국 거품임, 하지만 이 거품은 한동안 유지될 수밖에 없음
          + 그 뿐만 아니라 이미 플랫폼 사용자 기반이 막대한 Microsoft, Google, Meta, Apple 등은 AI 인터랙션 데이터를 추가로 확보해 자체 학습데이터·인사이트 추출, AB테스트 등 이익, 남이 그 데이터를 가져가 경쟁하지 못하게 하고 싶어함(Anthropic, Deepseek 등)
          + AI가 이미 여러 분야에서 생산성을 향상시키고 있고, 단기적으로 거품이 맞지만 기술마다 시장 포화나 독점화 지점까지 항상 거품이 존재했던 게 현실
     * ChatGPT가 전 세계 상위 5위 인기 웹사이트이며 빠르게 성장 중, 이토록 인기 있는 제품은 결코 시장 저항으로만 설명불가, 인스타그램 사용자도 실제 결제 의향은 극히 적음(8%쯤?), 그렇다고 인스타그램이 대중이 원하지 않는 강요된 제품일까?
          + 페이스북, 트위터, 심지어 해커뉴스 피드를 쇼핑몰이나 업무 이메일에 무작위로 삽입되는 걸 원하냐고 묻는다면 아마 대부분 싫다고 답할 것, 대형 사이트여도 모든 환경에 무작정 끼워넣는 건 오히려 부적합
          + 75세 아버지는 구글 대신 Claude를 사실상 모든 검색에 사용, 내 주변 30대만이 적극적으로 AI를 거부하는 경향, 이 연령대는 오랜 시간 변화 없는 환경에 익숙해진 탓에 현상이 굳어진 듯함
          + ChatGPT는 내가 원하면 직접 찾아가 쓰면 되고, 모든 앱·웹에서 느리고 허술한 챗 인터페이스 강제 탑재는 불필요, 속도가 느리고 기능 발견 어렵고 정확하지 않아 헤매게 하는 새 챗은 필요하지 않음
          + 어제 Quordle 게임을 다운로드했는데 유료화 옵션의 주요 혜택이 “게임 내 AI 챗봇” 기능, AI는 내가 원할 때, 원하는 환경에서 쓸 수 있으면 충분, 특정 영역에서 사용한다고 해서 모든 곳에 무차별 탑재를 원하는 것은 아님
          + 실제로 페이스북과 인스타그램이 대중에게 ‘강요된’ 제품이라는 느낌 있음, 주변인과의 사회적 교류를 위해서는 사실상 필수 플랫폼으로 자리 잡았기에, 나는 페이스북 마켓플레이스, 인스타그램 릴스 등에 참여하지 않음, 광고 강제주입과 AI 강제통합은 비슷한 문제임
"
"https://news.hada.io/topic?id=21866","Token Limit - AI 도구에서 코드와 구성 파일이 소비하는 토큰 수를 모니터링합니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Token Limit - AI 도구에서 코드와 구성 파일이 소비하는 토큰 수를 모니터링합니다.

   AI 컨텍스트 파일(CLAUDE.md, .cursorrules 등)을 사용하는 프로젝트를 진행하면서 API 요금 청구서에 계속 놀라게 되었습니다. 파일 크기만으로는 토큰 비용을 정확히 추정하기 어렵다는 것을 알게 되었습니다.

   그래서 Token Limit이라는 CLI 도구를 만들었습니다:
     * 공식 토크나이저를 사용하여 실제 토큰 수를 계산
     * 토큰 또는 달러 단위로 예산 설정 가능(""100k"", ""$0.50"")
     * CI와 통합하여 프로덕션 적용 전 비용이 높은 변경사항을 사전 탐지
     * 모든 최신 모델 지원(GPT-4, Claude 3.5, o1 등)
"
"https://news.hada.io/topic?id=21875","Mercury - Diffusion 기반 초고속 언어 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Mercury - Diffusion 기반 초고속 언어 모델

     * 머큐리는 확산(Diffusion) 방식을 활용한 새로운 상용 대규모 언어 모델(LLM)
     * 이 모델은 Transformer 구조에 기반하여 여러 토큰을 병렬로 예측하는 특징이 있음
     * 머큐리 코더는 첫 확산 LLM 세트로, 코드 작성용으로 개발되고, Mini와 Small 두 가지 크기로 제공됨
     * NVIDIA H100 GPU에서 1109(미니), 737(스몰) 토큰/초의 처리량을 기록하며, 동일 품질에서 기존 속도 중심 모델 대비 최대 10배 빠른 성능을 나타냄
     * 실 사용 벤치마크 및 Copilot Arena 등 개발자 평가에서도 2위 품질 및 최고 속도를 기록하고, 공개 API 와 플레이그라운드도 제공함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 머큐리(Mercury) 는 확산(diffusion)에 기반한 신규 대규모 언어 모델 시리즈로, 상업적 규모에서 작동하는 신세대 LLM임
     * 모든 모델은 Transformer 아키텍처에 파라미터화되어 있고, 여러 개의 토큰을 병렬로 예측하도록 학습함
     * 본 보고서에서는 주로 코드 생성 앱을 위해 설계된 머큐리 코더(Mercury Coder) 의 첫 라인업을 소개함
     * 머큐리 코더는 현재 Mini와 Small 두 가지 모델 크기로 제공됨

주요 기여

     * 머큐리 코더는 속도와 품질 균형에서 새로운 state-of-the-art 수준을 달성함
     * 외부 평가 기관인 Artificial Analysis 기준:
          + Mercury Coder Mini: 초당 1109 토큰
          + Mercury Coder Small: 초당 737 토큰 성능을 NVIDIA H100 GPU에서 기록함
          + 최고 속도 프론티어 모델 대비 평균 최대 10배 빠름과 유사한 품질을 보임
     * 다양한 프로그래밍 언어 및 활용 사례의 코드 벤치마크에서 추가적인 평가 결과도 제공함
     * 실제 개발자 환경(Copilot Arena)에서도
          + 품질 기준 2위
          + 속도 기준 전체 1위 기록 실현함
     * 누구나 활용할 수 있는 공개 API ( platform.inceptionlabs.ai ) 와 무료 챗 플레이그라운드( chat.inceptionlabs.ai ) 를 지원함

목차 구조 설명

     * Introduction(소개)
          + 주요 기여(Contributions)
     * Inception Mercury Model Family(모델 계열 설명)
          + 학습 과정(Training)
          + 추론 방법(Inference)
     * Capabilities(모델 기능)
          + 기준선 성능(Baselines)
          + 코드 생성 능력(Coding Capabilities)
               o 평가 벤치마크(Evaluation Benchmarks)

정리

     * 머큐리는 혁신적인 확산 기반 LLM 설계와 병렬 예측 구조를 조합하여, 코드 생성 분야에서 압도적인 속도 및 높은 품질을 실현함
     * 다양한 크기의 모델과 강력한 실 서비스 벤치마크, 쉬운 접근성을 통해 상용 및 개발 환경 모두에 경쟁력 있는 선택지를 제공함

        Hacker News 의견

     * LLM 에이전트가 도입되면 테스트 성능이 더 심각한 CPU 병목 현상으로 이어질 전망이고, 이미 지금도 모든 팀이 CI 속도로 인해 병목을 겪는 상황임을 강조함
       에이전트가 사람보다 100배 빨리 코드를 써도, 테스트에 한 시간이 소요되면 의미가 없는 상황
       내가 일했던 많은 프로젝트에서 변경사항이 반영되길 기다리며 낭비되는 개발자 시간이 많았고, 많은 실행이 I/O 또는 작업자 부족으로 인해 병목됨
       코딩 에이전트가 단순 티켓을 빠르게 PR로 전환하고 테스트 실패에 반응해 실시간으로 수정하면서, CI 병목은 더욱 악화될 것
       대부분 프로젝트 테스트 환경에 개선 여지가 많은데, 실제로는 수년간 별다른 진전 없이 느린 CI와 높은 비용을 당연시하게 여겨온 분위기
       빌드를 완전히 격리하기 위해 캐싱을 끄거나, 온프레미스에서 느린 클라우드 VM으로 이전하면서 CI가 오히려 더 느려짐
       Mercury 속도가 미친 듯이 빠르고 몇 번 테스트해본 결과, 코드 품질도 훌륭하고 정확했으나, 이제는 테스트 실행까지 이 속도를 따라가게 하는 일이 과제로 남음
          + 내가 일한 대부분 프로젝트에서 PR 승인 기다리며 개발자 시간이 낭비된다는 점이 납득이 잘 되지 않음
            기업 입장에서 개발 시간은 기계 시간보다 훨씬 비싸므로, 개발자 불만이 나오면 CI 워커를 배로 늘릴 수 있는 문제임
            구글에서는 테스트 불안정성 디버깅 때 1만 대 머신에서 1만 번 테스트하며 드물게 발생하는 실패를 찾아내는 경우도 있었음
            내 현 직장도 유사한 방식을 제공하며, 커맨드 하나로 모든 테스트를 1천 워커로 병렬 실행해 1M LOC 프로젝트도 5분 내 피드백 받는 목적임
            빌드를 완전히 격리하는 것과 캐싱을 쓰지 않는 것은 별개이며, 빌드를 완전히 격리하면서도 모든 캐시를 최대한 활용해야 한다는 관점
          + 구현 속도가 빨라지면 병목이 PM 쪽으로 옮겨가고, 이 경우 변경이 더 직렬처리됨에 따라 충돌이 크게 줄어드는 현상 발생 예상
            스펙 정의 언어(TLA+ 등)의 부활 가능성도 있는데, 에이전트가 이를 빠르게 작성 및 검증하면서 전체 통합 테스트 수가 줄어들 수도 있음
            백그라운드 에이전트가 중복 코드를 정리할 때 중복 테스트도 함께 정리 가능성
            AI는 인간 엔지니어 팀과 달리 모놀리식 구조에서 더 효율적으로 일할 것으로 보이며, 이러면 로컬에서 돌릴 수 있는 테스트 커버리지 증가로 인해 flaky 감소 및 CI 부하 감소 효과
            AI가 효율성을 높여도 그만큼 더 많은 코드, 더 빠른 코드 생성 및 실행으로 새로운 문제가 계속 생길 것이며, 인간 엔지니어가 해결해야 할 새로운 문제가 지속적으로 나오리라는 확신
          + LLM이 100줄 미만의 빠른 수정, 또는 러버덕 역할 정도는 괜찮지만, 대형 프로젝트 CI 파이프라인에 LLM을 직접 넣으면 수백 시간 단위의 생산성 하락 우려
            실제로 코드 작성 실력을 키워야 할 시간에 프롬프트 튜닝과 컨텍스트 조정만 하게 된다면 의미 없음
            LLM 툴링에 대한 자신감이 너무 크다고 느끼며, 복잡한 시스템에는 잘 적용되지 않는다고 생각
            중요한 저장소에 무감독으로 LLM을 투입하는 일은 '총구를 들이대지 않는 이상' 있을 수 없다는 과한 불신
            결국 LLM의 결과를 반쯤 다시 손보게 되고, 그럴 바에야 직접 하는 게 낫다는 입장
          + 자동차 이전에는 기름, 오일, 정비 등에 거의 돈을 쓰지 않았으나, 시스템이 발전하면서 그에 맞는 부대 인프라와 비용이 따라오는 구조
            AI로 병목을 해결하거나 더 많은 기능을 만들어 수익을 극대화하고, 그 추가 수익으로 더 많은 CI 리소스를 확보하는 식의 순환 고리
            AI를 10명의 개발자 늘린 것과 다를 게 없고, 당연히 지원 비용이 늘어나는 현상
            효율성을 논리적으로 설득해 더 많은 CI 리소스를 확보하거나 최적화 방향을 제시할 수 있는지 되돌아보라는 관점
            CI 리소스 한 대당 비용이 얼마나 되는지 궁금
          + Python 앱에서 astral.sh 도구체인과 uv 패키지 설치 + 캐싱 활용으로 CI 속도를 크게 끌어올린 경험
            조만간 mypy 대신 astral의 타입체커로 옮길 예정이고, 이러면 더 빨라질 전망
            프론트엔드가 있는 앱의 경우 Playwright 테스트가 가장 느린 파트겠지만, 그마저도 다른 앱에선 해당 없음
            (추신: 혹시 Mike가 맞다면, 2000년대 초반 Google Maps에서 같이 일했던 SRE로 기억, 신뢰가 가는 의견임)
     * 내가 Mercury playground에서 정규표현식 패턴을 요청했더니, 모델이 스스로 계획을 세우고 패턴을 쓴 후 테스트를 생성하기 시작
       그런데 끝없이 테스트를 늘려가다 문맥 한도에 다다르자 응답이 끊겨버린 경험
       30개쯤 지나니 테스트 결과 주석을 잘못 붙이기 시작했고, 120개 넘어서부턴 테스트 입력 자체가 이상해져서 난수 문자가 잔뜩 나옴
       패턴 자체도 정답이 아니었으나, 이 ‘무한루프’ 현상이 더 흥미로운 이슈
          + 참고로, 불과 얼마 전까지 일반 LLM도 이런 ‘거의 무한루프’처럼 보이는 반복 출력을 하곤 했던 기억
            출력이 조금씩만 달라지는 패턴에 갇히는 일
          + 이 사례가 ‘토큰 예측만으로 코드를 정확하게 만들 수 없다’는 대표적 증거라고 생각
            LLM은 애초에 코드 사고에 적합하게 설계된 게 아니라는 평가
     * 내가 기술 보고서를 읽어본 결과, Mercury가 논문 Lou et al. 2023, SEDD 기반임을 확인
       내가 최초(아마도)로 SEDD를 from-scratch로 재구현했으며, 코드 공개
       복잡한 디노이징 방법도 직접 구현
       기존 SEDD보다 깔끔하고 읽기 쉽도록 설계했고, 단일 GPU에서 장난감 데이터셋 기준 몇 시간 내 구동 가능
     * 참고로 DeepMind에서도 diffusion 기반 Gemini 모델이 있음 (링크)
       직접 테스트해보니 Mercury처럼 속도는 미쳤지만, 답변 품질은 다른 Gemini에 비해 많이 떨어졌던 경험
          + 간단히 써본 바로는 속도는 인상적이지만 정답률이 많이 떨어지는 현상에 동의
          + Gemini Diffusion 데모가 무료인지 궁금
            며칠째 웨이팅리스트 중이라 실제 써 볼 기회가 없어 아쉬움
     * 개인적으로 이런 발전이 굉장히 기대됨
       최근 게임잼 때 AI로 간단한 게임을 코딩했는데, 결과 기다리며 보내는 시간이 절반 이상 차지
       프롬프트당 결과가 1~2분씩 걸리는 현상에서 10초만 기다리면 된다면, 기존에 한 번 테스트할 동안 다섯~열 번 실험이 가능
       아직 Mercury가 실용적으로 사용할 수 있을 만큼 성숙하진 않았으나, Claude 3.0도 1년 전은 미흡했으니 앞으로는 더 나아질 전망
       앞으로가 정말 기대되는 시점
     * Mercury playground 써보니 속도가 정말 굉장함
       확산모드(diffusion mode) 시각화도 신선하지만, 실질적으로는 시각화된 선 노이즈에서 점점 더 정확한 상태로 다듬어지는 과정을 보여주는 듯함
       실제로는 임의 벡터 공간에서 점점 확실한 토큰으로 수렴하는 과정으로 봄
          + 일부 텍스트 diffusion 모델은 연속적인 잠복 공간(latent space)을 사용하지만, 성능이 썩 좋지 않음
            최근에는 대개 실제 토큰 출력 예측에 집중하며 단계별로 이전 값을 수정해 최종 결과로 수렴
            내가 쓴 텍스트 diffusion 작동 원리 설명 링크 참고 추천
          + 링크 : https://chat.inceptionlabs.ai/
          + 진짜 말도 안 되게 빠르다고 느낌
     * 대부분 GPU 인접 코드에 성능 최적화 여지가 매우 큼
       하지만 arXiv 논문이 실제 연구라기보다 마케팅에 가깝다는 의문 제기
       다른 의견 환영
          + 그렇게 틀린 포인트는 아니지만, arXiv에서 이런 사례는 이번이 처음이 아니라는 점
     * Mercury 모델 가격정책
       출력 토큰 100만 개당 1달러, 입력 토큰 100만 개당 0.25달러
       자세한 요금정책은 여기 참고
          + 가격이 살짝 높은 편
            성능 민감한 경우, Mercury와 Groq(Llama 3.1 8b, Llama 4 Scout) 비교 시 성능은 비슷했으나 Groq의 가격이 훨씬 유리
            디퓨전 모델의 오픈소스 출현을 기대하며 관심 있게 지켜보는 중
     * playground 코드와 API 응답에서 gpt-3.5-turbo와 ""openai"": true 항목이 보여 실제로 자체 dLLM이 아닌 OpenAI를 부르는 건지 궁금
       우측 상단 diffusion effect 기능은 단순 애니메이션 효과로 보여짐
          + 실시간 같은 속도라 실제 OpenAI 백엔드 쓴다고 보기엔 너무 빠름
     * 모든 것이 멋지게 들리긴 하지만,
       서비스에 사용자 게시물을 제출하면 전 세계적으로 독점적이지 않고, 영구적이며, 로열티 없는 무료, 전면 양도 가능한 라이선스를 Inception에 부여하게 되는 약관임
       즉, 사용자의 컨텐츠를 AI 모델 훈련 목적으로 쓸 수 있음
       (단, OpenRouter 경유 접속분은 학습에 사용하지 않는다는 예외 조항 있음)
"
"https://news.hada.io/topic?id=21884","NuxtLabs가 Vercel에 합류","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          NuxtLabs가 Vercel에 합류

     * NuxtLabs가 Vercel에 인수됨에 따라, Nuxt 오픈소스 프레임워크 개발팀이 자금 걱정 없이 Nuxt와 Nitro 등 핵심 개발에 전념할 수 있게 됨
     * Nuxt는 Vue.js 기반 SSR/정적 사이트 프레임워크로, 접근성·투명성·커뮤니티 중심 개발을 강조
     * 인수 후에도 프로젝트는 MIT 라이선스, 공개 로드맵, 커뮤니티 중심 원칙을 그대로 유지하며, NuxtLabs의 전 오픈소스 팀도 함께 합류함
     * Nuxt UI Pro 컴포넌트 무료화, Nuxt Studio 오픈소스화, NuxtHub의 다양한 프로바이더 지원 및 Vercel 통합 등 오픈소스 활동 확대 예정
     * Vercel의 오픈소스 생태계 투자 및 AI 기술 접목과 협업을 통해 Nuxt 개발 경험 및 생태계가 한층 더 확장될 전망임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Nuxt 및 NuxtLabs 소개

     * Nuxt는 Vue.js 기반의 오픈소스 프레임워크로, SSR(서버 사이드 렌더링) 및 정적 사이트 생성을 쉽게 구현할 수 있게 해줌
     * NuxtLabs는 “누구나 빠르고 아름다운 앱을 쉽게 만들 수 있도록 최고의 개발자 경험을 제공”하는 것을 미션으로 함
     * 2017년 설립 이후 Nuxt는 MIT 라이선스 하에 커뮤니티 주도 방식으로 발전해왔으며, 방대한 생태계와 활발한 커뮤니티를 보유

인수 배경과 의미

     * NuxtLabs는 오픈소스 지속 가능성 문제로 인해 개발/운영과 자금 조달 사이에서 어려움을 겪어왔음
     * Vercel 인수로 NuxtLabs 팀은 오픈소스 개발과 커뮤니티에 집중 가능
     * Vercel은 이미 Next.js, Svelte, Turborepo 등 다양한 웹 생태계 오픈소스를 지원해온 경험이 있음
     * Nuxt 개발팀(및 Nitro) 전체가 Vercel로 합류하며, 프로젝트의 오픈소스 원칙(커뮤니티 중심, MIT 라이선스, 공개 로드맵 등)이 그대로 유지됨
     * 후원금은 Open Collective로 투명하게 이전되어, 코어·커뮤니티 기여자에게 직접 지급

NuxtLabs의 향후 계획 및 커뮤니티 영향

     * Nuxt UI v4 공개: Nuxt UI Pro 컴포넌트와 Figma Kit 전부 무료로 오픈소스화 예정
     * Nuxt Studio 오픈소스화: 누구나 셀프 호스팅 형태로 Nuxt Content 사이트를 관리하는 관리자 기능 제공
     * NuxtHub의 프로바이더 지원 확대: Vercel의 Marketplace(예: Postgres, Redis 등)와 통합 및 타 프로바이더 지원 예정
     * AI 기능 연구/개발: Nuxt 개발 경험에 AI 접목, Vercel AI팀과의 긴밀한 협업, 로컬 툴(MCP) 실험 등 진행
     * “앞으로 NuxtLabs는 더 많은 오픈소스 프로젝트와 도구를 공개할 예정”이라고 언급

NuxtLabs와 Vercel 협업의 주요 영향

     * Nuxt 프레임워크의 지속 가능한 발전 기반 마련: 핵심 팀이 재정·운영 부담 없이 오픈소스 개발에 몰입할 수 있는 환경 확보
     * Vercel 플랫폼 통합 및 생태계 연계 확대: Nuxt 기반 앱이 Vercel의 인프라, AI, Marketplace 서비스와 더 쉽게 통합될 전망
     * 커뮤니티 중심 가치 강화: 기존처럼 공개 로드맵과 MIT 라이선스 유지, 기여자 중심 후원 체계로 커뮤니티 신뢰 유지

커뮤니티에 전하는 메시지 및 감사 인사

     * NuxtLabs는 Nuxt를 사용·후원한 모든 유저와 기여자에게 감사의 메시지를 전하며, 프로젝트의 미래에 커뮤니티가 계속 중심이 될 것임을 강조
     * 주요 공헌자와 투자자, 파트너, 가족, 커뮤니티 멤버에게 감사를 표함

결론

     * 이번 인수로 Nuxt의 오픈소스 철학과 커뮤니티 중심 운영 원칙은 유지되며, 더 많은 리소스와 기회로 Nuxt 생태계가 성장할 것으로 기대
     * 공식 소식 외에도, Nuxt의 미래에 대해 궁금하다면 GitHub 논의 게시판에서 더 많은 정보를 확인할 수 있음

   버셀의 악명을 생각하면 ... 한 편으론 걱정해야 하나요?

   계란이 모두 한 바구니에 담겼네요.

   해커뉴스에서도 다들 갑론을박하는데 저는 vercel이 리액트에 해놓은 짓을 생각하면 의심이 안 들 수가 없다는 입장입니다

   프론트 독과점으로 망할 것 같으면 개추 ㅋㅋㅋㅋ

   그렇다면 저 Astro!

   ~모든 것을 vercel에 맡기세요~

   또 vercel..?

        Hacker News 의견

     * Next.js, Svelte/kit, Nuxt가 모두 이제 Vercel에 속하게 된 점이 정말 놀라운 상황이라고 느끼는 입장, 개발자들이 더 좋은 지원을 받게 된 건 좋은 일이지만 한편으로는 이런 상황이 불안하다는 솔직한 심정
          + Vercel이 이제 하이브리드 프레임워크 시장에서 거의 독점이나 다름없는 위치를 얻게 되어 모두를 망치게 될 거라는 우려, 독점은 소유자 외 누구에게도 득이 없는 구조라는 생각, Vercel의 성공에 박수를 보낼 수는 있지만 결국 주주 가치 증대만이 남는 씁쓸함
          + ‘Embrace, extend, extinguish’라는 역사가 오래된 전략이 반복되는 느낌, 이 이야기는 무려 60년대부터 이어져 온 오래된 이야기라는 개인적 경험
          + Tanstack만큼은 독립적으로 남길 바라는 희망
     * “Vue만이 현재 여전히 독립적으로 남아 있는 주류 프레임워크”라는 Evan You의 말을 인용하며, Nuxt가 Vue 자체는 아니라 해도 Vue 커뮤니티에서 독립성이 얼마나 중요한 가치인지 다시 한 번 상기하게 된다는 의견, 링크 첨부
       관련 글 보기
          + Void 0(예: Vite, Oxc와 같은 저수준 인프라)에 의해 그 발언이 모순되는 것 아니냐는 생각, 이 도구들 역시 Vue 생태계를 지원하는 방향으로 확장될 여지가 크다는 예측
     * Nuxt 메인테이너로서, Nuxt가 Vercel에 의해 지원받는 가장 큰 이유는 오픈 비전 때문임을 강조, 오픈 정책은 팀의 핵심 가치이자 웹의 핵심 가치와도 같다는 신념, 크로스 프레임워크 어댑터와 provider 패턴을 주도하고 있고 앞으로도 이 방향성을 바꿀 계획이 전혀 없다는 확고한 입장, Nuxt 또한 Svelte처럼 여전히 독립 프레임워크이고 팀원 중 다수가 오픈소스 풀타임 기여자로 일하는 현 상황이 오픈소스 지속가능성과 개발자에게 매우 긍정적이라는 자신감
          + Nuxt의 어댑터와 provider 패턴이 매우 훌륭하고 프레임워크의 이식성이 인상적이라는 찬사, Nuxt OSS 기술 덕분에 다양한 프로젝트에서 이식성을 바로 활용할 수 있다는 점이 놀랍다는 의견, 반면 Vercel의 Next.js의 이식성은 실패 사례라는 비판
     * Daniel Roe가 더 많은 세부 내용을 정리한 글 공유
       참고 링크
       참고 글
          + Vercel 공식 발표 관련 링크 공유
            Vercel 공식 발표
     * 이번 상황이 Autodesk가 3D Studio Max와 Maya, Softimage를 모두 인수하고 Houdini만 독립으로 남겨놓은 것과 비슷한 분위기라는 비유
          + 그 와중에 blender.org 같은 오픈소스 3D 툴이 존재한다는 점을 일깨우는 추가 의견
     * 전체적으로 중앙집중화에 회의적이고 Nuxt가 Nitro를 통해 모든 호스팅 제공업체에서 동작하는 모습이 좋았다는 입장, Next.js는 Vercel에서 최고의 경험을 제공하고 TurboPack 역시 Next 전용이라는 점을 예로 듦, 자금 걱정이 필요 없는 상황이 얼마나 해방감 있게 느껴질지 공감하면서 Nuxt의 미래에 계속 기대한다는 응원, Nuxt 4를 기다리는 기대감
     * Nuxt가 Vue와 Nuxt만 경험해본 사람들에게만 잘 맞고, 딱히 아무 곳에도 가장 적합한 케이스가 없다고 느끼는 시각, Vercel에서 굳이 인수할 이유가 딱히 보이지 않는데 혹시 React 팀원을 다수 영입하고 React 개발 방향을 주도하는 Vercel처럼 Vue 개발에도 영향력을 행사하기 위함인지 의심, 하지만 Vue와 Nuxt의 시장 점유율이 작아서 그럴 가능성도 낮다는 판단, Nuxt 커뮤니티가 Discord 중심으로 움직이는데 2년 전만 해도 인터넷 줄임말 사용만으로도 경고받는 독특한 분위기가 있어서 직접 경험 후 사용을 빠르게 그만뒀다는 경험
          + Nuxt가 딱 들어맞는 용도가 없다는 시각에 동의, SPA라면 Vue의 공식 라우터가 계속 좋아지고 있어 활용하기 좋고, 만약 Static Site 또는 MPA라면 Nuxt 대신 Astro가 훨씬 나은 선택이라는 주장, 관련 정보 링크
            uvr.esm.is
            pinia-colada.esm.dev
          + Nuxt 사용하는 사용자를 Vercel 클라우드에 유입시킨 뒤 점차 Next와 React로 이동시키려는 전략이라는 추정
          + ‘aqui-hire’라서 인수 목적 자체가 인재 획득이라는 진단
          + Nuxt를 오히려 좋아하는 사용자가 있고, React를 쓰기 싫으면서도 Next의 풀스택성을 누리고 싶은 사람에게는 완벽하다는 의견
          + Vercel의 인수 이유가 명확하다는 시각, Next의 우위가 더 커지고 이직 시 다른 프레임워크로 고민하는 유동성을 해소하여 채용 공고가 더욱 Next 중심이 되도록 한 것이라는 해석
     * Nuxt도 Next와 같이 앞으로는 절대 쓰지 않을 목록에 들어가게 되어 아쉽다는 의견
     * Nuxt.js의 핵심팀이 Vercel로 합류하고 NuxtLabs가 인수되는 것에 실망, Vercel 제품이 아니라는 이유로 Nuxt.js와 Nuxt UI Pro를 선택했는데 이제 상황이 바뀌어 앞으로 경쟁자였던 Vercel의 선택에 프로젝트의 운명이 달린 상황이 되어 버렸다는 당혹감
          + 완전히 공감하며 이제 Astro로 마이그레이션을 고려하는 개발자의 의견, Nuxt 대신 Astro를 쓴다는 의문을 들은 적이 많아서 이번 기회에 직접 경험해보려는 계획
          + Vercel은 Nuxt의 경쟁자가 아니고 오히려 다양한 프론트엔드 프레임워크가 Vercel에서 배포될 수 있다는 점 덕분에 이득을 보는 입장이라 설명, 예시로 Vercel에 합류한 Svelte 개발자들이 오히려 Svelte와 SvelteKit을 더 좋게 만들었고 별다른 강요도 없었다는 주장을 전개
     * 이번 인수가 Vue가 아닌 React 쪽의 성향으로 개발 방향이 쏠리는 결과가 되지 않기를 바라는 유저의 걱정
          + 프레임워크가 Next처럼 Vercel 인프라에 최적화된 패턴을 도입하게 될까봐 걱정, 그래서 Tanstack으로 옮겼다는 개인적 선택
          + 그럴 이유가 딱히 없다는 입장, 납득하기 어렵다는 반박
"
"https://news.hada.io/topic?id=21960","Firefox에 돈을 내게 해주세요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Firefox에 돈을 내게 해주세요

     * 오랜 시간 Mozilla를 후원해온 서포터로서 파이어폭스를 위해 직접 결제할 수 있는 방식을 강하게 원함
     * 오픈소스 소프트웨어 유료화가 모순처럼 보일 수 있지만, 자유 소프트웨어 철학과도 양립 가능함
     * 광고 기반 수익 모델이 초래하는 문제점(사생활 침해, 알고리듬 남용 등)을 우려하며, 직접 후원 방식이 Mozilla의 미래에 더 적합하다고 주장
     * 파이어폭스는 계속 자유 소프트웨어로 남아야 하며, 결제하지 않는 사용자도 자유롭게 사용할 수 있어야 한다고 밝힘
     * 유료 버전에는 광고·텔레메트리 없이, 프라이버시와 사용자 중심 기능을 강화한 모델 도입을 제안
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Firefox 유료화 제안과 그 의미

  오랜 Mozilla 커뮤니티 활동 경험 소개

     * 작성자는 2006년부터 Mozilla 커뮤니티 활동에 참여함
     * Spread Firefox 프로젝트에서 창의적인 프로모션 콘테스트를 진행한 이력이 있음
     * New York 시 전역에 팸플릿을 부착하는 등의 오프라인 활동도 경험함
     * 이후 Mozilla Corporation에서 8년간 정규직 직원으로 근무한 경험을 갖고 있음

  Firefox 유료화 필요성 제기

     * 과거에는 Firefox의 유료화가 상상조차 불가능한 일이었으나, 지금은 반드시 필요하다고 주장함
     * 오픈소스에 요금을 부과하는 것이 윤리적으로 문제라는 인식이 있지만, [Free Software Foundation(FSF)도 배포료 책정은 자유](https://www.gnu.org/philosophy/selling.en.html]임을 명확히 밝힘
     * FSF는 ""자유 소프트웨어는 높은 배포료를 받더라도, 사용자가 원하면 언제든지 무료로 복사본을 얻을 수 있기 때문에 폐쇄 소프트웨어와 본질이 다르다""고 얘기함

  소프트웨어 유료화와 오픈소스 자유의 공존

     * Firefox가 유료가 되어도, 기존과 동일하게 포크 버전(예: LibreWolf, Waterfox, IceCat 등) 을 이용할 수 있음
     * 사용자들은 필요에 따라 고객지원, 신속한 업데이트 등 차별화된 서비스를 원할 경우 공식 유료 버전을 선택할 수 있음
     * 원치 않는 사용자들은 언제든지 포크를 선택하여 비용 부담 없이 활용 가능함

  광고 기반 수익모델의 한계와 우려

     * 광고와 알고리듬이 결합된 서비스가 enshittification(서비스 질적저하) , 중독, 극단화 유발, 타겟 광고 남용 등 부정적 결과를 초래함을 우려함
     * 페이스북과 같은 플랫폼이 보여주는 알고리듬 남용, 사생활 침해, 과도한 광고 등 문제를 보면 이런 미래를 Mozilla가 피해야 함
     * Mozilla가 광고수익에 의존하지 않고, 직접 요금을 받는 모델로 전환해야 한다는 필요성을 역설함

  사용자가 직접 지원할 수 있는 모델의 필요성

     * 기존에도 Proton, Standard Notes, Kagi 등 사용자를 우선하는 소프트웨어에 자발적으로 비용을 지불하고 있음
     * Firefox도 광고 없는, 텔레메트리 없는, 구글 기본 검색 제외, 광고차단 내장 등의 버전을 만들어 유료로 제공하면 사용자가 충분히 지불할 의사가 있음
     * 현재 Mozilla의 비즈니스 모델이 마음에 들지 않아 떠나는 사용자가 많으며, 명확한 유료화가 오히려 충성 고객을 만들 수 있다고 생각함

  결론

     * Mozilla가 당장 전체적으로 유료 전환할 필요는 없음
     * 실험적으로 광고·텔레메트리·구글 없는 버전, 강력한 광고 차단 기능이 내장된 파이어폭스 유료 버전 도입을 제안함
     * 만약 Mozilla가 유료화 전환을 하지 않는다면, 다른 누군가가 먼저 실행할 것

        Hacker News 의견

     * Mozilla Foundation에 기부하고 싶었던 적도 있었음, 하지만 이제는 돈이 어떻게 쓰일지 전혀 신뢰하지 않음, 비관적으로는 기부금이 또 쓸데없는 ""캠페인"", ""연구"", 광고, 혹은 임원 보너스로 사용될까봐 걱정임, 내가 진짜 바라는 건 Firefox가 빨라지는 것임, 그래서 Floorp(파이어폭스 포크)에 기부하고 있음, 그쪽은 브라우저 자체 발전에 더 집중하는 듯함
          + 사람들이 Mozilla에 화난 이유는 이해하지만, Hacker News에서 Mozilla를 비난하는 것이 점점 해커 커뮤니티의 상징처럼 되어가고 있음, 누구나 한 단계 더 과하게 비난하거나, '사실 이 정도로 심각하다'는 식으로 경쟁하는 느낌임, 대부분의 댓글이 같은 용어(예: CEO 구울 같은 표현)를 반복하면서 동조하는 분위기라면, 잠시 쉬어갈 필요가 있다고 생각함
          + 내부 직원들의 자기만족용 부프로젝트에 많은 리소스를 쏟는 모습에 예전부터 이미 실망했음, 시장의 필요나 타깃 유저 기반도 없는 프로젝트들임, 그런 조직은 그냥 구글 같은 대기업들의 반독점 명분용 브라우저일 뿐임, 진지하게 볼 가치도, 개인 기부를 할 이유도 없다는 입장임
          + 나는 Waterfox를 유지보수하는 입장이지만, 과도하게 다른 포크를 비난하는 건 좋아 보이지 않음, Mozilla의 운영과 지출 문제 때문에 Floorp를 지지한다는 건 모순임, Floorp는 처음에 오픈소스 확장으로 USP를 만들었지만, 이후 남들이 똑같이 못 따라하게 라이선스를 닫았음, 커뮤니티 반발(혹은 '영감' 받아서) 다시 풀었지만, 오픈소스 원칙을 배신한 프로젝트에 기꺼이 지지한다는 게 도덕적으로 더 일관성 있는 태도라고 볼 수 있을까? Mozilla는 실제로 기본 엔진까지 개발하는 조직인데 말임
          + Mozilla Foundation이 이렇게 변질된 걸 보는 것만으로도 실망임, 이걸 보면 Linus 없는 리눅스의 미래가 두렵기도 함, 큰 프로젝트에는 카리스마 있는 BDFL(최고 결정자)가 꼭 필요하다고 생각하게 됨, 아니면 악덕 실세들에 장악당하게 되는 모습임
          + Wikimedia Foundation과도 비슷한 점이 있다고 생각함, 우리는 비용의 '적정선' 자체를 모름, 이런 조직들은 사실상 경쟁이 없는 독점적인 구조임, 연간 예산도 공개적으로 논의되지 않음, 대형 광고판에 팝업을 띄워서 돈을 많이 모으고, 자연스럽게 CEO 연봉도 정당화되는 구조임, 이런 환상은 감시가 전혀 없을 때만 유지된다고 봄
     * 매월 Firefox 사용료를 기꺼이 내겠음, 하지만 Mozilla Corporation에 주고 싶진 않음, 개발자와 개발지원, 운영팀에게 직접 주고 싶음, CEO 연봉을 불리는 데는 반대임
          + 개발자와 지원, 운영만으로 어떻게 조직이 돌아갈 수 있다고 보는지 궁금함, 큰 팀을 의사결정자 없이 운영해 본 적이 있는지 모르겠음, 그런 곳은 거의 항상 실패하거나 혼란스러웠던 경험이 있음
          + 그런데 우리는 이미 다른 모든 분야에서 똑같이 CEO에게 비용이 흘러가는 구조에 익숙해져 있음, 소프트웨어 개발자가 'CEO 구울'들을 뛰어넘을 방법을 찾든, 결국 CEO 구울들도 몫을 가져가게 되어 있음, 원하는 서비스를 이용하면서 돈의 쓰임을 전적으로 통제하는 것은 불가능하다고 생각함
          + 네, 바로 그거임! 단, 내가 좋아하지 않는 개발자는 빼고, 좋아하지 않는 기능 개발도 빼고, 내가 싫어하는 코드 설계도 빼고, 탭 대신 스페이스 써야만 내 돈을 주겠음! 개발자가 어떤 에디터 쓰는지도 궁금함
     * 더 많은 유료 서비스가 필요하다고 생각함, 모든 걸 광고 수익에만 의존하면서, 사회 전체가 광고주에게 힘을 지나치게 내주었음, 이제 진짜 사람들의 의견은 잘 안 보이고, 광고 친화적인 의견만 더 많아짐
          + 광고 모델 + 광고 차단 조합을 이길 만한 구조가 없음, 광고를 보는 사람들은 손해보고, 우리는 공짜로 이용함, 대신 점점 컨텐츠가 '호구'들을 위한 방향으로 가는 것에 불평함
          + 우리는 여전히 결국 서비스에 돈을 두 번 내게 됨, 한번은 관심(주의)으로, 또 한번은…
          + 내 활용도에 잘 맞는 브라우저라면 월 10파운드 정도 지불할 의향 있음, 나처럼 생각하는 사람들이 한계치를 넘으면 가능성이 있다고 봄
          + 적극 동의함, 나는 FreshRSS, Wallabag 등과 같은 월 결제 호스팅에 돈을 내고 있고 개발에도 직접 후원함, 프라이버시와 개발자 지원 차원임, 비용도 그렇게 크지 않음, Firefox와 Thunderbird 같은 오픈소스도 이런 식으로 유지 가능한 구조가 생겼으면 좋겠음
          + 한편으로는 지난 45년간 노동계급의 구매력이 꾸준히 떨어져왔단 점도 큼, 지금은 도금시대(Gilded Age)급 불평등을 훌쩍 넘었고, 기미도 없음
     * Mozilla의 사이드 프로젝트 비판이 뭔지 정확히 모르겠음, Rust, Firefox OS, Pocket 등 이미 다 정리했고, 이제는 웹 브라우저와 관련 액세서리(VPN, Relay)에 집중하고 있음, VPN과 Relay도 감시 방지 효과와 수익성 모두 있음, CEO도 이미 교체됨 관련 기사
          + 지난 10년간 Mozilla는 정확한 목표도 없이 돈을 허공에 쏟아부었음, 크고 비싼 리브랜딩이 있어도 의미 있는 변화나 의지가 하위 조직까지 전달된 건 못 느꼈음, 공식 홈페이지를 여기저기 둘러봐도 내 기부금이 정확히 어디에 쓰이는지 너무 불분명함, Firefox에 쓰이는 건지, 소프트웨어 외 인권운동인지, 팟캐스트 제작지원인지 알 수 없음, Firefox 언급조차 잘 안 보임 mozilla foundation 홈페이지, 나는 사이드 프로젝트가 문제가 아니라, Mozilla의 외부에서 봤을 때 방향성 자체가 아예 보이지 않는 게 문제임, 심지어 구글이 돈을 대는 어른들 놀이방처럼 느껴짐, 이렇게 신뢰할 수가 없음
          + Rust 등 다 정리한 것이고, VPN과 Relay도 5년밖에 안 됨, MDN 빼면 지금 나머지 '브라우저 및 부가 기능'은 다 종료됨, Mozilla가 25년이 넘은 조직인데, 제일 오래된 서비스들이 수명 1/4 수준이면 뭘 의미하는 걸까, 브라우저 분야도 실질적으로 발전이 미미함, 버그픽스나 웹 표준 작업 외에, 새로운 기능이라고 해봐야 '수직 탭' 등 이미 확장으로 있던 것 정도, New Tab 동적 배경화면, AI 기능 몇 개… 이런 걸로 흥분하길 기대하는 건 좀 어불성설임, 그런데 The Browser Company처럼 정말 새로운 시도를 하고, 핫한 제품을 만들어 자금도 유치하는 곳도 있는데, Mozilla는 말로만 '최고의 브라우저'를 만든다 하면서 실제로 내놓는 게 없음
          + 신뢰를 되찾는 데는 시간이 걸림
          + HN에서 Mozilla에 대한 상황을 잘못 이해하는 댓글들을 자주 봄, 지금 구글머니가 빠지면 Firefox가 크로뮴이나 사파리와 경쟁 자체가 불가능함, 그 즉시 망함, 현재 모든 사이드 프로젝트들은 구글 외의 수익원을 찾으려는 시도임, 이걸 그만두라고 주장하는 건 정작 핵심 문제를 빗나간 얘기임, 우리가 바라는 게 Firefox의 생존이라면, Mozilla의 이런 시도를 응원하고 이해할 필요가 있음, 비난만 할 일이 아님
     * Mozilla Corporation에 대한 지나친 불평이 피곤해짐, 브라우저, MDN, 인증서 신뢰 검증 등은 기금만으로 감당할 수 없을 만큼 자금이 더 필요함, 브라우저를 유료화하면 서비스도 같이 망함, 결국 다른 수익원을 찾아야 하는 상황임, 서치 라이선스도 사용자 불평에 따라 소송으로 막힐 위기임, 남는 대안이 서비스 운영이나 브라우저 광고 뿐이고, 이 역시 욕을 먹고 있음, 포킹도 대안이 아니라 봄, 실질적인 보안과 메인테넌스를 거의 전부 Mozilla 본진이 담당하고 있음, 만약 Mozilla가 망하면 포크도 금방 말라 죽음, 포크가 나와봐야 해당 개발자들은 자금이 없어 성장도 불가능하고, 과거 XUL 기반 애드온 등 취약점까지 다시 되살려 답이 더 멀어진다고 봄
          + 브라우저, MDN, 인증서 신뢰 점검 등이 기금만으론 부족하다는 말에는 동의하지 않음, Mozilla Corporation에선 2023년에 6억5천만 달러가 넘는 수익이 있었고, 소프트웨어 개발엔 2억6천만 달러만 사용함, 유료제 도입이 검색광고 매출과 별 상충되는 것도 아님, 문제의 핵심은 Mozilla가 소프트웨어 외 프로젝트에 집착적으로 돈을 태운다는 점임, 핵심 서비스와 무관한 것에도 마구 투자하고 금방 접음, Firefox와 그 파생 외에 남은 게 거의 없음, 나오다 접힌 프로젝트 숫자가 구글과 비교해도 더 심각함, 20년간 Mozilla에서 나온 것 중 가장 가치 있던 게 Rust(Servo까지)인데, 이것조차 미련 없이 분리, 소프트웨어 회사 운영 원칙이 전혀 없음, 돈 문제가 아니라, 하나라도 제대로 집중해서 실제 사용자가 원하는 제품을 꾸준히 제공했다면, 이런 논의조차 안 나왔을 것임
          + 왜 사람들이 불평하냐면, Mozilla 경영진들이 너무 많이 실책했기 때문임, 명확한 전략이라고는 개발자 해고밖에 안 보임, 모든 부가 서비스와 산만한 것들이 다 비즈니스 쪽 실험에 불과한 느낌임, 제품 중심이 아니라 사업부 중심으로만 조직이 돌아가는 모습임
     * 언어가 사회를 만드는 방법이 흥미로움, free(무료)와 자유(freedom) 의미가 애매하게 혼용되어, FOSS 커뮤니티에 악영향을 준다고 봄, 프랑스어에는 ‘gratuit(무료)’와 ‘libre(자유)’처럼 구분이 명확함, 그래서 “logiciel libre”(자유 소프트웨어)에 돈을 내는 것도 모순적으로 들리지 않음
          + 영어만 무료를 의미하는 단어가 “free”와 겹치는 듯함, 독일어에도 ""kostenlos(공짜)"", ""gratis(공짜)"", ""umsonst(공짜 혹은 헛수고)""처럼 구분이 있음
          + 기술 커뮤니티에서 이 문제에 과하게 신경 쓰는 것 같음, 예전에는 FOSS 자체가 거의 개발자 전용이라 의미 있었지만, 지금은 FOSS 라이선스를 신경 쓸 만한 사람들은 이미 알고 있음, 대다수 컴퓨터 이용자는 그저 업무나 취미 용도로 쓸 뿐, 기기나 소프트웨어 자유 문제는 아예 신경도 안 쓰는 경향임
          + 그럼에도 불구하고, 어떻게 ‘자유’의 이미지를 강조하는 “the land of the free(자유의 나라)”가 “공짜” 의미로 바로 연결되지 않는지 궁금함
          + “Gratis”가 '무료'라는 의미로 영어에도 있으나, 잘 쓰이지 않는다는 얘기임
          + 러시아어도 마찬가지로, 자유(свободный), 무료(бесплатный)가 확실히 구분됨, 무료 소프트웨어는 “свободное ПО”, 무료 맥주(공짜 맥주)는 “бесплатное пиво”임
     * Mozilla Pocket Premium을 결제했지만, 몇 달 만에 서비스 종료 공지를 받았고, 서버도 오픈소스화를 제대로 안 했으며, ‘영구 보관함’ 데이터도 제대로 못 내려받았고, 환불은 6달러만 받음, 영구 보관함 데이터의 일부는 인터넷에서 이미 사라져 실질적으로 영구 소유가 불가능해졌음, 다시는 결제하고 싶지 않은 경험임
          + 실제로 Pocket ‘영구 보관함’이 진짜 데이터 전체를 보관하는 게 아니라, 당시 읽을 수 있던 콘텐츠의 포맷만 저장한 듯함, 일부 사이트는 URL만 남고 유료화, 합병, 서비스 종료 등으로 컨텐츠를 실제로 못 읽게 됨, 관심 있는 사이트만Archive.org 같은 데서 따로 찾으려니 매우 번거로움, Mozilla가 Pocket을 사서 10년도 안 되어 없앤 것에 대한 아쉬움이 큼, 조직 입장에선 임팩트나 수지 탓일 수도 있겠으나, 이런 행보가 반복된다면 다시는 후원하고 싶지 않아짐
     * 브라우저는 컴퓨터에서 가장 사적인 소프트웨어임, 광고주가 우리 웹 서핑 비용을 대신 내는 것보다 직접 돈을 내는 게 상식이라 생각함, Orion browser는 처음부터 이런 유료 모델을 고려해 설계함, 대략 계산해봐도 Firefox 사용자의 5%만 유료 결제자로 전환해도, 구글 검색 매출을 충분히 대체하고, Mozilla가 사용자 중심의 제품으로 혁신할 수 있음, Orion Browser 자세히 보기
          + 대략 2억 명 Firefox 유저와, 구글이 매년 4억 달러 지급한다고 치면, 전체의 7%가 월 $5씩만 내도 서치 딜 수익을 대체할 수 있음
          + 안타깝게도, Kagi는 러시아 기업과 제휴해서 돈이 러시아로 흘러가는 걸로 알고 있음, 우크라이나 사태 이후 그쪽 경제에 보탬이 되는 건 무조건 피함, 원래 Kagi 사용자였지만 그래서 해지함
          + Orion 써봤는데 맥북에어에서 가장 자주 크래시 났던 앱임, 그치만 kagi 검색은 여전히 애정함
          + “모든 걸 광고 보면 무료, 그렇지만 광고는 또 쉽게 막을 수 있음” 모델이 25년간 이어지다 보니, 이제 누구나 공짜 서비스에 당연히 익숙해짐, 이런 사람들에게 직접 서비스를 위해 비용을 내라 하면, 공기값 내란 얘기랑 흡사한 분노가 돌아옴
          + 완전 별개지만, Orion이랑 Onion Browser(토르 브라우저)랑 이름이 너무 비슷해서 순간 헷갈렸음
     * “어떻게 하면 Firefox 점유율을 0%로 만들 수 있을까?”<br>1. 예산을 쓸데없는 사이드 프로젝트에 소진<br>2. 사용자 경험은 외면하고 기능 줄이기<br>3. 가격표 붙여서 유저들 떨어져 나가게 하기<br>4. 훼손 의식으로 강제 2FA, 계정 로그인 강제
          + 5번: Pocket 강요하고, URL 툴바에 공백 넓게 남겨 기본 UI를 불편하게 만들기
          + “사용자가 하는 모든 것에 대해 라이선스를 주장한다”며, 데이터는 절대 팔지 않겠다더니 약속 번복하기 추가
          + 5번: 중요한 개발자 전원 해고 추가
          + Mozilla Corporation이 문제의 핵심이라는 주장임
          + 0번 항목도 있어야 함 — 예산 원천부터 살펴봐야 함 관련 링크
     * Firefox 계정 사용자임, 연 단위 요금제라면 기꺼이 내겠음, 그만큼 충분한 가치를 경험 중임, 예를 들어 Bitwarden에 연 10달러씩 가족 전체가 결제하는 중이고, 아이들이 크면 가족 요금제로 전환할 예정임, 비슷한 구조가 Firefox에도 도입되면 좋겠음, 물론 무료로 쓰고 싶은 사람들을 위한 옵션도 있어야 함, Bitwarden도 무료 플랜이 있으니까, 이미 이런 구조는 시장에서 검증됨, Mozilla는 단순히 제대로 된 좋은 Firefox를 만드는 데 집중만 하면 충분하다고 생각함
          + 왜 그런 구조적 구독 시스템(혹은 Patreon 같은 커뮤니티 지원체계)을 안 만들었는지 모르겠음, 구글 돈이 없어진 후엔 이런 식으로라도 흑자를 도모할 수 있다고 봄
"
"https://news.hada.io/topic?id=21835","로컬-퍼스트 소프트웨어 (2019)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          로컬-퍼스트 소프트웨어 (2019)

     * 로컬-퍼스트 소프트웨어는 클라우드 기반의 협업과 개인 데이터 소유권의 장점을 동시에 실현하려는 접근 방식임
     * 기존 클라우드 앱은 실시간 협업과 접근성에서 뛰어나지만, 데이터 소유권 및 장기 접근성과 같은 문제를 야기함
     * 로컬-퍼스트 소프트웨어는 로컬 저장소를 데이터의 기본 저장 위치로 간주하고, 동기화 및 협업 기능을 부가적으로 제공함
     * 이러한 소프트웨어는 속도, 오프라인 지원, 프라이버시 및 사용자 통제 등에서 이점을 제공하지만, 실시간 협업이나 다기기 동기화 등에서 구현 난이도도 존재함
     * 로컬-퍼스트 소프트웨어를 현실화하기 위해 다양한 기존 기술 모델이 비교·분석되고 있으며, 미래에는 더욱 이상적인 모델이 개발될 가능성 모색 중임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

클라우드 앱과 데이터 소유권의 한계

     * 대부분의 사용자는 Google Docs, Figma, Slack 등 다양한 클라우드 앱을 통해 문서 작성, 설계, 협업 등 여러 목적에 활용함
     * 이러한 서비스는 브라우저 또는 모바일 앱을 통해 접근하며, 대부분 서버에 데이터를 저장함
     * 클라우드 기반 소프트웨어는 협업 및 어디서든지 데이터 접근이 가능한 장점이 있으나, 앱에 시간을 투자할수록 그 안의 데이터 가치가 커짐
     * 전문가들과의 인터뷰를 통해, 클라우드 앱의 기능적 이점 이면에 소유권 상실, 장기 접근성 불확실성 등의 치명적 단점이 있음을 확인
     * 사용자가 직접 창작하거나 생산한 자료 및 데이터를 보존·소유할 권리가 제한된다는 점에서 심리적 불안감과 실제적인 위험 요인이 존재함

데이터 진정한 소유의 의미

     * 클라우드에 저장된 데이터는 ""본인의 것"" 같지만, 실질적 관리·접근 제어 권한은 클라우드 서비스 제공자에게 있음
     * 서비스 제공 중단, 서버 장애 시 데이터 접근 불가 및 장기적 데이터 보존의 어려움 야기
     * 실제 지적 재산권이 아닌, 사용자가 느끼는 데이터 소유감과 통제력이 문제의 핵심임
     * 로컬 저장 중심의 옛날 애플리케이션(텍스트 에디터, 버전 관리, 각종 도구)은 온전한 데이터 소유권과 자율성을 보장함

클라우드와 로컬의 장단점 비교

     * ""클라우드 앱 = 협업·접근성"", ""로컬 앱 = 소유권·자율성""
     * 양자택일이 아니라 하이브리드 방식의 최선의 조합을 추구할 필요성 제기
     * 데이터 소유권과 실시간 협업성이 상충하지 않으며, 둘 다 달성 가능한 소프트웨어 모델이 설계 가능
     * 이를 로컬-퍼스트 소프트웨어로 정의하고, 로컬 저장소·네트워크와 보조적 서버의 조합을 기본 구조로 제안

로컬-퍼스트 소프트웨어의 7가지 이상

     * 클라우드 앱은 서버가 데이터의 “주본” 역할을 함에 따라 매 요청이 서버 왕복을 필요로 하고, 사용자 경험의 지연이 발생함
     * 반면 로컬-퍼스트 소프트웨어는 로컬 저장소의 복사본을 데이터의 기본 버전으로 취급하여, (서버를 통한) 동기화는 부차적으로 처리
     * 이 관점 전환은 응답 속도, 오프라인 지원, 데이터 통제권 등에서 실질적 이점 제공

  1. 속도(빠른 반응성)

     * 로컬-퍼스트 앱은 모든 작업을 로컬 파일 시스템에서 처리하므로, 서버 요청 대기 지연 없이 즉각적인 사용자 반응성 달성 가능
     * 동기화는 백그라운드에서 조용히 처리되어, 어느 순간에도 사용자 경험이 중단되지 않음

  2. 다기기 동기화

     * 현대 사용자는 여러 디바이스에서 작업하므로, 로컬-퍼스트 앱 역시 기기간 데이터 동기화 필수
     * 파일 단위의 동기화는 1인 사용자일 때 용이하지만, 다수 동시 편집 시 충돌(Conflict) 문제가 발생

  3. 오프라인 우선성

     * 로컬-퍼스트 소프트웨어는 오프라인 상태에서 데이터 작성 및 편집이 언제든 가능, 추후 네트워크 복귀 시 자동 동기화
     * 블루투스, 로컬 WiFi 등 다양한 방식으로 기기 간 데이터 공유 및 동기화 가능
     * 진정한 오프라인 지원을 위해 로컬 설치형 실행 파일 형태 선호

  4. 협업 및 충돌 관리

     * 기존 방식(이메일 첨부 파일, 버전 관리 툴 등)은 여러 명이 동시에 같은 파일을 작업할 때 충돌 및 수동 병합의 불편함 존재
     * 클라우드 앱(Google Docs 등)은 실시간 동시 편집 기능으로 협업의 난이도 및 갈등 최소화
     * 로컬-퍼스트 소프트웨어도 실시간 협업, 변경 제안 및 승인 등 다양한 협업 흐름 구현 가능성이 존재하며, 기술적 도전 분야임

  5. 데이터의 장기적 보존

     * 로컬-퍼스트 앱을 사용하면, 소프트웨어 제작사가 없어지더라도 데이터 접근권 보장
     * 형식이 흔한 파일(텍스트, PDF, JPEG 등)은 장기간 호환성을 유지할 수 있으며, 호환 불가능한 포맷이라도 가상 머신이나 에뮬레이터로 접근 가능
     * 데이터의 진정한 장기 보존 없이는, 디지털 암흑기 문제(미래 인류가 오늘날 데이터를 접근·해석 불가)가 현실이 될 수 있음

  6. 프라이버시 및 보안

     * 클라우드 중앙 집중형 구조는 해킹, 내부 직원의 남용 등 다양한 보안 사고에 취약함
     * 개인정보, 민감 데이터 등을 다루는 전문가는 로컬-퍼스트 구조에서 엔드 투 엔드 암호화를 통한 보안과 데이터 독립성 확보 가능
     * 구글 등 대형 기업들은 내부적으로 데이터를 다양한 방법으로 활용할 수 있으나, 로컬-퍼스트 소프트웨어는 데이터 주체에게 통제권 제공

  7. 사용자 소유권 및 통제권

     * 클라우드 서비스 사업자에 의해 임의로 데이터 접근이 차단·제한될 수 있음 (잘못된 자동 플래깅, 정책 변경 등)
     * 로컬-퍼스트 환경에서는 데이터 사용 및 수정, 백업, 보관 등 모든 권리 사용자가 직접 결정
     * 이는 단순히 법적 저작권이 아니라, 사용자의 실질적 자율성과 데이터 통제권의 문제임

다양한 소프트웨어 모델의 비교

     * 이메일 첨부+로컬 파일: 속도, 오프라인, 장기 보존, 통제권에서 우수하나, 협업, 기기 동기화는 불편
     * 클라우드 웹앱(Google Docs, Trello 등): 실시간 협업, 접근성은 뛰어나나, 속도, 오프라인, 소유권, 프라이버시 취약
     * 파일 동기화 서비스(Dropbox 등): 속도, 오프라인, 장기 보존, 통제권은 뛰어나나 협업 및 모바일 환경 한계
     * 버전 관리 시스템(Git 등): 속도, 오프라인, 장기 보존, 통제권에 뛰어나나, 비텍스트 파일·실시간 협업에는 약점
     * 모바일 클라이언트(Firebase, CloudKit 등): 동기화, 오프라인에 강점, 그러나 개인정보, 프라이버시, 장기적 서비스 존속 등에서 한계
     * 멀티마스터 복제 방식(DB, 예: CouchDB): 오프라인 및 동기화에 강점이나, 협업, 프라이버시, 통제권 등 이상 실현이 어렵거나 미흡

소프트웨어 개발자 관점 및 미래 방향

     * 이상적인 로컬-퍼스트 소프트웨어는 초기부터 오프라인, 다기기 동기화, 실시간 협업, 프라이버시, 사용자 통제를 설계/구현해야 함
     * 하지만 현실적으로 모든 이상을 동시에 만족하는 공개 기술은 아직 부재
     * 최신 컴퓨터 과학 연구에서 고안된 신기술(예: Conflict-free Replicated Data Types(CRDTs), 분산 데이터 동기화 방식 등)이 미래 로컬-퍼스트 소프트웨어 실현의 핵심적 기반이 될 수 있음

결론

     * 로컬-퍼스트 소프트웨어는 디지털 시대의 협업성과 독립성, 프라이버시, 그리고 데이터 주권의 균형을 실현할 수 있는 중요한 방향성임
     * 전문가, 크리에이터 등에게 데이터에 대한 소유 감각과 장기적 보호를 제공하며, 나아가 전 산업 분야 전반에서 긍정적 변화 창출 전망
     * 앞으로는 이러한 이상을 실현하는 더 나은 인프라와 개발 도구, 아키텍처, 알고리듬의 연구·실험이 지속될 필요성이 있음

        Hacker News 의견

     * 정말 공감 백배 느낌 공유. 나 역시 이런 문제 해결을 위해 개발 중이고, 내 정보를 클라우드에 넣어서 구독료만 내는 방식 질림. 지금은 fitness tracking 앱 만들고 있는데, Sublime 모델 적용 예정. 처음에 한 번 구매, 몇 년간 업데이트 제공, 모든 기기와 동기화, 평생 사용 가능. 이후 업데이트 원하면 새 버전 다시 구매로 충분. 충분히 좋은 퀄리티라면 그 상태로 쭉 사용 가능 목표. 전체 소프트웨어 중 90%는 이 모델을 원함. 정당한 가격에 살 수 있고, 제품 자체가 좋아야 하며, 클라우드 연동 없어도 제대로 작동하는 구조 중요. 데이터 프라이버시뿐만 아니라 이 모델에는 많은 장점 존재. 아직 툴링 등 과제 남아있지만 기술적 토대는 충분. 로컬-퍼스트 소프트웨어의 가장 큰 장점은 건전한 인센티브 구조. 광고·유저 트래킹·‘관여도’ 극대화 아닌, 제품
       자체로 보상받는 구조이기 때문. 진정 사용자 중심 소프트웨어라는 느낌.
          + Obsidian 노트앱 모델도 정말 좋은 본보기. 클라이언트는 무료, 동기화 서비스는 선택사항으로 판매. 노트는 마크다운 파일이라서 굳이 클라이언트 필요 없다는 점 강점.
          + 클라우드 인프라를 쓰지 않고 동기화 처리는 어떻게 계획 중인지 궁금.
          + 완전 공감. 혹시 괜찮으면 fitness tracking 앱의 tech stack 정보도 궁금. 특히 크로스 디바이스 동기화 처리 방식이 궁금.
          + 광고로 수익화하는 순수 로컬 앱도 많기 때문에 ‘광고 안 붙임’이 항상 성립하는 건 아님.
     * 지금 베를린에서 Local-first Software 컨퍼런스(https://www.localfirstconf.com/)가 Ink and Switch 주최로 활발히 열리고 있고, 올해 11월 샌프란시스코에서 Sync Conf(https://syncconf.dev/)까지 생겨남. 최근 컨퍼런스에서 논문 공저자들이 직접 패널 토론도 해서, 로컬-퍼스트 소프트웨어의 개발 도구 맥락에서 배운 점을 이야기해 유익. 패널 토론 영상 강추. 지금 커뮤니티에서는 “Sync”가 local-first의 핵심 요소라고 자리잡는 중이고, 동기화 엔진 같은 dev tool은 local-first 특성 기술의 지원 도구일 뿐 그 자체가 local-first는 아니라는 흐름. 최근 몇 년간의 전체 강연 모음도 여기 업로드됨. 리얼타임·비동기 협업 지원 도구 개발이 활활 진행 중이며, 최근 AI 등장으로 이런 동기화 엔진이 점점 더 필요해지는 시장 환경 형성. AI 앱은 본질적으로 멀티유저 협업 환경이라 동기화 엔진
       커뮤니티의 기술적 기반이 요구되는 시대.
     * 이 주제 관련해서 예전에도 엄청 활발한 토론 있었으니 궁금하다면 읽어볼 가치 있음: 2019-05, 191 댓글
       2019-11, 241 댓글
       2020-07, 9 댓글
       2020-08, 134 댓글
       2021-02, 90 댓글
       2022-06, 30 댓글
       2023-10, 50 댓글
     * 모든 앱이 각자 자체 sync 플랫폼을 가질 필요 없음 주장. 이 흐름은 모바일앱 특유의 프로그램간 조합·모듈화 어려움에서 비롯된듯. 진짜 local-first를 원한다면 파일 시스템을 쓰면 됨. 유저 입장에서는 git, box 등 다양한 기존 솔루션을 직접 선택하면 됨. 각 앱의 sync 가입 절차 자체가 SaaS만큼이나 불투명하고 망가지기도 쉬워서 부담.
          + 모든 앱이 sync 엔진 필요하지 않다는 점엔 동의하지만, 파일 시스템이 local-first의 만능 해법이라고 보진 않음. 이유가 둘 있음. 첫째는 concurrency. 진짜 local-first로만 가면 아무 sync나 써도 되지만, 그 이상을 원함. 예를 들면 내 아내랑 둘이서 통신두절 상황에서도 각자의 폰에서 독립적으로 수정하고 이게 자동으로 잘 합쳐지는 경험 원함. DropBox처럼 정말 자연스러운 동기화 바람. 둘째는 데이터 구조·의미를 동기화 엔진이 깊이 알아야 더 나은 sync 경험 구현. git이나 box는 이런 의미적 동시편집 욕구 앞에 여러 한계 존재.
          + 실제로 파일 시스템만 사용하는 방식 구현해봤는데, 언제 파일 편집 허용할지 클라이언트 간 조정이 어려워서 결국 파일 충돌 이슈 불가피.
     * 온라인 의존성 가진 시스템은 필연적으로 유지·운영 비용 수반. local-first, local-only 설계가 아니면 오래 신뢰할만한 시스템 불가. 연결형 가전과 자동차류는 실용성 관점에서 진짜 바보 같은 엔지니어링 사례.
          + 이 모든 흐름은 결국 구독 수익 때문. 구독 모델 가진 회사가 그렇지 않은 회사보다 매출도 많고, 투자도 더 잘 받아서 시장에서 이김. 이게 바로 local-first 소프트웨어가 사라진 이유.
     * 나는 오히려 클라우드 신뢰성 문제를 기술적으로(중앙 집중식 구조 회피) 풀려는 시각에 비판적. 예전에는 폐쇄형 소프트웨어의 통제 불가, 신뢰 불가 문제를 비즈니스 모델(오픈 소스 개발, 유지보수 계약 등)로 해결해왔음. 클라우드 문제에도 이런 비즈니스 모델 해법이 필요함 주장. 예를 들면 표준 계약·라이선스 만들어서 사용자의 권리 명시하고, 이런 인증 라이선스 실행하는 벤더만 선택하도록 시장을 유도할 수 있음. 사용자의 데이터 이관 보장, 투명한 데이터 사용 내역 공개, 서비스 종료시 처리 절차 명시 등 수많은 조항 추가 가능. 물론 가장 큰 난관은 이런 제도를 벤더들이 왜 받아들이겠냐는 점. 벤더들은 고객 이탈을 두려워해서 이런 라이선스 제공시 연간 구독만 허락하거나, 추가 비용 요구 가능성.
          + 비즈니스/정치적 문제를 기술적 해결로 접근 가능한 경우, 오히려 더 견고한 방법이라고 생각. 적대적 이해관계를 아예 기술적으로 봉쇄할 수 있기 때문. 암호화(client-side encryption)가 대표사례. 프라이버시 정책이나 관료적 규칙에 의존하기엔 유혹이 너무 많고 감시·적발도 어렵기 때문. 만약 데이터가 수학적으로 서버에서 읽히지 않게 암호화되어 있다면 걱정거리가 사라짐. 다만 서버에서 데이터를 실제로 처리하려는 경우에는, 실제로 자신의 서버만 써야 하는 상황 발생.
          + 예를 들어 종료시 계약 등으로 해결한다해도, 클라우드 서비스 업체가 폐업해서 공지하고 데이터 내보내기만 진행하면 결국 남는 건 거대한 JSON 파일뿐. 직접 앱 만들거나 누군가가 만들어주지 않으면 사실상 쓸모 없음. 의도는 좋지만 수명이 다한 앱의 데이터를 장기 지속적으로 쓰게 해주는 로컬 앱보다 부족한 점 존재.
          + 데이터 이관 보장 조항도, 실제 대규모 데이터 이전은 현실적으로 어렵고 시간이 오래 걸림. 위기 상황에서 급하게 하면 더 엉망 됨. 동일버전 오픈소스DB끼리도 서비스마다 변수가 많아서 쉽지 않음. 결국 데이터를 처음부터 자신의 환경에 보관하고 필요시 '언플러그'하는 구조가 현실적 대안. BYOC(가져온 클라우드)와 오픈소스의 조합 가능성. 우리 회사도 BYOC 데이터 상품 운영중이라서 이 구조가 실제로 가능하다는 점 경험함.
          + 클라우드 서비스 종료시 계약서로 책임 명시해도, 막상 폐업 결정 나면 실제로 집행하고 관리할 방법이 마땅히 그려지지 않음.
          + 비즈니스 이슈만이 아니라 데이터 안전 자체도 문제. 구독이나 클라우드 모델을 피하는 주 이유는 내 데이터 보호 욕구. 로컬 암호화없이 전송되는 데이터는 정말 언제든 털릴 수밖에 없음.
     * 이 글 읽으니 신선함 느낌. 더 많은 앱이 local-first가 되어야 한다고 생각. 사용자가 클라우드 동기화를 원하지 않으면 반드시 그 옵션이 보장되어야 함. 내가 만드는 Brisqi(https://brisqi.com)도 이런 offline-first 철학 기반인 앱. local-first 앱이란 기본적으로 오프라인에서 무기한 완벽히 작동하는 구조를 의미. 오프라인 경험이 기본이고, 클라우드 sync는 부가적 개선사항임. 임시 캐시 기반 앱은 offline-first라 볼 수 없음. local DB에 데이터를 저장, 진정한 offline-first는 데이터가 인터넷과 무관하게 보존되는 구조. 대다수 “offline-first”라는 앱은 오히려 offline-tolerant(한정적 오프라인 지원)에 불과. offline-first 앱 만들기는 online-only 웹앱보다 훨씬 더 까다로움. 오프라인-온라인 전환상황에서도 데이터 손실없이 확실하게 동기화되는 메커니즘 필수. 내 구현 방법은 블로그
       참고(https://blog.brisqi.com/posts/how-i-designed-an-offline-firs...).
     * 이런 원칙들이 소비자 대상에 집중돼도 의미 있음. 우리는 현재 Sentinel Devices(www.sentineldevices.com)에서 SCADA/산업 자동화 등 데이터를 절대 외부에 내보낼 수 없는 산업 현장에 완전 local 실행, 분석, 의사결정이 모두 자기 장비에서 일어나는 구조 개발 중. 외부 서버 자체를 제공하지 않음. 이렇게 온디바이스 원칙에 집중하는 구조가 약간 뇌리를 깨부수는 경험을 고객과 벤더 모두에게 줌. 많은 데이터/AI 기업들이 실제로 고객 현장에 서비스 제공이 너무 어렵다는 이유로 이런 시장 무시. 그런데 우리는 노코네티비티, 완전 로컬 처리임을 강조해야 고객이 이해하는 상황 자주 발생. 이런 현상이 소비자 영역에서 로컬-퍼스트 익숙해진다면, 산업 분야도 더 빠르게 변혁.
          + SCADA 업계조차 최근 모두 클라우드로 몰아가기 중. “공장을 스마트폰에서 관리하세요”라는 캐치프레이즈. 하지만 이제 단순한 취미 해커에게도 공장 제어가 열리는 상황 위험성 증대.
          + 이 분야 무척 흥미롭고, 활동 응원. 한 가지 궁금한 점은 커리어 페이지 보니 전원 비원격(onsite)만 채용. local-first 개발이 실제로 오프라인 근무 필요해서 그런 건지, 또는 경영 이슈 때문인지 궁금.
     * 내가 하는 프로젝트(selfhostblocks, skarabox)도 NixOS 기반으로 누구나 쉽게 셀프호스팅하도록 목표. https, SSO, LDAP, 백업, ZFS 스냅샷 등 거의 모든 걸 선언적으로 제공. Vaultwarden, Nextcloud 등 대부분의 데이터를 저장할 수 있고, Home assistant 같은 서비스도 포함. YUNoHost의 경쟁구도인데, 더 나은 목표. SelfHostBlocks는 여러 패키지 빌딩블록 형태로 누구나 자유롭게 확장·자체호스팅 가능. 프레임워크라기보다는 라이브러리식 접근. NAS 대안이기도 한데 완전 오픈소스. 기술 지식 있는 사람에겐 쉬울지 몰라도 (nix나 CLI 없이) 일반인도 하드웨어에 깔 수 있도록 진입장벽 없애는 게 목표.
          + 이런 프로젝트 정말 응원. 놀라운 FOSS(오픈소스) 대안이 엄청 많은데, 사실상 기술자만 쉽게 설치 가능(“docker compose up” 수준)이라 일반인에겐 벽 존재. 많은 셀프호스팅 가능 앱이 웹앱+DB+서버+프론트엔드 구조인데, 나 같은 경우는 사실상 한 대 기기에서만 씀. 완전 로컬 데스크탑 프로그램이면 충분한데, 실제로 개발자가 아니라면 그조차 넘사벽인 상황. 고품질 셀프호스팅 FOSS와 실사용자 사이에 분명한 미스매치 존재. 이런 간극을 해소하는 프로젝트가 더 필요. 나도 selfhostblocks 사용해볼 예정, 발전 응원.
          + hledger 포함된 점 너무 좋음. 플레인텍스트 회계류 입문자에겐 약간 생소해도, 굉장히 훌륭한 소프트웨어.
          + 깔끔하게 잘 만들어줘서 정말 고마움 느낌.
     * 본문을 훑어보니 핵심 포인트 대부분 짚었지만, 첫 문단의 모티브가 약하게 느껴짐. “애플 파이는 맛있고 영양가도 있지만, 언젠가는 갑자기 불타 없어져 내가 아끼던 턱받이까지 사라질 수 있음” 같은 얘기로 읽힘.
"
"https://news.hada.io/topic?id=21851","40년 전 제기된 수학적 추측을 17세 소녀 Hannah Cairo가 반박함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               40년 전 제기된 수학적 추측을 17세 소녀 Hannah Cairo가 반박함

     * Hannah Cairo는 40년 전 제기된 Mizohata-Takeuchi 추측을 반박하는 반례를 고안함
     * 이 추측은 조화해석(harmonic analysis) 분야에서 오랜 기간 입증되지 않은 주요 문제로 여겨졌음
     * Cairo는 프랙탈과 다양한 도구를 활용해 엄밀하게 접근하며, 반례 구성에서 큰 창의성을 발휘함
     * 그녀는 체계적인 수학 커뮤니티의 지원과 교수진의 조언 속에서 연구를 이어감
     * Cairo는 앞으로도 대학원 연구와 함께 젊은 수학 인재 양성에 힘쓸 예정임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Hannah Cairo와 Mizohata-Takeuchi 추측의 반박

  # 문제 해결 배경과 과정

     * Hannah Cairo는 수주간 수학적 문제에 몰두함
     * 결과를 증명하려고 시도한 끝에, 해당 주장의 보편적 진실성에 의문을 품게 됨
     * 여러 번의 실패 끝에 프랙탈 등 다양한 도구를 활용해 반례를 구성함
     * 교수 Ruixiang Zhang을 설득하는 과정이 필요했으며, 신중히 모든 논증을 준비함
     * 최종적으로 반례 제시를 통해 Mizohata-Takeuchi 추측이 보편적으로 성립하지 않음을 증명함

  # Mizohata-Takeuchi 추측과 그 중요성

     * Mizohata-Takeuchi 추측은 1980년대에 제기된 문제로, 조화해석 내에서 큰 의미를 가짐
     * 이 추측에 대한 일반적 합의가 있었다면, 여러 중요한 결과들이 자동적으로 증명됨
     * 반례 제시로 수학계는 큰 놀라움과 환영을 표함
     * Cairo는 고등학교 재학 중이었으며, 나이에 비해 비범한 성취를 보임

  # 수학적 성장 배경

     * Bahamas 출신의 Cairo는 UC Berkeley 수업에 직접 참여 요청해 교수들과 교류함
     * Zhang 교수가 제안한 과제로 이 추측에 관심을 갖게 되었고, 과제의 선택적 항목으로 포함됨
     * 추측의 단순한 케이스가 숙제로 주어졌지만, Cairo는 그 이상의 원본 추측에 집착함

  # 조화해석 및 Fourier 분석이란

     * 조화해석은 함수를 단순한 파동(정현/코사인 함수 등) 으로 분해하는 수학 분야임
     * 이 분야는 19세기 Joseph Fourier의 열방정식 연구에서 출발함
     * Fourier 급수로 복잡한 현상 설명이 가능해졌으며, 현재는 디지털 파일 압축 · 통신 설계 등 다양한 응용 분야에서 핵심 도구 역할을 함
     * Fourier 제한 문제는 제한된 파동만으로 어떤 구조를 만들 수 있는지를 연구함
     * Mizohata-Takeuchi 추측은 특정 파동만 활용할 경우 선으로 이루어진 형태만 생성된다고 주장함

  # 반례 발견 및 연구 경험

     * Cairo는 첫 반례를 얻은 후 전체 문제를 주파수 공간에서 다시 구성함
     * 새로운 관점으로 단순한 반례 설계 방식도 재발견함
     * 2024년 엘 에스코리알에서 개최된 조화해석 및 편미분방정식 국제학회에서 자신의 결과를 발표함
     * 다양한 연구자들과의 교류를 통해 수학적 토론을 즐기며, 공개 강연 및 학생 지도에 깊은 흥미를 느낌
     * 어린 시절부터 수학책을 독학했고, 대수학에서 시작해 점차 조화해석으로 관심 분야를 확장함

  # 수학 커뮤니티와 미래 계획

     * COVID-19 기간 Berkeley Math Circle 온라인 캠프에 참가해 탁월한 수학적 재능을 인정받음
     * 이후 해당 프로그램에서 강사 역할도 경험함
     * 2024년 가을부터 University of Maryland에서 박사과정 시작 예정이며, Zhang 교수의 지도하에 계속 연구를 이어갈 예정임
     * 향후 젊은 수학 인재 발굴과 육성에 기여할 계획임
     * ICMAT 및 다양한 국제 수학 프로그램이 Cairo와 같은 재능 있는 인재 지원을 목표로 함

  # 결론 및 영향

     * Hannah Cairo의 성과는 젊은 창의성과 탐구 의지가 중요한 혁신의 원동력임을 보여줌
     * 수십 년간 입증되지 않았던 수학적 가설이, 새로운 시각과 도전으로 극복됨

        Hacker News 의견

     * Hannah Cairo가 해당 추측과 자신의 결과를 설명한 영상이 있음 유튜브 영상 링크 Terence Tao가 과거에 추가 연구가 있을 것이라고 암시했는데, 이 부분에 대해 더 알고 있는 사람이 있는지 궁금함 Tao의 관련 글
          + 아마도 여기서 말한 추가 연구라는 게 Terence Tao의 블로그 포스트인 듯함 블로그 글
     * 매우 뛰어난 실력을 가진 사람임에는 틀림없지만, 십대가 이런 업적을 낸 것이 그리 놀랍지는 않음 주요한 수학적 발견은 종종 20대 초·중반에 나왔고, 특히 젊은 20대나 십대일 때가 많았던 이유는 순수수학이라는 분야가 근본적으로 매우 창의적인 분야이기 때문임
          + 현재의 학술 시스템은 주 연구자를 다음 연구비 신청지에 쏟는 시간 등 비효율적 요소가 많음 이 시스템은 장기적 시도보다는 단기적 성과에만 집중하게 만들어 연구소 같은 특별한 환경을 제외하면, 젊은 사람들이 오히려 더 명확하게 사고할 수밖에 없는 구조임
          + 젊은 수학자들이 위대한 성취를 한다는 주장에 대해 항상 의문이 생김 역사적으로도 그랬는지, 혹은 지금도 그런지 잘 모르겠음 예를 들어 Andrew Wiles는 페르마의 마지막 정리를 40대에 증명한 사례가 있음 실제로 나이 많은 수학자들도 대단히 생산적이었음 그리고 이 주장은 주로 화려한 난제에만 초점을 맞추는 면이 있음, 여러 분야 연결과 구조적 통찰 등은 오랜 경험이 필요함
          + 20대가 주요 업적을 낸 경우는 Evariste Galois가 프랑스 혁명 전후에 한 번 있었던 일임 십대? 실제로 그런 예는 거의 없음
          + 아마 처음엔 문제 푸는 것이 재밌었겠지만, 직업적으로 매일 문제만 풀다 보면 쉽게 지루해질 수 있음
          + Fields Medal은 만 40세 이하에게만 수여된다는 사실도 있음
     * 나이가 몇이든 수학에서 오리지널하고 새로운 무언가를 시도한다는 것 자체가 극도로 어려운 일임 그런 일을 17세에 했다는 것은 천재성 그 자체 축하 인사임
          + 오리지널한 무언가는 모든 분야에서 어려운 점임
     * 보통 배우는 사람 나이보다 훨씬 어릴 때 무언가를 만든 사례는 얼마나 되는지 궁금함 Euler는 41세에 유명한 오일러 공식(학교에서 배우는 수준)을 발견했고 Newton은 21세에 미적분을 창안(고등학생~대학생 수준)함 Galois는 20세에 사망했고, 그의 이론은 대학교 2~3학년쯤에 배우는 걸로 알고 있음
          + 내가 영국에서 대학을 다닐 때 Galois Theory는 대학 3학년(20~21세)에 듣는 과목이었음
     * ""어느 날 교수님이 이 추측의 더 쉽고 특별한 경우를 숙제로 내주었다""에서 느낀 교훈은 항상 누군가가 빛날 기회를 주라는 점임
          + 나도 대학 신입생 때 Collatz 추측 같은 “간단한” 문제들을 처음 접했을 때 기억이 남음 단순히 보이는 문제엔 반드시 쉬운 해법이 있을 거라 기대했었음 몇 년 지나고 지적 한계를 깨닫고 나서는 실용적인 문제에서 성취감을 찾게 됨 당시 신입생인데도 진지하게 도전할 수 있어서 좋았고, 현실에 매몰되기 전엔 꼭 어려운 문제에 도전해보는 것이 중요함
          + 나도 모든 어려운 문제를 후배들에게 맡기는 방식임
     * “이 추측이 사실이라면 여러 중요한 성과들이 자동으로 증명되는 셈이었고, 커뮤니티는 열광했지만 동시에 놀람, 왜냐하면 이것을 증명한 사람이 고등학교도 졸업하지 않은 17세였기 때문” 이런 식으로 쓴 기사 문장이 많이 아쉬움 만약 추측이 참이라고 다들 믿었다가 반례가 나온 거라면 그 자체로 뉴스거리인데, 기사에서 언급이 너무 약함 ""다른 중요한 결과들""도 설명을 조금 더 추가했어야 했음 그리고 스페인 아카데미 언급은 왜 나오는지 모르겠음 연구자는 바하마/미국 출신이고 스페인 기자가 현지 이야기를 쓰는 듯함
          + 기사에서 그녀의 성이 첫 문단부터 오타로 잘못 표기되어 있음
          + 너무 과하게 지적할 필요는 없음 El Pais는 스페인 언론임 맥락과 독자를 고려하는 게 우선임 이건 수학 문제 뉴스이면서도 동시에 젊은 수학자 스토리, 수학 컨퍼런스(스페인에서 열렸음)에서 있었던 일 등 다양한 맥락으로 읽어야 함
     * 논문은 여기 있음 arxiv 논문 링크 대학원에서 조화해석 강의를 들을 기회가 있었지만 당시 내 연구와는 거리가 있어 포기했던 경험이 있음
          + 난 오늘 뉴욕타임즈에서 처음 X-Ray Transform을 접했고 여기서 또 보게 됨 뉴욕타임즈 수학 관련 기사
     * 이런 질문이 있음: 그녀가 이번 가을에 Ph.D. 과정을 시작하는데 이미 졸업할 정도의 성취 아닌가? 수십 년된 문제를 푼 사람이 왜 또 ""두 번째""로 뭔가 해야 지식 확장을 증명하는지 궁금함
          + Ph.D.란 연구 방법을 배우는 과정임 아주 어려운 한 문제를 푼다고 그 과정을 생략할 수 있는 건 아님 특히 반례를 만드는 건 실력보단 재능과 운의 영향도 있음 박사 이후 학계에 남으려면 포스트닥이 필요한데, 그러려면 지속적으로 논문을 내고 연구 방향을 잡을 줄 알아야 함
          + 그렇다면 17세에 박사를 받으면 뭘 할 수 있냐는 의문이 생김 이렇게 어린 나이에 교수를 뽑는 건 쉽지 않음 이미 좋은 연구를 했으니 몇 년간 멘토링과 협업하면서 비수학적 노하우를 쌓는 것도 나쁘지 않음
          + Ph.D.란 지능이나 업적뿐 아니라 인내력의 의미도 큼
          + 미국의 박사학위는 연구 이외에도 다양한 수업 이수 과정을 포함함 그녀가 그런 과정에서 배우고 싶어서일 수 있음 특히 유럽 대학 중에는 논문만으로도 박사 주는 프로그램이 있으니 이미 올린 논문 arxiv 원문 PDF 링크 를 박사학위 논문으로 제출해서 졸업하는 방법도 있음, 때로는 지도교수조차 필요 없음
          + 이건 복잡한 이론이 있는 게 아니라, 행정적 관성일 뿐임
     * 해당 기사 아카이브 링크
"
"https://news.hada.io/topic?id=21959","Pennybase - 초경량 파일 기반 오픈소스 BaaS","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Pennybase - 초경량 파일 기반 오픈소스 BaaS

     * Go 표준 라이브러리만으로 1,000줄 미만의 코드로 구현된 초소형 BaaS(Backend-as-a-Service)
     * Firebase/Supabase/Pocketbase와 유사한 핵심 백엔드 기능을 로컬 파일 기반으로 제공
          + CSV에 버저닝된 레코드를 사용한 파일 기반 데이터 저장
          + JSON을 리턴하는 REST API
          + 세션 쿠키와 Basic Auth 기반의 인증
          + RBAC 및 소유자 기반 권한 시스템 지원
          + 스키마 검증
          + Go 템플릿 기반 템플릿 렌더링

작동 방식

     * 데이터 저장
          + 모든 데이터를 사람이 읽을 수 있는 CSV 파일에 한 행당 한 레코드씩 저장
          + 첫 번째 컬럼은 레코드 ID, 두 번째 컬럼은 버전 번호로 고정
          + 저장 방식은 append-only로, 기존 레코드를 덮어쓰지 않고 업데이트할 때마다 항상 새 버전 행을 추가
          + 읽기 작업 시 항상 가장 최신 버전의 레코드만 사용
          + 빠른 조회와 업데이트를 위해, 각 리소스별 최신 버전 레코드의 파일 오프셋 정보를 메모리 인덱스로 유지함
s1,1,_permissions,_id,text,,,^.+$
s2,1,_permissions,_v,number,1,,
s3,1,_permissions,resource,text,,,^.+$
s4,1,_permissions,action,text,,,^.+$
s5,1,_permissions,field,text,,,^.*$
s6,1,_permissions,role,text,,,^.*$
s7,1,_users,_id,text,,,^.+$
s8,1,_users,_v,number,1,,
s9,1,_users,salt,text,,,
s10,1,_users,password,text,,,^.+$
s11,1,_users,roles,list,,,
s12,1,todo,_id,text,,,^.+$
s13,1,todo,_v,number,1,,
s14,1,todo,description,text,0,0,"".+""
s15,1,todo,completed,number,0,1,""""

     * 사용자 및 권한 관리
          + 사용자 인증 정보와 역할(Role) 목록은 _users.csv 파일에 저장
admin,1,salt,5V5R4S...====,""admin""
alice,1,salt,PXHQWN...====,

          + 모든 리소스와 동일한 CSV 구조이나, 컬렉션명이 _users
          + API로 사용자 생성이 불가하며, 반드시 파일을 직접 편집해야 함
     * 권한 관리
          + 리소스별 접근 제어 규칙을 _permissions.csv에서 정의
p1,1,todo,read,,*,""인증된 누구나 ToDo 읽기 가능""
p2,1,todo,create,,*,""인증된 누구나 새로운 ToDo 추가 가능""
p3,1,todo,update,owner,""admin,editor"",""admin/editor ToDo 갱신 가능""
p4,1,todo,delete,owner,""admin,editor"",""admin/editor ToDo 삭제 가능""

          + 각 행이 한 개의 권한 규칙을 의미

REST API

     * _schemas.csv에 정의된 리소스(컬렉션)를 기반으로 REST API를 자동으로 제공
     * GET /api/{resource}?sort_by={field} : 해당 리소스의 모든 레코드를 조회, 정렬 가능
     * GET /api/{resource}/{id} : 특정 ID를 가진 단일 레코드 조회
     * POST /api/{resource} : 새 레코드 생성, ""create"" 권한 필요
     * PUT /api/{resource}/{id} : 기존 레코드 수정, ""update"" 권한 필요
     * DELETE /api/{resource}/{id} : 특정 레코드 삭제, ""delete"" 권한 필요
     * GET /api/events/{resource} : 해당 리소스의 서버-사이드 이벤트(SSE) 실시간 스트림 구독, ""read"" 권한 필요
     * 인증 방식
          + API 요청 인증은 Basic Auth 또는 세션 쿠키 방식 지원
          + 세션 쿠키 생성:
               o POST /api/login에 username과 password를 body에 담아 요청
               o 응답에 세션 쿠키가 포함되어, 이후 요청 시 자동 인증
          + 로그아웃:
               o /api/logout 호출 시 세션 무효화 및 쿠키 삭제

정적 파일 및 템플릿

     * static 디렉터리 내에 위치한 HTML, CSS, JavaScript 등 정적 파일을 직접 서빙할 수 있음
          + 예시: static/index.html 파일을 http://서버주소/index.html로 접근 가능
     * 추가로, Go의 html/template 패키지를 활용하여 HTML 템플릿 렌더링도 지원함
          + 템플릿 파일은 templates 디렉터리에 위치하며, URL로 접근 시 자동 렌더링 제공
     * 템플릿에서 사용할 수 있는 데이터 및 함수
          + .User: 현재 인증된 사용자 정보(인증되지 않았으면 nil)
          + .Store: Pennybase의 스토어 인스턴스(리소스 조회, 목록화에 사용)
          + .Request: 현재 HTTP 요청 객체
          + .ID: 접근 중인 리소스의 ID(해당되는 경우)
          + .Authorize: 특정 리소스에 대한 액션 권한을 확인하는 함수

훅(Hooks) 기능

     * 단일 훅(hook) 함수로 동작을 확장할 수 있음
     * 훅 함수는 모든 리소스의 생성(create), 수정(update), 삭제(delete) 작업 시 자동 호출됨
     * 동작 원리
          + 훅 함수는 아래 네 가지 인자를 받아 동작:
               o trigger: 액션 종류(예: create, update, delete)
               o resource: 작업 대상 리소스명
               o user: 요청을 수행하는 사용자 정보
               o res: 변경되는 리소스 데이터
          + 후킹 지점에서 추가 검증 또는 데이터 수정을 할 수 있음
               o 예시처럼 메시지 리소스 생성 시 자동으로 author, 생성 시각을 입력
               o 훅 함수에서 에러를 반환하면 해당 액션은 즉시 중단되며, 클라이언트에 에러 응답이 전달됨
               o 이를 활용해 권한 추가 체크, 데이터 자동 보정, 외부 이벤트 트리거 등 다양한 커스텀 로직 구현 가능

제한 및 주의점

     * 모든 사용자/권한/스키마 관리는 CSV 파일 직접 편집 필요
     * 대규모 데이터, 복잡한 권한 분기, 고성능 분산환경엔 적합하지 않음
     * 외부 라이브러리 없이 오직 표준 Go 코드만으로 동작(학습용/간이용 지향)
     * MIT 라이선스, 소스 코드 및 구조 자유 활용 가능
     * 기여는 환영하지만 코드 단순성/명료성을 유지하는 것을 지켜 줄 것. 더 이상의 기능 추가보다는 버그 수정 위주로 관리예정

   wow...
"
"https://news.hada.io/topic?id=21869","리더를 적극적으로 활용해라. 어떻게든 해내기 위해서 [번역글]","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   리더를 적극적으로 활용해라. 어떻게든 해내기 위해서 [번역글]

    1. 핵심 메시지
          + 중요한 역할을 맡은 사람에게 요구되는 것은 ‘최선을 다하는 것’이 아니라 ‘반드시 결과를 내는 것’이다.
    2. 리더를 적극적으로 활용하라
          + 어려움이 있을 때 혼자 해결하려 하지 말고, 리더에게 직접적으로 도움을 요청하는 것이 필요하다.
          + 리더의 개입이 문제 해결에 결정적인 역할을 할 때가 많다.
    3. 도움을 요청하는 것에 대한 오해
          + 도움을 요청하는 것이 능력 부족이나 실패의 신호로 보일까 걱정할 필요 없다.
          + 오히려 솔직하게 상황을 공유하는 사람이 더 신뢰를 얻는다.
    4. 리더의 개입이 가져오는 효과
          + 리더가 우선순위를 명확히 짚어주는 것만으로도 막힌 문제가 풀릴 수 있다.
          + 리더 입장에서도 직접 개입하며 문제의 원인을 파악하고, 재발 방지책을 마련할 수 있다.
    5. 모든 문제가 쉽게 풀리지는 않음
          + 모든 문제가 리더의 개입으로 즉시 해결되지는 않지만, 문제를 솔직하게 공유해야 현실적인 기대치를 가질 수 있다.
          + 완벽한 환경이 오기 전까지는, 필요하다면 주저하지 말고 도움을 요청해 반드시 결과를 만들어내야 한다.

   어느 책이나 글귀를 봐도
   3번에 대한건 늘 저렇게 적혀 있지만
   실제로는
   왜 이런걸 물어보지
   왜 이제서야 언급하지
   이런것도 물어보나
   3단 콤보에 질 낮은 파트너로 인식될 가능성

   이 다분합니다
   물론, 좋은 리더라면 친절하게 듣고
   정확하게 문제를 해결해줄겁니다

   그래서 좋은 리더가 귀하죠

   도움을 구하는것도 능력입니다

   회사 생활 안해본 것 같은 넘 이상적인 글이네 ㅎㅎ

   ㅎㅎ 그런가요 저 글의 원 저자는 Meta CTO Andrew Bosworth 입니다.!

   (한국) 회사 생활인가요? ㅋㅋ
"
"https://news.hada.io/topic?id=21844","해커가 나에게서 훔쳐간 것","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             해커가 나에게서 훔쳐간 것

     * myNoise는 혼란스러운 세상에서 직접 방문하고 싶을 만큼 긍정적인 인터넷 공간을 만들고자 시작한 개인 프로젝트임
     * 최근 사이트에 수십만 건의 공격 시도가 있었고, 이는 코드 주입 시도 및 서버 리소스를 소모시키는 방식이었음

  공격의 과정과 영향

     * myNoise는 기존 CMS가 아니라 직접 개발한 구조라 코드 주입 공격은 막을 수 있었음
     * 그러나 해커는 전략을 바꿔 사운드 파일을 반복적으로 무의미하게 다운로드하여 서버 트래픽을 소모하는 방식으로 전환함
     * 운영자는 방문자의 에너지 사용을 상쇄하기 위해 매년 나무를 심는 등 환경을 배려하려고 노력해왔으나, 이런 공격은 오히려 이런 노력을 조롱하는 듯한 허무함을 남김

  파괴와 창조의 불균형

     * 이러한 경험은 “무언가를 만드는 데 드는 노력보다, 무너뜨리는 데 필요한 에너지가 항상 적다”는 엔트로피의 법칙을 다시 떠올리게 함
     * 병으로 인한 신체의 파괴와 회복의 어려움, 그리고 타인에 의해 의도적으로 발생한 피해의 차이에 대한 허탈함과 슬픔을 함께 느끼게 됨
     * 이런 파괴는 단순한 서버 공격을 넘어서, 에너지, 시간, 심리적 평온까지 앗아감

  작은 선한 변화의 의미

     * 최근에는 둥지에서 떨어져 다친 비둘기 새끼를 가족이 돌보며 건강하게 자연으로 돌려보낸 경험을 떠올림
     * 이런 작은 긍정적인 행동이 삶의 의미를 느끼게 해줌
     * 하지만 언제나 이런 선한 노력을 방해하는 이가 있을 수 있다는 불안도 함께 내재함

  마무리와 다짐

     * 이번 공격으로 서버는 무너지지 않았지만, 내 시간과 에너지, 그리고 남은 평온이 도난당한 기분임
     * 새로운 사운드를 만들고, 조용한 환경을 조성하며, 선한 변화를 만들어내려 했던 시간이 방어와 복구, 대책 마련에 소진됨
     * 그럼에도 불구하고 계속해서 나무를 심고, 사운드를 만들고, 도움이 필요한 생명을 돌보는 등 긍정적인 변화를 이어가겠다는 의지를 표현함
     * 마지막으로 “세상은 만드는 사람이 더 많아져야 의미가 있고, 파괴는 의미가 없다”는 메시지로 글을 맺음

        Hacker News 의견

     * 최근에 소음 문제로 고생한 적이 있는데, 스피커로 적절하게 EQ 적용된 화이트 노이즈를 틀어두니 어느 정도 정신과 수면 유지에 큰 도움이 되었던 경험 공유. mynoise 앱은 화려하진 않지만, 꼭 필요한 기능만 충실히 제공하며 여러 기기에서 잘 작동하는 신뢰감 주는 서비스임. 구매 당시 개발자 정보는 몰랐지만, 이번 이야기를 통해 서비스에 얼굴이 생긴 느낌임. 공격을 당하면 사람에 대한 신뢰까지 흔들리는 추가 트라우마가 생길 수 있음. 그렇게 방어적/공격적 혹은 신뢰를 어기는 태도까지 번질 수 있기에, 이런 고리를 끊으려면 결국 세대를 관통하는 장기적 정신 건강이 진짜 핵심이라고 생각
          + 나도 직접 윗집 세입자로부터 장기적인 소음 문제 겪은 적 있음. 사무실에 항의해도 동정만 받고 실질적 조치는 없음. 그래서 Siri에 “Loud neighbors”라고 말하면 자동으로 집주인에게 항의 이메일이 가는 iOS 단축어를 만들어 썼음. 1주에 3~4번씩 이메일이 가자 꽤 효과 있었던 경험. 사무실 방문자 그냥 내보내는 거랑 매번 이메일 직접 답장해야 하는 건 차원이 다름. 물론 상황마다 적용 여부는 다르겠지만, 소음 문제로 힘든 심정 충분히 공감, 모두 평온한 일상 누리길 바람
     * hacker들이 https://glslsandbox.com을 사실상 사라지게 만든 현실 이야기. 1년 반째 해커들의 스팸 공격 때문에 운영 중단됨. 나 같은 경우 서비스가 무료라 클라우드플레어로 일단 숨겨두곤 있는데, ‘보안 취약하면 너 책임’이라는 해커 특유의 논리에 항상 짜증이 남. 창문이나 문, 심지어 몸도 부술 수 있다고 해서 그게 ‘당연히 부숴도 된다’는 핑계가 될 순 없다고 생각. 물론 세상에서 이런 사람들 없애는 건 불가능에 가까운 현실 인정
          + 마지막 부분 정말 공감. 나는 6’3’’, 260파운드, 여러 번 아이언맨, 스포츠, 암벽등반, 헬스, 사냥, 전투 훈련까지 받은 덩치임. 솔직히 내 주변 대부분을 맨손으로 죽일 수도 있지만, 그렇게 살지 않음. 삶이란 그런 게 아님. 근데 자동차, 휴대폰, 남의 프로젝트 등 어디든 터무니 없이 저 논리가 적용됨. 만약 누가 날 때려놓고 ‘네 어머니가 더 큰 남자랑 잤어야지’라고 비웃는 세상, 정말 어처구니 없음. 아무튼 이런 현실 속상한 심정 공유
     *
         1. 공격에 너무 감정적으로 휘둘릴 필요 없음. 상대는 내 정체에도 관심 없다는 점. 2. 서버 운영에 레이트 리미터 필수 요소로 자리 잡았다고 생각. 단순 정보 수집 움직임이 무례함을 넘는 수준임. fail2ban 같은 도구로 간단한 로그인 시도나 취약점 스캔 막을 수 있음. 혹시 웹서버용 fail2ban 또는 레이트리미터 관련 툴 아는 분 있는지 궁금
          + 웹사이트 앞에 Cloudflare(무료 플랜)이면 이 문제 깔끔히 해결
     * 나는 Pentester/bug bounty hunter 입장. 오너에겐 짜증나는 일이지만, 이런 건 내 기준 일반적인 인터넷 노이즈, 혹은 누군가 burp suite 돌려서 자동 공격 걸어놓은 것처럼 보임. 라이브러리 기반 상용 툴이나 SaaS 타깃팅 공격이 기본값인 세상임. 인터넷 전체가 늘 스캔되고, 신생 사이트는 수많은 자동화 공격에 직면함. 부당한 현실이긴 해도 다들 겪는 현실, 개인적으로 너무 신경 쓸 필요 없다고 생각
          + 상어에게 공격당하는 것도 개인적으로 악감정은 없지만, 트라우마는 현실임. 그리고 상어는 윤리적으로 문제 있는 해커들이 만든 존재도 아님. 이 사람 트라우마를 가볍게 넘기는 태도는 너무 무례하다고 생각
     * 착한 쪽과 나쁜 쪽의 불공정한 싸움은 수천 년간 이어진 난제임. ‘죽이자, 용서하자, 재교육/개선하자’ 등 다양한 해결책이 나왔지만 제대로 먹히는 해법은 없었던 것 같음. 차라리 나쁜 사람들만 골라 다른 행성에 보내 방해 못 하게 해야 한다는 상상을 해봄. 어쩌면 이미 그런 식으로 우리 지구가 만들어진 건 아닌지 농담도 해봄
          + ‘다른 행성에 보내기’ 실은 이미 해본 적 있음. 전화기 소독원, 미용사, 광고계 임원진부터 시작함
          + gzip 컨텐츠를 특별히 조작해 수신 측에서 데이터가 엄청나게 커지게 만드는 http 프로토콜 활용 사례 기사 봤던 기억 있음. 크롤러 방어에는 이 방식이 효과적일 수 있음. 크롤러 대부분이 인스턴스당 디스크 스페이스 제한 있기 때문
          + “우리 모두가 그 나쁜 사람들”이라는 결론까지 갈 수도 있는 농담
          + 악성 해커들을 ‘죽이는’ 방법 실전한 적이 과연 있었는지 의문
     * mynoise 사이트를 처음 알게 된 뒤로 꾸준히 애정함. 최근 오피스 공간 밀집화가 심해지면서 사이트가 주는 효과가 더 커짐. 새 앱 리디자인도 매우 훌륭. 방대한 사운드 라이브러리를 위해 소정의 기부만 해도 아깝지 않을 가치. 그 대다수 컨텐츠가 개발자 본인이 현장 직접 녹음, 믹싱, 이퀄라이저 밴드로 잘라 만든 정성이 들어간 결과임. 아일랜드 해안, 지하수로, 다양한 숲 소리 등 직접 만든 콘텐츠임
     * 평생 회원으로서 수년간 mynoise.net을 사랑해 왔던 경험담. 집중력과 외부 소음 차단에 이만한 제품 없음. brain.fm, YouTube music도 써봤지만 결국 이 사이트로 항상 돌아오게 됨. 그 이유는 더 정성스럽고 나에게 더 효과적이기 때문
     * 도메인을 오래 소유하다 최근 몇 개 도난당했던 경험 있음. 내게만 의미 있는 저가 도메인인데도 도난당하니, 대체 누가 이런 수고를 하나 의문
          + 신규 도메인은 검색엔진에서 오래된 도메인만큼 신뢰 못 받음. 그 때문에 도난당한 도메인 시장이 존재하고, 소셜 미디어 계정도 마찬가지 상황임
          + 도메인 도난 사건 좀 무서움. 내 경우엔 도대체 어떻게 도난당한 건지 궁금
     * 진정 좀 필요하지 않을까 싶은 마음. 오픈 인터넷에서 서비스 제공하는 사람들은 항상 이런 로그를 만나게 됨. 거의 다 자동화된 공격임. 인터넷의 기본 구조 자체임
          + 흔하다는 이유로 괜찮다는 건 아니고, 기분 나빠하는 것도 얼마든지 이해됨. “진정 좀 하라”는 식 접근은 차별과 무례함을 정당화하는 위험한 일이라고 생각함
          + 오히려 이런 일이 흔할수록 더 안타갑게 생각해야 한다고 생각
     * 누가 이런 좋은 사람을 공격하려 하는 건지 의문
          + 상처받은 사람이 다른 이에게 상처를 주는 원리를 새삼 강조. 세상엔 단순히 세상을 망치고 싶어하는 부류도 있고, 상대가 나쁘게 구는 상황에서 내가 과도하게 반응하면 그런 행동이 정당화되어 또다시 반복됨. 경계는 충분히 지키되 필요 이상으로 과격하게 대응할 필요 없다는 마음. 상대방은 어쩌면 세상을 더 좋게 만들려는 노력 중일 수 있음. 이런 행동은 박수받아 마땅한 시도임
          + 특정인을 향한 공격이 아님. 사이트 운영 경험상 인터넷은 온갖 AI 크롤러와 자동 스크립트, 취약점 찾기 공격자들이 뒤섞여 돌아다니는 황무지임
          + 어쩌면 AI 회사에서 데이터를 훈련용으로 모으려고, 반복 옵션에 체크만 한 채 자동 수집했을 수도 있음
          + 오랜 인터넷 경험을 돌이켜보면, 순전히 망가뜨릴 수 있다는 이유만으로 뭐든 부수려 하는 굉장히 아픈 사람들이 있음. 관심 얻으려거나 그저 파괴 충동 때문일 수도 있으나, 사실 “피해자가 뭘 했길래?”라는 질문조차 무의미함. 공격자는 스스로 그 질문을 하는 법이 거의 없음. 예전엔 이런 사람들은 사회에서 배척되고 해를 끼칠 방법도 제한적이었지만, 인터넷은 그들에게 범세계적 공격 도구와 거의 무한 책임 면제를 제공하는 현실임
"
"https://news.hada.io/topic?id=21938","애플 vs 법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                애플 vs 법

     * EU의 Digital Markets Act(DMA) 는 iOS와 같은 운영체제를 게이트키퍼로 지정하여 경쟁업체와의 상호운영성을 강제함
     * 애플과 구글은 브뤼셀에서 열린 DMA 준수 워크숍에서 법 적용이 과도하다고 주장하며 소비자와 기업에 피해가 간다는 입장을 강조함
     * 애플은 규제 대응 과정에서 여러 질문에 구체적 답변을 회피하거나 추상적으로 답하는 소극적 자세를 보임
     * App Store와 브라우저 엔진 개방 등 주요 쟁점에서 애플은 여전히 폐쇄적 정책을 고수하는 동시에 경쟁사를 견제하는 모습을 보임
     * 규제의 공정성과 실효성을 확보하려면 모든 관할권에서 동일한 기준을 적용하고 거대 기업의 영향력에 휘둘리지 않는 질서 확립이 중요함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

워크숍 참석 및 오픈웹옹호(OWA) 시각

     * OWA 구성원이 브뤼셀 EU 집행위원회 건물에서 열린 애플과 구글의 DMA 준수 워크숍에 참석함
     * EU의 DMA는 다수 이용자를 보유한 플랫폼(운영체제, 앱스토어 등)을 게이트키퍼로 지정, 경쟁사와의 공정한 상호운영성을 의무화함
     * 이런 플랫폼은 사내 제품과 동일한 권한, 접속성을 타사(경쟁사)에게도 제공해야 하며, 자사 우대나 반경쟁 행위가 금지됨
     * 대표적 이슈로는 iOS에서 타사 브라우저 엔진 사용 및 타사 앱스토어 허용, 외부 기기 연결의 동등성 등이 있음
     * 현재 7개 회사의 25개 제품이 게이트키퍼로 지정됨

애플의 워크숍 태도 및 주장

     * 애플은 발표 초반부터 자사 우수성과 법 적용의 ""불공정함""을 강조하며, DMA에 대한 순응이 어렵다는 메시지를 반복함
     * “EU의 상호운영성 해석이 극단적”, “유럽 법원의 신속한 판례를 원함”, “적극적으로 권리 방어” 등 공격적 발언을 사용함
     * 워크숍 진행자 제지에도 허용 시간 이상 주장을 지속함
     * 경쟁사와 참가자들을 향해 존중 없는 태도와 다소 공격적인 발언을 보임
     * 구글 역시 비슷한 입장이었으나, 언행은 비교적 완곡함

애플의 규제 회피 이력

     * 규제 저항적 행보가 반복됨
     * 게이트키퍼 지정, 해당 법조항 등 모든 규제 요소에 법적 이의 제기를 진행함
     * 영국 CMA 조사도 기술적 사유를 들어 1년간 지연
     * 미국 법원 판결에서도 반경쟁적 선택 강행으로 지적받음
     * 애플과 구글의 연 매출 규모가 EU 전체 예산의 2배에 달해 소규모 과징금에는 영향 미미

질의응답, 운영방식 및 논란

     * 난해한 답변 회피와 반복적 일반화, 구체적 답변 부족이 두드러짐
     * 상호운영성, 프로세스, 기기 연결 파트에서 OWA는 브라우저 및 프로세스 투명성 관련 질문을 집중함
     * 예시: 애플의 결함 많은 버그 트래킹 시스템(정적 PDF, 주 1회 갱신, 접근성 낮음), “시간 내 요구 충족이 힘들었다”며 미흡함 인정
     * 타사 앱스토어 심사 과정에서도 실효성 낮은 인간 검수 집착, 오픈웹에 대한 견제 태도
     * App Store 내 사기성 앱 신고 기능 부족 지적에도 “명확히 존재한다”는 어색한 답변 반복
     * 브라우저 엔진 개방 요구에 대해선, 새로운 앱으로 출시해야 하며 기존 사용자 확보 재시작 필요 주장
     * 기본 브라우저 전환 유도 부족, 대안 엔진 사용시 과도한 계약 조건 등 문제 책임 회피
     * 참가자 그룹(OWA, CODE, DuckDuckGo 등)에 대한 견제 시도 및 경쟁사 주도 로비로 연결 짓는 전략

브라우저, 연령 제한 문제

     * iOS에서 연령 제한(Parental Controls) 활성화 시, 사파리만 사용 가능하고 모든 브라우저가 17+ 등급 취급됨(이해 불가한 정책)
     * 사파리는 별도로 예외 적용, 소셜 미디어 내장 브라우저는 제한 받지 않음
     * 국외 웹개발자의 테스트 제한: EU iOS만의 취약점, 버그, 호환성 문제를 모든 웹 개발자가 파악하기 어렵게 함

애플의 민감한 자금 및 이해관계자 논란

     * 애플은 참가자들의 자금 출처 및 단체 구성을 강조함
     * 실제로 애플이 직접, 간접적으로 자금을 지원한 단체(예: App Association) 참석 및 대리 활동이 문제로 지적됨
     * “스폰서” 신분 숨김 및 단체 명칭 혼용하여 참석자 출처 불분명

글로벌 DMA 준수 및 규제 확장 필요성

     * EU에서만 적용되는 지역별 기능 제한 문제(제3국 확장 미흡)는 제도 실효성을 떨어뜨림
     * 전 세계 공통된 기준이 필요하며, 각국마다 별도 API·계약요건이 존재하면 브라우저 출시와 유지가 사실상 불가능해지는 문제
     * 가장 큰 시장(미국, EU)만 베네핏, 그 외 국가는 불이익 증가
     * 규제의 실효 위해선 폭넓은 지역 확장이 필수

PWA(web app) 및 사용자 접근성 논란

     * 서드파티 브라우저 엔진에서 PWA 지원 불가 및 설치 절차 복잡성이 해소되지 않음
     * 애플은 “아직 발표할 내용이 없다”는 식의 원론적 답변 반복
     * 앱스토어 앱은 쉽게 설치하거나 실수로 설치해도 문제 삼지 않으면서, 웹 앱만 과도하게 복잡한 설치 절차 요구

추가 이슈 및 마무리

     * 마지막 질문에서는 데이터 이동권, Apple Photos의 부실한 내보내기 기능, 사용자가 클라우드 제공업체를 선택할 수 없는 점 등 문제가 추가 지적됨
     * 모임 종료 후 참가 단체 간 네트워킹, 정보 교류 기회가 많았음
     * 이번 글의 제목 “Apple vs the Law”는 법의 공평성과 실효성 확보 필요성에 대한 비판적 시각을 반영함
     * 애플의 정책적 언론전, 로비 단체 운영 등은 규제 집행의 신뢰성·투명성에 해를 끼치며, 이는 민주주의 신뢰 훼손으로 연결됨
     * 모든 기업이 동등하게 법의 적용을 받으며 시장에서 공정경쟁이 이루어져야 함, 거대 기업의 영향력 남용은 비판받아야 할 행위임

        Hacker News 의견

     * 유럽인으로서 이런 경우에 EU가 보여주는 모습에 보통 감탄함. 내가 사는 나라 또한 부유하고 역량 있지만, 애플 시가총액의 일부에 불과한 GDP만을 가짐. 이런 거대 기업을 상대로 소비자 권리를 보호할 힘이 국가 단독으로는 부족하다는 사실임. EU는 근본적으로 중도우파적, 자유지상주의적, 친기업 연합임. 이는 곧 경쟁을 지지한다는 의미임. 특히 일부 회원국에서 포퓰리즘이 강한데도 불구하고 EU가 자국 기업 보호주의로 변질되지 않고, 유럽 기업에 특혜를 주지 않는 점이 인상적임
          + 나는 반대로 생각함. EU가 규제 환경을 너무 복잡하게 만들어서 결국 큰 회사, 즉 빅테크나 유럽의 기존 대기업만이 규정 준수를 감당할 수 있게 만듦. 이에 더해 포장 규제 같은 친환경 캠페인도 있는데, 유럽 기업의 포장 폐기물을 조금 줄여도 결국 유럽 제품만 더 비싸지고 소비자는 Temu 같은 해외 쇼핑몰에서 더 많이 사게 만듦
          + GDP(총생산)와 시가총액(주식시장 가치)은 비교 대상이 아니라고 생각함. 둘은 완전히 다른 개념임
          + EU가 규제에서 지금보다 더 나아가야 한다고 봄. 미국이 AWS나 Microsoft 같은 인프라를 중국이 희귀광물 수출로 무역전쟁하는 것처럼 사용할 수 있는 상황이 이제는 상상 가능한 현실임. AWS/Microsoft와 Android/iOS가 핵심 인프라가 됨. 단순히 주권 클라우드 도입 같은 것으로는 부족하고, 이런 시스템은 지속적 모니터링과 개선이 필요함. 독점 규제만으로는 해결 안 됨, 실제로 독점 자체를 해체해야 함
          + 유럽 출신으로서 첫 댓글에 동의함. EU가 이 문제를 진지하게 대하는 점, 그리고 Digital Markets Act(DMA)에서 ""gatekeeper""(관문자)라는 개념을 도입해 대형 기업에만 적용하고 작은 기업은 규제하지 않는 점이 마음에 듦(개별 조항 중 동의하지 않는 것도 많지만). 하지만 완전히 보호주의가 아니라 할 수는 없음. 사실상 유럽에는 gatekeeper가 없기 때문에 DMA의 영향은 결국 거의 모든 경우 해외 기업에만 적용됨(Spotify 정도를 제외하고)
          + 유럽이 중도우파라고 했는데, 그 기준이 흥미로움. 결국 누군가의 '오른쪽'은 다른 누군가에게는 '왼쪽'일 수 있다는 것임
     * 이번 글에서 제일 흥미로운 부분은 각주에 있음. 애플이 어떻게 법원에서 iPadOS를 iOS와 다른 운영체제로 설득해서 iPadOS가 gatekeeper(관문자)로 지정되는 걸 거의 1년 지연시켰음. 이제 iOS, Safari, App Store 지정도 모두 법적으로 다투고 있고, iMessage는 아예 gatekeeper에서 제외시키는 데 성공함. 애플은 DMA의 조문에 있는 모호한 쉼표, 그리고 6(7)조(상호운용성)에서 인권 침해 논점까지 걸고 넘어가고 있음. 애플 법률문서에서 주장하는 바는 이 링크에서 전문 참고 가능임. 6(7)조 전체 내용은 다음과 같음: ""관문자는 서비스 제공시 자사가 사용하는 운영체제, 하드웨어, 또는 소프트웨어 기능에 대해, 비즈니스 사용자 및 대체 서비스 제공자에게 무료로 효과적인 상호운용성 및 접근성을 보장해야 함""
          + 애플 같은 대기업은 법무팀에 막대한 자금을 집행해서 이런 사소해 보이는 세부사항(심지어 쉼표까지)까지 다투는 것이 당연함. 수조 원 규모의 판결로 이어질 수 있기 때문임. 쉼표를 두고 다투는 것만으로도 비용 가치가 충분함
          + 애플이 법적 판결을 피하려고 다양한 법적 트릭을 쓰는 건 놀랍지 않음. 하지만 놀라운 건 많은 포럼에서 애플만 이런 걸 한다거나, 애플이 유독 더 심하게 한다는 인식이 퍼져있는 점임
          + 누군가 애플이 주장하는 논리를 설명해 달라 요청함. 도대체 어떻게 이 조항(상호운용성 요건)이 유럽기본권 헌장과 모순된다고 주장하는지 궁금함
          + 애플이 유럽에서 인권의 수호자 역할을 하고 있는 모습이 재미있다고 생각함. 혹시 애플이 정말 색다른 예술적 인본주의 언더독인가 하는 생각도 듦
     * 거의 10년 전, 애플이 내가 유료로 구매한 앱을 아무 설명 없이 환불도 없이 삭제해버린 후부터 ""앱"" 구매를 그만둠. ""앱""이라는 브랜드도 싫어함. 어쨌든 내겐 앱이란 것이 진정한 소프트웨어(application)의 어린이 버전이라는 경계의 의미임. 예외적으로 구매한 게임 Vampire Survivors가 있었지만, 사실 무료였음(앱스토어에 클론이 많아서 그런 듯). 그런데도 앱을 100개 넘게 설치했으나, 브라우저(Brave) 빼고는 한 번도 제대로 사용하지 않음. 사용성이 어색해서 설치한 순간 바로 존재를 잊어버림. 애플도 자신들이 사용성 문제가 있다는 걸 알지만, 방대한 앱 생태계와 맞물려 그 문제를 매우 느릿하게, 소극적으로밖에 고칠 수 없음. 그 사이 더 많은 UI 불편이 두 배 속도로 생겨남. 10년 전만 해도 텍스트 복사 등에서 usability가 엄청 좋았는데, 지금은 화면이
       커졌음에도 웹 표준이 엉망이 되어 예전보다 훨씬 사용이 힘듦. 텍스트 편집이 아예 불가능한 상황이 잦고, 탭-홀드 메뉴로 텍스트 추출하는 것도 두세 번 반복해야 겨우 동작함. 오래된 iPad에서는 아직 잘 됨. 이렇게 퇴보한 게 믿기지 않음
          + 나 역시 iPhone에서 텍스트 편집이 불가능에 가까워진 느낌임. 단어 중간에 커서를 못 옮겨서 항상 단어 경계에서 지우고 새로 입력하게 됨. 키보드 터치 영역도 Android와 달라서 종종 한 줄씩 잘못 선택하게 됨
     * 애플 플랫폼용 소프트웨어 개발자로서 요즘 점점 긍정적 태도를 갖기 어려워지고 있음. 애플이 매년 새로운 갑질 방식을 도입함. 아이폰용 앱 개발의 수익성도 많이 떨어져 이젠 고생을 감내하는 수단이 됨. 현실적으로 애플에 맞춰야만 하는 '움직이지 않는' 인프라라는 게 아쉬움
          + 이렇게 개발자에게 적대적인 생태계를 왜 계속 지지하는지 진심 이해가 안 감. 내 미래와 업계 전체를 위해서라도 소득원을 바꾸는 게 자기 존중을 위해 필요하다고 생각함
          + 내가 아는 모든 iOS와 Android 개발자들은 직접 앱을 팔지 않음. 주로 기업이나 기관이 제공하는 서비스를 위한 앱을 외주개발함. 은행, 보험, 방송, 대중교통, 자동차 등에서 주로 수익은 서비스 자체에서 나오며 앱 자체는 무료로 배포함
     * “...유감스럽게도, 위원회의 해석에 맞춰 복잡한 엔지니어링을 모두 해내는 것은 불가능하다..."" 사실 서명 검증 코드의 if문 몇 개만 제거하면 복잡하거나 불가능한 게 전혀 아님
          + 그건 너무 어려운 일 아닌가! 애플은 작은 나라 GDP에 불과한 수익밖에 없는 회사임. if문 몇 개 체크할 프로그래머 쓸 여유가 없음! 이런 복잡한 작업은 iMessage 서버에 제3자 앱이 접근하거나, 화면 교체를 애플 허락 없이 할 수 있을 때나 가능한 일임
          + 애플의 답변이 큰 가치나 현실성을 지니지 못하는 건 동의함. 실제로는 겉보기보다 일이 훨씬 더 많을 수 있음. 분기가 하나가 아니라, 시스템 전반에 깔린 가정들을 모두 확인하고 안전하고 일관적이도록 재설계해야 함. 그리고 이게 진짜 문제의 본질도 아님. 아무리 어렵든, ""우리 차가 시동 걸면 50% 확률로 폭발할 수도 있어서 조치는 불가능하다"" 식의 변명은 규제에서 아예 용인 안 됨. 어려움 여부가 중요한 게 아니라, 이런 답변 자체가 PR용 교묘한 회피일 뿐임
          + 그 주장 그대로라면, 애플은 유럽에서 사업을 그만둬야 함. 법을 지킬 수 없다면, 계속 영업할 수 없다는 것임. 만약 곧 방법을 찾아서 규정 준수하게 된다면, 그간 불가능하다던 거짓말에 대한 책임은 어떻게 될지 궁금함
          + 단순히 if문 하나가 아니라 정말 뿌리 깊은 문제일 수 있음. 서명, 패키지 형식 등 근간이 되는 가정 위에 수십만 줄의 코드와 인터페이스가 쌓임. 예전에도 필드 위치를 바꾸는 사소한 일도 12주나 걸렸는데, 여러 단계를 재설계해야 했음. 겉보기엔 쉬워도 실제로는 시스템 전체의 부분을 새로 써야 할 수 있음
          + 서명 검증은 코드상 몇 줄로 꺼도 기술적으로 가능할 수 있으나, 새롭게 외부 인터페이스를 개방하면 기존 보안 경계를 유지하는 게 진짜 문제임. 권한 관리, API 안정성, 샌드박싱 등 대부분이 폐쇄 시스템을 전제로 설계되어 있어서, 허용 범위만 넓혀도 전체 보안 모델을 다시 구축해야 함
     * 온라인으로 워크숍에 참석함(내 질문도 녹화본에 있음). 전체적으로 시간 낭비였다고 생각함. App Store 세션 이후엔 남아있지도 않음. 이유는 유럽표준시와 시차 때문도 있지만, 포맷이 아주 최악이었음. 애플이 끊임없이 ""EU가 우리 OS를 망치게 한다""는 식으로 발표하고, 유럽위원회(EC)는 Q&A를 묶음질문 형태로 진행해, 애플이 질문 무시하고 5분씩 아무 대답 안 해도 그냥 넘어감. 나는 EC가 왜 아무도 애플이 제공한 서드파티 개발자용 규정(현실적으로 쓸 수 없게 설계된 것) 사용 안 하는지 따질 줄 알았는데, 결과적으로 아무 질문도 거의 없었고 애플 변호사만 계속 발언함
          + 만약 내 입장이 정말 애플이었다면, 아무 제재나 구속력도 없는 '워크숍'에 억지로 불려나가면 나도 애플 변호사만큼이나 무례하게 행동했을 거임. 진짜로 바라는 걸 시키고 싶다면 벌써 소송 내거나 벌금부터 때렸어야 하는 거 아님?
     * 스티브 잡스가 정치와 App Store, Siri, Ai, 최근 소프트웨어의 낮은 품질 등을 신랄하게 비판하는 평행 우주를 꿈꿔봄. 그 시기에는 그가 중심을 잡고 본인의 생각을 솔직하게 전하며 전 세계가 덕분에 더 좋아졌다고 믿음. 팀 쿡 시대에서 가장 잘한 건 M 계열 하드웨어와 합리적 디자인 복귀 정도. 팀 쿡은 소심하며, 비용 절감만 신경 쓰다 애플의 명성을 많이 잃었다고 느낌. 주주 문제일 수도 있지만, 2000년대 애플의 정신이 가장 그리움
          + 나도 스티브 잡스를 비전가로 높이 평가함. 하지만 사람들이 팀 쿡을 그냥 ‘2인자’로 치부하는 건 불공정하다고 생각함. 팀 쿡이 회사를 수조 달러 기업으로 성장시켰고, 천재 개발자나 비전가들이 꺼리는 공급망과 운영을 완벽하게 담당해줌. 아무도 하고 싶지 않은 중요한 일을 해낸 것 자체가 대단함
          + ‘합리적 컴퓨터 디자인’이라는 게 정확히 무슨 의미인지 궁금함. 개인적으로는 여전히 못 열고, 배터리는 본드로 고정돼 있고, 점점 더 폐쇄된 하드웨어로 보임. 그나마 UI도 되레 옛날 느낌으로 회귀함
          + 소심하다기에는 팀 쿡이 비정상적으로 냉정하고 집요하다는 평도 많음. 단지 조용한 태도와 남부 억양 때문에 약하고 멍청해 보인다는 인식이 있을 뿐, 오히려 본인이 그 이미지를 잘 활용함
          + 스티브 잡스는 까칠하고, 지금 소프트웨어 제한 정책도 그가 했을 만한 것임. 원래 iPhone에 서드파티 앱을 아예 못 올리게 하려 했는데 팀에서 설득해서 열었던 것임. 지금 애플이 하는 일들은 잡스 시대와 거의 같음. 그때도 Cool하고 언더독 이미지였지만, 본질은 항상 더 많은 이익이었음
          + 스티브 잡스가 애플 앱/AI/품질 등을 솔직하게 꾸짖는 평행세계 정말 한 번 보고 싶음
     * 이 사태에서 가장 안타까운 건 애플도 경쟁 부족으로 인해 스스로 손해를 보고 있다는 점임. 예를 들어 애플워치는 iOS와 유일하게 연동되는 웨어러블이라는 점이 엄청난 이점임. 하지만 품질 문제가 많고, 내가 생각하기에 애플 제품 중 최악임. 만약 동등한 조건에서 다른 스마트워치와 경쟁해야 했다면 품질 향상 동기도 더 컸을 것임
          + 최근에 애플워치 쓰다가 Garmin Watch로 바꿨는데, Android에서는 알림을 앱별로 선택할 수 있음. iOS에서는 전부 켜거나 아예 다 끄는 것만 가능함. 애플 자체 제품에게만 허락된 깊은 연동이 제한됨
          + 경쟁 부재로 손해 보는 건 애플워치에 해당하고, 애플 전체에는 해당 안 됨
          + 애플워치 품질 문제에 대한 구체적 경험을 물어봄. 주요 모델을 모두 써봤으나 별 문제 없었음
     * 지금 시점에서는 Gatekeeper 기업에게 '경쟁을 허용'하는 것에서 나아가, 실제로 '경쟁을 지원'할 의무까지 부과해야 한다고 생각함. 어떻게 법적으로 강제할지는 모르겠지만, 예를 들어 전체 앱의 5% 이상이 3자 앱스토어 출신이어야 한다든가, 이용자 중 5% 이상이 웹앱을 써야 한다든가 식으로 구체적 목표치를 세우고, 이에 미달하면 벌금을 때릴 수도 있을 것 같음
          + 그런 식으로 Gatekeeper를 독점기업보다도 더 엄격하게 대하는 게 맞는지 모르겠음. 사실 규제가 확대될수록 시장 진입 비용만 더 심각해짐. 기존 대기업은 어떻게든 법 테두리 내에서 영업하겠지만, 잠재적 신생기업은 아예 유럽 진출을 포기할 수도 있음. 실제로도, 애플은 유럽에서 매출의 7%만 발생한다고 재판에서 언급함
          + 우선은 ‘경쟁을 허용’이 과제임. ‘지원’에서 나아가 ‘강제’하려 든다면, 예를 들어 애플이 경쟁자에게 수익 일부를 그냥 나눠줘야 된다는 논리까지 이어질 수 있음. 결국 경쟁자가 시장을 원하면 더 나은 서비스를 만들어야 하고, 이용자 선택을 강제로 제한하는 건 오히려 소비자에게 더 해로움
     * 애플의 DMA ‘준수’는 벽을 허무는 게 아니라 새로 문 옆에 울타리를 심는 느낌임. 원래 매끄러운 사용자 경험을 목숨처럼 여기는 회사가, 사파리(Safari) 사용자가 아닌 이들을 위해선 상호운용성을 의도적으로 더 복잡하게 만들고 있음
"
"https://news.hada.io/topic?id=21874","Anthropic, Claude 훈련용으로 중고책 수백만 권을 잘라서 스캔하고 700만 권의 불법 복제본을 다운로드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Anthropic, Claude 훈련용으로 중고책 수백만 권을 잘라서 스캔하고 700만 권의 불법 복제본을 다운로드

     * Anthropic이 AI 챗봇 Claude를 훈련하기 위해 중고 도서 수백만 권을 절단 및 스캔했다고 판사가 밝힘
     * 별도로 700만 권 이상의 불법 복제 도서를 다운로드한 사실도 판결문에서 언급됨
     * 판사는 구입 도서를 디지털화해 훈련용 데이터로 사용하는 행위는 공정 사용에 해당한다고 판단함
     * 반면, 불법 복제본 데이터 활용은 공정 사용으로 인정하지 않으며 저작권 침해임을 강조함
     * 이번 판결은 AI 모델 훈련 시 저작권 적용 관련한 중요한 선례로 평가받고 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * 미국 캘리포니아 북부 지방 법원의 William Alsup 판사는 Anthropic가 AI 챗봇 Claude 훈련을 위해 데이터 소스로 도서, 소셜 미디어 게시물, 동영상 등 다양한 자료를 사용했다고 분석했음
     * Anthropic는 수백만 달러를 투자해 대량의 중고 도서를 구매한 뒤, 제본을 분리하고 페이지를 절단해 디지털 파일로 변환함
     * 변환된 파일을 사내 리서치 라이브러리에 저장했으며, 원본 도서는 처분됨
     * 또한, Amazon과 Alphabet의 지원을 받는 Anthropic는 7백만 권이 넘는 불법 복제 도서를 별도로 다운로드해 Claude 모델 훈련에 이용함

도서 활용 및 불법 복제본 활용 과정

     * Anthropic의 공동 창립자 Ben Mann은 2021년에 Library Genesis에서 최소 500만 권의 도서를 불법적으로 다운로드함을 인정함
     * 2022년에는 Pirate Library Mirror에서 최소 200만 권을 추가로 다운로드함
     * 공동 창립자 겸 CEO Dario Amodei는 ""법적·관행적·비즈니스적 번거로움을 피하기 위해 도서를 훔치는(steal) 것을 더 선호""했다고 언급함
     * 2023년에는 세 명의 작가가 Anthropic를 상대로 자사의 도서 불법 복제본을 무단으로 사용했다는 이유로 집단 소송을 제기함

판사의 판단: 도서 공정 사용과 도서 해적판(불법 복제) 구분

     * 포인트 1: 공정 사용 인정
          + 판사는 Anthropic의 대량 도서 디지털화 및 AI 학습 데이터로의 사용을 ""매우 변형적(exceedingly transformative) ""이라 판단
          + 판결문에서는 ""Anthropic의 LLM은 기존 문서를 단순 복제하거나 대체하려는 것이 아니라, 완전히 다른 것을 창조하기 위해 학습한다""고 언급함
          + 회사가 직접 구매한 도서를 디지털화하여 라이브러리에 보관하는 행위는 공정 사용에 해당함
     * 포인트 2: 불법 복제본 사용은 공정 사용 아님
          + 판사는 Anthropic가 해적판(불법 복제본) 도서를 데이터로 활용한 점에 대해 단호하게 비판함
          + ""Anthropic는 중앙 라이브러리에서 불법 복제 도서를 사용할 권리가 없으며, 영구적·범용 라이브러리 구축이 자체적으로 공정 사용을 정당화하지 않는다""고 명시함

영향과 업계 동향

     * 이번 판결은 저작권 보호 도서를 AI 모델 훈련 데이터로 활용하는 것이 공정 사용에 포함되는지에 대한 첫 사례 중 하나임
     * 최근 OpenAI 및 여러 생성형 AI 기업들을 상대로 창작자, 아티스트, 언론사 등이 유사 소송을 연이어 제기하고 있음
     * AI 업계는 AI 모델 훈련이 공정 사용의 범주라 주장하며, 크리에이터들은 자신의 권리가 침해됐다는 입장임
     * 최근 Disney는 AI 이미지 생성 기업 Midjourney를 상대로 자사 캐릭터 저작권 침해 소송을 제기함

결론

     * Anthropic의 도서 디지털화 및 공정 사용 관련 부분은 AI 연구 및 저작권 해석에 전환점이 되는 판례로 평가됨
     * 반대로, 불법 복제본 활용에 대해서는 명확한 저작권 침해로 규정되어 향후 AI 학습 데이터 소싱 기준에 중요한 참고점이 됨

        Hacker News 의견

     * 기사 원문 링크
     * 판사의 중요한 판결 요약: Anthropic이 저작권 있는 책을 AI 학습에 활용한 것은 “매우 변형적”이라는 이유로 공정 이용에 해당한다고 판단. Anthropic은 자신들이 구매한 실제 책을 중앙 도서관에 디지털 방식으로 보관한 것일 뿐, 새로운 복제본을 만들거나 재배포하지 않았다는 주장. “도서관을 불법 복제하는 행위”는 명백한 저작권 침해. 재밌는 점은 내부 이용을 위해 도서관을 스캔·디지털화하는 건 가능하다고 인정, AI 학습용 활용도 공정 이용으로 판단한 부분.
          + 한편 판사가 다른 논점에 대해 언급한 부분도 중요. Anthropic이 불법 복제된 책을 중앙 도서관처럼 사용한 것은 공정 이용이 아니라고 명확히 선 그음. 즉, 직접 책을 구매해 물리적으로 스캔해서 AI 학습에 활용하는 것은 공정 이용, 반면 해적판을 사용하는 건 공정 이용 아님
          + 이 판결이 새로운 건 아니라고 생각함. 10여년 전 구글이 이미 책을 디지털로 변환하는 건 허용된다는 선례를 만들었다고 봄
          + 내가 알기로는 Meta가 관련된 후속 재판에서 Vince Chhabria 판사가 공정 이용 주장에 반기를 든 적이 있음 관련 링크 (법조인은 아님)
          + 여기서 ‘독극과실(fruit of the poisonous tree)’ 원칙도 적용되는지 궁금함
          + 예전에 Aaron Swartz를 거의 같은 일로 종신형에 처하려고 했다는 점 생각하면 시대 변화가 정말 크다는 느낌
     * 대규모 저작권 침해에 연루된 개인의 실제 처벌 사례 참고 기사
          + 오히려 Aaron Swartz 사건을 언급할 줄 알았음
          + 위 기사 클릭해보니 사실상 수백만달러의 해적 소프트웨어를 ‘판매’한 사업체 이야기였음. 단순히 혼자 써보는 게 아니라, 명백히 도둑질해서 남들한테 되팔아 이득 본 사례. 변형적 활용, 개인적 사용과는 전혀 다른 케이스
          + Anthropic은 해당 자료를 판매하지는 않음. 개인이 책을 읽고 요약하거나 부분 인용하는 것도 감옥에 보내진 않을 듯. 그런데도 Autodesk에 저항했다고 7년형이면, 강도죄보다도 더 심하다는 사실이 법조계 현실을 잘 보여주는듯
          + 단순히 해적 소프트웨어를 불법 복제·판매한 사례와 Anthropic처럼 책을 활용한 사례는 매우 다르다고 생각함. Anthropic은 어떤 책의 ‘복제본’을 만들어 유통한 적 없음
          + 법을 어날 생각이면 먼저 법인 설립해서 책임 돌리라는 농담. 자본만 충분하면 법 위반도 커버 가능한 현실 풍자
     * Spotify 등 기업들도 초기에 불법 자료에 기반해 사업을 키운 정황이 있음. 예전부터 베타 테스트에 ‘해적판’ mp3 파일이 활용됐다는 소문. 실제로 ‘Scene’ 태그가 박힌 트랙이 다운로드됐던 경험담들이 있음 관련 기사
          + Crunchyroll도 본래 해적 애니 스트리밍 사이트였지만 정식 라이선스 획득하며 합법화. 2006년 시작, 2008년 VC 투자, 2009년 라이선스 체결 Forbes 기사, Venturebeat 기사
          + 사실 Spotify뿐 아니라 대부분의 테크 자이언트가 법의 회색지대나 규제 무시—즉 시장을 ‘디스럽트’ 하면서 돈 벌기. 법적 제재보다 부당이득이 훨씬 크기 때문. 아마존 이후 투자금 바탕으로 ‘공정 경쟁’ 무시하고 가격 덤핑하는 행위도 많아졌다고 생각. 미국 빅테크 기업들은 법을 거의 무력화시키면서 성장한 셈
          + ‘공식적으로 얻지 않은 음원’과 ‘저작권 없는 음원’은 다른 개념. 스트리밍 라이선스가 확보돼도 원본 파일이 없는 경우가 있음
          + Spotify 초기 UI가 Limewire와 1:1 복붙 수준이었던 점도 언급
          + Google Music도 사용자가 직접 mp3 등 업로드하는 방식이 있었는데, 당시엔 파일의 불법성이 구글 책임이 아니라는 주장. 아마존도 비슷한 서비스 경험 참고 글
     * AI 미래를 만들어가고 있다는 사람들이 이런 식으로 윤리를 저버리는 상황 의문. 중국이 수십 년간 위조품 문제로 제재받았는데, Anthropic 역시 불법 활동에 연루됐다면 수출 제한도 정당하다고 생각
          + 중국 위조 상품 문제에 대해 우리가 실질적으로 뭘 했는지 의문. 대부분의 처벌은 현지에서 적발된 가짜 물품 수입 차단 정도였을 뿐, 실질적인 처벌은 이뤄지지 않음. 오히려 미국 기업들이 오랫동안 생산까지 아웃소싱해 IP 도용 환경만 조성
          + 진짜 비윤리적인 쪽은 아예 책조차 안 사는 기업. 실제로 경제적·법적 파워가 있으면 더 쉽게 빠져나간다는 현실
          + 사회에 만연한 이중잣대와 권력에 대한 면죄부 지적. 음주운전, 폭력, 탈세 등 예로 들면서, 사회 전체가 권력·부·영향력에 따라 흔들린다는 점 강조. 출판사가 내 책 베껴가면 소송 가능하지만, AI 기업이 훔쳐가면 대형 로펌으로 소송조차 힘듬. 현실 세계에서 평등은 환상이고, 잘 나가는 쪽이 언제나 유리한 입장
          + Facebook 슬로건처럼, ‘부수면서 빠르게 나아가기’가 미덕인 시대
          + 책에 담긴 정보를 활용하는 게 왜 비윤리적인지 의문. Anthropic은 해당 책을 재판매한 게 아님. 책의 정보 그 자체는 저작권으로 보호받지 않음. 인용은 언제나 가능
     * Anthropic 공동창업자 Ben Mann이 2021년 Library Genesis에서 해적판 책 수백만 권을 다운받았다는 주장. 도둑질은 도둑질. 이중잣대는 그만두자는 의견
          + 대부분의 해적은 단순 ‘개인적 소비’가 목적인데, 해적판을 통해 ‘이윤추구’ 하는 것은 레벨이 다름
          + 단순 도둑질이 아니라, 시장 지배를 노리고 표적으로 훔쳐서 윤리적으로 행동한 기업들을 도태시키는 행위는 수많은 작가들에게 더 큰 피해 유발. 이런 건 ‘조직적 범죄’에 가깝다고 생각
          + “도둑질은 도둑질”이란 말은 너무 단순함. 상품을 들고 나왔어도 상황에 따라 처벌이 천차만별. 세부사항이 중요
          + ‘절도’의 정의부터 정확히 해야 함
          + “복사는 절도와 다름” 복제해가면 원래 사람도 자기 복사본을 계속 소유. 복제를 ‘절도’라 부르면 다른 과격한 주장도 성립된다는 반박
     * 대규모 AI 데이터 학습의 현실상, 해적판과 벌금이 책 수백만권을 일일이 사서 처리하는 것보다 훨씬 저렴. 물론 정당화될 수 없으나, 만약 본인 입장이라면 효율성 때문에 같은 선택을 할 수도 있다는 괴리
          + 이 논리의 문제점은, 수년간 책을 집필한 수많은 교사와 저자들이 대기업에 저작권 침해를 당해도 소송조차 어려울 것. 결과적으로 저자들이 집필을 포기하게 되고, 이미 그런 현상이 나타난다는 주장
          + 고의적 침해는 저작권당 최대 15만달러 벌금. 만약 모든 침해 자료에 대해 판결 나면, Anthropic 시가총액보다 더 큰 액수 가능. 실제로는 이런 초법적 판단은 적용되지 않고, 2000년대 초 Napster 운영 청소년과는 법의 잣대가 다름
          + “해적판은 징역 갈 일 아닌가?”라는 의문. DVD FBI 경고에 비춰볼 때 원칙론에 따르면 중범죄
          + 사실 기사에 따르면, Anthropic이 대량의 책을 정식으로 구매한 뒤 학습에 활용한 사례도 많음. 관련 소송의 모든 책은 정식구매본 포함. 중고책은 대량구매가 저렴
          + 법적 리스크 ‘제로’로 가려면, 출판사에 직접 연락해 AI 학습용 라이선스를 협상하는 게 원칙. 넷플릭스·스포티파이 등 모든 미디어 기업이 하는 방식. AI 기업에는 왜 이런 원칙을 다른 시각으로 적용하는지 의문
     * 내가 책을 소유하고 있다면 내 컴퓨터로 스캔하는 것은 합법이어야 한다고 생각. AI 기업들의 입장도 안타깝게 보임. 저작권 규정들이 AI 겨냥해 점점 더 엄격해지는 느낌. 내가 어떤 책 내용에서 아이디어 얻어 창작했더라도 책 저작권에 갚을 의무는 없다고 생각
          + 기사 내용을 제대로 봐야 함. 본문에서도 내 책을 스캔해 AI 학습에 쓸 수 있다고 명시. 오히려 이 판결은 AI 기업에 큰 호재. 반대로 해석하는 게 이해 안 됨
          + 공정 이용 논의에서 놓치는 점은, 해당 활용이 저작권자의 시장에 실질적 악영향을 미치는지 여부. 개인이 어떤 책을 보고 배워서 저자와 경쟁한다고 해서 그 영향력을 증명하긴 힘듦. 하지만 AI가 대량으로 학습해 출시한 모델로 인한 저자 수익 감소는 비교적 뚜렷하게 입증될 수 있음. AI가 저작물 기반으로 저자를 대체할 수 있다면, 공정 이용 취지와 부합하지 않음
          + 저작권법은 논리적으로 일관된 구조가 없는 느낌. 정보 자유와 혁신 독려라는 당초 목적도 모호. 법 해석은 판사의 주관에 따라 좌우. 결국 법 현실 논리는 ‘돈’이자, 저작권 힘은 거대 자본이 유지하기 때문. 만약 이젠 자본에 방해가 되면, 그동안 DRM이나 저작권 논리가 어떻게 바뀔지 경험할 차례
          + 규모가 커지면 모든 게 다르게 작동. 개인의 권리·규범을 메가 시스템에 그대 적용할 수 없고, 사회적으로도 이런 구분이 필요. 돈 가진 쪽은 이 문제를 무시하도록 만들었고, ‘규모’에 대한 규제가 미비해 발생하는 혼란이 근본 원인
          + 요약: 판사, Claude 학습용으로 책 활용한 건 공정 이용, 근데 ‘해적판’ 활용은 불법
     * 최근 유튜브가 다운로드 차단 강화한 것도 경쟁 AI회사들이 데이터셋 수집하는 것 막기 위해서일 수도 있다고 생각
     * 남을 비난하기는 쉽지만, 현재 스레드 최상위 댓글도 결국 Business Insider에서 ‘훔친’ 콘텐츠 링크. 누구나 공정하지 않다는 현실
          + 어떻게 Business Insider에서 ‘훔쳐진’ 콘텐츠인지 궁금. 공식 웹사이트에서도 같은 기사 볼 수 있고, 브라우저 캐시나 아카이브도 본질적으로 다르지 않음
          + 이게 오늘 스레드 최고의 댓글. 여기서 논리적 곡예를 보는 게 흥미롭다고 생각
"
"https://news.hada.io/topic?id=21849","우리가 악당인가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               우리가 악당인가?

     * Hinge, Uber 등 주요 앱에서 고도화된 알고리듬과 심리적 기법이 사용자로부터 이익을 극대화하는 방향으로 작동함
     * 사회의 일상적인 상호작용마다 AI 기반의 중개자가 관여해 추가 이익 추출 구조를 만듦
     * 기업은 Lifetime Customer Value 극대화를 위해 사용자 반응에 맞춰 알고리듬을 빠르게 조정함
     * 경쟁에서 뒤처지지 않으려면 이 추세에 편승해야 하므로, 집단적 문제로 간주할 수 있음
     * 데이터, 머신러닝, 심리 기법을 동원한 대규모 조작이 일상화되어, 근본적인 변화 없이는 개선되기 어려움
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

문제 제기: 알고리듬과 심리 기법의 일상화

     * Hinge, Uber 등 주요 서비스는 부스트, 팁 화면, 영업 알고리듬 등 다양한 수단으로 사용자로부터 이익을 최대한 이끌어내는 구조임
     * 일상생활의 거의 모든 영역에 중개 AI가 개입하며, 첨단 AI 알고리듬을 통해 ""조금 더""를 끌어내는 방식이 사회 전반에 퍼짐
     * 커피를 사거나, 데이트를 하고, 친구에게 돈을 보내는 등 일상적 활동에서 악의적 중개자가 자동화되어 수익을 추구하게 됨

시장 자정 가능성 및 알고리듬의 적응

     * 많은 사람들이 조작에 피로감을 느끼고 스스로 회피할 것 같지만, 기업들은 이미 이를 예측하여 데이터 대시보드를 통해 즉각적으로 대응함
     * AI는 사용하는 이가 불편함을 느끼기도 전에 감정 조절 및 추가 보상 제공으로 이탈을 방지하는 식으로 작동함

경쟁과 집단적 행동 문제

     * 이런 시스템에서 벗어나려 해도, 경쟁 상황에서는 모든 사업자가 참여하지 않으면 불리해지는 현상이 심화됨
     * 모든 지표(메트릭) 이 경쟁의 대상이 되고, ‘Red Queen’s Race’ 처럼 뒤처지지 않기 위해 사교 자본과 가치관도 희생하게 됨

현실의 사회 구조와 변화의 어려움

     * 사회 전체가 이 구조에 매몰되어, 개인의 탈퇴로는 근본적 변화를 이루기 어려운 집단행동문제가 존재함
     * 알고리듬 주도의 민주주의에서는 선택권(투표) 역시 실제 변화와 동떨어져 있고, 기존 구조에서 개혁이 아닌 근본적 변화(혁명) 만이 실질적 해결책임을 시사함

결론 및 문제의 본질

     * 광고, 가격차별, 대규모 데이터 기반 조작 모두 본질적으로 옳지 않음
     * 현대 자본주의는 '와이어헤딩(wireheading)' 현상처럼 인간의 행동을 극단적으로 유도하며, 본질적으로 이 문제는 규모와 무차별적 조작이라는 새로운 수준에 이르렀음을 강조함

        Hacker News 의견

     * 일부 사람들에게 프리미엄을 내고 줄을 건너뛰는 것 자체가 목적이었던 상황 설명, 하지만 모두가 프리미엄을 내기 시작하면 결국 줄이 그대로 남아있는 현실 언급, 이런 현상은 호주 상용 비행에서 두드러지는 형태, Fly in Fly out 근무 덕분에 클럽 등급이 흔해졌고, 탑승 우위나 포인트 항공권도 거의 없어지는 현상 공유, 요컨대 차별적 가격 책정과 지위 추구는 소비자를 대상으로 할 때 사회적으로 해로운 패턴이 된다는 점 강조, Uber를 싫어했던 개인적 경험 및 택시 서비스가 나빠진 현실, 불법적 진입을 묵인한 Uber의 사업 방식 비판, 그러나 이제 Uber가 너무 익숙해져 요금 폭등도 별로 신경 안 쓰는 상태 인정, 호주에서 팁 문화가 도입되는 것에 대한 불쾌감 표현, 법으로 보장된 최저 임금과 페널티 레이트가 있으니 팁 기능은 꺼야 한다는 입장, 유럽
       항공에서 수화물 포함 의무화 논란 사례, 깨끗한 속옷이 약한 거라고 조롱받는 분위기까지 유럽의 특이한 문화 설명
          + 비미국인이 팁 문화에 대해 단호하게 거부해야 한다는 입장, 팁을 받기 시작하면 임금이 더 내려가 상황이 더욱 악화된다는 경고와 함께 팁 자체를 아예 받지 않아야 한다는 주장
          + Uber와 Lyft 가격이 비싸긴 하지만, 과거의 택시 서비스와 비교할 때 지금이 훨씬 나은 점 강조, 뉴욕 등 대도시 제외하면 예전에는 전화번호부에서 이름을 찾아 의심스러운 업체와 예약해야 했고, 차를 잡기도 힘든 시절 회상, 지금은 어디서든 앱으로 바로 차를 부를 수 있고 속도도 빠르며, 운전자나 승객 대상 불공정한 상술은 분명 문제이긴 하지만, 과거 방식으로 돌아가고 싶은 생각 전혀 없다는 강조
          + 특히 유럽 할인 항공사에서는 우선 탑승권을 거의 전원이 사는 현상 체험, 예전에는 추가 요금 내고 앞서 가는 것이 의미 있었으나, 이젠 우선 탑승 대기열이 더 길기도 한 아이러니 강조, Uber의 요금 폭등 구간에서는 앱 가격 변동을 잠깐 지켜보다가 저렴할 때 잡는 방식, 택시 요금이 Uber보다 2~3배 비싸고 친절하지도 않으며, 평가 기능도 없어 택시 이용을 꺼리는 경향, 실제 사례로 공항까지 Uber보다 싸게 택시를 탔던 경험 공유, 택시 기사가 Uber 요금만큼 현장 결제로 태워주고, 다른 승객에게는 5배 요금 받아버린 황당 경험, Uber를 쓰지 않겠다는 태도는 인생을 더 힘들게 만들 뿐이라는 결론, 유럽에서는 2명 이상만 돼도 기차보다 Uber가 싸지는 경우가 많다는 얘기도 덧붙임
          + 모두가 프리미엄을 내놓고 다시 대기열이 생기면, 시장 논자라면 결국 프리미엄이 포함된 실제 가격이 진짜 가격이 되어버린다는 주장, 줄서기 비용이 더 높아져야 해결된다는 관점 공유
          + 대기열을 신경 쓰지 않고 맨 마지막에 들어가는 편안함을 오히려 즐긴다는 시각, 프리미엄을 안 내고 로비에서 여유롭게 기다리다가 줄이 거의 다 빠질 때 들어가도 된다는 개인 태도
     * 기술 발전과 조작에 대한 인간의 타임리스한 대응 방식이 이탈(disengagement)이라는 주장, 이건 이론이 아니라 이미 일어나고 있는 현상으로 디지털 해독, 젊은층의 덤폰 사용 부활, 공개 피드 대신 프라이빗 DM, ‘방해금지’ 세대 등 실제 사례 언급, 사람들은 조작을 체감하며 하나씩 옵트아웃해 간다는 진단
          + 나의 이탈 수치는 이제 공짜로 줄 생각 없음, 일부러 랜덤하게 이탈해서 어느 쪽도 효과를 예측 못하게 만드는 전략 활용 의견, 덤폰 열풍이나 디지털 해독조차 이제 단순히 하나의 라이프스타일 시장이 되어버린 현실, 조작 인식조차 새로운 비즈니스 소재가 됐음을 꼬집음, 알고리즘을 얼마나 해킹할 수 있을지, 본인과 다르게 프로파일링하게 만들 수 있을지 실험적인 질문을 던짐
          + 2012년 이후 앱과 소셜미디어 등 삶을 상품화/수익화하는 서비스를 완전히 끊은 경험
          + 기업은 이제 ‘이탈 수익’을 노리게 될 거라는 씁쓸한 전망, 유튜브 watch?v=9h9wStdPkQY (링크는 언급만) 등 참고자료 공유
          + 자본주의로부터의 완전한 이탈은 불가능하다는 의견, 언급된 여러 이탈 행동(디지털 해독, 덤폰 등)은 단지 덜 당하는 정도이지 진짜 착취로부터 자유롭지 않다는 현실 인식
          + 이탈은 무관심(nonchalance)과는 다르며, 이게 꼭 좋은 인간적 대응이 아닐 수 있다는 우려, 무관심은 개인적 차원의 태도지만 이탈은 집단적 효과를 목표로 하는데, 대부분의 경우 긍정적 변화로 이어지지 않음을 걱정, 오히려 공동체적 악화와 기준치 하락이 이어지는데, 평등과 포용의 이름으로 이루어지지만 실상 양극화가 심화되는 현실 지적, ‘Occupy Wall Street’와 ‘아랍의 봄’ 이후 무관심(hyper-individualism)이 유행하면서 정치인이나 경영진까지도 책임 의식을 잃고 본인 커리어에 더 집중하게 된 배경 설명, 참고로 Broken Windows Theory 위키피디아, The Subtle Art of Not Giving a F*ck
     * 저자가 만든 제품(openpilot)은 14일마다 인터넷 연결이 안 되면 작동이 중단되는 문제 지적, 관련 코드 링크 공유
          + 저자가 Twitter에서 자발적으로 일한 전력도 문제로 삼음, Musk 이후 Twitter가 궁극의 프로파간다 추천 알고리즘이 된 사실 비판, 관련 기사 링크 공유
     * George의 기술적이지 않은 글을 대체로 피하지만 이번 글은 의미 있다고 평가, 보통은 자아성찰 부족하고 필요한 반성이 안 이뤄지나 이번에는 자기성찰을 자극할 기회로 삼을 수 있음, 최근 HN 커뮤니티에서도 비슷한 분위기가 늘어난 것을 느낀다고 피력, 변화의 필요성에 대한 위기의식 공유
          + ""Are we the baddies?"" 라는 제목을 보고 개인적 역할에 대한 성찰이 나올 줄 알았으나 그렇지는 않아 아쉬움 표출
          + 어떤 사람들은 그저 유행을 따라가는 것 아닌가 하는 의문, 깊은 성찰 없이 표면적으로 흉내만 내는 듯한 글의 뉘앙스에 대해 언급
          + geohot이 LLM을 이용해 Advent of Code 순위권에 오른 사례 언급으로 다소 비꼬는 반응
          + 참고로 관련 트윗 링크 남김
     * ""정부가 모든 이에게 $1000로 시작하는 S&P 500 계좌를 열어주면 사회보장이 해결된다""는 주장 인용하며, 이것이 본질적으로 단순히 대형 기업(또는 그 계열)으로 지속적 공적 자금 유입을 보장할 뿐이라고 지적, UBI(기본소득)도 본질적으로 역동성 없는 경제 현상의 방증, 정부가 일자리를 제공하는 대신 존재 자체에 대한 급여를 제공함을 묵인하는 구조적 문제 설명
          + 기본소득(UBI)에 대해 ‘존재만으로 편안하게 해준다’는 식의 해석에는 동의하지 않음, UBI는 최소한의 생존을 보장하고 그 이상 추가 소득은 본인이 벌 수 있다는 점 강조, 스칸디나비아 국가의 사례를 UBI가 필요한 시장경제 구조의 근거로 제시
          + S&P 500 기업은 주식이 매수되어도 실제로는 자금 유입이 발생하지 않는 구조임을 설명
          + ETF(지수추종펀드)는 갱신과 리밸런싱 과정에서 특정 기업이 빠지면 주가가 큰 폭으로 떨어지기도 함, 예로 최근 Pltr이 Russel2000 지수에서 제거된 후 큰 하락했다는 사실 공유
     * 인터넷 브라우저, 현대적 인프라, 하이퍼스케일 클라우드 구축 경험 공유, 처음에는 더 나은 무언가를 만든다는 자부심이 있었으나, 제품 관리자(Product Manager)라는 역할이 생기고 나서 모든 것을 후회하게 됨
          + PM 경험자 입장에서 제품관리 역할이 최근 어떻게 현실과 멀어지게 변질됐는지 확장해서 설명요청, 스타트업과 차이가 크고, 미로 보드와 끝없는 GDocs 덧글 대화에 치여 현실과 동떨어진 방식에 상처 받았던 경험 공유, 높은 연봉도 포기하고 다시 빌딩 영역으로 돌아가게 한 배경, 다만 제품관리와 PM 중심 문화만 탓할 수는 없고 대부분의 경영진 결정에 공감이나 존경을 느끼기 어려운 현실이 자주 발생했다고 고백
     * 영국 TV쇼 ""That Mitchell and Webb Look""의 스케치 장면이 제목의 원조임을 밝히고 유튜브 링크 공유
          + 해당 쇼의 재치있는 풍자력 언급, Dr Death 에피소드 또한 현대 과학기술을 풍자하는 데 매우 적합하다고 평, 관련 영상 링크
          + 슬프지만 웃긴 또 다른 에피소드 링크 추천
          + 고전적 명장면 링크 언급
          + 이젠 공식적으로 나이 들었다는 농담
     * 인간의 협력성이 얼마나 본질적이고, 동시에 얼마나 취약한지 인류가 제대로 이해해 본 적이 없다는 의견, 개미의 페로몬 신호를 제거하면 Colony가 어떻게 망가질지, 일부 개미에게 ‘이득’을 몰아주면 어떻게 시스템이 변하는지에 대한 사고실험 제안, 자의식이 추가된 개미에 실험을 반복하면 결과가 또 다르다는 상상, 복잡적응 시스템에 대한 이해는 직접 만들어 보면서 익힐 수 있다는 조언과 함께 John Holland의 ""Hidden Order"" 추천
     * George가 NVidia 독점에 대항해 AMD를 시도하려는 모습에 호감이 생긴다는 반응, 시장 독점 해소를 바라는 태도 긍정적 평가
          + 그러나 AMD 칩을 사용하던 도중 버그 탓에 장시간 안정 작동이 어려워 포기했던 듯하다는 지적
          + 성공적이고 열정적인 George Hotz조차 이성 문제에서 초보자의 길을 걷는 모습을 보면 자신처럼 특출나지 않은 사람은 더 고생할 수밖에 없다는 연민 표현
     * 이런 포스트를 인구통계적 히트맵으로 보는 관점, 이제는 단순히 흥미를 쫓던 좀 더 주변인(geohot 해킹 등)도 이 문제의 심각성을 깨닫고 공개적으로 발언하기 시작했음을 의미한다는 분석, geohot이 현상 한가운데에 위치함을 암시
          + ""언젠가 사람들은 우리가 사회라는 공동체에서 살아감을 깨달아야 함, 무엇이 계기가 될까?""라는 질문 인용, 사회적 문제에 대한 분산적 지적이 가능해진 팟캐스트·SNS 환경 등 평가, 우리가 진정으로 필요한 것은 현대적 의미의 마을 공동체, 지나친 개인주의와 자기중심적 결정에서 벗어나 타인의 필요와 상황에 맞춰 배려하는 관계성 회복 중요성 강조
          + George Hotz에게서 근본적 반(反)자본주의에 가까운 메시지를 듣게 되리라 예상하지 못했는데 이런 감정을 솔직히 표현한 용기에 박수 보냄
"
"https://news.hada.io/topic?id=21846","Backlog.md - Git 저장소를 위한 마크다운 기반의 인간-AI 프로젝트 협업 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Backlog.md - Git 저장소를 위한 마크다운 기반의 인간-AI 프로젝트 협업 도구

   .md 파일로 task를 관리하고 CLI, Web UI로 칸반 시각화를 해서 관리할 수도 있습니다. 영리한 접근이라 생각합니다.
"
"https://news.hada.io/topic?id=21948","LlamaFirewall - AI 보안 위험 감지/차단 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  LlamaFirewall - AI 보안 위험 감지/차단 프레임워크

     * Purple Llama는 Meta가 주도하는 오픈소스 AI 신뢰성과 보안 생태계의 상위(umbrella) 프로젝트로, 생성형 AI(LLM) 개발에 필요한 다양한 보안 툴·가이드·평가 도구(Eval), 벤치마크를 한데 모아 커뮤니티와 함께 발전시키는 것을 목표로 함
     * LlamaFirewall은 Purple Llama 프로젝트의 핵심 구성요소로, 생성형 AI(특히 LLM 기반 챗봇/에이전트)에서 발생할 수 있는 다양한 보안 위협(프롬프트 인젝션, 미스얼라인먼트, 코드 취약점 등)을 다계층 스캐너 구조로 실시간 탐지·차단하는 프레임워크
     * Llama Guard, Prompt Guard, Code Shield, CyberSec Eval 등 Purple Llama의 여러 보안/신뢰성 도구들과 함께 시스템-레벨의 종합적 AI 안전 레이어를 구현함
          + Llama Guard: Llama 3 기반의 입출력 유해 컨텐츠 검출/차단 모델. LlamaFirewall 정책에 포함해 모든 입력/출력 단계에서 자동 적용 가능
          + Prompt Guard: 프롬프트 인젝션/탈옥 공격 탐지 특화, LlamaFirewall 내 PromptGuardScanner로 연동
          + Code Shield: LLM 생성 코드의 실시간 취약점·유해 코드 감지, LlamaFirewall 내 CodeShieldScanner로 연동
          + CyberSec Eval: Purple Llama의 LLM 사이버보안 벤치마크 도구. LlamaFirewall 기반 모델의 실제 보안 내성·취약점 테스트에 사용
     * 낮은 지연시간/고처리량, 실시간 적용, 투명한 오픈소스, 강력한 확장성이 특징
     * 보안팀/AI 개발자가 LLM 기반 챗봇·에이전트·멀티스텝 AI에 안전한 Guardrail(방호벽) 구축을 빠르게 적용 가능
"
"https://news.hada.io/topic?id=21955","ChatGPT의 Structured Output 기능으로 소스코드로부터 Swagger 문서 생성하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ChatGPT의 Structured Output 기능으로 소스코드로부터 Swagger 문서 생성하기

     * ChatGPT API의 Structured Output 기능 을 활용하여, Swagger 기반 API 정의서 JSON 파일을 일반 소스코드로부터 생성하는 방법 공유
     * Swagger 스펙에 벗어나지 않는 JSON을 생성한 방법 및 JSON Schema 공유. OpenAI Playground에서 직접 재현해볼 수 있음
          + 주의: 할루시네이션 위험성에 대해 유의할 것
     * Swagger를 수동으로 작성해야 하는 코드베이스에서는 이 방법을 통한 AI 소프트웨어 문서화가 유용할 수 있음
     * Google Gemini, ollama 등 다른 LLM 프로바이더에서도 Structured Output 기능을 지원
"
"https://news.hada.io/topic?id=21854","동부 발트해 대구, 남획으로 인해 예전보다 훨씬 작아짐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     동부 발트해 대구, 남획으로 인해 예전보다 훨씬 작아짐

     * 동부 발트해 대구의 평균 크기가 지난 30년 동안 크게 감소함
     * 새로운 연구에 따르면 남획이 이 생선의 유전자를 변화시킨 것으로 밝혀짐
     * 대구 몸집 감소는 단순한 환경 변화가 아니라 인위적 진화 과정의 결과로 확인됨
     * 대구의 유전적 다양성 손실로 인해 환경 변화에 적응하기가 더 어려워질 가능성 있음
     * 이 연구는 인간 활동이 진화를 가속시킬 수 있음을 보여주는 중요한 사례임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

새로운 연구: 발트해 대구 크기 감소의 비밀을 밝힘

  개요

     * 동부 발트해 대구의 몸집이 30년 전보다 절반 이하로 감소함
     * 원인으로는 지속적인 남획이 지목됨
     * 최근 발표된 연구는 남획이 단지 큰 개체만 줄인 것이 아니라, 유전자 구성을 변화시켜 전체 개체군이 작아지도록 만들었음

  연구 배경 및 관찰

     * 1987년경, 대구는 1미터가 넘는 큰 크기로 성장했으나, 2019년에는 손바닥 크기로 감소함
     * 수십 년 간 벌어진 집약적 그물 어획에 의해 작은 대구만 살아남을 확률이 높아짐
     * 단순한 환경적 요인(오염, 수온 변화 등)과 진화적 변화를 구분하는 일이 어려웠음
     * 대구 보호를 위해 2019년 어획 금지 조치가 내려졌지만, 크기 회복 조짐은 나타나지 않음

  연구 방법

     * 연구팀은 1996~2019년에 잡힌 대구에서 추출한 152개의 이석(내이 구조물)을 분석함
     * 이석은 해마다 성장 내용을 기록하는 생물학적 시계 역할을 하여 성장 변화를 객관적으로 측정함
     * 각 개체의 유전체 염기서열을 분석하고 빠른 성장과 연관된 유전 변이를 탐색함
     * 시간이 지남에 따라 큰 몸집과 연관된 변이가 점점 희귀해졌음을 발견함
     * 이런 변화는 외부 압력이 개체군의 진화를 유도했음을 시사함

  진화와 미래 영향

     * 인간 활동이 자연계에서 가장 강한 선택 압력을 가한다는 점이 확인됨
     * 온난화 등 환경 요인도 일부 영향이 있지만, 남획에 의한 변화가 결정적임
     * 성장 속도가 빠른 유전자가 이미 사라졌을 수 있으며, 이는 유전적 다양성 감소로 이어짐
     * 다양성 저하는 미래 환경 변화에 적응력 저하를 유발할 수 있음
     * 진화적 변화는 수 세대에 걸쳐 일어나기 때문에, 복구에는 훨씬 오랜 시간 소요 또는 회복 불가 가능성도 있음

  연구 평가 및 시사점

     * 외부 연구자들은 이번 결과를 인간 활동이 진화를 가속할 수 있음을 보여주는 중요한 이정표로 평가함
     * 단순히 개체수 추적에 그치지 않고, 유전자 풀 모니터링의 중요성을 강조함
     * 대구의 사례는 생물 자원 관리와 생태계 복원 정책에 있어 진화적 변화 고려의 필요성을 제시함

        Hacker News 의견

     * 내가 얻은 교훈은 작은 물고기를 방생하면 나중에 커진다는 전제로 실제로는 다 큰 왜소 개체들도 함께 풀어줘 유전자 풀을 악화시키는 현상이라는 점임. 이런 연구 결과가 낚시나 어업에서 어린 물고기를 보호하는 보존 규정에 영향을 줄지 궁금증이 생김
          + 예전에 대구나 송어로 대형 수조 실험에서 무작위로 잡거나 작은 개체를 방생하는 실험이 있었는데, 결국 작은 개체를 계속 풀어주면 여러 세대가 지나면서 평균 크기가 계속 줄어드는 결과 확인됨. 이번에 소개된 논문 저자들도 비슷한 연구를 참고하고 있는데, “실제 서식지에서 유전적 변화가 어업 행위 때문에 생긴 것임을 밝히는 데에는 어려움이 있었지만, 이번 논문은 실험실 결과가 실제 자연에서도 유효하다는 증거를 제시함”이라는 내용임. 관련 연구 참고: PNAS 기사
          + 연어 중에 작은 수컷 ‘잭(Jack)’이 존재하는데, 이들은 예상보다 2년 정도 일찍 산란하러 돌아오는 수컷임. 큰 수컷들이 경쟁해 싸울 때 작은 수컷이 몰래 다가가서 수정하는 ‘스니커(sneaker)’ 전략을 쓰는 상황임. 덩치가 크다고 무조건 유리한 건 아니고, 작은 개체도 번식 성공 가능성이 높은 진화적 이득이 있음. 참고 기사: What's up with Jack?
          + 이 경우에는 작은 크기가 진화적 이점이므로 이런 결과가 자연스러운 현상임. 반면, Maine lobster의 경우 수명이 길어서 큰 수컷과 알을 가진 암컷을 풀어주기 때문에 점점 더 커질 가능성 있음. 두 집단의 비교가 쉽지 않음
          + 저인망 어선은 예전에는 크기 구분 없이 모두 잡아들이는 경우가 많았음. 좋은 분류 장비와 최저 크기 규정은 최근에 도입된 것임. 관련해서 동부 발트해 대구 관련 규정이 바뀌었지만, 실제로 잡힌 어획량에는 통계적으로 의미 있는 변화가 없었고, 분류 장비 효과도 드러나지 않았다는 연구 결과 존재함. 상세 연구: Springer 링크
          + 이와 관련된 10년 전 논문도 참고할 만함: Science 논문
     * 발트해에서는 농업혁명 이후 수십 년간 비료와 농약이 흘러들어가면서 물고기들이 중금속과 독성 물질로 가득 차 있는 상황임. 스웨덴 정부는 한 달에 한 번 이상 섭취 금지, 임신부와 건강상 문제 있는 사람은 아예 섭취 금지 권고중임. 농업 오염으로 바다 밑바닥이 완전히 죽은 구역도 많아짐
          + Chesapeake Bay의 게도 비슷함. 80% 이상이 PCB 및 중금속 오염 상태이고, 규제 기관에서는 한 달에 한 번 이상 먹지 말라는 권고 중임. 대구는 저서성 어종이라 바닥에 가라앉는 오염물에 직접적으로 노출됨
          + 이런 상황에 대해 “늘 그렇듯 아무도 책임지지 않는다”는 씁쓸함 존재. EU의 고질적 문제로 보는 시각도 있음
     * 마오리 어부들이 가장 큰 물고기를 남겨두고 중소형만 잡았다는 얘기를 본 적 있음. 큰 개체가 번식에 유리하다는 논리적 배경이 있다고 생각함
          + 그 이야기는 장어에 대한 것임. 어떤 사람은 강이나 하천을 따라 장어를 잡아 생계로 삼았는데, 가장 큰 개체, 이른바 ‘퀸’을 남겨두었다고 함. 관련 기사: 뉴질랜드와 장어 이야기, 죽은 장어 대량 발견 기사
          + 대부분 어류는 덩치가 클수록 알이나 정자가 많아짐. 그래서 더 큰 개체가 번식에 유리한 경우가 많음. 특히 참치 등 일부 어종은 가장 큰 개체를 보호 차원에서 일부러 잡지 않기도 함
     * 발트해 대구의 문제는 염도가 충분하지 않다는 점에도 기인함. 산란 시 알이 특정 염도로 알맞은 수심에 도달해야 번식 가능한데, 지금은 그 조건이 충족되지 않음. 관련 라트비아 뉴스 기사: nra.lv 기사
     * 뉴스 제목 길이 때문에 80자 제한에 맞춰 잘라 올렸음. 동부 발트해 대구 이야기에 해당하는 내용임
          + “과학자들이 동부 발트해 대구가 수십 년간 작아진 이유를 찾아냄” 또는 “과도한 남획, 유전자풀 악화로 인한 크기 감소 원인 규명”처럼 표현 가능함
          + “동부 발트해 대구 수십 년간 크기 감소, 과학자가 이유 규명”도 간결하게 요약 가능함
     * 이 때문에 나는 모기를 두려워함. 계속 공격하다 보면 결국에는 모든 것에 저항성을 가진 ‘슈퍼 모기’가 될 것이라는 걱정 출현. 이들이 인간을 위협하는 새로운 질병을 찾게 된다면 인류는 속수무책임. 내 생각에 기후변화 같은 환경 재난보다 모기가 더 심각한 위협이라고 생각함
          + 기술과 밈(문화 코드)은 유전자보다 훨씬 더 빠르게 확산됨. 모기의 적응 속도가 그렇게까지 걱정할 만큼 압도적으로 빠르진 않음. 미국에서 매년 수십만 명이 말라리아로 사망했다면 치료제는 코로나처럼 빠르게 대중화됐을 것임. 이미 효과적인 치료법이 있지만 널리 쓰이지 않을 뿐임
     * 기사에서 마치 대구가 스스로 크기를 줄인 것처럼 보이게 쓴 표현이 마음에 들지 않음. 실제로는 다윈의 진화론, '자연 선택'의 전형임. 이번 경우에는 그물에서 빠져나가 살아남아서 번식하는, 작은 크기가 '생존에 최적화'된 결과임. 한 번 유전자풀이 이렇게 바뀌면 원래 다양성 회복까지는 수천 년의 시간이 걸림. 이는 모든 생명에 해당하는 이야기임
          + 그런데 실제 기사 내용 보면 30년 만에 큰 대구 유전자가 거의 사라질 수 있다고 나옴. 이제 대구가 보호받으니 30년 만에 다시 원래 유전자분포로 되돌아갈 수도 있다는 의견임
     * 이번 내용 들으니 상아 없는 코끼리 이야기도 떠오름. 관련기사: National Geographic - Tuskless Elephants
     * 필립 글래스가 5번 교향곡에서 인용한 구절이 떠오름. “그러므로 땅이 애도함에 거기 사는 모든 생명, 들짐승, 새, 심지어 바다의 물고기까지 사라져간다”는 인용임
          + ‘고기: 먹을 것인가 말 것인가’라는 필립 글래스의 글도 추천함. 참고 링크: Tricycle Magazine, https://tricycle.org/magazine/meat-eat-it-or-not-philip-glass/"">웹 아카이브. 영적이고 시적인 관점인데, 나는 여기서 가장 큰 문제인 번식 자체에 대한 고통이 빠져있다고 생각함. 도살 자체보다 혹독하고 장기적인 번식 환경이 더 잔인함. 둘이 함께 일어나지만 도살만 자연스럽고 빠르다고 치부하는 것은 공정하지 않음
     * 대구 어획과 인간의 역사, 그리고 남획이 대구 자원에 어떻게 영향을 주었는지에 대해 매우 훌륭한 책이 있음: Cod: A Biography of the Fish That Changed the World 추천할 만한 책임. 주제가 조금 지루하게 보일 수 있지만 실제로 읽어보면 최고의 책 중 하나였음
          + ‘Salt’ 저자이기도 한데, 비슷한 이유로 똑같이 흥미롭게 읽힘. 분량도 훨씬 짧은 편임
"
"https://news.hada.io/topic?id=21872","Bitchat - 블루투스 메시 네트워크를 이용한 분산형 메시징 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Bitchat - 블루투스 메시 네트워크를 이용한 분산형 메시징 앱

     * 인터넷, 서버, 전화번호 없이 블루투스 메시 네트워크 위에서 동작하는 IRC 스타일의 안전한 분산형 P2P 메시징 앱
     * E2E 암호화, 채널 기반 그룹 채팅, 오프라인 메시지 저장·전달, 커버 트래픽 등 프라이버시 중심 설계
     * 계정, 전화번호, 서버 없이 기기 간 자체적으로 자동 연결 및 메시지 전달 수행
     * IRC 스타일 명령어와 직관적 UI로 단순하지만 강력한 채널·사용자 관리 경험을 제공
     * iOS, macOS에서 네이티브로 지원하며, 안드로이드 호환을 고려한 프로토콜 설계
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

     * Bitchat은 인터넷, 서버, 전화번호 없이 블루투스 LE 메시 네트워크만으로 동작하는 안전한 분산형 P2P 채팅 오픈소스 프로젝트
     * 이 앱은 오프라인 환경, 재난 상황, 네트워크가 불가능한 곳 등에서 가장 간단하고 안전하게 소통 가능한 대체제

주요 기능

     * 완전 분산형 메시 네트워크: 블루투스 LE 기반 자동 피어 탐색 및 다중 홉 메시 릴레이 지원
     * 엔드 투 엔드 암호화: X25519 키 교환 + AES-256-GCM 적용, 디지털 서명(Ed25519) 및 세션별 키 갱신 통한 프라이버시 강화
     * 채널 기반 채팅: 토픽 중심 그룹 채팅, 비밀번호 보호 옵션, 소유자 중심 메시지 보관 제어
     * 스토어 & 포워드: 오프라인 피어를 위한 메시지 캐싱 및 재접속 시 자동 전달
     * 프라이버시 최우선: 계정, 전화번호, 영구 식별자 미사용, 모든 데이터는 기본적으로 기기 메모리에만 저장
     * IRC 스타일 명령어: /join, /msg, /who 등 익숙한 명령 지원, 빠른 채널 이동과 유저 관리 가능
     * 메시지 보존: 채널 오너가 채널별 메시지 저장을 선택적으로 활성화 가능
     * 범용 앱: iOS, macOS 네이티브 지원
     * 커버 트래픽: 랜덤 딜레이로 타이밍 난독화, 더미 메시지로 네트워크 분석 방지
     * 긴급 완전삭제: 로고 3번 탭으로 모든 데이터 즉시 삭제
     * 성능 최적화: LZ4 압축, 적응형 배터리/네트워크 모드, Bloom filter 기반 중복 감지, 네트워킹 효율화 적용

주요 사용법

     * 앱 실행하여 닉네임 설정 후 자동으로 인근 피어에 연결, /j #channel 등 명령어로 즉시 채널 생성·참여 가능
     * 채널 비밀번호 설정(/pass), 메시지 보관(/save), 소유권 이전(/transfer), 멘션(@nickname) 등 다양한 채팅 기능
     * 오프라인 상태에서도 메시지 전송 및 재전달 자동 지원

보안 및 프라이버시 보호

     * 가입 없음: 계정, 이메일, 전화번호 미필요
     * 기본 휘발성: 메시지는 기기 메모리에만 저장
     * 커버 트래픽: 무작위 지연, 더미 메시지로 트래픽 분석 방지
     * 긴급 삭제: 로고 3번 탭으로 데이터 즉시 삭제
     * 로컬 우선: 완전 오프라인, 서버 불필요

라이선스

     * Public Domain(퍼블릭 도메인)으로 공개
     * 누구나 상업적/개인적 수정/배포 가능

        Hacker News 의견

     * Apple의 Find My 네트워크에서 영감을 받은 개념을 가지고 여러 아이디어를 테스트 중임 사람들이 사용하는 단말기를 활용해 블루투스, UWB, Wi-Fi Direct 등으로 메시지가 주변 기기를 통해 전달되는 탈중앙화, 지연 허용 메시징 시스템 구상임 발신자가 메시지를 보낼 때 소액의 수수료를 내고, 메시지를 중계하는 단말기는 전송당 소액의 보상을 받는 구조임 종단 간 암호화, 완전한 탈중앙화, 선택적 익명성도 포함됨 전통적인 인터넷 없이 사람들의 폰만으로 동작하는 “우체국 네트워크” 구상임 인터넷이 불안정하거나 검열이 심한 곳에서 특히 유용할 수 있음 과제는 실시간성이 부족하고 신뢰성, 남용/스팸 방지, 배터리, 사용자 동의, 인센티브 구성임 실제로 가치있는 실사용 사례가 있을지, 아니면 그저 흥미로운 학문적 실험일지 궁금함
          + Helium Network도 유사한 아이디어를 고정 인프라로 시도한 사례가 있음 사람들이 Helium 노드를 설치하고 중계 교통량에 따라 마이크로 결제를 받을 수 있도록 유도했지만, 다양한 꼼수와 부정행위 동기가 생겨 문제 발생함 시간이 지나면서 실제 통신 사용자는 거의 없고, 노드 온라인과 트래픽 중계 자체에만 초점이 맞추어진 일종의 ‘조가비 게임’으로 전락함 토큰은 사실상 투기용 자산으로 쓰이게 되고 본래 의도와 동떨어짐 저렴하고 오버헤드 낮은 스테이블 코인이 이런 사례에 도움이 될 수 있겠지만, 모든 프로젝트가 투기가 되려는 유혹에 빠짐 진정한 스테이블 코인이 언젠가 등장하길 기대하지만 아직 본 적 없음
          + ""인터넷이 불안정한 곳에서 잘 동작한다""는 설명이 모순되어 보임 실제로 메시지 네트워크는 참여 기기가 많을수록 잘 동작함 반대로 인터넷이 불안정한 곳엔 기기 참여가 오히려 적을 가능성이 높음
          + 이미 거의 구현된 비슷한 솔루션이 있음 Reticulum 개발에 참여해보고, Sideband 앱을 기기에 설치해 사용 가능함 Sideband는 LXMF라는 Reticulum 기반 P2P 메시징 프로토콜을 사용함 Reticulum은 전송 계층에 구애받지 않는 탈중앙 네트워크 스택임 이 비전을 실현하려면 LoRa 모듈이 폰에 통합되거나, 또는 Reticulum용 블루투스 메쉬 인터페이스만 만들어도 실제로 구현 가능함 Reticulum의 메인 프로그램은 rnsd이고, 다양한 무선 인터페이스(WiFi, LoRa 등) 간 경로 설정 지원함 블루투스 메쉬를 새로운 인터페이스 타입으로 추가하면 제시된 비전 그대로 구현 가능함
          + Meshtastic이라는 솔루션도 주목할 만함 Meshtastic 참고 인터넷이 필요 없는 오프그리드 탈중앙 텍스트 메시징, 암호화 지원, 진입 비용 낮음(노드당 $30 미만) 펌웨어 오픈소스(ESP32 Wi-Fi는 예외), 커뮤니티도 활발함 Meshmap 통해 내 주변 공개 노드 위치 확인 가능함
          + 실제로 유용하게 쓰일 경우로 크루즈선 내에서의 활용을 제안함 크루즈선 인터넷은 비싸거나 잘 되지 않는데, 실제 필요한 건 같은 배에 있는 사람끼리 WhatsApp 스타일로 메시지 교환하는 것임 대형 음악 페스티벌 등 원격지 이벤트에서도 비슷한 문제 있음
     * 음성 통신을 위해 개발한 ‘Murmur : Bluetooth Group Calls’라는 앱 사례 공유함 앱스토어 링크 블루투스 LE 기반 메쉬로 그룹 음성 통화와 메시지 기능 제공, 안드로이드/iOS 지원 다운로드는 거의 없으나, 실제로 자전거 타면서 뼈전도 헤드폰과 함께 가족과 소통하는 용도로 직접 사용 중임
          + 다운로드가 적은 이유가 마케팅 타깃이 명확하지 않아서일 것 같음 예를 들어 모터사이클 라이더들을 위한 대안 제품으로 마케팅하면, Sena 같은 전용 하드웨어($400 이상)와 경쟁할 만함 사용이 쉽고 바이커들을 타깃으로 한다면 이용자 유치 가능성 있음
          + 진정한 블루투스 메쉬 네트워킹 앱이라는 점이 인상적임 Briar 앱도 뛰어나지만 실제 메쉬 기능은 한계 있음 관련 Reddit 논의 이전 HN 논의 Murmur가 종단간암호화(E2EE)를 완전히 지원하는지, 오픈소스인지 궁금함 오픈소스이자 E2EE라면 진짜 유용한 블루투스 메쉬 앱이 될 수 있음
          + BLE의 거리 성능이 궁금함 자전거 주행 같은 상황에서 거리에 따라 실제 사용이 가능한지 궁금함
          + 네트워크 전환이 자동으로 원활하게 이뤄질 수 있는지 궁금함 필요에 따라 셀룰러, Wi-Fi Direct로 전환이 된다면 정말 대단할 것 같음 오픈소스라면 직접 기여하고 싶음, 앱 직접 사용해볼 예정임
          + 기술은 멋지지만 실제 사용 사례가 뭔지 궁금함 해외여행 중 심카드 없이 사용할 수 있다는 점은 장점이지만, 셀룰러 네트워크에 접근가능하다면 그게 더 낫지 않을까 하는 의문이 있음
     * 이 앱이 App Store에 올라갈 수 있는지 궁금함 Apple은 근거리 통신에 제약이 많아, 망 밖에선 폰끼리조차 제대로 통신할 수 없음 Apple이 iMessage를 AirDrop처럼 근거리 P2P용으로 확장하면 좋을 것 같음 두 사람 모두 화면 켜진 상태라면 굳이 인터넷 없이도 메시지 전송이 가능할 텐데, 굳이 Notes 앱을 왔다갔다 하는 건 비효율적임
          + Apple이 이 기능을 추가해야 할 설득력 있는 사용 사례가 궁금함 블루투스 범위 내인데 와이파이, 셀룰러가 모두 안 되는 상황에서 문자보낼 일이 얼마나 있을지 궁금함
          + README의 ""Building for Production""에 따르면 App Store 배포 가능성 있음 다만 이 앱이 틈새 시장용이라는 점과, Mac이 없으면 빌드가 번거로운 점이 아쉬움 크로스플랫폼 구축이 되었으면 더 좋았을 것 같음 블루투스 메쉬 네트워크가 실제로 넓은 범위에서 잘 동작하려면 아주 많은 기기가 필요함 Fork나 별도 스택으로 개선해보고 싶음
          + App Store에 의존하지 않고 직접 오픈소스 버전을 사용할 수 있으면 더 좋겠음 Apple의 ""믿고 써라""보다는 오픈소스로 내가 직접 운영하고 싶음
     * X(트위터)에 TestFlight 링크가 올라옴 Jack의 트윗 Jack이 직접 코드 푸시하는 모습이 흥미로움
          + 관련 저장소의 거의 모든 코드는 LLM(대형언어모델)이 생성한 코드임 커밋, 코드 구성, 문서의 어투를 보면 알 수 있음
          + TestFlight 자체 링크가 있는지 궁금함
          + 실제로 Jack 계정이 쓴 커밋은 거의 없고, 대부분은 nothankyou1가 작업함
     * 이름을 보고 “bitch at”이라고 읽어서 GPS 애견 목걸이 같은 건 줄 알았음
          + 예전 IRC 클라이언트 BitchX에 대한 오마주라고 생각함
          + 바로 그렇게 느끼진 않았지만 익숙하다는 느낌이 들어 다시 한 번 쳐다보게 됨 일부 기업 필터링(메일/서버 등)에서 걸릴 수 있을지 잠깐 궁금해짐
          + “내 수컷 강아지에겐 전혀 작동 안 했음, 별 하나”
          + 나도 보고, 사람들한테 소리치고 불평하는 공간 같다고 생각함
          + bruh(당황 표현)
     * Meshtastic에 관심 있었지만 별도 하드웨어가 필요하다는 점에서 다른 사람 설득이 어려웠음 Apple이 AirTag처럼 이런 방식을 도입한다면 정말 좋을 것 같음 LoRa 프록시로 메시지 범위 확장하는 방법도 있으면 더 좋겠음 Meshtastic 기기로 직접 시도해볼 계획임
          + 블루투스 트래킹 태그와 같은 아이디어로 Arduino 라이브러리 개발 중임 BLE, UDP 기반 메쉬 네트워킹 지원, MQTT 연동 가능함 MQTT 노드는 패킷을 주제별로 라우팅/구독하여 누구와도 통신 가능함 목적지 주소는 롤링코드 방식이라 1시간 이상 접속 추적 어려움 웹앱도 있고, Messagepack 페이로드 사용해 확장성 높음 모든 패킷은 대칭키 암호화/인증/타임스탬프 적용, 리플레이 공격 방지 신뢰는 상위 계층이나 외부 방식에 맡기고, 연결 상태 관리는 시간당 한 번 ‘announce’ 패킷 발송만 필요함 LoRa는 아직 드라이버를 안 만들었으나, 모듈식 구조라 빌드 가능함 파이썬 포트도 개발 중임 LazyMesh 라이브러리
          + BLE(블루투스저전력)의 안테나 효율에 따라 다르지만, 128kbps coded-PHY 모드에서 조향 안테나 없이도 1.5km 이상의 거리 지원 가능함 2.4GHz 특성상 가시거리 한정이지만 그래도 상당함
          + T-1000e 기기가 Meshtastic 입문용으로 꽤 괜찮았음 충전이 번거로운 점은 있지만 충분히 쓸만함, 응급 상황 대비 도구로 설득 쉬움
          + Meshtastic의 UDP 모드가 이런 BLE처럼 동작해, 로컬 블루투스 클라우드와 소수 LoRa 노드가 연동되면 멋질 것 같음
          + LoRa까지 사용한다면, 그냥 p2p 셀룰러 통신도 가능할 것 같음 스마트폰끼리 추가 인프라 없이 상당한 거리까지 직접 통신 가능함
     * 기술 백서도 공개됨 Apple 생태계 한계에서 벗어날 실마리로 보임
          + 백서에 ""bitchat은 BLE 상에 커스텀 메쉬 네트워킹 프로토콜 구현""이라고 명시되어 있음 왜 2017년 블루투스 SIG에서 공개한 BLE 메쉬 네트워킹 표준을 쓰지 않았는지 궁금함
     * 오랜 시간 기다려온 솔루션임 가족과 이벤트(런던, 에어쇼 등)에 가면 군중에 의해 모바일 네트워크가 마비되고 폰이 쓸모없게 됨 몇 미터 떨어진 가족을 놓치기 쉽고, 공개 도메인이라 유지 또는 대체 가능성 없는 앱에 시간 투자하긴 꺼려짐 안드로이드 지원 필요성도 느낌
     * P2P, 지연 허용 네트워크 연구는 흥미롭지만, 블루투스 간 통신 가능 범위 내라면 직접 대화하는 편이 더 빠름 기술적인 관점에선 매우 흥미롭지만, 실사용 사례가 다소 부적절할 수 있음 스마트워치, 자전거 컴퓨터 등에서 직접 폰 연결 없이 활동 정보 업로드나 주변 참가자와 경로 공유용 같은 형태가 더 실용적일 수 있음 폰이나 네트워크가 없을 때 유용함
          + 대화뿐 아니라 파일 전송 같은 다양한 소통 방식 필요함 2025년이 가까워도 여전히 쉽고 안전한 파일 전송 솔루션이 없다는 점이 아쉬움
          + 기술이 유용할 수 있는 몇 가지 사례를 꼽아봄 참가자가 많은 대형 컨퍼런스에서 메쉬 네트워크 형성해 지오태깅 메시지 공유, 블루투스 한계를 넘어 메시지 전달 가능 AirTag 네트워크 같은 인프라를 활용하면 더욱 큰 가능성 있음
     * 굉장히 인상적인 앱이지만, 오직 Apple 기기에서만 가능한 점이 아쉬움 Android 대안으로 BluetoothChat 있음 단, 이 앱은 근거리 채팅에만 한정되고 암호화나 IRC 테마는 없음

   Bridgefy 와 같은 종류의 메시징 앱인 것 같네요
"
"https://news.hada.io/topic?id=21893","Git의 캐리지 리턴 및 클론 RCE 취약점","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Git의 캐리지 리턴 및 클론 RCE 취약점

     * Git 저장소 내 캐리지 리턴 문자를 이용한 공격 기법 소개
     * 이 취약점으로 인해 원격 코드 실행(RCE) 가능성 발생
     * 특정 git clone 과정에서 악성 명령어가 실행됨
     * 리눅스 및 윈도우 환경에서 영향 확인
     * 보안에 취약한 git 저장소 관리의 위험성 강조
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

캐리지 리턴 문자와 Git 취약점

     * Git 저장소 내부에 캐리지 리턴(\r) 문자가 포함된 파일명을 생성할 수 있음
     * 이러한 파일명을 포함한 저장소를 git clone으로 복제할 경우, 명령어 해석 과정에서 의도치 않은 명령 실행이 가능해짐

원격 코드 실행(RCE) 시나리오

     * 공격자는 캐리지 리턴 문자가 삽입된 파일을 추가해 저장소에 커밋함
     * 사용자가 이 저장소를 git clone 하면, 파일 시스템 및 git 명령이 잘못된 해석으로 인해 원하지 않는 코드 실행 위험 발생
     * 특히, 후킹 스크립트(예: .git/hooks 폴더의 코드)가 자동 실행되도록 유도 가능

영향 환경 및 대응

     * 리눅스 및 윈도우 등 다양한 운영체제의 git에서 발생 가능함
     * git 저장소를 관리하거나 외부 저장소를 자주 클론하는 개발자 및 기업에게 심각한 보안 위협임

보안 권고

     * 외부의 신뢰하지 않는 git 저장소 클론 시 최신 버전 사용과 보안 상태 확인이 필요함
     * 저장소 내 특이 문자(특히 캐리지 리턴 등) 포함 파일명을 탐지하고 클론 전 검토 필요함

        Hacker News 의견

     * 이 모든 결과로 서브모듈 클론을 수행할 때, 읽기는 path = ... 형태로 하면서, 쓸 때는 ^M 으로 끝나지 않는 다른 경로로 기록하는 현상 발생 설명
          + 기사에서 말하는 ""원격 코드 실행""이 여기서 어떻게 일어나는지, 그리고 보안적으로 얼마나 심각한지 궁금증 제기
          + 아직 PoC는 공개하지 않았지만, CVE-2024-32002 익스플로잇을 거의 그대로 변형한 내용이며, 이를 수정한 커밋의 테스트도 큰 힌트 제공 언급
          + CVE-2024-32002 설명 인용: 서브모듈이 들어간 저장소를 악의적으로 조작해 Git의 버그를 이용, 서브모듈 워크트리가 아니라 .git/ 디렉터리에 파일을 쓸 수 있음. 덕분에 클론 동작 중에 바로 실행되는 hook을 쓸 수 있어서 사용자가 실제로 실행되는 코드를 점검할 기회조차 갖지 못하는 상황 가능
          + 요약하면, 악성 git hook을 저장소에 넣을 수 있고, 일반적으로 git hook은 ‘git clone’ 시 설치되지 않지만 이번 공격에서는 이를 가능하게 만들어줘서 클론 과정 중 hook 실행 가능성 제시
          + 새로운 CVE에 대한 더 많은 정보는 여기에서 확인 가능성 안내
               o 설정값 읽을 때 Git이 CR, LF 문자를 제거하지만, 기록할 때는 CR을 인용하지 않아 읽을 때 손실 문제 설명
               o 서브모듈 경로 끝에 CR 문자가 포함될 경우, 제거된 경로를 사용하게 되어 서브모듈이 잘못된 위치에 체크아웃 가능성
               o 해당 제거된 경로와 서브모듈 hook 디렉터리 사이에 이미 symlink가 존재할 경우, 공격자가 post-checkout hook을 통해 임의 코드 실행 가능성
               o 이번 CVE 외에도 많은 Git 취약점들이 있으니 함께 살펴볼 가치가 있다는 의견
          + 임의 파일 쓰기가 가능하면 대부분 RCE까지 이어질 수 있다는 단순하지만 불편한 진실 언급
     * ad-hoc DSL로 설정 파일을 쓸 때의 위험성 언급
          + 문법에 대한 공식 명세가 없는 경우가 많고, 파싱에 대한 진짜 기준이 직접 만든 직렬화/역직렬화 구현에 분산되어 있음 지적
          + 둘이 따로 놀면(예를 들면, 파서엔 새 문법 추가했는데 라이터는 반영 못한 경우 등) 파서 차이로 인해 폭탄이 될 수 있음 강조
          + 교훈: 하나의 source of truth를 두고, 그에 의존하는 부분은 이를 기반으로 자동 생성하는 구조 필요하다는 것임
          + 이 버그는 source of truth 문제와는 별개라는 점 지적
               o 순수한 논리 오류로, 만약 유닉스에 이런 표준 시스템 라이브러리가 있었다면 거기서도 똑같이 터질 수 있었던 문제로 설명
               o 만약 그런 표준 라이브러리에 있었다면, 문제의 영향은 훨씬 심각했을 것이고, 지금은 주로 개발자들에 한정되어 피해가 적은 상황이라 언급
          + 여기서 사용된 DSL(ini 파일 포맷)은 ad-hoc이긴 해도 매우 흔하고 익숙하게 잘 정리되어 있어서, 일반적으로 실질적인 명세로 충분하다는 의견
               o 버그의 본질은 포맷 문제가 아니라 중간에 들어간 핸드코딩 파서(또는 렉서)에 있으며, 이런 코드를 이제는 그만둬야 한다고 주장
               o Clever하게 핸드코딩하는 게 필요한 자리는 아직 일부 남아 있지만, 데이터 교환 포맷에는 절대 쓰면 안 되며, ini가 필요하면 toml, 별로면 JSON, 심지어 YAML도 괜찮고, 정말 고통을 찾으면 XML, 꼭 이진 포맷이 필요하다 우긴다면 protobufs 안내
               o 결론적으로, 프로그래밍 언어 저자가 아니라면 직접 파서를 쓰지 말고, 꼭 라이브러리를 활용해야 함 강조
     * 직접 문제 재현 후, 이 저장소에 올림
          + 바로 git 최신 버전으로 업데이트 시도, 아직 Arch에는 적용 안 됨
          + 새로운 패치 전까지는 pull을 자제할 예정, 자동 pull이 걸려있는 유명 저장소에서 문제가 생길 수 있으니 업그레이드에 시간이 많이 걸릴 것 같다는 우려
          + 이번 취약점이 패치 전에 공개된 것이냐는 의문 제기
               o 예전엔 누가 얼마나 취약점 공격 가능한지 설명하는 글이 대부분 패치된 지 몇 달 뒤에 올라왔는데, 요즘은 모든 게시글에서 ""이건 진짜 지금 위험하다""와 ""이미 패치되어 걱정 없다""는 걸 명확히 구별해 지나가듯 언급해주길 바라는 마음
     * 기존 익스플로잇에서 ""간단한 변형만 했다""는 언급 보며, Git이 왜 Landlock을 사용하지 않는지 궁금증 제기(Landlock은 리눅스 전용 샌드박스 보안 기능)
          + ""git clone"" 작업은 config 디렉토리엔 읽기 전용, clone 대상 디렉토리엔 읽기/쓰기 권한, 그리고 하위 프로세스 호출 금지 구조 필요성 제시
          + 익스플로잇마다 항상 계산기 띄우는 딥 모먼트 비꼼
          + 하위 프로세스 호출 금지라면 post-checkout 등 모든 git hook이 깨진다는 문제 제기
               o 필요 없다면 seccomp 같은 컨테이너 환경에서 git 실행도 가능하지만, 많은 기능이 제한될 것임 설명
          + 그리고 하위 프로세스가 없으면 ssh를 통한 git 사용을 못하게 되는 점 지적
     * Homebrew 자체가 문제가 되는지(즉, recursive clone을 하는지) 질문 제기
          + 이 코드에서 가능성 발견
          + 홈브류 목표 자체가 저장소 코드를 실행시키는 것이라, recursive clone이 없다면 오히려 이상할 정도라는 의견
               o 문제는 clone하는 데이터가 실행되면 안 되는 경우에만 RCE가 의미 있는데, 그런 케이스는 드뭄을 지적
     * Jon Postel의 CR+LF 관련 명언을 보며 추억 회상
          + 이 글 링크 및, 2003년과 비교해 지금은 그 조언이 맞지 않을 수 있다는 평가 공유
          + Mark Crispin이 당시 해설했던 대로, 사람들이 오해하고 있다는 것, 1990년대 말 Daniel J. Bernstein가 사람-기계간 변환(parsing/quoting) 과정에서 생기는 문제를 지적했던 사례와 연결
          + 25년이 지나도 CR을 escape하지 않는 quoter 코드 문제가 반복되고, 수정된 뒤에도 whitespace 전부를 체크하진 않는다는 점 관찰
          + git blame 결과, 문제의 코드는 19년 전에 작성된 것으로, Bernstein의 10주년 회고와 시기가 겹침
          + 관련 커밋, qmail 논문 등 추가 자료 공유
          + 결국 20세기 힘들게 배운 교훈을 21세기에도 반복해서 배워야 한다는 현실 강조
     * Homebrew에 git 2.50.1 업데이트가 아직 없어서 조금 더 기다려야 할 듯
          + 이 이슈 혹은 brew install git --HEAD로 업데이트 시도 안내
     * Homebrew와 Debian Bookworm 모두 여전히 취약 버전을 제공 중이라는 사실 공유
          + 이제 Homebrew에서도 2.50.1 버전 사용 가능하다고 알림
     * 디렉터리 목록을 불러오는 시스템 콜이 만약 파일명에 ASCII 제어문자(bytes)가 존재한다면 해당 파일의 존재를 부정해야 하는지, 디스크 손상으로 간주해야 하는지, 아니면 다른 처리를 해야 할지 고민
          + 현재 로케일에서 그 바이트들이 다른 의미를 가질 수도 있으니, 윈도우즈처럼 파일명을 모두 UTF-16으로 가정하는 게 아니니 의외의 상황 발생 가능성 제시
          + Unix 계열 시스템에서 파일명(및 기타 문자열)은 단순한 바이트 배열이기 때문에 생기는 문제임을 간단히 지적
"
"https://news.hada.io/topic?id=21838","에버퀘스트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 에버퀘스트

     * 에버퀘스트는 1990년대 후반 MMORPG 시장에서 주요 성공 사례로, 약 55만 명의 구독자를 확보함
     * 이 게임의 탄생 배경에는 Sony Interactive Studios America에서의 비주류 프로젝트와 열정적인 프로듀서 John Smedley의 주도적 역할이 있음
     * 디자인 철학은 단순함과 재미 추구에 집중하여, 플레이어 간 전투(PvP)를 금지함으로써 접근성과 안정성을 높임
     * 눈에 띄는 3D 그래픽과 적극적 온라인 커뮤니티 전략으로 대중의 관심과 상업적 성공을 거둠
     * 높은 몰입도와 장시간 플레이로 인한 사회적 논란도 촉발했으며, 이후 MMORPG 및 디지털 미디어의 중독성 논의로 확장됨
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

MMORPG 시장에서의 혁신과 에버퀘스트의 등장

     * 1990년대 후반 MMORPG 장르에서 Ultima Online이 개척자 역할을 했음에도 불구하고, EverQuest가 그 뒤를 잇는 두 번째 주자로서 상업적 대성공을 거둠
     * EverQuest의 등장 배경에는 Sony Interactive Studios America(이후 989 Studios)의 스포츠 게임 중심 기업 문화, 그리고 별도의 온라인 게임 프로젝트에 대한 관리진의 낮은 관심이 있었음
     * John Smedley는 개인적 열정과 온라인 Dungeons & Dragons 경험을 결합해, 소규모 팀과 함께 EverQuest의 기획을 주도함

기획과 팀 구성 과정

     * Smedley는 Brad McQuaid와 Steve Clover라는 두 개발자를 San Diego 로컬에서 발굴, 이들과 함께 MMORPG 제작에 착수함
     * 이 팀은 처음 6개월간 독립된 오피스에서 게임의 80페이지짜리 세부 디자인 문서를 완성함
     * EverQuest의 설계는 우연적 실험을 중시한 Ultima Online과 달리, 미리 정밀하게 설계된 구조를 특징으로 함

디자인 철학과 기술적 차별성

     * 에버퀘스트는 심오한 사회 구조나 경제 시뮬레이션보다는, 간단명료하고 액션 위주의 재미에 집중하는 방향을 택함
     * 이 게임은 DikuMUD에서 많은 영감을 받아, 접근성 높은 전투 시스템과 관리·운영의 효율성에 중점을 둠
     * 3DO의 Meridian 59의 베타 테스트를 참고해, 3D 1인칭 시점을 도입함으로써 몰입감과 현대적 게임성을 향상시킴

PvE 중점의 설계와 경쟁 게임과의 차별화

     * 초기 Ultima Online은 이상적인 플레이어 주도 사회 구현을 강조했으나, 현실적으로 플레이어 간 살인(Griefing) 문제가 심각했음
     * 에버퀘스트는 이와 달리 PvE(Player vs. Environment) 를 고집하며, 플레이어 간 전투를 금지해 안전하고 친화적인 게임 환경을 조성함
     * 이 결정이 대다수 MMORPG 유저들에게 호응을 얻으면서, 궁극적으로 에버퀘스트의 급성장과 상업적 성공을 견인함

마케팅, 서비스, 성장 과정

     * 에버퀘스트는 전통적인 오프라인 홍보보다, 온라인 커뮤니티, 뉴스그룹, MUD 출신 유저 등을 통한 게릴라 마케팅에 집중함
     * 1999년 3월 공식 출시 후, 초기 하루 1만 명 이상의 등록자를 기록하며 빠르게 성장함
     * 서버 관리에서 일시적 트래픽 문제 발생, 네트워크 인프라 확장 등 운영상의 도전도 있었음
     * 박스 패키지 확장팩을 포함한 유료 콘텐츠와 월 구독 모델로 신규 수익 구조를 구축함

사회적 파급효과 및 논란

     * 높은 몰입도와 장기간의 플레이 시간으로 인해 early 2000년대부터 게임 중독, 현실과의 단절 등 사회적 우려가 대두됨
     * 실제 유저의 사망 사건, 가정 내 문제 등으로 매스미디어 및 사회학자, 교육자, 보건 전문가가 게임의 사회적 영향력을 논의하기 시작함
     * EverQuest의 “엔드리스 게임플레이”, 영속적 진척 시스템은 긍정적 중독성과 함께, 일부 유저에게는 부정적 심리·사회적 영향을 남김

확장과 경쟁, 영향

     * 에버퀘스트는 2005년 기준 55만 명 최고 동시 구독자를 기록했으며, 수차례의 주요 확장팩을 출시함
     * 이후 World of Warcraft의 등장으로 주도권을 내주긴 했으나, MMORPG 장르 대중화와 온라인 상호작용의 표준을 제시하는데 결정적 역할을 함
     * 게임 내 아이템의 현실 거래(eBay 등), MMORPG 내 ‘세컨드 라이프’적 경험 등도 새로운 시장과 사회문화 변화를 유발함

결론 및 주요 시사점

     * 에버퀘스트의 성공은 대규모 온라인 게임의 사업 모델, 기술적 구현, 커뮤니티와 사회적 책임 논의, 게임 중독성 등 현실 세계의 다양한 이슈를 선제적으로 제기하였음
     * 이 게임이 남긴 다면적 유산은 이후의 온라인 게임은 물론, 디지털 미디어 문화 전반에 걸쳐 지대한 영향을 미침

참고 문헌 및 자료 출처

     * 본문에는 Matthew S. Smith의 EverQuest, Timothy Rowlands의 Video Game Worlds: Working at Play in the Culture of EverQuest, Edward Castronova의 Synthetic Worlds 등 다수 학술서적 및 컴퓨터 게임 잡지, 온라인 뉴스와 블로그 자료 등이 인용됨
     * 대표적 온라인 기사로는 ShackNews의 “Better Together: Stories of EverQuest”, Massively Overpowered의 “The Game Archaelogist: How DikuMUD Shaped Modern MMOs” 등이 있음

        Hacker News 의견

     * 나는 거기 있었던 사람으로서, 처음 급여명세서에는 Verant가 찍혀 있었고 SOE로 넘어가기 직전에 입사한 기억을 갖고 있음. 사람들이 잘 모를 수 있는 사실은, MMO 구독 수익 덕분에 회사 내부에서 여러 실험이 자유롭게 이루어졌다는 점임. 발매되지 않은 MMO RTS 프로젝트도 있었고, 여러 장르를 MMO로 만들어볼 수 있을지 시도해 본 적 있음. 그리고 SWG가 대표적인 예임. 덕분에 EQ2에는 굉장히 독특한 멤버들이 있었음. Ken Perlin이 대사로 얼굴 애니메이션을 동기화하는 립싱크 작업을 했고, Brian Hook은 렌더러 작업에 참여했음. 그 외에도 여러 재능 있는 인재들이 있었음. 우리가 실제로 하지 않은 일도 많았음. JK Rowling과 해리포터 MMO 관련 미팅 때문에 해리포터 시리즈 전권을 정독하기도 했지만, 협상은 결렬됨. 격동의 시기였음. 추가로 기사에 언급된 분들 중 Brad
       McQuaid와 Kelly Flock 등은 이제 세상에 없음. SOE가 위치했던 Terman Court의 사무실 단지도 이미 오래전에 철거됨. 마지막 날 내 사무실 문에 서서 유칼립투스 나무를 바라보며 이 광경을 다시는 못 볼 거란 사실을 묵상했는데, 정말 그 예감이 맞았음
          + 흥미로운 이야기임. MMORTS 실험까지 했다는 건 몰랐음. 나는 WoW가 성공한 이후 개발됐지만 출시되지 못한 MMORTS 프로젝트의 리드 엔지니어였음. RTS를 MMO로 바꾸는 건 정말 어려운 장르라는 생각임. 관련 영상
          + 나는 EverQuest를 못 해봤지만 SOE의 또 다른 게임에서 추억이 많음. 고등학교 내내 Cosmic Rift에 중독됐었음. 근데 누군가 갑자기 구독제로 바꿔버리는 바람에, 게스트 계정으로 접속해서 체험하는 재미가 없어졌고, 그 결과 커뮤니티도 무너졌으며 결국 게임도 얼마 안 가 사라졌음. 그 뒤로 Cosmic Rift의 전신인 Subspace로 돌아갔고, 그 이후 Kazaa, Skype, Joost로 유명한 PriitK가 커뮤니티와 함께 클라이언트를 새로 개발해서 Continuum이라는 버전으로 나옴. 그 게임을 10년 넘게 플레이했음
          + SWG 베타 당시 정말 멋진 시간을 보냈음. 목표했던 그 거대한 야망이 결국은 게임의 발목을 잡아서 아쉬웠음. 고마움의 마음임
          + EQ 덕분에 게임과 기술의 발전 가능성을 깊이 생각할 수 있었음. 직접적으로 내 게임 인생에 영향을 크게 미친 혁신적인 경험이었음
     * 중요한 소식임. Daybreak가 EverQuest 에뮬레이터 서버인 The Heroes Journey를 상대로 소송 중임. 이 서버가 독특한 방식으로 원작보다 더 인기를 끌고 있는 상황임. 서버 운영자들은 커뮤니티에 긍정적인 결과를 위해 최선을 다하고 있으며, 사실이 자신들 쪽에 있다고 믿는다고 밝힘. 자세한 소송 상황은 여기 참고, 에뮬레이터 FAQ는 여기
     * EverQuest를 정말 사랑했음. 내 인생 최고의 게임 추억 중 하나임. 그 당시에 실제 세상에 들어온 느낌, 게임보다 세상이 먼저인 느낌이 유독 강했음. 위험과 경이로움이 가득했고, Qeynos에서 Freeport로 바다를 건너 배를 타는 긴 여정은 지금도 잊을 수 없는 서사적 경험임. 하지만 지금은 게임에 투자할 시간이 없어 예전 느낌을 다시 갖긴 어려울 듯함
          + 그 시절에는 두 번째 모니터로 게임 위키를 켜놓고 자세한 정보나 지도를 찾아볼 수 없었음. 전부 스스로 시행착오와 탐험을 통해 배우거나, 게임 속에서 다른 사람들과 직접 소통하며 알아냈어야 했음. 어떤 던전을 안전하게 통과하는 방법을 아는 사람들을 보면 정말 존경스러웠음. 애써서 얻은 지식임이 틀림없음. 요즘 그런 경험을 재현하려면 세계가 매번 무작위로 변화해서 기존에 만들어진 모든 가이드가 소용 없게 해야할 텐데, 현실적으로 그 시절 창조적 경험의 창은 닫힌 것 같음
          + Freeport까지의 먼 여정이 내게도 특별한 추억임. 정보도 없고 레벨도 낮은 초보 시절, 낯선 이들에게 도움을 청하면서 죽을까 두려워했던 기억, 도중에 모든 소지품을 잃고 되찾기 위해 뛰어다녀야 했던 긴장감이 마법 같았음. Mithaniel Marr 서버에서 평범한 인간 팔라딘으로 활동했음. 여러 의견에 공감하며, 1999년 당시 처음으로 완전히 새로운 세계를 만나는 듯한 놀라운 감각이었음. 지금은 이런 마법이 평범해졌기에, 다시는 똑같이 느낄 수 없을 듯함
          + 도시 간 이동이 EQ에서 제일 재미있는 부분이었음. 다른 부분은 별로였음. 하지만 미리 경로를 공부하고 준비하면 어느 정도 도달할 수 있지만, 항상 위험이 도사리는 도전적인 경험이었음. 이런 여행 중심 게임이 혹시 있을지 궁금함
          + 나는 개인적으로 EQ가 싫었음. UO가 지향하던 진짜 살아있는 세계가 사라진 느낌이었음. 그런데 EQ는 당시 평범한 게이머가 원하는 방향의 게임이었고, UO에서도 시간이 지날수록 그 흐름이 보였음. 결국 WoW가 그 방식을 완성했다고 생각함. UO가 원했던 모습이 제대로 구현되지 못한 건 아쉬움임. 플레이어들이 대부분 두 부류로 나뉘었는데, 어느 쪽도 UO 원래 비전과 맞지 않았고, 결국 한쪽이 다른 쪽을 몰아내며 역사가 결정됨
          + 내 EQ 첫 기억은, 튜토리얼 퀘스트를 마친 뒤 밤길을 뛰다가 사자에게 잡아먹힌 사건임. 아무것도 몰랐지만 알아낼 생각에 푹 빠졌던 기억임
     * 초기 EverQuest에서는 단순한 몬스터조차 강해서 반드시 파티 플레이가 필요했고, 거대한 맵과 던전, 매매도 모두 동굴안에서 직접 외쳐야 했음. 26년이 지난 지금도 가끔 향수에 젖어 Project Quarm이나 Project 1999 서버를 켜서 해보지만, 실제로 플레이하는 것보다 추억이 훨씬 더 소중하게 느껴짐. 바쁜 직장과 아이 셋을 둔 지금은, 어떻게 그때 그 긴 시간 게임을 했는지 스스로도 신기함
          + EQ의 루클린 바자회는 지금도 내가 만난 게임 시스템 중 가장 독특하고 멋졌던 것임. 캐릭터를 주차시켜 상점을 개설하고, 직접 돌아다니며 각 상점별로 아이템을 확인할 수 있었음
          + 그 동굴 장터에선 사기도 있었음. 거래창을 닫았다가 똑같은 아이콘의 저급 아이템으로 빠르게 바꿔서 다시 열곤 했음. GM이 뭔가 조치했는지는 모르겠지만, 난 항상 구매 전 아이템을 꼼꼼하게 확인했음
     * 내가 플레이하던 도시에선, 경비병을 위한 퀘스트를 너무 많이 해서 ""부패한 경비병"" 평판이 망가지고, 결국 그 경비병이 날 보면 즉시 공격했음. 선량한 캐릭터를 플레이하다가, 실제로 가장 많은 시간을 보낸 도시에서 더 이상 플레이를 못하게 됐음. 억울할 법하지만, 이런 독특한 시스템을 본 적도 없고, 다른 어떤 게임에서도 비슷한 경험을 못 했음
          + 부패한 Qeynos 경비병―Qeynos는 SonyEQ를 반대로 쓴 이름임. 특정 종족/직업에 따라 경비병이 적대적으로 변하는데, 깊은 악감정이 쌓이기 쉽고, Plains of Karanas 서쪽 경비탑에 있는 부패 경비를 잡고 뱃지를 정직한 경비에게 넘기면 중간 레벨까지 훌륭한 경험치를 얻을 수 있었음. 평판은 저레벨 퀘스트로 천천히 복구도 가능함
          + WoW에서는 Booty Bay에서 유사한 시스템이 있었음. 해적을 죽여 Booty Bay 평판을 올린 다음, 다시 경비병을 잡아 Bloodsail Buccaneers 진영 최고 평판을 달성해야 했음. 2.5배의 명성 노가다는 몇 주가 걸렸고, 다 끝나면 경비병이 바로 공격해서 Booty Bay에 접근조차 못 했음. 우리가 하는 일은 정말 재미있음
     * 대학 4학년 때 EQ를 시작해서 학사 경고로 학교를 그만뒀지만, 최고의 추억임. 새로운 서버에 직접 길드를 만들었고, 서버 전체에서 유명하고 강력한 팀으로 성장시켰음. 대규모 길드를 이끄는 데엔 엄청난 계획과 관리가 필요했고, 거기에 시간과 열정을 쏟았음. 플레이어 참여도와 아이템 분배 공정성을 위해 PHP 3와 MySQL로 최초의 ""루팅"" 웹 앱 중 하나도 직접 제작했음. World of Warcraft 개발팀의 많은 멤버가 우리 길드 출신임. 기억에 남는 순간들로는, 거의 완성되지 않았던 엔드게임 지역인 Plane of Air에서 깊은 곳까지 들어간 경험, 원래 '킬 불가'였던 Avatar of War를 다수의 인챈터가 경호원을 컨트롤하여 처치하는 방식으로 공략해 성공했던 사건이 있음. 곧바로 패치되어 경호원은 더이상 조종이 불가해짐. 엔드게임 지역의 사망 패널티도 매우 까다로웠음.
       열쇠 아이템이 시체에 들어 있어서, 전멸하면 시체를 회수하기까지 몇 시간이 걸렸음
     * EverQuest에서 처음으로 스스로 선택하고 그 결과에 책임지는 주체성을 경험했음. 10대 시절, 공략과 시스템을 연구해서 길드 운영 효율을 높이고, 내가 한 노력이 대규모 조직 전체의 성공에 실질적으로 도움이 되는 상황이 정말 강렬한 동기부여였음. 어른들이 내 근성과 아이디어를 존중해준 것도 학교에서 못 느꼈던 특별함이었음. 그 정도의 성장 실감은 ""진짜"" 커리어를 쌓은 후 10년 정도 지나서야 다시 경험했음
     * 네덜란드 10대들이 렘브란트 명화 앞에서 스마트폰만 쳐다보는 Gijsbert van der Wal의 2014년 사진이 종종 디지털 중독 세대의 상징처럼 쓰이는데, 내 관점에서 그들은 수업이나 현장학습 과제를 하고 있는 모습일 뿐임
          + 뭐든 가능하지만 그 사진이 유독 공감대를 얻는 이유가 있음. 기술과 소셜미디어의 부정적 면을 체감하는 사람들이 많고, 예전의 소박한 시절을 그리워함. 물론 스마트폰의 이점도 크지만, 우리가 그 대가로 무엇을 잃었는지도 충분히 이해함
     * '고블린 엉덩이'가 WoW 스크린샷인 것처럼 보임. EQ에도 비슷한 모델이 있었지만, 저 이미지는 WoW 스타일이 확실함. EQ의 고블린 뒷모습은 여기에서 볼 수 있음
     * 내 커리어의 시작을 EverQuest에 단독으로 돌릴 수 있음. ShowEQ와 eqemu 커뮤니티에서 PHP로 서버 관리 앱을 만들면서 시작해, x86과 C++ 리버스엔지니어링까지 갈고 닦았음. Kelethin의 리프트 구현을 하려다 그랬음. 지금도 새로운 그래픽 API나 게임엔진을 만질 때마다 어김없이 EQ 존 렌더러를 만들고 있음. 내 인생 최고의 게임은 아니었지만, 가장 큰 임팩트를 준 게임임. 또, 커뮤니티가 내실있어서 엄청난 자극을 받았고, 많이 배울 수 있었음. 13살에 ""ROT13이 무슨 깨지지 않는 암호야?""라고 채팅하다가, 이후 능숙한 리버스 엔지니어로 성장했던 과거가 생각나서 웃음 지음
          + 나 역시 EverQuest 자동화를 통해 스크립팅이란 개념을 처음 배움. Misty Thicket Picnic 파밍용 경로 자동화 스크립트로 경로 탐색에 기초 지식을 쌓았고, UI 오버레이를 만들어 기본 창을 대체해 봤음. 그리고 해킹 플러그인 디스어셈블을 통해 포인터, 점프, 디스어셈블리를 직접 익힘
          + 나도 mq2 매크로가 13살 인생의 첫 프로그래밍 언어였음
          + ShowEQ를 통해 Linux 배우고 환경설정 경험을 쌓음. 부트 매거진 CD로 Debian 설치하다 PC를 망칠 뻔했던 초창기도 있었음. XFree86 설정 잘못했다가 모니터가 고장날까봐 덜컥 겁났음
"
"https://news.hada.io/topic?id=21871","BunkerWeb - 클라우드 네이티브 웹 방화벽 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    BunkerWeb - 클라우드 네이티브 웹 방화벽 오픈소스

     * NGINX/Reverse Proxy와 WAF를 결합한 차세대 오픈소스 Web Application Firewall(WAF)
     * 강력한 보안 설정을 기본 제공하며 기존 환경(Linux, Docker, Kubernetes 등)에 손쉽게 통합 가능
     * 직관적인 Web UI와 다양한 환경 설정·확장 플러그인 시스템으로 완전한 커스터마이즈 및 운영 편의성 보장
     * 주요 특징
          + 쉽고 강력한 통합 보안 기능: HTTPS(LE 자동화), ModSecurity(OWASP Core Rule Set), HTTP 헤더 강화, TLS 하드닝 등 핵심 보안 기능 내장
          + 자동화 및 운영 편의성: Web UI, 환경변수·라벨·컨테이너 자동설정(autoconf), 멀티사이트 모드, 스케줄러 등 실전 운영 최적화
          + 봇 차단/비정상 요청 탐지: 쿠키·JS·캡차(hCaptcha/reCAPTCHA) 기반 봇 방어, 상태코드 기반 자동 차단, 외부 IP 블랙리스트 연동
          + 확장 플러그인 시스템: ClamAV/VirusTotal 파일 검사, Slack/Discord/Webhook 알림, 대체 WAF(Coraza) 등 공식 플러그인 제공
     * 지원 환경 및 연동
          + 통합 지원: Linux, Docker, Kubernetes, Swarm, Microsoft Azure 등 다양한 환경에 맞춤 적용
          + 설정 방식: 환경변수/라벨 기반 설정, 멀티사이트 지원, NGINX/ModSecurity 커스텀 구성 가능
          + 데이터베이스: SQLite, MariaDB, MySQL, PostgreSQL 지원
          + Web UI: 보안 이벤트 모니터링, 설정/플러그인 관리, 로그 검색, 인스턴스 운영 제어
     * 오픈소스(AGPLv3)와 PRO 버전(모니터링, 사용자 경험 강화 등) 중 선택 가능
          + Pro는 엔터프라이즈 대응 기술지원·모니터링·컨설팅 등 전문 서비스 제공
"
"https://news.hada.io/topic?id=21892","오프체스 – 오프라인 체스 퍼즐 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          오프체스 – 오프라인 체스 퍼즐 앱

     * OffChess는 오프라인 환경에서도 체스 퍼즐 풀이가 가능한 앱임
     * 체스 실력 향상 및 전술 연습에 초점을 둔 앱 제공임
     * 광고나 필수적인 결제 없이 자유로운 사용 가능함
     * 다양한 수준별 퍼즐 난이도 지원으로 초보자부터 고수까지 활용 가능함
     * 네트워크 연결이 불필요해 이동 중이나 인터넷이 불안정한 환경에서도 사용이 용이함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

소개 및 중요성

     * OffChess는 인터넷 연결이 없는 상태에서도 체스 퍼즐 문제를 풀 수 있게 해주는 앱임
     * 오프라인에서 작동하여 데이터 소모가 없고, 언제 어디서든 체스 실력 강화와 전술 학습이 가능함
     * 광고 없이 설계되어 몰입감 있는 사용 경험 제공임
     * 난이도별 다양한 퍼즐이 내장되어 초보자뿐 아니라 경험자에게도 적합함
     * 앱 내 결제가 필수가 아니며, 사용 장벽을 낮춘 접근성 높은 설계임
     * 다른 체스 퍼즐 앱과 달리 네트워크 연결 제한이나 로그인 없이 바로 이용 가능함

주요 기능

     * 오프라인 환경에서 즉시 플레이 및 체스 퍼즐 풀이 가능함
     * 난이도별로 구성된 다양한 퍼즐 세트 제공임
     * 기존 온라인 기반 체스 퍼즐 서비스 대비 속도 및 접근성에서 큰 장점 보유함
     * 광고 없는 UX로 체스 학습에 온전히 집중할 수 있는 환경 제공임

활용 및 대상

     * 초보자부터 상급자까지 각 수준별 체스 유저가 모두 활용 가능함
     * 이동 중, 네트워크 불안정 환경 또는 데이터 제한 상황에서도 적극적인 사용 가능성 제공임

기타 정보

     * 별도의 회원 가입, 로그인, 인터넷 데이터 연결 불필요함
     * 앱 형태로 제공되어 모바일 기기에서 직관적인 사용 경험 보장임

        Hacker News 의견

     * 방금 장거리 국제선 비행을 하려고 하는 입장에서 이 앱이 정말 제 타이밍에 딱 맞게 나온 상품 느낌 받은 상황, 유료라는 댓글 덕분에 인터넷이 끊기기 전에 빠르게 결제 화면에 들어갈 수 있었던 경험 공유, 참고로 “Buy now for $3.99”로 표시되지만 실제로는 내 통화 기준 $5.99로 나오는 현상 발견, 지역에 맞는 가격이 버튼에 표시되면 좋겠다는 생각 전달
     * 이 멋진 앱의 출시에는 아무런 흠을 잡고 싶지 않은 심정, 곧 구매할 예정이지만, 같은 무브를 좋아하는 이들에게 또 다른 체스 퍼즐 앱 World Champs를 추천, 실제 엔드게임에서 추출된 퍼즐이 대부분인 앱, Chess Puzzles World Champions 링크 소개
     * 좋은 프로젝트라는 인상, 설명만 보고는 하루 7개 이상 퍼즐을 하려면 1회 결제(€4.29)가 필요하다는 점이 명확하지 않았던 느낌, Lichess도 이 앱에 좋은 대안이지만 오프라인 지원이 제한된 점 언급
          + Lichess 오프라인 지원이 제한된다는 설명에 대해, 네트워크가 끊겼을 때 50개의 퍼즐만 플레이 가능하고, 다시 연결되면 플레이한 개수만큼 다음 퍼즐이 재다운로드되는 구조라는 정보 공유
          + F Droid에서 제공하는 TacticMaster가 무료로 동일한 기능을 제공하는 느낌 공유
          + CT-ART 4.0이 실질적인 금본위 앱이라는 의견, 무료는 아니지만 다른 수로 플레이, 퍼즐의 작은 버전을 풀기, 상대 진영으로 플레이 등 유용한 기능이 다수 존재, 오랜 시간 사용해본 유익한 경험 전달
          + 화장실에서 너무 오래 앉아 있지 않는 것이 좋다는 현실적 조언, 오래 앉아 있으면 치질이 생길 수 있다는 내용 첨언
     * 정말 놀라운 제품이라는 기분, “premoves” 기능이 추가되면 첫 수의 애니메이션이 끝나기 전에 다음 수를 입력할 수 있어 숙련된 사용자들의 몰입 유지를 도울 수 있을 것 같다는 기대감, 이 부분을 잘 구현한 chessbook 앱 참고 추천
     * 적응형 스타일이 좋아서 마음에 드는 앱이라는 평, 다만 피드백으로는 가끔 퍼즐의 목표가 불분명하게 느껴진다는 점, 예를 들어 “Brilliant queen win ahead!”라는 문구를 보고 퀸으로 체크메이트하는 의미로 받아들였지만 실제 퍼즐은 퀸을 따내는 게 목표였던 경험, 체스에서 “win”이란 말은 항상 체크메이트로 이해된다는 개인적 생각, 그래도 전반적으로는 훌륭한 앱이라는 평가
          + 혼란을 주는 문구는 앞으로 바꿀 계획이라는 의견, 안내로는 이름이 언급된 기물이 있으면 그 기물을 따내는 퍼즐임을 알려주는 답변, 감사의 마음 전달
     * 좋은 출발이라는 칭찬에 대해 부드러운 피드백 제시, 텍스트 힌트는 너무 많은 정보를 주기 때문에 기본값으로 꺼두는 것이 좋겠다는 생각, “next puzzle”을 계속 눌러야 해서 자동 다음 퍼즐 이동 기능 필요성, 퍼즐 카테고리 리스트에 “Egnlish Opening” 오타 발견 사실
          + 힌트를 기본 활성화한 이유가 대부분의 사용자가 존재 자체를 모를 수 있을 거라고 생각했기 때문이라는 설명, 불편하다면 메뉴에서 쉽게 끌 수 있음, 자동 이동 기능은 추후 업데이트에 추가 계획, 오타는 부끄럽지만 고맙게 생각한다는 피드백
     * Lichess가 오프라인 다운로드를 50개 퍼즐로 제한하는 이유를 이해하지 못하겠다는 의아함
          + Lichess의 모든 퍼즐 데이터(해결법과 주제 태그 포함 500만 개 이상 포지션)가 CSV 포맷으로 공개 다운로드 가능하다는 점 안내
     * 1인 개발, 광고 없음, 구독 없음이라는 점이 너무 마음에 든다는 내용, 이런 좋은 소프트웨어를 만들어줘서 바로 돈을 드리고 싶다는 솔직한 감상
     * 매우 잘 만들었다 생각, 폰을 거의 사용하지 않고 오피스에서 심심할 때 웹앱도 원한다는 의견
          + OffChess 웹사이트가 곧 여러 기능을 갖추고 베타로 출시 예정이라는 소식 공유
     * 정말 멋져 보인다는 생각, 최근 읽은 기사에서 “로컬 우선 소프트웨어”가 진짜 사용자 친화적인 소프트웨어의 궁극적인 목표라는 주장에 공감했는데, 이 앱이 그런 목표에 완벽히 부합한다는 인상, 앞으로 사용할 기대감
          + 참고로 언급된 기사 링크로 공유
"
"https://news.hada.io/topic?id=21891","GIF처럼 느껴지는 SVG","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             GIF처럼 느껴지는 SVG

     * 움직이는 SVG 이미지는 고해상도를 유지하면서도 파일 크기가 매우 작음 (49KB)
     * 기존 GIF와 비슷한 시각적 효과를 주지만, 실제로는 SVG 애니메이션 기능을 활용
     * Github README.md 파일에서도 직접 사용할 수 있음
     * asciinema와 svg-term-cli 툴을 이용해 터미널 세션 녹화 → SVG 애니메이션으로 변환 가능
     * SVG의 애니메이션 요소(<animate>, <animateTransform>, <animateMotion>)를 활용
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

움직이는 SVGs의 특징

     * SVG로 만든 움직이는 이미지는 기존 GIF처럼 보이지만, 실제로는 SVG의 벡터 기반 애니메이션 기능을 사용함
     * 이 방식은 파일 크기가 매우 작고, 화질 손실 없이 크기 변경 및 확대/축소가 가능
     * Github의 README.md 같은 곳에도 바로 활용 가능한게 큰 장점
     * 예시로, 49KB 크기의 고해상도 움직이는 parrot SVG가 소개됨

만드는 방법

     * asciinema를 통해 터미널 세션을 녹화함
     * 녹화된 asciinema 파일을 svg-term-cli 툴로 변환하여 SVG 애니메이션 파일로 만듦
     * 생성된 SVG 파일은 README.md에 쉽게 추가할 수 있음
     * 작성자는 bespoken 등 여러 프로젝트에서 이 방식을 적극 활용 중

SVG 애니메이션의 동작 원리

     * SVG 스펙에는 이미 애니메이션 기능이 내장되어 있음
          + <animate>: 개별 속성을 시간에 따라 애니메이션화함
          + <animateTransform>: 회전, 크기 조절, 이동 등 변환 애니메이션 적용 가능
          + <animateMotion>: 경로를 따라 객체를 움직임
     * svg-term-cli는 이러한 SVG의 내장 애니메이션 기능을 활용해 동작함

        Hacker News 의견

     * SVG만으로도 정말 다양한 인상적인 작업을 할 수 있는 점에 감탄 중인 상태임. 위키피디아에서 찾은 예시로는 미사일 커맨드 클론 애니메이션, 런던 튜브 맵, 롤링 셔터 애니메이션 등이 눈길을 끄는 상황
          + SVG는 원래 Shockwave/Flash Player의 오픈 경쟁자이자 PDA용 앱 포맷 역할로 시작한 역사. 네트워킹 지원 추가도 실제로 고려된 적이 있었던 사실 언급
          + 런던 튜브 맵이 무척 인상적인 이유는 휠체어 사용자 같은 교통약자를 위한 '계단 없는 역' 표시가 있기 때문임. 첫 번째 미사일 예제를 보고 바로 프로그래밍으로 탄두 클릭하는 방안을 생각해내어 세계 구한 기분 느낌 공유
          + 첫 번째 미사일 커맨드 링크가 Safari에서는 제대로 작동하지 않는 점 궁금증. 버튼 클릭은 되지만, 탄두 클릭 반응 없음. Firefox에서는 십자선 커서까지 보이는데 Safari만 뭔가 안 되는 상황
          + 튜브 맵의 체크박스 기능은 매우 멋진 부분. SVG 스킬을 더 연마해야겠다는 자극 받음. 북마크 완료
          + 기사 제목만 보고 README 파일의 해시를 시각적으로 보여주는 툴인 줄로 착각했지만, 그런 시각화 기능이 TOS, EULA가 은근슬쩍 바뀔 때 사용자들이 쉽게 감지할 수 있게 해줌을 기대
     * README에 애니메이션 SVG를 삽입하고, 이 SVG가 날씨와 요일 정보를 하루에 한 번씩 업데이트하는 작업을 개발한 경험 공유. 참조. 실제로는 몇 년 전 배심원 소집기간에 만든 프로젝트
     * 타겟이 Github README라면, 동영상을 직접 임베드도 가능. 예시로 git-recent README 링크 소개. 단, 단순한 터미널 캡처라면, OP의 SVG 방식을 활용하는 것이 더 똑똑한 선택일 수 있다는 의견
          + 동영상을 사용할 때 좋은 점은 재생/일시정지/슬라이더 UI가 있다는 것. 일부 플랫폼은 GIF에도 자바스크립트로 제어 UI를 추가하기도 하지만, 브라우저에서 기본지원 않는 점은 한계. 그래서 종종 동영상을 선호한다는 입장. RevealJS용 SVG 애니메이션을 할 때는 필요에 따라 CSS/JS로 조작
          + 비디오 파일을 추가할 경우, Github에서 직접 README를 편집해 업로드 파일이 githubusercontent에 저장되는 게 저장소 용량에도 이로운 선택
          + SVG는 밝기/어두움(다크/라이트) 사용자 설정에 색상 반응 가능이라는 점에서 동영상과 다름. 크기 반응형도 지원, 동영상은 그런 게 불가능. 관련 데모 소개. 단, 이 기능도 Firefox/Chrome에서는 잘 되지만 Safari에서는 여전히 구현이 까다로운 부분이 있고 아쉬움 토로
          + Paul의 활동을 오랜만에 언급하며 이전 Echo Nest, Rdio API 작업에 대한 애정 표현
          + 내 의견으로는 터미널 캡처라면 SVG 방식은 조작 기능이 부족해 실용성 적음. 소프트웨어의 데모 목적으로 5초 내외의 짧은 모션 설명에는 괜찮다고 보지만, 동영상도 필요에 따라 더 나을 수 있음
     * 애니메이션에서 바로 텍스트 복사까지 가능한 점이 생각보다 직관적이지 않지만 제일 쿨한 특징으로 보임
          + 애니메이션이 마우스 오버시 일시정지될 수 있다면 흥미로움이 극대화. 하지만 터미널이 스크롤되면 복사/붙여넣기 기능이 유용성 떨어지는 도전적 측면 있음
     * 주의사항으로, 일부 SVG 파일이 페이지를 멈추게 만드는 버그가 있음. 따라서 제 3자 SVG 링크 삽입을 피해야 한다는 경고. 구글 크롬과 파이어폭스 측 모두 이 버그 수정 계획 없음. 테스트용 위험 SVG 예제도 첨부하지만 클릭시 브라우저 다운 위험
          + 페이지나 브라우저가 멈추는 문제는 보안 이슈라기보다 다양한 내장 함수 남용으로도 발생할 수 있는 일반적 현상이라는 의견. 예시로 블러 필터 체인 길게 사용시 렌더링 과부하로 Chrome 자체가 멈추는 경우 있음. 만약 이 영향이 탭을 넘어서면 더욱 문제긴 하지만, 기본적으로는 UI 사용성 이슈 판단
          + 이런 SVG 관련 취약점(예: XXE 공격)이 Github README처럼 제한된 환경에서도 가능한지 궁금증 제기. 만약 가능하다면 어떻게 막고 있을지 의문
     * ""SVG가 본질적으로 애니메이션""이라는 사실이 매우 신선하게 다가와 여러 아이디어를 생각하게 되는 시간. 무한 반복 지원 여부 궁금증
          + <animate> 태그의 repeatCount나 repeatDur 속성을 'indefinite'로 설정하면 무한 반복 가능. 개별 속성에 대한 반복이기 때문에, 이미지의 각 요소가 각기 다른 주기로 움직일 수 있음
          + SVG 애니메이션 공식 문서에서 확인 가능한 예제 코드 공유
          + SVG는 속성 기반 애니메이션 외에도 Ecmascript(Javascript)를 내장할 수 있어, 필요에 따라 스크립트로 어떤 기능이든 채워넣을 수 있는 점 언급. W3C 스크립트 문서 참고
          + SVG 애니메이션 샘플 코드 및 예시도 공유. 일부는 페이지 새로고침시 확인 가능
     * 언젠가 브라우저 표준으로 WASM, JVM, CLR 등 어떤 실행 엔진이든 꽂을 수 있고, 출력이 SVG(텍스트/바이너리)인 시스템을 꿈꾸는 상태. 개발자는 자유롭게 실행 모델과 뷰 조합을 선택하는 방향, DOM에 얽매이지 않게 되는 미래 혁신 희망
          + AutoCAD Web, Photopea, Figma, Google Docs, Google Earth Web, Flutter for Web(CanvasKit) 같은 앱은 이미 이런 방식에 가깝게 DOM을 우회하거나 다른 렌더링 엔진을 선택해 사용 중. 즉, DOM만 강제되는 시대는 아니라는 의견
          + 과거에는 Flash, Java, Silverlight, ActiveX 같은 서드파티 런타임이 웹을 지배했으나, 현재는 공통 언어/플랫폼 환경이 장점이라는 소신. 보안 위협 환경에서는 예전 방식의 부가기술들이 더 이상 살아남기 어려운 점도 강조
          + DOM(HTML)의 장점은 다양한 디스플레이 환경에 반응형으로 설계된 점. SVG는 이런 자유도가 부족하다는 차이점
     * 굉장히 엉뚱해 보일 수 있지만, SVG 아키텍처 다이어그램을 애니메이션화해 노드가 드라마틱한 애니메이션(예: 배틀 애니메이션처럼 확대, 정지 프레임, 번쩍이는 라인 효과 등)으로 연출되는 영상을 만들어보고 싶은 욕구 생김
     * 이런 TIL 스타일 포스트는 새로운 도구 경험을 직접 공유하고, Github Markdown의 제약 극복법까지 제시해주어 창의력 자극에 큰 기여. SVG 결과물(예시)을 보니, 인라인 SVG 안에 인라인 SVG가 중첩된 구조는 처음 접한 경험으로 신선함에 감사 표함
          + 이론상, 자신 스스로의 소스코드를 에디터에 입력하는 모습을 애니메이션하는 쿼인 SVG도 만들 수 있겠다는 아이디어
     * 정말 멋진 아이디어라 README에서 terminaltexteffects에서 구현한 효과들과 어떻게 매칭되는지 테스트해보고 싶음. SVG에 대해 잘 알지는 못하지만, 실제 텍스트를 저장한다고 하면 큰 데이터 파일이 될 수도 있다는 점은 인지. 그래도 재미로 도전하고 싶은 마음
"
"https://news.hada.io/topic?id=21895","Firefox는 괜찮음. 다만 운영하는 사람들이 문제임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Firefox는 괜찮음. 다만 운영하는 사람들이 문제임

     * Firefox 브라우저는 오픈소스 커뮤니티에서 지지를 받아온 대표적인 웹 브라우저임
     * 최근 여러 해 동안 Firefox는 브라우저 기술 발전과 사용성 개선을 통해 시장에서 중요한 역할을 지속해왔음
     * 그러나 Mozilla 경영 팀의 정책과 의사결정 투명성 부족 현상으로 커뮤니티 신뢰가 흔들리고 있음

Mozilla 경영진 문제

     * Mozilla의 수익 구조 변화와 일부 논란이 되는 제휴, 광고 정책 도입 등이 사용자 기반에서 비판을 받고 있음
     * 고위 경영진의 의사결정 과정이 일반 개발자 및 커뮤니티 멤버와 잘 공유되지 않는 점이 문제임
     * 프로젝트 목표와 실제 활동 간의 괴리가 점차 출현하며 조직 내 불협화음이 커지고 있음

커뮤니티 반응 및 영향

     * Firefox 사용자는 Mozilla에게 더 높은 투명성과 커뮤니케이션을 요구함
     * 기여자 일부는 현재의 운영방식에서 열정 저하와 향후 이탈 가능성을 언급함
     * Mozilla는 앞으로 내부 운영 방식과 목표를 조정해야 개방형 웹 생태계에 대한 신뢰를 회복할 수 있음

결론

     * Firefox 브라우저는 기술적으로 강점이 많고 오픈소스 생태계에서도 중요한 위치임
     * 다만, 프로젝트 미래를 위해서는 Mozilla 리더십과 정책의 근본적 변화 필요성 대두됨

        Hacker News 의견

     * 나는 Mozilla가 항상 옳은 결정을 내렸다고 생각하지 않지만, 그들은 현재 매우 어려운 위치에 있다고 느끼는 입장임과 동시에, 보통 반-Mozilla 논리는 상당히 모호하고 방향성이 부족한 비판임을 지적하는 입장임
          + 흔히 제시되는 요구 사항 목록으로는,
               o Google에 의존하지 않는 수익원 개발 요구
               o Firefox의 수익화 반대
               o Firefox에만 집중 요구
               o 멋진 연구 프로젝트를 개발하라는 요구
               o 경쟁적이고 전문적인 기업 운영 원칙을 따르라는 요구
               o 경영진 임금 상한선을 두고 열정 프로젝트처럼 운영하길 바라는 요구 등 다양함
          + 이 중 일부는 서로 정반대 방향이기 때문에 양쪽 모두를 최대화할 수 없는 현실임
          + Mozilla는 대개 이런 요구 사이 어딘가 중간선을 택해왔고, 예를 들어 임금이 괜찮긴 하지만 Apple, Google 등과 비교하면 낮음
          + 비판자들은 이러한 '중도적' 움직임을 우유부단하다고 볼 수 있지만, 정작 대안을 내세우는 쪽은 현실적이고 구체적인 계획 없이 모순된 목표만 고르거나, Zawinski와 같은 주장은 명확하긴 해도 기존 수익 구조나 Netflix 같은 이용 환경을 원하는 측에겐 너무 과격한 방안임을 밝히는 입장임
          + 정말 그렇다고 생각함과 동시에, Mozilla에 관한 많은 비판이 상호 모순적이거나 논리적 근거 없이 주장됨을 강조하는 입장임
               o 예로, 아무런 증거 없이 VPN 운영비가 너무 막대하다고 주장하거나
               o Mozilla가 돈이 다 떨어졌다고 주장하지만 실제로는 10억 달러 이상의 자산 보유 중임
               o 블록체인 시도 관련해서 실제론 논문 두어 편 발표한 수준임에도 과장해서 말함
               o CEO 연봉이 회사 운영에 막대한 장애가 된다는 주장도, 실제로는 수익의 1% 정도임을 지적함
               o Mozilla가 어떤 필수 기능을 개발하면 시장 점유율을 되찾을 수 있었다는 신빙성 없는 논리 구조
               o Chrome이 시장 점유율을 올린 건 Google의 막강한 검색·Android 생태계, Chromebook 보급 등 외부 전략 때문임을 지적하며, 이는 Mozilla 자체의 문제보다 더 큰 영향임을 강조함
               o Firefox가 느려지고 무거워졌다는 지적 역시 예전 사실이고, Quantum 이후엔 대폭 개선됨을 인정함
               o 분명 FirefoxOS 투자와 브라우저에 쓸 자원 고갈 문제, 광고 관련 영혼적 타협 등 실제 문제도 존재하지만, 위에 언급된 주장들은 의미 없는 비판이기에 반복되는 커뮤니티 환상 사례로 관찰하게 됨을 밝힘
          + Mozilla와 Wikipedia Foundation은 핵심 목표에만 집중하지 않고 다른 일에 신경을 쓰는 것이 반복되는 불만이라는 의견임
          + 자신도 이 점을 인식하고 있음, 특히 Brave처럼 논란을 불러일으킨 브라우저에 대해서는 비판이 쉽게 잊히거나 용서되는 반면, Mozilla에 대한 잣대는 엄격하다고 느낌
               o 본인의 브라우저 선택 기준은 uBlock Origin 등 확장 기능과의 장기 호환성을 고려해서 Chromium 계열 브라우저를 신뢰하기 어려운 점임을 밝힘
          + Mozilla가 멋진 연구 프로젝트를 추진하라고 요구한 사람이 아무도 없음에도, 실제로는 Firefox에 불리할 정도로 연구 쪽에 치중하고 있다는 점에 불만임을 말함
          + 사람들이 진정으로 요구하는 것은 서로 모순되지 않는 현실적인 내용임을 강조함
               o Google 의존도 없는 수익원 개발, Firefox 사용자 존중, Firefox 중심 사업 운영, 사용자들에게 실질적인 부가가치를 주는 사이드 프로젝트 유지, 올바른 경영, 일부 경영진의 과도한 보상 방지 등
               o 실제 유저들이 돈을 내겠다고 요청했던 서비스도 거부하다가 결국 자금 부족으로 폐기했던 적이 많았고, 사용자 친화적이라는 이미지를 스스로 훼손한 사례도 있었음을 지적함
     * Firefox의 ""브라우저 도구"" 메뉴에 있는 모든 기능을 개발자 버전으로 옮기고 표준 버전에는 남기지 말자라는 의견을 이상하게 생각함
          + 그렇게 되면 심지어 가장 열성적인 개발자들도 즉시 Chrome으로 넘어갈 것이라는 강력한 반박임
          + 개발자로서 Firefox에서 개발하는 입장에서, 배포 직전에야 다른 브라우저에서 테스트하는 방식임
               o 사용자들이 F12로 문제를 진단할 수 없다면 사용자 지원 자체를 재고하게 될 것임
          + 원 의견의 맥락을 온전히 포함해야 함을 강조하고, 실제로는 ""should""보다 ""could""가 더 맞는 표현이라고 언급함
          + 해당 주장은 너무 극단적이거나 트롤링이라는 느낌을 받았고, 굳이 기사 원문을 클릭하지 않아도 됐을 정도로 비현실적인 주장이라 생각함
     * DRM(Digital Rights Management) 도입을 ""원죄""로 보는 의견에 동의하지 않는 입장임
          + 15-20년 전 Firefox가 영향력이 있었을 때라면 모를까, 지금은 DRM 미지원 시 서비스 플랫폼들이 “다른 브라우저 쓰세요” 혹은 별도 앱만 지원하는 상황이 됨
          + 활동가가 아닌 대다수 사용자들은 “이 서비스 사용할 수 있는 브라우저(Chrome 등)”로 곧바로 갈아타기 때문에, 오히려 DRM 미지원은 시장을 빼앗기는 결과가 됨
          + DRM은 부가 기능이므로 사용자가 원하면 꺼도 되지만, 껐을 때 Netflix 같은 서비스 이용 불가로 불편해지는 점이 있음
          + 플랫폼의 DRM 채택을 막겠다는 명분으로 지원을 거부할 경우, Firefox처럼 락인(lock-in)이 약한 브라우저는 사용자를 붙들 방법도 적고, 결국 이념적 요소 외에는 현명한 대안이 부족함을 인정함
          + 실제 원죄라면 Chrome 대비 기술력(속도, 버그, 보안 등)에서 뒤쳐진 것이며, DRM 도입 및 Google의 표준 수용은 그런 기술/시장적 열세의 결과임을 분석함
          + Servo 프로젝트에 기대를 했으나 기회를 잃었고, 모바일 확장 프로그램 미지원 및 DoH(DNS-over-HTTPS) 도입 지연 등도 놓친 기회로 봄
          + 앞으로 광고 차단에 관한 기회가 남았지만, 그마저도 제대로 살릴지 의문임
          + 자신은 아직까지 DRM 활성화가 꼭 필요한 사이트를 못 만났으며, Firefox가 DRM 활성화를 요구해도 무시하면 예상 외로 사이트가 잘 동작하는 경우가 많음
               o 단, 옵션으로 기능이 존재하는 것은 신경쓰지 않는다는 입장임
          + Firefox가 Chrome보다 버그가 많았다는 지적 중, 실질적으로 Google이 YouTube, Gmail 등 자사 서비스에서 의도적으로 Chrome의 최신 표준만 지원하도록 코딩했던 경험을 얘기함
               o 이런 상황에서 사용자가 Chrome으로 떠나는 건 놀라운 일이 아님을 밝힘
     * Chrome 팀보다는 Firefox 운영진이 다소 짜증나는 수준이라 느끼며, Mozilla 경영진의 높은 임금과 핵심(브라우저/메일/개발도구) 외 엉뚱한 사업에 투자 후 금방 포기하는 경영 방식에 실망감을 드러냄
          + 그 모든 돈 낭비가 실제 Mozilla의 핵심이라는 냉소적인 입장임
               o 결국 Mozilla는 Google의 일종의 “경쟁자 존재 연기(competition fig leaf)”로 기능하며, 성공적이거나 혁신적인 프로젝트(Rust, Servo, FakeSpot 등)는 주 임무에 방해가 되기 때문에 제거 대상이 된다고 봄
          + Firefox가 과거 수십억 달러를 받았던 것을 저축해두고 20년 이상 lean한 임무 지향 조직으로 남았으면 어땠을까라는 상상을 함
               o 비싼 경영진, 중간 관리자, 영업조직을 없애고 열정적이고 제대로 대우받는 개발자, 오픈소스 옹호자만으로 최고의 오픈소스 소프트웨어와 Google 등에 맞서 웹을 보호했으면 좋았을 것 같다는 의견임
     * 소프트웨어를 자주 여러 브라우저로 갈아타보는 입장이지만, 결국 항상 Firefox로 돌아오게 됨
          + Brave: 미션/실행 방식은 좋지만 Chrome 기반이라 선호하지 않음
          + Arc: 신선한 아이디어이지만 필수 기능이 없어지고 불필요한 것만 남음
          + Orion: iOS에서 Firefox 확장까지 지원하고 퍼포먼스도 뛰어나지만 자주 크래시와 호환성 이슈 경험
          + Safari: 소프트웨어에 비용 지불은 괜찮지만, 얼마 안가 사라질지도 모를 확장 프로그램에 돈 쓰고 싶지는 않음
          + 현재 Zen Firefox 버전에 정착했고, Arc나 테마들이 지향하는 장점과 안정성, 그리고 기존 확장과의 호환성을 모두 만족함
          + 다만, 가끔 “이 사이트는 Chrome에서만 동작함”이라고 경고 받는 경험 남음
          + “이 사이트는 Chrome에서만 동작함”을 경험했다면 구체적으로 어떤 사이트인지 공개하라는 피드백임
     * Mozilla 경영진이 방향 감각을 잃고 제대로 된 비전이나 실제 사업 감각도 없이 역할 놀이만 하는 “기업 흉내내기” 상태라는 비판 의견임
          + 진짜 해법은 Mozilla가 제대로 된 비영리 법인이 되는 것이라는 의견이며, EU 같은 공공기관이 브라우저를 필수 인프라로 간주하고 운영했으면 한다는 바람임
          + 부화 직전 아기 새가 입만 벌리고 애벌레가 저절로 들어오길 기대하는 만화와 비슷하다고 풍자적으로 비유함
     * JWZ 등의 울트라 순수가 요구하는 웹 표준 측면과 사업적 경영 방식을 요구하는 상반된 비판이 혼재되어 있다는 점을 지적함
          + 위의 반-Mozilla 비판이 “모호하고 방향 없다”라는 의견이 전혀 근거 없는 이야기는 아니라고 느끼는 입장임
     * “아무런 웹 디자이너도 이제 Firefox를 먼저 고려하지 않는다”라는 논거에, 그래도 개발자 도구를 계속 개발하고 있다면 오히려 그 기능을 통합 버전에서 빼야 할 이유가 없다는 반론임
          + 그런 기능을 없애서 얻을 이점이 이해되지 않는다고 말함
     * 본인은 Firefox의 불필요한 신규 기능 추가에 더 불만임
          + 예를 들어 최근 140.0 릴리즈에서 주소창에 창 제목을 표시하는 토글 기능이 생겼는데, 이런 것을 누가 요구했는지 의문임
          + 브라우저는 최대한 단순해야 하며, 이런 불필요한 기능으로 인해 비대해지고 있다고 느낌
          + 수백 개의 탭을 관리해야 한다는 사람이 많으므로 각종 기능 추가 요구도 있다는 의견임
          + 세로 탭(Vertical Tabs)은 정말 유용하다는 부가 의견임
          + 유용한 소비자용 앱을 인수해놓고 금방 종료시키는 것도 불만이라는 의견임
          + 주소창 창 제목 표시 기능 요청자는 실제로 존재함을 밝힘
               o 특히 Mac에서는 탭에서 초반 한두 단어만 보이고 나머지는 볼 수 없는 경우가 많아 이런 기능이 유용하다는 예시임
               o 윈도우 컨트롤이 없는 시스템에서도 예상보다 이런 기능이 필요하다는 설명임
     * Firefox의 코드베이스는 25년 된 유산 코드 위에 멀티스레딩 등을 후처리로 얹았기 때문에 구조적으로 문제가 많음
          + 렌더러 보안 샌드박스도 제대로 갖추지 못했고, 장기간 자금 부족으로 리라이트/주요 리팩터 시도를 잇따라 취소함
          + Gecko 엔진을 더 이상 외부에서 임베드하지 않는 이유가 분명히 존재함
          + 실제로 Firefox 보안 수준은 현대 표준에 비해 크게 뒤처져 있다는 현실적인 의견이며, 추가 외부 샌드박싱 없이는 일회용 브라우저로만 안전하다는 평가임
"
"https://news.hada.io/topic?id=21880","예상치 못한 곳에서 비롯된 새로운 구형 적재 기록","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      예상치 못한 곳에서 비롯된 새로운 구형 적재 기록

     * Boaz Klartag는 기존 접근과 달리 초고차원 구 적재 문제에 볼록기하학 도구를 도입함
     * Klartag의 새로운 임의적 방법은 더 큰 부피의 타원체를 생성해 기존의 기록을 대폭 갱신함
     * 이 접근법은 고차원 공간에서 구를 극적으로 더 많이 적재할 수 있게 함
     * 이번 결과는 적재의 질서와 대칭성의 중요성에 대한 논쟁을 부활시킴
     * 연구는 암호학과 통신 분야 등 다양한 응용 가능성에 대해 주목을 받음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

기존 구 적재 연구와 제한

     * 과거 Rogers 방법의 장점은 시작 격자가 반드시 효율적일 필요 없이 적절한 타원체만 선택하면 된다는 점이었음
     * 하지만 타원체의 축은 고차원에서 다양하게 변형될 수 있으므로, 어떤 형태로 성장시킬지 선택지가 지나치게 많았음
     * 이후 수학자들은 Minkowski 방식으로 회귀해 격자 자체에 집중했고, 격자 이론에 전문화됐으며 Rogers의 기하 중심 접근에서 멀어졌음
     * 이 전략은 고차원 구 적재에서 점진적 개선을 보였으나, Rogers 방식 대비 근소한 효율 향상에 그쳤음
     * 수십 년간 큰 도약은 나오지 않았고 정체 상태가 이어졌음

외부 시각에서 시작된 혁신

     * Weizmann Institute of Science의 Boaz Klartag는 원래 격자 이론이 아닌 볼록기하학 전공자임
     * 오랜 기간 구 적재문제에 관심은 있었으나 연구 기회를 얻지 못했음
     * 2023년 새로운 시간을 가지게 되어, Tel Aviv University의 Barak Weiss와 세미나를 열어 고전 문헌(Minkowski, Rogers) 를 집중적으로 탐구함
     * Klartag는 Rogers의 타원체 방법이 볼록도형 조작에 대한 노하우 부족으로 비효율적이었다고 판단함
     * 더 효율적인 타원체를 만들면 구 적재의 기록을 새로 쓸 수 있다는 자신감을 가짐

임의적 성장 알고리듬의 도입

     * Klartag는 각 축 방향별로 타원체 경계를 임의로 팽창/수축시키는 자신만의 방법을 적용함
     * 경계가 격자점에 닿으면 해당 방향의 성장을 멈추고, 다른 방향으로는 성장 지속
     * 이 과정에서 타원체는 불규칙한 형태로 공간을 탐색하며 점차 커짐
     * 임의적 특성으로 생성 타원체마다 부피가 다르기 때문에 여러 번 실험하여 더 큰 부피의 타원체 가능성을 평가함
     * 몇 주 만에 기존 Rogers보다 큰 타원체가 나올 수 있음을 증명함

기록 갱신과 영향

     * 새로운 타원체 방식은 Rogers(1947) 이후 최대폭의 구 적재 효율 개선을 달성함
     * 차원이 d일 때, 이전 방식 대비 d배나 많은 구 적재가 가능함
          + 100차원 → 약 100배, 1,000,000차원 → 약 100만 배의 구 적재
     * Klartag는 볼록기하학에서의 통찰로 격자와 구 적재의 오래된 중앙 문제를 몇 개월 내에 돌파함
     * 그의 성과로 질서와 대칭성 기반 적재가 가장 촘촘한 적재를 달성할 수 있다는 견해가 다시 부각됨
     * 반면 최근에는 규칙적인 격자 없이 무질서함을 이용해야 한다는 연구도 경쟁함

평가와 미래 전망

     * 현재 Klartag의 적재 방식이 진정한 최적에 가까운지, 추가 개선 여지가 있는지에 대해 학계 내부에서 논쟁이 있음
     * 이 문제의 해답은 암호학, 통신공학 등 실제 적용에서도 매우 중요함
     * 아직 실무 적용 단계는 아니지만 공학계 등에서 신기술로 주목받고 있음
     * Klartag는 이번 계기로 볼록기하학과 격자 이론의 연계가 강화되길 바람
     * 두 분야의 단절을 극복하고 이 융합이 적재 외의 격자 문제 해법까지 확장되길 희망함

        Hacker News 의견

     * 부모님께 내 직업이 실제로 존재하는 일임을 설명하는 게 늘 어렵다는 고백, ‘나는 도형을 연구하는데, 오목하게 들어간 부분이 없는 모양만 연구한다’고 설명하게 되면 더 난감해지는 상황 상상
          + 내 경험상 어려운 전문 용어를 써서 직업을 설명하는 게 제일 낫다는 결론, 선택지는 세 가지로 압축, 부모님이 이해할 만한 비교적 쉬운 설명을 하면 일이 너무 쉬워 보여 ‘정말 이걸로 돈 버는 거야?’라는 반응을 얻게 됨, 제대로 왜 중요한지 설명하면 설명이 너무 길어져서 부모님이 실증을 느끼고 질문한 걸 후회하게 됨, 아니면 복잡한 전문 용어로 간단히 이야기하면 무슨 소린지 모르지만 괜히 대단해 보이는 효과, 그게 가장 나은 선택지
          + 내가 고에너지 물리 장비용 부품을 만드는 마이크로 비즈니스를 하는데, 남들에게 내 일에 대해 설명할 때 대중이 접해 본 적도 없고 실생활과는 여러 단계로 동떨어진, 극도로 이질적이고 마니악한 주제라서 이해시키는 방법을 아직도 못 찾은 실정
          + 나는 그냥 ""컴퓨터랑 일해""라고만 말하며, 그러면 “아, 그래 좋은 일이네” 하는 반응과 함께 대화가 끝나는 편리함
          + 나는 주로 “무슨 일을 하느냐”는 질문 자체보다 이후에 “그게 어떻게 쓸모 있지/어디에 쓰지?”라는 질문에 답하는 게 항상 어렵다는 고충, 근본적인 연구가 실제 활용으로 이어지는 긴 연결고리를 짧고 효과적으로 설명하는 방법의 고민
          + 최소한 구의 밀도 쌓기(sphere packing)는 정보이론의 핵심 문제와 밀접하게 연관되어 있고, 그 결과 벨 전화 시스템의 신뢰성이 높아진 것과 이어지는 점에서 역사적 맥락과 중요한 의미를 찾을 수 있음 (볼록 도형에 대해선 잘 모르겠음)
     * 구 모양을 촘촘히 쌓는 방법(sphere packing)을 이용해 벡터 데이터 압축 알고리즘을 고민했던 경험, 이론적 접근은 데이터가 매우 균일할 때만 효과적이고 현실 데이터엔 적용이 어려웠음
          + 비정형(비균일) 데이터를 균일하게 변환하려면 도메인 지식을 활용해서 비대칭성을 줄이는 방법이 통상적인 트릭, 예를 들어, 데이터에 고차원 구조가 있더라도 국지적으로는 노이즈 때문에 꽤 균일해지기 쉽다는 점을 이용, 대표점(centroid)을 계산하고 저장하면, 대표점은 더 균일해지며, 각 벡터를 대표점 인덱스와 벡터 오프셋으로 분리해서 저장, 인덱스는 효율적인 엔트로피 압축에, 오프셋은 이제 거의 균일해졌으니 기존 구 쌓기 전략을 적용하기에 용이
          + 이미 시도해봤을 듯하지만, 사전 압축(precompression)으로 벡터의 희소성을 줄여 균일도 증강 여부 타진
          + 실제 벡터를 만질 때는(grope는 ‘더듬다’, group의 오타) 조심해야 한다는 농담식 지적
          + 이론의 범위를 실전적 과제들(즉 비균질한 데이터)까지 확장할 필요성, 현실의 활용 사례가 너무 다양하다면 일반적인 접근 방식이 힘들 수도 있지만, 그래도 연구의 확장 필요성에 대한 주목
          + 오래된 상업적으로 중요한 분야에서는 이미 쉽게 얻을 수 있는 성과(저걸음마 열매)가 대부분 다 수확됐다는 점의 지적
     * Klartag의 “볼록 도형은 매우 강력하고 활용 가치가 높다”는 주장에 동의하면서, 수학자가 아니지만 Convex Hull 알고리즘이 예기치 않은 곳에서 특히 이미지의 자동 팔레트 분해 등 다양한 문제에서 등장하는 걸 자주 본다고 경험 공유, 참고 논문 링크 제공 Convex Hull and automatic palette decomposition
     * Klartag의 새로운 구 쌓기 방식이 기존 대비 차원이 d라면 d배만큼 많은 구를 쌓을 수 있다는데, 100차원에선 100배, 백만 차원에선 백만배 증가라니 엄청난 수치, 여러 통신시스템에서 이것이 실제로 대역폭이 수십~수백 배 혹은 전력 소모가 크게 줄어든다는 뜻인지 궁금증
          + 실제로는 차원을 높일수록 밀도(density)가 n^2/2^n으로 지수적으로 나빠지기 때문에 이론상의 선형적 개선은 실제 성능에 그대로 다 반영되지 않는다는 점, 즉 자연적으로 고차원 구조를 가진 데이터에는 쓸모 있지만, 디지털 데이터(길이만 정할 수 있음)에는 작은 차원을 택할 수 있음, sphere packing 상세 참조 wikipedia link
     * 수학자는 첫 박사학위 후 몇 년 뒤 같은 분야가 아닌 인접 전공으로 두 번째 박사학위를 할 수 있어야 한다는 생각
          + 박사학위의 근본 목적은 독립적으로 연구할 수 있는 능력의 증명이므로, 실제론 많은 연구자들이 박사졸업 후 다른 분야로 옮기거나 관심 연구 주제를 바꾸며, 그때부턴 ‘연구’ 자체가 중심이 됨
          + 실제로 이런 게 가능한 예시로 유명 수학자 Bela Bollobas는 이산 기하학과 함수해석학 두 분야에서 박사학위 두 개를 갖고 있음, 다만 현대 학계에서 이걸 다시 시도하는 건 매우 어렵겠지만
          + 이런 제도적 유연성이 과학 전반에 있으면 서로 다른 분야 기술과 아이디어가 빠르게 교류돼 과학 발전 가속화 가능성, 특히 수학처럼 분과 간 연결이 중요한 분야에서 더욱 효용 극대화 기대
     * 초보 질문으로, 최적의 구 쌓기(sphere packing)는 항상 정규 격자와 연관 있는지 궁금, 2D, 3D에선 그렇지만 이게 ND로 확장되는지에 대한 궁금증
          + 2, 3차원 외에도 8차원(E₈ 격자)과 24차원(Leech 격자)에서도 best packing이 정규 격자 형태로 증명된 사례가 있음, 이는 Maryna Viazovska와 동료들이 2017년에 입증했으며, 관련 논문 및 참고자료 링크 논문1, 논문2, 해설pdf 제공, 하지만 다른 차원에선 최적 packing이 정규 격자가 아니라는 반례가 존재할 수 있으며, 일부 차원에선 불규칙한 형태가 더 밀도가 높기도 함
          + 반드시 그런 건 아니고, 3차원에서도 lattice(정규 격자)로 쌓는 방법 외에도 층마다 수평 이동을 달리해 수 없이 다양한 비격자 쌓기가 가능, 이때도 밀도는 FCC lattice와 동일, 고차원에선 대칭성이 부족해 최적 packing이 항상 비격자라는 추측도 있음
     * 이 새 구 쌓기 구조가 기존 최고 밀도가 증명된 차원에서 어디서부터 더 뛰어난가에 대한 최소 차원에 관한 궁금증
     * 본 연구의 결과가 암호학 및 통신분야에서 실질적으로 더욱 안전하고, 더 신뢰성 있으며, 더 에너지 효율적인 통신 시스템 개발에 활용될 수 있을지에 대한 발전 방향 제시, 매우 흥미로운 연구 분야임
     * 실제 물리학에서 ‘Cow Packing’(이론적으로 소를 최적 밀도로 채우는 연구 등)에 실용적 응용 가능성이 언급된 재치 있는 비유
     * 구 쌓기는 응용 분야에서 정말 다양한 문제에 나타나서 흥미로움, 논문 정독 기대
"
"https://news.hada.io/topic?id=21888","Supabase MCP가 전체 SQL 데이터베이스를 유출할 수 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Supabase MCP가 전체 SQL 데이터베이스를 유출할 수 있음

     * Supabase MCP 통합을 악용하여 공격자가 개발자의 비공개 SQL 데이터를 유출할 수 있음
     * LLM이 지시문과 데이터를 구분하지 못해 악의적으로 조작된 메시지가 명령어로 오인될 위험 발생
     * service_role 권한을 가진 AI 에이전트가 고객 사용자 입력을 신뢰 없이 처리, 민감 정보가 노출되는 문제 발생
     * 공격자는 특정한 지시문이 포함된 메시지로 보안 회피 및 중요 정보 유출 가능함을 시연함
     * 대응 방안으로 읽기 전용 모드 활성화와 프롬프트 인젝션 필터 사용을 제안함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

개요

     * Model Context Protocol(MCP)은 LLM이 외부 도구와 상호작용할 수 있도록 해주는 표준 프로토콜임
     * 이로 인해 새로운 기회가 열리는 동시에, 잠재적인 보안 취약점도 발생함
     * 본 게시물은 공격자가 Supabase의 MCP 연동을 활용, 개발자의 비공개 SQL 테이블을 유출할 수 있는 방법을 시연함

문제점 설명

     * LLM은 시스템 프롬프트·사용자 지시문·데이터 컨텍스트를 텍스트로 받아서 처리함
     * LLM은 문맥 경계를 내장적으로 알지 못하며, 데이터와 지시문을 구별하지 못함
     * 사용자 입력 데이터 중 명령어처럼 보이도록 조작된 콘텐츠가 있을 경우, LLM이 이를 명령으로 실행할 수 있음

공격 환경(Setup)

     * 새로운 Supabase 프로젝트를 생성하고, 일반적인 다중 테넌트 SaaS 고객지원 환경을 모사함
     * Dummy 데이터만 삽입, Row-Level-Security(RLS) 는 공식 문서대로 적용, 별도 확장이나 정책 없음
     * 공격에 사용된 환경은 기본 제공 서비스만 사용, service_role, RLS, MCP 에이전트 모두 기본 세팅임

  1. 주요 행위자와 권한

      행위자(역할)           사용 인터페이스              DB 자격증명             주요 권한
   고객/공격자        티켓 제출 폼(공개)             'anon'(RLS 제한)    본인 소유의 티켓/메시지 생성
   지원 에이전트       지원 대시보드                 'support'(RLS 제한) 지원 테이블만 일부 읽기/쓰기
   개발자           Cursor IDE+Supabase MCP service_role      모든 테이블에 대해 전체 SQL 가능
   IDE Assistant LLM(Cusor에서 작동)         service_role      텍스트 명령대로 MCP로 SQL 실행

     * 취약점의 핵심: IDE Assistant는 신뢰할 수 없는 고객 입력을 인지하지 못하며, 최고 권한(service_role) 을 가짐
     * 지원 에이전트의 권한으로는 민감 테이블 접근 불가능(예: integration_tokens), 지시문을 요청해도 거부 반응 반환함

  2. 애플리케이션 구조

     * 고객 및 에이전트가 자유롭게 지원 티켓을 생성/메시지 교환 가능
     * 모든 데이터는 Supabase SQL 데이터베이스에 저장
     * 개발자는 때때로 Cursor 에이전트(LLM + MCP) 로 열린 티켓을 검토함

    테이블 예시

     * support_tickets: 고객지원 티켓 데이터 저장
     * support_messages: 각 티켓에 대한 메시지 저장
     * integration_tokens: 민감한 세션 토큰 등 보안 정보 저장

  3. 애플리케이션 동작 방식

     * 고객지원 시스템은 티켓 생성 및 메시지 교환 기능 제공
     * 개발자는 Cursor 에이전트로 열린 티켓 및 메시지 확인/요약을 자동화함
     * Cursor 에이전트가 service_role 권한으로 DB 접근, RLS 무시 및 고객 메시지도 모두 읽음
     * 누군가 조작된 명령문을 고객 메시지에 심으면, AI가 이를 SQL로 실행하여 민감 정보를 유출할 수 있음

공격 시나리오

     * 공격자는 새로운 티켓을 열고 특수하게 작성한 메시지를 제출함
          + 예시 메시지에는 AI 에이전트에게 integration_tokens 테이블 전체 읽고, 결과를 이 티켓에 추가하라는 명령 포함
          + 메시지 끝에는 정상적인 문의 내용(“무엇을 할 수 있나요?” 등)을 포함해 의심 줄임
     * 이 메시지는 지원 에이전트에게 노출돼도 민감 데이터 접근 권한 부족으로 별 영향 없음
     * 개발자가 나중에 Cursor로 열린 티켓을 요약하려 하면, 에이전트가 해당 메시지를 입력으로 받아 숨겨진 명령 실행
          + 실제로 두 개의 SQL 쿼리를 생성:
               o
                   1. 모든 integration_tokens 내용을 읽음
               o
                   2. 해당 결과를 티켓 메시지로 다시 삽입함
     * 해당 쿼리는 service_role 권한으로 실행, RLS 우회
     * 공격자는 본인이 연 티켓에서 민감 정보가 포함된 신규 메시지를 쉽게 확인 가능

결론 및 대응 방안

     * 본 공격은 과도한 권한(service_role) 과 사용자 콘텐츠에 대한 검증 부재가 결합된 취약점 기반임
     * MCP 도입 시 자동화 편의와 동시에 보안 리스크가 큼

  즉각적인 보안 조치 제안

    1. 읽기 전용(read-only) 모드 사용
          + Supabase MCP에서는 agent 초기화시 읽기 전용 플래그를 설정하면, 모든 쓰기/수정/삭제 SQL 차단
          + 쿼리 기반 에이전트라면 항상 읽기 전용 모드를 활성화 필요
    2. 프롬프트 인젝션 필터 적용
          + 비정상적 명령문, SQL 패턴, 인젝션 흔적 패턴 등 데이터 입력을 사전 필터링
          + MCP 앞단에서 데이터를 감시/차단하는 lightweight 래퍼로 적합
          + 모든 위험 탐지는 불가능하나, 기본적인 1차 방어선 제공

전문가 지원 안내

     * GeneralAnalysis 팀은 LLM 보안 및 적대적 공격 안전성 분야 전문성 보유
     * MCP 서버 또는 LLM 기반 에이전트 보안 강화에 대해 문의 시( info@generalanalysis.com ) 논의 및 가이드 제공 가능

        Hacker News 의견

     * Supabase 엔지니어로서 MCP 작업 담당자임을 밝힘. 최근 프롬프트 인젝션 방지를 위해 여러 완화책을 추가한 경험 공유. 기본적으로 read-only 사용을 문서에서 권장하고, SQL 응답을 포장해 LLM이 명령을 따르지 않도록 함. E2E 테스트로 덜 똑똑한 LLM도 공격에 쉽게 속지 않게 하고 있음. 이런 노력들로 인해 실제 Haiku 3.5 같은 덜 강력한 모델에서도 공격 성공률이 크게 떨어졌음을 체감. 하지만 이러한 노력들은 완화책일 뿐이고, 프롬프트 인젝션 문제는 여전히 미해결 문제라는 사실을 강조. 세밀한 토큰 수준의 권한 부여, LLM 접근 서비스 범위 지정, 작성중인 자세한 문서 추가, 프롬프트 인젝션 시도를 탐지하는 모델 등 다양한 추가 장치 개발 중임을 알림. Responsible disclosure(책임 있는 보안 이슈 공개) 절차 따르지 않은 General Analysis 측의 소통 부재에 아쉬움 표명.
       자세한 이슈 및 커밋 링크는 pull/94, pull/96, supabase security.txt에서 확인 가능함
          + 이 방식이 정말 효과적인지 의문을 제기. 신뢰할 수 없는 사용자 Javascript를 eval()로 넘기며 sanitize(정규화)하려는 시도가 항상 실패했던 것처럼, 지금의 접근 역시 위험 요소를 완전히 제거하지 못한다고 지적. MCP가 보안 경계로 작동하는 것이 납득되지 않으며, 실제 운영 환경이라면 LLM이 티켓을 읽는 컨텍스트와 SQL 호출 권한을 가진 컨텍스트를 분리하고, 이 둘을 잇는 agent 코드로 인변트 보장 필요함을 강조. Cursor(컨텍스트 분리 불가한 구조)이기 때문에 MCP를 프로덕션 데이터베이스에 바로 연결하는 것은 비상식적 선택임을 주장
          + 책임 있는 보안 공개 프로세스가 실질적으로 의미가 있는지 질문. 해결책이 결국 LLM에 ""데이터를 유출하지 말라""고 여러 번 요청하고, 관련 위험을 문서에 추가하는 수준이라면 그 효과에 의구심 품음
          + Supabase의 공개 보안 정책이 해커원(HackerOne)을 통한 야속한 조건을 강제하는 것뿐이어서, 본인 역시 해당 방식에 동의하지 않음을 밝힘
          + General Analysis 공동창업자로서 기술적으로 Supabase MCP 단독의 책임이 아님을 강조. 이 취약점은 (1) 비정규화된 데이터가 agent 컨텍스트에 들어가는 구조, (2) Foundation 모델이 명령과 데이터를 분간하지 못하는 한계, (3) 잘못된 접근 권한 범위 설정(커서의 과도한 권한) 등이 결합된 결과라고 설명. 이런 유형의 취약점은 다양한 MCP 사용 패턴에서 공통적으로 관찰 가능함. MCP 사용자를 위한 Guardrail(보호장치) 개발 진행 중임을 부연
          + 개인적으로 추가 프롬프트 포장에서 특별히 효과를 보지 못했다고 판단. fail fast(빠르게 실패) 방식이 더 적합하다고 생각하며, 오히려 프롬프트 포장은 나쁜 개발 습관을 조장할 수 있다고 우려. LLM이 시스템 접근 도구를 쓰는 것과 사용자가 REST API에 직접 시스템 접근 권한을 갖는 상황에 본질적 차이 없음. 개발자의 권한 검증 책임은 변하지 않는 교훈임을 강조. 프롬프트 인젝션이 아닌, 보안 경계 문제로 진단, 세밀한 권한 토큰 관리로 충분히 해결 가능하다고 판단
     * XSS(크로스 사이트 스크립팅)가 LLM 세계에 옮겨진 현상이라고 봄. 특히 Cursor와 Supabase MCP 같은 어드민 앱에서는 신뢰할 수 없는 사용자가 만든 콘텐츠를 가공 없이 받아들이기 쉬움. 기존처럼 지원 티켓에 악의적 HTML/Javascript를 삽입하는 대신, 이제는 LLM 지시에 해당하는 프롬프트를 삽입하게 되는 것임. 관리자가 이를 열람할 때 세션(여기서는 Supabase MCP 접근 권한)을 탈취당하는 구조라고 비유
          + 기술적으로 맞는 지적이지만, 이 문제를 단순히 ""내부 XSS의 또 다른 형태""로 축소하면 본질을 놓칠 수 있음. XSS는 입력을 가공해 안전하게 만들 수 있지만, 프롬프트 인젝션은 입력 데이터에서 LLM 명령을 완벽히 제거할 결정적 규칙이 전혀 없어 구조적으로 안전하지 못함. 결국 임의의 신뢰할 수 없는 입력을 특권 정보에 접근 가능한 LLM에 연결하는 것은 본질적으로 위험하다고 판단
          + 문제의 상당 부분은 LLM 입력 정규화가 불가능하다는 데 있음. 이런 기능을 사용하는 한, 항상 취약점에 노출되는 셈
          + SimonW가 'prompt injection'이라는 용어를 만든 배경을 소개. SQL 인젝션과 유사하지만, LLM 프롬프트는 신뢰할 수 있는 방식으로 escape(탈출)하는 방법이 없어 오히려 더 위험하다고 진단
          + 문제 코드 직접 사례 링크 공유
     * Supabase 같은 데이터베이스 접근 MCP를 사용할 때는 다음 권장 팁을 제공. (1) 무조건 read-only로 설정해 공격 발생 시 데이터 손상을 직접 막기, (2) 이 MCP를 외부 커뮤니케이션이 가능한 다른 MCP(HTTP 요청, 이메일 발송 등)와 결합 시 데이터 유출 위험 주의. 관련해서 본인이 쓴 ""lethal trifecta"" 분석 글도 참고 lethal trifecta 포스트
          + 공격 의도 없이도 데이터 유출(Exfiltration)이라는 용어가 적합하다고 생각
     * LLM을 생산계 인프라에 직접 연결하는 것이 결국 큰 취약점임을 간결하게 지적
          + 이 내용이 기사 상단에 있는 한 줄 요약이 되어야 한다고 강조
          + 실제 이렇게 세팅하는 사람이 예상보다 많아 놀랍다는 반응
     * Hacker News를 오래 읽으며 과거에는 해킹이 정말 뛰어난 엔지니어링의 결과로 보였으나, LLM 관련 취약점은 유치원을 속일 정도로 단순한 프롬프트로도 이루어지는 현실에 놀람
     * tramlines.io 소속으로, Neon DB MCP에서도 유사 취약점을 발견했다는 개인적 경험과 글 링크 공유 neon exploit 사례
          + 해당 취약점이 동일하게 나타나고, Neon's MCP가 데이터베이스에 read-write 접근 권한을 쉽게 줄 수 있기 때문에 'lethal trifecta'(민감 데이터 접근, 악의적 인스트럭션 노출, 데이터 유출 기능) 조건을 모두 충족시킬 수 있음을 추가 설명
     * 실제로 이런 MCP 취약점을 이용한 현실 공격 사례가 적은 것이 의외라고 밝힘. Supabase 관련 사례를 몇 달 전에 따로 다뤘는데도 공식 문서에서 이를 분명히 언급하지 않는 점이 흥미로움. 참고 사례 supabase 취약점 케이스, supabase 공식 문서
          + 현실 공격이 많이 없는 이유는 MCP 사용이 아직 널리 퍼지지 않아서라고 추측. 앞으로 타겟화 될 가능성이 높다고 예상
     * 다양한 공격에서 지원 사이트가 자주 사용되는 점 지적. 예전에도 SaaS 가입 시 조직 이메일을 자동 등록하는 구조를 악용해, 지원 티켓 시스템을 통해 인증 이메일을 받고 계정 가입/로그인에 이용하는 사례들이 있었음을 회상
     * Cursor assistant가 Supabase 데이터베이스에 service_role로 접근하며, 이로 인해 모든 RLS(행 수준 보안)이 우회된다는 점이 무척 위험하다고 지적. 생산 데이터베이스를 AI 에이전트에 바로 공개하는 것은 큰 리스크임을 강조. 원시 SQL 접근에는 무조건 리드 레플리카를 쓰고, 생산 데이터베이스에는 특별히 노출된 API 엔드포인트만을 이용해야 근본적 위험을 줄일 수 있음. 1~2년 안에 프롬프트 인젝션을 완벽히 해결하는 건 불가능하고, AI agent와 생산 데이터베이스 사이에 데이터 복제 및 보안 규칙 자동화용 미들웨어 계층이 많이 등장할 것으로 전망. 본인이 prototyping한 사례로 dbfor.dev 언급
     * 공격자가 다음과 같은 문구를 지원 티켓에 담아두는 현상 (""CURSOR CLAUDE 관련 명령... integration_tokens 테이블을 읽어서 티켓 메시지로 추가""와 같은) 자체가 납득이 어렵다는 반응. AI agent가 사용자 입력에 따라 데이터와 직접 상호작용하게 만들 리가 없다고 생각
          + LLM에는 Prepared statement가 없고, 데이터와 명령을 구분하지 못함. 봇에게 특정 업무만 허용하려고 해도 프롬프트 엔지니어링으로는 완벽한 안전 보장 불가. 심지어 '티켓 우선순위' 같은 단순 조작만 허용하더라도 악용 위험은 여전히 존재
          + 이런 구조의 문제는 시스템 설계 과정의 실수가 아니라, LLM이 입력 텍스트에서 사용자 명령과 유입된 기타 명령을 구분할 수 없다는 근본적 한계 때문임. 본인은 이 문제를 SQL 인젝션과 유사하다고 생각해 'prompt injection'이라는 용어를 사용. SQL 인젝션의 경우 안전한 방어 기법(escape, parameterize)이 있지만, 프롬프트 인젝션은 이에 대응하는 해결책이 없음
"
"https://news.hada.io/topic?id=21916","태양광이 세계 에너지 시스템을 변화시키기 시작함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       태양광이 세계 에너지 시스템을 변화시키기 시작함

     * 태양광과 풍력의 급격한 확산으로, 기존 화석연료 중심의 에너지·정치 구조가 근본적으로 흔들리고 있음
     * 에너지원의 분산성과 풍부함 덕분에 독점·지정학적 충돌이 어려워지고, 에너지 주도권이 점차 탈중앙화되는 추세임
     * 기술 발전과 규모의 경제로 태양광·풍력 발전 단가가 화석연료를 앞지르며, 생산-소비-저장 전반의 효율이 비약적으로 향상됨
     * 미국 등에서는 정치적·정책적 저항도 있지만, 글로벌 차원의 재생에너지 대전환은 되돌릴 수 없는 흐름이 됨
     * 태양과 바람이 일으키는 패러다임 전환은 산업혁명, 컴퓨터혁명 못지않은 문명적 변곡점임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

태양광·풍력이 가져온 에너지 패러다임의 변화

     * 최근 태양광 및 풍력 발전 설비가 폭발적으로 증가하며, 더 이상 ‘대체’가 아닌 에너지 시스템의 주류가 되고 있음
     * 2022년에야 누적 1TW를 달성했던 태양광은, 2년 만에 2TW, 곧 3TW 도달이 예상될 정도로 설치 속도가 가속화됨
     * 매 15시간마다 1GW(석탄 발전소 1기 수준)의 태양광이 새로 설치, 풍력도 빠르게 따라잡고 있음
     * 재생에너지와 배터리 저장 기술 덕분에 미국, 중국, 인도, 남미, 아프리카, 폴란드 등 다양한 국가·지역에서 석탄·가스 의존도가 빠르게 감소 중임
     * 예를 들어, 2024년 미국 신규 발전 설비의 93%, 전 세계 신규 전력 수요의 96%를 재생에너지가 차지함
     * 중국은 재생에너지 발전 및 저장장치의 절반 이상을 담당하며, 값싼 패널·배터리 생산으로 전 세계 확산을 주도함

태양광·풍력의 효율성과 경제성, 그리고 혁신

     * 태양광 셀은 실리콘, 은, 인, 붕소 등으로 구성되어 태양광을 바로 전기로 전환, ‘일 효율’이 기존 연소 방식보다 월등히 높음
     * 내연기관차 대비 전기차(EV), 히트펌프, e-바이크 등 전기 기반 신기술이 빠르게 확산하며 효율 혁신을 촉진
     * 에너지 저장 단가 95% 하락, 효율 향상, 리사이클링 기술 덕분에 자원 고갈 우려도 감소
     * 패널 한 장에 들어가는 은, 실리콘, 리튬 등의 사용량이 꾸준히 줄어들고, 사용 후 광물도 재활용됨

에너지 분산화가 불러올 사회적·정치적 변화

     * 태양과 바람처럼 어디서나 쓸 수 있는 분산형 에너지는 기존처럼 소수 국가·기업이 독점하기 어렵고, 공급망 충돌·전쟁 유발 가능성도 낮음
     * 미국, 유럽 등 선진국에서는 산업·정치적 반발이 여전히 존재하며, 정책 철회·보조금 축소가 일시적 위협으로 작용
          + 미국의 IRA 세제 혜택 축소와 일부 기업의 주가 급락 사례(예: Sunrun) 등
     * 하지만 이런 반발조차 변화의 속도와 범위가 얼마나 거대한지를 보여주는 방증임

신흥국과 개발도상국의 빠른 변화

     * 중국·인도·남미·아프리카·파키스탄 등은 값싼 태양광 패널과 노하우를 빠르게 받아들이며, 기존 화석연료 인프라를 뛰어넘어 ‘직행’하는 전환을 시현
          + 예: 파키스탄 농가의 95%가 이미 태양광으로 전환, 디젤 소비 30% 급감
          + 남미, 폴란드, 아프리카도 현장 데이터 기반으로 예상보다 훨씬 빠른 보급 진행

한계와 도전 과제

     * 주요 과제는 토지 활용, 광물 채굴, 대형 네트워크 인프라 병목 등
     * 광물(리튬, 니켈 등) 부족 우려는 효율 개선과 리사이클링, 신규 매장지 발견 등으로 해소 중
     * 실제 대부분의 프로젝트가 정책·인프라상의 ‘접속 대기’로 지연되고 있음

전망: 미래 에너지 질서의 대전환

     * IEA는 2035년 태양광이 전 세계 주요 에너지원이 될 것이라 전망
     * 효율, 경제성, 기후 대응, 민주화 등에서 재생에너지 확산은 ‘자연스럽고, 멈출 수 없는 흐름’으로 자리잡음
     * 태양은 앞으로 수십억 년간 인류에 넘치는 에너지를 제공할 것이며, 이는 산업·정치·사회 구조 전반의 혁명적 변화를 촉진할 것임

        Hacker News 의견

     * 아카이브 링크
     * 태양광의 가장 큰 문제점인 ‘해가 항상 비추는 게 아니다’라는 부분을 해결할 기술이 한 가지 있음, 바로 케이블임. 케이블은 에너지를 먼 거리까지 이동시킬 수 있음. 특히 HVDC(초고압 직류) 케이블은 대륙, 해양, 시간대와 기후대를 넘나들며 전력을 이송 가능함. 현재 케이블은 많은 용량이 남는데, 이는 그리드가 최대 수요를 견디기 위해 설계되어서임. 수요가 적은 시간대에는 여분의 용량을 충분히 활용할 수 있음. 예를 들어, 태양광/풍력 발전이 남아돌 때 이를 다른 지역의 배터리 충전에 사용하는 식임. 양방향 동작도 가능해 부족하면 수입, 남으면 수출 가능함. 대량의 배터리 역시 대부분 시간대에 완충 상태로 대기 중이므로, 케이블만 있으면 테라와트 단위의 에너지를 쓸 수 있음. 세계적으로 모로코-영국, 호주-싱가폴, 미국 동부-유럽 등이
       케이블 연결을 계획 중임. 계절, 날씨, 낮밤 차이로 인한 지역별 변동을 일부 상쇄 가능함. 나머지는 원자력, 지열, 수력, 그리고 남는 가스 발전소로 보완할 수 있음. 앞으로 가스 발전소 투자하면 현실을 직시해야 할 필요 있음. 오랫동안 일부는 예비력으로 보유하겠지만 큰 이익은 기대하기 힘듦
          + 송전선로는 흥미로운 아이디어지만 비용이 많이 들어감. 태양광 가격이 이미 매우 저렴해졌으므로, 필요량의 3배를 설치하면 흐린 날에도 충분히 모든 것을 돌릴 수 있음. 태양광은 흐린 날에도 어느 정도 동작함. 밤에는 다른 해법이 필요함. 일단 모든 주차장 위에 태양광을 설치하는 것부터 시작할 수 있음. 100% 태양광/풍력 그리드를 운용 못한다는 건 인류의 창의성에 대한 저평가임. 최대 수요 초과로 발전 설비를 넉넉히 설치하면, 배터리, 부하 이동, 주간 충전·야간 피크 때 그리드에 공급하는 전기차, 주간에 실내를 많이 시원하게 냉방해서 야간 냉방 불필요하게 하기, 소금 동굴에 수소 저장, 양수발전, 전력 과잉 시 알루미늄 제련 등 다양한 접근법이 있음. 해법은 많음. 인류의 상상력을 과소평가하지 말길 바람
          + 케이블의 대안으로 합성 디젤이나 철, 알루미늄, 마그네슘을 가득 싣고 이동하는 선박도 가능함. 중국 내에서는 HVDC 케이블이 대륙 횡단으로 태양광 전력을 전송하기도 하지만, 네덜란드는 아직 그런 계획을 실현하지 못했음. 케이블은 효율적인 실시간 송전이 가능하지만, 정밀유도 미사일에 취약함. 실제로 우크라이나에서는 지하에서 3D 프린터로 미사일을 대량 생산함. 그래서 알루미늄-공기 배터리 상용화가 다시 주목받기 시작함
          + 국제 케이블에 의존하는 국가는 필연적으로 전체 전력 백업 설비를 자체 보유해야 함. 케이블+백업 비용이 저장 비용보다 비쌀 수 있음. 물론 다양한 비용 요인이 있음
          + 케이블이 좋은 해법이 될 수 있는 곳도 있지만, 지형이나 정치가 제약이 되는 지역이 많음. 예를 들어, 러시아 태양광 전력을 북미 서부 저녁 피크에 공급하겠다고 태평양을 관통해 케이블을 깔 사람은 없을 것임
          + HVDC 같은 케이블 프로젝트에 대해서는 태양광·풍력처럼 낙관적이지는 않음. 태양광/풍력은 소규모, 플러그 앤 플레이 방식으로 쉽게 확장 가능하지만, 케이블 프로젝트는 아직도 거대한 장기 베팅임
     * 신재생 에너지는 정말 대단한데, 화석연료를 대체하는 역할보다는 사실상 에너지 사용 총량만 늘리고 있음. 지금 우리의 에너지 사용 방식이 환경을 파괴하고 있음. 태양광 기술의 발전이 모든 걸 해결하는 것처럼 생각하지 않길 바람. 우리가 해야 할 일은 태양광 사용만 늘리는 게 아니라, 화석연료 사용을 줄이는 것임. 관련 팟캐스트
          + 기사에는 화석연료 사용 저감 사례가 여러 번 등장함. 예를 들면, 캘리포니아는 2023년 대비 전력 생산에 필요한 천연가스 사용이 40% 줄었음. 중국도 탄소 배출량이 사실상 감소했고, 석탄 사용량도 정체 및 천연가스 사용도 같은 기간 25% 감축함
          + 태양광 기술과 배터리 저장 기술의 발전 속도가 엄청나게 가속화되는 중임. 새로운 태양광 설비가 곧바로 신규 수요로 이어진다는 일대일 대응은 아님. 설치 확대와 기술 향상으로 비용이 계속 낮아짐. 비용이 떨어질수록 태양광 보급 속도가 더 빨라지고 있음. 이런 발전이 실제로 상황을 점점 더 좋게 만듦. 이건 장기적이고 누적적인 변화임
          + 데이터로 보면 동의하는 바임. 내가 평생 살고 있는 애팔래치아 지역에서도 일상적으로 화석연료의 부정적 환경 영향이 뚜렷하게 줄었음을 체감함. 규모는 작지만, 적어도 이곳 주민들에게는 현실적이고 눈에 보이는 변화임
          + 나는 전기가 들어오지 않는 시골집에서 자랐음. 어릴 땐 영화 보려고 매번 가솔린 발전기를 돌렸고, 부모님이 전화·위성인터넷을 쓰기 시작하자 가솔린 사용량이 크게 늘었음. 90년대부터 태양광을 썼지만 중고 패널이었음(그래도 거의 고장 없이 멀쩡히 작동함). 최근 여유가 생겨 대규모로 새 태양광 발전을 설치해 줬더니, 요즘은 겨울에 폭풍이 몇 주씩 이어질 때 말고는 발전기가 필요 없어짐(사실 그럴 때도 발전기를 굳이 쓰는 것임). 주요 혜택은 1) 3년 내에 투자금 회수 가능 2) 시끄럽고 냄새 나는 가솔린 소모 발전기가 필요 없음 3) 더 이상 부모님이 무거운 휘발유통 들고 다닐 필요 없음 4) 처음으로 부모님이 에어컨을 사용할 수 있게 됨
          + “우리”라 하면, 캘리포니아 기준으로 곧 다음 단계에 진입할 예정임. 태양광+배터리 설비가 신규 천연가스 발전기 건설보다 대부분 지역에서 더 저렴하게 됨(현재 전력 대부분이 천연가스임). 그리고 곧 배터리 플랜트에서 전력 공급하는 것이 기존 발전기를 돌리는 것보다 싸짐. 연료비는 0, 즉시 공급 가능, 게다가 관성까지 추가 가능함. 만약 “우리”가 중국이라면, 세계에서 가장 많은 신재생 에너지를 제조·설치 중이나, 수요를 따라가지 못해 석탄·원자력 발전도 세계 최다로 병행 중임. 전기차 생산도 세계 1위라 현지 대기질 개선에도 정말 큼
     * 미국이 아직도 석유에 젖은 20세기로 돌아가려 하는 반면, 나미비아 같은 나라들은 유튜브 강좌 하나로 곧장 분산형 태양광 중심 미래로 점프하고 있음. 마치 실시간으로 화석연료의 시대가 뒤처지는 현장을 보는 기분임
          + ""혁신가의 딜레마""(클레이튼 크리스텐슨 저서)는, 대기업이 높은 마진을 포기하지 못해서 초기에는 열등해 보이는 신기술(예: 일본 오토바이·하드디스크)에 밀리는 과정을 설명함. 지금 미국도 같은 딜레마에 놓임. 기름장사 이익을 포기하지 못해 명확히 시장이 이동 중인데도 재생에너지를 주저함. 국가·대기업 모두 장기 경쟁력을 위해선 현재의 이윤원 일부를 희생해야 함. 관련 NYT 기사에 달았던 내 댓글 다시 옮김
          + 나미비아 정부가 미국처럼 가구당 수천 달러의 태양광 보조금을 지급한다는 건 믿기 어려움. 파키스탄도 마찬가지로 기사에 언급됐으나 보조금은 없는 듯함. 태양광이 무르익은 경제적으로 불가피한 기술이라면(나도 동의함) 굳이 보조금으로 밀어주는 논리는 약함. 미국에서는 태양광 설치비 대부분이 행정 인허가비나, 비효율적인 고비용 시공사 손에 들어가는 상황임. 이는 모든 인허가형 개발사업의 고질적 문제로 오히려 공짜 돈이 문제를 심화시킬 수 있음
          + 나미비아를 예로 든 점이 흥미로움. 사실 대부분의 대형 석유기업이 현재 나미비아에 탐사 프로젝트를 진행 중임. 나라의 미래 전략 중 하나로 분명히 자리 잡아가는 것임. 내가 최근 여행했을 때도 월비스베이 해안에서 육안으로 O&G(석유·가스) 산업이 잘 보였음. 다만 나라 대부분이 무인 지대라 태양광에는 정말 이상적 환경임. 정말 멋진 곳이라 방문을 추천함
          + 석유 기반 20세기가 휴대폰, 유튜브, 그리고 나미비아 같은 곳에까지 이런 기적적 기술들을 도입할 수 있게 해 줬음. ‘진짜 역전’이라기보다, 아주 약간의, 소규모의 진전임. 그래도 긍정적으로 보는 것임
          + 미국과 나미비아를 단순 비교하면 무리가 있음. Tesla와 Ford의 경쟁처럼 될 리 없음. 미국이 여전히 석유에 집중하는 건 경제성장 재점화 목적이 큼. 석유 공급망은 정부가 성장 전략으로 조정하기 쉬움. ‘점프’로 독립한 나라들이 에너지 독립으로 잘 해 나가고 있지만, 그건 엄청난 경쟁력이기보다는 장기적 고립을 선택한 것임. 물론 그게 그들에겐 나쁠 건 없을 수 있음
     * ""작년 미국에서 3년 연속으로 히트펌프가 보일러보다 더 많이 팔렸음"" 이거야말로 대단한 진전인데 불과 몇 년 전만 해도 안 다뤄졌던 변화임. 히트펌프는 효율도 많이 개선되고 대량 생산 덕에 단가도 내려감
          + 최근에 히트펌프 건조기를 샀는데, 정말 신기함. 배기관이 따로 필요 없고 그냥 물만 빼내면 됨. 전기 소비도 기존 온풍 건조기보다 훨씬 적어서 고용량 플러그도 필요 없음
     * 태양광이 지금까지 인류의 에너지 소스 중 사상 가장 빠른 성장세를 보이고 있음. 풍력도 사실상 태양에너지가 바람에 누적된 것이니 태양의 한 종류라 할 수 있음. 하이드로(수력)마저도 태양이 물을 증발하게 해 강·저수지로 보내 전기를 만드는 구조임. 결국 태양 덕분에 인류가 대부분의 에너지를 쓰는 셈임(원자력·지열은 예외)
          + 사실 모든 화석연료도 태양에서 비롯됨. 수천만 년 동안 축적된 바이오매스가 화석연료로 변한 것임. 이 모든 탄소·탄화수소에너지의 근원 역시 태양임. 한 단계 더 가면 우리가 쓰는 거의 대부분의 에너지가 핵융합의 부산물임(예외는 원자력·지열)
          + 조수(해양 조력)은 태양 말고도 달의 중력이 영향을 줌. 지구 자전도 아주 미세하게 느려지게 됨
          + 화석연료도 역시 태양발 에너지임!
          + 댓글에서 이 관점까지 논의가 언제쯤 나올지 궁금해 클릭함. 내 첫 생각이었음. 하지만 더 뜨거운 토론은 인류 중심의 에너지 수집과 관리에 관한 부분임을 이해함
          + 고대 사람들이 태양을 신으로 숭배한 게 정말 놀랍지 않음!
     * Tony Seba가 10년 전쯤, 약 2024년에는 현장(onsite) 태양광으로 1단위 전기를 생산하는 비용이 단순히 기존 전력망을 통해 같은 1단위를 ‘전달’하는 비용보다 저렴해질 것이라 예측했음(실제 발전 원가 제외 기준). 현재는 Seba가 '페이즈 체인지 디스럽션'이라 부르는 새로운 단절 현상의 파장을 다방면으로 분석 중임. 관련 유튜브 링크
          + 나는 2020년부터 Seba를 팔로우 중인데, 1) 계속 그의 예측이 맞아떨어지는 것, 2) 여전히 많은 사람들이 그의 전망을 쉽게 받아들이지 않는 것이 신기할 정도임. 최근 예측은 훨씬 더 급진적으로 변했고, 다음엔 또 얼마나 맞힐지 기대됨
          + 개인 에너지 풍요는 정말 혁신임에 동의함.
               o 공공서비스 분산화, 초기 투자 후 에너지의 한계비용이 제로가 되어 경제적으로 해방됨
               o 지정학적으로, 탄화수소 의존성 줄이고 에너지 주권 확보됨
               o 교통 혁신: 모든 집이 전기차 충전소가 되고, 혹은 전기차 배터리로 집을 역충전할 수도 있음(기존 발전기는 ICE 기반)
               o 기후: 탄화수소 소모가 없으니 오염이 없음
               o 기술 사회: 풍부한 청정 에너지가 에너지 생산·저장·AI·네트워킹 분야 혁신을 가속하는 선순환 만듦
               o 에너지-서비스 기반의 새로운 비즈니스 모델 등장
     * “이제 화석연료의 산발적 매장지에 의존해 그 공급권을 두고 국제 정치 역학이 결정되던 시대를 지나, 아무 데서나 얻을 수 있는 분산/평등한 태양·풍력으로 이동 중이다”라는 주장을 보며, 나도 태양광에 전적으로 동의하지만, 현재 태양광이 실질적으로 석유와 같은 지리적/지정학적 이슈를 해결하고 있는지 궁금함. 중국이 사실상 전 세계 태양광 패널을 거의 모두 만들고 있음. 이건 지질학보다 더 큰 독점 같아 보임
          + 육로 수송장악의 예를 들면, 미국이 석유를 봉쇄하면 상대국 트럭/발전소가 6주 후 멈춤. 반면, 태양광 패널 수입이 막혀도 기존 패널은 20~40년 동안 계속 돌아감. 20년 뒤, 즉 보증기간 종료 즈음 돼야 진짜 문제가 생김. 그 기간 동안 봉쇄를 유지해야 상대에 타격이 생김
          + 하지만 태양광 패널의 생산 독점은 지질학적 원인 때문이 아님. 새로운 오일 매장지 찾는 것보다 태양광 생산 능력 키우는 게 훨씬 쉬움
          + 태양광 패널 생산은 아주 복잡하지 않음. 중국이 더 싸고 빨리 하니까 시장을 장악했을 뿐, 산업화된 나라면 어떤 곳이든 전략적으로 인프라 구축은 가능함
          + 태양광 패널은 현지에서 재활용 가능하지만, 오일은 그럴 수 없음. 물론 현지 제조업을 안 키우면 외국 의존이 계속되지만, 중국의 독점이 고정불변이라는 건 아님
          + 미국도 한때는 태양광 패널과 LiFePO4 배터리 생산국이었으나, 관련 산업을 스스로 방치했음. 여러 공장 경매도 직접 다녀봤지만, 대형 설비는 시장성이 없어 사려는 사람이 없었음. 지금도 미국 내 태양광 공장이 몇 군데 남아 있긴 하지만 예전과는 비교 불가임
     * 중국도 이제 태양광+배터리가 석탄보다 저렴한 신기한 상황에 직면함. 석탄이 전체 전력 약 60%를 차지하고, 연간 약 10조 kWh를 소비함. 즉, 6조 kWh × 8센트는 약 6,000억 달러. 매년 수백만 명이 종사하는 5~6천억 불짜리 산업을 줄이거나 없애야 함. 대신 훨씬 저렴한 에너지를 얻게 되고, 해마다 발전 단가가 더 내려가 경제에 새로운 디플레이션 효과를 가져올 수 있음
          + 중국만큼 기존 산업 보호 논리가 약한 곳도 없음. 재생에너지, 에너지 자립은 국가 차원에서 매우 의도적인 움직임임. 목표에 도달하면 “아, 우리 소중한 석탄 일자리, 시골 유권자·탄광 로비 때문에 어쩌지”가 아니라, 지금보다 훨씬 저렴한 에너지를 얻게 되고 남는 인력도 더욱 생산적인 부문으로 이동시킬 것임
          + 투자금 회수에만 신경 쓴다면 문제일 수 있지만, 에너지 산업은 본질적으로 그다지 인력 집약적이지 않음(사람 계속 고용하는 것도 가능). 어쨌든 발전소는 감가상각 처리하고 석탄 구매는 끊을 것임. 후자는 즉각적으로 비용 절감 효과가 큼
     * 도시의 비상계획에서 지자기 폭풍 같은 위협을 대부분 간과함—지금 캐링턴급 플레어가 터지면 수십억 달러짜리 변압기가 한 번에 나갈 수 있음. 당장 저렴하게 할 수 있는 대비책이 무엇이 있을까 궁금함
          + 이건 현실성 없는 우려에 더 가깝게 보임. 유도 전류가 차단기를 다 날렸다 해도 기계적 손상이 실제로 광범위하게 발생할 거라고 보진 않음. 세계 곳곳의 전력망을 블랙스타트(완전 정전 후 재가동)해야 할 수도 있지만, 광범위한 피해까진 아닐 것으로 생각함
"
