"https://news.hada.io/topic?id=19600","QwQ-32B: 강화 학습으로 더 작은 파라미터에서 DeepSeek-R1과 유사한 성능 내기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          QwQ-32B: 강화 학습으로 더 작은 파라미터에서 DeepSeek-R1과 유사한 성능 내기

     * QwQ-32B 모델은 320억 개의 파라미터를 가진 모델로, DeepSeek-R1과 유사한 성능을 보임
     * 이 모델은 대규모 언어 모델의 지능을 강화하기 위해 강화 학습(RL)을 활용
     * Hugging Face와 ModelScope에서 Apache 2.0 라이선스로 공개되어 있으며, Qwen Chat을 통해 접근 가능함

성능

     * QwQ-32B는 수학적 추론, 코딩 능력, 일반 문제 해결 능력을 평가하는 다양한 벤치마크에서 테스트됨.
     * DeepSeek-R1-Distilled-Qwen-32B, DeepSeek-R1-Distilled-Llama-70B, o1-mini, 그리고 원본 DeepSeek-R1과 비교하여 성능을 평가함
          + QwQ-32B는 LiveBench, BFCL에서 최고 성능을 기록하며, IFEval, AIME24에서도 DeepSeek-R1-671B와 비슷한 수준임
          + LiveCodeBench에서는 DeepSeek-R1-671B보다 약간 낮지만, 여전히 다른 모델보다 우수함
          + 전반적으로, DeepSeek-R1-671B와 비슷하거나 더 나은 성능을 보이면서도 **훨씬 적은 파라미터(325억 vs 6710억)**로 경쟁력을 입증
          + 즉, QwQ-32B는 강화 학습을 통해 최적화된 모델로서, 훨씬 작은 규모임에도 불구하고 최상위 성능을 달성한 것이 핵심 포인트

강화 학습

     * 초기 단계에서 수학과 코딩 작업을 위한 강화 학습(RL) 스케일링 접근 방식을 도입함
     * 전통적인 보상 모델 대신 정확성 검증기와 코드 실행 서버를 사용하여 최종 솔루션의 정확성을 보장
     * 일반적인 능력을 위한 추가 RL 단계가 있으며, 이는 인간의 선호도와 에이전트 성능과 같은 일반적인 능력의 성능을 향상시킴

향후 작업

     * Qwen은 강화 학습(RL)을 확장하여 추론 능력을 향상시키는 초기 단계에 있음
     * 강화된 기초 모델과 스케일링된 계산 자원을 결합하여 인공지능 일반 지능(AGI) 달성에 가까워질 것임
     * 에이전트와 RL의 통합을 통해 장기적인 추론을 가능하게 하여 더 큰 지능을 발휘할 수 있도록 탐구 중임

        Hacker News 의견

     * 긴 문맥 길이(130k 토큰)를 주의해야 함. 충분한 문맥 없이 긴 CoT를 생성하는 것은 무의미함
          + 첫 번째 프롬프트가 너무 길어서 작업을 잊어버림
          + 사용자가 특정 작업을 제공하지 않았음
          + 초기 지침은 AI 에이전트로 행동하라는 것임
          + 사용자가 문제를 주고 단계별로 추론하라는 것 같음
     * 수학 학습과 코딩이 일반적인 추론 능력을 향상시킴
     * Deep Seek보다 20배 작음. 어떤 하드웨어에서 실행 가능한지 궁금함
          + 512GB M3 Ultra가 필요 없을 것 같음
          + Deepseek과 맞먹지만 20배 작음
     * 중국의 전략은 오픈 소스 소프트웨어와 로봇 공학에서 수익을 창출하는 것임
          + 미국은 어떻게 힘을 유지할 것인지 궁금함
          + 인도는 이 경쟁에 참여하지 못하고 있음
     * Qwen2.5-plus를 테스트하기 위해 링크를 제공함
     * 2024년 11월에 ""프리뷰""로 출시되었음
          + ""기다려""라는 표현을 많이 사용함
          + 많은 추론 토큰을 생성한 후 플롯을 잃어버리는 문제 발생
     * Deepseek-R1 바로 아래에 위치함
          + 32B로 매우 인상적임
          + 생각하는 토큰이 최종 답변보다 10배 크기도 함
          + 주말에 함수 호출로 테스트할 예정임
     * 개인 경험에서 역방향으로 읽고 질문에 답변하는 테스트를 함
          + ""ip fo eulav si tahw""를 역방향으로 읽으면 ""what is value of pi""가 됨
          + π의 값은 약 3.14159임
          + π는 무리수로, 끝없이 반복되지 않음
     * 즉시 처리했으며 긍정적인 경험이었음
"
"https://news.hada.io/topic?id=19694","2025년에 안드로이드 앱을 만들기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          2025년에 안드로이드 앱을 만들기

   요즘 기준의 안드로이드 앱 개발 환경 소개
     * 빌드 : gradle
     * 빌드 설정: convention plugin
     * 의존 관리 : version catalog
     * build cache 도입
     * 빌드 성능 분석 : build-scan
     * 모듈 구성 : feature 별 분리
     * 네트워킹 - retrofit
     * json 매핑 - kotlinx serialization
     * 영속적 데이터 저장 - jetpack datastore, room
     * DI - koin
     * 이미지 로더 - coil
     * UI - compose
     * View 와 ViewModel 간의 커뮤니케이션 - flow
     * 코드 품질 관리 - ktlint , konsist
     * 단위 테스트 - junit 4

   좋은글 감사합니다

   음.. 여담으로 최근 몇년사이 start-up은 대부분 Flutter, META, OpenAI같은 큰 기업들은 native로 가는 기이한 현상이 목격되고 있죠..

   마침 올해 안드로이드 앱을 만들어보려고 하는데 유용한 지침이 되었습니다. ㅎㅎ

   어쩌다가 안드로이드 앱 빌드 엔지니어로 정착하게 된 사람으로서 의견을 남긴다면..

     빌드 : gradle

   대단히 크거나, 복잡해도 gradle 써야합니다... (먼산)
   대단히 크거나 복잡한 프로젝트에서 gradle의 빌드 성능을 개선하기 위해 아래 프로젝트들이 진행되고 있으니, 큰 프로젝트에서 gradle을 사용중이라면, 미리미리 마이그레이션 준비 해두는게 좋습니다.
     * https://docs.gradle.org/current/userguide/configuration_cache.html
     * https://docs.gradle.org/current/userguide/isolated_projects.html

     모듈 구성 : feature 별 분리

   개인적으로는 아키텍쳐 레이어를 굳이 빌드 시스템에 노출시킬 이유는 없다고 봅니다.
   제가 관리하는 앱의 경우 feature-api / feature-impl 로 모듈을 빌드시스템에 노출시키도록 하고 있습니다.
     * feature-app :
          + 데이터 모델, 또는 다른 모듈과 연계되는 interface
     * feature-impl:
          + feature의 실제 구현

   이렇게 구성하면, feature-impl의 코드 변경이 feature-api를 참조하는 다른 모듈에 영향을 끼치지 않기 때문에(의존성 격리), incremental build나 build cache hit rate 상승에 많은 도움이 됩니다.

     단위 테스트 - junit 4

   이건 구글의 결정이 큰 역할을 한 것 같습니다.
     * https://issuetracker.google.com/issues/127100532
     * Android Platform의 경우 JUnit3 (처럼 보이는 JUnit4), Android빌드 툴의 테스트 프레임워크는 JUnit4 기반으로 동작하는데, JUnit5로 이전할 생각없다고 Google이 못박았습니다.
       그런데 최근에 출시된 screenshot testing plugin은 JUnit5 기반입니다.

   그런데 최신 기술(?)을 도입하려면 JUnit4 가 발목잡는 경우가 종종 있어서, 개인적으로는 JUnit5로 이전이 되었으면 하는 자그만한 소망이 있긴합니다.
   https://docs.gradle.com/develocity/test-distribution/

   junit-vintage-engine 을 쓰면 큰 수정없이 junit4 테스트를 junit5에서 동작시킬 수는 있는데, 오버헤드가 상당히 큽니다. (대략 20% 정도 느려짐)

   헛 가문의 영광이네요

   윌슨이다!
"
"https://news.hada.io/topic?id=19707","Local Deep Research - 로컬에서 나만의 연구 조수 운영하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Local Deep Research - 로컬에서 나만의 연구 조수 운영하기

     * 강력한 AI 기반 연구 도구, 여러 LLM과 웹 검색을 사용해 깊이 있는 반복 분석을 수행
          + ArXiv, Wikipedia, Google, PubMed, DuckDuckGo, SerpAPI, 로컬 RAG, The Guardian 등의 검색 기능을 통합
     * 로컬에서 실행해 개인정보 보호를 강화하거나 클라우드 기반 LLM을 설정해 성능을 향상시킬 수 있음

고급 연구 기능

     * 자동화된 심층 연구: 지능적인 후속 질문 생성
     * 출처 추적 및 검증: 인용 및 출처 자동 추적
     * 반복 분석: 다단계 반복 분석으로 포괄적 커버리지 제공
     * 전체 웹페이지 콘텐츠 분석: 스니펫이 아닌 전체 콘텐츠 기반 분석

유연한 LLM 지원

     * 로컬 모델 지원: Ollama 기반의 로컬 AI 처리
     * 클라우드 모델 지원: Claude, GPT 등 클라우드 LLM 지원
     * Langchain 모델 호환: 다양한 Langchain 모델 지원
     * 모델 선택 가능: 성능, 응답 속도 등에 따라 모델 설정 가능

풍부한 출력 옵션

     * 상세 연구 결과: 인용 포함된 상세한 보고서 제공
     * 종합 연구 보고서: 포괄적인 연구 결과 제공
     * 빠른 요약: 핵심 내용 요약 가능
     * 출처 추적 및 검증: 출처 추적 및 검증 지원

프라이버시 중심 설계

     * 로컬 실행 가능: 로컬 모델 사용 시 모든 데이터가 사용자 기기에 저장됨
     * 검색 설정 가능: 개인정보 보호 강화
     * 투명한 데이터 처리: 데이터 처리 방식 명확하게 공개

향상된 검색 통합

     * 자동 검색 엔진 선택: 검색 엔진을 쿼리 내용에 따라 자동 선택
     * Wikipedia 통합: 신뢰할 수 있는 사실 검색
     * arXiv 통합: 과학 논문 및 학술 연구 검색
     * PubMed 통합: 의학 및 생물 의학 연구 자료 검색
     * DuckDuckGo 통합: 일반 웹 검색 (속도 제한 가능)
     * SerpAPI 통합: 구글 검색 결과 제공 (API 키 필요)
     * Google Programmable Search: 사용자 정의 검색 설정 (API 키 필요)
     * The Guardian 통합: 뉴스 및 저널리즘 콘텐츠 검색 (API 키 필요)
     * 로컬 RAG 검색: 개인 문서 검색 가능 (벡터 임베딩 사용)
     * 전체 웹페이지 콘텐츠 검색: 웹페이지 전체 내용 검색 가능
     * 출처 필터링 및 검증: 신뢰할 수 있는 출처로 필터링 가능
     * 검색 매개변수 설정 가능: 검색 범위, 기간 등 설정 가능

로컬 문서 검색 (RAG)

     * 벡터 임베딩 기반 검색: 개인 문서에서 내용 검색 가능
     * 사용자 정의 문서 컬렉션 생성: 주제별로 문서 그룹화 가능
     * 프라이버시 보호: 모든 문서는 로컬에서 처리됨
     * 지능적 청킹 및 검색: 문서 내용을 청킹 및 검색
     * 다양한 문서 형식 호환: PDF, 텍스트, Markdown 등 지원
     * 통합 메타 검색 자동 적용: 로컬 및 웹 검색 통합 가능

웹 인터페이스

     * 대시보드 제공: 직관적인 인터페이스
     * 실시간 진행 상황 업데이트: 연구 진행 상태 실시간 제공
     * 연구 이력 관리: 이전 연구 기록 접근 및 관리 가능
     * PDF 보고서 내보내기: 연구 보고서 PDF로 다운로드 가능
     * 연구 관리: 진행 중인 연구 중단 또는 삭제 가능

지원 검색 엔진 옵션

     * Auto: 쿼리에 따라 자동 엔진 선택
     * Wikipedia: 일반 정보 및 사실 검색에 적합
     * arXiv: 과학 및 학술 논문 검색에 적합
     * PubMed: 생물 의학 및 의학 연구에 적합
     * DuckDuckGo: 개인 정보 보호 중심의 일반 웹 검색
     * The Guardian: 뉴스 및 저널리즘 검색 (API 키 필요)
     * SerpAPI: 구글 검색 결과 제공 (API 키 필요)
     * Google Programmable Search: 사용자 정의 검색 (API 키 필요)

        Hacker News 의견

     * 지역적(로컬)이고 저해상도(로파이)인 공간을 위한 노력에 박수를 보냄. 그러나 문서의 예시를 읽어보니 결과물이 다소 혼란스러운 느낌임
          + 중간 단계가 하나 이상 필요하다고 생각함. 예를 들어, 그래프 데이터베이스를 사용하여 LLM이 정보를 저장하고 상호 연결성을 확인하며 스스로 질문을 던져 최종 보고서를 생성할 수 있음
          + 최종 보고서는 사용자가 질문하거나 직접 편집할 수 있는 인터랙티브 HTML 파일이 될 수 있음
          + Onyx라는 유사한 오픈 딥 리서치 도구가 있으며, UI/UX가 더 나은 것 같음. 저자가 이 도구를 로컬로 포팅하는 것을 고려할 수 있음
          + 이 프로젝트가 좋지 않다는 것이 아니라, 많은 오픈 딥 리서치 프로젝트가 사라질까 걱정됨. 사람들이 가장 관심 있는 부분에 집중하여 협력하는 것이 더 나을 것임
     * 이 프로젝트는 멋짐
          + 인터넷을 소스로 임베딩을 추가하고 싶다면 exa.ai를 시도해보길 권장함. Wikipedia, 수천 개의 뉴스 피드, Github, 7천만 개 이상의 논문을 포함함
          + 참고: 나는 창립자 중 한 명임
     * 시도해봤지만 많은 오류가 발생하여 보고서를 생성할 수 없었음. 생성 실패 시 재개할 방법이 없어, API 호출이 실패하면 처음부터 다시 시작해야 함
     * 웹 검색을 위해 Kagi와 Tavily API도 고려할 것
     * 매우 멋져 보임. open-webui의 RAG 기능과 비교하면 어떤지 궁금함
          + 웹 검색과 문서 임베딩 방법이 있지만, 결과가 임베딩에서 세부 사항이 손실되어 미흡함. 이 방법이 더 나은지 궁금함
     * (로컬) LLM을 사용하여 벡터 검색에 의존하지 않고 자료집에서 관련 자료를 직접 검색하는 사람이 있는지 궁금함
     * 좋은 작업임
          + 최근에 RAG를 위해 큐레이션된 구조화된 정보를 사용하여 사전 처리된 로컬 컬렉션이 이 동적 검색 접근 방식에 좋은 보완이 될 수 있다고 생각함
          + LangChain을 사용한 것을 보았으며, txtai를 확인해볼 가치가 있음
     * AI 검색 경험을 제공하고 북마크의 내용을 혼합하여 보고서를 생성하는 도구가 있는지 궁금함. 현재 북마크는 쓸모없는 상태임. 이것이 유용하게 만들 수 있음
          + 현재 OpenAI의 딥 리서치에서 자주 발생하는 실패 모드는 낮은 권위의 출처에서 답을 가져와 과학 저널인 것처럼 참조를 제공하는 것임. 이런 출처는 가치 있는 내용을 거의 포함하지 않으며, 다른 출처가 고품질이어도 저품질 출처가 모든 것을 망침
          + 이미 큐레이션한 콘텐츠(북마크)를 강조하면 신호 대 잡음비(SNR)를 크게 향상시킬 수 있음
     * LLM을 위한 3D 게임 같은 GUI를 만드는 사람이 다음의 Jobs/Gates/Musk이자 노벨상 수상자가 될 것이라고 생각함. 이는 LLM의 내부를 수백만 명이 볼 수 있게 하여 정렬 문제를 해결할 것임. 컴퓨터는 GUI가 있는 OS가 등장한 후에야 대중화되었으며, 현재의 챗봇은 명령줄과 비슷함. AI 안전 아이디어를 공유하기 위해 ASK HN을 시작했음

   이해 안됨. 아카데믹 수준은 커녕 초딩 코딩 수준도 안되는걸 왜 공유 하는지...
     * 생명 계열 종사자로서 간략하게 사용한 결과를 공유하고자 함.

     Reseach mode는 2개로 제공됨.

    1. Quick summary

     * 소요시간은 약 5~6분 정도 (4070 ti super, 16GB 기준, Mistral 및 Gemma 3:12b)
     * 환각 증상이 있어서 Reference를 직접 생성하나, 문서에 링크가 걸리는 Ref는 출처가 명확한 것 같음.
     * 질문에 대한 대답을 신기술에 초점을 맞춰서 답변하려는 의도가 있음. 특히 AI와 연관 지으려고 함.

    2. Detailed Report

     * 소요 시간은 약 1시간 (4070 ti super 16GB, Gemma 3:12b)
     * 하나의 리뷰 페이퍼를 만들어주는 격임. 그런데 Reference가 확 줄어버리는 문제가 있음. 내용은 맞다고 쳐도 근거를 댈 수 없으니 약간의 개선이 필요함. (아무래도 되새김질을 진행하여 글의 퀄리티를 높이는 것 같은데 이 과정에서 Ref link들이 유실되는 것 같음.)
     * 다만 확실히 Quick summary보다는 퀄리티 높은 내용들을 제공함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   Config 파일에서 다양한 설정이 가능. 검색할 데이터베이스를 PubMed에만 국한되게 만들어서 자료의 퀄리티를 한층 더 높일 수 있음. 한번에 검색할 텍스트들이나 RAG 사용 시 얼만큼의 청크를 만들지 설정할 수 있음.

   현재 0.01V 임을 감안했을 때 Local 머신으로 이 정도까지 보고서를 만들어낼 수 있다는 것이 매우 놀라움. 특히 생명과학 쪽은 Chatbot들이 일반화된 서술을 사용하는 경우가 많은데 해당 프로그램을 통해서 만들어진 보고서는 굉장히 과학적인 서술을 사용함.

   해당 프로그램은 현재 한글을 지원하지 않음. 질문을 한글로 해도 보고서는 영문으로 출력됨.
   또한 PDF 내보내기를 통해서 PDF 파일로 답변을 받을 때 한글은 나오지 않는 문제가 있음.

   Ref가 보고서 생성 도중에 사라지는 문제, 환각을 일으키는 문제만 해결된다면 정말 강력한 도구라고 생각함.

   더 사용해보니 Ollama에서는 다양한 모델 중에서도 Qwen2.5에서 잘 작동하는 것 같음. Deepseek-r1은 Search 할 때 쿼리를 이상하게 만들어서 근거가 되는 내용을 잘못 가져오고 Gemma류는 예시로 든 프롬프트를 실제 프롬프트로 인식해서 해당 관련 주제 내용을 꼭 집어넣으려고 함.
"
"https://news.hada.io/topic?id=19681","SARS-CoV-2 우려 변이주를 강력하게 중화하는 이중특이 항체","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  SARS-CoV-2 우려 변이주를 강력하게 중화하는 이중특이 항체

        Hacker News 의견

     * 제목은 ""N-말단과 수용체 결합 도메인을 표적으로 하는 이중특이 항체가 SARS-CoV-2의 우려 변종을 강력하게 중화함""임. 항체는 감염 전에는 유용했지만, 감염 후 치료 효과는 제한적이었음. 따라서 치료제가 아님. 또한, 이 연구는 인간이 아닌 쥐에서 진행되었으므로 현재 사용할 수 있는 것이 아니라 미래의 가능성임
     * 안타깝게도 이는 COVID 항체 검사 결과가 유효한 면역 증명서가 되지 않았던 것을 상기시킴
     * 이러한 유형의 이중특이 항체가 백신을 통해 신체가 생성하는 스파이크 단백질을 중화하는 데 사용될 수 있을 것임. 표적 삼각근은 수명이 긴 세포로, 아직 알려지지 않은 기간 동안 스파이크를 생성하고 방출함. 다양한 특정 부스터를 고려할 때, 지속적인 면역 체계 자극을 피하기 위해 중화 항체를 사용하는 것을 상상할 수 있음
     * 이것이 의미하는 바는? 더 나은 백신?
     * 모든 변종? 그러나 N-말단은 돌연변이에 면역이 아니며 특정 항체는 이러한 돌연변이를 위한 진화적 선택을 유도할 것임 - 그리고 새로운 변종의 빠른 개발
     * 거의 모든 생물학 논문이 놀라운 그림을 가지고 있다는 점에 감명받음 (단백질 다이어그램을 제외하더라도). 이는 지도교수들이 학생들에게 그래픽 디자인을 얼마나 가르치는지 궁금하게 만듦
     * 최근 정치적 선택 때문에 주목할 만한 점은, 이들은 인간화된 쥐로, 유전자 변형이 되어 있음. 쥐 ACE2 유전자 대신 인간 ACE2 유전자를 가지고 있어 COVID 바이러스가 세포에 들어가는 데 사용하는 인간 버전의 효소를 만듦. 정확한 분야는 아니지만, 모든 COVID 쥐 모델이 유전자 변형 쥐를 필요로 한다고 들은 기억이 있음
     * 참여하고 싶음
     * [쥐에서] 태그가 필요함
     * [삭제됨]
"
"https://news.hada.io/topic?id=19659","AI 에이전트 시장 지도","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             AI 에이전트 시장 지도

     * AI 에이전트 스타트업 170여 개를 26개의 카테고리로 분류한 시장 지도
          + 또한 AI 에이전트 기술 발전 현황과 한계점 및 향후 전망을 분석

개요 및 시장 현황

     * AI 에이전트(자율적이고 의사결정 범위가 넓은 시스템)는 개념을 넘어 실제로 기업 환경에 빠르게 도입되는 중
     * AI 에이전트 스타트업은 2024년에 38억 달러(약 3배 증가)의 투자를 받음
     * 대형 테크 기업들도 적극적으로 AI 에이전트를 개발하거나 관련 도구를 제공하고 있음
     * 기업들은 인간과 AI 에이전트가 함께 일하는 하이브리드 팀 구성을 추진하고 있으며, 일상적인 업무를 자동화하여 효율성을 극대화할 것으로 예상됨

  AI 에이전트 스타트업 현황

     * AI 에이전트 스타트업을 선정할 때 Mosaic 건강 점수(500 이상)와 최근 자금 조달 여부(2022년 이후)를 기준으로 함
     * 스타트업을 인프라와 애플리케이션으로 나누어 분류하며, 주요 카테고리는 다음과 같음:
          + 추론(Reasoning): 복잡한 사고와 언어 이해를 담당하는 기초 모델
          + 기억(Memory): 정보를 저장하고 관리하는 시스템
          + 도구 활용(Tool use): 외부 소프트웨어 및 인터넷과 상호작용할 수 있는 기능
          + 계획(Planning): 복잡한 업무를 나누고 적응하는 구조

  AI 에이전트 기술 전망

     * 아직 완전 자율적인 에이전트는 신뢰성, 추론능력, 접근성 등에서 제한적이며, 대부분 제한된 환경에서만 작동
     * 향후 기술 발전으로 추론과 기억 능력이 향상되면 더 정교한 결정과 업무 수행이 가능할 것
     * 예시:
          + 법률 AI 스타트업 Harvey는 OpenAI의 o1 모델을 활용해 법률 업무 전반을 자동화하는 에이전트를 개발 중이며, 최근 3억 달러 투자를 받음
     * 앞으로는 기존 챗봇과는 다른 새로운 형태의 AI 기반 업무 환경(AI-native workspace)이 확산될 것으로 예상됨
          + Eve: 법률 업무 전체 프로세스 자동화
          + Hebbia: 스프레드시트를 통해 파일 내 데이터를 자동으로 분석·정리
          + The Browser Company: 웹 브라우징 작업을 자동화하고 예상 가능한 새로운 인터페이스 개발

분야별 시장 분석

  AI 에이전트 인프라

     * AI 에이전트 개발 전용 인프라 도구가 증가 중
     * 개발 도구: Letta(기억 관리), Composio(외부 연동), Anon(인증), Browserbase(브라우저 자동화) 등
     * 음성 및 결제 도구 시장도 성장 중이며, 노코드 및 로우코드 형태의 개발 플랫폼 인기가 높아지고 있음
     * Cohere, Mistral과 같은 주요 LLM 업체 및 Amazon, Microsoft, Google 등 빅테크 기업도 인프라 제공 중

  신뢰성과 성능(Trust & Performance)

     * AI 에이전트의 신뢰성 및 보안 문제를 해결하는 스타트업들이 등장 중(예: Haize Labs, Langfuse)
     * 다중 에이전트 시스템(Multi-agent systems)은 여러 전문화된 에이전트가 협력하여 정확도를 높이는 방식으로 인기를 얻고 있으며, CrewAI가 포춘 500 기업의 40%가 사용 중이라고 보고됨
     * 에이전트의 신뢰성 확보를 위한 5가지 방법:
         1. 투명성
         2. 인간 감독
         3. 기술적 보호 장치
         4. 보안 및 규제 준수
         5. 지속적인 성능 개선

  수평적 애플리케이션 및 업무 기능(Horizontal applications & job functions)

     * 전체 AI 에이전트 시장의 절반 가까이를 차지하며, 고객 서비스 및 소프트웨어 개발 분야가 특히 두각을 나타냄
     * HR, 마케팅, 보안 등 산업 전반에 걸친 다양한 업무 자동화가 이뤄지고 있음
     * 고객 서비스 분야는 특히 도입이 활발하여, 조사 대상 기업의 3분의 2가 향후 1년 내 AI 에이전트를 사용할 예정이라고 답변함

  수직적(산업 특화) 애플리케이션(Vertical applications)

     * 산업별 특화 AI 에이전트 시장도 성장 중이며, 금융 서비스, 헬스케어, 산업 분야가 대표적
     * 금융 및 보험 분야가 가장 많으며(예: Boosted.ai, Indemn 등), 헬스케어에서는 Hippocratic AI와 Thoughtful AI 등이 의료 업무 전반의 자동화를 제공하고 있음
     * 산업 분야에서는 Composabl이 산업 장비 제어를 위한 에이전트 플랫폼을 제공 중

결론 및 향후 전망

     * AI 에이전트 시장은 빅테크 중심의 범용 시장과 전문성을 강조한 수직적 시장으로 나뉘어 발전 중
     * 에이전트의 신뢰성과 보안 이슈가 주요 관심사가 될 것이며, 이를 해결하는 전문 기업이 부상할 전망
     * 앞으로 AI-native 워크스페이스 등 새로운 형태의 에이전트 활용 환경이 증가하면서 AI 에이전트의 정의와 활용 방식이 확대될 것으로 기대됨

   Michael Tefula 가 만든 AI 에이전트 시장 지도 하고는 살짝 다르지만 거의 비슷합니다.
   이 CBInsight 꺼는 회사 클릭이 불가능해서 상세 정보를 알기가 어려운데(유료 사용자에게만 제공하는듯),
   위에 Tefula 꺼는 회사를 클릭해서 그 회사의 웹사이트로 이동할 수 있으니 참고하세요.
"
"https://news.hada.io/topic?id=19654","Show HN: Mr. Worldwide로부터 매일 지혜를 얻는 앱 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show HN: Mr. Worldwide로부터 매일 지혜를 얻는 앱 개발

     * ""성공은 최고의 복수임""이라는 Mr. Worldwide의 지혜.
     * 6월 29일 19:30까지의 카운트다운.
     * Pitbull의 음악을 배경으로 즐길 수 있는 옵션 제공.

     끔찍함

        Hacker News 의견

     * 내 iPhone 16 Pro가 페이지를 열자마자 즉시 뜨거워짐. 11/10 설계대로 작동함
     * 꽤 오랜만에 본 가장 어리석고 놀라운 것 중 하나임. 누군가가 단순히 재미로 어리석은 일을 하는 것을 보니 기쁨
     * 형편없는 웹사이트 디자인의 전형이며 사랑스러움. 불필요한 그라데이션, 메스꺼운 움직임, 모호한 버튼, 전반적인 혼란이 Mr. worldwide의 조잡함을 잘 상징함
     * 멋지게 보이지만, Mr Worldwide가 충분한 지혜를 가지고 있어 하루에 한 번만 인용할 필요는 없을 것 같음
          + Pitbull을 두 번 봤는데, 항상 훌륭한 쇼였음. 에너지가 넘치고 노래 사이에 많은 지혜의 조각들이 전해짐, 웃음
     * 멋지지만, 동시에 싸우고 싶어짐
     * Pitbull 팬들을 위해 http://www.pitbullparty.com/이 있음
     * 좋은 것임. 유머를 감사함. Nokia Lumia의 Windows Phone에서 사용하던 앱이 생각남. 언제든지 열어 GOAT의 인용문을 얻을 수 있는 간단한 Chael Sonnen 지혜 앱이었음
     * 이 모든 것은 브라우저에서 로드될 때 즉시 재생되는 노래가 필요함. 그러면 완전한 향수 여행이 됨
     * 주말 HN의 정점임
     * 끔찍함
"
"https://news.hada.io/topic?id=19708","Show GN: 자동 회의록 작성 서비스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Show GN: 자동 회의록 작성 서비스
"
"https://news.hada.io/topic?id=19650","미국의 우크라이나 F-16 지원 중단","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          미국의 우크라이나 F-16 지원 중단

미국, 우크라이나 F-16 지원 종료

     * 미국의 지원 종료: 도널드 트럼프 행정부는 우크라이나의 F-16 전자 방해 능력 지원을 중단함. 이는 우크라이나 공군에게 중요한 항공 방어 수단을 잃게 할 수 있음.
     * 프랑스 Mirage 2000의 역할: Forbes 분석가 David Ax는 우크라이나가 프랑스 Dassault Mirage 2000 전투기의 방해 능력을 활용할 수 있다고 언급함. Mirage 2000은 강력한 방해 장치를 갖추고 있으며, 미국의 개입 없이도 프로그램이 가능함.
     * F-16의 전자 방해: 우크라이나 공군은 AN/ALQ-131 포드를 장착한 F-16을 사용하여 러시아 레이더에 전자 소음을 발생시킴. 그러나 러시아 공군은 레이더 주파수를 변경하여 이를 우회할 수 있음.
     * 프랑스의 지원: 프랑스 국방부는 Mirage 2000에 새로운 전자 대책을 설치할 것을 약속함. 이는 기존 시스템보다 개선된 것으로, AN/ALQ-131의 대체 가능성을 가짐.
     * 장기적 대책: 우크라이나는 장기적으로 F-16에 비미국산 전자 대책을 장착할 수 있지만, 이는 시간과 비용이 소요됨.
     * 관련 뉴스: 덴마크는 우크라이나에 F-16 전투기를 추가로 기증할 예정이며, 우크라이나는 이미 6대의 F-16을 수령함.

        Hacker News 의견

     * 이야기는 계속되고 있음. 이는 어떤 나라도 F16을 구매하고 싶지 않다는 것을 의미함. 지원이 없다면 쓸모없음
          + 미국의 신뢰와 명성이 빠르게 사라지고 있음
          + 이는 미국 경제에 큰 영향을 미칠 것임. 내부 소비로는 이를 구제할 수 없음
          + 제국의 종말을 맞이하고 있음. 부유한 지도자들은 세금으로 주말마다 골프를 치고 있음
          + 현실을 왜곡하여 자신의 이익에 반하는 것을 옹호하는 사람들이 여전히 많다는 것에 놀라움
     * 오늘 읽은 몇몇 댓글은 매우 계몽적임. 미국 하드웨어와 소프트웨어의 능력에 대한 지능적인 대화가 있음
          + F-35의 정교함은 논쟁의 여지가 없음. 그러나 세계는 더 이상 미국을 신뢰하지 않음
          + 사람들은 더 낮은 위험으로 보이는 제품을 기꺼이 탐색할 것임
          + 미국의 제품 우수성은 세계에 관련이 없음. 관계가 제품보다 중요함
          + 미국이 판매를 원한다면 소프트웨어 통제에 대한 기대에 맞춰야 함
     * 스웨덴이 우크라이나에 Saab의 Gripen 전투기를 공급할 것이라는 보도가 있음
          + Gripen은 우크라이나에 장점이 있음. 더 견고하고 유지보수 비용이 낮음
          + 기본적인 활주로와 도로에서도 작동 가능함
          + 미국은 과거에 Gripen 구매를 막으려 했으나 그 판매 이점은 사라짐
     * AN/ALQ-131 재머에 대한 기사에서 미국이 러시아의 대응 조치에 맞춰 업데이트해야 한다고 언급됨
          + 덴마크가 기증한 F-16은 Terma의 파일런을 가질 가능성이 높음
          + 유럽이 필요한 파일런을 만드는 것은 어렵지 않을 것임
     * 전체주의 정부들이 당신의 행동을 칭찬하기 시작하면 뭔가 잘못되었다는 것을 알아야 함
          + 중국과 러시아의 전체주의 정부를 언급함
     * 이 논의가 드디어 이루어져 기쁨. 주류 언론도 이 문제를 다루고 있음
          + ""미국이 유럽의 무기를 끌 수 있는가?""라는 주제가 논의되고 있음
          + 고급 전투기와 무기 시스템이 미국의 부품과 소프트웨어 업데이트에 의존하고 있음
     * 기사는 미국만이 재머 시스템을 재프로그래밍할 수 있다는 인상을 줌
          + 미국, 노르웨이, 덴마크의 협력으로 F-16 재프로그래밍이 이루어졌음
          + 68th EWS 팀이 시스템을 이해하고 작업을 시작함
     * 신뢰를 쌓는 데는 100년이 걸리지만, 이를 잃는 데는 두 달이면 충분함
     * 오늘은 우크라이나와 F35, 내년에는 누가 될 것인가?
          + 유럽 정부들은 미국에 대한 전략적 의존성을 심각하게 검토하고 있음
          + Microsoft와 Google 같은 미국 SaaS에 의존하는 경제가 모두 중단된다면 큰 기업들이 어떻게 운영할지 모름
     * 덴마크 공군은 F35 구매에 대해 후회하고 있을 가능성이 높음
"
"https://news.hada.io/topic?id=19697","Goravel - Laravel에서 영감을 받은 Go 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Goravel - Laravel에서 영감을 받은 Go 프레임워크

     * 완전한 기능과 우수한 확장성을 갖춘 웹 애플리케이션 프레임워크
     * Gopher(Go 개발자)가 빠르게 애플리케이션을 구축하도록 돕는 스타터 스캐폴딩 역할 수행
     * Laravel과 일관된 디자인을 통해 PHP 개발자들이 쉽게 적응 가능

주요 기능

     * Config – 설정 관리. 모든 구성 파일은 config 디렉토리에 저장.
     * Http – HTTP 처리 및 요청 라우팅 facades.Route()
     * Authentication – 사용자 인증, JWT 지원
     * Authorization – 사용자 권한 관리 내장. 클로저 기반의 권한 관리인 Gates 와 특정 리소스에 대한 컨트롤러인 Policies 로 구성
     * Orm – 객체-관계 매핑 지원. MySQL 5.7+, PostgreSQL 9.6+, SQLite 3.8.8+, SQL Server 2017+
     * Migrate – 데이터베이스 마이그레이션 관리
     * Logger – 로그 관리
     * Cache – 캐시 관리. memory 드라이버 및 Redis 드라이버 제공
     * Grpc – gRPC 지원
     * Artisan Console – CLI 도구에서 명령어 기반 작업 수행
     * Task Scheduling – 작업 스케줄링
     * Queue – 작업 대기열 처리
     * Event – 이벤트 관리
     * FileStorage – 파일 저장. local 및 다양한 드라이버 제공 : S3, Aliyun OSS, Tencent COS, Minio, Cloudinary
     * Mail – 이메일 전송 및 관리
     * Validation – 데이터 유효성 검사
     * Mock – 모의 객체 및 테스트 지원
     * Hash – 해싱 처리. Argon2id, Bcrypt
     * Crypt – 암호화 처리. OpenSSL을 통해 AES-256 암호화를 제공
     * Carbon – 경로, 시간, 맵, 변환등 헬퍼 함수들
     * Package Development – 패키지 개발 지원
     * Testing – 유닛 테스트 부터 통합 테스트 까지 테스트 프레임워크 제공
     * Localization – 다국어 지원
     * Session – 세션 관리

   테스트를 해 보고 있는데, 뭔가 종합선물세트 같은 느낌입니다.

   와우 세상에 이걸 미리 알았더라면 프로젝트를 훨씬 편하게 했을 거 같은데... ㅎㅎㅎㅎㅎ
"
"https://news.hada.io/topic?id=19648","Show GN: until – 노션처럼 쉽고 강력한 블로그 플랫폼","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Show GN: until – 노션처럼 쉽고 강력한 블로그 플랫폼

   [서비스 소개]

   until은 누구나 노션처럼 쉽게 블로그를 만들고 운영할 수 있는 서비스입니다.
   개발자뿐만 아니라 비개발자도 쉽고 빠르게 글을 작성하고 공유할 수 있도록 설계되었습니다.

   처음에는 노션 데이터베이스를 연동한 기술 블로그를 오픈소스로 공개했는데, 예상보다 많은 관심을 받았고, 이를 계기로 비개발자도 손쉽게 활용할 수 있도록 서비스로 발전하게 되었습니다.

   [이런 분께 추천해요]
     * Notion 스타일의 에디터를 선호하는 분
     * 잔디를 심으며 성장하고 싶은 분
     * 개인 또는 팀 기술 블로그가 필요한 분
     * 깃허브 꾸미기를 좋아하는 분
     * 개인 블로그 운영에 피로감을 느끼는 분

   [주요 기능]
     * 강력한 Notion Like Editor로 쉽고 빠르게 글 작성
     * 피드, 랭킹 등 커뮤니티 기능을 통해 동기부여 제공
     * 나만의 기술 블로그를 만들고 꾸밀 수 있는 기능
     * 개인 블로그뿐만 아니라 팀/회사 블로그 운영 가능

   첫 인상은 마음에 드네요. ""깃허브 꾸미기""에 더 자세하게 알 수 있을까요??

   디자인 깔끔하고 좋네요. 한 번 이용해 봐야겠네요

   멋져요~!! 초창기 핀터레스트 느낌입니다.
   응원합니다.

   감사합니다!

   우와 깔끔하고 너무 좋네요 👏 rss 나 커스텀 도메인 지원, seo 등에 대한 개발 계획도 궁금합니다

   관심 가져주셔서 감사합니다!
     * rss: 블로그 우측 상단에 제공하고 있습니다.
     * 커스텀 도메인 지원: 이부분은 추후에 추가될 예정입니다.
     * seo: 현재도 지원하고 있습니다. light house 기준 90점 이상 나오고 있습니다. 계속해서 개선해나갈 예정입니다.

   응원합니다.!!!
   고생하셨고 수고 많으셨어요..
   혹시 note.com 을 벤치마킹 하신 건가요?

   응원해주셔서 감사합니다..!

   말씀해주신 사이트는 처음봤습니다. 비슷한 부분이 있는 것 같아서 신기하기도하고 이것저것 써보면서 참고하면 좋을 것 같네요. 감사합니다 ㅎㅎ

   medium처럼 멋진 플랫폼으로 성장하길 바랍니다!
   velog나 medium에서 가져오는 기능도 있으면 좋겠어요 ㅎ

   의견 감사합니다!! 말씀해주신 기능 좋은 것 같습니다. 한번 고려해보겠습니다.

   깔끔하고 보기 좋아보입니다!

   감사합니다! 계속 디벨롭 해보겠습니다. ㅎㅎ

   velog랑 다르게 modal로 blog 포스팅을 볼 수 있는게 마음에 드네요.

   감사합니다! 열심히 만들어보겠습니다.

   블로그 시작하려고 플랫폼 고민중 이었는데 깔끔하고 좋네요.

   감사합니다!
"
"https://news.hada.io/topic?id=19663","Claude Code 사용 후기 - 스티브 예이그 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Claude Code 사용 후기 - 스티브 예이그

     ""Cursor, Windsurf, Augment, Copilot 등 기존 도구들이 구식처럼 느껴질 정도로 성능이 강력함""

     * 버그 수정 능력
          + Claude Code는 레거시 코드의 버그를 빠르고 효과적으로 수정함
          + 놀라울 정도로 복잡한 작업도 단순한 채팅을 통해 처리 가능함
          + 컨텍스트 선택이 필요 없고, 그냥 명령을 입력하면 작동함
     * 사용 흐름 및 제어
          + 코드 실행 전에 기본 읽기 전용 명령어 실행 허가를 반복적으로 요청함
          + 주기적으로 작업 상태를 사용자에게 알림
          + 사용자가 지켜봐야 함 — 너무 적극적으로 문제를 해결하려는 경향이 있음
          + 은행 결제 승인이 계속된다면 프로덕션 배포까지 밀어붙이고, 이후 사용자 로그까지 스캔함
     * 기능적 한계와 경쟁 제품 대비 우위
          + 클라우드 코드는 폼 팩터가 불편하고 멀티모달 지원이 없음
          + 다른 도구와 병행 사용하기 어려움
          + 그럼에도 불구하고 Cursor, Windsurf, Augment, Copilot 등 기존 도구들이 구식처럼 느껴질 정도로 성능이 강력함
     * 기술적 진보와 Anthropic의 전략
          + 실험 단계에 있지만 현재까지 경험상 가장 큰 기술적 도약임
          + 코드 작성 분야에서 Anthropic이 다른 경쟁사보다 우위에 있음
          + Anthropic은 항상 최고의 모델, 챗봇 인터페이스, 예측 능력을 보유하고 있음
          + Claude Code로 인해 Anthropic이 업계에서 가장 뛰어난 기술적 이해도를 갖춘 회사임을 다시금 입증함

   원문이 삭제된 것인지 트윗이 없네요.
   사용해 보고 싶은데, 프리뷰 기간이지만 유료이고 체험 기간도 없네요 ㅠ
   검색해보면 몇 번 쿼리하는데 5달러 들었다는 사람도 있고 프로젝트 코드 분량에 따라 달라지나봐요.

   Cursor가 구식으로 느껴진다니 시도해보고 싶네요. 그런데 비용이 만만치 않을것 같아 엄두가 안나네요.
   음, 그런데 해커뉴스 의견은 좀 부정적이군요.

        Hacker News 의견

     * Claude Code와 Aider를 비교해 보았음. Claude Code는 코드베이스를 검색하고 51줄의 차이를 만드는 데 60초와 $0.73이 소요되었음. 결과에 매우 만족했음
          + Aider는 처음에 필요한 파일을 찾지 못했지만, 수동으로 파일을 추가한 후 Claude Code와 동등한 결과를 얻었음. Aider는 1 LLM 프롬프트로 15초, $0.07의 비용이 들었음
          + 더 높은 수준의 자율성은 더 높은 비용을 수반함. 큰 프로젝트에서는 비용이 증가할 수 있음
     * AI에게 작업을 요청할 때마다 올바른 답변을 거의 받지 못함. Twitter에서의 성공 사례는 놀랍지만, 간단한 작업에만 유용함
     * 다양한 AI 코딩 도우미를 시도하지 않은 것 같음. 에이전트 기반 AI는 90%의 효율성을 제공하지만, 나머지 10%는 디버깅이 어려움
          + LLM 코딩 도우미의 최적 사용 시나리오는 아키텍처 논의와 단일 파일 내의 작은 작업임
          + 에이전트는 여러 파일을 관리하는 데 위험하고 비효율적임
     * 스크린샷이나 코드 예시 없이 비유만 있는 트윗은 단지 말에 불과함
     * 작은 Django 앱에서 시도했지만 인상적이지 않았음. 문제에 부딪히면 비효율적인 전략을 반복함
          + $12를 사용하여 1200줄의 부분적으로 작동하는 코드를 생성했지만, 결국 모든 변경 사항을 버리고 웹 UI로 돌아갔음
     * 코드를 잘 모르지만 AI 개발에 집착함. Claude를 사용하여 웹 브라우저에서 실행되는 타워 디펜스 게임을 만들었음
          + 8번의 프롬프트를 통해 게임을 만들었고, Claude의 제안에 동의했음. 결과는 놀라웠음
     * 더 큰 마이그레이션 작업을 Claude에게 맡겼지만 실패했음. HTML 구조와 CSS를 변경하는 등 요청하지 않은 작업을 수행함
     * LLM을 사용한 코드 유지 및 개발은 이상적인 사용 사례가 아님. 대부분의 작업은 기초 모델과 다음 토큰 예측에 있음
          + 가장 흥미로운 LLM 응용 프로그램은 제품 경험과 통합되어 있으며, 깊은 도메인 전문 지식을 활용함
     * 작업의 100%를 수행하도록 만들지 말고 적절한 세부 정보를 제공해야 함. 테스트를 수동으로 검토하고, 문제를 해결하기 위해 LLM을 사용해야 함
     * 오픈 소스 라이브러리 문제를 해결하려고 했지만, 같은 문제를 반복적으로 경험함. Claude Code는 많은 경우에 시간을 절약하지만, 때로는 더 많은 문제를 야기함

   결국 기존것과 다를바 없다는거 아닌가요? 괜히 마루타, 시간 낭비만 할거같아서 이젠 시도 안하게 되네요
"
"https://news.hada.io/topic?id=19594","Tailscale은 꽤 유용합니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Tailscale은 꽤 유용합니다

     * 많은 사람들에게는 오래된 뉴스일 수 있지만, 최근에 Tailscale을 사용하기 시작했고 경험을 공유하고 싶었음
     * 전에도 Tailscale에 대해 여러 번 들어본 적이 있지만 최근까지 그 매력을 느끼지 못했음
     * Raspberry Pi 1을 이용해 간단한 서버를 운영하면서 외부에서 접근이 필요했는데, CGNAT 문제로 인해 기존의 DDNS 방식이 더 이상 동작하지 않음
     * Tailscale을 사용하면 가상 사설 네트워크(VPN)를 생성하여 어디서든 쉽게 접속할 수 있고, 잘 작동함
     * 물론 결국엔 Raspberry Pi 1이 너무 느려 실행이 어려워져서 제거했고, 프로젝트는 클라우드로 이전했음

Tailscale 사용법

     * 각 장치에 클라이언트 소프트웨어 설치 (대부분 오픈소스)
     * 계정 로그인 후 설정 (과정이 간단함)
     * 설치 및 사용법은 공식 문서를 참고하는 것이 좋음

Tailscale의 추가 기능

     * 포트 노출
          + 웹 개발 시, 실제 기기에서 테스트할 필요가 있음
          + http://my-macbook-air:3000 같은 주소를 사용해 간편하게 접속 가능
          + 기존에는 ngrok 같은 서비스를 사용했지만, Tailscale로 대체 가능
     * Taildrop
          + Macbook에서 Windows HTPC로 파일을 전송하는 게 번거로웠음
          + Snapdrop도 좋지만, 클릭이 필요 없는 대안을 찾고 있었음
          + Taildrop을 사용하면 Airdrop처럼 간편하게 파일 전송 가능
     * Exit Nodes
          + Tailscale은 일반적인 VPN과 다르지만, 가끔 VPN이 필요할 때가 있음
          + Tailscale을 이용해 특정 기기를 Exit Node로 설정 가능
          + 예를 들어, 해외 VPS를 Exit Node로 설정하면 VPN처럼 사용 가능
     * Mullvad Exit Nodes
          + VPN 서비스는 다양한 국가에서 접속할 수 있고, 로그를 남기지 않음 (믿는다면)
          + Mullvad와의 파트너십을 통해 Tailscale에서 이 기능을 활용할 수 있음
          + 2단계 VPN 구조로, Tailscale은 사용자의 트래픽을 볼 수 없고, Mullvad는 사용자를 알 수 없음

총평

     * 개인 용도로만 사용 중이며, 무료 플랜을 이용하고 있음
     * 기업용 플랜도 있지만 사용 경험이 없음
     * Tailscale을 활용하면 간편한 네트워크 연결이 가능
     * 오픈소스 대안으로 Headscale 이라는 프로젝트도 존재

        Hacker News 의견

     * Tailscale는 좋아하는 회사 중 하나임
          + CTO의 블로그 글이 동기와 비전을 잘 설명함
          + VPN 모델이 정말 최선인지 의문이 있음
          + Tailscale 노드에 접근하면 모든 서비스에 접근 가능함
          + BeyondCorps/Zero Trust가 이런 상황을 피하기 위해 만들어짐
          + 일반 사용자 시장으로 확장 가능성에 대해 궁금함
          + Google과 파트너십을 맺어 Android와 통합할 가능성을 상상함
          + DERP 시스템은 신호/대체 용도로 좋지만, CGNAT 채택이 IPv6보다 빠르게 증가하는 것 같음
          + 웹 브라우저에서의 사용은 복잡함
          + WireGuard에 의존하는 것이 제한적임
     * Tailscale의 신뢰성에 대한 이유를 알고 싶음
          + Tailnet locks와 같은 기능이 신뢰성을 높이는지 궁금함
     * Go의 tailscale.com/tsnet 패키지가 유용함
          + 단일 바이너리 HTTP 서버를 만들 수 있음
          + golink 프로젝트가 좋은 예시임
     * 남아프리카에서 CVS 앱을 사용해야 했을 때 Tailscale이 문제를 해결해 줌
          + 집에 있는 Tailscale exit node를 사용하여 문제를 해결함
     * 정부 웹사이트가 GitHub Actions에서 스크래핑을 차단했을 때 Tailscale로 해결함
          + Apple TV에 exit node를 설정하여 문제를 해결함
     * Tailscale을 내부 네트워크에 사용 중이며 매우 만족함
          + 여러 나라에 분산된 팀이 마치 한 사무실에 있는 것처럼 연결됨
          + 중앙 관리 ACL, TLS 인증서, Microsoft 계정과의 SSO 제공
          + DNS 관련 불만이 있음
     * 90년대 Hamachi가 Tailscale과 같은 기능을 제공했음
          + 가상 LAN DOOM을 플레이할 때 사용했음
     * Tailscale의 구현에 대해 비판한 적이 있지만, 이번 사례는 훌륭함
          + 방화벽의 포트 포워딩에 의존하지 않음
          + CGNAT이나 IPv6/IPv4 부족과 같은 문제를 해결함
          + 다양한 형태의 exit node와 호환됨
     * Tailscale의 가장 좋아하는 사용 사례
          + 작업장에서 Cassia X1000 블루투스 게이트웨이를 사용함
          + 집에서 Android 작업을 할 때 Tailscale을 사용하여 문제를 해결함
          + 마치 마법이 일어난 것 같았음

   DERP 서버만 안타면 생각보다 tailnet 내부간 데이터 전송도 빠릅니다.

   또한 저는 서로 물리적 거리가 다소 있는 서버들을 엮고
   몇몇 서버를 에지 서버로써 둔 형태로 서비스를 서빙하고 있는데,

   최근에는 그냥 서버간 통신을 전부 tailnet으로 엮었습니다.
   노드 추가하는 것도 쉽고 호스트 서버를 tailscale 측에서 돌려주니 관리도 편하죠.
"
"https://news.hada.io/topic?id=19691","강화 학습(RL)의 수학적 기초 : 책과 유튜브 강의","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     강화 학습(RL)의 수학적 기초 : 책과 유튜브 강의

     * 이 책은 강화 학습의 기본 개념, 문제, 알고리듬을 수학적으로 친근하게 소개하는 것을 목표로 함
     * 알고리듬의 절차뿐만 아니라 왜 설계되었고 효과적인지 이해할 수 있도록 수학적 관점에서 설명
     * 수학의 깊이는 적절한 수준으로 조절되어 있으며, 독자가 선택적으로 읽을 수 있는 예시를 제공
     * 알고리듬의 핵심 아이디어를 복잡한 요소와 분리하여 독자가 더 잘 이해할 수 있도록 함
     * 각 장은 이전 장을 기반으로 구성되어 있으며, 다음 장을 위한 기초를 제공

     * 영어로 된 비디오 강의가 Youtube에 오픈

내용

     * 이 책은 10개의 장으로 구성되어 있으며, 기본 도구와 알고리듬에 관한 두 부분으로 나뉨.
     * 각 장은 상호 연관되어 있으며, 초반 장을 먼저 공부하는 것이 필요함.

독자층

     * 이 책은 강화 학습에 관심 있는 학부 고학년, 대학원생, 연구자 및 실무자를 대상으로 함.
     * 강화 학습에 대한 배경 지식이 없어도 이해할 수 있도록 기본 개념부터 시작함.
     * 확률 이론과 선형 대수에 대한 지식이 필요하며, 필요한 수학 기초는 부록에 포함되어 있음.

강의 비디오

     * 책과 강의 비디오를 결합하여 더 나은 학습을 할 수 있음.
     * 중국어 강의 비디오는 Bilibili 채널과 유튜브 채널에서 확인 가능하며, 2025년 2월까지 1,300,000회 이상의 조회수를 기록함.
     * 영어 강의 비디오는 유튜브에 업로드됨.

저자 소개

     * 저자 정보는 홈페이지와 연구 그룹 웹사이트에서 확인 가능.
     * 2019년부터 강화 학습에 관한 대학원 과정을 가르치고 있으며, 이 책은 강의 노트로 준비됨.
     * 이 책이 독자들이 강화 학습 분야에 원활하게 진입하는 데 도움이 되기를 희망함.

인용

     * 책 제목: ""Mathematical Foundations of Reinforcement Learning""
     * 저자: S. Zhao
     * 출판 연도: 2025
     * 출판사: Springer Nature Press 및 Tsinghua University Press

업데이트 기록

     * 2025년 2월: 5,000+ 스타 획득
     * 2024년 12월: 4,000+ 스타 획득
     * 2024년 10월: 책 표지 디자인 완료
     * 2024년 9월: Springer 출판 전 최종 수정
     * 2024년 8월: 3,000+ 스타 획득 및 코드 추가
     * 2024년 6월: 출판 전 최종 수정
     * 2024년 4월: 그리드 월드 환경 코드 추가
     * 2024년 3월: 2,000 스타 획득
     * 2024년 3월: 세 번째 버전의 초안 온라인
     * 2023년 9월: 1,000+ 스타 획득
     * 2023년 8월: 두 번째 버전의 초안 온라인
     * 2022년 11월: Springer Nature 및 Tsinghua University Press와 공동 출판 예정
     * 2022년 10월: 강의 노트 및 비디오 온라인
     * 2022년 8월: 첫 번째 초안 온라인

   좋은자료 소개 감사합니다.

        Hacker News 의견

     * OpenAI Gym 시대의 강화 학습(RL)은 초보자에게 접근하기 쉬운 점이 큰 장점이었음. 작은 환경에서 취미로 RL을 배우고 Cartpole 같은 간단한 문제에 적용해 볼 수 있었음. LLMs와 관련된 비슷한 접근 가능한 RL 과제나 학습 환경이 있는지 궁금함. 일반적인 MacBook Air로 LLM x RL 분야에서 할 수 있는 것이 있는지 궁금함
          + Pieter Abbeel의 Deep RL 기초에 대한 6강 시리즈도 매우 추천됨. 좋은 개요와 직관을 제공함
          + 강화 학습과 관련 주제에 대한 최고의 강의는 Dimitris Bertsekas의 강의임
          + RL에 대한 훌륭한 시각적 개요를 제공하는 다이어그램과 30분 소개 유튜브 비디오도 매우 추천됨
          + 엔지니어링, 물류, 의학 분야의 실제 문제를 해결하기 위해 RL을 사용하는 하이퍼 성장 스타트업이 많이 생길 것으로 기대됨
          + LLMs가 현재 많은 주목을 받고 있지만, 벤처 캐피털이 RL 회사에 특별히 관심을 두지 않는 것이 놀라움
     * RL에 대한 또 다른 훌륭한 자료는 Mykel Kochenderfer의 교과서 모음임
          + Murphy의 RL에 초점을 맞춘 진행 중인 교과서도 언급할 가치가 있음
          + 관심 있는 사람들을 위해 Sutton의 책 대부분을 구현한 GitHub 리포지토리가 있음
          + MinRL의 코드도 링크되어 있어 감사함. RL 연구를 하면서 비교 연구를 재현하고 자신의 기여를 검증하는 것이 큰 문제였음. 시각화 도구와 관찰만으로 검증할 수 있는 그리드월드 샌드박스를 갖춘 간단한 라이브러리가 매우 유용함
     * 이 책은 독자가 확률 이론과 선형 대수에 대한 지식이 필요하다고 함. 이런 문구는 항상 소금 한 알과 수학 덕후들이 썼다는 이해와 함께 받아들여야 함. 평균적인 수학 실력을 가진 평균적인 프로그래머는 주의해야 함
     * 이 자료를 이해하는 것에서 이 분야의 직업을 얻는 방법을 모르겠음. 현재는 소프트웨어 엔지니어(SWE)로 머물러 있음
"
"https://news.hada.io/topic?id=19617","M3 ultra 512G는 3090보다 조금 딸리는 정도","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    M3 ultra 512G는 3090보다 조금 딸리는 정도

   M3 ultra 512G는 약간 열화된 3090정도인데,
   메모리 대역을 고려해서
   M4 ultra는 가격만 10k 언저리에 나오면 쓸만할지도…

   (DeepL 번역)

   M3 울트라는 512GB로 약간 약화된 3090입니다.

   결론적으로, 3090의 경우 최대 구성에서 114.688TFLOPS FP16 대 142.32TFLOPS FP16, 메모리 대역폭은 819.2GB/s 대 936GB/s이므로 512GB를 사용하는 3090이 약간 약화됩니다.

   M3 울트라 사양에 대한 정보를 찾을 수 있는 곳은 여기뿐입니다:

   https://apple.com/newsroom/2025/…

   하지만 사양에 대한 정보가 매우 모호합니다. 그래서 저는 이 기사를 바탕으로 M3 Ultra의 정확한 사양을 추측해 보았습니다.

   M2 울트라의 2배, M1 울트라의 2.6배 성능의 GPU를 구현하려면 코어당 셰이더를 128개에서 256개로 두 배 늘려야 합니다. 이 정도면 큰 폭의 개선이 이뤄진 것으로 보입니다.

   M4 울트라의 성능에 대한 추정치도 만들어봤습니다.

   칩             M3 울트라  M2 울트라  M1 울트라  M4 울트라?
   GPU 코어        80      76      80      80
   GPU Shader    20480   9728    8192    20480
   GPU GHz       1.4     1.4     1.3     1.68
   GPU FP16      114.688 54.4768 42.5984 137.6256
   RAM 유형        LPDDR5  LPDDR5  LPDDR5  LPDDR5X
   RAM Speed     6400    6400    6400    8533
   RAM 컨트롤러      64      64      64      64
   RAM Bandwidth 819.2   819.2   819.2   1092.22
   CPU P-Core    24      16      16      24
   CPU GHz       4.05    3.5     3.2     4.5
   CPU FP16      3.1104  1.792   1.6384  3.456

   애플은 10-15천에 판매할 가능성이 높습니다. 10k라면 성능은 4배 정도이고 RAM은 훨씬 빠르기 때문에 꽤 좋은 거래라고 생각합니다. 그런 관점에서 15k도 여전히 나쁘지 않습니다.

   셰이더 밀도가 두 배로 증가하지 않고 Apple이 말로만 장난을 치고 있을 가능성도 있습니다. 그것은 큰 실망이 될 것입니다. 이 경우 M4 Ultra를 기다리는 것이 좋습니다.

   가상화는 윈도우즈가 좀 더 유연하고
   서비스 애플리케이션 자원 효율성은 리눅스가 더 뛰어난것같고..

   예전부터 궁금했던건데 애플 실리콘의 GPU 코어가 정확히 어떤 걸 말하는 걸까요? 엔비디아 GPU 같은 경우는 막 수천개씩 있던 걸로 기억하는데 코어수만 보고서는 뭔지 잘 감이 안 오네요

   애플실리콘 코어 = 엔비디아 SM(streaming multiprocessor) 정도로 볼 수 있을것같습니다. 3090에는 82개의 SM이 있다네요.

   https://discussions.apple.com/thread/253792546
"
"https://news.hada.io/topic?id=19653","왜 해고는 효과가 없는가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             왜 해고는 효과가 없는가

     * 2001년 9/11 테러 이후 미국 항공업계에서 약 81,000개의 일자리가 사라짐
     * 아메리칸항공, US 에어웨이즈, 유나이티드항공 등 주요 항공사가 직원의 15~23%를 감축
     * 사우스웨스트항공은 유일하게 해고를 하지 않음
          + 신규 항공기 구매 연기 및 본사 리모델링 취소 등으로 비용 절감
          + 공동 창립자 허브 켈러허(Herb Kelleher) 는 ""해고는 기업 문화에 치명적""이라고 주장

  최근 대규모 해고 사례

     * 2023년: 1,000개 이상의 기술 기업이 총 264,000명 해고
     * 2025년: 연방 정부에서 110,000명 이상 해고, 이 중 30,000명은 엘론 머스크가 이끄는 정부 효율성 부서에서 발생
     * BP, 블랙록, IBM, 메타, 스타벅스 등 주요 기업에서 해고 발표
     * 사우스웨스트항공도 50년 만에 첫 대규모 해고 실시

  해고의 부정적인 영향

     * 연구 결과에 따르면 해고는 기업과 직원 모두에게 해로움
          + 비용 절감을 위한 해고는 기업에 장기적으로 손실 발생
          + 해고된 직원은 자살률 증가 등 심각한 정신 건강 문제 경험
          + 해고를 피한 직원들도 사기 저하와 생산성 감소 경험

  해고를 조장한 경영 스타일: 뉴트론 잭과 체인소 앨

     * 20세기 중반: 미국 기업은 직원 복지와 공공의 이익을 고려한 자본주의 운영
     * 1980년대 이후: 주주 가치를 중시한 자본주의로 변화
          + ""뉴트론 잭"" 잭 웰치(General Electric): 매년 성과 하위 10% 해고
          + ""체인소 앨"" 앨 던랩: 빠르고 과감한 구조조정을 통해 단기 수익 창출 전략
     * 결과적으로 기업에서 해고가 일상화됨
          + 1979년: 포춘 100대 기업의 5%가 해고 단행
          + 1994년: 포춘 100대 기업의 45%가 해고 시행

  해고가 주가 및 재정 상태에 미치는 영향

     * 해고가 장기적인 수익 개선으로 이어지지 않음
          + 해고 후 주가가 즉각 하락하거나 변화 없음
          + 수익성 하락이 최대 3년간 지속
          + 해고 기업의 파산 위험이 2배 높음
     * 해고 후 기업의 문제점
          + 근본적인 경영 전략 실패 문제 해결하지 못함
          + 해고된 직원 자리에 비용이 더 드는 컨설턴트 또는 계약직 고용
          + 기존 직원의 업무 부담 증가 → 사기 저하 및 퇴사율 증가

  해고의 예외적 성공 사례

     * 일부 기술 기업은 해고 이후 주가 상승 경험
          + 2023년 스포티파이: 해고 발표 후 주가 7.5% 상승
          + 메타: ""효율성의 해"" 선언 이후 주가 23% 상승
     * 하지만 대부분은 구조적인 문제 해결이 아닌 단기 성과 개선에 불과

  더 나은 대안: 근무 시간 단축 및 비용 절감

     * 해고 없이 비용 절감 가능
          + 사우스웨스트항공 사례처럼 신규 투자 및 경비 절감으로 해결 가능
     * 시간 단축 및 무급 휴가(휴직) 시행
          + 연구에 따르면 해고 대신 이러한 전략을 사용하는 기업이 장기적으로 성과가 더 좋음
     * 경영진의 책임 필요
          + 잘못된 채용 결정과 인력 과잉 문제는 직원이 아닌 경영진의 책임

  결론: 해고는 쉽지만 근본 해결책은 아님

     * 기업은 비용 절감을 통한 성과 개선을 선호함
     * 하지만 해고는 기업의 장기적인 성장을 보장하지 않음
     * 장기적인 전략 개선 및 직원 복지 강화가 더 효과적인 해결책임

   상황에 따라 맞거나 틀릴 수 있는 주장임에도 전제 사항을 생략하는 건 일반화의 오류 아닌가요? '모든 해고는 소용없다' / '모든 해고는 소용있다' 둘 다 거짓인 문장이라고 생각합니다. 회사가 사업계획을 재검토하고 계획과 맞지 않는 부서를 정리했다면 해고가 효과 있는 것 아닐까요? 반대로 인력난에 시달리거나 업무강도가 높은 부서도 비용절감이란 미명 아래 일괄적으로 해고를 했다면 해고가 효과적이지 못한 것입니다

   필자가 상정하고 있는 어떤 상황이 있는건지, 아니면 이런 걸 알면서도 다른 이유로 일반화의 오류를 범하는 건진 글만 봐서는 알 수가 없을 따름입니다

        Hacker News 의견

     * 기술직 종사자들이 해고에 대해 과도하게 반응하는 이유에 대한 의견임. 많은 사람들이 2~4년 이상 한 직장에 머무르지 않음. 기술직 문화는 '직업 이동'이 특징임
          + 고용주 입장에서는 가족을 해고하는 것이 아니라 6개월에서 1년 내에 떠날 사람들을 해고하는 것임
          + 기술 산업은 돈과 변동성이 많은 예외적인 산업임
     * 해고는 효과가 있으며, 근무 시간 단축은 효과가 없음. 많은 사람들이 비즈니스 운영 방식을 이해하지 못함
          + 회사가 수익을 잃고 있다면 직원 유지가 불가능함. 급여를 줄이는 것은 급여를 받는 사람들에게는 효과가 없음
          + 직원의 감정은 재무제표에 반영되지 않음. 특별한 사람은 다수 주주가 아닌 이상 없음
     * 연구에 따르면 해고는 회사에 해로움. 그러나 이는 오해의 소지가 있음
          + 해고는 이미 발생한 손해를 인식하는 시점임. 경제학에서는 손해가 인식되지 않더라도 이미 발생한 것으로 간주됨
     * COVID 이후 중형 기술 회사에서 느린 채용과 목표 감소를 주장했으나, 새 CEO 하에 빠르게 진행됨
          + 새로운 리더십 하에 주식 상승을 위해 해고가 실행됨. 이는 생존이 아닌 새로운 CEO의 전략적 접근임
          + 내부 신뢰와 브랜드 인식이 하락함. 많은 유능한 인재들이 해고됨
          + CEO의 전략이 실패하면서 고성과자들이 회사를 떠나기 시작함
     * 해고에 대한 의견: 하위 10%를 해고하면 상위 10%도 잃게 됨. 회사의 심리적 안전이 파괴됨
     * 여러 산업에서 해고를 경험한 사람의 관찰
          + 첫 번째 해고는 신중하게 이루어지지만, 이후에는 정밀도가 떨어짐
          + 모든 부서에서 일정 비율을 줄이는 것은 회사가 상황을 잘 모른다는 신호임
          + 해고는 성과 관리가 부족한 회사의 지팡이가 될 수 있음
     * 해고는 과거에는 경기 침체 시 회사 구제 수단이었으나, 이제는 분기별 수익 관리 수단이 됨
     * 전 Nintendo CEO Iwata의 발언: 단기 재무 결과를 위해 직원 수를 줄이면 사기 저하가 발생함
     * Boise 지역에서 Micron과 HP의 빈번한 대량 해고를 목격한 경험
          + 해고는 너무 자주 첫 번째 수단으로 사용됨. 시장이 불안정하면 안전을 위해 5%를 줄임
          + 경영진이 먼저 재정적 손실을 감수하는 약속을 한다면 직원의 충성심과 존경을 얻을 수 있음

   ""기술직 문화는 '직업 이동'이 특징임"" 동의

   제가 좀 겪어보니, 규모가 큰 회사에서 해고 자체가 공정하기는 상당히 어렵습니다 - 정말 필요한 곳만 알맞게 잘라내기가 어렵습니다.

   그래서 더더욱, 해고 다음의 후속조치가 너무 중요합니다. 직원의 사기, 적절한 자원 재분배 등. 필요한 인원 재고용 (이건 욕먹을 짓이지만 불가피...)

   ""경영 악화""를 핑계로 ""사내 주도권 쟁취""의 도구로써 ""객관화된 성과지표""제시도 안한채 해고하지만 않으면 뭐. (피식)

   반대입니다. 해고는 어렵지만 근본 해결책입니다.

   일관되게 사측 포지션이시네요
   매니저가 아니라 IC시고 대공황에서도 같은 말씀을 하실 수 있다면야 뭐..
"
"https://news.hada.io/topic?id=19693","엔지니어링 팀 집중의 기술: 적게 하면 더 많이 할 수 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   엔지니어링 팀 집중의 기술: 적게 하면 더 많이 할 수 있음

     * 엔지니어링 팀은 종종 ""더 많은 기능을 더 빠르게 출시""해야 한다는 압박을 받음
     * 하지만 너무 많은 작업을 동시에 진행하면 오히려 생산성이 떨어짐
     * ""더 많이 출시하는 비결은 오히려 덜 하는 것"" - Less is More

핵심 원칙

     * 모든 작업을 가시화함
     * 작업을 작은 단위로 정의
     * 진행 중인 작업을 제한함
     * 용량에 맞게 자원을 할당함
     * 보너스: 혹시 모를 것을 위해 여유 공간을 확보함
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

# 모든 작업을 가시화함

     * 작업을 가시화하면 현실을 직시하게 됨
     * 모든 작업이 한눈에 보이면 다음과 같은 장점이 있음
          + 우선순위를 명확히 설정 가능
          + 불필요한 작업을 중단하거나 일시 중지 가능
          + 팀이 시작한 작업을 완료하도록 집중 가능
     * 목표는 모든 작업을 영원히 추적하는 것이 아님 → 현실을 명확히 파악하고 더 나은 의사 결정을 내리기 위함

# 작업을 작은 단위로 정의함

     * 작업이 너무 크면 팀의 에너지가 소진되고 진행 상황이 명확하지 않음
     * 작업 단위를 1~2주 정도로 제한
          + 개발자는 단기적 성과를 통해 동기 유지
          + 빠르게 피드백 받고 수정 가능
     * 작은 작업 단위의 장점
          + 코드 리뷰가 더 쉬워짐
          + 자연스러운 지식 공유
          + 팀원 간의 협력이 강화됨
          + 배포 위험 감소
     * 작업 단위를 줄이면 속도가 빨라짐 → 복잡한 기능에 압도되지 않고 모멘텀 유지 가능

# 진행 중인 작업을 제한함

     * 여러 기능을 동시에 처리하면 오히려 생산성이 저하됨
     * 맥락 전환 비용이 발생 → 새로운 작업에 적응하는 데 최대 23분 소요됨
     * 진행 중인 작업이 많아질수록 다음과 같은 문제가 발생
          + 품질 저하
          + 버그 증가
          + 팀의 사기 저하
     * 팀 수준의 과부하 신호
          + 개발자당 4개 이상의 작업 수행
          + 예상보다 완료 시간이 길어짐
          + 완료된 기능보다 진행 중인 기능이 많음
     * 개인 수준의 과부하 신호
          + 집중력 저하
          + 코드 리뷰 응답 시간 증가
          + 상태 회의에서 우선순위 설명 어려움

# 용량에 맞게 자원을 할당함

     * ""한 명의 개발자가 하나의 기능을 맡는다""는 접근 방식은 비효율적임
     * 가장 중요한 작업에 팀의 리소스를 집중
          + 협업 강화 → 문제 해결 속도 향상
          + 코드 품질 향상 → 실시간 피어 리뷰 활성화
          + 작업 완료 속도가 빨라짐
     * 개발자들이 협업을 통해 더 깊은 이해 가능
     * 팀 단위 성과를 장려해야 함 → 개인 성과보다는 팀 성과에 중점

# 여유 공간을 확보함

     * 100% 용량으로 운영하면 오히려 성과가 저하됨
     * 예상치 못한 작업은 불가피함 → 언제 발생할지 모를 뿐임
     * 여유 공간이 없으면 발생하는 문제
          + 팀이 반응적으로 일하게 됨
          + 품질 저하
          + 혁신 감소
          + 기술 부채 증가
     * 여유 공간이 있으면 다음과 같은 장점이 있음
          + 예상치 못한 문제에도 유연하게 대응 가능
          + 창의적인 문제 해결 가능
          + 높은 품질 유지
          + 지속 가능한 작업 속도 유지
     * 적정 여유 공간은 약 20% → 팀 특성에 따라 조정 가능

핵심 전략 요약

     * 작업을 가시화 → 현실을 직시할수 있게
     * 작업을 작은 단위로 정의 → 모멘텀을 유지
     * 진행 중인 작업 제한 → 집중력을 높임
     * 용량에 맞게 자원 할당 → 우선순위에 맞춰 집중
     * 여유 공간 확보 → 유연성 확보

결론

     * 더 많은 작업을 하기 위해서는 덜 하는 전략이 필요함
     * 팀의 성과는 얼마나 많은 기능을 동시에 처리했는지가 아니라, 얼마나 효과적으로 고객에게 가치를 제공했는지로 측정됨
     * 리더의 역할은 팀에 더 많은 작업을 추가하는 것이 아니라, 불필요한 작업을 덜어내는 것임

   80%의 업무 그리고 20% 여유 공간을 두고자 노력하지만, 어떤 기준으로 할지.. 매번 고민이 되긴하네요. 단순 시간으로 해야하나 싶기도하구요

   저는 그래서 금요일 오후는 개인개발시간으로 아예 빼놓고 있어요!

   이렇게 작은 태스크로 나누게 되면 큰 그림을 가지고 있는 리더가 큰 권한을 가지게 됩니다. 같이 있는 엔지니어들은 오히려 동기가 박탈되고 ""우리는 대체 어딜 향해 가는거지"" 가 됩니다. 스프린트 기반 애자일의 대표적인 단점.
   너무 리더의 관점으로만 쓰여진 것 같네요, 제목 그대로.

   엔지니어의 모멘텀은 리더가 깃발을 어느 방향으로 들고 있는지도 크게 영향을 받습니다. 고객에게 주고싶은 가치가 무엇인지, 스프린트마다의 output 과 딜리버리 outcome이 무엇인지 제시 할 수 있는 방법에 대해서도 조금 더 고민이 필요해보입니다. 물론 어려운 소프트스킬이라 제대로 하는 리더도 보기 힘들고 글도 잘 없긴 하지만.

   이 댓글에 격하게 공감되네요. 기술적인 부분에 대한 마이크로매니징이 발생할 위험이 있(었)습니다. 참 쉽지 않아요.

   큰 그림을 공유하고, 모두가 이해한 상태에서 업무를 작은 태스크로 쪼개는건 아닐까요??

   1-2 주로 나누게 되면 자연스럽게 하나의 기능에 대한 그림은 제한적인 사람만 알게 될 것 같습니다. 프로세스와 쓰레드의 차이처럼요. 관심을 제한하면서 생산성을 높이는거니까요.

   그림을 공유하더라도 그 그림에 대해 의문을 가질거라는 전제이긴 한데, 매 스프린트 플래닝마다 조금씩 달라지는 방향에 따라 큰 그림을 어떻게 추적해가고 있는지 맞추지 못한다는 전제도 제가 자연스럽게 한 것 같습니다.

   저는 이 글에서 제시하는 바에 전적으로 동의하면서도, 말씀해주신 문제도 동의합니다,
   실제로 제가 고민하고 있는 포인트이기도 합니다.
   스쿼드마다 다르긴 했지만 스프린트 플래닝에 팀원들을 적극적으로 참여시키면 말씀해주신 문제가 발생하지는 않았습니다. 프로젝트의 맥락을 공유하고 매 스프린트마다 변화하는 상황을 공유하면서 바뀌는 작업들을 충분히 인지할 수 있게 노력하면서도 작업은 굉장히 세분화해서 나눠보자고 요구했습니다.
   말씀하신대로 관리하는 측면에서 진행 상황, 작업 속도 측정, 예상치 못한 상황에 대한 대처, 작업 내용이 의도대로 안되었을 때의 기회 비용을 생각하면 잘게 나누어야 결국 잘 진행되긴 하더라구요.

   비슷한 글이 반복되지만, 인간의 욕심은 끝이 없고 같은 실수를 반복하죠
     * 최고의 성과를 내는 팀을 만들려면, 85%의 노력만 요구하세요
     * 제품개발을 망치는 6가지 맹신

   컴퓨터의 CPU로드 100%는 정상이 아니지만,
   인간의 업무로드 100%는 더 열심히 해야 한다..는 결론이 나오니까요

   긱뉴스에서 여러번 언급 되었던 책 <피닉스 프로젝트>에서도 비슷한 이야기가 나옵니다. 100% 용량에 가까울수록 응답시간이 기하급수적으로 길어진다고.

   오. 그 얘기는 Goal 이라는 책에서도 나옵니다!

   <피닉스 프로젝트> 자체가 <The Goal>의 IT 버전으로 쓴 책이니까요

   헐........ 감사합니다!!
"
"https://news.hada.io/topic?id=19662","향후 10년은 AI 에이전트 이코노미의 시대가 될 것","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     향후 10년은 AI 에이전트 이코노미의 시대가 될 것

     * AI 에이전트의 시대가 도래하고 있음. 곧 AI Agent가 수행하지 못하는 작업은 거의 없을 것으로 예상
     * AI Agent를 만들고 운영하는 프레임워크가 빠르게 발전 중이며, 구축 비용과 난이도가 점점 낮아지는 추세
     * 이제부터는 다양한 산업에서 AI Agent를 활용해 작업을 의뢰하고, 거래하고, 협력하는 AI Agent Marketplace가 부상할 것

1. AI 에이전트 전략 매트릭스: 당신은 어디에 들어맞을까?

     * 과거 소프트웨어 시장에서의 전략
          + 한때는 수평(Horizontal)으로 다양한 비즈니스를 포괄하는 소프트웨어가 크게 성장함
          + 그 후로 특정 산업에 특화된 수직(Vertical) 소프트웨어 전략도 성공을 거둠
          + 복잡도와 고객 규모에 따라 어떤 전략이 적합한지가 달라졌음
     * 소프트웨어 사례
          + 수평(Horizontal)
               o 작업 난이도가 비교적 낮은 범용 업무를 다룸
               o 주로 SMB(중소사업자) 대상이며, 간편성과 빠른 도입이 강점인 시장임
               o 예) QuickBooks, Calendly, Square 등
          + 수직(Vertical)
               o 특정 산업의 복잡하고 전문적인 업무를 다룸
               o 대기업이 주요 고객이 되며, 고도의 커스터마이징과 전문성이 필요함
               o 예) Procore, Veeva Systems, OpenGov 등
     * AI Agent에도 동일한 패턴이 나타남
          + 수평적 AI Agent: 회계, 마케팅, 세일즈 등 범용적인 업무를 대규모로 자동화하는 AI Agent
          + 수직적 AI Agent: 특정 산업이나 복잡한 전문 업무를 대체 또는 지원하는 AI Specialist
     * SMB 시장에 대한 기회
          + SMB는 미국 경제 절반가량의 생산에 기여하며, IT 지출은 약 750B 달러 규모임
          + 기존 테크 웨이브에서 충분한 혜택을 받지 못했으나, AI Agent로 인해 값싸고 전문적인 서비스를 누릴 수 있게 됨
          + AI Agent가 SMB에게는 이미 필요한 업무 능력을 저렴하고 간편하게 제공할 수 있는 솔루션임
     * 예시: Triple Whale
          + 전자상거래 플랫폼에 필요한 모든 기능을 통합해 보여주는 대시보드를 제공함
          + 최근 AI Agent 기능을 추가해, 사용자가 귀찮아하거나 잘 못 다루는 업무를 자동으로 수행해 주는 방식을 채택함
          + SMB 사용자에게 간편하고 직접적인 이점을 제공함

2. AI 에이전트 마켓플레이스가 수평적 전략에서 지배적인 이유

     * ""AI = 서비스"" 시대
          + AI는 기존 소프트웨어를 완전히 대체하기보다, 소프트웨어를 ‘서비스’ 형태로 변화시키는 기술임
          + 수요와 공급을 연결하는 가장 강력한 모델은 ‘마켓플레이스’이며, AI Agent가 제공하는 서비스도 마찬가지임
     * 집결지(Marketplace)의 필요성
          + 특화된 개별 AI Agent를 각각 홍보하는 데 드는 마케팅 비용은 비효율적임
          + 한곳에 모아두면, 수요자가 직접 방문해 다양한 AI Agent를 선택할 수 있음
     * 독립적인 서비스 마켓플레이스의 가능성
          + 소프트웨어 애플리케이션 마켓플레이스는 대부분 AWS, Azure, Microsoft, Shopify, App Store 같은 거대 플랫폼 위에서 돌아감
          + 하지만 서비스 자체를 거래하는 마켓플레이스는 독립적으로 운영될 수 있음
          + 이전에도 Upwork, Fiverr, A.Team 같은 전문가 서비스 마켓플레이스가 성공한 바 있음
     * 기존 인력 마켓플레이스와의 충돌
          + 기존 플랫폼은 사람을 고용하는 구조이므로, AI Agent가 인간 공급자를 대체하면 내부 충돌이 생길 수 있음
          + 따라서 신생 AI Agent 전용 마켓플레이스가 새롭게 성장할 가능성이 높음
     * 네트워크 효과
          + 마켓플레이스는 한 번 자리를 잡으면, 공급자와 수요자가 계속 유입되어 강력한 방어력을 갖게 됨
          + NFX가 제공하는 Network Effects 매뉴얼에서 다뤄왔듯이, AI Agent 마켓플레이스에도 똑같이 적용되는 공식임

3. AI 에이전트 마켓플레이스의 작동 방식

     * 승자독식 구조
          + 마켓플레이스는 통상적으로 ‘Winner-take-all’ 형태로 굳어지는 경향이 있음
          + 초기부터 시장 형성을 제대로 하는 기업이 우위를 차지하게 됨
     * 사례: Enso
          + SMB를 위한 Vertical AI Agents Marketplace를 표방하는 회사임
          + LinkedIn 글쓰기, SEO, Instagram 디자인, 리드 발굴 등 다양한 작업을 수행하는 AI Agent를 다수 확보함
          + 이미 300개가 넘는 마이크로 AI Agent를 선보였으며, 곧 수천 개로 확대할 예정임
          + Persistent memory를 통해 사용자의 비즈니스를 기억하고, 반복적 학습을 통해 더 정교해짐
          + 월 49달러라는 매우 낮은 가격으로, SMB가 종합적인 디지털 마케팅 및 운영 역량을 얻을 수 있게 하는 모델임
     * Persistent memory의 가치
          + AI Agent가 사용자와의 상호작용을 쌓아가며 점차 고도화됨
          + SMB 입장에서는 대규모 비용 없이 전문 에이전시나 컨설턴트를 활용하는 것과 유사한 효과를 누림
          + 시간이 지날수록 맞춤형 분석과 실행력을 갖춘 디지털 직원이 되는 셈임

4. AI 에이전트 마켓플레이스의 부상

     * 향후 10년간의 주요 테마
          + AI Agent Marketplace가 SMB 영역을 중심으로 폭발적으로 성장할 전망임
          + 기존 마켓플레이스 빌딩 노하우와 네트워크 효과 이론을 AI 환경에 맞게 재해석해야 하는 시점임
          + ‘Winner-take-all’ 방식으로 전개될 가능성이 크며, 누가 먼저 제대로 된 마켓플레이스를 구축하는지가 관건임
     * 결론
          + AI Agent 기술이 진화함에 따라 SMB는 전례 없는 기회를 누릴 수 있음
          + 저렴하고 효율적인 AI Agent Marketplace가 창출될 것이며, 이는 소규모 사업자들의 전반적 역량을 끌어올리는 기반이 될 것임
          + 시장이 이미 움직이기 시작했고, 향후 10년은 이런 변화를 주도하는 업체들이 새롭게 부상할 것임
"
"https://news.hada.io/topic?id=19592","리처드 서튼과 앤드류 바르토, 2024 튜링상 수상","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      리처드 서튼과 앤드류 바르토, 2024 튜링상 수상

     * ACM A.M. Turing Award Honors Two Researchers Who Led the Development of Cornerstone AI Technology
     * Andrew Barto and Richard Sutton Recognized as Pioneers of Reinforcement Learning
          + ACM은 2024년 ACM A.M. Turing Award 수상자로 Andrew G. Barto와 Richard S. Sutton을 선정하였음. 이들은 강화 학습의 개념적 및 알고리듬적 기초를 개발하였음.
          + Barto는 매사추세츠 대학교 애머스트 캠퍼스의 정보 및 컴퓨터 과학 명예 교수이며, Sutton은 앨버타 대학교의 컴퓨터 과학 교수로 활동 중임.
          + Turing Award는 컴퓨팅 분야의 노벨상으로 불리며, Google의 재정 지원을 받아 100만 달러의 상금이 수여됨.
     * What is Reinforcement Learning?
          + 인공지능(AI) 분야는 주로 인지하고 행동하는 에이전트를 구축하는 것에 중점을 둠. 강화 학습(RL)은 이러한 에이전트가 보상 신호를 통해 더 나은 행동을 학습하는 과정임.
          + 강화 학습의 기초는 1980년대 초 Barto와 Sutton이 심리학에서의 관찰을 바탕으로 일반적인 문제 프레임워크로서 강화 학습을 공식화하면서 시작되었음.
          + 이들은 마르코프 결정 프로세스(MDP)를 기반으로 한 수학적 기초를 활용하여 강화 학습 알고리듬을 개발하였음.
     * 주요 기여
          + Barto와 Sutton은 강화 학습의 기본 알고리듬 접근법을 개발하였으며, 특히 시간 차 학습과 정책 경사 방법, 신경망을 활용한 학습 함수 표현을 포함함.
          + 이들의 교과서 ""Reinforcement Learning: An Introduction""은 여전히 이 분야의 표준 참고서로 사용되며, 75,000회 이상 인용되었음.
     * 강화 학습의 실제 응용
          + 강화 학습은 최근 15년 동안 심층 학습 알고리듬과 결합하여 큰 발전을 이루었음. 대표적인 예로 AlphaGo의 바둑 승리와 ChatGPT의 개발이 있음.
          + 강화 학습은 로봇 모터 기술 학습, 네트워크 혼잡 제어, 칩 설계, 인터넷 광고 최적화 등 다양한 분야에서 성공을 거두고 있음.
     * 강화 학습의 신경과학적 영감
          + 최근 연구에 따르면, AI에서 개발된 특정 강화 학습 알고리듬이 인간 뇌의 도파민 시스템에 대한 설명에 가장 적합하다는 결과가 나왔음.
     * ACM A.M. Turing Award에 대한 설명
          + Turing Award는 1966년부터 정보 기술 산업을 발전시킨 컴퓨터 과학자와 엔지니어를 기리기 위해 수여되고 있음.
     * 2024 ACM A.M. Turing Award 수상자
          + Andrew Barto는 매사추세츠 대학교 애머스트 캠퍼스의 정보 및 컴퓨터 과학 명예 교수로, 다양한 상을 수상하였음.
          + Richard Sutton은 앨버타 대학교의 컴퓨터 과학 교수로, 다양한 연구 기관에서 활동하며 여러 상을 수상하였음.

        Hacker News 의견

     * 매우 멋진 일임. 아내와 나는 Andy Barto와 그의 아내의 집을 구매했음
          + 구매 과정에서 입찰 전쟁이 있었음
          + 그가 수학자라는 것을 알고 소수(prime number)로 제안을 했음
          + 그의 업적이 인정받는 것을 보니 정말 기쁨
     * 멋짐! 잘 자격을 갖춘 사람임. 그들은 RL 교과서 두 판을 무료 PDF로 제공함
          + 1982년부터 AI 실무자로 일해왔고, RL은 개인적으로 마스터하기 어려운 주제였음
          + Sutton/Barto 책, White 교수의 Coursera RL 강의 등이 큰 도움이 되었음: 추천함
          + 그들의 책의 예제 프로그램은 Common Lisp와 Python으로 제공됨
     * The Bitter Lesson을 다시 읽기 좋은 시기임
     * Sutton은 인간 후계주의자이며, 인간이 모두 죽어도 상관하지 않음. 그는 신뢰할 수 없고 축하받을 인물이 아님
     * 물리학자들에게 상을 줬으면 더 좋았을 것임
     * Sutton이 미국 대신 캐나다 에드먼턴에 사는 것이 놀라움
          + 이는 그가 명예와 돈보다 진실성과 성실함을 중시한다는 것을 보여줌
     * 이들은 훌륭하지만, 불행히도 Sutton과 Barto의 AI 책은 정말 나쁨
          + Trask의 Grokking Machine Learning과 몇 달간의 ML 논문 구현이 더 나을 것임
     * 내가 가르친 강의에서 그들의 RL 책을 사용했음
          + 아름답게 쓰여졌고 무료로 제공됨
          + 아름다운 글에 자주 집중하다가 실제 내용을 놓치곤 했음
     * Andrew Barto와 Richard Sutton의 Turing Award 수상을 진심으로 축하함
          + 학생 시절, 그들의 교과서 Reinforcement Learning: An Introduction이 이 분야에 입문하는 계기가 되었음
          + 'Temporal Difference Learning'에 대한 6장이 순차적 의사결정에 대한 사고방식을 근본적으로 바꾸어 놓았음
          + 오늘날에도 여전히 읽기를 강력히 추천하는 고전임
     * 오랜 시간이 걸린 일임. 아이디어를 처음부터 끝까지 관철시키고, 이를 동적 프로그래밍 책의 하위 장이 아닌 전체 분야로 확장시킴
          + 더 많은 게임이 실제로 RL을 사용했으면 좋겠음 - 이 모든 것이 시작된 곳임 - 정말 멋질 것임
"
"https://news.hada.io/topic?id=19638","수십억 기기에 사용된 Bluetooth 칩에서 발견된 미등록 백도어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 수십억 기기에 사용된 Bluetooth 칩에서 발견된 미등록 백도어

Bluetooth 칩의 백도어 발견

     * ESP32 칩의 백도어: 중국 제조사 Espressif의 ESP32 마이크로칩에서 문서화되지 않은 ""백도어""가 발견됨. 이 칩은 2023년 기준 10억 개 이상의 장치에 사용되고 있음. 백도어는 신뢰할 수 있는 장치를 스푸핑하고, 무단 데이터 접근을 허용하며, 네트워크의 다른 장치로 이동하거나 장기적인 지속성을 확립할 수 있음.
     * 발견 배경: 스페인 연구자 Miguel Tarascó Acuña와 Antonio Vázquez Blanco가 이 백도어를 발견하고, 마드리드의 RootedCON에서 발표함. 이 백도어는 모바일 폰, 컴퓨터, 스마트 잠금 장치, 의료 장비 등 민감한 장치에 영구적으로 감염시킬 수 있음.

ESP32에서 백도어 발견

     * 블루투스 보안 연구: 블루투스 보안 연구에 대한 관심이 줄어들었지만, 이는 프로토콜이나 구현이 더 안전해졌기 때문이 아님. 대부분의 공격은 작동하는 도구가 없거나, 일반 하드웨어와 호환되지 않으며, 현대 시스템과 호환되지 않는 오래된 도구를 사용함.
     * 새로운 도구 개발: Tarlogic은 하드웨어 독립적이고 크로스 플랫폼인 새로운 C 기반 USB 블루투스 드라이버를 개발하여 운영체제 특정 API에 의존하지 않고 하드웨어에 직접 접근할 수 있게 함. 이를 통해 ESP32 블루투스 펌웨어에서 숨겨진 벤더 특정 명령어(Opcode 0x3F)를 발견함.
     * 발견된 명령어: 총 29개의 문서화되지 않은 명령어가 발견되었으며, 이는 메모리 조작(읽기/쓰기 RAM 및 Flash), MAC 주소 스푸핑(장치 스푸핑), LMP/LLCP 패킷 주입에 사용될 수 있음.
     * 위험성: 이러한 명령어로 인해 OEM 수준에서 악의적인 구현 및 공급망 공격이 발생할 수 있음. 특히 공격자가 이미 루트 접근 권한을 가지고 있거나, 악성 펌웨어를 심거나, 악성 업데이트를 푸시한 경우 원격으로 백도어를 악용할 수 있음.
     * 물리적 접근의 위험성: 일반적으로 장치의 USB 또는 UART 인터페이스에 물리적으로 접근하는 것이 더 위험하고 현실적인 공격 시나리오임.
     * 연구자 설명: 연구자들은 ESP32 칩을 완전히 제어하고, RAM 및 Flash 수정 명령어를 통해 칩에 지속성을 얻을 수 있으며, 다른 장치로 확산될 가능성이 있다고 설명함.
     * Espressif의 반응: BleepingComputer는 연구 결과에 대한 Espressif의 입장을 요청했으나 즉각적인 답변을 받지 못함.

        Hacker News 의견

     * 제목이 오해를 불러일으킬 수 있음. ""백도어""는 자신의 USB Bluetooth 어댑터의 메모리와 다른 저수준 기능을 엿보고 조작할 수 있게 하는 것 같음. 무선으로 사용 가능한 것은 아님
          + 문서화되지 않은 디버깅 명령은 흔함. WiFi 어댑터와 GPS 수신기에서 비슷한 기능을 발견한 경험이 있음. 이는 칩 펌웨어나 벤더 드라이버를 역공학하여 발견됨. 자체적으로는 큰 문제가 아님. 서명되지 않은 펌웨어를 허용하는 것은 동일하게 취약함
          + 만약 이 기능이 호스트 외부에서 사용 가능하다면, 이는 매우 다른 이야기가 될 것임
     * 연구자들은 ESP32 WiFi 스택에 대한 저수준 접근을 허용하는 문서화되지 않은 하드웨어 기능을 발견함
          + 이를 ""백도어""라고 부르는 것은 단순한 클릭 유도임
     * 이 헤드라인은 거짓임. Bluetooth 칩의 백도어는 무선 공격자가 칩에서 코드 실행을 할 수 있게 하는 것임. 이 기사는 연결된 장치의 드라이버가 칩에서 코드 실행을 할 수 있게 하는 것을 보고함. 이는 보안 경계를 위반하지 않음
          + 잘 작동하는 저널리즘 생태계에서는 철회가 필요하고, 이를 작성한 매체의 평판에 큰 손상을 줄 것임. 하지만 이는 일어나지 않을 것임
     * Bluetooth 스택에 몇 가지 문서화되지 않은 명령이 있는 것인지 혼란스러움. 만약 이것이 이미 장치에서 실행 중인 코드에만 접근 가능하다면, 이를 백도어라고 부르지 않을 것임
     * 이론적으로는 연결된 BT 라디오 자체에 저수준 접근을 해야 함. 이는 기대되는 것임
          + 장치가 이러한 저수준 인터페이스를 갖는 것을 선호함. 문제는 존재보다는 문서화의 부족일 수 있음
          + Qualcomm 라디오에서 USB를 통해 메모리 읽기/쓰기 명령을 사용하여 잠긴 장치를 해제하고 소유권을 가졌음. 이는 완전한 OOB 읽기/쓰기였기 때문에 좋지 않을 수 있지만, 만약 이것이 플래시된 코드에서만 접근 가능하다면 더 나을 것임
     * 좋은 연구이지만 나쁜 헤드라인임. 공격 벡터로서 물리적 접근이 필요하고 거의 모든 경우에 다른 방법으로 이미 수행 가능함. ""일반적인 Bluetooth 칩에서 발견된 문서화되지 않은 명령""이 더 나은 헤드라인일 것임
     * TL;DR: 펌웨어를 역공학하여 메모리 읽기/쓰기, 패킷 전송, MAC 주소 설정 등의 HCI 명령을 발견함
          + 실제로 백도어가 아님. 이들이 이를 백도어라고 불렀는지(발표는 스페인어로 되어 있음), 아니면 기자들이 클릭을 유도하기 위해 백도어라고 부르는지 모르겠음
          + HCI 명령을 장치에 보내려면 임의의 접근이 필요함. 이는 이미 장치를 제어하고 있는 것임. 무선 링크를 통해 원격으로 악용되는 것이 아님. 모든 익스플로잇은 이미 장치의 완전한 제어를 필요로 하며, 이 시점에서 MAC 주소를 변경하거나 패킷을 보내는 것은 놀라운 일이 아님
          + 흥미로운 연구이지만 ""백도어""로 포장된 것을 보는 것은 정말 실망스러움. 이 표현에 대한 책임이 누구에게 있는지 모르겠음. 아마도 기자들일 것임
     * 모두가 커널 공간에서 실행되는 불투명한 바이너리 블롭 드라이버를 데스크톱과 노트북에 설치하고, 자신의 클라우드 제어 전화기에 루트 접근조차 하지 못하는 것에는 괜찮지만, 이미 장치가 손상된 상태에서만 사용할 수 있는 문서화되지 않은 저수준 ESP32 명령은 뉴스 가치가 있는 위협 벡터임
          + 번역 과정에서 무언가가 잘못된 것인지 궁금함. 과거에는 이것이 멋지다고 생각하고 이를 SDR로 변환할 방법을 찾았을 것임
"
"https://news.hada.io/topic?id=19588","Brother, 서드파티 프린터 잉크 카트리지를 사용 못하게 강제 펌웨어 업데이트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Brother, 서드파티 프린터 잉크 카트리지를 사용 못하게 강제 펌웨어 업데이트

     * Brother가 강제 펌웨어 업데이트를 통해 서드파티 프린터 잉크 카트리지를 사용 못하게 하고, 구형 펌웨어 버전을 지원 포털에서 제거했다는 비난을 받고 있음
     * 유명한 수리 유튜버 Louis Rossmann은 Brother의 이러한 변화에 실망감을 표명했으며, Brother가 ""안티-컨슈머 프린터 회사""로 변했다고 주장
          + Brother 프린터가 최근 펌웨어 업데이트로 인해 서드파티 잉크 사용을 막고 있다고 지적
          + 특히 컬러 장치에서는 서드파티 잉크 사용 시 색상 등록 기능이 작동하지 않는 문제가 발생
          + Brother는 이러한 업데이트에 대해 사전 경고를 하지 않으며, 구형 펌웨어를 웹사이트에서 제거해 롤백이 불가능하게 만듦
     * Rossmann은 이러한 변화가 개인의 소유권이 사라지고 있음을 보여주는 사례라고 주장하며, 이러한 변화가 문서화되어야 한다고 강조
     * 많은 사용자들이 Brother의 변화에 실망감을 표명하며, 다른 프린터 브랜드로의 전환을 고려하고 있음
          + 일부 사용자들은 기업의 반소비자적 행태에 대해 비판하며, 소비자들이 지갑으로 투표해야 한다고 주장

        Hacker News 의견

     * 나는 Brother 제품을 좋아하지만, 예전에 소비자에게 불리한 펌웨어 업데이트를 시도한 적이 있었음
          + 그 이후로 update.brother.co.jp의 rdns를 차단하고 있음
          + 보통 4개의 IPv4 주소로 해결되며, DNS 해석기에 따라 특정 서브넷에 속함
          + Brother가 CloudFront를 사용하여 CDN 서비스를 제공하는 것으로 보임
          + 각 지역마다 다른 서브넷을 받으므로, 직접 쿼리하는 것이 좋음
     * Brother와 관련된 문제를 확인하고 싶음
          + 항상 Brother 제품에 비정품 토너를 사용했지만 잘 작동하고 있음
          + Louis의 위키에 있는 모든 게시물은 2-3년 전 것이며, Reddit에서 3명의 사람만이 이 문제를 언급하고 있음
          + 그의 긴 영상은 새로운 정보를 제공하지 않으며, tomshardware 기사도 그의 영상을 반복하는 내용임
          + 이 문제를 주장하는 사람들의 출처는 Reddit, GitHub, Hacker News임
     * Epson EcoTank 프린터로 전환한 것이 최고의 결정 중 하나였음
          + 카트리지 대신 잉크 저장소가 있으며, 저장소에서 프린트 헤드로 연결된 작은 영구적인 튜브가 있음
          + 어떤 잉크를 사용하는지 알 수 없으며, 탱크가 매우 큼
          + 몇 년 동안 리필할 필요가 없다는 것이 매우 좋음
          + 당시 카트리지 기반 프린터의 두 배 정도의 비용이 들었지만, 여전히 최고의 구매 중 하나로 생각함
     * EU가 강경한 입장을 취한 여러 사안 중 프린터가 포함되지 않은 것이 아쉬움
          + 쿠키보다 훨씬 더 짜증나는 문제임
     * 우리는 이벤트 현장에서 사용하는 Brother 프린터를 많이 보유하고 있음
          + 12년 이상 Samsung을 사용했지만, 그들이 프린터 사업에서 철수한 후 Brother를 선택했음
          + HP의 토너 정책 때문에 Brother를 선택했지만, 이제는 큰 차이가 없을 것 같음
     * 제3자 잉크 리필 제조업체가 코드 요구로 소송을 제기하면 이길 수 있을 것 같음
          + 이미 많은 법이 존재하며, 대부분 자동차를 염두에 두고 작성되었지만 프린터에도 적용 가능함
          + 그러나 소송 비용이 수백만 달러에 이를 것이며, 리필로 변호사 비용을 충당할 수 있을지 확신할 수 없음
     * 현재 어떤 프린터를 구매해야 할지 궁금함
          + Facebook 마켓플레이스에서 $30에 구매한 Brother 프린터를 사용 중이며, 당분간 유지할 예정임
          + 다른 사람에게 추천하거나 새로 구매해야 할 경우 안전한 브랜드를 알고 싶음
          + 레이저 프린터를 선호하며, 이는 갑작스러운 작업량을 더 잘 처리함
     * 내 경험에 따르면, 현재 Brother 프린터가 리필된 잉크 카트리지를 인식하지 않음
          + 제3자 카트리지도 인식하지 않음
     * 사실이라면 실망스러움, Brother 프린터가 가장 덜 싫어하는 제품임
     * 오픈 소스 프린터를 개발할 때가 된 것 같음
"
"https://news.hada.io/topic?id=19630","크롬 135버전부터 버튼에 command 및 commandfor 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 크롬 135버전부터 버튼에 command 및 commandfor 도입

     * 버튼은 동적 웹 애플리케이션을 만드는 데 필수임. 메뉴를 열고, 작업을 전환하고, 폼을 제출하는데 사용
     * Chrome 135에서는 새로운 command 및 commandfor 속성으로 이전의 popovertargetaction 및 popovertarget 속성을 개선하고 대체함
     * 기존에 버튼 동작을 구현할 때 발생하는 문제점:
          + HTML의 onclick 핸들러는 보안 정책(CSP)으로 인해 실제 코드에서 사용이 제한될 수 있음
          + 버튼과 다른 요소의 상태 동기화가 필요하며, 접근성을 유지하면서 상태를 관리하는 코드는 복잡함
          + React, AlpineJS, Svelte 등에서도 상태 및 이벤트 핸들링이 복잡함

command와 commandfor 패턴

     * command와 commandfor 속성을 사용하면 버튼이 다른 요소에 대해 선언적으로 동작할 수 있음. 이는 프레임워크의 편리함을 제공하면서도 유연성을 유지
     * commandfor 버튼은 ID를 사용(for속성과 비슷) 하고, command는 내장 값을 받아 더 직관적인 접근 방식을 제공
     * 예제: 메뉴 열기 버튼 구현
          + aria-expanded나 추가적인 JavaScript가 필요하지 않음
<button commandfor=""my-menu"" command=""show-popover"">
  Open Menu
</button>
<div popover id=""my-menu"">
  <!-- ... -->
</div>

command와 commandfor vs popovertargetaction과 popovertarget

     * popover를 사용한 적이 있다면 popovertarget과 popovertargetaction 속성에 익숙할 수 있음
     * 이들은 commandfor와 command와 유사하게 작동하지만, 팝오버에 특화
     * 새로운 속성은 이전 속성을 완전히 대체하며, 추가 기능을 제공함

내장 명령

     * command 속성은 다양한 API와 매핑되는 동작들을 내장
          + show-popover: el.showPopover()와 매핑됨
          + hide-popover: el.hidePopover()와 매핑됨
          + toggle-popover: el.togglePopover()와 매핑됨
          + show-modal: dialogEl.showModal()와 매핑됨
          + close: dialogEl.close()와 매핑됨
     * 예제: 삭제 확인 다이얼로그 구현
          + JavaScript 없이 상태 및 접근성 관리 가능
<button commandfor=""confirm-dialog"" command=""show-modal"">
  Delete Record
</button>
<dialog id=""confirm-dialog"">
  <header>
    <h1>Delete Record?</h1>
    <button commandfor=""confirm-dialog"" command=""close"" aria-label=""Close"">
      <img role=""none"" src=""/close-icon.svg"">
    </button>
  </header>
  <p>Are you sure? This action cannot be undone</p>
  <footer>
    <button commandfor=""confirm-dialog"" command=""close"" value=""cancel"">
      Cancel
    </button>
    <button commandfor=""confirm-dialog"" command=""close"" value=""delete"">
      Delete
    </button>
  </footer>
</dialog>

          + 결과 처리 코드: 다이얼로그의 close 이벤트에서 반환 값 처리 가능
dialog.addEventListener(""close"", (event) => {
  if (event.target.returnValue === ""cancel"") {
    console.log(""Cancel was clicked"");
  } else if (event.target.returnValue === ""delete"") {
    console.log(""Delete was clicked"");
  }
});

사용자 정의 명령

     * 내장 명령 외에도 -- 접두사를 사용하여 사용자 정의 명령을 정의할 수 있음
     * 사용자 정의 명령은 대상 요소에서 ""command"" 이벤트를 발생시키지만, 추가적인 로직은 수행하지 않음
     * 예제: 이미지 회전 명령 구현
<button commandfor=""the-image"" command=""--rotate-landscape"">
  Landscape
</button>
<button commandfor=""the-image"" command=""--rotate-portrait"">
  Portrait
</button>
<img id=""the-image"" src=""photo.jpg"">

<script type=""module"">
  const image = document.getElementById(""the-image"");
  image.addEventListener(""command"", (event) => {
    if (event.command === ""--rotate-landscape"") {
      image.style.rotate = ""-90deg"";
    } else if (event.command === ""--rotate-portrait"") {
      image.style.rotate = ""0deg"";
    }
  });
</script>

Shadow DOM에서 명령 처리

     * Shadow DOM에서는 commandfor가 ID를 기반으로 작동하기 때문에 다음과 같은 제한 사항이 있음:
          + Shadow DOM 간에 요소 참조 불가
          + 이 경우 JavaScript API를 사용하여 .commandForElement 속성을 설정할 수 있음
     * 예제: Shadow DOM에서 명령 연결
<my-element>
  <template shadowrootmode=""open"">
    <button command=""show-popover"">Show popover</button>
    <slot></slot>
  </template>
  <div popover><!-- ... --></div>
</my-element>

<script>
  customElements.define(""my-element"", class extends HTMLElement {
    connectedCallback() {
      const popover = this.querySelector('[popover]');
      this.shadowRoot.querySelector('button').commandForElement = popover;
    }
  });
</script>

향후 계획

     * Chrome에서는 추가 내장 명령 도입을 계획 중:
          + <details> 요소 열기 및 닫기
          + <input> 및 <select>에서 ""show-picker"" 명령 지원
          + <video> 및 <audio> 재생 명령
          + 요소에서 텍스트 복사 기능

        Hacker News 의견

     * 프로그래밍 언어 이론가들은 80년대부터 ""goto""의 더 강력한 버전인 ""comefrom""에 대해 추측해 왔음. 이는 intercal에서만 구현되었음. intercal은 C와 같은 언어보다 안전성, 성능, 인체공학적으로 우수하지만 상업 시장에 진입하는 데 어려움을 겪고 있음. javascript가 intercal의 이 기능을 통합하는 것을 보는 것은 흥미로움. 이는 javascript의 클로저 기반 객체가 함수형 프로그래밍을 주류로 이끈 것처럼 정중한 프로그래밍의 급증으로 이어질 수 있기를 바람
     * Invokers는 Chrome만의 것이 아님. Firefox nightly에서도 이미 사용 가능함
     * JS 없이 선언적 UI 동작을 구현하는 아이디어는 매력적임
          + 팝오버/모달의 보일러플레이트를 제거함 (aria-expanded 조작 불필요)
          + show-modal과 같은 내장 명령은 접근성을 마크업에 통합함
          + 사용자 정의 명령(e.g., --rotate-landscape)은 HTML을 통해 컴포넌트가 API를 노출할 수 있게 함
     * 의문점:
          + 추상화 vs. 마법: 이는 단순히 복잡성을 JS에서 HTML로 이동시키는 것인가? 프레임워크는 이미 상태를 추상화함. 이는 어떻게 공존할 것인가?
          + Shadow DOM 마찰: shadow roots 간에 .commandForElement를 설정하기 위해 JS가 필요함. 이는 절반만 해결된 문제처럼 보임
          + 미래 대비: OpenUI가 20개 이상의 명령(e.g., show-picker, toggle-details)을 추가하면, 플랫폼이 틈새 구문으로 부풀어 오를 것인가?
     * 사양:
          + button element, commandfor 속성
          + button element, command 속성
     * 이것이 Next, Be, Apple 등이 약 30년 전에 사용한 액션/메시징 패턴인가, 아니면 내가 뭔가 놓친 것인가
          + 이는 유용했지만 기본적인 디자인 패턴을 유지하려는 복잡성 때문에 인터페이스 기반 컨트롤러 패턴으로 진화했음. 따라서 이 상자가 열리면 많은 개선 요청이 있을 것으로 예상함
     * Netscape의 초기 Java UI 툴킷(IFC)이 액션 요소를 연결할 수 있게 했음
     * 새로운 command 및 commandfor 속성은 popovertargetaction 및 popovertarget 속성을 개선하고 대체함
          + 이것들이 기본적으로 사용 가능해진 것인가? 대체한다는 것은 무슨 의미인가? 언젠가 이를 제거할 것인가? 웹 개발자들이 더 이상 필요하지 않은 것을 업데이트로 제거할 수는 없음
     * 문자열로 프로그래밍하는 것에 완전히 알레르기 반응을 보임. 접근성 이점은 이해하지만, 또 다른 웹 앱 동작 레이어로 요소 ID를 사용하는 것에 대해 특별히 흥미롭지 않음
     * 전체 API 없이 이를 구현하지 말았어야 함. 5개 정도의 명령 대신, HTML을 통해 모든 JavaScript 기능을 구현할 수 있는 것처럼 보임. 이는 수천 개의 명령이 될 수 있음
     * HTML에서 command and conquer에 대한 기대감이 있었음
     * HTML을 개선하고 확장하는 것은 좋지만, 아직 갈 길이 멀음. HTMX 팀이 몇 가지 좋은 아이디어를 가지고 있음
"
"https://news.hada.io/topic?id=19605","Mistral OCR 공개- 최고의 문서 이해 API ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Mistral OCR 공개- 최고의 문서 이해 API

     * Mistral OCR은 세계 최고의 문서 이해 API로, 기존 모델보다 문서를 더 정확하게 이해하고 분석하는 능력을 제공
     * PDF 및 이미지에서 텍스트, 미디어, 수식, 테이블을 추출하여 구조화된 출력으로 변환
     * API는 현재 1000페이지/1$ (배치 처리 시 페이지당 비용 절반)로 제공

Mistral OCR의 주요 특징

     * 복잡한 문서 이해 능력: 표, 이미지, 수식, LaTeX 서식까지 정확히 해석
     * 다국어 및 다중 모달 지원: 다양한 언어, 글꼴, 스크립트 지원
     * 업계 최고 수준의 성능: 다른 OCR 모델보다 높은 정확도를 기록
     * 최고 속도: 단일 노드에서 분당 2000페이지 처리 가능
     * 문서를 프롬프트로 활용 가능: JSON 등의 구조화된 출력 지원
     * 온프레미스(Self-host) 옵션 제공: 기밀 문서 처리를 원하는 기업에 적합

복잡한 문서 이해

     * Mistral OCR은 과학 논문, 그래프, 수식, 표, 이미지를 포함한 문서를 심층적으로 분석할 수 있음
     * 예제 노트북을 통해 OCR이 PDF에서 텍스트와 이미지를 어떻게 추출하는지 확인 가능 (예제)

성능 비교 (벤치마크)

   Mistral OCR은 다른 주요 OCR 모델과 비교했을 때 전반적인 성능에서 가장 높은 점수를 기록함
     * 전반적 성능(Overall): 94.89 (다른 모델보다 높은 수치)
     * 수식(Math) 분석 성능: 94.29 (GPT-4o보다 7점 이상 높음)
     * 다국어 인식 성능: 89.55
     * 스캔 문서(Scanned) 처리 성능: 98.96
     * 테이블(Table) 인식 성능: 96.12 (다른 모델 대비 가장 뛰어남)

다국어 지원

   Mistral OCR은 전 세계 다양한 언어와 스크립트를 처리 가능. 주요 모델과 비교 시 모든 언어에서 최고의 OCR 성능을 기록
     * 러시아어(ru): 99.09 (Azure OCR 97.35, Google Doc AI 95.56)
     * 프랑스어(fr): 99.20 (Azure 97.50, Google 96.36)
     * 중국어(zh): 97.11 (Azure 91.40, Google 90.89)
     * 독일어(de): 99.51 (Azure 98.39, Google 97.09)

빠른 처리 속도

     * Mistral OCR은 기존 OCR 모델보다 가벼우며, 단일 노드에서 최대 2000페이지/분 처리 가능
     * 대량 문서 처리가 필요한 환경에서 지속적인 학습과 개선을 지원

문서를 프롬프트로 활용 (Doc-as-prompt)

     * 문서에서 특정 정보를 추출하고 JSON 등의 구조화된 출력 생성 가능
     * 추출된 데이터를 후속 AI 프로세스와 연결하여 자동화 가능
     * 예: 법률 문서에서 특정 조항 추출 후 AI 챗봇 응답 생성

온프레미스(Self-host) 옵션

     * 기업 내 기밀 문서 처리가 필요한 경우 자체 호스팅 가능
     * 데이터 프라이버시와 보안이 중요한 기관 및 기업에 적합

주요 활용 사례

    1. 과학 연구 디지털화: 논문과 저널을 AI가 처리할 수 있는 형식으로 변환하여 연구 협업 가속화
    2. 역사 및 문화유산 보존: 박물관 및 비영리 단체가 역사적 문서를 디지털화하여 보존 및 공유 가능
    3. 고객 서비스 개선: 매뉴얼과 문서를 인덱싱하여 고객 응대 속도 향상
    4. 디자인, 교육, 법률 문서 AI 활용: 엔지니어링 도면, 강의 자료, 규제 서류 등을 인덱싱하여 AI 기반 정보 검색 가능

Mistral OCR 체험하기

     * Mistral OCR은 Le Chat에서 무료 체험 가능 (Le Chat)
     * API는 la Plateforme에서 사용 가능 (API 사용)
     * 온프레미스 배포 및 기업용 맞춤 솔루션도 제공됨 (문의)

   한국어 성능에 대한 내용은 없지만 뽑아보니 나쁘지 않아 보이네요

        Hacker News 의견

     * ""나쁘지 않음""이라는 의견이 있음. 그러나 여전히 환각 현상이 발생함
          + 예시로 제공된 이미지에서 중앙 블록의 텍스트는 정확하게 출력되었음
          + 그러나 다음 블록에서는 이전 블록의 텍스트 일부가 반복되고, 다음 블록의 일부가 잘못 포함되었으며, 존재하지 않는 단어가 생성되었음
          + 올바른 텍스트는 ""Louis, commandeur de Malte, capitaine aux gardes, 2 juin 1679.""임
     * Mistral과 Marker의 성능 비교를 위한 벤치마크를 부분적으로 실행했음
          + 375개의 샘플에서 LLM이 심사한 결과, Mistral은 4.32점, Marker는 4.41점을 기록했음
          + Marker는 H100에서 초당 20~120페이지를 추론할 수 있음
          + 샘플과 벤치마크 코드는 각각 Hugging Face와 GitHub에서 확인 가능함
          + Mistral OCR은 인상적인 모델이지만, OCR 문제는 여전히 어려움
     * OCR 기술이 발전하면서 논문과 교과서를 읽는 것이 더 쉬워질 것이라는 기대가 있음
          + 그림 참조와 실제 그림을 연결할 수 있어 읽기 흐름을 방해하지 않음
          + HTML로의 깔끔한 변환이 가능해져, 정의를 클릭하거나 이해를 확인하는 질문을 추가할 수 있음
          + Andy Matuschak의 Orbit SRS를 PDF에 자동으로 통합할 가능성도 있음
     * OCR 기술이 거의 해결된 상태에 도달하고 있음
          + 그러나 비즈니스에서 원시 OCR 출력에서 문서 처리로 전환하는 데는 여전히 큰 격차가 있음
          + LLM과 VLM은 마법이 아니며, 100% 자동화를 기대하는 것은 무리임
          + 데이터셋 구축, 파이프라인 조정, 불확실성 감지 및 인간의 개입을 통한 수정 등이 필요함
     * 의료 교과서를 PDF에서 MD로 변환하는 경우, MinerU/PDF-Extract-Kit의 결과가 더 좋다는 의견이 있음
          + 기사에 있는 콜랩 링크가 작동하지 않지만, 문서에서 작동하는 링크를 찾았음
     * 기술이 발전하여 PDF를 편집할 수 있게 된 날이 왔다는 의견이 있음
          + 그러나 여전히 개인 데이터가 포함된 PDF 아카이브의 OCR 문제는 해결되지 않음
     * 매우 빠르고 구글, Claude 등보다 정확하다는 의견이 있음
          + 가격은 1000페이지당 $1, 배치의 경우 2000페이지당 가격이 책정됨
          + PDF를 Markdown으로 변환하는 데 훌륭하다는 의견이 있음
     * 특정 모델 대신 일반 VLM을 사용하는 경우, 특정 사례에 맞게 조정하기 어렵다는 단점이 있음
          + 예를 들어, Gemini를 사용하여 추출된 Markdown에 매우 구체적인 대체 텍스트를 추가함
          + Gemini Flash보다 2~3배 비용이 들지만 성능 향상이 중요함
     * VLM OCR이 환각을 일으키는 이유에 대한 간단한 설명을 찾고자 함
"
"https://news.hada.io/topic?id=19692","OpenAI, AI 에이전트 개발을 위한 개발자 도구들 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   OpenAI, AI 에이전트 개발을 위한 개발자 도구들 공개

     * 웹 서치: 웹에서 최신정보 검색 및 인용 URL 리턴
     * 파일 서치: 업로드된 파일 목록에서 시맨틱/키워드 검색
     * Computer Use: 컴퓨터를 제어하고 작업을 수행
     * Responses API: 고급 통합 답변 인터페이스. 텍스트/이미지 입력 가능하며 웹/파일 검색 및 CUA 기능을 모두 이용
     * Agents SDK: 에이전트 개발을 위한 오케스트레이션 프레임워크

     * 자격이 되는 일부 개발자/회사는 OpenAI와 프롬프트를 공유하여 모델을 개선하는데 도움을 줄 수 있음
          + 올해 4월말까지 gpt-4.5-preview, gpt-4o, o1 에 대해서 하루에 최대 100만 토큰, gpt-4o-mini, o1-mini, o3-mini 에 대해서는 최대 1천만 토큰까지 무료로 사용 가능
          + 자격은 OpenAI 개발자 대시보드에서 확인 가능

     * OpenAI의 소개글 : New tools for building agents

Web Search

     * ChatGPT에서 최신 정보를 제공하기 위해 웹에서 직접 정보를 검색할 수 있음
     * Chat Completions API를 통해 미세 조정된 모델 및 검색 도구를 직접 사용할 수 있음
     * Chat Completions API에서 웹 검색 사용 방식
          + 모델은 응답 전 항상 웹에서 최신 정보를 검색함
          + 필요할 때만 웹 검색 도구(web_search_preview)를 사용하도록 하려면 Responses API로 전환해야 함
     * 웹 검색을 사용할 수 있는 모델
          + gpt-4o-search-preview
          + gpt-4o-mini-search-preview

File Search

     * 모델이 응답을 생성하기 전에 사용자의 파일에서 관련 정보를 검색할 수 있도록 함
     * Responses API에서 제공되며, 업로드된 파일의 지식 기반에서 의미 검색 및 키워드 검색을 통해 정보를 검색함
     * Vector Store 및 의미 검색 활용
          + 벡터 저장소(Vector Store)를 생성하고 파일을 업로드하면 모델의 기본 지식을 확장할 수 있음
          + OpenAI에서 관리하는 도구로, 사용자가 직접 코드를 구현할 필요가 없음
          + 모델이 필요하다고 판단하면 자동으로 도구를 호출해 파일에서 정보를 검색하고 응답 생성
     * 사용 방법
          + 먼저 벡터 저장소에서 지식 기반을 설정하고 파일 업로드 필요
          + 벡터 저장소 설정 후 file_search 도구를 모델의 사용 가능 도구 목록에 추가 가능
          + 현재는 한 번에 하나의 벡터 저장소에서만 검색 가능 (단일 벡터 저장소 ID만 사용 가능)

Computer Use

     * 사용자의 컴퓨터에서 작업을 수행할 수 있는 Computer-Using Agent(CUA) 모델 기반
     * GPT-4o의 시각 처리 및 고급 추론 능력을 결합해 컴퓨터 인터페이스 제어 및 작업 수행 가능
     * Responses API를 통해 제공되며, Chat Completions에서는 사용 불가
     * 현재 베타 버전으로, 취약점이나 실수 발생 가능성 있음. 완전히 인증된 환경이나 중요한 작업에서는 사용 비권장
     * 작동 방식
          + 모델이 클릭(x, y), 입력(text) 등 컴퓨터 작업 명령을 전송
          + 사용자의 코드가 해당 작업을 컴퓨터 또는 브라우저 환경에서 실행하고 결과 스크린샷 반환
          + 모델이 스크린샷을 기반으로 환경 상태를 이해하고 다음 작업을 제안
          + 연속 루프를 통해 클릭, 입력, 스크롤 등 다양한 작업 자동화 가능
     * 활용 사례 예시 : 항공편 예약, 제품 검색, 양식 작성

Responses API

     * OpenAI의 가장 발전된 모델 인터페이스
     * 텍스트 및 이미지 입력 지원, 텍스트 출력 생성
     * 이전 응답의 출력을 다음 입력으로 사용할 수 있는 상태 유지 상호작용 제공
     * 기능 확장 가능
          + 내장 도구를 통해 모델의 기능 확장 가능
               o File Search – 업로드된 파일에서 의미 및 키워드 검색 가능
               o Web Search – 최신 웹 정보 검색 가능
               o Computer Use – 컴퓨터 인터페이스 제어 및 자동화 작업 수행 가능
          + Function Calling – 외부 시스템 및 데이터에 접근 가능
               o Python 함수 호출 및 외부 시스템과 상호작용 가능

Agents SDK

     * 복잡한 추상화 없이 간단하고 사용하기 쉬운 패키지로 Agent 기반 AI 앱 개발 가능
     * 이전 실험 플랫폼인 Swarm의 프로덕션 레벨 업그레이드 버전
     * 주요 구성 요소(Primitive):
          + Agents – 명령 및 도구를 갖춘 LLM 기반 에이전트
          + Handoffs – 특정 작업을 다른 에이전트에 위임
          + Guardrails – 에이전트의 입력 값 검증 및 필터링
     * Python 통합 및 강력한 기능
          + Python과 함께 사용 시 강력한 도구 간 관계 설정 및 복잡한 워크플로우 구현 가능
          + 시각화 및 디버깅을 위한 트레이싱(Tracing) 기능 포함
          + 평가, 디버깅, 모델 파인 튜닝까지 지원
     * Agents SDK의 주요 특징
          + 설계 원칙
               o 기능은 충분히 강력하지만, 배울 것이 적어 빠르게 익숙해질 수 있을 것
               o 기본 상태에서 우수한 성능 제공, 필요 시 세부 설정 가능
          + 기본 기능
               o Agent Loop : 내장 루프로 도구 호출 → 결과 처리 → LLM 응답 생성 → 종료까지 자동 처리
               o Python-first 설계 : Python 언어 기능을 그대로 사용해 에이전트 연결 및 오케스트레이션 가능
               o Handoffs : 여러 에이전트 간 작업 위임 및 조정 가능
               o Guardrails : 입력 값 검증 및 병렬 체크 수행, 오류 발생 시 조기 종료 가능
               o Function Tools : Python 함수를 자동으로 도구화 → 자동 스키마 생성 및 검증 수행
               o Tracing : 내장된 트레이싱 기능으로 워크플로우 시각화, 디버깅, 평가 및 개선 가능
"
"https://news.hada.io/topic?id=19587","SmartestKid - 윈도우 데스크탑용 AI 어시스턴트 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 SmartestKid - 윈도우 데스크탑용 AI 어시스턴트 오픈소스

     * 약 1000줄의 파이썬 코드로 구축된 Windows 데스크톱 AI 어시스턴트
          + OpenAI API 키 필요
     * Windows의 COM Automation을 사용하여 Microsoft Office(Word, Excel), 이미지 및 파일 시스템과 연동
     * 채팅 인터페이스. 음성/텍스트 입력간 전환
"
"https://news.hada.io/topic?id=19616","CodeTracer - Nim 과 Rust로 개발된 시간여행 디버거 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 CodeTracer - Nim 과 Rust로 개발된 시간여행 디버거

     * 다양한 프로그래밍 언어를 지원하는 사용하기 쉬운 타임 트래블 디버거
          + 프로그램 실행을 기록하여 공유 가능한 독립적인 트레이스 파일을 생성하고, GUI 환경에서 실행을 앞뒤로 이동하며 모든 메모리 위치의 히스토리를 확인할 수 있음
     * 타임 트래블 디버깅의 장점
          + 재현하기 어려운 버그를 쉽게 해결할 수 있음 : 버그가 발생한 실행 기록 녹화가 있으면 30분 이내에 원인을 파악 가능
          + 값의 기원을 알면 버그 해결이 쉬워짐
               o 프로그램에서 예기치 않은 출력이 발생하면 해당 이벤트를 클릭해 문제의 발생 지점을 즉시 확인 가능
               o CodeTracer는 해당 값이 어디에서 생성되었는지를 추적해 몇 번의 이동만으로 버그의 근본 원인을 찾아낼 수 있도록 지원
               o 프로그램 실행의 어느 순간이든 자유롭게 앞뒤로 이동하며 탐색할 수 있음
     * 트레이싱은 오픈 포맷을 사용하며, Ruby, Python 등의 언어 지원 프로젝트 진행중
          + RR 백엔드와 통합하여 C/C++, Rust, Nim, D, Zig, Go, Fortran, FreePascal 등 시스템 프로그래밍 언어 디버깅 지원 계획

CodeTracer의 주요 기능

  전지적 디버깅 (Omniscience)

     * 실행 중 특정 코드 줄에서 과거와 미래의 변수 값을 즉시 확인 가능
     * 루프 내 변수 값의 변화를 쉽게 탐색 가능
     * 실행된 코드와 실행되지 않은 코드가 명확하게 구분됨

  트레이스포인트 (Tracepoints)

     * 추가적인 코드 실행 없이 프로그램 내 변수 값의 변화를 즉시 확인 가능
     * 조건문, 함수 호출, 데이터 출력 등을 손쉽게 추가하여 디버깅 가능

  콜 트레이스 (Call Trace)

     * 단순한 스택 트레이스가 아니라 프로그램 실행 전체의 함수 호출 트리를 제공
     * 필터링 및 정렬을 통해 쉽게 탐색 가능

  상태 및 히스토리 탐색 (State and History Explorer)

     * 모든 변수의 값 변경 내역을 추적 가능
     * 변수의 값이 변경된 코드 지점으로 즉시 이동 가능
     * 복사된 변수의 원본 값을 자동 추적하여 버그 분석을 용이하게 함

  이벤트 로그 (Event Log)

     * 프로그램 내 중요한 이벤트를 시간순으로 정리하여 제공
     * 특정 이벤트를 클릭하면 해당 순간의 코드로 즉시 이동 가능

  터미널 출력 (Terminal Output)

     * stdout, stderr 출력을 터미널처럼 재현하여 기록된 프로그램 출력을 확인 가능
     * 클릭하면 출력이 발생한 정확한 코드 위치로 이동 가능

  마우스 스테핑 (Mouse Stepping)

     * 마우스를 사용해 코드의 특정 부분으로 즉시 이동 가능
          + 라인 이동: 마우스 가운데 클릭 (Ctrl+클릭 가능)
          + 함수 진입: 함수 호출을 더블 클릭하여 내부로 이동 (Ctrl+Alt+클릭 가능)
          + 추가 옵션: 우클릭 메뉴에서 추가 기능 탐색 가능

  스크래치패드 (Scratchpad)

     * 특정 시점의 변수 값을 고정하여 비교 및 분석 가능
     * 코드 실행 흐름을 시각적으로 비교하며 문제를 분석 가능

CodeTracer CLI 명령어

     * ct run <application> - 프로그램 실행 및 자동 기록
     * ct record <application> - 트레이스 파일 생성
     * ct replay - 생성된 트레이스 파일 재생
     * ct replay <program-name> - 마지막 실행 기록 불러오기
     * ct replay --id=<trace-id> - 특정 트레이스 ID로 실행
     * ct replay --trace-folder=<trace-folder> - 특정 폴더 내 트레이스 파일 실행
     * ct help / ct --help - 사용 가능한 명령어 확인
     * ct version - 현재 버전 확인

키보드 단축키

     * 기본 단축키는 Visual Studio™ 유저에게 친숙한 방식
     * 기존 디버깅 기능의 역방향 기능을 Shift 키와 함께 제공 (F10 = ""다음 스텝"", Shift+F10 = ""이전 스텝"")
     * ~/.config/codetracer/.config.yml 파일을 수정하여 단축키 사용자 지정 가능

        Hacker News 의견

     * 멋있음. 오래 전 Intel 프로세서 디자이너들에게 기능 요청을 할 기회가 있었음
          + 로그 스탬핑을 위한 시스템 틱 타이머를 요청했는데, 그들은 그것을 구현했음
          + 디버그 인터럽트를 트리거하는 버스 마스크와 값 레지스터도 요청했는데, 그것도 구현했음
          + 점프 소스 히스토리를 요청했으나, 그것은 실현되지 않았음
          + 당시 Intel은 버스를 기록하는 비싼 디버그 프로브를 판매했음
          + 내 점프 히스토리가 대부분의 사용자에게 필요성을 없앨 수 있었을 것임
          + 결국 실현되지 않았고, 우리는 코드 '디버그'를 다시 빌드하여 추적과 추적을 추가함
     * Noir 지원은 ZK 증명에서 실행 추적이 특히 가치가 있기 때문에 의미가 있음
          + Python과 Ruby 구현을 기대하고 있음
          + 이 언어들의 동적 특성 때문에 버그가 특히 찾기 어려운 경우가 있음
          + Noir을 사용해본 사람이 있는지 궁금함
          + 추적 메커니즘의 성능 오버헤드가 궁금함
          + 웹 개발을 위한 JavaScript/TypeScript 지원 계획이 있는지도 궁금함
     * Clojure 또는 ClojureScript를 사용하는 경우 FlowStorm을 확인해보길 권장함
          + FlowStorm 웹사이트
     * Noir은 SNARK 증명 시스템을 위한 도메인 특화 언어임
          + Noir 웹사이트
     * 왜 CodeTracer를 두 개의 언어로 작성했는지 궁금함
     * 정말 마음에 듦. 항상 그런 것을 원했음
          + 나중에 Python으로 테스트해볼 예정임
          + JS/TS 지원도 있었으면 좋겠음
          + rr 디버거가 MacOS, Windows, Android를 지원하는지 궁금함
          + 일반 앱에 대한 기록이 얼마나 무거운지도 궁금함
          + LLM이 MCP 서버를 통해 컨텍스트를 제공하거나, LLM이 보고 싶은 변수 히스토리를 선택하게 하는 것도 좋을 것임
          + 기록 필터링 기능도 좋을 것임
     * 멋져 보이지만, 프로덕션 시스템에서는 추적 파일이 매우 빠르게 증가할 것임
          + 파일을 특정 세션과 연관시키는 방법이 궁금함
     * Nim 생태계를 구축해줘서 고마움
     * 매우 기대됨. 이미 Open Collective에 기부했음
          + 팀은 재능 있는 사람들로 가득 차 있음
          + 시간 여행 디버깅에 대한 멋진 인터페이스가 있음
          + rr을 사용하면 macOS에서 실행할 수 없을 것임
          + 다행히 lima vms가 원격으로 쉽게 만들 수 있음
     * 출시를 축하함. 지금까지 훌륭한 일을 해냈음
          + 현재 나에게는 필요하지 않지만, 대체 백엔드 발전과 추가 프로그래밍 언어 지원을 주시할 것임
          + 고마움
"
"https://news.hada.io/topic?id=19658","Leaflet - 문서 작성 및 공유를 위한 웹앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Leaflet - 문서 작성 및 공유를 위한 웹앱

     * 빠르고 가벼우면서도 리치 블록과 멀티 페이지를 지원하는 문서 작성 웹앱
     * Notion과 Google Docs 사이의 균형을 찾는 것을 목표로 개발
     * 계정 없이도 즉시 문서 생성 & 작성 가능
     * 간편한 공유 가능하며 읽기 및 편집 링크 제공
     * 이메일 로그인으로 기기 간 문서 동기화
     * 리치 블록 지원 : 캔버스, 서브페이지, RSVP, 투표 등 추가 가능
     * 깔끔한 디자인 : 출판용 웹페이지처럼 보기 좋게 구성
     * 유스케이스 : 일회성 협업, 이벤트 운영, 빠른 메모 작성 등
     * 예제 문서
          + 전통 수공예 교육 Slöjd에 대한 프레젠테이션
          + 웹사이트 리디자인 문서화
     * 기술적 특징
          + TypeScript + React & Next.js + Supabase + Replicache + TailwindCSS
          + Replicache를 활용한 실시간 동기화 및 클라이언트 상태 관리
          + Datomic 스타일의 데이터 모델 (엔티티 기반 그래프 구조)
          + ProseMirror 활용 (모든 텍스트 블록을 개별 ProseMirror 인스턴스로 관리하여 유연성 확보)
          + 오픈소스 프로젝트 (leaflet 의 GitHub Repo)
     * 향후 개발 계획
          + 문서 관리 기능 개선 (검색, 태깅, 컬렉션 등 추가)
          + ATProto 및 Bluesky 통합 (문서 출판용 AppView 및 리치 텍스트 문서 표준 개발)
          + 더 많은 블록 추가 (테이블, 코드 블록 등)
     * 강점
          + 우수한 리스트 처리 방식
          + 커스텀 테마 지원
          + iOS Safari에서 최적화된 키보드 입력 처리
          + 사이드 스크롤 방식의 멀티 페이지 인터페이스
          + PWA 지원 (앱처럼 설치 가능)

   엄청 멋지네요

   위에 제가 적은 내용을 문서로 만든후 보기 링크로 만든 것이 https://leaflet.pub/955dc6a0-bc24-4c56-8713-6fa3f824dd4c 입니다.
   뷰어용/수정용 두개의 링크가 만들어지는데 위에 공유한 것은 뷰어 전용 링크입니다.
   특이하게 og:image 를 현재 문서의 내용으로 계속 새로 만들어 주네요.
"
"https://news.hada.io/topic?id=19596","Apple, 영국 정부의 '백도어' 명령에 반발하며 소송 제기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Apple, 영국 정부의 '백도어' 명령에 반발하며 소송 제기

     * 애플이 영국 정부가 iCloud 데이터 암호화를 해제하도록 강제하는 명령에 반발하며 영국 조사권한재판소(IPT)에 법적 소송을 제기함
     * 이는 IPT에 접수된 최초의 사례로, 해당 기관은 공공 기관이나 영국 정보기관의 불법적인 행동에 대한 법적 불만을 심사하는 독립적인 사법 기관임

영국 정부와 애플 간 암호화 논란

     * 영국 내무부(Home Office)는 법 집행 기관이 특정 인물의 데이터를 조사할 수 있도록 iCloud에 백도어를 만들 것을 애플에 요구함
     * 2024년부터 논의되던 이 문제는 2025년 1월 내무부가 조사권한법(Investigatory Powers Act, IPA) 에 따라 기술적 역량 통지(Technical Capability Notice, TCN) 를 애플에 발행하면서 본격적으로 대립하게 됨
     * 해당 명령은 '기술적'이라는 명칭과 달리, 애플에 구체적인 기술적 지침을 제공하지 않고 단순히 iCloud의 백도어를 제공하라는 요구로 해석됨
     * 내무부는 TCN의 존재 여부에 대해 공식 확인을 거부했으며, IPA 2016에 따라 애플은 이 명령의 세부 사항을 공개할 수 없음

애플의 대응: 영국 내 E2EE(종단간 암호화) 기능 중단

     * 애플은 정부의 요구를 완전히 수용하지 않으면서도 부분적으로 대응하기 위해, 영국 사용자에 대한 고급 데이터 보호(ADP) 기능을 중단
     * 이로 인해 iCloud 백업, 사진, 메모 등의 데이터는 종단간 암호화(E2EE)가 적용되지 않으며, 법원이 승인한 영장에 따라 애플이 데이터 제공 가능
     * iMessage와 건강 데이터는 여전히 보호됨
     * 사용자에게 알리지 않고 데이터 제공이 가능하며, 내부 고발자가 나오지 않는 한 정부의 접근 여부를 알 방법 없음
     * 애플은 이에 대해 ""우리는 백도어나 마스터 키를 만들지 않았으며, 앞으로도 만들지 않을 것"" 이라는 입장을 고수

영국 정부의 암호화 해제 정책에 대한 논란

     * 내무부는 WhatsApp 등 모든 인기 메시징 플랫폼의 E2EE를 해제하려는 목표를 가지고 있음
     * 영국 정부는 테러 예방 및 아동 성범죄 방지를 주요 논거로 삼아 암호화 해제 정책을 추진 중
     * 보안 장관 Dan Jarvis는 TCN을 통한 데이터 접근이 ""예외적인 경우에만, 필요하고 비례적인 방식으로 이루어질 것"" 이라고 주장
     * 그러나 정부가 무차별적으로 사용자 데이터를 접근할 가능성에 대한 우려는 해소되지 않음

국제적 반응 및 법적 문제

     * 감시단체 Big Brother Watch는 영국 정부의 조치를 ""독재적이고 터무니없다"" 고 비판하며, 강제적인 암호화 해제가 오히려 범죄자들만 보호하는 결과를 초래할 것이라고 경고
     * 도널드 트럼프 전 미국 대통령은 영국의 애플 대응을 중국의 감시 정책과 비교하며 비판
     * 미국 국가정보국장(Tulsi Gabbard) 은 애플에 대한 TCN이 미국 시민의 데이터를 수집하는 데 사용될 가능성을 우려하며 법적 검토를 지시
     * 이는 미국과 영국 간의 Cloud Act 협정을 위반할 소지가 있음

추가 업데이트 (1833 UTC)

     * 영국 정부는 과거에 변호사, 법률가, 기타 민감한 직업군이 애플의 ADP를 사용할 것을 권장했던 문서를 웹사이트에서 삭제한 것으로 보임

   프라이버시 종말의 시대인가요. 지난 번 스페인 등 EU 몇몇 국가들 주도 하에 종단 간 암호화 자체를 불법화시키려는 시도가 있었던 것이 불과 몇 개월 전인데요. 왜 사람들은 스스로 빅 브라더에게 모든 것을 맡기려고 할까요.

   개인폴더의 사진들을 시진핑과 공유할지 전세계와 공유할지 고민해보면 오히려 전자가 유출범위는 더 작을지도.

   엌ㅋㅋㅋ sarcasm 대박이네요!

   GN⁺: 영국, Apple에게 사용자들의 암호화된 계정을 감시하라고 명령

        Hacker News 의견

     * 영국 기반 ADP 사용자로서 그들이 이렇게 하는 것이 매우 기쁨. 기존 사용자에게 강제로 끄기 전까지 얼마나 걸릴지 기다리고 있음. 그 시점에 iCloud에서 모든 것을 제거할 것임
     * Apple의 클라우드 저장소에 이미 백도어가 없는지 어떻게 알 수 있을까? 이 싸움은 Apple의 클라우드 저장소가 안전하고 정부의 감시로부터 자유롭다는 관점을 정당화하기 위한 연극일 수 있음
          + 신뢰하고, 검증해야 함. 검증할 수 있는 능력이 없으면 신뢰도 없음
     * ""2021년: 불만 제기자에게 유리한 (IPT) 사례는 발견되지 않음"": <a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Investigatory_Powers_Tribunal#Statistics"" rel=""nofollow"">https://en.wikipedia.org/wiki/Investigatory_Powers_Tribunal/…;
     * 사람들이 프라이버시를 잃는 것이 무엇을 의미하는지 진정으로 느끼기 전까지는 큰 변화가 없을 것임
          + 현재 영국에서는 암호화에 대한 정부의 십자군 전쟁과 전반적인 프라이버시의 종말에 대한 강한 지지가 여전히 존재함
          + ""왜 신경 써야 하지, 숨길 게 없는데""라는 생각 때문임
          + 사람들이 이 문제에 대해 교육받는 데는 시간과 비극이 필요함. 몇 년 또는 10년 후에야 추세가 반전될 수 있음
     * 그때까지 Apple이 할 수 있는 것은 많지 않음. 법도 없고, 대중의 지지도 없으며, 돈은 있지만 사람들을 교육하는 데 쓸 계획은 없음
          + 영국 정부를 법정에 데려가는 것이 지금으로서는 최선의 방법임. 세계에 '우리는 당신의 프라이버시를 중요하게 생각합니다, 아이폰을 사세요'라고 말하는 거대한 광고 같은 것임
     * 이로부터 큰 결과가 나올 것 같지 않음. 최소한 가장 큰 두 정당은 이러한 종류의 암호화 백도어를 지지하고 있으며, '법원'이 어떤 결정을 내리든 의회는 그에 맞춰 법을 제정할 수 있음
     * 암호화를 사용하고자 하는 사람들은 클라우드 서비스와 별도로 자신의 소프트웨어를 사용해야 한다고 생각함. (이것만으로는 충분하지 않을 수 있으며, 다른 보안도 구현해야 하지만, 할 수 있는 한 가지 방법임)
     * 좋음. 설령 패배하더라도 영국 시장을 포기하기 전에 최대한 소음을 내야 함. 아마도 대중의 인식을 바꾸기 시작할 수 있을 것임
     * Apple이 충분한 자원이 있다면, 영국을 포기하고 끝낼 것임. 법적으로 승리하지 못한다면. 꿈 같은 이야기임을 알지만
     * 그렇게 해야 함. 정부 외에는 아무에게도 이익이 되지 않는 것에 대해 최후통첩을 던질 수 없음
          + 비슷한 상황에 영향을 받은 다른 회사들도 이를 법정에 가져가기를 바람
     * 영국이 표현의 자유에 대해 하고 있는 일은 완전히 수치스러움. Apple이 이렇게 행동하는 것을 보니 매우 기쁨
"
"https://news.hada.io/topic?id=19614","Wanaku - 오픈소스 MCP 라우터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Wanaku - 오픈소스 MCP 라우터

     * Model Contenxt Protocol을 통해 AI 에이전트가 엔터프라이즈 시스템과 원활하게 통합될 수 있도록 지원
     * MCP는 AI와 외부 데이터 소스를 연결하는 표준으로 자리 잡고 있지만, 1500개 이상의 MCP 서버가 존재하고 품질과 기능이 제각각임
          + AI 엔지니어들은 수작업 설정 없이 통합을 자동화할 솔루션이 필요함
     * Wanaku는 Apache Camel(통합 프레임워크) 과 같은 검증된 기술을 활용하여 수백~수천 개의 통합을 쉽게 설정하고 관리할 수 있도록 지원
          + 통합 허브: 하나의 시스템에서 다양한 에이전트 애플리케이션을 연결 가능
          + 편리한 CLI/UI: HTTP, Kafka, FTP 등 다양한 프로토콜 지원(향후 더 많은 프로토콜 추가 예정)
          + 재사용 가능한 도구: 프로젝트 간 도구 공유 및 관리 가능
          + 플러그인 아키텍처: Apache Camel을 기반으로 확장 가능
"
"https://news.hada.io/topic?id=19608","미국, 전 세계 대사관에서 Air Quality Data 공유 중단","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 미국, 전 세계 대사관에서 Air Quality Data 공유 중단

     * 미국 정부가 대사관과 영사관에서 수집한 대기질 데이터를 더 이상 공유하지 않기로 결정함. 이는 전 세계 대기질 모니터링과 공중 보건 개선에 중요한 역할을 했던 노력에 우려를 제기
     * 국무부는 예산 제약으로 인해 데이터 전송을 중단한다고 밝혔으며, 대사관과 영사관은 모니터를 계속 운영할 것이며 예산이 복구되면 데이터 공유가 재개될 수 있다고 함
     * 이 결정은 트럼프 행정부의 환경 및 기후 이니셔티브 우선순위 축소의 일환
     * 데이터 공유 중단의 영향
          + PM2.5와 같은 미세먼지를 측정하는 미국의 대기질 모니터는 호흡기 질환, 심장 질환, 조기 사망을 유발할 수 있는 위험한 물질을 측정함
          + 세계보건기구(WHO)는 대기 오염으로 매년 약 700만 명이 사망한다고 추정함
          + 데이터 공유 중단 소식에 과학자들은 즉각적인 반응을 보였으며, 이 데이터가 신뢰할 수 있고 전 세계 대기질 모니터링을 가능하게 했으며 정부가 공기를 정화하도록 촉구하는 데 도움을 주었다고 언급
     * 글로벌 대기질 연구에 미치는 영향
          + 뉴델리의 지속 가능한 미래 협력체의 대기 오염 전문가인 바르가브 크리슈나는 데이터 손실을 ""큰 타격""이라고 표현함.
          + 미국 대사관의 데이터는 많은 개발도상국에서 대기질을 이해하는 데 중요한 참고 자료로 사용되었으며, 현지 데이터의 품질에 대한 우려가 있을 때 교차 확인할 수 있는 잘 보정된 데이터로 간주되었음.
          + 콜롬비아 보고타의 프리랜서 대기질 컨설턴트인 알레한드로 피라코카 마요르가는 미국 대사관의 모니터링이 현지 모니터링 네트워크와 독립적인 대기질 정보를 제공했다고 언급함.
     * 지역적 노력 강화
          + 미국의 대기질 모니터는 일부 국가에서 자체 대기질 연구를 시작하고 인식을 높이는 데 기여함.
          + 중국에서는 베이징 주재 미국 대사관의 데이터가 정부의 공식 보고서와 상충하여 중국이 대기질을 개선하는 계기가 되었음.
          + 인도의 글로벌 기후 및 건강 연합의 캠페인 리더인 슈웨타 나라얀은 모니터링 중단이 ""큰 후퇴""이지만 인도 정부가 대기질 모니터링 인프라를 강화하고 데이터 투명성을 보장하며 대기질 보고에 대한 공공 신뢰를 구축할 기회라고 언급함.

        Hacker News 의견

     * 미국의 대사관에서 제공하는 공기 질 데이터가 다른 나라의 연구와 인식을 높이는 데 기여함
          + 중국에서는 미국 대사관의 데이터가 정부의 공식 보고서와 상충하여 공기 질 개선을 촉진함
          + 2008년부터 미국은 해외 대사관을 통해 공기 질을 모니터링하며, 이는 검열될 수 있는 과학 데이터를 공유하는 방법으로 사용됨
          + 2014년 중국은 오바마 대통령이 참석한 국제 정상 회담을 앞두고 미국 대사관의 데이터를 공유하는 앱을 금지함
          + 연구자들은 이러한 투명성이 중국의 행동을 유도했다고 평가함
          + 오바마 대통령의 중국 대사였던 Gary Locke는 대사관과 영사관에 모니터를 도입하여 중국의 스모그 문제를 추적함
          + 뉴델리에서도 미국 대사관의 공기 질 데이터가 자주 참조됨
          + 데이터 공유 중단은 예산 제약으로 인한 것이며, 예산이 회복되면 데이터 공유가 재개될 수 있음
          + 워싱턴 기념비 증후군은 예산 삭감 시 정부가 가장 눈에 띄는 서비스를 중단하는 현상을 설명함
          + 이러한 데이터 공유 중단은 미국의 세계 리더십을 약화시킬 수 있음
          + 과거 Windows 95에서 시스템 파일을 삭제하여 컴퓨터가 부팅되지 않았던 경험을 떠올리며, 이러한 예산 삭감이 비슷한 수준의 분석으로 이루어지고 있다고 느낌
          + 미국이 깨어났을 때는 다른 나라들이 더 나은 기술을 미국에 판매할 준비가 되어 있을 것임
          + 데이터 방송의 실제 반복 비용이 무엇인지 궁금함
          + 이로 인해 절약되는 금액이 크지 않을 것이라고 생각함
          + 미국이 오랜 기간 동안 제공한 공기 질 데이터에 감사함
          + 영향력은 평화 시기에 초강대국의 가장 강력한 무기이며, 이를 끊는 것은 돈을 절약하는 것이 아니라 국가를 약화시킴
          + 이러한 조치가 연방 지출의 사기를 줄이고, 인플레이션을 감소시키며, 미국을 다시 위대하게 만드는 데 어떻게 기여하는지 의문임
"
"https://news.hada.io/topic?id=19623","Ozempic처럼 체중을 감소시키지만 부작용 없는 천연 분자 BRP 발견","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Ozempic처럼 체중을 감소시키지만 부작용 없는 천연 분자 BRP 발견

     * Stanford Medicine 연구진이 semaglutide(Ozempic)와 유사하게 식욕을 억제하고 체중을 감소시키는 자연 발생 분자를 발견함
     * 해당 분자(BRP)는 메스꺼움, 변비, 근육량 손실 등 semaglutide 계열의 대표적인 부작용을 유발하지 않는 특성을 보유함
     * BRP는 semaglutide와 다른 대사 경로를 통해 작용하며, 특정 뇌세포만을 목표로 하는 장점을 갖추고 있음
     * Ozempic(semaglutide)은 GLP-1 수용체에 작용하는 약물로, 소화기관, 췌장 등 여러 부위에 다양한 영향이 있음
     * 새롭게 발견된 BRP는 뇌의 시상하부에 직접적으로 작용해 식욕과 신진대사를 조절하는 것으로 보임
     * 연구를 주도한 Stanford Medicine의 Katrin Svensson, Ph.D.는 BRP의 임상 시험을 계획하기 위해 회사 설립을 주도함

BRP의 분자 구조 및 작용 기전

     * BRP(BRINP2-related peptide)는 12개의 아미노산으로 구성된 펩타이드임
     * 동물(쥐, 미니픽) 실험에서 식욕 감소 효과를 보였으며, 체중 증가 억제 효과가 확인됨
     * 주요 특징은 투여 후 메스꺼움이나 식품 기피 현상이 관찰되지 않았다는 점임
     * 또한, 주로 지방 조직 감소를 유도해 근육량 손실을 최소화하는 것으로 나타남
     * GLP-1(semaglutide 등)의 수용체와 달리, BRP는 별도의 신경 경로를 활용함
     * 뇌 시상하부에 작용함으로써 보다 특정적이고 선택적인 체중 조절 가능성을 가짐

인공지능(AI)을 통한 발견 과정

     * 연구진은 prohormone이라 불리는 단백질 그룹에 주목함
     * prohormone은 다른 단백질에 의해 절단(clipping)되어 활성화된 뒤, 호르몬 역할을 수행하는 펩타이드가 됨
     * 기존에는 생물학적 시료에서 펩타이드를 하나하나 분리해 대조군과 비교하는 방식이 복잡하고 번거로웠음
     * 이를 위해 연구진은 “Peptide Predictor”라는 컴퓨터 알고리듬을 개발해, 신호서열과 절단 부위를 예측함
     * 인간이 보유한 20,000여 개 유전자 중 prohormone convertase 1/3(PCSK1/3)이 절단할 수 있는 가능성이 있는 단백질들을 선별함
     * 그 결과, 373개 prohormone이 후보로 추려졌고, 여기서 만들어질 수 있는 2,683개 펩타이드가 예측됨
     * 연구진은 이 중 뇌에 생리학적으로 작용할 가능성이 높은 펩타이드 100종을 선별해 세포 실험을 시행함
     * 그 결과, 기존 GLP-1보다 훨씬 큰 세포 활성 효과를 보인 12아미노산짜리 BRP가 발견됨

동물 실험 결과

     * 실험용 쥐와 사람에 가까운 대사 패턴을 가진 미니픽에게 BRP를 근육 주사 후 음식 섭취량을 관찰함
     * 한 시간 내에 최대 50% 가까이 음식 섭취량이 감소함
     * 14일간 비만 쥐에게 매일 BRP를 투여한 결과, 평균 3g 체중 감소를 보임(대부분 체지방에서의 감량임)
     * 대조군 쥐는 같은 기간 약 3g 체중 증가를 보임
     * 혈당과 인슐린 반응 능력도 개선되는 경향을 보임
     * 행동적, 생리학적 변화를 관찰했을 때, 메스꺼움이나 변비 같은 부작용이 나타나지 않음
     * BRP가 작용하는 신경 경로 및 대사 경로가 GLP-1 계열과 구분됨을 시사함

후속 연구 및 전망

     * 연구진은 BRP가 인체 내에서 결합하는 세포 표면 수용체를 규명하고, 작용 메커니즘을 더 구체적으로 분석 중임
     * 체내에서 BRP의 효과를 오래 유지할 방법을 모색해, 환자들이 더 편리하게 사용할 수 있는 치료법 개발 가능성을 검토 중임
     * 현재 비만 치료 분야에서 semaglutide(Ozempic)는 강력한 체중 감량 효과로 주목받고 있지만, 다양한 부작용이 이슈가 됨
     * 새롭게 발견된 BRP의 경우, 보다 안전하고 구체적인 체중 조절 효과를 낼 수 있을 것으로 기대됨
     * 만약 인체 시험에서 유효성과 안전성이 입증된다면, 비만 치료와 대사 증후군 개선을 위한 혁신적 대안이 될 가능성이 있음
     * 연구진은 Merrifield Therapeutics를 공동 설립해, BRP 관련 임상 시험과 상용화 가능성을 추진 중임

관련 연구 협업

     * University of California, Berkeley, University of Minnesota, University of British Columbia 연구진이 참여함
     * 공동 연구를 통해 BRP의 다양한 작용 기전을 확인하고, 추가 효능 및 안전성 검증을 진행 중임

결론

     * BRP는 자연 발생 펩타이드로, Ozempic(semaglutide) 수준의 체중 감량 효과를 보여 주면서도 부작용 위험이 낮은 특성을 지님
     * 인공지능을 활용해 발견된 사례로, 향후 비만 및 대사 질환 분야의 치료 옵션 확대에 기여할 가능성이 높음
     * “Peptide Predictor” 알고리즘은 희소 펩타이드 호르몬을 찾는 혁신적 접근임
     * 연구진은 향후 임상 시험을 통해 BRP의 안전성과 효능을 확인할 예정임
     * 성공적인 인체 적용 시, 비만 치료에 새로운 전환점을 마련할 만한 가치가 있음

        Hacker News 의견

     * 이와 같은 혁신이 복잡한 정규 표현식에 기반을 두고 있다는 것을 발견하게 되어 기쁨
     * 자연 발생적이기 때문에 특허를 받을 수 없으며, 이는 기업들이 상업적 제품을 개발할 가능성을 낮춤
          + 정부가 부여하는 독점권이 없다면 FDA 승인을 받기 위해 비용을 지불할 이유가 없음
          + 이는 의약품 개발을 장려하는 메커니즘으로 특허를 사용하는 것의 문제점 중 하나임
     * 이 링크는 광고와 함께 게시된 보도 자료임
     * 자연 발생 분자이고 이 보고서가 이를 상세히 설명하고 있으므로, 생산이 저렴하고 쉬울 수 있는지 궁금함
     * 근육 손실이 약물의 부작용인지 체중 감소의 부작용인지 궁금함
     * 이 분자가 금 나노입자와 어떻게 비교될지 궁금함
          + 헤드라인: 금이 일반적인 체중 감량 약물을 능가하고 근육을 그대로 둠
     * 분자의 출처를 알려주지 않을 것인가? 어떤 베리나 콩류를 섭취해야 하는지 알고 싶음
     * 만약 이것이 정말로 Ozempic과 경쟁할 잠재력이 있다면 Novo Nordisk의 주가에 눈에 띄는 영향을 미쳐야 하지만, 아직 그런 모습을 보이지 않음
     * AI가 분자를 걸러내는 데 사용되었다고 언급하지만, 어떻게 사용되었는지는 언급하지 않음
          + 사전 훈련된 모델을 사용했는지, 아니면 처음부터 훈련했는지 알고 싶음
     * Ozempic의 분자도 자연 발생적인 것 아닌가?
"
"https://news.hada.io/topic?id=19714","GoatDB - Deno, React를 위한 경량 NoDB","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    GoatDB - Deno, React를 위한 경량 NoDB

     * 경량 배포 환경을 위한 실시간 버전 관리 데이터베이스
     * 프로토타이핑, 셀프 호스팅, 싱글 테넌트(Single-Tenant) 앱 및 백엔드 및 DB가 없는 초경량 멀티 테넌트(Multi-Tenant) 환경에 최적화됨
     * 별도 인프라 불필요 → 전체 DB를 클라이언트에서 실행하며, 서버 인덱싱이 필요 없음
     * 오프라인 우선(Offline-First) 구조 → 서버가 다운되더라도 클라이언트에서 계속 작동하며 복구 가능
     * 엣지 네이티브(Edge-Native) → 대부분의 처리를 클라이언트에서 수행하여 서버 부하 최소화
     * 실시간 동기화 지원 → 자동으로 클라이언트와 서버 상태를 동기화
          + 초기화 할때 peers에 복제본 위치를 설정하여 서버 클러스터를 쉽게 설정 가능
          + 동기화 프로토콜을 이용해 서버간 동기화를 지원하며, 여러 서버를 추가해도 코드 변경 없이 확장 가능함
     * React Hooks 사용
          + GoatDB의 React Hooks는 완전한 상태 관리 솔루션을 제공하며, 동기적(mutable) 상태 수정이 가능
          + 예를 들어, task.set('done', true)와 같은 변경 사항은 즉시 메모리에 반영되며, GoatDB가 자동으로 차이 계산(diffing), 로컬 저장소 커밋, 서버 동기화, 충돌 해결을 백그라운드에서 처리함
     * 보안 모델
          + 각 노드는 공개/개인 키 쌍을 유지하며, 개인 키는 절대 외부로 노출되지 않음
          + 모든 커밋은 디지털 서명되어, 조작된 변경 사항을 자동으로 거부함
          + 사용자 정의 권한 정책을 통해 데이터 접근 제어 가능
     * 충돌 해결 방식
          + 세 방향 병합(Three-Way Merge) : 변경 사항이 충돌할 경우 자동 병합하여 정리
          + Logoot 방식의 연속 ID 할당 : 데이터 내 삽입/삭제 충돌을 방지하는 고유 식별자 시스템 적용

예제 프로젝트

     * Todo → 셀프 호스팅용 최소한의 모던 투두 리스트
     * EdgeChat → 완전한 브라우저 기반 ChatGPT 스타일 인터페이스
     * Ovvio → 2024년부터 GoatDB를 사용 중인 생산성 도구

   GOAT..ㅎㄷㄷ
"
"https://news.hada.io/topic?id=19656","디스크월드 규칙","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                디스크월드 규칙

Discworld 규칙

     * LOTR와 기술자들: '반지의 제왕'은 훌륭한 이야기지만, 기술자들에게는 잘못된 사회와 기술의 비유로 여겨짐. 이 이야기는 선택받은 자들이 암흑 군주와 싸우며 몰락하는 세계를 다루고 있음.
     * Discworld의 우월성: Terry Pratchett의 'Discworld'는 기술과 사회에 대한 비유로 훨씬 우수함. Discworld는 기술적 호기심을 자극하며, 다양한 대안적 사고를 장려함.

Roundworld와 Discworld

     * Discworld의 특징: Discworld는 '반지의 제왕'과 반대되는 세계로, 아이러니와 과학적 규칙에 기반을 둠. Discworld는 이상한 규칙에 관한 이야기로, 마법사, 용, 엘프 등이 등장하지만, 이는 모두 풍자적임.
     * Discworld의 과학: Discworld는 'Science of Discworld'라는 메타 시리즈를 통해 과학적 요소를 탐구함.

Discworld의 규칙

     * Discworld의 이야기: Discworld는 선택받은 자들의 이야기를 풍자하며, 일반인들이 협력하여 문제를 해결하는 이야기를 다룸. 주요 시리즈로는 Unseen University, City Watch, Witches, Death 소설이 있음.
     * Vetinari와 길드: Ankh-Morpork의 지배자인 Vetinari는 권력을 미세하게 조정하며, 길드 간의 균형을 유지함. 그는 Discworld의 안티-선택받은 자로, 시스템이 원하는 방향으로만 개입함.

Discworld의 신과 수도승

     * Discworld의 신: Discworld에는 신들이 존재하지만, 대부분 은퇴 상태로, Discworld는 사실상 무신론적 우주임. 신들은 믿음에 따라 존재가 결정되며, Discworld는 신들의 계획에 구속되지 않음.
     * 시간 수도승: 시간 수도승은 역사를 자유롭게 유지하며, 현실의 감사관들을 막아냄.

엘프와 내러티비움

     * 엘프의 본질: Discworld의 엘프는 기생적이고 매력적이지만, 상상력이 없고 인간의 고통을 즐김. 이들은 내러티브를 파괴하는 반-내러티브적 존재임.
     * 내러티비움의 역할: 내러티비움은 Discworld의 가장 흔한 요소로, 내러티브 아이러니를 통해 Discworld의 역사를 만족스럽게 만듦.

Discworld의 목표

     * 진화와 발전: Discworld는 기술 혁신을 통해 과거에서 벗어나며, 무한 게임을 추구함. 이는 모두가 계속해서 더 나은 방식으로 게임을 할 수 있도록 함.
     * 내러티비움의 중요성: 내러티비움은 Discworld가 다양한 대안적 미래를 선택할 수 있게 하며, 선택받은 자들의 현실 포획을 막음.

특별한 세계

     * Discworld의 특수성: Discworld는 선택받은 세계로, 더 큰 생성력과 복잡성을 향해 발전하려는 경향이 있음. 이는 Discworld가 친절한 세계가 될 수 있는 이유임.
     * Roundworld와의 비교: Roundworld는 Discworld와 달리 특정한 목표가 없으며, 역사가 종종 불만족스럽고 엘프에 의해 쉽게 파괴될 수 있음.

   일단 이 글의 큰 주제나 맥락이 뭔지부터 알려주면 좋을거 같네요... 비유인지 진짜 서사시인지 .. 돌려까는건지...

   아 그냥 세계관 같은거였나보군요. 뭔가 테크 글인줄 알았어요

        Hacker News 의견

     * 이 작가는 많은 흥미로운 생각을 가지고 있음에도 불구하고, ""반지의 제왕""의 핵심 주제를 놓친 것 같음. 이야기의 주인공들은 약하고 거의 알려지지 않은 사람들이며, 그들의 선택이 세상을 구하는 데 중요한 역할을 함. 호빗들은 위대함이나 운명을 추구하지 않고, 그들이 선택할 수 있는 유일한 길을 따랐음.
     * ""Discworld""를 진지하게 받아들일수록 ""Roundworld""에 대해 더 똑똑해짐. Terry Pratchett는 그의 작품이 인생의 조언처럼 받아들여지는 것을 두려워했음. 그는 영국적 유머를 가지고 있었고, 그의 작품을 진지하게 받아들이지 않기를 바랐음.
     * ""반지의 제왕""의 규칙을 현실 세계에 적용하면 세상이 더 나빠질 수 있음. 그러나 ""반지의 제왕""은 사실보다는 감정에 관한 이야기임. 우정, 충성, 희망, 그리고 세상의 좋은 것들을 소중히 여기는 것에 관한 이야기임.
     * 대중문화에서 ""선택받은 자""의 문제를 언급함. ""Star Wars""와 Marvel Universe는 ""선택받은 자"" 문화의 극단적인 사례임. 이러한 이야기들은 사람들로 하여금 특별한 지도자를 찾게 만듦.
     * ""Discworld""와 ""Middle Earth""를 비교하지 않겠음. 오늘은 두 책을 평가하는 규칙을 만들고, 그것이 무엇을 성취했는지 보겠음.
     * Terry Pratchett의 Ankh-Morpork 묘사를 사랑했음. 혼란스럽고 기능 장애가 있는 도시이지만, 그 도시를 사랑하게 됨. Tolkien의 Mordor와 Shire 묘사는 그의 개인적인 경험에서 비롯되었음.
     * ""반지의 제왕""을 오용하는 사람들 때문에 이 작품이 훼손되지 않기를 바람. ""Discworld""의 두 번째 책을 읽고 있으며, 그 황당함이 많은 것에 대한 해독제처럼 느껴짐.
     * Tolkien은 비유적 해석을 경계하라고 했음. 그는 기독교인들로부터 비판을 받았지만, 이를 가볍게 무시했음. 그의 전기에서 이러한 점들이 다루어짐.
     * ""Discworld""의 대화 예술가로서의 Pratchett에 대한 언급이 부족함. 그의 책을 어디서든 열고 캐릭터들의 대화를 듣는 것만으로도 즐거움을 느낄 수 있음.
     * ""Discworld""와 ""반지의 제왕""을 둘 다 사랑함. 어느 하나를 선택할 필요가 없음. 두 작품 모두를 사랑하는 것이 더 좋음. ""Tiffany Aching"" 시리즈는 Pratchett의 도덕적 개념을 잘 보여줌.
"
"https://news.hada.io/topic?id=19655","Presenterm - 터미널에서 Markdown 슬라이드쇼 하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Presenterm - 터미널에서 Markdown 슬라이드쇼 하기

     * 터미널에서 마크다운 형식으로 프레젠테이션을 만들고 실행할 수 있는 도구
     * 이미지와 애니메이션 GIF 지원, 고도로 커스터마이징 가능한 테마, 코드 하이라이팅, PDF 형식으로 프레젠테이션 내보내기 등 다양한 기능을 제공
     * 단일 마크다운 파일로 프레젠테이션 구성 가능
     * kitty, iterm2, wezterm 같은 터미널에서 이미지와 애니메이션 GIF 지원
     * 색상, 여백, 레이아웃(왼쪽/가운데 정렬된 콘텐츠), 각 슬라이드의 푸터 등 커스터마이징 가능한 테마 제공
     * 여러 프로그래밍 언어에 대한 코드 하이라이팅 지원
     * 터미널에서 지원하는 경우 글꼴 크기 조정 가능
     * 선택적/동적 코드 하이라이팅으로 코드의 일부만 강조 가능
     * 열 레이아웃 지원
     * mermaid 그래프 렌더링
     * LaTeX 및 typst 수식 렌더링
     * 프레젠테이션 제목과 이름을 표시하는 소개 슬라이드
     * 슬라이드 제목 표시
     * 다양한 프로그래밍 언어의 코드 스니펫 실행
     * PDF로 프레젠테이션 내보내기 가능
     * 슬라이드의 일부를 일시 정지 가능
     * 사용자 정의 키 바인딩
     * 프레젠테이션이 변경될 때마다 자동으로 다시 로드하여 빠른 개발 루프 제공
     * 발표 중에 도움을 줄 수 있는 발표자 노트 정의 가능

   터미널은 정말이지...

   아이디어가 너무 좋네요!

   와 세상에 이건 뭐죠 ㅎㄷㄷㄷ 터미널 슬라이드쇼라니...!!!

   파워포인트 안쓰고 슬라이드쇼 만들겠다는 시도는
   W3C slidy를 시작으로 s3, s5, s6, s9… 유서깊은 역사가 있는데…

   거기에서 한발 더 나아가서… 터미널에서 바로 발표까지 하다니 재미있네요. 아쉬운 건… 아직은 터미널 그래픽 프로토콜(?!)이 표준화되지 않아서… 지원하는 터미널이 제한되는…

   FYI, 마크다운 기반 프레젠케이션 도구들…
   https://gist.github.com/johnloy/27dd124ad40e210e91c70dd1c24ac8c8
"
"https://news.hada.io/topic?id=19639","Vtm - 텍스트 기반 데스크톱 환경","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Vtm - 텍스트 기반 데스크톱 환경

     * 텍스트 기반 애플리케이션으로, 전체 사용자 인터페이스가 텍스트 셀 모자이크로 표현되어 TUI 매트릭스를 형성
     * 이 TUI 매트릭스는 자체 GUI 창이나 호환 가능한 텍스트 콘솔에 렌더링됨
     * 콘솔 애플리케이션을 감싸고 무한히 중첩될 수 있어 텍스트 기반 데스크톱 환경을 구성함
     * 지원 플랫폼
          + Windows 8.1 이상
          + *nix : Linux, macOS, FreeBSD, NetBSD, OpenBSD
     * 현재, 네이티브 GUI 창으로의 렌더링은 Windows 플랫폼에서만 가능하며, *nix 플랫폼에서는 터미널 에뮬레이터가 필요함.

        Hacker News 의견

     * 솔직히 궁금한 점은, 텍스트 기반 데스크톱 환경이 그래픽 인터페이스가 필요하고 tty에서 실행되지 않는다면 어떤 용도가 있는지에 대한 것임
     * 5년 전 큰 토론이 있었음 링크
     * 명백한 것을 놓치고 있는 것 같은데, 이게 터미널 멀티플렉서(예: tmux)인지, 아니면 타일링 터미널 에뮬레이터(예: iTerm 등)인지 궁금함
     * 우리는 완전한 순환을 겪고 있음. TUI를 대체하기 위해 GUI를 발명했는데, 이제는 TUI에서 GUI를 다시 구현했음. 터미널 만세임
     * 나는 마우스를 필요로 하지 않기 위해 터미널을 사용함. 많은 TUI 도구를 사용하지만, 이 도구는 절대 사용하지 않을 것임
     * 매우 부드러워 보임
          + 그러나 내 관점에서는 창을 끌고 크기를 조정하는 것은 윈도우 환경의 습관임. 아마도 이 도구는 마우스를 위한 tmux와 Neovim 같은 것일 수 있음
          + tmux에서는 내가 필요한 창 레이아웃이 2x2 패널의 고정 세트로, 이를 조정하고 전체 화면으로 전환하는 몇 가지 사전 정의된 방법이 있음
          + telescope와 nvim 같은 효과적인 도구 덕분에 모든 창을 정렬할 필요가 없어짐. 전환이 매우 효율적이고, 시각적인 것보다 정신적인 그림이 더 많음. 예를 들어, 대부분의 IDE에서 왼쪽에 있는 파일 트리가 필요하지 않음
     * 터미널 내부에 TUI 스타일의 창 관리자가 있는 것이 가능한지 항상 궁금했음. 이 프로젝트는 환상적이며, 만든 사람은 훌륭한 일을 했음
     * 이해하려고 노력 중임... tmux를 사용하고 있다면, 이런 도구로 전환하면 마우스 기반의 창(패널) 관리가 추가되는 것인지 궁금함
     * 일부 웹 앱이 이 순수 텍스트 디자인 언어를 채택했으면 좋겠음
     * Zellij에 이러한 아이디어가 통합되는 것을 보고 싶음
"
"https://news.hada.io/topic?id=19646","미 법무부, Google의 Chrome 매각 여전히 원해","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    미 법무부, Google의 Chrome 매각 여전히 원해

     * DOJ, Google에 Chrome 매각 요구
          + 미국 법무부는 Google이 Chrome 브라우저를 매각할 것을 요구하는 최종 제안서를 제출함.
          + Google은 검색 엔진의 우선 배치를 위해 파트너에게 지불하는 것을 중단해야 하며, Chrome을 매각해야 함.
          + Google은 경쟁사와의 새로운 협력이나 파트너십에 대해 사전 통보해야 함.
          + 인공지능 투자에 대해서는 매각 요구가 철회되었으나, 향후 투자에 대한 사전 통보는 필요함.
     * Google의 반응
          + Google은 법무부의 제안이 과도하며, 미국 소비자, 경제, 국가 안보에 해를 끼칠 것이라고 주장함.
          + Google은 검색 시장에서의 성공이 최고의 검색 기술을 제공한 결과라고 주장하며, 소비자들이 쉽게 기본 검색 엔진을 변경할 수 있다고 설명함.
     * 법적 배경
          + 법무부는 2020년에 Google을 상대로 반독점 소송을 제기함.
          + Google이 불공정한 계약을 통해 검색 시장에서의 지배력을 유지하고 있다고 주장함.
          + 2024년 판결에서 Google이 불법적인 독점을 유지하고 있다고 판결됨.
     * Google의 대응 제안
          + Google은 계약 구조를 재검토하고, 다양한 기본 검색 엔진 계약을 허용할 의향이 있다고 밝힘.
          + 파트너와의 수익 공유 계약을 단기화하고, Android 기기 제조업체에 더 많은 유연성을 제공할 계획임.
     * 향후 전망
          + Google은 법무부의 제안에 대해 항소할 계획이며, 법적 절차가 수년간 이어질 가능성이 있음.
          + 이번 사건은 새로운 행정부 하에서의 첫 주요 반독점 사건으로, 기술 산업에 대한 강경한 입장을 보여줄 것으로 예상됨.

        Hacker News 의견

     * Safari에서 검색 엔진을 변경하는 과정은 간단하지만, 많은 사용자가 이를 수행하지 않음. 기본 설정이 불공정한 이점을 가진다는 결론이 나옴
     * Chrome을 기본 브라우저로 설정하는 과정은 복잡하지만, 많은 사용자가 이를 수행하여 Chrome이 불공정한 이점을 가진다는 결론이 나옴
     * Google 독점 해체에 대한 효과적인 해결책이라고 믿지 않음. Google이 브라우저에 대한 검색 엔진 트래픽 비용을 지불할 수 없게 된다면, 개발과 발전을 지속할 비즈니스 모델이 궁금함
     * Google 소유가 아닌 Chrome이 어떻게 스스로를 지원하고 개발을 지속할 수 있을지 궁금함
     * Chrome 확장 프로그램에 의존하는 모든 애플리케이션은 어떻게 될지 궁금함
     * Google의 행동을 싫어하지만, 이것이 좋은 일이라고 보지 않음
     * Google이 Chrome을 판매하고 Chromium에 대한 통제를 유지한다면, 사용자에게 이익이 되지 않을 것임. 새로운 Chrome은 아마도 더 나쁜 스파이웨어와 함께 올 것임
     * Chromium 유지 관리가 감사받지 못하는 일이며, 이를 수행할 수 있는 엔티티가 보이지 않음. Linux보다 훨씬 크고, 개발자들은 자원봉사자가 아닌 직원임
     * Google이 Chromium을 독립적인 비영리 단체로 분리하고, 이를 오랜 기간 동안 자금을 지원하도록 요구받는 것이 최선의 결과일 것임. 비영리 단체는 Google이나 다른 회사와의 결탁을 피하기 위해 경쟁 회사의 감독이 필요함
     * 기술의 주요 경쟁자들이 해외에 있음. 검색 독점 해체가 미국이나 신생 기업에 도움이 되는지 의문임
     * Chrome 자체에 무슨 일이 일어나든, Chromium에서 주요 논란이 되는 변화를 추진하는 사람이 중요함. Manifest v3와 Web Integrity API는 Google 팀이 모든 Chromium 기반 브라우저에 영향을 미치는 예임
     * 웹 브라우저를 소유하는 회사가 문제가 아님. 웹 브라우저, OS, 검색 엔진을 소유하는 회사도 문제가 아님. 해결책이 문제를 실제로 해결할 수 없는 이유를 모르겠음. DOJ가 업계 전반에 걸친 반독점 문제를 더 빨리 해결할 수 없는 이유를 모르겠음
     * Chrome을 누가 구매할지 의문임. 새로운 브라우저를 만드는 회사가 없고, MS도 브라우저 게임에서 물러났음. Mozilla와 Firefox는 10년 동안 관련성이 없었음. 유일한 구매자는 사모펀드일 수 있으며, 이는 버려진 브라우저 플러그인을 구매하여 추적하고 더 많은 광고를 보여주는 것과 비슷함
     * Chromium 프로젝트를 자세히 보면, 다양한 구성 요소에 특화된 팀들로 구성되어 있음. 그 팀의 대다수 구성원은 Google 직원임. DOJ의 Google에 대한 결정이 이를 어떻게 바꿀지 모르겠음. Google 직원을 프로젝트에서 제외시키면 누가 그들을 대체할지 의문임
     * Google은 아마도 이 문제를 뇌물로 해결할 수 있을 것임. 돈이 필요하지 않을 수도 있음. 검색 결과의 유리한 위치만으로도 가능할 것임
"
"https://news.hada.io/topic?id=19647","Show GN: 지피티 내가한 질문목록 한눈에 보는 크롬 확장 프로그램 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show GN: 지피티 내가한 질문목록 한눈에 보는 크롬 확장 프로그램

   ChatGpt 탭에서 질문이 길어지면 어떤 질문을 했는지 기억하는 데 어려움을 겪는 분들이 있나요?
   저의 경우, 질문을 한 눈에 보기 위해 따로 메모를 한 다음 답변을 복사해야 하는데 귀찮아서 크롬 확장 프로그램을 만들었습니다.
   프로토타입 수준이긴한데, 써보시고 평가주시면 감사하겠습니다~!
    1. 하나의 탭 내에서 여러 질문들을 확인 가능합니다
    2. 질문과 답변을 마크다운으로 복사가능합니다.

   https://chromewebstore.google.com/detail/…

   기능 추가 요청드립니디:
     * 백업기능. 자꾸 예전 챗 지워짐.

   처음엔 지정폴더에 마크다운 다운, 그 다음은 대화별 동기화 (같은 대화에 나중에 더 추가하는 경우 있음. 이때 대화 id는 안변하는데 내용은 추가됨), 그 다음은 노션/옵시디안 연동 및 클라우드 싱크되면 좋겠네요.
     * 검색기능. 모아놓고 검색해야 의미있을거같네요. 1단계는 단순 부분일치 검색, 그 다음은 유사도-최신순 기반 더 빠르고 성능좋은 검색 되면 좋겠네요.
     * 메타데이터로 자동 분류: 처음엔 날짜, 답변모델별, 첨부파일 존재여부, 웹검색 수행 여부등 태그기반으로 하다가 나중엔 대화에서 키워드를 뽑아 자동생성태그를 달아주면 좋겠네요

   소중한 피드백 감사합니다.
   다음 버전은 말씀주신 기능들을 하나씩 추가해보겠습니다~!

   좋은 익스텐션 개발해주셔서 감사합니다. 아무리 크롬 익스텐션 마켓플레이스 뒤져봐도 저런 기능 있는 앱이 없는 것 같습니다. 만드시고 llm, chatgpt 서브레딧 같은 곳에 올리시면 엄청 흥할 것 같습니다!

   빠른시일내에 동기화 기능 소식 들고오겠습니다 :)

   혹시 익스텐션 소개글의 스크린샷 (썸네일들?) 은 어떻게 만드셨나요? 깔끔하고 이해하기가 쉽네요 :+1:
"
"https://news.hada.io/topic?id=19645","Ask GN: 깃허브에 정체모를 계정들은 무엇일까요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Ask GN: 깃허브에 정체모를 계정들은 무엇일까요?

   https://github.com/candidtrapdoo/traefik-oidc-auth/stargazers

   해당 별 기록을 보면 모두 2025년 2월 ~일에 가입된 것을 볼 수 있습니다.
   저 계정들을 타고 스타를 누른 저장소를 확인하면 모두 go에다가 정체모를 계정들이 스타를 눌렀습니다.

   이에 대해 아시는 분이 계실까요?

   계정이 폭파되었네요 https://github.com/candidtrapdoo

   크립토 쪽에서 깃헙 계정에 대해서 이득을 주는 것들이 있습니다. 그거 작업 치는걸꺼에요.

   가짜 GitHub Star 암시장 추적하기 (Dagster, dbt, BigQuery를 이용)
   이거 글에서 보듯이 GitHub Star를 돈 주고 살 수 있는데요. 아마도 그런게 아닐까 합니다.

   그런데 제가 추적한거로는 모두 구매자로 보이는것없이 수상한 계정끼리만 연결되어있는데 어떻게 된걸까요?

   let's go!!!!!!!
"
"https://news.hada.io/topic?id=19628","자기 개선 추론자를 가능하게 하는 인지 행동","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        자기 개선 추론자를 가능하게 하는 인지 행동

     * 인지적 행동이 자기 개선 추론자를 가능하게 하는 방법, 또는 매우 효과적인 STaRs의 네 가지 습관
     * 테스트 시 추론: 언어 모델이 복잡한 문제를 더 길고 신중하게 생각할 수 있게 하는 강력한 패러다임임. 강화 학습(RL)은 검증 가능한 작업에서 언어 모델의 자기 개선을 촉진할 수 있지만, 일부 모델은 상당한 성과를 보이는 반면 다른 모델은 빠르게 정체됨. 예를 들어, Qwen-2.5-3B는 동일한 RL 훈련 하에서 Llama-3.2-3B를 크게 능가함.
     * 내재적 속성: 효과적인 자기 개선을 가능하게 하는 내재적 속성에 대한 질문이 제기됨. 이를 조사하기 위해 검증, 백트래킹, 하위 목표 설정, 역방향 체인닝이라는 네 가지 주요 인지적 행동을 분석하는 프레임워크를 도입함. 이 행동들은 전문가 인간 문제 해결자와 성공적인 언어 모델이 사용하는 것임.
     * 실험 결과: Qwen은 자연스럽게 이러한 추론 행동을 보이는 반면, Llama는 초기에는 부족함. 제어된 행동 데이터셋을 사용한 체계적인 실험에서 이러한 추론 행동을 포함한 예시로 Llama를 준비시키면 RL 동안 상당한 개선을 이루어 Qwen의 성능과 일치하거나 능가함을 발견함.
     * 추론 행동의 중요성: 정답의 정확성보다는 추론 행동의 존재가 중요한 요소임. 올바른 추론 패턴을 포함한 잘못된 솔루션으로 준비된 모델이 올바른 솔루션으로 훈련된 모델과 유사한 성능을 달성함.
     * 계속된 사전 훈련: OpenWebMath 데이터를 사용하여 추론 행동을 증폭시키는 필터링을 통해 Llama 모델이 Qwen의 자기 개선 궤적을 따라갈 수 있게 함. 초기 추론 행동과 개선 능력 간의 근본적인 관계를 확립하여 일부 언어 모델이 추가 계산을 효과적으로 활용하는 이유를 설명함.
"
"https://news.hada.io/topic?id=19664","하스켈과 OCaml의 모나드 접근 방식 비교","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        하스켈과 OCaml의 모나드 접근 방식 비교

  Haskell의 모나드: 우아한 추상화

     * 모나드는 단순히 Promise와 유사한 개념이 아닌 강력한 추상화 도구
     * Monad 타입클래스를 통해 다양한 컨텍스트(Maybe, [], IO, State)에서 코드 재사용
     * 제네릭 함수(예: sequence, mapM)가 모든 모나드에서 활용 가능
     * do 표기법으로 가독성 높은 코드 작성 가능
     * 하나의 패턴으로 다양한 계산 맥락을 일관되게 표현

  OCaml의 다른 접근법: 실용주의

     * 타입클래스 대신 모듈 시스템과 함수자 사용
     * 문법적 지원(예: do 표기법) 부재로 모나드 코드가 더 장황함
     * 직접적인 부수 효과 허용으로 모나드가 필수적이지 않음
     * option, result 타입의 직접 사용과 모듈 수준 추상화 선호
     * 지역적으로 이해하기 쉬운 코드 작성 가능

  언어 설계 철학의 차이

     * Haskell: 순수 함수형으로 효과 관리를 위해 모나드 필수
     * OCaml: 부수 효과 허용으로 더 직접적인 코드 작성 가능
     * 추상화, 명시성, 타입 시스템의 역할에 대한 철학적 차이
     * Haskell은 일관성과 추상화, OCaml은 명확성과 실용성 강조

  결론적 견해

     * Haskell의 일관된 추상화 방식이 복잡한 시스템에서 특히 매력적
     * OCaml의 직접적 접근법은 즉각적인 이해가 중요한 상황에서 유용
     * 타입클래스와 문법적 지원이 하스켈에서 특별히 우아한 코드 구조화 가능
     * 두 접근법 모두 각자의 장점이 있으며 상황에 따라 적절한 선택 필요
"
"https://news.hada.io/topic?id=19612","Awesome MCP Servers - Model Context Protocol 지원하는 서버들 목록","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Awesome MCP Servers - Model Context Protocol 지원하는 서버들 목록

     * AI 모델이 로컬 및 원격 자원과 안전하게 상호작용할 수 있도록 지원하는 MCP 서버 목록
     * 파일 액세스, DB 연결, API 통합, 마케팅, 메모, 클라우드 플랫폼, 자동화, 소셜 미디어 등을 통해 AI 기능을 확장가능한 것들을 모두 정리
     * 지원 클라이언트 : Claude Desktop, Zed Editor, Sourcegraph Cody, Continue, Cursor, Enconvo,..

MCP 서버 구현 유형

     * 파일 시스템: 로컬 파일 읽기, 쓰기, 관리 지원
     * 버전 관리: GitHub, GitLab 등과 연동하여 코드 분석 및 PR 관리 지원
     * 클라우드 스토리지: Google Drive 등과 통합하여 파일 액세스 지원
     * 데이터베이스: PostgreSQL, MySQL, MongoDB 등 다양한 DB와 연결 가능
     * 커뮤니케이션: Slack, Linear와 연동하여 메시지 및 이슈 관리 가능
     * 모니터링: Sentry, Raygun 등을 통해 오류 추적 및 성능 모니터링 지원
     * 웹 검색 및 스크래핑: Brave Search, Google News, Puppeteer 등과 연동하여 웹 정보 검색 가능
     * 위치 서비스: Google Maps API 지원
     * 마케팅: Open Strategy Partners 등의 마케팅 도구 통합
     * 메모 및 노트: Obsidian, Notion, Apple Notes 등과 연동
     * 클라우드 플랫폼: Kubernetes, Cloudflare, Tinybird 등과 연결
     * 자동화: Windows CLI, Apple Shortcuts, Shell 등의 시스템 제어 지원
     * 소셜 미디어: Bluesky, YouTube, Spotify 등과 통합하여 콘텐츠 관리 가능
     * 금융: CoinMarket, Stripe 등의 금융 데이터 액세스 지원
     * 연구 및 데이터: ArXiv 논문 검색, Ancestry 유전자 데이터 분석 지원
     * AI 서비스: OpenAI, Perplexity, HuggingFace Spaces 등 AI 모델과 직접 연결
     * 가상화: Docker, E2B 등과 연동하여 안전한 코드 실행 가능
     * 개발 도구: Postman, OpenRPC 등과 연동하여 개발 지원
     * 데이터 시각화: VegaLite를 이용한 데이터 시각화 가능
     * ID 관리: Keycloak을 통한 사용자 인증 및 권한 관리

MCP 서버 관리 도구

     * mcp-get: MCP 서버 설치 및 관리를 위한 CLI 도구
     * Remote MCP: 원격 MCP 서버 통합 및 관리 지원

   요즘 mcp 공부해보고 있는데 진짜 대단하네요..

   어디서부터 공부해가면 좋을까요?
   좋은 자료가 있으면 부탁드려봅니다.

   두 분 답글 감사합니다. :-)

   저는 아래 github 참고하면서 해보고 있어요
   https://github.com/modelcontextprotocol/servers

   Model Context Protocol (MCP) 개발 방법
   댓글로 달려다가 별도 토픽으로 올려봅니다!
"
"https://news.hada.io/topic?id=19687","유럽, "DARE"로 슈퍼컴퓨팅을 위해 다시 한번 RISC-V에 베팅","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 유럽, ""DARE""로 슈퍼컴퓨팅을 위해 다시 한번 RISC-V에 베팅

     * 유럽의 기술 기업 38곳이 참여한 Digital Autonomy with RISC-V in Europe(DARE) 프로젝트가 출범
          + 목표: 유럽의 슈퍼컴퓨터 및 고성능 머신에 사용할 프로세서 유닛 개발
     * 유럽은 이미 수년간 RISC-V 기반 슈퍼컴퓨팅에 관심을 가져왔으나 첫 엑사스케일 시스템은 Arm 아키텍처를 사용함
     * 미국과의 기술 독립성 확보를 위한 시도

DARE 프로젝트 주요 내용

     * EuroHPC Joint Undertaking 지원, **Barcelona Supercomputing Center(BSC-CNS)**에서 주도
     * 3개의 칩렛(chiplet) 개발 목표 설정:
          + 벡터 수학 가속기: HPC 작업용, 바르셀로나의 Openchip에서 주도
          + 차세대 추론 칩렛: 네덜란드의 Axelera AI에서 주도
          + 범용 프로세서: 독일의 Codasip에서 주도
     * 프로젝트 리더인 Osman Unsal: ""유럽의 디지털 주권을 위한 복잡한 기술 개발 도전""이라고 언급

프로젝트 일정 및 자금 지원

     * 첫 단계는 6년 기한, 3개 RISC-V 칩렛을 3년 내 개발 목표
     * 총 2억 4천만 유로(약 3,600억 원) 규모의 자금 지원
     * Axelera AI는 EuroHPC로부터 6,160만 유로(약 920억 원) 확보

Axelera AI의 역할 및 성과

     * Axelera AI의 현재 칩은 주로 네트워크 엣지에서 AI 모델 구동
     * 차세대 Titania 칩렛은 서버급 작업에 최적화 예정
     * 주요 특징:
          + 4개의 가속 코어 포함
          + 각 코어는 행렬 곱셈 누산(MAC) 유닛 포함
          + 프로그래머블한 RISC-V 제어 코어 포함
          + 뉴럴 네트워크 활성화 함수 처리용 DSP 포함
          + 내장 SRAM으로 메모리 내 처리(in-memory processing) 지원
     * 200 INT8 TOPS 성능 달성 가능 (소비 전력은 15~20W)
     * Titania는 프로세서 코어와 멀티다이 시스템을 통해 확장 계획

Codasip의 역할 및 목표

     * 현재 32비트 임베디드 및 64비트 애플리케이션급 RISC-V 코어 보유
     * DARE 프로젝트를 통해 고성능 RISC-V 프로세서 포트폴리오 확장 목표
          + AI, 빅데이터 처리, 슈퍼컴퓨팅 작업 포함

     * Openchip의 벡터 가속기에 대한 구체적인 세부 사항은 공개되지 않음

글로벌 RISC-V 동향

     * 유럽 외에도 다른 국가에서 RISC-V 채택 확산 중
          + 인도: 자국 기술 독립을 위한 RISC-V 채택
          + 중국: Alibaba의 XuanTie C930 발표 → PC부터 자동차까지 적용 가능
     * 미국에서는 중국의 RISC-V 기술 접근을 제한하려는 움직임 존재

        Hacker News 의견

     * 중국이 최근 RISC-V 칩 사용을 전국적으로 확대하는 정책을 발표할 예정임. EU와 중국 간의 협력이 기대됨
     * RISC-V의 발전을 위해서는 Raspberry Pi와 유사한 프로젝트에 자금을 지원하여 열성적인 사용자들에게 유용한 기기를 제공해야 함
          + 소프트웨어 포팅을 위한 저렴한 컴퓨터가 필요함
          + 준비된 소프트웨어가 없다면 하드웨어는 무의미함
     * 일반 컴퓨팅에도 적용되어야 하며, 정부 사무실 컴퓨터부터 시작해야 함
          + x86에 Windows 11을 설치한 것보다 느릴 수는 없음
     * hpcasia25의 관련 슬라이드와 FPGA 에뮬레이션 플랫폼 보고서가 있음
          + Semidynamics의 Atrevido 코어와 Vitruvius VPU를 사용한 벡터 프로세서 개발 중임
          + 최근 보고서에 따르면 16,384 비트의 벡터 길이와 16개의 레인을 가짐
          + 32개의 코어, 공유 L3 캐시, HBM 접근을 목표로 함
     * 수출 규제에 의해 통제되지 않는 OS와 프로그래밍 언어에 의존해야 함
     * 유럽이 슈퍼컴퓨팅 주권을 위해 노력하는 것에 대해 회의적임
          + 유럽은 자체 칩을 만들 가능성을 포기했으며, 중국의 공급에 의존할 수밖에 없음
     * ARM이 100% 영국 유럽 기업이라는 아이러니가 있음
     * Axelera의 칩은 Google의 텐서 프로세싱 유닛과 유사한 공식을 따름
          + 현재 아키텍처에 집중되어 있으며, 행렬 곱셈의 근본적 한계를 벗어날 수 있는 새로운 것이 필요함
     * 유럽의 투자 규모가 너무 작음
          + 6년 동안 2억 4천만 유로의 자금 지원은 부족함
          + 미국의 기업들은 수십억 달러를 투자하고 있음
          + 38개의 파트너에게 자금을 분산하는 대신 집중된 투자 필요함
          + EU는 기술에 대해 진지하지 않음
          + 미국과의 신뢰가 떨어지고 있는 상황에서 더 큰 투자가 필요함
     * RISC-V를 슈퍼컴퓨팅 주권을 위해 선택한 사람들은 결국 중국 제품을 구매할 가능성이 높음
"
"https://news.hada.io/topic?id=19602","소비자 심리가 AI 제품 설계에 미치는 영향","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        소비자 심리가 AI 제품 설계에 미치는 영향

     * AI 제품의 인터페이스가 너무 복잡하여 일반 사용자가 사용하기 어려움
          + 사용자 친화적이고 직관적인 인터페이스 필요성이 증가
     * 사용자 심리 ( 이케아 효과, 선택의 역설, 밴드왜건 효과, 소유 효과, 문전 걸치기) 를 AI에 적용해보기

이케아 효과 : The IKEA Effect

     * 이케아 효과는 사용자가 제품 제작에 참여하면 그 가치를 더 높게 평가하는 현상을 의미함
     * 이는 달걀 이론과 유사하지만 차이가 있음
          + 달걀 이론: 과정이 너무 쉬우면 사용자가 기여했다고 느끼지 못함
          + 이케아 효과: 사용자가 직접 만든 것이기에 가치를 더 높게 평가함
     * AI 제품 디자인에서의 시사점
          + AI 제품은 개인화를 강조해야 함
          + 사용자가 직접 설정하고 맞춤화할 수 있는 AI 비서, 챗봇 등이 더 높은 만족도를 제공할 수 있음
          + 예: 이메일 관리 AI가 사용자의 스타일에 맞게 설정 가능하도록 하면 사용자는 더 가치 있게 느낄 것임

선택의 역설 : The Paradox of Choice

     * 선택지가 너무 많으면 불안, 선택 마비, 불만족을 초래함
          + 2000년 연구에서 6가지 잼을 제공한 경우 30%가 구매했지만, 24가지 잼을 제공한 경우 3%만 구매함
          + 선택지가 많을수록 사용자는 오히려 결정을 내리기 어려워함
     * AI 제품에서의 문제점
          + 현재 AI 제품들은 너무 많은 옵션을 제공하여 사용자 혼란을 초래함
          + 예: Gemini의 모델 선택 UI는 너무 복잡하여 사용자 경험을 저해함
          + 최적의 모델을 자동으로 선택해주는 기능이 필요함
     * 잘 설계된 AI 제품의 예시
          + Midjourney: 하나의 프롬프트, 하나의 이미지 모델, 4가지 결과 제공 → 단순하고 직관적임
          + Granola: 회의 요약 AI로, 깔끔한 UI와 최소한의 사용자 입력만 필요함
     * AI는 사용자의 부담을 줄이고 직관적인 경험을 제공해야 함
          + 지나치게 많은 기능과 설정보다는, 사용자가 원하는 작업을 쉽게 수행할 수 있도록 설계하는 것이 중요함

밴드왜건 효과 : The Bandwagon Effect

     * 밴드왜건 효과: 사람들이 다른 사람들이 하는 행동을 따라하는 심리적 현상
          + 예: 틱톡 댄스, 스키니진 유행, ALS 아이스버킷 챌린지 등
          + 스타트업에서는 바이럴 성장과 네트워크 효과를 유발함
     * AI 제품의 문제점
          + 현재 대부분의 AI 제품이 소셜 기능이 부족하여 사용자들이 개별적으로 탐색해야 함
          + 예: ChatGPT는 사용자가 공유할 수 있는 네트워크 기능이 부족함
          + 틱톡에서는 ChatGPT 프롬프트를 공유하는 문화가 활발하지만, 공식적으로 이를 지원하는 기능이 없음
     * 이미지 생성 모델도 개선 필요
          + Midjourney의 ""Explore"" 기능은 인기 있는 이미지를 볼 수 있도록 제공하지만, 내 친구나 네트워크에서 생성한 콘텐츠를 볼 수 있는 기능이 부족함
     * AI는 현재 ""싱글 플레이어"" 상태
          + 앞으로 더 많은 네트워크 기반 기능과 협업 기능이 추가될 가능성이 큼
          + 사용자들이 더 쉽게 정보를 공유하고, AI 사용 경험을 소셜 환경에서 확장할 수 있도록 설계해야 함

소유 효과 : The Endowment Effect

     * 소유 효과: 사람들이 자신이 소유한 물건을 실제 가치보다 더 높게 평가하는 심리적 현상
          + 1990년 연구에서 머그컵이나 펜을 무작위로 제공한 후 교환할 기회를 줬을 때,
            소유한 물건을 더 높은 가치로 평가하는 경향이 나타남
     * AI 제품에서의 시사점: 개인화의 중요성
          + 사용자가 직접 설정하고 개인화된 경험을 쌓을수록 제품에 대한 애착이 증가
          + 예: 이메일 AI가 사용자의 스타일을 학습하면, 이를 쉽게 포기하기 어려워짐
          + Granola가 사용자의 피드백을 반영해 맞춤형 요약을 제공하면, 사용자는 제품을 더 가치 있게 느낄 것임
          + 감성적인 AI(예: NSFW 챗봇)도 사용자와의 개인적인 연결이 깊어질수록 대체하기 어려워짐
     * 좋은 AI 디자인은 ""이 제품이 나만을 위한 것""이라는 느낌을 줘야 함
          + AI가 사용자 데이터를 학습하여 개인화된 경험을 제공할수록 충성도가 증가
          + 보유 효과를 극대화하려면 AI 제품이 점점 더 사용자에게 최적화되도록 설계해야 함

문전 걸치기 기법 : The Foot-in-the-Door Technique

     * 문전 걸치기 기법: 작은 요청을 먼저 수락하게 한 후, 점진적으로 더 큰 요청을 수락하도록 유도하는 심리적 전략
          + 1966년 연구에서, 작은 ""Drive Carefully"" 표지판을 집 앞에 설치한 사람들이
            2주 후 더 큰 광고판을 설치하는 요청에도 더 쉽게 동의함
          + 기업에서는 무료 체험 → 유료 구독 전환 같은 방식으로 널리 활용됨
     * AI 제품에서의 적용 사례
          + 대부분의 AI 서비스는 프리미엄 모델을 사용하여 무료 체험 후 결제를 유도함
          + AI가 새로운 사용 행태를 유도하려면, 처음엔 작은 기능을 제공하고 점진적으로 확장하는 것이 효과적임
     * 법률 AI 예시
          + 법률 AI가 처음부터 모든 업무를 자동화하면, 보수적인 법률 업계에서 거부감이 클 수 있음
          + 따라서 초기에는 계약서 검토 같은 간단한 작업을 도와주고,
            사용자가 익숙해지면 서류 초안 작성 같은 더 강력한 기능으로 확장해야 함
     * AI 제품은 사용자가 자연스럽게 더 강력한 기능을 사용하도록 유도해야 함
          + 초기에는 부담 없는 기능 제공 → 점진적으로 사용자가 더 깊이 활용하도록 설계하는 것이 중요함

최종 생각: 복잡성 증가 문제

     * 현재 AI 제품들은 너무 복잡함
          + 제품팀이 AI의 모든 기능과 가능성을 과시하려는 경향이 있음
          + 하지만 절제된 설계가 더 좋은 사용자 경험을 제공함
     * 소비자와 기업 간 경계가 흐려지는 추세
          + 예: Cursor, ElevenLabs, Elicit, GPTZero, Granola, HeyGen, Midjourney, Perplexity, Runway, Suno 등은
            소비자와 기업 시장에서 동시에 채택됨
          + 하지만, 많은 AI 제품들이 기업용처럼 느껴지며 소비자 친화적인 설계가 부족함
     * AI 제품 설계의 핵심 원칙
          + 사용자는 단순한 제품을 원함: 너무 많은 선택지보다 직관적인 경험이 중요함
          + 기능을 명확하게 설명해야 함: 사용자가 어떤 기능을 사용할 수 있는지 쉽게 이해할 수 있도록 설계해야 함
          + 사용자가 자연스럽게 기능을 확장하도록 유도: 점진적으로 더 강력한 기능을 사용할 수 있도록 설계해야 함
     * 결론
          + AI 제품은 소비자 중심의 직관적인 경험을 제공해야 함
          + 복잡성을 줄이고, 핵심 기능을 강조하며, 사용자가 자연스럽게 적응하도록 설계하는 것이 중요함
"
"https://news.hada.io/topic?id=19688","Lynx - 웹 기술 기반 네이티브 앱 개발 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Lynx - 웹 기술 기반 네이티브 앱 개발 도구

     * 틱톡(ByteDance)이 만든 더 빠르고 부드러운 React Native 대체제
     * Lynx는 웹 기술을 사용해 네이티브 UI를 생성할 수 있도록 돕는 기술 패밀리
          + 하나의 코드베이스에서 모바일과 웹등 다양한 플랫폼에 대응 가능
     * TikTok과 같은 대규모 앱에서 성능 중심의 UI 프로그래밍 및 Rust 기반 툴링을 제공
          + 기존 크로스 플랫폼 개발의 한계를 넘어서기 위해 오픈소스화 결정

대규모, 고속의 네이티브 앱 제공

     * 모바일 앱 사용자에게 비네이티브 경험은 부정적인 인식으로 이어짐
          + 빈 화면, 0.1초의 애니메이션 지연, 비일관된 UI 등은 신뢰도 하락 요인
     * 다양한 플랫폼에 대응하면서 동일한 경험을 구축하는 것은 여전히 어려운 문제임
     * Lynx는 단일 코드베이스에서 다양한 플랫폼을 지원하여 개발 시간과 비용 절감 가능
     * TikTok은 Lynx를 점진적으로 도입해 성공적인 결과 도출
          + TikTok Studio, Shop, LIVE 등 다양한 플랫폼에서 Lynx 사용
          + 대형 이벤트(Disney100, Met Gala 등)에서도 Lynx 활용

웹 커뮤니티에 영감 제공 및 성장 촉진

     * 웹 플랫폼은 본래 문서 기반으로 설계되었지만 점차 앱 개발 플랫폼으로 진화함
     * PhoneGap(Cordova)와 React Native는 웹 기술과 네이티브 UI를 연결한 선구적 사례임
     * Lynx는 웹 기술의 강점을 유지하면서 명확한 제약과 확장을 통해 앱 개발에 최적화된 모델 제공
          + 웹 기술 준수: 마크업 및 CSS 지원
          + 확장 및 차별화: 웹과는 다른 명확한 설계 의도 적용

마크업 및 CSS 기반 디자인 가능

     * Lynx는 웹 개발 방식의 친숙함 유지
          + CSS 애니메이션 및 전환 효과 지원
          + CSS 선택자 및 변수 지원으로 테마 설정 가능
          + 클리핑, 마스킹 등 최신 CSS 비주얼 효과 지원

메인 스레드의 효율적 사용

     * 사용자 스크립트를 두 개의 런타임으로 나누어 처리
          + 메인 스레드 런타임: PrimJS(JavaScript 엔진) 기반으로 UI 초기 렌더링 및 우선 이벤트 처리
          + 백그라운드 런타임: 기본 사용자 코드 실행
     * 두 가지 핵심 기능 제공
         1. Instant First-Frame Rendering (IFR): 첫 프레임 즉시 렌더링 → 블랭크 화면 제거
         2. Main-Thread Scripting (MTS): 고우선 순위 이벤트를 부드럽게 처리
     * Lynx 기반 UI는 평균 2~4배 빠른 실행 성능 제공

Lynx 오픈 소스화

     * Lynx는 ByteDance가 개발하고 TikTok에서 광범위하게 사용 중
     * TikTok은 Lynx 오픈 소스를 지원하고 기술 강화, 커뮤니티 활성화, 생태계 성장에 기여 예정

크로스 플랫폼 기술의 대중화

     * 기존 크로스 플랫폼 개발은 일부 주요 업체가 주도
     * Lynx는 단일 솔루션이 아닌 메타 인프라 제공 → 다양한 접근 방식 허용
     * ReactLynx: Lynx 기반의 React 스타일 컴포넌트화 및 선언적 UI 지원
     * Rspeedy(Rust 기반 번들러) 제공 → 빠른 빌드 및 모듈 페더레이션 지원
     * Lynx는 특정 프레임워크나 렌더링 백엔드에 종속되지 않음
          + Chromium, Flutter, React Native 등의 프로젝트에서 영감 받음
          + 브라우저에서 Lynx 구동 가능 → 데스크탑, TV, IoT 등으로 확장 가능

새로운 시작

     * Lynx는 이미 프로덕션에서 사용되고 있으며 버전 3.x로 공개됨
     * 오픈 소스를 통해 투명한 개발 과정 공개 예정
     * 추가 컴포넌트, 그래픽 렌더러, 프레임워크 등은 추후 공개 예정
     * 오픈 소스 커뮤니티와 협력해 크로스 플랫폼 개발의 한계를 뛰어넘고자 함
     * 커뮤니티 피드백 및 기여를 환영함

     * Lynx Family GitHub Repo

   미리 빌드된 Lynx Explorer를 사용하는 것을 개발 단계만 그럴것 같고. 현실적으로는 Lynx Explorer를 build하는 과정에 effort가 들어가는 것으로 이해됩니다.

   React-Native에 관심이 많은데, 이 친구도 궁금하네요.

   위 내용은 공식 소개글인 Lynx: Unlock Native for More 에서 가져왔습니다.
"
"https://news.hada.io/topic?id=19619","Show GN: ezmcp - fastapi스타일로 간단하게 만드는 sse mcp 서버","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Show GN: ezmcp - fastapi스타일로 간단하게 만드는 sse mcp 서버

   MCP 서버에 대해서 이리저리 알아보고 테스트해보고 구현해보는 와중에 stdio모드와 sse모드에서 진짜 잠재력은 sse에 있다고 생각해서 최대한 간단하게 sse에만 특화된 형태로 구현해보았습니다.

   데코레이터를 통한 tools등록 기능과 순차적인 middleware 등록 기능, docs기능 등 여러 개를 fastapi에서 차용해보았습니다.

   아직 0.0.2버전이므로 많은 피드백 부탁드리겠습니다!
"
"https://news.hada.io/topic?id=19590","Mox – 현대적이고 안전한 오픈소스 올인원 이메일 서버 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Mox – 현대적이고 안전한 오픈소스 올인원 이메일 서버

     * 이메일 송수신을 위한 완전한 솔루션을 제공
     * IMAP4, SMTP, SPF, DKIM, DMARC, MTA-STS, DANE, DNSSEC 등을 지원하며, 명성 기반 및 콘텐츠 기반의 스팸 필터링, 국제화(IDNA), ACME 및 Let's Encrypt를 통한 자동 TLS, 계정 자동 구성, 웹메일을 포함
     * 10분 이내에 설정할 수 있는 퀵스타트 명령을 제공. 바이너리 다운받아 실행하고 출력된 DNS만 추가하면 메일서버 동작 끝
     * 현대적인 Go 코드베이스로, 자동화된 테스트와 통합 테스트가 풍부함
          + 인기 있는 메일 서버 및 클라이언트 소프트웨어에 대해 수동 테스트를 거쳤으며, Fuzz 테스트도 수행됨
          + 코드가 잘 문서화되어 있으며 관련 표준(RFC)과 교차 참조 지원
     * 오픈 소스 프로젝트, 소스 코드는 MIT 라이선스로 제공
     * 최신 릴리스는 v0.0.14로, 2025년 1월 20일에 출시됨.
     * 배경
          + Mox 개발은 2021년에 시작됨.
          + 이메일 소프트웨어 운영 및 유지 관리가 시간이 지남에 따라 복잡해져, 관리자들이 몇몇 클라우드/호스팅 제공업체로 이메일을 이전하고 있었음
          + Mox는 모든 현대적인 이메일 프로토콜을 단일 애플리케이션에서 쉽게 사용하고 유지 관리할 수 있도록 구현함

   전 개인적으로 https://news.hada.io/topic?id=9960 이게 더 편한듯..ㅎ

   댓글보고 한번 설치해봤는데, 대시보드나 히스토리 같은 편의 기능들이 다 유료전용이라 좀 아쉬워 보이네요

   와...이런걸 제가 몇년을 찾은거같은데 드디어...!!!

   저도 과거 직장에서 postfix 와 dovecot 설치하고 설정하고 운영할때 진짜 고생을.... 하다가 이후 국내 상용 솔루션으로 넘어갔던 기억이 있네요.. 그리고 개인 서버에 메일 솔루션 설치한다고 이것저것 찾다가 iRedMail로 구축했었는데 이것도 간단하지는 않았었습니다..ㅠㅠ
   근데 단일 바이너리로 동작한다니 너무 좋네요! 다만... UI는 어...음... 외부 클라이언트 프로그램 지원하겠..죠? ㅎㅎ

   mox - 최신식 메일 서버 오픈소스
   2년전에 소개했었는데 그동안 뭔가 정리가 더 되고 설치가 더 간편해 진거 같아요

        Hacker News 의견

     * Postfix와 Dovecot 설정에 20시간 이상을 소비한 후, Rspamd 설정의 복잡함에 대해 불만을 표출함. Mox를 더 일찍 알았더라면 좋았을 것이라는 의견을 제시함
          + Postfix와 Dovecot의 복잡함에 지쳐, 단순한 단일 바이너리 메일 서버를 만들고 싶다는 생각을 했음
          + Mox를 검토할 예정이며, Postfix와 Dovecot에 대한 지식이 어느 정도 있음
     * 몇 달 전부터 Mox를 사용하기 시작했으며, 개인 메일 서버에 적합한 솔루션이라고 평가함
          + 가장 간단한 메일 서버 중 하나이며, 유지 관리에 거의 시간을 들이지 않음
          + 백업 및 업데이트가 몇 분 안에 완료됨
          + 단순한 웹 인터페이스가 '구식'으로 오해받기도 함
     * 더 많은 사람들이 대형 광고 기술 회사의 '무료' 이메일 제공자에 의존하지 않고 자신만의 이메일을 운영하길 바람
          + 인터넷에서의 균형이 필요하다는 의견을 제시함
     * 새로운 현대적 이메일 솔루션의 등장을 반가워하며, 작은 자가 호스팅 이메일 제공자의 부활을 기대함
          + Stalwart도 좋은 솔루션으로 언급됨
     * Mox 설정 경험을 공유하며, 문서와 빠른 시작 가이드가 유용하다고 평가함
          + 웹메일이 기본적으로 공용 IP에서 접근 불가능한 점에 놀랐으며, HTTPS로의 기본 리디렉션이 없음을 지적함
          + 리버스 프록시 뒤에서 서비스가 제공되길 희망함
     * 소프트웨어 제작자에게 몇 가지 질문을 제시함
          + 웹메일 클라이언트의 2FA 지원 여부
          + Thunderbird에서의 2FA 가능 여부
          + BEC 공격에 대한 사용자 정의 규칙 설정 가능 여부
          + 웹메일 클라이언트의 배너 기능 여부
     * 21년간 이메일 서버를 운영하다가 유지 관리의 어려움으로 유료 솔루션으로 전환한 경험을 공유함
          + 이메일 흐름에 대한 방대한 지식을 얻었으며, 이는 대체 불가능한 것임
          + 직접 운영해보며 깊이 이해한 후 유료 솔루션으로 전환할 것을 추천함
     * 이메일 서버를 자가 호스팅할지 고민 중이며, 외부 의존성을 줄이는 아이디어를 좋아함
          + forwardemail.net을 메일 서버로 사용 중이며, Snappymail을 통해 웹 브라우저로 접근함
     * Mox와 Maddy의 비교를 요청하며, Mox의 안티바이러스 추가 지원 여부에 대해 궁금해함
     * 데스크톱 이메일 클라이언트 추천을 요청하며, macOS/Linux에서 사용할 수 있는 클라이언트를 찾고 있음
          + Thunderbird 사용 시 몇 가지 문제가 있었음을 언급함
"
"https://news.hada.io/topic?id=19673","MCP와 API 비교 설명","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             MCP와 API 비교 설명

     * MCP (Model Context Protocol) 는 AI 모델이 외부 도구 및 데이터 소스와 상호작용하는 방식을 표준화한 새로운 개방형 프로토콜임
     * USB-C 포트가 여러 기기를 연결하는 방식을 단일화하듯이, MCP는 AI 시스템이 다양한 도구 및 데이터 소스와 연결하는 방식을 단일화함

기존 API보다 MCP를 사용하는 이유

     * 전통적인 API 통합은 각 도구 및 서비스마다 별도의 코드 작성, 인증 방식, 오류 처리, 유지 보수가 필요함
     * API는 각 문에 맞는 별도의 열쇠를 사용하는 것과 같음
          + 각 서비스나 도구별로 개별 통합이 필요하고 문서화, 인증, 오류 처리 및 유지 보수가 복잡함

MCP의 등장 배경

     * MCP는 Anthropic에서 시작된 프로젝트이며, Claude와 같은 AI 모델이 도구 및 데이터 소스와 쉽게 상호작용하도록 설계됨
     * 현재는 오픈 소스로 공개되어 여러 회사와 개발자가 채택 중임
     * AI 도구 상호작용의 새로운 표준으로 자리잡아가는 중임

MCP vs 기존 API 비교

     * 통합 노력: MCP는 단일 표준, 기존 API는 개별 통합 필요
     * 실시간 통신: MCP 지원, 기존 API 미지원
     * 동적 발견: MCP 가능, 기존 API 불가능
     * 확장성: MCP는 플러그 앤 플레이, 기존 API는 추가 통합 필요
     * 보안 및 제어: MCP는 일관성 유지, 기존 API는 다름

MCP와 기존 API의 주요 차이점

     * 단일 프로토콜: 한 번 MCP로 통합하면 여러 도구와 서비스에 연결 가능
     * 동적 발견: AI 모델이 사전에 코딩 없이 사용 가능한 도구를 자동으로 검색 및 상호작용 가능
     * 양방향 통신: 실시간으로 정보를 가져오고 작업을 수행할 수 있음 (예: WebSocket과 유사)

MCP의 양방향 통신이 중요한 이유

     * 데이터 가져오기: AI 모델이 서버에서 필요한 정보 검색 → 예: 일정 확인
     * 작업 수행: AI 모델이 서버에 작업 수행 명령 → 예: 회의 일정 변경, 이메일 전송

MCP의 작동 원리: 아키텍처

     * MCP 호스트: Claude Desktop과 같은 AI 애플리케이션
     * MCP 클라이언트: MCP 서버와 연결을 유지하며 명령 및 데이터 교환
     * MCP 서버: 특정 기능을 노출하고 로컬 또는 원격 데이터 소스와 연결
     * 로컬 데이터 소스: 파일, 데이터베이스 등
     * 원격 서비스: 외부 API 및 인터넷 기반 서비스

     * MCP는 복잡한 로직을 처리하는 것이 아니라 AI 모델과 도구 간 데이터 흐름을 조정하는 역할

실제 MCP 클라이언트 예시

     * Python 스크립트(client.py)가 Gmail, Slack, 캘린더 앱 등과 상호작용
     * 단일 프로토콜 사용으로 복잡한 통합 과정을 제거하고 빠르게 기능 추가 가능

MCP 사용 예시

  1. 여행 일정 도우미

     * 기존 API 사용: Google Calendar, 이메일, 항공사 예약 API 등 별도 코드 작성 및 인증 필요
     * MCP 사용: 단일 MCP 프로토콜로 일정 확인, 항공권 예약, 이메일 전송 가능

  2. 고급 IDE (지능형 코드 편집기)

     * 기존 API 사용: 파일 시스템, 버전 관리, 패키지 관리자 등 개별 통합 필요
     * MCP 사용: MCP를 통해 통합 → 코드 추천 및 더 풍부한 컨텍스트 제공

  3. 복합 데이터 분석

     * 기존 API 사용: 개별 데이터베이스 및 시각화 도구와 수동으로 연결
     * MCP 사용: 단일 MCP 레이어로 여러 데이터 소스와 자동 상호작용 가능

MCP 구현의 이점

     * 개발 간소화: 한 번 작성하면 여러 도구에 적용 가능
     * 유연성: AI 모델 및 도구 교체 시 복잡한 재구성이 필요 없음
     * 실시간 응답성: MCP 연결이 활성 상태로 유지되어 실시간 업데이트 및 상호작용 가능
     * 보안 및 규정 준수: 일관된 접근 제어 및 보안 유지
     * 확장성: 새로운 기능 추가 시 간단히 새로운 MCP 서버 연결 가능

기존 API가 더 적합한 경우

     * 정밀하고 예측 가능한 상호작용이 필요한 경우 기존 API가 유리
     * 성능 최적화 및 제어가 필요한 경우 기존 API가 적합

  기존 API가 유리한 경우

     * 세밀한 제어 및 제한된 기능이 필요할 때
     * 성능 최적화가 중요한 경우
     * 최소한의 컨텍스트 자율성이 요구될 때

MCP 시작하기: 주요 단계

    1. 기능 정의: MCP 서버에서 제공할 기능 정의
    2. MCP 레이어 구현: MCP 프로토콜 사양에 따라 개발
    3. 전송 방식 선택: 로컬(Stdio) 또는 원격(Server-Sent Events/WebSockets) 결정
    4. 리소스/도구 생성: 노출할 데이터 소스 및 서비스 개발
    5. 클라이언트 설정: MCP 서버와 클라이언트 간 보안 연결 설정

요약

     * MCP: AI 에이전트가 외부 도구 및 데이터와 상호작용하기 위한 표준화된 인터페이스
     * API: 개별 통합이 필요하고 더 많은 수작업 요구

   MCP는 AI 모델이 외부 도구 및 데이터를 쉽게 통합하고 실시간으로 상호작용하도록 지원함

결론

     * MCP는 AI 모델이 외부 도구 및 데이터와 상호작용하는 단일화된 표준 프레임워크 제공
     * 단순한 API가 아니라 AI 애플리케이션이 보다 지능적이고 동적이며 맥락 중심의 상호작용이 가능하도록 돕는 강력한 연결 솔루션

   MCP가 JSON이 될 수 있을것인지 궁금함.

   MCP가 JSON이 되기에는 데이터 통신을 위한 규격도 아니고, 과하게 어렵다고 생각합니다.

        Hacker News 의견

     * MCP는 런타임에 도구를 추가할 수 있게 하여 사용자가 LLM 애플리케이션에 임의의 기능을 추가할 수 있게 함
          + MCP는 상태가 있으며 복잡하여 HTTP보다는 FTP와 더 유사함
          + 관련 블로그 게시물 링크 제공: 블로그 링크
     * 개발자가 MCP를 이해해야 하는 가장 중요한 점은 AI 애플리케이션에 추가 기능을 동적으로 로드하는 프로토콜이라는 것임
          + 자체 애플리케이션을 구축하는 경우 LLM이 제공하는 ""Tools APIs""를 사용할 수 있음
          + MCP는 애플리케이션 확장이 필요한 경우에만 고려할 필요가 있음
     * MCP가 이전의 API 레이어 시도와 어떻게 다른지에 대한 의문 제기
          + AI가 API 클라이언트를 작성하는 데 있어 사람만큼 똑똑하다면 왜 기계가 읽을 수 있도록 만들어야 하는지에 대한 의문
     * MCP는 Anthropic에 의해 만들어졌으며 널리 채택되고 있음
          + Apple App Store와 유사한 새로운 플랫폼 기회로 보임
          + GitHub, Stripe, Slack, Google Maps, AirTable 등에서 빠르게 채택되고 있음
     * ANP (AgentNetworkProtocol)라는 다른 프로토콜 추천
          + ANP는 MCP와 유사하지만 에이전트 간의 통신 문제를 해결하도록 설계됨
          + ANP는 P2P 아키텍처를 사용하고, W3C DID를 통한 분산 ID 인증을 사용함
     * MCP 서버를 수백 개 큐레이션하여 사람들이 접근하고 탐색할 수 있게 함
          + API를 통해 MCP 서버 검색 및 기능 식별 가능
          + MCP 서버 작성, 발견 및 호스팅을 위한 포괄적인 플랫폼을 만드는 것이 목표임
     * MCP는 HTML과 대략적으로 동등하며, 동적 ""도구"" 검색 등의 기능을 잘 해결함
          + 클라이언트 구현이 더 쉬울 수 있지만 표준화 부족, 미성숙함 및 비인간 가독성 문제 있음
     * 모든 주요 AI 모델이 이미 잘 알려진 API와 완벽하게 인터페이스하는 코드를 작성할 수 있음
          + 필요한 것은 API 문서뿐이라는 의견
     * MCP 프로토콜은 Language Server Protocol (LSP)와 매우 유사함
          + LSP는 원격 서버에서 실행될 때 지속적인 웹소켓을 사용하여 작은 요청에 대한 빠른 응답을 제공함
"
"https://news.hada.io/topic?id=19696","Y Combinator 20주년 기념 행사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Y Combinator 20주년 기념 행사

        Hacker News 의견

     * ""Founders at Work""라는 책이 Jessica에 의해 쓰여졌고, 그것이 내가 HN에 관심을 갖게 된 계기였음
          + YC는 처음부터 HN을 가지고 있지 않았고, 1년 후에 시작되었음 (2006년 10월, pg 프로필에서 확인 가능)
          + 책은 그 다음 해인 2007년에 출간되었음
     * PG가 창업자 여름 프로그램을 발표했을 때, 그 프로그램에 참여하고 싶었음
          + 내 삶의 상황상 YC에 참여할 수 없었지만, 이 커뮤니티가 내 삶에 큰 가치를 더해주었음
          + YC와 이 커뮤니티가 존재한다는 것에 항상 감사할 것임
     * HN 웹사이트에 몇 일 후 가입했음
          + HN 커뮤니티는 내 경력에 큰 영향을 주었고, 개발 커뮤니티와 같은 생각을 가진 사람들과 소통할 수 있게 해주었음
          + 내 게시물과 프로젝트가 홈 페이지에 도달했을 때 목소리를 낼 수 있었음
          + 이곳이 점점 커지면서 ""90년대 뉴스 그룹"" 같은 특성이 사라지고 있지만, 여전히 매일 방문할 가치가 있다고 생각함
     * HN은 내가 찾은 유일하게 좋은 인터넷 커뮤니티임
          + 모든 친절한 게시물과 댓글, 지적인 토론에 감사함
          + 모두에게 사랑을 보냄
     * YC 생일 축하함
          + YC는 많은 가치를 창출했고, 내 경력의 주요 전환점에 책임이 있음
          + Paul, Jessica, Robert, Trevor에게 감사함
          + 우연히도 reddit도 몇 주 후면 20주년을 맞이함
     * 18.5년 전의 https://news.ycombinator.com/item?id=1을 보는 것은 항상 재미있음
     * PG와 daang에게 감사함
          + HN 덕분에 첫 번째 보안 관련 직업을 얻었음
     * YC는 내 삶을 바꾸었고, PG, Jessica, 팀에게 감사함
          + 홈스쿨링을 받은 GED 소지의 솔로 창업자에게 기회를 준 것에 감사함
     * 9년 전 HN을 읽기 시작했음
          + 세 번째 스타트업이 실패했을 때 영감을 필요로 했고, 공유된 뉴스 중에서 다시 영감을 주는 이야기를 찾았음
          + 매일 이 사이트를 방문하게 되었음
          + 잘 다듬어진 토론과 배우는 것들을 좋아하고, 기술 트렌드를 놓치지 않는다고 느낌
          + 훌륭한 커뮤니티임
          + PG와 Dang에게 감사함
          + 모든 기여자들에게 고품질 콘텐츠에 감사함
     * 생일 축하하고 감사함
"
"https://news.hada.io/topic?id=19699","Factorio 학습 환경 – 공장을 건설하는 에이전트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Factorio 학습 환경 – 공장을 건설하는 에이전트

     * Factorio 게임을 기반으로 한 Factorio Learning Environment(FLE)는 장기 계획, 프로그램 생성, 자원 최적화를 테스트하는 환경임
     * FLE는 기본 자동화에서 복잡한 공장까지 확장 가능한 도전을 제공하며, 두 가지 설정을 포함함: 고정된 자원으로 24개의 구조화된 작업을 수행하는 'Lab-play'와 무한한 과제를 제공하는 'Open-play'.
     * FLE의 중요성
          + FLE는 코드 생성, 공간 추론, 장기 계획을 평가하기 위한 인프라, API, 메트릭을 제공함.
          + 에이전트는 자원을 추출하고 복잡한 생산 체인을 관리하며, 이를 통해 점점 더 복잡한 목표를 설정하고 달성해야 함.
     * 환경 및 에이전트
          + 에이전트는 Python API를 통해 환경과 상호작용하며, 프로그램을 제출하고 피드백을 받아 전략을 개선함.
          + 에이전트 프로그램은 생산 점수(PS)와 기술 발전을 나타내는 이정표를 생성함.
     * 실험 설정
          + 두 가지 실험 설정: 'Open-play'와 'Lab-play'.
          + 여섯 가지 최첨단 언어 모델을 평가: Claude 3.5-Sonnet, GPT-4o, GPT-4o-Mini, Deepseek-v3, Gemini-2-Flash, Llama-3.3-70B-Instruct.
     * Open-Play
          + 에이전트는 절차적으로 생성된 세계에서 ""가장 큰 공장을 건설""하는 목표를 가짐.
          + 생산 점수를 통해 에이전트의 능력을 평가하며, 더 뛰어난 모델은 더 높은 점수와 가파른 성장 곡선을 보임.
     * Lab-Play
          + 에이전트는 자원을 제공받고 제한된 시간 내에 목표를 달성해야 함.
          + 24개의 목표 엔티티를 생산하는 과제를 수행하며, 각 엔티티는 점점 더 복잡해짐.
     * 주요 통찰
          + 코딩 능력이 성능을 예측하며, 기술 투자와 계획이 성장을 주도함.
          + 공간 추론과 오류 복구는 주요 도전 과제임.
          + 모델은 서로 다른 프로그래밍 스타일을 보임.
     * 결론
          + 최신 LLM도 자동화 작업의 조정 및 최적화 문제에서 어려움을 겪음.
          + Factorio의 기술 트리의 복잡성은 AI 연구가 계속 발전하더라도 여전히 도전적인 평가 시나리오를 제공함.
          + FLE는 복잡하고 무한한 도메인에서 에이전트의 능력을 연구하기 위한 오픈 소스 플랫폼으로 제공됨.

        Hacker News 의견

     * Anthropic Factorio 연구소에 지원하고 싶음. 멀티모달 데이터 전송 여부가 궁금함. 최근 출시된 Qwen 2.5 VLM이 크기에 비해 강력해 보임
          + 공간 능력 부족에 대한 언급이 많음. 이미지 전송 여부와 관련된 생각이 궁금함
          + 이 작업이 놀라움. 지금 당장 이 프로젝트에 참여하고 싶음
          + MCP가 파이썬 라이브러리를 활성화하는 것이 자연스러운 필수 작업으로 보임
     * 강화 학습을 사용하여 포켓몬 레드를 이긴 팀에 대한 HN 게시물이 있었음. 이 접근법을 Factorio에 사용할 수 있을지 궁금함
          + Factorio의 주요 ""필수 작업""은 새로운 아이템과 과학 팩의 자동화 설정임
          + 보상 함수는 각 아이템의 생산 속도에 대한 작은 보상, 새로운 아이템 자동화에 대한 중간 보상, 새로운 과학 팩 자동화에 대한 큰 보상을 포함할 수 있음
          + Factorio 에이전트에게 ""큰 공장을 만들어라""라고 말하는 것은 포켓몬 레드 에이전트에게 ""게임을 이겨라""라고 말하는 것과 같음
     * 모든 모델이 다중 섹션 공장을 구축할 때 공간 계획에서 제한을 보였음
          + LLM이 공간 추론에 약한 이유는 훈련 데이터가 많지 않기 때문임
          + 공간 추론이 해결되면 어떤 추가적인 추론 능력이 나타날지 궁금함
     * 대규모 효율적인 공장을 자율적으로 구축하기 위해 LLM을 고급 에이전트로 사용할 수 있음
          + 자원 생산을 위한 목표 설정
          + 공장 그래프 생성 및 자원 운송 계산
          + 하드웨어 설명 언어로 그래프 매핑
          + 2D FPGA 레이아웃으로 컴파일
          + 계획을 구체적인 Factorio 디자인으로 매핑
     * 실험할 흥미로운 요소가 많음. 시간 관련 요소가 있는 실험실 시나리오가 좋은 아이디어로 보임
          + DOTA 2나 StarCraft 2 실험과는 다른 프레임워크 디자인이 마음에 듦
          + 레이아웃 최적화 벤치마크 계획이 있는지 궁금함
     * 이 스타일의 인터페이스에 대한 인간 플레이 벤치마크가 있는지 궁금함
          + 프로그램적 Factorio가 어떤 느낌일지 궁금함
     * 몇 년 후 모든 게임 내 상대가 게임 제어 API에 액세스하는 LLM이 될지 궁금함
          + 모델이 어려움을 겪는 특정 작업 유형이 있는지 궁금함
     * ""Lab Play"" 작업의 또 다른 카테고리로 밸런서 디자인이 흥미로울 것 같음
          + 작은 밸런서도 복잡할 수 있음
     * 더 큰 공장의 사진을 더 보고 싶었음
          + 현재 LLM의 큰 약점을 명확히 보여줌
          + 온라인 학습/적응에서 더 큰 개선을 기대함
     * 복잡한 시나리오가 몇 개만 있는 것이 흥미로움
          + ML 게임 에이전트가 게임 메커니즘을 제대로 배우려면 수백 개의 작은 퍼즐이 필요하다고 항상 생각했음
          + 시나리오를 프로그램적으로 생성하여 IQ 테스트 질문 은행처럼 사용할 수 있음
          + ML 에이전트가 더 큰 시나리오 은행에서 샘플을 평가할 때 더 빨리 학습한다고 가정함
"
"https://news.hada.io/topic?id=19635","피드를 제거하라 – 알고리듬이 당신의 사고를 지배하지 못하게 하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  피드를 제거하라 – 알고리듬이 당신의 사고를 지배하지 못하게 하기

     * 우리는 끓는 물 속의 개구리처럼 점진적으로 알고리듬에 의해 통제되는 상황에 놓였음
     * 소셜 미디어는 친구와 연결하기 위한 수단에서 기업이 ""우리의 소비를 통제하고 사고를 미묘하게 조작할 수 있는 시스템""으로 변모
     * 초기에는 Facebook과 Instagram 같은 앱을 우리의 선택으로 제어했지만, 이제는 무한한 알고리듬 콘텐츠가 우리의 피드를 채우고 있음. 이는 기업이 광고 수익을 극대화하기 위한 전략
          + 기업의 입장에서 사용자가 앱을 닫는 것은 수익 손실로 이어짐 → 사용자를 더 오래 앱에 머물게 하기 위해 알고리듬이 동작함
          + 예를 들어, 귀여운 강아지 사진을 자주 보면 알고리즘이 이를 학습해 비슷한 콘텐츠를 계속 노출
     * TikTok, Instagram 등의 창작자들은 우리가 보는 것을 통제하며, 이는 우리의 사고에 큰 영향을 줌
          + 알고리듬이 사용자의 분노와 극단적인 반응을 유도 → 참여율(engagement) 증가로 이어짐
          + 이는 사용자의 신념을 강화하고 반대 의견을 배제함으로써 고립된 의견의 형성으로 이어짐
          + 알고리듬이 분노와 극단주의를 강화하면서 피드백 루프 형성 → 사회적 분열 초래
     * 독립적인 사고를 형성하는 것이 중요한 시기에, 알고리듬에 의존하는 것은 우리의 능력을 파괴하고 있음
          + 이를 알고리듬적 안일함(Algorithmic Complacency) 이라고 부름
            → 알고리듬이 제공하는 정보에만 의존하게 되면서 비판적 사고 능력이 약화됨

주도권을 되찾기

     * 사고의 통제권을 되찾아야 할 때임. 문제를 인식했으니 이제 행동할 차례임
     * 소셜 미디어를 완전히 삭제할 필요는 없음. 친구와의 연결, 현실에서의 일시적 탈출, 그리고 오락의 원천으로 여전히 유용함
     * 다음과 같은 방법으로 알고리듬의 영향을 줄일 수 있음:
         1. 좋아하는 TikTok 창작자, Facebook 페이지, YouTube 채널의 페이지를 직접 방문하고, 개별적으로 북마크할 것.
         2. 피드를 통해 발견하지 않고도 관심 있는 주제에 대해 비디오를 만들거나 글을 쓰는 창작자를 찾아볼 것.
         3. 경험을 제어할 수 있는 플랫폼과 기능을 사용할 것 - Instagram의 '팔로잉' 피드, YouTube의 구독 페이지, Bluesky, Mastodon, RSS 피드 등.
         4. 알고리듬 피드가 참여를 유도하는 방식을 인식하고, 스크롤을 멈추고 숨을 고를 것.
         5. 이 문제에 대해 이야기할 것 - 친구와 가족이 피드가 그들의 주의와 신념을 어떻게 조작하는지 알지 못할 수 있음.
            개입이 없으면 극단적인 의견 강화와 그로 인한 사회적 결과는 더욱 심각해질 것
     * 인터넷은 당신을 위해 존재해야 함. 피드가 당신의 독립적인 사고 능력을 파괴하기 전에 통제권을 되찾아야 함.

결론: 인터넷이 당신을 지배하게 두지 말 것

     * 인터넷은 당신을 위해 위해 존재해야 함 → 인터넷에 휘둘리면 안 됨
     * 제어권을 가져올 것. 피드가 당신의 독립적 사고를 방해하기 전에 피드를 끊어야 함

        Hacker News 의견

     * 저자는 중간에 이를 인정하는 듯하지만, 이는 최근 Technology Connections의 비디오 Algorithms are breaking how we think의 요약임
          + Alec을 이 글의 영감/출처로 처음부터 명시적으로 인정했으면 좋겠다는 의견임
          + 그래도 비디오 링크를 제공한 점은 긍정적임
     * 소셜 미디어는 ""매체가 메시지다""라는 문구를 증명했음
          + LLM 분야의 새로운 것들이 나오면서, 이에 대해 냉소적이고 기계적인 관점을 가지게 되었음
          + 현재 인기 있는 소셜 미디어는 짧은 맥락 창에서 작동하도록 우리를 조건화하고 있음
          + 이는 고급 추론에 충분하지 않음
          + 따라서 소셜 미디어를 끄고 책을 읽는 것이 좋음
     * 추천 알고리즘을 좋아하는 부분이 있음
          + YouTube가 새로운 구독으로 전환된 비디오를 추천해준 경험이 있음
          + ""책임 있는"" 추천 시스템이 필요함
               o 발견의 즐거움을 제공하면서도 분노 유발 콘텐츠와 극단적 관점을 억제하는 시스템
               o 사회적으로 유익한 보상 함수로 훈련되어야 함
          + 기존 소셜 그래프 위에서 작동할 수 있을지 궁금함
     * Kyle Chayka의 Filterworld를 읽어보길 권장함
          + 알고리즘이 문화를 평평하게 만든다는 점을 잘 설명함
          + 취향과 큐레이션에 대한 논의가 가장 흥미로웠음
          + 알고리즘이 지루함으로 밀어붙이는 방식에 대해 설명함
          + 취향은 추상적이고 설명하기 어려운 것임
          + 예술 작품을 접할 때 즉시 평가하고 아름다움을 찾는 것이 중요함
          + 취향은 모호해야 하며, 놀라움과 도전, 위험을 필요로 함
          + 안전함은 지루함을 피할 수 있지만, 흥미를 잃게 만듦
          + 미적 수용 가능성의 경계가 점점 좁아지고 있음
     * Reddit은 내 삶에서 중요한 부분을 차지하고 있음
          + 작은 유럽 국가의 관련 서브레딧에서 좌우 정치 간의 영원한 전쟁이 벌어지고 있음
          + 건강하지 않으며, 인터넷에서 ""누군가 틀렸다""는 피드가 끝없이 이어짐
          + ""우파""는 미국 민주당의 정치적 입장과 대략적으로 일치함
          + 균형 잡히지 않은 서브레딧 때문에 휴식을 취할 때 다른 쪽이 더 많이 ""이기는"" 것을 보게 됨
     * 메시지를 수용할 사람들은 이미 오래전에 결론을 내렸을 것임
          + 피드 자체가 그들을 쫓아냈을 것임
          + 중독자를 사용을 멈추게 할 수 있을지 의문임
          + 성공 가능성이 높지 않다고 생각하지만, 틀리길 바람
     * 나에게 인터넷의 절정은 2000년대 중반 StumbleUpon이었음
          + 버튼 클릭 한 번으로 주제별로 가볍게 정렬된 랜덤 사이트를 찾을 수 있었음
          + 사람들이 가장 많은 조회수를 얻기 위해 경쟁하지 않았음
          + 오늘날의 피드는 알고리즘을 만족시키려는 사람들 때문에 덜 흥미로움
     * YouTube 시청 기록을 비활성화하고 Unhook을 설치했음
          + 이를 통해 모든 추천, 쇼츠 등을 숨김
          + 과거에 YouTube를 완전히 차단하려 했지만, 학습과 작업에 유용한 도구임
          + 새로운 접근 방식은 정보를 얻으면서도 끝없는 탐색과 수동적 소비로부터 나를 보호함
          + 훨씬 더 자유로워진 느낌임
     * 이 조언은 피드 없이 새로운 창작자를 발견하는 방법을 놓치고 있음
          + 불가능하다고 말하는 것은 아니지만, 그들이 이 분야에서 뛰어남
          + 많은 옛 방법들이 사라졌음
     * 대부분의 삶에서 신뢰할 수 있는 동료와 출처의 조언이나 정보를 의존해 왔음
          + 신뢰할 수 있는 참고 자료로 그들의 이유를 뒷받침할 수 있는 출처임
          + 지금까지 만난 알고리즘에는 포함되지 않음
"
"https://news.hada.io/topic?id=19674","Opsy - AI로 동작하는 SRE 동료","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Opsy - AI로 동작하는 SRE 동료

     * SRE(Site Reliability Engineers), DevOps 엔지니어, 플랫폼 엔지니어를 위한 지능형 CLI 도우미
     * AI를 활용하여 운영 문제 해결, 자동화, 기존 도구 통합을 지원하여 효율적인 업무 처리를 도움
     * ""도구를 에이전트로 활용하는 구조""를 채택하여, 각 도구(Kubernetes, Git, AWS 등)가 특정 도메인에서 전문 AI 에이전트로 동작하도록 설계됨
          + 이를 통해 안전성 강화, 컨텍스트 관리 최적화, 새로운 기능 추가 용이성을 확보
     * Opsy는 Anthropic의 Claude AI 모델을 사용하여 지능형 지원을 제공(API 키 필요)
     * 다양한 CLI 도구와 통합되며, 설치된 도구만 활용함
          + Git → 버전 관리 (git)
          + GitHub CLI → GitHub 작업 자동화 (gh)
          + kubectl → Kubernetes 관리 (kubectl)
          + AWS CLI → AWS 작업 (aws)
          + Helm → Kubernetes 패키지 관리 (helm)
          + Google Cloud CLI (gcloud) → GCP 관리 (gcloud)
          + Jira CLI → Jira 자동화 (jira)
     * 일반적인 자연어 명령어를 입력하면 자동으로 작업을 수행함
          + Repo 관리 : opsy 'Create a new private repository in datolabs-io organization named backup'
               o datolabs-io 조직에 'backup'이라는 비공개 Repo 생성
          + K8s 트러블슈팅 : opsy 'Check why pods in the production namespace are crashing'
               o 프로덕션 네임스페이스의 Pod가 크래시하는 원인을 확인하기
          + 로그 분석: opsy 'Find errors in the application logs from the last hour'
               o 지난 1시간 동안 발생한 애플리케이션 오류 로그 찾기
"
"https://news.hada.io/topic?id=19703","대규모로 Terraform을 운영하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        대규모로 Terraform을 운영하는 방법

     * 165,000개 이상의 클라우드 리소스를 625개의 Terraform 워크스페이스와 38개의 AWS 계정에서 관리
          + 170명의 엔지니어중 40명은 인프라 스페셜리스트
          + 매일 225회의 인프라 릴리스(terraform apply)와 723회의 플랜(terraform plan)을 수행
     * 이를 위해 Terraform Cloud를 도입하여 인프라 릴리스 프로세스를 자동화하고, 개발자들의 수작업과 오류를 줄였음

Terraform Cloud 도입 전의 문제점

     * 높은 AWS 접근 권한 필요 : 인프라 팀이 높은 수준의 AWS 접근 권한을 가져야 했음
     * 시간 소모적 작업 : 각 디렉토리에서 terraform apply를 실행하고 검토 및 승인을 반복해야 했으며, 한 번의 변경 사항이 120개 이상의 워크스페이스에 영향을 줄 수도 있었음
     * 인프라 드리프트 발생 : 예상치 못한 변경 사항이 누적되어, 적용 시 추가적인 검토와 조치가 필요

Terraform Cloud 도입 및 효과

     * 드리프트 제거 → 인프라 드리프트를 제거하여 위험과 개발자 부담을 줄였음
     * 개발자 시간 절약 → 연간 약 8,000시간의 개발자 시간 절약 (개발자 4명의 업무량에 해당)
     * 변경 사항 추적 가능 → 감사 로그를 통해 변경 사항을 추적하고 디버깅 용이
     * 스펙큘레이티브 플랜 지원 → 변경 사항을 자동으로 테스트하고 결과를 GitHub CI에서 직접 확인 가능

현재 Terraform Cloud 운영 방식

     * 자체 호스팅 : Terraform Cloud for Business를 자체적으로 설치하고, AWS 계정 내 ECS 클러스터에서 TFC 에이전트를 운영
     * 에이전트 풀 구성 : 120개의 에이전트를 개발 환경(40개)과 프로덕션 환경(80개) 으로 나누어 운영하여 높은 동시성 유지

중점적으로 모니터링하는 요소

    1. 에이전트 고갈 및 동시성 제한 → 에이전트 부족 시 온콜 담당자에게 알림
    2. 플랜 시간 → 개발 환경에서 플랜 시간이 4분을 초과하면 팀에 알림
    3. 인프라 드리프트 → 현재는 측정하지 않음 (드리프트가 거의 발생하지 않음)

품질 향상을 위한 최적화

     * TFC CLI 개발 : 여러 워크스페이스에서 변경 사항을 CLI로 자동 검토 및 승인할 수 있도록 함
     * 알림 시스템 구축 : 슬랙 알림을 통해 Terraform 적용이 누락되지 않도록 자동화
     * 워크스페이스 자동 관리 : Terraform을 사용해 625개의 워크스페이스를 관리하고, 태그를 적용하여 소유 팀을 구분
     * Terraform Cloud 사용량 분석 : TFC API를 활용하여 상태 버전 데이터를 수집하고, 리소스 사용량과 성장 추이를 파악
     * Terraform State 백업 : 상태 파일을 S3 버킷에 자동 백업하여 장애 발생 시 복구 가능하도록 함
     * 워크스페이스 종속성 관리 : 모듈 종속성 트리를 작성하여, 워크스페이스가 감시해야 할 디렉토리를 자동 설정
     * 프로바이더 업그레이드 자동화 : Dependabot을 활용하여 프로바이더를 월간 주기로 업그레이드하고, 자동화를 통해 관리 부담을 줄임

향후 개선 사항

     * 단계적 롤아웃 : main 브랜치 기반 릴리스에서 다단계 배포(개발 → 스테이징 → 프로덕션) 방식으로 전환
     * 대형 워크스페이스 분할 : 현재 625개의 워크스페이스를 1500개 이상으로 세분화하여, 플랜 및 적용 시간을 단축하고 변경 영향 범위를 축소하려 함
     * 알림 기능 향상 : 슬랙 알림의 재할당 기능 추가 및 tfc review 명령어 자동 생성 기능 도입
     * 에이전트 자동 스케일링 : EKS 기반의 자동 스케일링 시스템을 도입하여 가변적인 워크로드를 효율적으로 처리할 계획
     * 자체 개발 도구 오픈소스화 : 내부적으로 개발한 다양한 도구를 오픈소스로 공개하여, 다른 팀들도 활용할 수 있도록 할 계획
"
"https://news.hada.io/topic?id=19675","uBlock Origin, Chrome 스토어에서 더 이상 이용 불가","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 uBlock Origin, Chrome 스토어에서 더 이상 이용 불가

     * uBlock Origin은 CPU와 메모리 효율성을 주요 특징으로 하는 광범위한 콘텐츠 차단기임.
          + ""ublock.org"" 사이트와는 전혀 관련이 없음.
     * 광고 차단기가 아닌 다양한 콘텐츠 차단기로, 기본적으로 여러 필터 목록이 로드되고 적용됨

기본 필터 목록

     * uBlock Origin 필터 목록
     * EasyList (광고)
     * EasyPrivacy (추적)
     * Peter Lowe’s 광고 서버 목록 (광고 및 추적)
     * 온라인 악성 URL 차단 목록

추가 기능

     * 사용자가 선택할 수 있는 추가 목록 제공 (예: 쿠키 경고, 오버레이 등)
     * JavaScript를 로컬 또는 전역적으로 차단할 수 있는 기능
     * 필터 목록의 항목을 무시할 수 있는 전역 또는 로컬 규칙 생성 가능
     * 다양한 고급 기능 제공

오픈 소스

     * 무료로 제공되며, 공개 라이선스(GPLv3)를 따름.
     * 사용자에 의해, 사용자를 위해 개발됨.
     * 필터 목록을 유지하는 사람들에게 기여를 고려할 수 있음.

        Hacker News 의견

     * Google이 시장 지위를 남용할 것이라는 것은 예상할 수 없는 일이었음
          + Chrome에서 벗어나게 된 이유는 Google의 프라이버시 개선 이야기가 믿기 어려웠기 때문임
          + 성능 개선을 위해서는 확장 프로그램을 저성능으로 표시하면 충분했을 것임
          + Google이 정말 개선을 원했다면 검색 엔진을 통해 사이트를 재정렬할 수 있었을 것임
          + 이는 사람들의 웹 경험을 개선하기 위한 것이 아니었음
     * Mozilla가 Firefox를 통해 확장 프로그램을 제공하는 강력한 브라우저로 자리 잡을 기회를 인식하길 바람
          + 최근 Mozilla가 확장 프로그램에 집중하고 있는 것으로 보임
          + 하지만 Mozilla의 Firefox에 대한 헌신이 충분히 강하지 않을까 걱정됨
          + Firefox의 사용 통계가 증가하길 바람
     * uBlock Origin Lite가 Chrome에서 잘 작동하고 있음
          + 이론적으로는 문제가 있을 수 있지만, 실제로는 차이를 느끼지 못함
          + 광고 차단이 YouTube에서도 잘 작동하고 있음
          + 페이지 로딩 속도가 더 빨라진 것 같음
     * 많은 사람들이 Chrome에 익숙해져 Firefox로 전환하지 않음
          + Google이 이 싸움에서 이긴 것 같음
          + 사람들은 습관을 유지하기 위해 많은 불편을 감수함
     * Fedora 시스템에서 Chrome을 블랙리스트에 추가했지만, Google이 내 시스템에서 확장 프로그램을 비활성화함
          + 이로 인해 계획을 가속화해야 했음
          + 이제는 빠르게 전환해야 할 때임
     * uBlock Origin Lite가 Manifest v3와 호환되며 Chrome Web Store에서 추천됨
     * Chrome을 주 브라우저로 사용한 지 10년 이상 되었지만, 이제는 완전히 벗어남
          + Firefox를 사용하면서 내 감정이 많이 변했음을 느낌
          + Chromium 기반 브라우저를 사용할 때마다 불편함을 느낌
          + Firefox로 전환하길 권장함
     * Firefox와 Chrome을 비교하며 사용 중임
          + 전환을 고려하는 사람들에게 큰 차이가 없음을 알림
          + 일부 사이트에서만 문제가 발생함
          + uBlock Origin을 계속 사용할 수 있어 만족함
     * Google이 Manifest V2 확장 프로그램을 비활성화했을 때 Firefox로 전환함
          + 설정을 내보낼 수 없었기 때문에 결단을 내림
"
"https://news.hada.io/topic?id=19684","우리는 전기차를 잘못 충전하고 있습니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         우리는 전기차를 잘못 충전하고 있습니다

     ""복잡하고 비용이 많이 드는 충전 인프라가 전기차(EV) 도입을 제한하고 있음""

     * 전기차로의 전환을 가속화하기 위해 가장 중요한 것은 강력한 공공 EV 충전 인프라를 구축하는 것이지만, 공공 전기차 충전소는 건설 비용이 매우 높음
          + 소비자들은 전기차가 기존 차량처럼 장거리 여행을 포함한 모든 요구를 충족하기를 기대함
     * 현재 선진국에서는 약 90%의 충전이 자택서 이루어지지만, 나머지 10%의 공공 충전이 전기차 운전자에게는 매우 중요함
          + 배달 트럭, 택시, 아파트 거주자, 학생, 여행 가족 등에게 공공 충전 인프라 부족이 문제로 작용함
          + 2022년 Forbes 조사에 따르면, 전기차 소유자의 62%가 충전 문제로 인해 여행 계획을 변경한 경험이 있음
     * 국제에너지기구(IEA) 보고서에 따르면, 중국에서는 충전 인프라에 대한 투자가 전기차 성공에 있어 보조금보다 4배 더 효과적임

전기차 충전의 원리

     * 충전소는 AC 전력을 DC 전력으로 변환해 배터리에 공급하는 역할 수행
     * 충전 시 다음 조건이 충족되어야 함
          + 배터리 전압이 임계치를 초과하지 않아야 함
          + 배터리 온도가 설정된 한계를 넘지 않아야 함
          + 전력망에서의 전류가 일정 값을 초과하지 않아야 함
     * 전기 충격 방지를 위해 접지(grounding)가 중요함
          + 접지가 깨지면 충전 포트는 갈바닉 절연(Galvanic Isolation)을 통해 안전 보호함
          + 갈바닉 절연은 전류가 회로 간에 흐르지 않도록 회로를 물리적으로 분리함
     * 충전소의 갈바닉 절연은 변압기(transformer)로 수행됨
          + 변압기는 고주파 교류(AC)로 변환된 전력을 통해 절연 수행

갈바닉 절연은 매우 비쌈

     * 갈바닉 절연이 충전 장비 비용의 약 60%를 차지함
          + 300kW 포트당 전력 전자 장치 비용: 약 $90,000
               o 그중 $54,000이 갈바닉 절연 비용에 해당
          + 4포트 충전소의 전력 전자 장치 총 비용: 약 $360,000 (절연 비용만 $200,000 이상)
     * 갈바닉 절연은 충전 장치의 크기와 무게를 증가시킴
     * 온보드 충전기(OBC)에서 고속 충전이 어려운 이유도 갈바닉 절연의 크기와 비용 때문임

갈바닉 절연을 제거할 수 있을까?

     * 갈바닉 절연을 제거하면 충전 장비 비용 및 에너지 손실이 절반 이상 감소 가능
     * 문제 해결 방안:
          + 이중 접지(double ground) 적용
               o 두 개의 접지선을 사용해 하나의 접지가 끊어져도 다른 접지가 보호 역할 수행
               o 접지 연속성 감지 회로 추가 → 접지 손상 시 충전 중단
          + 버크 레귤레이터(Buck Regulator) 적용
               o 입력 전압이 배터리 전압보다 높을 경우 전류 과부하 방지
               o 버크 레귤레이터는 기존 갈바닉 절연 비용의 10% 미만, 전력 손실은 20% 미만

공공 전기차 충전의 미래

     * 현재 온보드 및 공공 충전 방식은 복잡하고 비용이 과도하게 높음
          + 기존 4단계 충전 과정에서 3단계 제거 가능
               o 활성 정류기(active rectifier) 단계만 유지하고, 필요 시 저비용 버크 레귤레이터(buck regulator) 추가 가능
          + 안전성 강화:
               o 이중 접지(double ground) 및 접지 연속성 감지 추가
               o 기존 갈바닉 절연 수준 이상의 안전성 확보 가능
     * 직접 전력 변환(DPC, Direct Power Conversion) 방식의 장점
          + 장비 비용 절감: 충전 장비 비용이 50% 이상 감소
          + 에너지 효율 개선: 2~3% 개선
          + 충전소 설치 및 유지 비용 감소 → 수천 개의 충전소를 몇 년 내 확충 가능
          + 충전 인프라 확충으로 전기차 보급 촉진
     * 갈바닉 절연 제거 논의 필요
          + 전기차 충전 과정의 간소화와 비용 절감이 필수적임
          + 기술 커뮤니티에서 갈바닉 절연 제거에 대한 논의가 필요함
          + 갈바닉 절연 제거는 전기차 충전 인프라 강화의 첫 단계가 되어야 함

        Hacker News 의견

     * 기사 속 깊이 묻혀 있는 클릭베이트 헤드라인이 암시하는 바: 자동차 충전기는 너무 복잡하고 비쌈. 더 간단하고 저렴하게 만들면서 안전성을 유지할 수 있음. 이렇게 하면 더 많은 충전소를 건설할 수 있음
     * 빠른 충전 문제 대신 표준화된 배터리 팩에 초점을 맞추면 좋겠음. 50-100kWh 배터리를 소유하고 싶지 않음. 그 안의 충전을 사용하고 그에 대해 기꺼이 비용을 지불하고 싶음
     * 일반인에게는 설득력 있게 들릴 수 있음. 하지만 규제나 다른 엔지니어링 전통이 갈바닉 절연이 안전에 필요하다고 결정하지 않았다면 이 기사를 쓸 필요가 없었을 것 같음
          + 갈바닉 절연은 물리적으로 안전하고, 접지 감지는 능동적인 안전 조치임
          + 현재 시스템에서도 두 개의 접지선을 넣을 수 있음
          + 접지선이 끊어져도 신호를 가질 수 있는 방법이 있는지 궁금함
          + 칩이 안전하지 않은 방식으로 고장 날 수 있는지 궁금함
     * 기사를 읽으면서 왜 시장에서 성공하지 못했는지 궁금함. 저자가 언급했듯이, 20년 전에 프로토타입으로 기술이 있었음. 왜 Tesla와 다른 전기차 제조업체들이 다른 방향으로 갔는지 궁금함
     * 농업과 석유를 보조하는 방식으로 이 인프라에 대한 보조금을 설정할 수 있다면 좋겠음
     * 큰 문제는 새로운 빠른 충전 표준이 필요하다는 것임. 이는 추가 접지 연결로 인해 기존의 빠른 충전 표준과 호환되지 않음. 전 세계적으로 이미 도로에 있는 4천만 대의 전기차에 쓸모없게 만듦
     * 모든 두 주차 공간마다 gfci와 차단기를 재설정할 수 있는 방법이 있는 동전 투입식 120V 콘센트를 요구해야 함. 많은 이점이 있음
          + 어디를 가든지 밤새 충전할 수 있는 곳이 있을 것임
          + 설치된 장소당 가장 저렴하여 훨씬 더 많은 장소를 제공함
          + 임차인도 전기차를 안전하게 구입하고 가정 충전을 할 수 있음
          + 동전 투입식 120V는 귀중한 구리로 된 케이블보다 훨씬 견고함
          + 과도한 주차를 억제함
     * 두 개의 접지선이 필요하지 않음. CP는 PE(접지)로 2.74K의 직렬 저항을 가진 다이오드를 가짐. EVSE가 CP를 통해 푸시/풀 파형을 보내고 푸시만 읽으면(다이오드 기억) 올바르게 연결되었음을 알 수 있음
          + 파일럿 전류의 반환 경로는 PE 접촉을 통해 이루어짐. PE가 저항이 낮다는 것을 감지하고 이중으로 확인할 수 있음. 이상적으로는 훨씬 작은 직렬 저항을 원할 것임
     * 기본적으로 절연 변압기를 제거하고, 라인 전압(약 7.2kV)을 간단한 벅 컨버터를 통해 자동차에 공급함
          + 갈바닉 절연 대신 연속성을 모니터링하는 중복 접지 커넥터를 사용함
          + 이에 동의하지 않음. EVSE 측에 너무 많은 책임을 부여함. 만약 문제가 발생하면 이를 차단할 수 있어야 함. 비상 피로 디스커넥트 같은 것이 의무화된다면 조금 더 신뢰할 수 있을 것 같음
     * 갈바닉 절연 충전 포트의 자재 및 조립 비용을 킬로와트당 약 $300으로 추정함. 공공 충전소의 단일 300-kW 포트에는 약 $90,000의 전력 전자 장치가 포함되며, 이 중 약 $54,000은 절연 링크에 해당함
          + 샘플 빌드의 구체적인 BOM과 이를 뒷받침하는 mouser 링크를 보고 싶음
          + 군사/우주 등급 프리미엄을 지불하거나 규모의 경제가 비용을 낮추지 않는 매우 틈새 부품을 사용하는 것처럼 보임
"
"https://news.hada.io/topic?id=19634","AI 도구가 연구 논문의 오류를 발견하고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       AI 도구가 연구 논문의 오류를 발견하고 있음

     * 최근 AI 도구들이 연구 논문에서 계산, 방법론, 참고 문헌의 오류를 찾아내고 있음
     * 지난해, 검은색 플라스틱 조리기구에 암을 유발하는 화학물질이 포함되어 있다는 연구 결과가 보도됨
          + 하지만 연구의 수학적 오류로 인해 실제 화학물질 농도가 안전 한계치보다 10배 낮았음이 밝혀짐
          + 인공지능(AI) 모델이 이 오류를 몇 초 만에 발견할 수 있었음

AI 기반 연구 논문 오류 탐지 프로젝트

  Black Spatula Project

     * 오픈소스 AI 도구로 약 500개의 논문을 분석해 오류를 탐지
     * 콜롬비아의 독립 AI 연구원 Joaquin Gulloso가 프로젝트를 조율하고 있으며, 8명의 개발자와 수백 명의 자문단이 참여 중
     * 오류 목록은 공개되지 않았으며, 오류 발견 시 연구자에게 직접 연락해 수정 유도 중

  YesNoError

     * Black Spatula Project에서 영감을 받아 시작된 프로젝트
     * 창립자이자 AI 기업가인 Matt Schlicht가 주도
     * 전용 암호화폐로 자금 지원받아 운영
     * 현재까지 약 37,000개의 논문을 두 달 만에 분석 완료
     * 오류가 발견된 논문은 웹사이트에 표시되지만, 대부분은 아직 전문가 검증 전 상태
     * 장기적으로는 ResearchHub(암호화폐로 박사 연구자에게 보상)와 협업해 오류 검증 계획

연구자 및 저널에 AI 도구 사용 장려

     * 연구자가 논문 제출 전, 저널이 논문 게재 전 AI 도구를 사용해 오류 사전 탐지 유도
     * 오류 및 연구 부정 방지를 통해 과학적 신뢰성 강화 기대

학계의 반응 및 우려

     * 연구 무결성 전문가들은 프로젝트에 신중하게 긍정적 반응
     * 틸뷔르흐 대학교의 Michèle Nuijten 연구원은 다음과 같은 우려 제기:
          + AI 도구의 정확도가 명확히 검증되지 않으면, 오류 지적이 잘못될 경우 평판 손상 우려
     * 린네 대학의 법의학적 메타과학자 James Heathers는 다음과 같이 지지 발언:
          + ""형편없는 논문을 철회하는 것보다 작성이 훨씬 쉽다""
          + AI가 논문을 선별하고 추가 검토를 유도하는 데 유용할 수 있음

AI 도구의 작동 방식

     * 대형 언어 모델(LLM) 사용해 논문의 오류 탐지
          + 논문에서 표, 이미지 등 정보를 추출 후 복잡한 명령어(프롬프트) 생성
          + AI 모델이 여러 번 논문을 분석해 다양한 유형의 오류 탐색 및 결과 교차 검증 수행
          + 논문 분석 비용: 논문 길이 및 프롬프트 복잡도에 따라 15센트~수달러 수준

오탐(False Positive) 문제

     * Black Spatula Project → 약 10%의 오탐 발생
          + 모든 오류는 전문가 검증 필요 → 전문가 부족이 가장 큰 병목 현상
     * YesNoError → 10,000개 논문 중 수학적 오류 100개 검증 결과 90% 이상이 실제 오류로 확인됨
          + YesNoError는 오탐률 감소 작업 중이며, 학계와 지속적 피드백 수용 중

오탐 문제에 대한 비판

     * 린네 대학의 Nick Brown 연구원:
          + YesNoError가 분석한 40개 논문 중 14개에서 오탐 확인 → 주로 글쓰기 문제
          + 사소한 오류로 인해 학계에 불필요한 부담 발생 가능성
          + ""기술이 대폭 개선되지 않는 한, 명백한 이득 없이 많은 작업이 필요할 것""

AI 도구의 향후 과제 및 기대

     * YesNoError는 암호화폐 보유자가 검토할 논문을 우선 결정하는 방식 도입 계획
          + 정치적으로 민감한 주제(예: 기후 과학) 논문이 타겟이 될 가능성 존재
     * Brown 연구원: ""AI 도구가 진짜 효과를 보인다면, 특정 연구 분야에서 큰 변화가 일어날 수 있음""

   저품질 논문은 걸러지겠지만, 반면 좋은 논문들도 허들이 높아지면서, 상대적으로 창의적이지 못하게 될 수 있을 것 같아 우려되네요. 논리적 빈틈이 있어도, 그로 인해서 발생하는 새로운 아이디어들도 있기 때문에, 개인적으로는 엄청 달갑지는 않은 것 같습니다.

   AI가 틀릴수도 있을텐데, AI가 지적한 사항이 틀리지 않았다는 걸 어떻게 검증할지 궁금하네요.

   LLM이 대중화되면서 정보의 불균형으로 인한 수요가 대부분이었던 곳에는 엄청난 변화들이 생기고 있네요.

   인류의 각종 경전을 분석하게 시켜보면 어떨까 싶네요 ㅎㅎ

        Hacker News 의견

     * AI가 출판된 논문에서 명백한 오류를 발견할 수 있다면, 검토 과정의 일부로 활용될 수 있음. 저자들이 제출 전에 자신의 작업에 이를 적용할 수 있어 논문의 질을 크게 높일 수 있음
          + 중요한 점은 전문가들, 즉 저자와 동료 심사자들이 이 과정에 참여한다는 것임. 그들은 잘못된 긍정 결과를 쉽게 무시할 수 있지만, 통계적 실수나 전문 분야가 아닌 부분에서의 경고를 받을 수 있음
     * 현재 YesNoError 웹사이트에는 많은 잘못된 긍정 결과가 포함되어 있음. Linnaeus University의 연구자인 Nick Brown은 40개의 문제 있는 논문 중 14개가 잘못된 긍정 결과라고 밝힘
          + 대부분의 문제는 글쓰기 문제로 보이며, 많은 탐지가 잘못되었다고 함
          + 이 기술이 크게 개선되지 않는 한, 명백한 이익 없이 많은 작업을 생성할 것이라고 경고함
     * 현재 AI가 주도하는 것이므로 사람들이 사기나 잘못된 논리를 검사한다고 생각할 수 있음. 실제로는 자기 일관성과 훈련 데이터와의 일관성을 검사함
          + 오타, 오해의 소지가 있는 표현, 사실 및 다이어그램의 교차 검증에는 좋을 수 있지만, 제조된 데이터나 그럴듯하지만 잘못된 결론에는 크게 기여하지 않을 것임
     * AI를 사용하여 철회된 논문의 영향을 매핑하는 아이디어 제안. 철회된 논문에서 더 이상 지원되지 않는 결론을 식별하고, 하류 논문에서 어디에 나타나는지 확인할 수 있음
     * 우리의 집단 기억이 너무 짧은가? AI가 만들어낸 버그 보고서로 인한 문제를 잊었는가?
     * Black Spatula 프로젝트에서 주요 오류를 감지한 두 가지 예시 제공
          + 복잡한 다중 에이전트 파이프라인이 필요하지 않았으며, 단일 프롬프트로 이러한 오류를 감지할 수 있었음
     * 이 아이디어는 좋으며, 자신의 회사 보고서에 적용하여 명백한 오류를 상사에게 보내기 전에 감지하고 싶음
          + 그러나 두 가지 접근 방식이 강조됨. 하나는 소규모 접근 방식으로 먼저 출판하지 않고 저자에게 비공개로 접근함. 다른 하나는 먼저 출판하고 인간 검토가 없으며 자체 암호화폐를 가짐
     * YesNoError는 암호화폐 보유자가 어떤 논문이 먼저 검토될지 결정하도록 계획 중임
     * 이 아이디어는 매우 나쁜 생각임. 첫 번째 섹션을 건너뛰고 ""잘못된 긍정 결과"" 섹션을 읽어야 함
     * 이 가치에 대해 매우 회의적임. AI ""검토""로 인해 근거 없는 주장에 응답하는 데 낭비된 시간이 이미 있었음. 이러한 주장은 이전에도 있었겠지만, 텍스트 생성기는 일반 사람들과 아마추어를 설득할 수 있는 올바른 용어로 환각하는 방법을 알고 있으며, 다루기 더 성가심
"
"https://news.hada.io/topic?id=19686","아인슈타인 AI 모델 - AI가 과학적 혁신을 이끌 수 있을까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  아인슈타인 AI 모델 - AI가 과학적 혁신을 이끌 수 있을까?

     * HuggingFace의 공동창업자 Thomas Wolf는 AI가 과학에서의 급격한 발전, 즉 ""압축된 21세기""를 가져오지 않을 것이라고 주장
     * ""압축된 21세기""는 Dario Amodei의 ""Machine of Loving Grace""에서 나온 개념으로, AI가 데이터 센터에서 수많은 아인슈타인과 같은 역할을 하며 5~10년 만에 21세기의 모든 과학적 발견을 이루어낼 것이라는 주장임
     * 처음에는 이 아이디어에 감명받았고 ""AI가 과학의 모든 것을 5년 안에 바꿀 것이다!""라고 생각했지만, 재차 읽으면서 이는 많은 부분이 희망적 사고(wishful thinking)처럼 보였음

AI는 천재가 아니라 'Yes맨'

     * 실제로 우리가 얻게 될 것은 ""서버에 있는 Yes맨의 나라""일 것이라고 생각함 (현재 추세가 이어진다면)
     * 이 차이를 설명하기 위해 개인적인 이야기를 소개함
          + 나는 항상 성적이 우수한 학생이었음
          + 작은 마을에서 자랐고, 프랑스 최고의 공과대학에 입학한 뒤 MIT에서 박사 과정에 합격함
          + 학교 공부는 항상 쉬웠음
               o 교수의 설명이 어디로 향하는지, 시험 출제자가 어떤 질문을 할지 미리 예측할 수 있었음
          + 결국 연구자(박사 과정 학생)가 되었을 때 나는 큰 충격을 받음
               o 나는 평균 이하의, 기대에 못 미치는, 평범한 연구자였음
               o 동료들은 흥미로운 아이디어를 많이 냈지만, 나는 항상 벽에 부딪히곤 했음
               o 책에 쓰여 있지 않은 것은 스스로 발명할 수 없었음 (그나마도 쓸모없는 기존 이론의 변형에 불과함)
               o 더 큰 문제는 배운 지식을 의심하고 현 상태를 도전하는 것이 매우 어려웠음
               o 나는 아인슈타인이 아니었고, 단지 학교 공부를 잘한 학생이었음
               o 어쩌면 내가 아인슈타인이 아니었던 이유는 학교에서 공부를 잘했기 때문일지도 모름
     * 역사 속 천재들은 학업에서 어려움을 겪은 경우가 많음
          + 에디슨은 교사에게 ""멍청하다(addled)""는 평가를 받음
          + 바버라 맥클린톡은 ""기이한 생각""을 한다고 비판받았지만 노벨상을 수상함
          + 아인슈타인은 취리히 공대 입학시험에서 첫 시도에 실패함
          + 이런 사례는 무수히 많음
     * 사람들이 흔히 저지르는 실수는 뉴턴이나 아인슈타인이 단순히 '확장된 우등생'이었다고 생각하는 것임
          + 즉, 상위 10% 학생을 선형적으로 확장하면 천재가 탄생한다고 잘못 추측함
     * 이 관점은 과학에서 가장 중요한 능력을 놓치고 있음
          + 올바른 질문을 던지고, 배운 지식조차 도전하는 능력이 진정한 과학적 돌파구의 핵심임
          + 실제 과학의 돌파구는 코페르니쿠스가 당시의 모든 지식을 거스르고 지구가 태양을 도는 것을 제안한 것에서 비롯됨
               o 머신러닝 용어로 표현하자면 ""모든 훈련 데이터에도 불구하고"" 기존 상식을 거스른 것임

아인슈타인을 만드는 방법

     * 데이터 센터에서 아인슈타인을 만들기 위해 필요한 것은 단순히 모든 답을 아는 시스템이 아님
          + 다른 사람이 생각조차 하지 못한 질문을 던지는 시스템이어야 함
          + 모든 교과서, 전문가, 상식이 반대할 때 ""만약 이게 다 틀렸다면?""이라고 질문할 수 있어야 함
     * 특수상대성이론의 급진적 패러다임 전환을 생각해보자
          + ""모든 기준틀에서 빛의 속도가 일정하다고 가정하자""라는 첫 번째 공리를 세울 때의 용기가 필요함
          + 이는 당시 상식(그리고 오늘날의 직관)조차 거스르는 일이었음
     * CRISPR은 1980년대부터 세균의 적응성 면역 체계로 알려져 있었음
          + 그러나 발견 후 25년이 지난 뒤 Jennifer Doudna와 Emmanuelle Charpentier가 이를 유전자 편집에 사용할 수 있다고 제안하면서 노벨상을 받음
          + ""우리는 XX가 YY를 한다는 것을 수년간 알고 있었지만, 만약 우리가 잘못 알고 있었다면? 또는 이것을 완전히 다른 개념인 ZZ에 적용할 수 있다면?""
               o 이러한 깨달음이 바로 기존 지식을 벗어난 사고(outside-of-knowledge thinking) 이자 패러다임 전환(paradigm shift) 의 본질임
               o 이는 과학적 진보를 이루는 핵심 메커니즘임
     * 이런 패러다임 전환은 드물게 발생함 (연간 1~2회 정도)
          + 이런 돌파구는 영향이 확인된 후 보통 노벨상으로 이어짐
     * 드물지만, Dario의 주장에 동의함
          + 과학 발전에서 가장 큰 비중을 차지하는 것은 이런 패러다임 전환이며, 나머지는 대부분 잡음에 불과함

AI가 과학 혁신을 이루기 어려운 이유

     * 현재 AI의 성능은 이미 존재하는 지식을 학습하고 답변하는 능력에 초점이 맞춰져 있음
     * 현재 AI 모델의 지능 개선을 평가하는 방식은 제한적
          + 가장 최근의 AI 테스트로는 ""Humanity's Last Exam""이나 ""Frontier Math"" 같은 것이 있음
               o 매우 어려운 질문들로 구성되어 있으며, 일반적으로 박사급 연구자들이 작성함
               o 그러나 명확하고 닫힌 형태의 정답이 존재함
     * 이런 시험은 내가 학창 시절에 잘했던 종류의 시험과 동일함
          + 이미 답이 알려진 문제에 대해 정확한 답을 찾는 능력을 테스트함
     * 하지만 진정한 과학적 돌파구는 이미 알려진 질문에 답하는 것이 아니라,
          + 새롭고 도전적인 질문을 던지고, 기존의 개념과 아이디어에 의문을 제기하는 데서 나옴
     * 더글러스 애덤스의 『은하수를 여행하는 히치하이커를 위한 안내서』를 떠올려 보자
          + 답은 ""42""이지만, 정작 질문이 무엇인지는 아무도 모름
          + 이것이 바로 연구의 본질임
     * 현재 LLM은 인류의 모든 지식을 기억하고 있음에도 새로운 지식을 창출하지 못함
          + 주로 ""manifold filling""을 수행하고 있음
               o 인간이 이미 알고 있는 지식 사이의 간극을 메우는 작업을 수행 중
               o 일종의 지식을 현실의 직물처럼 연결하고 있음
     * 현재 우리는 매우 순종적인 학생을 만들고 있음
          + 이는 현재 AI의 주된 목표인 뛰어난 도우미와 순응적인 헬퍼를 만들기에는 완벽함

AI가 진정한 과학적 혁신을 이루려면

     * 그러나 AI가 과학 혁신을 이루려면 다음과 같은 조건이 필요함
          + 자신이 가진 지식에 의문을 제기할 수 있어야 함
          + 과거 훈련 데이터와 모순되는 새로운 아이디어를 제안할 수 있어야 함
     * 그렇지 않으면 AI는 과학적 혁신을 가져오지 못할 것임
     * 과학적 돌파구를 원한다면 AI 모델 성능 측정 방식을 재검토해야 함
          + 현재는 지식의 양과 기존 질문에 대한 정확한 답변 능력을 측정함
          + 대신 지식과 추론 능력을 테스트할 수 있는 방식으로 전환해야 함
     * 과학적 AI 모델이 가져야 할 능력
          + 훈련 데이터에 대한 도전 : 자신이 학습한 데이터를 그대로 받아들이지 않고 의문을 제기할 수 있어야 함
          + 대담한 반사실적 접근 시도 : 기존의 상식을 거스르는 대담한 가정을 시도할 수 있어야 함
          + 작은 단서를 기반으로 일반화된 제안 도출 : 미세한 힌트에서 새로운 패턴을 찾아내고 일반화할 수 있어야 함
          + 비직관적인 질문을 던져 새로운 연구 경로를 열기 : 기존에 없던 질문을 던져 새로운 연구 방향을 개척할 수 있어야 함
     * 모든 질문에 답할 수 있는 A+ 학생이 필요하지 않음
          + 우리가 원하는 것은 다른 사람들이 놓친 것을 보고 질문할 수 있는 B 학생임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

PS : AI 벤치마크 개선 방향

     * 어떤 벤치마크가 필요한지 궁금할 수 있음
          + 예를 들어, 모델이 최근의 새로운 발견에 대해 테스트받는 상황을 상정할 수 있음
               o 모델이 해당 발견에 대해 사전 지식이나 개념적 틀이 전혀 없는 상태에서
               o 올바른 질문을 시작하고 문제를 탐구할 수 있는지를 평가함
     * 이는 매우 어려운 문제임
          + 대부분의 AI 모델은 현재 인류가 알고 있는 거의 모든 지식을 학습한 상태임
          + 따라서 답이나 개념적 틀이 전혀 없는 상황에서 작동하도록 하는 것은 도전적임
     * 그러나 과학적 혁신을 원한다면 이런 행동을 평가할 수 있는 벤치마크가 필요함
     * 결국 이것은 열려 있는 문제이며, 이에 대한 통찰력 있는 의견을 듣고 싶음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

PPS:

     * 많은 사람들이 (알파고의) ""Move 37"" 을 AI가 이미 아인슈타인 수준의 지능에 도달했다는 증거로 제시함
          + 이에 대해 구체적으로 설명하고자 함
     * Move 37은 인상적이지만, 결국 바둑 규칙이 정해진 상태에서 나온 우등생의 답임
          + 기존의 게임 규칙에 따라 문제를 풀었을 뿐임
     * 마찬가지로, AI 모델이 조만간
          + 가장 뛰어난 수학자가 만든 것보다 더 우아한 수학적 증명을 만들어낼 가능성이 큼
          + 그러나 이것이 진정한 패러다임 전환에 해당하지는 않음
     * 바둑에서 아인슈타인급 돌파구는 더 근본적인 것이어야 함
          + 바둑의 규칙 자체를 새로 정의하거나
          + 기존 게임보다 훨씬 더 흥미로운 새로운 게임 규칙을 창조하는 것에 가까워야 함
     * 수학에서의 더 적절한 비유는
          + 서로 다른 수학 분야를 연결해 새로운 연구 분야를 개척하는 것에 해당함
          + 이는 보통 필즈상(Fields Medal) 을 받게 하는 수준의 성취임
     * 아인슈타인 수준의 과학적 패러다임 전환은 여전히 매우 높은 기준을 요구함

   생각하지 못한 질문을 던질수 있는 AI 를 만들어냈다고 했을때 그 AI 가 사람은 왜 해치면 안되는가 같은 질문을 던지기 시작하면 아찔할 거 같네요

AI와 창의성: 패러다임 전환과 영감의 관계

     Hugh에게 보내는 생각 정리 <- ?

   Thomas Wolf의 글은 AI가 진정한 과학적 혁신을 이끌어내기 어려울 것이라는 주장을 담고 있습니다. 그는 AI가 기존 지식을 재조합하는 ""Yes맨""과 같다고 표현하며, 패러다임을 전환하는 아인슈타인 같은 천재성과는 거리가 있다고 말합니다.

   그의 관점은 AI의 한계를 정확히 짚으면서도, 동시에 우리에게 AI와 인간 협력의 가능성을 생각해보게 합니다. < 이 글은 클로드에게 의견을 묻자 대답한 내용인데 굳이 요청도 안 한 아티팩트로 만들어주고, 이 문장은 다른 얘기하다 갑자기 별 언급도 없이 추가한 문장임. 희안하네...

  영감과 AI의 역할

   그러나 영감이란 무엇일까요? 인간의 창의성도 결국은 기존 아이디어들의 새로운 연결과 조합에서 비롯됩니다. 아인슈타인조차 뉴턴, 맥스웰, 로렌츠와 같은 선배 과학자들의 어깨 위에서 더 멀리 보았습니다.

   AI가 제공하는 것은:
    1. 다양한 지식 영역의 연결: 인간이 미처 연결짓지 못했던 분야들을 연결하는 능력
    2. 패턴 인식: 방대한 데이터에서 인간이 놓칠 수 있는 패턴을 발견
    3. 아이디어 촉발: 때로는 AI의 ""엉뚱한"" 제안이 인간에게 새로운 관점을 제시

  AI와 인간의 공생 관계

   Thomas Wolf는 AI가 혼자서 패러다임 전환을 일으킬 수 없다고 말하지만, AI와 인간의 협력은 어떨까요? 인간이 질문을 던지고 AI가 다양한 가능성을 탐색하는 과정에서 새로운 아이디어가 탄생할 수 있습니다.

   인간은 질문을 던지는 능력, 직관, 그리고 결과의 가치를 판단하는 능력을 가지고 있습니다. AI는 방대한 데이터를 바탕으로 연결점을 제시합니다. 이 두 지성의 결합은 어쩌면 각자가 따로 도달할 수 없는 곳으로 우리를 데려갈 수 있을 것입니다.

  결론: 새로운 창의성의 가능성

   AI는 ""압축된 21세기""를 혼자 만들어내지는 못할 수 있습니다. 그러나 인간에게 영감을 주고, 새로운 생각의 경로를 열어주며, 인간 창의성의 동반자로 기능할 수 있습니다.

   진정한 혁신은 인간과 AI가 각자의 강점을 발휘하는 공동 창작의 과정에서 나타날 가능성이 높습니다. 이것은 단순한 ""Yes맨""의 역할을 넘어, 인간과 함께 새로운 패러다임을 모색하는 여정이 될 것입니다.

   https://news.hada.io/topic?id=19168
   AI는 절대 생각못했을거 같은 연구입니다
   본문 요지에 공감해요.

   ""모든 질문에 답할 수 있는 A+ 학생이 필요하지 않음
   우리가 원하는 것은 다른 사람들이 놓친 것을 보고 질문할 수 있는 B 학생""

   을 보고 바로 내가 B학생인데 대기업은 A+ 학생만 보고 뽑는 다는 생각이 든다

        Hacker News 의견

     * AI에게 ""아무것도 만들지 말고, 답이 없으면 모른다고 말하라""고 지시했을 때 운이 좋았음
          + AI가 ""미국식""보다는 ""네덜란드식""으로 조정되면 더 유용할 것 같음
          + ""네덜란드식""은 직설적이고 솔직한 것으로 유명함
          + ""미국식"" AI는 고객이 항상 옳다는 식으로 조정되어 있음
          + 인간 상호작용에서 네덜란드식 직설성과 솔직함은 불쾌할 수 있지만 효율적이고 효과적임
          + 소프트웨어가 정중할 필요는 없고, 감정을 상하게 하지 않아도 됨
     * Feyerabend의 ""Against Method""를 읽어보라 권장함
          + 반귀납적 사고의 필요성을 잘 재구성했음
     * BlueSky 버전 링크 제공됨
     * ""올바른 질문을 묻는 것""에 대한 흥미로운 게시물임
          + 첫 원칙 기반의 인과적 추론이 부족하다고 느낌
          + 진정한 지능 시스템은 교과서 버전과 일치하지 않는 것을 알아차릴 것임
          + 현실이 기대와 다를 때 후속 질문을 하여 더 깊은 통찰과 올바른 질문과 답변으로 이어짐
          + MIT Lab & Harvard의 ""Reasoning-Prior"" 접근 방식이 흥미로움
          + 관련 논문: ""General Reasoning Requires Learning to Reason from the Get-go""
     * 창의적인 B 학생과 AI A 학생이 함께 일하는 21세기 압축 가능성에 대한 의견
     * LLM의 진정한 참신한 응답과 환각을 구별할 수 없음
          + 문제의 결과가 어떻게 보여야 하는지 알고 더 나은 기능을 찾는 경우 일부 해결 가능
          + 복잡해질수록 1억 개의 잠재적 해결책을 테스트할 수 없음
          + 임상 시험을 1억 번 실행할 수 있는 물류가 없음
     * 현대의 Twitter/X보다 더 스마트한 곳에 있어야 할 좋은 게시물임
          + 벤치마크가 필요한 이유에 대한 설명
          + 천재(인간 또는 AI)는 새로운 통찰을 제공할 수 있음
          + 판매 브로셔 주장, 연구 논문 비교 차트, 개인 KPI/OKR, 승진 패킷이 필요 없음
     * 인간 엔지니어가 설계하지 않을 회로를 설계하는 알고리즘을 봄
          + 상자 밖의 사고가 더 쉽게 접근 가능할 수 있음
     * 저자는 추측을 만드는 것이 어려운 부분이라고 가정하는 것 같음
          + 강력한 도우미가 사람들에게 대담한 수학적 아이디어를 시도하게 하는 것이 큰 영향을 미칠 것임
     * 사실성에 엄격하게 고수하는 모델을 찾지 못했음
          + 이미 ""사실""을 질문하고 새로운 것을 발명할 수 있는 모델이 있을 수 있음
     * 직관이 아닌 직설적인 사실만 원함
          + 양심 있는 AI를 원하지 않음
"
"https://news.hada.io/topic?id=19622","Differentiable 로직 셀룰러 오토마타","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Differentiable 로직 셀룰러 오토마타

     * 간단한 로컬 규칙에서 복잡한 패턴을 역설계하는 방법을 탐구
     * Neural Cellular Automata(NCA)의 학습 가능성과 Differentiable Logic Gate Networks를 결합해, 이산적 로컬 규칙을 학습 방식으로 얻는 접근
          + ""Conway's Game of Life 규칙을 학습해낼 수 있을까?""
          + ""NCA처럼 복잡 패턴을 재현하며, 시공간 순환 구조를 학습할 수 있을까?""

Introduction

     * Cellular Automata(CA)는 단순한 로컬 규칙에서 출발해, 복잡하고 예측하기 어려운 패턴을 형성함
     * 전통적으로 CA에서는 규칙을 사람이 직접 설계했지만, 여기서는 목표 패턴이나 동작을 미리 주어 놓고, 이를 만족하는 로컬 규칙을 역으로 ‘학습’할 수 있는 방식을 소개함
     * 특히 Neural Cellular Automata(NCA) 는 CA 구조에 딥러닝 기법을 결합해, 연속 공간에서 학습 가능하도록 설계되어 왔음
     * Differentiable Logic Gate Networks는 논리 게이트(AND, OR, XOR 등)를 연속적으로 근사해 학습하고, 최종적으로 다시 이산 논리회로로 변환하는 기법임
     * 이 두 아이디어를 결합하여, DiffLogic CA라는 완전히 이산적이며 학습 가능한 CA 모델을 제안함
     * 이는 프로그래머블 물질(Programmable Matter) 혹은 Computronium을 향한 작은 발걸음으로 볼 수 있음
     * 본 글은 다음 흐름으로 진행됨
          + Neural Cellular Automata 요약
          + Differentiable Logic Gate Networks 요약
          + 두 방법론을 결합한 DiffLogic CA 구조
          + Conway’s Game of Life 규칙 학습 실험
          + 복잡 패턴(체커보드, 도마뱀, 컬러 이미지 등) 생성을 위한 학습 실험

Recap – Neural Cellular Automata(NCA)

     * 개념
          + 전통적 CA 규칙을 뉴럴넷으로 학습 가능한 형태로 대체한 시스템임
          + 각각의 셀이 여러 채널(state)을 가지고 로컬 상호작용을 통해 복잡한 패턴을 형성함
          + Sobel 필터 등을 활용해 주변 정보를 얻고, 뉴럴넷이 상태 변화를 결정함
     * 특징
          + 모든 계산 과정이 미분 가능해, 원하는 패턴을 만들도록 학습할 수 있음
          + 병렬성·로컬성·상태 기반 계산 등 CA 핵심을 유지하면서도 딥러닝 기법을 결합함

Recap – Differentiable Logic Gate Networks(DLGNs)

     * 핵심 아이디어
          + 전통적 NN 대신 논리 게이트(AND, OR, XOR 등)를 연속적으로 근사(soft gate)하여 학습함
          + 학습 단계에서는 게이트가 연속적으로 동작하고, 최종 추론 시에는 실제 이진 연산을 수행하는 구조임
     * 학습 과정
          + 게이트의 16가지 가능한 논리 연산에 대한 확률 분포를 학습해, 최종적으로 특정 연산에 수렴함
          + 연속 근사를 통해 미분 가능하게 만들고, 학습이 끝나면 완전히 이산 논리 게이트로 전환함
     * 장점
          + 최종 회로가 완전히 이진 논리 게이트로 구성되어, 하드웨어적으로 효율성이 높음
          + 이산 로직 기반이므로 해석 가능성과 에너지 효율에 장점이 있음

Differentiable Logic Cellular Automata (DiffLogic CA)

     * 구조
          + 2D 격자에서 각 셀이 n비트 상태를 가지며, Perception → Update 단계로 시뮬레이션함
          + Perception 단계
               o 이웃 정보(채널별)를 논리 회로 커널로 처리함
          + Update 단계
               o 현재 상태와 Perception 결과를 또 다른 논리 회로로 통합해, 다음 시점 상태를 결정함
     * 특징
          + 모든 셀이 분산적으로 움직이는 작고 독립된 프로세서처럼 동작함
          + 소프트(연속 근사)로 학습 후 하드(이진) 게이트로 추론해 효율성이 높음
          + CAM-8과 같은 CA 기반 컴퓨팅 구조와 유사한 철학을 가짐

  Experiment 1: Learning Game of Life

     * 목적
          + Conway's Game of Life 규칙을 DiffLogic CA로 학습해, 이를 완전히 재현할 수 있는지 확인함
     * 설정
          + 셀 상태 1비트 사용
          + Perception에 16개 커널(각각 8→4→2→1 게이트 구조)
          + Update에 23레이어(초반 16레이어 128노드, 이후 [64, 32, 16, 8, 4, 2, 1])
          + 3x3 그리드에서 모든 가능한 상태(512개)를 학습해, 다음 스텝의 정확한 상태를 예측하도록 함
     * 결과
          + 학습 손실이 0에 근접하며 Game of Life 로컬 규칙을 완벽히 학습함
          + 더 큰 그리드에서 실제 Game of Life처럼 글라이더, 블록 등 모든 패턴을 재현함
          + 최종 회로에서 AND·OR 게이트가 많이 사용됨

  Experiment 2: Pattern Generation

     * 체커보드(Checkerboard) 예시
          + 8비트 상태를 가진 셀이 20스텝 동안 16x16 체커보드를 형성함
          + Perception에 16개 커널, Update에 16레이어(최대 256게이트)
          + 최종 채널만 타깃 패턴과 비교해 손실 계산
     * 결과
          + 정확히 체커보드를 형성하며, 단 몇 개 게이트만으로 규칙이 간결하게 구현됨
          + 4배 큰 그리드에서도 동일 규칙으로 스케일 업해 문제없이 동작함
          + 일부 셀을 영구적으로 비활성화해도 패턴이 크게 망가지지 않고, 비활성 셀을 복원하면 자동으로 자기 치유함
     * Asynchronicity
          + 비동기 업데이트로 학습해도 체커보드 패턴을 문제없이 학습함
          + 동기식으로 학습한 규칙을 비동기 추론에 적용해도 잘 동작함
          + 비동기 학습 규칙이 잡음이나 손상 상황에 좀 더 빠르게 복원하는 경향을 보임

  Experiment 3: Growing a Lizard

     * 목적
          + 20x20 도마뱀 윤곽을 12스텝 만에 형성하도록 학습해, 복잡한 모양 생성 가능성을 확인함
     * 설정
          + 128비트 상태
          + Perception 4커널(각 [8, 4, 2, 1] 게이트 구조), Update 10레이어(초반 8레이어 512게이트, 이후 [256, 128])
          + 그리드 중앙에 하나의 활성 셀을 두고, 주기적 경계 조건 사용
     * 결과
          + 큰 그리드(40x40)에서도 정상적으로 도마뱀이 성장함
          + 수많은 게이트가 사용되지만, 필요한 하이퍼파라미터 튜닝으로 학습 가능함

  Experiment 4: Learning the G with colors

     * 목적
          + 3채널 RGB를 포함한 16x16 컬러 이미지를 15스텝에 걸쳐 생성해, 다채널 패턴 생성 검증함
     * 설정
          + 64비트 상태(첫 3채널을 RGB로 사용, 각 채널은 0 또는 1)
          + Perception 4커널(각 [8, 4, 2]), Update 11레이어(초반 8레이어 512게이트, 이후 [256, 128, 64])
          + 타깃 이미지는 8가지 컬러 중 하나씩 채우는 16x16 G 패턴
     * 결과
          + 손실 0에 가깝게 학습되며, 15스텝 후 타깃 컬러 G를 정확히 재현함
          + 회로는 TRUE·FALSE 게이트가 많이 사용되고 OR 게이트가 두드러짐

  Summary and Discussion

     * 무엇을 했는가
          + DiffLogic CA라는 완전히 이산적이면서도 학습 가능한 CA 모델을 제안함
          + Game of Life처럼 고전 규칙을 복제하고, 체커보드·도마뱀·컬러 G 등의 패턴 생성 능력을 보임
          + 이산 로직 회로로 구성되어 직관적 해석과 하드웨어 효율성을 기대할 수 있음
     * 의의
          + NCA가 보이는 자기 조직적 패턴을 이산 논리 게이트 기반으로도 학습 가능함을 입증함
          + 손상 복원이나 비동기 업데이트 같은 특성을 고려하면, 분산·내결함성(robust) 컴퓨팅에 응용 가능성이 높음
     * 한계 및 향후 과제
          + 복잡한 이미지나 패턴 학습 시, 적절한 하이퍼파라미터 튜닝이 필요함
          + LSTM형 게이트나 상태를 효율적으로 잊는 구조를 탐색해, 더 풍부한 패턴 형성을 가능하게 할 여지가 있음
          + 회로의 규모 최적화, 학습 안정화 등을 개선하는 방향으로 확장 가능함
     * 결론
          + DiffLogic CA는 프로그래머블 물질(Programmable Matter) 혹은 Computronium과 같은 이론적 분산 컴퓨팅 방향으로 이어질 수 있는 유망한 접근임
          + 완전히 이산적이면서도 학습 가능해, 미래 분산 시스템의 기반이 될 잠재성을 가짐

        Hacker News 의견

     * 매우 흥미로움. 나는 새로운 범용 튜링 기계 기판을 수집하고 있음. 유전 프로그래밍 실험을 위해 포켓몬처럼 수집하고 있음. 이전에 셀룰러 오토마타(CA)를 사용해봤지만, 이번 접근이 훨씬 더 매력적임. 커널을 디지털 논리 회로처럼 모델링할 생각은 해본 적이 없었음
          + 불리언 논리, 게이트, 회로의 제약이 피트니스 랜드스케이프를 구축하는 흥미로운 결을 만들어냄. 결과 매개변수는 하드웨어 구현으로 직접 변환되거나 추가 최적화 단계를 거쳐 간단한 프로그램으로 컴파일될 수 있음. 수십억 개의 매개변수를 가진 블랙박스의 마법 같은 부동 소수점보다 나아 보임
     * 셀룰러 오토마타를 예술에 활용하는 것을 좋아함. 어떤 패턴이 나타날 수 있는지 놀라움. DLCA를 사용해봐야 할 것 같음
     * 매우 흥미로움. Michael Levin이 동물 세포가 계층 없이 협력할 수 있는 방법에 대해 제기한 질문이 인상적임. 개구리 배아의 눈 세포가 원래 위치로 이동하는 실험이 있음. 세포가 언제 멈춰야 하는지를 아는 방법에 대한 답은 없었음
          + 비계층적 조직을 이해하는 것이 사회가 작동하는 방식을 이해하는 데 중요함. 다양한 규모의 죄수의 딜레마를 해결하는 데도 중요함
          + 복잡성을 이해하고 모델링하는 것에 대한 것이기도 함
          + 처음으로 이러한 것을 모델링할 수 있는 능력을 봄. 많은 방향으로 나아갈 수 있음. 놀라움
     * 최근 ""지능""에 대해 많이 생각해왔음. 우리는 지능이 어떻게 작동하는지 이해하는 결정적인 시점에 있는 것 같음. 지능은 고전적인 뉴턴 역학이나 전기와 크게 다르지 않은 자연 발생적 행동임. 결국 간단한 규칙으로 귀결됨
          + 뇌의 비이산적인 모든 것이 단지 ""인프라""라면? 실제 작업을 수행하는 근본적으로 간단하지만 중요한 핵심 프로세스를 지원하는 것이라면? 모든 것이 논리 게이트와 전기 신호로 귀결된다면?
          + 흥미로운 시대가 다가오고 있음
     * 이들은 특히 일반화 능력에 있어 매력적임. 하지만 비전은 무엇인가? 미래에 무엇을 할 수 있을까? 철학적으로, 이것들이 세상에 대해 무엇을 가르쳐줄까? 1D 셀룰러 오토마타가 튜링 등가임을 알고 있음. 따라서 NCA/이것들은 크게 놀랍지 않음
     * 획기적인 발견임. 체커보드나 도마뱀에 관한 것이 아님. Navier-Stokes 미분 방정식은 유체 운동을 지배하는 업데이트 규칙임. 구름 형성과 불꽃의 움직임 등 모든 복잡성이 간단한 법칙에 의해 지배됨. 이 방정식을 실제 샘플을 통해 발견하는 것이 과학임. DLCA 모델을 연기 비디오 녹화에 적용하여 Navier-Stokes 방정식을 유도할 수 있음. 업데이트 규칙 자체가 다른 업데이트 규칙에 따라 변경될 수 있음을 고려하면 흥미로운 영역에 들어갈 것임. 뇌의 뉴런이 수천 개의 뉴런과 연결되어 있는 이유일 수 있음
          + Google 임원들은 이 발견을 광고 사업과 관련이 없다고 무시할 것임. 몇 년 후 DLCA가 세상을 뒤집을 때, 그들의 직원이 발견했다고 주장할 것임
     * 매우 흥미로운 논문임. 질문이 있음: ""글로벌"" 경사 하강법을 사용하여 업데이트되기 때문에 셀 게이트가 진정한 병렬이 아님
          + 엄격히 지역적인 가중치 조정 방법에 대한 가능성이 있는가?
     * 불 대수의 연속적 완화는 오래된 아이디어임. 회로 합성은 잘 연구된 분야임. Google이 2년 전에 대회를 우승함. IWLS 대회 데이터 세트에 학습자를 적용해봤는지 궁금함. 그렇지 않다면, 왜 안 했는가?
     * ARC-AGI 챌린지에 사용할 수 있을까? 최근 것과 결합할 수 있을까?
     * 셀프 플러그이지만 관련 있음 => 다세포 인공 발생의 강건성과 정지 문제 (2011)
          + 업데이트 규칙이 퍼셉트론과 등방성 확산으로 결합된 셀룰러 오토마타. 신경망의 가중치는 셀룰러 오토마타가 그림을 그릴 수 있도록 최적화됨. 자기 치유(즉, 방해받았을 때 그림을 재구성함)
          + 당시에는 자동 미분이 지금처럼 접근 가능하지 않았음. 진화 전략으로 가중치를 최적화했음. 물론, 경사 하강법을 사용하는 것이 훨씬 나을 것임
"
"https://news.hada.io/topic?id=19603","딥 리서치, 딥 리서치, 딥 리서치의 차이점","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        딥 리서치, 딥 리서치, 딥 리서치의 차이점

     * 최근 AI랩들은 ‘딥 리서치(Deep Research)’라는 용어를 사용하여 다양한 기능을 발표하고 있음
     * Google은 2024년 12월 Gemini 1.5 Deep Research를, OpenAI는 2025년 2월 Deep Research를, Perplexity는 그 직후 자체 Deep Research를 공개함
     * 이 외에도 DeepSeek, Alibaba의 Qwen, Elon Musk의 xAI 등이 챗봇 어시스턴트에 Search 및 Deep Search 기능을 도입함
     * GitHub에는 수십 개의 오픈 소스 ‘딥 리서치’ 구현체가 등장함
     * 이는 2025년의 Retrieval-Augmented Generation(RAG)과 유사하게 ‘딥 리서치’라는 용어가 명확한 정의 없이 사용되고 있음을 시사함

Deep Research, Deep Search, 또는 그냥 Search

     Google : “딥 리서치는 AI를 사용하여 복잡한 주제를 탐구하고, 포괄적이고 읽기 쉬운 보고서를 제공하며, Gemini가 복잡한 작업을 처리하여 시간을 절약하는 데 더욱 능숙해지고 있음을 보여줍니다.” -
     OpenAI : “딥 리서치는 OpenAI의 차세대 에이전트로, 사용자가 프롬프트를 제공하면 ChatGPT가 수백 개의 온라인 소스를 찾아 분석하고 종합하여 연구 분석가 수준의 포괄적인 보고서를 생성합니다.”
     Perplexity : “딥 리서치 질문을 하면 Perplexity는 수십 개의 검색을 수행하고 수백 개의 소스를 읽으며 자료를 추론하여 자율적으로 포괄적인 보고서를 제공합니다.”

     * 마케팅 용어를 제외하면, 딥 리서치는 다음과 같이 정의할 수 있음

     사용자 쿼리를 받아들이고, 대형 언어 모델(LLM)을 에이전트로 사용하여 반복적으로 정보를 검색하고 분석하며, 상세한 보고서를 출력하는 보고서 생성 시스템

     * 자연어 처리(NLP) 용어로는 ’보고서 생성(report generation)’으로 알려져 있음

구현 방식

     * ChatGPT의 등장 이후, 보고서 생성 또는 ‘딥 리서치’는 AI 엔지니어링의 주요 초점이 되었음
     * 필자는 2023년 초 해커톤에서 이를 실험해보았으며, 이는 AI 엔지니어링이 막 떠오르던 시기였음
     * LangChain, AutoGPT, GPT-Researcher, 프롬프트 엔지니어링 등 도구와 수많은 데모가 트위터와 링크드인에서 큰 관심을 받았음
     * 그러나 실제 도전 과제는 구현 세부 사항에 있음
     * 아래에서는 보고서 생성 시스템을 구축하기 위한 일반적인 패턴을 탐구하고, 그 차이점을 강조하며, 다양한 벤더의 제공 사항을 분류함

비학습형: 방향성 비순환 그래프(DAG)

     * 초기에는 GPT-3.5와 같은 LLM에게 보고서를 처음부터 생성하도록 요청하는 것이 실용적이지 않다는 것을 발견함
     * 대신, 여러 LLM 호출을 연결하기 위해 Composite 패턴을 사용함
     * 사용자 쿼리를 분해하여 보고서 개요를 생성함
     * 각 섹션에 대해 검색 엔진이나 지식 베이스에서 관련 정보를 검색하고 요약함
     * 마지막으로 LLM을 사용하여 섹션을 일관된 보고서로 결합함
     * GPT-Researcher가 그 예시임
          + 이 시스템의 모든 프롬프트는 ‘프롬프트 엔지니어링’을 통해 세심하게 조정됨
          + 평가는 주관적인 출력물 확인에 의존하며, 보고서 품질은 일관되지 않음
          + 작동할 때는 훌륭하지만, 항상 안정적이지는 않음

비학습형: 유한 상태 기계(FSM)

     * 보고서 품질을 향상시키기 위해 엔지니어들은 DAG 접근 방식에 복잡성을 추가함
     * 단일 패스 프로세스 대신, Reflexion 및 자기 반성(self-reflection)과 같은 구조적 패턴을 도입하여 LLM이 자신의 출력을 검토하고 개선하도록 함
     * 이는 단순한 DAG를 유한 상태 기계(FSM)로 변환하며, LLM이 부분적으로 상태 전환을 안내함
          + DAG 방식과 마찬가지로, 모든 프롬프트는 수작업으로 작성되며, 평가는 주관적임
          + 시스템이 수작업으로 조정되므로 보고서 품질은 여전히 크게 변동함

학습형: 엔드 투 엔드

     * 이전 방법의 단점인 무작위적인 프롬프트 엔지니어링과 측정 가능한 평가 지표의 부족으로 인해 변화를 추구하게 됨
     * 스탠포드의 STORM은 이러한 문제를 DSPy를 사용하여 엔드 투 엔드로 시스템을 최적화하여 해결함
          + 그 결과, STORM은 위키피디아 기사와 견줄 만한 품질의 보고서를 생성함

학습형: 대규모 추론 모델

     * LLM의 추론 능력 향상으로 인해 대규모 추론 모델이 딥 리서치에 매력적인 옵션이 됨
     * 예를 들어, OpenAI는 딥 리서치 모델을 다음과 같이 훈련함
          + LLM-as-a-judge 및 평가 루브릭을 사용하여 출력을 평가
     * Google의 Gemini와 Perplexity의 챗 어시스턴트도 ‘딥 리서치’ 기능을 제공하지만, 이들이 모델이나 시스템을 최적화한 방법이나 실질적인 정량적 평가에 대한 문서를 공개하지 않음
     * 그러나 Google의 딥 리서치 제품 관리자는 팟캐스트 인터뷰에서 “특별한 접근 권한이 있습니다. 거의 동일한 모델(Gemini 1.5)입니다. 물론 자체적인 후속 훈련 작업을 수행합니다”라고 언급함
     * 이는 미세 조정 작업이 비중이 크지 않음을 시사함
     * 한편, xAI의 Grok은 보고서 생성에서 뛰어나지만, 두 번의 반복을 넘어서 검색하지 않는 것으로 보임
     * 개요 섹션을 몇 번, 각 섹션을 몇 번 검색하는 방식임

경쟁 구도

     * 딥 리서치 기능을 제공하는 다양한 서비스의 역량을 평가하기 위해 개념적 지도를 개발함
     * 수직 축: 연구의 깊이(이전 결과를 기반으로 추가 정보를 수집하는 반복 주기 수)
     * 수평 축: 학습 수준(수작업으로 조정된 시스템부터 기계 학습 기술을 활용한 완전 학습 시스템까지)
     * 대표적인 학습형 시스템:
          + OpenAI Deep Research: 연구 작업에 최적화된 강화 학습 기반 시스템
          + DeepSeek: 일반적인 추론 및 도구 사용을 위해 훈련되었으며 연구 요구 사항에 적응 가능함
          + Google Gemini: 광범위하게 훈련된 LLM으로 연구에 특화되지는 않음
          + Stanford STORM: 전체 연구 프로세스를 엔드 투 엔드로 최적화한 시스템
     * 이 프레임워크를 통해 각 서비스가 반복 연구의 깊이와 학습 접근 방식을 어떻게 균형 있게 조정하는지 이해할 수 있음

결론

     * 딥 리서치 기술은 빠르게 발전하고 있으며, 몇 달 전에는 효과가 없거나 구현되지 않았던 기술들이 현재는 성공적으로 적용되고 있음
     * 그러나 용어 사용이 모호하여 혼란을 가중시키고 있음
     * 이 글이 기술적 차이를 명확히 하고, 마케팅 용어에 휘둘리지 않도록 돕기를 바람

     동료가 ""AlphaGO가 이세돌을 이겼지만, 이세돌은 훨씬 나은 자율주행 알고리즘을 가지고 있다""고 농담했음

   하지만 이세돌은 한 명 뿐이고 복제가 안 됨

        Hacker News 의견

     * Han Xiao가 제안한 DeepSearch와 DeepResearch의 구분이 매우 흥미로움
          + DeepSearch는 최적의 답을 찾을 때까지 검색, 읽기, 추론을 반복하는 과정임
          + DeepResearch는 DeepSearch에 구조화된 프레임워크를 추가하여 긴 연구 보고서를 생성함
          + DeepSearch가 더 가치 있고 흥미로운 패턴이라고 생각함
          + DeepResearch는 결과를 ""보고서""로 포장하는 화장 효과에 불과하며, 부정확하거나 오해의 소지가 있는 결과를 초래할 가능성이 큼
     * 동료가 ""AlphaGO가 이세돌을 이겼지만, 이세돌은 훨씬 나은 자율주행 알고리즘을 가지고 있다""고 농담했음
          + 시간이 지남에 따라 가장 발전된 AI 시스템과 일반적인 사람의 ""평균적인 능력"" 간의 큰 차이를 강조함
     * OpenAI와 다른 회사들이 제공하는 것의 차이를 잘 포착한 것 같음
          + Google의 Gemini 2.0 Flash도 구글 검색과 네이티브 통합이 되어 있음
          + OpenAI의 DR은 특정 작업을 위한 모델을 훈련하는 경향이 있음
          + 모델 + 후속 훈련 RL을 제품으로 제공하는 방향으로 나아가고 있음
          + genspark MOA는 주어진 프롬프트에 대한 심층 보고서를 생성함
     * AI가 점점 더 다양해지고 있으며, 다양한 에이전트가 생성될 가능성이 있음
     * Grok이 보고서 생성에 뛰어나다고 하는데, 테이블 형식으로 답변을 요청하여 비교하기 쉽게 만듦
          + Amazon은 비교할 제품을 선택하지만, 비교 항목이 좋지 않음
          + Grok을 사용하여 열을 추가하거나 제거하고, 응답을 단축할 수 있음
     * DR은 정보를 수집하고, 집중된 출발점에서 실제 연구를 수행하는 좋은 방법임
          + LLM이 이를 수행했다고 해서 더 현명해진 것은 아님
          + LLM은 주제를 더 깊이 이해하지 못함
          + 정보 통합 및 적용을 위한 더 깊은 능력이 필요함
          + 변환기 아키텍처의 한계로 인해 실시간 학습이 어려움
     * OpenAI Deep Research와 Perplexity의 Deep Research를 비교한 결과, ""좁고 깊음"" vs ""얕고 넓음""의 차이가 있음
          + OpenAI는 고품질 소스를 선택하여 특정 주제에 깊이 들어감
          + Perplexity는 많은 소스를 사용하여 표면적인 문제 공간을 제공함
          + OpenAI는 시간이 더 오래 걸림
     * Deep Search/Research를 통해 다양한 워크플로우를 시도해 봄
          + 명령형(소스를 직접 선택하여 보고서 생성)과 선언형(DFS/BFS 알고리즘 사용) 접근법이 있음
          + STORM과 같은 시스템의 종단 간 흐름에 매료됨
     * STORM은 높은 평가를 받았지만 GPT Researcher는 그렇지 않음
          + 다양한 예산에 맞게 GPT Researcher를 구성할 수 있음
     * 인터넷에서 가장 큰 정보 조직 플랫폼들이지만, 제품을 설명할 다른 단어를 찾지 못함
"
"https://news.hada.io/topic?id=19710","에이전트 구축을 위한 새로운 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           에이전트 구축을 위한 새로운 도구

        Hacker News 의견

     * API 변경이 실제 제품에 OAI를 통합하려는 개발자에게 얼마나 도움이 될지 모르겠음
          + 벤더가 관리하는 상태 기계는 대화, 메시지, 프롬프트 전달 등을 처리하는 데 있어 불충분하거나 주의를 산만하게 함
          + 결국 채팅 완료 API만 사용하게 됨
          + 상태 관리를 제3자에게 아웃소싱하는 것보다 로컬에서 관리하는 것이 더 자율적임
          + 이 제품들의 전제는 문자열을 입력하면 새로운 문자열을 반환하는 것임
          + 적절한 문자열을 구성하는 것에 집중하면 다른 모든 것이 사라짐
          + 데이터베이스에 저장된 비즈니스 상태에 기반하여 구조화된 문자열을 구성하는 다른 방법을 생각해보면 됨
          + PHP로 웹페이지를 SSR할 때와 동일한 작업임
     * 새로운 API의 설계 결정 배경에 대한 디자이너의 좋은 트위터 스레드가 있음
          + 트위터 링크: https://twitter.com/athyuttamre/status/1899541471532867821
          + 트위터에 로그인하지 않은 사람들을 위한 대체 링크: https://nitter.net/athyuttamre/status/1899541471532867821
     * AI 에이전트 시도가 잘못된 방향으로 가고 있다고 느낌
          + 새로운 방법을 창출하기보다 기존 시스템에서 인간을 대체하려고 함
          + 경제와 삶은 인간 간의 상호작용에 관한 것임
          + AI 에이전트 접근 방식은 사람들의 문장을 길게 확장하고 다시 요약하는 농담의 변형처럼 보임
          + 레거시 시스템에서 작업을 자동화하는 용도가 있지만, 진정한 기회는 대부분의 레거시 시스템을 제거하는 것임
          + 인간은 그렇게 나쁘지 않음
          + AI를 사용하여 인간을 위한 UI를 만들고 AI가 이 UI를 사용하여 작업을 수행하는 것이 정말로 앞으로 나아가는 길인가?
     * 언급되지 않은 것: Model Context Protocol
          + 링크: https://www.anthropic.com/news/model-context-protocol
     * swyx가 API/DX 팀과 새로운 API에 대한 FAQ를 논의한 경험 공유
          + 링크: https://latent.space/p/openai-agents-platform
          + 주요 재미있는 부분: 응답 API를 데이터베이스로 악용할 수 있는 방법
          + 웹 검색을 위한 hparams - DIY Deep Research를 위한 검색의 깊이/폭
          + OAI가 RAG/재정렬을 기본 제공하는 시점에서 언제 자체 RAG를 구축해야 하는지
          + Agents SDK와 OAI Swarm의 차이점
          + search-preview와 computer-use-preview 미세 조정이 GPT5에 통합될 것인지
     * OpenAI의 새로운 Agent SDK와 API에 대한 초기 접근을 얻은 경험 공유
          + 오픈 소스 프로젝트를 만들어 기능을 보여줌
          + 다른 에이전트 프레임워크를 사용하는 경우 이 SDK를 시도해보기를 권장함
          + 전체 SDK와 예제를 단일 텍스트 파일로 제공하여 빠르게 시작할 수 있도록 함
          + 모듈식 코드로 다른 프레임워크를 사용하여 구현 가능
          + 블로그 게시물에서 SDK의 주요 기능에 대한 추가 생각 공유
          + 매우 만족함
     * 모든 LLM 제공자와 호환되는 간단하고 강력한 응답 API를 구축함
          + 링크: https://github.com/Anilturaga/aiide
     * OpenAI 검색 API의 가격이 비쌈
          + 1,000회 검색당 $30
          + Perplexity의 Sonar 모델은 1,000회 검색당 $5
          + 가격 차이에 대한 의문
     * 컴퓨터 사용의 발전에 감명받음
          + 이 기술이 사용성 테스트에 활용될 수 있을 만큼 성숙한지 궁금함
          + AI가 탐색하기 어려운 UI는 인간에게도 어려울 가능성이 높음
          + 개선이 필요하다는 신호일 수 있음
     * Assistants API의 중단 계획 발표
          + 새로운 Responses API는 올바른 방향으로 나아가는 단계임
          + 에이전트 사용 사례에 대한 제한이 있음
          + 개발자에게 에이전트 구축을 위한 원활한 플랫폼 경험 제공 목표
          + 그래프 기반의 제어 흐름이 나올 것으로 예상됨
          + 오픈 소스 솔루션이 많지만 대부분 불필요한 복잡성을 추가함
          + 도구 호출과 JSON 응답을 사용하여 에이전트 흐름을 구축했지만, 아직 해결되지 않은 고차원 구성 요소가 있음
"
"https://news.hada.io/topic?id=19624","사다리: 재귀적 문제 분해를 통한 자기 개선 LLMs","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     사다리: 재귀적 문제 분해를 통한 자기 개선 LLMs

LADDER: 자기 개선을 통한 LLM의 문제 해결 능력 향상

     * LADDER 소개: LADDER는 복잡한 문제를 점진적으로 더 간단한 형태로 변형하여 대형 언어 모델(LLM)이 스스로 문제 해결 능력을 향상시키는 프레임워크임. 기존의 데이터셋이나 인간의 피드백 없이 모델 자체의 능력을 활용하여 더 쉬운 문제 변형을 생성함.
     * 효과성: LADDER는 수학적 적분 분야에서 Llama 3.2 3B의 정확도를 1%에서 82%로 향상시켰으며, Qwen2.5 7B Deepseek-R1 Distilled가 MIT Integration Bee 예선에서 73%를 달성하게 함.
     * TTRL 소개: TTRL(Test-Time Reinforcement Learning)은 테스트 문제의 변형을 통해 추론 시 강화 학습을 수행하는 방법임. 이를 통해 Qwen2.5 7B Deepseek-R1 Distilled는 MIT Integration Bee 예선에서 90%의 최첨단 점수를 기록하며 OpenAI o1의 성능을 능가함.
     * 결과의 중요성: 이러한 결과는 자율적이고 전략적인 학습이 아키텍처 확장이나 인간 감독 없이도 상당한 능력 향상을 이룰 수 있음을 보여줌.

        Hacker News 의견

     * 이번 주에 무슨 일이 일어나고 있는지 궁금함. 최근 이틀 동안 머신러닝에서 흥미로운 돌파구를 여러 번 목격함
          + Google 연구팀이 디지털 논리 게이트를 매개로 NNs와 CLAs를 결합할 수 있다는 것을 발견함. 이를 통해 많은 비선형 문제를 간단하고 효율적인 디지털 회로로 줄일 수 있음
          + 신경망과 논리/지능 관련 새로운 발견들이 계속 나오고 있으며, 지능의 원리를 이해하는 데 얼마나 가까워졌는지에 대한 상상이 계속됨
     * 유명한 수론 수학자 Hendrik Lenstra의 인용문이 떠오름
          + ""해결할 수 없는 문제마다 해결할 수 없는 더 간단한 문제가 있다""는 말이 있음
     * 그들의 테스트 시간 강화 학습 접근법이 약간 의심스러움
          + TTRL은 언어 모델이 테스트 케이스의 더 간단한 버전을 생성하도록 요청함으로써 작동함. 간단한 문제를 얻으면, 그 문제에 대해 강화 학습을 수행하여 원래 문제에 대한 모델 성능을 강화하려고 함
          + 문제는 간단한 문제를 검증하기 위해 수치 적분기를 사용한다는 것임. 거의 간단하지 않은 문제가 생성되고, 모델이 실제 테스트 케이스에 대해 훈련할 수 있는 시나리오를 상상할 수 있음. 이는 테스트 세트에서 훈련하는 것과 같음
          + 나머지 논문은 괜찮음
     * LADDER의 수학적 적분 주제에서의 효과를 입증함. Llama 3.2 3B의 정확도를 1%에서 82%로 향상시킴
          + 이 방법이 작동한다는 것 자체가 흥미로움. 수학과 잘 작동한다는 점이 특히 흥미로움
          + 이 논문은 현재 훈련과 추론의 경계를 흐리는 움직임의 일부임. 그들의 방법 중 일부는 답을 모르는 질문을 더 간단한 질문으로 분해하고, 수치 '체커'를 사용하여 GRPO를 수행하는 것임. 이 강화된 모델은 더 많은 질문에 답할 수 있음
          + 인간도 이런 방식으로 많이 생각한다고 생각함. 어떤 것을 곰곰이 생각하고, 머릿속에서 돌리고, 비유하는 등. 테스트 시간 훈련을 추가하는 것은 고정된 추론에 대한 컨텍스트에 토큰을 추가하는 것보다 더 많은 생각을 할 수 있는 방법임
          + DeepSeek과 o1/o3가 추론 시간 토큰 생성 및 평가로 용량을 늘릴 수 있음을 보여주듯이, 추론 시간 자동화된 미세 조정으로도 용량을 늘릴 수 있을 것 같음
          + 이러한 기술이 확고해지면 이에 대해 새로운 방식으로 이야기하고 생각할 수 있기를 바람. 이들은 모두 어떤 수준에서 동일한 기본 프로세스의 일부임
          + 어쨌든 매우 멋짐
     * Frank Herbert는 이를 알고 있었음. 이는 Dune에서 묘사된 멘타츠의 재귀적 자기 검사 구현임
     * 테스트 시간 훈련/강화 학습은 미래의 수학 AI에 적합한 접근법임. 이는 주어진 문제에 대해 엄청난 양의 컴퓨팅을 사용하는 몇 안 되는 방법 중 하나일 가능성이 높음. Alphaproof가 이미 이를 수행했지만, 다시 수행되어 좋은 결과를 얻는 것이 좋음
     * 주제에서 벗어나지만, 그들의 사이트가 아름다움. 금광을 찾은 것 같은 느낌임
     * 어떤 이름들은 너무 매력적임
     * 논문 끝부분에서 2025 MIT Integration Bee 예선 시험의 두 문제를 언급함. 시스템이 계속해서 잘못된 답을 냈다고 함
          + 그들은 이 질문들이 시험에서 가장 복잡한 질문 중 하나라고 말하지만, 첫 번째 질문은 단지
          + ∫ ∛(x · ∜(x · ∜(x · √(x · √(x · ⋯ ))))) dx를 계산하는 것임
          + 이는 1/3 + 1/(34) + 1/(34*5) + ...를 계산하는 것임. 매우 고급 수학은 아님
"
"https://news.hada.io/topic?id=19640","RLama - Ollama를 활용한 오픈 소스 DocumentAI","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  RLama - Ollama를 활용한 오픈 소스 DocumentAI

     * 로컬 Ollama 모델과 연결하여 사용하는 문서를 위한 AI기반 질의응답 도구
     * 문서화 요구 사항에 맞춰 RAG(Retrieval-Augmented Generation) 시스템을 만들고, 관리하고, 상호 작용할 수 있음
     * macOS, Linux, Windows에서 사용 가능
     * 문서 폴더 색인: 지능적인 검색 및 쿼리를 위해 문서 폴더를 색인화 가능하며, 텍스트, 코드, PDF, DOCX 등 다양한 문서 형식을 지원함
     * 로컬 처리: Ollama 모델을 사용하여 모든 데이터를 로컬에서 처리하며, 데이터가 외부로 유출되지 않음
     * 상호작용 RAG 세션: 문서 지식 기반을 쿼리하기 위한 상호작용 세션을 생성할 수 있음.
     * 관리의 용이성 : RAG 시스템을 생성, 목록화, 삭제하는 간단한 명령어 제공
     * 개발자 친화적: 개발자와 기술 사용자들을 위해 Go 언어로 설계됨

        Hacker News 의견

     * 이 시스템은 문서를 청크로 나누지 않고 전체 문서를 Ollama에 임베딩 요청으로 보냄. 따라서 문서가 작을 때만 유용함
          + bge-m3 임베딩 모델은 8192 토큰의 시퀀스 길이를 가짐. rlama는 책 전체를 임베딩하려 하지만 Ollama는 처음 몇 페이지만 임베딩 요청에 넣을 수 있음
          + 검색 시 관련 구절 대신 전체 문서를 검색하고, 이를 1000자까지 잘라냄. 결과적으로 ""Buddha""라는 단어가 문서에 44,121번 등장하지만 모델은 ""Buddha에 대한 직접적인 언급이 없다""고 응답함
          + 더 나은 해결책은 문서를 임베딩 모델의 컨텍스트에 맞게 청크로 나누고, 메타데이터와 함께 해당 청크를 검색하는 것임
     * 사용자에게 검색 결과를 보여주는 것을 추천함. 벡터 검색 엔진만으로도 매우 유용함
          + 프롬프트를 변경하여 참조를 제공하도록 함 (예: 페이지 번호와 같은 청크 메타데이터 기반)
     * 프로젝트에 대한 칭찬과 함께 몇 가지 빠른 노트
          + 파일 시스템을 사용하는 앱에 대한 주요 우려 사항
               o 누가 읽을 수 있는지, 앱이 데이터를 공유하는지
               o 인터넷 접근을 차단하는 하드 블록이 필요함. rlama가 여전히 제대로 작동하는지
               o 앱이 파일을 수정/삭제할 수 있는지
               o 전체 파일 시스템 접근이 아닌 읽기 권한만 허용해야 함
     * 코드 노트: .ts (typescript)가 목록에 없는 것이 놀라움
     * 웹사이트가 매우 깔끔함. 처음부터 코딩한 것인지 템플릿 기반인지 궁금함
     * 자체 RAG를 만드는 것이 매우 쉬움. Ollama에 빠른 시작 튜토리얼이 있음. 필요에 맞게 프로세스를 조정할 수 있음
     * 이러한 도구의 유용성에 대해 회의적임. 환각 문제로 인해 얼마나 신뢰할 수 있는지, 출처를 얼마나 잘 인용하는지 궁금함
          + 데이터를 정확하게 얻는 것이 가장 중요함. AI 도구를 코딩에 가끔 사용하지만, 다른 용도로는 결과에 대해 확신할 수 없음
     * 이 프로젝트의 아키텍처/기술 스택에 대한 정보가 없음. github readme나 웹사이트에도 없음
          + Go로 작성되어 주말에 훑어볼 수 있을 만큼 작다는 점이 마음에 듦. 하지만 llm 생태계 도구에 시간을 낭비한 경험이 있어 기본적인 정보를 보지 않고 코드를 탐색하는 것을 주저함
          + 프로젝트의 아키텍처에 대한 고수준 개요를 제공하면 더 많은 사람들이 도구를 채택할 것임
     * 아마추어 역사가로서 아카이브에서 문서를 스캔하여 JPG 파일로 저장함. 이 지식 집합을 이해하는 가장 좋은 방법은 무엇인지 궁금함
          + 현재 Gemini로 자체 제작 중이지만, RAG 시스템을 처음부터 구축하지 않고 해결할 수 있는 방법이 있는지 확신이 없음
     * Ollama의 엔진인 llama.cpp와 함께 작동할 수 있는지 궁금함
          + 보통 llama.cpp를 소스에서 빌드하고 Huggingface에서 양자화된 모델을 다운로드함. Ollama는 사용한 적이 없음
     * API 인터페이스가 있어 다른 시스템에 통합할 수 있으면 좋겠음
     * 멋진 프로젝트임. 어떤 라이선스로 출시되었는지 궁금함. 문서화되어 있지 않음
     * RAG의 성능이 궁금함. 벡터 데이터베이스만 던져서는 유용하지 않음
"
"https://news.hada.io/topic?id=19595","LLM 개발 과정 8부 - 학습 가능한 Self-Attention 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                LLM 개발 과정 8부 - 학습 가능한 Self-Attention 기술

블로그 소개

     * Sebastian Raschka의 책 ""Build a Large Language Model (from Scratch)""를 기반으로 한 블로그 시리즈의 여덟 번째 글임.
     * 이번 글에서는 ""trainable self-attention""을 구현하는 방법을 다루고 있음.

GPT-유형 디코더 전용 트랜스포머 기반 LLM의 작동 방식

     * 문자열을 토큰으로 분할하고, 각 토큰을 벡터 시퀀스로 매핑하여 토큰 임베딩을 생성함.
     * 위치 임베딩을 생성하여 입력 임베딩 시퀀스를 만듦.
     * 입력 임베딩을 사용하여 각 토큰에 대한 주의 점수를 생성함.
     * 주의 점수를 정규화하여 주의 가중치를 생성함.
     * 각 토큰에 대한 컨텍스트 벡터를 생성함.

스케일된 내적 주의 메커니즘

     * 입력 시퀀스를 세 가지 행렬(쿼리, 키, 값)로 투영하여 주의 점수를 계산함.
     * 주의 점수를 정규화하여 주의 가중치를 생성하고, 이를 사용하여 컨텍스트 벡터를 계산함.
     * 이 모든 과정은 효율적인 행렬 곱셈을 통해 수행됨.

행렬을 사용한 공간 간 투영

     * 행렬은 벡터를 다른 차원의 공간으로 투영하는 데 사용됨.
     * 입력 임베딩을 쿼리, 키, 값 공간으로 투영하여 주의 점수를 계산함.

주의 점수의 정규화

     * 주의 점수를 정규화하기 위해 소프트맥스 함수를 사용함.
     * 차원의 제곱근으로 나누어 정규화하여 작은 기울기 문제를 해결함.

컨텍스트 벡터 생성

     * 주의 가중치를 사용하여 각 토큰의 컨텍스트 벡터를 계산함.
     * 입력 임베딩을 값 공간으로 투영하고, 주의 가중치로 가중합하여 컨텍스트 벡터를 생성함.

다음 단계

     * 인과적 자기 주의와 멀티헤드 주의를 다룰 예정임.
     * 자기 주의 메커니즘의 ""왜""에 대한 탐구를 계획 중임.

결론

     * 이 블로그 글은 자기 주의 메커니즘을 이해하는 데 도움을 줄 수 있음.
     * 추가적인 질문이나 의견은 댓글로 남길 수 있음.
"
"https://news.hada.io/topic?id=19613","AI 에이전트의 다음 단계: 2025년 주목할 트렌드들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     AI 에이전트의 다음 단계: 2025년 주목할 트렌드들

   AI 에이전트는 사용자를 대신해 복잡한 업무를 최소한의 개입으로 수행하는 LLM 기반 시스템이며, 기업 활동에서 급격히 증가하고 있음
    1. 범용 AI 에이전트 분야를 지배하는 빅테크와 주요 LLM 개발사들
    2. 전문화가 강화되는 민간 AI 에이전트 시장
    3. 명확하게 자리 잡는 AI 에이전트 인프라 시장
    4. 기업들의 AI 에이전트 도입이 본격화됨

1. 범용 AI 에이전트 분야를 지배하는 빅테크와 주요 LLM 개발사들

     * 빅테크 기업 및 주요 LLM(대형 언어 모델) 개발사들은 2025년에 더 저렴하고 성능이 뛰어난 AI 에이전트를 대중화시킬 것
     * 모델 비용은 매년 약 10배씩 저렴해지고 있으며, 개방형과 폐쇄형 모델 간의 성능 격차도 점차 좁혀지고 있어, 에이전트 개발에 유리한 환경 조성 중
     * 특히 OpenAI는 주간 활성 사용자 4억 명의 ChatGPT를 기반으로 자체 AI 에이전트 'Operator' 를 출시할 예정이며, Klarna와 Uber 같은 기업들은 이미 고객 지원용 AI 에이전트를 OpenAI와 협력하여 구축 중
     * Lyft는 Anthropic과 협력하여 고객 지원 에이전트를 도입, 문제 해결 시간을 87% 단축하는 성과를 냄

2. 전문화가 강화되는 민간 AI 에이전트 시장

     * AI 에이전트 스타트업들이 고객 데이터와 깊이 연동된 특화된 솔루션을 개발하여 경쟁력을 강화할 것으로 전망
     * 현재는 고객 지원, 코딩, 영업, 일반 기업 워크플로우 등의 범용 분야가 주류를 이루며, 앞으로 이 분야에서 데이터와 통합 워크플로우를 깊숙이 활용하는 기업들이 차별화될 전망
     * 특히 버티컬 산업별 솔루션(예: 헬스케어, 금융 서비스)이 빠르게 성장할 것으로 예상되며, 규제가 엄격하고 데이터 민감도가 높은 분야에서 산업별 전문성을 갖춘 AI 에이전트가 확산될 것
     * 헬스케어 분야의 Hippocratic AI는 데이터 통합과 설명 가능한 AI로 주목받고 있으며, Norm AI는 컴플라이언스 워크플로우 특화로 Citi Ventures 등에서 투자를 유치

3. 명확하게 자리 잡는 AI 에이전트 인프라 시장

     * 현재 분산된 AI 에이전트 개발 및 관리 환경이 점차 구조화되며, 분야별 특화된 솔루션들이 등장 중
     * 주요 인프라 분야:
          + 데이터 큐레이션(Data Curation): 기업의 비정형 데이터를 AI가 사용할 수 있는 형태로 변환하는 솔루션(LlamaIndex, Unstructured 등)
          + 웹 검색 및 도구 활용(Web Search & Tool Use): AI 기반 웹 자동화 도구(Browserbase 등)
          + 평가 및 모니터링(Evaluation & Observability): AI 에이전트의 신뢰성 및 정확성을 지속적으로 모니터링하는 도구(Langfuse, Haize Labs, Coval 등)
     * 또한 모든 기능을 한 번에 제공하는 통합 AI 에이전트 개발 플랫폼이 주목받으며, 특히 노코드 및 로우코드 솔루션을 통해 AI 전문지식이 없는 사용자도 쉽게 에이전트를 개발할 수 있도록 지원

4. 기업들의 AI 에이전트 도입이 본격화됨

     * 조사에 따르면 기업의 63% 가 AI 에이전트를 향후 12개월 내에 매우 중요한 전략으로 보고 있으며, 단순 실험에서 본격적인 도입 단계로 넘어가고 있음
     * Twilio와 같은 기존 기업용 소프트웨어 회사들이 자사 제품과 내부 업무에 AI 에이전트를 통합하며 시장의 성숙도를 높이고 있음
     * 그러나 다음과 같은 주요 과제가 존재:
          + 신뢰성 및 보안(응답자의 47%가 주요 우려 사항으로 지목)
          + 기술적 구현 어려움(41%)
          + 인력 및 기술 부족(35%)
     * 기업들은 데이터 프라이버시, 기존 시스템과의 통합 문제를 해결하고, AI 도입을 위한 전문 인력 확보에 주력해야 함
     * 'Human-in-the-loop'(인간이 개입하는 AI 감독 방식) 을 활용하거나 데이터 인프라를 견고히 구축하는 것이 성공적인 AI 에이전트 도입의 핵심 요소가 될 것

결론적으로 주목할 2025년의 AI 에이전트 트렌드 요약:

     * 빅테크와 주요 LLM 개발사가 일반적 용도의 AI 에이전트를 주도할 것
     * 민간 AI 에이전트 시장은 특정 산업 및 고객 데이터 중심으로 전문화될 것
     * AI 에이전트 인프라 시장은 보다 구조화되고 전문적인 형태로 자리 잡을 것
     * 기업들의 AI 에이전트 활용은 실험을 넘어 실제 구현 단계로 빠르게 전환될 것

   지금도 엄청나게 AI를 업무/개인적 케이스 모두에서 잘 활용하고 있는데, 에이전트는 또 어떨지 기대됩니다
"
"https://news.hada.io/topic?id=19618","간결한(Succinct) 데이터 구조","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          간결한(Succinct) 데이터 구조

     * 성능 최적화를 위해 논문을 읽던 중 Succinct Data Structures(간결한 데이터 구조) 개념을 처음 접하게 됨
     * 관련 논문을 찾다가 저명한 연구자인 Gonzalo Navarro 교수와 직접 연락을 주고받음
     * 기존의 배열, 해시맵, 트리 등과 달리 왜 이러한 데이터 구조가 잘 사용되지 않는지 의문이 생김
     * 이에 대해 간략히 설명하고자 함

Succinct Data Structures 개요

     * 일반적인 데이터 압축과 유사하게 데이터를 압축하여 저장하지만, 압축된 상태에서도 직접 활용 가능
     * 기존 압축 방식과 차이점: 데이터를 압축 해제하지 않고도 접근 및 조작 가능
     * 최근 25년 동안 연구가 활발하게 진행된 분야

Rust에서의 활용

     * 시스템 프로그래밍에서는 성능과 메모리 사용이 중요한데, 이러한 데이터 구조가 유용할 가능성이 높음
     * 기존 연구는 주로 **C++**에서 이루어졌으나, Rust에서도 구현을 찾기 시작함
     * Rust 개발자들에게 도움이 될 만한 라이브러리를 소개

Bit Vectors (비트 벡터)

     * 비트 배열 예시: [0, 1, 0, 1, 1, 0, 1, 0]
     * 64비트 시스템에서 64개의 비트를 단일 정수로 저장 가능하여 공간 절약 효과 있음
     * 비트 벡터 자체는 succinct 구조가 아니지만, 이를 효율적으로 활용하는 방법이 존재

Rank/Select Bit Vector

     * Rank 연산: 특정 인덱스 이전에 1이 몇 번 등장했는지 계산
          + 예시: rank(3) → 2
     * Select 연산: 특정 번째 1이 등장하는 위치 반환
          + 예시: select(2) → 3
     * O(1) 시간 복잡도로 실행 가능
     * 메모리 오버헤드가 적으며, 큰 문자열을 다룰 때 유용함
     * 활용 사례
          + 큰 문자열을 작은 문자열 단위로 나누어 저장할 때 유용
          + 특정 인덱스가 어느 부분 문자열에 속하는지 효율적으로 찾을 수 있음
          + 압축 저장 방식을 통해 메모리 사용량을 줄이면서도 빠른 검색 가능
     * Rust 라이브러리
          + vers: 높은 성능과 최소한의 오버헤드 제공
          + sucds: SArray 같은 희소(Sparse) 구현 지원
          + vers는 효율적인 데이터 구조 생성에 강점이 있어 향후 희소 구현도 지원 예정

Wavelet Matrix (웨이블릿 행렬)

     * Rank/Select 개념을 더 큰 알파벳을 포함하는 데이터에 확장
     * 예: DNA 서열 분석(A, C, G, T) 또는 텍스트 검색(UTF-8 문자, 256개 기호)
     * Rank/Select 비트 벡터를 기반으로 동작
     * Rust 라이브러리
          + vers에 웨이블릿 행렬 구현 포함

FM-Index (압축된 문자열 색인)

     * 대량의 텍스트 데이터를 압축하여 저장하면서도 검색 기능을 지원
     * 핵심 기능:
          + count(pattern): 특정 패턴(문자열)이 몇 번 등장하는지 계산
          + locate(pattern): 해당 패턴이 등장하는 모든 인덱스 반환
     * DNA 서열 검색 및 대규모 텍스트 검색에서 유용
     * Rust 라이브러리
          + fm-index 라이브러리 사용 가능
          + 기존에는 fid을 사용했으나 vers로 마이그레이션 후 성능 향상됨

Balanced Parentheses (균형 잡힌 괄호 표현)

     * 트리 구조를 2비트 per 노드 수준으로 압축하여 저장
     * 예제 트리:

   a
 /   \
b     c

     * (()()) 형태로 표현 가능
     * 1(열린 괄호)와 0(닫힌 괄호)로 변환 가능: 110100
     * Rank/Select 연산을 활용하여 트리 내 탐색 연산 최적화
     * Rust 라이브러리
          + vers의 dev-bp 브랜치에서 구현 중

응용: XML 저장 및 처리

     * XML을 균형 잡힌 괄호 표현을 이용해 저장 가능
     * XML 태그(p, div 등)를 효율적으로 처리하기 위해 Rank/Select 비트 벡터 활용
     * FM-Index를 사용하여 텍스트 검색 성능 향상

결론

     * succinct 데이터 구조는 적은 메모리 사용과 빠른 연산을 동시에 제공
     * C++에서 연구가 많았지만 Rust에서도 적극적으로 구현되고 있음
     * 연구자 및 오픈 소스 개발자들과 협업하면서 많은 가능성을 발견
     * 향후 다양한 컴퓨터 과학 분야에서 더 널리 사용될 가능성 큼

   Wavelet 을 활용한 압축 구조는 Djvu에서 표준으로 잘 사용되고 있습니다. 이미지 압축이 정말 훌륭하죠.

        Hacker News 의견

     * Gonzalo Navarro에게 이메일을 보내 질문을 했고, 그 결과로 함께 논문을 작성하게 되었음
          + 그의 또 다른 논문은 몇 가지 우아한 아이디어를 결합하여 비트벡터 랭크/셀렉트의 간단한 구현을 다루고 있음
          + 이 시기에 간결한 데이터 구조에 대해 매우 흥미를 느껴 여러 비트벡터 타입과 웨이브렛 매트릭스를 구현하는 Rust 라이브러리를 작성했음
          + 데이터 시각화 관점에서 공간 효율적인 데이터 구조가 클라이언트 측에서 대규모 데이터셋의 상호작용 탐색을 근본적으로 개선할 수 있는지 궁금했음
     * 이 분야에 30년 넘게 있었지만 ""간결한 데이터 구조""라는 것을 처음 들어봤음
          + 이 게시물을 보지 않았다면 아마도 알지 못했을 것임
          + 이 데이터 구조가 그래프 처리에 실질적인 응용을 가지고 있다면 중요한 발견일 수 있음
          + 이 주제가 매력적으로 느껴짐
     * 간결한 데이터 구조는 데이터셋이 메모리에 맞는 경우 기존 구조보다 빠르지 않을 수 있음
          + 하지만 대규모 데이터셋에서는 저장소 접근 시간이 지배적이므로 간결한 데이터 구조가 유리함
          + 간결한 트리는 예술 작품과 같음
     * Edward Kmett로부터 간결한 데이터 구조의 개념을 처음 들었음
          + 그는 유명한 Haskell 라이브러리 개발자이며, 오래전에 간결한 데이터 구조에 대한 강연을 했음
     * 간결한 데이터 구조는 매우 재미있음
          + Zig로 이를 구현했으며, 주요 구현은 4비트 미만의 요소를 사용하는 최소 완벽 해시 함수임
          + 이러한 알고리즘을 구현하는 것은 마법과 같음
     * Navarro의 책은 훌륭한 조사서임
          + Erik Demaine의 간결한 데이터 구조에 대한 강의도 훌륭함
     * 간결한 데이터 구조에 대해 아침을 보냈으며, 메모리 효율성이 놀라움
          + 대규모 XML 파일을 분석하는 프로젝트에서 RAM을 많이 소모하고 있음
          + 웨이브렛 매트릭스 개념이 텍스트 중심의 작업에 유망해 보임
     * 대형 구조체의 메모리 내 노드 표현을 효율적으로 만드는 방법이 있음
          + 드물게 사용되는 필드의 오프셋을 할당하고 비트마스크를 사용하여 필드의 존재를 나타냄
          + 마스킹과 popcount는 빠른 접근을 가능하게 함
     * Marisa trie는 매우 멋지고 유용한 간결한 데이터 구조임
          + High Performance Python 책에서도 언급됨
     * 간결한 데이터 구조를 위한 나의 기본 라이브러리는 SDSL-Lite임
"
"https://news.hada.io/topic?id=19671","Glue: 묵묵히 조직이 굴러가게 만드는 사람들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Glue: 묵묵히 조직이 굴러가게 만드는 사람들

   <개발자를 넘어 기술 리더로 가는 길>(원제: The Staff Engineer's Path)의 저자 타냐 라일리(Tanya Reilly)가 쓴 Being Glue라는 글을 소개하고, 내 생각을 덧붙임
     * Glue Work에 대해 언급한 과거 긱뉴스 글: https://news.hada.io/topic?id=17816

글 내용 요약

   분명 직함은 '소프트웨어 엔지니어'지만, 시니어가 되어가면서 코딩보다는 미팅에 더 많은 시간을 쏟게 되는 사람들이 겪는 문제가 있음

   이들은 아무도 '해야 한다'고 명시적으로 말한 적은 없지만 눈에 밟히는 일들을 하는 사람들임
     * 주니어 엔지니어 온보딩
     * 제품 로드맵 갱신
     * 사용자들과 대화
     * 놓친 이슈 챙기기
     * 설계 문서에 태클 걸기
     * 그리고 모두가 대략 같은 방향으로 가고 있는지 확인하기

   팀이, 제품이, 조직이 성공시키기 위해 이런 일을 자처했었지만 어느샌가부터 기술적 역량 향상에 쏟을 시간이 부족해졌고, 결국 '덜 기술적인' 역할을 제안받는 사람들을 저자는 Glue라고 정의함

   Glue Work을 하는 사람들은 조직에 큰 가치를 가져다주지만, 이러한 작업들을 충분히 인정하며 알아봐주지 못하는 조직에서는 행복하게 오랫동안 일하기 어려움.
     * 엔지니어인데 기술적 역량과 성과를 인정받지 못하니 번아웃이 오기도 하고, 승진에서 누락되기도 함

   저자는 Glue Work를 하다 보니 ""not technical enough""라고 평가받는 (특히 여성인) 엔지니어들이 덜 고통받고 더 인정받기 위한 몇 가지 방법을 제안

  1) Have that career conversation

   매니저와 커리어에 대한 대화를 나눠라. 내가 다음에 승진하려면 어떤 일들을 해야 하는가. 내가 지금 하는 일들이 승진에 영향을 미치는가 등. 매니저와 함께 목표를 세우고, 올바른 방향으로 가고 있는지 주기적으로 확인하라.

  2) Get a useful title

   Glue Work를 계속해야만 한다면 그 작업을 인정받기에 적절한 직함을 받아라. 테크 리드가 됐든 뭐가 됐든, Glue Work을 하고 있어도 '그래, 저건 저 사람이 자기 일을 잘 하고 있는 거지'라는 평가를 받기에 충분한 그런 직함.

  3) Tell the story

   본인이 하고 있는 일에 대한 내러티브, 스토리를 만들어 왜 이게 의미있는 일인지 주변에 알려라. 매니저 또한 같은 스토리를 얘기해줘야 한다. 다른 Glue들을 발견하고, 치하하라.

  4) Give up and do exactly the thing on the job ladder

   슬프게도 위 방법이 전부 먹히지 않는다면, Glue Work를 그만두는 것도 한 방법이다. 적어도 일시적으로는 '정확히 주어진' 일, 누가 봐도 '기술적인' 일만 해보라. '비공식적인 팀 리드' 역할도 그만둬라.

  5) Learning

   한편, 엔지니어라면 기술적으로 뛰어나야 하는 것도 당연한 일이다. Glue Work 대신 확보한 시간과 기회를 통해 성장하고, 본인이 엔지니어로서도 충분히 조직에 가치를 부여할 수 있음을 증명하라.

Glue Work에 대한 생각

   조직이 커지면 생기는 일들
     * 조직이 점점 커지다 보면 사람들 사이에, 조직 사이에 R&R이 겹치는 일이 생기게 됨
     * 그렇게 '겹치는' 부분은 아이러니하게도 그 누구도 열심히 챙기지 않는 영역이 되어버리는 일도 꽤 흔함
     * 애초에 아무도 맡지 않았지만 조직 전체가 굴러가기 위해 필요한 일들도 분명 존재함
     * 이것들이 모두 Glue Work

   나는 운이 좋았지만, 다른 사람들은?
     * 나도 여러 회사에서 Glue 역할을 많이 해왔음
     * 프론트엔드 개발자로서, 여러 조각난 컴포넌트들을 이어붙이고 부족한 부분을 채워서 '배포 가능한' 수준까지 (야근을 하든 어쩌든 간에) 완성하는 일도 자주 있었음
     * 다행히 나는 제 노력과 성과를 열심히 드러내는 사람이기도 했고, 좋은 매니저들을 만나기도 한 덕분에 인정받으며 빠르게 성장할 수 있었지만, 그렇지 못한 사람도 분명 주변에 많았음
     * 그래서 나는 일과 일 사이의 빈 공간을 (때론 말 없이) 묵묵하게 연결함으로써 조직이 굴러가게 만드는 분들의 작업에 명시적으로 감사인사를 드리고, 다른 사람들에게도 알리려고 노력을 많이 했음

   여러분 본인이 Glue이거나, Glue의 관리자라면, Glue Work이 더 인정받게 되기 위해 조직 차원에서 어떤 노력을 해야 할지 한번쯤 생각해보면 조직 구성원의 리텐션이 유지되는데 더 유리해질 수도 있음

   많은 분들이 4번으로 빠지는 것을 보게 되는데, 매우 안타깝습니다.
    4. Give up and do exactly the thing on the job ladder

   와...이 글과 굉장히 비슷한 사람이 있는데 공유해줘야겠네요.
   좋은 글 감사합니다.

   짧은 직장 생활입니다만, 본문에 내용에 공감하면서 한편으로는 ""묵묵히"" 업무를 한다는 건 피해야 한다는 생각도 듭니다. 너무 티나게 요란스럽게까지는 아니더라도, 최소한의 어필은 하는 게 본인에게 좋은 것 같습니다.

   네 동의합니다. 본인도 드러내야 하고, 기버들끼리 상호 샤라웃을 많이 해주면 좋을 것 같아요. 조직 문화 자체가 그걸 권장하고요.

   공감하는 바입니다. 나름 후배들에게는 티나게 일하라라고 조언하는편입니다
"
"https://news.hada.io/topic?id=19705","LLM을 활용한 코드 작성시 유의할 14가지","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        LLM을 활용한 코드 작성시 유의할 14가지
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  1. 합리적인 기대치 설정 (Set reasonable expectations)

     * 주요 내용:
       LLM은 본질적으로 고급 자동완성 도구임을 인지해야 하며, 전적으로 의존할 경우 오류나 부정확한 결과가 발생할 수 있음.
     * 활용법:
       자신의 코딩 능력을 보완하는 보조 도구로 활용하며, 과도한 기대를 버리고 실수를 검증하는 태도가 필요함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  2. 학습 데이터의 종료 시점을 고려 (Account for training cut-off dates)

     * 주요 내용:
       모델이 학습한 데이터의 최신성이 제한될 수 있으므로, 최신 라이브러리나 기술 변화에 대해 주의해야 함.
     * 활용법:
       안정성과 보편성이 입증된 라이브러리 사용을 우선시하고, 최신 기술이 필요한 경우 직접 예시를 제공하여 보완함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  3. 문맥의 중요성 (Context is king)

     * 주요 내용:
       대화의 모든 히스토리(프롬프트와 응답)가 결과에 영향을 미치므로, 문맥 관리가 중요함.
     * 활용법:
       복잡한 작업 시에는 기존 코드를 대화에 포함시켜 모델이 참고할 수 있도록 하고, 필요 시 새 대화로 초기화함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  4. 다양한 옵션 제시 요청 (Ask them for options)

     * 주요 내용:
       초기 연구 단계에서 LLM에게 여러 구현 옵션과 예시를 요청하여 가능한 선택지를 탐색함.
     * 활용법:
       “어떤 옵션이 있는가?” 등의 질문으로 기술적 가능성을 확인하고, 이후 선택된 옵션을 기반으로 구체화함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  5. 구체적인 지시 제시 (Tell them exactly what to do)

     * 주요 내용:
       생산 코드 작성 시에는 상세하고 명확한 지시를 내려 원하는 기능을 정확히 구현하도록 유도함.
     * 활용법:
       함수 시그니처, 사용해야 할 라이브러리, 예외 처리 등 구체적인 사항을 지시하여 LLM이 해당 요구사항에 맞게 코드를 작성하도록 함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  6. 작성된 코드는 반드시 테스트 (You have to test what it writes!)

     * 주요 내용:
       LLM이 작성한 코드라도 실제 동작 여부를 반드시 확인해야 하며, 자동화된 테스트 및 수동 검증이 필요함.
     * 활용법:
       작성된 코드에 대해 pytest 등 테스트 프레임워크를 활용하여 정상 작동 여부를 검증함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  7. 대화형 상호작용 유지 (Remember it’s a conversation)

     * 주요 내용:
       LLM과의 상호작용은 단발성이 아닌 반복적 대화 과정을 통해 결과를 개선할 수 있음.
     * 활용법:
       초기 결과가 미흡할 경우 추가 지시나 피드백을 통해 코드를 리팩토링하고 개선함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  8. 코드를 실행할 수 있는 도구 활용 (Use tools that can run the code for you)

     * 주요 내용:
       실행 가능한 샌드박스 환경이나 통합 개발 도구를 활용하여 LLM이 작성한 코드를 실제로 실행해 볼 수 있음.
     * 활용법:
       ChatGPT Code Interpreter, Claude Artifacts 등 안전한 실행 환경을 제공하는 도구를 사용하여 실시간 검증함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  9. ‘바이브 코딩’으로 학습 (Vibe-coding is a great way to learn)

     * 주요 내용:
       반복적이고 자유로운 실험을 통해 LLM의 활용법을 익히고, 다양한 아이디어를 빠르게 구현해보는 방법임.
     * 활용법:
       간단한 기능부터 시작해 반복적 시도와 개선을 통해 LLM의 한계를 파악하고 자신의 코딩 감각을 향상시킴.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  10. Claude Code를 활용한 상세 예제 (A detailed example using Claude Code)

     * 주요 내용:
       실제 프로젝트 예제를 통해 Claude Code가 어떻게 구체적인 요구사항을 반영하여 작업을 수행하는지 보여줌.
     * 활용법:
       단계별 프롬프트와 피드백을 통해 Python 스크립트와 HTML 페이지 생성 등 복합 작업을 수행하는 과정을 참고함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  11. 인간의 개입 필요성 (Be ready for the human to take over)

     * 주요 내용:
       LLM이 생성한 코드에도 오류나 부적합한 부분이 있을 수 있으므로, 최종 검토와 수정은 반드시 인간이 수행해야 함.
     * 활용법:
       LLM이 놓치는 세부사항이나 미묘한 오류를 직접 점검하고 보완하여 완성도 높은 결과물을 만듦.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  12. 개발 속도의 극대화 (The biggest advantage is speed of development)

     * 주요 내용:
       LLM을 활용하면 프로토타입 제작과 반복적인 작업 속도를 획기적으로 향상시킬 수 있음.
     * 활용법:
       초기 아이디어 검증이나 간단한 코드 작성에 LLM을 적극 활용하여 개발 시간을 단축함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  13. 기존 전문 지식의 증폭 (LLMs amplify existing expertise)

     * 주요 내용:
       이미 숙련된 개발자라면 LLM을 활용하여 자신의 전문성을 더욱 강화하고 생산성을 높일 수 있음.
     * 활용법:
       자신의 경험과 지식을 바탕으로 LLM에게 명확한 지시를 내려 보다 정교한 결과물을 도출함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  14. 추가 기능: 코드베이스 관련 질문 응답 (Bonus: answering questions about codebases)

     * 주요 내용:
       LLM은 코드베이스에 대한 질문에 답변하거나 코드의 특정 부분을 설명하는 데에도 유용하게 활용될 수 있음.
     * 활용법:
       코드의 구조나 특정 기능에 대해 질문하고, 관련 설명이나 문서를 생성하는 데 도움을 받을 수 있음.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   이 분 블로그 엄청나군요. 감사합니다.
"
"https://news.hada.io/topic?id=19715","DuckDB Local UI 공개 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           DuckDB Local UI 공개

     * DuckDB v1.2.1부터 로컬 웹 UI가 기본 제공되어 DB/테이블/뷰를 탐색하고, SQL을 실행하고, 컬럼 상세보기 및 MotherDuck과 통합도 제공
     * DuckDB는 최신 DB 기술을 쉽게 활용할 수 있도록 설계된 프로젝트로 다양한 언어와 플랫폼에서 사용 가능
     * 기존의 CLI는 SQL 쿼리를 실행하는 데 유용하지만, 긴 쿼리 작업에는 불편함이 있음. DuckDB UI는 이러한 문제를 해결하기 위해 개발됨.

DuckDB UI 시작하기

     * DuckDB v1.2.1부터 로컬 웹 사용자 인터페이스가 기본 제공됨.
     * 터미널에서 duckdb -ui 명령어로 시작하거나, CALL start_ui(); SQL 명령어로 실행 가능함.
     * UI는 SQL 스크립트를 정의하고 쿼리 결과를 보여주는 인터랙티브 노트북을 사용함.

기능

     * 데이터베이스: 연결된 데이터베이스가 왼쪽에 표시됨. 테이블과 뷰를 탐색할 수 있음.
     * 테이블 요약: 테이블이나 뷰를 클릭하면 요약 정보가 표시됨. 열의 이름, 타입, 데이터 프로필 등을 확인할 수 있음.
     * 노트북: 작업을 노트북에 정리할 수 있음. SQL 문을 실행하고 결과를 정렬, 필터링, 변환 가능함.
     * 컬럼 탐색기: 결과를 요약하여 보여줌. 각 열을 자세히 탐색할 수 있음.
     * MotherDuck 통합: MotherDuck에 연결하여 클라우드 데이터 웨어하우스에 파일과 테이블을 저장 가능함.

기타

     * DuckDB UI는 계속 개발 중이며, 기능 추가 및 개선 예정
     * UI는 .duckdb 디렉토리에 파일을 생성하며, 노트북과 상태는 ui.db에 저장됨.
     * UI는 DuckDB 확장으로 구현되며, 로컬 HTTP 서버를 포함하여 UI 브라우저 애플리케이션을 제공함.

요약

     * DuckDB UI는 DuckDB의 강력한 웹 인터페이스로, 간단하고 빠르며 기능이 풍부하고 휴대 가능함.
     * DuckDB UI 확장은 오픈 소스로 제공되며, 더 깊이 있는 코드를 보고 싶다면 duckdb/duckdb-ui 저장소를 방문할 수 있음.
     * 프론트엔드 소스 코드는 현재 오픈 소스로 제공되지 않으며, 공개 여부는 검토 중임.

   멋짐. sqlite가 이렇게 한다면. 진짜 난리가 날 거 같다는 생각을 함. 물론 보안취약점도 함께.

        Hacker News 의견

     * 출시를 축하함. 매우 멋져 보임
     * 로컬 비웹 기반 편집기를 찾는 사람은 qstudio를 확인해 보길 바람
     * UI가 훌륭해 보임. 게시물에 오픈 소스라고 언급되었지만, 오픈 소스인 것은 DuckDB 확장임
          + 실제 UI의 코드를 찾을 수 없었음
          + 실제 UI가 오픈 소스인지, 아니면 MotherDuck이 독점적으로 사용하는 것인지 궁금함
          + 현재로서는 인터넷 연결 없이는 작동하지 않을 것 같음
     * UI 미학이 DuckDB로 구동되는 훌륭한 Rill과 유사해 보임
          + Rill은 더 나은 시각화와 피벗 테이블을 제공하며, Go/Svelte로 작성된 오픈 소스 코드로 전체적으로 완성도 높은 제품임
          + DuckDB UI는 SQL 쿼리를 편집하기 위한 Jupyter 노트북 스타일의 ""셀""이 매우 좋음
     * 데이터 시각화를 위해 Perspective를 내장할 것을 제안함
          + 우리는 DuckDB와 Perspective를 클라이언트 측 BI 용도로 사용하며, 매우 좋았음
     * MotherDuck이 DuckDB에서 더 많은 돈을 벌기 위해 이를 사용하려고 한다는 느낌이 들며, 이는 위험한 경로임
     * UI가 멋지고 자체적으로 환영할 만한 추가 사항임
          + DuckDB 릴리스에 기본 확장으로 포함되는 것에 대해 약간의 의견 차이가 있음
          + DuckDB는 지금까지 VC 자금 없이 번창했지만, MotherDuck은 최소 1억 달러의 VC 자금을 보유하고 있음
          + 무료 및 오픈 소스 작업과 상업적 작업의 경계가 어디인지 궁금함
          + DuckDB의 인기가 증가함에 따라 미래에 대한 명확한 설명을 원함
          + DuckDB는 좋은 도구이며, 주로 Python을 통해 Jupyter에서 사용함
          + 상업적 서비스가 필요하지 않았으며, 이 UI는 상업적 측면으로 기울어져 있는 것 같음
          + DuckDB와 그 커뮤니티가 더 큰 성과를 이루기를 희망함
     * 나는 MotherDuck의 공동 창립자 중 한 명임
          + 우리 팀은 DuckDB Labs 팀과 협력하여 UI를 구축하고 있음
          + 첫 번째 릴리스임. 많은 기능 요청이 있을 것임
          + 이 릴리스를 즐기길 바람. 우리는 이를 만드는 데 많은 재미를 느꼈음
     * 나는 컬럼 탐색기를 정말 좋아함
          + 며칠 전 Kaggle Dataset과 같은 기존 컬럼 탐색기를 찾고 있었지만, 찾을 수 없었음
          + DuckDB의 이 탐색기가 더 나음
     * 프론트엔드가 현재 오픈 소스가 아니라는 의견이 있었음
          + CLI에서 시작하여 GUI가 더 나은 경우가 있어, CLI에서 시작할 수 있는 기능이 매우 좋음
     * DuckDB Labs를 사랑함
          + 그들은 멋진 엔진을 작업하고, Databricks로부터 Delta 지원을 구축하기 위해 돈을 받음
          + MotherDuck으로부터 UI를 구축하기 위해 돈을 받음
          + 항상 핵심 오픈 소스 제공을 개선하지만, 대규모 VC 자금을 받은 회사들이 이를 위해 비용을 지불함
"
"https://news.hada.io/topic?id=19679","Python 3.14 tail-call(꼬리 호출) 인터프리터의 성능","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Python 3.14 tail-call(꼬리 호출) 인터프리터의 성능

     * CPython 프로젝트는 최근 바이트코드 인터프리터의 새로운 구현 전략을 도입. 초기 결과는 다양한 플랫폼에서 평균 10-15%의 성능 향상을 보여줬음
     * 그러나 이 성능 향상은 주로 LLVM 19의 회귀 문제를 우회한 결과였음. 더 나은 기준(예: GCC, clang-18, 특정 튜닝 플래그가 있는 LLVM 19)과 비교했을 때 성능 향상은 1-5%로 감소

성능 결과

     * 여러 컴파일러와 구성 옵션을 사용하여 CPython 인터프리터의 여러 빌드를 벤치마크했음. Intel 서버와 Apple M1 Macbook Air에서 테스트했음.
     * 모든 빌드는 LTO와 PGO를 사용했음. clang18을 기준으로 pypeformance/pyperf compare_to에서 보고된 평균을 사용했음.
     * 컴파일러 성능 비교
          + Apple M1 Macbook Air :
               o clang18: 기준
               o clang19: 1.12배 느림
               o clang19.taildup: 1.02배 느림
               o clang19.tc: 1.00배 느림
               o gcc: N/A
     * 꼬리 호출 인터프리터는 여전히 clang-18과 비교하여 속도 향상을 보였지만, clang-19로 이동하면서의 속도 저하가 더 극적이었음.

LLVM 회귀

  간단한 배경

     * 전통적인 바이트코드 인터프리터는 while 루프 내의 switch 문으로 구성됨. 대부분의 컴파일러는 switch를 점프 테이블로 컴파일함.
     * 현대 C 컴파일러는 레이블의 주소를 취하고 이를 ""계산된 goto""로 사용하는 패턴을 지원함. CPython은 꼬리 호출 작업 전까지 이 패턴을 사용했음.

  LLVM 19 회귀

     * LLVM 19는 tail-duplication 패스에 제한을 두어, IR 크기가 특정 한계를 초과할 경우 중복을 중단하도록 했음. 이로 인해 CPython에서는 모든 디스패치 점프가 병합되어 계산된 goto 기반 구현의 목적이 완전히 무산됨.

    추가 이상 현상

     * 꼬리 호출 중복 논리의 변경이 회귀를 초래했음을 확신하지만, 회귀의 크기를 완전히 설명할 수는 없음.
     * 현대 프로세서에서는 2-4%의 속도 향상이 더 일반적임.

    계산된 goto가 필요한가?

     * clang19.nocg 벤치마크는 clang19보다 빠르다고 주장함. 이는 컴파일러가 switch 기반 인터프리터를 사용하여 동일한 최적화를 수행할 수 있음을 보여줌.

  수정

     * LLVM 풀 리퀘스트 114990이 회귀를 수정했음. 이 수정은 예상 성능을 복원함.

반성

  벤치마킹에 대하여

     * 시스템 최적화 시 벤치마크와 벤치마킹 방법론을 구성하고, 제안된 변경 사항을 평가함.
     * 벤치마크는 특정 데이터 포인트를 일반화하기 위해 더 많은 가정과 믿음을 필요로 함.

    기준선

     * 새로운 솔루션이나 방법을 제안할 때, ""현재 가장 잘 알려진 접근 방식""과 비교하는 것이 일반적임.

  소프트웨어 엔지니어링에 대하여

     * 소프트웨어 시스템은 복잡하고 상호 연결되어 있으며, 빠르게 변화하고 있음.
     * 최적화 컴파일러는 프로그래머의 의도를 존중하면서도 코드를 최적화해야 하는 긴장 관계에 있음.

    최적화 컴파일러

     * musttail 속성은 최적화와 관련된 새로운 종류의 컴파일러 기능을 나타냄. 이는 성능에 민감한 코드를 작성하는 데 더 강력한 스타일을 제공할 수 있음.

  nix에 대한 한 가지 더

     * nix는 이 프로젝트에서 매우 유용했음. 여러 버전의 Python 인터프리터를 관리하고 빌드하는 데 큰 도움이 되었음.

        Hacker News 의견

     * 안녕하세요. 저는 CPython에 tail-calling 인터프리터를 도입한 PR의 작성자임
          + 먼저, 이 문제의 근본을 찾기 위해 거의 한 달을 소비한 Nelson에게 감사의 말을 전하고 싶음
          + 또한, 이런 큰 실수를 저질러 매우 부끄럽고 죄송함을 느끼고 있음
          + 우리가 사용한 컴파일러에 이런 버그가 있을 줄은 CPython 팀도 예상하지 못했음
          + 사과 블로그 게시물을 여기에 올렸음: 링크
     * 벤치마킹은 정말로 잘하기 어려운 작업임
          + 최근에 알고리즘을 약 15% 더 빠르게 만드는 방법을 발견했음
          + 그러나 테스트 중에 더 빠른 버전의 함수를 호출하지 않고도 원래 코드가 15% 더 빨라짐
          + 이는 코드와 메모리 배치 문제로, CPU 캐시와의 정렬이 더 잘 맞았기 때문임
          + Casey Muratori가 이런 주제에 대해 흥미로운 시리즈를 진행 중임
     * 저자가 이 문제의 진실을 파헤친 것에 찬사를 보냄
          + Python 3.14의 tail-call 인터프리터는 여전히 좋은 개선점임
          + 이 사건은 벤치마킹의 엄격함과 다양한 환경에서의 테스트 중요성을 가르쳐 주었음
          + 또한, 이제 모든 사람에게 이익이 될 수 있는 컴파일러 버그를 발견하게 됨
          + 얼마나 많은 ""X% 더 빠름"" 결과가 실제로 벤치마킹 아티팩트나 알려지지 않은 회귀로 인한 것인지 궁금함
     * C가 ""기계에 가까운"" 언어가 아니라는 좋은 예임
          + clang-19가 계산된 goto 인터프리터를 ""올바르게"" 컴파일하지만, 최적화 의도와는 완전히 다른 출력을 생성함
          + 다른 컴파일러 버전도 ""순진한"" switch() 기반 인터프리터에 최적화를 적용함
     * 컴파일러가 루프를 조직하는 방식을 조정하여 tail-call 인터프리터가 발표된 만큼 효과적이지 않음
          + CPU 아키텍처와 버전이 매우 중요함
          + C 추상 기계는 의도를 제대로 표현하기에 충분히 저수준이 아님
          + 특정 파라노이드 인터프리터 구현은 직접 어셈블리를 작성하는 것으로 돌아감
          + luajit는 매크로 시스템을 구현하여 효율적인 어셈블리 루프 구현을 아키텍처 간에 이식 가능하게 만듦
     * Python 빌드의 성능을 평가하는 것은 매우 어려움
          + 최근 astral 팀이 conda-forge 빌드가 다른 대부분의 빌드보다 빠르다는 것을 보여줌
          + tail-call 인터프리터가 다른 빌드 최적화와 함께 어떻게 작동하는지 궁금함
     * 관련 논의:
          + Python 3.14의 새로운 기능
          + 블로그 게시물
     * 훌륭한 기사임
          + 참조된 기사 중 하나에서 3.14.0a5가 3.13보다 1.12배 빠르다고 언급함
          + 벤치마크를 다른 프로세스로 과부하된 상태에서 실행했는지 혼란스러움
          + 벤치마크는 외부 변수를 제거하기 위해 엄격히 통제된 환경에서 수행되어야 함
     * 최근 Python 3.9에서 3.13까지 벤치마킹을 수행함
          + 3.11까지는 성능이 개선되었으나, 3.12와 3.13은 3.11보다 약 10% 느렸음
          + 자체 벤치마크가 충분하지 않다고 생각했지만, 핵심 서비스에 배포했을 때도 동일한 변화를 관찰함
     * 이런 최적화가 tail-call 최적화와 어떻게 관련이 있는지 궁금함
          + 인터프리터 점프 테이블 구현이 스택 프레임 생성에 영향을 주지 않아야 함
"
"https://news.hada.io/topic?id=19678","조용한 스타트업 킬러","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              조용한 스타트업 킬러

     * ""대부분의 이사회 멤버는 부족한 점을 보완하지 못함"" , ""좋은 이사회(Board) 멤버가 되는 것은 매우 어려움""
     * 스스로를 솔직하게 바라보면, 이사회 역할 수행이 쉽지 않다는 사실을 깨닫게 됨
     * 대부분의 사람은 자신이 이사회에 적합하다고 여기는 경향이 있지만, 실제로는 역할과 책임, 권한, 그리고 창업자와의 관계 측면에서 오해가 많음
     * 본인의 사례: 짧은 시간 안에 상황을 정확히 파악해 해결책을 제시하는 능력은 탁월하지만, 훌륭한 board 멤버가 되는 데에는 한계가 있었음
     * 투자자의 자금, 경험, 질문이 가치를 더할 때도 있지만, 종종 걸림돌이 되기도 함
     * 투자와 거버넌스 사이의 근본적인 차이를 제대로 이해하지 못하면 회사가 피해를 입게 됨

투자자들: 당신의 잡은 관리하는 것이 아니라 지원임

     * 투자자로서 스타트업에 투자하는 이유는 창업자를 신뢰하기 때문임
     * 창업자가 배워나가며 실행하고 조정할 수 있다는 믿음에서 투자금을 제공하는 것임
     * 투자금은 창업자의 실행력을 믿는 베팅이지, 미시적 관리나 불안 해소를 위한 핑계가 아님

  당신의 Role

     * Stay informed
          + 정기 업데이트를 꼼꼼히 확인하고, 필요한 질문을 하며, 필요 시 건설적인 문제 제기를 시도하는 태도임
          + 통제나 불안 대신 호기심과 협조를 기반으로 대화하는 접근법임
     * Be available
          + 창업자가 연락할 때 언제든 응답할 준비가 되어 있어야 함
          + ego가 아니라 요청에 따라 도움을 주는 지원자 역할임
     * Know your limits
          + 회사 경영은 창업자의 몫임
          + 최종 의사결정권은 창업자에게 있음
     * 최고의 투자자는 이를 본능적으로 이해함
     * 최악의 투자자는 “투자금 = 의사결정권”으로 착각하고, 지나친 간섭으로 회사 운영에 방해를 줌

     예시: 투자를 받은 후, 투자자가 유명 CFO나 FAANG 출신의 VP를 영입하라고 무리하게 요구하는 상황
     * 겉보기에는 훌륭해 보이지만, 실제로는 회사 스테이지에 맞지 않아 실패하거나, 창업자가 투자자를 달래려다 시간과 리소스를 낭비하는 결과임

거버넌스(Governance) : 스타트업을 살릴 수도 망칠 수도 있는 보이지 않는 손

     * 거버넌스는 투자와는 전혀 다른 개념임
     * 이사회 멤버가 되었다면, 회사 운영 자체가 아니라 “운영이 원활히 이루어질 수 있는 환경”을 마련하는 것이 역할임
     * 그 의미는
          + Setting up the right structure
               o 이사회 멤버 구성이 적절한지, 어떤 주기로 미팅을 할지, 갈등이 생길 때 어떻게 해결할지 결정하는 틀임
          + Creating an environment for hard conversations
               o 정치적 계산이나 포장 없는 솔직한 대화를 가능케 하는 환경임
          + Holding people accountable
               o 창업자는 실행을 담당하고, 이사회는 지원하며, 문제가 생기면 빠르고 효과적으로 개입할 책임이 있음
     * 이상적인 거버넌스는 지루할 정도로 효율적이고 명확하며 유지 비용이 적음
     * 최악의 거버넌스는 무질서함
          + 단지 큰 투자금을 낸 사람 위주로 이사회가 구성되거나, 너무 많은 멤버가 참여해 의사결정이 지연되는 상황임

     예: 네 명의 투자자가 서로 다른 목표를 추구해 이사회가 분열된 스타트업
     * 창업자는 투자자들 간의 정치 싸움을 조율하느라 실제 사업 운영에 집중하지 못함
     * 결국 이사회를 세 명으로 축소하고, 의사결정 규칙을 명확히 설정하며, 미팅을 행동 중심으로 재구성해 문제를 해결함

이사회 거버넌스? 충분히 커질때 까지는 잊어버릴 것

     * 초창기(Seed~Series A) 스타트업에 과도하게 공식적인 거버넌스를 도입하는 것은 실용적이지 않음
     * 작은 팀으로 빠르게 움직여야 하는 시점에는 위원회나 투표 절차 같은 복잡한 이사회 구조가 맞지 않음
     * 빠른 의사결정과 유연한 커뮤니케이션이 필요한 단계이므로, 형식적인 거버넌스보다 핵심 멤버가 밀접하게 대화하는 환경이 중요함

언제부터 공식적인 거버넌스가 의미를 갖기 시작할까?

     * 매출이 실제로 발생하고, 경영진이 구성되며, 창업자 열정에만 의존하지 않을 정도로 사업이 안정되었을 때
     * 수십~수백 명의 인력에게 영향을 미치는 의사결정이 늘어갈 때
     * 회사가 복잡해져 책임 소재를 체계적으로 구조화해야 할 필요성이 생겼을 때

그럼 그전에는? 거버넌스는 절차보다는 대화에 가까운 개념임

     * 많은 투자자는 이사회 멤버로 적합하지 않음
     * 큰 금액을 투자했다고 해서 곧바로 거버넌스 권한을 가져야 하는 것은 아님
     * 투자자는 아래와 같은 내면적 갈등을 스스로 관리 할 수 없음
         1. 회사에 최선은 무엇인가?
         2. 수익에 가장 좋은 것은 무엇인가?
         3. 자존감(ego)에 가장 좋은 것은 무엇인가?
     * 상황이 어려워지면, 대부분 자기 이익을 우선하거나 두려움에 기반해 행동하게 됨
     * 창업자는 이런 이해 충돌이 있는 인물이 회사의 핵심 의사결정에 영향을 주는 리스크를 최소화해야 함

     예
     * 회사가 더 크게 성장할 수 있음에도, 투자금 회수를 위해 인수가를 제안하며 exit을 유도하는 행동
     * 포트폴리오 가치 상승을 위해 무리한 높이의 밸류에이션으로 라운드를 진행하도록 압박하는 상황
     * 창업자를 신뢰하지 못해 과도한 고용이나 조직 변화를 요구하는 경우

     * 그중에 최악은 많은 창업자들이 자신들이 선택할 옵션이 없다고 생각해서 그대로 내버려 둔다는 것
          + 이사회 멤버 선정 권한은 창업자에게 있음, 가장 큰 투자자를 기준으로 하지 않음
     * 많은 창업자가 잊는 사실: 이사회 멤버는 결국 창업자 당신이 결정하는 것임
          + 투자금을 가장 크게 낸 사람, 목소리가 가장 큰 사람, 이력만 화려한 사람을 무조건 이사회에 들일 필요가 없음
     * 투자금을 모을 때, 당신은 단순히 자본을 선택하는 것이 아니라, 회사에서 누가 권력을 가질지 선택하는 것
     * 좋은 창업자는 첫날부터 명확한 기대치를 설정함
          + “돈이 이사회 자리를 사는 것이 아니라, 가치가 그 자리를 얻는 것”
          + “자신의 지분만 지키려는 사람들로 가득 찬 이사회는 필요 없음”
          + “이것은 내 회사임 누가 경영을 돕는지는 내가 결정함”
     * VC는 흔히 이사회 자리를 ‘투자 금액에 대한 당연한 대가’처럼 여기지만, 최고의 창업자는 이 부분에서 치열하게 협상함

거버넌스는 당신을 추진(Propel)할 수도 있고, 침몰(Sink)시킬 수도 있음

     * 좋은 거버넌스는 훌륭한 심판처럼, 눈에 잘 띄지 않으면서도 경기를 공정하게 운영하도록 돕는 역할임
     * 잘못된 거버넌스는 회사 전체를 흔드는 치명적 장애물이 됨
     * 창업자는 이사회가 부담이 아니라 추진력이 되도록 설계해야 함
          + lean하게 구성하고, 실질적 가치를 주는 사람만 선택하며, 스스로의 갈등을 해결하지 못하는 투자자에게 끌려다니지 않는 자세가 필요함
     * 근본적으로, 투자자는 투자하고, 창업자는 실행함
          + 서로의 역할을 침범하는 순간 회사의 속도와 추진력이 떨어짐
     * 거버넌스는 회사 운영에 교량 역할을 해야 함, 병목을 만들어서는 안 됨

     “Suppress the noise” — 불필요한 소음(간섭)이나 혼란을 없애는 것이 궁극적 목표임

   이사회를 바라보며 느꼈던 점이었는데, 대입하며 잘 읽었습니다. 회사를 처음 만들고 지금 내가 하고있는 일이 대화수준의 거버넌스였구나! 라고 이해하게되었습니다. 잘 꾸려나가보겠습니다.

   한가지 여쭈어보고 싶은 것이 있는데, 이사회에서 객관적인 의견과 지지와 응원, 네트워크 지원을 해주는 분이 계신데요. 초기 투자를 받고 회사 핵심 C레밸로 들어오시면 이해관계가 생겨버려 가치가 훼손되지 않을까 고민이 되는데 좋은 해결방법이 있을까요?

   흥미롭게 잘 읽었습니다

   국내 회사는 이사회 멤버들 구성이 그냥 구색 맞추기인 경우가 많기도 하고, 이런 내용은 실제로 창업하고 거버넌스가 필요할 정도까지 회사를 키워봐야지만 느낄수 있는 얘기이긴 합니다만, 미리 읽어두면 좋을 내용이라 공유해 봅니다.

     회사가 더 크게 성장할 수 있음에도, 투자금 회수를 위해 인수가를 제안하며 exit을 유도하는 행동

   이런거 한번 당해보면 투자자에 대한 신뢰가 팍 사라지죠.
"
"https://news.hada.io/topic?id=19668","테슬라 주행 거리 불만 억제를 위한 비밀 팀 설립 (2023)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   테슬라 주행 거리 불만 억제를 위한 비밀 팀 설립 (2023)

테슬라의 주행거리 문제 및 은폐 전략

     * 테슬라는 약 10년 전부터 차량의 대시보드 주행거리 예측 소프트웨어를 조작해 ""장밋빛"" 예측치를 제공함
     * 실제 주행거리가 회사의 광고된 수치보다 훨씬 짧다는 고객 불만이 폭증
     * 작년에 테슬라는 라스베이거스에 ""전환팀(Diversion Team)""을 신설해 주행거리 관련 서비스 예약을 취소하도록 함

  고객 불만 사례

     * 알렉상드르 폰신(Alexandre Ponsin)은 2021년식 중고 모델 3을 구입 후 콜로라도에서 캘리포니아로 여행 중 주행거리가 광고된 353마일의 절반에도 미치지 못함
     * 테슬라는 원격 진단에서 배터리에 문제가 없다는 메시지를 보냈고, 서비스 예약을 취소
     * 폰신은 여전히 문제가 있다고 주장했으나 테슬라는 서비스 방문을 거부

  전환팀의 운영 방식

     * 전환팀은 고객의 주행거리 불만이 제기되면 예약을 취소하도록 교육받음
     * 직원들은 예약 취소 시 동료들이 축하하며 금속 실로폰을 치는 방식으로 성과를 기념함
     * 직원들은 매일 평균 몇 건의 예약을 취소했는지 추적됨
     * 관리자들은 예약 취소 1건당 약 $1,000를 절감할 수 있다고 직원들에게 설명

  과장된 주행거리 예측의 원인

     * 테슬라는 약 10년 전부터 마케팅 목적으로 주행거리 예측 소프트웨어에 과장된 값을 입력
     * 배터리가 50% 이하로 떨어지면 보다 현실적인 수치를 보여주도록 설계됨
     * 배터리가 완전히 방전되었을 때 약 15마일(24km)의 추가 주행거리를 제공하는 '안전 버퍼' 포함
     * 이 같은 과장된 예측은 엘론 머스크의 지시에 따른 것

  주행거리 예측 오류의 영향

     * 주행거리는 전기차 구매에서 가장 중요한 요인 중 하나이며, 주행거리 불안(range anxiety)이 전기차 보급의 주요 장애물임
     * 테슬라는 2023년에 미국 환경보호청(EPA)으로부터 주행거리 예측을 평균 3% 낮추도록 요구받음
     * 한국에서는 테슬라가 추운 날씨에서 광고된 주행거리의 절반에 미치지 못한다는 이유로 약 $210만의 벌금 부과됨

  다른 자동차 제조업체와의 비교

     * 다른 제조업체(포드, 메르세데스, 현대 등)는 보수적인 주행거리 예측을 제공
     * 메르세데스는 ""소비자의 실제 운전 습관을 가장 잘 반영하기 위해"" 보수적인 예측을 제공한다고 설명
     * 테슬라는 EPA의 표준 계산식을 사용하지 않고 자체 테스트를 통해 유리한 결과 도출

  전환팀의 내부 운영 방식

     * 테슬라는 고객의 불만을 원격 진단으로 해결하도록 하고, 실제 서비스 예약을 최소화하도록 지시
     * 서비스 예약은 테슬라 앱을 통해 진행되며, 주행거리 문제로 인한 예약은 자동으로 전환팀으로 이관됨
     * 상담원들은 고객의 차량 상태에 대해 원격 진단 없이 ""문제 없음""이라고 통보하도록 훈련됨
     * 고객과의 전화 통화는 5분 이내에 종료해야 하며, 응답이 없으면 케이스를 종료하도록 지시됨

  주행거리 문제에 대한 고객 반응

     * 폰신은 자신의 모델 3이 기대했던 성능에 미치지 못한다고 인식
     * 테슬라의 주행거리 예측이 실제 상황을 반영하지 못한다고 결론
     * ""테슬라는 특정 조건에서 성능 변동이 클 수 있다는 점을 명확히 밝혀야 한다""고 주장

  결론

     * 테슬라는 주행거리 문제를 고객에게 투명하게 설명하지 않고 은폐 전략을 사용
     * 고객들은 실제 주행거리가 광고된 것보다 짧다는 점을 인지하고 있음
     * 테슬라는 여전히 주행거리 문제와 관련된 규제 당국의 감시 대상임

        Hacker News 의견

     * ""완전 자율 주행"" 자동차를 판매하는 회사에서, 광고된 주행 거리가 ""큰 과장""일 것이라고 이미 예상했음
          + 대시보드의 코드가 주행 거리를 더 과장하는 것은 흥미로움
          + Tesla가 PR이나 커밋을 하지 않고, 누구나 자신의 노트북에서 무엇이든 빌드하여 자동차에 넣는다고 상상함
          + 기사 작성자가 EPA를 여러 번 언급하는 것을 즐기는 것 같음
     * 2023년형 모델 3을 소유하고 있으며, 270마일로 평가되었으나 최대 120마일, 보통 90마일 정도 주행 가능함
          + 출퇴근 시 가파른 언덕을 오르며, 날씨는 매우 춥지 않음
          + 무료 사무실 충전이 없었다면 주행 거리 때문에 화가 났을 것임
          + Tesla의 서비스가 유명하게 나쁘며, 직원들이 서비스 요청을 처리하는 방식이 많은 것을 설명함
     * 플로리다에서 워싱턴까지 자동차 여행을 하며, Tesla 주행 거리 추정에 불만을 가진 사람들은 모두 과속한다고 믿음
          + 운전 스타일을 바꾸면 추정치보다 더 많은 주행 거리를 얻을 수 있음
          + 자율 주행 컴퓨터/카메라의 전력 소모를 인식할 수 있을 정도로 예측 가능하고 정확함
          + 산 정상에서 다음 충전소까지 100km 남았다고 했으나, 실제로는 90km 남았을 때 17km 남은 상태로 도착함
          + 과속하지 않으면 추정치는 정말 좋고 유용함
     * Tesla는 350마일 이상의 주행 거리를 광고하지만, 보통 날씨와 조건에서 300마일을 달성할 수 없을 것이라고 생각함
          + EPA 추정치가 다르다고 변명할 때 사용하는 요소들임
     * 예약을 취소하지 말고 수리를 요구하며, 3-4번 시도 후에도 ""예상된 특성""이나 ""교육""으로 종료되면 레몬법 환불 요청을 하라고 조언함
          + 구매 계약서를 확인하여 레몬법 요청을 어디로 보내야 하는지 확인할 것
          + 환불 과정에서 대체 차량을 제공하지 않았다면 사건 보상을 요구할 것
     * Tesla가 주행 거리 추정 소프트웨어를 조작하여 차량의 주행 거리를 과장하기 시작했다는 이야기를 모르는 사람들에게는 큰 스캔들임
          + 배터리가 최대 충전량의 50% 이하로 떨어지면 더 현실적인 주행 거리 추정을 보여주도록 알고리즘을 작성함
          + 많은 운전자들이 조작된 기기가 실제와 일치하지 않는다는 것을 깨닫고 서비스 요청을 시작함
          + Tesla는 고객에게 거짓말을 하기 위해 팀을 구성했으며, 이번에는 조작된 기기가 아닌 사람이 직접 거짓말을 함
          + 완전 자율 주행의 오해, 민감한 비디오 감시 처리 문제, 품질 문제, 불만을 제기한 사람들에 대한 보복 등 Tesla의 부정직한 문화가 엿보임
          + 다른 Musk가 통제하는 회사들이 더 나은 문화를 가지고 있기를 바람
     * 기사는 추운 날씨에서의 주행 거리 손실에 집중하지만, 실제로는 실내 히터 사용 시 많은 주행 거리 손실이 발생함
          + 모든 현대 Tesla는 실내 난방을 위해 히트 펌프를 사용하여 주행 거리 손실을 절반으로 줄이지만 여전히 상당함
     * 2022년형 EV6는 광고된 주행 거리에 거의 근접하며, 310마일로 광고되었고 80% 충전 시 240마일을 자주 얻음
     * Volkswagen의 주행 거리 추정기가 신뢰할 만하다고 생각하며, 이곳에서 유사한 Tesla 모델의 주행 거리를 추정할 수 있을 것이라고 생각함
          + WLTP는 쓸모없다고 생각하며, 여름에는 WLTP 주행 거리의 2/3, 겨울에는 1/3을 달성할 수 있음
          + 장거리 운전을 거의 하지 않기 때문에 다행임
"
"https://news.hada.io/topic?id=19701","이익보다 나무: Ecosia 영구 매각 포기 선언 (2018)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   이익보다 나무: Ecosia 영구 매각 포기 선언 (2018)

     * Ecosia의 창립자 약속
          + Ecosia를 설립할 때 두 가지 약속을 했음
               o Ecosia를 절대 팔지 않음
               o 회사에서 이익을 가져가지 않음
          + 목표는 부자가 되는 것이 아니라 세상을 더 푸르고 나은 곳으로 만드는 것임
          + 윤리적인 비즈니스 방식을 증명하고자 함
     * Ecosia의 성장과 약속 갱신
          + Ecosia는 매달 수백만 그루의 나무를 심으며 세계 최대의 환경 운동 중 하나로 성장함
          + 두 가지 약속을 갱신하기 위해 Ecosia를 ""스튜어드 소유 회사""로 전환함
          + 법적으로 구속력 있는 두 가지 제한 사항이 있음
               o 주식을 이익을 위해 팔거나 회사 외부인이 소유할 수 없음
               o 회사에서 이익을 가져갈 수 없음
     * 전통적인 기업가와의 차이점
          + 전통적인 기업가에게는 나쁜 아이디어처럼 보일 수 있음
          + Ecosia는 전통적이지 않으며, 이익 극대화보다 나무 심기 극대화에 관심이 있음
          + 더 많은 기업이 의미 있는 목표를 추구하길 바람
     * 스튜어드 소유 회사의 의미
          + Ecosia를 이익을 위해 팔거나 회사에서 돈을 가져갈 수 없음
          + 공동 창립자 Tim도 이익을 포기하고 비영리 회사로 전환하는 데 동의함
     * Ecosia 사용 방법
          + 브라우저 확장 프로그램 설치 및 앱 다운로드로 Ecosia 사용 시작 가능
          + Ecosia가 항상 비영리로 남고 배당금을 지급하지 않도록 제3자와 협력 중임
          + 스튜어드 소유 회사에 대해 더 알고 싶다면 TED 강연, 웹사이트, Purpose Foundation 참고 가능

        Hacker News 의견

     * 엔지니어로서 우리는 어떤 것을 듣고 그에 대한 설계와 영향을 생각하기 시작하는 경향이 있음. 이는 정상적이지만, 우리가 유일하게 그것을 생각한 사람이라고 가정하고 우리의 우려가 해결되지 않았다고 생각하는 경향이 있음. 그래서 우리는 그것을 공유해야 한다고 느끼게 됨
     * Ecosia는 좋은 회사일 수 있지만, 이런 헤드라인은 항상 약간의 의심을 불러일으킴. 비영리 단체도 창립자에게 많은 수익을 줄 수 있음. Ecosia는 월급으로 60만 유로 이상을 보고하고 있으며, 그 중 CEO에게 얼마나 가는지 알고 싶음
          + 충분한 수입이 있다면 사업을 팔 필요가 없음
     * Ecosia를 ""스튜어드 소유 회사""로 전환함으로써 두 가지 약속을 했음. 이 모델은 법적으로 구속력 있는 두 가지 제한을 부과함
          + 적어도 몇몇 국가에서 이것이 실제로 가능하고 지속 가능한 법적 선례가 생기길 바람. 이는 OpenAI의 약속이기도 했음
          + 현재 또는 잠재적인 Ecosia의 스튜어드에 대해 나쁜 의심이 있는 것은 아니지만, 특히 자선 기부가 관련된 경우 약속보다는 법적 보장을 선호함
     * 웹사이트가 혼란스러움. 나무를 심는 비영리 단체인데 검색 엔진이기도 함. 이 두 가지가 어떻게 관련이 있는지, 하나의 회사로 결합되어 어떤 이점이 있는지 이해하기 어려움
     * Ecosia와 스튜어드 소유 회사의 아이디어가 마음에 들지만, 광고 게임에서 완전히 벗어나고 싶어하는 사람으로서 uBlock Origin을 열심히 사용하고 이메일과 검색 같은 서비스에 비용을 지불함. Ecosia를 실제로 사용해본 적은 없지만 다른 사람들의 경험에 관심이 있음. HN 사용자 중 많은 사람들이 나와 같은 프로필에 맞을 것이라고 상상함
     * ""스튜어드 소유 회사""의 법적 구조에 대한 추가 연구를 위한 정보를 가진 사람이 있는지 궁금함. 독일에 기반을 두고 있으므로 독일 법률 용어의 번역일 것으로 추정되지만, 원본이나 더 알아볼 수 있는 자료를 찾을 수 없었음
     * Ecosia는 최근 Qwant와의 파트너십을 발표하여 자체 검색 엔진 인덱스를 구축할 예정임. 이는 열린 웹에 좋으며 Ecosia의 다음 행보가 기대됨
     * 보상이 제한되지 않으면 ""비영리""라는 선언은 공허하게 들림
     * 매일 Ecosia를 사용하는 사람이 있는지 궁금함. DuckDuckGo와 Qwant와 비교했을 때 어떤지 알고 싶음
     * Ecosia는 꽤 오래 운영되고 있으며, 단순히 질문만 하는 사람이 되고 싶지는 않지만...
          + 심어진 나무와 그 영향에 대한 독립적인 검증이 있는지 궁금함. 그들의 흥미로운 녹색 재투자 설정과 전통적인 영리 기업(예: Google)과의 환경적 영향을 비교한 연구가 있는지 궁금함
"
"https://news.hada.io/topic?id=19589","세계 최초 인간 뇌 세포 기반 "생물학적 컴퓨터" 상용화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    세계 최초 인간 뇌 세포 기반 ""생물학적 컴퓨터"" 상용화

   Cortical Labs의 CL1, 생물학적 AI 시대 개막
     * 호주 Cortical Labs가 인간 뇌 세포와 실리콘 하드웨어를 결합한 세계 최초 ""생물학적 컴퓨터(CL1)"" 를 공식 출시.
     * 기존 AI보다 더 역동적, 지속 가능하며 에너지 효율적인 컴퓨팅 기술로 평가됨.
     * 2025년 하반기부터 본격적인 상용화 예정.

   CL1의 핵심 기술과 특징
     * ""합성 생물학적 지능(SBI, Synthetic Biological Intelligence)"" 기반으로 뇌 세포를 실리콘 칩 위에 배양하여 신경망을 형성.
     * 현재의 대형 언어 모델(LLM)보다 훨씬 빠르고 유연한 학습 속도를 가짐.
     * 자율 학습을 통해 최적의 연결망을 형성하며, 기존 실리콘 기반 AI보다 뛰어난 정보 처리 능력을 보유.
     * CL1 내부에 생명 유지 시스템이 포함되어 있어 배양된 뇌 세포의 생존을 보장.

   연구 및 실험 혁신
     * 2022년, DishBrain 실험에서 인간·쥐 뉴런 80만 개를 칩에 배양하여 비디오 게임(퐁) 플레이 학습에 성공.
     * 뉴런들이 보상을 받을 때 특정 패턴을 학습하고, 예측 가능한 행동을 유지하는 것이 밝혀짐.
     * CL1은 기존 CMOS 칩 대비 더 안정적이며, 뉴런 활동을 더욱 세밀하게 조절 가능.

   ""Wetware-as-a-Service"" (WaaS) 제공
     * 연구자들은 CL1을 직접 구매하거나 클라우드를 통해 원격 액세스하여 사용 가능.
       이를 통해 의료 연구, 약물 개발, 로봇 지능 연구 등의 분야에서 획기적인 발전 가능.

   최종 목표: ""Minimal Viable Brain(MVB)"" 개발
     * CL1을 이용해 최소한의 뉴런으로 기능하는 인간형 뇌 모델 구축 연구 진행 중.
     * 이를 통해 뇌 질환(알츠하이머, 간질 등) 치료법 연구 및 신경과학 발전에 기여할 전망.

   가격 및 상용화 계획
     * 초기 CL1 장치 가격: 약 35,000달러 (기존 유사 기술의 85,000달러 대비 저렴).
     * 2025년까지 클라우드 기반 SBI 서버 구축, 연말까지 총 4개 서버 스택 가동 예정.

   윤리적·규제적 고려 사항
     * 생물학적 컴퓨터의 윤리적 논란 (의식·자아 개념 등) 대비를 위해 다양한 규제 준수.
     * Cortical Labs는 AI 및 생물학의 경계를 넘는 새로운 기술을 개척하며 투자 유치에 도전 중.

   미래 전망
     * CL1은 단순한 연구 도구를 넘어 의료·생명과학·AI 기술 전반에 혁신적인 영향을 미칠 가능성이 큼.
     * 기존 실리콘 기반 AI를 넘어선 ""더 자연스러운 인공지능"" 구현 목표.
     * ""생물학적 컴퓨팅"" 시대를 여는 첫걸음이 될 것으로 기대됨.

   통속의 뇌!!!!

   바이오 컴퓨터...!!

   아 저 모습은 뭔가 영화에서나 보이던 느낌인데요. 진짜 기분이 매우 이상해요

   진짜 너무 거부감 드는데요
   블로그에 사진 보니까 더 심해졌어요 ㅋㅋ 충격적인 비주얼이다

   이런것은 스카이넷이라기 보다는 일본 만화 Five Star Story의 전투 보조 파티마가 먼저 생각났고, 그 다음으로 일본 애니 싸이코패스의 시빌라 시스템이라는 인간의 뇌를 병렬로 연결한 의사결정기구가 생각났습니다.

   배양한 뉴런에서 의식이 발생 할 수 있다면.

   우리 인류도 누군가가 이 파란별에 뿌려둔 배양의 씨앗이 아닐까 하는 무모한 생각도 들구요.
"
"https://news.hada.io/topic?id=19637","PayPal Honey 확장 프로그램, Chrome 웹 스토어에서 다시 "추천" 플래그 획득","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          PayPal Honey 확장 프로그램, Chrome 웹 스토어에서 다시 ""추천"" 플래그 획득

        Hacker News 의견

     * 많은 사람들이 Honey가 유명해진 이유는 거의 모든 큰 인플루언서들이 이를 홍보했기 때문임
          + 사람들은 인플루언서들이 자신들의 결정에 대해 어떻게 느끼게 만드는지가 중요함
          + 많은 사람들이 다른 VPN 제공자가 있다는 것을 모르거나 신경 쓰지 않음
     * Google이 갑자기 부정적인 리뷰가 급증한다면, Chrome과 연결된 계정에서 확장 프로그램을 다운로드하지 않은 사용자로부터 온 것이라면, 그 리뷰를 다르게 처리할 이유가 있을 수 있음
          + 이는 평판이 좋은 곳에서 비인기 있는 일이 발생하여 많은 사람들이 리뷰를 남기는 것과 유사함
     * Honey는 여전히 꽤 인기 있는 확장 프로그램이며, 기술 중심 그룹이 불편해하는 것이 대다수 사용자에게는 중요하지 않을 수 있음
          + 사람들이 부패에 대해 신경 쓴다면 Comcast/Xfinity 같은 회사는 존재하지 않을 것임
     * Honey와 악성 소프트웨어의 차이는 후자가 안티바이러스에 의해 공격받는다는 것뿐임
          + 둘 다 추천을 훔치는 일을 함
     * Honey와 유사한 확장 프로그램들은 브라우저의 모든 활동을 모니터링함
          + 사람들이 이런 식으로 모니터링되는 것을 기쁘게 받아들일 줄은 몰랐음
     * Honey가 여전히 스토어에 있다는 것이 놀라움
     * PayPal Honey가 무엇인지, 왜 중요한지 궁금함
     * Firefox에서는 평점이 2.9로 떨어졌는데, 어떻게 여전히 4.6점인지 의문임
     * Manifest v2를 제거하고 사기 확장 프로그램을 지원하는 Chrome이 점점 더 불쾌하게 보임
     * YouTuber들과 그들의 팬들이 PayPal의 Honey 인수를 망쳤다는 것은 GameStop 주식 사건과 비슷함
          + PayPal은 웹 사용자들의 프라이버시와 보안을 구원하는 것처럼 보이는 또 다른 의심스러운 기술 회사임
          + 사람들은 암호화폐로 이동하고 있으며, 스테이블코인이 결국 승리할 것임
"
"https://news.hada.io/topic?id=19620","로컬 우선(Local-First) 소프트웨어가 미래인 이유와 그 한계점","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                로컬 우선(Local-First) 소프트웨어가 미래인 이유와 그 한계점

   로컬 우선(Local-First) 소프트웨어는 사용자 데이터를 클라우드 서버가 아닌 사용자의 기기에 직접 저장하여 데이터 보안, 속도 향상 및 오프라인 사용성을 보장하는 소프트웨어 개발 방식입니다. 그러나 이러한 방식은 여러 기기 간 데이터 동기화 및 충돌 관리에서 기술적 어려움을 동반합니다. 이 글에서는 로컬 우선 소프트웨어가 미래 소프트웨어 개발의 중요한 방향인 이유를 살펴보고, 이 접근법이 현재 가진 한계와 해결해야 할 과제에 대해서도 논의합니다.
"
"https://news.hada.io/topic?id=19711","Show GN: 스마트한 북마크 관리 서비스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Show GN: 스마트한 북마크 관리 서비스

   [서비스 소개]
     * Pouder는 누적되는 사용자의 북마크를 효과적으로 관리하고 공유하는 서비스 입니다.
     * 북마크를 쉽게 관리하고 재사용할 수 있는 방향으로 제작 되었습니다.
     * 개인적으로 리서치하면서 북마크를 많이 하는 편인데 관리가 어려워 제작하게 되었습니다.

   [기존 서비스와 차이점]
     * 기존 북마크서비스는 체계적으로 관리하고 다양한 다시 보기 기능이 장점이라면,
     * Pouder는 관리를 자동으로 하고 검색과 질의를 통해 재생산하는 것이 장점입니다.

   [이런 분께 추천해요]
     * 북마크를 많이 하는데 나중에 찾기 힘드신 분
     * 리서치 도구가 필요한 팀이나 개인
     * 블로그 운영하면서 포스트를 공유하고 싶으신 분
     * 북마크 쌓아 놓고 재활용 잘 못하시는 분

   [주요 기능]
     * 자동으로 카테고리 분류, 메타데이터/주요키워드 추출, 요약생성, 본문 벡터화 저장
     * 키워드 검색으로 빠르게 검색
     * 자연어 질의를 통해 질의에 관련된 북마크를 찾아 질문에 답변을 제공
     * 내 북마크를 공유하고 다른 사용자를 구독
"
"https://news.hada.io/topic?id=19695","10배 더 빠른 TypeScript","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          10배 더 빠른 TypeScript

     * Microsoft가 컴파일러와 도구의 네이티브 포팅을 통해 Typescript 성능 10배 향상 발표
     * 에디터 시작 시간 대폭 향상, 빌드 타임 10배 단축, 메모리 사용량을 대폭 줄임
     * 2025년 중반까지 tsc 미리 보기 버전을 출시하고, 2025년 말에 완전한 프로젝트 빌드 및 랭귀지 서비스 제공 예정

TypeScript 성능 개선 배경

     * TypeScript의 핵심 가치는 뛰어난 개발자 경험임
     * 코드베이스가 커질수록 TypeScript의 가치가 높아지지만, 대규모 프로젝트에서는 성능 문제 발생
          + 긴 로드 및 검사 시간 문제 발생
          + 빠른 에디터 시작 시간 vs 전체 코드베이스 분석 간의 균형 필요
     * AI 기반 기능은 빠르고 정확한 의미 정보 제공 필요
     * 명령줄 빌드를 통한 코드베이스 상태 검증 요구 증가

네이티브 포트 진행 계획

     * TypeScript 컴파일러와 도구의 네이티브 포트 작업 시작
     * 성능 개선 목표:
          + 에디터 시작 시간 대폭 단축
          + 빌드 시간 최대 10배 단축
          + 메모리 사용량 감소
     * 2025년 중반: 명령줄 타입 검사 가능한 tsc 미리보기 버전 출시 예정
     * 2025년 말: 완전한 프로젝트 빌드 및 언어 서비스 제공 예정

코드 실행 및 테스트

     * TypeScript Go 코드 저장소에서 코드 빌드 및 실행 가능
     * 저장소에서 tsc 및 언어 서버 빌드 및 실행 지침 제공
     * 새로운 기능에 대한 정기 업데이트 예정

얼마나 빨라졌나?

     * 현재 TypeScript 프로젝트의 빌드 시간을 여러 인기 코드베이스에서 테스트한 결과 다음과 같은 성능 향상이 나타남:
          + VS Code 프로젝트는 약 150만 줄의 코드에서 기존 77.8초에서 7.5초로 약 10.4배 빨라짐
          + Playwright 프로젝트는 약 35만 줄의 코드에서 기존 11.1초에서 1.1초로 약 10.1배 개선
          + TypeORM 프로젝트는 약 27만 줄의 코드에서 기존 17.5초에서 1.3초로 약 13.5배 개선
          + date-fns 프로젝트는 약 10만 줄의 코드에서 기존 6.5초에서 0.7초로 약 9.5배 개선
          + tRPC 프로젝트는 약 1만 8천 줄의 코드에서 기존 5.5초에서 0.6초로 약 9.1배 개선
          + rxjs 프로젝트는 약 2천 줄의 코드에서 기존 1.1초에서 0.1초로 약 11배 개선
     * 아직 기능이 완전하지 않지만, 대부분의 코드베이스에서 10배 이상의 성능 개선 예상
     * 빠른 타입 검사와 코드 탐색 가능해짐
     * AI 도구 통합 및 고급 리팩토링 지원 가능

에디터 성능 개선

     * 에디터 로드 및 응답 속도 개선
     * Visual Studio Code 코드베이스 기준 로드 시간:
          + 현재: 9.6초 → 네이티브 버전: 1.2초 (약 8배 개선)
     * 메모리 사용량도 약 50% 감소
     * 언어 서비스 작업 (자동 완성, 빠른 정보 보기, 정의로 이동 등) 성능 향상 예상
     * 언어 서버 프로토콜(LSP) 기반으로 이전 작업 진행 중

버전 로드맵

     * TypeScript 5.8 출시 완료, TypeScript 5.9 곧 출시 예정
     * JS 기반 TypeScript 코드베이스는 6.x 버전으로 계속 개발 진행
     * 네이티브 코드베이스가 안정화되면 TypeScript 7.0으로 출시 예정
          + TypeScript 6 → JS 기반 버전
          + TypeScript 7 → 네이티브 기반 버전
     * TypeScript 7 출시 후에도 6.x 버전은 일정 기간 유지 예정

다음 단계

     * 성능, 컴파일러 API, LSP 등에 대한 추가 정보 공개 예정
     * GitHub FAQ에서 자주 묻는 질문 확인 가능
     * 2025년 3월 13일 TypeScript 커뮤니티 Discord에서 AMA 진행 예정 (PDT 오전 10시 | UTC 오후 5시)

   어느 순간부터 TS에 손이 덜 가기 시작했었는데 이런 소식을 보니 또 솔깃하네요?

   개인적으로 ts 가 어떤 경우는 유형이 매우 복잡해저서... 거의 포기하다시피 하는 경우(그냥 any로 써버림)가 있는데, 언어에 대해 이해가 부족해서 이겠죠? 상황에 따라 진짜 빨간줄 없애려고 시간낭비 많이 합니다.

   ts 에서 진짜 불가피한 경우를 제외하고 any 를 남발하게 되면 vanilla 를 쓰는것과 다름없죠..ㅎ

   타입스크립트로 컴파일해서 결과물이 바로 바이너리로 나왔으면 하는 1인

   프론트는 문외한이라.. swc 와는 다른건가요?

   SWC는 바벨처럼 호환 가능한 자바스크립트 코드를 생성하고, 번들링하는 것 까지가 초점이고, 이건 타입스크립트 코드를 자바스크립트로 변환하거나 오류를 체크하는 게 초점입니다.

     TypeScript 코드가 더 이상 TypeScript로 작성되지 않으면, 팀이 TypeScript를 직접 사용하지 않게 되어 장기적으로 개발 경험에 영향을 미칠 수 있음

   개밥을 먹는다고 하죠. 자신이 만든 것을 직접사용하는. 그런데 언어의 경우는 조금 고민이 되는군요.

   개인적인 생각으로 ts의 기반인 js의 runtime들이 (e.g. spidermonkey, v8) 대부분 c++로 짜여져있고 js로 구현한 런타임이 없으며,
   js -> js 컴파일또한 pure js를 쓰면 너무 느려 esbuild니 뭐니 다 넘어가는걸 보면,
   ts에서도 굳이 개밥먹기를 고집해야하나 싶긴 합니다

   나중에는 기존 typescript 코드베이스에 대한 관리가 소홀해지지 않을까 걱정이네요

   어라 이미 deno 쪽에서 Rust 기반 툴체인을 만든게 있을텐데... 갑자기 Go 인가요?

   그건 Node같은 런타임을 말씀하시는 것 같고, 여기서 말하는 건 TS 언어 자체의 컴파일러 입니다.

   아, 글을 좀 더 읽어보니 에디터가 빨라지고 그런 이야기가 있어서 헷갈렸던 것 같네요.
     * tsc 가 10배 빨라짐. 즉, ts -> js 트랜스파일링 시간이 매우 줄어듬.
     * VSCode 같은 ts 로 개발된 큰 프로젝트를 로드할 때 속도가 매우 빨라짐. 즉, ts 의 구문 검사 등 tsc 의 기능을 공유하는 로직이 빨라졌다는 의미.
     * VSCode 가 동작하는 속도가 빨라졌다는 것은 아님
       이런 내용이었군요.

   재귀로 구성된 제너릭 타입을 사용할 때, 느려져서 차선책을 사용한 경험이 있습니다. 10배라면 이런 부분도 개선할 수 있을지 기대되네요.

   Write in Go~

   너무 기대됩니다.

        Hacker News 의견

     * TypeScript 팀의 Daniel Rosenwasser가 발표 소식을 전하며, 팀 리더 Ryan Cavanaugh와 함께 질문에 답변할 준비가 되어 있음
          + Discord AMA에서 더 많은 정보를 얻을 수 있음
     * 빠른 개발 도구는 훌륭하며, TypeScript 팀이 항상 개발 경험에 깊이 고민하는 점이 기쁨
          + TypeScript 코드가 더 이상 TypeScript로 작성되지 않으면, 팀이 TypeScript를 직접 사용하지 않게 되어 장기적으로 개발 경험에 영향을 미칠 수 있음
          + Flow가 OCaml로 작성되어 실패한 사례를 언급하며, 팀의 생각이 궁금함
     * 이전에 Rust로 빠른 tsc를 시도한 사례로 두 프로젝트를 언급함
          + stc: 중단됨
          + ezno: 활발히 개발 중이며, tsc와 1:1 대응을 목표로 하지 않음
     * 프로젝트가 유연한 스크립팅 언어로 시작하지만, 결국 더 네이티브한 표현이 승리하는 경우가 많음
          + 낮은 수준의 표현으로 시작하는 것이 더 나을 수도 있다고 생각함
          + JS 런타임을 서버에서 사용하는 기본 가정을 재고하게 됨
          + 스크립팅 언어의 장점이 점점 줄어들고 있음
     * 잠시 만우절인 줄 알았음
     * Go를 선택한 것이 좋음
          + Rust 대신 Go를 선택한 것이 인상적임
          + AOT 컴파일된 .NET을 선택하지 않은 것이 아쉬움
     * 새로운 코드베이스를 기존과 최대한 호환되게 유지하는 것이 중요함
          + Go의 문법이 TypeScript 코드베이스와 유사하여 포팅이 용이함
     * Golang과 TypeScript의 문법적 유사성에 놀람
          + Golang에서 sum types를 사용하기 어려웠던 경험을 공유함
     * Daniel과 Anders가 네이티브 포트에 대해 심도 있는 논의를 한 팟캐스트를 소개함
     * 대규모 TypeScript 파일을 리팩토링하는 과정에서 성능 문제가 발생함
          + TypeScript로의 코드베이스 전환이 팀에 큰 도움이 되었지만, 성능 문제는 여전히 존재함
     * PHP를 사용하다가 4년 전부터 TypeScript를 사용하기 시작함
          + TypeScript의 타입 시스템이 유용하며, 컴파일 속도가 빠름
          + Microsoft의 팬은 아니지만, TypeScript는 잘 만들어진 언어라고 생각함

   다들 structural typing 은 생각 안하고 던지는 게 아닌가 싶었습니다.
   c#이나 rust같이 norminal typing인 언어로 재작성하려면 프로젝트의 근본 구성을 너무 많이 바꿔야하니 쉽지 않았겠죠.
   structural typing을 채택한 언어 중에서 기존 js 기반보다 성능 높여줄 수 있는 건 c++ 아님 golang 둘 중 하나일텐데 생산성까지 감안하면 대안이 없습니다

   논란이 꽤 핫한지 Anders Hejlsberg가 직접 코멘트를 남겼네요

   https://github.com/microsoft/typescript-go/…

   반가운 소식입니다! 신기하게 MS의 타입스크립트 언어는 예상과 달리 정말 의외의(?) 선택들을 많이 하는 것 같습니다. MS 입장에서는 거의 첫번째 오픈소스 프로젝트인데다 JS를 대체하려고 했던 구글의 Dart와 달리 JS를 보완하려고 했던 선택도 참 현명하게 느껴졌고, 이번 네이티브 포팅 언어도 자사 언어도 많고 할텐데 구글의 Go를 선택한 점도 놀랍습니다.

   왜 Go 인가란 논의 스레드 재미있네요.

   https://github.com/microsoft/typescript-go/discussions/411

   고민해야할 것들도 많고...

   그러게요 닷넷 개발자분들 심정도 근데 이해가 됩니다...

   닷넷 러스트 개발자들이 화가 많이낫네요

   닷넷은 이해가 가는데 러스트는 go 와 같은 위치라고 생각돠네요 아무래도 기존 만들어진 js 관련 go 프로젝트와 라이브러리도 결정에 영향을 미쳤을것 같숩니다

   C# 언어에 대한 개발이 멈춘건 아니지만 C#을 이용한 프레임워크들이 방치되는 느낌이 너무 많아요
"
"https://news.hada.io/topic?id=19626","Microsoft는 OpenAI 없는 미래를 계획하고 있음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Microsoft는 OpenAI 없는 미래를 계획하고 있음

     * 마이크로소프트의 AI 책임자 무스타파 술레이만은 OpenAI에 대한 의존도를 줄이려는 전략을 추진 중
     * 마이크로소프트는 2019년 이후 OpenAI에 130억 달러 이상을 투자했지만, 자체 모델을 개발해 비용 절감 및 독립성 확보를 목표로 함
     * 술레이만은 OpenAI쪽에 최신 모델(예: o1)에 대한 기술적 세부 사항을 요구하면서 긴장감을 형성하기도
     * 독립의 이유
          + 비용 절감: OpenAI의 모델(GPT-4 등)을 Azure에서 운영하는 비용이 높아 비용 절감 필요
          + 전략적 독립성 강화: OpenAI의 내부 혼란(예: 2023년 샘 알트만 해임 사건)에서 드러난 취약성을 해결하고자 함
     * 하지만 단시일 내엔 불가
          + OpenAI의 기술이 마이크로소프트 제품(Copilot, Bing 검색, Microsoft 365)에 깊이 통합돼 있어 독립이 쉽지 않음
          + OpenAI와의 계약은 2030년까지 지속
          + 술레이만의 팀은 xAI, DeepSeek, Meta 등 다른 AI 모델을 테스트 중이나 대체 작업이 더딘 상황
          + 마이크로소프트는 이미 자체 모델(예: Phi-4)을 마이크로소프트 365 Copilot에 통합 중
          + 하지만 OpenAI 모델 완전 대체에는 시간이 걸릴 것으로 예상됨
     * 향후 전망
          + 2024년 OpenAI의 예상 손실: 약 50억 달러(약 6조 7천억 원)이고, OpenAI의 경영 불안정은 Microsoft의 장기 전략에 영향을 줄 수 있음
          + 기술적 의존성, 계약 관계, OpenAI의 기술 발전이 독립 전략의 주요 변수로 작용할 전망
          + 독립이 성공하면 마이크로소프트는 비용 절감과 더불어 AI 시장에서 독자적인 경쟁력을 확보할 가능성이 높음

        Hacker News 의견

     * Microsoft 내부에서 자신의 입지를 높이려는 사람들이 주도하는 것인지 궁금함
          + 과거 Google이 Angular를 React와 동등하게 만들려 했을 때 문서화가 부족했던 경험을 떠올림
          + 당시 프로젝트를 주도했던 사람은 이미 성공을 거두고 관심이 없었던 상황이었음
     * OpenAI가 AI 에이전트의 새로운 가격을 발표할 계획이라는 소식이 유출됨
          + PhD 수준 에이전트는 월 $20K, 소프트웨어 개발자 에이전트는 월 $10K, 지식 노동자 에이전트는 월 $2K
          + 이 가격은 실제로 수익을 내기 위한 것임
     * Microsoft가 2019년 이후 AI 회사에 130억 달러 이상을 투자했다는 소식
          + 대부분이 Azure 크레딧으로 이루어졌으며, 실제 비용은 그리 크지 않음
          + 쿠폰이나 무료 상품권을 제공하는 회사들은 비용을 부담하지만, 실제 비용은 명시된 금액과 다름
     * OpenAI가 처음이라도 오래 지속되지 않을 것이라는 인식
          + Microsoft는 이미 대규모 컴퓨팅을 자체적으로 수행하고 있음
     * OpenAI와 Microsoft는 서로 없는 미래를 원함
          + OpenAI는 애플리케이션 쪽으로 수직 통합을 원하고, Microsoft는 우선순위와 비용 통제를 위해 반대 방향을 원함
     * Apple의 접근 방식이 더 전략적이었다고 생각함
          + 자체 모델 사용을 통합하고 OpenAI 쿼리를 통해 능력을 증폭시킴
          + 제품 출시의 실제 품질은 좋지 않았지만, 자체 모델에 의존하려는 기초는 올바른 출발점이었음
     * AI 프론티어 모델에 수십억을 투자하는 것은 AGI가 수조 달러의 가치를 가질 것이라는 믿음에 기반함
          + 2위, 3위에 투자하는 것도 유사한 규모로 가치가 있을 가능성이 있음
          + MSFT의 움직임은 프론티어 모델의 가장 가치 있는 현재 사용 사례가 기업 수준의 API 사용자라는 것을 나타냄
          + 수익의 대부분은 통합 제품 배포를 가진 MSFT와 데이터 센터 파트너가 차지할 가능성이 큼
     * OpenAI 사건 중 Satya Nadella가 말한 내용
          + ""우리는 사람, 컴퓨팅, 데이터, 모든 것을 가지고 있음. 우리는 그들 아래, 위, 주변에 있음""
     * 최신 모델인 GPT 4.5가 기대만큼 혁신적이지 않음
          + Deepseek 등 다른 경쟁자들이 따라잡고 있음
     * Softbank의 Masa는 항상 자신이 투자한 시장에서 최고점을 찍지 않았다고 설득하는 마법을 가짐
          + Satya가 마침내 그 마법에서 벗어난 것일 수도 있음
"
"https://news.hada.io/topic?id=19606","나이와 인지 능력: 사용하지 않으면 잃는다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        나이와 인지 능력: 사용하지 않으면 잃는다

     * 일반적으로 인지능력이 30대부터 하락한다고 알려져 있으나, 이는 실제 개인의 능력 변화가 아닌 서로 다른 세대 간의 차이를 반영한 결과
     * 실제 개인의 연령별 언어능력(literacy)과 수리능력(numeracy)의 변화를 관찰해본 결과:
          + 평균적으로 인지능력은 40대까지 증가하다가, 이후 언어능력은 완만히 감소하고, 수리능력은 더 뚜렷하게 감소
          + 그러나 능력 사용 빈도가 높은 사람들은 나이가 들어도 인지능력이 감소하지 않으며 오히려 증가하는 경우도 있음
          + 사무직과 고학력자 그룹은 높은 능력 활용 시 40대 이후에도 능력이 증가
          + 여성의 경우, 특히 수리능력에서 더 큰 감소

서론(INTRODUCTION)

     * 기존 연구는 인지능력이 성인 초기에 정점을 찍고 이후 감소한다고 가정
     * 그러나 대부분의 기존 연구는 연령효과(age effect)와 세대효과(cohort effect)가 혼재된 횡단적 데이터를 사용
     * 이 연구는 OECD가 주관한 성인역량 국제평가(PIAAC)의 독일 패널 데이터(PIAAC-L) 를 활용
     * 동일한 개인의 3.5년 간격 데이터를 이용해 실제 연령별 능력 변화를 관찰 가능
     * 연구 방법:
     * 연령별로 실제 개인의 능력 변화를 관찰하고, 측정 오차(평균 회귀 현상, reversion to the mean)를 보정
     * 이 방법으로 보다 신뢰성 있는 연령별 인지능력 프로필 생성 가능
     * 주요 목적은 개인의 배경과 인지능력 사용 빈도(skill usage)가 인지능력 변화에 어떤 영향을 미치는지 탐구하는 것

결과(RESULTS)

  평균적 연령-인지능력 프로필

     * 기존의 단면적(cross-sectional) 조사 결과에서는 OECD 국가에서 20대 후반부터 인지능력이 감소한다고 나타남
     * 그러나 독일의 종단적(longitudinal) 자료를 통해 개인의 능력 변화를 직접 관찰하면 전혀 다른 양상
     * 실제 개인의 인지능력은 언어능력(literacy)의 경우 45세까지 증가, 수리능력은 40세까지 증가 후 감소
     * 수리능력이 언어능력보다 더 빠르게 감소
     * 연령에 따른 인지능력의 변화는 측정 오차를 보정했을 때, 40대까지 증가 후 이후 서서히 감소하는 패턴으로 나타남

     * 흥미로운 점: 평균적으로 능력 감소는 불가피한 현상이 아니라, 능력 사용의 빈도에 따라 달라짐

  능력 사용 빈도에 따른 차이(Heterogeneity by usage)

     * 업무와 일상에서 능력을 자주 사용하는 사람들은 65세까지도 능력 감소가 나타나지 않음
     * 능력을 평균 이상 사용하는 집단:
     * 인지능력이 50대까지 증가하다 이후 유지되는 경향
     * 능력 사용이 낮은 집단은 30대 중반부터 능력이 감소하기 시작
     * 능력 사용 빈도가 높은 경우, 노화로 인한 능력 감소는 나타나지 않음

     * 예: 자주 이메일이나 편지를 읽거나, 비용을 계산하는 사람들은 능력이 더 오래 유지되거나 향상됨

  배경 특성에 따른 차이(Heterogeneity by background characteristics)

     * 직업, 교육 수준, 성별에 따라 연령별 인지능력 패턴이 뚜렷하게 차이 남
     * 직종 및 교육 수준:
          + 화이트칼라 및 대학 교육 이수자는 능력 사용 빈도가 높아, 평균적으로 40세 이후에도 인지능력이 계속 상승하거나 유지
          + 블루칼라 및 저학력 노동자는 사용 빈도가 낮아 조기에 능력 감소 시작
     * 성별 차이:
          + 여성의 경우 남성보다 수리능력의 감소가 30대 초반부터 더 두드러짐
          + 성별 차이는 특히 수리능력에서 두드러지며, 언어능력은 남녀 간 차이가 크지 않음
     * 특이점:
       여성의 수리능력 감소는 단순히 능력 사용 빈도의 차이로만 설명되지 않으며, 생물학적, 사회적 요소도 고려될 수 있음

논의(DISCUSSION)

     * 인지능력의 노화가 경제적으로 중요하다는 기존 가설에 대한 새로운 시각 제공
     * 나이가 든다고 인지능력이 필연적으로 감소하는 것은 아니며, 능력 사용 빈도가 핵심적 역할
     * 특히, 높은 난이도의 직업적 활동이나 일상적 자극이 많은 환경에서는 인지능력을 오랫동안 유지하거나 심지어 증가시킬 수 있음
     * 여성과 남성 간의 차이는 신경과학적 요인에 의한 생물학적 차이와도 연관 가능

한계점(Limitations)

     * 연구 대상이 독일 성인으로 제한되어 다른 국가나 환경에서 일반화 여부는 추가 연구 필요
     * 분석 대상이 65세까지만 한정되어 있어, 그 이후 노년층의 변화는 알 수 없음
     * 관찰적 자료로 인과성을 명확히 밝히는 데는 한계 존재
     * 다른 사회적, 경제적 맥락에서도 연구가 필요

추가 배경지식(Background)

     * PIAAC(국제 성인 역량 조사)는 OECD가 주관하여 성인의 문해력과 수리력을 측정하는 국제적 조사
     * 독일은 특별히 동일 인물에게 3.5년 간격으로 재조사하여 연령에 따른 개인의 능력 변화 직접 확인 가능

결론적 시사점

     * 인지능력의 노화는 불가피하지 않으며, 지속적이고 빈번한 능력 사용이 인지능력을 유지하는 데 매우 중요한 요소
     * 이러한 결과는 노령화 사회의 경제적 관점에서 긍정적이며 희망적인 메시지를 제공

        Hacker News 의견

     * 40대가 넘은 한 사용자가 대학에 등록하여 선형대수학 중간고사를 준비 중임. 컴퓨터 과학 전공과 수학 부전공으로 대학을 졸업했으며, 수학 전공으로 두 번째 학위를 목표로 하고 있음. 행운을 빌어달라고 함
     * 생존 모드에서의 스트레스가 뇌에 미치는 영향을 연구하고 싶다는 의견이 있음. 지난 25년간 순수 연구보다 이익 중심의 혁신이 우선시되는 상황에 실망감을 느끼고 있음. 자동화를 통해 기본 자원을 무료로 제공할 수 있었음에도 불구하고, 현재의 상태를 유지하려는 경향이 있다고 함. AI와 같은 새로운 혁신을 수용하기 어려움을 느끼고 있음. AI로 인해 문제 해결 능력이 필요 없어질 것이라는 우려가 있음
     * 40대가 넘은 사용자가 대학에 돌아가고 싶어 함. 일반 상대성이론까지 수학과 물리학을 배우고 싶어 함. 젊은 사람들에게 재정적 자유를 우선시하라고 조언함. 35-40세에 은퇴하면 원하는 프로젝트를 추구할 시간이 충분하다고 함
     * 공립 대학이 무료여야 한다는 의견이 있음. 형식적인 교육이 비디오 튜토리얼이나 자기 주도 학습보다 더 효과적이라고 믿음. 모든 사람이 새로운 것을 배우고 기술을 연습할 수 있는 환경이 사회 전체에 이익이 된다고 함. 다양한 직업군의 사람들이 새로운 기술을 배우고 싶어 하는 사례를 제시함
     * 시어머니가 매일 두뇌 퍼즐을 했지만 알츠하이머에 걸렸다는 경험을 공유함. 알츠하이머가 사람의 고유한 특성을 빼앗아간다고 함
     * 소프트웨어 개발 경험이 25년인 사용자가 긴 코딩 세션 후 피로감을 느끼지만, 경험 덕분에 생산성이 높아졌다고 함. AI 보조 코딩을 탐색 중이며, 경험과 전문성이 인지적 성능 저하를 상쇄한다고 믿음
     * 나이가 들면서 기술이 저하되는 것은 평균 이하의 기술 사용을 하는 사람들에게만 해당된다는 의견이 있음. 평균 이상의 기술 사용을 하는 사람들은 기술 저하를 경험하지 않는다고 함
     * 나이가 들면서 자동 조종 모드로 작동하는 뇌가 나이 관련 저하의 원인일 수 있다는 의견이 있음. 일상적인 작업 중 새로운 세부 사항을 더 많이 알아차리려고 노력하고 있음. 짧은 형식의 지식은 함정일 수 있다고 경고함
     * 음악, 춤, 스포츠와 같은 복잡한 조정이 필요한 활동도 인지적 참여에 포함된다고 상기시킴. AI가 문제 해결을 피하게 하여 대규모로 조기 저하를 초래할 수 있다는 우려를 제기함
     * 단기 기억력이 떨어지고 있다는 사용자가 이를 방지하기 위한 조언을 구함. 추가적으로 알아야 할 사항이 있는지 질문함
"
"https://news.hada.io/topic?id=19680","캐논 EF 및 RF 렌즈 – 모든 오토포커스 모터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      캐논 EF 및 RF 렌즈 – 모든 오토포커스 모터

캐논 렌즈 기술

  자동 초점 시스템

     * 자동 초점 렌즈의 도입은 사진 촬영에 많은 변화를 가져왔음. 빠르게 움직이는 물체를 더 정확하고 신뢰성 있게 촬영할 수 있게 되었음.
     * 1981년 첫 자동 초점 렌즈 출시 이후, 캐논은 다양한 접근 방식을 통해 렌즈 기술을 지속적으로 발전시켜 왔음.
     * 캐논은 EF, EF-S, RF, RF-S 렌즈에 사용되는 7가지 자동 초점 모터 기술을 개발했음.

  자동 초점 액추에이터의 종류

     * 자동 초점 렌즈 요소는 항상 광축을 따라 선형으로 이동함.
     * 자동 초점 액추에이터는 회전 구동 시스템과 선형 구동 시스템으로 나뉨.
          + 회전 구동 시스템: 회전을 선형 슬라이딩 운동으로 변환함.
          + 선형 구동 시스템: 직접 슬라이딩 운동을 수행함.

  캐논 자동 초점 비교

     * 캐논의 USM 자동 초점 구동 시스템은 여러 메커니즘 패밀리로 구성되어 있음.
     * 링 타입 초음파 모터는 FTM(Full-Time Manual) 초점 오버라이드를 허용하는 첫 번째 자동 초점 시스템이었음.
     * 최신 자동 초점 드라이브는 포커스 바이 와이어를 제공하며, 이는 렌즈 배럴의 수동 초점 링이 초점 그룹과 기계적으로 연결되지 않고 전자적으로 제어됨을 의미함.

  아크 폼 드라이브 (AFD)

     * 1987년부터 1990년까지 사용되었으며, EF 렌즈에 사용된 첫 번째 자동 초점 모터였음.
     * AFD는 수동 초점과 자동 초점 간 전환이 가능한 기어 드라이브와 전송 장치를 포함함.
     * AFD 렌즈는 작동 중 소음이 크고 반응 시간이 느리지만 신뢰할 수 있는 자동 초점 성능을 제공함.

  링 타입 초음파 모터 (USM)

     * 1987년부터 현재까지 사용되고 있으며, 초음파 모터는 전통적인 모터와 달리 자기장이 아닌 압전 효과와 마찰을 사용함.
     * 링 타입 USM은 초고속, 무소음, 높은 토크를 제공하여 대형 초점 렌즈 요소를 움직일 수 있음.
     * 이 모터는 전자기장에 영향을 받지 않으며, 복잡한 전원 공급 및 구동 회로가 필요함.

  DC 마이크로 모터

     * 1990년부터 2012년까지 사용되었으며, 초소형 직류 모터를 사용하여 자동 초점을 구동함.
     * 이 모터는 주로 입문용 자동 초점 렌즈에 사용되며, 소음이 크고 토크가 제한적임.

  마이크로 USM 및 마이크로 USM II

     * 1992년부터 2016년까지 사용되었으며, 초소형 초음파 모터로 압전 세라믹 요소를 사용하여 진동을 생성함.
     * 마이크로 USM II는 원래 버전보다 절반 크기로 설계되었음.

   이 요약은 캐논의 다양한 자동 초점 기술과 그 발전 과정을 설명하며, 각 기술의 특징과 장단점을 다루고 있음.

        Hacker News 의견

     * 나는 예전에 강아지 사진을 찍을 때 수동으로 초점을 맞춰야 했음. 초기 Ring USM AF의 소음이 강아지를 미치게 했고, 방에서 뛰쳐나가곤 했음
          + 카메라를 강아지에게 겨누는 것이 심리적인 영향을 미치는지 궁금했지만, 커튼 뒤에 숨어 AF 모터를 사용했을 때도 강아지가 방에서 뛰쳐나갔음
          + 이후 USM AF 모터는 조용해졌고, 강아지는 사진 찍히는 것을 편안하게 받아들였음
     * 정말 멋진 웹사이트임
          + 같은 저자의 다른 글에서는 카메라 바디가 ""초점"" 버튼을 눌렀을 때 모터를 사용하는 방법에 대한 알고리즘적 질문을 다루고 있음
          + 카메라 바디가 어떤 대상을 원하는지 결정하는 방법에 대한 기사를 찾을 수 없었음. 아마도 사람이나 새의 얼굴을 감지할 수 있는 머신러닝 관련 기술이 포함되어 있을 것 같음
     * 80년대 중반부터 Canon 사용자인 나에게는 흥미로운 읽을거리였음
          + Canon 렌즈 기술에 대한 기사가 많이 있음
     * 정말 흥미로운 작업임
          + 비디오 촬영 시 초점 모터를 직접 제어할 수 있는 방법이 없다는 점에 불만을 가졌음
          + 비디오 촬영자들은 여전히 렌즈에 기어 이빨 스트립을 붙이고, 외부에 기계식 팔로우 포커스 메커니즘을 부착하고 있음
          + 제조업체들이 ""시네마"" 렌즈 라인을 보호하기 위해 직접 제어를 제공하지 않는 것 같음. 수동 렌즈가 수천 달러에 판매되고 있음
          + Canon 카메라 제어 SDK를 살펴보았지만, 초점 제어는 PTZ 카메라 두 대를 제외한 모든 라인에서 누락되어 있음
     * @ExAr - 정보의 보물창고, 노력해줘서 고마움
          + 그래픽을 만드는 방법에 대해 블로그를 운영하는지 궁금함. 예를 들어, 이 뷰파인더 이미지가 매우 인상적임
          + 광선과 눈을 어떻게 시뮬레이션하는지 궁금함
     * 다양한 자동 초점 시스템이 어떻게 작동하는지 항상 알고 싶었음. 이 페이지는 놀라움
          + Nikon 자동 초점 시스템에 대한 페이지도 있었으면 좋겠음
          + 자동 초점 모터가 없는 렌즈가 여전히 몇 개 있음. 모터는 카메라 바디에 있고, 렌즈 마운트의 작은 나사가 모터 회전을 렌즈의 자동 초점 부품으로 전달함. 하지만 매우 느리고 시끄러웠음
     * 훌륭한 글, 고마움
          + 질문이 있음. EF 400mm f2.8 (2세대) 렌즈가 오래된 7Dmk2에서는 매우 빠르게 초점을 맞추지만, 새로운 R6Mk2에서는 그렇지 않음. 다른 렌즈들은 반대임. 왜 이런 일이 발생하는지 궁금함
          + 오래된 7D와 1D 바디가 AF 모터에 더 많은 전력을 보내기 때문이라는 말을 들었지만, 어디에서도 확인할 수 없었음
     * 이 압전 드라이버는 매우 멋짐
          + 메커니즘을 보여주는 비디오가 있음
          + 모터가 최대 속도로 작동하는 비디오도 있음
     * 이 모터 유형은 모두 개방 루프임. 특정 상태를 정확하게 명령할 수 없음
          + 예를 들어, 렌즈에 3m에 초점을 맞추라는 신호를 보내면, 다음 번에 3m에 초점을 맞출 때와 정확히 같은 상태가 아닐 수 있음
          + 이 때문에 카메라 보정이 까다로울 수 있으며, 보정 후에는 카메라를 만지지 않는 것이 좋음
     * 놀라운 웹사이트임. Canon 자체에서 나온 콘텐츠인 줄 알았음
          + Canon의 EF, EF-S, RF, RF-S 렌즈에서 사용된 모든 자동 초점 드라이브 유형을 보여주는 비교 차트가 있음
          + EF-M, Canon의 미러리스 교환 렌즈 카메라에 대한 언급이 빠져 있음
          + 초음파 소음은 인간의 귀로 들을 수 없지만, 민감한 마이크로폰이 이를 감지할 수 있어 비디오 촬영 시 문제가 될 수 있음
          + 여러 Ring USM 렌즈를 사용했으며, 초점 맞출 때 소음을 들을 수 있었음. 부드러운 화이트 노이즈 같은 소리였음
          + 최신 자동 초점 드라이브 유형인 스테퍼 모터, Nano USM, 보이스 코일 모터는 포커스 바이 와이어를 제공함
          + 포커스 바이 와이어 자체에는 반대하지 않지만, 구현이 좋지 않았음. 여러 EF-M (모두 STM) 및 RF (일부 STM 및 일부 Nano USM) 렌즈를 사용했을 때, 모터 작동이 사용자가 포커스 링을 돌리는 것보다 상당히 느렸고, 포커스 단계의 세분성이 보였음
          + 반면, 오래된 EF Ring USM의 풀타임 수동(FTM)은 비교적 좋았음. 힘이 많이 들지 않았고, 지연 없이 완전히 반응했으며, 손으로 돌릴 때 완전히 아날로그였고 이산 단계가 없었음. 새로운 렌즈는 이 디자인을 사용하지 않아 아쉬움
          + Canon EF 15mm F2.8 Fisheye 등의 구문을 ""f/2.8""으로 변경해주길 바람. Canon의 공식 페이지에서도 이렇게 표기함
          + 왜냐하면 f는 실제로 초점 거리를 나타내는 소문자 이탤릭 변수이고, ""/""는 나눗셈을 의미함. 조리개 크기는 (15 mm / 2.8) = 5.4 mm이며, 이는 빛이 통과하는 구멍의 실제 직경임. 절대 조리개는 5.4 mm이고, 상대 조리개는 f/2.8임
"
"https://news.hada.io/topic?id=19599","애플, 새로운 Mac Studio 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         애플, 새로운 Mac Studio 공개

Apple, 새로운 Mac Studio 발표

     * Mac Studio 소개
          + Apple은 M4 Max와 새로운 M3 Ultra 칩을 탑재한 가장 강력한 Mac Studio를 발표함
          + Thunderbolt 5, 최대 512GB의 통합 메모리, 최대 16TB SSD를 갖춘 컴팩트한 디자인으로 탁월한 성능 제공
          + AI 및 대규모 언어 모델(LLM)을 메모리 내에서 실행할 수 있는 강력한 GPU와 최대 512GB의 통합 메모리 제공
     * M4 Max를 탑재한 Mac Studio
          + 비디오 편집자, 개발자, 엔지니어 등에게 적합한 성능 제공
          + 최대 16코어 CPU, 40코어 GPU, 초당 500GB 이상의 메모리 대역폭 제공
          + M1 Max 대비 최대 3.5배, Intel 기반 27인치 iMac 대비 최대 6.1배 빠른 성능 제공
     * M3 Ultra를 탑재한 Mac Studio
          + 고성능 작업을 위한 최상의 성능 제공
          + 최대 32코어 CPU, 80코어 GPU, 32코어 Neural Engine 제공
          + M1 Ultra 대비 최대 2.6배, Intel Xeon W 기반 Mac Pro 대비 최대 6.4배 빠른 성능 제공
     * Thunderbolt 5 및 확장성
          + Thunderbolt 5 포트를 통해 최대 120Gb/s의 전송 속도 제공
          + PCIe 확장 카드 연결을 위한 외부 확장 섀시 지원
          + 최대 8개의 Pro Display XDR을 6K 해상도로 구동 가능
     * Apple Intelligence 및 macOS Sequoia
          + Apple Intelligence를 통해 사용자의 작업을 더욱 향상시킴
          + macOS Sequoia는 iPhone 미러링, 창 타일링, 새로운 비밀번호 앱 등 다양한 기능 제공
          + Safari는 기사 요약, 비디오 뷰어, 방해 요소 제어 기능 제공
     * 환경을 위한 노력
          + Apple 2030 목표에 따라 재생 가능한 전기로 제조 전환
          + Mac Studio는 30% 이상의 재활용 소재로 제작됨
          + 포장은 완전히 섬유 기반으로, 2025년까지 모든 포장에서 플라스틱 제거 목표
     * 가격 및 출시
          + Mac Studio는 $1,999부터 시작하며, 교육용 가격은 $1,799부터 시작
          + Apple Store 및 Apple 공인 리셀러에서 3월 12일부터 구매 가능
          + Apple Trade In을 통해 기존 컴퓨터를 새 Mac으로 교환 가능
     * Apple 소개
          + Apple은 1984년 Macintosh 도입으로 개인 기술을 혁신함
          + iPhone, iPad, Mac, AirPods, Apple Watch, Apple Vision Pro 등 혁신적인 제품 제공
          + iOS, iPadOS, macOS, watchOS, visionOS, tvOS 등 6개의 소프트웨어 플랫폼 제공

        Hacker News 의견

     * 512GB의 RAM을 Chrome과 데스크톱 JS 앱 개발자에게서 멀리 두어야 한다는 의견이 있음
     * AI와 통합 메모리에 대한 관심이 높지만, M4 mini에서 4K 콘텐츠를 편집한 후 M1 Max Mac Studio보다 M4의 미디어 처리 성능이 훨씬 뛰어남을 깨달음
          + CPU의 성능이 더 강력해져서, 비디오/사진 편집을 위해 64GB RAM을 가진 M4 Max를 주문함
          + H.265 콘텐츠를 4K/고급 설정으로 실시간 이상으로 내보낼 수 있을 것 같음
     * AI 관련 논의가 중급 워크스테이션 빌드에 대한 모든 논의를 차지한 것에 대해 아쉬움을 느낌
     * macOS Sequoia가 iPhone 미러링을 포함한 다양한 기능으로 새로운 Mac Studio 경험을 완성함
          + 프로 워크스테이션 사용자에게는 이 기능이 하이라이트임
     * SSD 가격이 비정상적으로 높음
          + 1TB에서 2GB로 업그레이드하는 데 $400이 필요함
          + 1TB에서 16TB로 업그레이드하는 데 $307/TB가 필요함
          + 이는 Amazon 가격의 3배임
     * 메모리 대역폭이 증가하지 않았음
          + M2 Studio에서 제공되는 것과 동일한 메모리 대역폭을 얻을 수 있음
          + 512GB의 uRAM을 10,000달러에 얻을 수 있음
          + 새로운 M3 칩의 처리 속도가 증가했음에도 불구하고 메모리 대역폭이 동일하여 AI 성능에서 수익 감소가 발생함
     * 완전 구성 시 $14,000임
     * M3 Ultra와 M4 Max 두 칩의 성능 비교를 제공하지 않는 이유에 대한 의문이 있음
     * 이전 기사에서 M3 Ultra가 가장 강력한 칩이라고 언급됨
     * Mac 생태계가 PC 세계와 비슷해지고 있음
          + 저렴한, 좋은, 비싼 세 가지 옵션만 제공해주길 바람
          + 청소년용 노트북에 몇 개의 전용 그래픽 코어가 필요한지 결정하는 것이 불가능함
     * 최신 Mini의 전원 버튼을 뒤에 두지 않았지만 Studio에는 그렇게 했다는 점이 불만임
     * Mac Studio with M3 Ultra는 96GB의 통합 메모리로 시작함
          + 여전히 8GB 메모리가 있는 노트북이 판매되고 있으며, 최소 32GB는 되어야 한다고 생각함
          + 작업용 노트북이 여전히 16GB에 불과함
"
"https://news.hada.io/topic?id=19712","스타트업 CTO 핸드북","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              스타트업 CTO 핸드북

스타트업 CTO 핸드북

  고성능 엔지니어링 팀을 위한 필수 기술 및 모범 사례

    소개

     * 항상 배우기: 저자는 어릴 때부터 컴퓨터와 소프트웨어 프로그래밍에 대한 열정을 가지고 있었으며, 이를 통해 지속적인 학습의 중요성을 깨달았음. 기술 리더로서 성공하기 위해서는 끊임없이 배우고 성장하는 것이 중요함.
     * 스타트업 기술 리더의 딜레마: 대부분의 스타트업은 기술 공동 창업자가 있으며, 이들은 초기 코드베이스를 작성하고 첫 엔지니어들을 고용함. 그러나 팀이 성장하면서 기술 리더는 관리 역할로 전환해야 하며, 이 과정에서 리더십 기술이 부족할 수 있음.

    저자 소개

     * 저자는 여러 스타트업에서 경험을 쌓았으며, 기술 리더로서의 역할을 수행해왔음. 다양한 스타트업에서의 경험을 통해 기술 리더십에 필요한 다양한 기술과 도전 과제를 이해하게 되었음.

    이 책의 사용법

     * 이 책은 소프트웨어 엔지니어링 팀을 관리하는 리더를 위한 참고서로, 다양한 주제를 독립적인 장으로 다루고 있음. 각 장은 주제를 소개하고, 개요를 제공하며, 모범 사례를 제시함.

  비즈니스 프로세스

     * 비즈니스 프로세스를 설명하여 문제 해결의 출발점을 제공함. 팀과 회사의 규모에 따라 프로세스를 조정하고 확장할 필요가 있음.

  사람과 문화

    관리 기본 원칙

     * 관리의 황금률: 팀의 성과가 관리자의 성과를 측정하는 기준임. 팀원들이 최선을 다할 수 있도록 지원해야 함.
     * 전문 기술 트리: 기술 리더십을 위해서는 기술뿐만 아니라 관리 기술에도 투자해야 함.

    지속적인 개선

     * 카이젠: 팀과 개인 모두 지속적인 개선을 추구해야 함. 실수를 개선의 기회로 삼아야 함.

    코칭

     * 관리자는 팀원들이 최선을 다할 수 있도록 돕는 코치의 역할을 해야 함.

    관리 멘토 찾기

     * 리더십 전환을 위해 관리 멘토를 찾는 것이 중요함. 적절한 멘토를 통해 리더십 기술을 향상시킬 수 있음.

    1:1 미팅

     * 1:1 미팅은 팀원과의 관계를 구축하고, 그들의 강점과 약점을 파악하여 최선을 다할 수 있도록 돕는 기회임.

    스킵 레벨 미팅

     * 정기적으로 관리자의 직속 보고자와 미팅을 하여 다양한 관점을 수집하고, 이를 통해 비즈니스를 개선할 수 있음.

    관리자를 위한 코칭

     * 중간 관리자의 성과가 조직의 성과에 중요함. 지속적인 교육과 지원을 통해 관리자를 육성해야 함.

    엔지니어와의 1:1 미팅

     * 엔지니어와의 1:1 미팅은 그들이 직면한 문제를 듣고, 해결책을 찾도록 돕는 기회임. 미팅의 목적을 명확히 하고, 생산적인 대화를 이끌어야 함.

        Hacker News 의견

     * ""두 팀"" 체계에 대한 비판적 의견이 있음
          + 소프트웨어 개발에서 피드백 루프를 끊으면 개발자와 고객 모두에게 부정적인 영향을 미침
          + 개발자들이 피드백을 통해 배우지 못하면 시간이 지날수록 개발이 느려지고 비용이 증가함
          + CTO는 개발자들이 개선할 수 있도록 돕는 책임이 있음
     * 컴플라이언스 인증 준비에 대한 의견
          + SOC2 인증은 사전에 준비할 필요가 없으며, 큰 고객이 요구하지 않으면 불필요함
          + 초기부터 단일 로그인 설정과 보호된 Git 브랜치 같은 기본적인 최선의 관행을 따르는 것이 중요함
     * CTO가 코딩을 멈추는 것에 대한 의문
          + 관리 기술과 코딩 기술은 다르지만, 기술적인 CTO로서 팀과 회사를 적극적으로 지원할 필요가 있음
          + CTO가 직접 코딩에 참여하는 것이 중요함
     * ""두 팀"" 시스템의 실효성에 대한 의문
          + 이론적으로는 좋지만 실제로는 잘 작동하지 않을 것이라는 의견이 있음
          + 라이브러리 팀이 다른 팀이 활용할 수 있는 서비스를 구축하는 것이 가장 가까운 사례임
     * 문화 적합성에 대한 논의
          + 문화 적합성은 종종 차별을 숨기는 요소로 작용하며, 이는 회사에 부정적인 영향을 미침
          + 성공적인 리더는 채용 실수를 인정하고, 천천히 채용하고 빠르게 해고하는 것을 두려워하지 않음
     * 책임과 우려에 대한 포괄적인 가이드의 중요성
          + 좋은 조언자나 경험이 없으면 필요한 사항을 알려주는 사람이 없을 수 있음
          + 각 섹션에 대해 우리 회사의 답변은 무엇인지, 동의하는지, 프로세스가 더 나은지 등을 고민하는 것이 유익함
     * 설명 비디오 라이브러리 구축에 대한 의견
          + UI나 애니메이션 같은 특정 분야에서는 유용할 수 있지만, 일반적으로 텍스트를 읽는 것이 더 효율적임
          + 급할 때는 텍스트에서 중요한 부분을 찾기가 더 쉬움
     * 2023년에 인기 있는 주제에 대한 링크 제공
     * 회의 빈도와 유형을 미리 결정하는 것은 정부 기관의 부서를 운영하는 방식과 비슷하다는 의견이 있음
"
"https://news.hada.io/topic?id=19633","Model Context Protocol (MCP) 개발 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Model Context Protocol (MCP) 개발 방법

     * MCP는 AI 시스템과 다양한 데이터 소스를 연결하는 범용 프로토콜로, AI 모델의 성능과 활용도를 높이는 것을 목표로 함
     * MCP의 주요 특징
          + 개방형 표준: MCP는 모든 AI 시스템이 사용할 수 있는 오픈소스 프로토콜
          + 양방향 연결: AI 도구와 데이터 소스 간의 안전한 양방향 연결을 지원
          + 범용성: 콘텐츠 저장소, 비즈니스 도구, 개발 환경 등 다양한 데이터 시스템과 연결할 수 있음
          + 표준화: 각 데이터 소스마다 별도의 커넥터를 개발할 필요 없이 단일 프로토콜로 통합이 가능
     * MCP의 구조 : 클라이언트-서버 아키텍처 기반
          + 호스트: LLM 애플리케이션으로, 연결을 시작
          + 클라이언트: 호스트 애플리케이션 내에서 서버와 1:1 연결을 유지
          + 서버: 클라이언트에 컨텍스트, 도구, 프롬프트를 제공
     * MCP의 장점
          + 데이터 접근성 향상: AI 모델이 다양한 데이터 소스에 쉽게 접근할 수 있음
          + 개발 효율성: 개발자는 표준 프로토콜을 사용해 여러 데이터 소스와 연결할 수 있음
          + 확장성: AI 시스템이 여러 도구와 데이터셋 간에 컨텍스트를 유지할 수 있어 더 지속 가능한 아키텍처 구축이 가능
          + 보안: 프로토콜에 보안이 내장되어 있어 LLM 제공업체와 API 키를 공유할 필요가 없음

목차

1장 MCP 소개

    1. 정의와목적
    2. 기본아키텍처
    3. 호스트 클라이언트 서버구조
    4. 보안및신뢰모델

2장 MCP 핵심기능

    1. Resources
    2. Prompts
    3. Tools
    4. Sampling

3장 구현가이드

    1. Quickstart 튜토리얼
    2. 서버구현 Python
    3. 서버구현 TypeScript
    4. SQLite 데이터베이스연동
    5. 파일시스템접근
    6. MCP 서버 예제 구현

4장 MCP 클라이언트

    1. Claude Desktop
    2. Zed Editor
    3. Sourcegraph Cody
    4. Firebase Genkit
    5. Continue

5장 개발자도구와디버깅

    1. MCP Inspector
    2. 디버깅테크닉
    3. 로깅과모니터링
    4. 문제해결가이드

부록

   A. JSON-RPC 메시지포맷
   B. 주요인터페이스정의
   C. 설정예제

   테스트를 위해 알아보던 중 linux용 claude나 gpt desktop이 없다는 것을 알고 놀랍니다. 맙소사.

   애플 우승!ㅜㅜ

   Anthropic, Model Context Protocol 오픈소스로 공개
   앤스로픽이 공개한지 3달 만에 엄청나게 핫해졌네요.
   긱뉴스에서 한글로된 개발 가이드는 올린 적이 없는듯 해서 올려봅니다.
"
"https://news.hada.io/topic?id=19641","Athena 우주선, 달에서 전복 후 사망 선언","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Athena 우주선, 달에서 전복 후 사망 선언

     * Intuitive Machines LLC의 Athena 우주선이 달에 착륙한 후 전복되면서 임무가 조기 종료됨.
          + 아테나는 텍사스 기반의 Intuitive Machines(IM)이 발사한 탐사선으로, 달 남극 근처에 착륙했으나 목표 지점에서 약 250미터 떨어진 곳에 도착함.
          + 초기에는 전력을 생성하고 데이터를 지구로 전송했으나, ""잘못된 자세""를 나타내는 데이터로 인해 엔지니어들이 분석 중이었음.
     * IM은 금요일에 아테나가 사망했다고 선언함.
          + 태양의 방향, 태양 전지판의 방향, 그리고 분화구의 극한의 추운 온도로 인해 아테나가 재충전될 가능성이 없다고 발표함.
          + 임무는 종료되었으며, 팀은 임무 동안 수집된 데이터를 계속 평가 중임.
     * 아테나의 실패는 2024년 2월 IM의 첫 달 착륙과 거의 동일한 결과를 보임.
          + 오디세우스 우주선은 달에 도착한 첫 민간 임무였으나, 표면을 미끄러져 다리가 부러지고 전복됨.
          + 아테나와 함께 수백만 달러 상당의 장비가 손실됨. 여기에는 NASA의 트라이던트 레골리스 드릴이 포함되어 있었으며, 이는 물과 다른 생명 유지 성분을 찾기 위해 토양을 발굴할 예정이었음.
          + 착륙선은 또한 세 개의 로봇 이동 탐사선을 실었으며, 그 중 하나인 모바일 자율 탐사 플랫폼(Mapp)은 콜로라도 회사 Lunar Outpost가 제작한 최초의 상업적으로 제작된 달 탐사 로봇이었음.
     * IM-2 임무와 NASA의 CLPS 프로그램
          + 아테나의 10~14일간의 예정된 임무인 IM-2는 NASA의 26억 달러 규모의 상업적 달 페이로드 서비스(CLPS) 프로그램에 의해 계약된 10개 임무 중 하나였음.
          + 이 프로그램은 민간 산업이 실험 및 기타 장비를 달에 보내도록 장려하기 위한 것임.
     * 긍정적인 측면
          + IM은 아테나의 도착이 ""가장 남쪽의 달 착륙 및 표면 작전""을 달성했다고 긍정적으로 평가함.
          + 이 남극 지역은 험준한 지형과 지구와의 제한된 직접 통신으로 인해 회피되었으나, IM은 IM-2의 통찰력과 성과가 이 지역을 더 많은 우주 탐사를 위해 열어줄 것이라고 믿음.

        Hacker News 의견

     * 두 번의 실패는 쉽게 피할 수 있었음
          + 미국 정부가 플루토늄-238을 생산하고 비축하여 NASA와 민간 사용을 위해 제공해야 한다고 생각함
          + 왜 모든 우주 과학 기기가 Voyager 1처럼 RTG로 구동되지 않는지 의문임
          + 태양 전지는 방향에 따라 실패할 수 있고, 방사선, 미세 유성체, 먼지 손상에 취약함
          + 이러한 이유로 과학 기기의 수명이 Voyager 1보다 짧음
     * 좋은 조언:
         1. 겨울에 러시아를 침공하지 말 것
         2. 로봇 달 착륙선의 무게 중심을 낮게 유지할 것
     * 과학과 전복에 대한 논의에서 250마일 떨어진 곳에 착륙한 이유에 대한 설명이 부족함
     * 비슷한 구조의 얇고 높은 기체가 1년 전 달에 도착했으나 결국 전복됨
          + 다음 임무에서는 착륙 단계에서 탑 모양이 아닌 게 모양의 디자인을 사용할 가능성이 있음
     * 달에서 다른 로봇을 지원하는 로봇을 만드는 사업 아이디어
     * 착륙선이 가늘고 불안정해 보임
          + 착륙 후 재정렬하거나 스스로 일어설 수 있는 장치가 있는지 궁금함
          + 화성에서 사용된 기억이 어렴풋이 남아 있음
     * Intuitive Machines의 첫 번째와 두 번째 달 착륙선이 전복되었으나 세 번째는 전복되지 않기를 바람
     * 최근 두 개의 민간 달 착륙선이 착륙했으며 첫 번째는 성공적이었음
     * 90%까지는 쉽게 도달할 수 있지만 마지막 10%는 매우 지루하고 느림
     * 레이저 거리 측정기가 착륙 중 작동하지 않는 것에 대한 우려가 있음
          + Noca-C 착륙선의 비율에 대한 많은 논의가 있음
          + 두 개의 큰 연료 탱크가 네 개의 작은 탱크보다 효율적임
          + 다음 두 착륙선의 다리는 더 넓어야 함
"
"https://news.hada.io/topic?id=19586","애플 M3 울트라 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              애플 M3 울트라 출시

M3 Ultra 공개

     * Apple은 M3 Ultra를 발표하며, 이는 M1 Ultra 대비 최대 2.6배의 성능을 제공하고 Thunderbolt 5 연결 및 개인용 컴퓨터에서 가장 많은 통합 메모리를 지원함.
     * M3 Ultra는 32코어 CPU, 80코어 GPU, 두 배의 Neural Engine 코어, Thunderbolt 5, 그리고 개인용 컴퓨터에서 가장 많은 통합 메모리를 특징으로 함.
     * Apple의 혁신적인 UltraFusion 패키징 아키텍처를 사용하여 두 개의 M3 Max 다이를 10,000개 이상의 고속 연결로 연결하여 낮은 지연 시간과 높은 대역폭을 제공함.
     * M3 Ultra는 1840억 개의 트랜지스터를 결합하여 새로운 Mac Studio의 성능을 극대화함.

  초고성능 및 효율성

     * M3 Ultra는 Mac 칩 중 가장 높은 성능을 제공하며, Apple 실리콘의 업계 최고 전력 효율성을 유지함.
     * 최대 32코어 CPU와 80코어 GPU를 갖추고 있으며, M2 Ultra 대비 최대 1.5배, M1 Ultra 대비 최대 1.8배의 성능을 제공함.
     * AI 및 머신러닝을 위한 강력한 32코어 Neural Engine을 탑재하여 AI 개발에 최적화된 데스크탑 환경을 제공함.

  비할 데 없는 메모리

     * M3 Ultra의 통합 메모리 아키텍처는 개인용 컴퓨터에서 가장 높은 대역폭과 낮은 지연 시간을 제공하는 메모리를 통합함.
     * 96GB에서 시작하여 최대 512GB까지 구성 가능하며, 이는 오늘날의 가장 진보된 워크스테이션 그래픽 카드의 메모리를 초과함.

  차세대 연결을 위한 Thunderbolt 5

     * M3 Ultra는 Mac Studio에 Thunderbolt 5를 도입하여 최대 120 Gb/s의 데이터 전송 속도를 제공함.
     * 각 Thunderbolt 5 포트는 칩에 직접 설계된 맞춤형 컨트롤러로 지원되어, Mac Studio에서 가장 강력한 Thunderbolt 5 구현을 가능하게 함.

  내장된 첨단 기술

     * M3 Ultra는 Apple의 첨단 기술을 칩에 직접 통합하여 성능과 효율성을 극대화함.
     * UltraFusion 패키징 기술은 두 개의 M3 Max 다이를 10,000개 이상의 신호로 연결하여 2.5TB/s 이상의 낮은 지연 시간의 프로세서 간 대역폭을 제공함.
     * 미디어 엔진은 H.264, HEVC, 그리고 네 개의 ProRes 인코드 및 디코드 엔진을 하드웨어로 지원하여 최대 22개의 8K ProRes 422 비디오 스트림을 재생할 수 있음.
     * 디스플레이 엔진은 최대 8개의 Pro Display XDR을 지원하며, 1억 6천만 픽셀 이상을 구동함.
     * Secure Enclave는 하드웨어 검증된 보안 부팅 및 런타임 악용 방지 기술과 함께 최첨단 보안을 제공함.

  환경을 위한 더 나은 선택

     * M3 Ultra의 전력 효율적인 성능은 새로운 Mac Studio가 Apple의 높은 에너지 효율성 기준을 충족하도록 도우며, 제품 수명 동안 소비되는 총 에너지를 줄임.
     * Apple은 2030년까지 전체 탄소 발자국에서 탄소 중립을 달성할 계획임.

        Hacker News 의견

     * 512GB의 통합 메모리는 새로운 지평을 여는 것임. Apple이 메모리 제약을 극복할 때가 언제일지 궁금했는데, 이제 반 테라바이트 수준의 통합 메모리를 보게 됨. 이는 대형 AI 모델을 로컬에서 실행하는 데 매우 실용적이며, Apple의 효율적인 메모리를 단일 칩에 통합하는 접근 방식은 NVIDIA의 솔루션과 비교해 매력적임
          + 두 개의 M3 Max 칩을 ""융합""하는 이 디자인이 열 방출과 전력 소비 측면에서 어떻게 성능을 발휘하는지 궁금함
     * M3 대신 M4. 이것이 기본적으로 비닝인지 궁금함. M1 칩에 대해 이를 가능하게 했던 인터포저가 사용 가능하지 않다는 것을 어디선가 읽었던 것 같음
          + 512GB의 통합 램과 NPU 접근은 절대적인 게임 체인저임. 내 추측으로는 Apple이 내부 AI 작업을 위해 이 칩을 개발했으며, 이제 다른 사람들이 사용할 수 있도록 공개하고 있는 것임. 이를 위해 2U 랙 형태가 정말 필요함
          + 이 하드웨어는 현재 운영 체제에 의해 제약을 받고 있음
     * 이전 M2 Ultra 모델은 최대 메모리가 192GB였음. Pro와 다른 M3 모델은 128GB로, 이는 심지어 99.9%의 전문 작업에도 충분하다고 생각함
          + 이제 이를 512GB로 늘림. 512GB Mac Studio의 가격은 $9499로 매우 비쌈. 이는 AI 골드 러시임이 확실함
     * Studio를 M3 Ultra로 업데이트했으니, M4 Ultra는 WWDC에서 Mac Pro에 직접 들어갈 수 있을 것임. 흥미로운 타이밍임. 아마도 Mac Pro의 폼 팩터도 변경할 것임
          + 또한, 이는 매우 소량의 제품일 것이므로 N3B에 있는 것이 큰 문제가 아님. 동시에, 이 칩들은 제작 비용이 매우 비쌀 것이므로, 고급 가격의 RAM과 결합하는 것이 일리가 있음
     * 512GB 통합 메모리는 AI 작업에 절대적으로 놀라운 것임. NVIDIA GPU가 얼마나 많이 필요한지에 비해, 가격이 거의 합리적으로 보임
     * M3 Ultra와 M4 Max의 일반 컴퓨팅 가치를 비교할 때, Studio의 M4 버전에서 RAM을 최대한으로 설정한다고 가정하면 어떻게 생각하는지 궁금함
     * Thunderbolt 5 (TB 5)는 매우 유용함. 매우 얇고 가벼운 노트북을 가지고 있다가 필요할 때 TB 5를 통해 외부 GPU나 eGPU에 접근할 수 있음
          + Asus가 세계 최초의 Thunderbolt 5 eGPU를 발표했음
     * AI 모델을 실행하기 위해 최대 메모리(512GB)를 원하고 모델 가중치를 아카이브하기 위해 드라이브를 연결하는 것이 괜찮다면, 약 $10K에 이를 얻을 수 있음. 꿈의 기계임
          + Nvidia의 Project DIGITS는 $3K로 곧 출시될 예정이며, 이 Mac의 128GB & 4TB 버전을 약 $4700에 얻을 수 있음. 차이점은 이를 일주일 내에 실제로 얻을 수 있으며 macOS를 실행할 것임
          + 누군가가 이 전체 DeepSeek 모델을 테스트하는 것을 보고 싶음. 아마도 이것이 완전히 소유할 수 있는 첫 번째 작은 동반자 AI 장치가 될 것이며, 번거로움 없이 원하는 대로 할 수 있을 것임
     * Apple은 오늘 M3 Ultra를 발표했으며, 이는 지금까지 만든 가장 높은 성능의 칩임
          + 몇 주 전에 M4 Max가 나왔던 것 같았음
     * 요즘 컴퓨터 - 더 매력적이고, 흥미롭고, 멋지고 바람직할수록 가격이 천문학적으로 높아짐
          + $9499
          + 컴퓨팅에서의 경쟁은 어떻게 된 것인지 궁금함
          + 컴퓨팅 하드웨어 경쟁은 예전에는 치열하고, 잔인하게 경쟁적이었음. 이제는 단순한 대규모 골드 러시 현금 획득임
"
"https://news.hada.io/topic?id=19690","Show GN: 스마트 쇼핑 – 복잡한 할인 계산을 간편하게","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Show GN: 스마트 쇼핑 – 복잡한 할인 계산을 간편하게

   할인, 제대로 계산하고 계신가요?
   2+1 행사, 추가 할인, 쿠폰까지… 매장에서는 다양한 프로모션이 쏟아지지만, 실제로 어떤 게 더 저렴한지 계산하기는 쉽지 않습니다.

   왜 이런 앱이 필요할까요?
   예를 들어, 1500원짜리 상품을 2+1으로 살 때와 1000원짜리 상품을 개별 구매할 때, 10% 할인이 적용된 또 다른 제품까지 비교해보면 어떤 게 더 이득일까요? 직접 계산하려면 번거롭고 실수하기 쉽습니다.

   그래서 더 똑똑한 쇼핑을 돕기 위해 ‘알뜰계산기’를 출시했습니다.
   라이프스타일 비즈니스를 꿈꾸며, 일상에서 느낀 불편함을 해결하고자 만든 작은 앱입니다. 사용자가 가격과 할인 조건을 입력하면 다양한 할인 가격을 손쉽게 계산하고, 장바구니에 담아 비교나 합계를 편리하게 확인할 수 있도록 돕습니다.

   직접 사용해보시고 피드백을 주시면 감사하겠습니다.
   여러분의 의견이 앱을 더 나은 방향으로 발전시키는 데 큰 도움이 될 거예요!
"
"https://news.hada.io/topic?id=19698","Seven39  - 매일 저녁 3시간만 열리는 소셜 미디어 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Seven39 - 매일 저녁 3시간만 열리는 소셜 미디어 앱

     * 매일 오후 7시 39분부터 10시 39분까지 동부 표준시(EST)에만 열리는 소셜 미디어 플랫폼
     * 모든 사용자가 같은 시간 동시에 로그인해서 같이 사용(아이디는 미리 생성가능)
     * 끝없는 스크롤이나 FOMO(놓칠까 봐 두려운 마음)가 없는 매일 저녁 3시간의 즐거움 제공
     * 이름의 유래: 7시 39분에 열리는 이유는 Seven39 도메인이 사용 가능했기 때문

   지금이 아침 8시 40분인데 무심코 보니까 딱 7:40:28 PM EST네요... 신기해라

   정말 참신한 아이디어인데 다른 댓글처럼 트래픽이 몰리는 것을 어떻게 해결할지도 궁금하내요

   트래픽이 해당시간에만 엄청 집중될텐데 효율적인 처리가 필요하겠네요.

        Hacker News 의견

     * 정말 멋진 아이디어라고 생각함. ""EST""를 ""European Standard Time""으로 착각해서 가입했음. 현재 시간대는 나에게 맞지 않지만, 모든 것이 모두에게 맞을 필요는 없다고 생각함. 인위적인 규칙이 새로운 상호작용을 만들 수 있음
          + 더 많은 사람들을 수용하기 위해 규칙을 조정한다면, ""현지 시간대에 맞춰 7:39부터 10:39까지 열림""으로 하는 것은 아이디어를 망칠 것 같음. 모두가 같은 시간에 있어야 한다는 것이 중요함
          + 대안으로 여러 시간대를 두는 것이 좋을 것 같음. 예를 들어, 7:39 PM EST와 7:39 AM EST에 시작하는 두 개의 창을 두면 전 세계 사람들이 참여할 수 있는 시간이 늘어날 것임
          + 각 창을 한 시간 정도로 줄이는 것도 고려할 만함
     * 하루에 한 번만 게시할 수 있는 소셜 미디어가 있으면 좋겠음. 대부분의 사람들은 하루에 한 가지 소식을 공유할 정도로 충분함. 10분마다 게시하는 것은 스팸이나 비자연적인 의도가 많음
          + 자연스러운 소셜 네트워크에서 과도한 공유는 부정적으로 작용함. 너무 많은 소음과 적은 신호로 인해 사람들이 압도되고, 놓칠까 봐 두려워하며, 합의에 도달하지 못함
          + ""좋아요"" 버튼 대신 ""감사합니다"" 신호로 바꾸는 것이 좋을 것 같음. 사람들이 유용하다고 생각하는 것을 기반으로 소셜 네트워크를 구축하는 것이 더 나음
     * 3시간 창을 매일 한 시간씩 이동시키는 것도 좋을 것 같음. 다른 시간대 문제 해결책들은 아이디어를 정상으로 되돌리는 방향으로 가고 있음
          + 이동하는 창은 더 ""느린 인터넷"" 느낌을 줄 것임. 프라임 타임에 맞춰서 그날의 내용을 따라잡을 수 있음
     * 뉴스 피드가 없는 소셜 미디어 사이트가 있으면 좋겠음. 친구로 추가한 실제 사람들로부터만 알림과 업데이트를 받는 것임. 피드와 알고리즘이 주는 참여를 유도하지 않겠지만, 더 건강한 경험이 될 것임
     * 웹사이트에 ""영업 시간""이 있는 것도 생각해봤음. 지원 직원이 새벽 2시에 문제 해결 요청을 받지 않아도 됨
     * 흥미로운 아이디어지만, 특정 그룹에만 편리한 시간에 열리면 다양한 세계적 관점을 잃을 수 있음. 각 시간대에 3시간을 주는 것은 효과적이지 않을 것 같음. 매일 다른 시간대에 맞춰 3시간을 회전시키면 다양성을 촉진할 수 있을 것임
          + 친구 그룹에서 성공을 거두었다면, 그룹 채팅 앱에 적합한 메커니즘일 수 있음
     * 좋은 아이디어지만, 24/7로 열리고 3시간 창을 8개 두는 것이 좋을 것 같음. 한 계정은 24시간 동안 한 창만 사용할 수 있음. 시간대 차이를 해결할 수 있음
     * Cory Doctorow의 ""Eastern Standard Tribe""를 추천할 만한 시기임. 사람들이 지리적 위치와 상관없이 가장 활동적인 시간대에 따라 하위 문화로 나뉘는 세계를 배경으로 함
     * 친구와 2014년 스타트업 주말에 비슷한 아이디어를 만들었음. ""Let's Get Weird""라는 이름이었음. 앱은 11시부터 4시까지 열렸고, 근처 사람들과 채팅하고 사진을 공유할 수 있었음. 셀카는 거꾸로 찍혔고, 하루가 끝나면 모든 것이 삭제됨
     * 실직했을 때 지역 실업 사무소 웹사이트가 실제 업무 시간 외에는 ""닫힘"" 상태였음. 짜증나면서도 재미있었음. 더 제한적이지만 진정성 있는 소셜 미디어가 있으면 좋겠음

   요새 횟수나 시간을 제한 하는 서비스들이 다시 유행하던데 그 얼마전에 유행했던, 이름이 정확히 기억 안나는데 방송 비스무리하게 말하는 앱처럼 반짝 하고 사그라들지 않을까 싶네요.

   클럽하우스 일듯하네요 저도 마침 딱 그게 떠올랐습니다

   네 맞아요 그거요!
"
"https://news.hada.io/topic?id=19672","LLM이 실제로 프로그래머의 생산성을 얼마나 향상시키고 있을까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  LLM이 실제로 프로그래머의 생산성을 얼마나 향상시키고 있을까?

     * LLM 기반 코딩 보조 도구가 출시된 지 약 2년이 되었음
     * 일부 개발자는 생산성이 최대 5배에서 10배까지 증가했다고 보고함
     * 그러나 소프트웨어 업계 전체의 생산성이 5~10배 증가했다는 명확한 증거는 없음
     * 실제로 코드베이스에 단순한 보일러플레이트 기능을 추가하는 것 이상의 작업에서는 LLM 도구가 까다롭게 작동함
     * 대부분의 프로그래머는 LLM 도구를 효과적으로 사용하는 방법을 모르거나 관심이 없음

생산성 향상이 특정 사용자에게만 집중되는 이유

     * 만약 생산성이 5배에서 10배 증가했다면, 이는 LLM을 잘 다루는 소수의 고급 사용자나 숙련된 개발자에게 국한될 가능성이 높음
     * 전체 소프트웨어 업계가 급격히 더 많은 유용한 기능을 제공하거나 품질이 눈에 띄게 향상되었다는 징후는 없음
     * 필자는 지난 1~2년 동안 LLM의 영향력을 거의 체감하지 못했음

실제로 LLM이 어떤 프로젝트를 가능하게 했는가?

     * LLM의 성능 덕분에 활성화된 프로젝트가 무엇인지 명확히 확인되지 않음
     * 연구 결과에서도 구체적인 사례는 거의 발견되지 않음 (COBOL 리팩터링 정도가 유일한 예)
     * AGI 연구소의 LLM 기반 제품도 특별히 인상적인 성과를 보이지 않음
          + 대화 상자에서 PDF 업로드와 같은 기본적인 기능 제공 수준
          + LLM이 다양한 소프트웨어 및 데이터 유형에 원활히 인터페이스하도록 하는 기능은 부족함

질문: 실제로 생산성이 증가한 분야가 있는가?

     * 어떤 프로젝트가 LLM 덕분에 빠르게 출시되었는지에 대한 명확한 증거가 없음
     * 소프트웨어 생태계에서 특정 분야가 10배 성장한 흔적이 보이지 않음

원하는 것은 명확한 실질적 증거

     * 아래와 같은 유형의 정보는 불필요함
          + 생산성 10배 향상에 대한 모호한 주장
          + 추상적인 경제 지표나 코드 생산량 증가에 대한 언급
          + 단순한 LLM 기반 도구나 기능 생성 사례
          + ""ChatGPT로 Snake 클론 만들기"" 같은 사소한 예제

음모론: LLM이 실제 생산성을 증가시키지 못하고 있을 가능성

     * LLM이 생성한 코드 수정 및 문제 해결에 오히려 시간이 소모됨
     * LLM이 생성한 대규모 코드베이스가 일정 복잡성을 넘어서면 수정이 불가능해져 결국 처음부터 다시 작성해야 하는 경우 발생
     * LLM이 새로운 소프트웨어를 만들더라도 대부분 일회성 도구나 사용되지 않는 증명용 코드에 그칠 가능성 높음
     * 실제 유용한 소프트웨어에서 코드 양이 늘어나더라도 불필요한 기능이나 블로트웨어(bloatware)가 증가할 위험 있음
     * 프로그래머들이 LLM을 통해 즉각적인 결과를 얻는 '마법' 같은 경험에 속고 있을 가능성 존재

현실적인 생산성 향상 범위

     * 필자가 경험한 바에 따르면 LLM은 다음과 같은 특정 경우에만 유용함
          + 사소한 기능 작성
          + 특정 라이브러리나 코드베이스 학습 보조
          + 간단한 리팩터링 작업 수행
     * 생산성 향상 폭은 대략 10~30% 수준일 가능성이 높음
     * 생산성 극대화는 AGI(인공 일반 지능)가 등장하기 전까지는 어려울 것으로 보임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

[Richard Horvath의 댓글]

  특정 상황에서 LLM이 10배 속도 향상을 제공할 수 있는 경우

     * 작은 독립형 스크립트 작성
          + 간단한 작업(예: 파일 조작을 위한 bash 스크립트, Excel VBA 코드) 작성 시 큰 성과를 보임
          + 짧은 설명만으로 쉽게 작성 가능하며 검증도 용이함
          + 언어에 대한 깊은 지식이 없어도 작성 가능함
          + 유지보수, 모듈화, 유닛 테스트 등을 고려할 필요가 없음
          + 특히 정규식(regex)과 관련된 작업에서 매우 효과적임
     * 낯선 스택에서 작업할 때 학습 속도 향상
          + 새로운 라이브러리의 클래스 및 메서드를 빠르게 파악 가능
          + 코드가 완전히 작동하지 않더라도 문제 해결 접근법을 제공함
          + 기존에 문서나 강의를 찾아보는 데 걸리던 시간을 대폭 단축시킴
          + 그러나 생성된 코드는 직접 수정 및 리팩토링이 필요함

10배 생산성 증가를 보고하는 사람들의 유형은 다음과 같은 경우에 해당할 가능성이 높음

     * 개발 지식이 낮은 경우
          + 기초적인 코딩 능력이 부족한 경우, LLM의 도움으로 작성된 코드가 이전보다 월등히 나아 보일 수 있음
          + 그러나 이런 경우 LLM 코드가 장기적으로 부정적인 영향을 미칠 가능성이 높음
     * 작고 독립적인 솔루션을 많이 작성해야 하는 경우
          + 엑셀 자동화 작업이나 DevOps에서의 쉘 스크립트 작성 등은 LLM이 특히 유용함
     * 다양한 스택과 라이브러리를 자주 실험해야 하는 경우
          + 장기적으로 특정 스택에서 작업하는 경우보다 실험 위주의 작업이 주를 이루는 경우에 해당
     * 앵커링 효과(Anchoring Effect) 발생
          + LLM이 특정 작업에서 즉각적인 성과를 내자 이를 장기적인 생산성 향상으로 과대평가할 가능성이 높음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

[Davidmanheim의 댓글]

     * 일반적인 회사에서 코딩하는 사람들과 경영진의 관점에서 LLM의 생산성 향상이 실제로는 제한적일 수밖에 없음
     * 이는 제약 이론(Theory of Constraints) 의 관점에서 설명됨:
          + 이전에는 다음과 같은 작업 프로세스를 통해 작업이 완료되었다고 가정:
               o 비즈니스 애널리스트(Business Analyst) → 하루 소요
               o QA 테스터 → 하루 소요
               o 프로그래머 → 하루 소요
          + 프로그래머의 생산성이 2배 또는 5배로 증가하더라도 전체 작업 시간이 단축되지 않음
               o 다른 단계(비즈니스 분석 및 QA)가 병목이 되기 때문에 전체 프로세스의 속도는 그대로 유지됨
     * 기업 프로세스 재구성이 필요함
          + LLM의 생산성 향상을 최대한 활용하려면 기업의 전체 프로세스를 재구성해야 함
          + 그러나 현재 일부 기업에서만 이와 같은 프로세스 재구성이 시작되고 있는 상황임
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

[faul_sname의 댓글]

     * LLM으로 특히 UI 목업 생성에서 다음과 같은 성과를 경험했음:
          + 이전에는 UI 목업 생성이 전체 작업 시간의 약 10%를 차지했음
          + LLM 덕분에 UI 목업 생성 속도가 약 5배 빨라짐
          + 그러나 작업 시간 자체가 줄어든 것은 아님
               o 대신 UI 목업의 디테일과 상호작용성이 크게 향상됨
               o 더 많은 반복 작업이 가능해져 결과적으로 제품의 품질이 개선됨
     * ""버려질 코드""가 반드시 쓸모없다는 의미는 아님
          + 프로토타입이나 증명용 코드라도 더 나은 최종 제품 개발에 기여할 수 있음
     * 또한 LLM은 검색 엔진으로 찾기 어려운 특정 오류에 대한 답변을 제공함
          + 예시: ""xyz 스택에서 실행 중인 작업에서 발생한 오류 해결 방법""
          + 구체적인 스택 및 Kubernetes 설정 상황에서 디버깅을 도와줌
     * 전체 생산성 증가율은 약 10~30% 수준으로 평가함
          + 그러나 모든 작업에서 고르게 생산성이 향상된 것은 아님
          + 특정 작업에서 획기적인 속도 향상 (예: UI 목업, 디버깅 등)
          + 복잡하거나 레거시 코드 작업에서는 별다른 성과 없음
          + 프로젝트 초기에 생산성 향상이 두드러지며, 복잡한 유지보수 단계에서는 효과 감소
     * 따라서 여기서의 한계는 에이전시(Agency) 부족이 아니라 문맥 관리(Context Management) 문제라고 봄
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

[Noosphere89의 댓글]

     * Ajeya Cotra의 견해를 인용하며 LLM의 프로그래머 생산성 향상 효과에 대해 다음과 같은 요점을 언급함:
          + 코딩 작업에서 AI의 생산성은 예상보다 높음
               o AI는 코딩 작업에서 상당한 성과를 내고 있음
               o 그러나 코딩 외 작업에서는 성능이 크게 떨어짐
               o 따라서 AI의 전체적인 산업적 영향은 아직 제한적임
     * Ajeya Cotra의 관련 발언 링크
          + 트윗 링크 1
          + 트윗 링크 2
     * ""장기적인 성과를 내려면 AGI가 필요하다""는 주장에 대해서는
          + 현재 AI의 발전 경로에는 일반적인 능력(Generality)이 예상보다 적음
          + AI의 성능이 특정 작업에서 급격히 향상되거나, 특정 영역에서 약점이 나타나는 경우가 많음
          + 이러한 성능의 불균형 때문에 AGI(인공 일반 지능)라는 개념이 예상보다 덜 유용할 수 있음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

[yo-cuddles의 댓글]

     * 내 사무실에서 로봇 프로세스 자동화(RPA) 를 하는 사람의 예
          + 그는 자신이 훨씬 더 생산적이라고 강하게 주장함
          + 그러나 실제로는 비효율적이고 신뢰성이 떨어져 다른 사람들이 그의 작업을 수정하느라 시간 낭비 발생
          + 동료들은 그를 워크플로에서 배제하려고 함
     * 사람들은 자신의 생산성을 제대로 측정하지 못하고, 특정한 성과나 손실만 잘 인식함:
          + 눈에 띄는 성과에 집중
               o 자동화된 방법으로 작업을 빠르게 완료하면 즉각적인 성취감이 큼
               o 빠른 성과는 즉각적으로 눈에 보이기 때문에 긍정적인 효과로 인식됨
          + 장기적인 비용은 인식하기 어려움
               o 작업 이후 발생한 시간 비용은 쉽게 추적되지 않음
               o 특히 문제가 다른 사람이 수정한 경우, 그 비용은 잘 보이지 않음
               o 자동화된 작업에서 발생한 오류가 수정되더라도 그로 인한 시간 낭비는 느끼기 어려움
     * LLM 코드가 발생시키는 문제는 다음과 같은 이유로 인식하기 어려움:
          + 버그 발생 시 원인이 LLM 코드임을 정확히 추적하기 어려움
          + 문제를 수정하는 과정에서 다른 사람이 추가로 시간을 낭비할 수 있음
          + 문제 발생의 근본 원인을 인지하지 못하고, 자신이 자동화 도구를 사용한 탓임을 깨닫지 못함
          + ""자동화 덕분에 빨리 끝냈다""는 성취감은 크지만, ""자동화 때문에 낭비된 시간""은 체감하기 어려움
     * LLM 사용이 보편화되었음에도 불구하고 산업 전반의 생산성 증가가 명확하게 보이지 않음
          + 사람들이 ""2배 더 생산적""이라고 주장하지만, 실제로는 숨겨진 문제로 인해 오히려 생산성이 저하되었을 가능성 높음
          + 즉, 문제 해결에 소모된 시간과 자원이 눈에 보이지 않아 과장된 성과 인식 발생

   저의 체험과 비슷한 느낌이네요.
     * 간단하지만 외우기는 힘든 코드들(파일 입출력 처리, 컨테이너 다루기 등)을 작성할 때
     * 컴파일, 런타임 오류가 생겼을 때 이게 어떤 에러고 어느 코드가 원인인지
     * 이미 작성해둔 함수와 비슷하지만 조금 다른 기능을 넣은 함수를 재작성 하고 싶을 때
     * 어떤 라이브러리에 의존하고 있는 코드를 다른 라이브러리로 교체하거나 자체 함수로 대체하고 싶을때
     * 특정 기능을 구현하거나, 특정 환경에서 작업해야 할때 어떤 식으로 개발하면 될 지 가이드가 필요할 때

   위와 같은 케이스에선 꽤 많은 시간이 단축되었습니다. 구글+스택오버플로우 조합으로는 잘 안 찾아지는 경우도 많고, 특히 스택오버플로우에선 어떤 답변이 있으면 댓글로 이의도 항상 많이 제기되고 옛날 버전의 구현방식이라 쓰면 안된다던지 그런 문제들이 있어서 짜증나는 경우가 참 많았는데...

   10x 생산성은 프로토타이핑할때 나오는거 같습니다

   저는 달달하네요.

        Hacker News 의견

     * 시애틀의 인기 있는 기술 회사에서 일하고 있으며, AI 사용이 강요되고 있음. 리더십이 개발자들이 AI를 얼마나 사용하는지 추적하고 있으며, 개인적으로 AI를 더 많이 사용하지 않는 이유를 묻기도 했음. 적절한 도구를 적절한 작업에 사용하는 것이 중요하다고 믿고 있으며, AI가 항상 적합한 것은 아님
          + 많은 수석 이사와 SVP들이 10년 이상 전에 코드를 작성했으며, 간단한 프로젝트를 시작하는 방법을 모름. AI가 그들에게 잃어버린 무언가를 되찾아 주었지만, 전문가에게는 도움이 되지 않음
          + AI는 취미로 정원을 가꾸는 사람에게는 도움이 되지만, 농부에게는 수확량을 늘리는 데 도움이 되지 않음
     * 소프트웨어 프로젝트의 마지막 10%가 90%의 시간을 차지한다는 오래된 격언이 있음. AI는 처음 90%에서는 유용하지만, 마지막 10%에서는 도움이 되지 않음
          + AI 사용이 신중하지 않으면 복잡한 코드로 인해 AI가 도움이 되지 않는 상황에 빠지기 쉬움
          + 소프트웨어 생산성의 폭발적인 증가가 보이지 않는 이유 중 하나일 수 있음
     * FAANG에서 LLM을 IDE에 통합하여 사용하고 있으며, 약간의 긍정적인 효과가 있음
          + IDE 내 생산성이 약간 향상되었으며, 반복적인 작업을 자동완성할 수 있음
          + 그러나 LLM이 그럴듯한 결과를 생성하여 생산성 향상을 저해하기도 함
          + 직접적으로 기능을 생성하도록 요청하면 더 나은 결과를 얻을 수 있을 것 같음
     * 실제로 10배의 개선을 경험한 개발자의 예로 Pieter Levels가 3D 멀티플레이어 비행 시뮬레이터를 며칠 만에 코딩한 사례가 있음
          + 간단한 작업에서 시간을 절약할 수 있지만, 복잡한 작업에서는 도움이 되지 않음
     * LLM을 사용하여 코드 생성을 시도했으나, 처음에는 생산성이 떨어졌음
          + 최근에는 Claude Code를 사용하여 생산성이 크게 향상되었으며, 페어 프로그래밍 스타일로 작업하고 있음
          + 비개발자가 고품질의 출력을 생성할 가능성은 낮다고 생각함
     * GitHub에서 Copilot Autofix를 개발하는 팀의 일원으로, CodeQL 경고를 기반으로 수정 제안을 제공함
          + 실제 개발자와의 상호작용 데이터를 기반으로 평균 3배, 최대 12배의 속도 향상을 보임
     * LLM 코딩 도우미의 답변 품질은 프로그래머의 의사소통 능력에 크게 영향을 받음
          + 주니어 개발자들이 질문을 명확하게 하지 못해 잘못된 답변을 받는 경우가 많음
          + 시니어 프로그래머의 능력이 크게 향상되는 경우를 보았으며, 주니어나 중급 개발자가 LLM 코딩 도우미가 쓸모없다고 불평할 때는 그들의 의사소통 능력에 문제가 있을 가능성이 높음
     * 소프트웨어의 생산성이 5-10배 향상되지 않았다는 가정은 잘못된 것일 수 있음
          + 대안으로는 회사가 더 적은 엔지니어를 필요로 하여 해고를 하거나, 비용을 줄여 소프트웨어 제품이 더 저렴해지는 경우가 있음
          + 개인적으로는 간단한 스크립트를 작성하여 하루에 조금 더 많은 일을 할 수 있게 되었지만, 5배 더 많은 일을 할 수 있는 것은 아님

   Hacker News 의견 요약 번역 마지막 항목인 '소프트웨어의 생산성이 5-10배 향상되지 않았다는 가정은 잘못된 것일 수 있음'은 오역인 듯 합니다. 원문을 보면 '소프트웨어의 생산성이 5-10배 향상되었다고 하는 건 생산성 향상에 대한 잘못된 가정에 기반한 것임' 정도가 더 무난한 요약일 듯 싶네요.

     대부분의 프로그래머는 LLM 도구를 효과적으로 사용하는 방법을 모르거나 관심이 없음

   주변의 많은 개발자들이 의외로 기술에 관심이 없음. 그들은 새로운 혹은 반복되는 유튜브 쇼츠를 기계적으로 탐미하는데 대부분의 시간을 할애하고 있음.
"
"https://news.hada.io/topic?id=19642","Globstar - 오픈소스 정적 분석 툴킷","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Globstar - 오픈소스 정적 분석 툴킷

     * 개발자 및 보안 엔지니어가 코드 분석 체크(Checker)를 작성하고, 단일 바이너리로 실행가능한 오픈소스 정적 분석 툴킷
     * 트리시터(Tree-Sitter) 기반의 강력한 AST(추상 구문 트리) 분석을 활용하며, 직관적인 YAML 또는 Go 인터페이스를 통해 체크를 작성 가능
          + 복잡한 DSL 없이 S-표현식(S-expressions) 으로 체크 작성 가능
     * Go로 개발되어 대규모 코드베이스에서도 빠르게 동작
     * CI/CD 친화적 : 추가 설치 없이 단일 바이너리로 실행 가능
     * MIT 라이선스**로 배포되어 상업적 사용 및 수정 가능
"
"https://news.hada.io/topic?id=19709","코드 가독성을 떨어뜨리는 시각적 복잡성 패턴 (2023)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    코드 가독성을 떨어뜨리는 시각적 복잡성 패턴 (2023)

     * 최근 코드베이스를 검토하면서 코드의 품질에도 불구하고 정신적으로 피로해지는 경험을 함
          + 이는 코드의 복잡성보다는 가독성과 관련이 있었음
     * 코드의 가독성을 높이기 위한 8가지 패턴을 도출

  코드 가독성 메트릭 및 대체 복잡성 메트릭

     * 코드 가독성을 측정하는 보편적이고 널리 사용되는 메트릭은 존재하지 않음
     * 현실에서 사용되지 않는 학술 논문이나 개인적인 의견만 존재함
     * 새로운 메트릭을 만들기보다는 누구나 쉽게 논의할 수 있는 시각적 패턴에 집중
     * 복잡성 메트릭에서 중요한 조건:
          + 소스 코드 스니펫이나 개별 함수에서 작동해야 함
          + 알고리즘 복잡성 대신 코드 작성 방식에 초점
          + 스타일 요소(변수명, 공백, 들여쓰기 등)에는 초점 두지 않음

  Halstead 복잡성 메트릭

     * 1970년대 Maurice Halstead가 개발한 코드 복잡성 메트릭
     * 언어와 플랫폼에 상관없이 코드 작성 방식을 수치화 가능
     * 연산자와 피연산자 수를 기반으로 프로그램의 길이, 볼륨, 난이도를 계산
     * 주요 측정값:
          + 고유 연산자 수 (n1)
          + 고유 피연산자 수 (n2)
          + 전체 연산자 수 (N1)
          + 전체 피연산자 수 (N2)
     * 더 많은 연산자와 피연산자가 사용될수록 코드의 복잡성 증가
     * 모든 언어에서 연산자 및 피연산자의 정의가 명확하지 않아 일관된 도구 사용이 중요

    Halstead 복잡성에서 얻은 인사이트

     * 짧고 변수 수가 적은 함수가 가독성이 높음
     * 언어별 연산자나 구문 설탕(syntactic sugar) 사용은 최소화
     * 함수형 프로그래밍의 체인 사용(map/reduce/filter 등)은 너무 길어지면 가독성이 떨어짐

  인지 복잡성 (Cognitive Complexity)

     * SonarSource에서 개발한 복잡성 메트릭
     * 코드 읽기 어려움을 보다 정확하게 측정하기 위한 시도
     * 세 가지 주요 원칙:
         1. 단축 구문(shorthand constructs)이 읽기 난이도를 줄임
         2. 비선형 흐름의 단절이 난이도를 증가시킴
         3. 중첩된 제어 흐름이 난이도를 증가시킴

    인지 복잡성에서 얻은 인사이트

     * 단축 구문은 간결하지만 잠재적 버그 위험 존재
     * 조건문 및 논리 연산자는 과도하게 사용하면 가독성이 떨어짐
     * 예외 처리는 코드 복잡성을 높이는 주요 원인
     * goto는 일반적으로 피해야 하지만 특정 상황에서는 유용할 수 있음
     * 중첩된 제어 구조는 가능하면 줄이는 것이 좋음

  함수의 모양, 패턴 및 변수

     * 함수의 시각적 ""모양""은 코드 가독성에 중요한 역할 수행
     * 가독성을 높이는 세 가지 원칙:
         1. 명확하고 구체적인 변수명 사용
          + 변수 중복(Shadowing) 피하기
          + 시각적으로 구별 가능한 이름 사용 (i, j와 같은 유사 이름 피하기)
         2. 변수의 수명(liveness) 단축
          + 변수의 사용 범위는 짧을수록 좋음
          + 함수 경계를 넘어서 오래 유지되는 변수는 복잡성 증가
         3. 익숙한 코드 패턴 재사용
          + 일관된 코드 패턴을 유지하면 가독성 향상
          + 새로운 접근 방식보다 기존에 익숙한 패턴을 우선 사용

  코드 가독성을 향상시키는 8가지 패턴

    1. 라인/연산자/피연산자 수 감소 – 작은 함수와 적은 변수 사용이 가독성 향상
    2. 새로운 접근 방식 회피 – 코드베이스에서 익숙한 패턴을 유지
    3. 그룹화 – 긴 함수 체인, 반복자 등은 보조 함수로 분리
    4. 조건문의 단순화 – 조건문은 짧게 유지하고 논리 연산자 혼합 최소화
    5. goto 최소화 – 필요할 경우 에러 처리에서만 제한적으로 사용
    6. 중첩 최소화 – 중첩된 로직은 줄이고, 필요하면 함수로 분리
    7. 명확한 변수 이름 사용 – 구체적이고 중복되지 않는 변수명 사용
    8. 변수의 수명 단축 – 함수 내에서 짧게 유지하고 함수 경계를 넘지 않도록 함

  결론

     * 코드 가독성은 코드 품질에 중요한 요소
     * Halstead 및 Cognitive Complexity는 가독성 문제를 수치화하고 개선 방향 제시 가능
     * 간결하고 명확한 코드를 작성하면 코드 유지 보수가 쉬워지고 버그 발생 가능성 감소
     * 최적의 코드 작성은 단순함, 일관성, 명확성을 우선시하는 것임

        Hacker News 의견

     * map, reduce, filter와 같은 함수형 프로그래밍 구조를 연결하는 것은 간결하지만, 긴 체인은 가독성을 해치는 경향이 있음
          + 이는 기사에서 암시된 바가 아님
          + 익숙하지 않아서 나쁘다고 생각하는 일반적인 불평처럼 느껴짐
          + 조금만 익숙해지면 다른 방법보다 읽고 쓰기 쉬움
          + 함수형 프로그래밍의 기본을 배우는 것이 중요함
          + Monad를 설명할 필요는 없지만, map과 filter를 무작위로 비난하지 않을 정도로 익숙해져야 함
     * 좋은 코드의 중요한 측면은 질적이고 문학적임
          + 수학적 사고방식을 가진 프로그래머와 학자들에게는 불편할 수 있음
          + 도스토옙스키와 우드하우스를 좋아하지만, 그들의 글은 매우 다름
          + 코드베이스의 스타일을 이해하는 데 시간이 걸림
     * 코드 읽을 때 가장 피로한 문제는 가변성임
          + 변수를 한 번만 ""고정""할 수 있는 능력은 큰 선물임
          + 메서드를 이해하는 과정은 0%에서 100%로 단조롭게 증가해야 함
          + GOTOs가 해로운 이유는 가변 변수의 상태를 알기 어려워서임
     * 작은 함수와 적은 변수는 일반적으로 읽기 쉬움
          + ""가독성""에 대한 초점이 미세 가독성에 치우쳐 있음
          + 이는 코드가 지나치게 분열되게 만듦
          + APL 계열 언어는 반대 극단에 있음
     * TypeScript는 코드 읽기 어렵게 만듦
          + 데이터 모델이 ""원자적""으로 유지되면 괜찮음
          + 타입 유추에 의존하면 필드를 원래 위치로 추적하기 어려움
     * getOddness4 함수는 비대칭성을 줌
          + getOddness2 함수는 대칭적 선택을 제공함
     * 기사는 흥미롭지만 만족스럽지 않음
          + 언어 특정 연산자나 구문 설탕 사용을 피하라는 의견에 동의하지 않음
          + map, reduce, filter 같은 구조는 잘 사용하면 다른 연산자를 대체하고 ""볼륨""을 줄임
     * 가독성을 정의하려는 시도는 칭찬할 만함
          + 많은 사람들에게 테스트를 통해 가독성의 실제 차원을 찾을 수 있을 것임
     * 코드 복잡성은 구문 트리의 크기로 표현됨
          + 지역적 복잡성 감소가 전체 복잡성에 큰 영향을 주지 않음
     * 긴 함수 체인이나 콜백은 작은 그룹으로 나누고 잘 명명된 변수를 사용하는 것이 좋음
          + 두 버전 모두 효율성 면에서 동일함
          + 차이는 컴파일러에 있음
"
"https://news.hada.io/topic?id=19627","연령 확인 법률: 감시로의 백도어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           연령 확인 법률: 감시로의 백도어

     * 나이가 들면서, 나이 확인 법안이 '아이들을 포르노로부터 구한다'는 명목으로 제안되었던 시절을 기억함. 이러한 법안들은 잘못된 의도로 시작되었으며, 결국 디지털 자유를 위협하는 감시 체계로 변질됨.

나이 확인 법안: 감시의 뒷문

     * 나이 확인 법안은 단순히 아이들을 보호하는 것이 아니라, 모든 사용자로부터 방대한 개인 정보를 수집하는 시스템을 요구함. 이는 인터넷을 더 안전하게 만드는 것이 아니라, 모든 사용자가 기본적인 콘텐츠나 제품에 접근하기 위해 신원을 확인해야 하는 상황을 만듦.
     * 이러한 법안은 감시 체계로 위장된 안전 조치로 시작되었으며, 이는 점점 더 많은 주에서 법안으로 제출되고 있음.
     * 스킨케어: 캘리포니아의 AB-728 법안은 특정 화학물질이 포함된 스킨케어 제품 구매 시 나이 확인을 요구함. 이는 무해해 보일 수 있지만, 실제로는 민감한 개인 데이터를 수집하여 추적 및 데이터 수집 시스템을 만듦.
     * 데이트 앱: 뉴욕의 A3323 법안은 온라인 데이팅 서비스가 사용자 나이, 신원, 위치를 확인하도록 요구함. 이는 사용자로부터 민감한 개인 정보를 요구하여 프라이버시 문제를 야기함.
     * 다이어트 제품: 워싱턴 주의 SB 5622 법안은 다이어트 약품 및 보조제 판매를 18세 미만에게 제한함. 이는 나이 확인 과정에서의 프라이버시 위험을 간과함.

나이 확인의 문제점: 안전한 해결책은 없음

     * 나이 확인 방법 중 프라이버시를 보호하면서도 완전히 정확한 방법은 없음. 모든 나이 확인 방법은 각각의 위험성을 가지고 있으며, 성인들이 인터넷을 탐색하거나 일상적인 물품을 구매할 때 대량의 데이터 수집에 노출됨.
     * 정부 발급 신분증이나 얼굴 스캔을 요구하는 시스템은 민감한 생체 데이터나 개인 데이터를 수집하여 프라이버시와 보안을 위협함. 이러한 데이터는 오용될 가능성이 높으며, 이미 해킹된 사례도 있음.
     * 나이 확인 법안이 감시 체계를 만들고 시민의 자유를 침해하는 것을 막아야 함. 아이들을 보호하려는 의도는 이해되지만, 결과적으로 프라이버시, 보안, 표현의 자유를 침해함.
     * EFF는 디지털 프라이버시, 보안, 표현의 자유를 옹호할 것이며, 입법자들이 이러한 가치를 지키는 해결책을 우선시하도록 촉구함. 인터넷이 학습, 연결, 창작의 공간으로 남아있도록 해야 함.

        Hacker News 의견

     * 인터넷은 기본적으로 등급이 없어야 하며, 성인 전용이어야 함. 이는 공공장소와 같음. (8살 아이가 뉴욕 시를 혼자 돌아다니게 허용할 것인가? 더 통제된 공간에 대한 논의는 가능하지만...)
          + 웹사이트를 운영하고 아이들이 볼 수 있게 하고 싶다면, 헤더에 해당 사이트가 등급이 매겨져 있고 관리된다는 것을 광고해야 함. 다양한 인덱서가 이를 수집할 수 있음
          + 불만 사항은 관련 정부 기관에 전달할 수 있음 (예: 미국 기반 웹사이트의 경우 FTC, 허위 광고), 또는 다른 범죄에 대해서는 다른 기관에 전달 가능
          + 부모는 컴퓨터 계정을 아동 계정으로 표시하고 브라우저를 부모나 현재 보호자(예: 학교)가 선택한 필터링 규칙 목록을 따르도록 구성할 수 있음
          + 다시 말해, 인터넷은 등급이 없는 자유 구역 == 아동 모드는 허용 목록 필터링된 콘텐츠임
     * 캘리포니아의 AB-728 법안은 특정 화학물질(예: 비타민 A 또는 알파 하이드록시산)을 포함한 스킨케어 제품이나 화장품을 구매할 때 연령 확인을 의무화함. 표면적으로는 무해해 보일 수 있음—미성년자를 유해한 화학물질로부터 보호하고 싶지 않은 사람이 있을까?
          + 왜 미성년자를 ""유해한 화학물질""로부터 보호하고 싶어하면서 성인은 그렇지 않은가? 비타민 A나 알파 하이드록시산이 포함된 스킨크림 제품이 유해하다면, 그리고 나는 그것들이 합리적인 농도에서 유해하다고 전혀 확신하지 않음, 그냥 없애버리면 됨
     * ""미끄러운 경사""가 본질적으로 오류가 아니라는 것을 보여주는 생생한 예로 삼아야 함. 많은 사람들이 주장하는 것처럼: 이는 원인이 분리될 때 오류로 이어질 수 있는 논증의 한 형태일 뿐임. 사람들은 그것에 대해 지나치게 경계하게 되었고, 아이디어를 무시하기 전에 경사가 얼마나 가파른지 분석하지 않고 결론의 전제에 반응함
     * Verifiable Credentials[0] 같은 기술이 이러한 법률로 인해 채택될 가능성이 있는지 궁금함. ""어떤 제3자 권위가 나를 대신해 보증할 수 있다""라고 말하고 싶을 때 합법적인 사용 사례가 있다고 생각함. 그리고 검증을 요청하는 제3자에게 누가 요청하는지 밝히지 않고, 검증을 요구하는 당사자에게 필요한 특정 주장 외에는 다른 주장을 밝히지 않음 (이 경우 나이)
          + [0] https://en.wikipedia.org/wiki/Verifiable_credentials
     * 미성년자가 구매해서는 안 되는 제품을 구매하는 문제를 해결할 수 있는지 궁금함. 판매자가 신용카드로만 결제를 받도록 하고, 배송 주소가 신용카드 계정 주소와 일치할 때만 판매를 완료하도록 요구할 수 있음
          + 아이가 성인의 카드를 빌릴 수 있지만, 그러면 물품은 그 성인의 주소로 배송되므로 아이가 성인이 알아차리지 않고 물품을 받기 어려울 수 있음. 구매는 다음 신용카드 명세서에 표시되어 아이가 성인의 신용카드를 몰래 사용하고 있는지 성인이 알아차릴 가능성을 높임
          + 신용카드 명세서에 그 달에 연령 제한 제품이 구매되었다는 주석을 눈에 띄게 요구할 수도 있음
          + 모든 구매를 막을 수는 없지만, 이를 더 어렵게 만들고 부모가 이를 알아차리기 쉽게 만들어야 함
     * 우리 주에서 발급한 eID 카드는 신뢰할 수 있는 당사자에게 익명으로 나이를 확인할 수 있는 기능을 갖추고 있음. 작동 방식은 다음과 같음: 요청 당사자가 주에서 발급한 인증서로 서명된 요청을 ID 카드에 보내면, 카드는 요청의 진위를 확인하고 법적 연령 확인 서명으로 응답함. 그런 다음 요청자가 서명을 확인할 수 있음
          + 개인 정보는 공유되지 않음
          + 광범위한 연령 제한에 동의하지 않지만, 이는 프라이버시를 보호하는 연령 확인에 대한 좋은 기술적 해결책임
     * 누가 이것을 예측할 수 있었을까? 만약 신뢰할 수 있는 글로벌 신원 서비스를 제공할 준비가 된 자비로운 기업 신이 있었다면
          + 만약 이것이 갑자기 나오지 않았다면, 지금쯤 누군가가 인터넷 전반에 걸쳐 당신의 신원이 함께 이동할 수 있도록 할 수 있었을지도 모름. 보이지 않는 디지털 지문과 여권이 있어 사람들이 계속해서 자신을 증명할 필요가 없도록 할 수 있었을지도 모름
          + 문제를 찾는 해결책이었을지도 모름
     * 연령 확인을 지지하지 않음 (그것이 아무것도 해결하지 않을 것이라고 생각함). 두 가지 대상 제품 카테고리, 스킨케어와 다이어트 식품/보충제는 요즘 내가 보는 가장 많은 광고 지출 카테고리 중 하나이며, 매우 사기꾼처럼 느껴짐
     * 연령 확인은 웹사이트가 아니라 브라우저에 내장되어야 함
          + 부모는 모든 브라우저에서 특정 유형의 웹사이트(예: 포르노)를 제외할 수 있는 (비밀번호로 보호된) 설정에 접근할 수 있어야 함
          + 정부는 해당 설정을 준수하지 않는 웹사이트를 자유롭게 추적할 수 있어야 함
          + 그러나 웹사이트에 연령 확인을 강요하는 것은 어리석음
     * 저자는 신원 기반 인증(익명 자격 증명)을 위한 영지식 범위 증명의 존재를 인식하지 못하는 것처럼 들림. 본질적으로 그들은 다음과 같이 작동함: 제3자가 서명된 약속으로 출생 연도를 약속함. 그런 다음 서비스 제공자에게 연령 제한이 준수되도록 범위 증명과 함께 보여줄 수 있음. 이렇게 하면 서비스 제공자는 사용자의 연도를 알지 못하면서도 모든 회원이 필요한 연령 제한을 준수하도록 할 수 있음
"
"https://news.hada.io/topic?id=19682","음악 레이블의 Internet Archive 소송, 후회할 것이라는 음향 역사학자 주장","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            음악 레이블의 Internet Archive 소송, 후회할 것이라는 음향 역사학자 주장

     * 음악 레이블이 Internet Archive(IA)의 Great 78 Project를 상대로 한 소송에 약 500개의 추가 음원 기록을 포함하도록 수정 고소장을 제출함
     * Great 78 Project는 1898년부터 1950년대까지 제작된 78 RPM 음반의 300만 개 녹음을 디지털화하는 프로젝트임
     * 추가 음원이 소송에 포함되면 전체 대상 음원은 4,624개가 되며, 패소 시 음반당 최대 15만 달러 배상금이 발생할 수 있음
     * 초기 소송에서 레이블은 약 4억 달러의 손해배상을 청구했으나, 이번 추가로 배상액이 약 7억 달러까지 증가할 가능성 있음
     * IA는 Ars Technica의 논평 요청에 응답하지 않았으며, IA가 수정 고소장 제출에 동의하지 않았다는 점이 명시됨

보존인가? 불법 복제인가?

     * 레이블은 새로운 고소장에서 IA가 저작권 침해를 계속하고 있다고 주장
     * IA는 Great 78 Project가 저작권법에 따른 '공정 이용(fair use)'에 해당한다고 반박
     * 일부 음악 산업 관계자는 레이블이 요구하는 배상금이 터무니없다고 지적
          + Doris Day 유산 관리자인 Sam Trust는 약 41,000달러의 손해가 현실적이라고 Rolling Stone과의 인터뷰에서 언급

레이블의 주장과 반박

     * 레이블은 Great 78 Project가 Spotify나 Apple Music과 경쟁하면서 아티스트의 로열티를 훔치고 있다고 주장
     * 그러나 850명 이상의 뮤지션이 IA를 지지하며 소송 철회를 요구
     * IA 지지자들은 Great 78 Project가 희귀 음반의 보존에 중요한 역할을 한다고 주장
          + 오래된 78 RPM 음반은 물리적으로 보존하기 어려워지고 있으며, 재생 장비도 부족한 상태
     * David Seubert (캘리포니아 대학교 산타바바라 음향 컬렉션 책임자)
          + IA의 프로젝트는 단순한 음원 제공이 아니라 음반 레이블, 저작권 정보, 카탈로그 번호 등 역사적 데이터를 보존하는 데 중요함
          + 많은 사람들이 IA를 단순히 음악 감상 용도로 사용하지 않고 연구 목적으로 이용함
          + Bing Crosby의 'White Christmas'는 Spotify에서 약 5억 5천만 회 스트리밍된 반면, Great 78 Project에서는 약 15,000회 시청됨
          + IA가 음반 산업의 수익에 실질적인 영향을 주지 않는다고 주장
     * Nathan Georgitis (Association for Recorded Sound Collections, ARSC 회장)
          + 78 RPM 음반은 중고 음반 매장에서도 거의 찾기 어려운 상태
          + 상업적으로 제공되지 않는 희귀 음원은 역사적으로 소실될 위험이 큼
          + IA의 역할은 단순한 스트리밍 서비스가 아니라 장기적인 보존과 접근 제공에 있음

저작권법의 변화와 보존 문제

     * ARSC는 Music Modernization Act(음악 현대화법)에서 도서관 및 아카이브의 음원 보존 권리를 강화하기 위해 활동
     * 음악 레이블은 IA가 이 법을 위반하고 있다고 주장
     * 저작권 보호와 공익 보호 사이의 균형이 중요하다고 ARSC는 강조

Internet Archive의 가치

     * David Seubert는 IA의 Great 78 Project 외에도 Wayback Machine 등 중요한 보존 서비스 제공
     * 레이블이 IA를 법적으로 압박할 경우, 역사적 관점에서 후회할 것이라고 주장
     * Wayback Machine은 웹사이트 스냅샷 보존에 중요한 역할을 하며, 레이블도 이를 정기적으로 사용할 가능성이 높음

결론

     * IA의 Great 78 Project는 희귀 음반 보존 및 연구에 중요한 역할 수행
     * 음악 레이블의 법적 압박이 지속될 경우, IA의 역사적 가치가 위협받을 수 있음
     * 레이블의 소송이 궁극적으로 공익에 부정적 영향을 줄 가능성 존재

        Hacker News 의견

     * 그들은 역사적으로 후회할 것이라고 명확히 하며, 금전적인 것이 아니라 역사적 관점에서 그 부분을 잃는다는 의미임
     * 이 논의는 마치 메뚜기 떼가 언젠가 많은 농작물을 파괴한 것을 후회할 것이라는 주장과 같음
     * 이 스레드에는 매우 피상적인 의견들이 많으며, 대부분은 기사를 읽지 않은 사람들로부터 나옴
          + ""그들은 후회할 것이다,"" Seubert는 예측함. ""금전적이거나 그런 것이 아니라, 역사적 관점에서 인터넷 아카이브는 우리 모두에게 가치가 있음""
          + 이는 기사의 중심 포인트가 아님. 그는 ""법인 Capitol Records가 감정을 드러내고 후회할 것""이라고 말하는 것이 아니라, ""Capitol Records를 구성하는 사람들이 이 작품들에 대한 접근을 제한하는 데 기여한 역할을 후회할 것""이라고 말함
     * 레이블들은 녹음이 사라지는 것을 후회하지 않을 것임. 그들은 돈에만 관심 있는 경영진들임
     * 불운한 음향 역사가가 자신의 불만을 자신과 완전히 다른 사람들에게 투영하고 있음
     * 인터넷 아카이브는 아무것도 삭제하지 않음. 때때로 ""항목""(URL)을 남겨두고 다운로드를 차단함. 최근에는 대량으로 ""어둡게"" 처리하여 검색 결과에서 제거함
          + 합리적인 해결책은 항목을 남겨두고 전체 파일의 다운로드를 차단하며, 발췌본을 제공하는 것임
          + Archive.org은 갈림길에 있으며, 이를 관리하는 사람들이 최근 매우 궁금한 결정을 내림
     * 기관들, 특히 이익을 추구하는 기관들은 후회하지 않음. 만약 그랬다면, 인터넷 아카이브 프로젝트가 Kurt Cobain과 Amy Winehouse 같은 인물들이 없을 때 이를 유발하지 않았을 것임
     * ""인터넷 아카이브는 녹음 산업의 수익에 전혀 영향을 미치지 않음,"" Seubert는 제안함. 그의 의견은 ""아무 의미가 없다""고 하면서도, 그는 변호사가 아님
          + 그는 레이블의 소송이 ""어떤 식으로든 보복적""이라고 의심함. 왜냐하면 레이블들은 아마도 ""인터넷 아카이브의 저작권과 공정 사용에 대한 도전 방식을 좋아하지 않기 때문""임
     * 레코드 회사, 아티스트 및 기타 권리 보유자들은 ""어떤 식으로든 보복적""이거나 메시지를 보내기 위해 소송을 제기하는 것이 아님
          + 소송은 엄청나게 비싸고, 원고가 민감한 문제에 대해 공개적인 입장을 취하도록 강요하며, 그들의 운영, 커뮤니케이션 및 비즈니스 관계에 대한 세부 사항을 공개하도록 강요함
          + 그들은 IP 사용 방식에 대한 장기적인 싸움의 일환으로 이를 보고 있음
     * 이익을 추구하는 레이블들이 이익 외에 다른 것에 관심이 있다는 암시
     * 인터넷은 도서관 공유를 허용하기 위해 만들어졌으며, 이제 회사들은 한 번에 한 사람씩 책을 공유하는 유일한 도서관을 막으려고 함. 이는 유사함
          + 우리는 IA를 무너뜨리고 그들이 가지고 놀던 장난감을 잊어버릴 변덕스러운 회사들 때문에 망할 것임
          + 음악이 공공 도메인에 들어가는 나이는? 여전히 Disney의 123년인가?
     * IA가 사라지면, 다음 디지털 알렉산드리아 도서관을 소송으로부터 보호할 수 있는 방법은 무엇인가? 이를 위한 기술이 있는가?
          + IPFS를 어떤 유형의 다크넷 프로토콜 위에 사용할 수 있는가?
          + Chia 같은 것이 도움이 될 수 있는가? 그 프라이버시 특성에 대해 잘 모름
     * 손해가 발생하려면 어떤 방식으로든 손실이 발생했음을 증명해야 하지 않겠는가? 이용할 수 없는 기록이 어떻게 영향을 받을 수 있는가?
"
"https://news.hada.io/topic?id=19661","Smart-turn - 오픈소스 오디오 턴 감지 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Smart-turn - 오픈소스 오디오 턴 감지 모델

     * 턴 감지는 음성 AI 스택에서 가장 중요한 기능 중 하나로, 사람이 말할 때 음성 에이전트가 응답해야 할 타이밍을 결정하는 기술
     * 대부분의 음성 에이전트는 VAD(Voice Activity Detection) 기반으로 오디오를 음성 및 비음성 세그먼트로 구분하여 음향적, 언어적 의미는 반영되지 않음
     * 인간은 문법, 억양, 말의 속도 등 복잡한 신호를 통해 턴 감지를 수행함
          + 목표: VAD 기반 접근 방식보다 인간의 기대치에 더 가까운 모델 구축
     * 오픈 소스 기반의 커뮤니티 주도형 오디오 턴 감지 모델 개발 프로젝트
          + BSD 2-clause 라이선스 → 누구나 사용, 포크, 기여 가능
          + 프로젝트는 Pipecat 생태계에서 시작됨
          + Pipecat: 오픈 소스, 공급업체 독립형 음성 및 멀티모달 AI 프레임워크
     * 프로젝트 목표
          + 고수준 목표
               o 누구나 쉽게 사용 가능
               o 프로덕션에서 쉽게 배포 가능
               o 특정 애플리케이션에 맞춰 손쉽게 파인튜닝 가능
          + 현재 모델 한계
               o 영어만 지원
               o 상대적으로 느린 추론 속도: GPU에서 약 150ms, CPU에서 약 1500ms
               o 훈련 데이터는 주로 세그먼트 끝에서 발생하는 완성되지 않은 말(filler words) 중심
          + 중기 목표
               o 다양한 언어 지원
               o 추론 시간: GPU에서 50ms 이하, CPU에서 500ms 이하
               o 더 폭넓은 음성 뉘앙스 훈련 데이터 반영
               o 완전 합성 데이터 생성 파이프라인 구축
               o 텍스트 기반 컨디셔닝 지원 (예: 신용카드, 전화번호, 주소 입력 등)
     * 모델 아키텍처
          + Meta AI의 Wav2Vec2-BERT 백본 기반 (매개변수 수: 580M)
               o 143개 언어, 450만 시간의 비지도 학습 오디오 데이터 사용
          + 현재 모델 구조:
               o Wav2Vec2-BERT → 2-레이어 분류기(classification head)
               o Hugging Face의 Wav2Vec2BertForSequenceClassification 사용
          + 실험 진행 중인 아키텍처:
               o 단순한 분류기가 데이터 세트 확장 시에도 효과적일지 테스트 중
               o 보다 복잡한 구조 도입 가능성 검토 중

        Hacker News 의견

     * pipecat을 사용해 본 적이 있고 좋았음. 하지만 네이티브로 컴파일되고 엣지 디바이스에서 실행할 수 있는 sherpa-onnx로 전환했음
          + 구글 번역기 앱을 사용할 때 긴 문장을 말하다가 잠시 멈추거나 속도를 늦추는 경우가 많아 대화 모드를 피함
          + 이 문제는 낮은 지연 시간의 턴 감지와 음성 중단 감지, 그리고 매우 빠른 로우 레이턴시 LLM이 필요함
          + 시스템이 이전 오디오를 버리지 않고 마지막 문장을 계속할 수 있도록 하는 좋은 복구 기능이 필요함
          + i/o 지연 시간 개선을 위해 낮은 지연 시간의 오디오 API, 매우 짧은 오디오 버퍼, 전용 오디오 카테고리 및 모드 사용 필요
          + 스트리밍 모드에서 TTS를 사용할 수 있는지 확실하지 않음
          + 잘 설계된 푸시 투 톡이 좋은 해결책일 수 있음
     * 오늘 몇 가지 흥미로운 업데이트가 있었음
          + CoreML을 사용한 100ms 추론
          + 데이터의 하위 집합으로 훈련된 LSTM 모델
     * README에서 대부분의 답을 얻었음. 잘 작성되었음
     * Wav2Vec2-BERT를 미세 조정하는 데 필요한 리소스와 양을 공유할 수 있는지 궁금함
     * 턴 감지가 무엇인지 궁금함
     * 이 기술이 더 발전하는 것을 보게 되어 기쁨
          + Siri와 같은 최악의 음성 시스템부터 ChatGPT 음성 모드까지, 컴퓨터가 이 작업을 잘 수행하지 못함
          + '에이전트'가 간단하지만 유용한 작업을 수행하는 데 가장 큰 장애물일 수 있음
          + AI가 여전히 어려움을 겪는 상황이 많고, 이러한 오류는 대화의 효율성을 파괴하거나 심각한 기능 오류를 초래할 수 있음
     * HF 자폐증 진단을 받은 사람으로서 이 기술을 이어피스에 적용하고 싶음
     * 몇 가지 턴 기반 모델을 검토한 결과, 구현이 매우 일치함. 이 기술이 어떻게 발전할지 기대됨
     * Vedal이 Neuro-sama의 모델에 이 기술을 통합했으면 좋겠음. osu 봇에서 AI Vtuber로 변신한 사례
     * 여러 화자를 지원하는지 궁금함
     * 포킹 중임
"
"https://news.hada.io/topic?id=19683","Strobelight - 오픈소스 기반의 프로파일링 서비스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Strobelight - 오픈소스 기반의 프로파일링 서비스

     * Strobelight은 Meta의 프로파일링 오케스트레이터로, 여러 오픈 소스 기술을 결합해 엔지니어들이 성능과 리소스 활용을 개선하도록 지원함
          + 도입 후 약 15,000대의 서버에 해당하는 연간 용량 절감 효과 달성

Strobelight의 동작 방식

     * Strobelight은 단일 프로파일러가 아니라 여러 프로파일러를 조정하는 오케스트레이터임
     * 모든 Meta의 프로덕션 호스트에서 실행되며, 다음과 같은 성능 지표를 수집함
          + CPU 사용량
          + 메모리 할당
          + 기타 성능 메트릭
     * 엔지니어가 이를 통해 성능 병목 현상 및 리소스 낭비 문제를 파악하고 코드 최적화 가능

프로파일러의 역할 및 필요성

     * 프로파일러는 샘플링 기반의 통계 분석 도구임
     * 예: CPU 사이클 이벤트에서 함수 호출 스택과 CPU에서 함수가 실행되는 시간을 분석 가능
     * 코드 실행 상태를 상세히 파악하여 성능 개선에 기여함

Strobelight의 다양한 프로파일러

     * Strobelight에는 총 42개의 프로파일러 포함됨
          + jemalloc 기반 메모리 프로파일러
          + 함수 호출 수 프로파일러
          + Python, Java, Erlang 등 언어별 이벤트 기반 프로파일러
          + AI/GPU 프로파일러
          + 오프-CPU 시간 추적 프로파일러
          + 서비스 요청 지연 시간 추적 프로파일러
     * 프로파일링 도구는 명령줄 도구나 웹 UI에서 실행 가능
     * 연속 프로파일링 및 특정 조건 발생 시 트리거 기반 프로파일링 설정 가능

Ad-hoc 프로파일러 지원

     * 엔지니어가 새 프로파일러를 추가하려면 여러 코드 수정 및 배포 필요
     * bpftrace 스크립트를 작성해 빠르게 프로파일러 추가 가능
     * 엔지니어가 특정 함수의 성능 문제를 신속히 추적 및 분석 가능

프로파일러 간 충돌 방지

     * Strobelight은 프로파일러 간 자원 충돌 방지 시스템 내장
     * CPU 사이클 추적 중 다른 PMU 카운터 사용 금지 등 규칙 적용
     * 동시 실행 및 대기열 관리 시스템 통해 리소스 충돌 최소화

자동 프로파일링 및 동적 샘플링

     * Strobelight는 모든 Meta 서비스에서 자동으로 프로파일링 실행
     * 각 서비스별 작업 부하에 따라 샘플링 빈도 및 기간 자동 조정
     * 샘플링 확률 및 수집 빈도 자동 보정하여 일관된 데이터 제공

성능 최적화 및 용량 절감 사례

  LBR 프로파일러

     * Intel의 하드웨어 기능인 Last Branch Record (LBR) 샘플링 지원
     * FDO (Feedback Directed Optimization) 에서 사용되어 바이너리 성능 향상
     * Meta의 상위 200개 서비스에서 CPU 사이클 사용량 최대 20% 절감 효과

  이벤트 프로파일러

     * Linux의 perf 도구와 유사한 기능 수행
     * 성능 이벤트 (CPU 사이클, L3 캐시 미스 등) 샘플링 및 시각화
     * 코드 경로에서 발생하는 문제를 사전에 감지 및 수정 가능

Stack Schemas 및 Strobemeta

  Stack Schemas

     * 함수 호출 스택에 태그 추가해 가시성 향상
     * 필터링 및 시각화에서 불필요한 함수 제거 가능

  Strobemeta

     * 런타임에서 동적 메타데이터를 호출 스택에 추가
     * 서비스 엔드포인트, 지연 시간 등과 관련된 세부 정보 제공

심볼화 처리 (Symbolization)

     * 바이너리의 가상 주소를 함수 이름 및 소스 코드 정보로 변환
     * DWARF, ELF, gsym, blazesym 등 오픈 소스 기술 기반
     * 심볼화 작업은 프로파일링 후 진행해 성능 저하 방지

Strobelight 데이터 시각화 도구

  Scuba

     * SQL 기반 쿼리 및 시각화 도구
     * 프로파일링 데이터에 대해 시계열, 분포, 플레임 그래프 등 제공

  Tracery

     * 시간 기반의 복합 프로파일링 데이터 시각화 도구
     * 서비스 요청 스팬, CPU 사이클, 오프-CPU 데이터 통합 시각화 가능

""Biggest Ampersand"" 사례

     * 엔지니어가 Strobelight 데이터를 통해 std::vector 복사 문제 발견
     * auto 키워드 뒤에 & 추가 → 불필요한 복사 방지
     * 결과적으로 연간 약 15,000대 서버 절감 효과 발생

오픈소스

     * Strobelight의 프로파일러 및 라이브러리 오픈 소스 : https://github.com/facebookincubator/strobelight

        Hacker News 의견

     * Grafana의 Pyroscope를 지속적인 프로파일링을 위해 추천함, Go에서 사용 중이며 잘 작동함
          + 여러 언어를 지원하며 eBPF 기반임
     * Meta/FB의 C++ 코드는 다른 오래된 대형 기술 기업의 코드보다 읽기 쉬움
     * Strobelight는 특히 높은 qps 서비스에서 최적화할 가치가 있는 부분을 쉽게 볼 수 있게 해주는 생명선임
     * Meta의 사용자 공간 바이너리에 프레임 포인터가 포함되어 있어 스택을 걷는 것이 가능해짐
          + 그렇지 않으면 복잡하고 비효율적인 방법을 사용해야 했을 것임
     * 비네이티브 언어를 위한 이벤트 프로파일러가 있다고 주장함 (예: 파이썬)
          + 파이썬 상태를 읽는 방법이 명확하지 않음
     * Strobelight의 GitHub 저장소는 아직 기본적인 수준임, 업데이트 시기를 궁금해함
     * 이름이 고속 주기 운동을 검사하는 스트로브 사용을 참조하는 것 같음
     * 오픈 소스 프로젝트가 이렇게 통합되었으면 좋겠음
          + Facebook의 내부 UI가 괜찮아 보임
     * 계산 비용 모델링은 어려움
          + 유체 역학을 계산 요구 사항에 적용하면 재미있을 것임
     * AWS/Azure/GCP의 주요 경쟁자들이 이런 도구의 부족으로 인해 어려움을 겪고 있다고 생각함
          + Microsoft에서 네트워크 트래픽을 추적하는 도구를 만들었고 디버깅에 매우 유용했음
          + Meta의 모든 것에 대해 의심을 가지고 접근함
     * 성능 프로파일링임
          + 제목과 도메인을 보고 사용자 프로파일링인 줄 알았음
     * Strobelight를 Parca와 Polar Signals를 통해 모두에게 제공하려고 노력 중임
          + 일부는 이미 존재하며 올해 더 많은 것이 나올 예정임
"
"https://news.hada.io/topic?id=19660","CTO를 뽑는 방법 - 코슬라벤처스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          CTO를 뽑는 방법 - 코슬라벤처스

     * 기술 스타트업의 CTO는 회사의 성패를 좌우함
          + 실현 가능성과 야망을 바탕의 제품의 기술적 비전을 설정
          + 시드 단계에서는 제품의 첫 번째 버전을 만들고 제품-시장 적합성(PMF) 달성할 때까지 반복
          + 성장 단계에서는 엔지니어링 인력을 관리함으로써 투자금의 대부분을 책임지게 됨
          + 모든 단계에 걸쳐서 CTO는 AI를 적용하거나 성공적인 하드웨어 출시 경쟁에서 결정적인 역할을 할 수 있음
     * 또한 CTO는 향후 수년간 제품 개발 조직의 문화를 수립
          + 이는 CTO가 장기적으로 가장 큰 영향을 미칠 수 있는 부분
          + 회사가 성장함에 따라 CTO가 뽑은 사람들이 다시 팀원을 뽑으면서 그 영향력이 전파됨
          + A급 리더는 A급 인재를 유치하고 채용함
          + 훌륭한 엔지니어는 감명받지 않은 팀에는 합류하지 않음
          + CTO의 영향력은 그가 떠난 후에도 오랫동안 지속됨

[ 찾고싶은 CTO 역할 결정하기 ]

     * CTO 포지션은 스타트업에서 가장 다양한 역할을 수행하는 임원 중 하나
     * 조직도를 계획하여 CTO에게 필요한 책임을 정확히 파악해야 함
     * 실제론 Head of AI나 엔지니어링 부사장(VP of Engineering) 이 필요할 수도 있음
     * 가장 간단한 시나리오는 실무형 기술 공동창업자나 CEO에게 직접 보고하는 Head of Engineering을 찾는 경우
* CEO
  * Head of Engineering (CTO 또는 VPE 직함)
      * Head of AI
  * Head of Product (CEO일 수도 있음)

     * 첫 버전의 제품을 만든 창업 멤버 CTO가 이미 있지만 관리나 임원 책임은 원하지 않는 경우
          + 이 경우 CTO는 기술에 전념하면서 프로토타입이나 AI 같은 하이-임팩트 분야의 작은 팀을 이끌 수 있음
          + 이때는 VPE를 고용할 수 있고, CTO 직함은 AI 전문가에게 주어질 수도 있음
* CEO
  * CTO (...또는...)
  * Head of Engineering (VPE 직함)
  * Head of Product
  * Head of AI

     * 점점 더 많은 CEO/창업자들이 제품 개발 전반을 한 임원에게 위임하려 함 (~15%)
          + 고객 관계와 우선순위 설정(무엇을 만들 것인가)과 제품 개발 방식(엔지니어링)의 균형을 잡는 능력 필요
          + CTPO(Chief Technology & Product Officer)라는 직함이 이 역할을 가장 잘 설명하며, 보통 산하에 기능별 책임자들이 있음
     * 디자인 책임도 맡는 경우가 많음
* CEO
  * CTPO
      * Head of Engineering
      * Head of Product
      * Head of Design
      * Head of AI

     * 회사의 성장 속도가 개인의 역량 확장 속도보다 빠를 경우, 미래지향적인 ""Head of Engineering"" 직함을 사용
          + 초기 스타트업이 좀 더 큰 기업 출신의 이사급 인재를 뽑고 2-4년 후 한계에 도달하면 그 위에 고용할 수 있는 유연성 제공
          + 직함을 이사나 부사장으로 바꾸는 것이 강등보다는 훨씬 덜 고통스러움(강등은 퇴사할 가능성이 높음)
          + 채용 과정에서 가능한 결과에 대해 투명해야 하며, 공개적으로는 항상 최저 수용 가능한 직함(Title)을 광고하고 거기서부터 협상을 진행

[ CTO 선발 기준 ]

     * 채용 프로세스의 핵심은 Job Description임
     * 좋은 JD는 회사에 대해 알려주고, 역할의 범위를 제시하며, 적합한 후보의 자질을 나열하고, 성공적인 채용 후 1년 내 달성 목표를 제시해야 함
     * 역할을 지나치게 상세히 기술하면 후보자들이 자진 포기할 수 있음
     * 또한 요구되는 경험은 없는데, 말빨 좋은 후보자들이 시험 요령만 익히지 않도록 주의
     * 평가 방식을 정확히 공개하지 않으면서도 찾는 바를 후보자에게 알려주어야 함
     * 채용팀에 훌륭한 직무 기술서 예시를 요청하고, 다음과 같은 기준을 포함시킬 것

  성장 단계 적합성

     * 현재 단계에서 일해본 경험이 있고 다음 단계로 성장시킨 경험이 있는가?
     * (시드 단계) 최초 제품을 만들고 PMF 달성을 도울 수 있는가?
     * 스타트업에서 일해본 경험이 없다면, 스타트업 역할만 고려하고 있는가?
     * (성장 단계) 채용, 팀 관리, 프로젝트 현황 보고, 제품 품질/보안 개선이 가능한가?

  기술적 신뢰성

     * 실무 역량
          + 얼마나 실무에 강한가? 개발 환경 구축, 버그 수정, 작은 기능 개발이 가능한가?
          + 과거에 도전적인 기술 작업을 했던 증거가 있는가?
     * 기술적 비전
          + 어떤 언어/프레임워크를 옹호하는가?
          + 구매/개발 의사결정은 어떻게 내리는가?
          + 아키텍처 토론에 참여하고 제안을 올바르게 평가할 수 있는가?
     * AI/ML 경험
          + 프로덕션에 반영해본 모델의 비즈니스 임팩트는?
          + 최신 생성형 AI를 다뤄본 팀 경험이 있는가? (토큰화, 파인튜닝, RAG, 벡터 DB 등)
          + LLM 이전 기술 배포 경험은? (Regression, Boosted Tree, GAN 등)

  훌륭한 엔지니어 채용 역량

     * 채용 기준을 어디에 두는가?
     * 최고 인재를 어떻게 유치하는가?
     * 내외부 리크루터와 어떻게 협력하는가?
     * 기술 평가는 어떻게 수행하는가?
     * 급성장을 경험해보았는가?
     * 누가 채용 결정을 내리는가?

  인사 관리

     * 구성원을 어떻게 동기부여 하는가?
     * 성과는 어떻게 관리하는가?
     * 엔지니어의 경력 개발을 어떻게 돕는가?

  프로젝트 관리

     * 이해관계자에게 현황과 예측 가능성을 어떻게 전달하는가?
     * 효율적인 프로세스를 유지하는 방법은?
     * 진전이 비선형적이고 결과를 사전에 규정할 수 없는 AI/ML 프로젝트는 어떻게 관리하는가?
     * 과거에 활용했던 프로젝트 관리 프레임워크는?
     * 선호하는 특정 시스템은?

  제품 품질

     * 팀이 출시하는 SW의 품질을 어떻게 파악하는가?
     * 기준 미달일 경우 어떤 조치를 취하는가?
     * 어떤 유형의 테스트를 작성하고 누가 하는가?

  제품 보안

     * 어떻게 적절한 보안 투자를 정당화하는가?
     * 위험은 어떻게 평가하는가?
     * 어떤 종류의 보안 활동을 관리했는가?

간접적으로 파악해야 할 기준

     * 일부 중요 기준은 직접 물어서는 평가하기 어려움
     * 후보자가 이런 자질을 보일 기회를 주어야 함

  미션 적합성

     * 지원 동기는 무엇인가?
     * 우리 회사가 없다면 다음에 무엇을 할 것인가?
     * 회사 미션이 후보자의 일이나 개인사에서 경험한 도전과제를 해결해주는가?
     * 미션 적합성은 채용 과정에서 발전할 수 있으며 초기 면접에서는 잘 드러나지 않을 수 있음

  의사소통 스타일

     * 일부 질문에 장황한 답변을 할 기회를 줄 것 (직관에 반하는 해법이 있는 비즈니스 과제, 최근 직장에서의 재직 스토리 등)
     * 생소한 기술 정보를 주제에 익숙하지 않은 사람에게 효과적으로 요약할 수 있는가?
     * 리크루팅팀과의 소통을 교차 기능적, 비동기적 업무 방식의 프록시로 간주해서 평가

  겸손함

     * 'I' 대신 'We'를 자주 쓰는가?
     * 과거 성과를 언급할 때 팀원들을 인정하는 시간을 갖는가?
     * 과거 이해관계자에 대한 과도한 비판을 자제하는가?

   선발 기준에 대한 더 자세한 내용은 Vinod의 글 ""CEO를 뽑는 방법""를 참고할 것 (CTO 채용에도 대부분 적용됨)

[ 전문 채용 에이전시 활용의 중요성 ]

     * 많은 창업자들이 처음에는 직접 채용하려 하며 에이전시 수수료를 아끼려 함
     * 또는 초기 공동창업자가 임원급이 아니라고 생각해 수백 명의 엔지니어를 관리하고 코딩은 안 하는 후보만 보게 될 수도 있음
     * 그러나 최고의 전문 채용 에이전시가 제공하는 장점을 이해해야 함
          + 과거 채용을 통해 최고 후보자들과 이미 관계를 맺고 있음
          + 훌륭한 후보자 경험을 제공해 경쟁이 치열한 시장에서 스타트업의 차별점이 됨 (대기업의 높은 연봉 제안과 경쟁할 때도)
          + 보상 협상을 중재해 모두가 만족하는 합의에 이르게 하고, 입사일과 온보딩을 앞두고 모두가 긍정적인 마음가짐을 갖도록 함
          + 훨씬 더 많은 우수 후보자(최대 5배)를 제공해 검증에 도움 됨
     * 최근에 우리 포트폴리오 회사의 CTO 후보의 세번째 면접을 지원 (내부 리크루터/CEO 다음, 팀 현장 면접 전 단계)
          + 에이전시 활용 전: 15명 면접, 합격률 27%, 꾸준했으나 '강력 추천' 후보 없음
          + 에이전시 활용 후: 13명 추가 면접, 합격률 46%로 상승. 마지막 4명 중 3명 합격, 1명은 '강력 추천'으로 오퍼 수락
          + 채용 기준을 낮추지도 않았고, 에이전시 활용 시 채용 기간이 절반 이상 단축되었을 것

[ 면접 단계 ]

     * 채용 프로세스는 휴리스틱임. 몇 시간 내에 몇 년을 함께 일할 사람인지 판단해야 함
     * 고위 직책 채용은 그들의 직관에 따라 사업 성과를 내도록 믿어주되, 전략과 현 상태에 대해 투명할 것을 신뢰하는 것
     * 후보자 간 프로세스를 최대한 대칭적으로 유지할 것. 어떤 단계도 건너뛰지 말되 지나치게 길어지지도 않게 할 것
     * 스타트업이 대기업의 높은 연봉과 경쟁할 수 있는 핵심 방법 중 하나는 신속한 의사결정임
# 1. 리크루터 스크리닝 (30분)
1. 상위 수준 기준 평가
  - 성장 단계 적합성
  - 미션 적합성
  - 의사소통 스타일
  - 겸손함
2. 보상 기대치 조율
3. 후보자 관심도 확인

# 2. 채용 담당자(CEO) 면접 (30분)
1. 상위 수준 기준 평가
  - 성장 단계 적합성
  - 미션 적합성
  - 의사소통 스타일
  - 채용 역량
  - 겸손함
  - 프로젝트 관리
2. 전문적 호환성, 긍정적 기업문화 기여 여부 평가
3. 남은 프로세스에 대한 관심, 열정, 추진력 고취

# 3. Quality Control (외부 어드바이저) 면접 (60분)
1. 전문가가 높은 기준을 유지할 기회
2. 강점과 약점 파악해 온사이트 팀 면접에서 추가 평가
3. 모든 기준을 빠르게 점검해 예외 사항 포착

# 4. 팀 온사이트 면접 (반나절)
1. 코딩 실습 (60분)
  - 기준: 기술적 신뢰성(실무, AI) 평가
  - 개발자 평가에 사용하는 것과 동일한 문제 사용
  - 성장기 CTO는 다소 녹슬 수 있음을 감안
  - 또는 Take-home 과제 고려
2. 아키텍처 실습 (60분)
  - 기준: 기술적 신뢰성(비전, AI) 평가
  - 최근 또는 임박한 시스템 문제 다루기
  - 비교를 위해 모든 후보자에게 동일한 문제 사용
3. 엔지니어와의 문화 적합성 면접 (60분)
  - 기준
    - 채용 역량
    - 인사 관리
    - 프로젝트 관리
    - 보안
    - 품질
4. 동료(보통 PM) 면접 (60분)
  - 기준
    - 의사소통 스타일
    - 미션 적합성
    - 프로젝트 관리
    - 인사 관리
  - SDLC
  - 기술 부채와 기능 간 균형
  - 엔지니어의 고객 공감 유지 방법

# 5. 창업자와의 워킹 세션 (반나절)
1. 실제 다가올 비즈니스 문제 해결
2. 비교를 위해 모든 후보자에게 동일한 문제 사용
3. 회의 초반에는 구조화되어야 하나 후반에는 자연스럽게 진행되어야 함

# 6. 사교/일화 나누기
- 임원진과 저녁식사/음료를 하며 삶, 가족, 관심사 등 파악

# 7. 레퍼런스 체크

# 8. 채용 제안

     * 프로세스 커스터마이징 : 필요에 따라 기술 평가 횟수와 강도 조정 가능
     * 어드바이저 활용 여력이 제한적이면 QC 면접을 뒤쪽으로 이동 가능
     * 각 단계별 백업 면접관을 지정해 일정에 차질이 생기지 않도록 할 것
     * 면접관에게 ""강한 반대"", ""반대"", ""미결정"", ""찬성"", ""강한 찬성"" 의 척도로 전반적 추천 의견 제시해달라고 요청
     * 온사이트 면접 후 팀 회의를 통해 피드백 논의 및 의견 조율
     * 면접관이 ""미결정(Maybe)"" 대신 확고한 의견을 내도록 독려. 조율 후에는 ""미결정""을 ""반대""로 간주
     * 미래 리더 선발에 팀을 최대한 참여시킬 것
          + 개발자들이 임원 역할의 가치를 과소평가하고 이를 평가하는데 미숙할 수 있음에 유의
          + ""그냥 개발자 한 명 더 뽑으면 되지 않나요?""라고 하면서도 채용 품질, 기술 부채, Uptime 저하 등 엔지니어링 관리가 해결하는 문제를 한탄하는 경우가 있음
     * 누구의 시간도 낭비하지 말되, 프로세스 초반에는 다소 여유를 둬서 온사이트까지 가는 후보자 일부를 확보할 것
     * 변화하는 회사의 미래 수요에 보정하는 시간을 가질 만한 가치가 있음
     * 그러나 CEO가 채용 담당자로서 최종 결정을 내림을 강조할 것

[ 면접 섀도잉(Shadowing) ]

     * 면접 전에 후보자와 미리 협의하여 채용 관리자가 운영 파트너 중 한 명이 진행하는 면접에 동참하는 것이 도움이 될 수 있음
     * 공유 문서에서 실시간으로 메모하는 것을 지켜보면, 후보자로부터 들은 정보를 어떻게 해석하는지 파악할 수 있음
     * 특정 기준에 대해 후속 질문을 어떻게, 언제 하는지 주의 깊게 관찰할 것
     * 섀도우는 면접이 패널 인터뷰처럼 느껴지지 않도록 가능한 말을 아끼는 것이 좋음
     * 면접을 녹화할 수 있는지 물어보는 것도 나쁘지 않음. 녹화한 내용은 면접 팀과 기밀로 공유될 수 있음

[ 레퍼런스 체크 ]

     * 레퍼런스 체크는 구식이고 시간이 많이 소요된다는 이유로 인기가 줄어들었지만, 여전히 두 가지 주요 측면에서 매우 유용함:
          + 새 관리자가 될 사람으로서 후보자를 성공적으로 자리 잡을 수 있도록 돕는 방법을 학습할 수 있음
          + 잘못된 인재가 최종 단계까지 진행되었음에도 불구하고 이전 직장에서의 협업이 좋지 않았다는 기록이 있는 드문 사례를 걸러낼 수 있음. (잘못된 채용은 조직에 연봉의 3-5배 비용을 초래할 수 있음)
     * 여러 명의 관리자 레퍼런스를 받되, 한 명 이상의 동료와 한 명의 직접 보고서를 포함하여 360도 관점을 얻는 것이 좋음
     * 훌륭한 후보자는 매우 인상적인 레퍼런스를 제공함
     * 백도어 레퍼런스를 찾아내되, 후보자가 현재 회사에 퇴사를 알리지 않았을 수 있으므로 기밀성을 유지해야 함. 백도어 레퍼런스는 더 신뢰할 수 있음
     * 프론트도어 레퍼런스는 긍정적으로 평가되기 위해서는 다음과 같이 매우 뛰어난 평을 받아야 함:
          + ""이 사람은 내가 가졌던 최고의 상사였어요!""
          + ""이 사람은 팀의 모든 사람을 더 나아지게 만들었어요!""
          + ""이 사람이 떠났을 때 너무 슬펐어요!""
     * 채용 관리자는 레퍼런스 체크를 리크루터에게 위임하지 않고 직접 수행해야 함
     * 다음은 15분 내에 다룰 수 있는 대본임. 조직 외부 사람과의 모든 접촉은 인상을 남기고 동맹을 만들 기회임을 기억할 것:
1. ""통화해주셔서 감사합니다. 시간을 내주셔서 고맙습니다. 공유해 주신 내용은 기밀로 유지될 것입니다.""
2. ""후보자와의 관계는 무엇이었나요?""
  - 어떤 회사에서?
  - 얼마나 오랫동안?
  - 당신의 역할은 무엇이었나요?
  - 후보자의 역할은 무엇이었나요?
  - 후보자는 누구에게 직접 보고했나요?
3. 후보자가 이 사람에게 직접 보고했나요?
  - 예
    - ""후보자의 주요 성과는 무엇이었나요?""
    - ""함께 일하는 동안 후보자가 개선하기 위해 노력한 것은 무엇이었나요?""
  - 아니요
    - ""후보자의 강점은 무엇인가요?""
    - ""후보자의 약점은 무엇인가요?""
4. ""이 사람과 다시 일하고 싶으신가요? 어떤 역할에서?""
5. ""이 사람은 당신이 함께 일했던 사람들 중 몇 퍼센트(예: 25%, 50%, 90%)에 속하나요?"" 또는 ""이 사람을 팀 내에서 어떻게 평가하나요?""
6. ""이 후보자가 성공하기 위해 관리자에게 필요한 것은 무엇인가요?""
7. ""제가 물어봐야 할 다른 사항이 있을까요?""
8. ""시간 내주셔서 감사합니다! 질문에 답변하거나 제 네트워크에서 소개를 제공하는 등 도움이 필요하면 언제든지 연락 주세요.""

     * 이 사람의 시간을 효과적으로 사용하고, 자신과 회사를 잘 대표하며, 보답할 기회를 제공할 것
     * 기술 분야는 작기 때문에 레퍼런스를 제공한 사람을 언젠가 채용하고 싶을 수도 있음

[ 최종 후보자 계약 마무리 ]

     * 후보자는 회사가 그들을 평가하는 것처럼, 회사와 당신을 평가하고 있음
          + 모든 상호작용이 슈퍼스타를 얻거나 잃을 기회임을 명심할 것
          + 과정 전반에 걸쳐 후보자에게 흥분감과 추진력을 지속적으로 심어줘야 함
          + 후보자를 동기부여하는 것이 무엇인지 파악하고, 그들이 회사에 미칠 영향을 분명하게 느끼게 해야 함
          + 동시에, 너무 '판매'에 집중하여 평가의 본질을 잃지 않도록 주의해야 함
     * 임원 리크루터와 협력하여 오퍼의 타이밍과 내용을 결정하되, 직접 전달할 것
          + 이 사람이 회사에 합류하는 것에 대한 당신의 흥분을 전달하고, 그들이 다른 후보자들과 차별화되도록 만든 특정 특성을 강조할 것
          + 모든 측면에서 투명하게 소통하고 조사했다면, 이미 총 보상(기본급, 선택적 보너스, 주식 포함)에서 15% 이내에 있어야 함
          + 즉각적인 '예'를 받지 못한다고 해서 기분이 상하지 않아야 함
          + 직장 변화는 인생의 몇 가지 중요한 변화 중 하나이며, 신중한 사람들은 결정을 내리기 전에 시간을 가지는 것을 좋아함
     * 그러나 최종 결정에 대한 일정은 기대해야 함
     * 합리적인 반대 제안을 받아들이는 것에 기분 상하지 않도록 해야 함
          + 당신은 회사에 합류한 후, 후보자와 공급업체를 대신해 열심히 협상할 수 있는 리더를 채용하려고 하는 것임
     * 논의할 수 있는 일반적인 주제들은 상황에 따라 다르지만 다음을 포함할 수 있음:
          + 더블 트리거 RSU
          + 퇴사 후 행사 기간 연장
          + 더 빠른 베스팅(Vesting)
          + 조기 행사
          + 사이닝 보너스
          + 인센티브/목표 기반의 연간 임원 보너스
     * 이후, 면접 팀의 구성원, 다른 임원들, 그리고 투자자들에게 후보자에게 연락하여 입사 제안을 축하하도록 격려할 것
     * 이는 환영하는 분위기를 보여줄 뿐만 아니라, 후보자에게 잘 운영되는 팀에 합류한다는 인상을 줄 수 있는 조직적 정렬과 협조를 보여줌

   HR 관점에서나 조직 문화 관점에서나 흥미로운 이야기들이 많네요.
   제가 잘 몰라서 찾아보니 백도어 레퍼런스 체크는 비지정 평판조회라고 하네요. 저같은 분들이 계실 수도 있을 것 같아서 남겨놓습니다.

   CTO는 어떻게 뽑을까
   그래도 안된다면
   당신이 기술 코파운더를 찾을 수 없는 이유
   당신이 바로, 당신이 찾던 기술 코파운더에요
"
"https://news.hada.io/topic?id=19611","Show GN: Nash, 단일 HTML 로 동작하는 노트 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Show GN: Nash, 단일 HTML 로 동작하는 노트

   이번에 만들게 된 작은 프로젝트를 소개 하고 싶어서 공유 드립니다.

   Nash 는 Note as HTML이라는 컨셉으로 단일 HTML 파일이 그 자체로 편집기 이면서 문서 파일이 될 수 있도록 구상을 했습니다.

   브라우저만 있다면 온라인, 오프라인 제약 없이 로컬에서 작업도 가능하고, 문서를 공유 받은 사람이 별도 회원가입이나 프로그램 설치 없이도 해당 HTML을 다운로드 받아 수정하고 다시 저장 및 공유하는 것이 가능합니다.

   클립보드의 이미지도 붙여넣기 하여 노트에 첨부할 수 있고 아주 적은 편집기 기능들이 구현되어 있어 간단한 글을 작성하기도 괜찮습니다.

   다만 브라우저의 저장 기능이 덮어 쓰기가 쉽게 되지 않다보니 내파일, 내파일 (1), 내파일 (2)... 이런식으로 의도치 않은 버전 관리가 가능합니다. 이외에도 편집기의 기능들을 개선하려고 숙고 했으나 아쉽게도 한계가 많습니다.

   사용성에 대해서는 제가 느끼기에도 부족한 점은 많으나, 셀프호스팅 블로그에 사용한다거나. 간단한 메뉴얼, 긴글과 이미지가 들어간 컨텐츠 용으로 사용해도 좋을 듯 합니다.

   구경해 보시고 다른 활용법에 대해 생각이 있다면 조언 주시면 감사하겠습니다.

   공유주신 훌륭한 프로젝트로 셀프호스팅에서 사용할 정적사이트생성기 에디터로 잘 활용하고 있습니다. 감사합니다!

   너무 멋지네요...! 별표쾅!
     * 제목이 비어있을 때 브라우저 제목이 <br>으로 설정되는 현상이 있습니다~

   TiddlyWiki 생각나네요. 폴더 문서 문서 내용 3단 컬럼식도 괜찮을 것 같습니다

   생각난 김에 TiddlyWiki와 비슷한 물건이 또 있나 찾아봤는데, Feather Wiki라는 게 있더군요. 이건 빈 HTML 파일의 크기가 60KB도 되지 않는 초경량입니다.

   심플하면서도 멋지네요!!

   멋집니다.
   다만, 너무 복잡한 스타일을 가진 HTML 데이터들이
   복사 붙여넣기 되어야할 때 간단한 normalization 과정을 거치면 더 좋을 것 같습니다.

   멋지네요. 주말동안 좀 살펴봐야겠습니다. 기존에 있던 개념들 몇개를 추가시키면 더 훌륭하지 않을까 싶네요.

   개인적인 의견입니다만.
     * 첫 줄을 filename으로 사용하고 있네요. 그렇다면 사용자에게 그것이 filename이라는 것을 알려주는 무언가(label이든 icon이든)가 있으면 좋겠습니다.
     * 파일명관련해서는 여러의견이 있을 수 있겠지만. 간단한 Rule을 정해서 적용해도 좋을것 같습니다.
       rule: 파일명 + ISO년월일시분초 + 확장자
       ex: Hello, This is Nash.2025-03-07 13.47.09.html
       역시 파일명에 :을 사용하지 못하는건 좀 아쉽습니다.

   저장시 파일명에 시간 정보를 넣는 건 엄청 좋은 아이디어 같습니다.
   덮어쓰기가 안되는 단점을 가리기에도 더 좋아보이네요.

   소증한 의견 감사합니다.

   뭔가 TiddlyWiki 생각나네요.
   개인적으로는 인쇄할 때 조금 더 깔끔하게 나오는 기능과 특정 부분을 고정폭 글꼴로 표시되게 하는 기능이 있었으면 좋겠습니다. 툴바에서 툴팁으로 단축키를 알려주거나, 안내 페이지에 단축키에 대한 설명이 있으면 금상첨화겠네요.
   생성된 HTML 파일에서 코드 부분은 가급적 위로 몰아두고 내용 부분은 최대한 아래에 나오게끔 하는 것도 좋을 것 같지만, 굳이 그렇게까지 HTML 코드를 직접 편집할 일이 있을까 싶기도 합니다. 하여튼 내용이 빈 파일을 하나 받아두면 경우에 따라서 유용하게 쓰일 수 있겠다 싶습니다.

   소중한 의견 감사합니다.
     * 단축키, 툴팁
     * 코정폭 글꼴 (코드)
     * 들여쓰기 내어쓰기
     * 읽기전용 내보내기

   이런것들은 확실히 있으면 훨씬 좋을것 같네요 참고해서 더욱 개선해보겠습니다.

   한 가지 더 생각나는 것은 들여쓰기/내어쓰기 지원 기능 정도입니다.
   간혹 긴 내용의 글을 작성해야 할 때 일부 내용을 들여쓰기 등으로 강조하는 것이 유용할 때가 있었습니다.

   만약에 이걸 셀프 호스팅 웹사이트에 쓰고자 한다면, 수정이 되지 않는 HTML 부분을 '내보내기'하는 기능이 있는 쪽이 더 좋을 것 같습니다.
   어쨌든 편집이 되지 않는 HTML 파일이라고 해도 단일 파일만 있어도 된다는 건 매력적이지요.
"
"https://news.hada.io/topic?id=19607","Chicory - JVM 네이티브 웹 어셈블리 런타임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Chicory - JVM 네이티브 웹 어셈블리 런타임

     * 별도의 의존성 없이 순수 Java로 구현된 Wasm 런타임
          + JVM이 동작하는 어디서든 Wasm 모듈을 구동 가능
     * 자신의 프로젝트 안에 간편하게 연동이 가능하여 플러그인 시스템을 쉽게 구현할 수 있음
     * 웹 어셈블리 모듈은 샌드박스 환경에서 실행되므로 설계상 보안 면에서 유리함. 모든 리소스에 대해서 제어 가능
     * Wasm 코어 스펙을 완전하게 지원하는 것을 지향함
     * 다른 Wasm 런타임의 단점
          + v8, wasmtime, wasmer, wasmedge, wazero 등 다양한 Wasm 런타임이 있지만, 대부분 네이티브 언어로 작성되어 배포 시 OS/아키텍처별 바이너리를 포함해야 함
          + 네이티브 코드와 FFI(외부 함수 호출)를 사용하면 JVM의 도구, 보안 모델, Observability에서 벗어날 수 있음

   wasm 런타임 단점이라는 부분은 jvm에도 해당되는게 아닌가요.. 자바 개발자 입장에서의 단점을 적으신거겠죠?

   자바장이인데, 자바로 wasm 하는 게 썩 맘에 드는 게 없어 러스트 공부하는 중이라 반갑네용.

   러스트 공부 이유 중엔 로우 레벨에 대한 노스텔지어도 있긴 합니다만.
"
"https://news.hada.io/topic?id=19651","16개월간의 테아닌(theanine) 셀프 실험","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       16개월간의 테아닌(theanine) 셀프 실험

    왜 이 실험을 했는가

     * 인터넷에서는 테아닌이 주목받고 있음. 이는 차에 자연적으로 존재하는 아미노산 유사체로, 불안, 기분, 기억력 향상에 도움이 되는 영양 보충제로 판매되고 있음.
     * 많은 사람들이 테아닌을 시도하고 긍정적인 효과를 보고함. 하지만 실제로 효과가 있는지 의문이 있음.
     * 테아닌은 글루타메이트와 구조적으로 유사하며, 뇌에 도달할 수 있는 것으로 보임.
     * 유럽 식품안전청의 2011년 평가에 따르면, 테아닌의 인지 기능 개선, 심리적 스트레스 완화, 정상적인 수면 유지, 생리통 감소와의 인과 관계가 확립되지 않았음.
     * 과학적 증거가 약하다는 것을 알고, 자가 실험을 통해 테아닌의 효과를 검증하고자 함.

    실험 방법

     * 테아닌과 비타민 D 캡슐을 사용하여 이중 맹검 실험을 설계함.
     * 스트레스를 느낄 때마다 캡슐을 복용하고, 시작과 끝의 스트레스 수준을 기록함.
     * 16개월 동안 94개의 데이터 포인트를 수집함.

    결과

     * 스트레스 수준은 테아닌을 복용했을 때와 비타민 D를 복용했을 때 모두 감소했음.
     * 테아닌이 실제로 효과가 있는지 확신할 수 없었음.
     * 여러 가능성을 고려했으나, 테아닌이 효과가 없다는 결론에 도달함.

    생각

     * 테아닌이 효과가 있다고 믿었으나, 실험 결과는 그렇지 않았음.
     * 과학적 문헌에서도 테아닌의 효과에 대한 강력한 증거가 없었음.
     * 다른 물질에 대한 자가 실험에서도 비슷한 결과가 나왔음.
     * 맹검 실험의 중요성을 강조하며, 테아닌의 효과를 입증하려면 추가적인 증거가 필요함.

    부록: 통계 논쟁

     * 통계적 유의성을 요구하는 사람들을 위해 p-값을 제공함.
     * 실험 데이터가 독립적이지 않기 때문에 통계적 분석의 신뢰성에 의문을 제기함.
     * 테아닌과 비타민 D의 스트레스 감소 효과에 큰 차이가 없었음.

        Hacker News 의견

     * 이 글은 훌륭함. 저자가 자신만의 지표를 정의하고, A/B 테스트를 수행하며, 해석과 원시 데이터를 공개함. 모든 건강 블로그가 이렇게 운영된다면 좋겠음
          + 개인적으로 4년 동안 이와 같은 실험을 해왔으며, 48874개의 데이터 포인트를 수집했음. Vim을 사용해 간단한 시스템을 구축했음
          + 데이터를 분석하기 위한 여러 도구도 개발했음
          + 더 많은 사람들이 무작위 연구를 수행하고 데이터를 해석하는 방법을 찾는다면 인류에게 큰 도움이 될 것임
          + 저자가 이 연구를 수행하고 원시 데이터를 제공한 것에 대해 정말로 칭찬함
          + HN의 글과 댓글을 읽으며 실험 해석에 더 집중했으면 좋겠다는 생각이 듦. 대부분의 댓글이 일화적임
          + 저자의 해석을 살펴보자. 개인적으로 그 부분이 조금 짧다고 느낌
          + 저자는 4개의 p-값을 계산하고 다음과 같이 작성함: ""기술적으로 두 가지 유의미한 결과를 발견했음""
          + 여기서 ""기술적으로""라는 말이 무슨 의미인지 궁금함. ""유의미한 결과""가 ""기술적으로 유의미한 결과""보다 더 나은 것이 있는지 궁금함
          + 저자는 계속해서 ""물론, 이것이 내가 테아닌이 해롭다는 것을 증명했다고 생각하지 않음""이라고 말함
          + 그렇다면 이것이 무슨 의미인지? 데이터를 수집한 목표는 무엇이었는지? 데이터가 테아닌의 긍정적인 효과를 보여주었다면 해석이 어떻게 되었을지 궁금함
          + 원시 데이터를 제공하는 것이 훌륭함. 오늘 나중에 그것을 살펴보기를 기대함
     * 이 연구가 완벽하게 실행된 것은 아닐 수 있지만, ""N=1 실험"" 부분은 문제가 아님
          + N=1 실험으로 알려진 많은 의학 및 과학 연구가 있었음. 이러한 실험은 증상이 안정적이고 측정 가능한 만성 질환에서 매우 유용하며, 여러 교차 기간을 통해 치료 효과를 정확하게 평가할 수 있음
          + 또한 자기 실험에 기반한 모든 의학적 발견을 잊지 말아야 함
          + Werner Forssmann은 자신에게 첫 심장 카테터 삽입을 수행했으며 노벨상을 받았음
          + Barry Marshal은 헬리코박터 파일로리를 자신에게 주사하여 위궤양을 유발한다는 것을 증명했으며 노벨상을 받았음
          + Jessie Lazear는 황열병에 감염된 모기에 물려 모기가 전염 매개체라는 가설을 증명했음. 노벨상은 받지 못했지만, 황열병에 걸려 2주 후 사망하기 전에 가설을 증명했음
     * 수면 보조제를 찾는 사람들에게, 테아닌, Mg 등의 복잡한 문제에 빠지기 전에 한 달 동안 OTC Azelastine 또는 Fluticasone 비강 스프레이를 시도해 보길 권장함
          + 내 만성적인 질 낮은 수면은 10년 전에 알아내고 치료했어야 했던 먼지 진드기 알레르기였음. 아침에 코가 막히고 입이 매우 건조했지만 낮에는 큰 문제가 없었음. 침대에 알레르기가 있었음
          + 항히스타민제와 제습기를 몇 달 동안 사용한 후 몇 년 만에 가장 잘 자고 있음. 먼지 진드기 알레르기가 매우 흔하기 때문에 여기에는 진단되지 않은 문제가 있는 사람들이 많을 것임
     * 테아닌에 대한 논의에서, 실제 이점은 카페인과 함께 섭취했을 때 나타난다고 함. 테아닌이 카페인의 불안한 효과를 완화하여 사용자가 더 높은 용량의 카페인을 섭취할 수 있게 해준다는 생각임
          + 저자가 그 이론을 구체적으로 다루었으면 좋겠음
     * 차가 커피보다 덜 긴장하게 만든다는 것을 오랫동안 느꼈음. 많은 사람들이 테아닌을 이유로 제시했지만, 나는 회의적임. 대부분의 차는 컵당 약 5mg의 테아닌만 함유하고 있으며, 보충제로 섭취할 때는 100-400mg을 섭취함. 그늘에서 자란 일본 차는 특히 테아닌 함량이 높다고 함. 나는 그 차들이 특히 진정된다고 느낌. 하지만 여전히 컵당 약 25mg만 함유함
          + 물질이 다른 용량에서 다른, 심지어 반대 효과를 가질 수 있는 것은 드문 일이 아님. 예를 들어, 고용량 멜라토닌은 잠을 깨우고 스트레스를 줄 수 있지만, 대부분의 사람들에게는 수면을 촉진하기 위해 최대 1mg만 필요함
     * 이런 것이 존재했으면 좋겠지만, 지금은 만들 시간과 에너지가 없음. 한 달에 $25 이상 지불할 의향이 있음
          + 기본적으로 이런 자기 실험을 제대로 블라인드 처리하고 좋은 통계로 수행할 수 있는 애플리케이션임. 도전-비도전-재도전 연구는 내가 좋아하는 것 중 하나지만, 하나를 수행하려면 매번 새롭게 설계해야 하며, 가능하다면 여러 개를 동시에 실행할 수 있으면 편리할 것임
          + 일반화에는 관심이 없으며, 예를 들어 매일 1000 iu의 비타민 D를 섭취하는 것이 충분한지, 더 많이 또는 적게 섭취해야 하는지 알고 싶음. 물론 실험실 검사를 받을 수 있지만, 결핍이나 과다비타민증을 피하는 것 외에는 혈중 농도보다 주관적인 웰빙에 더 관심이 있음
          + 아마도 그런 앱이 존재할 수도 있지만, 내가 모르는 것일 수도 있음
     * 자기 주도 실험을 실행하고 싶은 사람들을 위해 Reflect라는 앱을 만들었음. 앱에서 지표로 모델링할 수 있는 모든 것에 대해 자기 주도 실험을 실행할 수 있음. 얼마 전 ProductHunt에서 상위 3위에 올랐으며, 최근에는 노트로픽 커피와 관련된 실험에 대해 글을 썼음
     * 대부분의 의약품과 영양소는 상당히 잘 연구되어 있으며, 과학적 연구 결과는 대부분 신뢰할 수 있음
          + 대부분의 연구에서 유의미한 개선이 나타나지 않는다면, 그 물질은 효과가 없는 것임. 연구가 더 큰 인구에서 일부 개선을 보여주었다고 해서 그것이 당신에게 효과가 있다는 것을 의미하지 않으며, 개선이 눈에 띄는 것도 아님
     * Gwern은 블라인드 자기 실험의 큰 컬렉션을 가지고 있음. 그의 결과가 종종 보충제 커뮤니티의 일반적인 지혜와 모순되기 때문에 더 가치 있는 자원이 되지 않는다고 생각함
          + 그의 마그네슘 실험은 부정적인 결과를 보여줌
          + 인터넷이 그것을 기적이라고 확신했을 때 LSD 마이크로도징을 시도했지만, 이점이 없었고 일부 우려되는 부정적인 효과를 발견했음
          + 마그네슘, 생선 기름, B-비타민, 심지어 LSD 마이크로도징이 인생을 변화시키는 긍정적인 효과를 가져온다는 믿을 수 없을 정도로 긍정적인 일화와 대조됨
          + 플라시보 효과는 대부분의 보충제의 인식된 효과의 강력한 동인으로 잘 알려져 있음. 플라시보 효과는 사람들이 큰 효과를 기대하도록 준비될 때 훨씬 강해짐. 우연히도, 가장 극적인 효과를 보고하는 사람들은 종종 보충제에 대한 팟캐스트, 유튜브 비디오, 소셜 미디어 인플루언서 콘텐츠를 많이 소비하는 사람들임. 누군가가 ""프로토콜""이나 보충제가 놀라운 일을 할 것이라고 설명하는 3시간짜리 Huberman Lab 에피소드를 듣고 많은 신경전달물질 이름과 과소평가된 쥐 연구를 자주 오용하면서 그 효과를 기대하도록 깊이 준비된다면, 그 사람은 거의 확실히 그 효과가 발생할 것임. 이상하게도, 그것은 실제로 그들에게 효과가 있지만, 보충제가 결과를 생성하기 때문은 아님. 그들이 결과를 기대하도록 깊이 준비되어 있기 때문에 (예: 더 많은 에너지를
            느끼고, 잠들기 위해 이완) 스스로 플라시보 효과를 만들어내는 것임
     * 이것은 좋음. 사람들이 이렇게 엄격하고 정직할 수 있다는 것이 좋음
          + 스트레스를 줄이는 것은 작은 의식임. 집중할 것, 잘 할 것, ""순간을 잡을 것""임. 나에게는 아침 커피 만들기, 빵 만들기/굽기, 식기세척기 채우기임
          + 아마도 나는 경계선 강박증일지도 모름. 하지만 아마도 많은 사람들이 그렇고, 약을 복용하는 의식이 실제로 스트레스를 줄여줌. 연구에 따르면 그렇게 보임
          + 과학 경력을 20년 정도 쌓아오면서 데이터만 보는 것을 선호하게 되었음
"
"https://news.hada.io/topic?id=19625","DeepSeek-R1-671B-Q4_K_M을 1/2개의 Arc A770 Xeon에서  실행하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          DeepSeek-R1-671B-Q4_K_M을 1/2개의 Arc A770 Xeon에서 실행하기

     * 최신 _llama.cpp Portable Zip_을 사용하여 Xeon에서 1 또는 2개의 Arc A770으로 DeepSeek-R1-671B-Q4_K_M을 실행할 수 있음
     * 이 가이드는 Intel GPU에서 ipex-llm을 사용하여 llama.cpp를 직접 실행하는 방법을 설명

  지원 환경

     * Intel Core Ultra 프로세서
     * Intel Core 11세대 - 14세대 프로세서
     * Intel Arc A-Series GPU
     * Intel Arc B-Series GPU

  목차

     * Windows 빠른 시작
          + 사전 준비
          + 1단계: 다운로드 및 압축 해제
          + 2단계: 런타임 구성
          + 3단계: GGUF 모델 실행
     * Linux 빠른 시작
          + 사전 준비
          + 1단계: 다운로드 및 추출
          + 2단계: 런타임 구성
          + 3단계: GGUF 모델 실행
     * (새로운 기능) FlashMoE를 사용한 DeepSeek V3/R1 671B 실행
     * 팁 및 문제 해결
          + 오류: 다른 sycl 장치 감지됨
          + 다중 GPU 사용
          + 성능 환경
     * 자세한 내용

  Windows 빠른 시작

    사전 준비

     * GPU 드라이버 버전 확인 및 필요 시 업데이트
          + Intel Core Ultra 프로세서 또는 Intel Arc B-Series GPU의 경우 최신 드라이버 권장
          + 기타 Intel iGPU/dGPU의 경우 드라이버 버전 32.0.101.6078 권장

    1단계: 다운로드 및 압축 해제

     * Windows 사용자는 IPEX-LLM llama.cpp portable zip을 다운로드하고 폴더에 압축 해제

    2단계: 런타임 구성

     * ""명령 프롬프트""를 열고 cd /d PATH\TO\EXTRACTED\FOLDER 명령어로 폴더에 접근
     * GPU 가속을 사용하기 위해 몇 가지 환경 변수가 필요하거나 권장됨
          + set SYCL_CACHE_PERSISTENT=1 설정
     * 다중 GPU 사용자는 특정 GPU 선택 방법을 팁에서 확인

    3단계: GGUF 모델 실행

     * 커뮤니티 GGUF 모델을 로컬 디렉토리에 다운로드 또는 복사
     * 모델 경로를 설정한 후 llama-cli.exe 명령어로 실행

  Linux 빠른 시작

    사전 준비

     * GPU 드라이버 버전 확인 및 필요 시 업데이트
     * Intel 클라이언트 GPU 드라이버 설치 가이드에 따라 드라이버 설치 권장

    1단계: 다운로드 및 추출

     * Linux 사용자는 IPEX-LLM llama.cpp portable tgz를 다운로드하고 폴더에 추출

    2단계: 런타임 구성

     * ""터미널""을 열고 cd /PATH/TO/EXTRACTED/FOLDER 명령어로 폴더에 접근
     * GPU 가속을 사용하기 위해 몇 가지 환경 변수가 필요하거나 권장됨
          + export SYCL_CACHE_PERSISTENT=1 설정
     * 다중 GPU 사용자는 특정 GPU 선택 방법을 팁에서 확인

    3단계: GGUF 모델 실행

     * 커뮤니티 GGUF 모델을 로컬 디렉토리에 다운로드 또는 복사
     * 모델 경로를 설정한 후 ./llama-cli 명령어로 실행

  FlashMoE for DeepSeek V3/R1

     * FlashMoE는 llama.cpp 기반의 명령줄 도구로, MoE 모델에 최적화됨
     * Linux 플랫폼에서 사용 가능
     * 테스트된 MoE GGUF 모델: DeepSeek-V3-Q4_K_M, DeepSeek-V3-Q6_K 등

  팁 및 문제 해결

    오류: 다른 sycl 장치 감지됨

     * 서로 다른 sycl 장치가 감지되면 성능이 가장 느린 장치에 맞춰 제한됨
     * SYCL_DEVICE_CHECK=0 설정으로 이 검사를 비활성화하고 모든 장치를 사용할 수 있음

    다중 GPU 사용

     * 여러 Intel GPU가 있는 경우 기본적으로 모든 GPU에서 실행됨
     * 특정 GPU를 사용하려면 ONEAPI_DEVICE_SELECTOR 환경 변수를 설정

    성능 환경

     * SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS 설정으로 성능 향상 가능
     * 이 모드가 성능을 향상시키지만 예외가 발생할 수 있음

   이 가이드는 Intel GPU에서 llama.cpp를 효율적으로 실행하기 위한 방법을 제공하며, 다양한 설정과 최적화 방법을 포함함.
"
"https://news.hada.io/topic?id=19665","당신에겐 Redis가 필요하지 않을 수도 있습니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      당신에겐 Redis가 필요하지 않을 수도 있습니다

     * Redis는 기술 업계에서 가장 긍정적인 평판을 얻고 있는 기술 중 하나임
          + 매우 잘 설계된 뛰어난 기술이고 자체에 결함이 있는 것은 아니지만, 항상 필요하진 않을 수 있음
     * 10+년동안 3곳의 회사에서 같은 패턴을 봄:
          + 문제가 발생하고 Redis가 적합해 보였지만, 실제로는 상황을 개선하지 못했거나 근본적인 문제를 해결하지 못함
          + 그저 복잡성을 위해 복잡성을 더했을 뿐

첫 번째 사례: Tantan에서의 경험

     * Tantan은 중국의 두 번째로 큰 데이팅 앱이며, PostgreSQL 기반의 50~100대의 고성능 데이터베이스 서버를 운영함
     * 각 서버는 사용자 ID별로 샤딩되어 특정 사용자의 데이터는 하나의 서버에만 저장됨
     * 문제 상황
          + '스와이프' 횟수를 저장하고 빠르게 업데이트해야 하는 요구사항 발생
          + 초기에는 Redis에 저장하는 것이 적합하다고 판단함
          + 고성능 Redis 서버 몇 대만 있으면 충분하다고 생각하고 설정 진행
     * 재고 및 해결책
          + 팀 내에서 Redis 대신 PostgreSQL에 직접 저장하는 방안을 논의함
          + PostgreSQL 서버의 부하가 이미 높기 때문에 추가 부하는 미미할 것으로 예상
          + PostgreSQL에 저장한 후에도 성능 저하가 없었고, Redis 도입이 불필요했음

두 번째 사례: Bannerflow에서의 경험

     * 배경
          + Bannerflow는 광고 제작 및 게시 플랫폼임
          + 새로운 마이크로서비스에서 Facebook 같은 소셜 네트워크에 광고 게시를 지원하기 위해 Redis 도입 결정
     * 문제 상황
          + 로드가 Tantan에 비해 현저히 낮은 상황에서 Redis 도입이 필요했는지 불분명함
          + 초기 개발자가 떠난 후 Redis 도입 이유를 명확히 설명할 수 있는 사람이 없음
     * 결과
          + Redis는 로드가 낮아 굳이 필요하지 않았음
          + 장기적으로 Redis를 제거하는 것이 최선이라는 결론에 도달

세 번째 사례: MAJORITY에서의 경험

     * 배경
          + MAJORITY는 핀테크 회사로 외부 API 호출 결과를 캐싱하기 위해 Redis 도입
          + Redis는 위치 조회 데이터를 캐싱해 처리 속도를 높이고 비용을 절감하기 위해 도입됨
     * 문제 상황
          + 동일한 데이터가 DB(Azure SQL)에도 저장됨
          + Redis 호출 대신 DB 호출로 교체해도 부하 증가가 거의 없을 것으로 예상됨
          + 잠금(lock) 처리가 필요해 Redis를 계속 사용하려 했으나, Azure SQL에서 충분히 처리 가능했음
     * 결과
          + Redis 도입이 불필요하다는 결론에 도달
          + Redis 대신 Azure SQL 사용으로 전환 계획 수립

결론

     * 세 가지 사례는 모두 서로 다른 도메인, 기술 스택, 로드 조건에서 발생했음
     * 공통점은 불필요한 Redis 도입이었음
     * Redis 도입 전에는 실제 필요성과 성능 이점을 충분히 고려해야 함
     * Dan McKinley의 'Choose Boring Technology' 강연 추천

   레디스 사용여부를 떠나 도메인과 퍼시스턴스 사이에 캐싱 레이어를 끼워놓는(기본 구현은 바이패스) 건 전혀 오버엔지니어링이 아님. 로깅, 페이크데이터, 디버깅, 프로파일링, 어쩌면 진짜 캐싱…

   +1 저도 동의합니다. 레이어 하나 추가하는 것만으로도 여지 가 생기고, 수많은 일들을 해결할 수 있는 공간을 만들어주죠.

   레디스에 문제가 있다기 보다는 DB만으로 충분한데 왜 추가 구성 요소를 도입해서 관리 부담을 높여야 하느냐는 관점으로 보입니다.
   좀 간략하게 설명하고 있는 편이라서, 이런 관점도 생각해봐야 한다는 정도로 받아들이면 좋을 것 같네요.
   어플리케이션 로직을 단순하게 유지하면서 레디스 캐시를 도입하는 게 더 나은 선택일 수 있는 상황도 있으니
   상황에 맞게 선택해야 하겠습니다.

   타이틀에 낚였네요. ㅎㅎ 동의합니다~~

        Hacker News 의견

     * 2015년 Uber에서 근무할 때, 우편번호 기반의 지리적 분할을 육각형 기반의 방식으로 전환하려고 했음
          + 도시를 수십 개의 우편번호로 나누는 대신, 수십만 개의 육각형으로 나누고 동적으로 영역을 생성하는 방식이었음
          + 피닉스에서 첫 출시가 있었고, 팀은 수요 가격 시스템을 확장하기 위해 밤을 새웠음
          + 글로벌 출시가 지연되었음
          + Redis를 좋아하는 엔지니어들이 많았음
          + 가격 서비스는 Redis를 기반으로 했고, 수백만 건의 요청을 처리했음
          + 비용이 많이 들었고, 확장성 문제도 있었음
          + 알고리즘을 개선하여 단일 기계에서 여러 도시의 동적 영역을 계산할 수 있었음
          + Isaac이라는 엔지니어가 주말 동안 구현하고 배포했음
     * Redis를 과도하게 사용하는 것에 대한 논쟁이 있었음
          + Redis는 멋지지만, 사용 시 네트워크 지연과 직렬화 오버헤드가 발생함
          + 데이터가 이미 분할되어 있다면, 일반적인 해시맵이 더 나을 수 있음
          + Java에서는 ConcurrentHashMap, Guava Caches, Caffeine Caches 등이 있음
          + 로컬 캐싱 구현이 네트워크를 사용하는 것보다 거의 항상 빠름
          + Redis는 과도하게 사용되는 경향이 있음
     * Redis 사용 문화가 그 인기에 비해 발전하지 않았음
          + Redis는 다양한 데이터 구조를 지원하며, 회사 문화가 발전할수록 더 많은 패턴을 배울 수 있음
          + Redis의 패턴 모음집이 없다는 것이 아쉬움
     * Redis와 비Redis의 문제가 아니라, 직렬화가 잘 되지 않는 데이터와의 작업 문제임
          + 카운터, 뉴스 피드, 채팅 메시지 등은 Redis가 더 효율적일 수 있음
          + 대부분의 경우 MySQL로도 충분히 처리 가능함
     * 소프트웨어 개발은 종종 다른 사람의 방식을 반복하는 경향이 있음
          + Memcached에서 시작하여 Redis로 발전했음
          + 데이터베이스의 복잡성을 피하기 위해 캐시를 사용하는 경향이 있음
          + 데이터베이스는 여전히 복잡하고 어려움
     * Redis는 유일한 프로덕션 준비된 ""데이터 구조 서버""임
          + 여러 인스턴스에서 동일한 서비스를 접근할 때 유용함
     * 캐시가 필요하지 않을 수도 있음
          + 캐시를 도입하지 않고 아키텍처 개선에 집중한 경험이 있음
     * Redis의 API는 훌륭하지만, 운영상의 위험이 있음
          + 캐시로는 좋지만, 프로덕션 데이터 저장소로는 신뢰할 수 없음
     * Redis 사용을 추천하지 않는 경향이 놀라움
          + Redis는 여전히 훌륭한 데이터 구조와 성능을 제공함
     * Redis는 임시 캐시로는 괜찮지만, 트랜잭션이나 분산 저장소로는 부족함
          + 분산 잠금 문제에 대한 학습이 필요함
"
"https://news.hada.io/topic?id=19713","Krep - grep 보다 5배 빠른 문자열 검색 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Krep - grep 보다 5배 빠른 문자열 검색 도구

     * 성능이 중요한 애플리케이션을 위해 C로 작성된 초고속 문자열 검색 도구
     * 패턴 특성과 하드웨어에 따라 최적의 알고리듬을 동적으로 선택
     * SSE4.2/AVX2 같은 하드웨어를 활용하여 최대 처리량을 제공
     * 대용량 지원을 위해 파일을 청크로 나눠 멀티스레딩 병렬 처리
     * 패턴에 따라 가장 적합한 검색 알고리듬 사용
          + Boyer-Moore-Horspool: 일반적인 패턴 매칭에 적합
          + Knuth-Morris-Pratt (KMP) 알고리즘: 짧은 패턴에 최적화
          + Rabin-Karp: 긴 패턴에 효과적
          + SIMD 가속: SSE4.2, AVX2 지원 하드웨어에서 성능 향상
     * 메모리 매핑 파일 I/O 사용으로 시스템 호출을 최소화해 처리량 극대화
     * 유연한 검색 옵션
          + 대소문자 구분 및 구분 없는 검색
          + 파일 검색 외에 직접 문자열 검색 가능
          + 일치 횟수만 출력하는 모드 제공

  사용 방법

krep [OPTIONS] PATTERN [FILE]

     * 로그 파일에서 “error” 검색 : krep ""error"" system.log
     * 대소문자 구분 없이 8개의 스레드 사용해 검색: krep -i -t 8 ""ERROR"" large_logfile.log
     * 일치 횟수 출력 (매칭된 줄은 출력하지 않음): krep -c ""TODO"" *.c
     * 파일이 아닌 문자열에서 직접 검색: krep -s ""Hello"" ""Hello world""

  명령줄 옵션

     * -i : 대소문자 구분 없이 검색
     * -c : 매칭된 줄 출력 없이 일치 횟수만 출력
     * -t NUM : NUM 개의 스레드 사용 (기본값: 4)
     * -s STRING : 파일이 아닌 문자열에서 검색
     * -v : 버전 정보 출력
     * -h : 도움말 출력

  벤치마크

     * krep의 성능은 일반적인 문자열 검색 도구와 비교해 매우 뛰어남.
          + krep은 1GB 텍스트 파일에서 일반적인 패턴을 검색하는 데 0.78초가 걸렸으며, 이는 초당 1,282MB의 속도를 의미함
          + grep은 같은 작업에 2.95초가 걸렸으며, 초당 339MB의 속도를 기록함
          + ripgrep은 1.48초가 걸렸으며, 초당 676MB의 속도를 보임
     * → krep은 grep보다 약 3.8배 빠르고, ripgrep보다 약 1.9배 빠름 (하드웨어 및 파일 특성에 따라 성능이 달라질 수 있음)

  이름의 유래

     * “krep” 은 아이슬란드어 **“kreppan”**에서 유래함
     * “빠르게 움켜잡다”는 뜻을 가짐
     * 효율적인 패턴 인식을 상징함
     * 짧고 간결한 명령어로 타이핑이 용이함

   정규식 지원을 버리고서 ripgrep보다 2배밖에 빠르지 못하면 활용도가 좀 낮긴 하네요.
   저는 그냥 정규식 되는 ripgrep을 계속 쓸 것 같아요.

        Hacker News 의견

     * CPU 기능(예: AVX2)은 런타임에서 감지되어야 함
          + ifdef는 컴파일러가 지원하는지 빌드 타임에만 감지함
          + 프로그램은 컴파일러가 AVX2를 지원할 때만 컴파일됨
          + 런타임에서 CPU가 AVX2를 지원하는지 확인해야 함
          + 프로젝트에서 ""구성 시간에 CPUID 플래그와 실제 명령어 실행 테스트를 통해 감지""라는 부분이 있음
          + SSE4.2와 AVX2 명령어를 자동으로 활용할 수 있음
     * krep 프로젝트에 대한 블로그 게시물 소개
          + 홈페이지에서 ripgrep보다 빠르다고 나옴
          + 전체 ripgrep 벤치마크와 비교해보고 싶음
          + madvise() 관련 오류 발생, Makefile의 CFLAGS에 '-D_GNU_SOURCE' 추가 필요
     * 테스트 케이스의 중요성
          + 멀티스레드 파일 검색에서 청크 경계 문제는 신경 쓰임
          + 단순 검색에 새로운 엣지 케이스를 도입함
          + 파일에 한 글자를 추가하면 매치가 깨질 수 있음
     * 빌드 문제 해결 후 벤치마크 결과
          + 첫 번째 벤치마크 시도에서 속도가 느림
          + ripgrep이 krep보다 1.52배 빠름
     * 매치 빈도가 높은 벤치마크 시도
          + krep이 ripgrep보다 3.40배 빠름
          + 매치 수가 크게 차이남
          + krep이 정확한 결과를 제공하지 않을 수 있음
     * 추가 벤치마크 시도
          + ripgrep이 특정 패턴을 찾는 데 더 빠름
          + krep이 매치를 찾지 못함
     * ripgrep의 알고리즘과 메모리 맵 사용
          + ripgrep은 고급 서브스트링 검색 알고리즘 사용
          + 메모리 맵과 병렬 처리 사용
          + krep도 병렬 처리 사용, 단일 파일 검색 시 멀티스레드 사용
     * 벤치마크 결과에 대한 의문
          + ripgrep이 5GB 파일에서 패턴 검색 시 40초 이상 걸린다는 것은 이상함
          + OP에게 벤치마크 재현 방법 요청
     * krep의 이름에 대한 의견
          + grep의 ""re""는 정규 표현식을 의미함
          + krep은 정규 표현식을 사용하지 않으므로 이름이 잘못된 것일 수 있음
"
"https://news.hada.io/topic?id=19601","Parquet와 Polars로 텍스트 임베딩을 효율적으로 사용하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Parquet와 Polars로 텍스트 임베딩을 효율적으로 사용하는 방법

텍스트 임베딩을 휴대 가능하게 사용하는 최고의 방법은 Parquet와 Polars

     * 텍스트 임베딩은 대형 언어 모델에서 생성된 벡터로, 단어, 문장, 문서를 수치적으로 표현하는 방식임
     * 2025년 2월 기준, 총 32,254개의 ""매직: 더 개더링"" 카드 임베딩을 생성함
     * 이를 통해 카드의 디자인 및 기계적 속성을 기반으로 유사성을 수학적으로 분석 가능함
     * 생성된 임베딩을 2D UMAP 차원 축소를 통해 시각화 가능
     * 사용한 임베딩 모델은 gte-modernbert-base이며, 상세 과정은 GitHub 저장소에 정리됨
     * 해당 임베딩 데이터셋은 Hugging Face에서 제공됨

벡터 데이터베이스의 필요성 재고

     * 일반적으로 벡터 데이터베이스(faiss, qdrant, Pinecone)를 활용하여 임베딩을 저장 및 검색함
     * 그러나 벡터 데이터베이스는 복잡한 설정이 필요하며, 클라우드 서비스는 비용이 높을 수 있음
     * 작은 규모의 데이터(수만 개 수준)라면 벡터 데이터베이스 없이도 numpy를 활용하여 빠른 유사도 검색 가능함
     * numpy의 dot product 연산을 활용하면 단순한 코사인 유사도 계산이 가능하며, 32,254개 임베딩에 대해 평균 1.08ms 소요됨

def fast_dot_product(query, matrix, k=3):
    dot_products = query @ matrix.T

    idx = np.argpartition(dot_products, -k)[-k:]
    idx = idx[np.argsort(dot_products[idx])[::-1]]

    score = dot_products[idx]

    return idx, score

     * 벡터 데이터베이스를 사용하면 특정 라이브러리 및 서비스에 종속될 가능성이 큼
     * GPU 서버에서 임베딩을 생성 후 로컬로 다운로드하는 경우, 효율적인 데이터 저장 및 전송 방식이 필요함

최악의 임베딩 저장 방식

     * CSV 파일
          + 부동소수점(float32) 데이터를 텍스트로 저장하면 크기가 6배 이상 증가함
          + OpenAI의 공식 튜토리얼에서도 작은 데이터셋에만 CSV 사용을 권장함
          + numpy의 .savetxt()를 사용하여 저장하면 파일 크기가 631.5MB로 증가함
     * pickle 파일
          + 빠르게 저장 및 로드 가능하나 보안 위험이 존재하며, 버전 호환성이 떨어짐
          + 파일 크기는 94.49MB로 원본 메모리 크기와 동일하지만, 이식성이 낮음

나쁘지는 않지만 최적이 아닌 저장 방식

     * numpy의 .npy 형식
          + allow_pickle=False 설정을 통해 pickle 저장을 방지 가능함
          + 파일 크기와 속도는 pickle 방식과 동일하며, 개별 메타데이터를 함께 저장하기 어려움
     * 메타데이터와 분리된 저장 구조의 문제점
          + numpy 배열(.npy)로 저장하면 카드 정보(이름, 텍스트 등)와 임베딩이 분리됨
          + 데이터가 변경(추가/삭제)될 경우 메타데이터와 임베딩의 매칭이 어려워짐
          + 벡터 데이터베이스에서는 메타데이터와 벡터를 함께 저장하고 필터링 기능을 제공함

최적의 임베딩 저장 방식: Parquet + polars

  Parquet 파일 형식 소개

     * Apache Parquet는 컬럼 기반 데이터 저장 형식으로, 각 컬럼의 데이터 타입을 명확하게 지정 가능함
     * 리스트 형태(float32 배열)의 데이터를 저장할 수 있어 임베딩 저장에 적합함
     * CSV보다 빠른 저장 및 로드 성능을 제공하며, 일부 데이터만 선택적으로 로드 가능함
     * 압축 기능 제공하지만, 임베딩 데이터는 중복성이 낮아 압축 효과가 적음

  Python에서 Parquet 파일 활용

     * pandas를 활용한 Parquet 파일 저장 및 로드:
df = pd.read_parquet(""mtg-embeddings.parquet"", columns=[""name"", ""embedding""])
df

          + pandas는 중첩된 데이터(리스트)를 효율적으로 처리하지 못하며, numpy object로 변환됨
          + numpy 배열 변환 시 추가적인 연산(np.vstack())이 필요하여 성능 저하 발생 가능함
     * polars를 활용한 Parquet 파일 저장 및 로드:
df = pl.read_parquet(""mtg-embeddings.parquet"", columns=[""name"", ""embedding""])
df

          + polars는 float32 배열을 그대로 유지하며, to_numpy() 호출 시 즉시 2D numpy 배열 반환 가능함
          + allow_copy=False 설정을 통해 불필요한 데이터 복사를 방지 가능함
embeddings = df[""embedding""].to_numpy(allow_copy=False)

     * 새로운 임베딩을 추가할 때도 간단하게 컬럼을 추가하여 저장 가능함
df = df.with_columns(embedding=embeddings)
df.write_parquet(""mtg-embeddings.parquet"")

Parquet + polars를 활용한 유사도 검색 및 필터링

     * 특정 조건을 만족하는 데이터만 필터링한 후 유사도 검색 수행 가능함
     * 예: 특정 카드(query_embed)와 유사한 카드를 찾되, 'Sorcery' 타입이며 'Black' 색상이 포함된 카드만 검색
df_filter = df.filter(
    pl.col(""type"").str.contains(""Sorcery""),
    pl.col(""manaCost"").str.contains(""B""),
)

embeddings_filter = df_filter[""embedding""].to_numpy(allow_copy=False)
idx, _ = fast_dot_product(query_embed, embeddings_filter, k=4)
related_cards = df_filter[idx]

     * 평균 실행 시간 1.48ms로, 전체 데이터 검색보다 37% 느리지만 여전히 빠름

대규모 벡터 데이터 처리를 위한 대안

     * Parquet와 dot product 방식은 수십만 개 임베딩까지는 충분히 처리 가능함
     * 더 큰 데이터셋을 다룰 경우, 벡터 데이터베이스 사용이 필요할 수 있음
     * 대안으로 SQLite 기반의 sqlite-vec을 활용하면 추가적인 벡터 검색 및 필터링 가능함

결론

     * 벡터 데이터베이스가 필수적인 것은 아님
     * Parquet + polars 조합은 임베딩을 효율적으로 저장, 검색 및 필터링할 수 있는 강력한 대안임
     * 특히 작은 규모의 프로젝트에서는 Parquet 파일을 활용하는 것이 더 빠르고 비용 효율적임
     * 프로젝트에 따라 Parquet와 벡터 데이터베이스 중 적절한 솔루션을 선택하는 것이 중요함
     * GitHub 저장소에서 코드 및 데이터 확인 가능함

        Hacker News 의견

     * Parquet의 문제점은 정적이라는 것임. 지속적인 쓰기와 업데이트가 필요한 경우에는 적합하지 않음. 그러나 DuckDB와 객체 저장소의 Parquet 파일을 사용했을 때는 좋은 결과를 얻었음. 빠른 로드 시간임
          + 자체 임베딩 모델을 호스팅하면 numpy float32 압축 배열을 바이트로 전송한 후 다시 numpy 배열로 디코딩할 수 있음
          + 개인적으로는 SQLite와 usearch 확장을 사용하는 것을 선호함. 이진 벡터를 사용한 후 상위 100개를 float32로 재정렬함. 약 20,000개의 항목에 대해 약 2ms가 소요되며, 이는 LanceDB보다 빠름. 더 큰 컬렉션에서는 Lance가 이길 수도 있음. 그러나 내 사용 사례에서는 각 사용자가 전용 SQLite 파일을 가지고 있어 잘 작동함
          + 이동성을 위해서는 Litestream이 있음
     * 정말 멋진 기사임. 오랫동안 당신의 작업을 즐겼음. SQLite 구현에 뛰어드는 사람들을 위해 DuckDB가 Parquet을 읽고 이 사용 사례를 완벽하게 다루는 몇 가지 벡터 유사성 기능을 시작했다는 점을 추가할 수 있음
     * 데이터프레임을 여전히 좋아하지 않지만, Polars는 pandas보다 훨씬 나음
          + 시간 시리즈 계산을 하고 있었는데, 기본적으로 간단한 주식 가격 조정을 했음
          + 코드 읽기와 테스트가 실제로 가능하다는 점에서 놀라웠음
          + 실행 속도가 너무 빨라서 고장 난 것처럼 보였음
     * Unum의 usearch를 확인해 보세요. 무엇이든 이기고 사용하기 매우 쉬움. 필요한 것을 정확히 수행함
     * 시도해 보고 싶다면 HF에서 게으르게 로드하고 필터링을 적용할 수 있음
          + Polars는 사용하기 훌륭하며 강력히 추천함. 단일 노드에서 CPU를 포화시키는 데 탁월하며, 작업을 분산해야 한다면 Ray Actor에 POLARS_MAX_THREADS를 적용하여 단일 노드의 포화 정도에 따라 조정할 수 있음
     * 많은 훌륭한 발견이 있음
          + 구조화된 데이터를 임베딩 API에 전달하는 것이 더 나은지, 비구조화된 데이터를 전달하는 것이 더 나은지 궁금함. ChatGPT에 물어보면 비구조화된 데이터를 보내는 것이 더 낫다고 함
          + 내 사용 사례는 jsonresume을 위한 것임. 전체 json 버전을 문자열로 보내 임베딩을 생성하고 있지만, 먼저 resume.json을 전체 텍스트 버전으로 번역한 후 임베딩을 생성하는 모델을 사용해 실험하고 있음. 결과가 더 나은 것 같지만, 이에 대한 구체적인 의견은 보지 못했음
          + 비구조화된 데이터가 더 나은 이유는 자연어로 인해 텍스트/의미론적 의미를 포함하기 때문임
     * Vespa 문서에서 벡터를 이진수로 변환한 후 16진수 표현을 사용하는 깔끔한 트릭이 있음
          + 이 트릭은 페이로드 크기를 줄이는 데 사용할 수 있음. Vespa에서는 이 형식을 지원하며, 동일한 벡터가 문서에서 여러 번 참조될 때 특히 유용함. ColBERT 또는 ColPaLi와 같은 경우(여러 임베딩 벡터가 있는 경우) 디스크에 저장된 벡터의 크기를 크게 줄일 수 있음
     * Polars + Parquet는 이동성과 성능에 있어 훌륭함. 이 게시물은 Python 이동성에 중점을 두었지만, Polars는 엔진을 여러 곳에 임베딩할 수 있는 사용하기 쉬운 Rust API를 가지고 있음
     * Polars의 열렬한 팬이지만, 이를 사용하여 임베딩을 저장하는 방법을 고려하지 않았음 (sqlite-vec을 가지고 실험 중이었음). 정말 흥미로운 아이디어인 것 같음
     * 전체 텍스트 인덱싱 및 변경 사항 버전 관리 기능과 같은 뛰어난 성능과 기능을 가진 또 다른 라이브러리로 lancedb를 추천함
          + 벡터 데이터베이스이며 더 복잡하지만, 인덱스를 생성하지 않고 사용할 수 있으며, 뛰어난 polars 및 pandas 제로 복사 화살표 지원도 있음
"
"https://news.hada.io/topic?id=19677","유럽 탐방: 유럽 제품 및 서비스 발견","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         유럽 탐방: 유럽 제품 및 서비스 발견

     * 유럽 제품 및 서비스 발견
          + 유럽 전역의 추천과 통찰을 제공하는 커뮤니티 기반 디렉토리임
          + 카테고리: 자동차 및 운송, 도서, 미디어, 엔터테인먼트 및 게임, 의류 및 패션, 전자제품 및 가젯, 식음료, 건강 및 미용, 가정 및 생활, 아동 및 가족, 기타, 사무용품 및 문구, 전문 및 비즈니스 서비스, 소프트웨어 및 온라인 서비스, 스포츠 및 야외활동, 여행 및 숙박
     * GOG (Good Old Games)
          + 대체: Steam, Epic Games
          + 요약: DRM 없는 타이틀, 클래식 게임, 인디 출시작을 전문으로 하는 비디오 게임 디지털 배포 플랫폼임
     * Le Chat - Mistral AI
          + 대체: ChatGPT
          + 요약: 프랑스 스타트업 Mistral AI가 개발한 고속 AI 어시스턴트로, 보고서 작성, 코드 작성, 실시간 통찰 제공 등의 작업을 지원하여 생산성을 향상시킴
     * Allegro.pl
          + 대체: Amazon
          + 요약: 전자제품, 패션, 가정용품 등 다양한 제품을 경쟁력 있는 가격과 안전한 쇼핑 환경으로 제공하는 폴란드 온라인 마켓플레이스임
     * DeepL
          + 대체: Google Translate
          + 요약: 여러 언어에 걸쳐 매우 정확한 번역을 제공하는 AI 기반 번역 도구임
     * Koofr
          + 대체: Google Drive, Dropbox
          + 요약: 여러 기기와 플랫폼에서 파일을 안전하고 효율적으로 저장, 접근, 관리할 수 있는 클라우드 스토리지 서비스임
     * Lemmy
          + 대체: Reddit
          + 요약: 주류 소셜 미디어 사이트의 대안으로 설계된 오픈 소스, 분산형 소셜 네트워킹 플랫폼으로, 사용자가 온라인 커뮤니티를 생성하고 참여할 수 있게 함
     * Vivaldi
          + 대체: Google Chrome, Safari, Microsoft Edge
          + 요약: 프라이버시를 강조하며, 내장 광고 차단기, 고급 탭 관리, 독특한 사용자 인터페이스 등 다양한 기능을 제공하는 고도로 맞춤화 가능한 웹 브라우저임
     * Cryptee
          + 대체: Google Docs, Google Drive
          + 요약: Google Docs, Drive 및 Photos의 프라이버시와 보안을 우선시하는 대안임
     * Mastodon
          + 대체: Twitter
          + 요약: 오픈 소스, 셀프 호스팅 소셜 네트워킹 서비스로, 마이크로블로깅 기능을 제공하며 Fediverse의 일부로 간주됨
     * Linux Mint
          + 대체: Windows, Mac OS
          + 요약: 전통적인 레이아웃과 혁신적인 기능을 제공하는 Ubuntu 기반의 사용자 친화적이고 우아한 데스크톱 운영 체제임

        Hacker News 의견

     * 영국을 포함해줘서 고맙다는 의견과 함께 Mailpace.com을 추가했음. 유럽의 기술 회사들이 혁신을 되찾기를 기대하고 있으며, 여기의 인재와 교육은 놀라울 정도로 훌륭함. 투자 개선과 기술을 법률, 금융 등과 같은 '명망 있는' 경로로 대우하는 것이 필요함
     * 세계가 민족주의적 보호주의로 분열되는 것을 보는 것이 슬프다는 의견. 과거에는 점진적이지만 실질적인 글로벌 커뮤니티로의 통합이 있었음. 국가들이 자유롭게 거래하고 전문화할 수 있었음
     * 현재는 '국가 주권'과 '독립'을 강조하며 상호 의존의 강점을 무시하는 경향이 있음. 신뢰가 깨진 느낌이며, 이를 다시 구축하는 것이 어려울 것 같음
     * 유럽 제품을 지지한다면 Google Analytics 대신 Plausible 같은 제품을 사용하는 것이 좋다는 의견. 이렇게 하면 쿠키 배너를 표시하지 않아도 됨
     * 물리적 제품을 포함하는 디렉토리가 시작된 것을 보니 좋다는 의견. 의사결정에 도움이 될 추가 데이터 포인트에 관심이 있음
          + 제품/회사의 공급망 중 얼마나 많은 부분이 EU에 있는지
          + 회사가 EU에서 '공정한' 세금을 내고 있는지 여부를 보여주는 방법
          + 이러한 데이터는 얻기 어렵지만, 커뮤니티 노트를 통해 데이터를 크라우드 소싱하고 디렉토리에 업데이트할 수 있을지 궁금함
     * DeepL이 독일 회사라는 것을 오늘 알게 되었음. 일본어에서 영어로 번역하는 데 최고라는 평가를 받았으며, 많은 동료들이 사무실에서 사용하고 있었음
     * 개인적으로 클라우드 시대 초기에 내린 개인 데이터 선택을 재평가하고 있음. 당시에는 클라우드 대기업들이 무결성 위반으로 잃을 것이 많아 그런 일이 일어나지 않을 것이라고 생각했음. 이제는 데이터가 지정학적 게임에서 인질로 잡힐 수 있다는 것을 고려해야 한다고 생각함. 자가 호스팅과 지역 클라우드 서비스를 대안으로 심각하게 고려 중임
     * EU 출신으로서 운동을 지지하지만, Amazon 같은 것을 포기하기 어려운 이유를 설명함. 가격이 중요하며 매달 100유로 이상을 절약할 수 있음. Amazon은 EU 전역에 15만 명을 고용하고 있음. 대안이 필요하지만 부유한 EU 사람들이 투자해야 한다고 생각함. 지역 생산자도 마찬가지로 지원해야 한다고 하지만 가격 차이가 너무 큼
     * Codeberg라는 브라우저 확장 프로그램이 있으며, 이는 유럽의 Github 대안임
     * 성공적인 유럽 회사들이 미국에 완전히 합병되는 것이 항상 슬프다는 의견. datadog, algolia, dataiku, dashlane 등이 이에 해당함. 또한 pigment, aircall, contentsquare 같은 기술 회사들이 누락된 것 같음
     * 사람들이 생각하는 것과 다르다는 의견. Logitech 같은 회사는 거의 모든 제품을 중국에서 생산하며, 유럽 회사라고 해도 유럽 제품이 아님. 제품이 중국에서 만들어졌다면 유럽 제품이 아님. 이와 같은 의견이 여러 번 반복되는 것을 보며 유기적인 홍보 캠페인인지 궁금함
"
"https://news.hada.io/topic?id=19676","좋은 엔지니어 되기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               좋은 엔지니어 되기

     * 많은 소프트웨어 엔지니어들이 소프트웨어에 대한 열정 없이 일함
          + 단순히 좋은 급여를 받기 위해 일하지만, 열정이 없으면 결국 성과가 저하됨
          + 오래된 기술과 잘못된 신념에 머물러 배우지 않으면 성장하지 못함
     * 좋은 엔지니어가 되기 위해 필요한 요소
          + 엔지니어링의 본질을 이해하고 깊이 있는 지식을 쌓아야 함
          + 새로운 기술을 지속적으로 배우고 비판적으로 접근해야 함
          + 실전에서 배운 지식을 적용하고 개선하는 습관이 필요함

# 무엇이 좋은 엔지니어를 만드는가

     * 엔지니어의 정의

     ""과학적 원칙을 적용해 문제를 분석하고 설계, 코드 작성, 제작, 창조 등을 통해 문제를 해결하고 세상을 더 나은 곳으로 만드는 사람""
     * 소프트웨어 엔지니어에게 요구되는 역량
          + 컴퓨터가 어떻게 작동하는지 원리를 이해해야 함
          + 하드웨어와 소프트웨어가 상호작용하는 방식에 대한 깊은 이해 필요
          + 추상화된 언어나 기술에만 의존하지 않고 기초부터 학습해야 함

  도메인에 대한 깊이 있는 이해

     * 기초 원리에 대한 강력한 이해가 필요함
          + 기계 엔지니어 → 재료의 특성과 응용 지식
          + 소프트웨어 엔지니어 → 메모리와 CPU의 작동 원리 이해
     * 기초 원리에서부터 학습해야 함
          + HTTP, 메모리 구조, 시스템 동작 등 기본 개념에 대한 깊은 이해 필수
          + 상위 레벨에서 시작하지 말고 기초부터 쌓아가야 함

  지속적인 학습

     * 최신 기술 및 개발 동향을 계속 학습해야 함
     * 새로운 기술이 가진 장점과 단점을 비판적으로 분석해야 함
     * 학습 과정에서 발견한 새로운 주제에 대해 더 깊이 파고들기
          + 수학을 배울 때 세부 주제로 연결되는 것처럼 학습의 깊이를 확장해야 함

  기술의 한계와 문제점 이해하기

     * 도구나 언어의 장단점을 명확히 이해해야 함
     * 특정 언어나 도구를 과도하게 신봉하는 태도를 경계해야 함
     * 프로젝트에 맞는 최적의 도구를 선택하는 것이 중요함

  실전에서 지식 적용하기

     * 이론만 알고 있는 것은 의미 없음
          + 배운 지식을 실제 프로젝트에 적용해야 함
          + 문제를 해결하거나 개념을 증명하는 데 활용해야 함
     * 실전 적용의 예시
          + 소규모 프로토타입 구축
          + 일상에서 발생하는 문제 해결
          + 배운 내용을 다른 사람에게 설명하고 가르치기

# 더 나은 엔지니어가 되는 방법

  비판적 사고 능력 키우기

     * 비판적 사고는 엔지니어링의 핵심 요소
          + 개념과 그 효과를 이해하고 도전하기 위해 필수적임
          + 비판적 사고가 부족하거나 이를 소홀히 하면 비효율성과 복잡성을 초래함
     * 비판적 사고 능력 강화하기
          + 새로운 개념을 접할 때 무조건 받아들이지 말고 효과성과 타당성을 검토해야 함
          + 특정 접근 방식의 장단점과 대안을 논리적으로 분석해야 함
     * 비판적 사고 학습 자료 : Critical Thinking 참고

  더 많은 책 읽기

     * 독서는 지식을 습득하는 효과적인 방법
          + 소프트웨어 엔지니어링 관련 다양한 주제의 서적 존재
          + 단순히 책의 내용을 받아들이지 말고 비판적으로 접근해야 함
     * 비판적으로 읽기 위한 질문 예시
          + ""이 접근 방식에 문제가 있는가?""
          + ""더 나은 방법이 있는가?""
          + ""내가 다르게 한다면 어떻게 할 것인가?""
          + ""이 책에서 설명하는 내용이 실제로 옳은가?""
     * 노트 작성 습관 기르기
          + 배운 내용과 생각을 정리하고 기록
          + 모르는 주제가 언급되면 추가로 조사
          + 노트 작성 도구로 Obsidian 추천 (개인 선호에 따라 선택 가능)
     * 추천 읽기 목록
          + @gizmobly reading list
          + @ludwigABAP reading list
          + @seatedro reading list

  배운 지식을 프로젝트에 적용하기

     * 이론에서 실전으로 연결하기
          + 배운 내용을 실제 프로젝트에서 적용해야 진정한 학습이 이루어짐
          + 개념을 실제로 구현하면서 깊이 있는 이해 가능
          + 작은 프로젝트나 프로토타입이라도 직접 만들어 보는 것이 중요함
     * 실전 적용 과정에서 얻는 이점
          + 이론에서는 보이지 않던 실제 문제에 직면하게 됨
          + 문제 해결 과정에서 지식을 구체화하고 개선 가능
          + 문제 해결 능력과 논리적 사고력이 강화됨
     * 배운 내용을 적용하는 방법
     * 작은 프로토타입 구축
          + 새로운 프레임워크, 언어, 개념 학습 후 작은 프로젝트 시도
          + 예: 데이터베이스 인덱싱 학습 후 간단한 검색 시스템 구현 및 성능 비교
          + 실제 문제 해결
               o 일상이나 작업에서 발생하는 작은 문제를 해결해 보기
               o 예: 반복적인 수작업 자동화, 성능 저하 문제 개선 등
          + 배운 내용 가르치기
               o 배운 내용을 다른 사람에게 설명하면서 이해도 강화
               o 블로그 작성, 트위터 스레드 작성 또는 동료와 토론
               o 가르치는 과정에서 새로운 관점을 발견할 수 있음
     * 지속적으로 지식을 적용하면 이론적 이해가 실전 역량으로 전환되며, 더 유능한 엔지니어로 성장 가능

  자기 코드 평가 및 개선

     * 자기 비판은 뛰어난 엔지니어의 핵심 습관
          + 많은 엔지니어들이 코드가 작동하면 ""충분하다""고 생각하는 실수 범함
          + 그러나 진정한 엔지니어는 항상 개선의 여지가 있음을 인식함
     * 자기 평가의 목표
          + 스스로에게 과도하게 엄격해질 필요는 없음
          + 지속적인 개선의 기회를 찾는 것이 핵심
          + 코드를 작동시키는 데 만족하지 말고 성능, 유지보수성, 가독성 개선 방안 탐색
     * 지속적인 자기 평가의 효과
          + 코드 품질이 점진적으로 향상됨
          + 자기 비판을 통해 문제 해결 능력 강화
          + 자신의 지식과 역량에 대해 끊임없이 발전 가능

# 소프트웨어 엔지니어를 위한 추천 목록

  추천 도서

     * Designing Data-Intensive Applications – 데이터 중심 애플리케이션 설계
     * Introduction to Algorithms – (한글판도 제목이 영어임)
     * Writing a C Compiler
     * Essential Maths for Data Science – 개발자를 위한 필수 수학
     * Elements of Information Theory

  추천 프로젝트

     * 컴파일러 - 선택한 언어에 대한 컴파일러 작성해보기, LLVM 또는 JVM 참고
     * 에뮬레이터 - 간단한 CPU(예: 8086) 에뮬레이터 작성
     * 렌더 엔진 / 게임 엔진 - OpenGL 또는 Vulkan을 사용해 그래픽 프로그램 작성
     * 메모리 뷰어 및 편집기 작성 - 다른 프로그램의 메모리와 상호작용하는 프로그램 작성
     * HTTP 서버 작성 - 저수준 언어로 HTTP 서버 작성

     * 웹사이트나 단순한 프로젝트는 피할 것. 학습 효과가 낮을 수 있음. 위에 언급된 프로젝트에서 하나를 선택하고, 주제를 연구한 후 직접 구현해 보기

결론

     * 좋은 엔지니어가 된다는 것은 많은 프로그래밍 언어를 아는 것이 아님
     * 기본 원리의 깊은 이해 + 비판적 사고 + 실전 적용이 핵심
     * 배우고, 적용하고, 끊임없이 개선하는 태도가 필요함
     * 엔지니어링은 끝이 없는 여정이며, 성장하려는 자세가 중요함

결론

     * 좋은 엔지니어가 되는 것의 본질
          + 가장 많은 프로그래밍 언어를 아는 것, 최신 프레임워크를 마스터하는 것, 새로운 기술을 쫓는 것이 아님
          + 엔지니어링의 기본 원리에 대한 깊은 이해가 핵심
          + 배운 지식을 실제 프로젝트에 적용하고, 비판적으로 사고하며, 끊임없이 성장해야 함
     * 최고 엔지니어의 특징
          + 배움을 멈추지 않고 새로운 지식을 습득함
          + 자신의 가정을 끊임없이 의심하고 개선 방안을 찾음
          + 배운 지식을 실제 문제 해결에 적용하고, 동료와 협업하며 성장함
     * 엔지니어링은 평생의 여정
          + 호기심(curiosity), 꾸준함(discipline), 성장에 대한 의지가 필요함
          + 이러한 원칙을 실천한다면 좋은 엔지니어를 넘어 위대한 엔지니어가 될 수 있을 것

   얼마전에 회사에서 Kotlin 언어 스터디를 위해 세미나를 한 번 한적이 있었는데, 부서에서 주로 쓰는 C++ 언어와 비교하는 방식으로 설명을 해보니까 반응이 좋았던 기억이 납니다. 정작 저는 C++을 거의 안쓰고, 부서원들은 Kotlin을 처음 접하는 상황이었는데 여러 모로 모두의 성장에 도움이 된 것 같았습니다.

   리눅스 커널의 메모리 관리쪽도 컨트리뷰션을 해봤고, 저수준의 동작에 대해 어느정도 이해하고 있다고 생각하지만, 결국 원하지않게 개발과는 거리가 있는 일을 하고 있는걸 생각해보면, 이 글의 반대로 행동해야 잘 나가는 엔지니어가 되는게 아닌가 생각됩니다.
     * 새로운 기술을 빠르게 쫒을것
     * 개인적 호기심보다 시장을 생각할것
     * 자기 비판보다 자기 포장을 잘할것
     * 원라/성장보다 코딩테스트에 집중할것
       귀국해보니 한국은 시장이 너무 작고 경쟁이 심해서, 개발에 집중할 수 있는 회사나 포지션이 적고, 그 적은 자리를 서로 가지려고하니 결국 눈에 잘 띄는 것에 집중해야 자기가 하고 싶은 개발을 할 수 있어보입니다.

   저도 공감합니다! 그리고 여기서 말하는 '좋은' 엔지니어가 어떤 엔지니어인지 사람마다 해석이 너무 다른 것 같아요. 극단적일 수 있지만, 기초지식의 중요성을 안다고 해도 시장에서 가치가 없는 엔지니어는 좋은 엔지니어인지 생각해보게 되네요

   진짜 공감갑니다,,,
   본질적인 걸 얼마나 제대로 파악하고 잘 다루냐의 게임이 아니라
   특정 언어와 특정 기술 관련을 트렌드에 맞게 잘 쓰느냐의 게임이라 아쉽네요,,

   한국에도 잘하는 엔지니어 많다고 생각하는데, 저도 시장 크기로 인해 아쉽게 느껴지는 부분이 많습니다.

   FuriosaAI 같은 곳이 잘됐으면 좋았을텐데 하는 생각이 듭니다.

   FuriosaAI 망했나요...?

   약간 공감이 되네요.. ㅋㅋ
   한국 시장만 그런건지...

        Hacker News 의견

     * 책 읽기에 대한 의견이 매우 마음에 듦. 많은 엔지니어들이 문서와 책보다 비디오와 얕은 게시물을 선호하면서 많은 것을 놓치는 것을 자주 봄
          + 또한, 사람들이 사소한 것에 대해 문서를 읽거나 최소한 구글링을 하기보다는 질문을 하는 경우가 얼마나 많은지 놀라움
          + 정보를 검색할 수 있는 능력이 매우 중요한 기술임
     * 이 글에서 언급된 많은 점에 동의함. 하지만 CPU, 메모리, HTTP 등의 깊은 기초를 아는 것이 어떻게 더 나은 엔지니어가 되는 데 도움이 되는지 확신이 서지 않음
          + 대부분의 엔지니어는 매우 높은 수준의 추상화에서 작업하며, 그 수준에서 사용되는 언어와 프레임워크는 메모리 등의 저수준 접근을 허용하지 않음
          + 이러한 기본적인 것들에 대해 무지해서는 안 되지만, 학문 외의 일상적인 응용에 대해서는 이해가 되지 않음

   깊은 기초까지는 모르겠지만, 기초를 모르면 정말 황당하고 도저히 상상이 안 되는 결과를 만들어내는 것을 봤습니다.
   예를 들면 DB에 있는 모든 레코드를 메모리에 넣고 나서 메모리에서 검색하도록 구현.
   레코드가 적을 때는 잘 돌아가지만, 레코드가 많아지면 메모리 터짐.
   메모리와 DB가 어떻게 다른지 전혀 모르기 때문에 이렇게 짭니다.
   이 것은 하나의 예이고, 매번 정말 상상도 못 하는 방향으로 구현 합니다.
   일반(?) 프로그래머는 정말 상상 할 수 없습니다.
"
"https://news.hada.io/topic?id=19652","마치 스마트폰을 사용하는 것처럼 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           마치 스마트폰을 사용하는 것처럼

     * ""It is as if you were on your phone""은 미래의 휴대폰 사용 압박과 피로를 다룬 게임임
     * 사용자가 실제로는 아무것도 하지 않으면서 휴대폰을 사용하는 척하도록 유도함
     * p5와 Hammer.js를 사용하여 터치 제스처를 구현
     * 언론
          + Iwan Morris는 이 게임을 ""기묘한 새로운 자기 성찰적 데스크톱 모바일 출시작""이라고 설명함
          + Jason Kottke는 이 게임이 사용자가 휴대폰을 사용하는 것처럼 보이도록 설계되었다고 언급함
     * 문서
          + 프로세스 문서에서 할 일 목록과 디자인 탐색을 확인할 수 있음
          + 커밋 히스토리에서 개발 과정의 세부 사항을 알 수 있음
          + 코드 저장소에서 소스 코드를 확인할 수 있음
     * 라이선스
          + 이 게임은 Creative Commons Attribution-NonCommercial 3.0 Unported License 하에 라이선스됨

        Hacker News 의견

     * 같은 제작자의 다른 작품 (매우 재미있음): 링크
     * 같은 제작자의 관련 작품: 링크
     * 데스크톱에서 더 접근하기 쉬움
     * 몇 초 만에 이 경험이 싫어졌음. 그래서 예술적 목표를 달성했다고 생각함
     * 이 작품을 사랑함. 감사함. 현재 혼자 점심을 먹고 있는 중이고, 당연히 휴대폰을 꺼내서 처음 본 것이 HN의 이 게시물이었음. 게임을 시작했고 미소를 지을 수밖에 없었음. 로봇이 인간 행동을 연구하면서 나를 모방하는 것을 보는 것 같았음
          + 스마트폰 이전에 내가 무엇을 했을지에 대해 생각하게 되었음. 피처폰 시절에도 여전히 문자를 많이 보냈기 때문에 크게 다르지 않았지만, 그때는 책을 더 많이 읽었음
     * 귀를 긁어야 할 때를 알려주는 것이 마음에 듦. 언제 해야 할지 항상 헷갈렸음. 11/10
     * ""오른쪽으로 스와이프""는 나에게 아무 효과가 없었음 (안드로이드의 Fennec)
     * 가장 나쁜 점은 어색한 순간에 유용할 것이라고 즉시 생각한 것임. 버스에서 모두가 휴대폰을 꺼내므로 밖을 바라보는 대신 이걸로 잘 어울릴 수 있음
     * AI 로봇이 공공장소에서 자연스럽게 어울리기에 완벽함. 바텐더가 유리잔을 닦는 것처럼, 사람들을 불편하게 만드는 시선을 피할 수 있음
     * 자신을 다른 관점에서 볼 수 있는 것이 좋음. 마음에 들었음
          + 도파민 효과에 대해 궁금함. 더 지루하게 만들 수 있을지 궁금함
     * 이걸 휴대폰이 아닌 다른 기기에 넣어야 함. 천천히 스크롤되는 종이 테이프에 지시사항을 표시하는 간단한 기계 장치일 수 있음
"
"https://news.hada.io/topic?id=19632","Manus - 사고와 행동을 연결하는 범용 AI 에이전트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Manus - 사고와 행동을 연결하는 범용 AI 에이전트

     * 문제를 분석하고 작업을 수행해서 결과를 만들어내는 자동화된 에이전트
     * 작동 예제
          + 이력서 스크리닝 : zip으로 압축된 이력서 묶음을 업로드하면 압축풀고 각 이력서에서 중요한 내용을 캡쳐하여 분석. 평가기준과 함께 상위 후보자를 추천. 엑셀로 결과 달라고 하면 생성해줌
          + 뉴욕에서 좋은 학교가 가깝고 안전한 집 찾기 : 요구조건에 따라 ToDo 리스트를 작성하고, 기사를 검색해서 ""안전한 지역""들을 찾음. 그리고 학교들을 검색. 예산을 계산하기 위한 파이썬 코드를 작성. 예산에 따라서 부동산 사이트에서 조건에 맞는 집들을 검색하여 보고서를 작성해줌
          + 주식 분석 : NVidia, Marvell, TSMC의 3년간 주식가격 변화에 대한 관련성 분석. API를 통해서 데이터소스에 접근하여 데이터를 취득하고, 데이터 분석 및 시각화를 위한 코드를 작성하고 실행. 해당 데이터 기반으로 웹사이트를 만들고 디플로이까지 한뒤 공유 가능한 링크를 제공
     * 현실 세계의 문제 해결 능력을 평가하는 GAIA 벤치마크에서 최첨단(SOTA) 성능을 달성
     * 멀티 에이전트 시스템으로 동작하며 이중 일부는 오픈소스로 공개 예정
     * 현재 베타 테스트 중으로 초대코드가 필요함

   가끔씩 invitation codes 올려준다고, #announcement와 #use-cases 2개 채널 밖에 없는 discord에 몇십만명이나 모아 놓은 것도 흥미롭더라고요.

   자기 자신의 소스코드를 제공했다던 그 manus!!

   기존에 처리한 내용들을 Replay 형식으로 볼 수 있는게 재미있네요.

   Manus 리플레이 링크 : Comprehensive Tesla Stock Analysis and Investment Insights

   Manus로 테슬라 주식을 분석한 세션 리플레이. 주요 지표, 재무데이터, 매출 추세, 이익 마진 부터 투자자를 위한 SWOT 분석 및 성향에 따른 추천까지.
   다양한 데이터 소스에 접속해서 가져오고, 코드를 작성해서 보고서를 작성하는 과정을 모두 볼수있습니다.

   replay가 신뢰성을 높여주는 큰 피쳐인거 같네요.
   하나하나 뜯어보면 기존에도 구현 가능했던 영역인데, 덕지덕지 붙여서 구현했던걸 유려하게 통합한 느낌이네요
   멀티 에이전트면 비용이 많많치 않을 것 같은데 얼마에 나오려나..

   혹시 replay 구현과 관련하여 research 할 수 있는 keyword를 알고 계신게 있으세요?
   어떻게 구현하는지 너무 궁금하네요.
"
"https://news.hada.io/topic?id=19706","HP 프린터 펌웨어 업데이트 오류로 작동 불능, HP 카트리지도 사용 불가 문제 발생","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            HP 프린터 펌웨어 업데이트 오류로 작동 불능, HP 카트리지도 사용 불가 문제 발생

     * HP는 펌웨어 업데이트로 인해 기존에 구매한 프린터가 고장 나는 문제로 악명이 높음
     * HP가 최근 펌웨어 업데이트를 통해 일부 프린터가 HP 정품 토너를 인식하지 못하는 문제가 발생함
     * 문제의 펌웨어 버전은 20250209로, 3월 4일에 LaserJet MFP M232-M237 모델에 배포됨
     * 업데이트 내용 : 보안 업데이트, 규제 요구사항 업데이트, 일반적인 개선 사항 및 버그 수정, IPP Everywhere 관련 수정
     * 그러나 업데이트 후 HP 정품 토너를 사용 중인 프린터에서 Error Code 11이 발생하고 토너 표시등이 깜빡이는 문제가 보고됨
          + 사용자들은 토너 접점을 청소하고 토너를 재설치했음에도 불구하고 문제 해결이 되지 않음
     * 한 사용자는 다음과 같이 불만을 표시함:

     ""소규모 사업장에서 사용하는 프린터가 아무 이유 없이 작동을 멈췄음. 새 토너를 $60에 구입했지만 여전히 프린터가 작동하지 않음.""
     * HP는 문제를 인지하고 있으며 다음과 같이 발표함:

     ""HP LaserJet 200 시리즈의 일부 장치에서 펌웨어 문제가 발생했으며, 현재 해결책을 마련 중임. 영향을 받는 고객은 HP 지원팀에 문의하길 바람.""

HP의 반복적인 펌웨어 문제

     * HP 프린터의 펌웨어 업데이트 문제가 이번이 처음이 아님
     * 2023년 5월에도 OfficeJet 프린터에서 펌웨어 업데이트로 인해 프린터가 멈추고 블루 스크린이 발생한 바 있음
     * HP의 사용자 불만은 주로 다음과 같은 이유에서 발생함:
          + 타사 잉크 사용을 차단하려는 정책
          + 자사 정품 토너 사용 중에도 프린터가 작동하지 않는 문제 발생
     * 한 사용자는 다음과 같이 언급함:

     ""이런 일이 반복되면 HP의 이미지가 더 나빠질 것임. 문제를 인식하고 포럼에 글을 올리는 사람들은 일부에 불과함. 영향을 받는 사용자 수는 훨씬 많을 수 있음.""

다른 프린터 브랜드로의 전환 사례 증가

     * 일부 사용자는 HP의 반복된 문제로 인해 다른 브랜드의 프린터로 전환하고 있음
     * 한 사용자는 HP 포럼에 다음과 같이 작성함:

     ""비슷한 Brother 프린터를 Walmart에서 $144에 구입함. 자동 펌웨어 업데이트가 없고 250매 용지함과 수동 용지 급지기가 포함되어 있음. 첫 페이지 출력이 약간 느리지만 큰 문제는 아님.""
     * 그러나 Brother도 최근 타사 토너 사용 시 인쇄 품질 저하 및 프린터 작동 불능 문제가 발생한 바 있음
          + Brother는 이에 대해 ""타사 토너 사용 차단을 위한 펌웨어 업데이트는 아님""이라고 해명함

   Brother, 서드파티 프린터 잉크 카트리지를 사용 못하게 강제 펌웨어 업데이트

        Hacker News 의견

     * 몇 년간 HP 프린터와 비싼 잉크로 고생한 후, Epson EcoTank을 구입했음. 가격은 더 비쌌지만 인쇄 품질이 훌륭하고 잉크가 오래 지속됨. 포함된 잉크를 다 쓰는 데 2년이 걸렸음
     * HP가 LLM(대규모 언어 모델)이 대부분의 프린터 구매 결정에 관여할 때, 그동안의 문제로 인해 대가를 치르게 될지 궁금함. LLM은 Reddit, HN 등에서 훈련받았을 것임
     * 소비자 ""AI"" 서비스가 브랜드에 대한 유효한 비판을 무력화하는 ""통합 배치""를 제공할지 궁금함
     * 이런 펌웨어 업데이트를 적용하고 싶지 않다면 Linux를 사용하는 것이 좋음. 어떤 프린터 회사도 자동으로 펌웨어 업데이트를 설치하지 않을 것임. 오늘 작동하는 프린터는 내일도 작동할 것임
     * <i>bricks</i>의 의미가 바뀌었는지 궁금함. 이 프린터들이 영구적으로 고장난 것처럼 들리지 않음
     * 오래된 잉크젯이 비싼 카트리지 문제로 많은 문제를 일으켜서, 밤늦게 온라인 상점에서 매우 저렴한 가격에 새로운 세대의 레이저 프린터를 구입했음. 100페이지를 인쇄한 후, ""소개용"" 토너가 일반 토너의 1/2, 대용량의 1/4만 인쇄할 수 있다는 것을 발견하고 후회했음
          + 프린터는 140USD에 좋은 할인을 받았지만, 토너는 전체 세트(1500페이지 버전)에 280USD, XL(3000페이지) 버전에 480USD가 들어서 매우 비쌈
          + 이 레이저 프린터의 인쇄 품질은 과거에 사용했던 대부분의 프린터보다 뛰어나고, 소프트웨어도 원활하게 작동함. 빠르고 잘 인쇄되지만, 고객에게 적대적인 회사가 뒤에 있음
          + 다행히도 기존 토너에서 칩을 추출하여 새로운 일반 토너에 옮기는 기술이 있다고 함. ""terrajet"" 칩이 곧 누군가에 의해 역설계되어 일반 토너를 사용할 수 있기를 바람
          + 참고로, 프린터는 LaserJet Pro 3302FDW이며, 219/219X terrajet 토너를 사용함
     * 몇 년 전부터 HP 제품을 구매하거나 추천하지 않음. 그들의 드라이버 EXE가 300MB로 부풀어 오르고 온갖 잡다한 소프트웨어가 포함되었을 때부터 그랬음
     * 최근 프린터 DRM 펌웨어 업데이트 문제에 대한 논의: Brother가 타사 프린터 잉크 카트리지를 잠그는 것으로 비난받음
     * 오늘날의 업데이트 전략은 무엇인가? 주요 가능성은 1) 빠를수록 더 잘 보호됨. 2) 며칠/몇 주 기다림. 두 번째 쥐가 치즈를 얻음
     * 관련하여, 오픈 소스 2D 프린터를 만드는 것은 비현실적이라는 글을 읽은 기억이 있음. 연구와 매우 구체적인 제조가 필요하기 때문임. 하지만 인기 있는 상업용 프린터 모델에 대한 오픈 소스 대체 메인보드를 설계한다면 어떨까? 펌웨어에 ""비법""이 얼마나 들어 있는지, 독립적으로 복제하기 얼마나 쉬울지 궁금함
     * HP는 항상(Compaq 합병 이후) 비윤리적인 사람들이 회사를 운영해왔음. LaserJet4 이후로 그들의 프린터를 구매하지 않았음. 그러나 25년 전 1천 달러 이상을 지불한 DDS4 테이프 드라이브가 있었음. 보증 기간이 끝난 직후 펌웨어를 업데이트했는데, 카트리지를 로드하거나 꺼낼 때마다 새로운 큰 소리가 나는 것을 즉시 알게 되었음. 며칠 내에 고장났고, HP가 의도적으로 고장냈다고 항상 의심했음. 미디어 플랫폼에 묶여 있어서 그들에게서 재생된 유닛을 또 큰 돈을 주고 구매했음
     * 그 이후로 HP 제품을 구매하지 않았음
"
"https://news.hada.io/topic?id=19667","Show GN: 텍스트 이모지를 간편하고 빠르게 만들 수 있는 정적웹","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Show GN: 텍스트 이모지를 간편하고 빠르게 만들 수 있는 정적웹

   sveltekit으로 만들고
   github pages로 서빙하고 있습니다
   (https://github.com/jujumilk3/text-emoji)

   촌철살인 피드백 감사합니다

   궁금한데요. 이미지로 만들어진 순간부터 이모지가 아니라 이모티콘이나 스티커라고 해야하는 것 아닐가요? 너무 짜치는 부분이라 미리 송구합니다.

   오... 예리한 지적 너무감사드립니다.
   사실 이모지라는 단어에 대해서 깊게 생각해본 적이 없이
   슬랙이나 디스코드에서 쓰는게 이모지였나? 이모지! 해서 그냥 이모지가 됐습니다 ㅋㅋㅋ

   이미지는 이모지로 쳐주지 않나요?

   달아주신 피드백들 모두 적용 완료했습니다 많은 성원 감사드립니다 🫡

   animation 의 duration 을 speed 로 표현해서 어색하게 느껴졌어요.
   speed 라길래 최대속도로 해봐야지 했는데 오히려 느려지길래 읭? 했네요.

   오 그렇네요..! 스피드는 높아지면 빨라진다는 개념인데. 너무 감사합니다!

   유용하게 써먹어 보겠습니다.

   텍스트나 스타일을 바꿔도 Sm/Md/Lg 프리뷰 이미지는 안바뀌어요!

   감사합니다 적용하겠습니다!
"
"https://news.hada.io/topic?id=19666","Luft's Road to Elasticity - Part 1: From Shared Nothing to Shared Storage","                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Luft's Road to Elasticity - Part 1: From Shared Nothing to Shared Storage

     자체 제작 데이터베이스인 Luft의 탄력성(elasticity)을 개선하기 위해, Shared Nothing 아키텍처에서 Shared Storage 아키텍처로 전환한 경험을 공유합니다.

     * 이전에는 각 노드가 독립적인 스토리지를 사용하여 데이터를 처리했으나, 대용량 데이터 처리 시 탄력성이 부족하여 스파이크성 워크로드 대응에 어려움을 겪음.
     * 컴퓨팅 자원과 스토리지를 분리하는 Compute-Storage Separation 개념을 적용하여, 스토리지를 공유하는 Shared Storage 아키텍처로 전환을 결정함.
     * S3에 접근하기 위해 FUSE를 활용하는 방식을 실험했으나, Go 런타임의 특성상 FUSE 사용 시 성능 문제가 발생하여 애플리케이션 레벨에서 Buffer Pool Manager를 자체 구현함.
     * 이러한 개선을 통해 직접 S3로 쿼리가 가능해졌고, 사전에 데이터가 분배되어있지 않은 경우의 쿼리 성능이 최대 70% 이상 향상되어 Luft의 탄력성이 크게 개선됨.

   이거 진짜재미있는거 하셔서 저도 해보고싶네요
"
"https://news.hada.io/topic?id=19629","Anthropic, 기업 가치 90조원으로 평가 받으며 5조원 신규 투자 유치 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Anthropic, 기업 가치 90조원으로 평가 받으며 5조원 신규 투자 유치

     * Anthropic이 기업 가치 $61.5B(90조원) 로 평가됨. 기존 약 $16B 에서 급상승
     * VC Lightspeed의 주도로 $3.5B(5조원) 의 자금 유입되고, 설립 이후 현재까지 총 $14.5B(21조원) 의 자금 조달
          + 주요 투자자: Amazon, Google, Salesforce, Menlo Ventures
     * 주요 AI 스타트업의 투자 현황
          + OpenAI : $40B의 신규 투자 유치 진행 중, 기업 가치 약 $300B(434조원) 로 평가 → 5개월 전보다 거의 2배 상승
          + xAI (Elon Musk) : 신규 투자 유치 논의 중, 기업 가치 약 $40B → 최대 $75B(108조원) 까지 상승 가능성
     * AI 산업의 투자 환경 변화
          + 2022년 말 ChatGPT 출시 이후 AI 스타트업에 대한 투자 붐 시작
          + 2024년 투자 열기 감소
               o 일부 스타트업은 Google 및 Amazon에 인수됨
          + 그러나 OpenAI와 Anthropic의 기술 개선으로 투자자 관심이 다시 증가
     * Anthropic은 CEO Dario Amodei와 사장 Daniela Amodei가 공동 창립
          + 이전에 OpenAI에서 근무 → 기술 개발 및 자금 조달 전략에 대한 의견 차이로 퇴사
               o Claude라는 AI 챗봇 개발 중
     * Dario Amodei의 견해 변화
          + 2023년 인터뷰에서 AI가 인류를 멸망시킬 확률을 **10~25%**로 추정
          + 그러나 2023년 10월, AI의 긍정적 잠재력 강조
          + ""AI의 긍정적 측면과 위험 모두 과소평가되고 있다""고 언급
     * 2023년 11월, Amazon이 40억 달러 투자 → 총 80억 달러 투자
          + Anthropic은 Amazon 및 Google의 데이터 센터에서 AI 시스템 운영 중

   90조원은 좀 무섭네요 ㄷㄷㄷ;;

        Hacker News 의견

     * 기술 회사들이 높은 수익을 내는 경우는 시장 점유율에서 독점적 위치를 차지하거나 Apple의 수직 통합이나 Amazon의 물류 네트워크처럼 비용 측면에서 방어벽을 가진 경우가 많음
     * Anthropic과 OpenAI 같은 여러 LLM 제공업체가 모두 그들의 평가에 부합하는 시나리오는 어떤 모습일지 궁금함
          + Claude가 코드에서 1.1배 더 좋고 OpenAI가 다른 부분에서 1.1배 더 좋다고 해도 충분한 차별화가 되지 않을 것 같음
     * 이러한 거대 평가 중 일부는 나를 불안하게 만듦
          + 내가 지나치게 비관적인 것일 수도 있지만, Anthropic이 충분한 수익을 창출할 가능성은 낮다고 생각함
          + 특히 많은 무료 경쟁자가 있는 세상에서 더욱 그러함
     * 내가 맞다면, 5년 후 주주들이 모두 동의하는 시점이 오기를 기대하지 않음
     * Anthropic의 보도 자료: https://anthropic.com/news/…
     * 많은 의미가 있음
          + 오픈 소스 에이전틱 코더를 작성하면서 Claude가 다른 것들보다 훨씬 뛰어남을 발견함
          + 투자할 수 있으면 좋겠음
     * Claude Code를 사용하고 있으며, 가격이 조금 비싸지만 지금까지 기대를 초과함
     * DeepSeek과 Qwen이 무료인 세상에서 이 평가를 어떻게 정당화할 수 있을지 궁금함
     * Claude가 가장 마음에 듦
     * xAI의 평가 성장을 이끄는 요인이 무엇인지 설명해 줄 수 있는 사람 있음?
     * 1999년처럼 자금을 모으고 있음
"
"https://news.hada.io/topic?id=19716","구글 딥마인드, Gemini Robotics 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      구글 딥마인드, Gemini Robotics 공개

     * Gemini 2.0을 로봇공학에 도입하여 비전-언어-행동(VLA) 모델과 공간을 이해하는 ER 모델을 발표함
     * Google DeepMind는 복잡한 문제를 해결하기 위해 텍스트, 이미지, 오디오, 비디오를 활용한 멀티모달 추론 능력을 발전시켜 왔음
     * 그러나 이러한 능력은 지금까지 디지털 환경에만 국한됨
     * 물리적 세계에서 AI가 유용해지려면 인간처럼 환경을 이해하고 반응하며, 안전하게 작업을 수행하는 ""구체적 추론(embodied reasoning)"" 능력이 필요함
     * 이에 따라 두 가지 새로운 모델 발표
          + Gemini Robotics: Gemini 2.0 기반으로 로봇을 직접 제어할 수 있는 비전-언어-행동(VLA) 모델
          + Gemini Robotics-ER: 향상된 공간 이해력과 로봇 제어 능력을 제공하는 모델
     * Apptronik과 협력해 다음 세대의 인간형 로봇을 개발 중
     * 소수의 신뢰할 수 있는 테스트 사용자와 협력해 모델 성능 개선 중

  Gemini Robotics: 가장 발전된 비전-언어-행동 모델

    1. 일반화 능력(Generality)

     * 새로운 상황에서도 적응하고 다양한 작업을 수행 가능
     * 새로운 사물, 명령 및 환경에서 우수한 성능 발휘
     * 기술 보고서에 따르면, 기존 VLA 모델 대비 일반화 성능이 2배 이상 향상됨

    2. 상호작용 능력(Interactivity)

     * 자연어 명령을 이해하고 반응 가능
     * 다양한 언어 및 일상 언어 명령에 대응
     * 환경 변화에 실시간으로 반응하며 행동 수정 가능
     * 사물이 손에서 미끄러지거나 위치가 바뀌어도 즉시 재계획 후 작업 지속 가능

    3. 손재주(Dexterity)

     * 세밀한 작업 수행 능력 강화
     * 복잡한 다단계 작업 수행 가능 (예: 종이접기, 지퍼백에 간식 담기 등)

    4. 다양한 형태의 로봇 적용 가능(Multiple embodiments)

     * 다양한 로봇 형태에 쉽게 적용 가능
     * ALOHA 2, Franka 기반 로봇 및 인간형 Apollo 로봇에서 작동 확인

  Gemini Robotics-ER: 강화된 공간 이해 능력

     * Gemini 2.0의 공간 인식 및 3D 탐지 성능 대폭 강화
     * 로봇이 사물의 위치를 인식하고 적절한 방식으로 조작 가능
     * 코드 생성 능력 결합 → 로봇이 새로운 작업 방식을 즉석에서 생성 가능
     * 성공률이 Gemini 2.0 대비 2~3배 향상됨
     * 시연 예시: 커피잔의 손잡이를 인식하고 안전한 경로로 접근해 집어 올림

  AI 및 로봇의 안전 강화 전략

     * 로봇의 물리적 안전 문제 해결에 초점
     * 로봇이 충돌 방지, 접촉력 제한, 동적 안정성 유지 등 전통적인 안전 조치 수행
     * Gemini Robotics-ER은 안전이 우려될 경우 작업 수행 여부를 판단하고 적절히 대응
     * 새로운 ASIMOV 데이터셋 출시 → 로봇 행동의 안전성 평가 및 개선 목적
     * 내부 책임 및 안전 위원회와 외부 전문가와 협력해 윤리적 문제 해결

  주요 파트너 및 향후 계획

     * Apptronik과 협력해 인간형 로봇 개발
     * Agile Robots, Agility Robots, Boston Dynamics, Enchanted Tools 등에서 Gemini Robotics-ER 테스트 중
     * 향후 AI와 로봇 기술의 발전을 지속 추진할 계획

  관련 링크

     * 기술 보고서 읽기
     * Gemini Robotics 소개 페이지

        Hacker News 의견

     * YouTube에서 20개의 비디오 데모를 볼 수 있는 전체 재생 목록 링크가 있음
     * 이전에 Google Gemini의 인상적인 데모가 조작된 적이 있었음을 기억하는 사람이 없는지 궁금함
     * 아시모프의 로봇 법칙이 흥미로운 SF 소품이지만 실제 컴퓨팅과는 거리가 멀다고 생각했음
          + 알고 보니 아시모프는 시대를 앞서 LLM 프롬프트를 작성하고 있었음
     * 쓰레기 분류가 더 쉽고 빨라진다면 재활용 효율성을 100배 향상시킬 수 있을 것임
          + 이미 그렇게 하는 곳도 있지만, 로봇이 세상을 개선할 수 있는 단순 작업이 많음
     * 메인 비디오 끝부분에서 로봇이 풀리에 원형 벨트를 끼우는 장면이 인상적이었음
          + 훈련 데이터에 이와 같은 행동이 많겠지만, 셔츠 접기나 물건 분류보다 직관적으로 느껴졌음
          + 페이지에서 비디오 자동 재생/일시정지/스크롤 기능이 고장난 것 같음
     * 실시간 양방향 번역기로 작동하는 장치를 원함
          + 독일어나 다른 언어를 배우는 데 시간을 낭비하지 않고 그곳에서 생활할 수 있으면 좋겠음
          + 영어만으로 음식 주문과 행정 처리를 할 수 있다면 놀라운 일일 것임
     * 누구나 중국에서 로봇 팔을 주문해 차고에 설치하고 LLM처럼 텍스트로 프로그래밍할 수 있게 될 것임
          + 더 큰 생각을 할 때임
     * 비디오가 실제 성능을 나타내는지 마케팅 전략인지 확신할 수 없지만 인상적임
          + Iron Man 1의 로봇 팔을 연상시킴
     * 로봇이 식사를 준비할 수 있을 정도로 능숙해지면, 일자리 시장의 전환점이 될 것임
          + 현재 모델은 그 수준에 도달하지 않았지만, 향후 몇 년간 합성 데이터 생성에 대한 큰 투자가 그 수준에 가까워질지 지켜볼 것임
     * Google의 문제는 광고 사업이 너무 많은 수익을 가져와 다른 제품이 의미가 없다는 것임
          + 로봇을 통해 배운 것을 광고 수익을 높이는 데 사용할 것임
"
"https://news.hada.io/topic?id=19717","NSA 대규모 감시 폭로한 AT&T 내부고발자 마크 클라인 사망","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NSA 대규모 감시 폭로한 AT&T 내부고발자 마크 클라인 사망

     * EFF의 슬픔
          + EFF는 Mark Klein의 사망 소식에 깊은 슬픔을 느끼고 있음
          + Mark는 수백만 미국인의 권리를 침해한 대규모 감시 프로그램을 폭로하기 위해 민사 책임과 형사 기소의 위험을 감수한 진정한 영웅이었음
     * Mark Klein의 배경
          + Mark는 22년 동안 AT&T에서 통신 기술자로 일했으며, 대부분 샌프란시스코에서 근무했음
          + 그는 항상 옳고 그름에 대한 강한 감각과 프라이버시에 대한 헌신을 가지고 있었음
     * NSA의 비밀 감시 프로그램 폭로
          + 2005년 말, 뉴욕 타임즈가 NSA의 미국 내 감시 활동을 보도했을 때, Mark는 자신이 그 과정을 목격했음을 깨달음
          + 그는 NSA가 AT&T 샌프란시스코 중앙 사무소에 비밀 보안실(Room 641A)을 설치했음을 알게 되었음
          + Mark는 인터넷 데이터를 비밀 NSA 방으로 연결하는 광학 ""스플리터""에 회로를 연결하는 임무를 맡았음
     * Mark의 증거와 영향
          + Mark는 AT&T의 인증된 도면과 표가 포함된 100페이지 이상의 문서를 EFF에 제공했음
          + 그는 주요 언론, 의회 직원, 두 명 이상의 상원의원에게 이 정보를 공유했음
          + EFF는 Mark의 증거를 사용하여 NSA 감시에 대한 두 건의 소송을 제기했음
     * Mark의 용기와 유산
          + Mark는 자신과 가족에게 큰 개인적 위험을 감수하고 진실을 밝혔음
          + AT&T는 그를 고소하겠다고 위협했지만, 결국 그렇게 하지 않기로 결정했음
          + 그의 용기는 수많은 미국인들에게 불법적인 대규모 감시 종식을 요구하도록 영감을 주었음
     * 현재와 미래의 싸움
          + Mark가 처음 폭로한 감시를 계속 허용하는 법률인 섹션 702는 2026년 초에 만료됨
          + EFF와 다른 단체들은 계속해서 개혁을 추진하고 불법 감시를 완전히 끝내기 위해 노력할 것임
          + Mark의 유산은 개인 프라이버시 보호를 위한 싸움에서 계속 살아있음

        Hacker News 의견

     * ""Nooooooo! 그는 몇 년 전 내 이웃이었고, 그를 영웅으로 알기 전에 사람으로 알았음""
          + 그의 개들은 집을 매우 보호했음
          + 어느 날 그의 집 뒤에 ""하수구 청소"" 밴이 있었는데, 그게 진짜인지 믿기 어려웠음
     * ""이건 미친 짓임... 여러분은 밴과 작은 이야기들에 집중하고 있지만 그의 희생과 수천 명의 미국인의 희생이 사라졌음""
          + 의회는 FISA 개정법을 통과시켜 NSA 스파이 프로그램에 관여한 통신사들에게 ""소급 면책""을 부여했음
          + 이는 통신 프라이버시를 보호하는 여러 주 및 연방법 위반에 대한 전례 없는 면책임
     * ""관련 있음. 아마도 관련된 다른 스레드들이 있을 것임—누군가 찾을 수 있는지?""
          + Room 641A에 대한 여러 링크가 공유됨
     * ""몇 년 전 EFF에서 상을 받는 것을 볼 수 있는 특권을 가졌음""
          + 그는 도덕적 강인함을 가지고 있었고, 그가 옳다고 생각한 일을 했음
          + 그가 편히 쉬기를 바람
     * ""젠장""
          + 이 운동이 시작된 것인지 모르겠지만, 프라이버시와 대중의 인식에 큰 도움이 되었음
          + Room 641A에 대한 정보 공개 전에는 정부의 스파이 행위에 대한 명확한 증거가 없었음
     * ""그는 스노든과 같은 중대한 불법 감시를 몇 년 전에 폭로했지만, 유명해진 사람은 한 명뿐이었음""
          + 그 이유를 알고 싶음
     * ""R.I.P.""
          + 그는 진정한 용감한 내부고발자였음
          + 그의 문서를 법원 봉인 상태에서 입수하여 Wired에 게시했음
          + 그는 도덕적 나침반을 가진 온화한 사람이었음
     * 여러 링크가 공유됨
          + Mark Klein에 대한 Wikipedia 링크
          + PBS 인터뷰 링크
          + EFF 문서 링크
          + Medium 기사 링크
          + YouTube 영상 링크
     * ""RIP - 진정으로 세상을 더 나은 곳으로 만들려고 했던 사람임""
"
"https://news.hada.io/topic?id=19643","폭스바겐, 주요 기능에 물리 버튼 복귀 결정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        폭스바겐, 주요 기능에 물리 버튼 복귀 결정

     * 폭스바겐은 향후 모든 모델에서 가장 중요한 기능에 물리 버튼을 다시 도입할 계획임
     * 최근 몇 년 동안 폭스바겐은 물리 버튼과 다이얼을 없애고 인포테인먼트 터치스크린으로 기능을 통합해 비판을 받아옴
     * 히터 및 볼륨 조절을 위한 햅틱 슬라이더와 스티어링 휠에 햅틱 패널을 사용하면서 사용자 불만 증가
     * 디자인 총괄 안드레아스 민트(Andreas Mindt)는 다음과 같이 언급함
          + ""ID 2all 모델부터는 다섯 가지 주요 기능(볼륨, 운전석 및 조수석 히터, 팬 속도, 비상등)을 화면 아래에 물리 버튼으로 배치할 것""
          + ""앞으로 모든 폭스바겐 차량에서 물리 버튼이 제공될 것""
          + ""더 이상 이런 실수를 반복하지 않을 것""
          + ""스티어링 휠에도 물리 버튼을 장착해 직관적인 피드백 제공 예정""

  터치스크린은 여전히 유지

     * 새로운 법적 요구사항(미국에서 후방 카메라 장착 의무화 등)에 따라 터치스크린은 여전히 유지될 예정
     * ""많은 기능이 시스템의 심층 메뉴에 포함될 것이나, 다섯 가지 주요 기능은 항상 물리 버튼으로 제공될 것""이라고 설명
     * 사용자 경험 강화와 직관적인 조작 편의성 제공 목표

   테슬라와 반대로 가는군요

   자율주행이 되기전, 전방 주시를 해야되는 상태라면 버튼이 훨씬 맞는 UI라고 생각합니다.

        Hacker News 의견

     * 최근 Tesla를 운전해본 경험이 있는데, 사용자 경험이 매우 불편했음. 방향 지시등의 촉각 피드백이 없어 간단한 차선 변경 후에도 여러 번 왼쪽과 오른쪽을 지시하게 됨. 에어컨과 와이퍼가 터치스크린 뒤에 있어 마치 조종사가 필요한 것 같았음
          + 운전자 보조 기능이 쉽게 속아 무작위로 조향을 수정하거나 급제동을 함. 구형/단순한 차와 비교해 후방 충돌 비율이 더 높을 것 같음
          + 차고에 주차할 때 우리 개를 오토바이로, 다른 차량을 트럭으로 착각해 충돌했다고 판단한 것이 재미있었음
     * Tesla가 시작한 이 모든 것은 그들이 더 잘 안다고 생각하기 때문임. 다른 자동차 제조사들은 초기 판매만 보고 이를 모방하며, 오랜 시간 동안 안전하다고 배운 것을 무시하고 나중에 다시 돌아옴
          + Apple도 ESC 키를 터치바로 대체하거나 USB-C 포트만 있는 노트북을 출시하며 비슷한 실수를 저지름
          + 많은 시간과 자원이 낭비됨. 곧 휴대폰에 탈착식 배터리가 다시 등장할 것이고, 이를 처음 보는 사람들도 있을 것임
          + 회의실에서 노트북을 연결하지 못해 사망한 사람은 없지만, 에어컨을 조작하다가 사슴을 치는 사고로 사망한 사람은 있을 것임
     * 2020 GTI를 2021 모델보다 더 비싸게 샀을 때 이런 일이 올 것이라고 예상했지만, 5년이 걸릴 줄은 몰랐음. 그들이 실수를 인정한 것을 보니 좋음
     * Hyundai가 승리함. 터치스크린 기능을 사용하지만 주로 설정과 구성에 사용하며, 운전 중 기본 제어에는 사용하지 않음
          + 많은 지역에서 운전 중 터치스크린 휴대폰 사용이 불법임. 그런데 왜 제조사들이 내장된 터치스크린 사용을 강제하는 것이 합법적인지 이해가 안 됨. 모순적임
     * 북미에 디젤을 다시 도입해주길 바람
     * 예전에 Saab를 소유했었음. 모든 것이 버튼/노브로 되어 있었고, 아마도 내가 사용/본 최고의 자동차 계기판이었음
     * 다른 자동차 제조사들도 Euro NCAP의 낮은 평가를 피하기 위해 버튼을 다시 도입할 것임
     * 터치스크린 대신 물리적 제어를 원하는 자동차 기능이 떠오르지 않음. GPS 같은 것은 예외일 수 있지만, 그것은 자동차 기능으로 간주하지 않음
     * Ioniq를 구매하지 않은 주된 이유는 어리석은 디스플레이와 버튼이 없었기 때문임. 가격이 더 저렴했다면 구매했겠지만, 예상보다 10% 낮은 가격표를 보고도 더 많은 비용을 지불하고 싶지 않았음
          + 자동차 주행은 마음을 안정시키는 방법임. 이를 방해하면 고객의 호의를 잃게 됨
          + VW의 디젤게이트에 아직도 약간 화가 나지만, 실제 버튼이 다시 등장하면 다시 고려할 것임
     * 2024 VW Jetta GLI를 소유하고 있음. 촉각 스티어링 휠 ""버튼""이 느슨하고 불확실함. 실제 버튼의 복귀를 환영함
          + 적어도 내 GLI는 물리적 볼륨 노브와 물리적 히터 제어 장치를 가지고 있음
"
"https://news.hada.io/topic?id=19685","Youtube가 TV(TVHTML5) 클라이언트를 사용하는 모든 동영상에 DRM 추가중","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Youtube가 TV(TVHTML5) 클라이언트를 사용하는 모든 동영상에 DRM 추가중

     * YouTube가 일부 계정에 대해 TVHTML5 클라이언트에서만 DRM 형식의 비디오를 제공하는 실험을 진행 중
     * 이 문제는 yt-dlp뿐만 아니라 여러 공식 YouTube TV 클라이언트(PS3, 웹 브라우저, Apple TV)에서도 동일하게 발생
     * 문제 재현 방법
          + yt-dlp 명령어에 -vU 플래그를 추가하여 실행하면 문제를 명확히 확인할 수 있음
          + API를 사용하는 경우, YoutubeDL 매개변수에 'verbose': True를 추가해야 함
     * 문제 해결 방법
          + 웹 클라이언트의 형식을 활성화하기 위해 PO 토큰을 제공하거나 TV 클라이언트를 제외해야 함
          + web_safari 및 web_embedded 클라이언트를 사용할 수 있음
     * 커뮤니티 의견
          + DRM 추가는 장기적으로 이상적이지 않으며, 쿠키와 토큰을 사용하는 것은 지속 가능하지 않다는 의견이 있음
          + 일부 사용자는 쿠키와 PO 토큰을 사용하여 문제를 해결했으며, 쿠키는 30일 이상 지속될 수 있음
     * 기타
          + yt-dlp는 다양한 플랫폼에서 사용되며, DRM 문제는 많은 사용자에게 영향을 미칠 수 있음

        Hacker News 의견

     * 기업들이 미디어 시청을 더 불편하게 만드는 것은 놀랍지 않음. DRM을 피하기가 매우 어려워지고 있음
          + 가상의 상황에서 400개 이상의 블루레이 영화와 40개의 시리즈를 소유하고 있음
          + 모든 미디어를 직접 리핑하고 DRM을 제거하여 Jellyfin 서버로 시청 중임
          + 불법 공유는 하지 않으며, 블루레이는 모두 정품임
          + DRM 없는 영화를 구매하는 방법이 거의 없으며, 아마존 같은 곳에서 스트리밍으로 구매해야 함
          + 미디어를 보존하는 유일한 방법이 불법 다운로드인지 궁금함
     * 기술적으로 잘 이해되지 않는 개념들이 많음
          + innertube 클라이언트가 무엇인지 궁금함
          + tv innertube 클라이언트가 무엇인지 궁금함
          + TVHTML5가 무엇인지 궁금함
          + ""DRM 포맷""이 무엇인지 궁금함
          + 이들이 ""사용 가능""하다는 것이 무슨 의미인지 궁금함
          + TV innertube 클라이언트에만 사용 가능하다면 왜 관심을 가져야 하는지 궁금함
     * YouTube가 비디오 다운로드를 막으려는 것 같음
          + Tor를 사용할 때 매일 ""로그인하고 봇이 아님을 증명하라""는 메시지를 받음
          + 광고를 보거나 캡차를 푸는 것은 괜찮지만, YouTube의 방법은 최악임
     * YouTube 앱 사용 시간을 크게 줄였음
          + yt-dlp를 사용해 구독을 다운로드하고 mp3로 변환하여 로컬 네트워크에 팟캐스트 피드를 호스팅 중임
          + 이 방법이 더 이상 작동하지 않으면 여가 시간에 밖에 나가야 할 것 같음
          + 현재는 잘 작동하고 있어 봄까지 계속되기를 바람
     * itag 18과 22, 오디오 트랙이 포함된 MP4 비디오가 사라졌다가 다시 돌아온 것 같음
          + 비디오와 오디오가 분리된 포맷으로 변경되어 ffmpeg를 사용해 오디오 트랙을 병합해야 했음
     * 사람들이 소유하지 않는 것에 만족하기 때문에 현재 상황에 있음
          + 스트리밍은 괜찮지만, 모든 제공자가 합리적인 가격으로 소유할 수 있는 디지털 복사본을 제공해야 함
          + DRM이 없는 파일을 소유하고 어디서든 재생할 수 있어야 함
          + 소유하는 것에 돈을 지불하는 것은 전혀 문제가 없음
     * 이는 매우 나쁜 소식임
          + Google이 고급 전략의 일환으로 이 방향으로 나아가고 있음
          + 기술이 잠기고 닫히는 시대에 접어들고 있음
          + 소비자들이 큰 반발을 하지 않을 것으로 예상됨
          + AI가 최종적인 이유일 수도 있음
          + 데이터 수집가들이 YouTube 비디오에 접근하지 못하게 하기 위해 DRM을 사용해야 함
     * YT가 ""로그인하여 봇이 아님을 확인하라""는 메시지를 보냄
          + 계정이 없는 사람들은 간접적으로 접근할 방법을 찾아야 함
     * 자녀를 위해 웹 기반 YouTube 플레이어를 만들고 있음
          + iframe 임베디드 비디오 재생이 제한될지 궁금함
     * lofi/synthwave 노래를 발견할 수 있는 YouTube 대안을 추천받고 싶음
"
"https://news.hada.io/topic?id=19593","미국의 좌절(demoralization), 이제 시작일 뿐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    미국의 좌절(demoralization), 이제 시작일 뿐

     * 미국과 중국의 주요 무역 파트너 관계는 지난 20년간 크게 변화해 왔음
          + 2000년: 대부분의 국가가 미국을 주요 무역 파트너로 삼고 있었음
          + 2020년: 중국이 전 세계적으로 주요 무역 파트너로 부상하며, 많은 국가가 미국에서 중국으로 이동
          + 특히 중국은 인접한 아시아 지역과 자원 부국인 아프리카에서 영향력이 증가하고, 동유럽 및 일부 중부 유럽 국가도 중국과의 교역이 증가, 브라질 아르헨티나 등도 중국과 긴밀한 경제 관계 형성
     * 80년대에도 일본에 대한 비슷한 공포가 있었던 것으로 알고 있지만, 일본의 인구는 미국의 3분의 1 수준이었음
          + 반면, 중국의 인구는 미국의 3배에 달하며, 미국은 일본에 군사 기지를 보유하고 있었음
          + 따라서 현재 상황은 과거와 다름
     * 미국은 달러를 주요 생산물로 삼아 모든 것을 아웃소싱해 왔음.
          + 이제 미국의 대부분 일자리는 가짜임. 실질적인 생산과 무관한 일자리로 전락함
          + 이는 5명이 땅에 파이프를 꽂는 경제와 유사하며, 그 파이프는 연방준비제도(Fed)를 의미하고, 그 오일은 1870년부터 1970년까지 축적된 선의였음
     * 2008년 구제금융으로 미국은 개혁에 관심이 없음을 드러냈음
          + 그 다음 10년 동안 연방준비제도는 금리를 0으로 유지함
          + 이는 이전에 없던 제로 금리 정책(ZIRP)으로, 비정상적인 왜곡을 초래했음
          + 미국 내 비즈니스는 대부분 사기와 다름없었으며, 시스템 전체를 보면 사기가 사기를 먹여 살리는 구조였음
     * 미국은 '선진국'으로서 실질적인 성장이 끝난 것처럼 보임
          + 총과 보트는 강철로 만들어지며, 비행기는 알루미늄으로 만들어짐
          + 그러나 미국의 철강 생산은 감소하고 있음
          + 알루미늄 생산도 마찬가지로 감소하고 있음
          + 미래는 반도체 칩에 달려 있지만, 고급 칩은 중화민국(대만)에서 제조되고 있음
     * 실리콘 밸리의 현실과 미국의 기로
          + 2021년 기사는 실리콘 밸리에서 본 것들이 왜 말이 안 되는지를 명확하게 설명함
          + 저자는 실리콘 밸리가 성장과 가치 창출을 목표로 한다고 생각했으나, 실제로는 “자기 만족적인 시스템(self-licking ice cream cone)” 과 같은 구조였음
          + 즉, 시스템이 자체적으로 유지되기 위해 돌아가며, 성장이나 가치는 부차적인 요소일 뿐
          + 이를 이해해야만 사람들의 행동이 이해됨
     * 미국의 선택지
          + 제국을 포기하고 보호주의적 지역 강국이 되는 길
               o 과거 유럽이 그랬듯이, 미국도 경제적 보호주의를 강화하면서 세계 패권을 내려놓을 가능성이 있음
               o 영국이 한때 전 세계를 지배했던 것처럼 보이지만, 현재는 인터넷 밈(meme) 때문에 감옥에 가는 수준까지 쇠퇴함
               o 보호주의적인 미국은 사회주의적, 정체된, 박물관 같은 나라가 될 가능성이 큼
          + AI 산업의 국가 통제 신호
               o 나는 과거 인터뷰(Lex Fridman 쇼)에서 NVIDIA의 국유화를 예측했으며, 실제로 AI 확산 프레임워크(AI Diffusion Framework)를 보면 이를 뒷받침하는 움직임이 있음
               o 이 정책은 미국이 GPU 수출을 18개국으로만 제한하는 내용으로, 사실상 미국식 국유화 모델을 의미
               o 결과적으로 나머지 177개국은 AI 인프라를 중국에서 구매하도록 유도됨
     * 미국이 제국의 지위를 유지하려면 경쟁력을 갖춰야 하며, 이를 위한 두 가지 간단한 해결책이 있음
          + 전 세계 인재 유치 (Brain Drain)
               o 노동 비자를 발급하여 소비보다 더 많은 생산을 할 수 있는 사람들을 적극적으로 유치
               o 공장 노동자, 농부, 광부, 엔지니어 등 가치를 창출하는 사람들을 받아들여 미국 인구를 두 배로 늘리는 전략
               o 이를 통해 미국 노동의 가치를 글로벌 시장 가치와 일치시키고, 궁극적으로 미국 평균 IQ를 중국보다 높이는 것이 목표
          + 달러를 금으로 뒷받침 (금본위제 복귀)
               o 달러를 암호화폐 같은 사회적 합의가 아닌 금으로 뒷받침
               o 금융 시스템을 대대적으로 개혁하여 실물 경제와 연계
               o ""거래는 직업이 아니며, 수동적 소득(passive income)도 존재하지 않는다.""
               o 즉, 실제로 무언가를 생산하고, 그것을 금과 교환해야 함
     * 이 전략의 장점
          + 첫 번째 방법(인재 유입)은 미국이 중국에 비해 가지는 독보적인 이점을 극대화하는 전략
               o 미국은 다양한 인재를 유입할 수 있는 열린 시스템을 갖추고 있음
               o 하지만 미국 노동의 시장 가치를 제대로 반영하는 데 대한 강한 저항이 존재
          + 두 번째 방법(금본위제)은 사기를 방지하는 효과가 있음
               o 현재 은행 산업이 거대한 이유는 달러가 실질적인 가치를 보장받지 못하기 때문
               o 만약 화폐가 금으로 뒷받침된다면, 금융권이 아니라 광업 산업(mining industry) 이 성장할 것
               o 광업은 실제로 철강과 알루미늄을 활용해 물리적인 것을 생산하는 실물 경제의 핵심 산업
               o 더 나아가 우주 채굴(space mining) 까지 발전할 가능성이 있음
     * 그러나 실현 가능성은 낮음
          + 이 두 가지 방법은 충분히 실현 가능하지만, 현재 미국은 아직 충분히 '좌절(demoralization)'하지 않았음
          + 즉, 사람들이 경제 시스템의 문제를 충분히 인식하고 개혁을 요구할 정도의 위기가 오지 않았다는 의미
          + 결국, 현재 미국은 변화의 기로에 서 있지만, 실질적인 개혁이 이루어질 가능성은 낮음

   천재들이 조리있게 주장을 전개하지 못하는 경우가 종종 있습니다. 훗날 돌아 보면 귀신같이 결론은 맞을때가 있죠;;;

   이 사람이 그 천재다라고 주장하고 싶으신건가요? 의도를 잘 모르겠네요

   천재는 천재이나, 평소 스타일로 봐서 생각나는 대로 마구 적은글일겁니다. 저런 분야에 전문가도 아닐테구요. 그냥 주변에 머리 좋은 사람이 이런 저런 얘기를 혼잣말 한다고 생각하시면 될듯.

   실물 경제에 집착하고 금본위제같은 상식 수준의 지식까지도 모르는 것 보면 글쎄요...

   미국 빅테크 기업이 세계 경제 다 잡아 먹고 있고
   그렇게 달러를 풀어도 안전자산이라고 강달러가 유지되고 있고
   세계의 브레인은 여전히 미국으로 몰리고 있는데 말이죠 ㅎ
   미국 내부가 썩어서 중산층이 무너지는게 문제일뿐 제국은 무너지지 않는다고 봅니다.

   문제 인식까지는 그럴듯했는데 금본위제를 왜 포기할 수밖에 없었는지에 대한 고찰이 필요하겠네요.

   금본위제를 유지하면 국가는 통화정책을 전혀 쓸 수 없어서 (연금술?) 주기적으로 경제가 나락으로 가고 운이 없으면 붕괴할 수도 있죠.

   맞습니다. 사실 어려운 내용도 아니고 접근이 어려운 정보도 아닌데 인터넷 검색 한 번만 하면 나오는 정보도 모른 채로 당당하게 금본위제로 돌아가자는 주장을 하는 것이 참.. 좀 그렇네요
    1. 현대의 금융 시스템이 사기니 금본위제를 다시 하자 2. 모든 일자리는 의미없다 3. 미국은 더 망해봐야 정신차린다는 얘기를 하는 걸 보면 화풀이로 글 쓴건가 하는 생각마저 듭니다

   금융 시스템의 기반 개념인 신용이라는 것을 이제야 알게 된 사람이 새로운 지식에 놀란 것 같아요.
   시스템의 단점만 눈에 들어오고 모든 것은 사기라는 망상에 빠져 지금 시스템은 잘못됐으니 모두 철폐하고 과거로 회귀해야 한다며 아무렇게나 작성한 푸념인 것 같습니다.

   서두에 비해 결론이 산으로 간것 같습니다.

   그리고 금도 사회적 합의에 의해 가치가 크게 부풀려진 화폐 중 하나죠... 이 사회의 모든 것은 합의와 약속으로 이루어져 있습니다.
   모든 것은 가치를 부여했을 때만 가치가 있다는 점을 모르는 듯 하네요.

   해결책이 좀...

   도메인을 보니 꽤 낯이 익은 이름이 있군요

        Hacker News 의견

     * 금본위제로 돌아가면 화폐 공급이 제한됨. 이는 자본이 줄어들어 경제가 과열될 때 붕괴하고 수축하여 디플레이션이 발생함. 이러한 상황은 경제 위기를 더 길고 어렵게 만듦. 이를 극복하려면 더 큰 재정적 규율이 필요함
     * 미국 ""제국""의 문제는 무역 제국이 작동하려면 계획이 필요하고 이를 고수해야 함
     * 중국은 전략적으로 필요한 국가들을 조용히 부채 함정에 빠뜨리고 있음. 인프라에 투자하고 이를 주최국에 다시 임대하고 있음. 이는 계획, 자금 비전, 시간이 필요함. 대통령이나 의회는 이를 수행할 능력이 없음
     * 미국은 40/50년대에 전쟁 부채와 마셜 플랜을 활용하여 영국 제국의 무역력을 탈취함. 달러는 글로벌 준비 통화가 되었고 모든 새로운 글로벌 기관들이 미국에 설립되고 있음
     * 경제학자나 실제로 경제를 연구하는 사람들의 경제적 견해를 선호함
          + 경제는 제조업 이상임. 제조업 지표로 경제를 평가하는 것은 축구 경기에서 선수들이 얼마나 멀리 뛰었는지로 점수를 매기는 것과 같음
          + 금은 좋은 통화나 통화 정책의 기초가 아님
          + 이러한 아이디어는 경제적 맥락 없이만 일관되게 들림
     * 해결책 1 — 세계의 두뇌 유출 —은 절대적으로 일류 정책임. 미국이 여기서 교육받은 새로 박사 학위를 받은 사람들이 다른 비자를 받거나 떠나야 한다는 사실은 절대적으로 자기 패배적임. 우리는 어디서나 숙련된 이민을 환영해야 함
     * 개인적으로 Krugman, Brad Delong, Michael Pettis를 읽는 것이 더 나음. Geohot는 엔지니어링이나 자율 주행 자동차에 관한 것일 때 읽음
     * Steve Jobs는 오바마에게 비슷한 말을 한 적이 있음. 아이디어는 잘하고 좋은 미국 대학을 졸업한 엔지니어들에게 근로 비자를 제공하는 것이었음. 기본적으로 그들에게 졸업장과 함께 비자를 주는 것임
     * 오바마는 이 아이디어가 흥미롭다고 생각했고 여러 번 고문들에게 언급했음. 그러나 아무런 진전이 없었음
     * 세계의 두뇌 유출은 미국의 성공의 주요 이유 중 하나임. 미국이 이민자의 나라였기 때문에 이를 할 수 있었음
     * 기사와 댓글에는 ""세계의 두뇌 유출""이 공짜 점심이라는 암묵적인 가정이 있음
     * 그러나 그 끝을 생각해 본 사람은 있는가? 가장 똑똑하고 생산적인 사람들을 다른 모든 나라에서 빼앗아 가면, 모든 나라가 덜 부유하고 더 기능 장애가 되어 사회적 쇠퇴, 빈곤, 불만, 급진화, 전쟁 등이 발생함
     * 다른 무엇보다도, 다른 나라들은 좋은 조건으로 무역할 수 있는 능력이 줄어들고, 따라서 미국 제품/서비스를 구매할 수 있는 능력이 줄어듦. 그래서 장기적으로는 자기 패배적인 정책이 됨
     * 좋은 경제학자들은 공짜 점심이 없다는 것을 알고 있음. 우리는 다른 모든 나라가 발전하고 번영할 수 있도록 노력해야 함. 그렇게 하면 우리 나라에서 생산된 제품/서비스의 고객이 더 많이 생기고, 모두가 더 부유해질 수 있음
     * 이 글을 쓰고 나니, 우리가 세계의 많은 경제적, 정치적 기능 장애를 보고 있는 것이 수십 년간의 두뇌 유출의 필연적인 결과인지, 아니면 더 많은 두뇌 유출이 필요하다는 표시인지 궁금해짐
     * 미국이 만드는 주요 제품은 달러이고, 그 제조된 달러를 사용하여 모든 것을 아웃소싱함. 미국의 대부분의 일자리는 이제 기본적으로 가짜임
     * 이 에세이의 맨 위에 있는 두 가지 뜨거운 의견은 저자가 기사에서 말할 수 있는 모든 것을 약화시키고 그들의 사고가 얼마나 진지하고 비판적인지를 의심하게 만듦
     * 이 기사에 반대하는 몇몇 댓글은 중국 경제 문제에 대해 이야기하고 있으며, 오늘 아침 BBC의 이 기사는 중국이 직면한 역학과 문제를 잘 요약하고 있음
     * Lex에서 당신은 Elon을 독재자로 두고 싶다고 말했음. 저녁 식사가 제공됨, 식사를 즐기세요
     * 이러한 종류의 분석의 큰 실수는 그것이 미국의 욕망에만 의존한다고 가정하는 것임. 그러나 다른 나라들도 주체성이 있으며, 그들도 일류 경제가 되기로 결정할 수 있음. 중국의 현재 상태는 위대함을 달성하기 위한 집중 덕분임. 미국이 중국의 성과를 방해할 수 있는 것은 많지 않음. 다른 나라를 막으려 하지 말고 더 열심히 일하도록 노력해야 함
     * 읽기에 부끄러웠음. 제발 경제학 교과서를 읽거나 적어도 경제학자와 대화한 후에 게시하세요
     * 산업 역량이 중요한가? 물론임. 가치 사슬의 정점인가? 아님
     * 그의 해결책:
          + ""두뇌 유출""은 지난 80년 동안 우리가 해왔던 것임. 잘 작동했음. 우리는 지금 사람들을 구체적으로 쫓아내고 있음
          + ""금본위제""는 모든 정상적인 경제학자들이 수십 년 전에 거부한 아이디어임
     * 기술 전문가가 ""소프트웨어가 세상을 먹어치우고 있다""에서 ""금속으로 만들어지지 않으면 가짜다""로 전환하는 것을 보는 것은 놀랍도록 복고풍의 경제적 견해임

   ㅋㅋㅋ 신나서 칼춤추는거 보소

   'This guy spent a few hours trying to ""solve"" covid from ""basic principles"", ran some python on the DNA sequence, and then gave up. None of this is serious.' 라는 Hacker News 의 리플이 궁금해서 찾아보니 https://reddit.com/r/programming/… 정말이군요. 굳이 관심을 줘야 하는 의견인가 싶습니다.
"
"https://news.hada.io/topic?id=19604","ForeverVM - AI 생성 코드를 안전하게 실행하고 유지하는 샌드박스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ForeverVM - AI 생성 코드를 안전하게 실행하고 유지하는 샌드박스

     * 원격 샌드박스에서 임의의 Python 코드를 안전하게 실행하고 결과를 반환하는 코드 실행 API
     * 일반적인 코드 인터프리터와 달리 세션 개념이 없어 상태가 만료되지 않음
     * 샌드박스가 유휴 상태일 때 메모리 스냅샷을 저장하고, 필요할 때 다시 복원하여 효율적인 자원 사용

어떻게 작동하는가?

    1. ForeverVM 머신을 생성하면 REPL (Read-Eval-Print Loop) 인터페이스를 통해 상호작용 가능
    2. 머신이 활성 상태일 때, 가용한 워커(worker)에 할당됨
    3. 샌드박스가 유휴 상태가 되면 메모리 스냅샷이 저장되고, 워커에서 분리됨
    4. 유휴 상태에서는 스토리지 공간만 차지하며, 컴퓨팅 및 메모리 자원을 사용하지 않음
    5. 다시 실행 명령을 받으면 저장된 상태에서 복원되어 새로운 워커에 할당됨.

     * 이러한 과정은 API 사용자에게 투명하게 처리되며, ForeverVM은 항상 실행 가능한 REPL처럼 동작함

Claude Desktop, Goose 등과 연동 가능

     * ForeverVM은 Model Context Protocol (MCP) 서버로 사용 가능
     * 이를 통해 Claude Desktop 및 기타 MCP 클라이언트에서 ForeverVM을 도구로 추가할 수 있음

   Anthropic, Model Context Protocol 오픈소스로 공개
"
"https://news.hada.io/topic?id=19657","Apple의 '더 개인화된 Siri' 출시 내년으로 연기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Apple의 '더 개인화된 Siri' 출시 내년으로 연기

     * 애플 대변인 Jacqueline Roy의 공식 성명:
          + Siri는 사용자들이 필요한 정보를 빠르게 찾고 작업을 수행하도록 돕고 있음
          + 지난 6개월 동안 Siri에 대화형 기능을 추가하고, '타이핑으로 Siri' 및 제품 지식 기능을 도입했으며 ChatGPT와의 통합을 구현함
          + 더 개인화된 Siri를 통해 사용자의 개인 정보를 인식하고 앱 간 작업을 수행할 수 있도록 개선 중
          + 예상보다 시간이 더 걸릴 것으로 보이며, 관련 기능은 내년에 출시할 예정임
     * 애플이 언급한 ""내년""은 2025년 WWDC에서 발표될 iOS 19 및 MacOS 16 사이클을 의미함
          + 애플의 OS 제품 주기는 WWDC에서 시작됨
          + 애플은 미래 제품에 대해 공개적으로 언급하지 않는 정책을 고수하고 있음
          + 그러나 Siri의 개인화 기능은 애플 인텔리전스(Apple Intelligence)에서 중요한 부분이므로 명확한 기대치를 설정하려는 것으로 보임
     * iOS 18.4/MacOS 15.4에서는 개인화 Siri 기능 제외 예상
          + 현재 개발자 베타에 개인화 Siri 기능이 포함되지 않음
          + 만약 iOS 18.5 또는 18.6에서 제공할 계획이었다면 발표가 필요하지 않았을 것
          + 따라서 실제 출시 시기는 iOS 19 및 MacOS 16으로 넘어갈 가능성이 높음
     * Siri의 개인화 기능의 핵심 내용
          + 앱 인텐트(App Intents) 기능 강화:
               o Siri가 사용자의 개인 정보에 접근하고 이해하는 능력 향상
               o 사용자의 이메일, 메시지, 일정 등에서 정보를 추출하고 실행 가능
          + 예시:
               o ""Jamie가 추천한 팟캐스트 재생해줘"" → Siri가 추천된 팟캐스트를 찾아 실행
               o ""엄마 비행기 언제 도착해?"" → 이메일이나 메시지에서 비행기 정보를 찾아 실시간 상태 확인 후 정확한 도착 시간 제공
               o Siri가 정확한 정보를 제공하지 못하면 사용자에게 큰 불편 초래 가능
     * 애플은 보통 제품 지연을 공식 발표하지 않음
          + 과거 제품 출시 지연 사례:
               o 화이트 아이폰 4: 2010년 6월 출시 예정 → 2011년 4월까지 연기 (약 10개월 지연)
               o 에어팟: 2016년 10월 출시 예정 → 12월로 지연
          + 애플의 입장:
               o ""완벽하게 준비되지 않은 제품은 출시하지 않는다""
               o 특히 LLM(대규모 언어 모델)이 개인 정보에 접근하는 경우, 완성도가 더 중요함
     * 지연의 근본 원인 및 영향
          + 애플 인텔리전스는 다른 애플 제품 대비 상대적으로 빠르게 공개됨
               o AI/LLM 열풍으로 인한 시장 및 투자자 압박 영향
               o Siri의 개인화 기능은 복잡하고 민감한 개인 정보와 관련되기 때문에 신중함이 필요함
          + 이번 발표는 실망스럽지만 예상 가능한 일이었음
               o 사용자 신뢰를 잃는 것보다 늦더라도 완성된 상태에서 출시하는 것이 더 중요함

   해당 기능이 포함된 광고를 삭제했네요.
   https://9to5mac.com/2025/03/…

   이 지연에 관해서 Simon Willison은 ""프롬프트 인젝션"" 관련한 보안 문제가 있어서라고 이야기 하네요
   https://simonwillison.net/2025/Mar/8/delaying-personalized-siri/
"
"https://news.hada.io/topic?id=19649","전문가 머릿속에서는 대체 무슨 일이 벌어지고 있을까","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      전문가 머릿속에서는 대체 무슨 일이 벌어지고 있을까

개요

     * 미국의 심리학자 개리 클라인은 소방관, 응급실 간호사, 비행기 조종사 등 급박한 현장에서 전문성을 발휘해야 하는 사람들을 수십년간 연구한 '전문성 전문가'임
     * 클라인은 전문가들에 대한 심층 인터뷰와 관찰을 통해, 문제 상황을 만났을 때 그들의 머릿속에서 무슨 일이 벌어지는지를 인식-행동 촉발 모델(RPD: Reconition-Primed Decision Model)로 추상화함. 수십년간 여러 연구에서 실제로 다양한 분야의 전문가들이 이렇게 행동하고 있음이 밝혀짐
     * RPD 모델을 응용하면 전문가에게, LLM에게 잘 배울 수 있음

RPD 모델의 5단계

   (RPD 도식은 원 블로그에 있습니다)
    1. 전문가가 문제 상황을 경험한다.
    2. 상황 속의 신호 몇 가지에 집중해 과거 경험과 패턴 매칭해본다.
    3. 매칭이 잘 되면 행동 전략(무엇을 목표로 어떤 행동을 해야 할지, 행동 결과가 어떻게 될지)이 대략 떠오른다. 잘 떠오르지 않으면 추가 정보를 수집하고, 다른 신호도 보면서 다시 매칭.
    4. 떠오른 행동 전략을 머릿속으로 시뮬레이션을 돌린다. 이걸로 문제 해결이 될까? 안 될 것 같으면 다음 행동 전략으로 넘어가 시뮬레이션을 돌린다.
    5. 이건 되겠다 싶은 게 있으면 이행한다. 그러면 상황이 바뀌고, 1로 돌아간다.

   이는 우리가 전문성을 높이기 위해 전문가에게 뭘 배워야 하는지를 시사해주기도 함
     * 전문가가 문제 상황 인식을 위해 어떤 신호들을 어떤 순서로 관찰하나?
     * 특정 상황에서 문제 해결을 위해 어떤 행동 전략부터 사용하나?
     * 다른 게 아니라 그걸 선택한 이유는? 시뮬레이션 어떻게 했지?

주니어로서 코드 리뷰에서 배우기

   ""변수명 XX가 너무 짧네요. 변수명은 이해할 수 있을 정도로 긴 게 좋습니다. YY로 바꿀까요?"" 같은 코멘트를 받았다면, '넵' 하는 대신 RPD를 적용해 시니어를 괴롭혀보자
     * 혹시 변수명이 짧아도 괜찮은 상황은 없을까요?
          + 그럼 여기서는 변수명이 너무 짧다는 걸 어떻게 판단하셨어요?
     * 변수명 XX를 그대로 가져간다면 이후 어떤 문제가 생길 것 같으신가요?
     * YY라는 변수명은 어떻게 떠올리셨어요?
     * 나중에 YY가 부적절해질 만한 상황이 있다면 뭘까요?
          + 그땐 변수명을 어떻게 바꾸실 것 같으세요?

   괴롭혀도 불평 않는 LLM에게 하기에도 좋은 질문이고, '이런 피드백을 받았는데 RPD를 이용해 이런 질문을 제안해달라'고 해도 좋음

추가 자료들

     * 의심하는 대신 판단 기준을 알려주세요: RPD를 염두에 두며 시니어가 주니어를 성장시키려면 어떤 대화를 해야 할지에 대해 쓴 글
     * 어떻게 그 판단을 할 수 있었을까: 문제를 보자마자 원인을 파악했던 디버깅 사례에서 제가 어떻게 그럴 수 있었는지 쓴 글. 여기서 다루는 CDM(Critical Decision Method) 또한 전문가의 머릿속을 탐구하기 위해 개리 클라인이 개발한 질문법임
     * The RPD Model: Criticisms and Confusions: RPD 모델 발표 이후 받은 비판과, RPD에 대한 오해들에 대해 개리 클라인이 2021년에 직접 반박한 글
     * Source of Power: How People Make Decisions: RPD에 대해 더 자세한 설명이 담긴 개리 클라인의 1999년 책

LLM 활용하기

   LLM이 개리 클라인의 입장에서, RPD와 CDM(Critical Decision Method)을 활용해 좋은 질문을 구성해주는 프롬프트 템플릿을 만듦. 테스트해보니 질문 품질이 상당히 괜찮음

   물론 현실에서는 시니어가 리뷰해줬을 때 ""잠시만요"" 하면서 LLM에게 물어보고 질문하기는 어려울 것. 그러니 장기적으로는 LLM이 생성해주는 질문들을 체화하여 스스로 생성해낼 수 있는 사람으로 성장하는 게 더 유리함

   재밌었습니다.

   재밌는 탐색이네요 잘 읽었습니다

   책, 탤런트 코드에서 말하는 심층연습의 하나의 구체적인 방법이 되겠네요. 좋은글 감사합니다.

   오 네 맞습니다. 심층연습에 관심이 생기셨다면 그 개념의 원작자(?)인 안데르스 에릭손의 <1만 시간의 재발견>도 아주 좋습니다.

   글도 좋지만, 이러한 것에 관심 갖고 배우시는 모습도 멋진 것 같습니다.

   감사합니다. 오랫동안 검증된 연구를 공부해서 AI에 접목하는 게 재밌더군요.

   흥미로운주제네요 잘읽었습니다

   감사합니다 ㅎㅎ
"
"https://news.hada.io/topic?id=19669","Apple Exclaves에 관하여","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Apple Exclaves에 관하여

모놀리식 운영체제 커널의 문제점

     * 현대 운영 체제는 일반적으로 두 가지 주요 보호 도메인으로 나뉨:
          + 비특권 도메인(유저 모드): 프로그램이 파일 액세스, 네트워크 통신 등 강력한 작업을 직접 수행할 수 없음
          + 특권 도메인(커널 모드): 시스템 호출을 통해 프로그램이 커널에 작업 수행을 요청하면, 커널 코드가 해당 작업을 수행 후 유저 모드에 결과 반환
     * 대부분의 운영 체제는 모놀리식 커널 설계를 사용함:
          + 커널이 시스템의 모든 하드웨어, 메모리, 사용자 데이터에 대한 무제한 액세스 권한 보유
          + 소프트웨어에 결함이 없고 보안 침해 시도가 없다면 괜찮겠지만, 실제로는 버그와 보안 취약점이 존재함
          + 모놀리식 커널의 크기가 크기 때문에 보안 취약점이 발생할 가능성이 높고, 하나의 취약점이 전체 시스템 손상으로 이어질 위험 존재
     * 마이크로커널 설계는 보안을 강화하기 위해 커널에서 대부분의 기능을 제거하고, 별도의 비특권 프로세스로 처리함:
          + 보안 강화 가능
          + 성능 저하 및 애플리케이션 소프트웨어 복잡성 증가 문제 발생 가능
          + 그럼에도 불구하고 성능상의 장점 때문에 모놀리식 커널이 여전히 널리 사용됨
     * 애플의 XNU 커널:
          + iOS, macOS, tvOS, visionOS, watchOS에서 공통으로 사용되는 커널
          + Mach 기반 마이크로커널이지만, 대부분의 시스템 기능이 동일한 특권 범위에서 실행되기 때문에 사실상 모놀리식 커널처럼 작동함
          + 따라서 모놀리식 커널과 동일한 보안 취약점이 발생 가능함

격리 노력

     * 소프트웨어 및 하드웨어 기반 격리 기술 도입이 다양하게 시도됨 :
          + Microsoft Virtualisation-based Security (VBS) – Windows의 Credential Guard에서 사용됨
          + Intel Software Guard Extension (SGX) 및 VT-X2
          + ARM TrustZone – Samsung Knox, Samsung Pay, Android Verified Boot, Android 보안 PIN 입력 등에서 사용됨

애플도 커널에서 데이터를 분리하려는 시도를 점차 확대해 왔음

     * 2013 — Apple Secure Enclave
          + 2013년 iPhone 5s에서 최초 도입
          + Secure Enclave는 독립된 강화된 CPU 코어에서 실행되며, 마이크로커널 기반 OS인 SepOS에서 동작
               o SepOS의 커널은 애플의 커스텀 L4 임베디드 마이크로커널인 cL4 사용
               o 암호화 키 및 생체 정보(예: Face ID)와 같은 민감한 데이터를 저장하고 보호
               o iOS 커널에서 독립적으로 동작하며 보안된 상호작용을 통해서만 iOS에 서비스 제공
               o iOS 커널이 침해되더라도 추가적인 익스플로잇이 발생하지 않는 한 Secure Enclave는 영향을 받지 않음
          + Secure Enclave와 Secure Exclave는 다른 개념임에 주의
     * 2017 — 페이지 보호 레이어 (Page Protection Layer, PPL)
          + iPhone 8 및 iPhone X의 A11 프로세서에서 도입된 보안 기능
          + 하드웨어 + 소프트웨어 기반 기능으로, 커널의 특정 부분에만 메모리 페이지 테이블 수정 권한 부여
               o 나머지 커널은 페이지 테이블 수정 권한이 제한됨
               o 공격 표면이 작아져 우회 시도가 드물어짐
          + PPL은 보호 레이어를 추가했지만, 여전히 커널의 대부분의 권한은 유지되어 완전한 보안 강화에는 한계가 있었음
     * 2021–2023 — 보안 페이지 테이블 모니터 (Secure Page Table Monitor, SPTM)
          + iPhone 13의 A15 프로세서 및 iOS 17에서 도입된 새로운 기능
          + PPL을 대체하고 추가적인 메모리 기능을 보호하며, 이를 여러 하위 시스템으로 분리
          + 코드 서명 검증 및 애플에 의해 서명된 코드만 실행되도록 보안 강화
          + 이 시기에 XNU 소스 코드에서 exclave에 대한 간접적인 언급 등장
               o SPTM이 관리하는 하위 시스템이 exclave일 가능성 제기됨
     * 2024 — 엑스클레이브: XNU의 주요 보안 모델 개편
          + M4 및 A18 프로세서를 지원하는 XNU 소스 코드에서 엑스클레이브 개념 등장
          + 이전 프로세서에서는 엑스클레이브가 활성화되지 않음
          + 엑스클레이브는 XNU의 보안 모델을 대대적으로 재설계한 결과물임이 명확해짐
     * XNU 엑스클레이브

     면책 사항: 엑스클레이브의 내부 구조는 완전히 오픈소스가 아니므로 일부 내용은 추측이나 해석일 수 있음
          + 엑스클레이브는 XNU의 기존 모놀리식 커널 보안 모델을 대폭 강화한 새로운 기능 집합
          + 엑스클레이브는 XNU에서 격리된 자원으로, 커널이 손상되더라도 보호됨
          + 엑스클레이브의 특성:
               o OS 빌드 시 미리 정의됨
               o 이름 또는 ID로 식별됨
               o 다양한 유형으로 구성됨
               o 부팅 시 초기화됨
               o 독립된 도메인으로 조직화됨
               o SPTM이 새로운 엑스클레이브 전용 페이지 타입으로 엑스클레이브 메모리 보호
          + 엑스클레이브 자원 유형
               o 공유 메모리 버퍼 – 커널과 엑스클레이브에서 모두 접근 가능
                    # XNU에서 읽기 전용 또는 읽기/쓰기 설정 가능
               o 오디오 버퍼 및 센서 – 카메라 및 마이크 접근 표시 보안 강화
               o Conclave – 여러 자원을 자체 보안 도메인으로 그룹화하며, 이를 관리하는 Conclave Manager 존재
               o 서비스 – XNU의 스레드가 호출할 때 엑스클레이브에서 코드 실행
     * 보안 커널 — seL4 기반?
          + 엑스클레이브 서비스가 XNU에서 독립적으로 실행되기 위해 새로운 커널 Secure Kernel (SK) 도입
          + SK 이미지 파일에서 ""cL4"" 버전 문자열 확인됨
          + SK는 애플의 기존 cL4 (L4 기반) 커널이 아닌 seL4 기반일 가능성이 높음
               o XNU가 SK와 통신 시 사용하는 IPC 구조가 seL4의 구조와 유사
               o SK에서 사용되는 문자열에서 seL4에서 사용하는 개념(예: capabilities, frames, untyped memory 등) 다수 발견됨
          + 애플이 2024년 4월 seL4 Foundation에 합류한 것은 우연이 아닐 수 있음
               o C1 프로세서(애플의 새로운 베이스밴드 칩)의 커널도 L4 기반으로 보임
     * 보안 월드 — ARM TrustZone?
          + SepOS는 별도의 프로세서에서 실행되며, SK는 고속 애플리케이션 프로세서에서 실행됨
          + 이를 위해 추가적인 프로세서 특권 수준 필요 → 다음 중 하나로 구현될 가능성 존재:
               o 가상화 확장 지원
               o 애플의 SPTM 확장
               o ARM TrustZone 기술 활용 가능성이 가장 높음
          + TrustZone 구조
               o 시스템을 두 개의 월드로 분리:
                    # Secure World – 보안 코드 실행
                    # Insecure World – 일반 코드 실행 (XNU 및 iOS 실행)
               o XNU 소스 코드에서 TrustZone의 Secure World 및 Insecure World 간 전환에 대한 언급 다수 발견
                    # 애플은 TrustZone에서 제안하는 Trusted Application 모델 대신 엑스클레이브 서비스 모델 적용
               o SK는 격리된 환경에서 엑스클레이브 서비스 및 자원을 제공 → 보안 강화
                    # Secure World에서 Insecure World로 탈출해 XNU를 침해하기는 매우 어려울 것으로 예상
          + RINGGATE
               o 애플이 SPTM을 사용해 Secure World ↔ Insecure World 전환 관리 가능성 존재
               o 코드에서 이 전환이 **""RINGGATE""**로 언급됨

결론

     * 엑스클레이브 도입의 의미
          + 고급 위협 행위자들의 지속적인 공격에 대응하기 위해 애플은 엑스클레이브를 도입해 운영 체제의 보안 수준을 강화
          + 민감한 리소스를 격리함으로써 다음과 같은 효과 기대:
               o 공격 표면 축소
               o 단일 커널 취약점의 영향 감소
     * 모놀리식 커널 방어는 끝없는 도전이며, 엑스클레이브는 이를 해결하기 위한 하나의 접근 방식
          + 장기적으로 옳은 방향인지, 혹은 임시 방편인지 불확실
          + 개인적인 희망 → 미래에 CHERI 및 ARM Morello 기반 재설계 기대 😊
          + 그러나 현재로서는 소비자 기기 제조업체 중 가장 큰 방어 시도
     * 이 글에서는 구체적으로 어떤 컴포넌트가 엑스클레이브로 이동되었는지 명확히 다루지는 않았음
          + 빌드 이미지를 통해 다음과 같은 요소가 엑스클레이브에서 실행되는 것으로 보임:
               o 보안 카메라/마이크 표시기
               o Apple Neural Engine(ANE) 기능 일부
               o 일부 디바이스 드라이버
               o Secure Enclave와의 통신 컴포넌트
     * 앞으로 더 많은 컴포넌트가 엑스클레이브로 이전될 가능성 존재
          + 엑스클레이브의 보안 효과는 이러한 이전 작업의 최적화 수준에 달려 있음
     * 엑스클레이브가 Apple Private Cloud Compute 인프라에서 사용될 가능성 있음
          + 클라우드 기반 AI에서 높은 수준의 보안 및 프라이버시 보장 가능

        Hacker News 의견

     * Apple의 최신 SoC는 중첩 가상화를 지원하며, M4 iPad Pro에서는 카메라 LED를 위한 exclave가 사용됨
          + Apple Platform Security 가이드의 다음 개정판에서 SK exclave와 Wi-Fi 레이더 감지를 위한 기지국 완화에 대해 다루기를 희망함
     * SPTM에 대한 Apple의 특정 추가 사항이 있음
          + XNU는 마이크로 커널 영감을 받은 아키텍처로 리팩토링 중이며, 코드 베이스를 줄이고 보안 민감 작업을 분리하려고 함
          + 메모리 공간 격리는 Secure Page Table Monitor(SPTM)의 도움으로 수행됨
          + 코드 서명, 권한 검증, 개발자 모드, 제한 실행 모드 등 보안 민감 작업은 Trusted eXecution Monitor(TXM)에 의해 처리됨
     * ARM의 TrustZone 기술을 통해 수행될 가능성이 높음
          + XNU 소스 코드에는 TrustZone의 보안 세계 개념으로의 전환에 대한 여러 참조가 포함됨
          + 150개 이상의 TrustZone CVE가 존재함
     * Google은 몇 년 전 Pixel에 하드웨어 중첩 가상화를 사용하여 pKVM을 구현하고, 코드를 Linux 메인라인에 업스트림함
          + 그러나 Debian ""Linux Terminal"" VM 외에는 pKVM/AVF를 사용하는 방어 기능을 발표하지 않음
     * Steve는 노트북이 일기장이라고 믿었으며, 이에 대한 책임이 있다고 생각했음
          + Tim이 Steve의 신념을 공유하지 않았다면 CEO가 되지 않았을 것임
          + Steve가 그립다는 의견이 있음
     * Apple은 XNU 커널을 exclave로 재구성함
          + 이 글의 작성자는 매우 정교하고 잘 작성된 글을 썼음
          + exclave를 따라온 사람으로서 잘 작성되었다고 생각함
     * 이 수준의 지식에 익숙하지 않지만, enclave 자체를 공격하여 커널보다 높은 권한을 획득할 수 있는지 궁금함
          + 이 하드웨어가 공동 프로세서와 같은 것인지 궁금함
     * macOS 보안에 미칠 영향이 궁금함
          + Apple 문서에 따르면 SPTM이 사용되지 않음
          + 현재 카메라 표시기를 표시하는 exclave는 macOS에 적용되지 않지만, 미래에는 적용될 수 있음
     * Apple은 그들의 ""플랜테이션""을 보호하는 데 뛰어남
          + 그러나 그들로부터 자신을 보호하는 것은 무엇인지 궁금함
          + ""마지막 geohot""의 가능성을 생각해본 적이 있는지 물음
     * Apple이 SPTM을 사용하여 보안 세계와 비보안 세계 간의 전환을 관리할 수 있음
          + TrustZone이 없기 때문임
"
"https://news.hada.io/topic?id=19644","Kagi의 Orion 웹 브라우저, Linux로 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Kagi의 Orion 웹 브라우저, Linux로 출시

     * 유료, 개인 검색 엔진 Kagi가 WebKit 기반의 Orion 웹 브라우저를 Linux로 출시할 것이라고 발표
     * 현재 Orion은 macOS와 iOS에서만 사용 가능하며, Apple의 Safari보다 우수하고 Google Chrome, Mozilla Firefox 등 다른 브라우저보다 여러 면에서 뛰어남
     * Orion은 제로 텔레메트리 브라우저로, 내장 광고 및 추적 차단 기능을 갖추고 있으며, Apple 기기에서 다른 브라우저보다 메모리 사용량이 적고 페이지 속도가 빠르며 배터리 효율이 높음
     * Chrome과 Firefox 확장 프로그램을 지원함
     * Linux용 Orion 브라우저
          + Orion의 현재 비공개 소스 특성은 모든 사용자에게 호감을 주지 않을 수 있음
          + 많은 Linux 사용자는 Steam, Spotify, Vivaldi, Slack, Discord, Google Chrome, WhatsApp 등 비자유 소프트웨어를 사용하지 않음
          + 그러나 빠르고 사용자 친화적이며 유연한 WebKit 기반 웹 브라우저를 Linux에서 실행할 수 있는 가능성은 선택의 폭을 넓히는 유망한 발전임
          + Kagi는 Orion에 사용되는 많은 구성 요소를 오픈 소스로 전환하기 시작했으며, 더 많은 부분을 오픈 소스로 전환할 계획임

   사파리 느낌을 유지하고 있어서 개인적으로 좋네요

        Hacker News 의견

     * Kagi 검색을 좋아하고 있으며, Orion이 Apple 외의 플랫폼에서도 사용 가능해지기를 기대하고 있음
          + Kagi가 검색에 집중하기보다 브라우저 사업으로 확장하는 것이 우려됨
          + 모든 것을 동시에 시도하는 회사는 원래 제품에 집중하지 못할 수 있음
          + 소프트웨어에 돈을 지불하는 문화가 다시 돌아오기를 바람
     * Kagi는 온라인 생활에 큰 가치를 더해줌
          + Kagi의 최상위 플랜을 통해 최신 LLM 모델과 맞춤형 검색 엔진을 사용할 수 있음
          + Orion 브라우저는 iOS에서 가장 좋아하는 브라우저임
          + 데스크톱 버전은 웹킷 기반이라 사용할지 확신이 없음
     * macOS용 Orion은 아직 버그가 많고 기본 브라우저로 사용하기엔 불편함
          + 사용하고 싶고 월 $5를 지불하고 싶지만 아직 완벽하지 않음
     * Kagi는 멋지지만 유럽에 거주 중이며 미국 기반 서비스에서 벗어나고 있음
          + 좋은 유럽 대안을 찾고 있음
     * Mac에서 Orion을 조금 사용 중임
          + Ublock Origin을 지원하지 않는 것이 걸림돌임
          + 내장된 광고 차단 기능이 90% 정도 필요를 충족한다고 주장하지만, 페이지 요소를 제거하고 싶음
     * Kagi 검색을 몇 년간 만족스럽게 사용 중이지만, 여러 방향으로 확장하지 않기를 바람
          + Kagi 번역과 이메일 서비스도 언급되었음
          + Kagi 검색이 잘 작동하기 때문에 다른 제품은 피하고 있음
     * Orion 브라우저의 Linux 개발이 공식적으로 시작되었음을 발표함
          + 개발 연도 동안 뉴스와 초기 접근 기회를 받기 위해 등록할 수 있음
     * Kagi는 여전히 버그가 많음
          + 텍스트 선택이 불안정하며, 특히 비영어 웹사이트와 복잡한 레이아웃에서 문제가 발생함
     * Android용 Webkit 기반 브라우저가 있기를 바람
          + Firefox와 Chrome 기반 브라우저는 많지만 다른 것은 없음
     * Orion은 실망스러웠음
          + 여러 번 전환을 시도했지만 자동 완성 기능이 일관되게 작동하지 않아 포기하게 됨

   개인 정보 보호를 장점으로 삼는 브라우저가 더 많아져서 모질라가 위기감을 좀 느꼈으면 좋겠네요.
"
"https://news.hada.io/topic?id=19700","확률적 인공지능 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              확률적 인공지능 기술

확률적 인공지능

     * 인공지능은 인간의 지능이 요구되는 작업을 수행할 수 있는 인공 시스템의 과학과 공학을 의미함. 최근 몇 년간 학습 기반의 데이터 중심 접근 방식에서 흥미로운 발전이 있었으며, 머신러닝과 딥러닝은 컴퓨터 시스템이 세상을 인식하는 새로운 방식을 가능하게 했음. 강화 학습은 바둑과 같은 복잡한 게임과 로봇 공학 과제에서 돌파구를 마련했음.
     * 지능의 핵심 측면은 예측을 할 뿐만 아니라 이러한 예측의 불확실성을 이해하고, 결정을 내릴 때 이 불확실성을 고려하는 것임. 이 논문은 ""확률적 인공지능""에 관한 것임.

  확률적 접근 방식

     * 첫 번째 부분에서는 머신러닝에 대한 확률적 접근 방식을 다루고 있음. 데이터 부족으로 인한 ""인식적"" 불확실성과, 예를 들어 소음이 있는 관찰과 결과에서 비롯되는 ""우연적"" 불확실성의 차이를 논의함. 확률적 추론에 대한 구체적인 접근 방식과 효율적인 근사 추론에 대한 현대적 접근 방식을 논의함.

  순차적 결정 작업에서의 불확실성 고려

     * 두 번째 부분에서는 순차적 결정 작업에서 불확실성을 고려하는 것에 대해 다루고 있음. 능동 학습과 베이지안 최적화를 고려하며, 이는 인식적 불확실성을 줄이기 위해 정보를 제공하는 실험을 제안하여 데이터를 수집하는 접근 방식임. 강화 학습과 신경망 함수 근사를 사용하는 현대적 딥 RL 접근 방식을 고려함. 모델 기반 RL의 현대적 접근 방식을 논의하며, 이는 탐색을 안내하기 위해 인식적 및 우연적 불확실성을 활용하고 안전성을 고려함.

        Hacker News 의견

     * 텍스트에는 훌륭한 설명 다이어그램이 있으며, 확률의 관점에서 머신러닝을 고품질로 개관한 것 같음
          + 최근에 Zhao의 ""Mathematical Foundation of Reinforcement Learning""이라는 무료 교과서와 유튜브 강의에 깊은 인상을 받았음
          + 시간이 많지 않다면, Zhao의 개요 내용 다이어그램을 한 번 훑어보는 것이 좋음. 이는 전체 분야의 좋은 개념적 지도임
          + 그리고 소개 영상을 보는 것도 추천함
     * 며칠 전에 이 자료를 발견했으며, Andreas Krause가 Gaussian Processes와 Bandits에 대해 깊고 흥미로운 연구를 했다는 이유로 진지하게 살펴볼 핑계를 찾았음
     * 실존적 현실은 상태의 배열이 아닌 잠재적 분포임
          + 잠재력은 존재하며, 확률은 그 분포의 수학적 설명임. 모든 속성은 차원(벡터)임
          + 상태는 단지 해결의 순간적 측정임. 잠재력은 건설적 및 파괴적 간섭을 통해 상호작용함
          + 건설적 및 파괴적 간섭은 순간적 측정의 ""지금""이라는 상태로 해결됨
     * LLM(즉, 신경망)이 방금 내뱉은 답변의 확률을 말해줄 수 있는지에 대한 질문
          + 오래 전 대학에서 이러한 것들을 공부했으며, 각 용어에 대해 확률과 신뢰도 계수를 가진 Prolog 해석기를 만들었음
     * 모델의 해석 가능성을 민주화하고 게이머들도 탐색할 수 있도록 GUI가 필요하다고 생각함
          + 기본적으로 LLM을 3D 형태로 변환하여 인간이 이해할 수 있는 3D 세계에 배치하는 또 다른 모델을 훈련시키는 것임
          + 간단한 예로, LLM을 녹색 들판과 객체로 표현하고, 인간이 유일한 에이전트로 설정함
     * 적절한 커널을 가진 Gaussian Processes가 몇 개의 데이터 포인트와 작은 매개변수 세트만으로도 매우 강력하다고 생각함
          + 컴퓨터 비전 작업에서 입력을 조정하는 예측 가능한 비선형 프로세스로 사용했으며, 결과가 매우 좋았음
     * 주제에 대한 최고의 참고 자료와 부분적으로 겹치는 것 같음. Gareth James 등의 ""An Introduction to Statistical Learning""을 언급함
          + 이 자료가 더 접근하기 쉬울지 궁금하며, R/Python 예제가 도움이 될 것임
     * Kevin Murphy가 그의 Probabilistic Machine Learning 시리즈를 이름 변경 중임
     * Gemini 2.0 Experimental 02-05는 이를 ""단지"" 107K 토큰으로 봄
          + 이를 분해하는 데 도움이 필요하다면 유용함
     * Laplace Approximation은 복잡한 확률 분포를 간단한 Gaussian(벨 곡선)으로 변환하는 ""빠르고 간단한"" 방법임
          + 최고점을 찾아 그 지점에서 곡률을 맞추는 방식으로 작동함
          + 빠르고 쉬우나, 실제 분포가 벨 곡선과 다르면 매우 부정확하고 과신할 수 있음
     * ETH Zurich에서 이 수업을 들었으며, 가장 좋아하는 수업 중 하나임
          + 특히 불확실성을 정량화하는 방법과 강화 학습의 시작 블록을 구축하는 방법이 인상적임
          + 데이터 과학자와 ML 엔지니어에게 훌륭한 읽을거리임. 이 문서는 강의 노트임
"
"https://news.hada.io/topic?id=19597","NASA, 달에서 최초로 GPS 신호 수신 성공","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       NASA, 달에서 최초로 GPS 신호 수신 성공

     * NASA와 이탈리아우주국(ASI)이 3월 3일 Lunar GNSS 수신기 실험(LuGRE) 을 통해 달 표면에서 지구 기반 내비게이션 신호를 최초로 획득 및 추적하는 데 성공함
     * 이는 GNSS(Global Navigation Satellite System) 신호가 달에서도 수신 및 추적될 수 있음을 의미하며, 이번 성과는 NASA의 아르테미스(Artemis) 미션과 향후 달 및 화성 탐사에 자율적인 위치·속도·시간 결정 기술을 지원할 가능성을 열어줌
     * 이는 향후 달 및 심우주 탐사용 정밀 내비게이션 시스템 구축을 위한 중요한 초석이 됨

LuGRE 미션 개요 및 주요 성과

     * LuGRE는 Firefly Aerospace의 Blue Ghost 착륙선에 실려 3월 2일 달 착륙
     * NASA의 고다드 우주비행센터에서 과학 미션 시작
     * GPS와 유럽의 갈릴레오(Galileo) GNSS 신호를 획득 및 추적할 수 있을지에 대한 기대감 속에서 실험 진행
     * 3월 3일 새벽 2시(EST), 약 36만 km 떨어진 달 표면에서 GNSS 신호 획득 및 최초의 내비게이션 고정(Navigation Fix) 성공

추가 GNSS 관련 기록 및 향후 전망

     * LuGRE는 지구에서 가장 높은 고도에서 GNSS 신호를 수신한 기록을 경신
          + 2025년 1월 21일, 지구로부터 33만 800km(209,900마일) 거리에서 GNSS 신호 획득
          + 기존 기록 보유자는 NASA의 자기권 다중규모 탐사(MMS) 미션
          + 2월 20일, 달 궤도 진입 후 39만 1,000km(243,000마일) 거리에서도 GNSS 신호 수신
          + 이를 통해 지구-달 사이(cislunar space)에서도 GNSS를 활용한 내비게이션 가능성 확인
     * 14일간 LuGRE 실험 지속, 추가적인 GNSS 관련 데이터 확보 예정
     * 이탈리아우주국이 개발한 하드웨어가 달에서 작동한 최초의 사례로 기록됨

GNSS 기반 심우주 내비게이션의 중요성

     * 기존에는 지구 기반 추적소와 우주선의 센서를 조합해 위치를 결정해야 했음
     * LuGRE는 GNSS 신호만으로도 자동으로 내비게이션이 가능함을 입증
     * 향후 탐사선 및 우주비행사의 독립적이고 정확한 자율 내비게이션 가능성 확대

LuGRE 프로젝트 협력 및 후속 연구

     * NASA 고다드 우주비행센터, 이탈리아우주국(ASI), Qascom 및 Politecnico di Torino와 공동 개발
     * NASA의 우주 통신 및 내비게이션(SCaN) 프로그램에서 자금 지원 및 감독
     * Firefly Aerospace를 통해 NASA의 상업용 달 페이로드 서비스(CLPS) 프로그램 하에 달로 운송됨

        Hacker News 의견

     * 거리와 속도의 도전에도 불구하고 수신기가 위치 정확도 1.5km, 속도 정확도 2m/s를 달성했음
     * GPS 위성 4개(L1 및 L5 주파수)와 Galileo 위성 1개(E1-E5 밴드)에서 신호를 성공적으로 수신했음
     * 신호는 더 약해지겠지만, 21배 더 멀리 떨어져 있어 잡음이 적고 신호 반사가 거의 없다는 이점이 있을 것 같음
     * 위성이 하늘의 작은 부분에 집중되어 있고, 수신기와의 거리와 비교해 상대적으로 가까운 거리에서 위치 계산이 얼마나 어려울지 궁금함
     * 기사 제목은 GPS라고 하지만, 실제로는 GPS와 Galileo에서 신호를 수신했다고 하여 위치 고정을 위한 GNSS 위성의 수가 증가했음
     * 기사를 통해 명확하지 않으며, 초보적인 질문이지만, 시간 지연 효과를 고려할 필요가 없다는 의미인지 궁금함
     * 달에서 시도했지만, 달에만 국한된 것은 아닌 것 같음. 지구 궤도 어디서든 380,000km 높이까지 위치를 얻을 수 있는 것 같음. 1.5km 정확도는 인상적임
     * 거리로 인한 감쇠 외에도, 내비게이션 위성은 주로 지구를 향해 안테나를 향하지만, 바깥쪽으로 방사하는 위성도 있을 수 있음. 그러나 절반의 위성에서 수신할 수 있을 것이라고 기대하지는 않음
     * 정말 멋짐. GNSS 별자리를 향한 쪽에서만 작동하는 것 같음. 다른 쪽에서는 사용할 신호가 없음
     * 이런 예상치 못한 아이디어를 시도하는 것이 마음에 듦
     * 이것이 ESA의 Pathfinder를 불필요하게 만드는지 궁금함. 아니면 다른 물질적인 것을 측정하는 것인지 궁금함
     * 언제 화성 주위에 GPS 위성을 설치할지 궁금함. 아니면 위성을 달에 설치하는 것이 더 나을지도 모름. GPS의 12K와 비교해 9K와 14K로 표면에서 꽤 멀리 떨어져 있어 나쁘지 않을 것 같음. 또한 대기가 적고 라디오 잡음도 적음
     * 이전에는 Artemis 프로젝트가 지구와 달 사이의 공간에서 PNT(위치, 내비게이션, 타이밍)를 생성하는 것을 포함한다고 이해했음. 지구의 GNSS 위성으로는 충분하지 않을 것이라고 생각했음. 그 계획이 변경된 것인지 궁금함
"
"https://news.hada.io/topic?id=19636","연방 당국, 2022년 LastPass 해킹과 사이버 강탈 연관성 확인","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                연방 당국, 2022년 LastPass 해킹과 사이버 강탈 연관성 확인

     * 2023년 9월, LastPass 해킹 사건
          + KrebsOnSecurity는 2023년 9월, LastPass의 마스터 비밀번호가 도난당해 여러 피해자에게 수십만 달러의 사이버 절도가 발생했다고 보도함.
          + 미국 연방 수사관들은 2024년 1월 30일 발생한 1억 5천만 달러 규모의 암호화폐 절도 사건을 조사하며 같은 결론에 도달함.
     * 암호화폐 절도 사건
          + 2024년 3월 6일, 캘리포니아 북부의 연방 검찰은 1억 5천만 달러 규모의 사이버 절도 사건 이후 약 2천 4백만 달러 상당의 암호화폐를 회수했다고 발표함.
          + 이 사건의 피해자는 Ripple의 공동 창립자인 Chris Larsen으로 추정됨.
     * 연방 수사관의 조사 결과
          + 미국 비밀경호국과 FBI는 LastPass 해킹 사건과 관련된 절도 사건에 대해 같은 결론을 내림.
          + 도난된 데이터와 비밀번호가 피해자의 온라인 비밀번호 관리자 계정을 통해 불법적으로 접근되어 암호화폐와 기타 데이터를 탈취하는 데 사용되었음을 확인함.
     * 공통된 피해자 특징
          + 보안 연구원 Nick Bax와 Taylor Monahan은 피해자들이 이메일, 모바일 계정, SIM 스와핑 공격과 같은 전형적인 공격을 겪지 않았음을 발견함.
          + 피해자들은 모두 LastPass 계정의 ""Secure Notes""에 암호화폐 시드 구문을 저장했었음.
     * 복잡한 절도 패턴
          + 도난된 자금은 다양한 암호화폐 거래소의 여러 계정으로 빠르게 이동됨.
          + 정부는 이러한 복잡한 절도 패턴이 여러 악의적인 행위자들의 협력에 의해 이루어졌다고 판단함.
     * LastPass의 반응
          + LastPass는 연방 수사관이나 다른 출처로부터 절도 사건이 LastPass 해킹과 관련이 있다는 결정적인 증거를 보지 못했다고 주장함.
          + 2022년 8월 LastPass는 소프트웨어 개발 환경에서 비정상적인 활동을 감지했으며, 일부 소스 코드와 기술 정보가 도난당했다고 발표함.
          + 2022년 11월, LastPass는 암호화된 비밀번호 금고와 개인 정보가 해킹당했다고 고객에게 알림.
     * 보안 전문가의 의견
          + 많은 피해자들이 복잡성이 낮은 마스터 비밀번호를 사용했으며, 이는 LastPass의 오래된 고객일 가능성이 높음.
          + LastPass는 새로운 사용자에게 더 복잡한 비밀번호를 요구했지만, 오래된 고객에게는 이를 적용하지 못한 것으로 보임.
     * 보안 강화 필요성
          + 연구원들은 LastPass가 고객에게 비밀번호 변경을 권장했어야 한다고 주장함.
          + LastPass의 부정적인 반응에도 불구하고, 보안 연구원들은 더 많은 해킹을 방지하기 위해 추가적인 조치가 필요하다고 강조함.

        Hacker News 의견

     * 1Password는 모든 금고를 고급 비밀 키로 암호화하는 선택으로 충분한 인정을 받지 못함. 이는 사용자 경험과 지원 부담에 비용이 들지만, 이로 인해 데이터 유출이 발생해도 큰 문제가 되지 않음
     * LastPass는 데이터 유출을 과소평가했고, 노트 섹션과 같은 데이터를 제대로 암호화하지 않음. 책임을 회피했지만, 소송을 당했어야 함
     * LastPass는 사용자 마스터 비밀번호가 충분히 안전하지 않다는 것을 알면서도 적극적으로 대처하지 않음. 이는 용서할 수 없는 일임
     * LastPass를 사용하는 사람들은 1Password, Bitwarden, Keepass와 같은 더 신뢰할 수 있는 옵션으로 이동하고, 중요한 모든 비밀번호를 변경해야 함
     * LastPass 해킹이 어떻게 비밀번호 손실을 초래했는지 혼란스러움. 1Password와 같은 방식으로 작동한다고 생각했는데, 그렇다면 여전히 매우 어렵거나 불가능해야 함. 비밀번호 관리자나 LastPass가 어떻게 다른지 설명해줄 수 있는 사람 있음?
     * 1Password는 복호화 키가 두 부분으로 나뉘어 있음: 사용자의 단일 비밀번호 + 비밀 키. 두 가지 모두 필요함. 비밀 키는 무작위로 생성되며 128비트 정도임. 1Password가 생성하고 사용자에게 보내지만, 다시는 보지 않음. 금고가 도난당해도 비밀번호와 128비트 비밀 키를 해독해야 하므로 최소 128비트 보안이 보장됨
     * LastPass는 어떻게 다른가? 비밀 키도 도난당했나? 도난당한 금고의 대상이 추가 공격을 받아 비밀 키를 추출했나? LastPass는 1Password와 유사한 구조를 사용하지 않나? 아니면 1Password를 사용하면서도 안전하지 않다고 생각해야 하나?
     * 2013년 두 번째 주요 보안 침해 이후 LastPass를 사용하지 않음. Wikipedia에는 총 3건의 사건만 나와 있지만, 2010년부터 오늘까지 최소 5건의 보고를 본 적이 있음. 그동안 회사에서 LastPass를 사용하는 것을 계속 보았고, 매번 놀라움
     * LastPass는 두 사건을 연결하는 증거가 없다고 주장함. 하지만 수백만 달러의 ""수집품""을 저장하는 사람들이 최소한 매년 비밀번호를 변경하지 않는다는 것은 믿기 어려움
     * 비밀번호 회전이 더 이상 최선의 관행이 아니지만, 이 경우에는 여전히 신중한 선택임
     * 로컬 KeepassXC를 보며 차분하게 유지함
     * 클라우드에 비밀번호를 저장하라고 했지만, 아무 문제도 없을 것이라고 했음
     * 모든 사람의 자격 증명을 중앙 집중화하는 것은 여전히 가장 위험한 아이디어임. 해커에게 더 매력적인 것은 무료 성과 약물일 수 있지만, 잠시뿐이고 다시 모든 사람의 자격 증명을 훔치려고 할 것임
     * 다른 목표: 모든 사람의 개인 식별 정보, 친구, 가족, 애완동물에 대한 정보, 보안 질문에 대한 답변, 모바일 ID, PIN 번호, 계좌 번호, 서명, 사진, 지문, 음성 패턴, 얼굴 및 망막 스캔, 걸음걸이, DNA, 미토콘드리아 RNA
     * LastPass가 처음 등장했을 때 모두가 약하고 신뢰할 수 없다고 생각했던 것을 기억함. Pepperidge Farm도 기억함
     * 보안에 민감한 사람들은 비밀번호에 대해 무엇을 하나? 모든 것에 동일한 비밀번호를 사용하거나 비밀번호 관리자를 사용해야 하는 것 같음. 하지만 모든 비밀번호가 한 곳에 모이면 하나만 손상되는 것이 아니라 모두 손상될까 봐 항상 걱정됨
     * 많은 솔루션에서 편리함과의 거래가 있는 것처럼 느껴짐. 집무실에 비밀번호가 가득한 물리적 바인더를 보관할 수 있지만, 매번 찾아보고 입력하는 것이 번거롭고, 물리적 접근이 가능한 사람에게 큰 위험임
"
"https://news.hada.io/topic?id=19670","Ecosia와 Qwant의 유럽 검색 인덱스 구축 협력","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Ecosia와 Qwant의 유럽 검색 인덱스 구축 협력

     * 디지털 시장법과 우리의 노력
          + 우리는 기술이 더 공정하고 경쟁적이며 민주적이기를 추구하고 있음.
          + 기술 독립을 향한 다음 단계로, 자체 검색 인덱스를 구축하고 있음.
          + Qwant와 협력하여 유럽 검색 관점을 구축하고 있으며, 이는 AI 인프라를 포함한 미래 기술의 견고한 기반을 제공할 것임.
     * 검색 인덱스란 무엇인가?
          + 검색 인덱스는 검색 엔진이 정보를 검색하고 가장 관련성 있는 순서로 제공하는 데 사용되는 데이터베이스임.
          + 현재는 Google과 Bing의 라이브러리를 혼합하여 검색 결과를 제공하고 있음.
          + 2025년부터는 프랑스어와 독일어로 결과를 제공하기 위해 새로운 인덱스를 데이터베이스 풀에 추가할 예정임.
     * 왜 자체 검색 인덱스를 구축하는가?
          + 유럽 검색 관점을 통해 유럽 내 디지털 주권을 구축하고, AI 기술을 위한 투명하고 안전한 데이터 풀을 제공하려고 함.
          + 프라이버시를 우선시하는 검색 인덱스를 개발하고 있으며, 이는 Ecosia와 Qwant에서 사용될 것임.
          + 독점 솔루션과 달리, 우리는 인덱스를 다른 이들에게도 제공할 것임.
          + 기술 자율성의 다음 단계를 기념하며, 이는 우리가 원하는 녹색 기술의 미래를 구축할 수 있는 더 많은 자유를 제공함.
          + Ecosia의 기후 영향은 검색 엔진의 성능에 달려 있으며, 이 혁신적인 기술 개발은 지구를 위해 필수적임.
"
"https://news.hada.io/topic?id=19704","Show GN: VSCode extension: Open Storybook – 원하는 Storybook만 빠르게 실행하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Show GN: VSCode extension: Open Storybook – 원하는 Storybook만 빠르게 실행하기

배경

   저희 팀은 Storybook을 실행할 때 속도 문제를 겪고 있었습니다.
   프로젝트가 커지면서 Storybook의 전체 빌드 시간이 점점 길어졌고,
   테스트할 스토리 일부만 열고 싶은데 매번 전체 Storybook을 실행하거나 .storybook/main.ts에서 경로를 수정하는 불편함이 있었습니다.

   이를 해결하기 위해, VSCode 익스텐션인 ""Open Storybook""을 만들었습니다.
   Jest Runner처럼 Storybook도 ""파일 탐색기에서 특정 폴더만 선택해서 실행"" 또는 ""원하는 스토리북 파일 선택해서 실행""할 수 있도록 했습니다.

기능

     * 폴더 - 우클릭 - Open Stories 커맨드: 해당 폴더 안의 모든 스토리북을 추가로 열 수 있습니다.
     * 커맨드 팔레트: Open Storybook 커맨드: 커맨드로 열어둔 스토리북이 있으면 기존 + 새 스토리북을 합쳐서 볼 수 있습니다. (Open Stories로 열어도 마찬가지로 합쳐집니다.)
     * 모노레포 관리: 패키지 별로 스토리북 터미널 따로 관리합니다.
     * script에서 storybook 커맨드를 찾아서 실행합니다. 없으면 npx storybook으로 실행합니다.

설치

     * extension에서 roseline-song.open-storybook or open storybook 검색
     * cursor의 경우: vscode 버전 호환성 에러가 발생한다면, install 옆의 톱니바퀴 버튼 클릭 - install specific version - 최신 버전 설치

  0.0.5 버전

   스토리북이 아닌 파일을 Open Storybook으로 열려고 하는 경우 에러 토스트 띄움
   package별 스토리북 경로가 계속 누적해서 쌓이는 문제 해결
   Storybook 터미널 종료 시 main.ts 복원
"
"https://news.hada.io/topic?id=19609","Revolt - 디스코드 대안 오픈소스 플랫폼","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Revolt - 디스코드 대안 오픈소스 플랫폼

     * Revolt는 사용자 중심으로 설계된 채팅 앱으로, 개인화된 경험을 제공
     * 무료 및 오픈 소스 프로젝트로, 사용자의 프라이버시를 존중하며 광고나 추적기가 없음
     * 유럽에서 개발되어 GDPR을 준수
     * 주요 기능
          + 텍스트 채널: 이미지 첨부, 사용자 멘션, 웹사이트 링크 기능을 제공하여 현대적인 채팅 경험을 제공함.
          + 커뮤니티 구축: 세밀한 권한 설정, 모더레이터 도구, 봇 기능을 통해 커뮤니티를 쉽게 관리할 수 있음.
          + 개인화: Revolt는 사용자가 원하는 대로 외관을 설정할 수 있는 기능을 제공함.
          + 보안 및 기밀성: 사용자의 프라이버시를 존중하며, 광고나 추적기가 없음.
     * 다음 세대의 DM 및 그룹
          + 친구 요청을 보내고 간단하게 대화를 시작할 수 있는 기능을 제공함.
     * 다운로드 및 지원
          + 데스크톱, 안드로이드, iOS 및 iPadOS용 다운로드 가능
          + 개발자 지원, 소스 코드, 문서화, 번역 지원 등을 제공

        Hacker News 의견

     * 포럼의 사라짐과 문제 해결을 위한 ""구글 가능성""의 감소가 우울함
     * Discord의 가장 큰 장점은 강력한 네트워크 효과임
          + 다양한 주제의 서버가 존재하며, 서로 연결된 이벤트와 메시지를 공유함
     * Reddit와 같은 플랫폼 독점의 위험성을 우려함
     * 기술 커뮤니티에서 널리 사용되는 모든 채팅 플랫폼을 사용 중임
          + 대부분의 사용자는 커뮤니티가 선택한 플랫폼을 사용함
          + 커뮤니티 관리자들이 플랫폼을 선택하는 이유는 회사의 지원과 관리의 용이성 때문임
     * 오픈 소스 라이브러리 지원을 위해 다양한 플랫폼을 사용할 수 있음
          + 커뮤니티 운영 시에는 관리와 DevOps 워크플로우에 잘 통합되는 플랫폼을 선택함
     * Discord의 성공 요인은 웹훅과 봇 API의 활용임
          + GitHub Actions, 알림/모니터링 플랫폼과의 통합이 쉬워야 함
          + 이메일보다 쉽게 알림을 보낼 수 있어야 함
          + 이메일과의 기본적인 ""브릿지"" 통합이 필요함
     * M365에서 Teams와 Outlook 간의 전환이 불편함
          + 이메일을 Teams 내에서 처리할 수 없는 점이 아쉬움
     * rvlt.gg에서 활성 서버는 대부분 터키어 또는 애니메이션 관련임
          + 터키는 2024년에 Discord를 차단함
     * 잘못된 URL 입력 경험 공유
     * GitHub의 revoltchat 프로젝트 언급
     * 예전의 PHPBB와 VBulletin 포럼을 그리워함
          + 구글 검색이 용이하고, 실제 페이지네이션이 있었음
     * 새로운 포럼은 Discord(동기식) 또는 Discourse(비동기식)로 이동 중임
          + 덜 유용하다고 느낌
     * 영국 회사의 채팅 앱의 개인정보 보호 정책에 대한 의문
     * Discord의 UX/UI에 대한 비판
     * 프로젝트의 자금 조달이 중요함
          + 오픈 소스로 시작한 프로젝트가 기부로 인해 개발자의 좌절과 번아웃을 초래할 수 있음
"
"https://news.hada.io/topic?id=19615","emcee - OpenAPI를 MCP로 변환해주는 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     emcee - OpenAPI를 MCP로 변환해주는 도구

     * OpenAPI 스펙으로 만들어진 서비스를 Model Context Protocol (MCP) 서버로 만들어 주는 도구
     * 이를 통해 Claude Desktop 및 기타 MCP 지원 앱에서 외부 도구 및 데이터 서비스에 접근 가능하여, ChatGPT 플러그인과 유사한 역할 을 수행
          + Claude의 mcpServers 항목에 emcee를 추가하고 인자로 openapi.json만 넘겨주면 바로 사용 가능 : https://api.weather.gov/openapi.json
     * 다양한 인증 방식 지원: Bearer Token, Basic Auth 및 1Password Secret Reference로 전달 가능

   MCP가 요즘 핫! 쏘핫!!
"
"https://news.hada.io/topic?id=19610","유럽산 제품 구매, 유럽 가치 지원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          유럽산 제품 구매, 유럽 가치 지원

     * 유럽산 제품 구매
          + 유럽에서 제작된 소프트웨어, 전자제품부터 일상용품까지 다양한 제품과 서비스를 소개하는 디렉토리임
          + 카테고리: 자동차 및 운송, 도서, 미디어, 엔터테인먼트 및 게임, 의류 및 패션, 전자제품 및 가젯, 식음료, 건강 및 미용, 가정 및 생활, 아동 및 가족, 기타, 사무용품 및 문구, 전문 및 비즈니스 서비스, 소프트웨어 및 온라인 서비스, 스포츠 및 야외 활동, 여행 및 숙박
     * Cryptee
          + 에스토니아에 등록된 회사
          + 웹사이트: https://crypt.ee
          + 대체 제품: Google Docs, Google Drive
          + 요약: Cryptee는 Google Docs, Drive, Photos에 대한 프라이버시와 보안을 우선시하는 대안임
     * DeepL
          + 독일에 등록된 회사
          + 웹사이트: https://www.deepl.com/en/translator
          + 대체 제품: Google Translate
          + 요약: DeepL은 AI 기반 번역 도구로, 여러 언어에 걸쳐 매우 정확한 번역을 제공함
     * Vivaldi
          + 노르웨이에 등록된 회사
          + 웹사이트: https://vivaldi.com
          + 대체 제품: Google Chrome, Safari, Microsoft Edge
          + 요약: Vivaldi는 프라이버시를 강조하는 고도로 맞춤화 가능한 웹 브라우저로, 내장 광고 차단기, 고급 탭 관리, 독특한 사용자 인터페이스 등의 다양한 기능을 제공함
     * Le Chat - Mistral AI
          + 프랑스에 등록된 회사
          + 웹사이트: https://chat.mistral.ai
          + 대체 제품: ChatGPT
          + 요약: Le Chat은 프랑스 스타트업 Mistral AI가 개발한 고속 AI 어시스턴트로, 보고서 작성, 코드 작성, 실시간 인사이트 제공 등의 작업을 지원하여 생산성을 향상시킴
     * Lemmy
          + 독일에 등록된 회사
          + 웹사이트: https://join-lemmy.org/
          + 대체 제품: Reddit
          + 요약: Lemmy는 주류 소셜 미디어 사이트에 대한 대안으로 설계된 오픈 소스, 분산형 소셜 네트워킹 플랫폼으로, 사용자가 온라인 커뮤니티를 생성하고 참여할 수 있도록 함
     * Mastodon
          + 독일에 등록된 회사
          + 웹사이트: https://joinmastodon.org/
          + 대체 제품: Twitter
          + 요약: Mastodon은 오픈 소스, 자체 호스팅 소셜 네트워킹 서비스로, Twitter와 유사한 마이크로블로깅 기능을 제공하며, 일반적으로 Fediverse의 일부로 간주됨
     * GOG
          + 폴란드에 등록된 회사
          + 웹사이트: https://www.gog.com/
          + 대체 제품: Steam, Epic Games
          + 요약: GOG (Good Old Games)는 DRM 없는 타이틀, 클래식 게임, 인디 출시작을 전문으로 하는 비디오 게임 디지털 배포 플랫폼임
     * Koofr
          + 슬로베니아에 등록된 회사
          + 웹사이트: https://koofr.eu/
          + 대체 제품: Google Drive, Dropbox
          + 요약: Koofr는 여러 기기와 플랫폼에서 파일을 안전하고 효율적으로 저장, 액세스, 관리할 수 있는 클라우드 스토리지 서비스임
     * Bolt
          + 에스토니아에 등록된 회사
          + 웹사이트: https://bolt.eu/
          + 대체 제품: Uber
          + 요약: Bolt는 경제성과 지속 가능성에 중점을 둔 승차 호출, 전동 스쿠터 및 자전거 서비스를 제공하는 교통 플랫폼임
     * Posteo
          + 독일에 등록된 회사
          + 웹사이트: https://posteo.de/de
          + 대체 제품: Gmail, Microsoft Outlook
          + 요약: Posteo는 독일에 기반을 둔 보안, 프라이버시 중심의 이메일 제공업체로, 암호화된 이메일 서비스를 제공하며 지속 가능성과 데이터 보호에 중점을 둠

        Hacker News 의견

     * 모든 유럽 회사가 유럽의 가치를 구현하는 것은 아님. 예를 들어, Signal은 미국 회사로 유럽 대체품을 찾고자 하는 사람들이 있지만, Signal은 많은 대안보다 유럽의 가치를 더 잘 대표함
     * 이 제출물이 플래그된 것이 재미있거나 슬픔
     * 매우 흥미로운 기술 항목이 포함된 목록임. 폴란드에 실제 RAM/저장소 공장이 있다는 것을 몰랐음
     * MAIA - ""Make America Irrelevant Again""의 시작인가? 그들이 정말로 도움이 필요한가? 이미 잘하고 있는 것 같음
     * 1위에서 몇 분 만에 플래그됨. 시대가 평화롭지 않음
     * 소비자 보호, 프라이버시, 환경 기준과 같은 유럽의 가치는 세계 최고 중 하나라고 생각함. 그러나 관료주의와 정치가 이를 잘못된 방향으로 밀거나 모든 것을 얽어매고 있음. 이에 대해 많이 생각해본 적이 없었지만 이제 유럽 산업을 지원하는 것에 대해 더 알아볼 계획임. 그러나 품질이 비교 가능한 제품에 한해서임. 제품이 기준에 미치지 못하면 단지 유럽 제품을 구매하기 위해 선택하는 사람은 많지 않을 것임
     * 디지털 제품만 해당: https://european-alternatives.eu/
     * 거의 모든 판매에서 Amazon, Google, Microsoft, Nvidia, Intel, Dell/HP, Snowflake/Databricks, Datadog 등을 암묵적으로 지원하지 않겠음? 많은 유럽 기업의 경우 인프라와 플랫폼 비용이 자체 마진을 초과할 가능성이 높음. 그런 의미에서 많은 유럽 기업은 실제로 미국 하드웨어와 플랫폼의 ""부가가치 리셀러""임
     * 이 댓글을 게시하기 위해 계정을 만들었음
          + 최근 비중국산 무선 키보드와 마우스를 구매하려고 이 웹사이트를 방문했음. 검색창에 ""keyboard""를 입력했을 때 첫 번째로 나온 회사는 Logitech이었음
          + 지난 두 달 동안 모든 기술 상점과 아울렛을 방문했지만, 확인한 모든 Logitech 키보드는 중국산이었음. 중국산이 아닌 키보드가 있었다면 즉시 구매했을 것임
          + 이 웹사이트의 목적이 무엇인지 이해할 수 없음. 여기서 말하는 유럽의 가치란 무엇인가? 모든 것을 저렴한 중국 노동력에 아웃소싱하는 것인가? 이 웹사이트가 SEO 백엔드인가? 복잡한 기업 장난인가?
          + 누군가 설명해주길 바람
     * 쿠키 배너가 내 휴대폰 화면의 60%를 덮고 있는 것이 매우 상징적임
     * https://european-alternatives.eu/
     * https://isitamerican.eu/
"
"https://news.hada.io/topic?id=19702","Fastplotlib: GPU 가속, 빠르고 인터랙티브한 플로팅 라이브러리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Fastplotlib: GPU 가속, 빠르고 인터랙티브한 플로팅 라이브러리

     * fastplotlib은 새로운 GPU 가속 과학적 플로팅 라이브러리로, WGPU를 활용하여 빠르고 상호작용적인 시각화를 제공
     * 대규모 데이터셋을 빠르게 탐색하고 실시간 분석 시스템을 구축하는 데 유용
     * 과학적 시각화는 어렵지만, fastplotlib을 사용하면 더 쉽게 접근할 수 있음
          + 전통적으로 과학적 시각화는 정적 플롯에 의존했지만, 동적이고 상호작용적인 시각화가 데이터 탐색과 분석을 향상시킴
          + 예를 들어, fastplotlib을 사용한 공분산 행렬의 상호작용적 시각화는 데이터 이해를 돕고, 미래의 분석 유형을 변화시킬 수 있음
     * API 설계가 중요함
          + 과학적 시각화 생태계는 발전해왔으며, fastplotlib은 사용하기 쉬운 직관적인 API를 제공하여 데이터와 상호작용을 쉽게 함
          + 데이터는 배열로 유지되어야 하며, 이벤트 시스템은 간단한 콜백 함수로 정의할 수 있음.
     * 새로운 하드웨어 활용의 중요성
          + GPU는 과학적 작업에 필수적이며, fastplotlib은 GPU 자원을 최대한 활용하여 고해상도 시각화를 가능하게 함
          + 이는 pygfx 렌더링 엔진 위에 추상화되어 있으며, WGPU를 통해 Vulkan, Metal, DX12를 지원
     * fastplotlib은 상호작용적 플롯을 통해 과학적 발견을 촉진하고, 사용하기 쉬운 API로 현대 그래픽 하드웨어를 활용하여 빠르고 상호작용적인 시각화를 제공함

        Hacker News 의견

     * ""GPU가 과학을 하는 데 필수적이라는 주장에 대해 웃음이 나옴""
          + ""3백만 포인트를 플로팅하는 것이 대단한 일처럼 보이지만, 실제로는 CPU로도 쉽게 처리 가능함""
          + ""Fastplotlib의 성능이 Rust와 Python의 조합 때문에 느린 것일 수 있음""
          + ""Fastplotlib은 Python 사용자에게 유용하지만, 웹사이트의 과장된 홍보가 불편함""
     * ""GitHub에서 유용한 도구를 찾고 있으며, Fastplotlib이 유망해 보임""
          + ""통계 유전학에서 큰 스캐터플롯을 시각화하는 데 도움이 될 것 같음""
          + ""Manhattan plots와 같은 큰 플롯을 시각화하는 데 적합할 것 같음""
     * ""이 플로팅 라이브러리가 Python 외의 환경에서도 사용 가능했으면 좋겠음""
          + ""Ruby에서도 비슷한 것을 찾고 있었지만, 설치 지침이 오래되었고 Windows에서 지원되지 않음""
     * ""WGPU를 사용하여 Vulkan, Metal, DX12를 타겟으로 하는 점이 흥미로움""
          + ""데이터가 클러스터의 머신에 있을 때 서버를 시작하고 데이터를 HTTP로 전송하여 브라우저에서 렌더링할 수 있음""
          + ""HTTP를 통한 데이터 전송 프로토콜 정의가 필요할 수 있음""
     * ""Jupyter 노트북에서 어떻게 작동하는지 궁금함""
          + ""GPU 가속이 클라이언트 측인지 서버 측인지, 혹은 둘 다 가능한지 궁금함""
          + ""Google Colab에서 시각화 라이브러리를 사용했을 때, 업데이트가 느렸던 경험이 있음""
     * ""플롯할 수 있는 데이터 포인트의 대략적인 수치가 궁금함""
          + ""수백만 개의 데이터 포인트를 스캐터플롯으로 그릴 수 있는지 궁금함""
     * ""최근 발표를 보고 Fastplotlib을 시도해보기로 결정함""
          + ""인터랙티브 네트워크 시각화를 만들고 싶음""
          + ""클릭/박스 선택으로 서브그래프를 강조하는 기능을 구현하고 싶음""
     * ""이 GPU 플로팅 라이브러리가 torch/jax cuda 배열을 직접 받아들일 수 있다면 좋겠음""
     * ""라이브러리 소개 글이 매우 좋음""
          + ""Fastplotlib 대신 다른 라이브러리를 선택할 때가 언제인지 궁금함""
          + ""큰 데이터셋을 처리하는 방법이 궁금함""
          + ""Pandas와의 호환성 여부가 궁금함""
          + ""Jupyter 노트북에서 작동하는지, marimo와의 호환성 여부가 궁금함""
     * ""Windows 데스크톱과 원격 Linux 박스를 사용하며, 원격 호스트에서 로컬로 플롯하고 싶음""
          + ""Fastplotlib이 이를 쉽게 해결할 수 있는지 궁금함""
"
"https://news.hada.io/topic?id=19621","VeyraX MCP - 1개의 연결로 모든 MCP들을 연결하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   VeyraX MCP - 1개의 연결로 모든 MCP들을 연결하기

     * MCP-호환 환경에 각종 서비스들을 모두 연결해주는 도구
     * Cursor/Claude/VS Code/Windsurf 등에 VeyraX에 연결된 20+개의 도구와 100+개의 액션을 한번에 추가 가능
     * 지원 도구들: Notion, Gmail, GitHub, Slack, Dropbox, Google Drive/Calendar, Confluence/Jira, Youtube, Linear, Perplexity 등
     * VeryaX는 AI 에이전트용 도구 연결을 해주던 플랫폼으로 MCP 확장을 추가함
          + Agenic Component Interface
"
