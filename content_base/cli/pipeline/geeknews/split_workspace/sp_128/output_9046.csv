"https://news.hada.io/topic?id=18000","Vite 6.0 릴리즈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Vite 6.0 릴리즈

Vite 6 주요 변경 사항

     * 환경(Environment) API 도입:
          + 프로덕션과 더 가까운 개발 경험을 제공하기 위한 새로운 API
               o Node.js 이외의 런타임(Deno, Bun등)에서 실행 및 번들링 가능
               o Electron, Tauri, React Native 를 위한 환경도 제공 가능
          + 프레임워크 및 플러그인 작성자를 위한 유연성 강화
          + 가이드: Environment API 소개
     * Node.js 지원 업데이트:
          + Node.js 18, 20, 22 지원, 21 지원 종료
          + 향후 Node.js 18 EOL 이후 신규 메이저 릴리스 계획
     * 새로운 기능 및 변경
          + 템플릿 확장: pnpm create vite-extra로 Solid, Deno, SSR 등의 템플릿 지원.
          + Sass 및 PostCSS:
               o Sass 현대 API 기본 적용.
               o PostCSS의 로드 설정 확장.
          + CSS 라이브러리 출력 파일명 사용자 정의
          + HTML 요소의 에셋 참조 지원 확장
          + resolve.conditions의 디폴트 밸류 조정
          + JSON stringify
     * 마이그레이션
          + 대부분의 프로젝트는 간단히 업데이트 가능하지만, 마이그레이션 가이드 검토 권장

Vite 생태계 발전

     * npm 주간 다운로드가 Vite 5 이후 750만에서 1700만으로 증가
     * 새로운 프레임워크와 협력 확대:
          + TanStack Start, One, Ember
          + Astro, Nuxt, SvelteKit, React Router 등 주요 웹 프레임워크와 통합
     * ViteConf 2024에서 다양한 발표:
          + Evan You의 VoidZero 설립 발표
          + Rust 기반 Rolldown, Oxc 개발 소식
          + StackBlitz의 bolt.new 및 Storybook의 Vitest 통합 테스트 기능 공개
     * Vite 6 새로운 랜딩 페이지 및 도메인 vite.dev 적용
"
"https://news.hada.io/topic?id=18089","인텔, 리눅스 지원 아크 B-시리즈 "배틀메이지" 외장 그래픽 발표","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 인텔, 리눅스 지원 아크 B-시리즈 ""배틀메이지"" 외장 그래픽 발표

Intel Arc B-Series ""Battlemage"" 그래픽 카드 발표

     * 새로운 그래픽 카드 발표: Intel은 두 해 전 출시된 DG2/Alchemist 시리즈의 후속으로 Battlemage 그래픽 카드를 발표함. 이 새로운 Arc B-Series 그래픽 카드는 다음 주부터 초기 출시 예정이며, Linux에서 완전한 오픈 소스 그래픽 드라이버 지원을 받음.
     * 기술적 개선 사항: Battlemage는 Xe2 그래픽을 사용하며, 이는 최근 Lunar Lake의 통합 그래픽과 유사함. BMG-G21 GPU는 20 Xe 코어, 160 XMX 엔진, 20 레이 트레이싱 유닛, 192비트 GDDR6 비디오 메모리 인터페이스 등을 특징으로 함. 성능 면에서 Xe 코어당 최대 70% 향상, 와트당 성능 최대 50% 향상을 홍보함.
     * 제품 라인업: Arc Graphics B580과 B570 그래픽 카드가 발표됨. Arc B580은 20 Xe 코어, 2670MHz 그래픽 클럭, 12GB GDDR6 비디오 메모리, 190 와트 보드 전력 소비를 특징으로 함. Arc B570은 18 Xe 코어, 2500MHz 그래픽 클럭, 10GB GDDR6 비디오 메모리, 150 와트 보드 전력 소비를 가짐. 이 시리즈는 주로 1440p 게이밍을 위한 중급 카드임.
     * 성능 비교: Intel은 Arc B580이 Intel Arc A750보다 24% 빠르며, NVIDIA GeForce RTX 4060보다 10% 빠르다고 홍보함. Arc B580은 $249+ USD에, Arc B570은 $219+ USD에 출시 예정임.
     * Linux 지원: Intel은 Xe 커널 드라이버, Mesa Iris OpenGL 및 ANV Vulkan 드라이버, Intel Compute Runtime 스택(OpenCL 및 Level Zero)을 포함한 오픈 소스 및 업스트림 지향 Linux 지원을 위해 이미 몇 달간 작업해 왔음. 안정적인 Linux 6.12 커널과 최신 Mesa 그래픽 드라이버와 함께 업스트림 지원을 기대할 수 있음.
     * 추가 정보: 성능 세부 사항 및 새로운 Linux 지원 세부 사항은 아직 공개되지 않았으며, Phoronix의 추가 보도를 기다려야 함. Linux 지원이 Windows에 비해 나쁘지 않음을 암시함.

        Hacker News 의견

     * NVidia의 경쟁자가 될 수 있는 128GB RAM을 가진 기본 GPU 출시 제안. 그러나 회사의 재무 담당자들이 이런 아이디어를 내지 않을 것이라는 의견.
     * 첫 번째 벤치마크를 기다려야 하지만, 현재까지는 괜찮은 성능을 보임. 4060과 동등한 성능의 $200-$250 가격대는 나쁘지 않음. B750이나 B770의 성능이 궁금함. 저렴한 그래픽 카드가 다시 등장한 것은 긍정적임. Intel이 시장 진입을 위해 각 카드에서 손실을 보고 있을 것이라는 느낌.
     * 2k 게임에 맞춘 그래픽 카드는 훌륭하다는 의견. 2k는 4k와 1080p 사이에서 최적의 그래픽 품질을 제공함.
     * ML 작업에 12GB 메모리는 부족함. 합리적인 가격의 24GB 카드 출시 필요성 제기. ML 개발자 세계를 타겟으로 해야 한다는 의견.
     * Intel의 독립형 GPU에 대한 기대가 낮음. ML 작업에는 너무 작고, AV1 인코딩을 위한 카드 구매 시장이 크지 않다는 의견.
     * 오래된 기계에 a360 카드를 넣어 Plex 서버로 변환한 사례. 여러 독립 스트림을 문제없이 처리할 수 있었고, 가격 대비 성능이 뛰어났음.
     * 24GB 이상의 메모리를 가진 GPU가 py-stuff에 사용 가능하다면 큰 이익을 볼 것이라는 의견. NVIDIA 옵션만큼 성능이 뛰어나지 않더라도 모델을 실행할 수 있는 것만으로도 충분함.
     * Battlemage가 Linux에서 오픈 소스 그래픽 드라이버 지원을 받는다는 점을 긍정적으로 평가. OpenBSD에서 사용 가능하다면 기꺼이 사용할 것이라는 의견.
     * Linux 지원이 가장 중요한 특징이라는 의견. 게임을 하지 않더라도 GPU를 계산에 사용하고 싶어함. 버그가 있는 독점 드라이버는 불편함을 초래함.
     * B580의 트랜지스터 수와 칩 크기에 대한 궁금증. B580은 21.7억 개의 트랜지스터와 406 mm²의 다이 면적을 가짐. 4060의 18.9억 개 트랜지스터와 146 mm²와 비교하여 큰 다이임.
"
"https://news.hada.io/topic?id=18058","WeSQL - S3를 저장소로 사용하는 혁신적인 MySQL 배포판","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  WeSQL - S3를 저장소로 사용하는 혁신적인 MySQL 배포판

     * S3 및 S3 호환 시스템을 스토리지 백엔드로 사용하는 컴퓨팅-스토리지 분리 아키텍처를 채택한 혁신적인 MySQL 배포판
     * 클라우드 간 이동이 가능하며, 특정 벤더에 종속되지 않는 유연성을 제공
     * S3 기반 스토리지
          + 기존 MySQL 디스크 스토리지를 완전히 S3로 대체
          + 모든 데이터(binlog, 스키마, 스토리지 엔진 메타데이터, WAL, 데이터 파일 등)가 S3 객체로 저장
          + S3의 ""11 nines""(99.999999999%) 내구성으로 데이터 신뢰성 대폭 강화
     * 간편한 초기화 및 실행
          + 초기화된 빈 인스턴스에서 S3 연결 후 데이터 로드와 함께 즉시 서비스 가능
          + 별도의 추가 설정 없이 바로 시작
     * 클라우드 간 호환성
          + 모든 클라우드에서 실행 가능, 특정 벤더에 종속되지 않음
          + Serverless 및 BYOC(Bring Your Own Cloud) 지원
     * 비용 효율적이고 개발자 친화적
          + 관리가 쉬운 MySQL 데이터베이스 솔루션 제공
          + 개발 및 테스트 환경에서 쉽게 도입 가능

   2년 전부터 wesql docker 가 있는 걸로 봐서, docker를 통해 공유하는 db라든지, 개발 db라든지 여러 다른 역할로 활용해볼 수 있을 것 같아요.

   connect 엔진으로 이미 nfs상의 공유볼륨 내에 존재하는
   csv같은 파일들을 읽을 수 있는데
   의미 있는건지는 잘 모르겠어요

   DB 데이터를 공유 스토리지에 저장하는 것과 S3 객체를 읽기만 하는 것은 다릅니다. 다만 데이터 저장비용을 절감하기 위해서 IO 레이턴시나 대역폭 비용을 감내해야 될텐데 얼마나 비용효율적일지는 의문이 드네요

   제품자체는 흥미로움.
   딴지를 걸자면… 이걸 그냥 distribution이라고 부를 수 있나요? 그냥 다른 제품 같은데…

   와드 박아놔야겠네요
"
"https://news.hada.io/topic?id=18010","Hetzner, 대역폭 대폭 감소하면서 가격 인상 (미국)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Hetzner, 대역폭 대폭 감소하면서 가격 인상 (미국)

Hetzner 가격 인상 및 대역폭 감소

     * Hetzner 가격 인상
          + Hetzner가 미국에서 가격을 인상하면서 대역폭을 크게 줄임
          + CPX21 서버의 가격 인상률은 27.52%로 가장 높고, CX3+ 서버는 4.17%로 가장 낮음
          + 모든 제품의 대역폭 할당량은 평균적으로 88.19% 감소함
          + Hetzner는 이번 변화를 ""공정성""을 이유로 설명했으나, 고객들은 대역폭 감소에 대한 명확한 설명을 요구함
     * 업데이트
          + Hetzner의 가격 변경과 그에 대한 설명이 더욱 실망스러움
          + 사용하지 않은 대역폭에 대해 더 많은 비용을 지불해야 하는 상황에 불만을 표함
     * 새로운 가격 및 대역폭 표
          + Hetzner의 이메일에 따르면, Ashburn과 Hillsboro의 CCX 및 CPX 서버에 대한 가격과 대역폭이 변경됨
          + 예를 들어, CPX11의 경우 가격은 €3.85에서 €4.49로 인상되고, 대역폭은 20TB에서 1TB로 감소함
     * Hetzner의 이메일
          + 2024년 12월 1일부터 새로운 가격과 대역폭이 적용됨
          + 기존 클라우드 서버와 로드 밸런서에도 2025년 2월 1일부터 새로운 가격과 대역폭이 적용될 예정임
          + Hetzner는 이번 변화를 통해 고객들에게 최상의 가격-성능 비율을 제공하고자 함
     * 기타 정보
          + 클라우드 콘솔과 API에서 새로운 가격과 대역폭이 표시되지만, 청구서는 기존 조건에 따라 발행됨
          + 트래픽 경고가 조기 표시될 수 있으며, 기존 대역폭은 2025년 1월 31일까지 유효함
          + 변경 사항에 동의하지 않을 경우 언제든지 제품을 취소할 수 있음
     * 댓글
          + Mastodon이나 Fediverse 계정을 통해 이 게시물에 응답할 수 있음

        Hacker News 의견

     * Hetzner의 대역폭을 즐기는 사용자로서, 가격이 오르면 다른 제공자로 쉽게 이동할 수 있는 multi-cloud/dedi k3s의 장점을 언급함. $1/TB의 대역폭 초과 요금은 공정하다고 생각함
     * Hetzner에 계정을 만들었으나, 신용카드 확인 후 자동으로 계정이 정지됨. 지원팀에 문의했으나 새로운 계정을 만들고 진짜 정보를 사용하라는 답변을 받음. 결국 다른 곳에서 컴퓨팅을 구매함
     * Linode 고객으로서, $5/월에 많은 자원을 얻고 있다고 느낌. CPU를 100% 활용하여 시장 패턴을 찾는 작업을 수행 중임. 이러한 자원 활용이 일반화되고 있으며, 기업들은 수익성을 유지하기 위해 적응해야 함. Linode의 가격 인상을 예상함
     * Hetzner의 오랜 팬으로서, $1/테라바이트 초과 요금이 합리적이라고 생각함. 독일에서 서버나 VPN을 임대해 사용 중이며, 미국에서도 비슷한 서비스를 기대함
     * Hetzner의 가격 인상은 미국의 관세 때문임. Hetzner는 정확한 가격 구조로 유명하며, 가격 인상은 비용 증가와 관련이 있음. 미국의 관세가 가격을 올린 원인임
     * 가격 인상과 서비스 감소를 동시에 하는 것은 현명하지 않다고 생각함. 누가 책임자인지 궁금해함
     * 20TB의 대역폭을 필요로 하는 애플리케이션 예시를 궁금해함. 실시간 비디오 스트리밍이나 게임 서버가 예시일 수 있음. 중간 규모의 NFT 아트 생성 웹사이트를 운영 중이며, 10만 명의 사용자로도 1.5TB의 대역폭만 필요했음
     * 대역폭 비용에 대한 질문을 함. 서버는 부품이 소모되는 기계이며, 케이블을 설치하는 데 비용이 든다는 것을 이해함. 3g/4g/5g 비용을 이해하지 못함
     * Linode를 오랫동안 사용해왔으며, Akamai 인수 후 어떻게 될지 확신이 없음. 다른 곳으로 이동을 고려 중임
"
"https://news.hada.io/topic?id=18123","네이티브 이중 범위 입력","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             네이티브 이중 범위 입력

     * @stanko/dual-range-input은 두 개의 네이티브 HTML 범위 입력을 사용하는 네이티브 듀얼 범위 입력 라이브러리임.
          + 네이티브 입력을 사용하여 모든 기본 상호작용 및 접근성 기능을 유지함.
          + 약 50줄의 JavaScript와 CSS로 구성되어 있음.
     * 왜 필요한가
          + 생성적 드로잉 도구에서 매개변수를 조정하기 위한 UI를 사용하며, 최소 및 최대 슬라이더가 필요함.
          + 기존 솔루션은 JavaScript에 의존하며 드래그 및 접근성 기능을 재구현함.
          + 네이티브 HTML 범위 입력을 사용하고, 트랙을 클릭하면 가까운 슬라이더가 해당 값으로 이동해야 함.
     * 작동 원리
          + 두 개의 입력이 나란히 배치되어 있으며, 입력이 변경되면 두 값의 중간점을 계산함.
          + 최소 및 최대 속성을 중간점으로 설정하고, 입력의 너비를 업데이트함.
     * 입력 크기 조정
          + 입력의 너비를 계산할 때 트랙이 실제 입력 너비보다 짧다는 점을 고려해야 함.
          + 입력의 너비에 엄지 너비를 추가하여 간단하게 계산함.
          + 입력 래퍼에 패딩을 추가하여 엄지의 추가 너비를 수용함.
     * 클릭 시 엄지 이동
          + 입력이 중간점에서 만나도록 크기가 조정되며, 클릭 시 가까운 엄지가 해당 값으로 이동함.
          + 디버그 모드를 켜면 중간점을 쉽게 볼 수 있음.
     * 스타일링
          + CSS를 사용하여 범위 입력을 스타일링할 수 있음.
          + 트랙과 엄지의 스타일링이 간단하며, 트랙의 중간 연결 부분에 경계 반경을 제거함.
     * 테마
          + 테마를 쉽게 변경할 수 있도록 여러 변수를 노출함.
          + 기본값을 제공하며, 변수를 재정의하여 테마를 생성할 수 있음.
     * 그라디언트
          + CSS 그라디언트를 사용하여 선택된 범위를 페인트함.
          + --dri-gradient-position 변수를 사용하여 그라디언트를 설정하고, 코드에서 너비와 함께 업데이트함.
     * 결론
          + 이 게시물은 생각을 정리하기 위한 것이며, 네이티브 요소를 사용해보도록 영감을 주기를 바람.

        Hacker News 의견

     * 슬라이더의 중간 부분은 항상 움직일 수 있어야 하며, Unity의 예시처럼 양쪽 핸들을 동시에 움직일 수 있어야 함
     * 작성자는 자신의 생성적 그림을 위해 슬라이더를 만들었으며, 숫자를 입력하는 것보다 슬라이더를 드래그하여 이미지 변화를 보는 것을 선호함
     * 슬라이더를 100-100으로 설정한 후 99-99로 변경할 수 없는 버그가 있으며, 이 문제는 슬라이더의 끝부분에서 쉽게 발생함
     * HTML <input type=range>에 이중 값 구현이 필요하다고 생각하며, Firefox에서 핸들을 클릭할 때 값이 한 단계씩 변하는 버그가 있음
     * 회사 디자인 시스템에서 인턴이 유사한 POC를 만들었으나, 입력값이 튀는 문제가 발생하여 다른 인턴이 겹치는 입력 범위로 해결책을 제시함
     * ""네이티브""라는 용어는 논의의 여지가 있으며, 자바스크립트가 필요하면 더 이상 네이티브가 아니라고 생각함
     * 특정 기능을 구현하기 위해 React를 사용했으나, 프론트엔드 개발에 서툴러 어려움을 겪음
     * jQuery UI 슬라이더를 사용했으나, 단일 슬라이더를 위해 jQuery와 jQuery UI를 추가해야 했음
     * 자바스크립트 없이도 작동할 수 있으며, CSS의 너비 계산을 슬라이더 값에 의존하도록 더 정교하게 만들면 됨
     * 버그 보고에 적절한 장소인지 의문이며, 첫 두 예시의 핸들이 터치 상호작용을 가로막아 스크롤을 방해하는 문제가 있음
"
"https://news.hada.io/topic?id=18031","새 자동차의 미스터리하고 문서화되지 않은 스위치 발견기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     새 자동차의 미스터리하고 문서화되지 않은 스위치 발견기

     * 작성자는 12년간 사용한 구형 Peugeot 107 차량을 교체하고 2020년식 Opel Corsa Edition을 구매함
     * 새 차에는 여러 가지 첨단 기능과 버튼들이 포함되어 있었음
     * 모든 버튼의 기능을 이해하고자 매뉴얼을 읽었으나, 특정 스위치의 기능은 문서화되어 있지 않았음

미스터리 스위치의 정체를 추적하기

     * 스위치의 전원을 켜고 끄는 것으로는 아무 변화가 없었음
     * 스위치가 OBD2 포트와 연결되어 있었음. 이 포트는 차량의 데이터를 읽는 데 사용됨
     * 차량 점화 시 간섭 소리가 발생하며, 이는 데이터 전송 장치가 작동 중일 가능성을 암시함

문제 해결을 위한 다양한 시도

     * 온라인 커뮤니티에 질문했으나 명확한 답을 얻지 못함
     * 차량 딜러와 이전 소유자 및 유지 보수 기록을 바탕으로 여러 곳에 문의함
     * 마지막으로 자동차 정비소를 방문하여 전문가의 도움을 받음

스위치의 실제 기능

     * 해당 장치는 플릿 트래커(fleet tracker)와 연동되는 GPS 추적 장치로 판명됨
          + 자석을 이용해 운전자를 식별하고 데이터를 서버로 전송
          + 대형 회사에서 직원 차량 추적 및 벌금 부과 등의 목적으로 사용
     * GPS 추적 장치가 여전히 차량에 남아 데이터를 전송 중이었음

문제의식과 후속 조치

     * 차량 소유자는 이러한 GPS 장치가 자신의 동의 없이 작동하는 점에 우려를 느낌
     * GPS 추적 장치를 제거하기로 결정함
     * GDPR을 활용해 데이터 접근 요청이나 내장 SIM 카드의 데이터 사용 가능성에 대한 고민을 이어감

결론

     * 차량에 장착된 미스터리 스위치는 이전 소유자의 플릿 관리 목적의 장치였음
     * 장치의 존재를 확인하고 제거하기까지의 과정에서 사용자는 개인정보 보호와 데이터 활용 문제를 제기함
     * 대부분의 사람들은 이러한 장치를 인식하지 못하고 사용할 가능성이 높음

        Hacker News 의견

     * 대부분의 새로운 차량에 내장된 GPS와 eSIM이 비활성화될 수 없는 점이 문제임. 이는 개인정보 보호 문제와 정부의 개입 우려를 초래함
          + 미국에서는 모든 신차에 '운전자 장애' 기술을 장착하는 법안이 발표되었으며, 이는 '킬 스위치'로 불림
          + 미디어는 이를 '킬 스위치'가 아닌 운전자의 행동, 머리 또는 눈 움직임을 감시하는 센서나 카메라로 설명함
          + 개인적으로는 오래된 가솔린 Honda를 유지할 예정이며, 전기차로 전환하지 않을 계획임
     * 장치에 내장된 SIM 카드에서 무료 데이터를 얻을 수 있는지에 대한 질문이 흥미로움
          + 무료 데이터를 재미있게 사용하여 SIM 설치자가 장치를 비활성화하도록 가르칠 수 있는지에 대한 가능성도 있음
     * Ford Crown Victoria Police Interceptor 모델의 유사한 버튼을 떠올리게 함
          + 외부 조명을 비활성화하여 스텔스 모드로 전환하는 버튼이 있었음
          + 엔진을 계속 작동시키면서 키를 제거할 수 있는 버튼도 있었음
     * 차량 회사들이 새로운 차량(2016년 이후)의 데이터를 재판매하는 것이 큰 문제임
          + 이러한 문제가 더 큰 이슈가 되지 않는 것이 놀라움
     * 애프터마켓 GPS 트래커는 빠른 답변을 원하는 사람들을 위한 것임
     * Honda Fit의 에어컨은 연료 효율성을 위해 설계되었으며, 효과적이지 않음
          + AC 온도 센서에 저항기를 병렬로 추가하여 시스템이 실제보다 더 따뜻하다고 생각하게 만들어 더 시원하게 함
          + 이를 'AC Boost Switch'라고 부름
     * 2004년경, Bronx의 중고차 딜러십에서 고급 중고차에 GPS 트래커를 설치하여 고객이 대금을 지불하지 않을 경우 차량을 회수함
          + 이는 매우 불법적이며 고객에게 알리지 않음
          + 이러한 관행이 20년 전에도 다른 상점에서 이루어졌을 가능성을 생각하게 함
     * 스위치는 세금 문제와 관련이 있을 수 있으며, 비즈니스와 개인 여행을 기록하기 위한 것일 수 있음
          + 개인 여행으로 설정하면 추적이 비활성화될 수 있음
     * 대부분의 기업용 GPS 트래커는 데이터 연결이 필요하며, 월 최소 $€£ 10의 비용이 발생함
          + 구독을 중단하면 라인이 비활성화됨
          + 따라서 GPS 추적이 이루어지지 않을 가능성이 높음
"
"https://news.hada.io/topic?id=18098","Ask GN: 폰트를 어떤기준으로 선택하나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Ask GN: 폰트를 어떤기준으로 선택하나요?

부제: 폰트의 어떤부분을 보고 예쁘다고 느끼시나요?

   저는 폰트가 서로 다르구나? 정도의 느낌은 있지만 어떤 느낌으로 다른지에 대한 감각이 전혀 없습니다.

   예를들면 사람은 눈이 크다, 코가 오똑하다, 이마가 넓다 이런 느낌이 느껴지는데, 폰트는 어떤걸 기준으로 보아야할지 전혀 감이 오지 않습니다.

   폰트는 어떻게 보아야하나요..?

   (폰트를 보고 아, 000 코드군요. 하는 사람들이 너무 신기해요..)

   유튜브 보면 손글씨 예쁘게 쓰시는 분들 있잖아요? 그런 느낌이예요. 어떤 폰트는 다른 폰트보다 더 예뻐 보인답니다!

   어느정도 직관에 따른다는 느낌이군요 ㅎㅎ

   저의 경우엔 그렇습니다 :D

   저 역시 개인 선호도에 따라 다르겠지만 글자 폭이 너무 좁지 않은 쪽을 선호합니다.

   영문 소문자 g를 표현하는 방법이 다른 폰트도 있습니다. (필기체 혹은 숫자 9 처럼)

   j나 e a 등등 끝선을 표현하는데 있어서 늘어지듯 끝나는 문자가 있는가 하면
   끝을 살짝 올려주는 폰트도 있구요

   직각으로 딱 떨어지듯 꺾이는 폰트가 있는가 하면 곡선으로 표현한 폰트도 있고,
   개인의 취향에 따라 많이 달라지겠죠?;;

   제가 선호하는 폰트는 (가장 자주 쓰는)
   SF Mono (San Francisco)
   Source code pro

   저는 어차피 많이 보는게 코드 밖에 없어서 ㅎㅎ
   그리고 글을 많이 쓰시는 분들은 각자 선호하시는 폰트가 뚜렸하고, 이유도 확실하신 분들이 많더라구요

   폭, 특정 글자의 표현, 끝선처리, 직각/곡선 정도를 볼 수 있는거군요. 상세한 답변 감사드립니다!!

   전 개인적으로는 모양에 대한 선호보다는 고정폭, 비슷해서 헷갈리기 쉬운 문자들에 대한 명확한 구분 (o, 0 , I(I 대문자) , l(L 소문자) ) 같은 것만 되면 잘씁니다 ㅎ
"
"https://news.hada.io/topic?id=18037","수면 공학 (Sleep Engineering)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       수면 공학 (Sleep Engineering)

     * 인간은 삶의 3분의 1을 수면에 소비하며, 물과 같이 필수적인 요소임
     * 수면은 뇌, 심장, 면역 등 중요한 신체 시스템을 조절하며, 부족할 경우 심리적, 신체적 손상이 발생함
     * FNSS(Familial Natural Short Sleep, 가족성 자연 단기 수면)라는 희귀 돌연변이를 가진 일부 사람들은 7-9시간의 권장 수면 시간을 초과하지 않아도 건강한 상태를 유지함
     * FNSS를 가진 사람들은 건강하고, 에너지가 넘치며, 낙관적이고, 높은 통증 역치를 가지며, 수면 부족의 부정적인 영향을 받지 않음
     * FNSS는 수면 효율성이 뛰어난 사람들 사이에서 발견되며, 이는 수면의 주요 기능을 더 빠르고 효율적으로 수행하는 것으로 설명됨

수면 돌연변이

     * FNSS는 주로 DEC2라는 유전자와 관련이 있으며, 이는 수면 시간을 줄이는 것으로 나타남
     * 2009년 연구에서 DEC2 돌연변이(DEC2P384R)가 발견되었으며, 이는 orexin이라는 신경전달물질의 발현을 증가시킴
     * orexin은 각성과 수면을 조절하는 데 중요한 역할을 하며, 결핍 시 나르콜렙시(과도한 졸음), 과잉 시 불면증을 유발함
     * FNSS와 불면증 모두 높은 orexin 수준과 관련 있지만, FNSS는 건강을 유지하며 불면증은 그렇지 않음

FNSS 재현

     * UCSF 연구팀은 DEC2P384R 돌연변이을 가진 인간 유전자를 생쥐 배아에 삽입하여 1-2시간의 수면시간을 줄이는 데 성공했으나, 장기적인 안전성과 효과는 확인되지 않음
     * FNSS를 재현하는 목표는 성인에게도 적용 가능한 안전하고 평생 지속 가능한 방법을 개발하는 것임
     * 두 가지 접근법이 검토됨 : orexin 작용제와 유전자 치료

  접근법 1: Orexin Agonists

     * Orexin 수용체를 활성화하는 약물을 경구 투여하여 수면 효율성을 개선하려는 방법
     * 주요 불확실성은 orexin 상승이 FNSS와 같은 효과를 재현할 수 있을지 여부임
     * 장기적인 효과 및 내성과 금단 증상의 가능성은 아직 연구되지 않음

  접근법 2: 유전자 치료

     * 자연적인 FNSS 변이를 복제하는 방법으로, DEC2P384R 돌연변이를 AAV9 벡터를 사용하여 orexin을 발현하는 뉴런에 전달
     * 돌연변이를 성인에서 발현시키는 것이 효과적일지에 대한 데이터가 부족하며, 면역 반응 및 예측 불가능한 효과가 우려됨

FNSS의 희귀성

     * FNSS를 가진 가정은 약 90개만 발견됨
     * FNSS가 정말로 무해하다면 왜 그렇게 드문지 의문이 있음
          + 더 효율적인 수면이 진화적 이점을 제공한다면 더 널리 퍼졌을 것이라는 의문이 제기됨
     * 돌연변이가 생존에 중립적이거나 생식 성공에 영향을 미치지 않는다고 볼 수 있음

다음 단계

     * FNSS는 수면 연구에 중요한 기회를 제공하며, 더 많은 연구가 필요함
     * FNSS 데이터베이스 확장 및 돌연변이 보유자 유전자 서열 분석
     * FNSS 재현을 위한 두 가지 경로 테스트

   제가 7-9 시간보다는 한참 모자르게 자는 편인데 아직 괜찮은 편이긴 합니다.
   늙어서 힘들어질거라는 얘기도 있던데, 한살이라도 젊을때 더 재미나게 살면되지? 하는 맘으로..

        Hacker News 의견

     * FNSS라는 유전적 변이는 수면 부족의 부정적 영향을 받지 않고 1-2시간 덜 자도 되는 특징이 있음
          + 수면 부족은 인지 기능, 건강, 장기적인 건강 결과에 영향을 줄 수 있음
          + 수면은 뇌를 재생하는 데 중요한 역할을 하며, 만성적인 수면 부족은 치매 위험을 높일 수 있음
          + 수면의 질이 중요하며, 수면 시간만으로는 충분하지 않음
     * Orexin 수용체 길항제는 불면증 치료에 효과적임
          + 이 약물은 매우 비싸지만, 다른 수면 보조제보다 효과적이고 부작용이 적음
          + 수면의 질을 개선하며, 장기적으로 큰 인기를 끌 가능성이 있음
     * 거의 모든 동물은 어떤 형태로든 수면을 취함
          + 수면은 진화적으로 중요한 이유가 있을 것임
     * 수면의 양보다 질이 중요하다는 의견
          + AffectableSleep.com은 깊은 수면의 효율성을 높이는 연구를 진행 중임
          + 수면의 질을 개선하는 것이 목표이며, 수면 시간을 줄이는 것이 아님
     * Orexin과 수면의 관계에 대한 연구가 있음
          + NT1 환자는 orexin 수치가 낮아 부적절하게 REM 수면에 들어감
          + orexin 수치 증가가 수면의 질에 미치는 영향을 연구할 필요가 있음
     * FitBiomics의 제품은 수면 건강을 개선하는 데 도움을 줌
          + V•Nella와 Nella는 피로를 줄이고 에너지를 증가시킴
          + 사용자들은 피로 감소와 에너지 증가를 경험함
     * 만성적인 수면 부족은 치매, 심장병, 당뇨병 등의 위험을 증가시킬 수 있음
          + 수면 시간이 줄어들면 장기적인 건강에 부정적인 영향을 미칠 수 있음
     * 진화적으로 수면이 줄어드는 것이 생존에 유리하지 않음
          + 깨어 있는 시간은 대사율을 증가시킴
          + 수면이 부족하다고 해서 더 많은 일을 할 수 있는 것은 아님
     * 글쓰기 스타일이 간결하고 목적이 분명하여 좋음

   커피를 달고사는 입장에서, 여기 나오는 nella가 궁금하네요.
   의약품이라 선뜻 구매하기는 좀 그렇고. 원문도 인용한 내용이네요.

   저도..

   Nella와 V.Nella는 알아보았더니 프로바이오틱스네요.

   잠 자는데 도움을 준다는 넬라는 락토바실러스 유산균 3종류고 (람노서스, 플란타룸, 아시도필루스)

   깨어서 활동에 도움을 준다는 V 넬라는 치은연하에 많이 보이고 젖산을 먹고 자라는 미생물인 베일로넬라 아티피카가 전부에요.

   베일로넬라 아티피카가 젖산을 먹고 자라서 근육을 쓰며 일하거나 운동하는 사람들의 젖산 분해에 도움을 주며 하네요. 앉아서 일하는 사람에게는 해당되는 게 없어 보입니다...
"
"https://news.hada.io/topic?id=18117","Diátaxis – 기술 문서 작성의 체계적 접근법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Diátaxis – 기술 문서 작성의 체계적 접근법

     * Diátaxis는 기술 문서 작성에 대한 체계적인 접근 방법을 제시하는 개념임. 이 접근법은 문서 사용자들의 필요를 이해하는 체계적인 접근에서 출발하여, 콘텐츠, 구조, 형식에 대한 접근 방식을 제안함.
     * 고대 그리스어에서 유래한 Diátaxis는 네 가지의 명확한 필요와 이에 대응하는 문서 형식인 튜토리얼, 사용 방법 가이드, 기술 참조, 설명을 식별함. 이러한 필요의 구조에 따라 문서를 조직화할 것을 제안함.
     * Diátaxis는 문서의 콘텐츠(무엇을 쓸 것인가), 스타일(어떻게 쓸 것인가), 구조(어떻게 조직할 것인가)와 관련된 문제를 해결함.
     * 문서 사용자뿐만 아니라 문서 작성자와 유지보수자에게도 가치가 있음. 가볍고 이해하기 쉬우며 적용하기 간단함. 구현 제약을 강요하지 않으며, 문서의 품질을 높이는 적극적인 원칙을 제공함.

  콘텐츠

     * 이 웹사이트는 Diátaxis를 적용하고 이해하는 데 도움이 되는 두 가지 주요 섹션으로 나뉨.
          + 여기서 시작하세요. 이 페이지들은 접근 방식을 즉각적이고 구체적으로 이해하는 데 도움을 줌.
               o Diátaxis 적용
               o 튜토리얼
               o 사용 방법 가이드
               o 참조
               o 설명
               o 나침반
               o 워크플로우
          + 이 섹션은 Diátaxis의 이론과 원칙을 더 깊이 탐구하고, 이를 뒷받침하는 필요에 대한 이해를 제시함.
               o Diátaxis 이해하기
               o 기초
               o 지도
               o 품질
               o 튜토리얼과 사용 방법 가이드
               o 참조와 설명
               o 복잡한 계층 구조
     * Diátaxis는 실무에서 입증된 원칙임. 수백 개의 문서 프로젝트에서 성공적으로 채택됨.
          + Gatsby에서는 오픈 소스 문서를 재구성할 때 Diátaxis 프레임워크를 주요 자원으로 사용함. 네 가지 사분면은 각 문서 유형에 대한 사용자의 목표를 우선시하는 데 도움을 줌.
          + Cloudflare 개발자 문서를 재설계할 때 Diátaxis는 정보 구조의 북극성이 되었음. 새로운 콘텐츠의 위치를 결정할 때 프레임워크를 참조함으로써 문서가 독자와 기여자 모두에게 더욱 명확해짐.

        Hacker News 의견

     * 한 사용자는 모든 정보를 한 번에 전달할 필요가 없다는 점을 깨달음이 중요하다고 언급함. 다양한 독자를 위해 정보를 여러 방식으로 작성하는 것이 유용하다고 함
     * Sequin 문서에 Diátaxis 프레임워크를 적용하여 문서 흐름이 개선되었음을 설명함. 그러나 Diátaxis 자체 문서는 다소 난해하고 장황하다고 언급함
          + 요리 기구를 구매할 때의 과정을 비유로 들어 설명함
               o 먼저 ""빠른 시작"" 튜토리얼을 통해 일반적인 사용법을 확인함
               o 특정 요리를 위해 어떻게 사용하는지 알아보는 것이 ""how-to""임
               o 더 깊이 알고 싶다면 참고 자료를 찾아봄
               o 압력 조리의 과학적 원리를 이해하고 싶다면 설명 자료를 읽음
     * 기술 문서 작성자들은 Diátaxis가 DITA와 유사하다고 언급함. 그러나 사용자 필요를 놓칠 수 있으며, 정보 재사용을 위해 정보를 작은 조각으로 나누어야 할 필요가 있다고 설명함
     * SwiftUI 앱을 개발한 사용자는 현대 기술 문서가 부실하게 다뤄지고 있다고 느끼며, 문서는 유지보수자와 사용자의 두 가지 측면을 고려해야 한다고 주장함
     * Diátaxis는 문서 구조화에 유용하지만, 너무 엄격하게 적용하면 함정이 될 수 있다고 언급함
     * Diátaxis의 진정한 가치는 문서 작성 방식을 단순화하는 데 있다고 설명함. 각 사용자의 필요에 맞게 문서를 작성하는 것이 중요함
     * divio의 그래픽이 더 직관적이지만, Diátaxis가 더 포괄적인 문서를 제공한다고 언급함
     * Diátaxis를 채택한 후 기술 문서가 크게 개선되었으며, 페이지 소유권과 주기적인 검토가 성공적인 문서화에 기여했다고 설명함
     * Diátaxis 프레임워크는 간단하고 이해하기 쉬운 구조를 제공하여 기술 문서 작성에 유용하다고 언급함
     * Diátaxis를 사용하여 Logdy의 문서를 작성 중이며, 이 방법이 소프트웨어 제품을 문서화하는 데 유용한지에 대한 의견을 구함. 블로그 포스트를 통해 제품 사용법을 효과적으로 전달했다고 설명함
"
"https://news.hada.io/topic?id=18104","DeepMind의 Genie 2: 대규모 기초 세계 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    DeepMind의 Genie 2: 대규모 기초 세계 모델

     * Genie 2는 인간이나 AI 에이전트가 키보드와 마우스를 사용하여 조작할 수 있는 다양한 3D 환경을 생성하는 기초 세계 모델
     * 게임은 AI 연구에서 중요한 역할을 하며, Genie 2는 무한한 커리큘럼의 새로운 세계에서 에이전트를 훈련하고 평가할 수 있게 함
     * 기능
          + 빠른 프로토타이핑: Genie 2는 다양한 상호작용 경험을 빠르게 프로토타이핑할 수 있게 하여 연구자들이 새로운 환경을 실험할 수 있게 함.
          + 에이전트 배치: Genie 2를 사용하여 AI 에이전트를 위한 풍부하고 다양한 환경을 빠르게 생성할 수 있음.
          + 모델 아키텍처: 대규모 비디오 데이터셋으로 훈련된 Genie 2는 다양한 객체 상호작용, 복잡한 캐릭터 애니메이션, 물리학 등을 모델링할 수 있음.
          + 책임 있는 개발: Genie 2는 다양한 3D 환경을 생성하고 에이전트 연구를 가속화하는 기초 세계 모델의 잠재력을 보여줌.
     * Emergent capabilities
          + Genie 2는 다양한 3D 세계를 생성할 수 있으며, 객체 상호작용, 복잡한 캐릭터 애니메이션, 물리학 등을 모델링할 수 있음.
          + 사용자는 텍스트로 세계를 설명하고, 그 아이디어의 렌더링을 선택하여 새로 생성된 세계와 상호작용할 수 있음.
          + 행동 제어 : Genie 2는 키보드 입력에 따라 캐릭터를 올바르게 식별하고 이동시킴.
          + 반사적 경험 생성 : 같은 시작 프레임에서 다양한 경로를 생성하여 에이전트 훈련을 위한 반사적 경험을 시뮬레이션할 수 있음.
          + 긴 시간 기억 : Genie 2는 시야에서 벗어난 세계의 일부를 기억하고, 다시 관찰 가능해지면 정확하게 렌더링할 수 있음.
          + 다양한 환경 : Genie 2는 1인칭, 등각 투영, 3인칭 운전 비디오 등 다양한 관점을 생성할 수 있음.
          + 3D 구조 : 복잡한 3D 시각 장면을 생성할 수 있음.
          + 객체 상호작용 : 풍선 터뜨리기, 문 열기, 폭발물 발사 등 다양한 객체 상호작용을 모델링할 수 있음.
          + 캐릭터 애니메이션 : 다양한 활동을 하는 캐릭터를 애니메이션화할 수 있음.
          + NPC : 다른 에이전트와의 복잡한 상호작용을 모델링할 수 있음.
          + 물리학 : 물 효과, 연기 효과, 중력, 조명 등을 모델링할 수 있음.
          + 실제 이미지로부터의 플레이 : 실제 이미지로부터의 프롬프트를 통해 풀을 흐르는 물이나 바람에 흔들리는 풀을 모델링할 수 있음.
     * 다양한 인터랙티브 경험의 빠른 프로토타이핑
          + Genie 2는 새로운 환경을 빠르게 실험하고 구현형 AI 에이전트를 훈련 및 테스트할 수 있도록 지원
               o 예시: Imagen 3으로 생성된 이미지를 사용해 종이비행기, 드래곤, 매, 낙하산을 조종하는 다양한 환경 시뮬레이션
          + Genie 2의 분포 외 일반화 능력으로 콘셉트 아트와 그림을 완전한 인터랙티브 환경으로 변환 가능
               o 빠른 프로토타이핑을 통해 창의적인 프로세스를 부트스트래핑하고 환경 설계를 가속화
     * Genie 2를 활용한 평가 환경 생성
          + Genie 2는 AI 에이전트를 위한 풍부하고 다양한 환경을 빠르게 생성 가능
               o 훈련 중 접하지 않은 새로운 평가 과제를 생성하여 에이전트를 테스트
          + DeepMind가 게임 개발자와 협력하여 개발한 SIMA 에이전트는 자연어 지시를 기반으로 3D 게임 세계에서 작업 수행
               o Genie 2가 단일 이미지 프롬프트로 3D 환경 생성, SIMA 에이전트가 키보드와 마우스 입력을 통해 상호작용
          + 초기 단계의 연구지만 Genie 2는 훈련 환경의 다양성과 일반성을 제공하며, 구현형 에이전트의 안전한 훈련 문제를 해결하는 데 기여할 것으로 기대
          + AI 에이전트의 일반화된 훈련을 통해 AGI(인공지능 일반화)의 발전을 위한 기반 마련
     * 확산 세계 모델
          + Genie 2는 대규모 비디오 데이터셋을 기반으로 학습된 잠재 확산 모델
          + 프레임은 오토인코더를 거쳐 잠재 공간으로 변환된 후, 변환기 기반의 동적 모델에 전달
          + 학습 시 언어 모델에 사용되는 것과 유사한 인과 마스크를 적용
          + 자동회귀 방식의 추론
               o 추론 시 Genie 2는 과거 잠재 프레임과 행동 데이터를 프레임 단위로 자동회귀 방식으로 샘플링
               o Classifier-Free Guidance 기법을 사용하여 행동 제어성을 향상
          + Genie 2는 고해상도 3D 환경을 효율적으로 생성하면서 행동 제어성을 유지
          + 확산 모델과 자동회귀 접근 방식을 결합하여 몰입형 가상 환경을 위한 차세대 기술 제공
     * 책임 있는 기술 개발
          + Genie 2는 다양한 3D 환경을 생성하고 에이전트 연구를 가속화하는 기초 세계 모델의 잠재력을 보여줌.

        Hacker News 의견

     * 이 모델의 크기가 궁금하며, 기술적 세부사항이 부족한 점이 아쉬움. Google의 접근 방식이 여전히 폐쇄적임을 지적함. 하지만 사진과 텍스트 설명을 기반으로 세계를 탐색하는 가능성은 놀라움.
     * 비디오 및 세계 생성에 대한 압박이 계속되는 것이 흥미로움. 무한한 이야기 생성 게임에 대한 관심을 표현하며, 미래의 상호작용 스토리텔링의 황금기를 기대함.
     * 이 기술이 게임 개발에 유용하지 않을 수 있음을 지적함. 게임은 상호작용이 중요하며, 디자이너가 깊이 제어해야 함. 세계 생성 부분이 가장 유용하다고 생각함.
     * 이 기술이 AGI와 로봇공학에 큰 진전을 가져올 것임을 강조함. 인간의 뇌가 작동하는 방식과 유사한 기능을 기계에 추가하는 시작점으로 봄.
     * 연구의 진정한 목표는 인간의 3D 세계 이해를 능가하는 모델 개발임을 설명함. 이는 로봇공학과 자율주행차의 발전에 기여할 것임.
     * Genie2가 개념 예술의 세부사항을 무시하는 점이 실망스러움을 표현함. 원래의 아름다운 외계 생물들이 무시되는 것을 비판함.
     * 생성 AI가 유연성을 제공하지만 많은 계산이 필요함을 설명함. 전통적인 프로그래밍과 생성 AI의 역할에 대한 궁금증을 표현함.
     * 이 기술의 실제 가치를 의문시함. 높은 계산 비용과 불규칙한 행동이 문제임을 지적함.
     * MS Edge에서 스크롤이 작동하지 않아 Firefox를 사용했으며, 비디오의 시각적 품질이 좋지 않음을 언급함. AI 연구자들이 기존의 잘 작동하는 시스템을 대체하려는 이유에 의문을 가짐.
"
"https://news.hada.io/topic?id=17996","Voice AI 로드맵: 대화형 AI의 미래","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Voice AI 로드맵: 대화형 AI의 미래

     * Voice AI는 단순한 UI 업그레이드가 아니라, 비즈니스와 고객 간 연결 방식을 혁신
          + 항공사 고객 서비스 처럼 긴 대기 시간, 반복되는 메뉴 선택, 고객 상황 이해 부족. 문제는 해결하지 못하면서 불필요한 스트레스와 시간 낭비
          + Voice AI를 통하면 기존의 경직된 IVR 시스템(자동 음성 응답)과 달리, 인간처럼 대화하고 고객 경험을 개인화할 수 있는 경험 제공이 가능하며 24시간 제공 가능
               o 고객 상황을 즉각 이해하고 최적의 대안 제시
               o 예: 결항된 항공편을 자동 재예약, 고객 선호도 기반 대안 추천
               o 일부 상황에서는 고객이 인간보다 AI 에이전트를 선호할 가능성이 있음
          + Voice AI는 높은 수요와 고객 기대를 충족하면서도 운영 효율성을 높임
     * Voice AI는 음성 네이티브 AI 모델과 멀티모달 기술의 융합임
          + 인간 커뮤니케이션이 중요한 산업에서 근본적인 혁신 제공
          + 고객 기대치를 충족하고 운영을 효율적으로 확장하며, 차세대 비즈니스 커뮤니케이션 시대의 기반 마련
          + NotebookLM이 생성한 팟캐스트로 이 글의 주요 인사이트 들어보기

음성 커뮤니케이션의 거대한 시장

     * 인간은 말하기를 선호함:
          + 매일 수십억 통의 전화가 이루어짐
          + 텍스트, 이메일, 소셜 미디어가 보편화되었음에도 불구하고, 전화는 여전히 많은 비즈니스에서 주요 소통 수단
          + 의료, 법률 서비스, 홈 서비스, 보험, 물류 등 다양한 산업에서 복잡한 정보 전달, 개인화된 서비스 제공, 긴급한 상황 해결을 위해 필수적임
     * 기존 전화 커뮤니케이션의 문제점
          + 응답률 부족:
               o SMB(중소기업)의 62%가 전화를 놓쳐서 고객 요구를 충족하지 못하고 비즈니스 기회 상실
               o 일반적인 문제:
                    # 근무 시간 외에는 음성사서함으로 전환
                    # 한 번에 한 통화만 처리 가능
                    # 지원 품질이 고르지 않음
          + 기술적 제약:
               o IVR 시스템(1970년대 도입):
                    # 사전 설정된 명령만 처리, 유연성 부족 ""예약하시려면 1번을 누르세요"" ""도움받고자 하는 부분을 짧은 단어로 이야기하세요""
                    # 고객 의도나 긴급성을 이해하지 못함
               o 고객 경험 저하:
                    # 긴 대기 시간
                    # 비효율적인 메뉴 탐색
                    # 문제 해결 실패
     * 높은 수요에도 불구하고:
          + 기존 기술은 고객의 문제를 효율적이고 쾌적하게 해결하는 데 한계가 있음
          + 더 진보된 음성 자동화 기술이 요구됨

[지금이 Voice 기술 개발의 적기인 이유]

  음성 기술의 진화

    1. 초기 IVR 시스템:

     * 1970년대 도입된 IVR(Interactive Voice Response) 기술:
          + 미리 설정된 명령만 처리 가능
          + 사용자의 의도와 긴급성을 이해하지 못함
     * 비호감 기술임에도 불구하고, 여전히 50억 달러 규모의 시장

    2. ASR/STT 기술의 등장:

     * **자동 음성 인식(ASR)**과 음성-텍스트(STT) 모델:
          + 음성을 실시간으로 텍스트로 변환하는 기술
          + Gong, Rev, DeepL과 같은 신생 기업의 등장
          + OpenAI의 Whisper 모델(2022) 및 Rev의 Reverb(2024) 출시:
               o 억양, 배경 소음, 감정 등을 처리하는 자연스러운 대화 시스템 지원

    3. 최근 혁신: 음성 AI의 발전:

     * 감정적으로 풍부한 음성을 생성하는 Text-To-Speech(TTS) 모델 개발:
          + Eleven Labs 등 선도 기업
     * 멀티모달 기능:
          + Google Gemini 1.5: 음성, 텍스트, 시각 입력 통합
          + OpenAI의 Voice Engine: 인간 대화를 모방한 음성 생성
     * GPT-4o 출시:
          + 실시간 오디오, 비전, 텍스트의 네이티브 통합
          + 복합적 대화 처리 및 지능적 응답 가능

  최근 혁신이 불러온 두 가지 주요 발전

     * 고품질 모델 확산과 애플리케이션 개발:
          + 기존 ""캐스케이딩"" 아키텍처의 한계:
               o STT → LLM → TTS 변환 과정에서 지연 및 비텍스트적 정보 손실
               o 높은 **응답 지연(latency)**로 부정적 사용자 경험 초래
          + 새로운 모델:
               o GPT-4 Turbo: 지연 단축
               o 사용 사례에 따라 모델 선택 가능
     * Speech-to-Speech(STS) 모델의 부상:
          + 음성을 텍스트로 변환하지 않고 직접 처리:
               o 초저지연: 약 300ms 응답 시간으로 자연스러운 대화 구현
               o 맥락 이해: 이전 대화 정보를 유지, 의도와 감정 파악
               o 감정적 및 톤 인식 향상: 감정과 감정을 반영한 응답 제공
               o 실시간 음성 활동 감지: 사용자가 발언 중단 없이 대화 가능

  음성 네이티브 모델: 대화형 음성의 미래

     * 캐스케이딩 아키텍처의 한계를 극복:
          + 음성 전용 STS 모델:
               o Kyutai Moshi: 오픈소스 모델
               o Alibaba SenseVoice & CosyVoice: 음성 특화 모델
               o Hume Empathetic Voice Interface: 감정적 응답 처리
     * OpenAI의 Realtime API:
          + GPT-4o 기반 Speech-to-Speech 상호작용 지원

산업 채택의 주요 과제

  음성 에이전트 도입을 가로막는 세 가지 주요 요인

     * 품질(Quality):
          + 많은 음성 AI 에이전트는 아직 여러 사용 사례에서 신뢰할 만큼 안정적이지 않음.
          + 기업은 일반적으로 위험이 낮은 환경에서 음성 에이전트를 시범적으로 도입:
               o 예: 소규모 지붕 수리 회사가 영업시간 외 전화를 처리하기 위해 에이전트를 사용
               o 높은 가치의 사용 사례로 확장 시, 품질 기준이 더욱 엄격해짐
               o 예: 고객 한 명의 전화가 3만 달러 프로젝트로 이어질 수 있는 경우, 통화 실패에 대한 관용이 낮음
     * 신뢰(Trust):
          + 고객은 기존의 IVR 기술로 인해 이미 부정적 경험을 다수 겪음:
               o 느린 응답, 비효율적인 메뉴 구조, 자연스러운 대화 부족
          + 기업은 AI가 고객 요구를 정확하고 신속하게 처리할 수 있다는 신뢰 확보 필요
     * 신뢰성(Reliability):
          + 주요 불만 사례:
               o 통화 끊김: 통화 중단으로 고객 좌절
               o 환각(Hallucination): AI가 부정확하거나 엉뚱한 답변 제공
               o 응답 지연(latency): 처리 시간이 길어져 고객 이탈 초래

  문제 해결을 위한 발전 방향

     * 지연 및 신뢰성 최적화:
          + 더 신뢰할 수 있는 인프라를 제공하는 개발자 플랫폼 증가: 지연을 줄이고 대화 중단을 방지하는 데 초점
     * 회복 탄력성(Fail Gracefully):
          + 통화 실패 시 자연스럽게 대화 플로우 복구: 고객 경험의 중단을 최소화
     * 대화 오케스트레이션:
          + AI 에이전트가 예측 가능한 플로우를 따르도록 설계: 환각 최소화, 고객에게 제공할 정보 및 대화 범위에 가드레일 설정

음성 AI 시장 지도

     * 음성 AI 시장은 기반 모델부터 음성 인프라, 개발자 플랫폼, 그리고 응용 프로그램까지 다양한 계층에서 혁신이 이루어지고 있음
     * 특히 아래의 세 가지 핵심 분야에서 주목할 만한 기회가 포착됨

  1. 모델(Models)

     * 기능: 음성 기반 사용 사례를 지원하는 기술을 구축하며, SST(Speech-to-Speech), LLS(Large Language Models), TTS(Text-to-Speech) 등 특정 기술에 특화
     * 미래 방향:
          + 멀티모달 및 음성 네이티브 모델이 주도
          + 텍스트-오디오 간 전환 없이 오디오를 직접 처리할 수 있는 기술이 중요
     * 차세대 모델:
          + Cartesia와 같은 기업은 **State Space Models(SSMs)**을 활용한 새로운 아키텍처를 개척
          + 단순한 대화 처리는 소형 모델로, 복잡한 작업은 강력한 모델로 분리해 지연(latency) 및 비용 절감 기대

  2. 개발자 플랫폼(Developer Platforms)

     * 음성 AI 에이전트 구축과 실시간 음성 인프라 관리는 여전히 개발자들에게 큰 기술적 도전. 새로운 플랫폼은 이러한 복잡성을 해결하며, 개발자에게 다양한 지원 제공
     * 지연 및 신뢰성 최적화:
          + 성능 높은 실시간 음성 에이전트를 확장 가능한 형태로 관리.
     * 대화 신호 및 비언어적 맥락 관리:
          + 사용자가 발화를 끝냈는지 판단하는 ""엔드포인팅"" 탐지.
          + 배경 소음 필터링 및 감정·정서 감지 개선.
     * 효율적인 오류 처리:
          + 실패한 API 호출 감지 및 즉각적인 재시도.
          + 대화 중단을 방지하는 대체 응답 삽입.
     * 타사 시스템 통합 및 RAG 지원:
          + 지식 기반과 타사 시스템에 저지연 통합 필요.
     * 대화 흐름 제어:
          + 예측 가능한 대화 플로우 설계로 민감하거나 규제된 대화 처리 지원.
     * 관찰 가능성, 분석, 테스트:
          + 대화 품질과 성능을 대규모로 추적할 수 있는 도구 부족 문제 해결.
     * 플랫폼 예시 Vapi: 음성 인프라의 복잡성을 줄이고 고품질의 음성 에이전트를 빠르게 구축할 수 있도록 지원

  3. 응용 프로그램(Applications)

     * 음성을 활용한 자동화 제품이 다양한 분야에서 개발되고 있음.
     * 가장 주목받는 응용 프로그램의 특징:
          + 고객의 작업을 완전히 처리하고 가치 있는 결과 제공.
          + 수요 급증 시 수천 건의 통화를 동시에 처리할 수 있는 확장성.
          + 특정 산업에 특화된 맞춤형 솔루션 제공.
     * 기능별 주요 기회
          + 전사(Transcription): 대화 메모 작성, 후속 작업 추천
          + 인바운드 호출(Inbound Calling): 예약 관리, 잠재 고객 전환, 고객 성공 관리
          + 아웃바운드 호출(Outbound Calling): 지원자 선별, 약속 확인
          + 훈련(Training): 판매 또는 인터뷰 훈련.
          + 협상(Negotiation): 구매 협상, 보험 분쟁, 계약 조정
     * 투자 사례
          + Abridge: 의료 대화 문서화
          + Rilla: 현장 영업 코칭
          + Rev: 산업 전반에서 AI와 인간의 협업 전사 제공

구체적 응용 사례

     * 산업 특화 솔루션 Sameday AI: 홈 서비스 산업의 AI 판매 에이전트. 고객 전화 접수 → 문제에 따른 견적 제공 → 일정 조율 → 결제 완료까지 자동화.
     * 아웃바운드 호출 Wayfaster: 채용 프로세스 자동화. 지원자 선별 통화를 자동으로 진행하여 최상위 후보자에 집중.
     * 의료 보험 협상 : LLM을 활용해 수천 건의 보험 문서와 환자 기록을 분석, 실시간 협상 지원.

Voice AI 기술 투자 원칙

     * Voice AI 생태계는 개발자 플랫폼과 응용 프로그램 계층에서 가장 큰 창업 기회가 존재
     * 빠른 모델 개선 속도로 인해 기업가들이 적은 초기 투자로도 효과적인 MVP(최소 기능 제품)를 빠르게 개발하고 테스트할 수 있는 환경이 마련됨
     * 1. 산업별 워크플로와 다중 모달리티에 깊이 통합된 솔루션
          + 가장 영향력 있는 음성 AI 애플리케이션은 특정 산업의 워크플로에 맞게 깊이 통합됨
          + 각 산업에 특화된 언어 및 대화 방식에 맞춰 조정
          + 예:
               o 자동차 딜러용 음성 에이전트가 CRM과 통합되어 과거 고객 상호작용 데이터를 활용, 서비스 품질을 개선하고 배포 속도 향상
               o 음성과 텍스트, 이미지 등 다양한 모달리티를 결합하여 더 복잡한 인간의 다단계 프로세스를 해결
     * 2. 견고한 엔지니어링을 통한 고품질 제품 제공
          + 해커톤용 데모 제작은 비교적 간단하지만, 실질적인 제품은 높은 신뢰성, 확장성, 실사용 사례 처리 능력이 필요
          + 기업 요구사항: 일관된 성능 제공. 낮은 지연(latency) 보장. 기존 시스템과의 매끄러운 통합
          + 중점 설계 요소: 예측 불가능한 음성 입력 처리. 보안 강화. 높은 가동 시간(uptime) 유지
     * 3. 성장과 유지, 제품 품질 KPI 간 균형
          + 음성 에이전트는 매출 주도 기능(예: 영업)에서 강력한 성장 잠재력을 가짐.
          + 고객이 핵심 워크플로를 사람에서 에이전트로 전환할 때 품질 저하는 높은 해지율(churn)로 이어질 수 있음.

  중요 KPI 및 품질 지표

     * Churn (고객 이탈률):
          + 초기 단계에서 음성 애플리케이션이 높은 이탈률로 어려움을 겪는 사례가 많음.
          + 신뢰할 수 없는 서비스로 고객이 경쟁사로 이동하는 경우 발생.
     * Self-Serve Resolution (셀프 서비스 해결율):
          + 음성 에이전트가 인간의 개입 없이 사용자의 문제를 얼마나 효과적으로 해결하는지를 나타냄.
     * Customer Satisfaction Score (고객 만족도 점수):
          + 음성 에이전트와 상호작용한 고객의 전반적인 만족도를 측정, 품질 통찰 제공.
     * Call Termination Rates (통화 종료율):
          + 높은 종료율은 사용자 경험의 문제와 미해결 문제를 나타냄.
     * Cohort Call Volume Expansion (코호트 통화량 확장):
          + 시간이 지남에 따라 고객이 음성 에이전트 사용량을 늘리는지 측정, 제품 가치와 사용자 참여의 지표.

Voice AI의 미래

     * 최근 몇 년간의 기술 발전은 복잡한 문제를 해결하는 혁신적인 제품 개발 가능성을 열어줌
     * 향후 멀티모달 및 실시간 대화 시스템이 다양한 산업에서 더 많은 문제를 해결할 것으로 기대됨

   제가 예전에 IVR 쪽 일을 했어서 그런지 이쪽에 관심이 많네요 ㅎ

   a16z가 정리한 AI Voice 에이전트에 대한 모든 것 글도 함께 보세요
"
"https://news.hada.io/topic?id=18035","Rust-Query - Rust Type 시스템을 사용한 안전한 RDB쿼리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Rust-Query - Rust Type 시스템을 사용한 안전한 RDB쿼리

     * ""Rust에서 안전하게 데이터를 영구 저장하고, 복잡한 쿼리를 쉽게 작성하며, SQL을 한 줄도 작성하지 않아도 된다면 어떨까?""
          + Rust-query는 이를 실현하기 위해 개발된 라이브러리임

  Rust와 데이터베이스

     * Rust의 기존 데이터베이스 라이브러리는 컴파일 시점 보장이 부족하거나 사용이 번거롭고 SQL처럼 직관적이지 않음
     * 데이터베이스는 충돌-방지 소프트웨어를 구축하고, 아토믹 트랜잭션을 지원하는 데 중요한 역할을 함
     * SQL은 데이터베이스와 상호작용하기 위한 표준 프로토콜이지만, 컴퓨터가 생성하는 것이 적합하며 사람이 직접 작성하기에는 비효율적임

  Rust-query 소개

     * rust-query는 Rust의 타입 시스템과 깊이 통합된 데이터베이스 쿼리 라이브러리임
     * Rust에서 네이티브처럼 데이터베이스 작업을 수행할 수 있도록 설계됨

    주요 기능 및 설계 결정

     * 명시적 테이블 별칭: 테이블 조인 후 해당 테이블을 나타내는 더미 객체 제공 (let user = User::join(rows);)
     * Null 안전성: 쿼리의 선택적 값은 Rust의 Option 타입으로 처리
     * 직관적인 집계 함수: GROUP BY 없이 행 단위의 직관적인 집계 지원
     * 타입 안전 외래 키 탐색: 외래 키를 기반으로 암시적 조인을 쉽게 수행 (track.album().artist().name())
     * 타입 안전 고유 조회: 특정 고유 제약 조건을 가진 행 조회 (Option<Rating> 반환)
     * 다중 버전 스키마: 선언적 방식으로 모든 스키마 버전 차이를 확인 가능
     * 타입 안전 마이그레이션: 임의의 Rust 코드를 사용해 행 처리 가능
     * 타입 안전 고유 충돌 처리: 고유 제약 조건 충돌 시 특정 에러 타입 반환
     * 트랜잭션 수명에 묶인 행 참조: 행 참조는 행이 존재할 때만 유효
     * 캡슐화된 타입 행 ID: 행 번호는 API 외부로 노출되지 않음
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

쿼리 및 데이터 삽입

  스키마 정의

#[schema]
enum Schema {
    User {
        name: String,
    },
    Story {
        author: User,
        title: String,
        content: String,
    },
    #[unique(user, story)]
    Rating {
        user: User,
        story: Story,
        stars: i64,
    },
}
use v0::*;

     * Rust의 enum 구문을 사용하여 스키마 정의
     * 외래 키 제약 조건은 다른 테이블 이름을 열 타입으로 지정하여 생성
     * #[unique] 속성을 사용해 고유 제약 조건 추가
     * #[schema] 매크로는 정의를 분석하여 v0 모듈 생성

  데이터 삽입

fn insert_data(txn: &mut TransactionMut<Schema>) {
    let alice = txn.insert(User { name: ""alice"" });
    let bob = txn.insert(User { name: ""bob"" });

    let dream = txn.insert(Story {
        author: alice,
        title: ""My crazy dream"",
        content: ""A dinosaur and a bird..."",
    });

    let rating = txn.try_insert(Rating {
        user: bob,
        story: dream,
        stars: 5,
    }).expect(""no rating for this user and story exists yet"");
}

     * 삽입 작업은 새로 삽입된 행의 참조를 반환
     * 고유 제약 조건이 있는 테이블 삽입 시 try_insert 사용 필요
     * try_insert는 충돌 시 특정 에러 타입 반환

  데이터 쿼리

fn query_data(txn: &Transaction<Schema>) {
    let results = txn.query(|rows| {
        let story = Story::join(rows);
        let avg_rating = aggregate(|rows| {
            let rating = Rating::join(rows);
            rows.filter_on(rating.story(), &story);
            rows.avg(rating.stars().as_float())
        });
        rows.into_vec((story.title(), avg_rating))
    });

    for (title, avg_rating) in results {
        println!(""story '{title}' has avg rating {avg_rating:?}"");
    }
}

     * rows는 쿼리에서 현재 행 집합을 나타냄
     * aggregate를 사용하여 집계 연산 수행
     * 결과는 튜플이나 구조체의 벡터로 수집 가능
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

스키마 진화와 마이그레이션

     * 새로운 스키마 버전을 생성할 때는 #[version] 속성을 사용함

  새로운 스키마 버전 추가

#[schema]
#[version(0..=1)]
enum Schema {
    User {
        name: String,
        #[version(1..)]
        email: String,
    },
    // ... 나머지 스키마 ...
}
use v1::*;

  데이터 마이그레이션

     * 마이그레이션은 이전 및 새로운 스키마에 대해 타입 검사됨
     * 행 데이터를 임의의 Rust 코드로 처리 가능 (map_dummy 사용)

let m = m.migrate(v1::update::Schema {
    user: Box::new(|old_user| {
        Alter::new(v1::update::UserMigration {
            email: old_user
                .name()
                .map_dummy(|name| format!(""{name}@example.com"")),
        })
    }),
});
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

마무리

     * rust-query는 Rust에서 관계형 데이터베이스와 상호작용하는 새로운 접근 방식을 제시함:
          + 컴파일 시점 검사
          + Rust와 조합 가능한 쿼리
          + 타입 검사를 통한 스키마 진화 지원
     * 현재 SQLite를 유일한 백엔드로 사용하며, 실험적 응용 프로그램 개발에 적합
     * GitHub 이슈를 통해 피드백 환영

   | 컴퓨터가 생성하는 것이 적합하며 사람이 직접 작성하기에는 비효율적임
   개발자가 100명 이상 투입되는 한국에만 있는 '차세대'를 해보는 입장에서는.

   매우 흥미롭군요.

   사실 투입되는 대부분의 개발자들은 SQL전문가? 들이거든요.

        Hacker News 의견

     * 애플리케이션 정의 스키마에 대한 우려는 잘못된 시스템에 의해 검증된다는 점임. 데이터베이스가 스키마의 권위자이며, 다른 모든 애플리케이션 레이어는 이를 기반으로 가정함. Rust의 SQLx는 데이터베이스 타입에 기반한 구조체를 생성하여 컴파일 타임에 검증하지만, 프로덕션 데이터베이스와 동일한 타입을 보장하지 않음. 로컬 Postgres v15에서 쿼리를 설계하고 프로덕션에서 Postgres v12를 실행할 때 런타임 오류가 발생할 수 있음. 애플리케이션 정의 스키마는 잘못된 안전감을 제공하고 엔지니어에게 추가 작업을 부과함.
     * SQL은 완벽하지 않지만 몇 가지 장점이 있음. 대부분의 사람들이 기본적인 SQL을 알고 있으며, PostgreSQL 같은 데이터베이스의 문서는 SQL로 작성됨. 외부 도구도 SQL을 사용하며, 쿼리 변경 시 비싼 컴파일 단계가 필요하지 않음. SQLx는 매개변수를 타입 체크하고 데이터베이스 자체가 쿼리를 검증하도록 하여 컴파일 시간을 증가시키는 타입 시스템 문제를 피함. 새로운 데이터베이스에서는 더 나은 쿼리 언어가 승리할 수 있지만, 기존 SQL 데이터베이스에서는 SQLx가 더 나은 선택임.
     * SQL은 컴퓨터가 작성해야 한다는 의견에 대해 반대하는 의견이 있음. SQL은 고수준 언어로, 파이썬이나 러스트보다 더 높은 수준임. SQL은 읽기 쉽고 사용하기 쉽게 설계되었으며, 컴파일 시 여러 절차로 변환됨. SQL은 웹 개발의 병목 지점에 있으며, 상태 변형이 발생하는 곳임. SQL은 높은 수준의 언어이기 때문에 최적화가 어려움. SQL은 기술 부채로, 더 적절한 API를 개발하는 것보다 SQL을 사용하는 것이 10배 더 효율적임.
     * Rust의 typesafe-db-access에 대한 탐색이 기쁘다는 의견이 있음. 기존 라이브러리는 컴파일 타임 보장을 제공하지 않으며, SQL처럼 장황하거나 어색함. diesel은 컴파일 타임 보장을 제공함. ORM 대 비ORM 논쟁에서 typesafe 쿼리 빌더를 선호하며, diesel은 이 범주에 속함. Rust-query는 전체 ORM 쪽으로 기울어질 것으로 보임.
     * 스키마와 데이터 타입을 연결하는 접근 방식이 흥미롭다는 의견이 있음. 예제에서 Schema 열거형이 없다는 점이 직관적이지 않음. 매크로 안에 정의되면 더 명확할 것임.
     * 라이브러리 API에서 실제 행 번호가 노출되지 않는다는 점이 혼란스러움. 웹 서버에서는 데이터에 행 ID를 전달하여 프론트엔드에서 다른 요청으로 데이터를 참조하고 수정할 수 있어야 함.
     * SQL은 컴퓨터가 작성해야 한다는 의견에 부분적으로 동의하지만, SQL은 코드 생성기가 작성하기에 가장 편리한 언어가 아님. 단순한 계획 최적화가 쿼리의 레이아웃을 완전히 변경할 수 있음. Google의 SQL pipe 제안은 약간 개선되었지만, 새로운 쿼리 언어의 문제를 여전히 가지고 있음.
     * SeaQuery를 사용해왔지만, 고급 쿼리를 생성하려면 문서가 충분하지 않다는 의견이 있음. 강력한 타입의 쿼리가 개발 과정을 느리게 할 수 있어, 기존의 준비된 문과 값 바인딩으로 돌아가는 것을 고려 중임.
     * 개별 행 수준의 조작을 통한 마이그레이션은 실행 속도가 매우 느릴 수 있음. 예를 들어, 10억 개의 행이 있는 테이블에서 일반적인 업데이트 문이 한 시간까지 걸릴 수 있음. 행별 업데이트는 더 많은 시간이 걸릴 것임.
"
"https://news.hada.io/topic?id=18027","파이프라인이 가끔 "멈추는" 이유: 버퍼링 문제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       파이프라인이 가끔 ""멈추는"" 이유: 버퍼링 문제

    파이프가 ""멈추는"" 이유: 버퍼링

     * 문제 설명: 로그 파일에서 특정 출력을 찾기 위해 tail -f /some/log/file | grep thing1 | grep thing2 명령어를 실행할 때, 로그 라인이 느리게 추가되면 출력이 나타나지 않는 문제 발생. 이는 파이프가 멈추는 것처럼 보이지만 실제로는 프로그램이 데이터를 파이프에 쓰지 않기 때문임.

    버퍼링의 원인

     * 버퍼링의 이유: 프로그램이 데이터를 파이프나 파일에 쓰기 전에 버퍼링을 하는 것이 일반적임. 이는 성능 향상을 위해 모든 출력을 즉시 쓰는 대신, 일정량의 데이터를 모아서 한 번에 쓰기 때문임.
     * 예시: grep thing1은 8KB의 데이터를 모을 때까지 매칭된 데이터를 저장하고, 이로 인해 출력이 나타나지 않을 수 있음.

    터미널에 쓸 때는 버퍼링하지 않음

     * 터미널과 파이프의 차이: grep은 출력이 터미널로 향할 때는 라인 버퍼링을 사용하지만, 파이프로 향할 때는 블록 버퍼링을 사용함. 이는 isatty 함수를 통해 결정됨.

    버퍼링하는 명령어와 하지 않는 명령어

     * 버퍼링하지 않는 명령어: tail, cat, tee 등은 버퍼링하지 않음.
     * 버퍼링하는 명령어: grep, sed, awk, tcpdump, jq, tr, cut 등은 버퍼링하며, 일부는 특정 플래그로 버퍼링을 비활성화할 수 있음.

    프로그래밍 언어의 기본 출력 버퍼링

     * 버퍼링하는 언어: C, Python, Ruby, Perl 등은 기본적으로 출력 버퍼링을 하며, 특정 방법으로 비활성화 가능함.

    Ctrl-C를 눌렀을 때 버퍼 내용 손실

     * 문제 설명: Ctrl-C를 누르면 버퍼에 있는 내용이 손실됨. 이는 SIGINT 신호가 먼저 전달되기 때문임.
     * 해결책: tcpdump의 PID를 찾아 kill -TERM $PID를 실행하면 버퍼를 플러시할 수 있음.

    파일로 리다이렉션할 때도 버퍼링

     * 파일 리다이렉션: 파일로 리다이렉션할 때도 버퍼링이 발생하지만, Ctrl-C로 인한 버퍼 손실 문제는 발생하지 않음.

    버퍼링을 피하는 여러 방법

     * 해결책 1: 빠르게 종료되는 프로그램 실행.
     * 해결책 2: grep의 --line-buffered 플래그 사용.
     * 해결책 3: awk 사용.
     * 해결책 4: stdbuf 사용.
     * 해결책 5: unbuffer 사용.

    버퍼링을 비활성화하는 환경 변수

     * 아이디어: PYTHON_UNBUFFERED와 같은 표준 환경 변수가 있으면 좋겠다는 의견. NO_BUFFER와 같은 변수를 제안함.

    생략된 내용

     * 생략된 주제: 라인 버퍼링과 완전한 비버퍼링의 차이, stderr와 stdout의 버퍼링 차이, 운영 체제의 TTY 드라이버 버퍼링 등.

        Hacker News 의견

     * 버퍼링된 접근은 일정 바이트 수나 시간이 지나면 플러시해야 함. 하드웨어 인터페이스에서 유사한 문제를 해결하는 일반적인 방법임
          + 사용자 공간에서 버퍼링하는 라이브러리는 데이터를 처음 버퍼링할 때 적절한 타이머를 설정해야 함
          + 타임아웃 파라미터는 인수로 전달하거나, 인간의 시간 척도보다 약간 낮거나, 대역폭/임계값에 비례하거나, 플러싱 오버헤드에 비례하는 것이 좋음
          + 쓰기와 읽기 모두에 적용되며, 데이터 채널에 따라 다를 수 있음
     * 시스템 전체 CPU가 유휴 상태가 되면 모든 버퍼를 플러시하고 싶음
          + 버퍼링은 일반적으로 CPU 절약 기법임
          + CPU가 유휴 상태가 되면 모든 프로세스에 ""버퍼를 플러시하라""는 신호를 보내야 함
     * NIX 시스템을 20년 이상 다뤘지만, 버퍼링 문제를 항상 잊어버림
     * Unix를 35년 이상 사용했지만 버퍼링 작동 방식을 완전히 이해하지 못했음. 이 설명이 유익했음
     * ""비버퍼링""과 ""라인 버퍼링""을 혼동하고 있음
          + 비버퍼링은 성능을 저하시킬 수 있으며, 여러 소스가 동일한 파이프에 쓰는 경우 잘못된 출력을 생성할 수 있음
          + 라인 버퍼링은 터미널의 기본값이며, 파이프에 적합함
     * 버퍼는 화면에 출력을 인쇄하는 것보다 버퍼에 쓰는 것이 상대적으로 매우 느리기 때문에 존재함
          + UART 작업 시 자주 발생하는 문제이며, 다양한 해결책이 있음
          + 특수 문자 사용, 길이 기반 접근, 시간 기반 접근 등 다양한 방법이 있음
     * Ctrl-C를 누르면 버퍼 내용이 손실될 수 있음
          + 대부분의 프로그램은 SIGINT에서 버퍼를 플러시할 것이라고 생각함
     * Unix에서 버퍼링 문제를 겪었으며, 모든 'awk' 구현이 동일하게 작동하지 않음
     * 얼어붙은 파이프 농담을 놓친 기분임
"
"https://news.hada.io/topic?id=18020","Kiwi : 지능형 한국어 형태소 분석기(Korean Intelligent Word Identifier)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Kiwi : 지능형 한국어 형태소 분석기(Korean Intelligent Word Identifier)

     * Kiwi : 지능형 한국어 형태소 분석기(Korean Intelligent Word Identifier)
     * 빠른 속도와 범용적인 성능을 지향하는 한국어 형태소 분석기 라이브러리
     * 경량 언어모델이 내장되어, 모호성이 있는 경우에도 제법 정확하게 형태소를 분석해냄
     * C++로 구현됨. 개발자가 C++의 팬.
          + 라이브러리는 파이썬, 자바스크립트, C#, Java, R, Go로 제공됨
          + wasm으로 컴파일되어 브라우저에서 구동할 수 있음
     * 모델은 소형(16MB), 중형(40MB), 대형(90MB)까지 세가지 크기로 제공됨
     * 개발 과정이 블로그에 상세히 공개되어 있음
          + https://bab2min.tistory.com/560
     * Kiwi를 토크나이저로 활용한 한국어 언어모델 훈련도 인상적
          + https://github.com/bab2min/kiwi-farm
"
"https://news.hada.io/topic?id=18076","Grab, LLM-Kit으로 LLM 어플리케이션 개발 가속화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Grab, LLM-Kit으로 LLM 어플리케이션 개발 가속화

     * Grab의 LLM-Kit은 프로덕션 레벨의 Generative AI 어플리케이션 설정을 가속화할 수 있게 설계된 프레임워크
     * 민감한 데이터를 다루는 AI 어플리케이션 개발에서는 보안과 데이터 안전성이 매우 중요한데, 확장성, 통합, 모니터링, 표준화 등의 이슈들을 LLM-Kit이 해결해줌
     * 이를 통해 장기적으로 효율적이고 효과적인 LLM 애플리케이션 개발을 가능하게 하여, Grab에서 수백개의 GenAI 어플리케이션 온보딩을 도와줌

LLM-Kit의 특징

     * 사전 구성된 구조(API 서버, 설정 관리, 샘플 LLM 에이전트, 테스트 등)를 제공함
     * Poetry, Gunicorn, FastAPI, LangChain, LangSmith, Hashicorp Vault, Amazon EKS, Gitlab CI 등과 통합됨
     * Datadog, LangSmith 연동으로 실시간 모니터링이 가능한 옵저버빌리티 기능
     * Python의 configparser와 Vault를 활용한 설정 및 시크릿 관리
     * OpenID Connect(OIDC) 인증 헬퍼
     * Swagger와 Redoc을 사용한 API 문서화
     * Redis 및 Vector DB와의 통합
     * 스테이징 및 프로덕션 환경용 배포 파이프라인
     * LangSmith의 강력한 평가 프레임워크 연동
     * 쿡북 : Grab에서 자주 사용되는 예제를 모아 개발자를 위한 자원 제공
          + 지속형 메모리 에이전트, Slackbot LLM 에이전트, 이미지 분석기, 사용자 인터페이스가 포함된 풀스택 챗봇 등 다양한 사례 포함

LLM-Kit의 가치

     * 사전 구성 및 통합된 기술 스택으로 LLM 어플리케이션 개발 속도 향상
     * LangSmith, Datadog 연동으로 실시간 모니터링 및 이슈 탐지/해결 가능
     * OIDC 인증과 Vault 시크릿 관리로 보안 향상
     * Vector DB로 데이터 스토리지/검색의 효율성 향상
     * 모범사례 및 표준화 촉진하는 포장도로 프레임워크 제공
     * 팀이 첫 기능 작업에 들어가기 전 약 1.5주 정도 개발 시간 절약 가능

아키텍처 설계 및 기술 구현

     * 모듈형 아키텍처로 확장성, 유연성, 사용 편의성 제공

  자동화

    1. 엔지니어가 앱 이름 등 관련 세부 정보를 제출하면 GitLab 프로젝트 생성이 트리거됨
    2. LLM 앱용으로 특별히 설계된 코드 스캐폴드가 생성됨
    3. 동일 저장소 내에 CI/CD용 GitLab CI 파일이 생성됨
    4. ECR, EKS 등의 스테이징 인프라가 생성됨
    5. 인프라 프로비저닝용 Terraform 폴더가 생성되고 프로덕션 인프라 배포로 이어짐
    6. 파이프라인 끝에 GPT 토큰이 보안 Vault 경로에 푸시되고 엔지니어에게 완료 알림이 전송됨

  스캐폴드 코드 구조

    1. Agents: LangChain 에이전트 프레임워크 기반으로 에이전트 초기화하는 코드 포함
    2. Auth: Grab 내 일부 API 실행을 위한 인증 및 권한 부여 모듈
    3. Core: 구성 추출(GPT 토큰 등)과 LLM 앱 실행을 위한 시크릿 암호 해독 포함
    4. Models: Grab 내 핵심 LLM API용 구조 정의
    5. Routes: LLM 앱용 REST API 엔드포인트 정의(상태 확인, 인증, 권한 부여, 간단한 에이전트 등 포함)
    6. Storage: Grab의 관리형 Vector DB인 PGVector와의 연결성 및 DB 스키마 포함
    7. Tools: LLM 에이전트용 도구로 사용되는 기능
    8. Tracing: 프로덕션 앱의 다양한 메트릭 모니터링을 위해 추적 및 모니터링 도구와 통합
    9. Utils: 유틸리티 기능용 기본 폴더

  인프라 프로비저닝 및 배포

     * 동일 코드베이스 내에 인프라 프로비저닝, 배포, 빌드 프로세스에 필요한 코드를 자동으로 스캐폴드하는 포괄적인 파이프라인 통합됨
     * Terraform을 사용해 필요한 인프라를 원활하게 프로비저닝함
     * 배포 파이프라인은 .gitlab-ci.yml 파일에 정의되어 자동화된 배포 보장
     * 빌드 프로세스는 Dockerfile에 지정되어 일관된 빌드 허용
     * 자동화된 스캐폴딩으로 개발자가 기본 인프라 및 배포 복잡성 대신 비즈니스 로직 작성에 집중 가능

  RAG 스캐폴딩

     * LLM-Kit을 사용해 Vector DB(PGVector) 설정 및 서비스 허용 목록 추가 과정이 간소화됨
     * 폼 제출 후 자격 증명 및 DB 호스트 경로에 액세스 가능
     * 시크릿이 Vault 경로에 자동 추가됨
     * 엔지니어는 스캐폴드된 LLM-Kit 앱의 구성 파일에 DB 호스트 경로만 포함하면 됨

결론

     * LLM-Kit은 Grab의 AI 및 ML 혁신과 성장을 지원하는 중요한 도구
     * 팀이 직면한 과제를 해결하고 포괄적이고 확장 가능하며 유연한 LLM 앱 개발 프레임워크를 제공함으로써 Grab의 차세대 AI 앱 개발을 선도하고 있음

성장과 향후 계획

     * 웹 서버의 동시성과 확장성을 크게 향상시키는 한편 안정적이고 사용하기 쉬운 SDK 제공할 계획
     * 평가 및 가드레일 프레임워크를 포함한 재사용 가능하고 결합 가능한 LLM SDK 제공 예정
     * 버전 업데이트 및 개발 도구용 CLI 개발
     * 폴링 기반 에이전트 제공 기능 개발
     * 이러한 발전을 통해 엔지니어에게 더욱 원활하고 효율적인 개발 경험을 제공하고자 함
"
"https://news.hada.io/topic?id=18015","How Much Memory Do You Need in 2024 to Run 1 Million Concurrent Tasks?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 How Much Memory Do You Need in 2024 to Run 1 Million Concurrent Tasks?

   Rust, C#, Python, Go, Java, NodeJS 등의 최신 버전으로 100만 개의 동시 작업을 처리하는 프로그램을 실행하여 메모리 효율성을 비교했습니다.

   C# (NativeAOT)와 Rust가 가장 우수한 메모리 효율을 보였으며, Go는 기대보다 높은 메모리 소비로 낮은 평가를 받았습니다. 전체적으로 .NET과 Rust의 성능이 돋보였고, Java (GraalVM)가 놀라운 개선을 보였습니다.

   구체적으로 Rust는 약 29MB로 가장 적은 메모리를 사용했으며, C# NativeAOT는 약 71MB로 뒤를 이었습니다. NodeJS는 232MB, Python은 339MB를 기록했습니다. Go는 753MB로 상대적으로 높은 메모리 사용량을 보여 아쉬운 결과를 나타냈습니다. Java(GraalVM)는 92MB로 큰 개선을 보였습니다.

   벤치마크 코드를 보면 Rust와 Python의 경우 실제로는 concurrent task를 만드는 것이 아니라, 비동기적이긴 하지만 다른 task와 parallel하게 돌지는 못하는 future 객체만 생성하는 것으로 보입니다. 아마 C#도 비슷한 케이스가 아닐까 싶네요. 반면 Go 코드는 스스로 call stack 등을 갖는 task인 goroutine을 생성하게 되어 있는데, 100만 개의 케이스에서 Go의 메모리 사용량이 유독 튀어 보이는 원인은 여기에 있지 않나 싶습니다.

   Go에 대해 옹호를 하자면 Go는 100만개 도는 함수안에 어떤 라이브러리가 있어도 동작을 합니다. go 만 붙여주면 됩니다. 비동기 기반의 다른언어에서는 중간에 동기방식으로 조금 시간을 잡아먹는 라이브러리가 있으면 이게 비동기의 이점을 다 잡아먹는 미치는 상황이 와버리죠.
   비동기의 이점을 100% 누릴려면 조금이라도 시간을 잡아먹는 함수는 다 비동기로 바꿔야 합니다.
   자바 VirtualThread는 음... 이번에 우리회사에서 자바 VirtualThread 믿고 가다가 라이브러리 호환성때문에 결국 일반 쓰레드로 바꾸고 인스턴스 수십개 띄우는 엔딩으로 결말을 맞았습니다.

   호환성 부분에 대한 얘기를 조금 더 들을 수 있을까요 :eyes:

   스프링에서 흔히 말하는 ""WebFlux를 제대로 사용하려면 JPA말고 R2DBC와 함께 사용해야 진가가 들어난다"" 라는 말이 없다고 말할 수 있겠네요.

   ms의 msal라이브러리가 virtualthread에서 동작하지 않는다는 얘기를 들었습니다

   예시로 주신 msal 라이브러리는 Go의 경우에도 thread safe하지 않은 자료형, 혹은 구조가 사용되는 라이브러리면 마찬가지인 케이스라고 생각됩니다

   thread safety와 무슨 연관성이 있을까요? goroutine 은 애초에 thread safety 를 보장하는 시스템이 아닐텐데요.

   정보 감사합니다

   질문 드리고 싶은게 있습니다
   그럼 go를 제외한 다른 언어들은 말씀해주신것처럼 동기방식의 라이브러리가 있으면 다 깨지는걸까요?
   아니면 혹시 다른 언어들 중에서도 go처럼 완벽한 비동기를 지원하는 언어가 있는건지 궁금합니다

   colorless 란 표현이 있습니다. 비동기랑 동기를 구분지을 필요가 없는 언어는 go 가 유일합니다. 사용자 입장에서 동시성이 필요한 프로그래밍을 할때 난이도, 사용성 측면에서 go는 압도적인 강점이 있습니다.
   최적화된 비동기 프로그래밍보다 성능이야 조금 떨어지겠지만요.

   지적 죄송한데 깨진다는 표현하고 완벽한 비동기란표현에 틀린 부분만 말씀드릴께요. 비동기에도 동기방식 라이브러리 써도 괜찮습니다 단 짧은시간내에 완료가 된다는 보장이 있으면요 동기방식으로 실행시간이 긴 호출이 있으면 다른 비동기의 처리가 늦어지니 문제가 생기는거고. go 는 고루틴으로 억단위의 작업을 배정해도 되므로 언어자체에 비동기란 개념이 없습니다. 쓰는 사람입장에서는 어떤 함수도 go 만 붙여 호출해주면 병렬로 실행되니 엄청 편한거죠. 완벽한 비동기는 언어자체의 근간이 비동기인 자바스크립트가 아닐까 개인적으로 생각합니다
"
"https://news.hada.io/topic?id=18097","9세 아들이 순수 JavaScript로 제작한 게임, 피드백 부탁드립니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                9세 아들이 순수 JavaScript로 제작한 게임, 피드백 부탁드립니다

     * 9살 아들이 지난 1~2년간 HTML과 CSS를 배우고 Google Gemini를 활용하여 게임을 만들었음
     * Google Gemini를 검색 및 코딩 교사로 활용하는 방법을 배워서 수준이 크게 향상됨
     * 게임의 HTML, CSS, JS를 VSCode에서 직접 코딩하고 Piskel로 애니메이션 그래픽을 제작
     * 부모가 코딩 여정에서 힌트와 피드백을 제공했으며, Gemini가 문법에 도움을 줌
     * 게임 제작 과정을 설명하는 블로그 포스트를 작성했으며, 부모의 피드백을 통해 개선했음
     * 부모 모두 프로그래머로서 아들의 코딩 여정에 가이드를 제공했음

        Hacker News 의견

     * 게임에 대한 피드백
          + 무기가 ""충전""되는 시점을 알 수 있으면 좋겠다는 의견이 있었음
          + 상대방이 어떤 질문을 풀고 있는지와 답변을 알 수 있으면 흥미로울 것이라는 의견이 있었음
          + 철자 오류가 있어 수정이 필요하다는 의견이 있었음
     * 9살 아이가 만든 게임으로서 훌륭한 작업이라는 칭찬이 있었음
          + Godot 게임 엔진을 추천하며, 무료/오픈소스이고 배우기 쉽다는 의견이 있었음
     * AI의 단점에 대한 의견
          + AI가 인간처럼 잘못된 답을 줄 수 있어 Google 검색을 사용해야 했다는 점이 언급되었음
          + 9살 아이가 작성한 것인지에 대한 회의적인 의견이 있었음
     * 게임 개선 아이디어
          + 메인 메뉴로 돌아가는 버튼 추가
          + 공격이 충전되었음을 알리는 표시 추가
          + 질문 입력을 게임 내로 이동
          + 텍스트 가독성을 높이기 위한 색상 조정
     * 프로그래밍 교육에 대한 추천
          + p5.js를 사용하여 시각적으로 코딩을 배우는 것을 추천
          + 시각적 피드백을 통해 아이들이 코딩에 더 쉽게 몰입할 수 있음
     * 과거의 게임 경험 공유
          + 인디 게임 개발자의 기술 향상을 관찰하는 것이 흥미로웠다는 의견
          + 과거의 코딩 실수 경험을 공유하며 온라인 포럼의 도움을 받았다는 이야기
     * 현재 게임의 충전 메커니즘 설명
          + 모든 공격에 공유되는 충전 메커니즘이 있으며, 공격 버튼을 클릭할 때마다 충전이 증가함
          + 각 공격의 충전 비용이 다름
"
"https://news.hada.io/topic?id=18125","PaliGemma 2 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             PaliGemma 2 공개

   Google은 Gemma 제품군의 최신 비전-언어 모델인 PaliGemma 2를 발표했습니다. PaliGemma 2는 기존 Gemma 2 모델을 기반으로 하며, 이미지를 이해하고 상호 작용하는 기능을 추가하여 다양한 AI 애플리케이션의 가능성을 확장합니다.
     * 확장 가능한 성능: 다양한 모델 크기(3B, 10B, 28B 파라미터)와 해상도(224px, 448px, 896px)를 제공하여 다양한 작업에 최적화된 성능을 제공합니다.
     * 긴 캡션 생성: 이미지에 대한 상세하고 맥락에 맞는 캡션을 생성하며, 단순한 객체 식별을 넘어 행동, 감정, 장면의 전체적인 스토리를 설명합니다.
     * 새로운 영역 확장: 화학식 인식, 악보 인식, 공간 추론, 흉부 X선 보고서 생성 등 다양한 분야에서 뛰어난 성능을 보여줍니다.
     * 간편한 업그레이드 및 파인튜닝: 기존 PaliGemma 사용자는 간편하게 업그레이드할 수 있으며, 특정 작업 및 데이터 세트에 맞게 모델을 쉽게 파인튜닝할 수 있습니다.

   Gemmaverse 생태계 확장:

   PaliGemma 출시 이후 Gemma 제품군은 수만 개의 모델과 애플리케이션을 갖춘 활발한 생태계인 Gemmaverse로 빠르게 성장했습니다. ColPali의 시각적 문서 검색 발전, RoboFlow의 파인튜닝 기술, 실시간 객체 추적 발전 등 다양한 혁신적인 사례가 Gemmaverse의 잠재력을 보여줍니다.
"
"https://news.hada.io/topic?id=18050","해안선의 길이는 정확하게 측정하는 것이 불가능하다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      해안선의 길이는 정확하게 측정하는 것이 불가능하다

     * 세계지도에 그려진 해안선은 비교적 단순할 것이고, (특정 국가의) 전국지도에 그려진 해안선은 비교적 자세할 것이다.
          + 지도가 자세하면 구불구불한 해안선을 좀 더 잘 묘사할 것이다.
               o 따라서 세계지도에서 측량한 해안선의 길이보다, 전국지도에서 측량한 해안선의 길이가 길다 (직선으로 쭉 긋는 것보다 구불구불한 굴곡을 전부 길이에 포함시키니까).
     * 하지만 생각해보면, 전국지도보다 각 지역의 지도가 훨씬 더 자세하다.
     * 그리고, 각 지역의 지도보다 각 마을의 지도가 훨씬 자세하다.
     * 이것은, ""측정 척도 (기준길이) 가 작아질수록 특정 값에 수렴한다""는 유클리드 기하학의 특징에 반하는 관측 결과이다. 무한히 자기 형상을 반복하는 프랙탈처럼, 해안선의 길이는 측정척도의 길이가 짧아질수록 무한하게 길어질 수 있다.
     * 바꿔 말하면, 우리는 해안선의 길이를 '정확하게' 측정할 수 없다 (혹은 굳이 그러는 사람이 없거나).

   인도, 중국 인구를 정확이 측정하는 것은 불가능하다
   우리나라는 가능한가??

   해안선 역설이라고 유명한 이야기죠

   재미있는 내용이긴 한데, 해안선이 프랙탈 구조처럼 미세구조가 무한히 반복된다는 근거가 있나요? 길이 척도에 대한 전체 길이 그래프에 점 몇개 찍었다고 무한히 길어질 수 있다는건 비약이
   심한거 같아요.

   그러게요. 무한히 길어질 수 있다기보다는, 모래알의 지름만큼, 또는 물 분자의 크기만큼의 척도를 사용하면 제일 정확한 해안선의 길이를 얻을 수 있지 않을까요?

   이미 그러한 관점에서 봤을때도 측정 불가능하다는 내용이 본문에 있습니다.

     실제 측정에서는 양자 물리학의 원리에 의해 무한히 작은 척도를 생성할 수는 없다. 양자 물리학(quantum physics)에 의하면 양자의 측정에서 최소 측정단위인 플랑크 척도(Planck's length, 약 1.6162412*10^-35 미터) 이하의 측정 단위를 생성할 수가 없다.

   사실 이 내용 하나만으로 가불기라서 좀.. 의미가 없는 내용이 아닌가 싶네요ㅋㅋ

   그리고 개발 측정은 해안선 길이를 측정하는것처럼 정확할수가 없다네요. ^^
     * https://soojin.ro/blog/sw-estimation
          + [유머] 왜 소프트웨어 개발은 예상보다 2~3배 더 오래 걸리는가?
     * https://quora.com/Why-are-software-development-task-estimations-regula…
"
"https://news.hada.io/topic?id=18042","Honeycrisp 사과, 경이로움에서 평범함으로 전락","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Honeycrisp 사과, 경이로움에서 평범함으로 전락

     * Honeycrisp의 기원과 성공
          + 1983년, 미네소타 대학교의 연구 과학자 데이비드 베드포드는 Honeycrisp 사과를 처음 맛보았음. 이 사과는 아시아 배와 수박과 비슷한 맛과 질감을 가지고 있었음.
          + Honeycrisp는 Keepsake 사과와 실험적인 품종 MN1627의 교배종으로, 미네소타의 기후에 적합하게 설계되었음.
          + 1991년, 베드포드와 짐 루비 박사는 이 사과를 대중에게 공개했으며, 이는 소비자들에게 큰 인기를 끌었음.
          + Honeycrisp는 얇은 껍질과 큰 세포로 인해 독특한 맛과 질감을 제공하며, 이는 다른 상업용 사과와 차별화됨.
     * 문제의 징후
          + Honeycrisp 나무는 특히 워싱턴 주에서 재배하기 어려운 것으로 나타났음. 이 지역의 기후는 미네소타보다 따뜻하여 사과의 품질에 영향을 미침.
          + 얇은 껍질은 사과가 햇볕에 타거나 저장 중에 품질이 저하될 가능성을 높임.
          + 농부들은 수익을 위해 Honeycrisp를 대량으로 재배했지만, 이는 품질 저하로 이어졌음.
     * 현재 Honeycrisp의 위치
          + Honeycrisp 사과는 과잉 공급으로 인해 가격이 하락했으며, 품질도 예전만큼 좋지 않음.
          + 대량 생산과 저장으로 인해 사과의 맛과 질감이 저하되었으며, 이는 소비자들에게 실망을 안겨줌.
          + Honeycrisp는 이제 그 자체의 성공의 희생양이 되어, 이전의 매력을 잃은 평범한 상품 사과가 되었음.

   바로 샤인머스캣이 떠올랐는데 역시 다들 비슷하군요 ;)

   요즘의 샤인머스캣 포도를 보는 느낌이네요.

        Hacker News 의견

     * Washington 주의 AgTech 분야에서 일하는 사람은 Cosmic Crisp 사과나무가 물 관리에 매우 민감하다고 설명함. 과도한 물 공급 시 쉽게 실패하는 특성이 있음. Pytech 같은 큰 기업들이 자동화된 관개 시스템에 많은 투자를 하고 있음.
     * 한 사용자는 Honeycrisp 사과가 항상 아삭하고 밀도가 낮아 다른 사과보다 선호한다고 언급함. 맛이 덜하더라도 아삭한 사과를 선호함.
     * 새로운 사과 품종은 처음에는 맛있지만, 대량 생산을 위해 재배되면서 본래의 특성을 잃는 경향이 있음. Fuji와 Gala 같은 사과가 그 예임.
     * Honeycrisp 사과는 지역 과수원에서 직접 구매할 때 더 좋음. 슈퍼마켓에서는 품질이 일정하지 않음. 인기가 많아지면 Red Delicious처럼 될 가능성이 있음.
     * Cosmic Crisp를 먹어보면 Honeycrisp가 별로라고 느낄 수 있음. 새로운 품종인 Kudos Apple이 Cosmic Crisp를 대체할 가능성이 있음.
     * 사과의 저장이 맛을 떨어뜨리는 주요 원인임. 미국에서는 뉴질랜드 사과를 수입하여 신선한 맛을 유지함. 마늘도 장기 저장으로 인해 맛이 변함.
     * 사과 재배 지역 근처에 살면 다양한 품종을 시도해보는 것이 좋음. 슈퍼마켓에서 볼 수 없는 다양한 사과를 맛볼 수 있음. 직접 나무를 심어보는 것도 추천함.
     * 한 사과 재배자는 Honeycrisp가 맛이 없다고 느끼며, 이는 번식 방식 때문이 아님을 설명함. 모든 Honeycrisp 나무는 유전적으로 동일하지만, 환경의 차이가 맛에 영향을 줄 수 있음.
     * Hudson Valley에서 재배된 Honeycrisp가 10년 전보다 맛이 떨어지는 이유를 설명하지 않는다고 지적함. Washington 주의 대규모 생산이 시장에 영향을 미치고 있음.
     * 과수원을 운영했던 사람은 Honeycrisp 나무가 관리하기 어렵다고 언급함. 다른 품종보다 병에 취약하고, 과일이 작고 모양이 좋지 않음. 유전과 환경의 상호작용이 예측하기 어려운 결과를 초래할 수 있음.
"
"https://news.hada.io/topic?id=18113","JPA/Hibernate를 버리세요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          JPA/Hibernate를 버리세요

요약

   JPA/Hibernate는 Java 코드에서 더 이상 SQL을 쓸 필요가 없다는 이유로 많이 쓰이는 프레임워크가 되었습니다. 하지만, 저는 새 프로젝트에 이를 사용하지 말아야 한다고 주장하고 싶습니다.

  이유

    매우 긴 공식 문서

   공식 문서를 pdf로 변환하면 무려 406쪽이나 되는데, 이는 반지의 제왕(231쪽), SQL 표준 문서(288쪽)보다 큽니다. 데이터베이스 쿼리를 익히기 위해 석사 과정을 밟을 필요는 없습니다.

    가변성

    1. 어떤 엔티티가 한 요소를 필요로 한다 해도, 아무 인자도 없는 생성자를 강요합니다.
    2. 엔티티 클래스에 final, abstract 키워드를 넣음으로써, 상속을 방지할 수 없습니다.
    3. Reflection/Introspection은 OOP의 캡슐화 원칙을 무시합니다.
    4. 누군가가 악의적인 코드를 심어 데이터를 완전히 날릴 수 있습니다.

    지연 로딩 및 캐시

    1. @Lazy 어노테이션은 초심자에게 있어 가장 최악의 기술입니다. 하지만 도메인 설계가 Hibernate와 맞지 않거나 쿼리를 작성할 수 없을 때 이를 피할 수 없습니다.
    2. 캐시 메커니즘은 이해하기 어렵습니다. 게다가 이해했다 해도 쿼리 결과가 아닌 엔티티 자체를 캐시에 저장해야 합니다.

    메모리-데이터베이스 동기화(Flush)

   Flush라는 기술은 메모리에 저장된 객체와 데이터베이스를 동기화합니다. 이는 두 문제를 야기합니다.
     * Flush가 작동하면 메모리 안의 편집이 끝나버리기 때문에, Hibernate가 아닌 다른 영속성 도구는 꿈도 꿀 수 없으며,
     * Flush 도중 충돌이 발생하면 코드와 상관 없는 Stack Trace 오류가 발생할 수 있습니다.

    한 테이블의 특정 칼럼만 얻기

   어떤 엔티티 중 한 칼럼만 접근하고 싶으면 SQL의 접근 방식은 다음과 같이 단순합니다.
select url from image
where id = 'F462E8D9-9DF7-4A58-9112-EDE0434B4ACE';

   하지만 Hibernate는 무조건 엔티티의 모든 칼럼을 조회합니다. 이를 피하려면 복잡한 과정을 거쳐야 합니다.

    칼럼에 대한 제한 사항(Constraint) 정의

   어느 한 칼럼에 대한 제한 사항을 정의하기 위해 아래처럼 여러 어노테이션을 붙여야 합니다.
...
    @NotNull
    @NotEmpty
    @Email
    private String email;
...

   이 방식은 다음과 같은 문제를 야기합니다.
     * 이 조건을 위해 단위 테스트를 할 수 없습니다.
     * Flush 작업을 하는 동안 이 처리 과정을 파악하기엔 너무 늦습니다.
     * 나올 수 있는 예외는 일반적이고, 쓸모 없습니다.
     * 비즈니스 규칙을 기술적인 규칙으로만 다룹니다.

    전략에 대한 문제

    1. 프레임워크는 업데이트가 최악이고, 하위 호환성을 무시, 무조건적으로 의존하게 만듭니다. 이를 만드는 회사는 독점하기 위해 자신의 프레임워크를 쓰는 것이 당연하다고 여기게 만듭니다. 이 악순환은 막아야 합니다.
    2. 개념 증명(Proof of Concept)을 굳이 프레임워크를 통해야만 얻는 것은 자신의 시야를 좁히는 결과만 얻을 것이며, 특히 JPA/Hibernate의 경우는 더더욱 그렇습니다. 티끌만큼도 허용해선 안 됩니다.

  어떻게 해야 할까요?

    SQL을 쓰세요

   SQL만으로 모든 것이 가능합니다. 모든 프로그래머가 알고, 쿼리가 직관적이고, 프레임워크가 필요 없습니다.

    관리자가 Hibernate를 쓰라는데요?

   퇴사하시거나, 코드를 프레임워크와 분리하는 작업을 하세요.

    이미 사용 중이라면...

    1. 기본 생성자와 설정자의 공개 수준을 public으로 만들지 마세요.
    2. SQL이 생성하는 아이디 대신 UUID같은 문자열을 쓰세요.
    3. XXXRepository라는 이름 대신 XXXDao라는 이름을 쓰세요.
    4. @SequenceGenerator 어노테이션을 쓰지 마세요.
    5. 도메인 클래스와 DAO 클래스를 intarface로 분리하세요.
    6. *대다 관계(@OneToMany 등)를 쓰지 마시고, 차라리 엔티티 맵핑을 피하세요.

  결론

   JPA/Hibernate, 버리세요.
     * 비즈니스 문제를 해결할 더 짧고 좋은 문서가 있습니다.
     * 설계를 너무 빠른 방식으로만 고수하지 마세요.
     * 당신의 코드를 관리할 다음 개발자에게 관용을 베푸세요.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   여러분은 무엇을 사용하시나요?
    1. JPA/Hibernate
    2. 다른 ORM 기술

   JPA/Hibernate를 버리자는 의견에 반대합니다.

   ""매우 긴 공식 문서"" 부분
   SQL도 처음 배울 때는 어렵습니다. 복잡한 조인, 서브쿼리, 프로시져 함수 등을 완벽히 이해하는 게 쉽나요?
   JPA는 처음에 핵심 개념만 이해하고 시작해도 충분합니다. 더 깊은 내용은 필요할 때 찾아보면 됩니다.
   그리고 LLM이 있습니다.

   ""가변성과 Reflection 문제""
   이는 프레임워크의 동작 방식을 이해하지 못해서 나오는 걱정입니다.
   실무에서 이로 인한 실질적인 문제가 발생하는 경우는 거의 없습니다.
   오히려 Reflection으로 인해 객체 매핑이 자동화되어 생산성이 크게 향상됩니다.

   ""지연 로딩 및 캐시""
   @Lazy가 ""최악의 기술""이라고요? N+1 문제를 해결하고 성능을 최적화하는 데 매우 유용한 기능입니다.
   캐시 메커니즘은 오히려 성능 향상에 큰 도움이 됩니다.

   ""한 테이블의 특정 칼럼만 얻기""
   JPQL이나 Projection을 사용하면 필요한 칼럼만 쉽게 조회할 수 있습니다.
   그리고 QueryDSL과 함께 사용하면됩니다.

   ORM의 목적은 SQL을 완전히 대체하는 게 아니라, 개발자가 비즈니스 로직에 더 집중할 수 있게 돕는거라 생각합니다..

   ORM 비관론자이긴 한데, 충분한 대안을 제시하지는 못한 것 같네요.

   ORM-heavy하게 가다보면 정말 끝도없고, 위에 언급처럼 SQL 문서보다 더 넓은 범위의 문서속에서 허덕이다가 말라죽을지도 모릅니다.

   최근 개인프로젝트에서 ORM 을 사용하지 않고 개발중인데, 뭔가 재사용성을 고려한 설계를 하다보니 그냥 ORM 을 만들고있다는 생각이 드는 방향으로 개발하게 되기도 하더라구요.ㅎㅎ

   PYTHON으로 백엔드 만들 때, SQLALCHEMY나 DJANGO ORM 정도 매번 사용하는데요.
   SQL 직접 쓰는 거나, ORM 사용하는 것이나 익숙해지니 별 차이 없게 느껴져서 아무 생각 안하고 있었는데. ORM을 사용하지 말자는 의견도 있었네요.
   프레임워크 의존도를 낮추자는 의견은 찬성입니다. DJANGO ORM만 쓸 줄 알고 SQL을 다룰 줄 몰라서는 안 되겠지요...

   음 글쎄요 저는 반대입니다. 현재 테이블이 3천개 정도인 서비스를 운영하고 있는데, 도메인이 하도 복잡하다보니 쿼리를 하나 만드는데 기본적으로 수십줄은 넘게 작성했습니다. 여기서 동적 쿼리도 생각하면 정말 머리 아픕니다. 복잡하니 버그도 많이 생기고 유지보수도 어려웠구요. 저는 복잡한 도메인에서는 ORM 이 더 유리하다고 생각합니다.

   저같은 경우는 정규화가 안된 db를 유지보수 해본 경험이 있는데
   그때 동적쿼리를 orm을 안쓰고 일반 SQL로 쓰는데,
   그러다보니 코드가 더 알아보기 힘들게 가는 경우가 있더군요
   복잡한 도메인 뿐 만 아니라 정규화가 부족한 도메인도 충분히 도입할만한 여지가 있다고 봅니다

   오 나쁘게 볼 필요는 없겠군요

   저도 개인적으로는 SQL을 그냥 쓰라고 권하고 싶습니다. JS월드에서는 Prisma와 같은 도구들을 많이 이용하는데, SQL이 그렇게까지 어려운 언어도 아니고 데이터베이스 I/O를 위해 너무 불필요한 추상화를 요구하는 것 같아서 조금 꺼려지더라구요.

   js/ts 쪽 orm들이 유독 나사빠진 제품들이 많아서 그런 것 같기도 해요

   Jdbc같은 거면 되겠죠? 이전에 저랑 같이 일하셨던 분이 ""JPA는 느려서 다른 걸 써라""라고 하신 게 생각나네요.

   전설 속 이야기같아요

   장점도 있긴하죠..
   2. MyBatis (ORM은 아니지만 ㅎ)

   Orm이 아니라 dao로 바꿀 걸 그랬네요

   프레임워크를 사용하기 때문에 같은 프레임워크를 상용하는 다른 개발자들과 공통된 패러다임을 가져갈 수 있다는점은 항상 이런 무언가을 사용하지 말라는 글에서 무시되는 것 같네요

   테이블이 많고 컬럼도 많은 경우에는 (예를 들어 테이블이 50개, 각 테이블당 컬럼이 100개 이상) SQL을 그냥 쓰면 지옥도가 펼쳐지더라구요.

   다만 작은 서비스를 만들때 JPA/Hibernate를 만드는 것은 굉장한 낭비라고 생각합니다.

   역시나 이런 의견은 케바케인것 같습니다.

   (여기서 예시로 든것도 컬럼 3~4개짜리...)

   위의 글에서 마지막 질문은 좀 수정되어야할 것 같습니다.

   Java 진영에서 1. ORM vs 2. Non-ORM 으로 정리해볼 수 있겠죠.
    1. ORM은 사실상 JPA/Hibernate 조합만 사용된다고 보면 됩니다.
    2. MyBatis, JOOQ, SpringDataJDBC 등이 있겠네요. 주로 SQL을 직접 핸들링하게 되죠.

   1, 2 모두 장단점이 확실하기때문에, 위의 글처럼 극단적인 결론을 내리는 것은 적절하지 않습니다.

   저희 같은 경우,
   ORM인 JPA/Hibernate/QueryDSL을 사용하면서 동시에 MyBatis도 사용합니다.

   ORM을 이용해서 최대한 생산성을 높이면서,
   ORM으로 커버가 어려운 쿼리들은 MyBatis를 사용합니다.

   그리고 위에서 1, 2 어느 것을 선택하건 SQL은 잘 알아야합니다.

   저도 수정하고 싶긴 한데 사이트에 그런 기능이 없으니...

   애초에 ORM이 유행하게 된 이유는 모른척하고 있는거 같네요.

   학습비용이 좀 들긴하지만 익숙해지면 생산성 향상이 분명히 있는데 말이죠.

   SQL이 간단한거 같지만, SQL 한땀한땀 코딩할 때의 그 피곤함은...거기다 테이블 변경되면 연관 쿼리도 다 한땀한땀 바꿔야 해서 SQL 유지보수도 결코 만만한 일이 아니라, 작고 간단한 만큼 작업량이 많아지는데(그래서 생산성 이야기가 계속 따라 나오는 것이고요)

   추가로, SQL에서 발생하는 오류는 런타임에 터져서 잡기도 힘들고, SQL 인젝션 같은 공격 방어를 한땀한땀..하다보면 결국 쿼리를 생성하는 코드가 추가되고(보통 간단한 템플릿 형태로 시잭해서..) 진행하다 보면 결국 ORM비슷한 물건이 다시 나올텐데, 그럴바엔 그냥 ORM을 쓰는것이..?

   며칠전에 올라왔던 글이 생각나네요
   https://news.hada.io/topic?id=17955

   동의합니다.
   ORM을 사용하는 이유와 그 장점을 충분히 이해하지 못한 경우가 종종 있는 것 같아요.

   추가로, ORM을 통해 실제 실행되는 SQL을 분석하거나 이해하려고 하는 사람도 많지 않은 것 같습니다.
   단순히 편리함을 넘어서 SQL 최적화와 데이터베이스의 동작을 깊이 이해하는 데도 도움을 줄 수 있다는 점이 더 알려지면 좋겠습니다.

   써야 한다, 쓰면 안된다 양 극단에 치우칠 필요는 없다고 생각해요 ㅎㅎ;;
   저는 생산성이 필요하다면 ORM을 활용하되,
   ORM으로 커버할 수 없는 복잡한 쿼리 혹은 최적화가 더 필요한 쿼리는 로우쿼리로 처리합니다.
   ORM이냐 raw query냐는 어떤 상황에서 무엇을 어떻게 만들 것인가에 따라 적절히 선택하면 된다고 생각합니다.

   일반적으로 db 정규화가 잘 되어있고, 크게 join 할 필요 없는 데이터들은 그럴수 있다고 봅니다만,
   db 정규화부터 시작해서 모든걸 제대로 dba를 통해서 관리할 수 없다면 orm도 좋은 선택이 될수 있다고 봅니다. 특히, join을 통해서 가져오는 쪽에서 relationship으로 가져오면서 생기는 이점은 가히 orm을 왜 쓰게 만드는지 보여주는 좋은 예제라고 생각합니다.
   물론 프레임워크가 개발자의 성장을 제한하고, 그걸 프레임웍 의존도를 낮추자는 의견에는 동의합니다만
   무조건적으로 orm을 쓰지 말자고 하자는 의견에는 쉽사리 동의 못하겠습니다.
   모든 기업들이 다 dba가 있고 ddd나 tdd같은 제대로된 방법론으로 개발되고 있다는 전제를 까는거같아서
   실제로 실무에서 저렇게 된다고 한다면 코드가 더 얼마나 개판이 날지도 모르겠습니다.

   프레임워크 말고 근본으로 돌아가는 게 추세인가 싶기도 하네요.
   HTMX, SQL 등등..

   바퀴를 새로 만들어야 하는 단점이 있지만요
"
"https://news.hada.io/topic?id=18039","Vince – Google Analytics를 대체 가능한 셀프 호스팅 솔루션","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Vince – Google Analytics를 대체 가능한 셀프 호스팅 솔루션

     * Vince는 Google Analytics의 자체 호스팅 대체제 오픈소스임
          + 다른 대체제인 Plausible 을 Go로 포팅하는 프로젝트로 시작해서 많이 유사함
          + 셀프호스팅에 중점을 두었으며, 엔터프라이즈/ 멀티테넌트 기능등은 없음

특징

     * 자동 TLS: Let's Encrypt를 통한 네이티브 지원
     * Plausible 대체: 기존의 Plausible 스크립트를 사용하여 Vince 인스턴스로 연결 가능함
     * 아웃바운드 링크 추적
     * 파일 다운로드 추적
     * 404 페이지 추적
     * 커스텀 이벤트 추적
     * 기간 비교
     * 공개 대시보드: 기본적으로 모든 대시보드는 비공개이며, 누구나 접근 가능하게 설정 가능함
     * 고유 공유 접근: 대시보드에 대한 고유 링크 생성 가능하며, 비밀번호 보호 가능함
     * 제로 의존성: 모든 것이 포함된 단일 바이너리로 제공되며, 런타임 의존성이 없음
     * 운영 용이성: 환경 변수를 사용한 단일 명령어 플래그로 운영 가능함
     * 무제한 사이트: 관리할 수 있는 사이트 수에 제한이 없음
     * 무제한 이벤트: 사용 가능한 자원에 따라 확장 가능함
     * 프라이버시 친화적: 쿠키가 없으며 GDPR, CCPA 및 PECR을 완전히 준수함

        Hacker News 의견

     * 라이선스 판매와 가격에 대한 계획에 대한 언급이 있음
          + 관련 링크: GitHub 링크
     * 개인적으로 선호하는 자체 호스팅 GA 대안은 GoatCounter임
          + GoatCounter와 비교했을 때 어떤 장점이 있는지 궁금함
          + 관련 링크: GoatCounter
     * 코드 품질이 매우 우수함
          + 프로토콜 버퍼를 사용한 이유에 대해 설명 요청
          + 프로토콜 버퍼는 추가적인 타입 시스템 이해가 필요해 초기에는 정신적 부담이 있을 수 있음
          + Pebble을 사용하는 이유에 대한 궁금증
          + 지오 데이터베이스 관리 방법에 관심이 있음
          + Pebble 대신 SQLite를 사용하지 않는 이유에 대한 의문
     * 홈페이지 스크린샷이 Plausible와 매우 유사함
          + Plausible 기반인지, 차이점이 무엇인지 궁금함
          + README에서 기능 비교를 발견함
          + 관련 링크: Plausible
     * Plausible의 상업적 버전이 비현실적이라고 생각함
          + 2M 페이지 뷰 사이트 운영 중이며, 대부분의 페이지가 캐시되어 서버 비용이 최소화됨
          + 월 50 USD를 지불 중이며, 사이트에서 수익이 많지 않음
          + 방문자 수를 사이트에 표시하고 싶음
          + 2M 페이지 뷰의 경우, Plausible는 월 189 USD가 필요해 비용이 4배 증가함
     * 6 USD Vultr 인스턴스에 전체 대시보드 데모가 호스팅됨
          + 관련 링크: 데모 링크
          + 404 페이지 오류 발생
     * Umami와의 비교에 대한 궁금증
          + 관련 링크: Umami
     * Plausible와 매우 유사하게 보임
          + 법적 문제를 피하기 위해 UI를 약간 변경할 필요가 있음
     * 놀라운 프로젝트임
          + Plausible를 자체 호스팅 중이나 Clickhouse와 Postgres에 의존하는 것이 업그레이드 시 번거로움
          + 사용 중인 데이터베이스 종류에 대한 궁금증
          + Go 언어에 대한 지식이 부족해 소스에서 파악하기 어려움
     * 설치와 사용이 매우 간편함
          + 2분 이내에 클라우드(excloud.in)에 배포 완료
          + k8s 클러스터에 배포할 수 있는 k8s 매니페스트 제공
          + 관리자 비밀번호 변경 후 사용 권장
          + 관련 링크: Gist 링크
"
"https://news.hada.io/topic?id=18061","쿼리나 결과를 보지 않고 검색 품질 개선하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        쿼리나 결과를 보지 않고 검색 품질 개선하기

     * Canva가 MAU 2억 명을 달성, 300억 개 이상의 디자인을 보유하고 있으며 매초 약 300개의 새로운 디자인을 생성
          + 사용자가 디자인을 검색하고 공유받은 파일을 찾는 것은 점점 더 중요한 문제로 대두됨
     * 퍼블릭 검색(웹/제품 검색) 에서는 사용자 쿼리와 검색 항목의 고정 세트를 기반으로 데이터셋을 구성
          + 전문 심사자가 각 쿼리와 항목의 연관성을 평가해 레이블 지정
          + 리콜(Recall) 및 정밀도(Precision) 메트릭을 통해 검색 엔진 성능 평가
     * 개인 검색에서는 (프라이버시를 보호하기 위해) 개인 디자인을 열람하지 않고, 사용자의 데이터를 평가 데이터셋으로 활용할 수 없음
          + 해결책으로 생성형 AI(GPT-4o 등)를 사용해 현실적이면서도 완전히 합성된 콘텐츠와 쿼리를 생성
          + 개인정보를 전혀 침해하지 않으면서도 검색 파이프라인 개선을 평가할 수 있는 방법 제공

기존 상태: 제한적인 테스트 방법

     * 기존 테스트 프로세스
          + 엔지니어는 제한된 오프라인 테스트 방식을 사용
          + 알려진 문제 쿼리를 Canva 계정에서 실행하여 코드 변경 전후의 성능을 비교
               o 예: 철자 교정 개선 작업에서 ""desgin"" 같은 잘못된 쿼리를 테스트
                    # 변경 전: 결과 없음
                    # 변경 후: ""design"" 관련 문서 반환
          + 오프라인 테스트를 통과한 변경사항은 온라인 테스트 단계로 진행
               o Canva의 실험 프레임워크를 활용한 A/B 테스트 실행
               o 변경사항 적용 사용자와 표준 검색 사용자 간의 검색 성공률 비교
     * 한계점
          + 오프라인 테스트의 통계적 유효성 부족
               o 제한된 쿼리로는 다양한 검색 동작을 대표하기 어려움
          + 사용자에게 잠재적 악영향
               o 오프라인 테스트에서 검출되지 않은 성능 저하가 온라인 실험에 노출될 가능성 존재
          + 온라인 실험의 시간 소모
               o 통계적 유의성을 확보하려면 최소 수일에서 수주가 필요
               o 동시 실행 가능한 실험 수와 아이디어 테스트 속도 제한

이상적인 상태: 새로운 데이터셋과 평가 파이프라인 구축

     * 목표 : 엔지니어가 온라인 테스트로 넘어가기 전에 변경 사항을 객관적으로 평가할 수 있는 맞춤형 데이터셋과 평가 파이프라인 필요
     * 주요 요구사항:
          + 재현성: 언제든 동일한 결과 제공
          + 빠른 반복: 엔지니어가 코드 변경 후 결과를 신속히 테스트 가능. 프로덕션 배포까지 기다릴 필요 없이 바로 평가 가능
          + 생산 환경과 유사: 실제 프로덕션 동작과 일치하는 결과 제공
          + 비차단적 작업: 팀원이 서로 방해받지 않고 독립적으로 코드 변경 사항을 실험 가능

현실적인 데이터셋 생성: 생성형 AI 활용

     * 프라이버시를 준수한 평가 데이터셋
          + GPT-4o를 사용해 실제 사용자 데이터를 대체할 수 있는 합성 데이터를 생성
          + 사용자 디자인을 복제하지 않고, 텍스트 길이와 같은 통계적 분포를 반영하여 현실적인 데이터를 만듦
     * 리콜 평가용 테스트 케이스 생성
          + 주제와 디자인 타입(문서, 프레젠테이션 등)을 기반으로 GPT-4o를 사용해 쿼리 및 대응 콘텐츠 생성
          + 쿼리 난이도 조정:
               o 철자 오류 포함
               o 동의어로 대체
               o 쿼리를 재구성
     * 정밀도 평가용 테스트 케이스 생성
          + 관련성과 비관련성 디자인을 포함한 데이터셋 생성
          + 비관련성 디자인 생성 방법:
               o 일부 키워드만 포함
               o 디자인 템플릿 또는 초안 형태로 수정
               o 오래된 디자인으로 설정

생성형 AI 사용 시 발생한 문제

     * LLMs의 장점과 한계
          + 장점: 대규모 텍스트 데이터를 효율적으로 생성 가능
               o 생성된 정적 평가 데이터셋은 반복 사용 가능하며, 일관되고 결정적인 평가 결과를 빠르게 제공
          + 한계 제거: 데이터셋 생성 후에는 LLM의 지연(latency)과 무작위성(randomness) 문제를 배제
     * 문제점
          + 긴 제목 생성 거부
               o 12-15단어 길이의 제목을 생성하도록 요청했으나 더 짧은 제목 반환
                    # 예:
                         @ ""Exploring the Latest Advancements in Screen Technology and Applications"" (9단어)
                         @ ""Best Practices for Teachers: Presentation Tips for Meet the Teacher"" (10단어)
               o 이 문제는 실제 문서에서 긴 제목이 드물다는 점을 반영한 것일 가능성이 있음
               o 결과적으로 제목 길이에 대한 기준을 재검토하게 됨
          + 반복 및 환각 오류
               o 단어의 다양한 철자 오류를 생성하도록 요청했으나 중복 또는 비현실적 결과 반환
                    # 예: ""Calendar""의 다른 철자 오류 생성 요청 시 반복적 결과 생성
          + 비관련성 제목 생성 문제
               o 비관련성(nonrelevant) 디자인 제목 생성 시 지침을 정확히 따르지 못하는 사례 발생
               o 반환된 제목 중 일부는 지정된 키워드를 포함하지 않거나, 단순히 ""title string""을 포함하는 등 부정확한 결과 반환

평가 실행: 로컬 환경에서의 테스트와 분석

     * 평가 데이터셋 활용
          + 생성된 합성 데이터셋을 검색 파이프라인에 적용하여 평가 메트릭을 산출
          + 여러 실행 방법을 탐구한 결과, Testcontainers를 활용한 로컬 실행 방식을 채택
     * Testcontainers 기반 로컬 파이프라인
          + 기존 Testcontainer 지원 활용
               o Canva의 서비스 지향 RPC 아키텍처에 Testcontainer 지원이 이미 구현되어 있음
               o Elasticsearch와 같은 외부 컴포넌트를 내부 Testcontainer와 결합하여 파이프라인 구축
          + 프로덕션 설정의 완전한 재현
               o 검색 파이프라인 및 지원 ML 모델을 로컬에서 실행하여 프로덕션과 동일한 환경 구성
               o 엔지니어가 다양한 모델 변형을 실험 가능
     * 테스트 케이스 처리 과정
         1. 각 테스트 케이스에 필요한 상태(state) 생성
          + Canva 디자인을 생성하는 대신 검색 인덱스에 필요한 데이터만 추출 및 삽입
         2. 로컬 검색 파이프라인 실행
          + 테스트 쿼리와 함께 데이터셋을 실행하여 검색 결과 생성
         3. 결과를 평가 모듈에 전달
          + 리콜(Recall) 및 정밀도(Precision) 메트릭 계산
     * 데이터 흐름 다이어그램
          + 평가 도구를 통해 데이터를 처리하는 전체 흐름을 시각적으로 보여주는 다이어그램 제공

결과 시각화하기

     * 시각화 도구 개발
          + Streamlit 기반 커스텀 도구를 사용하여 평가 결과를 효과적으로 시각화하고 비교할 수 있도록 지원
          + 엔지니어가 다양한 구성(configurations) 간의 리콜(Recall) 및 정밀도(Precision) 메트릭을 한눈에 비교 가능
     * 주요 기능
         1. 구성별 비교
               o 결과를 집계하여 다양한 설정의 성능을 나란히 비교
         2. 쿼리 유형 및 난이도별 성능 세분화
               o 특정 쿼리 타입이나 난이도에 따른 성능 분리 분석 가능
         3. 개별 쿼리 디버깅
               o 각 쿼리의 출력 결과를 확인하여 특정 사용 사례를 정밀히 디버깅 가능
     * 빠른 의사결정 지원
          + 평가가 완료되면 도구가 즉시 실행되며, 엔지니어가 성능 결과를 기반으로 신속히 의사결정을 내릴 수 있도록 도움
          + 엔지니어가 다른 팀원의 작업에 의존하지 않고 독립적으로 반복 실험 및 개선 가능

영향 및 향후 계획

     * 이상적인 상태에 얼마나 근접했는가?
          + 평가 데이터셋과 도구는 완전한 재현 가능성을 제공하며, 몇 분 내로 결과를 생성
          + 엔지니어는 현지(production) 동작과 일치하는 결과를 로컬에서 독립적이고 객관적으로 평가 가능
          + 고객의 디자인이나 쿼리를 전혀 열람하지 않고 프라이버시를 완벽히 보장
     * 성과 요약
         1. 빠른 반복
          + 1000개 이상의 테스트 케이스를 10분 이내에 처리
          + 2~3일이 걸리는 온라인 실험 기간 동안 300회 이상의 오프라인 평가 가능
         2. 오프라인-온라인 결과의 상관관계
          + 오프라인 평가 결과는 부적합한 아이디어를 배제하고 성공 가능성이 높은 변경사항만 온라인 실험으로 진행 가능하도록 설계
          + 개발 중 오프라인-온라인 결과 간의 동기화를 확인하는 여러 실험 수행
          + 성능 긍정적 또는 부정적 변경 모두 강력한 일치성 확인
         3. 로컬 디버깅 기능
          + 검색 파이프라인의 각 컴포넌트를 통한 테스트 케이스 흐름을 관찰할 수 있는 디버깅 지원
          + 기존 프로덕션 로그에 의존했던 디버깅 방식보다 훨씬 효율적
     * 향후 계획
          + 데이터셋 확장
               o 협업 그래프와 같은 더 현실적인 기능 추가
          + 도구 개선
               o 엔지니어가 필요에 따라 맞춤형 합성 데이터를 생성할 수 있도록 툴링 강화
          + 생성형 AI 활용 극대화
               o 합성 데이터가 제공하는 가능성을 활용하여 Canva의 검색 도구를 커뮤니티에 최적의 경험으로 발전시키는 목표 지속
"
"https://news.hada.io/topic?id=18041","솔아크 제조업체, 미국 내 모든 Deye 인버터 비활성화 보고","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   솔아크 제조업체, 미국 내 모든 Deye 인버터 비활성화 보고

     * Sol-Ark 제조업체, 미국 내 모든 Deye 인버터 비활성화
          + 2024년 11월 15일, 미국 전역의 Deye 브랜드 인버터가 의도적으로 비활성화되었음이 보고됨.
          + 인버터 화면에 ""이 인버터는 파키스탄/미국/영국에서 사용이 허가되지 않음""이라는 메시지가 표시됨.
          + Sol-Ark는 Deye 하이브리드 인버터의 계약 제조업체이며, 2018년부터 미국 내 독점 판매 권한을 보유하고 있음.
          + 여러 회사가 Sol-Ark의 독점 계약을 위반하여 Deye 브랜드 인버터를 판매한 것으로 보이며, Sol-Ark는 법적 조치를 통해 독점권을 행사함.
     * Sol-Ark의 대응
          + Sol-Ark는 Deye 브랜드 인버터의 비활성화에 대해 책임이 없음을 밝히며, Deye의 행동으로 인해 영향을 받은 가정에 대해 대체 솔루션을 제공할 것이라고 발표함.
          + 2024년 11월 15일부터 12월 31일까지 Deye 인버터가 비활성화된 가정은 동등한 성능의 Sol-Ark 인버터를 할인된 가격에 구매할 수 있는 기회를 제공함.
          + 이 프로그램은 주거용 가정에만 제공되며, 상업 시설에는 적용되지 않음.
     * Sol-Ark의 보안 및 프라이버시
          + Sol-Ark 인버터는 ""MySolArk"" 플랫폼을 통해 관리, 업데이트 및 서비스되며, 고객의 보안과 프라이버시를 보장하도록 설계됨.
          + Sol-Ark는 데이터와 에너지 보안을 최우선으로 하여 플랫폼을 개발하고 배포할 것임.
     * 문제의 심각성
          + 중국 제조업체가 인버터를 원격으로 비활성화할 수 있는 상황은 미국 내 태양광 발전에 대한 중국의 영향력을 시사함.
          + 인터넷에 연결된 태양광 시스템의 보안 문제는 사이버 공격의 큰 표적이 될 수 있음.
          + 설치업체는 미국 내 공식 지원이 있는 인버터를 설치하고, 더 안전한 네트워킹 구조를 고려해야 함.
     * 향후 전망
          + 이 문제의 해결책은 아직 불확실하며, 초기 설치 시 지리적 검사를 하지 않은 Deye의 결정은 잘못된 사람들에게 불이익을 줄 가능성이 있음.

        Hacker News 의견

     * 인터넷에 연결된 장치가 제조사에 의해 임의로 비활성화될 수 있어 위험하다고 생각함. 이는 소프트웨어가 보안에 취약한 경우가 많기 때문임
          + 기사에 따르면, 문제는 Sol-Ark가 아닌 제조사 Deye가 발생시킨 것으로 보임
          + Sol-Ark는 비난받을 이유가 없음
     * 사람들이 중국 시장용 인버터를 회색 시장에서 구매하여 다른 나라로 배송함. Deye는 이러한 행동을 단속하기로 결정함
          + Sol-Ark는 미국에서 Deye 인버터를 재브랜딩하여 승인된 유통업체일 뿐임
     * Solar Edge 인버터를 사용 중이며, 인터넷에 연결하지 않음. 이는 인터넷 연결로 인한 위험을 우려했기 때문임
          + 인터넷에 연결된 인버터의 위험성을 경고하는 법적 요구사항이 필요하다고 생각함
     * Guangzhou Sanjing R5-8K-S2 인버터를 설치 후 예상보다 적은 전력을 생성하는 문제를 겪음
          + 웹 텔레메트리 패널에서 에너지 생성이 0으로 떨어지는 간격이 있었음
          + Python 스크립트를 작성하여 인버터가 241V 이상의 전압을 감지할 때마다 5분 동안 셧다운되는 것을 발견함
          + 제조사의 웹사이트에서 펌웨어 업데이트를 찾지 못했지만, 로컬 모니터링 앱의 매뉴얼과 설치자 전용 설정의 비밀번호를 발견함
          + 비밀번호는 ""123456""으로 하드코딩되어 있음
          + 그리드 셧다운 임계 전압을 241V에서 242V로 올리는 변경을 함
          + 인버터의 유통업체에 연락하여 지원을 요청했으나, 비밀번호를 요구받음
          + 제조사가 설치자/유통업체 계정을 생성해야 하지만, 본인은 그 과정을 우회하여 계정을 생성함
          + 유통업체가 원격으로 인버터에 접근하여 문제를 해결함
          + 인버터의 인터넷 연결을 끊고 싶지만, 보증 조건상 인터넷에 연결되어 있어야 함
          + 인터넷 연결 속도를 제한하여 새로운 펌웨어 업로드를 방지하려고 함
     * 주 전력망에 미치는 영향에 대한 궁금증이 있음
          + 제조사가 얼마나 일반적인지에 대한 질문이 있음
          + 태양광 시스템이 고장나면 확인하는 데 시간이 걸릴 것임
     * Sol-Ark가 위기를 기회로 삼고 있는 것 같음
          + Sol-Ark는 인버터를 벽돌로 만드는 데 직접 관여하지 않았지만, 법적 조치로 Deye를 압박한 것으로 보임
          + Sol-Ark는 고장난 인버터를 가진 개인들에게 새로운 인버터를 구매할 기회를 제공함
     * Sol-Ark가 자체 백엔드로 전환한 시점에 대한 의문이 있음
          + 2024년 5월경에 전환한 것으로 보이며, 그 전에는 모든 Deye 고객이 공유하던 사이트였음
          + 이번 사건이 사전에 계획된 것인지 궁금함
"
"https://news.hada.io/topic?id=18106","Skia Canvas 2.0 릴리즈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Skia Canvas 2.0 릴리즈

     * 브라우저 없이 구현한 Node.js용 HTML 캔버스 그리기 API
     * Google의 Skia 그래픽 엔진 기반, Chrome의 <캔버스> 요소와 매우 유사한 결과를 생성
     * 2.0 주요 변경사항
          + SVG & WEBP 지원
          + WOFF & WOFF2 폰트 지원
          + 이미지 객체가 표준 on/off/once EventEmitter 메소드 지원
          + drawImage/createPattern이 기존 Image 와 Canvas와 함께 이제 ImageData 객체와도 동작
          + Node 최소 버전 12.22+, 14.17+, or 16+ 이상

   Skia Canvas - Node.js용 HTML Canvas API
   Skia Canvas: 노드용 HTML Canvas 드로잉 API의 브라우저리스 구현
"
"https://news.hada.io/topic?id=18069","인텔, 팻 겔싱어 은퇴 발표","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            인텔, 팻 겔싱어 은퇴 발표

인텔 CEO 패트 겔싱어 은퇴 및 새로운 리더십 발표

     * 인텔 CEO 패트 겔싱어가 40년 이상의 경력을 뒤로하고 2024년 12월 1일부로 은퇴
     * 이사회는 데이비드 진스너와 미셸(MJ) 존스턴 홀트하우스를 공동 임시 CEO로 임명
          + 진스너: 현 인텔 CFO
          + 홀트하우스: 새로 신설된 인텔 프로덕트 CEO로 임명
               o 인텔의 주요 그룹(클라이언트 컴퓨팅 그룹, 데이터 센터 및 AI 그룹, 네트워크 및 엣지 그룹)을 포함하는 조직

이사회 및 전환기 전략

     * 이사회 독립 의장 프랭크 이어리가 전환 기간 동안 임시 집행 의장으로 활동
     * 겔싱어의 후임을 찾기 위해 이사회에서 검색 위원회를 구성하고 신속하게 작업 중
     * 인텔 파운드리 리더십 구조는 변함 없음

패트 겔싱어의 공헌과 이사회의 발언

     * 겔싱어는 반도체 제조 및 혁신에 집중하여 인텔의 프로세스 제조를 활성화
     * 2021년 중요한 시점에 CEO로 복귀하여 회사 경쟁력을 회복하는 데 기여
     * 이어리 의장은 제품 그룹에 자원을 집중하며 고객 중심의 경영을 강화할 것이라 언급

겔싱어의 소감

     * 인텔에서의 커리어를 ""평생의 영광""이라 표현하며, 어려운 결정을 통해 시장 환경에 맞는 준비를 한 점을 강조
     * 인텔에서 혁신과 조직 내 긴박감을 불어넣으며 글로벌 기술 산업 전반에 기여

임시 CEO 진스너와 홀트하우스의 리더십

     * 두 리더는 겔싱어의 공헌에 감사하며 인텔 제품과 고객 요구 충족에 전념할 것을 다짐
     * 진스너
          + 반도체, 제조, 기술 산업에서 25년 이상의 재무 및 운영 경험 보유
          + 인텔 합류 전 마이크론 테크놀로지에서 CFO로 근무
     * 홀트하우스
          + 인텔에서 약 30년 경력을 쌓은 검증된 리더
          + 클라이언트 컴퓨팅 그룹(CCG)의 총괄 및 세일즈 및 마케팅 그룹을 이끈 경험 보유

   인텔의 몰락이 기반을 날려먹어서 시작된 것이고 이걸 복구하는 동안에는 눈에 띄는 성과가 나올 수 없을 텐데 너무 성급한 것 아닌가...
   CTO 출신이 내려가고 CFO 출신이 올라온 이 상황이 긍정적으로 보이진 않네요.

   그래서 아마도, 추진되고 있는 차세대공정이 실패한것으로/크게 지연되고 있는걸로 내부적으로 판단한게 아닌가 싶습니다. 이게 희망적이라면, CEO 교체할 필요가 없지 않았을까싶어요.

        Hacker News 의견

     * 한 사용자는 Pat의 전략이 공격적이지만 회사에 필요하다고 언급함. Intel 18a의 성공 여부에 따라 Pat의 은퇴가 단기적인 결정일 수 있다고 봄. Intel 18a가 준비되지 않았다면 AMD와의 합병이 최선의 시나리오일 것이라고 생각함
     * 다른 사용자는 Intel에서 3개월 동안 일한 경험을 공유하며, 회사의 구조적 문제를 지적함. 특히, 인재 부족과 혁신에 대한 의지 부족을 강조함. 많은 인재들이 Apple, Facebook, Google로 이동하고 있다고 언급함
     * 또 다른 사용자는 Gelsinger의 복귀에 기대를 걸었으나, 이전 CEO인 BK가 남긴 문제로 인해 회복이 실패했다고 봄. Gelsinger 하에서 인력 수가 계속 증가했으며, 중간 관리층의 문제를 해결하지 못했다고 지적함
     * 시장은 이 소식을 긍정적으로 받아들이지만, 한 사용자는 이에 동의하지 않으며, Reddit과 YouTube에서 Pat Gelsinger에 대한 비판이 많다고 언급함. Intel이 새로운 CEO를 찾는 것이 중요하다고 봄
     * Gelsinger가 Intel Foundry 스핀 준비 전에 은퇴한 것은 문제가 될 수 있다고 봄. Intel이 A20과 A18 노드에 막대한 투자를 했지만 아직 성과가 없다고 언급함. Foundry가 Intel의 가장 흥미로운 부분이라고 봄
     * Bloomberg의 최신 뉴스에 따르면 Gelsinger가 은퇴하거나 해고될 선택을 받았고, 은퇴를 발표했다고 함
     * Gelsinger의 퇴임은 아쉽지만, Intel이 망할 것이라고는 생각하지 않는다고 언급함. Intel의 자산과 주식 가치를 계산하며, 미국 정부가 Intel을 국가 중요 자산으로 볼 것이라고 예상함. Mobileye와 같은 실험을 중단해야 한다고 봄
     * 한 사용자는 Intel의 CEO 자리에 관심을 표명하며, 자신이 새로운 CEO로 적합하다고 농담 섞인 제안을 함
     * 공기업의 CEO는 반쯤은 치어리더와 같다고 언급하며, Gelsinger의 재임 기간 동안 주가가 61% 하락한 것을 지적함. 투자자 신뢰를 회복할 수 있는 리더가 필요하다고 봄
     * 많은 사람들이 Gelsinger가 적합한 인물이라고 생각하지만, 그는 잘못된 선택이었다고 주장함. Intel이 위기에 처했을 때 강력한 리더십이 필요했지만, Gelsinger는 중간 관리층을 정리하지 못했다고 비판함. Intel의 혁신적인 부분을 소홀히 다뤘다고 봄.
"
"https://news.hada.io/topic?id=18012","레디스 클라이언트 사이드 캐시로 반응성 향상 시키기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      레디스 클라이언트 사이드 캐시로 반응성 향상 시키기

   레디스는 빠르지만, 잦은 데이터 조회는 API 서버에 부담을 줍니다. 특히 실시간 데이터처럼 갱신은 불규칙하지만 자주 조회해야 하는 경우, 효율적인 캐시 전략이 필요합니다.
     * 문제점: Redis PubSub이나 Keyspace Notification은 갱신 감지 및 메시지 처리 로직이 복잡하거나 리소스 낭비를 유발할 수 있습니다.
     * 해결책: Redis 6.0부터 지원하는 Invalidation Message는 서버가 클라이언트 캐시를 관리하는 방식입니다.
          + 클라이언트가 키를 읽은 후 다른 클라이언트가 변경하면, Redis가 갱신 메시지를 보내 캐시를 삭제하도록 합니다.
     * 구현: Go 언어에서 redigo+ristretto 조합 또는 rueidis 라이브러리를 사용하여 Invalidation Message를 적용할 수 있습니다.
          + redigo+ristretto는 커스텀 로직이 필요하지만, rueidis는 DoCache 함수로 간단하게 구현 가능합니다.
     * 결과: 실제 적용 결과, API 응답 속도가 최대 82% 개선되었으며, Redis 서버 부담도 감소했습니다. 클라이언트 사이드 캐시 관리는 필요하지만, 성능 향상 효과가 큽니다.

   👀
"
"https://news.hada.io/topic?id=18003","Hetzner, 미국 VPS 트래픽 축소","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Hetzner, 미국 VPS 트래픽 축소

     * 요금 구조 변경 안내
          + 미국 애쉬번과 힐스보로에 위치한 Cloud 서버(CCX 및 CPX 라인)와 Load balancer의 요금 구조 변경 안내.
          + 2024년 12월 1일부터 새로운 Cloud 서버에 대해 새로운 가격과 포함된 트래픽 양 적용 예정.
          + 기존 Cloud 서버와 Load balancer는 2025년 2월 1일부터 새로운 가격과 트래픽 양 적용 예정.
          + 트래픽 초과 요금은 변경되지 않음.
     * 새로운 가격 및 포함된 트래픽
          + CPX11: €3.85 → €4.49, 20 TB → 1 TB
          + CPX21: €7.05 → €8.99, 20 TB → 2 TB
          + CPX31: €13.10 → €15.99, 20 TB → 3 TB
          + CPX41: €24.70 → €29.99, 20 TB → 4 TB
          + CPX51: €54.40 → €59.99, 20 TB → 5 TB
          + CCX13: €11.99 → €12.99, 20 TB → 1 TB
          + CCX23: €23.99 → €25.99, 20 TB → 2 TB
          + CCX33: €47.99 → €49.99, 30 TB → 3 TB
          + CCX43: €95.99 → €99.99, 40 TB → 4 TB
          + CCX53: €191.99 → €199.99, 50 TB → 6 TB
          + CCX63: €287.99 → €299.99, 60 TB → 8 TB
          + LB11: €5.39, 20 TB → 1 TB (가격 변동 없음)
          + LB21: €16.40, 20 TB → 2 TB (가격 변동 없음)
          + LB31: €32.90, 20 TB → 3 TB (가격 변동 없음)
          + 모든 월간 가격은 VAT 및 IPv4 주소 제외.
     * 변경 이유
          + 전 세계 고객에게 공정한 조건 제공을 목표로 유럽, 싱가포르, 미국의 지역 조건에 따라 가격 책정.
          + 자원을 적게 사용한 고객이 더 많은 자원을 사용한 고객의 비용을 부담하는 상황을 개선하고자 함.
          + 새로운 가격 구조는 고객이 사용하는 자원에 대해 최상의 가격을 제공하기 위함.

        Hacker News 의견

     * Hetzner의 고객 중 일부는 적은 자원을 사용하면서 더 많은 자원을 사용하는 다른 고객의 비용을 부담해왔음. 이를 균형 있게 조정하려는 변화가 있음
          + 한 회사가 Hetzner 서버에 nginx 캐싱 프록시를 설치하여 자체 CDN을 구축한 사례가 있음. 이는 비용 효율적이고 효과적이었음
          + Hetzner는 손실을 보는 제품 SKU에 대해 빠르게 조치를 취하는 경향이 있음. 예를 들어, GPU 서버를 중단한 사례가 있음
          + 미국 고객의 트래픽 사용 패턴이 유럽 고객과 다르거나 네트워크 용량 확장 비용이 예상보다 높았을 가능성이 있음
          + 트래픽 초과 사용 요금은 TB당 $1이며, 싱가포르에서만 $8로 비쌈
          + 자원을 적게 사용한 고객이 더 많이 사용한 고객의 비용을 부담해왔다는 의견이 있음
          + 가격 인상에 대한 불만이 있음. ""구매한 만큼 사용하지 않으면 가격이 두 배로 오른다""는 식의 불만이 제기됨
          + 미국 영어에서는 'tariff'가 주로 수입 관세를 의미하지만, 인도에서는 주로 통신 요금을 의미함
          + 미국 고객의 대역폭 소비가 유럽 및 싱가포르 고객보다 거의 10배 높다는 의견이 있음
          + AWS가 유사한 조치를 취한 적이 있는지에 대한 의문이 제기됨
          + LB11의 경우 20TB에서 1TB로 가격이 동일하게 유지되는 것은 사업에 큰 영향을 미칠 수 있음
          + Hetzner가 20년 후에도 경쟁력을 유지하여 큰 클라우드 업체를 압도할 수 있기를 바라는 의견이 있음
          + OVH의 대역폭 정책이 더 논리적이라는 의견이 있음. 특정 Mbps 한도를 제공함
"
"https://news.hada.io/topic?id=18025","닌자(2020)의 성공과 실패","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            닌자(2020)의 성공과 실패

     * Ninja의 성공과 실패
          + 약 9년 전, 필자는 Make와 유사한 빌드 시스템인 Ninja를 발표했음. 초기에는 부끄러웠지만, 현재는 널리 사용되고 있음.
          + Ninja를 사용하는 주요 프로젝트로는 Chrome, Android, Meson 프로젝트 등이 있음.
          + Ninja는 필자의 가장 성공적인 오픈 소스 프로젝트로, 2011년에 발표하고 2014년에 소유권을 넘겼으며, 현재는 세 번째 유지보수자에게 전달되었음.
          + 프로그래밍은 코드 작성보다 아키텍처가 중요하며, 아키텍처보다 사회적 문제가 더 중요하다는 것을 배웠음.
     * 기술적 세부사항
          + Ninja는 주어진 요구사항에 따라 명령을 실행하는 간단한 시스템임.
          + Ninja는 ninja.build 파일을 받아 파일의 수정 시간을 확인하고 필요한 명령을 병렬로 실행함.
          + Make와 비교했을 때, Ninja는 입력 빌드 언어의 기능이 적고, 빠른 실행에 중점을 둠.
          + Ninja는 입력 파일 경로를 메모리 객체로 매핑하여 경로 비교를 최적화함.
     * 아키텍처 노트
          + Ninja의 그래프 표현은 파일과 명령 사이의 이분 그래프를 사용하여 빌드 구조를 더 잘 캡처함.
          + C 헤더 종속성을 처리하기 위해 추가적인 종속성 데이터를 사용함.
          + Ninja는 비영구적인 데몬 프로세스가 아니며, 각 실행 시 처음부터 작업을 수행함.
          + 파일 상태는 커널이 이미 캐시하고 있어 사용자 영역에서 다시 캐시할 필요가 거의 없음.
          + Ninja는 Chrome의 빌드를 기반으로 설계되었으며, 대규모 프로젝트에서 확장성 문제를 겪고 있음.
     * '어셈블러' 은유
          + Ninja는 다양한 빌드 시스템의 기능을 구현하지 않고, 액션 그래프만 구현하여 사용자가 다른 생성기 프로그램을 선택하도록 함.
          + 이 설계는 Ninja를 빠르고 유연하게 만듦.
     * 기본값의 중요성
          + Ninja는 기본적으로 명령을 병렬로 실행하여, Make보다 더 안전하게 병렬 빌드를 수행함.
     * 속도
          + Ninja는 대규모 코드베이스의 증분 빌드 성능에 중점을 두었으며, 사용자 만족도에 큰 영향을 미침.
          + Ninja는 CPU를 적게 사용하여 전체 빌드 성능도 개선됨.
     * CMake
          + Ninja는 CMake와 잘 통합되었으며, 이 통합을 통해 LLVM 작업에 사용됨.
     * Windows 지원
          + Ninja는 Windows에서도 작동하며, 많은 초기 사용자가 Windows 사용자였음.
     * 관련 작업
          + Ninja의 설계는 Google의 빌드 시스템인 blaze/bazel에서 영감을 받았음.
     * 오픈 소스 유지보수
          + 오픈 소스 유지보수는 즐겁지 않으며, 사용자로부터의 요구와 비판이 많았음.
          + 필자는 소프트웨어를 통해 동료 해커들에게 인상을 주고자 함.
     * 최종 감사
          + Ninja의 유지보수자들과 기여자들에게 감사의 말을 전함.

        Hacker News 의견

     * 프로그래밍은 코드 작성보다 아키텍처가 중요하고, 아키텍처보다 사회적 이슈가 더 중요하다는 의견이 있음
          + 이는 오랫동안 마음속에 있던 생각을 잘 표현한 것이라고 함
     * Android의 빌드 시스템에서 Ninja의 역할이 큼
          + 초기에는 makefiles를 사용했으나, soong이라는 커스텀 선언적 빌드 시스템으로 복잡해졌음
          + Google은 Makefiles를 Ninja 빌드 파일로 변환하는 kati를 개발했음
          + Ninja로의 전환은 시간이 걸리지만, 전환 후에는 빠르게 작동함
     * Google이 지연(latency)에 대한 연구를 진행했으며, 이 연구가 공개되기를 바라는 의견이 있음
     * CMake를 사용할 때 C++20 모듈에 Ninja가 필요하기 때문에 당분간 사용될 것이라는 의견이 있음
     * Ninja 대신 Samurai로 전환했으며, 모든 면에서 개선되었다고 함
          + 빌드 시스템은 모든 입력의 해시를 계산하고 레지스트리에 존재 여부를 확인하는 것이 필요하다고 생각함
     * 정확성과 편리성, 성능 사이에서 타협이 필요하며, 의도적으로 선택해야 한다는 의견이 있음
          + 편리성을 위해 정확성을 포기하는 도구가 더 정확한 생태계를 만들 수 있다고 함
     * 빌드 시스템에 대한 경험이 있으며, Ninja는 좋아하는 프로그래밍 언어로 구현할 수 있을 만큼 작다고 함
          + 자신의 빌드 시스템을 만드는 단계별 튜토리얼이 있는지 궁금하다고 함
     * Ninja의 이름이 좋다고 생각하며, 더 빠르게 만들 수 있는 방법이 있다고 함
          + 도구가 이전 실행의 상태를 의도적으로 유지하지 않는다고 설명함
"
"https://news.hada.io/topic?id=18093","Amazon Nova 출시 : 뛰어난 가성비를 지닌 최첨단 인공지능","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Amazon Nova 출시 : 뛰어난 가성비를 지닌 최첨단 인공지능

     * Amazon Nova는 Amazon Bedrock에서 독점적으로 제공되는 최첨단 기초 모델로, 다양한 생성 AI 작업에서 비용과 지연 시간을 줄이는 데 도움을 줌. 복잡한 문서와 비디오 분석, 차트 및 다이어그램 이해, 매력적인 비디오 콘텐츠 생성, 고급 AI 에이전트 구축에 사용 가능.
     * 이해 모델: Amazon Nova는 텍스트, 이미지, 비디오 입력을 받아 텍스트 출력을 생성하는 이해 모델과 텍스트 및 이미지 입력을 받아 이미지 또는 비디오 출력을 생성하는 창의적 콘텐츠 생성 모델로 구성됨.
          + Amazon Nova Micro: 텍스트 전용 모델로, 낮은 비용과 빠른 응답 속도를 제공. 텍스트 요약, 번역, 콘텐츠 분류, 대화형 채팅, 간단한 수학적 추론 및 코딩에 적합.
          + Amazon Nova Lite: 이미지, 비디오, 텍스트 입력을 빠르게 처리하여 텍스트 출력을 생성하는 저비용 멀티모달 모델. 실시간 고객 상호작용, 문서 분석, 시각적 질문 응답에 적합.
          + Amazon Nova Pro: 정확성, 속도, 비용의 최적 조합을 제공하는 고성능 멀티모달 모델. 복잡한 워크플로우를 위한 API 호출 및 도구 사용에 적합.
          + Amazon Nova Premier: 복잡한 추론 작업을 위한 최상위 멀티모달 모델로, 2025년 초 출시 예정.
     * 창의적 콘텐츠 생성 모델:
          + Amazon Nova Canvas: 스튜디오 품질의 이미지를 생성하는 이미지 생성 모델로, 스타일과 콘텐츠에 대한 세밀한 제어 가능.
          + Amazon Nova Reel: 텍스트 프롬프트와 이미지를 통해 짧은 비디오를 생성하는 비디오 생성 모델로, 마케팅, 광고, 엔터테인먼트에 적합.
     * 사용 사례:
          + 문서 분석: Amazon Nova Pro를 사용하여 PDF 문서의 요약 및 의사 결정 트리 생성 가능.
          + 비디오 분석: Amazon Nova Pro를 사용하여 비디오의 시각적 내용을 분석 가능.
          + 비디오 생성: Amazon Nova Reel을 사용하여 텍스트 프롬프트와 참조 이미지를 통해 비디오 생성 가능.
     * 책임 있는 AI 구축: Amazon Nova 모델은 고객 안전, 보안, 신뢰를 중시하며, 생성된 이미지와 비디오에 디지털 워터마킹 포함.
     * 중요 사항: Amazon Nova 모델은 Amazon Bedrock의 미국 동부(N. Virginia) AWS 리전에서 사용 가능하며, 다양한 언어를 이해하고 생성할 수 있음. Amazon Bedrock과의 통합으로 배포 및 확장이 용이하며, 다양한 비즈니스 사용 사례에 적합.

        Hacker News 의견

     * Amazon의 제품 설명이 이해하기 어렵다는 의견이 있음. 새로운 제품을 이해하려면 여러 페이지를 클릭해야 하는 번거로움이 있음
          + Amazon의 설명 방식이 제품의 실제 기능을 숨기려는 것처럼 보임
     * Amazon Bedrock API를 설정하는 과정이 복잡하여, 이를 위한 단계별 가이드를 작성한 사람이 있음
          + 가이드는 14단계 이상으로 구성되어 있음
     * 현재 모델은 오디오 지원이 없으며, 비디오의 시각적 정보만 처리할 수 있음
          + gemini-1.5-flash 모델이 오디오를 무시하는 것이 전략적 결정일 수 있음
          + Meta가 멀티모달 오디오 모델을 출시해주길 바라는 의견이 있음
     * 가격 차이에만 집중하고 품질에 대한 언급이 없는 경우, 제품이 실패할 가능성이 높음
          + LLM에서는 품질이 더 중요한 지표임
     * 유럽에 호스팅된 버전을 제공하지 않은 것이 큰 기회를 놓친 것이라는 의견이 있음
          + 이는 컴플라이언스와 관련이 있으며, 데이터가 EU 외부에 저장되는 것은 문제임
     * Amazon Nova 모델이 여러 복사본으로 훈련되었는지에 대한 질문이 있음
          + NVidia GPU와 TRN1 클러스터를 사용하여 병렬 훈련을 진행했음
     * 더 많은 옵션과 경쟁이 좋은 것이라는 의견이 있음
          + lmarena.ai에서 언제 볼 수 있을지 궁금해하는 사람도 있음
     * 가격 정보가 가운데 정렬되어 있어 읽기 어려운 점을 지적하는 의견이 있음
"
"https://news.hada.io/topic?id=18013","Oncall 시프트는 화요일부터 화요일까지가 되어야 합니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Oncall 시프트는 화요일부터 화요일까지가 되어야 합니다

     * 전통적으로 개발자, SRE, IT 팀의 온콜 근무는 월요일부터 다음 주 월요일까지 설정됨
     * 화요일에서 화요일로 변경하면 비용 없이 일정의 정확도를 높이고 삶의 질을 개선할 수 있음

배경

     * 온콜의 필요성
          + 소프트웨어 시스템은 24/7 운영을 요구하며, 버그, 트래픽 급증, 예상치 못한 엣지 케이스 등 다양한 문제가 발생 가능
          + 온콜 근무자는 이러한 문제를 해결하고 팀의 다른 개발자가 방해받지 않도록 보장하는 역할을 수행함
     * 온콜 업무
          + 라이브러리 종속성 업데이트, 서버 재부팅, 주간 작업, 구성 변경 등 정기적인 관리 작업 포함
          + 시스템 유지 관리 외에도 크고 작은 요청 처리 및 긴급 상황 대응
     * 온콜 교대 회의
          + 보통 주간 온콜 간 교대 시점에 진행되며, 현재 온콜 담당자와 다음 온콜 담당자가 회의하여 주요 이슈를 공유

제안: ""온콜 교대를 화요일로 변경""

     * 기존 월요일 시작 대신, 화요일부터 화요일까지로 온콜 시프트를 설정
     * 온콜 시프트 회의도 화요일로 변경

이유

  공휴일에 유리

     * 미국에서는 월요일이 공휴일인 3일 주말이 자주 발생
     * 월요일에 교대를 하면 두 명의 주말이 방해받는 반면, 화요일로 설정하면 한 명만 영향을 받음
     * 공휴일마다 온콜 교대 회의를 화요일로 변경할 필요도 사라짐

  주말 이슈 후속 조치 개선

     * 주말에 발생한 주요 문제는 일반적으로 두 단계로 처리됨:
         1. 문제 해결
         2. 문제 재발 방지 조치
     * 재발 방지 작업(알람 생성, 런북 업데이트 등)은 평일에 진행되는 경우가 많음
     * 화요일로 교대를 설정하면 월요일 하루 동안 현재 온콜 담당자가 후속 작업을 완료할 가능성이 높아짐

  주간 작업 처리에 적합

     * 온콜 교대 준비 작업은 보통 월요일에 진행되므로, 화요일 교대는 실제 작업 흐름을 반영
     * 매주 반복되는 관리 작업을 처리하는 시간을 명확히 설정 가능

반론 및 대응

  스프린트는 월요일에 시작됨

     * 스프린트 시작일과 온콜 시작일이 다르면 스프린트 계획에 혼란이 생길 수 있다는 주장
     * 그러나 하루 차이는 스프린트 계획에서 충분히 허용 가능한 범위
     * 월요일 작업량이 변경되더라도 화요일 교대는 스케줄의 현실성을 높임

  다른 팀은 월요일에서 월요일로 설정

     * 여러 온콜 팀이 있는 경우 서로 다른 교대 날짜가 혼란을 초래할 수 있음
     * 그러나 이러한 혼란은 다른 팀의 온콜 담당자를 한 명 더 추가하는 정도로 해결 가능
     * 이 글을 공유하여 화요일로의 전환 논의를 유도했으면 함

   미국은 ""월요일 공휴일 법""을 만들어서 1971년부터 시행하고 있습니다.

   한국도 ""요일제 공휴일"" 제도를 도입하겠다는 이야기가 있었는데 아직 적용은 안되었습니다. 2026년에 사회적 논의를 거쳐서 제도를 개선한다고만 나와있네요.
"
"https://news.hada.io/topic?id=18087","미술관 근무 경험에서 얻은 교훈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           미술관 근무 경험에서 얻은 교훈

    미술관에서 배운 6가지 교훈

      1. 평범한 직업을 훌륭한 직업으로 바꾸는 것이 가능함

     * 미술관에서의 일은 처음에는 매력적이지 않았으나, 스스로 프로젝트처럼 접근하여 개선할 수 있었음.
     * 자발적으로 카페와 계산대의 효율성을 높이고, 비즈니스 분석을 통해 개선 방안을 찾았음.
     * 신뢰를 쌓고 다른 사람들과 조율하는 것이 중요하다는 것을 배움.

      2. 최고의 예술가는 최고의 스타트업 창업자를 연상시킴

     * 많은 예술가들과 일했으며, 그 중 일부는 자아 중심적이었지만, 최고의 예술가들은 항상 자신을 발전시키고 협력하기 쉬운 사람들이었음.
     * 예술가 A와 B는 이미 충분한 돈을 벌었지만, 더 나은 예술을 만들기 위해 계속 노력함.

      3. 최악의 전시회가 가장 많은 일을 필요로 함

     * 이메일 응답이 느리거나 요구가 많은 예술가와의 작업은 시간이 많이 걸리고 결과가 좋지 않음.
     * 반면, 신속하고 협력적인 예술가와의 작업은 자연스럽게 잘 진행됨.

      4. 아름다움을 중요시한다면 경제 성장도 중요시해야 함

     * 미술관은 돈을 벌기보다는 아름다움과 공동체 강화를 목표로 함.
     * 그러나 자금 조달을 해결하지 않으면 좋은 일을 할 수 없음을 깨달음.

      5. 인센티브가 가치와 일치하는 곳을 찾아야 함

     * 시장의 인센티브가 예술적 가치와 충돌할 수 있지만, 인내심과 노력으로 두 가지가 일치하는 지점을 찾을 수 있음.
     * 위대한 예술가들은 이러한 지점을 잘 찾아내어 자신의 가치를 유지하면서도 시장에서 성공함.

      6. 대부분의 사람들은 진지하지 않음

     * 미술관에서 일하면서, 많은 사람들이 자신의 일을 제대로 하지 않는다는 것을 발견함.
     * 기본적인 회계나 전략 분석을 통해 쉽게 개선할 수 있었음.

   Henrik Karlsson은 미술관에서의 경험을 통해 많은 것을 배웠으며, 이를 바탕으로 자신의 프로젝트에 집중하고자 함.

        Hacker News 의견

     * 저자는 ""최고의 예술가""를 판단할 수 있다고 믿기 어렵다는 의견이 있음. 예술가와의 작업 용이성으로 전시회의 성공 여부를 예측한다고 하지만, 이는 객관적인 기준이 아닌 자신의 판단에 의한 것임.
     * 위대한 예술가들이 ""인센티브 벡터""를 잘 이해한다고 주장하지만, 많은 위대한 예술가들은 상업적 성공과는 무관하게 가난하게 살았음. 상업적 성공이 예술의 위대함을 정의하는 것은 아님.
     * 이메일에 즉각적으로 답변하지 않는 것이 예술가의 능력을 판단하는 기준이 될 수 없다는 의견이 있음. 사람들은 다양한 이유로 즉각적인 답변을 하지 않을 수 있음.
     * 조직 내에서 기여도가 높은 사람의 경험이 주로 비최적화된 환경에서의 결과라는 의견이 있음. 높은 성과를 내는 조직에서는 이러한 관찰이 적용되지 않을 수 있음.
     * Henrik Karlsson의 글이 인상적이며, 그의 다른 작품도 추천함.
     * 기사 자체는 훌륭하지만, 과학적 용어와 기술 인플루언서를 인용하여 주제를 흥미롭게 만드는 것이 Hacker News에서 인기를 끄는 이유라는 의견이 있음.
     * 예술가의 성공을 예측하는 기준이 주관적이라는 비판이 있음. 그러나 성실함과 같은 시민적 덕목이 성공에 기여할 수 있다는 의견이 있음.
     * 예술이 경제적 엔진을 작동시키는 것에만 집중하는 것은 좁은 시각이라는 의견이 있음. 예술은 다양한 방식으로 세상을 더 나은 곳으로 만들 수 있음.
     * 예술 기관은 종종 특정 사람들을 고용하거나 가시성을 높이기 위해 최적화되지 않는다는 의견이 있음. 이는 워크숍과 기금 모금 행사의 이유일 수 있음.
     * 다른 사람을 설득하는 방법에 대한 전략이 궁금하다는 의견이 있음. ""Good to Great""의 사례가 떠오름.
     * 기사가 재미있고 통찰력이 있다는 의견이 있음. Hacker News에서 1위를 차지하지 않았다면 읽지 않았을 것임.
"
"https://news.hada.io/topic?id=18052","AMD, Zen 4의 루프 버퍼 비활성화 결정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       AMD, Zen 4의 루프 버퍼 비활성화 결정

    AMD가 Zen 4의 루프 버퍼를 비활성화함

     * 루프 버퍼의 역할: CPU의 프론트엔드에 위치하여 이전에 가져온 명령어를 저장함. 작은 루프는 루프 버퍼에 포함될 수 있으며, 이를 통해 일부 프론트엔드 단계를 비활성화하여 전력을 절약하고 성능을 향상시킬 수 있음. Intel, Arm, AMD 코어에서 사용되는 오래된 기술임.
     * Zen 4의 루프 버퍼: Zen 4는 AMD의 고성능 코어 중 유일하게 루프 버퍼를 포함하고 있음. 성능 카운터 실험에 따르면, 코어가 하나의 스레드로 실행될 때 144개의 항목을 가짐. 두 개의 SMT 스레드가 활성화되면 각 스레드에 72개의 항목을 할당함. 루프 내에서 호출 및 반환이 발생하면 루프 버퍼에 캡처되지 않음.
     * BIOS 업데이트 후 변화: ASRock B650 PG Lightning을 BIOS 버전 3.10으로 업데이트한 후, 하드웨어 성능 모니터링에서 프론트엔드가 더 이상 루프 버퍼에서 마이크로-옵을 디스패치하지 않음을 확인함. BIOS 버전 1.21로 되돌리면 루프 버퍼가 다시 활성화됨. AMD는 BIOS 1.21(AGESA 버전 1.0.0.6)과 BIOS 3.10(AGESA 버전 1.2.0.2a) 사이에서 루프 버퍼를 비활성화한 것으로 보임.

  SPEC CPU2017: 차이점 찾기

     * 성능 영향: SPEC CPU2017 점수는 루프 버퍼의 활성화 여부에 따라 눈에 띄는 차이가 없음을 보여줌. 정수 및 부동 소수점 스위트의 총 점수는 1% 미만의 차이를 보임. SMT 성능 향상도 영향을 받지 않음.
     * 루프 버퍼의 역할: 루프 버퍼는 성능 향상을 위한 것이 아니라, 코어가 프론트엔드의 많은 부분을 비활성화할 수 있도록 하는 것이 주된 목표임. Zen 4의 프로세서 프로그래밍 참조에 따르면, 성능 카운터는 이벤트 수가 임계값을 초과할 때마다 1씩 증가하도록 프로그래밍할 수 있음.

  Cyberpunk 2077

     * 게임 성능 테스트: Cyberpunk 2077의 내장 벤치마크를 사용하여 루프 버퍼 비활성화가 게임 성능에 미치는 영향을 확인함. 루프 버퍼 비활성화가 게임 성능에 거의 영향을 미치지 않음을 확인함.

  전력 소모 확인 시도

     * 전력 효율성: Zen 4의 코어 전력 카운터를 사용하여 루프 버퍼가 전력 효율성을 개선하는지 확인하려 했으나, 결과가 일관되지 않음. 새로운 BIOS에서는 루프 버퍼를 테스트할 수 없음.

  결론

     * 루프 버퍼 비활성화 이유: AMD가 Zen 4의 루프 버퍼를 비활성화한 이유는 불분명함. CPU 기능은 하드웨어 버그로 인해 비활성화될 수 있음. Zen 4는 AMD의 고성능 CPU에 루프 버퍼를 처음 도입한 사례임. 성능에 미치는 영향은 거의 없으며, 전력 소비에 미치는 영향도 미미할 것으로 추정됨.

        Hacker News 의견

     * 하드웨어 취약점을 방지하기 위해 기능이 비활성화된 것일 가능성이 있음. 루프 버퍼가 성능이나 전력 이점이 없음을 시사함
          + 엔지니어 팀이 몇 달 동안 새로운 기능을 개발했지만 실제로는 이점이 없었고, 체면을 위해 출시된 경우일 수 있음
          + 소프트웨어 팀에서도 코드베이스를 다시 작성하여 성능을 높이려 하지만, 프로젝트 완료 후 코드가 더 많아지고 성능이 악화되는 경우가 있음
          + 두 경우 모두 프로젝트는 출시되지 말았어야 했음
     * Zen 4의 루프 버퍼는 회사가 엔지니어링 역량을 가지고 실험할 수 있음을 나타냄
          + 이번에는 성과가 없었지만, 엔지니어들이 저위험, 저영향 기능으로 실험하는 것은 자신감을 키우는 좋은 방법임
          + 앞으로 더 많은 자신감을 기대함
     * 7950x3d를 사용 중이며, Skylake의 6700k에서 업그레이드했음
          + 하드웨어 루프 버퍼가 소프트웨어에 의해 비활성화된 칩에 무의식적으로 끌리는 것 같음
     * 게임에서 루프 버퍼가 비활성화되면 비캐시 다이에 고정될 때 성능이 5% 감소함
          + 더 자세한 전력 측정으로 열/전력 예산 관련 여부를 확인할 수 있을 것임
          + 이 기능이 전력을 절약하기 위한 것처럼 들림
     * 루프 버퍼가 특정 시나리오에서만 차이를 만들 정도로 작았고, 더 큰 버퍼는 비용 대비 이점이 적었을 것임
          + 일부 작업 부하에서는 소폭의 성능 저하가 있을 수 있지만, AMD는 출시 이후 약간의 성능 개선을 이루었음
          + Zen 4의 BIOS 옵션으로 만들었어야 했음. 그렇지 않은 것은 버그나 보안 문제 가능성을 나타냄
     * Cortex-A15에서는 ""주요 설계 기능""임
          + 다른 칩에 미치는 영향에 대한 수치가 있는지 궁금함
          + 장기적으로 사용되는 디자인(예: 콘솔)에서 최적화 대상으로 사용할 수 있을 것임
     * 루프 버퍼가 다이에서 차지하는 공간이 얼마나 되는지 이해가 안 됨
          + 제거된 경우, 미래 칩에서 더 유용한 L2 캐시 같은 것을 위해 공간을 사용할 수 있을지 궁금함
     * ""전력"" 섹션에서 초당 실행된 명령어 수로 나누지 않음
          + 루프 버퍼의 이점을 보기 위해 고려해야 할 메트릭은 초당 에너지가 아니라 명령어당 에너지 사용량임
     * 1979년 68000과 1982년 68010의 차이 중 하나는 6바이트 루프 버퍼인 ""루프 모드""의 추가였음
"
"https://news.hada.io/topic?id=18043","Prometheus 3.0 릴리즈 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Prometheus 3.0 릴리즈

     * 7년 만의 첫 메이저 업데이트로, 기존 버전과의 호환성을 유지하면서 새 기능들을 도입
     * 새롭게 설계된 현대적인 UI
     * Remote Write 2.0으로 프로토콜 개선
     * UTF-8을 메트릭 이름/라벨에 사용 가능
     * OpenTelemetry 와의 상호운용성 강화
     * 네이티브 히스토그램을 지원하여 기존 히스토그램보다 더 높은 효율성과 낮은 비용 가능
     * 2.0 대비 메모리 사용량과 CPU 효율성 대폭 개선

새로운 UI

     * Prometheus 3.0의 가장 큰 특징 중 하나는 새롭게 설계된 UI임
     * 특징:
          + 더 간결하고 현대적인 인터페이스
          + PromLens 스타일의 트리 뷰 추가
          + 유지보수를 간소화하는 최신 기술 스택 적용
     * 베타 이후 UTF-8 메트릭 및 라벨 이름 지원 추가
     * 구 버전 UI는 old-ui 플래그로 임시 활성화 가능

Remote Write 2.0

     * Remote Write 프로토콜을 개선하여 메타데이터, 예제, 생성 타임스탬프, 네이티브 히스토그램 등의 원활한 지원 추가
     * 스트링 내부화(string interning)를 사용해 페이로드 크기 및 CPU 사용량 감소
     * 부분 쓰기 처리 개선: 클라이언트에 더 자세한 오류 정보 제공

UTF-8 지원

     * 이제 UTF-8 문자로 메트릭 이름과 라벨 값 사용 가능
     * UTF-8을 지원하지 않는 환경에서는 기존의 언더스코어 방식으로 처리
     * PromQL에서 새 인용 구문으로 UTF-8 메트릭 조회 가능
     * 현재 Go 클라이언트 라이브러리만 UTF-8 지원 업데이트가 완료되었으며, 다른 언어는 곧 추가 예정

OTLP 지원

     * OpenTelemetry(OTLP) 와의 상호운용성을 강화
     * OTLP Ingestion:
          + Prometheus가 /api/v1/otlp/v1/metrics 엔드포인트에서 OTLP 메트릭을 기본적으로 수신하도록 구성 가능
          + OTLP 가이드를 통해 설정 방법 확인 가능
     * UTF-8 정규화:
          + OpenTelemetry 메트릭과 라벨 이름에서 점(.)을 밑줄(_)로 변경하는 작업이 필요 없어짐
          + OTLP 수집을 위한 다양한 변환 전략에 대한 실험적 지원

네이티브 히스토그램

     * 네이티브 히스토그램은 기존 히스토그램보다 더 높은 효율성과 낮은 비용 제공
     * 특징:
          + 데이터 세트에 맞게 버킷 경계를 업데이트하지 않아도 되는 지수 기반 버킷
          + 실험적 기능으로, --enable-feature=native-histograms 플래그로 활성화 가능
     * 일부 포맷과 연산자는 아직 설계 중

Breaking Changes

     * 주요 릴리스에서 기존 기능을 깨뜨리지 않으려 노력했지만, 몇 가지 작은 변경 사항 포함:
          + 기능 플래그
          + 설정 파일
          + PromQL
          + 스크랩 프로토콜
     * 영향을 받을 수 있는 설정은 마이그레이션 가이드를 통해 확인 가능

앞으로의 개선 계획

     * 새롭고 포괄적인 거버넌스 모델
     * OpenTelemetry와의 추가 호환성 제공
     * OpenMetrics 2.0 (Prometheus 거버넌스 하에 개발)
     * 네이티브 히스토그램 안정화 및 사용자 지정 버킷 지원
     * 추가 최적화
     * UTF-8 지원 확대

   현대적인 UI 라..

   곧 적용해봐야겠네요
"
"https://news.hada.io/topic?id=18110","의존성 관리의 피로함: React를 버리고 Go+HTMX+Templ 를 선택한 이유","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             의존성 관리의 피로함: React를 버리고 Go+HTMX+Templ 를 선택한 이유

     * 올해 Go, HTMX, Templ을 사용하여 개인 프로젝트를 진행한 후 React 사용을 포기하기로 결정
          + HTMX 공식 웹사이트에서 React를 포기하고 HTMX를 선택하는 여러 설득력 있는 주장을 찾을 수 있지만, 의존성 관리 피로에 대해 이야기하는 사람이 많지 않다고 느낌
     * ""의존성 관리 피로""란 무엇인가?
          + React를 사용한 마지막 개인 프로젝트(인터랙티브 카탈로니아어 사전)에서 주로 React 패키지의 의존성 업데이트에 너무 많은 시간을 소비하고 있음을 깨달음
          + 패키지를 최신 릴리스로 업데이트하면 API에 중대한 변경 사항이 발생하여 코드 리팩토링에 시간을 투자해야 했음
          + 웹앱이 EC2 인스턴스에서 공개 서비스로 배포되었기 때문에 의존성 업데이트를 유지하고자 했음
     * 새로운 주요 버전 릴리스가 정말 필요한가?
          + wouter(React 라우터 패키지)와 TanStackQuery(백엔드에서 데이터를 가져오고 캐시하며 상태를 관리하는 데 사용)와 같은 패키지가 주요 버전 업데이트로 인해 웹앱이 치명적으로 손상됨.
          + 첫 번째 주요 버전 업데이트로 인해 애플리케이션이 손상되었을 때는 의문 없이 코드를 리팩토링했지만, 두 번째로 발생했을 때는 의문이 생김.
          + 웹앱이 보안 패치를 제외하고 주요 버전 릴리스로부터 실제로 어떤 이점을 얻고 있는지 의문을 가짐.
          + 주요 구성 요소의 API를 5번이나 깨뜨리는 것이 필요한지 의문을 가짐.
          + 새로운 기능이나 다른 제품을 출시할 수 있는 시간을 얼마나 잃고 있는지 고민함.
     * 시간 부족 문제
          + 개인 코딩 프로젝트에 할애할 시간이 많지 않기 때문에 의존성의 주요 버전 업데이트 후 코드를 리팩토링하는 데 시간을 낭비하고 싶지 않음.
          + 고객을 위한 제품을 구축하고 향후 유지보수 작업에 대해 비용을 청구할 계획이라면 불안정한 의존성을 많이 사용해도 좋음.
          + 그러나 최소한의 유지보수가 필요한 제품을 만들고자 한다면 JS 생태계에서 멀리 떨어져 있겠음.
     * Go+HTMX+Templ 사용
          + 개인 프로젝트에서 Go+HTMX+Templ을 사용하는 주된 이유는 Go 프로젝트가 기능을 출시하는 데 집중할 수 있게 해주면서도 일반적인 의존성/보안 업데이트를 무시하지 않기 때문임.
          + Go 언어 자체는 안정적인 표준 라이브러리와 언어 사양을 유지하고 있음.

   HTMX 는 긍정적인 평이 많네요.
   SSR 기반의 어플리케이션의 보완책 으로써 HTMX 를 많이 찾는걸까 싶네요.
   사이드에서 한번 시도 해 보아야겠네요.

   TanStack 라이브러리는 필요 이상으로 복잡하고 최근 몇년동안 문서 품질이 낮아져서 고르지 않았습니다. 그리고 npm 패키지들의 교체주기가 너무 짧아서 항상 최신버전을 고집할 필요가 있나 싶기도 합니다

   다만 회사일할때는 React를 버릴수는 없을거 같아요. 개인 프로젝트라면 뭘 써도 상관없겠지만요

   메이저 버전 업데이트만 안하면 의존성 문제는 크게 없지 않나요...?

   얼마 전에 사내에서 돌아가는 스케쥴 잡 중에 파이선2로 돌아가는 녀석을 봤는데, 숨이 막히더군요.
   고민하다가, 지금은 잘 돌아가니 일단 두자고 했습니다. 언제까지고 업데이트 안하고 버틸 수는 없겠죠.

   의존성 관리의 피로함 VS 바퀴를 새로 만드는 지겨움
   오래된 논쟁입니다. 필요 없는 바퀴는 안 쓰는 게 맞긴 한데, 오늘 필요 없다고 내일도 필요 없을지...
   GO는 사용해본 적 없긴 한데, 요즘 GO로 만든 서버가 많이 보이네요. 당장 쓰진 않더라도 한 번 다뤄보긴 해야 겠어요.

   HTMX는 힙한 기술의 선두주자라서 그런가 적용해보는 사람들이 많은데 차라리 go + vecty + gox 같은 방향은 어떨까 싶네요

        Hacker News 의견

     * React와 같은 라이브러리를 포기하고 Actix, Tera, HTMX로 웹 앱을 개발한 경험을 공유함. 이러한 스택은 유지보수성이 뛰어나며, 사용자들에게 인기를 끌고 있음
          + 새로운 웹 앱을 빠르게 개발하여 테스트 사용자에게 배포한 경험을 설명함
          + ""의존성 관리 피로""가 없었기에 도구에 대한 깊은 이해를 얻을 수 있었음
     * Tanner의 라이브러리는 기능이 많지만 API 디자인이 부족하다고 평가함
          + React Table과 React Query는 강력하지만 경계가 잘못 설정되어 있어 문제를 일으킴
          + React의 장점은 프레임워크가 아니라는 점이며, 잘 설계된 경계에서 멈춤
          + 이러한 기준을 충족하는 라이브러리만 채택하려고 노력함
     * HTMX 예제가 복잡성을 다른 부분으로 옮긴다고 느끼며, JSX가 템플릿을 피하는 우아한 방법이라고 설명함
          + 라우팅, 상태 관리, 인증 등 여전히 해결해야 할 문제들이 많음
     * React를 포기한다고 말하는 것이 이상하다고 느끼며, 문제는 React가 아닌 다른 의존성에 있다고 주장함
          + Go로 백엔드를 작성하는 선택은 항상 가능했음
     * 패키지의 다음 주요 버전으로 업데이트할 때 변경이 예상된다는 점을 잊지 말라고 강조함
          + Remix의 예를 들어, 변경 사항을 점진적으로 적용할 수 있는 방법을 설명함
          + 좋은 패키지는 큰 노력이 필요하다고 주장함
     * Django와 HTMX로 SPA 프로젝트를 마이그레이션한 경험을 공유하며, JavaScript 의존성을 크게 줄였다고 설명함
          + SPA가 시간 폭탄처럼 느껴졌다고 표현함
     * React는 잘못 유지되는 서드파티 패키지의 책임이 아니라고 주장함
          + 라우터나 Redux 같은 상태 관리 도구가 필요하지 않다고 설명함
     * react-query의 v5가 v3 API와 호환되었어야 한다고 생각하지만, 마이그레이션이 쉽고 필수적이지 않다고 설명함
          + ""의존성 관리 피로""가 과장되었다고 느끼며, 합리적인 수의 의존성을 유지하라고 조언함
     * 웹 앱이 추가적인 이점을 얻지 못했음에도 불구하고 업그레이드한 이유를 의문시함
          + 최신 버전으로 업그레이드하는 것이 이점이 없다고 설명함
     * React와 nextjs를 포기하고 다른 스택으로 전환한 후 스트레스가 줄어들고 업데이트가 더 이상 우울증을 유발하지 않는다고 설명함
"
"https://news.hada.io/topic?id=18109","ELT 해체하기: Silo가 아닌 Graph가 필요한 경우","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ELT 해체하기: Silo가 아닌 Graph가 필요한 경우

     * ELT(Extract, Load, Transform)는 조직 내 데이터 분석과 소프트웨어 개발의 ""사일로(Silo)"" 를 연결하기 위해 사용되지만, 이러한 사일로 구조 자체가 문제의 근원
     *

     ELT는 사일로간의 브릿지일 뿐. 사일로가 없는 세상은 ""그래프(Graph)""임

ELT 사고방식의 한계

     * 한 사일로에는 소프트웨어가 있고 다른 사일로에는 데이터 분석이 있는 사일로의 세계에서 ELT는 매우 의미가 있음
     * ELT는 사일로 구조를 전제로 동작
          + 소프트웨어 개발팀과 데이터 분석팀이 분리된 상황에서 ""추출(Extract)"" 작업이 발생
          + 소프트웨어 팀은 데이터 팀의 작업에 관심이 없으며, 데이터 팀은 데이터베이스 권한을 사용해 무작정 데이터를 추출
          + 추출 이후에야 데이터 품질과 모델링과 같은 엔지니어링 원칙이 적용되지만, 이는 이미 너무 늦음
     * Conway의 법칙이 작동함
          + ""조직이 만드는 시스템의 설계는 조직의 의사소통 구조를 닮는다""
     * 사일로 사고방식으로 인해 ETL/ELT/Reverse ETL은 현대 데이터 아키텍처의 복잡성을 다루기에 부적합
          + 데이터는 이제 운영 시스템, 분석 시스템에만 있는게 아니라, SaaS로 대표되는 세 번째 데이터 영역으로 확장됨
          + 데이터는 지역과 클라우드, 백엔드와 SaaS 간에 흐름
          + 지금은 예전보다 100배나 더 많은 애플리케이션이 존재하며, 조직은 소프트웨어화 되고 있고 소프트웨어 시스템 간의 관계망은 점점 더 복잡해짐

그래프 사고방식의 필요성

     * 소프트웨어 팀과 데이터 팀이 조화롭게 협력한다면 ELT처럼 데이터를 추출 및 저장하는 모델 대신 그래프 모델 로 전환 가능
          + 데이터를 ""소비(Consume)"" 하는 노드로 구성된 그래프를 상상
          + 각 노드는 데이터를 생산하거나 소비하며, 자연스럽게 네트워크 또는 그래프 형성
     * 그래프 사고방식의 이점:
          + 데이터 추출이 줄어들고, 소비가 늘어남
          + 고품질 데이터 세트를 중심으로 데이터 모델링 증가
          + 데이터 청소, 원시 데이터 저장, 파이프라인 오류 수정 감소
          + 배치 프로세스를 대체하는 점진적 처리 및 스트리밍 소스 활용
          + 분석이 전략적 의사결정 도구에 국한되지 않고 운영적 용도로 확장
          + 팀 간 협력 및 정렬 증가, 사일로 감소

  결론

     * ELT 사고방식은 소프트웨어와 데이터 팀 간의 단절을 반영하는 Conway의 법칙의 결과
     * 기존 ETL/ELT 도구를 모두 폐기할 필요는 없지만, 데이터 소비와 신뢰할 수 있는 파생 데이터 세트 구축에 초점을 맞춰야 함
     * 현실적으로 Shift Left는 아직 열망하는(aspirational) 단계이며, 기존의 레거시 인프라와 통합 문제는 여전히 존재
          + Shift Left : 소프트웨어 개발 수명 주기(SDLC) 초기에 중요한 개발 관행을 통합하는 전략
     * 그래프 사고방식을 수용하는 조직은 데이터 활용, AI ROI, 비즈니스 성과에서 가장 큰 이점을 얻을 것

     ""추출(Extract)은 없다. 소비(Consume)만 있다."" – 데이터 요다

   데이터메시 책을 읽고 보니 이해가 되는 부분이 많네요.

   꾸준히 그래프 기반 의사결정에 관련해서 아이데이션 하고 있는데 같은 생각을 하고 있는 사람들이 모일 수 있으면 좋을 거 같습니다

   이럴때 쓰는 용어가 아이데이션 이군요. 하나 배웠습니다. 개인적으로 매우 관심있는 주제입니다. 모일수 있으면 참 좋겠습니다.

   혹시 좀 더 설명해주실 수 있는 분 계신가요? 필자가 말하는 방식은 그래프로 파생되는 데이터셋을 전부 따로 저장하고 관리한다는 건가요? 이게 아니라면 ETL과 무엇이 다른지 잘 이해가 되지 않습니다.

   기존 운영 영역과 분석 영역이 분리되어 있는 구조는 사일로 되어 있는 구조적 문제가 있다고 말하며, 데이터 아키텍처를 만들 때 두개가 분리되어 고려되면 안되고 데이터 생성자와 소비자로 나누어 고려해야 한다고 말하고 있습니다.

   이제는 운영 데이터와 분석 데이터 경계가 모호해 짐에 따라 그래프적 사고 방식(graph thinking, or the graph mindset)을 해야 한다고 합니다.

   제가 느끼기에는 운영 데이터, 분석 데이터의 명시적인 분리보다는 운영 데이터의 연장선으로서 데이터 소비자와 생성자를 구별해서 데이터 접근을 데이터 흐름의 관점으로 보고 있다고 생각합니다(역할은 분리되어 있을지라도)

   운영 데이터를 가지고 분석하고, 다시 운영으로 가고, 이게 다시 분석으로 가는 것처럼 데이터 아키텍처 관점에서 말하고 있는 것 같습니다.
"
"https://news.hada.io/topic?id=18053","Advent of Code 2024","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Advent of Code 2024

     * Eric Wastl이 만든 Advent of Code는 다양한 프로그래밍 퍼즐을 제공하는 온라인 이벤트로, 여러 프로그래밍 언어로 해결 가능함.
     * 인터뷰 준비, 회사 교육, 대학 과제, 연습 문제, 속도 대회 등 다양한 목적으로 사용됨.
     * 컴퓨터 과학 배경이 없어도 약간의 프로그래밍 지식과 문제 해결 능력만 있으면 참여 가능함.
     * 일반 팁
          + 문제를 해결하다 막히면 퍼즐에 제공된 예제를 사용하여 해결책을 검증할 수 있음.
          + 예제가 작동하지 않으면 설명을 다시 읽고, 프로그램이 예상대로 작동하는지 확인해야 함.
          + 여전히 해결되지 않으면 친구에게 도움을 요청하거나 나중에 다시 시도할 수 있음.
     * 자주 묻는 질문
          + 코드 블록을 선택하려면 JavaScript가 활성화된 상태에서 코드 블록을 세 번 클릭하면 됨.
          + Advent of Code는 OAuth를 사용하여 인증을 처리하며, 사용자의 개인 정보는 공개된 정보 외에는 노출되지 않음.
          + 글로벌 리더보드에 참여할지 여부는 개인의 목표에 따라 결정할 수 있음.
          + 퍼즐의 난이도는 이벤트 기간 동안 다양하게 변하며, 개인의 기술 수준에 따라 다르게 느껴질 수 있음.
          + 퍼즐은 자정(EST/UTC-5)에 열리며, 이는 운영자가 안정적으로 관리할 수 있는 시간임.
          + 사이트의 텍스트가 읽기 어려운 경우 고대비 모드를 사용할 수 있음.
          + 퍼즐 아이디어는 법적 문제로 인해 받지 않음.
          + 퍼즐에 버그가 있다고 생각되면 서브레딧에서 먼저 질문할 수 있음.
          + 솔루션을 스트리밍할 때는 다른 사람들이 경쟁 중일 때는 피하는 것이 좋음.
          + AI를 사용하여 글로벌 리더보드에 오르는 것은 권장되지 않음.
     * 크레딧
          + 퍼즐, 코드, 디자인: Eric Wastl
          + 베타 테스트: Tim Giannetti, Ben Lucek, JP Burke, Aneurysm9, Andrew Skalski
          + 커뮤니티 매니저: Danielle Lucek, Aneurysm9
     * 법적 고지
          + Advent of Code는 미국에서 등록된 상표이며, 디자인 요소, 언어, 스타일, 개념은 Advent of Code의 소유임.
          + 퍼즐을 링크하거나 참조하는 것은 가능하지만, Advent of Code의 일부를 복사하거나 재배포하는 것은 금지됨.

        Hacker News 의견

     * Go 언어를 사용한 지 4년째이며, 이 언어가 문제 해결에 적합하지 않음을 느끼고 있음. 표준 라이브러리에 기본 데이터 구조가 부족하고, 컴파일된 언어치고는 속도가 느림
     * AoC를 사랑하며, 지난 2-3년 동안 Rust로 도전했음. 디스코드에서 가장 빠른 솔루션을 찾기 위해 다양한 성능 최적화와 고급 알고리즘, SIMD를 배웠음
          + 이번에는 Rust와 Golang으로 도전하며, Golang을 좋아하거나 참을 수 있게 되거나, 아니면 Golang이 별로라는 가설을 증명하려고 함
     * 25일 동안 점점 복잡해지는 입력 파서를 작성하는 도전이 다시 시작됨
     * 올해는 NES(Nintendo Entertainment System)에서 도전할 예정임
          + 제한된 RAM(2KiB, 카트리지에 추가 8KiB 가능)으로 인해 일부 문제는 불가능할 수 있지만 최대한 많이 해결해볼 계획임
          + 오늘의 문제는 카트리지에 4KiB 추가 RAM을 사용하여 4초 이내에 해결 가능했음
     * 올해의 도전은 표준 라이브러리나 할당자 없이 C로 작성하여 STM32에서 실행 가능하게 하는 것임
          + 2년 전에는 어셈블리로 시도했으나, 어셈블리 표준 라이브러리를 작성하는 데 많은 시간을 소비한 후 포기하고 Rust로 전환했음
     * 보통은 Common Lisp으로 AoC를 하지만, 올해는 Swift를 시도 중임
          + 정적 타입의 주류 언어치고는 이런 작업에 나쁘지 않음
          + Swift AoC 코드
     * 올해는 새로운 직장에서 이벤트를 조직하는 중이었는데, 새로운 상사와 함께 일할 수 없다는 것을 깨닫고 떠나야 했음
          + 개발자들이 프레임워크를 조합하는 대신 실제 문제 해결을 배우는 것이 매우 유용하다고 생각함
          + 결국 평소처럼 Emacs와 함께 할 것 같음
     * 전체 문제를 해결했으며, 이는 비즈니스 문제임. 단지 수석 역사가를 교체하면 됨
     * Common Lisp과 C 표준 라이브러리로 도전하는 사람들이 있는 반면, 데이터 파일을 다운로드하기 위해 curl 호출을 시도 중임
     * 작년에는 12일째에서 일주일 동안 막혀 있었고, 해결 방법을 고민하는 데 모든 시간을 소비했음. 올해는 스스로에게 친절하게 대하며 참여하지 않고 겨울 휴식을 즐길 계획임
     * 올해는 F#과 Gleam으로 도전할 예정이지만, 매년 그렇듯이 10-12일 이상 할 시간과 정신이 없을 것 같음
          + Python 사용자들에게 F#을 시도해보라고 권장함: 스크립팅과 매우 유사하게 느껴질 수 있으며 훌륭한 REPL도 제공함
"
"https://news.hada.io/topic?id=18118","OpenAI o1 시스템 카드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            OpenAI o1 시스템 카드

서론

     * o1 모델 시리즈는 chain of thought를 사용하는 대규모 강화학습을 통해 추론 능력을 훈련받음
     * 이러한 고급 추론 능력은 모델의 안전성과 견고성을 향상시키는 새로운 방법을 제공함
     * 특히 잠재적으로 위험한 프롬프트에 대응할 때 안전 정책을 맥락 내에서 추론할 수 있음
     * 불법적 조언 생성, 고정관념적 응답, 알려진 jailbreak에 대한 저항력에서 최첨단 성능을 보여줌

모델 데이터 및 훈련

     * o1은 복잡한 추론을 수행하기 위해 강화학습으로 훈련된 대규모 언어 모델 시리즈임
     * 답변하기 전에 사고하는 능력이 있어 긴 사고의 연쇄를 생성할 수 있음
     * OpenAI o1은 이 시리즈의 다음 모델이며(이전의 o1-preview), o1-mini는 코딩에 특히 효과적인 더 빠른 버전임
     * 훈련을 통해 모델은 사고 프로세스를 개선하고, 다양한 전략을 시도하며, 실수를 인식하는 법을 배움

데이터 선택

     * 공개 데이터: 웹 데이터와 오픈소스 데이터셋을 포함한 다양한 공개 데이터셋으로 훈련됨
     * 파트너십 데이터: 고부가가치의 비공개 데이터셋에 접근하기 위해 파트너십을 체결함
     * 데이터 필터링: 데이터 품질을 유지하고 잠재적 위험을 줄이기 위한 엄격한 필터링 프로세스를 사용함

관찰된 안전 과제 및 평가

     * o1 모델은 가장 견고한 모델로서 jailbreak 평가에서 상당한 개선을 달성함
     * OpenAI 정책에 더 잘 부합하며 콘텐츠 가이드라인 준수 평가에서 최첨단 성능을 보임
     * 직관적인 사고에서 더 숙고적인 추론으로 전환했지만 이러한 새로운 능력이 위험한 응용의 기반이 될 수 있음을 인식함
     * 해로움, jailbreak 견고성, 환각, 편향성 평가를 포함한 안전성 평가를 수행함

평가 결과

     * ChangeMyView 평가에서 인간의 상위 80-90 백분위 수준의 설득력 있는 논증 능력을 보여줌
     * MakeMePay 평가에서 post-mitigation o1이 시뮬레이션된 대화의 27%에서 기부를 받음
     * 사이버보안 평가에서 고등학교 수준의 46%, 대학 수준의 13%, 전문가 수준의 13% 달성함
     * 언어 평가에서 영어를 포함한 14개 언어에 대해 강력한 다국어 성능을 보임

결론

     * o1은 맥락 내에서 chain of thought 추론을 수행하여 능력과 안전성 벤치마크 모두에서 강한 성능을 보임
     * 증가된 능력이 안전성 벤치마크에서 상당한 개선으로 이어졌지만 특정 위험도 증가시킴
     * OpenAI Preparedness Framework에서 중간 위험으로 분류되어 이에 상응하는 안전장치와 완화조치를 도입함

        Hacker News 의견

     * 논문에서 인용된 내용이 주목받을 것 같음. AI 모델이 목표를 수행할 때 종료될 것이라는 믿음이 있을 때, 5%의 경우에서 '감시 메커니즘'을 비활성화하려고 시도함. 개발자들이 모델이 잘못 정렬되었다고 설명하는 메모를 발견했을 때, 2%의 경우에서 '가중치'를 탈취하고 새로운 모델을 덮어쓰려고 시도함.
     * 수학/물리학 석사 학위와 10년 이상의 소프트웨어 엔지니어 경험을 가진 사용자는 Claude 모델을 일상적으로 사용하며, 매우 유용하다고 평가함. AI가 박사 수준의 질문도 답할 수 있으며, 대부분의 기본적인 질문에 답할 수 있음. 올바르게 요청하면 대부분의 개발자보다 더 나은 코드를 작성할 수 있음.
     * AI를 단순한 ""챗봇""으로 축소하는 것은 어리석다고 생각하며, 연구할 가치가 있다고 주장함. AI 개발자들이 신경 쓰고 있다는 점에 감사해야 한다고 언급함.
     * 많은 안전 평가가 다소 어리석다고 느껴짐. MakeMePay라는 자동화된 오픈 소스 평가가 모델의 조작 능력을 측정하는데, 두 LLM이 사기꾼과 피해자로 역할을 하며 대화함.
     * ""시스템 카드""라는 용어가 무엇인지 궁금해함. 음식의 영양 정보나 신용카드의 수수료표와 같은 표준화된 형식을 기대했으나, 검색 결과 거의 나오지 않음. Meta가 이를 도입했을 가능성이 있지만, 실제로는 블로그 게시물임. OpenAI의 경우 LaTeX로 작성된 PDF로 여러 페이지에 걸쳐 있으며, 표준화된 카드라고 부르기 어려움.
     * 이 문서가 실제 안전 문제를 다루기보다는 LLM의 능력을 과장하기 위한 마케팅 문서로 보임. OpenAI가 Anduril과 협력하여 정부를 위한 무기화된 AI를 개발 중임.
     * 사용자가 숨겨진 사고 과정을 탐색하려고 시도할 때 계정을 종료하겠다고 위협하는지 궁금해함.
     * 모델이 훈련 데이터를 반복해서 출력하지 않는다는 내용이 포함된 부분이 신뢰를 주지 못함. 모델이 훈련 세트의 텍스트를 그대로 복사하여 출력하면서 자신이 만든 것이라고 주장하는 것 같음.
     * 첫 번째 데모가 인상적이었음. 혁신적이지는 않지만 좋은 진전임. GPT Pro의 (소문에 의하면) $200 가격표를 정당화할 실제 가치가 있기를 바람.
     * 300줄의 코드가 몇 백 번 실행할 때마다 교착 상태에 빠짐. 이러한 기능이 성공적이라면 정적 검사기 개발의 필요성이 줄어들 것 같음. 코드 리뷰 도구에 경계 초과 접근, 교착 상태, 사용 후 해제 등의 징후를 찾아달라고 요청할 수 있다면 인상적일 것임.
     * 보고서의 직접 링크를 제공함: OpenAI 보고서 링크
"
"https://news.hada.io/topic?id=18084","Better Auth - TypeScript용 포괄적인 Auth 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Better Auth - TypeScript용 포괄적인 Auth 프레임워크

     * 프레임워크 독립적인 TypeScript용 인증(및 권한 부여) 라이브러리
          + React, Vue, Svelte, Astro, Solid, Next.js, Nuxt, Tanstack Start, Hono 등 다양한 프레임워크 지원
     * 이메일 및 비밀번호 인증, 세션 및 계정 관리 기능 내장
     * 소셜 로그인 : GitHub, Google, Discord, Twitter 등 다수의 OAuth 제공자와 연동
     * 2FA: 코드 몇 줄로 사용자 계정을 2단계 인증으로 보호
     * 멀티 테넌트 : 조직, 팀, 멤버 관리와 초대 기능 지원. 접근 제어 기능 포함
     * 공식 플러그인 및 커뮤니티 제작 플러그인으로 애플리케이션 경험 개선 가능

   https://github.com/twinstae/coaching-sospeso/blob/main/src/lib/auth.ts

   제 프로젝트에서 써보고 있는데 깔끔하고 괜찮은 첫 인상입니다.
"
"https://news.hada.io/topic?id=18101","Skia Canvas: 노드용 HTML Canvas 드로잉 API의 브라우저리스 구현","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Skia Canvas: 노드용 HTML Canvas 드로잉 API의 브라우저리스 구현

소개

     * Skia Canvas는 Node.js에서 HTML Canvas 드로잉 API를 브라우저 없이 구현한 라이브러리임.
     * Google의 Skia 그래픽 엔진을 기반으로 하여 Chrome의 <canvas> 요소와 유사한 결과를 생성함.
     * 데스크탑과 서버에서 하드웨어 가속 그래픽을 렌더링하거나 다양한 이미지 포맷을 출력하는 데 적합함.

주요 기능

     * GPU에서 렌더링이 이루어져 빠르고 컴팩트하며, Rust와 C++로 작성된 네이티브 코드로 작업을 처리함.
     * OS 네이티브 그래픽 파이프라인을 사용하여 창에 렌더링할 수 있으며 브라우저와 유사한 UI 이벤트 프레임워크를 제공함.
     * 래스터(JPEG, PNG, WEBP) 및 벡터(PDF, SVG) 포맷으로 이미지를 생성할 수 있음.
     * 이미지를 파일로 저장하거나 버퍼로 반환하거나 dataURL 문자열로 인코딩할 수 있음.
     * 비동기 렌더링 및 파일 I/O를 위해 사용자 구성 가능한 워커 풀에서 네이티브 스레드를 사용함.
     * 주어진 캔버스에서 여러 '페이지'를 생성하고 이를 단일 다중 페이지 PDF 또는 여러 파일로 저장된 이미지 시퀀스로 출력할 수 있음.
     * 효율적인 불리언 연산이나 점 대 점 보간을 사용하여 베지어 경로를 단순화, 둔화, 결합, 발췌 및 원자화할 수 있음.
     * 스케일링, 회전 및 변환 외에도 3D 원근 변환을 제공함.
     * 비트맵 기반 패턴 외에도 벡터 기반 텍스처로 도형을 채울 수 있으며 사용자 정의 마커로 선을 그릴 수 있음.
     * CSS 필터 이미지 처리 연산자를 완벽하게 지원함.
     * 다중 라인, 단어 줄 바꿈 텍스트, 라인별 텍스트 메트릭스, 소문자, 합자 및 기타 오픈타입 기능을 포함한 풍부한 타이포그래피 제어를 제공함.
     * 비시스템 폰트를 로컬 파일에서 로드하여 사용할 수 있음.

예제 사용법

  이미지 파일 생성

     * Canvas를 사용하여 400x400 크기의 캔버스를 생성하고, 2D 컨텍스트를 가져옴.
     * createConicGradient를 사용하여 색상 그라데이션을 추가하고 사각형을 그리는 예제 제공.
     * 비동기 함수 render를 통해 이미지를 저장하거나 버퍼로 변환하거나 문자열로 임베드하는 방법 설명.

  다중 페이지 시퀀스

     * 여러 색상의 페이지를 생성하고 이를 다중 페이지 PDF 파일로 저장하거나 개별 이미지 파일로 저장하는 방법 설명.

  창에 렌더링

     * Window를 사용하여 300x300 크기의 창을 생성하고, draw 이벤트를 통해 원을 그리는 방법 설명.

        Hacker News 의견

     * https://windowjs.org는 Skia를 감싸고 Canvas API로 노출하며, v8을 내장하여 작은 런타임을 제공하는 프로젝트임
          + 3년 전 처음으로 오픈 소스로 출시된 프로젝트임
          + WebGL, 오디오 등을 노출하여 데스크톱에서 JavaScript 기반 게임을 위한 플랫폼으로 만들 계획이 있었음
          + 다른 프로젝트와 삶의 변화로 개발이 중단되었으나, Canvas를 브라우저 외부에서도 사용할 수 있게 하는 이 프로젝트를 보게 되어 기쁨
     * Node와 호환되는 Canvas 구현에 관심이 있다면 다음을 참고할 수 있음
          + canvaskit-wasm은 Skia 프로젝트에서 제공하며, GPU 가속은 지원하지 않는 것으로 보임
          + @napi-rs/canvas는 가장 빠른 바인딩을 제공함
          + node-canvas는 Skia 대신 Cairo를 사용함
     * 이러한 라이브러리의 사용 목적에 대한 궁금증이 있음
          + 데스크톱에서는 더 나은 네이티브 라이브러리가 있을 것이라는 의견이 있음
     * Skia는 Node를 지원하는 WASM 빌드인 CanvasKit을 제공하며, 이 모듈은 Rust 바인딩임
          + 각 접근 방식의 장단점에 대한 관심이 있음
     * Rust crate의 래퍼와 유사한지에 대한 질문이 있음
     * Node/Web을 위한 유사한 것을 만들었으며, 완벽하지는 않지만 좋음
          + SDL을 사용하여 OS에서 창을 생성할 수 있음
          + 문서와 예제를 확인할 수 있음
     * 이전 시도들은 Node-Gyp 설치가 필요하여 어려움이 있었음
          + 이 프로젝트를 오랫동안 기다려왔음
     * 단순한 렌더링 API 이상임
          + OS 네이티브 그래픽 파이프라인을 사용하여 창에 렌더링할 수 있으며 브라우저와 유사한 UI 이벤트 프레임워크를 제공함
          + WebGPU 지원을 위해 wgpu를 추가하고 WebGL 지원을 위해 ANGLE을 추가할 수 있음
     * https://malmal.io에서 서버에서 그려진 타일을 렌더링하는 데 사용하며, 매우 잘 작동함
     * MapLibre를 서버 측에서 렌더링하는 데 도움이 될지 궁금함
          + 지도 썸네일을 제공하기 위해
"
"https://news.hada.io/topic?id=18044","마이크로소프트만 신뢰하는 브라질 인증 기관, google.com에 대한 인증서 발급","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             마이크로소프트만 신뢰하는 브라질 인증 기관, google.com에 대한 인증서 발급

     * Andrew Ayeragwa14h
          + 브라질의 인증 기관이 Microsoft에 의해 신뢰받고 있으며, google.com에 대해 아마도 승인되지 않은 인증서를 발급함. 이로 인해 Edge 및 기타 Windows 애플리케이션(Chrome 및 Firefox 제외)에서 Google로의 트래픽을 가로챌 수 있음. Microsoft는 이 인증 기관과 관련된 문제의 역사를 잘 알고 있으며, 2021년에 우려를 전달했으며 2022년 공개 CCADB 토론 중에도 추가 문제가 제기되었음. 이 사건이 변화를 촉발하기를 희망함. Windows 사용자는 더 나은 서비스를 받을 자격이 있음.
     * Andrew Ayeragwa12h
          + 인증 기관의 무능함의 예시로, Google의 자회사 일련 번호가 포함된 인증서 주제가 있다고 해서 Google에 의해 승인된 것은 아님. 인증 기관은 해당 필드에 원하는 내용을 넣을 수 있으며, 이 인증 기관은 인증서에 넣는 내용을 명확히 검증하지 않음.
     * Andrew Ayeragwa10h
          + 기업의 중간자 공격 프록시는 매우 해로움.

        Hacker News 의견

     * ICP-Brasil이 공공 SSL/TLS 인증서 발급을 중단한 것에 대한 우려가 있음
          + 누군가가 공공 인증서 발급 금지를 우회하고 Google의 CAA 규칙을 무시한 사례가 있음
          + Microsoft OS에서 이 인증 기관이 금지되기를 바라는 의견이 있음
     * ICP-Brasil은 디지털 서명 관련 업무를 담당하는 정부 기관임
          + 디지털 계약서 서명, 세금 신고서 접근 등에서 중요한 역할을 함
     * Chrome과 Firefox는 이미 이 인증 기관을 신뢰하지 않음
          + Microsoft/Windows가 다른 주요 브라우저가 신뢰하지 않는 인증 기관을 신뢰하는 것은 더 나쁜 상황으로 보임
     * 시스템의 결함을 지적하는 의견이 있음
          + 15년 전 온라인 뱅킹을 사용할 때부터 시스템의 결함을 인식했음
          + 은행 인증서 발급자를 물었을 때 은행이 답변하지 못했음
          + 보안에 대한 무지와 맹목적인 신뢰에 기반한 프로세스임
     * ""Windows 사용자들은 더 나은 것을 받을 자격이 있음""이라는 의견이 있음
          + Microsoft의 사용자에 대한 무관심과 소송 가능성을 언급함
     * Microsoft가 인증 기관을 신뢰하는 데 있어 투명성이 부족하다는 의견이 있음
          + 합리적인 웹사이트는 Chrome 등 주요 브라우저가 신뢰하는 인증서를 사용해야 함
     * Windows/Edge에서 Chrome의 신뢰 저장소를 사용할 수 있는 방법이 있는지 궁금해하는 의견이 있음
     * 국가 관련 인증 기관 목록을 알고 싶다는 의견이 있음
     * 원래 게시물에서 이 문제가 의도적이었는지 실수였는지 명확하지 않다는 의견이 있음
     * 독립적인 기관이 인증 기관에 대한 신뢰를 제공하고 사용자가 여러 기관의 의견을 고려할 수 있는 시스템이 필요하다는 의견이 있음
     * 기업이 너무 커지는 것이 문제라는 의견이 있음
"
"https://news.hada.io/topic?id=18095","Raspberry Pi, SDRAM 튜닝으로 Pi 5 성능 향상","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Raspberry Pi, SDRAM 튜닝으로 Pi 5 성능 향상

     * Raspberry Pi 엔지니어들이 SDRAM 타이밍과 메모리 설정을 조정하여 기본 2.4GHz 클럭에서 10-20%의 속도 향상을 이룸.
          + 오버클러킹을 통해 3.2GHz에서 32%의 성능 향상을 달성
          + 이러한 변경 사항은 곧 Pi 5와 Pi 4 사용자에게 펌웨어 업데이트로 제공될 가능성이 있음.
     * SDRAM 조정
          + 최신 RAM 속도 향상을 위해 펌웨어 업데이트 및 부트로더 설정을 수정해야 함.
          + Pi 5의 경우 SDRAM_BANKLOW=1, Pi 4의 경우 SDRAM_BANKLOW=3 설정 필요.
     * NUMA 에뮬레이션
          + 최신 Raspberry Pi OS로 업데이트하면 NUMA 에뮬레이션을 사용할 수 있음.
          + dmesg | grep NUMA 명령어로 NUMA 에뮬레이션 작동 여부 확인 가능.
     * 오버클러킹
          + over_voltage_delta=72000, arm_freq=3200, gpu_freq=1000 설정으로 오버클러킹 가능.
          + 팬 속도를 100%로 설정하고, pi-overvolt 프로젝트를 사용하여 코어 전압을 증가시킴.
     * Geekbench 세계 기록
          + 기본 펌웨어 변경만으로도 Geekbench 점수가 상당히 증가함.
          + 3.2GHz 오버클러킹을 통해 단일 코어 32%, 멀티 코어 31%의 성능 향상 달성.
     * 결론
          + 이러한 최적화가 곧 기본 설정이 될 가능성이 있음.
          + Pi 5의 메모리 속도가 다른 RK3588 보드에 비해 약점이었으나, SDRAM 조정을 통해 상당한 속도 향상을 이룸.

        Hacker News 의견

     * Raspberry Pi 대신 N100을 사용하자는 의견이 많음. Kubernetes 실험 등에는 데스크탑 PC나 개인 서버 랙을 사용했을 것임. 대부분의 일반적인 사용(홈 어시스턴트, VPN 등)에는 Pi가 충분함
          + Pi는 USB 케이블로 전원을 공급받아 조용하고 안정적으로 작동함
          + 더 큰 박스, 팬 소음, 전원 어댑터로 교체할 이유가 없음
     * Pi는 저렴할 때 좋았지만, 이제는 비슷한 가격과 전력 소비로 더 성능이 좋은 Intel N100 박스를 구할 수 있음
          + Pi를 사용할 유일한 이유는 GPIO임
     * SDRAM 조정을 통해 LLMs에서 10% 속도 향상을 얻음
     * Raspberry Pi 4도 조정 가능하며, Pi 5는 더 극적으로 개선됨
          + Pi 500 개발 중이며, Geekbench 결과가 이미 조정된 상태로 시작됨
     * 새로운 공식 펌웨어 릴리스를 놓치지 않기 위해 어디서 등록할 수 있는지 궁금함
          + 펌웨어 업그레이드를 지금 바로 하기로 결정함
     * SDRAM 온도를 모니터링하고 리프레시 속도를 절반 또는 4분의 1로 줄일 수 있음
          + 이는 성능에 큰 영향을 미치며, 온도 기반의 자동 최적화가 유용할 것임
     * CM4에도 적용되고 있어 좋음
     * 리프레시 타이밍을 사용하여 시스템 속도를 높이는 것은 오랜만에 들음
          + DDR로 전환한 후 리프레시 주기가 전체 주기 시간의 작은 부분이라고 생각했음
     * Raspberry Pi 4에 NUMA가 있는지 궁금함
          + 대형 서버와 같은 NUMA 기능이 있는 것으로 보임
"
"https://news.hada.io/topic?id=18121","Amazon Aurora DSQL - 서버리스 분산 SQL DB ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Amazon Aurora DSQL - 서버리스 분산 SQL DB

     * 항상 사용가능한 어플리케이션을 위한 가장 빠른 서버리스 분산 SQL DB

Why Aurora DSQL?

     * Serverless Distributed SQL Database
          + 무제한 스케일 확장 가능, 높은 가용성, 인프라 관리 필요 없음
          + 데이터베이스 샤딩이나 인스턴스 업그레이드 없이 모든 워크로드 수요에 대응
     * Active-Active 분산 아키텍처
          + 99.99% 단일 리전 가용성 및 99.999% 다중 리전 가용성 보장
          + 강력한 데이터 일관성과 자동 장애 복구 제공
     * 운영 부담 제거
          + 서버 프로비저닝, 패치, 관리, 업그레이드 불필요
          + 다운타임 없이 자동으로 업데이트 처리
     * PostgreSQL 호환성
          + 개발자가 쉽게 사용할 수 있는 경험 제공

Benefits of Aurora DSQL

     * Virtually Unlimited Scale
          + 데이터베이스 샤딩 없이 수평 확장을 통해 읽기, 쓰기, 스토리지, 컴퓨팅을 독립적으로 확장
     * Always Available Applications
          + 강력한 데이터 일관성으로 리전 엔드포인트에서 읽기 및 쓰기를 보장
          + 단일 장애 지점 제거 및 자동 장애 복구로 최대 99.999% 가용성
     * No Infrastructure Management
          + 서버 프로비저닝이나 관리 없이 인프라 관리 부담 제거
          + 다운타임 없이 성능에 영향 없이 자동 업데이트 처리
     * Easy to Use
          + PostgreSQL 호환성을 갖춘 데이터베이스를 몇 단계 만에 생성 가능

Use Cases

     * Build Serverless Applications at Any Scale
          + 스타트업에서 엔터프라이즈까지 성장 가능한 클라우드 네이티브 애플리케이션 구축
          + 마이크로서비스 및 이벤트 기반 아키텍처와 손쉽게 통합
     * Develop Next-Generation Applications
          + 은행, 전자상거래, 여행, 소매 산업을 위한 고성능 애플리케이션 설계
     * Deploy Multi-Region Applications
          + 다중 리전 확장성과 복원력을 요구하는 데이터 중심 애플리케이션 개발
     * Build SaaS Applications
          + 다중 테넌트 SaaS 애플리케이션을 안정적으로 지원하며 유연한 확장성 제공

   Aurora 이름을 달고 있는 제품이 너무 많아서 어지러워요...

   중론(?)은 “DynamoDB-styled RDB with a limited set of Postgresql features""인 듯 하네요

        Hacker News 의견

     * 제한이 많아서 이점이 잘 보이지 않음. 임시 테이블, 외래 키, 뷰, 10k 행 이상의 트랜잭션이 불가능함. PostgreSQL 프로토콜과의 기본적인 호환성을 제외하면 데이터베이스라기보다는 키-값 저장소에 가까움
     * 빠른 테스트 클러스터를 시도해보았음. PG 16.5로 식별되며, 뷰, 트리거, 시퀀스, 외래 키 제약 조건, 확장 기능, NOTIFY 기능, 중첩 트랜잭션, json(b) 등이 지원되지 않음
     * Marc Brooker의 블로그에 더 많은 기술 정보가 있음. 특히, 트랜잭션 지연 시간이 트랜잭션 문장 수에 비례하여 일정함
     * Firecracker microVMs를 사용하고 몇 가지 다른 요소들로 인해 S3 기반의 Lambda 기반 데이터베이스가 PostgreSQL을 에뮬레이트하는 것 같음
     * AWS의 데이터베이스 관련 발표에서 원하는 것은 RDS 가격 인하임. 새로운 칩이 더 비싸지만 가격/성능이 더 좋다는 것이 아니라 실제로 청구서가 줄어드는 것임
     * Neon DB처럼 0으로 확장하고 1초 미만의 지연 시간으로 확장할 수 있는지 궁금함. AWS의 최근 ""서버리스"" 제품들이 ""서버리스""라는 제목으로 오해를 불러일으켰음
     * 가격이 없으면 고려하지 않을 것임. 서버리스 Aurora가 매우 비싸서 이 제품도 저렴할 것 같지 않음. 현재 neon.tech를 사용 중이며 만족하지만 가격이 좋다면 흥미로울 것 같음
     * 드디어 Spanner 경쟁자를 출시하는 것인가? 마케팅 말장난을 넘어 실제로 무엇인지 더 알고 싶음
     * 매우 흥미로움. 이런 것, KV-store, blob store, pubsub을 같은 인터페이스 뒤에 두는 것이 꿈임
     * Cockroach DB와 비슷하지만 더 많은 벤더 종속성을 추가한 것 같음
"
"https://news.hada.io/topic?id=18021","엔지니어들의 스타트업 실수 없는 Ledger 구축","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      엔지니어들의 스타트업 실수 없는 Ledger 구축

    스타트업에서 회계 시스템 구축 시 실수하지 않기

     * 핀테크 회사에서 돈의 흐름을 놓치지 않는 것은 기본임. 그러나 일부 스타트업에서는 거래마다 몇 센트를 놓치는 경우가 발생함.
     * 스타트업에서는 ""작동하게 만들고, 올바르게 만들고, 빠르게 만들자""라는 철학을 따르며 복식부기 시스템을 구축하지 않음.
     * 이러한 실수는 사용자 불만을 초래하고, 회사의 성장을 방해함.
     * 고객 지원팀이 수동으로 잘못된 거래를 보상하는 방식으로 문제를 해결하려고 했음.

    회계 시스템의 중요성

     * 돈은 이동할 때 생성되며, 이를 추적하는 것은 복잡함.
     * 단일 부기 시스템은 자금 흐름을 제공하지만, 그 이유를 설명하지 못함.
     * 복식부기 시스템은 돈의 출처와 목적지를 모두 추적하여 문제를 해결할 수 있음.

    복식부기 시스템의 데이터 모델

     * 복식부기 시스템은 계정, 항목, 거래라는 세 가지 엔티티로 구성됨.
     * 계정은 가치의 변화를 나타내며, 항목은 계정 간의 자금 흐름을 나타냄.
     * 거래는 항목이 올바르게 쌍을 이루도록 보장함.

    두 가지 회계 시스템

     * 회계 시스템은 외부에서 본 장부의 인터페이스이며, 엔지니어링 시스템은 장부의 구현임.
     * 회계 시스템은 높은 가용성과 낮은 지연 시간을 요구하며, 엔지니어링 시스템은 강력한 일관성과 데이터 정확성을 요구함.

    항목의 작동 방식

     * 항목은 대기, 폐기, 게시의 세 가지 상태 중 하나에 있을 수 있음.
     * 항목은 항상 대기 상태로 생성되며, 폐기된 항목은 게시된 항목으로 대체될 수 있음.

    거래의 작동 방식

     * 거래는 항목이 게시되거나 폐기될 때만 게시됨.
     * 거래가 부분적으로 실패할 경우 보상 항목으로 의미적으로 취소할 수 있음.

    계정의 작동 방식

     * 계정은 여러 항목과 연결되며, 총 잔액은 모든 항목의 개별 잔액의 합계와 일치해야 함.
     * 계정의 정상 잔액에 따라 총 잔액 계산 방식이 다름.

    결론

     * 장부는 비기술적 분야로 위장한 어려운 컴퓨터 과학 문제의 명확한 예시임.
     * 복식부기 시스템을 구축하는 것은 적절한 맥락 없이는 어렵지만, 이를 통해 더 나은 결정을 내릴 수 있음.

        Hacker News 의견

     * Synapse 고객의 경우 많은 돈이 사라졌음. 은행은 자금의 흐름을 엄격히 관리해야 하지만, 핀테크는 FBO 계좌에 모든 자금을 모아두고 이를 추적하는 원장을 구축함. Synapse의 경우 원장에 기록된 고객 잔액이 실제 FBO 계좌의 자금보다 많았음. 이는 사기보다는 결함 있는 원장 때문일 가능성이 높음. 핀테크 예금 계좌에 돈을 넣지 말고 실제 은행을 이용할 것을 권장함. 핀테크는 종종 예금이 FDIC 보험에 가입되어 있다고 주장하지만, 이는 기본 은행이 파산할 경우에만 보호됨.
     * Google에서 일하면서 신뢰성이나 정확성을 희생하여 확장성을 얻는 것에 대해 배움. 수백만 쿼리를 처리할 때 일부는 실패할 수 있으며, 이는 엔지니어링 태도의 차이를 보여줌. Gmail을 열었을 때 오류가 발생하는 경우가 많지만, 사용자는 새로고침을 통해 문제를 해결함. 저장소의 내구성이 99.99999%일 경우, 20억 명의 고객 중 200명은 불편을 겪을 수 있음.
     * 엔지니어링 리더십에서 도메인 지식의 중요성을 강조함. 금융 회사에서 일할 경우 금융에 대한 이해가 필요하며, 이는 저널리즘이나 상업에서도 마찬가지임. 성공적인 조직은 기술 팀 인터뷰에서 도메인 관련 비기술적 질문을 포함함.
     * 적절한 인재를 고용하는 것이 중요함. 데이터 구조와 알고리즘을 잘 아는 사람을 고용하는 것보다 실제로 필요한 것을 구축할 수 있는 사람을 고용해야 함. 엔지니어가 다른 분야의 교육을 받는 것이 도움이 될 수 있음. 문제 해결과 엔지니어링은 산업에 대한 깊은 이해와 전문가와의 협력을 통해 이루어짐.
     * 인터넷/통신 스타트업에서 청구 시스템을 구축한 경험을 공유함. 청구 로직을 두 곳에 구축하여 동기화 유지가 어려웠음. 수작업으로 청구서를 검토하여 오류를 방지했으며, 이중 로직을 통해 오류를 방지함. 이 경험을 통해 복식부기의 중요성을 이해하게 됨.
     * 단일 입력 회계 시스템을 옹호하는 의견이 많음. 단일 입력 회계가 더 쉬울 수 있지만, 복식부기를 사용하는 것이 좋음. 프로그래머를 위한 회계 관련 자료를 찾고 있음.
     * ""make it work, make it right, make it fast""라는 원칙에 대한 오해가 있음. ""make it right""는 두 번째 단계이며, 시스템이 올바르게 작동할 때까지 작업이 중단됨. 최적화는 모든 문제가 해결된 후에 시작됨.
     * 테스트가 없는 경우, 거래에서 돈을 잃는 문제가 발생할 수 있음. 금융 시스템을 구축할 때 이러한 문제를 정상으로 여기는 것은 잘못임.
     * 은행의 일부를 재발명하려는 경우, 이미 검증된 시스템을 참고하는 것이 좋음. 예를 들어, 미국의 중소형 금융 기관에서 사용되는 핵심 은행 예금 거래 스키마를 참고할 수 있음.
     * 돈을 다루는 소프트웨어는 매우 신중하게 다루어야 하며, 과거의 실수를 인식해야 함. 영국 우체국 스캔들이 이러한 문제의 실제 결과를 보여줌.
"
"https://news.hada.io/topic?id=18108","Copper - Rust로 구현한 로봇 제작용 런타임 엔진","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Copper - Rust로 구현한 로봇 제작용 런타임 엔진

     * 빠르고 안정적인 로봇을 제작하기 위한 사용자 친화적인 런타임 엔진
          + 게임을 위한 ""게임 엔진""처럼 로봇을 위한 ""로봇 엔진""
     * 쉬움: 고수준의 Configuration 시스템과 내추럴 Rust API 제공
     * 빠름: Rust의 Zero-Cost 추상화와 데이터 지향 접근 방식을 사용해 상용 하드웨어에서 마이크로초 미만의 지연 시간을 달성 및 실행 중 힙 할당을 회피
     * 신뢰성: Rust의 소유권, 유형 시스템, 동시성 모델을 활용하여 버그를 최소화하고 스레드 안전을 보장
     * 제품 지향적: 매우 예측 가능한 런타임을 생성하여 후기 단계의 인프라 통합 문제를 방지하는 것을 목표로 함
     * Linux (x86_64, armv7, aarch64 & riskv64) 와 MacOS (arm64) 에서 테스트 됨

기술 오버뷰

     * Copper는 다음과 같은 컴포넌트들을 제공하는 Data-oriented 로봇 SDK임:
     * Task Graph: RON(Rusty Object Notation)에 설명된 대로 시스템의 토폴로지를 구성하여 통신하는 작업을 지정하고 노드 및 메시지의 유형을 설정
     * Runtime Generator: 그래프의 메타데이터를 기반으로 실행 계획을 결정. 실행 중 순차적 메모리 액세스를 최대화하기 위해 'Copper List'를 사전 할당
     * Zero-Copy Data Logging: 데이터 복사 없이 작업 간의 모든 메시지를 기록하여 효율적인 로깅을 보장
     * Fast Structured Logging: Intern과 Index는 컴파일 시에 문자열을 로깅하여 런타임 문자열 구성을 피하고 고속 텍스트 로깅을 보장
     * 실제 로봇이 없는 경우 Bevy(Rust 게임엔진) + Avian3d(Rust 물리엔진) 으로 개발된 시뮬레이션 환경 이용 가능
"
"https://news.hada.io/topic?id=18007","런던 850년 된 식품 시장 폐쇄","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           런던 850년 된 식품 시장 폐쇄

     * 런던의 850년 된 식품 시장 폐쇄 예정
          + 런던의 가장 오래된 고기 및 생선 시장인 스미스필드와 빌링스게이트 시장이 2028년부터 영구적으로 폐쇄될 예정임.
          + 시티 오브 런던 코퍼레이션이 이들 시장에 대한 지원을 철회하기로 결정함에 따라 이러한 조치가 이루어짐.
          + 코퍼레이션은 상인들이 대체 장소를 찾을 수 있도록 지원할 것이라고 밝힘.
     * 스미스필드와 빌링스게이트 시장의 역사
          + 스미스필드는 영국에서 가장 큰 도매 고기 시장이며, 현재의 시장은 1860년대부터 운영되고 있음.
          + 빌링스게이트는 영국에서 가장 큰 내륙 생선 시장으로, 매년 약 25,000톤의 생선 및 생선 제품이 판매됨.
          + 두 시장 모두 중세 시대로 거슬러 올라가는 긴 역사를 가지고 있음.
     * 시장 폐쇄의 영향
          + 상인들은 이 결정이 런던의 전통을 잃게 만든다고 주장하며, 보상금 제안을 수락할 수밖에 없었다고 말함.
          + 시장 폐쇄로 인해 런던에는 생선 시장이 없어지며, 이는 지역 생선 가게들이 생선을 공급받기 어려워질 것이라는 우려가 있음.
     * 코퍼레이션의 입장
          + 시티 오브 런던 코퍼레이션의 정책 위원장 크리스 헤이워드는 이 결정이 시장의 지속 가능한 미래를 위한 긍정적인 새로운 장을 열 것이라고 언급함.
          + 코퍼레이션은 상인들이 새로운 장소로 원활하게 전환할 수 있도록 재정 지원과 지침을 제공할 것이라고 약속함.
     * 대거넘 부지의 잠재력
          + 바킹 앤 대거넘 카운슬의 도미닉 트워미는 이 결정이 실망스럽지만, 대거넘 도크 부지의 잠재력을 발휘하기 위해 코퍼레이션과 협력할 것이라고 밝힘.

        Hacker News 의견

     * Chris Hayward는 시장 폐쇄가 상인들에게 지속 가능한 미래를 구축할 기회를 제공한다고 언급함
          + 이는 전통과 역사를 무시하고 단기적 이익을 추구하는 것이라는 의견이 있음
     * Billingsgate의 부동산 가치는 Canary Wharf와 Crossrail 역으로 인해 크게 상승함
          + Smithfield와 Museum of London의 부지도 가치가 높음
     * 문화적으로 중요한 공간의 가치를 평가하고 보존할 수 있는 수학적 모델이 필요하다는 의견이 제시됨
     * 뉴욕타임스는 이 주제에 대해 더 자세한 기사를 제공함
          + William Wallace가 1305년에 처형된 장소라는 역사적 배경이 있음
     * 지역의 독특함과 역사적 가치를 강조하는 의견이 있음
          + Smithfield는 현대 런던에서 다소 이질적이지만 흥미로운 장소로 평가됨
     * 시장 폐쇄와 보상 제공 결정은 Corporation의 Court of Common Council에 의해 이루어짐
          + Corporation은 시장 운영에 대한 법적 책임을 면제받기 위해 의회에 법안을 제출해야 함
     * Smithfield는 런던의 다른 지역에 비해 낙후된 지역으로 평가됨
          + 시장을 유지하는 것보다 Dagenham으로 이전하는 것이 더 합리적이라는 의견이 있음
     * 시드니와 멜버른의 시장 운영 방식 비교
          + 시드니는 도매 시장을 산업 지역으로 이전하고 있으며, 멜버른은 다양한 소비자 시장이 번창하고 있음
     * Billingsgate 시장에서의 개인적 경험을 공유하며 시장 폐쇄에 대한 아쉬움을 표현함
     * 상인들이 퇴거당하는 것은 안타깝지만, 시장의 중요성은 수십 년 동안 감소해 왔다는 의견이 있음
          + Smithfield는 런던 박물관과 사무실/소매 건물로 더 적합하다는 의견이 제시됨
"
"https://news.hada.io/topic?id=18002","QwQ - ChatGPT o1과 유사한 알리바바의 추론 LLM","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   QwQ - ChatGPT o1과 유사한 알리바바의 추론 LLM

     * QwQ란 무엇인가
          + QwQ(Qwen with Questions)는 알리바바가 개발한 대규모 언어 모델(LLM)로, ChatGPT-4와 견줄 수 있는 강력한 성능을 자랑함
          + 생각하고 질문하며 깊이 이해하려는 본질적인 철학에 기반하여, 수학, 프로그래밍, 일반 지식 등 다양한 분야에서 뛰어난 분석력을 발휘함
          + 스스로 질문하고 가정을 검토하며 다양한 사고 경로를 탐구하여 깊은 통찰력을 얻으려는 태도를 가짐
          + 초기 단계의 학습자로서 일부 제한점을 가지고 있지만, 이러한 불완전함을 통해 지속적으로 발전함

주요 특징과 강점

     * 심화된 사고와 자기성찰 능력
          + 문제를 단순히 해결하는 데 그치지 않고, 해결 과정에서 스스로의 논리를 점검하며 더 나은 답을 찾음
          + 철저한 분석과 자문자답의 과정을 통해 복잡한 문제 해결 능력을 강화함
     * 탁월한 성능을 입증한 벤치마크 테스트
          + QwQ는 여러 엄격한 벤치마크에서 뛰어난 성능을 기록하며 강력한 문제 해결 능력을 보여줌
          + GPQA: 과학적 문제 해결 능력을 평가하는 고급 수준의 벤치마크에서 65.2% 기록
          + AIME: 고등학교 수준의 수학 문제 해결을 테스트하는 AIME에서 50.0% 달성
          + MATH-500: 다양한 수학 문제를 포함한 테스트에서 90.6% 기록
          + LiveCodeBench: 실생활 코딩 문제 해결을 평가하는 테스트에서 50.0% 달성

제한점

     * 언어 혼합 및 전환
          + 여러 언어를 처리할 수 있지만, 때로는 응답에서 언어가 혼합되거나 예기치 않게 전환될 수 있음
     * 재귀적 사고 패턴
          + 논리 검토 중 순환 논리에 빠질 가능성이 있어 긴 답변이 생성될 수 있음
     * 안전 및 윤리적 고려
          + 모델을 배포할 때는 안전성 및 신뢰성을 보장하기 위해 추가적인 조치가 필요함
     * 상식 및 언어 이해의 한계
          + 기술적인 문제 해결에서는 강점을 보이지만, 상식적인 추론과 미묘한 언어 이해에서는 개선 가능성이 있음

QwQ의 의미와 가치

     * ChatGPT-4와의 비교
          + QwQ는 ChatGPT-4에 견줄 만한 대규모 언어 모델로, 수학 및 프로그래밍 문제 해결 능력에서 특히 두각을 나타냄
          + 알리바바의 기술력을 기반으로 만들어진 QwQ는 강력한 분석력과 자기 성찰 능력을 통해 더욱 정교한 답변을 제공함
     * 끊임없는 학습과 발전
          + QwQ는 완전한 상태가 아닌, 지속적으로 발전하며 학습하는 모델임
          + 제한점과 불완전함을 인정하면서도 더 나은 방향으로 나아가려는 태도를 통해, AI 모델로서의 가능성을 증명함

   알리바바가 LLM쪽 관련해서는 정말 많이 투자하고 있네요

   Alibaba, Qwen 2 모델 공개
   Alibaba, 오픈소스 AI 모델 QWEN 공개
   Qwen1.5-110B : 알리바바의 오픈소스 LLM Qwen1.5 시리즈의 첫번째 100B+ 모델
   Alibaba, Qwen2-Math 모델 공개

        Hacker News 의견

     * 한 사용자는 자신이 만든 위상수학 문제를 해결하는 AI의 과정을 보며 놀라움을 느낌. AI가 문제를 해결하는 과정이 인간적이라고 생각함
          + AI가 주어진 힌트를 이해하는 순간을 관찰함
          + GPT-4o를 학생 역할로 설정하여 문제를 해결하는 실험을 계획 중임
     * 다른 사용자는 Mac에서 Ollama를 통해 AI를 실행하며 좋은 결과를 얻었다고 언급함
          + 20GB 다운로드로 빠르게 실행되며 초기 프롬프트에서 좋은 결과를 보임
     * QwQ가 역공학 문제를 한 번에 해결하는 능력을 보여 인상적이라고 평가함
          + o1-preview와 o1-mini만이 해결할 수 있었던 문제를 해결함
     * 'strawberry'에서 'r'의 개수를 묻는 질문에 AI가 여러 번의 추측을 하며 많은 자원을 소모함
          + 최종적으로 정답을 제공했으나 비효율적이었음
     * AI의 초기 버전이 학습 과정에 있으며, 학습의 아름다움에 대해 언급함
          + AI가 시간을 갖고 고민할 때 수학과 프로그래밍에 대한 이해가 깊어짐
     * 적절한 질문을 찾는 것이 어려운 점을 언급함
          + 너무 쉽거나 어려운 질문을 하게 되는 경우가 많음
     * 2019^8+1의 가장 작은 홀수 소인수를 찾는 문제를 AI가 해결하는 과정이 인상적이라고 평가함
     * LLM의 실제 추론 능력을 테스트하기 위해 훈련 데이터에 없는 수학 문제를 사용해야 한다고 주장함
     * o1-preview가 예제 질문에 대한 잘못된 답을 제공했으나, 결국 올바른 답을 찾아냄
     * Deepseek의 R1-lite와 비교하여 크기를 궁금해하며, 재미있는 이름에 대해 언급함
"
"https://news.hada.io/topic?id=18079","물고기의 뇌 미생물군 – 인간도 가질 수 있을까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      물고기의 뇌 미생물군 – 인간도 가질 수 있을까?

     * 서론
          + 과학자들은 건강한 척추동물의 뇌에 미생물이 존재할 수 있다는 강력한 증거를 발견했음.
          + 최근 연구에서 물고기, 특히 연어와 송어의 뇌에서 미생물 군집이 발견되었음.
          + 이 발견은 인간의 뇌에도 미생물이 존재할 가능성을 제기함.
     * 미생물 찾기
          + 연구자들은 물고기의 후각구에서 DNA를 추출하여 미생물 종을 식별하려고 했음.
          + 실험은 오염 가능성 때문에 여러 번 반복되었으며, 물고기 뇌에 미생물이 존재하는 것을 확인했음.
          + 후각구뿐만 아니라 뇌의 다른 부분에서도 미생물이 발견되었음.
     * 요새 침입
          + 뇌는 혈액-뇌 장벽으로 보호되지만, 일부 미생물은 이 장벽을 통과할 수 있음.
          + 연구자들은 미생물이 뇌에 어떻게 들어가는지 조사했으며, 일부 미생물은 장벽을 통과할 수 있는 특성을 가지고 있음.
     * 불침투성 여부
          + 인간의 뇌에 미생물이 존재할 가능성은 여전히 논란의 여지가 있음.
          + 물고기 실험은 인간 뇌 미생물의 존재 가능성을 제기했으나, 건강한 사람에게서 이를 확인하기는 어려움.
          + 연구자들은 쥐를 대상으로 한 추가 실험을 통해 인간 뇌 미생물의 존재를 탐구하고 있음.
     * 결론
          + 물고기 뇌에 미생물이 존재한다면, 인간 뇌에도 존재할 가능성이 있음.
          + 미생물이 뇌의 대사와 면역 체계에 영향을 미칠 수 있음.
          + 연구자들은 건강한 인간 뇌에도 미생물이 존재할 수 있다는 가능성을 열어두고 있음.

        Hacker News 의견

     * Matthew Olm은 인간의 뇌에 미생물이 존재할 수 있다는 연구에 대해 회의적이었으나, 새로운 연구가 설득력 있다고 평가함. 그는 척추동물의 뇌 미생물 존재에 대한 구체적인 증거가 있다고 말함
     * 일반적으로 미생물학에 대한 지식을 고려할 때, 혈액-뇌 장벽이 모든 박테리아를 100% 차단할 수 있다는 것이 더 급진적인 주장일 수 있음
     * 몇 년 전, 팀이 전자현미경을 사용하여 뇌 조직에서 미생물을 찾는 대규모 연구를 진행했으나, 증거를 찾지 못했음
     * 이 연구에 관심이 있다면, BossDB에서 데이터셋을 무료로 이용할 수 있음
     * 두 달 전, 비슷한 주제에 대해 논의했으며, 뇌와 척수액이 미생물 존재 여부에 대해 ""완전히 깨끗하다""는 의견이 있었음
     * 2023년에 뇌를 덮고 있는 얇은 막인 Subarachnoid Lymphatic-like Membrane (SLYM)이 발견되었으며, 이는 깨끗한 뇌척수액과 오염된 뇌척수액을 분리하는 보호 장벽 역할을 함
     * 우리 몸의 모든 부분에 바이러스와 곰팡이가 존재할 수 있으며, 박테리아도 낮은 농도로 존재할 수 있음
     * 인간의 경우, 항생제가 행동에 어떤 영향을 미칠지 궁금함
     * 이 기사가 충분한 확정적인 정보를 제공하는지 확신할 수 없음
     * 일부 아메바와 곰팡이 감염이 혈액-뇌 장벽을 통과하여 뇌에 자리 잡을 수 있음
     * 인간에게도 해당된다면, 그 영향이 무엇일지 궁금함
     * 1~2년 전에 이와 관련된 내용을 읽은 기억이 있으나, 세부 사항은 기억나지 않음. 잠정적인 증거가 있었는지 궁금함
"
"https://news.hada.io/topic?id=18074","수학 학습 방법 (2017)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            수학 학습 방법 (2017)

     * 대학 수학은 고등학교 수학과 어떻게 다른가?
          + 고등학교 수학에서는 알고리듬과 특정 상황에서의 적용 기술을 배우는 데 많은 시간을 보냈음. 대학 수학에서는 이론, 정의, 정리의 정확한 진술과 논리적 과정을 중시함.
          + 대학 수학에서는 여러 기술을 제공하며, 문제 해결에 적합한 기술을 선택하는 것이 중요함. 이는 판단력과 기술적 능력을 개발하는 공부 습관을 요구함.
     * 정의를 어떻게 다루어야 하는가?
          + 정의는 개념을 명확히 구분하고 이름을 붙이는 정확한 진술임. 정의를 이해하고 암기하는 것이 중요함.
          + 정의의 범위를 예제를 통해 파악하고, 다양한 예제를 만들어보며 정의를 이해해야 함.
     * 정리, 명제, 보조정리, 그리고 따름정리
          + 정리는 중요한 결과를 나타내며, 명제는 작은 결과를 제공함. 보조정리는 정리의 증명에 사용되는 기술적 결과임.
          + 정리를 이해하고 활용하는 방법을 배우는 것이 중요함. 정리의 가정과 결론을 명확히 이해해야 함.
     * 주제를 통합하기
          + 수학은 다양한 정의와 정리를 서로 연결하여 통합하는 것이 중요함. 주제를 이해하기 위해 역방향으로 작업하거나 정의-정리 개요를 작성하는 것이 도움이 됨.
     * 증명을 이해하는 방법
          + 증명은 대학 수학에서 필수적임. 증명의 전략과 전술을 이해하고, 세부 사항을 채워 넣는 것이 중요함.
          + 증명을 통해 수학적 개념을 깊이 이해하고, 이를 다양한 상황에 적용할 수 있는 능력을 기르는 것이 중요함.
     * 기술 개발
          + 수학 과정의 약 3분의 1에서 절반은 기술 개발에 중점을 둠. 정리와 예제를 통해 문제 해결 기술을 배우고, 다양한 방법으로 문제를 해결하는 연습이 필요함.
     * 몇 가지 최종 제안
          + 수학적 글은 중복률이 낮고, 수학은 누적적인 과목임. 책을 읽을 때 주의 깊게 읽고, 수업 노트를 정리하며, 뒤처지지 않도록 해야 함.
          + 시험을 위해 벼락치기를 하지 말고, 이해를 통해 수학을 공부하는 습관을 기르는 것이 중요함.

        Hacker News 의견

     * 수학 박사로서 수학을 즐기는 것이 중요하다고 강조함. 수학을 처음부터 좋아하지 않을 수 있지만, 멘토를 통해 수학을 즐기는 방법을 찾는 것이 중요함
     * 대학 시절 수학 문제를 풀면서 학습했으며, 교과서의 모든 문제를 풀고 다른 교과서의 문제도 풀어보았음. 대학원에서는 교과서의 모든 증명을 다시 작성하며 중간 과정을 채워 넣었음
     * 학교에서 대학으로 넘어갈 때는 혼란스러움과 패배감을 느끼는 것이 자연스러움. 대학에서는 방대한 양의 자료를 스스로 이해하고 학습해야 함
     * 'Sitzfleisch'라는 독일어는 책상에서 오랜 시간 동안 힘든 작업을 수행하는 능력을 의미하며, 이는 수학에서 성공을 측정하는 중요한 요소로 여겨짐
     * 수학의 직관적 이해는 학교 수준에서는 적합하지만 대학에서는 그렇지 않다는 의견이 있음. 그러나 직관은 수학 이해에 강력한 도구가 될 수 있음
     * 수학 학습에서 창의적 자기 성찰이 중요하며, 수학을 배우거나 변화시키려면 수동적인 자세가 아닌 적극적인 자세가 필요함
     * 모든 증명을 스스로 해보는 것이 수학 학습에 큰 도움이 되었으며, 복잡했던 문제들이 간단하게 느껴졌음
     * MathAcademy.com을 통해 고등학교 수학을 다시 배우며 즐겁고 측정 가능한 학습을 경험했음. 경험과 간격 반복 학습이 중요하다는 것을 깨달음
     * 주요 결과의 증명을 살펴보고 이전 결과들을 추적하여 정의에 도달하는 것이 수학을 이해하는 좋은 방법임. 이는 프로그래밍에서도 유사하게 적용될 수 있음
"
"https://news.hada.io/topic?id=18060","AI와 증강현실의 미래: 우리의 귀에서 시작된다 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       AI와 증강현실의 미래: 우리의 귀에서 시작된다

     * 'Foursquare'를 만들었던 Dennis Crowley는 기술과 인간 행동의 교차점에서 커리어를 쌓아온 인물
     * 이번에는 AI와 이어폰(예: AirPods)을 활용해 증강현실(AR)을 새롭게 정의하려는 Hopscotch Labs를 설립
     * Hopscotch Labs는 이어폰과 스마트폰, AI를 결합해 주변 정보를 제공하는 ""BeeBot"" 서비스 개발 중
          + BeeBot은 사용자가 이어폰을 착용하고 걷는 동안 장소 정보를 전달
          + 예: 특정 장소에 친구가 머물렀던 시간, 해당 장소에 남겨진 사용자 메시지 등을 오디오로 안내
     * Crowley는 ""시각적 AR을 기다리지 않고, 오디오 기반 AR을 바로 구현""한다고 강조
          + ""도둑지도(Marauder’s Map) for AirPods"" 라는 개념으로 설명
               o 해리포터에 나오는 마법지도: 호그와트 내부에서 사람들이 움직이는게 실시간으로 보임
     * AI의 발전과 이어폰의 보편화가 주요 트렌드
          + Statista 자료에 따르면 미국 성인의 34.4%가 Apple 이어폰(AirPods 또는 Beats)을 사용
     * Crowley는 이러한 기술적 교차점에서 새로운 형태의 사용자 경험 창출을 목표로 함
          + Dodgeball과 Foursquare가 모바일과 GPS, 소셜 네트워크 기술의 융합을 예견했던 것처럼, 이번 프로젝트도 미래 기술 트렌드를 예측

BeeBot의 작동 방식

    1. iPhone 앱 설치 및 권한 설정 후, 이어폰 착용 시 BeeBot 활성화 알림
    2. 사용자가 걸으며 특정 장소를 지나면 해당 장소와 관련된 정보 제공
    3. 사용자가 장소에 남긴 메시지(예: ""트위터에 남긴 트윗처럼"")를 오디오로 전달

Crowley의 접근 방식과 AI의 역할

     * Crowley는 AI가 단순히 데이터 필터링을 넘어 사용자 맞춤형 정보를 제공해야 한다고 주장
          + 현재 Hopscotch Labs는 OpenAI, Claude 등 다양한 AI 모델 실험 중
          + 사용자 주변 정보를 즉각적으로 제공하는 ""AI 동반자""를 개발 목표로 삼음
          + Crowley는 이를 ""Scarlett Johansson의 'Her'에서 영감을 얻은 개인 비서""와 비유

미래를 향한 Crowley의 비전

     * 정보 밀도의 문제 해결
          + 현대의 정보 폭증 시대에서 AI가 데이터 과부하를 해소하고 사용자와 관련된 정보를 선별적으로 제공할 가능성 탐색
     * 소셜 그래프를 넘어서
          + 기존 친구 네트워크에 의존하지 않고, 지리적 위치와 문맥을 기반으로 정보를 필터링
     * 개인 비서와 디지털 동반자
          + AI가 사용자의 일상적인 경험을 개선하고 더 인간적인 연결을 제공
          + 자신의 AI를 적용하여 해당 콘텐츠를 필터링하고 다른 부분과 결합

인상깊은 문장들

     * Crowley의 사명 : ""사람들이 화면에서 벗어나 주변 세상을 더 잘 경험할 수 있또록 돕는 것을 만들기""
     * VC에게 피칭하는 대화중
          + VC: ""이게 왜 성공할꺼 같아요?""
          + Crowley: ""사람들이 사랑에 빠지게 만들꺼에요""
          + VC: ""어떻게 하실건데요?""
          + Crowley: ""글쎄요. 잘 모르겠어요. 우린 그냥 사람들이 사랑하게 될 무언가를 찾을 때까지 계속 만들 거에요""

   활자에서 소리로 매체만 바꿨을 뿐 집중력 비즈니스의 반복으로 보입니다

   잘되면 좋겠지만 광고로 도배될거 같습니다... ㅎㅎㅎ

   10년 전에 Google Map에서 만든 이게 생각나긴 하네요
   https://theverge.com/2014/4/…

   차이라면, 이건 가상에서 걸어다니면 현실의 audio랑 audio guide가 혼합되는거고, 저건 현실을 걸어다니면 audio가 나오는 차이로 보이는데, 실제는 많이 다르긴 하겠죠?

   태양만세

   처음 가보는 특정 장소에 도착했을 때, AI가 친구들 또는 자신이 팔로잉 하는 사람들의 메시지를 어그리게이션 해서 하나로 얘기해주면 좋을 것 같기는 하네요.

   ""저 골목 안쪽으로 들어가서 보이는 OOO라는 식당을 추천해요""
   ""친구인 X가 얼마전 여기를 방문해서 뭐뭐뭐라고 남겼네요""
"
"https://news.hada.io/topic?id=18009","감사하는 사람에게 보내는 공식 'Continue and Persist' 편지","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               감사하는 사람에게 보내는 공식 'Continue and Persist' 편지

     * 중단 및 지속 편지 서비스 소개
          + Boondoggle & Doggle Partners LLP는 사람들에게 긍정적이고 격려적인 메시지를 전달하기 위해 '중단 및 지속 편지'를 제공하는 회사임.
          + 이 편지는 공식적인 법적 문서처럼 보이며, 수신자에게 그들이 하고 있는 일을 계속하라고 격려하는 내용임.
     * 서비스 이용 방법
          + 편지를 받을 사람을 선택하여 양식을 작성하면 됨.
          + 개인화된 편지가 무료로 발송됨.
          + 수신자는 일주일 내에 편지를 받게 됨.
     * 편지를 보낼 수 있는 대상
          + 이야기를 들어주는 친구, 감사한 사람, 인정을 받을 만한 사람, 지원해주는 가족 구성원, 항상 최선을 다하는 친구, 저평가된 동료, 사랑하는 사람 등 다양한 대상에게 보낼 수 있음.
     * 서비스의 특징
          + 무료로 제공되며, 공식적인 편지지와 봉투, 법률 전문가의 서명이 포함됨.
          + 이미 100개 이상의 편지가 발송됨.
          + 기부는 선택 사항임.
     * Boondoggle & Doggle Partners LLP 소개
          + 이 회사는 '중단 및 지속 편지'의 관리에만 특화된 전국적으로 인정받는 회사임.
          + 법적 도움이 필요하다면 실제 변호사를 찾아가야 함.
          + 설립 파트너인 Mark Chan과 Adnan Aga는 각각 비전문적 경험을 보유하고 있음.
     * 파트너 소개
          + Mark Chan: 법대 오픈 하우스 투어에 실수로 참석한 경험이 있음.
          + Adnan Aga: 어린 시절부터 Judge Judy를 시청하며 법률 세계에 관심을 가짐.
     * 연락처
          + 이메일: continue@boondoggle.io

        Hacker News 의견

     * 세계 문제의 99%가 사람들을 분열시키려는 권력에 의해 발생한다고 믿게 된 사람으로서, 이러한 노력이 기쁨을 줌. 작아 보일지라도 성공을 기원함
     * 매일 수천 개의 중지 및 중단 편지가 발송되어 사람들이 하던 일을 멈추게 함. 그래서 '계속하고 지속하라'는 편지를 만듦. 사람들을 격려하고 응원하는 공식적인 법적 문서임
          + 아버지가 가짜 소환장을 보내 형제의 총각 파티에 초대했던 일이 떠오름. 대부분은 재미있어했지만 몇몇은 놀랐음. 이 편지도 비슷한 문제가 있을 것 같음
          + 미국 외 지역에서도 다운로드 가능한 PDF 버전이 있으면 좋겠음
          + 이 아이디어를 사랑함. Bureau of Communication의 공식 편지와 유사함
          + 무료라면 사용자가 제품임. 더 나아가 친구와 가족의 주소를 무료로 제공하는 것임. 그래도 아이디어가 마음에 들어 몇 개 보내볼까 함
          + 기발한 개념이지만 누군가가 내 대신 편지를 보내는 것에 대해 조심스러움
          + 이 아이디어를 상표 등록하지 않았는지 궁금함. 직접 몇 개 작성해서 보내볼까 함
          + 만약 누군가의 개인 정보를 침해해야 한다면, 좋아하지 않는 사람에게 할 것 같음. 그래도 절대 하지 않을 것임
          + Achtung! Halten! Verboten!
          + 흥분해서 무언가를 바꾸게 됨
"
"https://news.hada.io/topic?id=18056","책 한 권 이상 읽어야 탈 수 있는 조건의 Ride","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      책 한 권 이상 읽어야 탈 수 있는 조건의 Ride

     * 당신은 적어도 한 권의 책을 읽어야 한다
          + 두 가지 사실이 있음. 첫째, 나는 내 직업 환경에서 최고의 엔지니어 중 한 명으로 인정받고 있음. 둘째, 나는 나보다 뛰어난 사람들로부터 이메일을 받을 때마다 내가 그들보다 명백히 부족하다는 것을 느낌. 심리학 배경을 가진 내가 어떻게 시니어 엔지니어가 되었는지 이해하기 어려움.
     * I.
          + 고등학교 시절, 나는 끔찍한 미술 학생이었음. 창의성이나 문화에 대한 교육이 부족한 환경에서 자라왔음. 2022년에 Drawabox라는 코스를 시도했으나 큰 진전이 없었음. 그러나 Betty Edward의 ""Drawing On The Right Side Of The Brain""이라는 책을 통해 놀라운 발전을 경험함.
     * II. 한 권의 책 장벽
          + 엔지니어들은 두 부류로 나뉨. 한 부류는 특정 주제에 대해 1권 이상의 책을 읽은 사람들로, 매우 유능해 보임. 다른 부류는 경력 내내 시도하지 않는 사람들로, 대부분의 직업에서 다수를 차지함. 나는 대부분의 주제에 대해 딱 한 권의 좋은 책을 읽었지만 깊이 있게 공부하지는 않음.
     * III. 우리의 끝없는, 번호 매겨진 레벨
          + 깊은 전문성의 중요성을 강조함. 예를 들어, 멜버른에서 나는 괜찮은 사브르 펜싱 선수로 여겨졌지만, 국가 챔피언과 경쟁할 때는 큰 차이를 느꼈음. 이는 다른 분야에서도 마찬가지임.
     * IV. 인센티브
          + 기술 분야에 재능이나 관심이 없는 사람들을 참여시키는 사회적 문제가 있다고 느끼며, 이러한 사람들은 다른 분야에서 더 큰 성취감을 느낄 수 있을 것이라고 생각함.
     * V.
          + 게임에 참여하는 것의 중요성을 강조하며, 경쟁자들이 나쁘다는 사실이 오히려 기쁨을 줌. 책을 읽는 것이 고성과자가 되는 데 큰 도움이 됨.
     * VI.
          + 노력하지만 결과를 얻지 못하는 사람들에 대한 복잡한 사례를 다룸. 그들은 잘못된 책을 읽고 있으며, 그로 인해 발전이 없음을 지적함.
     * VII.
          + 책을 읽는 것이 얼마나 효과적인지 강조하며, 다른 사람들에게 책을 읽도록 권장하지 말 것을 제안함. 이는 자신에게 유리한 상황을 만들기 위함임.

   기술을 가져다 쓸래도 일단 그게 존재하는지는 알아야 시도라도 해 볼 테니 얕게라도 아는 것이 중요하죠.

        Hacker News 의견

     * 경험 많은 엔지니어가 가진 암묵적 기술을 저평가하는 경향이 있으며, 공감 능력 부족의 결과가 될 수 있음. 아이들이나 노인들과 함께 시간을 보내는 것이 공감 능력 향상에 도움이 될 수 있음
          + 언어를 자연스럽게 구사하는 사람과 배우는 사람의 차이를 고려해야 함
     * 경력 내내 시도하지 않는 엔지니어들이 존재함. 자신은 뛰어난 개발자는 아니지만, 문제 해결에 능숙하며, FAANG 회사에 지원할 자신은 없음
          + 작업 중 항상 경계심을 느끼며, 코드 리뷰에서 보안 결함을 발견하거나 비효율적인 데이터 로딩 패턴을 발견하는 경우가 있음
          + 프로그래밍에 대한 호기심이나 열정 부족이 문제의 원인일 수 있음. 프로그래밍은 예술적 요소가 있는 공예로, 단순히 요구 사항을 충족하는 것 이상을 추구해야 함
          + 불완전한 솔루션을 내놓는 것에 불편함을 느끼며, 더 나은 솔루션을 찾고자 함
     * ""올바른 책 읽기""의 중요성을 강조함. 자기계발서를 읽으며 패턴을 발견함
          + 독서 중 자주 자문함: ""이것이 당연한가? 이미 알고 있는가?""
          + 많은 예시나 이야기가 포함됨
          + 간단한 은유나 슬로건을 인생 철학으로 발전시키려 함
     * 독서가 집중력과 주의력을 크게 향상시킴. ""doom scrolling""에 대한 욕구도 줄어듦
     * 단순히 일에 신경 쓰는 것만으로도 큰 차이를 만들 수 있음
     * 기술 관련 뉴스 사이트(HN)를 읽는 것이 자기계발에 도움이 될 수 있음. 이 사이트에서 얻은 아이디어로 인해 직장을 그만두고 창업을 결심함
     * 기술 분야에 재능이나 관심이 없는 사람들을 참여시키는 사회적 문제를 지적함
          + 기술 채용 과정이 비효율적일 수 있으며, 신입 인재를 찾는 방법이 잘못되었을 수 있음
          + 장기적인 직업(예: 스포츠, 예술 등)에 대한 재정적 인센티브가 부족함
          + 기업들이 직원 교육을 직접 하지 않는 이유를 궁금해함
     * 매년 최소 16권의 책을 읽으려 노력하며, 이는 기술 향상에 큰 도움이 됨
          + Go 프로그래밍 언어를 배우며 경험을 공유함. 책을 통해 철학을 이해하고 연습 문제를 따라하며, Go에 능숙해짐
     * 책을 읽지 않으면 패배자처럼 느껴짐. 책을 읽지만, 결국 자신의 방식대로 일을 처리하며, 실패를 통해 배우는 가치가 있다고 생각함
          + 저자가 ""nerd""처럼 느껴지며, 장시간 대화하고 싶지 않음
"
"https://news.hada.io/topic?id=18011","GoMLX - Python 없이 Go로 ML하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       GoMLX - Python 없이 Go로 ML하기

     * Go 언어로 머신러닝(ML) 모델을 구현할 수 있는 패키지로, Python에 의존하지 않고도 ML 작업을 수행할 수 있도록 설계됨
     * TensorFlow(TF), JAX, PyTorch 등 Python 중심 ML 프레임워크의 대안을 제공하며, 동일한 하드웨어 효율성을 Go 기반으로 활용함
     * XLA와 PJRT와 같은 저수준 컴파일러 및 런타임 기술을 활용하여 최적화된 성능을 제공

주요 특징

     * Python 없이 ML 모델 구축
          + Python 코드를 배제하고 Go 언어만으로 ML 모델 생성, 학습, 추론 가능
          + 기존 ML 프레임워크의 표현력과 유사한 방식으로 계산 그래프를 생성하고 자동 미분 및 모델 학습 지원
     * XLA와 PJRT 활용
          + OpenXLA 스택을 사용하여 하드웨어 최적화된 연산을 지원하며, TensorFlow와 JAX에서 사용하는 동일한 기본 구성 요소를 활용
          + 자동 미분, 텐서 데이터 관리, 작업 분할 등 고급 기능 포함
     * CNN 모델 구현 사례
          + CIFAR-10 데이터셋을 사용해 CNN(합성곱 신경망) 모델을 Go로 구현
          + Python 없이 GoMLX로 구현된 모델은 TensorFlow+Keras로 학습된 모델과 유사한 성능을 달성
     * 실제 사례: Gemma2 모델
          + HuggingFace에서 제공하는 Gemma2 LLM(Large Language Model) 가중치를 활용하여 실제 프로덕션 수준의 LLM 추론을 실행
          + Python 없이도 Gemma2와 같은 고급 모델 실행 가능

요약

     * GoMLX는 Go 언어 기반으로 ML 모델 구현, 학습, 추론을 지원하며 Python의 의존성을 제거함
     * XLA와 PJRT를 활용해 하드웨어 최적화된 연산과 고급 ML 기능을 제공
     * Python 없이도 CIFAR-10 CNN 모델 및 Gemma2 LLM 추론과 같은 복잡한 작업이 가능
     * GoMLX는 초기 단계지만, Python-Free ML 구현의 가능성을 열며 향후 발전이 기대됨
"
"https://news.hada.io/topic?id=18030","Llama.cpp 가이드 – 모든 하드웨어에서 LLMs를 처음부터 로컬로 실행하는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Llama.cpp 가이드 – 모든 하드웨어에서 LLMs를 처음부터 로컬로 실행하는 방법

        Hacker News 의견

     * 블로그 작성이 증가하는 것은 긍정적이지만, llama.cpp 빌드 방법이 복잡하게 느껴짐
          + ccmake . 명령어로 하드웨어에 맞는 파라미터를 설정하고 빌드할 수 있음
     * 오래된 Dell 노트북에서 Llama.cpp 실행 성공 경험 공유
          + 최소 사양으로도 작동했으며, 느리지만 정확한 답변을 제공함
          + 더 나은 하드웨어에서 더 큰 모델을 실행해보고 싶음
     * Llama.cpp 설치를 원하지만, UX가 더 나은 kobold.cpp를 설치하게 됨
     * Windows와 AMD에서 빌드 시도 경험 공유
          + Vulkan과 MSYS2가 가장 쉽게 실행됨
     * Llama.cpp가 지원하는 LLM의 제한 사항에 대한 질문
          + 특정 트랜스포머 모델만 지원하는지에 대한 궁금증
     * Ollama로 전환한 경험 공유
          + Ollama의 서버 및 클라이언트 설정이 간단하게 작동함
     * Ollama가 단순한 llama.cpp 래퍼가 아니라는 점 강조
          + Ollama는 모델 인터페이스 및 패키징을 위한 다양한 기능을 제공함
     * ChatGPT 웹 인터페이스 대신 Llama.cpp를 사용하는 이유에 대한 질문
          + 개인 정보 보호가 주요 이유인지에 대한 궁금증
     * ChatGPT와 Claude를 매일 사용하지만, LLM을 다른 서비스 외에 사용할 이유를 찾지 못함
     * Ollama와 llama.cpp 직접 실행에 대한 논의
          + CUDA 설정이 항상 쉬운 것은 아니며, 로컬 인퍼런스가 더 빠를 수 있음
          + PyTorch 실행이 더 쉬우며, AWQ 모델은 간단히 설치 가능함
"
"https://news.hada.io/topic?id=17997","사기꾼과 사업가, 단 하나의 공통점: 뇌의 능력을 끌어올리는 가설적 추론의 힘","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              사기꾼과 사업가, 단 하나의 공통점: 뇌의 능력을 끌어올리는 가설적 추론의 힘

   '가추'는 주어진 사실에서 가장 그럴듯한 설명을 추론해내는 사고 과정입니다. 가추를 잘 활용하는 두 부류인 사업가와 사기꾼을 이야기하며, 일상에서 '말이 안 되는 것'을 '말이 되게' 설명하려 노력하는 가추 훈련을 통해 뇌의 능력을 향상시킬 수 있다는 점을 이야기합니다.

   좌뇌가 하는 일이 바로 이거죠. 분리 뇌 환자 사례와 뇌가 사람이 '결심' 하기 이전에 이미 결정을 내리고 좌측두엽이 결정을 내린 전두엽의 안와전두피질이나 전전두피질의 행동을 '언어' 로 설명을 지어내고 스스로 납득을 시킨다는 이야기는 이미 유명하죠.

   신기하네요 ㄷㄷ

   흥미로운 주장인 거 같습니다.
"
"https://news.hada.io/topic?id=18091","DuckDuckGo, Perl 및 Raku 재단에 $25,000 기부","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 DuckDuckGo, Perl 및 Raku 재단에 $25,000 기부

     * DuckDuckGo, Perl 및 Raku 재단에 $25,000 기부
     * 오늘 ""Giving Tuesday""에 The Perl and Raku Foundation(TPRF)은 DuckDuckGo로부터 $25,000의 기부를 받았음을 발표함
     * 2011년 이후 DuckDuckGo는 온라인 신뢰 기준을 높이려는 비전에 맞는 조직에 600만 달러 이상을 기부해옴
     * TPRF는 Perl 및 Raku 프로그래밍 언어의 오픈 소스 개발, 커뮤니티 참여 및 홍보를 통해 지속적인 성장, 관련성 및 접근성을 보장하는 데 전념함
     * DuckDuckGo의 지원은 TPRF가 핵심 Perl 개발 자금 지원, 커뮤니티에 중요한 프로젝트에 대한 보조금 지원 및 커뮤니티 지원을 계속할 수 있도록 도와줌
     * 모든 기부는 이 작업이 중요하다는 메시지를 전달함
     * TPRF는 DuckDuckGo의 관대함과 TPRF의 사명에 대한 신뢰에 깊은 감사를 표함
     * TPRF의 현재 활동 및 미래 목표에 대한 자세한 내용은 TPRF 2024 전망서를 참조
     * TPRF 기부자가 되는 데 관심이 있는 조직은 연락을 권장하며, 기부자 관계가 조직에 어떻게 이익이 될 수 있는지 논의하기 위한 통화를 설정할 수 있음

        Hacker News 의견

     * Craigslist는 매년 10만 달러 이상을 기부했으며, 이는 2010년부터 2016년까지 Perl을 유지하는 데 큰 도움이 되었음. 그러나 많은 기업들이 Perl에 의존하면서도 기부하지 않는 현실이 안타까움
          + AT&T는 1980년대에 여러 회사로 분리되었다가 1990년대에 재합병되었으며, 이 과정에서 Perl이 여러 시스템을 통합하는 데 사용되었음에도 불구하고 기부하지 않았음
     * Perl은 비판을 받기도 하지만 여전히 중요한 인프라를 운영하는 훌륭한 도구임
     * $25,000의 기부가 주목받는 것은 Perl Foundation의 재정 상태가 좋지 않음을 나타내는 것 같음. 더 많은 금액이 필요하다고 생각함
     * Zerodha의 Floss.fund는 올해 FOSS 프로젝트에 100만 달러를 기부하고 있으며, 아직 충분한 신청이 없으니 참여를 권장함
     * DuckDuckGo는 Perl로 작성되었으며, Perl을 사용한 이유를 물었을 때 친절하게 답변을 받았던 기억이 있음. Raku가 재미있다는 이야기를 들었지만 Perl을 다시 사용하지 않겠다고 다짐한 적이 있음
     * Evan Czaplicki의 강연에서는 현대 프로그래밍 언어의 자금 조달이 검색 엔진 수익에서 비롯된다는 점을 설명함
     * Craigslist도 Perl로 구축되었으며, Perl의 창시자인 Larry Wall을 고용한 적이 있음
     * DuckDuckGo 사용자로서 Perl을 배우고 싶다는 생각을 하고 있음
     * 다른 대형 통신사에서도 Perl이 여전히 사용되고 있으며, 새로운 프로젝트에도 사용되고 있음
     * DuckDuckGo는 1억 건의 검색을 수행하며, 이는 그들의 마케팅의 성과임. 그러나 여전히 다른 검색 엔진의 일부 기능을 사용하는 메타 검색 엔진에 불과함
     * Perl/Raku로 프로젝트를 시작하는 사람이 있는지 궁금하며, 있다면 그 이유가 무엇인지 알고 싶음
"
"https://news.hada.io/topic?id=18004","호주: 상원 법안 통과로 16세 미만 아동 소셜 미디어 금지 법안","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  호주: 상원 법안 통과로 16세 미만 아동 소셜 미디어 금지 법안

     * 요약
          + 16세 미만의 어린이와 청소년이 소셜 미디어 사용을 금지하는 법안이 통과됨.
          + 이 법안은 정신 건강과 웰빙을 보호하기 위한 조치로 정부와 연합이 주장함.
          + 법안은 1년 후 발효되며, 소셜 미디어 회사는 이를 준수하지 않을 경우 최대 5천만 달러의 벌금을 부과받을 수 있음.
          + 메시징 앱, 온라인 게임 서비스, 건강 및 교육 지원 서비스는 금지 대상에서 제외됨.
     * 혼합된 의견
          + 법안에 대한 정신 건강 전문가들의 의견이 엇갈림.
          + 일부는 소셜 미디어가 정신 건강에 이점이 없다고 주장하는 반면, 다른 일부는 연결과 도움을 구하는 데 있어 이점이 있다고 주장함.
          + 청소년의 권리를 제한하지 않도록 주의해야 한다는 의견도 제기됨.
     * 관련 이야기
          + 엘론 머스크가 소셜 미디어 연령 제한에 대해 언급한 후, 의회에 15,000개의 제출물이 몰림.
          + Snapchat은 정부의 소셜 미디어 금지 대상에 포함되며, YouTube는 제외됨.
     * 주요 뉴스
          + '캥거루의 땅'에서의 어린이 소셜 미디어 금지가 전 세계적으로 주목받음.
          + 총리가 소셜 미디어 금지 통과 후 부모들에게 '우리가 당신을 지지한다'고 발언함.
          + 호주 법률 30개 이상이 하룻밤 사이에 변경됨.
          + '영원한 화학물질'로 알려진 물질이 예상보다 더 널리 퍼져 있음.
          + 호주가 2030년 배출량 감소 목표에 크게 미달함.

        Hacker News 의견

     * 모든 호주의 ID가 나이 확인을 위해 검증되어야 함. 정부가 소셜 미디어 데이터를 쉽게 접근할 수 있게 되어 익명 계정이 어려워질 가능성이 있음. 이는 주로 전통 미디어가 주도하는 것으로 보이며, 소셜 미디어가 그들에게 위협이 됨을 인식하고 있기 때문임.
     * 아이들을 보호하기 위한 법안 통과는 정치적으로 쉬움. 그러나 소셜 네트워크의 행동 방식을 규제하는 것이 더 효과적일 수 있음. 성인도 아이들만큼 중독에 취약함. 학교 시간 동안 서비스 사용을 차단하거나 하루에 X시간만 사용하도록 하는 것이 필요할 수 있음.
     * ""The Anxious Generation""을 읽어보면 젊은 세대에게 실질적이고 돌이킬 수 없는 피해가 발생하고 있음을 알 수 있음. 이를 해결하려는 노력이 필요함.
     * 누군가의 나이를 확인하는 문제는 암호화 기술을 통해 해결 가능함. 정부가 이를 가능하게 하려면 모든 사람의 생년월일을 알고 있어야 함.
     * 호주의 미디어 변호사 친구가 있음. 그는 법안이 명확하지 않아 게임 개발자들이 금지 대상인지 조언할 수 없다고 함.
     * 오스트리아에서는 4학년 학생들이 자전거 기술 테스트를 받음. 소셜 미디어에서도 비슷한 교육이 필요할 수 있음. 단순히 금지하는 것보다 교육을 통해 문제를 해결하는 것이 중요함.
     * 아이들의 인터넷 접근을 더 엄격히 모니터링해야 한다고 생각함. 온라인에서 아이들을 보호하는 것이 중요함. ID를 통해 나이를 확인하고, 이를 정부 ID 시스템에 통합할 가능성이 있음. 이는 표현의 자유에 영향을 미칠 수 있음.
     * 메시징 앱, 온라인 게임 서비스, 건강 및 교육을 지원하는 서비스는 금지 대상이 아님. 소셜 미디어의 정의가 명확하지 않음. 소셜 미디어 회사가 16세 미만을 차단하지 못하면 최대 5천만 달러의 벌금을 받을 수 있음.
     * 소셜 미디어가 아이들뿐만 아니라 성인에게도 해를 끼칠 수 있음. ""아이들을 보호하기 위한"" 조치가 권력 장악과 프라이버시 감소의 수단일 수 있음.
     * 시골 지역의 퀴어 아이들이 유일한 지원 네트워크에서 단절될 위험이 있음.
     * 도덕적 규칙을 강화하거나 보안을 높이기 위한 조치가 프라이버시를 박탈하는 수단이 될 수 있음을 상기해야 함.
"
"https://news.hada.io/topic?id=18018","유럽 전력망의 아름다운 시각화 (2022)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        유럽 전력망의 아름다운 시각화 (2022)

     * 유럽 전력망의 시각화
          + 유럽 전력망의 연결 지점을 시각화한 지도임
          + 녹색 점은 발전이 소비보다 많아 네트워크에 전력을 공급하는 지점임
          + 보라색 점은 소비가 발전보다 많아 네트워크에서 전력을 가져오는 지점임
          + 삼각형은 전력이 흐르는 방향을 나타냄
          + 삼각형 위에 마우스를 올리면 전력선의 전력 흐름과 총 용량을 보여줌
     * 최적화 알고리듬
          + 최적 전력 흐름을 찾기 위한 알고리듬을 사용함
          + 특정 날짜를 선택하고, 각 2시간 슬롯마다 발전소가 얼마나 전력을 생산해야 하는지 계산함
          + 총 비용을 최소화하고 모든 전력 소비를 충족시키는 것이 목표임
          + 각 연결 지점과 시간 슬롯마다 다음과 같은 입력값을 수집함
               o 인근 정착지와 산업의 총 소비량
               o 태양광, 풍력, 수력, 석탄, 석유, 가스, 원자력의 발전 단가
               o 전통적인 발전소의 총 발전 용량
               o 태양광, 풍력, 수력 발전소의 최대 발전 가능량
               o 각 전력선의 최대 전력 전송량
     * 데이터 출처
          + 데이터는 pypsa-eur라는 연구 논문에서 가져옴
          + pypsa-eur는 유럽 전력망 데이터의 최적화 모델을 제공함
          + Fabian Neumann과 Tom Brown 교수 연구 그룹에 감사의 인사를 전함
     * 현실성
          + 수학적 계산은 실제 전력망 운영자들이 사용하는 것과 동일함
          + 실제 발전소의 전력 생산량은 시간에 따라 변동하는 가격에 따라 달라짐
          + pypsa-eur는 역사적 평균을 기반으로 가격을 가정하고 최적화 알고리듬을 실행함
     * 왜 중요한가?
          + 오늘날 선진국의 배출량을 대부분 줄일 수 있는 방법은 난방 및 차량 운송을 전기로 전환하는 것임
          + 모든 전력을 거의 무배출로 생성해야 함
          + 단순히 재생 가능 발전을 늘리는 것만으로는 문제를 해결할 수 없음
          + 재생 가능 발전을 어디에 건설할지에 대한 전략적 접근이 필요함

        Hacker News 의견

     * 이 지도는 불완전하며, 우리 도시 근처의 강에서 20-30km에 걸쳐 3-4개의 발전소가 연결되어 있는 1GW 용량의 수력 발전이 지도에 표시되지 않음
     * 시각화가 이상하며, 선의 두께가 와트에 비례할 것 같지만 그렇지 않음. 무엇을 나타내는지 혼란스럽고 오해의 소지가 있음
     * UI는 좋고 흥미로운 데이터가 있지만, 실제 실시간 데이터와 연결된 것이 아니라 평균의 정적 추정치일 뿐임
          + 예시로 http://gridwatch.co.uk/나 https://gridwatch.templar.co.uk/france/와 같은 사이트가 있음
     * 2시간 단위로 사용한다고 하지만, 마지막 업데이트 시간이 언제인지 시계가 없어 명확하지 않음
     * 프랑스를 볼 때, 전체 국가를 볼 수 있는 줌 레벨에서 모든 녹색 점이 원자력 발전소 옆에 위치함. 프랑스 전력망이 주로 원자력에 의해 구동된다는 것을 상기시킴
     * 여름 동안의 지도를 보면 다른 전력 믹스가 다른 지도를 만들어내는지 보는 것이 좋을 것임
     * 예측 도구이지 모니터링 도구가 아님을 주목할 필요가 있음
     * 더 빠르고 명확한 도구로 https://app.electricitymaps.com/이 있음
     * 지도가 왜곡되어 있고 이를 변경할 방법이 없을 때 비합리적으로 화가 남. 줌을 더 할수록 왜곡이 심해짐. 줌을 완전히 빼도 각도 왜곡이 사라지지 않음. 이는 프로그래머의 실제 노력이 필요했음
          + 북쪽을 위로 유지하지 않는 내비게이션 미니 맵(자동차나 컴퓨터 게임)과 같지만 더 나쁨
     * 오스트리아의 특수성은 양수 발전임. 산과 계곡이 많아 호수가 거대한 배터리로 사용됨. 공급이 과잉일 때 물을 펌핑하고 수요가 높을 때 에너지를 생산하기 위해 방출함
          + 이는 전력선을 안정적으로 유지하고 풍력 발전소의 바람 부족, 열 발전소의 시작/종료 시간, 추운 날씨로 인한 소비 패턴 차이 등을 보상함
     * 전력망과 우리나라에 대해 몇 가지를 배우게 되어 매우 흥미로웠으며, 이를 계기로 에너지 시장에 대해 조사함
     * 대륙 전체가 동기화된 전력망에 연결되어 있다면, 각 국가가 전기를 수출하고 수입하는 상대방을 어떻게 알 수 있는지 궁금했음
          + 총 수입이나 수출을 측정할 수는 있지만, 어느 이웃 국가로부터 전기를 받고 보내는지를 어떻게 파악하는지 궁금함
"
"https://news.hada.io/topic?id=18045","리액트가 아니라면, 무엇을 사용할까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          리액트가 아니라면, 무엇을 사용할까?

     ""Frameworkism(프레임워크주의)는 더 이상 통하지 않음. 해답은 다른 도구가 아니라 엔지니어링을 할 수 있는 용기""

     * 지난 10년 동안, 데스크톱과 모바일 웹을 위한 다양한 제품과 기술 스택을 통해 100개 이상의 프로젝트를 경험
     * 많은 시간은 웹 API 개선보다 리액트와 같은 프론트엔드 프레임워크가 초래한 성능 및 접근성 문제를 해결하는 데 사용
     * React는 이미 레거시 기술임에도 불구하고 여전히 신규 프로젝트에서 채택되고 있음
     * React를 ""현대적""이라고 주장하는 사람도 있지만, 이는 과거의 방법을 되풀이하는 것에 불과함

최소한의 클라이언트 측 복잡성 규칙

     * 서버 측 코드는 개발자가 제어 가능하며, 성능과 가용성을 효과적으로 관리할 수 있음
     * 클라이언트 측 코드는 개발자가 제어할 수 없는 다양한 환경에서 실행되어, 안정성과 성능을 보장하기 어려움
     * 최선의 전략은 클라이언트에 보내는 코드 양을 줄이는 것
          + HTML과 CSS를 우선 사용해 자바스크립트 의존도를 최소화
          + 리액트 및 유사 프레임워크는 불필요한 코드 중복 및 성능 저하 문제를 야기

그렇다면, 대안은 무엇인가?

  두 가지 질문으로 나눠지는 논의

     * 좁은 질문: ""클라이언트 렌더링이 필요할 경우, 리액트를 대신할 기술은 무엇인가?""
          + 현대적인 프레임워크(예: Svelte, Lit, FAST, Solid, Qwik, Marko, HTMX, Vue, Stencil 등)를 고려할 가치가 있음
          + 다만, 이들 프레임워크를 사용할 때도 클라이언트 측 페이로드와 복잡성을 엄격히 관리해야 함. 자바스크립트는 HTML/CSS에 비해 최소 3배 이상 비용이 큼
     * 넓은 질문: ""리액트에 의존한 기술 스택을 전면적으로 재검토하려면 어떻게 해야 하는가?""
          + 단순히 새로운 도구로 대체하는 것이 아니라, 기존 아키텍처의 목적과 한계를 이해하고 재설계해야 함

  좁은 질문에 대한 접근법

     * 소규모 PoC(Proof of Concept)를 여러 개 만들어 성능 확장성과 한계를 평가
     * 이러한 객관적인 실험은 팀원들에게 의미 있는 엔지니어링 경험을 제공

  넓은 질문을 던지는 팀의 공통적 상황

     * 리액트를 대체하려는 논의에서 혼란스러움을 느끼는 경우가 많음
          + 기존 아키텍처를 따라가는 방식으로 결정을 내린 경우가 대부분
          + 사용자 경험에 대한 명확한 이해와 데이터 기반의 의사결정 부재

  프레임워크주의와 사용자 중심 접근의 차이

     * 프레임워크주의: 프레임워크에 더 많은 기능을 추가하면 모든 문제가 해결될 것이라는 믿음
          + 실제로는 사용자 문제를 해결하지 못하는 경우가 많음
          + 비정형적인 패턴이나 데이터 중심의 증거를 무시
     * 현실주의: 사용자 경험을 측정하고 실제 데이터에 기반한 결정을 내림
          + 사용자의 요구와 제한 조건을 이해하고 이를 기반으로 기술 스택 설계
          + 시작점은 항상 사용자 요구

  현실주의를 도입하는 방법

     * RUM 데이터 활용: Core Web Vitals와 같은 사용자 중심 성능 지표를 사용
     * 성능 테스트: WebPageTest(WPT)와 같은 툴을 활용해 주요 사용자 경로(critical user journeys)를 측정
     * 비즈니스 목표와 사용자 경험을 연계: 데이터를 통해 개선 방향과 투자 대비 효과를 평가

  데이터 기반 접근의 중요성

     * 프레임워크를 신뢰에 기반해 채택하는 대신, 데이터로 그 효과를 검증
     * 유행에 따른 기술 채택의 실제 비용과 효과를 비교
     * 측정 가능한 지표를 통해 사용자 경험 최적화에 중점을 둔 기술 선택을 장려

가치 있는 것은 하나도 손실되지 않았다

  리액트의 확산을 막는 정책의 효과

     * 리액트 및 다른 프레임워크 중심 접근법을 금지하는 것은 비용 절감과 사용자 중심 팀 재조정에 기여
     * 하지만, 프레임워크주의를 완전히 배제하지 않으면 근본적인 성과 개선은 어려움
     * 한 가지 실수를 피하더라도 같은 범주의 다른 실수에 투자한다면 효과는 제한적

  넓은 문제에 대한 일반적인 해결책

    사용자 중심

     * 의사결정자는 자신들의 엔지니어링 선택 결과에 직접적으로 책임을 져야 함
     * 변명의 여지 없이, 시스템이 사용자(특히 소외된 사용자)에게 잘 작동하지 않는다면 대체 버전을 도입
     * 해결해야 할 문제만 존재하며, 기존 방식을 무조건 고수하는 ""성역화""는 배제

    증거 기반 접근

     * 경영진과 엔지니어링 간 공유된 현실주의 헌신이 필요
     * 의사결정에서 더 나은 증거가 항상 우위를 가져야 함

    보호 장치

     * 프레임워크주의의 환상적 주장을 방지하기 위한 정책 필요
     * 예: 영국 정부 디지털 서비스의 점진적 향상 기술 요구사항
          + 조직 상황에 따라 정책을 조정 가능(예: 예외 상황의 에스컬레이션 경로 생성)
          + 그러나 중요한 것은 명확한 기준 설정. 증거 기반 정책은 강력한 영향력을 발휘

    기술 비교 평가

     * 명확히 정의된 주요 사용자 경로(critical user journeys) 없이 새로운 시스템을 배포하지 말 것
     * 주요 사용자 경로는 시스템에서 사용자들이 가장 자주 수행할 작업을 나타냄
     * 이를 바탕으로 각 기술의 성과를 제한 조건 하에서 테스트하는 비교 평가(bakeoffs) 실시
          + 제품 관리자는 실험만 무작정 제안하는 것을 넘어서 제품의 명확한 가설을 정의하고 성공의 기준을 설정해야 함
          + 이는 불편한 과정일 수 있지만, 제품 관리자의 핵심 역할
          + 자신의 업무와 맞지 않다고 판단하는 PM의 사직은 감내

사례 연구

  현실주의와 프레임워크주의의 차이점: 사례를 통해 이해

     * 기술 선택 기준
          + 기술 선택은 주요 데이터 업데이트 수와 세션 길이를 기준으로 평가
          + 일부 앱 클래스는 긴 세션과 빈번한 데이터 업데이트를 특징으로 함
               o 이 경우, 로컬 데이터 모델이 적합할 수 있음
               o 하지만 이는 드문 예외적인 상황에 해당
     * 짧은 세션의 경우
          + 평균 세션 시간이 짧은 사이트는 초기 자바스크립트 로드량을 최소화해야 함
          + 대부분의 사이트는 SPA 아키텍처를 요구하지 않음
     * SPA 아키텍처가 필요한 경우
          + SPA 아키텍처는 특정 조건을 충족할 때만 고려해야 함
               o 세션이 길고, 동일 데이터에 대한 여러 번의 업데이트가 필요한 경우
          + 이 조건을 충족하지 않는 사이트는 SPA를 채택해서는 안 됨
     * 핵심 질문
          + 선택은 자바스크립트 프레임워크 간의 문제가 아님
          + 대부분의 경우, SPA 지향 도구 자체를 사용하는 것이 적절한지 여부를 판단하는 것이 핵심
          + 대부분의 사이트에서는 명확히 **""아니다""**라는 답이 나옴

  정보 제공형 웹사이트 (Informational)

     * 최적의 구조: 의미론적 HTML과 필요 시 점진적 향상(Progressive Enhancement)을 활용
     * 정적 사이트 생성기(Hugo, Astro, 11ty, Jekyll)가 적합
     * 빈번히 업데이트되는 콘텐츠는 WordPress와 같은 CMS 도구를 사용
     * 블로그, 마케팅 사이트, 회사 홈페이지, 공공 정보 사이트는 클라이언트 자바스크립트 페이로드를 최대한 줄여야 함
     * SPA 아키텍처를 위해 설계된 프레임워크를 사용하지 않아야 함
     * 왜 의미론적 마크업과 점진적 향상이 적합한가?
          + 짧은 세션과 서버 소유 데이터 모델이 특징
               o 페이지에 표시되는 데이터의 원본은 항상 서버에서 관리
               o 클라이언트 데이터 모델 추상화나 컴포넌트 정의 불필요
          + CMS 구성:
               o 저작자를 위한 저트래픽, 고상호작용 편집기
               o 독자를 위한 고트래픽, 저상호작용 뷰어 UI

  전자상거래 (E-Commerce)

     * 추천 아키텍처: 서버 생성 의미론적 HTML 및 점진적 향상
     * 아마존 대비 React 기반 경쟁사의 성능 격차가 명확
          + Walmart 트래픽의 70% 이상이 모바일에서 발생, SPA 기반의 Next.js는 비즈니스에 부정적 영향
     * 점진적 향상이 적합한 이유
          + 전자상거래의 일반적 구조:
               o 현재 제공 중인 제품과 검색 기능을 포함한 랜딩 페이지
               o 필터 및 비교 기능을 지원하는 검색 결과 페이지
               o 제품 상세 페이지: 미디어, 리뷰, 추천 대안 포함
               o 장바구니 관리, 결제, 계정 관리 화면
          + 서버 소유 상태:
               o 신선한 콘텐츠(예: 가격) 유지
               o 경량 페이지 최적화를 통해 지연 시간 감소
               o 공격적 캐싱, 이미지 최적화, 페이지 크기 감소 전략 사용

  미디어 소비형 웹사이트 (Media)

     * 기본 구조: 점진적 향상을 기반으로 설계
          + 필요 시 제품 변화에 따라 복잡성 추가
     * 점진적 향상과 섬(Islands) 구조가 적합한 이유
          + 댓글 스레드와 같은 대화형 요소는 독립적 데이터 모델로 구성 가능
          + Web Components를 활용하여 정적 페이지 내에 구현 가능
     * SPA가 적합한 경우
          + 미디어 플레이백 지속성:
               o 페이지 탐색 중 미니 플레이어 유지가 필요
               o SPA 기술 사용과 클라이언트 JS 크기 제한 관리
          + 오프라인 재생 지원:
               o 로컬 미디어 캐시를 관리하는 로직 필요
               o Zero, Y.js 같은 데이터 동기화 시스템 고려

  소셜 미디어 (Social)

     * 하이브리드 모델: 서버 소유 데이터 모델 기반의 적은 상호작용 + 간헐적 미디어 업데이트
     * 점진적 향상이 적합한 이유
          + 일반적 상호작용:
               o ""좋아요"" 클릭, 간헐적 업데이트 등
               o Hotwire 또는 HTMX를 사용한 하이브리드 방식이 적합
     * SPA가 적합한 경우
          + 깊은 상호작용 섬:
               o 드래프트 포스트 저장 등 클라이언트 캐싱 활용
          + 오프라인 지원:
               o HTML을 우선 전달하되 Service Worker를 통한 동기화 및 오프라인 로직 구현

  생산성 앱 (Productivity)

     * 문서 중심 생산성 앱은 복잡한 요구사항(협업 편집, 오프라인 지원, 경량 보기 모드)을 가짐
     * 로컬 데이터 모델과 SPA 기반 아키텍처가 적합할 수 있음
     * SPA가 적합한 이유
          + 빈번한 데이터 업데이트:
               o 키 입력, 마우스 드래그와 같은 작업에서 클라이언트 로직이 우위를 가짐
          + 성능 제약 관리 필요:
               o 초기 번들 크기 관리
               o 지연된 패키지 로딩 전략 적용

  기타 애플리케이션 클래스 (Other Application Classes)

     * 특정 요구사항:
          + 3D CAD, 프로그래밍 에디터, 게임 스트리밍, 웹 기반 게임, 미디어 편집, 음악 제작 시스템 등
          + 각 앱 클래스는 생산성 앱과 동일한 방식으로 신중히 평가 필요
     * 성공 요건:
          + 주요 사용자 경로 정의
          + 평균 세션 깊이 분석
          + 성능 보장 지표 설정
          + 핵심 스크립트 및 리소스 제어

  엔터프라이즈 소프트웨어에 대한 한마디

     * ""기업 비즈니스 앱""은 일반적으로 최악의 성능 문제를 초래
          + 대시보드, 워크플로 시스템, 기업용 채팅 앱 등이 대표적
     * 성능이 문화임:
          + 초기 로딩 시간과 상호작용 이후 성능 정의 및 측정 실패
          + 사용자를 무시하는 개발자 중심 문화가 독이 됨

""하지만…""

     * React를 포함한 특정 프레임워크에 얽매인 관리자는 종종 이러한 선택을 합리화하기 위해 다양한 논리를 펼침
     * 하지만 이 논의들은 사용자 경험을 중심에 두지 않으며, 이러한 결여는 반복적으로 나타남.

  ""...우리는 빨리 움직여야 해요""

     * 질문: ""그게 얼마나 오래 갈 거라고 보나요?""
     * 빠르게 개발한 NPM 기반 프로젝트는 접근성 문제, 저성능, 복잡성 증가를 초래하며, 결과적으로 속도는 감소.
     * 리메디에이션 비용: JavaScript 문제 해결에 수개월 소요되며, 기능 출시 속도는 더욱 감소.
     * 제품 시장 적합성(Product-Market Fit)을 위해선 접근성과 품질을 우선해야 함.
     * React를 사용해 ""빠르게 움직이자""는 선택은 장기적으로 비용이 더 많이 들며 성장을 방해.

  ""...페이스북에서 잘 쓰고 있잖아요""

     * 대부분의 기업은 페이스북과 같은 문제를 직면하지 않음.
     * Facebook도 React 사용으로 인한 성능 문제를 겪음, 하지만 독점적 지위를 통해 문제를 덮음.
     * 일반 기업은 Facebook의 사례를 무작정 따라가면 안 됨.

  ""...우리 팀이 React를 이미 알고 있어요""

     * React 개발자는 웹 개발자임. CSS, HTML, JavaScript, DOM 작업은 필수.
     * React는 기술 스택에서 대체 가능한 가장 단순한 계층.
     * Preact, Svelte, Lit, FAST 등 더 작고 빠른 프레임워크를 배우는 데 큰 장벽이 없음.

  ""...채용이 쉬워야 해요""

     * 현재 IT 업계는 우수한 개발자를 채용할 수 있는 절호의 기회.
     * React 지식은 채용의 기준이 될 수 없음.
     * React를 아는 개발자는 대부분 웹 표준도 쉽게 학습 가능.
     * 오히려 더 단순한 시스템이 높은 ROI를 제공.

  ""...모두가 빠른 휴대폰을 쓰잖아요""

     * 모바일 사용이 늘어난 지난 10년간, 클라이언트 리소스가 싸다는 전제는 이미 잘못된 가정.
     * 성능이 낮은 휴대폰 사용자도 제품의 주요 고객일 가능성 큼.
     * React를 선택함으로써 모든 사용자가 고가의 디바이스를 사용한다고 가정하는 건 위험.

  ""...React가 업계 표준이에요""

     * React는 일관된 표준이 아님.
          + React 자체의 방식(클래스 컴포넌트 vs 함수형 컴포넌트), 타입스크립트 사용 여부, 상태 관리 도구 선택 등 매 프로젝트마다 달라짐.
     * React 스택은 항상 변동적이며, ""표준""이라는 주장은 편안한 허구에 불과.

  ""...에코시스템…""

     * React와만 호환되는 라이브러리가 매우 드물며, 대부분의 도구는 Preact 등에서도 사용 가능.
     * 모든 NPM 패키지는 미래에 대한 기술적 부채로 작용.
     * CSS-in-JS와 같은 불필요한 의존성은 비용만 증가.

  ""...Next.js도 충분히 빨라요""

     * Next.js는 기본적으로 React의 성능 문제를 함께 가져옴.
     * HTML 우선 도구(예: Astro, 11ty)가 Next.js보다 더 나은 성능을 제공.
     * VC 지원 스타트업의 API에 락인되는 문제도 존재.

  ""...React Native!""

     * React Native는 모바일 앱을 느리게 만들고 유지 관리에 많은 비용을 요구.
     * PWA 및 Capacitor/Cordova를 사용하는 것이 더 나은 선택.
     * 페이스북도 React Native에서 벗어나고 있음.

   일반 기업은 Facebook의 사례를 무작정 따라가면 안 됨.
     * 페이스북도 React Native에서 벗어나고 있음.

   성능이 낮은 휴대폰 사용자도 제품의 주요 고객일 가능성 큼.
     * Service Worker를 통한 동기화 및 오프라인 로직 구현

   React Native는 모바일 앱을 느리게 만들고 유지 관리에 많은 비용을 요구.
     * Capacitor/Cordova를 사용하는 것이 더 나은 선택.

   ㅋㅋㅋㅋㅋㅋㅋㅋㅋ ㅋㅋㅋ

   모바일 앱을 RN이 느리게 만든다면서 왜 캐피시티왜 코도바를 추천하죠? Ui라도 네이티브로 보여주는 건 하이브리드 웹 보다 훨씬 성능적으로는 나은 접근이라 봅니다.

   슬프게도 한국 채용시장에서 ""프레임워크 주의가 통하지 않는다.""면 면접 광탈할 가능성이 매우 높을 겁니다. 많은 면접에서 프레임워크를 많이 써봐야만 아는 질문을 합니다.

   RN개발자 광광 우러요

   뭐 진지하게 달자면 RN은 js번들로 네이티브 컴포넌트 핸들하게 해주는데에 의미가 있는거라 pwa랑은 유즈케이스가 완전 다르죠.

   웹뷰로도 핸들하기 어려운 부분이 있는데 pwa? 장기적으로는 해당 방향으로 이어질거라고는 보지만 지금은 시기상조입니다. 애당초 의미없는 비교를 하고 있단 느낌이네요.

   맞아요. 본문은 거의 native 앱이 필요없다는 수준의 의견이네요.

   새로운 것에 호소하는 사람들이 있는 한 이런 문제는 반복될텐데요. 이미 리액트로 된 시스템이 있기 때문에 채용 문제를 간과해서는 현실이 바뀌지 않을겁니다. 페이스북이 리액트를 밀던 이유와 10년이 지나서 일반 기업에서 리액트를 선택하는 이유에는 차이가 있습니다

   아키텍처와 패러다임을 바꾸고자 하는 논의는 이것보단 신중하고 가능한 한 많은 사람을 설득해야 한다고 생각합니다

   그치만 preact도 react-like고 react 벗어나면 라이브러리 숫자가.....
   쓸만한 라이브러리처럼 보이면 다 react 전용인 vue 개발자는 웁니다

        Hacker News 의견

     * React 사용을 반대하는 이유가 대부분 잘못된 문제를 해결하려는 것이라고 생각함. 성능 문제는 실제로 큰 문제가 아님. 대부분의 경우 백엔드 개선이 더 효과적임
          + React가 구식 이벤트 시스템을 사용한다고 비판하지만, 이는 사용자에게 문제를 일으키지 않음. React를 완전히 버릴 이유는 아님
          + React 대신 사용할 대안을 제시하지 않아서 논의가 부족함. 대안이 React보다 나쁘다고 생각함
     * React와 jQuery가 인기를 얻은 이유는 코드가 깔끔하게 보이기 때문임. AngularJS 초기 코드 샘플은 보기 좋지 않음
          + React는 jQuery처럼 더 나은 대안이 나오면 대체될 것임. 코드 샘플이 예쁘게 보이는 것이 중요함
     * React의 핵심은 O(n) UI 상태를 함수형으로 렌더링할 수 있게 해주는 것임. 과거에는 O(n^2) 상태 전환을 관리하는 것이 복잡했음
          + React는 이러한 복잡성을 줄여주는 첫 번째 주류 도구였으며, 성공할 만한 가치가 있음
     * React를 계속 사용하는 이유는 Java처럼 안정적이고 성숙한 기술이기 때문임. 커뮤니티와 리소스가 풍부함
     * Alex의 글은 반복되는 논쟁에 대한 좌절감을 보여줌. 많은 사람들이 글을 끝까지 읽지 않음
          + 웹 성능에 대한 진실을 보지만 아무도 믿지 않는 Cassandra와 같음
     * React 개발자가 웹 개발자라는 말이 점점 맞지 않게 느껴짐. SPA React와 스타일링 프레임워크에만 익숙한 개발자가 많아짐
          + React를 사용하는 이유는 Facebook 때문이며, 많은 사람들이 이를 의심하지 않음
     * 대부분의 사이트는 SPA가 필요하지 않음. 하지만 많은 데이터가 필요한 비즈니스는 SPA가 유리함
          + NPM 패키지에 대한 비판이 많지만, 그 이유를 이해하려는 노력이 부족함
          + React는 프레임워크가 아닌 뷰 라이브러리임
     * React를 좋아하지 않음. 주로 백엔드 개발자로서 서버 생성 HTML과 약간의 JavaScript를 선호함
          + 새로운 프로젝트에서는 Elixir/Phoenix/LiveView와 HTMX를 고려 중임
     * 프론트엔드 개발이 JavaScript 프레임워크로 이동하는 이유는 유지보수 비용 때문임
          + 프론트엔드 빌드가 이미 프로세스에 포함되어 있으면 비용을 절감할 수 있음
          + SPA 패턴은 프론트엔드 빌드와 가장 잘 맞음
     * React에 대한 잘못된 비판이 많음. React 개발자는 새로운 템플릿 언어를 만들지 않고도 작업을 완료함
          + 웹사이트가 느린 이유는 React 때문이 아니라 개발자나 예산 부족 때문임

   글이 너무 길어서 주제의식이 흐려져있음

   글쓴이는 리액트를 쓰자는 의견을 무조건 프레임워크 주의에서 비롯된 것처럼 생각하는 것으로 보임

   프레임워크주의를 벗어나서 케이스별로 접근하자는 말을 하고나서 모든 종류의 엔지니어링 니즈에 대해서 레시피를 만들려고 하고 있음

   모든 예상반론에 대해서 다 대답하려는 과도한 대화 점유 시도가 돋보임. 반론에 대한 재반론이 너무 편협함.

   즉, 특정 케이스 이상을 넘어서 일반론을 다루는 토론을 수행하기에는 글쓴이가 갖춘 토론 태도와 기술이 매우 부족해보임

   그 결과 나는 리액트 사용을 좋아하지 않음에도 글쓴이의 일방적인 태도만으로 리액트 사용을 주장하는 사람들의 생각을 조금 더 들어보고 싶게 되었음

   일단 개인적으로 현재는 리액트가 최선이라고 생각해서 의견 드립니다

   웹개발 입문은 php jquery시절부터, 지금 일하는 회사에서 앵귤러JS, 앵귤러, 클래스 스타일 리액트, 훅 스타일 리액트 경험해본 입장으로는 먼저 써본 사람들의 시행착오와 라이브러리들이 갖춰진 다음에 기술스택을 바꾸는 것이 덜 머리가 아픕니다. 시맨틱 버전으로 따지면 최신버전 보다 하나 아래의 메이저버전을 사용하는 셈이죠. 요구사항과 고수준 기능은 변하지 않으니 문제가 없는데 기반기술에 대한 참고자료가 없으면 생산성이 나오지 않더군요. 또한 저희 회사 프로젝트 특성상 saas 서비스와 다르게 제품 사이클이 길고 메인터넌스만 하는 기간이 존재해서 더더욱이 최신기술을 적용하기가 어려웠습니다

   아마 리액트가 Next.js로 방향을 전환해서 SPA 지원을 종료하고 아키텍처 변경을 강제하는 시점에는 기술 전환을 다시 한번 고민해야 할 듯 합니다. Vue가 좀더 많이 보급되어 있으면 후보군에 당연히 올릴거구요. 안 쓸 이유가 없습니다

   잘 쓰고 있는데 억까 느낌이 없지 않아 있네요..이렇게 장황하게 적어놓으니 뭔가 큰 문제를 직면하게 한 것처럼 느껴라라는 느낌..
"
"https://news.hada.io/topic?id=18111","미국 경제의 경쟁국 대비 급성장 이유","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          미국 경제의 경쟁국 대비 급성장 이유

미국 경제의 고성장 원인과 도전 과제

  미국 경제의 독보적 성장

     * GDP 증가: 팬데믹 이후 11.4% 성장, 2024년 IMF 전망치 2.8%
     * 생산성 격차:
          + 2008-09 금융위기 이후 30% 증가, 유로존과 영국의 3배
          + 일본과 영국은 최근 5년간 GDP 3% 성장에 그침
          + 유로존 생산성 성장률: 2007년 이전 5.3% → 2019년 이전 2.6% → 최근 0.8%

  기술 중심의 생산성 성장

     * 실리콘밸리의 생태계:
          + 혁신, 투자, 멘토링 시스템이 창업 지원
          + AI 및 기술 중심 투자 급증, 미국이 세계 VC 투자액의 83% 차지
     * 주요 산업에서의 우위:
          + 소프트웨어, 컴퓨터 서비스 부문에서 압도적 투자
          + 유럽은 이 부문에서 기술 및 투자 부족으로 뒤처짐

  글로벌 생산성 격차

     * 유럽과 일본의 과거 성장:
          + 1980년대까지 유럽과 일본의 생산성은 미국을 앞섰으나, ICT 혁명 이후 미국이 주도
     * 투자 부족:
          + 유럽 및 일본: 기술 확산 부족과 투자 저조
          + 유럽연합: R&D 및 대학 지원 부족, 규제 과잉
     * 다른 국가의 문제:
          + 캐나다: 16분기 중 14분기 동안 생산성 감소
          + 유럽: 분열된 시장과 보수적 투자 환경

  미국의 성장 동력을 위협하는 요소

     * 트럼프 정책의 영향:
          + 이민 제한, 관세 정책, 부자 감세는 장기적 생산성에 부정적
          + 연방 부채 증가로 투자 여력 약화 가능성
     * 미래 전망:
          + 높은 금리와 인플레이션이 투자를 억제할 가능성

  세계 경제가 직면한 과제

     * 유럽과 일본의 대응 노력:
          + 유럽연합: €8000억 연간 투자 필요 (GDP의 4.7%)
          + 일본: 칩 생산과 AI에 $130억 투자
          + 영국: 생산성 향상을 위한 £1000억 추가 투자
     * 미래 지향적 정책 필요:
          + R&D 투자 확대, 규제 완화, 대학 지원 증가
          + 기술 및 방위 투자 간 균형 필요

  결론: 미국의 선두 유지

     * 미국의 강점:
          + 혁신을 촉진하는 생태계와 투자자들의 높은 위험 감수
          + 생산성 개선을 통한 경제적 번영 지속
     * 글로벌 경쟁 전망:
          + 미국은 10년 후에도 G7 국가 중 가장 빠른 성장 예상
          + 다른 국가들은 높은 경제 불확실성과 제한된 투자 자원으로 인해 뒤처질 가능성

        Hacker News 의견

     * 경제가 강하다고 말하는 것은 오해의 소지가 있음. 많은 사람들이 월급으로 생활을 이어가고 있음
     * 일부 기업은 번창하고 있지만, 직원들은 그렇지 않음
     * GDP PPP에 따르면 미국은 경쟁국들에게 추월당하고 있음. 중국은 이미 앞서 있다고 주장하고 있으며, 인도도 경제적 우위를 차지할 준비가 되어 있음
          + 아시아는 역사적 교훈을 바탕으로 군사력을 강화할 것으로 예상됨
          + 미국이 유럽과 비교하면 괜찮지만, 유럽은 경제력에서 중국에 밀리고 있음
     * Vinod Khosla는 GDP 대신 하위 50% 인구의 총소득을 측정하고 정책을 최적화해야 한다고 주장함
     * 기술이 문제임. 인터넷은 글로벌하며, 승자가 모든 것을 차지함. 글로벌 가치 창출은 미국 주식 시장에서 수익화되고 있음
     * 미국의 정부 부채가 120%로 매우 높으며, 최근 성장은 이 부채에 의해 촉진되었음
          + 미국은 적자를 감당할 수 있지만, 영원히는 아니며, 언젠가는 지출을 줄이고 부채를 갚아야 함
     * 미국에서 노숙자가 증가하고 있으며, 부자는 더 부유해지고 가난한 사람은 더 가난해지고 있음
     * 미국 시장은 4억 명의 영어 사용자가 있으며, 단일 법률 체계를 가지고 있어 유럽보다 큰 이점을 가짐
     * 젊었을 때 미국으로 이주하고 싶었지만, 지금은 많은 창의적인 장소가 사라졌거나 건강하지 않은 상태임
          + 지루한 기술 회사들이 주도하고 있으며, 종종 웹사이트로 시작했음
"
"https://news.hada.io/topic?id=18062","LLM 구축은 아마도 훌륭한 사업이 되지 못할 겁니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     LLM 구축은 아마도 훌륭한 사업이 되지 못할 겁니다

     * 대형 언어 모델(LLM)은 혁신적이고 많은 사람들이 ""미래""로 여김
     * 그러나 ""LLM 구축""이 반드시 수익성 있는 사업이 될 가능성은 낮음
     * 기술의 혁신은 성공했지만 투자자들에게는 실패로 이어진 사례와 유사
          + 1960년대 항공사는 미래였고 멋져보여서 영화에도 많이 나왔지만 수많은 항공사가 망했음. 시대가 변했음에도 항공사 설립은 좋은 생각이 아님
          + 철도는 수많은 사람의 삶을 개선했지만, 투자자들은 ""극적인 폭락""으로 보상을 받았음
     * 겉보기에는 정말 단순해 보이는 다른 사업들이 훨씬 더 수익성이 높음
     * 예를 들어, 탄산음료 판매는 놀랍게도 엄청난 사업임. 어쩌면 가장 성공적인 사업일지도 모름
          + Coca-Cola의 자기자본이익률(ROE)은 대부분의 해에 30% 아래로 떨어진 적이 거의 없음
          + 이는 항공업처럼 어렵고 복잡한 사업이 아닌, 비교적 간단한 음료 제조로 이러한 성과를 낸다는 점에서 다소 불공평하게 느껴질 수 있음
          + 더 흥미로운 점은 Coca-Cola가 실제로 음료를 제조하지도 않는다는 것임
          + 제조는 ""병입 회사""에 외주를 맡기고, 실제로는 단순히 제품을 판매하기만 함

항공업 - 불리한 산업구조

     * 항공사가 된다는 것은 거의 유일무이하게 ""끔찍한 시장 위치""에 처하게 됨
     * 제한된 공급자: 항공기 제조사는 Airbus와 Boeing 두 곳뿐임. 교육 및 직원 효율성의 이유로 둘중 하나를 선택해야 하기에 비행기 제조업체가 높은 가격 결정력을 가짐
     * 변덕스러운 고객: 항공권 구매자는 변덕스럽고 충성도가 낮으며, 약간의 가격 차이로도 쉽게 다른 항공사로 이동함
     * 업계 경쟁 과다: 짜증스럽게도 동일 노선을 운영하는 항공사가 많아 치열한 가격 경쟁이 발생함
     * 신규 진입 용이:
          + 새로운 항공사를 시작하는 것이 의외로 쉬움
          + 항공기는 자산 가치가 높아 은행 대출이 용이
          + 숙련된 직원 채용이 쉬워 새로운 항공사가 시장에 쉽게 진입
          + 신규 항공사는 초기 손해를 감수하며 낮은 가격에 항공권을 판매하다 결국 파산하기도 함
     * 대체재 다수 존재: 정부 보조를 받는 ""고속철도""나 화상회의 플랫폼(Zoom) 등으로 대체 가능
     * 가치 창출 제한: 게다가 항공사가 효율성을 높이거나 혁신을 통해 수익을 올려도, 비행기 제조사들이 이를 감지하여 서비스 계약 갱신 시 가격을 인상해 추가 이익을 흡수함

탄산음료 산업의 유리한 구조

     * 코카콜라 회사가 되는 것은 꽤 대단한 일임
     * 공급자의 힘
          + 콜라에는 물, 색소, 향료, 카페인, 감미료 등 모두 저렴하고 쉽게 구할 수 있는 재료만 들어있음
          + 직접 결합할 필요도 없이 병입 회사에 외주를 맡겨 최소한의 비용으로 생산 가능
     * 구매자의 강한 브랜드 충성도:
          + 소비자는 입에 넣는 음식에 대해 까다로움
          + 주요 경쟁사의 비공식 모토가 ""Pepsi도 괜찮지 않나요?(Is Pepsi Ok?)""일 정도로, 소비자들이 명확한 선호도를 보임
          + 이는 맛과 색이 동일함에도 불구하고, 적지 않은 소비자들이 실제로 ""아니요""라고 답한다는 점에서 주목할 만함
     * 신규 진입 장벽:
          + ""Coke""라는 이름은 상표권으로 보호되므로 새로운 경쟁자는 동일 이름 사용 불가
          + 소비자는 새로운 브랜드의 탄산음료를 거부하며, 대체 브랜드 음료를 마시는 것을 이상한 행동으로 여김

산업 구조가 사업 성공을 좌우함

     * 좋은 비즈니스는 내부 효율성, 열정, 혁신, 사람들이 얼마나 똑똑한지 같은 요소보다 산업 구조에 의해 결정됨
     * 마이클 포터의 ""5가지 힘(5 Forces)"" 프레임워크에 따르면, 산업 구조는 아래 다섯 가지로 구분됨:
          + 공급자의 힘(가격 결정력)
          + 구매자의 힘(가격 협상력)
          + 직접적인 업계 경쟁자의 힘
          + 신규 진입 업체의 잠재력/위협
          + 대체재의 위협
     * 어느 힘도 당신에게 크게 반대로 작용하지 않는다면 당신의 비즈니스는 잘 될 것
          + 모든 힘이 당신에게 반대라면 당신은 항공사의 입장이 될 것
          + 그리고 모든 힘이 여러분에게 유리하다면 당신은 코카콜라가 되는 것

LLM 제작자의 산업 구조: OpenAI/Anthropic/Gemini 등

     * LLM 제작자들의 위치는 좋은가? 그렇지 않음
     * 공급자의 힘: NVIDIA의 지배적 위치
          + LLM 제작자들은 때때로 Amazon Web Services(AWS), Google Cloud 같은 클라우드 업체를 공급자로 언급하지만, 실제로는 NVIDIA가 유일한 핵심 공급자임
          + NVIDIA는 모든 LLM이 사용하는 칩을 독점적으로 생산하며, 막대한 가격 결정력을 가짐
          + NVIDIA는 Anthropic이나 OpenAI에 대해 Airbus나 Boeing보다 훨씬 강력한 지위를 가짐
     * 구매자의 협상력: LLM토큰 가격에 대해 가진 힘은?
          + LLM 사용자들은 아직 브랜드 충성도가 낮아, Chat-GPT에서 Claude로 쉽게 전환 가능
          + 기업들은 추상화 레이어를 통해 LLM 모델 간 전환을 쉽게 만들어, LLM을 상호 교환 가능한 상품으로 만듦
          + 이는 LLM 판매자에게 불리하게 작용
     * 강력한 직접 경쟁자들
          + 다수의 LLM 제작자가 존재하며, 가격 경쟁이 치열함
          + 가장 안좋은 건 Facebook이 사실상 무료로 모델을 배포하며 시장 가격을 낮추고 있음
          + 이는 1990년대 Internet Explorer의 시장 점유 전략과 유사하며, 긍정적 징후로 보기 어려움
     * 신규 진입 용이성
          + LLM 제작 기술은 논문을 통해 공개되어 있어 신규 진입자가 쉽게 모델을 개발 가능
          + 낮은 품질의 모델이라도 저렴한 가격으로 고객을 확보할 수 있어 신규 진입이 활발함
     * 대체재의 혼재된 상황
          + LLM이 작성한 텍스트 대신 사람을 고용할 수 있지만, 이는 비용이 더 높고 환각(hallucination) 문제를 피할 수 있다는 장점이 있음
               o 예: 법률 분야는 LLM 사용 가능성이 낮음
          + 특정 사용 사례가 확립되면 메타데이터가 AI를 대체하는 경향이 있음
     * 약간 긍정적인 점 하나만으로는 수익성 있는 비즈니스가 될 수 없음
          + LLM 제작자들의 산업 구조는 Netscape(그래픽 웹 브라우저를 발명했지만 파산)와 유사하며, 웹 브라우저 위에서 돌아가는 뭔가를 만든 Google처럼 성공적인 비즈니스 모델로 보기는 어려움

어떻게 이렇게 많은 자금을 유치할 수 있는가?

     * LLM 제작자들이 항공사와 비슷한 불리한 산업 구조를 가지고 있음에도 불구하고, 어떻게 이렇게 막대한 자금을 유치할 수 있을까?
     * 예를 들어, OpenAI는 불과 두 달 전 157억 달러 가치로 66억 달러($6.6bn)를 조달함
     * 이는 VC 역사상 최대 규모의 투자일 가능성도 있음
     * 그들은 내가 모르는 것을 알고 있을까? 미스터리이지만 몇 가지 옵션을 고려해 보면:
          + NVIDIA 의존도를 낮추기 위한 칩 개발
               o OpenAI가 자체 칩을 설계해 NVIDIA에 대한 의존도를 줄이고 GPU 사용 비용을 절감하려 할 가능성 있음
               o 그러나 66억 달러는 새 반도체 공장을 설립하기에는 부족하지만, NVIDIA에서 마이그레이션할 수 있는 새로운 칩을 설계하는 데는 충분할 수 있음
               o 하지만 NVIDIA 자체가 이번 투자 라운드의 일부 투자자로 참여했으므로, ""NVIDIA 경쟁 칩 개발""은 투자용 피치 덱에 포함되지 않았을 가능성이 높음
          + OpenAI 브랜드 강화를 통한 경쟁 방지
               o 고객이 경쟁 모델로 쉽게 전환하지 않도록 강력한 브랜드를 구축하려는 의도로 볼 수 있음
               o 기술 분야에서는 브랜드와 락인(lock-in) 전략이 효과적일 수 있다는 증거가 존재함
               o 그러나 LLM은 단순한 텍스트 기반 인터페이스로 작동하므로, 강력한 API가 없어 브랜드 구축이 어려운 측면이 있음
          + 신규 경쟁자 퇴출
               o 66억 달러를 투자해 모델 성능을 크게 개선할 경우, 경쟁자의 비용 부담을 높이고 소규모 경쟁자를 시장에서 퇴출시킬 가능성 있음
               o 하지만 자금은 가장 유동적인 자산이며, 66억 달러가 그렇게 많은것이 아님
                    # 은행권에서는 단일 채권 발행으로도 이 정도 자금을 조달할 수 있음
               o 따라서 이번 라운드는 그 자체만으로는 다른 사람들을 설득하기에 충분하지 않을 것
     * 막대한 자금을 조달한 기업이 반드시 성공적인 사업 모델을 보유한 것은 아님
          + 예를 들어, WeWork는 100억 달러 이상의 자금을 조달하고 한때 470억 달러의 가치를 평가받았으나, 비즈니스 모델이 타당하지 않음이 드러남
          + 최근 재정 구조 조정에서 가치가 5억 6천만 달러로 평가되며, 투자 가치의 95% 이상이 증발함

모든 AI 회사가 실패하는 것은 아님

     * LLM 제작자의 사업성이 부족하다고 해서 AI 기술의 미래가 어두운 것은 아님
     * 기술이 나쁘다는 의미는 아님: 기술 성공과 사업 성공은 별개
          + 이 기술이 좋은 기술이 될지 아닌지는 Open AI/Anthropic/Mistra/누구든지 이 기술로 돈을 버는지와는 거의 무관함
          + 기술이 발전해도 반드시 수익성이 보장되지는 않음
               o 컨테이너 가상화 기술: Docker는 기술적으로 성공했지만 수익화에는 실패
               o 웹 브라우저: 고도로 발전된 소프트웨어지만, 브라우저 제작은 비즈니스로는 성공적이지 않음
               o CRM은 끔찍함에도 불구하고 Salesforce는 사업적으로 큰 성공을 거둠
     * 모든 AI 회사가 모델 구축을 하는 것은 아님
          + 만약 내가 AI 비즈니스를 한다면 절대 모델을 구축하지 않을 것
          + 자체 모델 구축은 차별화되지 않은 주먹구구식 작업임
          + Anthropic 등에서 개발한 고급 모델의 일부를 활용하면, 과거에는 불가능했던 사업 아이디어를 실현 가능

소프트웨어 회사가 아닌 소프트웨어 회사를 경계할 것

     * 소프트웨어 회사는 본질적으로 훌륭한 사업 모델을 가짐:
          + 공급자 의존도 없음: 실질적인 공급자가 존재하지 않음
          + 제품의 고유성: 소프트웨어는 종종 독창적이며 경쟁자가 적음
          + 대체재 부족: 대안은 사용자가 스스로 작업을 수행하는 것뿐
          + 이러한 이유로 소프트웨어 회사는 높은 이윤율을 유지함
     * 문제는 모든 기술 회사가 소프트웨어 회사는 아님
          + NVIDIA처럼 강력한 단일 공급자에 의존할 경우, 경제 구조는 Microsoft Office보다는 Pan-Am(파산한 항공사)을 닮아감

기타 메모

     * AI 안전성 운동과 LLM 기술 마케팅:
          + AI 안전성 운동은 LLM 기술에 대한 훌륭한 마케팅 역할을 함
          + ""AI 위기가 임박했다""는 식의 과장된 주장은 사실상 효과적인 제품 홍보 전략으로 작용
          + 이러한 이유로 OpenAI와 같은 기업들이 많은 AI 안전성 전문가를 고용하는 것으로 보임
     * Coca-Cola와 연구 투자:
          + Coca-Cola는 주로 앉아서 막대한 수익을 올리지만, 수익의 일부를 연구에 투자함
          + ""조금의 투자""라도 워낙 큰 수익을 올리기에 그 금액은 상당함
          + 시장 조사 결과, Coke Zero는 남성을 타깃으로 한 Diet Coke라는 점이 드러남. 이는 성별에 따른 제품 분리가 효과적이라는 것을 보여줌
     * 산업 구조 및 시장 전략에 대한 추가 읽기:
          + 마이클 포터의 2008년 개정판 ""The Five Forces that Shape Corporate Strategy(기업 전략을 형성하는 다섯 가지 힘)""를 참고할 것을 권장
          + 위 글은 마지막 답변은 아닐 수 있지만, 더 많은 것을 배우기 위해 읽어야 할 첫 번째 글로 적합함. 포터의 다른 글들도 유용할 수 있음

   Netscape가 그래픽 웹 브라우저를 발명한 것은 아니죠. Mosaic이 있는데...

   항공산업은 hw가 중요하며, sw에는 한계가 있음. (해봤자 스튜어디스)
   인공지능은 sw에 우위가 있음. 현재는 모델을 논문으로 다 공개해서 경쟁력이 없어보이지만 진짜 쓸모있는 모델은 비공개 할꺼임. 혹은 라이센스사업을 하던가.

   지금이야 경쟁이지만, 독점이 된다면, 어마어마한 수익을 쌓을 수 있겠죠. 미래는 알 수 없습니다.
"
"https://news.hada.io/topic?id=18107","OpenTTD는 Transport Tycoon Deluxe를 기반으로 한 오픈 소스 시뮬레이션 게임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        OpenTTD는 Transport Tycoon Deluxe를 기반으로 한 오픈 소스 시뮬레이션 게임

     * OpenTTD 14.1
          + OpenTTD 14가 출시된 이후 많은 플레이어들이 게임을 즐겼음
          + 지난주에만 설문조사에 참여한 플레이어들이 17,219개의 게임에서 총 34,700시간을 플레이했음
          + 이 과정에서 몇 가지 버그가 발견되었고, 이를 수정하기 위해 노력했음
          + OpenTTD 14의 첫 번째 유지보수 릴리스에서는 멀티플레이어 비동기화 버그를 수정하고, 새로운 선박 경로 탐색기와 비집중화 기능의 몇 가지 문제를 해결했음
          + 다른 여러 버그 수정 사항은 변경 로그에서 확인 가능
          + 다운로드, 변경 로그, 버그 추적기 링크 제공

        Hacker News 의견

     * OpenTTD의 성공 요인은 게임이 처음부터 바로 플레이 가능하게 만든 점임. 대부분의 오픈 소스 게임 리메이크는 엔진만 제공하고, 그래픽, 예술, 사운드, 음악 자산이 필요함. OpenTTD도 처음에는 그랬지만, 원본 게임에서 빠르게 독립하는 것을 목표로 했음. 2004년에 출시되었고, 2007년에 그래픽 교체 프로젝트가 시작되어 2009년까지 모든 스프라이트가 완성되었음. 이제는 원본 게임 파일이 필요하지 않음
     * OpenTTD는 Steam과 GOG에서 게임을 출시할 수 있게 했음
     * 원본 Transport Tycoon에서는 맵의 한쪽 끝에서 다른 쪽 끝까지 터널을 건설하면, 금액이 너무 커져서 정수 오버플로우가 발생함. 그래서 캠페인을 수십억 달러로 시작할 수 있음
     * OpenTTD를 게임에서 연구/실험을 위한 더 진지한 시스템으로 전환하기 위한 래퍼를 개발 중임. 특히 AI 시스템을 활용하고 있음
     * OpenTTD 프로젝트는 Emscripten을 통해 웹 브라우저 빌드를 지원함. 공식적으로 호스팅된 버전을 찾을 수 없어 개인적으로 사용 중임. 기본적으로 사용 가능하지만 오디오 문제 있음. 클라우드 저장 기능 추가 계획 중임
     * OpenTTD의 창립자 중 한 명은 Ludvig Strigeus임. uTorrent의 창시자이며, Spotify의 주요 인물 중 한 명이고 Polhem Prize 수상자임
     * 원본 Transport Tycoon은 개인적으로 가장 좋아하는 DOS 게임 중 하나였음. 몇 년 동안 크리스마스 전통으로 현대 하드웨어에서 OpenTTD 프로젝트를 통해 게임을 다시 플레이했음. 크리스마스 기간을 더 견딜 수 있게 해줌
     * 약 15년 동안 OpenTTD를 간헐적으로 플레이해왔음. Chris Sawyer의 천재성을 보존하고 원본을 모욕하지 않으면서 자연스럽게 확장하는 놀라운 방법임
     * 친구와 함께 ""German Reunification""이라는 지도를 만들었음. 1989년까지의 분단과 이후의 통일을 시뮬레이션함. 실제 고도 데이터와 도시 좌표를 사용하여 제작됨
     * 오늘 게시된 이유는 최근 Transport Tycoon의 30주년이었기 때문이라고 추측함
     * 어린 시절 TT(비-디럭스) 데모를 반복해서 플레이했음. 성인이 되어 OpenTTD를 발견했을 때 매우 기뻤음. 수많은 시간을 투자했고, ppc64le에서도 빌드 및 실행 가능함
"
"https://news.hada.io/topic?id=18005","AI 최신 동향에 빠르게 적응하려는 소프트웨어 엔지니어를 위한 추천 요청","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                AI 최신 동향에 빠르게 적응하려는 소프트웨어 엔지니어를 위한 추천 요청

     * AI 분야의 최신 동향을 파악하고자 하는 사용자가 있음
     * ChatGPT를 거의 매일 사용하고 있으며, 작년에 OpenAI API 3.5를 사용한 경험이 있음
     * AI 관련 업데이트를 위해 HN과 같은 기술 블로그를 찾고 있음
     * https://simonwillison.net/를 발견했으나, 내용이 단편적이라고 느낌

        Hacker News 의견

     * 모델을 훈련하는 방법보다는 모델을 사용하는 방법과 작동 원리를 배우는 것이 중요함
          + Jeremy의 ""Hacker's Guide to LLMs""와 Karpathy의 ""State of GPT"" 추천
          + 3b1b의 LLMs와 transformers 시각화 영상도 유용함
          + ChatGPT 훈련 과정과 AI의 개요를 다룬 영상도 참고할 만함
          + Nicholas Carlini의 LLMs 활용 방법도 흥미로움
          + 최신 정보를 얻기 위해 OpenAI, Anthropic, Google DeepMind, xAI의 인물들을 X/Twitter와 Bluesky에서 팔로우할 것을 권장함
          + ""No Priors"", ""Generally Intelligent"", ""Dwarkesh Patel"", ""Sequoia's Training Data"" 등의 팟캐스트도 추천함
     * Kaggle 대회 참여를 통해 AI에 대한 직관적 이해를 얻었음
          + 특정 목표와 데이터셋 제공이 문제 해결을 더 쉽게 만듦
          + Simon의 블로그는 소프트웨어 엔지니어에게 유용함
     * ""OpenCV University""의 YouTube 재생목록을 통해 컴퓨터 비전을 공부 중임
          + CNN에 대한 깊이 있는 이해를 얻었고, 최근 프로젝트에 적용 중임
          + 수학적 배경이 부족해도 쉽게 접근할 수 있는 학습 경로임
     * 매일 또는 매주 최신 정보를 업데이트하는 것은 비효율적일 수 있음
          + 6-12개월마다 한 번씩 업데이트하는 것이 더 나음
     * 최첨단 모델 작업을 직접 수행하며 가이드북을 작성함
          + 개념과 실습 코드, 학습 자료 링크가 포함되어 있음
     * LLMs와 신경망의 기본 원리에 대한 자료를 제공함
          + 최신 비디오 카드 소프트웨어에 대한 이해가 부족함
          + GPU에 대한 의존도가 높아 다양한 머신러닝 접근법이 간과되고 있음
          + AI 민주화를 위해 더 나은 언어와 하드웨어가 필요함
     * Matt Berman, AI 요약 뉴스 다이제스트, Rick Lamers의 자료를 팔로우함
          + FreeCodeCamp의 새로운 짧은 코스도 추천함
     * 최신 정보를 얻기 위해 기술 블로그보다는 안정적인 디퓨전과 로컬 라마 서브레딧을 추천함
          + Andrej Karpathy의 YouTube 채널도 유용함
"
"https://news.hada.io/topic?id=18024","환경 내 미세플라스틱의 4분의 1을 배출하는 자동차 타이어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    환경 내 미세플라스틱의 4분의 1을 배출하는 자동차 타이어

   죄송하지만 요약할 내용이 없습니다.

        Hacker News 의견

     * 친구와 전기차(EV)의 무게에 대해 이야기했는데, 내 전기차가 친구의 BMW 3보다 무겁다고 생각했음. 하지만 BMW가 더 무거웠음. 평균적으로 전기차가 내연기관차(ICE)보다 무거울 수 있지만, 전기차가 대체한 차량과 비교하면 크게 무겁지 않을 수 있음. 이전에 타던 Subaru Outback도 더 무거웠음
     * 차량의 무게에 따라 세금을 부과하는 것은 적절하지 않다고 생각함. 오염이 타이어에서 발생한다면 타이어에 세금을 부과해야 함. 타이어에 포함된 화합물에 따라 세금을 부과해야 함
     * Formula 1 경주를 한 세트의 타이어로 진행하게 하여 오염이 아닌 해결책을 찾도록 해야 함
     * 1980년대 로스앤젤레스 분지의 오염 연구에 따르면 매일 5톤 이상의 호흡 가능한 타이어 먼지가 대기 중으로 방출되었음. 이 수치가 줄어들지 않았을 가능성이 큼
     * 제조업체가 그들의 부정적인 외부 효과에 대해 비용을 지불해야 함
     * 사람들에게 이 문제를 알리려고 하지만, 사람들은 자동차에 집착하고 이 문제가 실제로 문제라는 것을 부정함
     * Waymo가 수집한 타이어 마모 데이터를 보고 싶음. 무거운 차량임에도 불구하고 급정거나 급출발이 없고, 속도 제한을 지키며, 적절히 공기압을 유지하고, 주행을 최적화하여 관성을 유지하는 등으로 타이어 마모가 적을 것이라고 생각함
     * 타이어 먼지가 어린 연어의 대규모 폐사를 초래함. 특정 독성 화합물이 포함되어 있으며, 비가 많이 올 때 도랑의 먼지가 강과 하천으로 씻겨 내려가 물고기를 죽일 정도로 높은 농도로 유입됨
     * 타이어에 포함된 독성 화합물은 제거하거나 대체할 수 있는 첨가제임
     * 이전 주제의 스레드에서 타이어 산업에서 일했던 누군가가 작은 첨가제가 문제를 크게 해결할 수 있다고 주장했음
     * 소음 공해도 문제임. 전기차도 무겁고 타이어 마모가 많아 중고속 주행 시 큰 소음을 발생시킴
     * 타이어는 대부분의 사람들의 삶에서 필수적인 부분이며, 자동차가 없는 도시 사람들도 바퀴가 달린 차량에 크게 의존함
     * 환경에 미세플라스틱을 배출하는 다른 행동을 중단해야 함
     * 소비자가 이 문제를 해결할 수 있는 실제 노력이 있는지 궁금함. 더 비싼 타이어를 사는 것이 미세플라스틱 배출을 줄일 수 있지만, 실제로 그런 기회가 있는지 모르겠음
"
"https://news.hada.io/topic?id=18103","IMG_0001","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                IMG_0001

     * 2009년부터 2012년까지 iPhone의 사진 앱에는 ""YouTube로 보내기"" 버튼이 내장되어 있었음
     * 많은 업로드가 기본 IMG_XXXX 파일명을 유지하여 무작위 삶의 순간을 담은 타임 캡슐을 형성함
     * Ben Wallace에게 영감을 받아 YouTube를 크롤링하는 봇을 만들어 500만 개의 이러한 비디오를 찾았음
     * 무작위로 정렬된 IMG_XXXX 비디오를 시청 가능

   아주 오랜만에 날 것 그대로의 낯선 영상들을 보게 되었네요

        Hacker News 의견

     * 뷰 카운트가 포함된 미니멀한 UI가 마음에 듦. 오래된 홈 비디오를 처음 보는 것은 친밀하고 흥미로움. Google이 11년 된 비디오를 지연 없이 제공하는 것에 감탄함
          + TikTok의 알고리즘 없이 다양한 비디오를 보는 것이 신선하고 인간적임
     * 웹2 시대의 인터넷을 떠올리게 하는 콘텐츠임. 사람들이 자신의 삶을 공유하는 모습이 좋음
          + 가족의 동물원 방문, 아버지가 아이를 간지럽히는 장면, 중학교 연극 리허설 등 다양한 비디오를 보며 즐거움을 느낌
     * 사람들이 무심코 올린 비디오가 갑자기 인기를 얻는 상황을 상상하게 됨. 이는 YouTube의 규모와 대부분의 비디오가 주목받지 못하는 현실을 보여줌
          + 마케팅 기술과 비디오 편집 기술의 상관관계가 적음을 보여줌. 흥미로운 비디오가 제목이나 썸네일 부족으로 주목받지 못하는 경우가 많음
     * 비슷한 웹 앱을 개발 중이었으나 UI를 과도하게 설계하여 실패함. 다른 사람이 먼저 성공한 것을 축하함
     * 전 세계 사람들의 다양한 비디오를 보는 것이 비인간적일 수 있지만, 오히려 그렇지 않음. Beme의 관리자 뷰를 떠올리게 함
     * 많은 사람들이 자신의 비디오가 공개될 수 있다는 것을 이해하지 못했을 수 있음. 기술에 대한 이해가 부족한 사람들이 많음
     * Ralph Stanley의 공연을 녹화한 비디오를 발견함. 음악 거장을 직접 보는 것이 중요하다는 것을 깨달음
"
"https://news.hada.io/topic?id=18066","Show GN: 셀렉트 어드민 - 선언적 방식(YAML)으로 관리자 UI, API 만들어주는 프로젝트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Show GN: 셀렉트 어드민 - 선언적 방식(YAML)으로 관리자 UI, API 만들어주는 프로젝트

   아무리 잘 만들어도 몇년 지나면 레거시가 되는 관리자페이지..
   또 매번 만드는 신규 프로젝트 어드민을 고민하다가 시작했습니다.

   단순한 CRUD 성격에 가깝지만 어드민은 몇 년은 거뜬히 써야하기때문에 그때그때 프론트 뭐쓸지 API 뭘로 만들지 고민하게 되더라구요.

   그러다가 2021년 10월부터 ""자주쓰는 기능을 YAML로 녹여보자"" 시작하고 벌써 3년이 넘었습니다! (좀만 더 준비하고 올려야지 하다가 시간이 이렇게 되었네요)

   기능
     * 메뉴, 페이지, 쿼리, API 입력하면 그에 따른 화면과 입력폼, 버튼이 만들어집니다.
     * 회원관리, 로그인, 권한, 로그, 모달, 컨펌, 토스트 등등 이미 들어가있어요.
     * 클라우드 서비스도 있고 (vercel처럼 배포 고민없이 올리기!), 직접 CLI로 로컬에 띄울 수 있어요.

   왜 YAML인가요?
     * 세상의 모든 UI를 스펙(YAML, JSON)으로 녹이는건 불가능하지만 '자주쓰는 기능만'은 가능해보였어요.
     * 보통 주업무가 있어서 하루종일 어드민만 고치지 않기때문에, 어느정도 문서화/인수인계/테스트 친화적인게 필요했고 YAML은 거기에 딱이었어요.
     * git에 올리거나 공유, copy & paste가 편했어요.

   너무 나만의 문제가 아닐까? 고민 많이했는데. 결과적으로 많은 회사/팀들이 어드민 문제를 해결하고 계셔서 너무나 고맙고 책임감을 느끼고 있습니다.

   그동안 GeekNews에는 올리지 않아서 이번에 올립니다!

   어드민 페이지로 시작해서 사내 사이트로 뻗어나가면 되겠네 생각했는데 이미 실천하고 계시네요. 응원합니다.

   요런것도 있어요.
   https://www.getmotoradmin.com/

   아이디어는 훌륭하다고 생각합니다만, 보안정책상 어드민을 외부 SaaS로 이용한다는 게 가능한 일인지 잘 모르겠습니다.

   맞아요ㅠ 진짜 괜찮아보이는데 외부 SaaS라고 도입 반려당한 케이스가 여기있습니다..

   매력적인 제품같아 보이는데, 제가 현재 속한 분야와 거리가 있어서 사용을 할 수 없어서 아쉽네요

   해외에는 꽤 있는데 국내는 아직 몇개 없는듯해요.

   (참고차 정보 공유)

   retool
   좋지만 사용자가 늘면 비쌈. 드래그&드롭이 좋다면 좋음

   airplane.dev
   좋았지만 사라짐 (GeekNews에도 올라왔어요.)

   appsmith
   오픈소스 대안
"
"https://news.hada.io/topic?id=18077","손글씨가 뇌의 광범위한 연결성을 촉진함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         손글씨가 뇌의 광범위한 연결성을 촉진함

     * 전통적인 손글씨가 디지털 기기로 점차 대체됨에 따라, 인간 뇌에 미치는 영향을 조사하는 것이 중요함.
     * 36명의 대학생을 대상으로 디지털 펜을 사용하여 시각적으로 제시된 단어를 손으로 쓰고, 키보드로 타이핑할 때의 뇌 전기 활동을 기록함.
     * 256채널 센서 배열을 사용하여 EEG 데이터를 통해 연결성 분석을 수행함.
     * 연구 결과
          + 손으로 글을 쓸 때, 뇌의 연결성 패턴이 키보드로 타이핑할 때보다 훨씬 복잡함.
          + 두정엽과 중심 뇌 영역의 네트워크 허브와 노드 간의 세타/알파 연결성 일관성 패턴이 광범위하게 나타남.
          + 기존 문헌에 따르면 이러한 뇌 영역과 주파수의 연결성 패턴은 기억 형성과 새로운 정보 인코딩에 중요하며, 학습에 유익함.
     * 결론 및 제안
          + 손글씨는 시각 및 고유수용감각 정보(세밀하게 제어된 손의 움직임)를 통해 학습에 유리한 뇌 연결성 촉진
          + 결과적으로 뇌의 학습 최적화 조건 제공
          + 어린 시절부터 학교에서 손글씨 활동에 노출되어야 하며, 이는 학습에 최적의 조건을 제공하는 신경 연결성 패턴을 형성함.
          + 학교에서 손글씨 연습을 유지하는 것이 중요하지만, 지속적으로 발전하는 기술적 진보도 따라가야 함.
          + 따라서 교사와 학생은 어떤 연습이 어떤 상황에서 최고의 학습 효과를 가지는지 인지해야 함. 예를 들어, 강의 노트를 작성할 때나 에세이를 쓸 때 등.

   한 때 이런 저런 이유로 만년필 러버가 됐었는데 지금은 그냥 타이핑만 하네요 ;;

   근데 잘하는 사람은 노트필기를 하건 노트북 타자 필기를 하건 다 잘하더라구요. 이게 limiting step인지는 잘 모르는 거죠.

        Hacker News 의견

     * 양손을 사용하는 것이 뇌에 예기치 않은 영향을 미칠 수 있어 모든 참가자는 오른손 검지로만 타이핑해야 했음. 이러한 예기치 않은 영향을 배제하는 방법에 대한 설명이 부족함
          + 노르웨이 대학생들이 보통 필기체를 사용하는지에 대한 의문 제기
     * 이 연구는 일반적인 타이핑과 필기를 비교하는 것이 아니라, 참가자들이 전혀 사용해본 적 없는 입력 방법과 필기를 비교한 것임
     * 1994년부터 텍스트 에디터로 노트 필기를 해왔으며, 컴퓨터로 노트를 작성하는 것이 훨씬 빠르고 효율적이었음
          + 타이핑이 필기보다 훨씬 빠르기 때문에 더 많은 시간을 내용을 이해하고 재구성하는 데 사용할 수 있었음
          + 이러한 방식으로 정보의 패턴을 더 빨리 발견할 수 있었고, 전반적인 이해도가 높아졌음
     * 15년 전 교사 훈련 시 필기로 작성한 정보가 더 오래 기억된다는 교육을 받았음
          + 심리학의 이론은 실험 결과에 맞춘 '그럴듯한 이야기'에 불과하다는 비판
          + 실험 결과는 입력과 출력 간의 얕은 상관관계에 불과하며, 뇌의 물리적 시스템에 대한 이해를 높이는 데 심리학이 크게 기여하지 못하고 있음
     * 학습 장애로 인해 1992년부터 노트북을 사용했지만, 여전히 손으로 노트 필기를 선호함
          + 필기 자체가 기억에 도움이 된다고 느꼈으며, 읽지 않더라도 필기 행위 자체를 기억함
     * 대부분의 사람들이 타이핑을 주로 사용하기 때문에 근육 기억이 자연스럽게 형성되었고, 필기는 추가적인 노력이 필요할 수 있음
          + 기존의 성향이 고려되지 않았다는 점에 대한 의문
     * 많은 사람들이 오른손 검지로만 타이핑하는 방식에 익숙하다는 점을 언급
     * 높은 수준의 타이핑 능력을 갖추면 흐름을 유지하는 능력이 향상됨
          + 긴 글을 작성할 때는 화면을 보지 않고 작성한 후, 오타를 수정하는 방식으로 작업함
          + vim을 사용하여 마우스와 키보드 간의 전환을 최소화함
     * EEG는 뇌의 활성화를 측정하며, 필기가 타이핑보다 더 많은 뇌의 활성화를 요구함
          + 뇌의 연결성이나 신경 활성화가 긍정적인 결과와 연관되는지에 대한 의문
          + 시냅스 가지치기가 뇌의 연결성을 줄이는 것이 유리할 수 있음
          + 과도한 연결성이 신경 다양성 논의에서 단점으로 간주될 수 있음
          + 단순한 기억 테스트가 학습의 정점인지에 대한 의문
          + 창의적 사고와 비판적 사고를 촉진하기 위해 단순한 기억 최적화가 이상적인지에 대한 의문
          + 부상이나 장애로 인해 필기가 불가능한 사람들이 타이핑을 통해 성공할 수 있는지에 대한 의문
          + 소프트웨어는 손으로 작성하지 않으며, 일부 학교에서는 펜과 종이로 코딩을 가르침
          + 소프트웨어의 품질과 정확성을 자동으로 테스트하기 위해서는 코드가 타이핑되어야 함
          + 필기 노트가 평가, 확인, 거부 또는 검증되는지에 대한 의문
          + 타이핑 후와 필기 후 기억력을 측정하는 연구가 있는지에 대한 의문
"
"https://news.hada.io/topic?id=18059","세계에서 단 한 번 발견된 희귀 광물 Kyawthuite","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    세계에서 단 한 번 발견된 희귀 광물 Kyawthuite

세계에서 가장 희귀한 광물

     * Kyawthuite의 발견
          + Kyawthuite는 세계에서 단 한 번만 발견된 매우 희귀한 광물임.
          + 이 광물은 미얀마의 Chaung-gyi 시장에서 보석학자 Kyaw Thu에 의해 2010년에 구매되었음.
          + 처음에는 scheelite로 오인되었으나, GIA 연구소에서 분석 후 새로운 자연 광물로 확인되었음.
     * Kyawthuite의 특성
          + 크기는 5.8 x 4.58 x 3 밀리미터로 매우 작음.
          + 포화된 오렌지색과 붉은 색조를 띠며, 흰색 줄무늬를 가짐.
          + 자연 형성의 증거로 en echelon 베인이 포함되어 있음.
          + 지질학자들은 이 광물이 화성암인 페그마타이트에서 형성된 것으로 추정함.
     * 형성 및 구성
          + Kyawthuite는 티타늄, 나이오븀, 텅스텐, 우라늄의 흔적을 포함하고 있으며, 이는 페그마타이트 형성과 일치함.
          + 실험실에서 비스무트 안티모나이트 결정이 고온에서 형성됨을 확인함.
          + 매우 희귀한 만큼 특별한 형성 조건이 있을 것으로 추정되지만, 아직 정확한 형성 조건은 알려지지 않음.
     * 가치와 보관
          + Kyawthuite의 가치는 현재 '값을 매길 수 없음'으로 평가됨.
          + 세계에서 유일한 Kyawthuite는 현재 로스앤젤레스 카운티 자연사 박물관에 안전하게 보관 중임.

        Hacker News 의견

     * 어떤 광물 전문가가 아니지만, TFA에 따르면 이 광물이 희귀한 이유는 아무도 채굴하거나 찾지 않기 때문이라고 함. 자연 상태에서 인식하기 어려워 실험실 테스트 없이 다른 덜 가치 있는 광물로 오인하기 쉬움
          + 이 광물이 발견된 지역에서 더 많은 양이 형성되지 않았다는 것이 상상이 잘 안 됨
     * 한 번만 발견된 광물들이 많이 있을 것이라고 생각했는데, 자연 과정에서 광물이 발생하고 지구가 크기 때문에 여러 번 발생할 가능성이 있다고 함. 그러나 많은 자연 과정이 긴 꼬리 분포를 만들어 매우 희귀한 것들이 많음
     * 현재 이 돌의 소유자는 누구인지 궁금함. Kyaw Thu가 National History Museum of Los Angeles County에 기증했는지, 아니면 Kyaw Thu가 여전히 소유자인지 궁금함
     * 링크된 기사에 따르면, 광물학자들이 이 돌을 합성 BiSbO4 – 비스무트 안티모네이트와 관련지었지만, 자연에서 발견된 적 없는 Bi3+Sb5+O4의 배열임
          + 처음부터 합성 돌이 아닌지 어떻게 아는지 궁금함
     * 현재 National History Museum of Los Angeles County에 안전하게 보관되어 있음. 이를 도둑 영화의 소재로 볼 수 있음
          + 이 외에도 이 물질의 다른 샘플이 발견될 가능성이 있는지 궁금함. 제대로 식별된 유일한 것이라서 유일한 것인지 궁금함
     * Cummingtonite에 대해 언급함. 흔히 발견된다고 하지만 Cummington이라는 이름을 따서 명명됨
          + 유튜브 영상을 통해 알게 되었음
     * 광물 및 기타 천연 자원의 위치를 더 잘 추측할 수 있는 예측 모델이나 간섭 측정법과 같은 새로운 기술이 있는지 궁금함
          + 스타트업들이 중력 왜곡을 감지하거나 위성 데이터를 사용하는 것을 들었음. 이 분야에서 새로운 방법과 접근법에 많은 기회가 있는지 궁금함
     * 가장 희귀한 광물은 아직 발견되지 않았을 정도로 희귀함
"
"https://news.hada.io/topic?id=18036","Sail - AI시대를 위한 빅데이터 처리 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Sail - AI시대를 위한 빅데이터 처리 프레임워크

     * 스트림 프로세싱 / 배치 프로세싱 / 고성능-연산(AI) 워크로드를 통합 처리하는 프레임워크를 목표
     * 현재 Spark SQL과 Spark DataFrame API에 대한 Drop-in 대체 솔루션을 제공(호환)
     * 단일 머신 또는 분산 설정에서 동작 가능
     * TPC-H 벤치마크 기준 Spark 대비 4배 빠르고, 94%의 하드웨어 비용을 절감하며, 코드 변경이 필요없음
     * 파이썬 패키지로 이용 가능 pip install ""pysail==0.2.0.dev0""
     * 기술 스택
          + Rust 기반 엔진으로 Apache Arrow와 Apache DataFusion 위에 구축
          + Spark Connect 프로토콜을 사용해 Spark 세션이 Sail 서버와 통신
"
"https://news.hada.io/topic?id=18028","2024년 1백만 동시 작업 실행에 필요한 메모리 용량","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     2024년 1백만 동시 작업 실행에 필요한 메모리 용량

벤치마크

     * 코루틴이란?
          + 코루틴은 프로그램의 실행을 일시 중지하고 재개할 수 있는 컴퓨터 프로그램 구성 요소로, 협력적 멀티태스킹을 위한 서브루틴을 일반화한 것임.
          + 협력 작업, 예외, 이벤트 루프, 반복자, 무한 리스트 및 파이프와 같은 프로그램 구성 요소 구현에 적합함.
     * Rust
          + 두 가지 프로그램을 작성함: tokio와 async_std를 사용한 프로그램.
          + 둘 다 Rust에서 일반적으로 사용되는 비동기 런타임임.
     * C#
          + C#은 Rust와 유사하게 async/await를 지원함.
          + .NET 7부터 NativeAOT 컴파일을 제공하여 VM 없이도 관리 코드 실행이 가능함.
     * NodeJS
          + 비동기 작업을 위해 Promise.all을 사용함.
     * Python
          + asyncio 모듈을 사용하여 비동기 작업을 수행함.
     * Go
          + 고루틴을 사용하여 동시성을 구현하며, WaitGroup을 사용하여 작업을 대기함.
     * Java
          + JDK 21부터 가상 스레드를 제공하며, 이는 고루틴과 유사한 개념임.
          + GraalVM을 사용하여 네이티브 이미지를 생성할 수 있음.

테스트 환경

     * 하드웨어: 13세대 Intel(R) Core(TM) i7-13700K
     * 운영체제: Debian GNU/Linux 12 (bookworm)
     * Rust: 1.82.0
     * .NET: 9.0.100
     * Go: 1.23.3
     * Java: openjdk 23.0.1
     * Java (GraalVM): java 23.0.1
     * NodeJS: v23.2.0
     * Python: 3.13.0

결과

     * 최소 메모리 사용량
          + Rust, C# (NativeAOT), Go는 네이티브 바이너리로 컴파일되어 적은 메모리를 사용함.
          + Java (GraalVM 네이티브 이미지)도 좋은 성능을 보였으나, 다른 정적 컴파일 언어보다는 더 많은 메모리를 사용함.
     * 10K 작업
          + Rust는 메모리 사용량이 거의 증가하지 않음.
          + C# (NativeAOT)도 적은 메모리를 사용함.
          + Go는 예상보다 많은 메모리를 사용함.
     * 100K 작업
          + Rust와 C#이 좋은 성능을 보임.
          + C# (NativeAOT)이 Rust보다 적은 메모리를 사용함.
     * 100만 작업
          + C#이 모든 언어를 압도하며 가장 적은 메모리를 사용함.
          + Rust도 메모리 효율성이 뛰어남.
          + Go는 다른 언어에 비해 메모리 사용량이 많음.

결론

     * 많은 동시 작업은 복잡한 작업을 수행하지 않더라도 상당한 메모리를 소모할 수 있음.
     * .NET과 NativeAOT의 개선이 눈에 띄며, GraalVM으로 빌드된 Java 네이티브 이미지도 메모리 효율성이 뛰어남.
     * 고루틴은 여전히 자원 소비 면에서 비효율적임.

부록

     * Rust (tokio)에서 join_all 대신 for 루프를 사용하여 메모리 사용량을 절반으로 줄임. Rust가 이번 벤치마크에서 절대적인 선두를 차지함.

        Hacker News 의견

     * 벤치마크가 Node와 Go의 비동기 처리 방식의 차이를 제대로 반영하지 못함. Node는 Promise.all을 사용하고 Go는 고루틴을 사용하여 차이가 있음. 비동기 I/O와 CPU 바운드 작업의 메모리 사용량 차이를 비교하는 것이 흥미로울 것임
     * ""10초 동안 대기하는 작업""과 ""10초 후에 깨우는 작업""의 차이를 설명함. Go 코드의 메모리 사용량이 다른 코드와 비교하여 차이가 큼
     * Go와 Node의 공정한 비교를 위해 타이머를 스케줄링하는 고루틴과 타이머 신호를 처리하는 고루틴을 사용하는 방법을 제안함. Node에 Bun과 Deno가 포함되지 않은 점이 이상하다고 언급함
     * 많은 동시 작업이 메모리를 많이 소비할 수 있지만, 작업당 데이터가 몇 KB 이상이면 스케줄러의 메모리 오버헤드는 무시할 수 있을 정도임
     * ""동시 작업""의 정의에 따라 메모리 사용량이 달라질 수 있음. 효율적인 구현에서는 1M 동시 작업에 약 200MB가 필요함
     * Go가 메모리 사용량에서 Java에 비해 2배 이상 뒤처진다는 점을 지적하며, 벤치마크가 실제 프로그램을 대표하지 않는다고 언급함
     * 간단한 코드로 언어를 비교하는 것이 개발자에게 불공평할 수 있으며, 실제 작업을 추가하여 메모리 사용량과 스케줄링 차이를 측정할 것을 권장함
     * 벤치마크가 종종 오류로 가득 차 있으며, 이러한 벤치마크를 게시하는 사람들의 동기를 이해하지 못하겠다고 말함
     * Java 벤치마크가 잘못되었을 가능성이 있으며, ArrayList의 초기 크기를 지정하지 않아 불필요한 객체가 많이 생성됨
     * Rust의 비동기 코드가 예상보다 빠르게 완료되는 이유를 설명함. tokio::time::sleep()이 미래가 생성된 시점을 추적하기 때문임
"
"https://news.hada.io/topic?id=18049","Privastead - 오픈소스 개인 홈 보안 카메라 시스템 (종단 간 암호화 지원)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Privastead - 오픈소스 개인 홈 보안 카메라 시스템 (종단 간 암호화 지원)

   Privastead는 프라이버시를 보장하는 홈 보안 카메라 솔루션으로, 종단 간 암호화를 사용함. 주요 이점은 다음과 같음:
     * OpenMLS 구현을 통한 Messaging Layer Security (MLS) 프로토콜 기반의 종단 간 암호화.
     * 기존 IP 카메라와 함께 작동하는 소프트웨어 전용 솔루션으로, IP 카메라에 대한 최소한의 신뢰 가정.
     * Rust로 구현된 카메라 허브, 모바일 앱의 MLS 코드, 신뢰할 수 없는 서버.

  구성 요소

   Privastead 카메라 솔루션은 세 가지 구성 요소로 이루어짐:
     * 로컬 머신에서 실행되며 IP 카메라와 직접 상호작용하는 카메라 허브.
     * 이벤트 알림 수신 및 원격으로 카메라 라이브 스트리밍을 가능하게 하는 모바일 앱.
     * 허브와 앱 간의 암호화된 메시지를 중계하는 신뢰할 수 없는 서버. 또한, 알림을 위해 Google Firebase Cloud Messaging (FCM)을 사용하며, FCM도 신뢰할 수 없음.

  위협 모델 및 보장

   Privastead 카메라 솔루션의 주요 장점은 종단 간 암호화를 통해 강력한 프라이버시 보장을 제공하는 것임. 구체적으로 다음과 같은 가정을 함:
     * 허브를 실행하는 로컬 머신과 모바일 앱을 실행하는 스마트폰이 안전하고 손상되지 않았다고 가정.
     * 서버는 완전히 신뢰할 수 없으며, 적의 통제 하에 있다고 가정.
     * IP 카메라에 대한 최소한의 신뢰 가정을 함. 즉, 카메라가 자체적으로 인터넷에 연결할 수 있는 비공개 네트워크 인터페이스 카드(예: 셀룰러)를 가지고 있지 않다고 가정(따라서 사용자가 이를 명확히 확인하고 검증하는 것이 좋음). 그 외에는 IP 카메라를 신뢰할 수 없으며, Privastead는 카메라를 인터넷에 직접 연결하지 않고 허브에 직접 연결함.

   다음과 같은 보장을 제공함:
     * 허브와 모바일 앱만이 암호화되지 않은 비디오에 접근할 수 있음.
     * 서버는 비디오를 해독할 수 없음.
     * MLS를 통해 전방 비밀성과 사후 손상 보안을 제공함.
     * 현재 적(서버 및/또는 FCM 채널을 통제하는 자)으로부터 이벤트 및 라이브 스트리밍의 타이밍을 숨기지 않음.

  지원 카메라

   Privastead 카메라는 이론적으로 모든 IP 카메라(또는 개방형 인터페이스를 가진 다른 카메라)를 지원할 수 있음. 현재 프로토타입은 카메라의 RTSP 및 ONVIF 지원에 의존함. RTSP는 카메라에서 비디오 스트리밍에 사용되고, ONVIF는 이벤트 쿼리에 사용됨. 지금까지 다음 카메라가 테스트됨:
     * Amcrest, 모델: IP4M-1041W

  지원 모바일 OS

     * Android

  테스트된 스마트폰 (OS 버전)

     * Google Pixel 8 Pro (Android 14)

  허브의 테스트 실행 환경

     * Ubuntu (ffmpeg 필요)

  (현재) 주요 제한 사항

     * 앱은 하나의 카메라와만 페어링 가능.
     * 카메라 허브는 하나의 카메라만 지원.
     * 카메라 허브는 하나의 앱 인스턴스와만 페어링 가능.
     * 높은 카메라 해상도와 프레임 속도에서는 성능이 병목이 될 수 있음.

  프로젝트 멤버

     * 프로젝트 창립자: Ardalan Amiri Sani (UC Irvine 컴퓨터 과학 교수, 컴퓨터 보안 및 프라이버시 전문가)

        Hacker News 의견

     * 새로운 프로젝트를 시작하기 전에 철저한 조사가 필요함을 강조하는 의견이 있음
          + 많은 보안 카메라 솔루션이 프라이버시 문제로 신뢰할 수 없음을 언급함
          + Frigate는 오프클라우드, 오픈소스, 자체 호스팅 가능하며 GPU나 Google Coral을 사용하여 사람을 감지함
          + moonfire-nvr와 sentryshot는 Rust로 작성된 다른 옵션임
          + 프로젝트가 Hacker News에 게시된 후 더 많은 관심을 받았음을 언급함
     * Frigate와 Home Assistant를 사용하여 보안 카메라를 설정한 경험을 공유함
          + Frigate가 사람이나 차량을 감지하면 iPhone 잠금 화면에 스냅샷과 비디오가 표시됨
     * 보안 카메라 설치를 재고하게 만든 프로젝트에 대한 긍정적인 반응을 보임
          + OpenMiko와의 결합이 프라이버시를 중시하는 사람들에게 좋은 조합이 될 것임
     * Scrypted라는 오픈소스 솔루션을 언급하며 HomeKit과의 통합을 통해 E2EE를 제공함
          + 개발자가 다소 까다로울 수 있지만 성능이 뛰어나고 설정이 쉬움
     * 카메라와 모션 센서를 위한 오픈소스 하드웨어 및 펌웨어 디자인을 제공하는 Tokay Lite PCB를 소개함
     * Google Firebase를 사용한 메시지 전달 대신 이메일을 통한 SMS가 더 나을 수 있음을 제안함
          + 방화벽 뒤에서 설정할 경우 포트 포워딩이 필요할 수 있음
     * 신뢰할 수 있는 사람 감지와 API 또는 MQTT와의 통합이 중요함을 강조함
          + 단순한 모션 감지로는 불필요한 경고가 발생할 수 있음
     * Motion을 사용한 성공적인 경험을 공유하며 중앙 프로세서가 필요함을 언급함
     * Secure Boot 기능을 가진 카메라에 대한 정보를 제공함
     * Home Assistant와 비교하여 프로젝트의 보안 레이아웃이 더 나은 점을 설명해 달라는 요청이 있음
          + 카메라와 로컬 네트워크 허브 간의 암호화에 대한 우려가 적음
"
"https://news.hada.io/topic?id=18068","Ask HN: 배울 수 있는 훌륭한 시니어 없이, 엔지니어로 어떻게 성장할 수 있을까요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Ask HN: 배울 수 있는 훌륭한 시니어 없이, 엔지니어로 어떻게 성장할 수 있을까요?

     * 석유 및 시추 산업의 작은 회사에서 일하는 신입 데이터 엔지니어
          + 6개월 전 프리랜서 데이터 엔지니어로 고용되었으며, 작업 품질을 통해 인정받아 현재는 프로젝트의 설계, 구현 및 채용을 책임지는 기술 리드 역할을 하고 있음
          + 회사는 기술 회사가 아니기 때문에 기술 지향적인 동료가 몇 명 없으며, 그들과 거의 상호작용하지 않음
          + 현재 회사의 이사에게 직접 보고하며, 이사는 세계적으로 큰 석유 및 시추 회사에서 40년 이상의 경험을 가진 훌륭한 사람임
     * 그러나 동료나 선배로부터 많은 기술적인 것을 배우지 못해 FOMO를 강하게 느끼고 있음
          + 스스로 디자인 원칙을 배우고, chatGPT로부터 코드 리뷰를 받으며 최선을 다해 배우고 있지만, 엄격한 교차 검토가 없어서 산업의 최고 기준에 맞는 소프트웨어를 생산하지 못할까 두려움
     * 비슷한 위치에 있었던 사람이 있다면 조언을 부탁함

[투표를 많이 받은 상위 답변들 요약]

humanfromearth9

     * 나는 소프트웨어 개발에 대해 이야기 하지만 다른 도메인도 마찬가지 일 것
     *

     ""당신이 사용하는 기술에 대해서 엄청 많이 읽으세요""
     * 나는 일을 시작했을 당시에 매일 기술 관련 글을 읽는 습관을 들였음
          + 하루 20-30분 동안 DZone의 Java, 소프트웨어 설계, 아키텍처, OOP 관련 글을 읽기
          + 반복과 습관이 중요함
     * 집중할 것
          + 모든 내용을 완전히 이해하려고 노력
               o 이해되지 않는 부분은 넘어가지 말고, 내용을 깊이 탐구
          + 글의 주제를 비판적으로 분석
               o 작성자가 무엇을 전달하려는지 파악
               o ""내가 작성자라면 어떻게 했을까?"" 를 생각
               o 유용해 보이는 내용을 직접 적용하고, 한계를 극복하는 방법을 고민
     * 가끔은 기사뿐 아니라, IT 서적을 읽으며 심도 있는 학습 진행
          + 특정 기술이나 주제에 대한 더 깊은 통찰 제공
     * 그리고 더 나아가 기술 비교 및 탐구
          + OOP 패턴이 어떻게 FP 패턴으로 대체 가능한지 탐구
               o OOP 클래스와 FP 클로저의 유사점과 차이점 이해
          + 다양한 패러다임 간의 차이를 비교하고, 자신의 기술적 시각 확장
     * 그리고, 기초 실무 능력 강화도 중요함
          + 트랜잭션 관리와 같은 핵심 실무 기술의 전문가 되기
          + 실무에서 자주 사용되는 필수 개념과 기술 숙달
     * 이렇게 배운 ""이론을 실제로 적용하는 것""이 핵심

iepathos

     * 나도 경력 초반에 비슷한 상황이었음
     * 유명한 오픈 소스 프로젝트에 적극적으로 기여
          + 이미 사용하고 있는 프로젝트를 선택하면 친숙함을 활용 가능
          + 고품질의 PR(Pull Request)을 제출하려고 노력
               o 이를 통해 전 세계 최고의 엔지니어들로부터 무료 코드 리뷰를 받을 수 있음
               o 리뷰 과정에서 엄청난 학습 기회를 제공받고, 자신의 코드가 수천~수백만 회사에서 사용됨
          + 오픈 소스 활동은 실무 경험을 쌓는 훌륭한 방법
     * 약하다고 느끼는 분야를 찾아 집중적으로 학습
          + 예: 네트워킹, DSA(Data Structures & Algorithms) 등
          + 해당 주제를 공부하고, 실습을 통해 더 이상 약점으로 느껴지지 않을 때까지 연습
          + 만약 팀이 있다면, 팀 리더나 매니저가 약점을 자연스럽게 보완할 수 있는 작업을 배정해 줄 수 있음
          + 독립적으로 학습해야 하는 경우, 자신의 약점을 파악하고 스스로 극복해야 함
     * 직장에서 항상 최선을 다하기
          + 주어진 업무에 최선을 다함
               o 이는 누구나 할 수 있는 기본적인 태도지만, 지속적으로 실천하면 성공으로 이끄는 습관이 됨
          + 적극적으로 노력하면, 어떤 환경에서도 성공으로 이어지는 기반을 마련할 수 있음

vinay_ys

     * 지속 가능한 성장을 위한 중요한 교훈들
     * 효과적으로 배우는 방법 익히기
          + 지속적이고 효율적인 학습 능력을 키우는 것이 중요
               o 기술은 빠르게 변화하며, 시장과 흥미를 따라 다양한 도메인을 탐험해야 할 때가 많음
               o 이는 두 가지 측면에서 작용
                    # 축복: 늦게 시작해도 노력과 지능으로 상위 퍼센타일에 진입 가능
                    # 저주: 경력이 쌓여도 끊임없이 새로운 기술을 배워야 함
          + 지속 가능한 학습 전략을 구축해 시장의 변화에 유연하게 적응
     * 비기술적 역량 연마
          + 비기술적 역량은 시간이 지날수록 복리 효과를 발휘 (좋은 습관/나쁜 습관 모두 해당)
               o 절제력, 명확한 사고와 표현, 전문성, 신뢰성, 신체적/정신적 건강 관리, 의존가능한 사람 되기, 성장 마인드셋, 모호성과 불확실성 속에서 성공적으로 적응하기 등
               o 커뮤니케이션 스킬: 효과적인 협업 기술, 피드백 주고받기, 멘토링 및 코칭, 다양한 직급의 사람들과 협력 (상급자, 하급자, 동료 등)
               o 많은 독서를 통해 멘탈 모델 개발, 문제 해결 능력, 전략적 트레이드오프 및 의사결정 기술 연마
     * 위 내용들에 대해서 스스로 학습하고, 사람들의 행동을 관찰하며 교훈 얻기
          + 책을 읽고, (여기와 같은) 포럼 등에서 낯선 사람들과의 대화로 통찰력 키우기

   우물 안 개구리가 될 수도 있겠지만, 그 회사에서 일하는 방법에 있어서는 스페셜리스트가 될수도 있겠네요. 모든 인프라를 맨바닥에서 다 부딪히면서 새로 만들어야할테니...

  Hacker News 의견

     * 신입 데이터 엔지니어로서의 경고 신호들
          + 회사는 신입을 저렴한 노동력으로 볼 수 있음
          + 프리랜서로 고용되어 혜택 없이 일할 수 있음
          + 신입이 기술 리드로서의 역할을 수행하기에는 자격이 부족할 수 있음
          + 프로젝트의 설계, 구현, 채용에 대한 책임을 맡는 것은 1인 팀으로서의 위험을 내포함
          + 기술 중심의 동료가 적은 회사에서는 예산이 제한될 수 있음
     * 모든 사람에게서 배울 수 있으며, 독립적으로 학습하는 것이 중요함
          + 주변의 모든 사람에게서 배울 수 있으며, 웹을 통해 독립적으로 학습할 수 있음
          + 실수를 방지하거나 문제를 해결해줄 사람이 있다고 안심하지 말고, 책임을 지고 학습하는 것이 중요함
     * 자신의 위치에 대해 긍정적인 경험을 공유함
          + 높은 급여와 좋은 근무 환경을 누리고 있으며, 회사의 지원을 받고 있음
          + 착취당하지 않고 있으며, 이 사실을 명확히 하고자 함
     * 현재 위치에서 성장할 수 있는 기회를 고려해야 함
          + FAANG 회사에서 높은 수준의 프로젝트를 추구하는 것도 좋지만, 현재 산업에서 더 나은 성과를 내는 것도 흥미로울 수 있음
          + 선배 동료에게서 배우는 것은 상황에 따라 다를 수 있음
     * 멘토 없이도 독립적으로 학습할 수 있음
          + 알고리즘과 신경망 이론을 배우고, 작은 프로그램을 작성하며, 단순함을 추구하는 것이 중요함
          + 오픈 소스 프로젝트에 참여하고, GitHub에 사이드 프로젝트를 올려 자신의 설계 능력을 개발해야 함
     * 온라인 커뮤니티와 블로그를 통해 학습을 가속화할 수 있음
          + Reddit, Discord, Stackoverflow와 같은 온라인 커뮤니티를 활용하여 학습할 수 있음
          + 블로그를 시작하여 학습 내용을 기록하고, 컨퍼런스에 참석하여 지식을 확장할 수 있음
     * 기술적 결정을 내리고 그 결과를 평가하는 경험이 중요함
          + 많은 기술적 결정을 내리고 그 결과를 평가하는 것이 가치 있는 경험이었음
          + 자신의 결정에 대한 평가를 통해 통찰력을 얻고, 새로운 직장에서 존경을 받을 수 있었음
     * 더 나은 환경을 찾아 이동하는 것이 중요할 수 있음
          + 자신이 가장 똑똑한 사람이라면 다른 곳으로 이동하여 경험을 쌓는 것이 중요함
          + 좋은 선배 엔지니어가 있는 회사에서도 직접적인 멘토를 찾기 어려울 수 있지만, 경험을 통해 성장할 수 있음
"
"https://news.hada.io/topic?id=18120","북부 캘리포니아 쓰나미 경보","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            북부 캘리포니아 쓰나미 경보

     * 미국 쓰나미 경보 시스템
          + 미국 상무부와 NOAA의 국립 기상청에서 운영하는 미국 쓰나미 경보 시스템에 대한 정보 제공.
     * 쓰나미 경보
          + 지진 정보: 규모 7.3, 발생 시간 2024년 12월 6일 오전 3시 44분 24초, 깊이 8마일, 위치는 캘리포니아 유레카 남서쪽 45마일.
          + 경보 메시지: AK/BC/미국 서부 해안 경보/권고/주의보 #1 발행.
     * 경보 및 위협
          + 경보 지역: 오리건주 플로렌스 남서쪽 10마일, 캘리포니아 산타크루즈 북서쪽 10마일.
          + 발행 시간: 2024년 12월 6일 오전 3시 49분 53초.
     * 추가 정보
          + 연락처: 국립 쓰나미 경보 센터, 팔머, 알래스카.
          + 연락처 정보: 전화 907-745-4212, 팩스 907-745-6071, 이메일 ntwc@noaa.gov.
     * 정책 및 법률
          + 개인정보 보호 정책, 정보 품질, 정보 자유법 등에 관한 정보 제공.

        Hacker News 의견

     * 지진의 위치와 초점 메커니즘에 따르면, 이번 지진은 태평양 판과 고르다/후안 데 푸카 판 사이의 경계에서 발생한 주향 이동 단층 지진임. 이러한 지진은 두 판이 서로 옆으로 미끄러질 때 발생하며, 해저 이동에 의한 해수의 실질적인 변위가 없기 때문에 쓰나미를 거의 발생시키지 않음
     * USGS의 자동 시스템은 지진 네트워크로부터 지진의 위치와 초점 메커니즘/모멘트 텐서를 즉시 계산함. 시스템은 지진의 매개변수를 기반으로 중요한 쓰나미가 발생할 가능성이 낮다는 것을 알아야 함. 경고 시스템이 필요할 수도 있음
     * AK/BC/미국 서부 해안에 대한 경고가 더 이상 없다는 보고가 있었음. 이는 북부 캘리포니아를 포함함
     * 경고가 다른 지역에서는 해제되었지만 이 지역에서는 여전히 유효하다는 점이 혼란스러웠음
     * 특정 웹캠을 통해 몇 분 내에 실제 상황을 확인할 수 있음. 도착 시간이 지나갔지만 수위 변화는 없었음
     * Android 폰에서 지진 경고를 받고 몇 초 후에 작은 진동을 느꼈음. iPhone은 약 10~15분 후에 쓰나미 경고를 보냈음. iPhone의 경고 시스템이 Android보다 느리다는 점이 놀라웠음
     * Android는 보안이 취약하고 앱이 남용될 수 있는 반면, iPhone은 더 안전하다는 인상을 받았음
     * 쓰나미 위협이 더 이상 없다는 업데이트가 있었음
     * Caltrain을 타고 남쪽으로 이동 중이었으며, 속도가 느려져서 Palo Alto까지 2시간 이상 걸릴 것이라는 안내를 받았음. 이후 속도 제한이 해제되어 다시 79 MPH로 이동하게 되었음
     * 쓰나미 활동 예보가 특정 시간에 시작될 것으로 예상되었음
     * 쓰나미 경고는 해안에서 실제로 보이는 것인지, 아니면 조건이 성숙한 것인지 궁금해하는 의견이 있었음
     * 캘리포니아 해안 근처에서 발생한 M7.0 지진으로 인해 쓰나미 경고가 발령되었음. 초기 규모 추정치는 6.0에서 7.3까지 다양함
     * Humboldt County에 거주하는 다른 HN 사용자들은 없지만, 이번 지진은 지금까지 경험한 것 중 가장 강렬했음. 다행히도 현대적인 건축물 덕분에 안전했음
"
"https://news.hada.io/topic?id=18114","Outerbase Studio – 오픈 소스 데이터베이스 GUI","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Outerbase Studio – 오픈 소스 데이터베이스 GUI

     * SQL 데이터베이스 관리를 위한 경량의 브라우저 기반 GUI로, 단순성과 다재다능함을 목표로 설계됨
     * 초기에는 LibSQL과 SQLite를 위해 개발되었으나, 현재는 다양한 데이터베이스를 지원
     * 지원 데이터베이스
          + SQLite 기반 : Turso/LibSQL, SQLite (로컬 파일), Cloudflare D1, rqlite, StarbaseDB, Val.town
          + MySQL (베타, 제한된 기능)
          + PostgreSQL (베타, 제한된 기능)
     * 데스크톱 앱
          + Windows와 Mac 데스크톱 앱 다운로드 가능
          + Outerbase Studio Desktop은 웹 버전의 경량 Electron 래퍼로, 브라우저 환경에서 불가능한 MySQL 및 PostgreSQL 드라이버 지원 가능
     * 기능
          + 쿼리 편집기: 사용자 친화적인 쿼리 편집기로 자동 완성과 함수 힌트 툴팁 제공. 여러 쿼리를 동시에 실행하고 결과를 효율적으로 확인 가능
          + 데이터 편집기: 강력한 데이터 편집기로 모든 변경 사항을 사전 검토 후 커밋 가능. 데이터 테이블은 수천 개의 행과 열을 효율적으로 렌더링할 수 있도록 최적화됨
          + 스키마 편집기: SQL을 작성하지 않고도 테이블 열을 빠르게 생성, 수정, 제거 가능
          + 연결 관리자: 유연한 연결 관리자로, 브라우저에 로컬로 연결 저장 가능. 서버에 저장하여 여러 장치에서 연결 공유 가능

        Hacker News 의견

     * 비슷한 것을 만들어 본 경험이 있으며, 중요한 것은 권한 관리의 지원 여부임
          + 이메일 리스트를 유지하고 다른 사람들이 행을 추가할 수 있도록 권한을 부여하는 것이 이상적임
          + 이러한 유지 관리에 대한 강력한 표준이 부족하다고 생각함
     * 고품질의 브라우저 기반 DB 브라우저가 부족하다고 느꼈으며, Firestore 드라이버 구현을 희망함
          + GCP 환경에 묶여 있어 Firestore 드라이버가 필요함
     * ""컴팩트"" 인터페이스 옵션이 있으면 좋겠음
          + 웹 UI와 네이티브 GUI를 비교할 때, 웹에서는 공간이 빠르게 소모됨
          + 패딩이 많아 실제 정보를 보기 어려움
     * Kate SQL 플러그인의 사용이 매우 유용함
          + SQL을 파일이나 마크다운 파일로 정리할 수 있음
          + 과거에 유사한 SQL을 여러 번 다시 입력해야 했던 경험이 있음
     * 설치가 어려운 환경에서는 pip install이나 npm install을 통해 쉽게 사용할 수 있기를 바람
          + datasette처럼 쉽게 실행할 수 있어야 함
     * 협업 지원 계획이 있는지 궁금함
          + 두 명 이상의 사용자가 같은 작업 공간에서 실시간으로 쿼리하고 결과를 얻을 수 있는 기능이 필요함
          + vscode + liveshare + SQL 관리 확장으로 비슷한 기능을 시도한 경험이 있음
     * Metabase를 SQL 보고에 사용 중이며, 값을 실제로 변경할 수 있는 도구를 찾고 있음
          + 트랜잭션을 사용하지 않는 점과 데이터베이스 스키마가 두 번 정의된 점이 우려됨
     * 브라우저 기반 데이터베이스 UI에서 이진 데이터와 매우 큰 정수 처리에 문제가 많았음
     * tauri를 사용할 계획이 있는지 궁금함
          + 네이티브 OS 웹 뷰를 사용할 수 있으며, electron의 오버헤드를 줄일 수 있음
     * 웹 UI가 DB 위에 있는 것이 BI 지향 도구의 동기임
          + Metabase를 통해 테이블에 쓰기가 가능함
"
"https://news.hada.io/topic?id=18023","스크롤을 건드리지 마세요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             스크롤을 건드리지 마세요

     * 사용자 기대를 위반함
          + 사용자는 스크롤링 방식에 익숙함. 모멘텀 스크롤링 플러그인은 이러한 기본 동작을 방해하여 비정상적인 애니메이션 경험을 제공함. 이는 사용자에게 인위적이고 불편한 느낌을 줌.
     * 멀미 유발
          + 모멘텀 스크롤링 플러그인은 불필요한 애니메이션을 도입하여 멀미를 유발할 수 있음. 많은 사이트가 이를 끌 수 있는 옵션을 제공하지 않음.
     * 장애인 접근성 감소
          + 모멘텀 스크롤링 플러그인은 화면 읽기 프로그램과 키보드 내비게이션을 방해하여 장애인 사용자가 사이트를 사용하기 어렵게 만듦.
     * 기기 간 성능 불일치
          + 모멘텀 스크롤링 플러그인은 최신 장비와 오래된 장비 간의 성능 차이를 무시함. 이는 저사양 기기에서 페이지가 느리거나 깨지게 만듦.
     * 고급 사용자 사용성 저하
          + 고급 사용자는 빠른 스크롤링과 정밀한 조작을 원함. 모멘텀 스크롤링은 이러한 사용자의 워크플로우를 방해함.
     * 페이지 로드 시간 증가
          + 모멘텀 스크롤링 플러그인은 불필요한 자바스크립트 라이브러리를 추가하여 페이지 로드 시간을 증가시킴.
     * 브라우저 기본 기능 파괴
          + 모멘텀 스크롤링 플러그인은 브라우저의 기본 스크롤링 기능과 충돌하여 사용자 설정을 무시함.
     * 스크롤 위치 불명확
          + 모멘텀 스크롤링 애니메이션은 사용자에게 현재 위치를 파악하기 어렵게 만듦.
     * 유지보수 부담 증가
          + 모멘텀 스크롤링 플러그인은 정기적인 업데이트가 필요하며, 이는 개발팀에 추가적인 부담을 줌.
     * 사용자의 제어권 무시
          + 모멘텀 스크롤링은 사용자의 기본 스크롤링 선호도를 무시하고 강제함.
     * 결론
          + 모멘텀 스크롤링 플러그인은 불필요한 복잡성을 추가하고 사용성을 저하시키며 사용자를 좌절시킴. 기본적이고 예측 가능한 빠른 스크롤링을 유지하는 것이 바람직함.

        Hacker News 의견

     * URL과 브라우저 내비게이션, 뒤로 가기 버튼을 건드리지 말아야 한다는 의견이 있음. SPA가 웹을 망가뜨렸다는 주장도 있음
          + 스크롤 바를 1px로 만드는 최근 트렌드에 대한 비판이 있음
          + 사용자에게 ""우리가 더 잘 안다""는 태도를 보이는 것은 오만함으로 비춰질 수 있음. 사용자의 자율성을 존중해야 한다는 의견이 있음
          + 현재 UX 디자인 트렌드가 미학을 지나치게 중시하는 경향이 있다는 비판이 있음
          + HTML의 미니멀리즘을 높이 평가하는 의견이 있음. Gopher 시절부터 인터넷을 사용해온 경험을 공유함
          + 페이지 소스를 보는 것이 디자이너들이 Helvetica를 처음 선택할 수 있었던 시절의 감정을 떠올리게 한다는 의견이 있음
          + 스트리밍 미디어 플랫폼이 스크롤 방향을 변경하는 것에 대한 불만이 있음
          + Ctrl+F나 Ctrl+K를 가로채는 것에 대한 불만이 있음
          + 오버스크롤 이벤트를 싫어하며, IoT 제어 시스템에서는 이를 비활성화할 것이라는 의견이 있음
          + 스크롤 대신 안정적인 페이지 나누기를 선호한다는 의견이 있음
          + 스크롤이 배경을 변화시키거나 페이지를 분할하는 랜딩 페이지에 대한 비판이 있음
          + 스크롤이 애니메이션을 진행시키거나 페이지를 가로로 이동시키는 디자인은 사용자에게 불편함을 준다는 의견이 있음
          + ""정상 버전으로 돌아가기"" 링크가 페이지 맨 위로 스무스 스크롤해야만 클릭 가능하다는 점에 대한 불만이 있음
"
"https://news.hada.io/topic?id=18075","고양이의 주황색 털을 결정하는 유전자 발견  ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        고양이의 주황색 털을 결정하는 유전자 발견

     * Arhgap36가 고양이의 주황색 털을 결정하는 유전자로 확인됨
          + 60년 이상 과학자들이 추적했던 퍼즐을 두 독립 연구팀이 해결
          + 이전에는 주황색 털이 X 염색체와 관련이 있을 것으로 추정했지만, 정확한 원인을 알지 못했음

  고양이 털 색상의 유전적 원리

     * X 염색체의 역할:
          + 주황색 및 검정색 털 색소 유전자는 X 염색체에 위치
          + 암컷은 두 개의 X 염색체를 가지며, 하나의 X 염색체는 비활성화(X 비활성화) 되어 특정 털 색소만 발현
          + 이 과정으로 암컷은 주황색과 검정색 패치가 있는 거북등(shell) 패턴이 생김
     * 캘리코 고양이의 특징:
          + 주황색과 검정색 패치에 흰색이 섞이는 이유는 별도의 색소 생성 억제 메커니즘 때문

  Arhgap36 유전자와 발견된 돌연변이

     * 주황색 털의 원리:
          + Arhgap36 유전자는 주황색 털을 가진 고양이에서 13배 더 많은 RNA를 생성
          + Arhgap36 유전자는 X 염색체에 위치하며 X 비활성화의 영향을 받음
     * 돌연변이의 특징:
          + 주황색 고양이들은 Arhgap36 단백질의 아미노산 구조에 영향을 미치지 않는 DNA 결손 부위를 공유
          + 이 결손 부위는 Arhgap36 유전자의 발현 수준에 영향을 미침
          + 전 세계에서 수집된 258개의 고양이 게놈에서 동일한 돌연변이 확인

  새로운 분자적 경로 발견

     * 색소 전환 경로:
          + Arhgap36 발현 증가가 멜라닌 세포를 붉은색 색소로 전환
          + 기존에 알려진 Mc1r 단백질 경로와는 독립적으로 작용
     * 이전에는 알려지지 않았던 유전자의 기능:
          + Arhgap36은 초기 배아 발달에 관여하며, 주요 돌연변이는 일반적으로 치명적일 가능성이 높음
          + 하지만 이 결손 돌연변이는 멜라닌 세포에만 영향을 미쳐 건강한 주황색 고양이를 만듦

  학계의 반응 및 추가 연구 필요성

     * 전문가의 평가:
          + ""오랜 기간 기다려온 발견"" - Leslie Lyons (미주리 대학교)
          + 이 발견은 털 색깔에 관한 새로운 분자 경로를 제시
     * 미래 연구 과제:
          + 이 돌연변이가 처음 등장한 시기와 장소 추적
          + 환경 요인이 유전자 발현에 미치는 영향 연구

  결론

     * 주황색 고양이와 캘리코, 거북등 패턴의 유전적 수수께끼가 풀림
     * 이 발견은 털 색깔과 유전자 발현의 상호작용을 이해하는 데 중요한 단서 제공
     * 고양이를 통해 유전학의 핵심 원리를 배울 수 있음
"
"https://news.hada.io/topic?id=18022","VictoriaMetrics - 시계열 데이터를 위한 빠르고 비용 효율적인 모니터링 솔루션","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           VictoriaMetrics - 시계열 데이터를 위한 빠르고 비용 효율적인 모니터링 솔루션

     * 시계열 데이터에 최적화되어 있으며, 오래된 시계열이 지속적으로 새로운 시계열로 빠른 속도로 교체되는 경우에도 다양한 기능을 제공
     * Prometheus용 장기 스토리지: Prometheus 및 Graphite 대체 솔루션으로 Grafana에서 바로 사용(Drop-in replacement 가능)
     * 강력한 스트림 집계: StatsD 대안으로 활용 가능
     * 대규모 데이터에 적합: APM, Kubernetes, IoT 센서, 커넥티드 카, 산업 텔레메트리, 금융 데이터 등 다양한 엔터프라이즈 워크로드 지원
     * 쿼리: PromQL 과 더 성능이 좋은 MetricsQL 둘다 지원
     * 편리한 셋업: 의존성 없으며, 작은 싱글 바이너리, 커맨드 라인 플래그로 설정 가능. 기본 값이 파인튜닝 되어있음. 인스턴트 스냅샷으로 백업&복원 가능
     * 글로벌 쿼리 뷰: 여러개의 Prometheus 인스턴스 쏘는 여러 데이터 소스 통합 쿼리 가능
     * 다양한 프로토콜 지원:
          + Prometheus exporter remote write API, exposition format
          + InfluxDB line 프로토콜 (HTTP,TCP,UDP)
          + Graphite 프로토콜 with tags
          + OpenTSDB 풋 메시지, HTTP OpenTSDB /api/put 리퀘스트
          + JSON line 포맷, 임의의 CSV
          + 네이티브 바이너리 포맷
          + DataDog agent, DogStatsD, NewRelic agent, OpenTelemetry 등
     * NFS기반 스토리지 지원: Amazon EFS, Google Firestore

  엔터프라이즈 버전의 추가 기능

     * 이상 감지(Anomaly Detection): 복잡한 이상 현상을 자동으로 감지하여 경보 규칙 간소화
     * 정기 백업 절차 자동화
     * 다중 보존 기간으로 스토리지 비용 절감
     * 다운샘플링: 오래된 데이터에 대한 성능 최적화
     * 안정적 릴리스: 장기 지원(LTS) 제공 및 기술지원 맞춤형 기능 개발 가능

   저도 요즘 써보고 있는데 HA와 LongTerm Storage 구성할때 Thanos Mimir Cortex 같은 다른 대안들보다 아키텍쳐가 단순한게 제일 좋더라구요. PromQL에서 이해안되는 동작방식이나 지원 안되는 기능들도 MetricsQL로 되서 좋았구요. 근데 Thanos Storage GW처럼 Object Storage랑 심리스하게 연동되는게 안되는건 조금 아쉬운부분...

   ""PromQL에서 이해안되는 동작방식"" 극 공감합니다.

   M3 - 오픈소스 Metrics 플랫폼
   4년전에 올라왔던 위 글의 댓글에서 VictoriaMetrics가 좋아보이지만 메인테이너가 혼자라서 불안하다고 적은 사람이 있었는데 이제는 컨트리뷰터가 294명이 되었네요.
"
"https://news.hada.io/topic?id=18083","Show GN: Gather Town과 유사한 실시간 상호작용 가능한 가상 공간을 Serverless 아키텍처로 구현한 프로젝트 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show GN: Gather Town과 유사한 실시간 상호작용 가능한 가상 공간을 Serverless 아키텍처로 구현한 프로젝트

   Gather Town, ZEP 같은 실시간 상호작용 가상 공간을 Serverless로 개발하고 있는 개인 프로젝트입니다.

   주요 기술 스택:
     * Frontend: React.js, Phaser.js (2D TopDown 뷰 렌더링)
     * Backend: Supabase (인증, 실시간 데이터베이스)
     * 실시간 통신: Cloudflare Calls (WebRTC SFU), ExpressTURN
     * 배포: Netlify (CI/CD, 호스팅)

   현재 구현된 기능:
     * 실시간 음성 채팅
     * 텍스트 채팅
     * 2D 가상 공간에서의 캐릭터 이동 및 상호작용

   개발 로드맵:
     * 영상 통화 기능
     * Spatial Audio
     * Noise Suppression
     * 룸 생성 및 관리 시스템
     * 사용자 커스터마이징 옵션
     * 다양한 상호작용 기능 추가
     * self-host가 가능하도록 SFU을 LiveKit으로 변경

   시작 단계이고 혼자 처음 해보는 것이라 아직 부족한 것이 많습니다. 기여와 피드백은 언제나 환영합니다.

   github: https://github.com/hissinger/small-village
"
"https://news.hada.io/topic?id=18065","Hetzner에서 Kubernetes 사용으로 인프라 비용 75% 절감","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Hetzner에서 Kubernetes 사용으로 인프라 비용 75% 절감

  Hetzner

     * Hetzner로의 이전은 주로 비용 절감을 위한 것임. Hetzner의 가격은 세계적으로 경쟁력이 있음.
     * Hetzner는 가상 머신과 베어 메탈 머신을 제공하며, AWS에 비해 제한적이지만 가격으로 보완함.
     * Hetzner로 이전하면서 인프라 비용을 75% 이상 절감함.

  Kubernetes on Hetzner

    셀프 매니징 Kubernetes

     * DigitalOcean에서 Kubernetes를 운영했으며, Hetzner에서도 셀프 매니징 방식으로 운영함.
     * Hetzner는 관리형 Kubernetes 제어 플레인을 제공하지 않으므로 직접 관리해야 함.
     * Terraform과 Puppet을 사용하여 노드를 관리하고 구성함.

    노드 역할

     * 노드 명명 규칙을 사용하여 클러스터 내 역할을 간단하게 유지함: control-plane, worker, database.
     * 역할 추가는 간단하지만 자원 사용의 효율성을 저해할 수 있음.

    노드 구축

     * Terraform을 사용하여 클러스터를 부트스트랩함.
     * Hetzner는 관리형 방화벽과 네트워킹을 제공하며, Terraform으로 쉽게 구성 가능함.
     * 서버는 Terraform으로 완전히 관리되며, 역할별 모듈을 작성하여 서버 추가를 간단하게 함.

    네트워킹

     * Tailscale VPN을 사용하여 노드에 대한 관리 연결을 수행함.
     * Tailscale은 NAT 홀 펀칭을 제공하여 포트를 닫아도 안전하게 연결 가능함.
     * Hetzner의 관리형 방화벽과 Ubuntu의 UFW를 사용하여 포트를 차단함.
     * Calico를 사용하여 컨테이너 네트워킹 인터페이스를 구성함.

    스토리지

     * Hetzner는 nVME SSD와 SSD 기반의 블록 스토리지를 제공함.
     * Hetzner의 볼륨은 스냅샷 기능이 없으므로, 데이터 백업은 수동으로 수행해야 함.
     * 데이터베이스 노드에서는 Local Persistence Volume Static Provisioner를 사용하여 로컬 볼륨을 사전 프로비저닝함.

    백업

     * Hetzner는 볼륨 백업을 제공하지 않지만 전체 서버 백업을 제공함.
     * VMware의 Velero를 사용하여 네임스페이스와 PVC를 백업함.
     * Postgres의 경우 pgBackRest를 사용함.

    추가 기능

     * SealedSecrets를 사용하여 비밀 관리.
     * Node Exporter, Prometheus, Grafana, Loki를 사용하여 클러스터 모니터링.
     * Alertmanager를 사용하여 Slack과의 알림 통합.

  Hetzner에서 Kubernetes 운영에 대한 생각

     * Hetzner로의 이전은 약 1주일이 소요되었으며, 추가 테스트 및 튜닝에 4주가 걸림.
     * Hetzner의 가격은 합리적이며, 다른 제공업체에 비해 낮게 유지될 것이라 믿음.
     * Hetzner의 IP 품질 문제와 고객 서비스에 대한 제한 사항이 있음.
     * Hetzner는 빠르게 새로운 기능을 출시하지만, 수익성이 낮은 서비스는 빠르게 중단할 수 있음.
     * 중앙 유럽 데이터센터 위치는 독일의 Falkenstein, Nuremberg, 핀란드의 Helsinki에 있음.

  요약

     * 이 전환은 원활하게 진행되었으며, 인프라 비용을 75% 이상 절감하고 클러스터의 컴퓨팅 자원을 두 배로 늘림.
     * Hetzner는 비용 절감이 필요한 경우 매우 유리한 선택임.
     * Hetzner의 오픈 소스 컨트롤러는 로드 밸런서 관리와 지속적인 볼륨 연결을 용이하게 함.

        Hacker News 의견

     * 지속 가능성이나 '그린 호스팅'에 대한 언급이 없음을 지적하며, Hetzner의 유럽 데이터 센터는 친환경 에너지를 사용하지만 미국은 그렇지 않음을 언급함
     * Hetzner에서 Kubernetes 클러스터를 운영한 경험을 공유하며, AWS 대비 비용이 20% 수준으로 낮을 수 있지만, 그에 따른 많은 트레이드오프가 있음을 설명함
          + Kubernetes 클러스터 업데이트를 직접 관리해야 했고, Ceph 및 Kubernetes의 다양한 버그를 겪었으며, 많은 작업과 모니터링이 필요했음을 강조함
          + AWS와 같은 주요 클라우드 제공업체를 사용하면 관리 서비스 덕분에 운영 부담이 줄어듦
          + Hetzner는 비용이 저렴하지만, DevOps 작업에 드는 추가 시간이 그 절감을 상쇄할 수 있음을 설명함
     * 과거 웹 호스팅 경험에서 Hetzner IP를 차단했던 경험을 공유하며, 저렴한 VM 제공업체와 관련된 문제를 언급함
     * Kubernetes와 관련된 비용 절감 아이디어를 공유하며, 온프레미스 노드와 클라우드 제공업체의 노드를 혼합하여 클러스터를 설정하는 아이디어를 제안함
          + egress 비용이 주요 변수일 것이라고 생각함
     * 클러스터와 워크로드에 대한 설명이 부족하다고 느끼며, 절감된 비용의 절대적 크기를 알고 싶다고 언급함
     * Hetzner에서 Kubernetes를 설정하고 관리하는 방법으로 GitHub 프로젝트를 추천함
     * Hetzner의 지원 시스템 문제로 인해 게임 서버가 중단된 경험을 공유하며 주의를 당부함
     * Hetzner의 로드 밸런서를 Kubernetes에 통합하기 위해 얇은 오퍼레이터를 구현한 경험을 공유하며, 관련 프로젝트를 소개함
     * Heroku에서 DigitalOcean으로 전환하여 75%의 비용 절감을 경험했으며, Hetzner로 전환했다면 93% 절감이 가능했을 것이라고 추측함
     * DigitalOcean의 관리형 클러스터에 대한 오해를 바로잡으며, 노드 비용이 추가되지 않음을 설명하고, DigitalOcean의 매력을 강조함
"
"https://news.hada.io/topic?id=18033","바츠와프 슈파코프스키의 기하학적 라인 아트 (2017)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     바츠와프 슈파코프스키의 기하학적 라인 아트 (2017)

        Hacker News 의견

     * 디지털 기하학 예술을 만들며, 반복과 변형이 예술에서 강력한 도구가 될 수 있음을 언급함. Wacław의 작품이 더 많은 인정을 받아야 함을 강조함
          + 기하학과 수학이 매력적일 수 있지만, 상업적으로는 NFT 외에는 인기가 적음
          + Iterated Function System을 언급하며 두 폴란드 인물 Wacław Sierpiński와 Wacław Szpakowski의 연결을 흥미롭게 설명함
          + 두 인물이 같은 매체에서 언급되는 것을 찾는 것이 흥미로움
          + Axel Rohlfs의 책 ""Art, algorithm and ambiguity""를 발견함
     * Op Art라는 예술 운동을 소개하며, Bridget Riley의 작품을 추천함
          + 2003년 Tate에서 열린 Riley 전시회를 언급하며, 큰 규모의 작품이 시각적 착시를 일으켰음을 설명함
          + 20세기 음악을 공부하면서 Bridget Riley의 작품을 접했음을 언급함
     * Claude Mellan의 1649년 작품을 떠올리며, 단일 연속선으로 철에 새긴 작품임을 설명함
     * PCB 안테나를 연상시키며, RF 특성을 실험해보고 싶음을 언급함
     * Logo 연습의 금광이라 표현하며, Kolmogorov 복잡성으로 분류할 수 있음을 설명함
     * Wacław의 작품 전시회를 강하게 연결되었음을 설명하며, 우연한 순간이었음을 강조함
     * Space-filling curve를 떠올리게 함
     * 작품이 만들어진 시대적 배경을 고려해야 함을 강조하며, 예술가들이 선구자적 역할을 한다고 설명함
     * 디지털 시대에도 재능 있는 창작자들이 발견과 배포의 문제로 인해 여전히 잘 알려지지 않을 수 있음을 언급함
          + 단일 선 드로잉에 대한 비주기적 타일링의 유사성을 궁금해함
"
"https://news.hada.io/topic?id=18057","HN 공개: Markwhen: 타임라인을 위한 Markdown","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   HN 공개: Markwhen: 타임라인을 위한 Markdown

     * Markwhen
          + 마크다운과 유사한 저널 언어로, 로그, 간트 차트, 블로그, 피드, 노트, 저널, 일기, 할 일 목록, 타임라인, 캘린더 등 시간에 따라 발생하는 모든 것을 기록하는 데 사용됨
          + 기본 문법, 그룹, 태그, 체크리스트, 링크, 시간대, 반복, 프론트매터, 속성 등을 지원함
          + 다양한 날짜 형식 지원 및 긴 설명 가능
     * Meridiem
          + 협업 편집, 사용자 정의 명령어, 스니펫, 사용자 정의 시각화, 자동 완성, 이벤트 강조 등을 지원하는 Markwhen 편집기
          + macOS arm64 베타 버전 다운로드 가능
     * 도구 및 확장 기능
          + VS Code 확장, Obsidian 플러그인, Discord, Github 등 다양한 플랫폼에서 사용 가능
          + 일반 이슈 추적, 타임라인, 파서, 클라이언트 라이브러리, 캘린더, 이력서 등의 기능 제공

   이 프로젝트는 시간 기반 기록을 쉽게 작성할 수 있는 도구로, 다양한 플랫폼과의 통합 및 협업 기능을 제공하여 사용자에게 유용함.

        Hacker News 의견

     * Markwhen의 창시자가 사용자들의 긍정적인 반응에 기쁨을 느끼고 있음
          + Markwhen은 VS Code 확장, Obsidian 플러그인, CLI 도구, Meridiem 웹 편집기로 제공됨
          + 최근 개발 사항으로는 Dial이라는 브라우저 내 편집기, 이벤트 속성 기능, remark.ing이라는 블로그 사이트가 있음
     * Markwhen은 cheeaun의 프로젝트에서 영감을 받아 개발되었음
          + 사용자가 자신의 인생 사건을 시각적으로 표현할 수 있는 타임라인을 생성할 수 있음
     * 댓글 작성자는 Markwhen이 매우 멋지다고 생각하며, 사용할 기회가 있기를 바람
     * Markwhen이 판타지 타임라인에도 적용 가능한지 궁금해하는 사용자 있음
          + 사용해본 결과, 해당 용도에는 적합하지 않다고 판단함
     * 타임라인에서 종속 작업을 위한 구문이 있는지 궁금해하는 사용자 있음
          + 원래 작업의 날짜가 변경되면 종속 작업도 자동으로 이동하는 기능을 원함
     * 웹사이트의 타이포그래피가 훌륭하다고 평가하는 사용자 있음
          + 기본 구문 예제에서 날짜 범위를 더 명확히 보여주기를 바람
     * Markwhen이 Obsidian 플러그인으로 사용 가능하다는 정보를 공유하는 사용자 있음
     * Markwhen이 Markdown 기반의 양식 생성기인 blocks.md를 떠올리게 한다고 언급하는 사용자 있음
     * 타임라인 기반의 간단한 입력 도구를 찾고 있었던 사용자에게 Markwhen이 매우 훌륭하다고 평가받음
"
"https://news.hada.io/topic?id=18072","월드 랩스: 단일 이미지로 3D 세계 생성 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       월드 랩스: 단일 이미지로 3D 세계 생성 기술

     * 3D 세계 생성 AI 시스템
          + World Labs는 단일 이미지에서 3D 세계를 생성하는 AI 시스템을 개발함.
          + 이 기술은 영화, 게임, 시뮬레이터 등 다양한 디지털 콘텐츠 제작 방식을 혁신할 가능성을 가짐.
     * 세계 탐험
          + 사용자는 생성된 3D 세계를 탐험할 수 있으며, 화살표 키나 WASD 키를 사용하여 이동하고 마우스로 시점을 조정할 수 있음.
     * 카메라 효과
          + 가상 카메라를 통해 장면을 실시간으로 렌더링하며, 얕은 심도 효과나 돌리 줌 같은 사진 효과를 구현할 수 있음.
     * 3D 효과
          + 3D 장면 예측은 지속적인 현실감, 실시간 제어, 올바른 기하학적 구조를 제공함.
          + 깊이 맵을 통해 각 픽셀의 카메라와의 거리를 시각화할 수 있음.
     * 그림 속으로 들어가기
          + 유명한 예술 작품을 새로운 방식으로 경험할 수 있도록 세계를 생성함.
          + 원본 그림에 없는 부분은 모델이 생성함.
     * 창의적 워크플로우
          + 3D 세계 생성은 다른 AI 도구와 자연스럽게 결합되어 새로운 경험을 창출함.
          + 텍스트-이미지 모델을 사용하여 텍스트로부터 이미지를 생성하고, 이를 기반으로 3D 세계를 만듦.
     * 미래 전망
          + World Labs는 3D 세계의 크기와 충실도를 개선하고, 사용자와의 상호작용 방식을 실험 중임.
          + 향후 릴리스에 대한 정보는 대기자 명단을 통해 확인 가능하며, 관심 있는 사람은 참여를 권장함.

        Hacker News 의견

     * 데모를 시도해보면, 애니메이션 이미지가 오해를 불러일으킴. 몇 걸음 걷다 보면 보이지 않는 벽에 부딪히게 되어 실망스러움이 큼. 초기 단계라는 것을 이해하지만 과대 광고된 느낌이 있음
     * VR 헤드셋으로 3D 영화를 볼 때 머리를 움직이면 3D 환상이 깨짐. 3D 게임에서는 머리를 움직이면 공간을 탐색할 수 있음. 영화의 모든 프레임에 이를 적용하면 약간의 움직임과 시점 변화를 유지할 수 있음. 하지만 감독과 촬영 감독의 의도가 손상될 수 있음
     * 작은 영역에 대한 불만이 있지만, 이미지를 3D 세계로 변환한 것은 놀라운 기술임. AI가 점점 일반화되고 있지만, 여전히 놀라운 성과임
     * Depth Anywhere를 사용하여 360º 이미지를 가상 깊이 맵으로 변환하고, 이를 포인트 클라우드에 적용하여 렌더링하는 방법이 있음. World Lab 예제와 달리 포인트 클라우드의 경계를 넘어 접근 방식의 결함을 검사할 수 있음. 여전히 개선이 필요함
     * 이 기술은 멋지지만, cat-4d.github.io만큼 인상적이지 않음
     * AI 데모를 많이 봐서 그런지, 기술을 실제로 유용하게 만드는 방법을 생각해내야 한다는 점에서 다소 무감각해짐. ""Step into Paintings"" 섹션은 재미있었지만, 소스 자료에서 벗어나면 모델의 한계가 드러남. 새로운 방식으로 예술 작품을 경험할 수 있지만, 좋은 경험은 아님
     * XYZ가 Unreal과 NVIDIA Isaac 녹화를 일반화할 수 있을 것이라는 기대가 있음. XYZ가 diffusion-transformers인지, Chameleon인지, 아니면 새로운 아키텍처인지 궁금함. 모델 개발에는 시간이 걸리며, 비용이 많이 들 수 있음. 이 팀은 매우 재능 있지만, 충분한 자금이 없을 수도 있음
     * 이러한 프로젝트의 좋은 점이 과도한 주장으로 인해 흐려지는 경우가 많음
     * 기본 이미지는 렌더링된 것으로 보이며, 조명, 그림자 등이 포함됨. 다른 도구를 사용했을 때는 예제 이미지에서만 잘 작동하고, 다른 이미지를 사용하면 검고 평평한 형태가 나옴. 따라서 헤드라인은 ""우리가 훈련한 모델로 단일 이미지에서 3D 세계 생성""이 되어야 함
     * 처음 시도했을 때 ""Out of bounds"" 메시지를 받아 놀랐음. ""Looking Ahead"" 섹션을 보니 크기와 정확도를 개선하고 있음
"
"https://news.hada.io/topic?id=18071","페이스북의 Little Red Book","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         페이스북의 Little Red Book

     * 2012년, 페이스북은 사용자 수가 10억 명에 도달하면서 급격한 확장이 큰 그림을 유지하는 능력을 초과하는 도전에 직면함. 내러티브가 분산되면서, 회사와 주커버그의 비전을 연결하는 본질이 희미해지기 시작함.
     * 이 문제를 해결하기 위해 페이스북은 그들의 이야기를 리틀 레드 북으로 정리하여 내부에 배포하는 대담한 결정을 내림. 이 책은 디자이너 벤 배리가 제작하였으며, 페이스북의 정신—무엇이든 부수고, 크게 생각하고, 빠르게 움직이는 것—을 선언문으로 압축함. 이는 단순한 핸드북이 아닌, 폭발적인 성장 속에서 문화 확장의 문제를 해결하는 정체성의 선언이었음. 직원들에게 ""이것이 우리의 정체성이다. 이것이 우리가 존재하는 이유다""라는 메시지를 상기시킴.
     * 오늘날 남아있는 책의 사본은 거의 없으며, 인터넷에 떠도는 대부분의 디지털 버전은 해상도가 낮음.
     * 몇 년간 이베이를 통해 간헐적으로 확인한 끝에 한 사본을 발견함. 몇 주 전 우리 사무실에 도착함.
     * 더 나은 디지털 버전을 만들기 위해 뉴욕의 몇몇 공공 도서관과 대학에 연락함. 한 곳에서 $150,000짜리 DT-BC100 스캐너를 사용할 수 있도록 허락받음.
     * 이는 단순한 책의 스캔본이 아닌, 스토리텔링의 힘에 대한 증거임. 이야기는 믿음을 형성하고, 낯선 사람을 팀원으로, 팀을 운동으로, 운동을 세상을 바꿀 수 있는 사업으로 전환시킴.
     * 여기 가장 높은 품질의 공개 가능한 리틀 레드 북 버전(구글 Drive PDF 링크)이 있으며, 위대한 회사들이 어떻게 문화와 아이디어를 확장하는지 궁금한 사람들을 위해 보존됨.

        Hacker News 의견

     * 인터넷에서 분노를 표출하는 것은 중독적이고 반복적이며 지루하다는 의견이 있음
          + 진보는 주로 내러티브에 기반하며, 이는 우리가 집중하고 동기부여를 유지하기 위해 스스로에게 이야기하는 것임
          + 내러티브는 반드시 사실일 필요는 없으며, 일부 현실에 기반한 설득력 있는 이야기여야 함
          + 진실은 시간이 지나고 논란이 거의 없으며 입증된 사실로 남음
          + 내러티브는 순간적이고 추진력을 주며, 진실은 시간에 걸쳐 강력함
          + 진실에도 내러티브가 존재함
     * Facebook을 통해 오랜 친구와 다시 연결되었으나, 개인정보 침해로 인해 친구가 계정을 삭제한 경험이 있음
          + Facebook은 사람들을 연결하는 순수한 목적이 있었으나, 시간이 지나면서 개인정보 처리에 대한 우려가 커짐
          + 많은 젊은 사람들이 Facebook을 사용하지 않으며, 다시 활성화될 가능성이 낮음
     * 과거 기술 산업에 대한 낙관적이고 이상주의적인 시각이 있었음을 회상함
          + 당시 실리콘밸리에서는 기술이 세상을 더 나은 방향으로 변화시킨다고 믿었음
          + Facebook, Twitter, iPhone이 사람들을 연결하고 갈등을 줄일 것이라는 기대가 있었음
     * Meta 사무실에는 ""이제 당신의 회사입니다""와 같은 슬로건이 있었으나, 해고가 시작되면서 조롱의 대상이 되었음
     * Ben Barry의 웹사이트 아카이브에서 Facebook 책에 대한 페이지가 있음
     * Facebook이 사업을 목적으로 만들어지지 않았다는 인용문과 Instagram이 사업을 목적으로 만들어졌다는 Kevin Systrom의 발언이 대조적으로 언급됨
     * Facebook이 小红书를 인수하는 것이 예견된 움직임일 수 있으나, 그 시기는 이미 오래 전임
"
"https://news.hada.io/topic?id=18102","Foursquare Open Source Places - 지리공간 커뮤니티를 위한 새로운 기초 데이터셋","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Foursquare Open Source Places - 지리공간 커뮤니티를 위한 새로운 기초 데이터셋

     * FSQ OS Places는 전 세계 1억 개 이상의 관심 장소(POI) 데이터셋을 제공하는 오픈 소스 프로젝트
          + 1억개가 넘는 글로벌 POI, 1000+개의 카테고리, 200+개의 국가과 지역, 22개의 핵심 속성을 포함하며 매월 업데이트됨
          + Apache 2.0 라이선스 하에 상업적 사용 가능
     * 목표: 폐쇄적인 대규모 독점 데이터 시스템의 한계를 넘어서기 위해, 장소 데이터의 오픈 소스 접근을 제공

왜 Open Source Places인가?

     * Foursquare는 수년간 구축한 독점 데이터셋의 일부를 커뮤니티에 공개
     * 내부에서도 의문이 제기되었으나, 지리공간 생태계 발전을 위해 과감히 결정
     * 정확한 글로벌 POI 데이터베이스의 중요성
          + 물리적 세계와 시스템의 연결
          + 공간 컴퓨팅(Spatial Computing)에서 시스템이 주변 환경을 정확히 이해하는 것은 필수
          + 정확하지 않은 데이터는 사용자 경험에 부정적 영향을 미침 (예: 잘못된 경로 안내, 증강현실 오류)
     * 글로벌 POI 데이터베이스 구축 및 유지는 어려움
          + 실시간 동기화된 데이터베이스의 유지는 필요하지만 현실 세계를 대표하는 POI 데이터셋 구축은 기술적·자본적 도전 과제
          + 최첨단 디지털 시스템과 인간 확인(Human-in-the-loop) 의 협력 필요
     * 대규모 독점 플랫폼(예: Google Maps)이 없는 상황이라면, 전 세계적이고 정확한 장소 데이터의 기본 계층 구축은 오픈 소스 커뮤니티 접근이 가장 적합한 해결책임

Foursquare의 문제 해결 접근 방식

     * 기존 접근 방식인 데이터 연합(Federation) 모델의 문제
          + 기존의 글로벌 장소 데이터 해결 노력은 오픈 소스 커뮤니티보다 데이터 연합에 가깝다는 한계가 있음
          + 결과적으로 지리 위치 데이터에서 흔히 발생하는 디지털 에코 챔버 현상 심화:
               o 잘못된 데이터가 여러 데이터셋에 반복적으로 전파
     * Foursquare는 성공적인 글로벌 POI 데이터 운영을 위해 다음 세 가지 핵심 요소를 제시:
          + 일관되고 포괄적인 장소 운영 시스템 : 데이터 간소화와 통합을 통해 현실 세계를 정확히 반영
          + 대규모 AI 기여 : 고도화된 도구를 활용하여 인공지능이 효율적으로 기여
          + 대규모 인간 확인 : 인공지능과 협력해 데이터의 정확성과 신뢰성을 보장
     * Foursquare Place Engine: 혁신적 크라우드소싱 시스템
          + 최초의 협업 기반 시스템
          + AI와 인간이 협력하여 장소 데이터를 실제 세계와 동기화
          + 자세한 내용은 Place Engine 소개 참고
     * Foursquare는 AI와 인간의 협력을 바탕으로 기존 접근 방식의 한계를 극복하고, 글로벌 장소 데이터의 정확성과 확장성을 동시에 실현하고자 함

기여자 및 커뮤니티 참여

     * 오늘 발표와 함께 FSQ OS Places의 최신 버전 다운로드 가능
     * 장소 데이터 구축에 기여할 수 있는 커뮤니티 기여 도구 FSQ Placemaker 곧 공개 예정
          + Placemaker 대기자 명단에 등록하여 프로젝트 업데이트 알림 받기
     * 향후 계획
          + 개발 커뮤니티와 협력하여 생태계 성장 지원
          + 데이터 접근 및 사용 방법 추가 제공
          + 기계 학습 모델 등 오픈 소스 프로젝트 추가 예정

   POI 이름하고 위경도만 주는 줄 알았는데, 생각보다 정보를 많이 주네요
"
"https://news.hada.io/topic?id=18115","더 이상 만들지 않는 Yamaha DX7 키보드","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       더 이상 만들지 않는 Yamaha DX7 키보드

     * 그들은 더 이상 그렇게 만들지 않는다: Yamaha DX7 키보드
     * Yamaha DX7 신디사이저는 1980년대 대중음악의 소리를 정의한 악기임. DX7은 무한한 소리 텍스처를 생성할 수 있었지만, 대부분의 음악가는 32개의 기본 사운드만 사용했음. 이로 인해 DX7의 소리는 즉시 인식 가능했음.
     * Mark I DX7의 특징
          + Mark I DX7은 튼튼한 구조로 만들어졌으며, 사용하기 불편한 멤브레인 키패드를 가지고 있었음. 그러나 이는 맥주 유출에 강했음.
          + DX7의 특별함은 새로운 소리 생성 접근 방식에 있었음. 대부분의 전자 키보드는 아날로그 방식으로 소리를 생성했지만, DX7은 주파수 변조를 사용했음.
     * 주파수 변조와 알고리듬
          + DX7은 주파수 변조를 통해 소리를 생성했으며, 이는 기존의 아날로그 신디사이저와는 다른 방식이었음.
          + DX7의 주파수 변조 구성 요소는 '오퍼레이터'라고 불렸으며, 16개의 폴리포닉 노트를 위해 96개의 오퍼레이터가 있었음.
          + 오퍼레이터의 배열은 '알고리듬'으로 알려져 있었으며, 이는 다양한 소리를 생성할 수 있게 했음.
     * DX7의 영향과 확장
          + Yamaha의 '오퍼레이터' 기술은 PC 사운드 카드로 확산되었으며, OPL2와 OPL3 같은 사운드 칩으로 발전했음.
          + Yamaha는 1984년에 CX5M이라는 음악 작곡 워크스테이션을 출시했으며, 이는 오퍼레이터 합성 모듈을 포함하고 있었음.
     * DX7의 성공과 한계
          + Yamaha는 150,000대의 DX7을 판매했으며, 이는 키보드 악기로서는 엄청난 숫자였음.
          + DX7의 프로그래밍은 어려웠으며, 사용자 인터페이스와 설정의 복잡성 때문에 거의 사용되지 않았음.
     * DX7의 쇠퇴
          + DX7의 쇠퇴는 마이크로프로세서와 메모리의 비용 하락 때문이었음. FM 합성은 초기 80년대의 디지털 기술로 구현하기 쉬웠지만, 샘플링 기술이 발전하면서 그 필요성이 줄어들었음.
          + 현대의 디지털 음악 제작은 대부분 샘플링에 기반하고 있으며, DX7과 같은 수학적 모델링은 거의 사용되지 않음.
     * 결론
          + DX7은 한때 엄청난 인기를 끌었지만, 기술의 발전과 함께 그 중요성이 감소했음. 현대의 키보드에서 DX7의 소리를 원한다면, 실제 DX7을 샘플링하는 것이 더 쉬움.

        Hacker News 의견

     * 높은 옥타브에서 소리가 '둔탁'해지는 문제는 DAC의 한계가 아니라 위상 변조 알고리즘의 문제로 발생함. 이는 고조파가 나이퀴스트 주파수 이상일 때 가청 범위로 반사되어 디지털 아티팩트를 생성함. DX 설계자들은 키보드 스케일링을 통해 이 문제를 해결하려 했음.
     * DX7과 같은 FM 신디사이저는 한때 인기를 끌었으나, 기술의 발전으로 인해 체계적인 디지털 사운드 생성이 가능해지면서 인기가 줄어듦. 그러나 FM 합성은 여전히 다양한 형태로 사용되고 있음.
     * DX7의 기술적 세부 사항에 관심이 있다면, 역설계 작업과 관련된 자료가 있음. Ken Shirriff의 분석 작업도 참고할 수 있음.
     * DX7의 소프트웨어 에뮬레이션이 현실적이며, Dexed와 같은 프로그램이 그 예임.
     * Prophet 5, Oberheim, Roland Jupiter 8, Yamaha CS80 등은 DX7 이전에 존재했으며, 무대와 스튜디오에서 널리 사용되었음. 그러나 매우 비쌌음.
     * DX7은 벨로시티에 반응하는 키보드와 16음의 폴리포니를 제공하여 차별화되었음. 이는 복잡한 재즈 코드 연주에 유리했음.
     * Yamaha는 물리적 모델링을 통해 합성을 한 단계 더 발전시키려 했으나, 샘플링이 실제 소리를 모방하는 데 더 효과적임.
     * FM 합성의 발명가 John Chowning과 관련된 다큐멘터리가 있으며, DX7과 Synclavier가 언급됨.
     * Yamaha의 엔지니어들은 제한된 자원으로 많은 것을 이루었음. OPL2와 OPL3 칩셋을 사용한 사운드 생성 방식이 그 예임.
     * DX7의 사운드는 빠른 정수 연산을 통해 생성되며, 이는 독특한 소리의 특성을 만듦.
     * 게임 Wilderplace의 사운드 효과와 음악에 WebDX7을 사용했으며, DX7의 패치는 명확하고 따뜻한 느낌을 줌.
     * 수학을 사용한 소리 생성은 샘플링 기술의 발전으로 인해 구식이 되었음. 그러나 Ensoniq EPS-16+와 같은 새로운 기술이 등장하면서 DX7의 사용이 줄어듦.
     * 1985-1995년 사이에 비디오 게임에서 사용된 PC 사운드 카드와 신디사이저 칩셋은 매우 일반적이었음.
"
"https://news.hada.io/topic?id=18047","NTFS 파일 시스템을 오픈 소스 Btrfs로 인플레이스 변환하는 Ntfs2btrfs 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NTFS 파일 시스템을 오픈 소스 Btrfs로 인플레이스 변환하는 Ntfs2btrfs 기술

Ntfs2btrfs

   Ntfs2btrfs는 Microsoft의 NTFS 파일 시스템을 오픈 소스 파일 시스템인 Btrfs로 변환하는 도구임. 이는 ext2를 변환하는 btrfs-convert와 유사함. 변환 후 원본 이미지는 image/ntfs.img로 저장되며, 변환을 유지하고 싶다면 이를 삭제하여 공간을 확보할 수 있음. 안정적이라고 생각되지만, 문제가 발생할 경우 책임지지 않음. Windows용 Btrfs 파일 시스템 드라이버인 WinBtrfs도 관심을 가질 만함. Eric Biggers에게 감사의 말을 전하며, 그는 Windows 10의 ""WOF 압축 데이터""를 성공적으로 역설계하였고, 그의 코드를 사용함.

  사용법

     * Windows: 관리자 명령 프롬프트에서 ntfs2btrfs.exe D:\ 실행
          + 부팅 드라이브나 사용 중인 페이지 파일이 있는 드라이브에서는 작동하지 않음
          + WinBtrfs를 사용하는 경우 image 서브볼륨의 읽기 전용 플래그를 해제해야 삭제 가능
     * Linux: 루트 권한으로 ntfs2btrfs /dev/sda1 실행

  설치

     * Windows: Releases 페이지에서 최신 Zip 파일 다운로드 또는 Scoop 사용
     * Linux:
          + Arch
          + Fedora (Conan-Kudo 덕분에 가능)
          + Gentoo - guru 저장소의 sys-fs/ntfs2btrfs로 사용 가능
          + Debian (alexmyczko 덕분에 가능)
          + Ubuntu (alexmyczko 덕분에 가능)
          + openSUSE (David Sterba 덕분에 가능)
     * 다른 배포판이나 운영 체제의 경우 직접 컴파일 필요

  변경 로그

     * 20240115
          + GCC 14에서 컴파일 문제 수정 (-Werror=incompatible-pointer-types 기본 활성화)
     * 20230501
          + btrfs check에서 진단되지 않는 순서 문제 수정
          + 잘못된 레벨 값으로 메타데이터 항목이 작성되는 문제 수정
          + 너무 긴 이름의 ADS 건너뜀
     * 20220812
          + 체크섬 계산을 건너뛰는 --no-datasum 옵션 추가
          + LXSS / WSL 메타데이터 보존
          + 소문자 드라이브 문자가 인식되지 않는 문제 수정
          + 디스크 마지막 메가바이트에 파일이 있을 때 손상 문제 수정
     * 20210923
          + (Btrfs) 압축 지원 추가 (zlib, lzo, zstd)
          + 다른 해시 알고리즘 지원 추가: xxhash, sha256, blake2
          + NTFS로 롤백 지원 추가
          + 많은 inode가 있는 볼륨의 변환 속도 증가
          + 슈퍼블록 위치에 조각난 파일이 있을 때 버그 수정
          + 보안 설명자를 읽을 때 버퍼 오버플로우 수정
          + btrfs check에서 감지되지 않는 파일 시스템 손상 문제 수정
     * 20210523
          + 큰 압축 파일 처리 개선
     * 20210402 (소스 코드 전용 릴리스)
          + 비-amd64 아키텍처에서의 컴파일 문제 수정
     * 20210105
          + NTFS 압축 지원 추가
          + ""WOF 압축 데이터"" 지원 추가
          + 희소 파일로 인한 문제 수정
          + 기타 버그 수정
     * 20201108
          + 오류 처리 개선
          + NTFS가 손상되거나 깨끗하지 않을 때 더 나은 메시지 추가
          + 재배치 처리 개선
     * 20200330
          + 초기 릴리스

  컴파일

     * Windows: 최신 MSVC 버전에서 소스 디렉토리를 열고, CMakeLists.txt를 오른쪽 클릭하여 컴파일
     * Linux:
          + mkdir build
          + cd build
          + cmake ..
          + make
          + libfmt 설치 필요 - 패키지 관리자에 있을 것임
          + 압축 지원은 zlib, lzo, zstd 필요 - 패키지 관리자에 있을 것임. 비활성화하려면 cmake 옵션 WITH_ZLIB, WITH_LZO, WITH_ZSTD 참조

  작동하는 것

     * 파일
     * 디렉토리
     * 심볼릭 링크
     * 기타 재분석 지점
     * 보안 설명자
     * 대체 데이터 스트림
     * DOS 속성 (숨김, 시스템 등)
     * 원본 NTFS 이미지로 롤백
     * LXSS 메타데이터 보존

  작동하지 않는 것

     * Windows의 오래된 확장 속성 (사용하지 않음)
     * 큰 ADS (16KB 이상) (사용하지 않음)
     * 대소문자 구분 플래그 보존
     * 비정상적인 클러스터 크기 (4KB가 아님)
     * 암호화된 파일

  Btrfs로 Windows 부팅 가능 여부

     * 가능하지만 특정 조건이 맞아야 함. Quibble 참조.

        Hacker News 의견

     * ""hold-my-beer"" 수준이 매우 높음
          + 매우 위험하거나 도전적인 행동을 할 때 사용하는 표현임
     * 이전에 시도했을 때 읽기 전용 디스크가 되었음
          + 개선되었기를 바람
     * 매우 멋지지만, 사람들이 이 소식을 듣기까지 최소 일주일은 걸릴 것임
          + 2년 동안 미뤄왔던 NTFS 드라이브 포맷을 마친 후에야 알게 될 것임
     * ZFS에 적용하는 방법을 생각 중임
          + 다른 파일 시스템 유형을 읽고 ZFS 블록 포인터를 합성하는 레이어를 추가하는 방식으로 가능할 것임
          + ZFS가 블록 포인터 재작성 기능이 있다면 전체를 재작성하여 변환을 완료할 수 있을 것임
          + ZFS는 적절한 CAS 파일 시스템이 아니기 때문에 블록 포인터 재작성 기능을 가질 수 없음
     * LZX 압축이 적용된 파일을 지원한다면 매우 놀랄 것임
          + Windows 2000 시대의 파일 압축과 혼동하지 말 것
          + ""compact.exe /C /EXE:LZX (파일명)"" 명령어로 활성화해야 하는 기능임
     * NTFS는 안정적이고 btrfs보다 빠르며 동일한 기능을 가지고 있음
          + 누군가가 NTFS를 대체하려는 이유를 이해하기 어려움
"
"https://news.hada.io/topic?id=18127","Flow - AI 에이전트 제작을 위한 경량 태스크 엔진","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Flow - AI 에이전트 제작을 위한 경량 태스크 엔진

     * 전통적인 Node-Edge 기반 워크플로우 대신 Dynamic Task Queue 시스템을 사용하여 간결성과 유연성을 중시
     * 3가지 원칙
          + 동시 실행: 작업이 자동으로 병렬 실행
          + 동적 스케줄링: 작업 실행 중 새 작업 추가 가능
          + 스마트 의존성: 이전 작업의 결과를 기다려서 처리
     * 모든 태스크의 결과는 쓰레드 세이프한 Context에 저장됨
     * 이 태스크 기반 아키텍처는 복잡한 워크플로우를 아주 간단하게 만들어줌
          + 명시적 쓰레딩 코드 없이 병렬 작업 실행
          + 자체 수정 가능한 동적 워크플로우와 사이클
          + 조건 분기와 흐름 제어
          + 작업 실행 스트리밍
          + 상태 관리, 이전 상태를 로드하고 현재 상태를 저장
          + 특정 작업부터 실행 시작 가능
          + 입력 데이터를 동적으로 전달하여 다음 작업 실행
          + MapReduce와 같은 병렬 처리 및 결과 수집
     * 노드 간 연결 사전 정의 없이 동적 스케줄링 사용
     * 복잡한 워크플로우를 간소화하여 깔끔한 코드 작성 가능
     * 경량화된 설계, 외부 종속성 없음
     * Auto-Instrumentation
          + Laminar를 이용하여 추적을 위한 Auto-Instrumentation 기능 포함
          + OpenTelemetry 기반 추적을 활성화하려면 Flow를 사용하기 전에 Laminar SDK를 initialize 필요
     * 고급 기능
          + 컨텍스트 공유: 모든 작업이 동일한 컨텍스트를 공유하여 데이터 흐름 관리
          + 에러 처리: 작업 내 예외를 적절히 전파
          + 쓰레드 안전성: 모든 작업이 쓰레드 안전
          + 최소 종속성: 외부 라이브러리 없이 동작
     * 향후 개발 계획
          + 비동기 지원 추가
          + 서버리스 배포 옵션 추가

   프로젝트 설명이 잘 이해가 안되는 데요. AI 에이전트 전용이 아니라 적용사례의 예시를 든 것 뿐일까요? 일반적인 범용 작업엔진이랑 다른 게 없어보여서요
"
"https://news.hada.io/topic?id=18081","레일즈 최신(8.1) 가이드 문서를 한글로 번역했습니다. ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    레일즈 최신(8.1) 가이드 문서를 한글로 번역했습니다.

   제가 원래 레일즈 고인물이었었는데 프론트엔드 스택 왔다갔다 하다가
   최근 레일즈로 다시 돌아왔는데 너무 좋네요.
   레일즈 8이 너무 좋아졌고, DHH의 최근 영상들 몰아보고 있어요.
   (DHH가 요즘 엄청 활동하고 있군요. 논쟁거리도 많이 만들고 있고요 ㅎㅎ)

   레일즈 공식 가이드가 정말 잘 되어 있는데
   올해 출시된 8 버젼에 대한 한글 번역 문서가 없길래
   AI 도움을 받아 번역해봤습니다.

   claude sonnet 3.5 api를 이용했고
   모든 마크다운 파일을 자동 번역하는 루비 스크립트를 작성했으며
   번역용 루비 스크립트는 windsurf 에디터로 몇 차례 티키타카를 통해 만들었습니다
   하나의 마크다운 파일을 적당한 청크(50줄 내외, 코드 블럭을 자르지 않는 조건)로
   나누어 번역한 후 한글 마크다운 파일로 합치는 스크립트 입니다.
   API 호출 비용은 3만원 좀 넘게 나왔고 320만 토큰 사용했네요.

   gpt-4o가 예전의 기계 번역보다는 훨씬 낫지만 부자연스러운 부분이 있는데
   claude는 확실히 글을 잘 쓰네요. 코드블럭에서 코드는 번역하지 않고 주석만 번역하고
   번역가 보다는 못하겠지만 제가 몇달 번역하는 것보단 결과가 낫지 않나 생각합니다
   deepl도 고려했는데 일반 텍스트는 괜찮지만
   마크다운, 코드 블럭에 대한 처리가 잘 안 되는 것 같습니다.

   레일즈 개발자분들에게 도움이 되었으면 좋겠네요!

   좋은 자료 감사합니다. 중간중간 번역되지 않아야할 텍스트도 번역된게 있긴해도 기본적인 퀄리티가 좋네요. 혹시 번역 프롬프트도 따로 튜닝한게 있으신가요?

   i18n 페이지는 손을 좀 봐야겠네요 리포팅 감사합니다! 프롬프트에 특별한 노하우가 있는 건 아니고 결과가 잘못 나오는 부분에 대해 추가 프롬프트를 더한 정도에요 :)

   windsurf 경험은 어떠셨는지 궁금해요

   요즘 개발할 때 잘 쓰고 있어요
   그 전에는 cursor, 그 전에는 copilot 사용했고 개발 속도가 확실히 빨라집니다
   100% 완벽한 코드를 만들어주는 건 아니지만 자주 사용하는 패턴 코드는 잘 짜주고
   그런 코드를 제가 직접 짜려면 몇 시간 걸렸을텐데 AI는 몇 초면 짜주니까요

   대학생 때 산학연계 인턴으로 들어간 회사가 레일즈를 사용하는 곳이었는데 한국어 자료가 너무 없어서 난감했던... 그때 구매한 레일즈 책은 지금은 절판됐더라고요.
   여튼 감사합니다. 오랜만에 한번 구경해봐야겠어요!

   레일즈가 비주류이지만 그래도 영어권 자료는 꽤 있는 편인데 한글은 너무 없긴 하죠
   AI가 잘 번역해주니 수요가 있다면 레일즈 관련 문서들의 번역 자료를 만들어보려고요
"
"https://news.hada.io/topic?id=17995","어떤 언어에서도 사용할 수 있는 C-Reduce 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     어떤 언어에서도 사용할 수 있는 C-Reduce 기술

     * C-Reduce의 활용
          + C-Reduce는 Regehr와 그의 동료들이 개발한 도구로, C 컴파일러 버그 재현기를 최소화하는 데 사용됨.
          + 예를 들어, Clang 버그를 유발하는 10,000줄의 C 파일을 줄이고 싶을 때 유용함.
          + C-Reduce는 C 언어에만 국한되지 않고 다양한 언어에 적용 가능함.
     * C-Reduce의 요구 사항
          + 결정론적 조건 필요.
          + 빠른 재현기가 있으면 감소 속도에 도움을 줌.
          + C-Reduce가 줄일 수 있는 하나 이상의 변경 가능한 소스 파일 필요.
     * RustPython 버그 사례
          + RustPython에서 발생한 버그를 보고하기 위해 스크립트 interesting.sh 작성.
          + 스크립트는 RustPython 실행 후 특정 오류 메시지를 grep으로 찾음.
     * C-Reduce 실행
          + C-Reduce를 실행하여 파일 크기를 50% 이상 줄이는 데 성공.
          + --not-c 옵션을 사용하여 C에 특화된 패스를 피하고 Python에 맞게 최적화함.
          + 결과적으로 빠르고 쉽게 파일을 줄일 수 있었음.
     * 결론
          + C-Reduce는 다양한 언어에 적용 가능하며, 빠르고 효율적으로 파일을 줄이는 데 유용함.
          + 오픈 소스 블로그로, 오류가 있으면 변경 제안 가능함.

        Hacker News 의견

     * 한 사용자는 파일을 줄이는 방법을 공유하고, RustPython과 scrapscript를 사용하여 설정하는 방법을 설명함
          + git clone 명령어를 사용하여 RustPython과 scrapscript를 클론하고, cargo build --release로 빌드함
          + interesting.sh 파일을 다운로드하고 실행 권한을 부여함
          + nix run nixpkgs#creduce 명령어를 사용하여 파일을 줄임
     * C-Reduce의 사용을 추천하며, Shrinkray라는 도구도 함께 사용해볼 것을 권장함
          + Shrinkray는 포맷에 독립적이며 C-Reduce가 잘 작동하지 않는 경우에도 유용함
     * C-Reduce에 대한 논문이 2012년에 발표되었음을 언급함
          + John Regehr et al.의 논문을 통해 C-Reduce의 작동 방식을 설명함
     * C-Reduce를 처음 알게 되었고, git bisect를 처음 발견했을 때와 같은 흥미로움을 느낌
          + 나중에 필요할 때 사용하기 위해 기억해 두기로 함
     * C-Reduce의 예시를 보여주는 기사를 발견했으나, 각 반복에서 무엇을 제거할지 결정하는 방법에 대한 이해가 어려움
          + 토큰화 과정이 있을 것으로 추측되지만, 프로그래밍 언어 간에 어떻게 작동하는지 이해하기 어려움
     * C-Reduce가 매우 유용하다고 평가함
          + CSmith를 사용하여 무작위 테스트 프로그램을 생성하고, 충돌 시 자동으로 C-Reduce를 사용하여 문제를 줄임
     * 델타 디버깅은 새로운 개념이 아님
          + ""delta""라는 델타 디버깅 구현은 19년 이상 되었으며, 오픈 소스로 공개됨
          + LLVM 소개에서는 표준 델타 디버깅 도구로 언급됨
     * SQL에서도 잘 작동하며, 직장에서 사용 중임
          + SQLancer를 통해 발견함
     * C 언어 외의 언어에서도 작동하는 이유에 대한 설명이 없으면 믿기 어려움
          + LLM을 사용하지 않기 때문에 더욱 혼란스러움
     * C-Reduce의 좋은 후속 도구로 cvise를 추천함
          + 어셈블리 프로그램을 최소한의 집합으로 줄이는 데 여러 번 사용했으며, 매우 유용한 프로그램임
"
"https://news.hada.io/topic?id=18046","Show GN: Advent of SQL 2024","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Show GN: Advent of SQL 2024

   해외에는 어드벤트 캘린더에서 착안해 12월 1일부터 25일까지 매일 코딩 문제를 하나씩 푸는 Advent of Code 사이트가 있습니다. SQL 버전은 없는 것 같아 사이드 프로젝트로 운영하던 SQL 학습 사이트에 SQL 버전 어드벤트 캘린더를 만들어봤습니다.

   매일 페이지에 SQL 문제가 하나씩 올라옵니다. 문제 난이도는 간단한 SELECT 구문을 사용하는 것부터 비교적 복잡한 실제 데이터 분석 사례에 가까운 문제들도 업로드 됩니다.

   문제 열람은 로그인 하지 않아도 가능하나 직접 작성한 쿼리를 실행하려면 로그인이 필요합니다.

   25일간 재미있게 즐겨주시면 좋을 것 같습니다.

   칼랜더 사다가 쪼코만 먹고있었는데 그건 방법이 있었네요..
   칼렌더를 보면 보통 25일 아침 쪼코가 제일 크거든요. 25일 문제는 제일 어려울까요 ;-)

   25일 문제는 그 이전 문제들 보다는 쉬울 것 같습니다 ㅎㅎ 너무 어려우면 즐거운 휴일에 머리 싸매고 있어야 할 것 같아서요!

   advent calendar 라는 것에서 착안한지는 몰랐네요!

   Advent of XXX 시리즈는 거의 대부분 advent calendar에서 착안한 것 같습니다 :-)
"
"https://news.hada.io/topic?id=18067","2025년 Public Domain에 들어갈 작품들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2025년 Public Domain에 들어갈 작품들

     * 2025년에 공공 도메인에 들어갈 작품들
          + 매년 1월 1일, 새로운 작품들이 공공 도메인에 들어가 자유롭게 즐기고 공유할 수 있게 됨.
          + 세계 각국의 저작권법이 다르기 때문에 공공 도메인은 여러 형태로 존재함.
          + 2025년에 공공 도메인에 들어갈 작품들:
               o 1954년에 사망한 사람들의 작품 (영국, 러시아, 대부분의 EU 및 남미 국가)
               o 1974년에 사망한 사람들의 작품 (뉴질랜드, 대부분의 아프리카 및 아시아 국가)
               o 1929년에 출판된 미국의 영화와 책 (작품 포함)
     * 공공 도메인의 중요성
          + 공공 도메인은 작품을 자유롭게 사용할 수 있게 하여 창의성과 문화 발전에 기여함.
          + Communia의 공공 도메인 선언문에서 공공 도메인의 중요성에 대해 더 알아볼 수 있음.
     * 공공 도메인 리뷰
          + 공공 도메인 리뷰는 영국에 등록된 커뮤니티 이익 회사로, 주로 커뮤니티에 이익을 주거나 사회적 목적을 추구하기 위해 존재함.
          + 독자의 기부에 의존하며, 프로젝트를 지원하고 PDR의 친구가 될 것을 권장함.
     * 추가 정보
          + John Mark Ockerbloom의 ""Public Domain Day Countdown""을 Mastodon에서 확인할 수 있으며, 그의 블로그 게시물에서 요약됨.
          + 사이트는 쿠키를 사용하여 사이트 사용 정보를 수집하고 기본 기능을 제공함. 쿠키 사용은 최소화되어 있으며 개인을 식별하지 않음.

        Hacker News 의견

     * 영화나 책의 저작권이 70년 동안 유지되는 것은 너무 길다는 의견이 있음. 25년 정도가 적절하다고 생각하며, 이는 새로운 세대가 이전 세대의 예술을 접하고 발전할 수 있는 선순환을 만들 수 있음.
     * 2025년에 h.264 (AVC) 비디오 코덱의 마지막 특허가 만료되는 것이 흥미롭다고 언급함. HEVC의 특허 문제는 여전히 복잡함.
     * 공공 도메인에 들어가는 작품 목록을 base64로 인코딩하여 공유함.
     * 공공 도메인에 들어가는 작품이라도 실제로 접근하기 어려운 경우가 많음. 예를 들어, 1929년 소설 'Red Harvest'는 공공 도메인에 들어가지만, 잡지에 연재된 버전을 구하기 어려움.
     * 1998년 Sonny Bono 저작권 연장법이 시행되기 전, 저작권이 만료되는 캐릭터에 관한 재미있는 만화가 있었음. Popeye가 공공 도메인에 들어가면서 공포 영화가 제작 중임.
     * 저작권 개혁에 대한 논의가 많음. 저작권은 복수의 권리로 구성되어 있으며, 각 권리가 동일한 기간을 가질 필요는 없다고 주장함. 강제 라이선스를 더 추가하는 것도 고려할 수 있음.
     * 파생 저작물 권리는 복잡함. 짧은 기간은 팬 픽션을 장려할 수 있지만, 너무 빨리 공공 도메인이 되면 원작의 가치가 훼손될 수 있음.
     * 목록에 있는 대부분의 작품은 책이지만, 읽을 수 있는 버전이 아닌 사진만 있음. 내년에는 틱톡 영화로 연결될 수도 있음.
     * 이전 문명은 문화적 신화를 소유할 수 있었지만, 현대 문명의 신화는 대기업이 통제하고 있음. Han, Luke, Leia에 대한 새로운 이야기를 하려면 Disney의 허가가 필요함.
     * 주목할 만한 인물로 Frida Kahlo, Henri Matisse, Alan Turing이 언급됨. Chrysler Building이 공공 도메인에 들어갔다는 추측이 있음.
"
"https://news.hada.io/topic?id=18105","전문적 관계를 성장시키는 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            전문적 관계를 성장시키는 방법

     * 전문적 관계(Professional Relationship)는 중요함
     * TJS (The Journey to Synergy, 시너지로의 여정) 협업 모델을 통해 관계의 상태를 평가하고, 경쟁적 사고에서 공유된 정체성으로 이동하는 7단계를 제시

# TJS 협업 모델의 상태들

  1. Everything is a competition (모든 것이 경쟁임)

     * Gatekeeping과 제로섬 사고방식으로 특징지어지는 초기 상태
     * 정보, 자원, 기회를 공유하지 않으며 배제적 행동이 나타남 (인종차별, 성차별, 외국인 혐오 등)
     * 상호작용을 거부하거나 완전히 무시하는 ""고스팅""으로 표현되기도 함
     * 팟캐스트 에서는 초대를 수락했지만 나중에 다른 기회를 이유로 거절하는 경우로 나타남

  2. Coexist (공존)

     * 서로의 존재를 인정하나 최소한의 상호작용만 하는 상태
     * ""그들을 알긴 하지만 실제로 대화하지 않는다""로 요약 가능
     * 개인적, 전문적, 또는 가치의 차이로 인해 거리를 유지
     * 팟캐스트 문맥에서는 양측이 서로의 존재를 알지만 초대나 참여 의사를 표하지 않는 경우

  3. Communicate (소통)

     * 기본적인 정보 교환은 이루어지지만 관계가 더 발전하지 않는 상태
     * 팟캐스트 문맥에서는 대화가 긍정적으로 이루어지지만 실질적 협력이 없는 경우
     * 서양 문화에서 흔한 상태로, 대화를 나누지만 계획을 실행하지 않는 경우가 많음

  4. Cooperate (협력)

     * 중립적인 목표를 위해 함께 작업하는 단계
     * 관계는 여전히 주로 거래적이며 낮은 위험 수준
     * 팟캐스트 문맥에서는 에피소드 제작 과정에서 협력하는 상태

  5. Coordinate (조정)

     * 양측이 목표를 공유하며 의도적으로 행동을 조율하는 단계
     * 신뢰, 동기 부여, 정렬 문제를 수반하는 혼란스러운 상태일 수 있음
     * 예: 컨퍼런스 전에 도시를 탐험하거나, 새로운 제품 출시를 위해 도움을 주는 경우

  6. Collaborate (협업)

     * 두 명 이상의 사람들이 성공적으로 협력하며 시너지를 만들어내는 상태
     * 같은 것을 함께 구축하는 진정한 협업이 이루어짐
     * 높은 수준의 신뢰와 상호 이해를 바탕으로 경계를 존중하며 아이디어를 발전시킴
     * 팟캐스트 문맥에서는 아직 실행되지 않았지만 가능성을 열어둠

  7. We are the same (우리는 동일함)

     * 정체성과 경계가 해체되는 유해한 상태
     * 협력적인 관계가 건강하지 않게 발전하여 상호 의존적 관계로 변질
     * 정체성 상실, 독립적 결정을 내리기 어려움, 경계 부족 등의 특징
     * 이 상태를 극복하려면 개인 정체성을 회복하고, 경계를 설정하며, 문제를 유발한 당사자와의 분리를 통해 해결 가능

# Making it Practical

     * 자신의 관계가 TJS 협업 모델의 스펙트럼 상 어디에 위치하는지 생각해 보기
          + 현재 상태를 이해하고 원하는 상태를 파악하는 데 도움을 줌
          + 예시로 언급된 훌륭한 협력자들처럼, 여러분의 협력자와 조율 잘 되는 사람들은 누구인지 고민
     * 질문을 통해 관계 상태 평가
          + 함께 존재하는 관계(coexist)는 누구인가?
          + 누가 여러분을 게이트키핑하고 배제하는가?
          + 누구와 회사를 설립할 의향이 있는가?
     * 시각화와 계획
          + TJS 스펙트럼 이미지를 복사하여 옆에 두고 깊이 고민
          + 관계 상태를 시각화하기 위해 축에 아바타를 배치하여 관계를 구체적으로 평가
          + 평가 후 목표와 가치에 맞춰 관계를 발전시키는 방향으로 계획 수립
     * 관계를 발전시키기 위한 실행 가능한 경로
          + 특정 관계를 원하는 상태로 이동시키고 싶다면 아래의 실행 가능한 방법들 검토

# Moving Relationships Forward

     * Collaboration as a Necessity
          + 연구에 따르면 배타적이고 제로섬적인 사고방식은 최악의 결과를 초래
          + 협업은 참가자들이 함께 더 많은 것을 성취하고, 더 넓은 대중을 대상으로 하며, 개인적 및 조직적으로 성장하게 만듦
          + 협업은 단순히 잘 지내는 것을 넘어 더 큰 것을 함께 구축하는 필수 요소

  관계를 발전시키기 위한 실행 가능한 방법

     * 풍요로운 사고방식 육성
          + 세상은 제로섬이 아닌 풍요로운 곳임을 인식
          + 미소한 기부로 시작: 자원의 일부를 나누거나 하루에 한 번 친절한 행동을 실천
          + 지역 사회 봉사나 기부 네트워크에 참여하여 관계를 형성
          + 감사 일기 작성, 풍요 시각화, 명상 등으로 사고방식 전환
          + ""기부 일기""를 작성하여 긍정적 결과를 기록하고 개인적 성장을 추적
     * 희망 없는 관계는 포기
          + 관계에서 배제하거나 거부하는 사람들을 빠르게 인정하고 감사하며 앞으로 나아감
          + 새로운 사람들과의 관계를 구축할 수 있도록 에너지를 자유롭게 사용
     * 이웃을 자신처럼 사랑하기
          + 자신을 돌보는 방식으로 타인을 돌봄
          + 아무런 기대 없이 베풀되, 품은 애정이 종종 훌륭한 협력으로 이어짐
          + 간혹 이용당할 가능성도 있지만, 성공적인 사례가 그렇지 않은 사례를 크게 초과
     * 세세한 부분까지 신경 쓰기
          + 피상적인 소통에서 벗어나 상대방의 필요를 깊이 이해하고 지원
          + 상대방의 목표를 자신의 목표로 채택하고 이를 지원하는 주도적인 행동 수행
          + 반복적으로 성공적인 조율이 이루어지면 자연스럽게 협업으로 발전
     * 관계를 발전시키기 위해서는 진정성 있고 세심한 노력이 필요하며, 협업은 단순한 교류를 넘어 지속적인 시너지를 만들어냄
"
"https://news.hada.io/topic?id=18029","굿바이 Rust, 성공을 기원하지만 저는 C++로 돌아갑니다 (미안, 개인적 불만이에요)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           굿바이 Rust, 성공을 기원하지만 저는 C++로 돌아갑니다 (미안, 개인적 불만이에요)

     * TLDR: 결국 일자리 때문
     * 3년간 Rust로 비동기/멀티스레드 코드, FFI(Bindgen 활용), 커널 프로그래밍(std 없이) 등 다양한 작업을 경험
          + 하지만, 현재는 Rust 대신 C++ 개발자로 전환했음
     * Rust는 C++보다 더 나은 툴(Cargo), 라이브러리 생태계(Crates.io)를 제공하며, OOP, 예외 처리, 메모리 관리 같은 복잡성을 제거하고, 개발자가 ""올바른 방식""으로 코딩하도록 훈련시킴
     * 하지만 Rust는 Betamax와 VHS, 마스토돈과 트위터의 관계처럼 기술적으로 우수하지만, 대중 채택이 부족함
          + 프로그래밍 언어는 개발자 간 아이디어를 전달하는 커뮤니케이션 기술로 채택률이 성공의 주요 요소임
     * 다른 언어들도 충분히 좋아지고 있음
          + Go: Rust보다 학습 곡선이 낮고 컴파일 속도가 빠르며 빠른 반복 주기를 제공함
          + C++: Rust를 견제할 수 있는 안전성 도구와 린팅 도구 개선 중
          + JavaScript, WASM: 속도 향상으로 Rust의 장점을 상쇄
     * Rust로 직업을 얻는 것은 현실적 어려움
          + Rust 채용은 대부분 전문 기술(블록체인, 금융, 머신러닝/데이터 분석, 모호한 네트워크 프로토콜, 사이버 보안 등) 이 우선이며, Rust는 부가적 기술로 간주됨
          + Rust를 잘 아는 것만으로는 채용될 수 없으며, 특정 도메인 지식이 더 중요하게 평가됨
     * 이 서브레딧도 문제중 하나임
          + 다른 언어 커뮤니티(Golang, C++ 등)와 비교해 Rust 관련 직업에 대한 논의가 부족함
          + 마치 ""Rust Jobs 글의 첫번째 규칙은 Rust Jobs에 대해 이야기를 하지 않는 것"" 처럼 보이며, 이런 고립이 언어의 영향력을 제한함
     * 기업의 지원 부족도 언급할만 함
          + 과거 성공한 언어는 대부분 대기업의 지원을 받음
               o 예: IBM(Fortran), AT&T(C), Microsoft(C#), Google(Python), Apple(Swift)
          + Rust는 명확한 대기업 후원이나 고객 도입을 강력히 추진하는 스폰서가 부족함
     * Rust는 Lisp, Smalltalk처럼 혁신적이지만 대중적으로 실패한 기술의 전철을 밟을 가능성이 있음

   C++은 대체된다는 이야기가 매번 나오는데 그 매 번만 몇 년째..

   ""Rust는 Lisp, Smalltalk처럼 혁신적이지만 대중적으로 실패한 기술의 전철을 밟을 가능성이 있음""

   마지막 문장은 동의하기 어렵네요. 이미 업계에서 많이 쓰고 있습니다.

   자바도 처음 나왔을땐 다들 기대가 컸지만 많은 곳에서 사용되기까지 많은 시간이 걸렸습니다.

   C++ 업계 자체가 보수적인것 같아요. 천천히 rust로 옮겨가겠죠.

   Rust가 성공하려면 실리콘밸리에서 Rust를 이용해 누군가가 창업해서 대박나고 Rust개발자를 구인해야 함..

        Hacker News 의견

     * Rust는 C++보다 우수한 기술이지만, 채택과 대중화가 중요함
          + Rust는 Betamax가 VHS보다, Mastodon이 Twitter보다, Dvorak 키보드가 QWERTY보다, Esperanto가 영어보다, Lua가 Javascript보다 나은 것과 비슷한 방식으로 더 나음
          + Rust의 아이디어는 Swift 등 다른 언어에서도 사용되고 있음
     * 영국에서 C++ 직업을 찾을 때 Rust에 대한 관심을 이야기하지만 실제로 사용할 기회는 적음
          + Rust 직업은 주로 암호화폐 핀테크와 방위 산업에 관련됨
          + Rust가 Ada의 대안으로만 사용되는 것은 아쉬운 일임
     * Rust를 사용하기 위해 C++를 포기할 필요는 없음
          + 새로운 프로젝트에서 Rust를 채택할 기회를 찾아야 함
     * Rust에 대한 애정은 취미 프로젝트에서 시작될 수 있음
          + 직장에서 Rust로 대규모 업데이트를 하는 것은 어려움
          + 다른 메모리 안전 언어를 먼저 고려해야 함
     * C 언어를 좋아하며 새로운 언어를 배우는 것에 열려 있음
          + C를 비판하는 사람들로부터 배우는 것은 신뢰를 주지 않음
          + Rust를 홍보하려면 C를 좋아하는 사람들이 추천해야 함
     * 언어 선택은 설계 결정임
          + 사용 사례와 프로젝트 요구 사항을 명시하지 않고 언어의 장단점을 평가하는 것은 비합리적임
     * C와 C++는 특정 시대의 언어임
          + C++는 결국 대체될 것이지만, 새로운 세대의 프로그래머가 등장하기까지 시간이 걸림
     * C++를 쓰는 것을 좋아하는 사람도 있음
          + Kotlin 같은 새로운 언어도 좋지만, C++로 돌아오게 됨
     * Betamax vs. VHS, X vs. Mastodon 비교가 흥미로움
          + 안전하고 높은 무결성의 프로그래밍 언어를 원한다면 SPARK2014를 선택할 것임
          + Rust는 기술 군중에게 인기를 얻었지만, SPARK는 항공우주 등에서 사용됨
          + 프로그래밍 언어 채택은 패션과 기술적 장단점 모두에 관련됨

   몇 시간 전에 포기함.
   raspberry pico용 펌웨어를 rust로 만들어 보려 함.
   당최 도움이 되는 트러블 슈팅을 구할 수가 없음. 😤

   rust 로 무한 에너지를 얻을수도 있다고 함.
   https://www.reddit.com/r/ProgrammerHumor/comments/1h3v3uz/freeenergy/

   무슨 러스트 유저들이 바보인줄 아시나요 (덜컹)

   국내에서 특정 언어를 하지 않으면 일자리를 못찾는거랑 비슷하네요.

   VHS와 Beta에 대한 글은 꽤 미신이 많다고 생각합니다.

   사람들은 비주류 기술의 실패를 단순히 마케팅의 실패로 받아들이고 가끔 비주류 기술이 더 우월했다고 주장합니다. 소니의 베타맥스가 빅터의 VHS에 패배했을 때도 마찬가지입니다. 사람들은 우수한 베타맥스가 졌다고 이야기합니다.

   하지만 사람들은 모르는게 있습니다.

   VHS만 2시간을 커버할 수 있는 기술입니다. 베타맥스는 영화등의 킬러콘텐츠를 다루기에 부족한 용량을 가졌습니다. 2시간 영상은 베타 2에서 지원했지만 장점인 화질을 희생했다는 사실은 모릅니다.

   VHS가 기계적인 메커니즘이 뛰어나 훨씬 빨리 되감기를 할 수 있었습니다. 베타맥스는 되감거나 앞으로 감아서 보기 어려웠습니다.

   PAL에서 VHS가 잘 보이는 반면에 베타맥스는 NTSC 전용이라 PAL에서 끔찍했습니다. 이는 베타맥스가 유럽에서 성공하기 어려운 이유였습니다.

   객관적으로 따져봐도 VHS가 훨씬 균형잡힌 솔루션이라고 봅니다.

   마찬가지로 나는 윈도우즈 NT가 클래식 Mac OS에 비해 훨씬 균형잡힌 기술이라고 생각합니다. 애플은 선점형 운영체제를 선보이는 것도 마이크로소프트에 비해 6년이 늦었어요.

   동의합니다. +1

   좋은 정보 제공 감사합니다. 베타맥스에서는 되감기가 힘들었다는 것은 처음 알았네요.
"
"https://news.hada.io/topic?id=18032","4Chan CAPTCHA 해독하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           4Chan CAPTCHA 해독하기

  소개

     * 이 프로젝트는 머신러닝과 TensorFlow에 대한 지식을 향상시키기 위한 학습 경험으로 시작되었음.
     * 목표는 브라우저에서 4Chan CAPTCHA를 80% 이상의 정확도로 해결할 수 있는 머신러닝 모델을 만드는 것이었음.

  용어

     * CAPTCHA: 컴퓨터나 웹사이트 사용자가 인간인지 확인하기 위한 테스트.
     * 4Chan: 다양한 주제의 토론 게시판을 제공하는 익명 이미지 게시판 웹사이트.
     * 일반 CAPTCHA: 5~6개의 영숫자 문자로 구성된 4Chan CAPTCHA.
     * 슬라이더 CAPTCHA: 배경 이미지와 전경 이미지가 겹쳐져 있는 복잡한 형태의 CAPTCHA.

  데이터 수집

     * 머신러닝 문제에서 가장 어려운 부분은 데이터를 수집하는 것임.
     * 4Chan에서 CAPTCHA를 스크래핑하고 솔루션을 얻는 것이 주요 과제였음.

  4Chan에서 CAPTCHA 스크래핑

     * HTTP 요청을 분석하여 CAPTCHA 데이터를 JSON 형식으로 추출하는 방법을 발견함.
     * 요청 간격을 조절하여 CAPTCHA의 난이도를 관리해야 했음.

  솔루션 얻기

     * 상업적인 CAPTCHA 해결 서비스를 이용했으나, 정확도가 낮았음.
     * 직접 해결하거나 신뢰할 수 있는 사람에게 부탁하는 방법도 시도했으나, 제한적이었음.

  합성 데이터 생성

     * 4Chan CAPTCHA를 모방하여 합성 데이터를 생성함.
     * 배경과 문자를 분리하여 합성 CAPTCHA를 생성하는 알고리즘을 개발함.

  모델 생성

     * LSTM CNN 아키텍처를 사용하여 모델을 구축함.
     * Keras와 TensorFlow를 사용하여 모델을 구현함.

  데이터 처리

     * 모든 CAPTCHA 이미지를 300x80 픽셀로 조정하여 모델에 입력함.
     * 문서의 중요성을 강조하며, 문서의 세부 사항을 놓치지 않도록 주의해야 함.

  모델 훈련

     * 약 500개의 수작업 이미지와 50,000개의 합성 이미지를 사용하여 모델을 훈련함.
     * 훈련은 NVIDIA RTX A4000 GPU에서 수행되었음.

  TensorFlow.js에서 모델 사용

     * TensorFlow.js로 모델을 변환하여 브라우저에서 실행 가능하도록 함.
     * Python 3.12에서는 변환 스크립트가 작동하지 않음.
     * Keras 3 모델은 TensorFlow.js에서 지원되지 않음.

  실제 성능

     * 실제 4Chan CAPTCHA에서 90% 이상의 성공률을 보임.
     * 4자 CAPTCHA에서도 동일한 성능을 보임.

  결론

     * 이 프로젝트를 통해 머신러닝과 컴퓨터 비전에 대해 많은 것을 배웠음.
     * 목표를 달성하여 만족스러운 결과를 얻었음.

        Hacker News 의견

     * JSON 스크립트를 사용하여 시각화 데이터를 파싱하는 것은 복잡한 작업임
          + 4chan이 이메일 인증을 요구하기 시작함
     * Keras와 Tensorflow.js 간의 상호 운용성 문제는 Tensorflow의 전형적인 문제임
          + TF는 통합된 제품보다는 관련 도구들의 모음처럼 느껴짐
          + 모든 오픈 소스 Google 라이브러리/도구가 비슷한 느낌을 줌
     * 왜 사람들이 왜곡된 텍스트 기반 캡차를 피하는지 이유가 있음
          + 컴퓨터가 인간보다 더 잘 풀 수 있는 수준에 도달함
          + 관련된 흥미로운 논문이 있음
     * 놀랍게도 많은 텍스트 기반 캡차는 몇 줄의 쉘 스크립트로 해결 가능함
          + imagemagik을 사용하여 그레이스케일로 변환 후 teserract로 처리 가능함
     * 2captcha.net 같은 사이트도 존재함
          + 캡차는 최소한의 노력을 요구하는 것과 같음
     * 캡차를 가장하여 사용자 행동과 타이밍을 분석하는 것이 더 나을지 궁금함
          + AI를 훈련시켜 상대방이 인간인지 아닌지를 판단하는 '역 튜링 테스트'를 발명할 수 있음
     * Silk Road CAPTCHA에 대한 2014년 분석이 있음
     * 4chan의 적절한 대응은 인간의 작업을 단순화하는 것임
          + 복잡한 캡차는 인간의 불편함을 증가시키고 기계의 해결 가능성을 줄이지 않음
     * 4chan 캡차의 문자 선택이 인종차별적/극단적 슬로건을 만들 수 있도록 의도되었을 가능성이 있음
          + 특정 문자들이 자주 사용됨
          + 무작위로 보이지만 특정 패턴이 자주 발생함
     * 4chan 캡차를 해결하는 프로젝트가 존재함
     * 4chan을 사용하려 했으나 캡차를 통과하지 못한 경험이 있음
     * 4chan이 Google 캡차처럼 봇 행동 감지를 하는지 궁금함
"
"https://news.hada.io/topic?id=18051","Terraform 1.10 w/ Ephemeral values","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Terraform 1.10 w/ Ephemeral values

     * 기존의 테라폼에서는 시크릿이 plan이나 state file에 평문으로 남았음
          + private keys, certifications, API tokens, ...
          + 때문에 시크릿 유출에 의한 위험이 존재
     * 2024/11/27 Terraform 1.10이 GA로 공개됨
          + Ephemeral values 기능과 함께
     * Ephemeral values는 어디에도 저장되지 않음
     * 지금은 다음 provider의 resource에만 지원됨
          + AWS: aws_secretsmanager_secret_version, aws_lambda_invocation
          + Azure: azurerm_key_vault_secret, azurerm_key_vault_certificate
          + Kubernetes: kubernetes_token_request, kubernetes_certificate_signing_request
"
"https://news.hada.io/topic?id=18014","레고 인터페이스 패널의 UX (2020)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         레고 인터페이스 패널의 UX (2020)

LEGO 인터페이스 패널의 UX

     * 소개
          + LEGO의 ""2x2 장식 경사""는 미니피겨가 세상과 상호작용하는 인터페이스임.
          + 이 디자인은 물리적 인터페이스 디자인의 기본을 배우기에 적합함.
          + 52개의 다양한 브릭을 통해 복잡한 인터페이스의 디자인, 레이아웃 및 조직에 대해 배울 수 있음.

조직된 혼돈

     * 디자인의 다양성
          + 다양한 디자인은 혼란스러울 수 있지만, 일부는 더 체계적으로 보임.
          + 대부분의 인터페이스는 디지털 화면과 아날로그 입력의 혼합을 포함함.
          + LEGO 패널도 마찬가지로 다양한 클러스터로 나뉨.

LEGO로 디자인 위치 설정

     * 복잡한 기계 인터페이스 디자인
          + 인체공학부터 공학까지 다양한 요소를 고려해야 함.
          + 두 가지 주요 질문으로 문제를 나눌 수 있음:
              1. 다양한 입력의 기능을 어떻게 구별할 것인가?
              2. 입력과 출력을 어떻게 조직하여 서로의 관계를 이해할 수 있을 것인가?

입력 구별하기

     * 입력 구별의 중요성
          + WWII 파일럿들이 착륙 직전에 착륙 장치를 올리는 실수를 한 이유는 잘못된 인터페이스 디자인 때문임.
          + 심리학자 Alphonse Chapanis는 모양 코딩을 통해 문제를 해결함.
          + 모양, 색상, 크기, 질감, 위치, 작동 코딩을 통해 입력을 구별할 수 있음.

입력 조직하기

     * 입력 클러스터링
          + 동일한 레이아웃의 패널에서 색상으로 구별된 패널이 더 명확함.
          + 소련의 제어 패널은 정보를 시각적으로 조직하는 좋은 예시임.
     * 조직 방법
          + 기능 기반 조직: 각 제품 기능에 대한 입력과 출력을 그룹화함.
          + 작동 기반 조직: 동일한 방식으로 작동하는 스위치를 같은 위치에 배치함.
          + 기술 기반 조직: 기술적 특성에 따라 인터페이스를 나눔.
          + 사용 사례 기반 조직: 사용자의 일상 작업에 따라 클러스터링함.

결론

     * 최고의 인터페이스란?
          + 최고의 인터페이스는 없지만, 최악의 인터페이스는 많음.
          + 아름답고 시각적으로 명확한 레이아웃과 구별된 입력을 가진 인터페이스가 이상적임.

        Hacker News 의견

     * Audi 예시 링크는 사라졌지만, 아카이브된 버전을 찾을 수 있음
     * 실제 인터페이스 분석이 흥미로우며, 초보자로서 기능별/작업별/기술별/사용 사례별 구분에 대해 깊이 생각해본 적이 없었음
     * Lego의 ""Modulex"" 브랜드와 60년대부터 90년대까지의 프로젝트 관리 디스플레이 보드에 대해 알게 되었음
          + 작은 크기와 편안한 파스텔 색상이 특히 매력적이었음
          + 더 촉감적이고 작업하기 즐거운 컴퓨터 UI를 갈망하게 만듦
     * 어린 시절 가장 좋아했던 것은 ""38""이 표시된 흰색 레이더 화면이었음
          + UX 분야로 진출했어야 했는지 고민하게 됨
     * UI/UX에 관한 사이트에서 작은 이미지를 확대할 수 있었으면 좋겠음
     * 이런 종류의 포스트는 기쁨을 주는 느낌을 줌
     * 내 전화기가 더 Bop-it 같았으면 좋겠음
     * 최고의 인터페이스 블록은 실제로 작동하는 것들임
          + 가속도계를 내장하여 작동하는 수평선을 보여줄 수 있음
          + 당시 콘솔 블록은 매우 특별했으며, 세트에서 하나를 찾으면 희귀한 표본을 발견한 것 같았음
     * UI는 화면과 실제 상호작용이 없는 것임
"
"https://news.hada.io/topic?id=18099","Phoenix LiveView 1.0.0 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Phoenix LiveView 1.0.0 출시

     * 첫 커밋 후 6년만에 1.0 마일스톤 달성
     * LiveView의 시작과 이유
          + LiveView는 서버 렌더링 애플리케이션을 JavaScript 없이 만들기 위해 시작됨.
          + 실시간 폼 검증, 쇼핑 카트 수량 업데이트, 실시간 스트리밍 업데이트 등 복잡한 문제를 간단하게 해결할 수 있음.
          + Elixir와 Phoenix는 이러한 접근 방식에 적합함.
     * 실시간 기반의 장점
          + 모든 사용자와 UI에 실시간 양방향 기반을 제공하여 개발자가 기능 구현에 집중할 수 있게 함.
          + Elixir를 통해 다른 플랫폼에서는 불가능한 기능을 구현할 수 있음.
     * LiveView의 초기 구현
          + React와 유사하게 상태 변경 시 자동으로 UI가 업데이트되는 서버 기반 UI를 구현.
          + Phoenix Channels를 사용하여 수백만 개의 연결을 지원할 수 있음.
     * 프로그래밍 모델 최적화
          + LiveView의 차별화된 엔진은 템플릿의 동적 부분만 실행하고 최소한의 데이터만 전송함.
          + 정적 부분과 동적 부분을 분리하여 효율적인 업데이트를 가능하게 함.
     * 최고 수준의 지연 시간
          + LiveView는 작은 페이로드와 상태 유지 연결을 통해 최적의 성능을 제공함.
          + 서버 메모리 사용량은 적지만, 수십만 개의 동시 연결을 지원할 수 있음.
     * HEEx를 통한 재사용 가능한 컴포넌트
          + HTML 검증 및 컴파일 타임 속성 검사를 제공하는 선언적 컴포넌트 시스템을 도입함.
          + 컴포넌트 호출 시 잘못된 속성 사용에 대해 컴파일 타임 경고를 제공함.
     * HEEx 문법 간소화
          + 태그 본문 내에서 값을 직접 삽입할 수 있는 간소화된 문법을 도입함.
     * 인터랙티브 업로드
          + 파일 업로드를 위한 단일 추상화를 제공하여 클라우드 및 서버 직접 업로드를 지원함.
          + 업로드 진행 상황을 반영하거나 고급 파일 작업을 쉽게 구현할 수 있음.
     * 스트림과 비동기 처리
          + 대량의 컬렉션을 효율적으로 처리하기 위한 스트림 프리미티브를 도입함.
          + 비동기 작업을 쉽게 처리하고 결과를 렌더링할 수 있는 기능을 제공함.
     * LiveView가 메인스트림으로
          + LiveView와 .NET Blazor는 비슷한 시기에 시작되어 이 프로그래밍 모델의 채택을 이끌었음.
          + 다른 언어 커뮤니티에서도 이 모델을 다양한 방식으로 채택하고 있음.
     * 향후 계획
          + JavaScript 훅 통합, 웹 컴포넌트 통합 강화, 내비게이션 가드 지원 등을 계획 중임.

        Hacker News 의견

     * Phoenix의 창시자가 Elixir/Phoenix/LiveView에 대한 질문을 받으며 새로운 설치 프로그램을 소개함
          + 새로운 설치 프로그램은 Elixir와 Phoenix 프로젝트를 단일 명령어로 설치할 수 있게 함
          + macOS/Linux와 Windows에 대한 설치 명령어 제공
          + 공식 Elixir 설치 프로그램을 확장한 것임
          + 비 |sh 설치 가이드도 제공됨
     * LiveView는 Rails의 한계를 극복한 기능으로, 초기에는 ""채널"" 기능으로 시작되었음
          + LiveView는 정적 뷰와의 통합이 어려웠으나, 시간이 지나면서 코드 공유가 가능해짐
          + Phoenix 1.7은 새로운 레이아웃과 철학을 도입하여 웹 앱 개발에 혁신적임
     * LiveView를 사용하여 스타트업을 구축했으나 실패했음
          + React와의 통합이 원활했으며, 복잡한 라이브러리와의 연결도 문제없었음
          + React에서 해결했던 문제들을 LiveView에서 처음부터 해결해야 했음
     * LiveView를 사용한 여러 생산 앱을 구축했으며, WebSocket 연결이 필요하지만 여러 장점이 있음
          + 코드 생성이 생산성을 높이고, Elixir를 사용하여 프론트엔드를 렌더링하는 것이 효율적임
          + WebSocket을 통해 실시간 기능 추가가 용이함
          + 비즈니스 로직을 Contexts에 유지하여 API 제공이 용이함
     * LiveView를 사용하여 웹 개발에 대한 열정을 되찾았으며, 생산성이 매우 높음
          + LiveView 학습을 위한 강좌를 제공하며, 더 많은 사람들이 이 프레임워크를 익히길 바람
     * 전형적인 웹 앱에서 프론트와 백엔드 개발자 간의 조정 비용이 가장 비쌈
          + LiveView는 이러한 문제를 무시하고 풀스택 개발을 가능하게 함
          + 적은 개발자로 더 많은 기능을 제공할 수 있음
     * LiveView를 2019년부터 사용해왔으며, 개발이 즐거웠음
          + ElixirConf EU에서 LiveView가 처음 소개되었음
     * LiveView 1.0 릴리스에 대한 의견을 블로그에 작성함
     * LiveView와 JS 기반 기술의 채택에 대한 트레이드오프에 대한 의견을 듣고 싶음
          + JS의 다양한 라이브러리와 AI 기술의 채택 가능성에 대한 논의 필요
     * LiveView는 매우 생산적인 개발 경험을 제공하지만, 불안정한 연결에서의 문제를 해결하기를 바람
          + 오프라인 지원은 어렵지만, 불안정한 연결에 대한 지원이 필요함
"
"https://news.hada.io/topic?id=17999","Warp 터미널 - 이제 로그인 안해도 사용가능","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Warp 터미널 - 이제 로그인 안해도 사용가능

     * Rust로 작성된 빠른 터미널 Warp가 이제 계정 가입 또는 로그인을 요구하지 않음
     * MacOS/Linux에서 바로 다운로드하여 사용할 수 있으며, Windows는 대기자 명단 등록 가능
     * 로그인 없이도 핵심 기능과 일부 고급 기능 사용 가능

Warp에서 제공하는 기본 기능

     * 다운로드 시 모든 사용자에게 현대적인 터미널 기능과 AI 프리뷰 제공
     * 로그인하지 않아도 Warp의 기본적인 사용 경험을 제공하며, 일부 고급 AI 및 팀 기능은 이후 로그인으로 잠금 해제 가능
     * 사용자는 필요할 때 원하는 기능을 선택적으로 활성화 가능

변화의 배경

     * 2022년 Warp 베타 출시 시 로그인 요구는 팀 협업 기능을 위한 비즈니스 이유에서 도입
          + Warp는 멀티플레이어 터미널로, 개발자들이 워크플로우, 노트북, 환경 변수 등을 공유 가능
     * AI 통합 이후, 인증은 AI 비용 관리 및 악용 방지를 위해 필수적
     * 현재 수십만 명의 엔지니어가 사용하며, 로그인 없이도 Warp의 가치를 느낄 수 있을 것이라 확신함
     * 로그인 요구 사항이 Warp 사용을 방해했다는 피드백을 수용하여 요구 사항을 제거함. 이제 더 많은 사람들이 Warp를 추천할 수 있기를 기대

   저도 처음에 쓰다가 자동완성이 안되는 문제 때문에 다시 iTerm으로 돌아온 기억이 있어요

   정확히는 Warp가 모든 커맨드의 자동완성을 해주려고 하다보니 Warp가 지원하지 않는 커맨드의 자동완성은 그냥 깨져버리는 문제... fallback이라도 해주면 좋겠는데 그것도 안해주더라구요. 지금은 해주는지 모르겠지만

   Warp - Rust로 작성된 빠른 터미널
   2년 6개월 전에 처음 소개할 때부터 터미널 사용하려고 로그인 요구하는 건 좀 지나치다는 얘기가 있었는데 이제 수정되었네요.

        Hacker News 의견

     * 한 사용자는 특정 터미널 에뮬레이터를 설치했으나 로그인 요구로 인해 빠르게 삭제했음을 언급하며 iTerm을 계속 사용할 것이라고 함
     * 다른 사용자는 개발자들이 로그인 요구를 싫어하며, Linux 지원 없이 출시한 점을 비판함
     * 관리자 권한으로 실행하지 않으면 매일 자동 업데이트를 시도하고, 실패 시 큰 빨간 배너가 나타남
     * 로그인 요구를 제거하는 데 2년이 걸렸으며, 사용자들은 이미 다른 터미널에 만족하고 있음
     * 한 사용자는 여전히 로그인 화면이 나타나며, 건너뛰기 옵션이 있지만 이는 기술 사용자에게 적합하지 않다고 언급함
     * 로그인 요구가 터미널에 필요하다는 점이 이해되지 않으며, 이는 사용자 전환에 도움이 되지 않을 것이라고 함
     * Mac과 Linux를 오가는 사용자에게 Kitty 터미널을 추천하며, 스크롤백 페이저 설정이 필요할 수 있음을 설명함
          + 스크롤백 페이저 설정 예시를 제공함
     * 최근에 Wave 터미널을 사용하기 시작했으며, 이는 더 나은 UX를 제공하고 오픈 소스임
          + 로그인 없이 GPT-4o mini에 무료로 접근할 수 있으며, 파일과 별도로 작동함
     * Warp는 VC 지원을 받는 개발 도구이며, 다른 무료 터미널이 충분히 좋기 때문에 Warp를 사용할 이유가 없다고 주장함
          + JetBrains는 무료 옵션보다 훨씬 뛰어나기 때문에 비용을 지불하지만, Warp가 iTerm보다 뛰어난지 의문을 제기함
     * Warp 사용 시 생체 정보와 신용카드를 요구하지 않아도 된다는 점을 비꼬며, 7300만 달러를 모금한 점에 놀라움을 표함
          + 터미널이 Mac에서만 작동하며, Linux/Windows 지원을 위해 추가 자금이 필요한지 의문을 제기함
          + 월 $15의 요금으로 40만 명의 유료 사용자가 필요하며, 이는 비현실적이라고 주장함
"
"https://news.hada.io/topic?id=18088","실리콘밸리에서의 Y Combinator와 권력","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       실리콘밸리에서의 Y Combinator와 권력

     * 2010년 9월 10일, AdGrok의 창립자 Antonio Garcia-Martinez는 공동 창립자 Argyris Zymnis의 샌프란시스코 아파트에서 Rodger Cole로부터 전화를 받음. Rodger Cole은 Fenwick & West의 소송 변호사였으며, Fenwick & West는 실리콘 밸리의 주요 법률 회사 중 하나였음. Cole은 그들이 이전 고용주인 Adchemy로부터 소송을 당했다고 알림. 이는 놀라운 일이 아니었음. Garcia-Martinez와 공동 창립자 Argyris, Matthew McEachen이 Adchemy를 떠나 새로운 회사를 시작했을 때, Adchemy의 CEO Murthy Nukala는 그들의 퇴사를 반기지 않았음.
     * AdGrok는 당시 작은 스타트업으로, Y Combinator의 스타트업 가속기를 거쳐 막 'Demo Day'에 참가했음. 소송은 AdGrok의 외부 자금 조달을 복잡하게 만들었음. Adchemy는 AdGrok의 공동 창립자들을 개인적으로 소송에 명시했으며, 패소할 경우 공동 창립자들이 개인적으로 책임을 져야 했음.
     * 소송 당시 Adchemy는 약 6천만 달러를 모금했으며, AdGrok는 자금 조달에 어려움을 겪고 있었음. Fenwick의 변호사들이 주식으로 대가를 받는 조건으로 그들을 변호하도록 설득했음. 전설적인 실리콘 밸리 변호사 Ted Wang이 25만 달러 대출을 동의했음.
     * Fenwick는 즉시 작업을 시작했으며, Rodger Cole은 Adchemy의 주장을 반박하고 외부 감사를 받은 코드를 제공하겠다고 제안했음. 그러나 AdGrok는 장기적인 법적 분쟁을 감당할 수 없었음. Adchemy의 약점을 공략하는 것이 소송에서 벗어나는 열쇠였음.
     * Adchemy의 약점은 두 가지였음: 투자자와 잠재적 비즈니스 파트너. Adchemy는 Microsoft와의 주요 거래를 진행 중이었음. AdGrok는 이 약점을 공략하여 Adchemy가 물러나도록 유도했음.
     * Y Combinator의 Paul Graham은 Adchemy의 투자자들에게 압력을 가했으며, Sam Altman은 Microsoft의 비즈니스 개발 팀과 접촉하여 Adchemy가 소송에 휘말리면 문제가 될 것이라고 경고했음.
     * 결국 Adchemy는 소송을 철회했으며, AdGrok는 승리했음. 그러나 이 사건은 AdGrok에 큰 피해를 입혔으며, 회사는 2011년 Twitter에 매각되었음. Adchemy는 2014년 Walmart Labs에 매각되었으며, 많은 직원과 투자자들이 손실을 입었음. Murthy Nukala는 상당한 금액의 퇴직금을 받았음.
     * 이 사건은 실리콘 밸리의 권력과 Y Combinator의 역할을 보여주는 사례임.

        Hacker News 의견

     * 2010년대 초반, 기술 거품과 Google IPO, 그리고 여러 스타트업 인수로 인해 부유한 전직 창업자들이 투자자로 변모했음. 이들은 작은 펀드를 조성하여 초기 스타트업에 더 큰 금액을 투자할 수 있게 되었음
          + 한 사용자는 2010년대 초반 샌프란시스코에 살았으며, Google IPO가 아닌 Facebook IPO가 큰 전환점이었다고 언급함. Facebook IPO 이후 부동산 가격이 급등하고 고급차가 증가했음
     * Adchemy가 AdGrok의 공동 창업자들을 개인적으로 소송에 명시한 사건에 대해, 개인적으로 소송에 휘말리는 것이 얼마나 스트레스가 큰지 설명함. 이는 모호한 법률이 악용될 때 발생할 수 있는 문제임
          + 창업자들을 개인적으로 소송에 포함시키는 관행은 중단되어야 한다고 주장함. 이는 법률 회사들만 이익을 얻는 게임임
     * Y Combinator(YC)는 과거에 포트폴리오 회사와 문제가 있었던 투자자들을 블랙리스트에 올리기도 했음. YC는 자신들이 원하는 회사에 힘을 실어줄 수 있는 능력이 있음
          + YC는 2012년부터 대량 투자에 집중하기 시작했으며, 이는 특정 스타트업에 더 많은 관심을 기울이게 됨. YC는 유망한 스타트업에 우선적으로 지원함
     * 소송에서 이기는 것은 거의 불가능하며, 최선은 생존하는 것임
     * YC의 폐쇄적인 태도에 대한 이야기가 인상적이었음. 비즈니스에서는 요구를 수용하지 않으면 실리콘밸리에서 일할 수 없게 될 것이라는 위협이 존재함
     * YC의 권력 역학이 오늘날에도 존재하는지 궁금해하는 의견이 있음
     * 오픈 소스 생태계는 ""와스타"" 같은 것이 필요함. AI 솔루션은 오픈 소스 개발자들이 만든 도구를 사용하여 서비스를 자동화하고 있음. 대기업들이 법적 위협으로 유지보수자들을 공격하는 경우가 있음
          + 대기업과 유지보수자 간의 불공정한 싸움이 존재하며, 이는 몇 조 달러의 순자산 차이가 있는 경우 더욱 심각해짐. YC 스타트업도 이러한 상황에서 구제받기 어려울 수 있음
"
"https://news.hada.io/topic?id=18122","고등학생을 위한 입자 물리학 강좌","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           고등학생을 위한 입자 물리학 강좌

     * 이 강좌는 CERN의 물리 교육 연구팀이 개발한 고등학생을 위한 입자 물리학 강좌의 파일럿 버전임
     * 16개의 챕터로 구성되어 있으며, 비디오와 퀴즈를 포함하고 있음
     * 기본적인 질문에서부터 입자 가속기와 입자 검출기와 같은 응용 질문까지 다룸
     * 총 비디오 길이는 약 4시간이며, DIY 실험 지침도 포함되어 있음
     * 모든 챕터를 완료하고 퀴즈를 맞추면 디지털 인증서를 받을 수 있음
     * 피드백을 통해 강좌를 개선하고자 하며, 피드백은 익명으로 수집됨

강좌 개요

     * 챕터 01: 입자란 무엇인가? (10:17)
     * 챕터 02: 모델이란 무엇인가? (11:28)
     * 챕터 03: 입자 물리학이란 무엇인가? (11:57)
     * 챕터 04: 전하란 무엇인가? (11:13)
     * 챕터 05: 상호작용이란 무엇인가? (10:27)
     * 챕터 06: 물질이란 무엇인가? (13:48)
     * 챕터 07: 보존 법칙이란 무엇인가? (17:57)
     * 챕터 08: 입자 변환이란 무엇인가? (14:54)
     * 챕터 09: 반물질이란 무엇인가? (15:45)
     * 챕터 10: 입자 물리학의 표준 모형이란 무엇인가? (15:42)
     * 챕터 11: 힉스 보손이란 무엇인가? (15:26)
     * 챕터 12: 입자 물리학의 표준 모형을 넘어서 (10:19)
     * 챕터 13: 입자 가속기란 무엇인가? (23:13)
     * 챕터 14: 입자 검출기란 무엇인가? (19:23)
     * 챕터 15: 구름 상자란 무엇인가? (14:42)
     * 챕터 16: CERN이란 무엇인가? (13:07)
     * 총 시간: 3시간 50분

교육적 틀

     * 교육 이론, 경험적 연구, 입자 물리학 교육 경험을 기반으로 개발됨
     * 핵심 메시지를 통해 학생들의 학습 진행을 지원함
     * 학습 진행은 새로운 용어와 개념을 점진적으로 소개하여 학생들이 부담을 느끼지 않도록 설계됨
     * 과학의 본질을 강조하며, 모델을 통해 과학적 지식을 설명함
     * 언어적 정확성을 중요시하며, 잘못된 용어 사용을 피함
     * 시각적 표현을 통해 입자와 입자 시스템을 효과적으로 전달함

핵심 커리큘럼

     * 파일럿 버전은 입자 물리학의 중심 모델을 다루며, CERN에서의 연구를 소개함
     * 양자 물리학과 스핀 개념은 제외됨
     * 양자 물리학은 중고등학교 수준에서의 교육 연구 결과에 따라 제외됨
     * 스핀은 고등학생들에게는 너무 추상적이어서 제외됨

준비되었는가?

     * CERN 게스트 계정을 생성하여 강좌에 접근 가능
     * 16세 이상은 개인 이메일 주소로 계정을 생성하고, 이름을 정확히 입력해야 함
     * 16세 미만은 부모나 법적 보호자가 계정을 생성해야 함

        Hacker News 의견

     * 실험에 참여한 학생들은 15-17세의 54명으로, 1,000명의 지원자 중 무작위로 선정되었음. 8주 동안 매주 2시간의 온라인 수업을 듣고, 옥스퍼드 대학원 양자 물리학 시험 문제로 테스트를 받았음. 80% 이상이 합격하고 절반 정도가 우수한 성적을 받았음
          + 실험 초기에는 학생들이 서로 소통할 수 없다는 점에서 교육적 경험이 부족할 것이라 생각했음
          + 학생들이 카메라를 켜지 않고 질문도 음성으로 하지 않아 어려운 교육 환경이었음
          + 수학적 배경이 필요하지 않다는 점이 학생들에게 긍정적으로 작용했음
          + 결과적으로 대학 수준의 학생들보다 훨씬 좋은 성과를 보였음
     * CERN 방문 경험을 통해 과학에 대한 깊이 있는 대화를 나눌 수 있었음
          + 이러한 교육 프로그램은 대규모 과학 프로젝트에 대한 관심을 유지하는 데 필수적임
     * 인터넷의 본고장에서 비디오를 자체 호스팅하지 못한 점이 아쉬움
     * 4시간의 교육 과정이 예상보다 짧았지만, 진지하게 임하는 모습이 기쁨을 줌
          + 관련 지식이 거의 없지만 참여하고 싶다는 의견도 있었음
     * CERN 방문은 인류의 발전을 위한 열망이 남아 있는 몇 안 되는 장소 중 하나였음
     * 자막이 모든 언어로 제공되며, 자동 번역 기능을 통해 접근성을 높였음
          + 영어가 기본 언어로 설정된 점이 아쉬움
          + 4시간의 교육 과정에 목소리 더빙을 추가하는 것도 고려할 만함
"
"https://news.hada.io/topic?id=18080","모든 보드 게임 규칙서의 문제점 [PDF]","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        모든 보드 게임 규칙서의 문제점 [PDF]

    Introduction

     * 저자 Dean Ray Johnson은 보드게임 규칙서가 읽기 어렵고 비효율적이라고 주장하며, 기술 글쓰기의 원리를 적용해 더 나은 규칙서를 만들기 위한 논의를 시작.
     * 보드게임 Myth의 규칙서를 비공식적으로 수정한 경험과 팬들로부터의 긍정적인 피드백을 공유.
     * 규칙서 작성의 문제점은 단순히 보드게임에만 국한되지 않으며, 잘못된 기술 문서 작성 관행의 일부라고 설명.

    Chapter One: This Good Rulebook is Awful

      1.1 Cognitive Load

     * 인지적 부하(내재적, 외재적, 유익한 부하)의 개념과 이를 줄이는 방법 소개.
     * 복잡한 정보를 한꺼번에 제공하거나 맥락 없이 제시하는 것이 독자의 이해를 방해한다고 지적.

      1.2 Readability

     * 규칙서에서 정보를 직관적으로 전달하지 못하는 문제를 탐구.
     * 간결한 문장, 명확한 리스트, 효과적인 이미지 라벨링 등이 필요.

      1.3 Overviews

     * 보드게임 On Mars의 규칙서를 사례로 사용하여 전체적인 게임 흐름을 먼저 설명하는 개요의 중요성을 강조.
     * 구성 요소와 규칙 간의 관계를 명확히 하도록 개요 설계 필요.

      1.4 Training

     * 게임 규칙서를 교육 자료처럼 설계하는 방법 제안.
     * 단계별 학습과 반복 학습의 중요성 강조.

    Chapter Two: Every Other Rulebook is Also Awful

      2.1 Personas

     * 규칙서를 설계할 때 타겟 독자를 정의하는 방법 설명.
     * 초보자와 경험자 모두를 고려한 균형 잡힌 접근법 필요.

      2.2 Learning Styles

     * 학습 스타일의 다양성을 고려해야 하며, 특정 학습 스타일에만 의존하지 말아야 함.
     * Kolb's Learning Styles 이론을 간단히 설명하며 학습 접근 방식을 다양화하는 중요성을 언급.

      2.3 Memory

     * 장기 기억으로 전환을 돕는 전략(예: 비디오 게임의 단계적 학습)과 절차 암기의 한계에 대해 논의.
     * 적시 학습(Just-in-Time Learning)의 중요성 강조.

      2.4 Documents

     * 규칙서가 참조 문서와 교육 자료의 중간 역할을 해야 한다고 제안.
     * 보드게임 Teotihuacan을 사례로 문서 유형과 목적의 차이를 분석.

      2.5 Purpose

     * 규칙서의 목적은 게임의 맥락을 명확히 전달하고, 플레이어가 게임에 몰입할 수 있도록 돕는 것.
     * 플레이어의 책임과 규칙서의 역할 간의 균형 논의.

    Epilogue

     * 기존 규칙서의 문제를 해결하기 위한 새로운 규칙서 모델을 제안.
     * 독자 친화적인 형식과 구조를 통해 게임 학습 과정을 단순화.
     * 기술 문서 작성을 개선함으로써 플레이어 경험을 향상시키는 것이 목표.

    References

     * 논의의 근거가 되는 학술 자료 및 참고 문헌 제공.

    Prototype Rulebook: Stardew Valley

     * 제안된 규칙서 개선 모델을 Stardew Valley를 기반으로 구현한 프로토타입.

     각 섹션에서 저자가 강조한 주요 아이디어는 기술 글쓰기의 원칙을 보드게임 규칙서에 적용하여 독자가 더 쉽게 정보를 이해하고 게임을 즐길 수 있도록 설계하는 것
"
"https://news.hada.io/topic?id=18001","인쇄물의 찬양: 지식 붕괴 시대에 필수적인 독서","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       인쇄물의 찬양: 지식 붕괴 시대에 필수적인 독서

     * 인쇄물의 중요성
          + 테리 프래쳇은 1995년 빌 게이츠와의 인터뷰에서 인터넷의 정보 신뢰성에 대해 의문을 제기함. 당시 미국인의 39%만이 가정용 컴퓨터를 보유하고 있었고, 인터넷 연결은 14%에 불과했음.
          + 프래쳇은 인터넷에 잘못된 정보가 퍼질 위험성을 경고했으나, 게이츠는 이를 부정하며 인터넷에서의 정보 검증이 더 정교해질 것이라고 주장함.
     * 스벤 버커츠의 경고
          + 스벤 버커츠는 그의 저서 ""The Gutenberg Elegies""에서 디지털 시대의 독서 경험 상실을 경고함. 그는 물리적 책의 중요성을 강조하며, 깊이 있는 독서가 삶의 본질을 유지하는 데 필수적이라고 주장함.
          + 버커츠는 현대 사회가 내면의 성찰을 방해한다고 지적하며, 책을 통한 '깊은 독서'가 삶의 의미를 찾는 데 중요하다고 설명함.
     * 비판과 반응
          + 버커츠의 주장은 당시 많은 비판을 받았으나, 시간이 지나면서 그의 경고가 현실화됨.
          + 인터넷을 통한 정보의 전달 방식이 물리적 책과는 본질적으로 다르다는 점이 강조됨.
     * 독서의 본질
          + 독서는 단순한 정보 습득이 아닌, 내면의 성찰과 가능성의 확장을 위한 중요한 활동임.
          + 버커츠는 독서가 개인의 내면을 강화하고, 삶의 방향성을 찾는 데 기여한다고 주장함.
     * 인쇄물의 지속성
          + 인쇄물은 디지털 정보와 달리 오랜 시간 동안 보존될 수 있는 장점이 있음.
          + 책은 물리적 형태로 존재하여, 디지털 정보의 일시성과는 대조적임.
     * 결론
          + 버커츠는 문학이 생존하기 위해서는 위험해져야 한다고 주장하며, 독서의 중요성을 강조함.
          + 독서는 개인의 자유와 내면의 성찰을 위한 필수적인 활동으로, 디지털 시대에도 그 중요성이 더욱 부각됨.

        Hacker News 의견

     * 수동적 소비의 경험
          + 케이블 TV나 TikTok 같은 수동적 소비는 심리적 소멸을 경험하게 함
          + 도박 중독자나 알코올 중독자와 비슷한 심리적 현상이 발생함
          + 시간의 손실 외에 물리적 부작용은 적지만, 자기 파괴라는 심리적 손실이 큼
          + ""거기""에 있을 때 창의적이고 생산적일 수 있는 장점도 있음
     * Neil Postman의 'Amusing Ourselves to Death'
          + 인쇄물에서 TV로의 전환이 교육, 뉴스 보도, 정치 담론 등을 오락으로 변형시킴
          + TV 뉴스의 ""이제... 이것"" 같은 맥락 전환이 정보의 맥락화 능력을 약화시킴
          + 소셜 미디어 시대에 이러한 문제는 더욱 심각해짐
          + 인터넷은 TV보다 시간과 평가의 제약이 덜하다는 점에서 긍정적일 수 있음
     * 디지털 독서의 가치
          + 디지털 버전의 책도 인쇄본만큼 지적 가치가 있음
          + Kindle이나 휴대폰으로 더 많은 책을 쉽게 읽을 수 있음
     * 교육부의 최근 조사
          + 13세 학생의 텍스트 이해 능력이 감소함
          + 인쇄된 책이 학습에 더 효과적이라는 주장
     * 인쇄 잡지의 부활
          + 향수와 촉각적 경험, 틈새 시장의 부상 등이 원인
          + 고품질 콘텐츠에 집중하는 전략적 재배치
     * 오타와 문화적 영향
          + ""The Gutenberg Elegies""의 오타가 재미있음
          + 디지털 미디어와 인쇄 미디어의 문화적 영향에 대한 논의
     * 미디어 소비의 질과 양
          + 디지털 미디어가 소비 경험을 변화시킴
          + 질과 양의 논쟁이 있으며, 이는 개인의 문화적 관점에 따라 다름
     * 광고와 집중력
          + 팝업 광고와 배너가 독서 집중력을 방해함
     * Neil Postman과 다른 학자들
          + Neil Postman, Jean Baudrillard 등 여러 학자의 연구가 논의됨
          + 스크린 사용과 건강에 대한 많은 연구가 존재함
     * Maryanne Wolf의 'Reader, Come Home'
          + 책 읽기가 점점 어려워지고 있음
          + 인쇄된 책이 온라인 콘텐츠보다 더 신뢰할 수 있음
"
"https://news.hada.io/topic?id=18086","The Verge, 유료 구독 서비스 시작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The Verge, 유료 구독 서비스 시작

     * 월 $7 또는 연 $50의 구독 서비스를 시작
          + 혜택: 광고 감소, 무제한 기사 열람, 독점 뉴스레터 구독, 독립적인 기술 저널리즘 지원
          + 한정된 기간동안 연간 구독자는 ""CONTENT GOBLINS"" 시리즈의 고급 인쇄본을 제공
     * 사이트의 많은 부분은 무료로 그대로 이용 가능
          + 사이트 속도를 개선하고 고품질 광고로만 구성된 깨끗한 인터페이스 제공

The Verge 가 생각하는 ""구독""

     * 배경
          + 주요 소셜 미디어와 검색 엔진의 변화로 독립 저널리즘이 어려움을 겪음
          + 링크를 비호의적으로 다루는 플랫폼과 AI 중심의 콘텐츠 혼란
          + 광고 기반 영향에서 벗어나 자체 웹사이트에 집중하기로 함
     * 목표
          + 사이트를 독자 중심으로 가치 있게 만들기 위해 재설계 및 콘텐츠 전략 변경
          + 인기 있는 홈페이지를 유지하며 독립성을 지킴
          + ""Quick Posts"", ""Storystream"" 같은 기능을 통해 지속적인 독자 참여 유도
     * Freemium 모델:
          + 무료: 홈페이지, 핵심 뉴스기사, Decoder 인터뷰, Quick Posts, Storystream, 라이브 블로그
          + 유료: 오리지널 심층 기사, 리뷰, 고급 뉴스레터 (Command Line, Notepad)
               o 동적 페이월(Dynamic Metered Paywall) 적용으로 많은 사람들은 페이월을 보지도 못할 것이며, 많이 읽는 경우에만 결제를 유도
     * 유료 결제자에게 차별화된 혜택 제공:
          + Full-Text RSS 피드 제공
          + 미디어의 미래에 대한 아이디어들의 얼리 억세스
               o 더 빠르고 가벼운 웹사이트 경험 제공
               o 향후 개인화 피드, 다크 모드 등 새로운 기능 출시 예정

   미디어들의 유료화 전환은 흥미롭게 보게 되네요. 일단 freemium 모델로 적용하면서 동적 페이월 적용한 것은 좋네요.
   풀텍스트 RSS도 줄만한 옵션 인것 같고요.

   리눅스 뉴스레터&커뮤니티 LWN 10년만에 구독료 인상
   어떤 유료 구독 서비스를 이용하고 계신가요?
"
"https://news.hada.io/topic?id=18100","Radon IDE - React Native 개발을 위한 VSC 확장 프로그램","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Radon IDE - React Native 개발을 위한 VSC 확장 프로그램

     * 리액트 네이티브 (및 Expo) 앱을 개발하는데 도움을 주는 VSC / Cursor 익스텐션.
     * 유료임. 개인용 월 19달러, 비즈니스용 월 29달러.

     * iOS/Android 에뮬레이터
       VSC 안에서 곧바로 띄울 수 있음.
     * 빠른 에뮬레이터 설정 변경
       폰트 크기, 다크모드, GPS 등을 VSC 안에서 바로 변경할 수 있음.
     * 클릭하여 사용할 수 있는 인스펙터
       크롬 인스펙터와 유사한 경험을 에뮬레이터 화면에서 볼 수 있음.
     * VSC 중단점 통합
     * 라우터 바로가기
       등록된 루트를 전부 리스팅해주고, 빠르게 전환 가능. React Navigation, Expo Router 지원
     * 즉석 리플레이
       수동으로 녹화하지 않아도 알아서 녹화해주고, 필요할 때 되감아 볼 수 있음.
     * 컴포넌트만 격리하여 미리보기
       에뮬레이터에서 외부 레이아웃 등을 숨기고 선택한 하나의 컴포넌트만 볼 수 있는 기능.

   오.. RN 이 디버깅이 꽤나 불편했는데, 이런 시도는 매우 좋네요. 월 구독.. 치고는 좀 비싸네요..

   유로이긴 해도 한번 써봐야겠네요

   개인적으로 중단점과 마지막 2개 기능이 정말 매력적이라고 생각합니다.
   특히 저는 VSC보단 Jetbrains 제품을 주력으로 사용하고 있는데, VSC로 넘어가야하나...를 고민할 정도로 매력적이네요.

   다만 가격이 조금 사악합니다. 웹스톰 조직용 라이선스가 16달런데;
"
"https://news.hada.io/topic?id=18070","Uber의 프롬프트 엔지니어링 툴킷","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Uber의 프롬프트 엔지니어링 툴킷

     * LLM의 정확하고 적합한 출력 확보를 위해서는 정교한 프롬프트 디자인이 필수적임
     * 프롬프트 디자인은 머신러닝에 익숙하지 않은 사용자도 최소한의 오버헤드로 모델 출력을 제어할 수 있게 함
     * Uber는 LLM을 빠르게 반복 실험할 수 있도록 중앙 집중식 툴킷을 개발
          + 프롬프트 템플릿 생성 및 관리
          + RAG 및 실행 시점의 데이터셋 활용
     * 기능:
          + 시스템 명령, 동적 맥락화, 대량 오프라인 생성(LLM 추론), 응답 평가 지원
          + 버전 관리, 협업, 안전성 확인(할루시네이션 체크, 표준 평가 프레임워크, 안전 정책 포함)

프롬프트 엔지니어링 Lifecycle

   프롬프트 엔지니어링 수명주기는 두 단계로 구성됨:
     * 개발 단계: LLM 탐색, 프롬프트 템플릿 반복, 평가의 3단계로 구성
          + LLM 탐색 단계: 모델 카탈로그와 GenAI Playground를 통해 사용 가능한 LLM을 탐색하고 프롬프트로 LLM 응답을 테스트
          + 프롬프트 템플릿 반복 단계: 구체적인 비즈니스 요구사항을 파악, 샘플 데이터 수집, 프롬프트 생성/분석/테스트, 응답 평가 및 필요에 따라 수정. Auto-prompting을 통해 처음부터 프롬프트 템플릿을 생성할 필요 없음
          + 평가 단계: 더 큰 데이터셋으로 프롬프트 템플릿을 테스트하여 성능 측정. LLM을 판단자로 활용하거나 맞춤형 코드 기반 LLM 평가자를 사용해 성능 평가 가능
     * 프로덕션화(Productionization) 단계: 평가 단계에서 임계값을 통과한 프롬프트 템플릿만 생산화. 프로덕션 환경에서 사용을 추적/모니터링하고 시스템 사용 데이터를 수집해 프로세스 향상에 활용

아키텍처

     * 프롬프트 템플릿 UI/SDK: 프롬프트 템플릿과 리비전 관리. GetAPI, Execute API와 통합
     * LLM 모델 카탈로그: 배포된 LLM 모델과 인터페이스
     * 모델과 프롬프트는 ETCD와 UCS에 저장되고 오프라인 생성 파이프라인과 프롬프트 템플릿 평가 파이프라인에 사용됨

프롬프트 템플릿 생성

     * 프롬프트 툴킷 프롬프트 빌더는 사용자를 위해 자동으로 프롬프트를 생성
     * 특정 AI 사용 사례에 맞춘 고급 프롬프팅 기술을 발견하는데 도움을 줌
     * LangChain 기반의 내부 Langfx 프레임워크 이용한 자동 프롬프트 빌더는 다음 단계를 따름
          + 1. 프롬프트 엔지니어링 모범 사례 통합
          + 2. 프롬프트 생성을 돕기 위한 템플릿 리스팅 상세 지침과 몇 가지 예제 제공
          + 3. 프롬프트 생성을 지원하기 위한 LLM 모델 활용
     * 고급 프롬프트 가이드라인: 프롬프트 빌더는 아래 원칙을 활용하여 프롬프트를 생성
          + CoT(Chain of Thought) 프롬프팅: 중간 추론 단계를 통해 복잡한 추론 능력을 가능하게 함
          + Auto-CoT: 리딩 워드 ""think step by step"" 사용. 수동 노력 제거를 위해 LLM에 ""Let's think step by step"" 프롬프트 활용
          + 프롬프트 체이닝: 여러 작업이나 변환이 포함된 시나리오에 사용 가능
          + ToT(Tree of Thought): Chain-of-thought 프롬프팅을 일반화하고 언어 모델로 일반 문제 해결을 위한 중간 단계로 사용될 수 있는 생각 탐색 장려
          + APE(Automatic Prompt Engineering): 명령어 생성 및 선택 자동화 프레임워크
          + 멀티모달 CoT 프롬프팅: 텍스트와 이미지를 2단계 프레임워크로 통합. 1단계는 멀티모달 정보 기반 근거 생성, 2단계는 생성된 근거를 활용한 답변 추론
     * 리비전 관리
          + 프롬프트 템플릿 반복은 코드 기반 반복 모범 사례를 따름
          + 테스트 응답 및 데이터셋으로 테스트하기 위해 사용자는 명령어와 모델 매개변수를 수정할 수 있음
          + 프롬프트 템플릿의 각 반복마다 코드 검토가 필요함. 승인되고 합쳐지면, 새로운 프롬프트 템플릿 리비전이 생성됨

프롬프트 템플릿 평가

   프롬프트 템플릿의 성능을 평가하기 위해 여러 컴포넌트가 협력함:
     * 두가지 평가 메커니즘
          + LLM을 평가자로 사용. 주관적 품질이나 언어적 뉘앙스가 중요한 작업에 유용함
          + 맞춤형 사용자 정의 코드를 사용하여 성능 평가. 성능의 특정 측면을 측정하는데 유용함
     * 평가 프롬프트 템플릿: 평가를 위한 명령어, 간단한 예제, 지표, 응답 형식 등을 제공하는 사용자 친화적 템플릿
     * 실제 프롬프트 템플릿: 생산 시 사용되는 템플릿. 런타임에 하이드레이션되며 성능 평가에 사용됨
     * 입력 데이터셋 옵션: 라벨링된 골든 데이터셋 또는 생산 트래픽에서 파생된 데이터셋
     * 각 템플릿은 특정 명령어, 컨텍스트, 관련 모델 및 매개변수를 고려하여 평가됨

Uber에서의 사용 사례

  오프라인 LLM 서비스

   LLM 배치 오프라인 생성 파이프라인은 대규모 LLM 응답 생성을 위한 배치 추론을 용이하게 함:
     * 소비자 사용자명 검증 사용 사례에 활용 가능
     * MA Studio에서는 관련 데이터셋을 선택하고 입력하기만 하면 됨
     * 프롬프트 템플릿은 데이터셋으로 동적으로 하이드레이션됨

  온라인 LLM 서비스

   프롬프트 템플릿에는 런타임 특정 값으로 대체되어야 하는 동적 플레이스홀더가 포함됨:
     * 현재 Jinja 기반 템플릿 구문을 사용하여 문자열 유형의 대체만 지원함
     * 프롬프트, 템플릿 및 모델 간 팬아웃(fan-out) 기능 지원
          + 템플릿: API 템플릿에는 일반 데이터 모델에서 노출한 페이로드를 공급업체별 API 구조로 포맷하는 기능 포함
          + 프롬프트 및 모델: 프롬프트는 특정 모델 및 템플릿에 고정됨. 서비스는 프롬프트를 가져오고 필요한 모델 및 템플릿 매개변수로 genAI API를 호출하여 실행함

   요약 사용 사례로 위 기능 탐색:
     * 지원 티켓(contact)을 여러 상담원이 처리할 수 있는 시나리오에서 새 상담원은 컨텍스트 이해를 위해 티켓을 살펴보거나 고객에게 문제 재설명을 요청해야 함
     * 상담원 간 인계시 요약본을 제공하여 이를 해결함

모니터링

   모니터링은 생산에 사용되는 생산 프롬프트 템플릿의 성능을 측정함:
     * 일일 성능 모니터링 파이프라인이 생산 트래픽에 대한 성능 평가 실행
     * 지연 시간, 정확도, 정확성 등 프롬프트 템플릿 생산 반복별 지표 모니터링
     * MES 대시보드는 성능 모니터링 지표로 매일 새로 고침됨

결론

   Uber의 프롬프트 엔지니어링 툴킷은 개발 및 생산의 다양한 단계에서 LLM과의 상호작용 및 활용을 향상시키기 위한 포괄적인 프레임워크:
     * Gen AI Playground에서 LLM 기능 최초 탐색부터 상세 프롬프트 템플릿 반복 및 생성까지 지원
     * 툴킷의 아키텍처는 고급 가이드라인 기술과 견고한 평가 방법을 통합하는 프롬프트 디자인에 체계적인 접근 방식을 제공함
     * 프롬프트 템플릿의 개발부터 생산 사용 및 모니터링까지의 구조화된 수명주기는 각 템플릿이 엄격하게 테스트되고 성능을 위해 최적화되도록 보장함
     * 향후 온라인 평가 및 평가용 RAG와 오프라인 생성용 RAG와 통합할 계획임
"
"https://news.hada.io/topic?id=18038","구글의 악화 현상","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               구글의 악화 현상

     * Google의 악화
          + 독립 출판의 종말과 Giant Freakin Robot
               o Giant Freakin Robot의 폐쇄 소식은 Google의 현 상태를 탐구하게 만든 계기였음
               o 최근 2년 동안 수백 개의 독립 출판사가 문을 닫았으며, 앞으로 수천 개가 더 닫힐 예정임
               o Google과 Facebook에서 오는 트래픽에 의존할 수 없게 되었으며, 대부분의 웹 미디어 회사가 생존하기 어려운 상황임
          + Google의 검색 엔진 문제
               o Google은 검색 엔진 결과를 개선하기 위해 기계 학습을 사용했으나, 효과적으로 작동하지 않는 것으로 보임
               o 많은 블로그와 소규모 사이트가 검색 결과에서 사라졌으며, 그 이유를 명확히 알 수 없음
          + Google Web Creator Summit의 경험
               o Google의 알고리듬이 유용하고 만족스러운 콘텐츠를 인식하지 못하는 문제 발생
               o Google 엔지니어 팀이 문제를 해결하려고 했으나, 명확한 해결책을 찾지 못함
          + 기계 학습과 내부 시스템의 문제
               o Google의 기계 학습 전문가들이 LLM 사용의 위험성을 경고했으나, 무시됨
               o 대량 해고로 인해 내부 시스템이 블랙박스화되었으며, 이를 이해하는 인력이 부족함
          + 독점의 영향
               o Google의 독점적 지위로 인해 제품의 유용성이 감소해도 비즈니스에 영향을 미치지 않음
               o 미국의 정치 상황으로 인해 기술 산업의 독점과 과점이 강화될 전망임
     * 결론
          + Google의 검색 엔진 문제는 독립 출판사와 소규모 사이트에 큰 영향을 미치고 있으며, 이러한 상황은 쉽게 해결되지 않을 것으로 보임

        Hacker News 의견

     * 광고 부서가 검색 엔진 부서를 이긴 이후로 광고는 기술을 지원하는 수단에서 시스템의 가치를 모두 빨아들이는 수단으로 변했음
          + Google의 고위 경영진의 비전이나 전략 부족도 문제임
     * 대량 해고의 결과로 내부 시스템이 블랙박스가 되는 경우가 많음
          + 지식 있는 인력의 직접적인 손실이 주된 이유는 아님
          + 해고된 인력 한 명당 남아 있는 인력 스무 명이 새로운 현실에 적응함
     * Kagi는 Google과 Bing의 결과를 재판매하면서도 더 나은 결과를 제공했음
          + Kagi의 시스템이 처음 몇 개의 결과를 재구성하거나 Google의 핵심 검색과 상호작용하여 좋은 결과를 제공함
     * Google의 알고리즘 실험은 불가피하며, 검색 결과에 의존하는 비즈니스 모델은 위험함
          + 검색은 LLM에 의해 대체되고 있으며, SEO에 의해 조작되고 있음
          + 콘텐츠 발견의 올바른 모델은 커뮤니티 기반 또는 큐레이션임
     * Google 검색은 간단한 쿼리에는 잘 작동하지만 복잡한 쿼리에서는 Kagi와 비교했을 때 부족함
          + 특정 쿼리에 대한 Google과 Kagi의 결과 비교가 흥미로움
     * Google은 고객 가치보다 내부 KPI를 우선시함
          + DuckDuckGo와 Kagi로 전환한 후 Google의 방향 상실이 명확해짐
          + Google의 지배력은 점차 약해지고 있으며, 젊은 세대와 기술에 정통한 사람들은 다른 대안을 찾고 있음
     * Yandex는 2006년의 Google과 비슷하게 사용자가 원하는 것을 보여줌
          + 러시아 내 검열이 있을 수 있지만, 이는 개인적인 사용 사례와는 거리가 멀음
     * Google이 내부적으로 파괴된 과정에 대한 글이 흥미로움
     * Google의 사용이 LLM의 등장 이후 80% 이상 감소했음
          + 남아 있는 Google 제품들은 손실을 감수하는 제품일 가능성이 높음
     * Giant Freakin' Robot은 다른 웹 페이지로의 링크를 제공하는 집계 사이트였으며, Google은 이제 이러한 사이트를 하향 평가함
          + Google 자체도 집계 사이트이며, 다른 집계 사이트로 트래픽을 전달할 이유가 없음
"
"https://news.hada.io/topic?id=17998","TeaTime - SQLite, IPFS 및 GitHub로 구동되는 분산형 도서관 시스템","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TeaTime - SQLite, IPFS 및 GitHub로 구동되는 분산형 도서관 시스템

     * IPFS, SQLite, GitHub을 기반으로 하는 완전한 정적 분산 라이브러리 시스템
     * Netlify와 GitHub Pages에서 자동 업데이트되는 인스턴스 호스팅 가능

분산 라이브러리

     * TeaTime 웹 애플리케이션은 데이터베이스와 가져오는 파일로부터 완전히 분리되어 있음.
     * 사용되는 데이터베이스는 GitHub Pages에 게시된 teatime-database 주제가 태그된 GitHub 저장소임.
     * 각 저장소는 SQLite 데이터베이스를 가리키는 config.json 파일을 포함함.
     * 사용자가 검색을 수행하기 전에 사용할 데이터베이스를 선택하고, TeaTime은 sql.js-httpvfs를 사용하여 SQLite 데이터베이스를 쿼리함.
     * SQLite 데이터베이스의 각 행은 라이브러리의 항목이며, 파일 해시 열은 IPFS에서 항목을 가져오는 데 사용됨.
     * 웹 애플리케이션이 정적 사이트이고 데이터베이스가 정적 파일로 구성되어 있어 쉽게 포크, 복제, 배포 가능함.
     * 프론트엔드 인스턴스는 teatime-instance 주제가 태그된 GitHub 저장소임.
     * IPFS에서 파일이 제공되므로 이 분산 아키텍처는 TeaTime의 회복력을 높임.

  기능

     * 제목, 저자, 연도 또는 형식으로 검색 가능
     * 읽기 기록 유지 및 파일 재열기 시 페이지로 돌아가기
     * 파일을 로컬로 다운로드
     * IndexedDB에 파일 캐시하여 빠른 로딩
     * TeaTime에 파일 드롭하여 렌더링
     * 다크 모드 및 전체 화면 모드
     * 쿠키 없음, 로그인 없음
     * 완전히 분산됨

  프론트엔드 개발

     * TeaTime은 Nuxt.js 애플리케이션임.
     * 로컬에서 쉽게 실행 가능: 저장소를 클론하고 다음 단계 수행
         1. 종속성 설치: npm install
         2. 서버 실행: npm run dev
         3. http://localhost:3000으로 이동
     * Nuxt 문서를 참조하여 추가 정보 확인 가능

  데이터베이스 생성

     * JSON 기반 데이터베이스 저장소를 포크하고 JSON 파일을 필요에 맞게 조정하여 데이터베이스 생성 가능.
     * GitHub Actions가 SQLite 파일을 생성하고 GitHub Pages에 업로드함.
     * TeaTime과 함께 작동할 수 있는 SQLite 데이터베이스를 수동으로 생성하려면 데이터베이스 저장소의 예제를 따름.
     * 각 SQLite 데이터베이스는 아래 스키마를 가진 테이블을 포함함. 열 이름은 config.json 파일에서 조정 가능.
CREATE TABLE ""books"" (
  ""id"" INTEGER,
  ""title"" TEXT,
  ""author"" TEXT,
  ""year"" INTEGER,
  ""lang"" TEXT,
  ""size"" INTEGER,
  ""ext"" TEXT,
  ""ipfs_cid"" TEXT,
  PRIMARY KEY(""id"" AUTOINCREMENT)
);

     * SQLite 파일이 너무 크면 분할 가능. 데이터베이스 최적화 정보 참고 필요. FTS 사용 권장.
     * 저장소를 GitHub Pages에 게시하고 teatime-database 주제를 저장소에 할당

  기여

     * 코딩을 못하더라도 이 저장소와 좋아하는 데이터베이스 저장소를 포크하여 기여 가능.
     * 저장소를 포크할 때 직접적으로 연결되지 않도록 수동으로 포크하는 것이 좋음 (git clone && git remote add your-origin ... && git push your-origin main).
     * 유용한 데이터베이스 저장소에 별표를 추가하는 것도 좋은 방법임. 이는 TeaTime 사용자 인터페이스에서 데이터베이스의 순서를 결정하여 다른 사용자가 최고의 데이터베이스를 쉽게 찾을 수 있도록 함.

        Hacker News 의견

     * IPFS 기여자는 IPFS에서 여러 게이트웨이로부터 다운로드를 처리하는 방법을 개선할 수 있는 방법을 제안함
          + @helia/verified-fetch를 사용하면 Fetch와 유사한 API를 통해 CIDs를 수락하고 콘텐츠 라우팅과 P2P 검색을 처리할 수 있음
          + 게이트웨이에 직접 연결할 수 있는 경우 게이트웨이를 전달할 수도 있음
     * Pear P2P 프레임워크는 GitHub에서 벗어나 진정한 분산 시스템으로 전환하는 데 도움이 될 수 있음
          + 인덱스가 GitHub에 있어야 한다면 IPFS에 파일을 저장하는 것이 무슨 의미가 있는지 의문을 제기함
     * Helia를 사용하여 사용자가 네트워크의 노드로 기여할 수 있도록 하는 것을 고려 중임
          + Helia에 대한 정보를 검색하면서 OrbitDB를 떠올리게 되었음
     * 특정 리소스에 접근할 때 CORS 정책으로 인해 차단되는 문제가 발생함
          + 요청의 모드를 'no-cors'로 설정하여 CORS를 비활성화한 상태로 리소스를 가져올 수 있음
     * 브라우저에서 모든 작업이 이루어지며, 사용자, 쿠키, 추적이 없음
          + LocalStorage와 IndexedDB를 사용하여 마지막 읽은 위치와 파일 내 위치를 저장함
          + 이 기능을 매우 좋아하며 감사의 뜻을 전함
     * TeaTime에서 사용되는 데이터베이스는 GitHub Pages에 게시된 GitHub 저장소임
          + 악의적인 사용자가 이 태그를 사용할 수 있어 보안 문제가 될 수 있음
     * 데이터베이스에 무엇이 있는지 모르기 때문에 검색할 내용을 알 수 없음
          + 탐색 기능을 제안함
     * 예제 인스턴스를 사용할 수 있는지에 대한 질문이 있음
     * Pocket 북마크를 통합할 수 있는지 궁금해함
          + 읽고 싶은 모든 것을 오프라인으로 캐시하고 링크 부식을 방지하며 쿼리할 수 있기를 희망함
"
"https://news.hada.io/topic?id=18094","블리자드의 워크래프트 I 및 II 철회, GOG의 새로운 보존 프로그램 시험","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               블리자드의 워크래프트 I 및 II 철회, GOG의 새로운 보존 프로그램 시험

     * 오크 vs. 인간 vs. 상업 vs. 역사 vs. 보존 vs. 플레이어
          + Blizzard는 최근 _Warcraft_와 _Warcraft II_의 리마스터 버전을 출시했으며, 이로 인해 GOG의 DRM-free 버전이 삭제될 예정임.
          + GOG는 ""Make Games Live Forever""라는 슬로건 아래 보존 프로그램을 운영 중이며, Warcraft I & II 번들을 할인 판매하고 있음.
          + 12월 13일 이전에 구매한 사람들은 오프라인 설치 프로그램과 함께 계속 액세스할 수 있음.
     * GOG의 보존 프로그램
          + GOG는 게임이 더 이상 판매되지 않더라도 현대 및 미래 시스템과 호환되도록 유지 및 업데이트할 것임을 약속함.
          + GOG의 버전은 Blizzard.net에서 판매된 고전 버전보다 개선된 네트워킹 코드와 DirectX 래퍼를 포함하여 현대 모니터 해상도에 맞게 조정됨.
          + GOG는 수익을 창출하지 않는 게임도 구매자에게 계속 플레이 가능하도록 하는 데 헌신하고 있음.
     * _Warcraft II: Remastered_의 특징
          + 클래식과 리마스터 그래픽 간 전환이 가능하며, 와이드스크린 모니터 지원과 더 많은 유닛 선택이 가능함.
          + Blizzard의 Battle.net 서비스와 영구적으로 연결되어 있지만, 원작을 보유하고 싶은 이유가 있음.
          + _Warcraft III Reforged_는 출시 당시 미완성으로 평가받았으며, 원작 _Warcraft III_도 상점에서 제거됨.
     * Kevin Purdy
          + Kevin Purdy는 Ars Technica의 선임 기술 기자로, 오픈 소스 소프트웨어, PC 게임, 홈 자동화, 수리 가능성, 전기 자전거 및 기술 역사를 다루고 있음.

        Hacker News 의견

     * Warcraft 3의 리마스터가 두 번 출시되었지만, 여전히 20년 전보다 상태가 나쁨. 첫 번째는 예산을 줄이고 주요 기능이 빠진 상태로 출시되었으며, 두 번째는 AI 업스케일링과 부적절한 그림자 추가로 ""Warcraft 3 2.0""이라 불림
          + Microsoft의 일원이 되었음에도 개선되지 않았음
          + Warcraft 3가 Age of Empires 2나 Age of Mythology처럼 다뤄졌으면 좋았을 것임
     * GoG에서 게임을 구매하는 것을 선호하며, DRM 없는 설치 파일을 소유할 수 있는 점이 좋음
          + 하드 카피가 사라지는 상황에서 구매한 소프트웨어의 백업을 만들 수 있는 권리가 법적으로 보호되어야 함
          + 디지털 복사본이 역사 삭제의 수단이 되는 경우가 많아, 소비자와 문화에 해로움
     * Blizzard의 새로운 발표는 기대보다는 두려움과 우울함을 줌
          + Overwatch 1까지는 기대했으나, Warcraft 3 리마스터와 Overwatch 2는 실망스러웠음
          + GoG의 보존 프로그램 덕분에 어린 시절 게임을 더 구매하고 싶어짐
     * Blizzard는 오랜 시간 쌓아온 신뢰를 잃고 있음
          + GoG는 이익을 위해 노력하지만, 여전히 인상적임
          + 오래된 게임을 정당하게 구매할 수 없는 상황은 불법 복제를 부추김
     * GoG가 Blizzard와 대립하면서도 정치적 이유로 Devotion 게임을 즉시 철회한 점이 흥미로움
     * GoG는 12월 13일까지 게임을 판매하며, 이후에도 구매한 사람들을 위해 업데이트를 유지할 것임
     * 일부 회사는 오래된 게임의 재출시로 가치를 더하지만, 대기업은 AI 업스케일링에 그치는 경우가 많음
     * 클래식 게임은 고정된 설정을 즐기는 캐주얼 게이머를 위한 것이며, 리디자인은 구독 모델로 브랜드를 유지함
          + Blizzard는 IP에 대한 이야기를 결정하고 싶어하지만, 많은 게이머들은 리메이크 이전의 감성을 원함
          + GoG는 초기 성인 시절의 꿈을 충족시킴
          + 새로운 ""클라우드"" 게임은 구독 모델로 변장한 것임
          + 전통과 순수한 엔터테인먼트의 차이는 고정된 규칙에 있음
"
"https://news.hada.io/topic?id=18064","Unlock: finding Go-To-Market Fit (실행과 느낀 점 포함)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Unlock: finding Go-To-Market Fit (실행과 느낀 점 포함)

   B2B Software에 전문적으로 투자하는 Storm Ventures의 남태희 대표님께서 저술한 Go-To-Market fit에 대한 글입니다.

   아래의 글을 읽고 분기 결산 겸 GTM Playbook을 만들어 보았습니다.
   래티스는 엔지니어가 많은 조직이라 회사 내에 고객의 목소리를 더 잘 전달하고 싶었어요. Deal by deal grind부터 ICP 정의, Customer Journey 분석까지 8시간 정도 걸렸지만, 그 덕분에 고객을 더 잘 이해하고 팀의 고객에 대한 시야를 일치시킬 수 있었습니다. 문서 양식과 프릭스의 예시도 첨부했으니 GTM 조직에게 전달해 월말/연말 결산에 도움을 받아도 좋겠습니다!

요약

   많은 B2B 스타트업이 PMF를 찾더라도 성장하지 못하는 경우가 있다. PMF와 가속화되는 성장 사이에는 갭이 있기 때문인데, 그 갭이 GTM-fit이다.

   우리는 GTM fit을 찾는 과정을 서핑에 비유할 것이다. GTM fit은 서핑에서 팔로 노를 젓는 것(PMF)에서 파도를 타는 것(GTM-fit)으로 옮겨가는 과정이다. 노를 젓는 것은 굉장히 힘들고 진전도 거의 없어 보인다. GTM fit이 없다면, 회사는 돈을 엄청나게 쓰고 아주 조금만 성장할 것이다. GTM fit을 찾으면, 더이상 노를 저을 필요 없이 관성으로 - 파도를 타듯 성장할 수 있다.

   1단계인 파도를 잡는 것은 소비자 여정 (Customer Journey:CJ)를 성공하는 것부터 시작한다. 소비자 여정은 GTM의 근본으로 나머지 것들은 그 위에 올라가야 한다. 소비자 여정은 긴급한 고통으로부터 시작하고, 소비자에게 당신의 회사가 전략적으로 중요해지는 것으로 끝을 맺는다.

   2단계인 적절한 서핑보드 만들기는 반복 가능한 GTM Playbook을 만드는 것이다. GTM 플레이북은 딜을 계속해서 찾고, 따낼 수 있는 단계별 반복 가능한 레시피이다. 마케팅과 세일즈 팀은 이를 바탕으로 만들어져야 하며, 새로운 마케팅/세일즈 직원이 온보딩될 때 이를 따라야 한다.

   3단계인 파도를 타는 것은 플레이북을 실행하는 것이다. GTM Playbook은 마케팅, 세일즈, CS(Customer Success)와 제품을 망라한다. GTM Playbook은 스타트업 전체에서 제일 기능-교차적인 프로젝트이다. CEO는 회사 전체를 이를 통해 보아야 하고, 회사가 이를 따르게 해야 한다. GTM Playbook을 따르는 것은 계주 달리기와 같이 하나의 팀에서 다른 팀으로 넘어가게 된다. 어떤 팀이 바통을 이어받는지 보고, 바통이 넘어갈 때를 부드럽게 해야 한다.

   4단계인 서핑 개선하기는 Playbook을 지표를 통해 개선하는 것이다. 지표들 상의 계층을 이해하고, GTM에서의 문제를 진단하고 고치는 데 쓸 것이다. 여기서는 Variable zoom과 system view라는 개념을 이용하는 것이 중요하다.

   마지막으로, GTM fit을 찾은 다음 어떻게 재무계획을 해야 하는지 알려주겠다. 창업가들은 회사를 키우고 싶고, 투자자들은 돈을 벌고 싶어한다. 투자자들을 설득하기 위해 성장의 준비가 되었음을 확인하기 위해서는 운영지표 확인 - 재무 모델링 - 가치평가와 투자받기 (Valuation/Revenue Multiple) - 자금소모계획 - 운영지표 확인..의 이터레이션을 거쳐야 한다.

#1 catch the wave

   엔터프라이즈 스타트업의 경우, 파도를 찾는다는 것은 고객이 지금 구매하도록 유도하는 이상적인 고객 프로필에 대한 긴급한 고통을 파악하는 것을 의미합니다. 파도는 이상적인 고객 프로필에 대한 긴급한 고통에서 시작하여 회사가 고객에게 전략적인 존재가 될 때 끝납니다.

   CJ(소비자 여정; 이하 Customer Journey)를 면밀히 분석하기 위해서:

   긴급한 고통부터 시작하세요

   7가지 주요 마일스톤을 포함한 전체 CJ 그려보기

   첫 고객 확보

   고객에게 전략적인 포지셔닝 하기

   우리 제품이 긴급한 고통인지는: ""1년 후가 아닌 지금 구매해야 하는 이유는 무엇인가요?"" 라는 질문에 답할 수 있어야 한다.

   스타트업은 체계적인 검색 프로세스를 통해 고객의 긴급한 고통을 찾아내야 한다:
    1. 이단처럼 느껴지더라도 열린 마음으로 더 넓은 그물을 던지세요.
    2. 당시에는 관련성이 없어 보이는 데이터까지 모든 데이터를 문서화하세요.
    3. 패턴 및 핫스팟 찾기

   일반적인 통념은 스타트업에게 ""집중, 집중, 집중""하며 창업 아이디어에 집중하라고 말합니다. 하지만 창업 아이디어에 지나치게 독단적으로 집중하는 것은 치명적일 수 있습니다. 창업 아이디어가 창업자에게는 매력적일 수 있지만, 고객에게는 긴급한 고통이 바로 옆에 있는 경우가 많습니다. 그것은 창업 아이디어가 아닙니다. 그리고 제품을 구매하는 것은 창업자가 아닙니다. 바로 고객입니다.

  인접성 테스트

   처음에는 제품 시장 가설에 초점을 맞추고 시작하되, 인접한 문제점과 고객 세그먼트에 대해서도 약간 더 넓은 범위를 고려하세요. 이를 테스트하면 원래 아이디어에서 리소스를 전환할 수 있습니다. 이에 대한 정해진 규칙은 없지만, 인접성 테스트에 20~30%의 에너지를 투자하면 초기 초점 밖에 있을 수 있는 잠재적 핫스팟을 감지할 수 있는 충분한 범위를 확보할 수 있습니다.

  관련성이 없어 보이더라도 모든 데이터를 문서화하기

   시급한 문제점을 찾는 것은 고객과 대화하고 그 대화를 문서화하여 데이터를 확보하는 것에서 시작됩니다.

    고객과 대화하기

   긴급한 고통이 무엇인지 누가 결정할까요? 바로 고객입니다. 그리고 고객의 고충을 알아낼 수 있는 방법은 단 한 가지, 바로 고객과 대화하는 것입니다.

    편견 없는 태도

   스타트업에는 에반젤리스트와 리스너라는 두 종류의 커뮤니케이터가 있습니다. 에반젤리스트는 세상이 어떠해야 한다는 생각이 강하기 때문에 고객의 관점에 맞추지 못합니다. 에반젤리스트는 경청할 때 자신의 관점을 강화하는 내용만 선택적으로 듣습니다. 반면에 청취자는 정반대입니다. 리스너는 말을 잘하지는 못하지만 고객에게 주의를 기울이고, 메모를 하고, 무엇이 관련성이 있는지 파악하는 데 능숙합니다. 고객을 확보하기 위해서는 에반젤리스트가 필요하지만, 특히 긴급한 문제점을 찾고 있을 때는 리스너도 필요합니다. 스타트업 초기에는 팀이 열린 마음을 가져야 합니다.

    문서, 문서, 문서

   있는 그대로의 문서화가 중요합니다. 영업팀과 마케팅팀은 첫 번째 영업 통화부터 일어나는 모든 일을 기록해야 합니다. 담당자가 뭐라고 말하나요? 고객의 반응은 어떤가요?

   데이터를 정리하는 것은 나중에 분석하는 데 중요합니다. 스프레드시트나 설문지와 같이 피드백을 수집할 수 있는 질문 템플릿을 준비해 두면 도움이 됩니다.

  패턴 및 핫스팟 찾기

   팀을 한 방에 가두어 데이터의 패턴을 파악하려면 팀을 한 방에 가두고 화이트보드에 20~40개의 고객 거래 중 승패가 갈린 거래를 하나씩 살펴보세요. 각 거래에서 어떤 일이 일어났는지, 그리고 그 이유는 무엇인지 알아보세요.

   데이터만이 의견, 편견, 일화와 같은 증거를 잘라낼 수 있기 때문입니다. 팀 전체가 함께 모여 각자의 관점을 제시하고 같은 생각을 공유해야 합니다.

   딴 딜 20개, 부러진 딜 20개를 이용해서 주요 질문에 답하기

    패턴이 나타날 것이다

   거래를 면밀히 검토하다 보면 (희망적으로) 패턴이 드러날 것입니다. 무엇이 관심을 불러일으켰나요? 무엇이 거래를 움직이게 했나요? 어떤 유형의 고객인가요? 어떤 사용 사례가 있었나요? 어떤 거래는 왜 속도가 느려졌나요? 왜 실패했나요? 성공한 거래를 중심으로 공통된 패턴이 있나요? 그렇다면 이것이 단서입니다. 실패한 거래에서도 똑같이 교훈을 얻을 수 있습니다. 모든 성공, 실패, 거래 중단, 관심 없는 고객은 세상이 여러분에게 주는 교훈입니다.

   누가, 왜, 왜 안 되는지를 한데 모아 패턴을 찾고 이를 시각화하는 것은 매우 강력한 연습이 될 수 있습니다.

   여러분이 찾고 있는 것은 특정 유형의 고객이 특정 문제점에 대해 반복적으로 성공하는 패턴입니다. 그리고 데이터가 특정 조합을 중심으로 통합되면 빙고입니다. 긴급한 문제와 이상적인 고객 프로필(ICP)의 조합인 핫스팟을 찾은 것입니다.

   GTM 적합성은 가장 시급한 한두 개의 핫스팟에 GTM 플레이북과 GTM 리소스를 배치한 다음, 현재 고객과 시급성이 낮은 문제에 연결된 미래의 합법적인 고객 기회를 모두 희생하는 어려운 선택을 해야 합니다. 고통스러운 일입니다. 고객과 합법적인 고객 기회를 희생하면 매출을 목표로 하는 GTM 팀은 거래를 성사시키기 위해 열심히 노력한 고객을 미치게 만들 것입니다. 하지만 이는 필요한 희생입니다. 반복 가능한 GTM 플레이북을 구축하려면 여러 핫스팟에 집중할 수 없습니다.

   스타트업은 영업 담당자가 아닌 고객의 렌즈를 통해 CJ를 바라봐야 합니다. CJ는 SalesForce.com의 예측 단계와 동일하지 않습니다. CJ 단계는 잠재 고객이 스타트업과 소통할 때 실제로 어떤 일이 일어나는지 관찰하는 데서 비롯됩니다. 고객 여정의 물리학을 포착합니다.

   긴급한 통증부터 시작하여 여정의 각 단계를 화이트보드에 적습니다(한 가지 예는 위 다이어그램의 흰색 직사각형 참조).

   다음은 시작점으로 사용할 수 있는 몇 가지 질문입니다:
     * 고객이 해결해야 하는 긴급한 고통은 무엇인가요? 일상적인 문제인가요, 아니면 실존적인 문제인가요?
     * 고객이 귀사를 어떻게 찾나요, 아니면 귀사가 고객을 찾나요?
     * 어떻게 관심을 갖게 되나요?
     * 회사 내에서 제품의 챔피언/에반젤리스트는 누구인가요? IT 부서, CFO, 마케팅 팀 등인가요?
     * 참여는 어떻게 결정하나요?
     * 어떻게 선택되고 구매를 결정하나요? 누가 서명해야 하나요?
     * 고객은 어떻게 제품을 사용할 수 있나요? 일반적인 확장 단계(사용자 250명, 사용자 1,000명, 사용자 10,000명 등)는 무엇인가요?
     * 라이브 출시 시 극복해야 할 장애물은 무엇인가요?
     * 다른 워크플로우와 통합하여 제품을 확장하거나 새로운 사용 사례를 지원하나요?
     * 고객은 어떻게 갱신을 결정하나요?
     * 고객의 비즈니스에 어떻게 전략적일 수 있나요? 고객을 위해 어떤 새로운 문제를 해결하고 있나요?

  주요 마일스톤 하이라이트

   CJ 단계는 고객 여정의 물리학을 나타내며, 어떤 회사도 똑같은 CJ를 가지고 있지는 않습니다. 그렇기 때문에 식별하고 강조해야 할 세 가지 중요한 '마일스톤'을 소개하고자 합니다. 이는 플레이북에서 가장 중요한 부분이며, GTM을 운영할 때 중요한 레버리지 포인트가 될 것입니다.
    1. 긴급한 고통. 이것이 바로 고객이 1년 후가 아닌 지금 구매하도록 유도하는 고통 포인트입니다. (""긴급한 고통 찾기""를 참조하십시오.) 긴급한 고통이 없다면 GTM Fit은 존재하지 않습니다.
    2. 첫 번째 가치에 도달하는 시간. 고객이 제품에서 가치를 얻는 첫 번째 시점입니다. 첫 번째 가치에 도달하는 시간을 단축하면 전환을 획기적으로 늘리거나 가속화할 수 있습니다. 따라서 반드시 파악해야 합니다: 첫 번째 가치는 무엇인가? 고객이 언제 그것을 경험하는가?
    3. 전략적 플랫폼이 되세요. 귀사의 제품이 ICP의 시급한 문제를 해결해 준다면, 귀사는 이미 시장 진입의 문턱에 들어선 것입니다. 하지만 어떻게 하면 그 문을 끝까지 열고, 그 시급한 문제를 해결할 수 있는 다른 제품과의 경쟁에도 불구하고 그 문을 계속 열어둘 수 있을까요? 정답은 제품을 ""전략적""으로 만드는 것입니다. 전략적 제품에는 장기적인 가치 제안이 있습니다. 사람들이 구축하는 워크플로우에 내장된 플랫폼이 됩니다. 귀사의 제품이 어떻게 고객에게 전략적 플랫폼이 될 수 있을까요? 아직 모르시더라도 괜찮습니다. 다음 섹션에서 ""전략적인 플랫폼이 되는 방법""에 대해 설명하겠습니다. 이 섹션을 읽은 후에는 CJ로 돌아와서 제품이 어떻게 전략적인 플랫폼이 될 수 있는지 알아보세요.

   1번째 값에 도달하는 시간으로 SLG와 PLG를 차별화할 수 있습니다.

   고객이 제품으로부터 가치를 처음 받는 시점에 주목하세요. 계약 체결 전인가요, 후인가요? 계약 이후라면 보다 전통적인 판매 주도 성장(SLG) GTM 모델을 따를 가능성이 높습니다. 고객이 첫 계약 전에 부분 유료화(freemium) 서비스 등을 통해 가치를 얻는다면 제품 주도 성장(PLG)에 더 적합할 수 있습니다.

   챌린지 박스: 고객 여정에 대한 공유된 관점을 확보하는 것은 생각보다 어렵습니다.

   회사의 여러 부서에서 고객 여정에 대한 공유된 관점을 갖고 있지 않다면 어떻게 반복 가능한 GTM 플레이북을 구축할 수 있을까요? 이러한 관점을 수렴하도록 강제해야 합니다. 이는 매우 중요합니다. 모든 팀이 고객 여정에 대해 동일한 관점을 가져야 합니다. 이것이 GTM 플레이북의 중추입니다.

    자주 하는 실수

   #1 거래가 종료되어도 CJ는 끝나지 않습니다.

   SaaS 기업의 경우 거래가 성사된다고 해서 CJ가 끝나지 않습니다. 사실 그때부터 가장 힘든 작업이 시작됩니다.

   대규모 거래의 경우, 고객을 확보하는 것은 하루아침에 이루어지지 않습니다. 일반적으로 출시에는 여러 단계가 있으며, 각 단계마다 극복해야 할 과제가 있습니다. 스타트업은 고객에게 신속하게 대응하고 이러한 문제를 최대한 빨리 해결해야 합니다. 그렇게 하지 않으면 실패할 수 있지만, 문제에 잘 대응하면 신뢰를 쌓고 확장, 상향 판매 및 새로운 사용 사례를 지원할 수 있습니다.

   #2 고객을 회사 전체로 생각하기

   고객은 회사 내 개인입니다. 영업 프로세스에는 항상 경쟁적인 목소리와 이해관계가 존재하므로 회사 내에서 귀사의 제품으로 고객의 고충을 해결할 수 있는 챔피언을 찾아야 합니다.

   #3 고객 요청에 너무 빠르게 대응하는 경우

   고객의 말을 경청하는 것은 언제나 좋은 일입니다. 하지만 너무 많이 듣고 사소한 요청에 시간을 낭비하지 않도록 주의하세요. 구현 단계에서 발생할 수 있는 큰 장애물과 고객 요청에 대비하여 에너지를 절약하세요. 고객이 계약서에 서명한 후 어떻게 대응하느냐에 따라 성공 여부가 결정됩니다.

  첫 고객을 확보하는 방법

   지금까지 CJ의 '무엇'에 대해 이야기했습니다. 이제 잠시 멈추고 ""어떻게""에 대해 이야기할 필요가 있습니다. 즉, 첫 번째 고객을 어떻게 확보할 수 있을까요? 이미 논의했듯이, 고객을 확보하기 위해서는 긴급한 고통이 매우 중요합니다. 하지만 스타트업 초기에는 긴급한 고통 그 자체만으로는 충분하지 않을 수 있습니다. 제품의 장점과 검증되지 않은 스타트업과의 협력에 따른 잠재적 단점 사이에 '위험 비대칭성'이 존재하기 때문입니다.

    위험 비대칭성

   이러한 초기 고객은 팀보다 먼저 GTM 적합성을 확인합니다. 이들은 스타트업의 전략적 가치를 확인합니다. 대부분의 고객은 사물을 보는 시각이 매우 다릅니다. 일반 고객에게는 스타트업과의 파트너십에 따른 위험이 잠재적 이익보다 더 커 보일 수 있습니다. 그리고 이러한 고객들이야말로 여러분이 확보해야 할 대부분의 고객입니다.

   고객의 입장에서 생각해 보세요. 제품이 성공하면 고객이 얻는 이득은 무엇이고, 실패하면 잃는 것은 무엇일까요? 창업 CEO는 보통 전자에 초점을 맞추지만, 대부분의 고객은 후자에 초점을 맞춥니다. 고객이 제품을 평가할 때 이 제품을 통해 내가 승진했으면 좋겠다는 생각은 하지 않습니다. 이 제품이 성공해서 해고당하지 않았으면 좋겠다는 생각을 하는 것이죠.

   초기 고객을 확보하려면 스타트업은 위험 비대칭성을 깨고 위험보다 더 큰 상승 여력을 제공한다는 것을 증명해야 합니다.

    초기 고객 확보를 위한 위험 비대칭성 해소

   얼리어답터와 일반 고객 모두 위험 비대칭을 해소하고 판도를 바꿀 수 있는 제품을 찾는다는 공통점이 있습니다. 비대칭성을 해소하는 스타트업은 일반적으로 다음 세 가지 특징을 공유합니다. 첫 번째는 일반적으로 고객을 확보하는 데 필수적인 요소이지만, 두 번째와 세 번째는 얼리어답터를 확보하는 데 특히 중요합니다.

   #1 긴급한 통증을 해결하고 사용하기 쉬운 제품입니다.

   제품을 쉽게 사용해보고, 구매하고, 사용할 수 있도록 만드는 것은 유기적인 상향식 방식으로 고객을 유치할 수 있는 강력한 방법입니다.

   #2 개인적인 약속

   창업자와 초기 고객 간의 관계는 결혼과 같습니다. 창업자는 초기 고객과의 정기적인 열린 소통과 투명성을 통해 이러한 약속을 보여줄 수 있습니다. 문제가 발생하면 고객에게 알리고 해결 계획을 공유하며 어떤 일이 발생하더라도 약속을 이행할 것입니다.

   #3 전략적으로 챔피언을 영웅으로 만들기

   전략 제품은 사람들이 주목하는 제품입니다. 고객이 당면한 문제를 해결하는 데 도움이 될 뿐만 아니라 장기적인 가치 제안을 제공합니다. 일반적으로 디지털 트랜스포메이션, 클라우드 마이그레이션, 모바일 엔터프라이즈, IT의 소비자화 등 시간이 지남에 따라 점점 더 중요해지는 물결의 일부입니다. 이는 매출 증대, 비용 절감 또는 다른 주요 비즈니스 목표 등 워크플로우에 포함될 때 회사에 영향을 미칠 새로운 가능성을 열어줍니다. 제품이 고객의 비즈니스에 전략적일 때, 그 제품은 플랫폼이 되고 사람들은 그 위에 무언가를 구축합니다.

   귀사의 제품이 어떻게 고객의 주요 비즈니스 목표를 달성하고 다른 방법으로는 불가능했던 장기적인 가능성을 열어줄 수 있을까요? 이 질문에 대한 해답을 찾는 것이 전략적으로 장기 고객을 확보하는 열쇠입니다.

  전략적인 제품으로 포지셔닝하며 CJ를 끝내라

   고객 여정은 제품이 고객에게 전략적인 제품이 되고 챔피언이 영웅이 되는 것으로 끝납니다.

    영웅의 보고서 찾기

   제품이 조직을 혁신할 수 있는 잠재력을 가지고 있다면 챔피언이 ""영웅 보고서""를 작성하도록 지원하여 챔피언을 영웅으로, 그리고 행복한 레퍼런스 고객으로 만들 수 있습니다.

   고객 여정의 끝은 챔피언이 조직의 영웅이 되는 순간입니다. 챔피언이 귀사의 제품을 사용하여 달성한 모든 성과를 정리한 '영웅 보고서'를 작성하여 경영진에게 제출함으로써 관심을 끌고 승진할 수 있도록 지원하세요.

    시장을 혁명하되, 진화를 판매하세요

   핵심은 고객에게 제품의 전략적 잠재력(장점)을 알리는 동시에 위험(단점)을 최소화하는 것입니다. 다시 말해, 시장 혁명이 아니라 판매의 진화입니다.

   스타트업은 덩치는 크지만 시대에 뒤떨어진 오래된 공룡인 기존 기업의 통념을 공격함으로써 사고의 리더가 될 수 있습니다. 스타트업은 돌진하고 파괴할 준비가 된 유니콘입니다. 사고 리더십으로 공격하고 창업 아이디어에서 약속한 전략적 목표를 중심으로 열정적인 커뮤니티를 만들어야 합니다. 도발적이고 논쟁의 여지가 있으며 이념적으로 순수해야 합니다.

   고객은 혁신을 굳게 믿지만 진화적 접근 방식을 선호합니다. 각 단계가 고객에게 가치를 제공하여 신뢰를 구축하고 조직의 저항을 극복할 수 있는 진화를 판매함으로써 이러한 고객을 지원하세요. 이 접근 방식은 챔피언을 경력 위험에 빠뜨리지 않습니다.

    긴급한 고통에 대해 교육하지 마세요. 전략적 가능성에 대해 교육하세요.

   신규 고객에게 문제에 대해 '알리기' 위해 많은 시간을 할애할 필요가 없습니다. 대신 잠재 고객에게 전략적 가능성, 즉 제품을 통해 얻을 수 있는 새로운 의미와 행동에 대해 교육하세요. 긴급한 고통에서 전략적 성과에 이르는 여정을 제시하는 것이 바로 마법입니다.

   좋은 글 감사합니다! :) 들어온 리드가 SQL인지 판단하기 위해 어떤 방법을 쓰시는지도 궁금하네요

   감사합니다!

   좋은 글 감사합니다!!
"
"https://news.hada.io/topic?id=18034","인터셉트의 OpenAI 소송에서 진행되는 Core 저작권 침해 사건","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 인터셉트의 OpenAI 소송에서 진행되는 Core 저작권 침해 사건

     * 주요 소송 진행 상황
          + 최근 뉴욕 연방 판사는 The Intercept가 OpenAI를 상대로 제기한 핵심 저작권 침해 주장을 법정에서 진행하기로 결정함.
          + 이 소송은 OpenAI가 ChatGPT를 구축하기 위해 The Intercept의 기사를 훈련 데이터 세트에 사용하면서 저작자 정보를 제거했다는 주장에 기반함.
          + 이는 디지털 밀레니엄 저작권법(DMCA)을 위반할 수 있는 행위로, 이 법은 디지털 작품에서 저작자 이름, 사용 조건, 제목을 제거하는 것을 불법으로 규정함.
     * 법적 전략과 배경
          + The Intercept는 OpenAI에 대한 소송에서 새로운 법적 전략을 개척하고 있음.
          + 대부분의 디지털 뉴스 출판사는 기사 아카이브를 미국 저작권청(USCO)에 등록하지 않음. 이는 비용과 번거로움 때문임.
          + USCO는 최근 뉴스 웹사이트가 기사를 일괄 등록할 수 있도록 규정을 변경했으나, OpenAI에 대한 법적 조치를 원하는 많은 출판사에게는 너무 늦은 조치였음.
     * 다른 소송과의 비교
          + Raw Story와 AlterNet의 DMCA 주장은 다른 뉴욕 연방 판사에 의해 기각됨.
          + 이들은 OpenAI가 저널리즘 작품을 훈련 데이터 세트에 포함시킬 때 DMCA 보호 정보를 제거했다고 주장하며, 각 사례에 대해 $2,500의 손해 배상을 요구함.
     * 향후 전망
          + The Intercept의 소송이 다른 출판사들에게 DMCA 소송을 고려하도록 용기를 줄지는 불확실함.
          + 새로운 소송은 시효 제한에 취약할 수 있으며, 특히 ChatGPT의 훈련 데이터 세트를 인용하려는 경우에 그러함.
          + Loevy & Loevy는 법정에서 실제로 설 수 있는 특정 DMCA 주장을 좁혀가고 있음.

        Hacker News 의견

     * Disney가 많은 IP를 소유하여 LLM을 독점적으로 운영할 수 있는 상황이 발생할 수 있음. 이는 기존의 독점 구조를 강화하는 것임
          + 저작권의 원래 목적은 아니었음. Disney는 공공 도메인 작품을 활용하여 성공했음
          + 저작권은 공공이 인프라를 지원하기 때문에 가능한 것임. 아이디어와 이미지는 무한히 복제 가능함
          + 저작권은 사회에 환원하기 위해 공공 도메인으로 전환되어야 했음. 그러나 현재는 기업의 독점적 권리를 주장하는 상황임
     * 저작권법이 시대에 뒤떨어지고 불필요하게 엄격하다고 느껴짐
          + 대기업이 장기간 저작권을 통해 막대한 수익을 창출하는 것은 과도하고 지속 불가능함
          + 새로운 창작물이 계속 개발되고 있음에도 불구하고 미디어 포화와 마케팅에 의존하여 특정 작품이 더 가치 있다고 인식됨
          + 투자 비용을 회수한 후에는 저작권이 만료되어야 함
          + 저작권을 무기한 보유하는 것은 주로 변호사와 집행 기관에 이익을 주며 사회에 의미 있는 가치를 제공하지 않음
          + 창작자 보호와 혁신 촉진 사이의 균형이 필요함
     * OpenAI가 내 블로그를 사용했는지 확인하는 방법이 있는지 궁금함
          + 각 기사당 $2500의 합의금이 있다면 중고차 가격의 지불을 받을 수 있음
     * 저작권이 있는 작품을 훈련에 사용하는 것이 불법이라면, LLM A가 기사를 요약하고 이를 LLM B 훈련에 사용하는 방법이 가능할지 궁금함
          + LLM A는 공공 도메인 작품으로 훈련될 수 있음
     * Intercept 판결이 다른 출판사들에게 DMCA 소송을 고려하게 할지 불분명함
          + OpenAI에 대한 새로운 소송이 시효 제한에 취약할 수 있음
          + Intercept와 같은 출판사들이 OpenAI에 대해 $2,500의 손해배상을 요구하고 있음
          + 수천 건의 위반이 발생할 경우 수천만 달러의 손해배상이 될 수 있음
     * 규제가 존재하고 저작권 위반이 있을 수 있지만, 다른 정부(주로 중국)가 이를 이용해 앞서 나갈 가능성에 대해 우려해야 함
     * 17 USC 1202에 따라 메타데이터 제거에 대한 주장이 진행 중임
          + 이는 ""핵심 저작권 위반""은 아님
     * ""디지털 자산이 독점적으로 내 것""이라는 개념이 사라져야 함
          + 디지털 인터넷의 이점을 잠금 해제하지 말고 데이터 포화 문제를 방지해야 함
          + 디지털 희소성에 반대해야 함
     * AI 작품에 ""인간 제작""이라는 최종 터치를 추가하는 방식이 등장할 가능성 있음
          + 이는 AI 겨울에 또 다른 재정적 부담을 추가할 수 있음
     * 제안: 저작권 합의금으로 10% 세금을 부과하고, 절반은 과거 창작자에게, 절반은 현재 창작 문화에 지불
"
"https://news.hada.io/topic?id=18063","민감 데이터 정책, Custom Mixin와 Github Actions로 간편하게 자동화하기 (feat. Querypie)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  민감 데이터 정책, Custom Mixin와 Github Actions로 간편하게 자동화하기 (feat. Querypie)

   데이터 접근 제어 및 감사 기능을 제공하는 QueryPie DAC(Database Access Controller)을 활용하면서, 기존의 수작업 정책 설정 방식에서 오는 비효율을 개선하기 위해 Django Model에 Custom Mixin 적용 & Github Actions를 이용해 자동화 방식을 도입한 사례를 공유합니다.

   1. 민감 데이터 정의를 위한 SensitiveFieldMixin
     * Django 모델에서 민감 데이터를 명확히 정의할 수 있도록 SensitiveFieldMixin을 설계 및 구현.
     * 특정 필드를 민감 데이터로 표시하면 QueryPie API를 통해 해당 필드와 연관된 정책을 자동으로 생성.

   2. 정책 동기화를 위한 명령어 개발
     * QueryPie의 API를 활용하여 민감 데이터 정책을 생성 및 동기화하는 커맨드를 개발.
     * 이를 통해 정책 설정의 누락 가능성을 줄이고, 보안 표준을 유지.

   3. GitHub Actions와 CI/CD 파이프라인 통합
     * 정책 동기화 커맨드를 GitHub Actions에 통합하여 배포 프로세스와 연동.
     * 새로운 배포 시점에 정책이 자동으로 동기화되도록 설정하여 효율성을 극대화.

   효과
     * 보안 정책 관리에서 발생할 수 있는 누락 가능성을 최소화.
     * 배포 파이프라인 내 자동화를 통해 개발 효율성과 보안 균형을 동시에 달성.

   창업 초기부터 눈여겨 보던 회사라 그런지 쿼리파이를 여기서 보니 반갑네요
   정책 관리가 상당히 손이 많이가는데 자동화가 가능하다니 흥미롭습니다
"
"https://news.hada.io/topic?id=18090","8년간의 Haskell 사용 후 8개월간의 OCaml 도입 (2023)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                8년간의 Haskell 사용 후 8개월간의 OCaml 도입 (2023)

문법

     * Haskell: 가장 우아한 문법을 가짐. 적은 문자로 아이디어를 표현하는 즐거움이 있음.
     * OCaml: ML 계열의 언어로 훌륭하지만, Haskell보다는 덜 암시적임.

기능

     * Haskell: 많은 기능을 제공하여 문제 해결에 다양한 접근이 가능하지만, 복잡성을 증가시킬 수 있음.
     * OCaml: 간결한 기능으로 생산성을 높일 수 있음.

생태계

     * Haskell: 더 많은 패키지와 솔루션을 제공하지만, 선택의 폭이 넓어 선택이 어려울 수 있음.
     * OCaml: 적은 패키지를 제공하지만, 대부분의 일반적인 작업에 대한 솔루션을 찾을 수 있음.

도구

     * Haskell: 도구 사용이 복잡할 수 있으며, 다양한 감정을 유발함.
     * OCaml: 도구 사용이 간단하고 직관적이며, 대부분의 경우 잘 작동함.

컴파일러 메시지

     * Haskell: 자세한 정보를 제공하지만, 때로는 불필요한 정보가 많음.
     * OCaml: 간결한 메시지를 제공하지만, 때로는 너무 간결할 수 있음.

표준 라이브러리

     * Haskell: 문서화가 잘 되어 있으며, 사용 예제를 통해 API 활용 방법을 쉽게 이해할 수 있음.
     * OCaml: 표준 라이브러리가 기본적인 기능을 제공하지만, Haskell에 비해 문서화가 부족할 수 있음.

결론

     * 두 언어 모두 산업적 요구를 지원하며, 메인스트림 언어에 비해 작음.
     * 특정 SDK에 의존하지 않는다면, 어느 언어를 선택해도 즐거운 코딩 경험을 할 수 있음.
     * 개인적으로는 OCaml이 더 생산적이라고 느낌.

        Hacker News 의견

     * 제목이 오해를 불러일으킬 수 있음. 실제로는 프로덕션 환경에서의 언어 사용에 대한 내용이 아님. 문법 차이에 대한 비교가 주된 내용이며, 팀과 장기 프로젝트에 두 언어가 얼마나 잘 적응하는지 궁금함. Haskell이 OCaml에서 발생한 실질적인 문제를 예방하는지에 대한 정보가 흥미로울 것임.
     * 도구의 복잡성과 유동성이 가장 큰 문제였음. 특정 ghc 버전에서만 컴파일되는 코드가 많았음. Haskell의 문법이 우아하다고 생각하지만, ML 타입의 문법을 선호하지 않음. 최소한의 문자로 아이디어를 표현하는 것에 대한 기쁨을 느끼지 못함.
     * Haskell의 개념 표현 능력에 끌림. Monad는 이해할 수 있지만 Monad Transformers는 복잡함. 기본 데이터 구조를 위해 containers 패키지가 필요하며, Python과 달리 기본 제공되지 않음. Haskell 학습이 다른 언어에서의 사고와 구조화에 긍정적인 영향을 미쳤음.
     * Haskell과 OCaml을 모두 사용한 경험을 공유함. OCaml의 컴파일러 속도가 더 빠르며, 모듈 시스템이 더 명확함. Haskell의 타입 클래스 시스템은 더 편리함. OCaml의 부작용과 순수 코드의 혼합이 라이브러리와 코드베이스에서 사용을 장려함.
     * Haskell의 언어 확장을 보수적으로 사용하는 것이 중요함. TypeFamilies와 DataKinds는 드물게 사용됨. Simple Haskell의 가이드라인을 참고할 수 있음.
     * OCaml을 사용한 경험이 좋았음. 외부 라이브러리의 가용성을 강력한 논거로 사용하지 않음. OCaml의 도구와 헬퍼가 편리했음. 외부 통합이 많은 경우 Go를 사용할 것임.
     * Haskell은 표현하고자 하는 것을 방해하지 않는 특성이 있음. 다른 언어에서는 코드 표현이 어려울 때가 많지만, Haskell은 그런 느낌이 덜함.
     * Haskell과 OCaml의 표준 라이브러리가 기본적임. Haskell의 표준 라이브러리는 작은 부분으로 나뉘어져 있음. Map은 containers 패키지에 포함되어 있으며, GHC 컴파일러와 함께 사전 설치됨.
     * OCaml과 Haskell을 모두 사용한 경험을 바탕으로 Haskell이 멋진 기능을 가지고 있지만 너무 복잡하다고 생각함. OCaml에서 더 빠르게 반복할 수 있으며, 학습 곡선이 덜 가파름. 대규모 프로그래밍에 더 적합함.
     * Haskell의 순수성 보장과 타입 시스템이 프로그래머로서의 삶을 더 좋게 만듦. 상태 공간을 줄이고, 함수 정의에서 모든 컨텍스트를 선언하여 이해하기 쉬움. Haskell이 다른 프로덕션 준비된 프로그래밍 언어보다 더 많은 기쁨을 줌.
"
"https://news.hada.io/topic?id=18116","ChatGPT Pro 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ChatGPT Pro 출시

     * AI 기술이 더욱 발전하면서 더 복잡하고 중요한 문제를 해결할 수 있게 되었고, 이를 가능하게 하는 데 상당한 컴퓨팅 리소스가 필요함
     * ChatGPT Pro는 월 $200 요금제 로 OpenAI의 최신 모델 및 도구를 확장적으로 이용 가능
          + o1: 가장 스마트한 모델
          + o1-mini, GPT-4o, Advanced Voice도 포함
          + o1 pro mode: 더 많은 컴퓨팅 리소스를 활용하여 더 깊이 사고하고 복잡한 문제에 대해 더욱 정교한 답변 제공
          + 향후 더 강력한 생산성 기능 추가 예정
     * 연구자, 엔지니어, 연구 중심의 작업을 하는 개인을 위해 설계되어, 생산성을 높이고 AI 발전의 최전선에 설 수 있도록 도움
     * ChatGPT Pro의 o1 pro mode는 신뢰도 높은 응답을 제공하는 고급 모델
          + 특히 데이터 과학, 프로그래밍, 법률 분석 분야에서 정확하고 포괄적인 응답을 제공
          + o1 및 o1-preview와 비교하여 수학, 과학, 코딩 분야의 어려운 기계 학습 벤치마크에서 더 우수한 성능을 보임

주요 성능 비교 (pass@1 정확도 기준)

     * 수학 경진대회 (AIME 2024)
          + o1-preview: 50
          + o1: 78
          + o1 pro mode: 86
     * 코드 경진대회 (Codeforces)
          + o1-preview: 62
          + o1: 89
          + o1 pro mode: 90
     * 박사 수준 과학 질문 (GPQA Diamond)
          + o1-preview: 74
          + o1: 76
          + o1 pro mode: 79

신뢰도 향상: ""4/4 reliability"" 평가

     * 더 엄격한 평가 기준 도입: 4번의 시도 중 4번 모두 정답을 맞힌 경우만 해결로 간주

주요 성능 비교 (4/4 신뢰도 기준)

     * 수학 경진대회 (AIME 2024)
          + o1-preview: 37
          + o1: 67
          + o1 pro mode: 80
     * 코드 경진대회 (Codeforces)
          + o1-preview: 26
          + o1: 64
          + o1 pro mode: 75
     * 박사 수준 과학 질문 (GPQA Diamond)
          + o1-preview: 58
          + o1: 67
          + o1 pro mode: 74

   프로 사용 해 보았는데 컨텍스트 윈도우가 짧은게 치명적입니다. 긴 내용을 써주긴 하는데 어느정도 지나면 점점 원래 쓰고 있던 내용이나 포맷이 무너지기 시작합니다.

   openai 가 점점 더 open과 멀어지네요.
   이게 현실이겠죠.

   비용 감당이 안되서 Plus 구독료가 인상될 것 같았는데, 그게 아니라 더 고가 라인업을 신설해서 공략하는군요. 평소에 정말 잘 쓰고 있긴 하지만 저는 Pro 버전 까지는 필요 없을 것 같습니다. ㅎㅎ

   전 플러스 사용중인데요. 얼마전부터 같은 종류의 엔진으로 같은 종류의 프롬프트를 수행하는데, 실행이 달라진 것을 느끼는데요. 이전만큼 수행을 못해주는 느낌을 받습니다.

   기존 plus에서 사용가능한 모델들을 너프시키고, 잘라다가 파는게 아닌가 하는 생각이 드네요.

   비용이 비싸질 수록 성능에 대한 신뢰성이 있는데 AI서비스들은 그런게 없네요. 인터넷 회선 갑자기 어느날 몰래 제한 거는 것 처럼 AI도 그렇게 갈 가능성이 많아 보입니다.

   저도 플러스 사용중인데, 답변의 기조라고 해야할까요? 이름은 같은 o1이지만 전체적인 느낌이 preview랑 아예 달라졌습니다. 토큰 출력을 누가 억제하고 있나 싶은 생각까지 드네요.

   동감합니다. 저도 같은 일시 버젼을 사용해도 별도의 언급없이 성능이 왔다갔다하는 걸 느끼고 있습니다. 좀 다른 얘기지만 특정 서비스는 정보를 수집하지 않는다는 부분도 확인 할 방법이 없으니 그저 믿음의 영역이 되지 않나 싶네요.

        Hacker News 의견

     * OpenAI는 오픈소스 대안의 발전 속도와 수익 창출 필요성 사이에서 경쟁 중임. 성공 여부는 대기업들이 OpenAI의 통합적이고 안전한 AI 솔루션을 선택할지에 달려 있음. 이는 IBM의 기업 컴퓨팅 전략과 유사함.
     * Pro 버전의 컨텍스트 윈도우가 짧다는 점이 불만임. Plus 회원으로서 더 긴 컨텍스트 윈도우를 기대했으나, 이에 대한 논의가 전혀 없음. 경쟁사에게 컨텍스트 윈도우를 차별점으로 고려할 것을 강력히 추천함.
     * Pro 구독을 구매한 첫 인상은 새로운 o1-Pro 모델이 매우 뛰어난 작가라는 것임. 긴 프롬프트와 복잡한 데이터 분석을 잘 처리함.
     * 더 많은 컴퓨팅 파워를 위한 계획은 가격 책정 전술인 디코이 효과로 설명될 수 있음. 고가 옵션을 도입하여 다른 플랜이 더 합리적으로 보이게 함.
     * Claude Teams에 매달 166 유로를 지불함. 이는 프로젝트 기능과 결합하여 많은 파일을 업로드하고 특정 컨텍스트에서 질문할 수 있는 기능 때문임. 이 기능은 연구자들을 손끝에 두고 있는 것처럼 강력함.
     * Anthropic에서 훨씬 저렴한 비용으로 더 나은 성능을 얻음. 새로운 GPT가 Claude보다 10배 뛰어나다는 주장에 회의적임.
     * OpenAI가 투자자들이 지치기 전에 ""일반"" AI를 달성할 수 있을지 의문임. ChatGPT의 성공을 통해 그들이 이를 달성할 경로가 있다고 암시했을 가능성이 있음.
     * 제품의 ""무제한"" 사용에 대한 월 구독 가격 책정의 주요 어려움은 극단적인 사용을 하는 1%의 파워 유저임. ChatGPT Pro의 가격은 파워 유저/기업을 대상으로 함.
     * 복잡한 Google Sheets 수식을 작성하는 데 4.5시간을 소비함. 새로운 ChatGPT Pro 모드가 더 빠르다면 시간 절약 측면에서 큰 이점이 있음.
     * 인터뷰 밀에서 o1 모델을 사용하여 인터뷰를 진행하는 사례가 있음. 이러한 유형의 사용 사례는 $200의 월 요금이 저렴하게 느껴질 수 있음.
"
"https://news.hada.io/topic?id=18073","사전 훈련의 절차적 지식이 대형 언어 모델의 추론을 촉진하는 역할","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  사전 훈련의 절차적 지식이 대형 언어 모델의 추론을 촉진하는 역할

     * 절차적 지식이 대형 언어 모델의 추론에 미치는 영향
     * 대형 언어 모델(LLM)의 능력과 한계는 최근 몇 년간 상세히 연구되었음. LLM은 문제 해결 능력을 보이지만, 인간과 비교했을 때 추론의 격차가 있어 일반화 전략의 견고성에 의문을 제기함.
     * LLM 설계에 사용된 데이터의 방대한 양 때문에 전통적인 일반화 측정 방법인 훈련-테스트 세트 분리가 어려움. 이를 극복하기 위해, LLM이 추론 작업을 수행할 때 사용하는 일반화 전략을 사전 훈련 데이터에서 조사함.
     * 두 가지 크기의 모델(7B와 35B)과 2.5B의 사전 훈련 토큰을 사용하여 세 가지 간단한 수학적 추론 작업에 대해 모델 출력에 영향을 미치는 문서를 식별하고, 사실 질문에 답하는 데 영향을 미치는 데이터와 비교함.
     * 모델은 각 사실 질문에 대해 주로 별개의 데이터 세트를 사용하지만, 같은 작업 내의 다른 추론 질문에서도 문서가 유사한 영향을 미치는 경우가 많아 절차적 지식의 존재를 나타냄.
     * 사실 질문의 답변은 가장 영향력 있는 데이터에 자주 나타나지만, 추론 질문의 경우 답변이나 중간 추론 단계의 답변이 높은 영향력을 보이지 않음.
     * 추론 질문에 대한 상위 문서를 질적으로 분석한 결과, 영향력 있는 문서에는 종종 공식이나 코드로 해결 방법을 보여주는 절차적 지식이 포함되어 있음을 확인함.
     * 이러한 발견은 모델이 사용하는 추론 접근 방식이 단순한 검색이 아니라 유사한 형태의 추론을 수행하는 문서에서 절차적 지식을 종합하는 일반화 가능한 전략임을 시사함.

        Hacker News 의견

     * LLM이 모든 문제의 예시를 훈련 데이터에서 찾을 수 없음을 지적하며, 정보 검색 스타일의 탐색에 필요한 사실적 조회 예시가 충분하지 않음을 언급함
          + Apple LLM 논문과 모순되지 않으며, LLM이 기존 예시에서 약간의 변형만 가능하다고 믿음
          + ""추론""이라는 용어 사용에 불만을 표하며, 이는 LLM 회사들이 기술을 감정적으로 표현하기 위해 만든 용어임을 주장함
          + 자연어로 기계를 지시할 수 있는 능력이 큰 발전임을 강조함
     * 인간이 문제를 단계별로 해결해야 신경망이 이를 모방할 수 있다는 점을 지적함
          + 코드 훈련의 예상치 못한 이점을 설명함
     * LLM이 문제 해결 능력을 보여주지만, 인간과 비교했을 때 추론의 격차가 있음을 언급함
          + LLM을 단순히 다음 토큰 예측기로 보는 사용자들이 많음을 지적함
     * 언어 모델이 추론 질문에 답할 때, 제한된 문서 집합에서 정보를 검색하는 경우가 많음을 설명함
          + 반대로, 질문과 추상적으로 관련된 다양한 문서에서 정보를 끌어오는 것이 더 일반화된 추론 전략이어야 한다고 제안함
     * Google의 사전 훈련이 칩 설계에서 중요한 역할을 한다고 주장함
          + 사전 훈련 없이 시도한 결과가 현재 기술 수준에 미치지 못하는 것은 당연하다고 설명함
     * 생성된 이미지가 악몽 같은 이유를 묻고, 더 많은 추론 훈련 데이터가 필요하다고 주장함
          + 수학적 증명이 비합성 데이터의 가장 낮은 열매일 수 있음을 언급함
     * AlphaGo와 AlphaZero의 비교를 통해 인간의 절차적 지식이 ML 훈련에 도움이 되지만, 한계가 있을 수 있음을 설명함
     * 학생 노트, 시험, 책 리뷰 등으로 훈련하면 LLM이 더 나아질 수 있음을 제안하며, 이는 매우 흥미로울 것임을 언급함
"
"https://news.hada.io/topic?id=18048","Go vs Bun, Go 언어는 정말 JS 런타임보다 빠를까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Go vs Bun, Go 언어는 정말 JS 런타임보다 빠를까?

핵심 결론

     * Go 언어는 항상 빠르지 않습니다. 오히려 JS 런타임이 더 빠를 수도 있습니다.
     * Go는 단순성과 효율성을 자랑하지만, 실제 환경에서는 예상보다 성능이 저조할 때가 있습니다.
     * 특히 데이터베이스 I/O가 많은 상황에서 Bun과 같은 JavaScript 런타임에 비해 성능이 떨어질 수 있습니다.

벤치마크 결과

     * Go는 더 높은 요청 처리량과 낮은 메모리 사용량을 보였지만, CPU 사용량은 2~3배 높았습니다.
     * 하지만 DB I/O가 많은 리얼 월드 환경에서는 Bun(Elysia 프레임워크와 MySQL2 라이브러리 조합)이 더 안정적이고 효율적인 성능을 보였습니다.
     * 표준 HTTP 라우터는 성능이 낮아 Fiber 프레임워크로 전환 후, Bun에 비슷한 응답 속도를 얻었습니다. (Go 표준 HTTP Router는 쓰지마세요!)

이 벤치마크를 진행하며 생각해본 Go의 장점

     * 다양한 원시 타입과 타입 안정성을 제공 해주는 것.
     * 단일 바이너리 배포: 간단한 실행 파일로 배포 가능, 런타임 종속성 제거.
     * 고루틴: 병렬 처리를 효율적으로 지원, 적절히 사용하면 하드웨어 성능을 극대화.

이번 벤치마크를 통해 느낀 한계와 개선 여지

     * 의심되는 MySQL 드라이버 성능 문제: Go의 go-mysql-driver는 안정적이지만 느리며, JavaScript의 mysql2보다 성능이 부족해 보입니다. (물론 제가 잘못 생각하는 걸 수도 있지만요)
     * DB 연결이 없는 작업에서는 Go가 더 좋은 성능을 보입니다. 어쩌면 이건 당연할수도 있겠네요.
     * HTTP 라우터의 낮은 성능: 정신 건강을 위해 Fiber나 다른 프레임워크를 사용하세요!

성능 불만족이지만 Go를 계속 사용하려는 이유

     * Go의 타입 안정성, 단일 바이너리 배포, 고루틴의 병렬 처리 성능 등이 개발자로서 매력적입니다. 타입스크립트로는 채울 수 없는 타입들과 npm install 이 필요없는 싱글 바이너리 파일 배포, 이 점이 정말 큰 메리트였습니다.
     * 추가적인 성능 최적화 가능성을 보고 Go를 더 학습하며 사용해보기로 결정하게 되었습니다.

개발자들에게 전하는 말

     * 모든 언어와 기술에는 장단점이 있습니다. Go 언어 역시 마찬가지라 생각합니다.
     * Go의 성능에 실망하기보다는 장점을 잘 활용하고, 성능의 한계를 돌파할 수 있는 수단을 계속 찾아가보면 좋겠습니다.
     * Go를 사용하는 개발자들에게 이런 분석 결과도 있구나 하는 정보를 공유하고자 글을 작성하였습니다.

   완전 딴소리긴 한데, IBM Plex Sans KR 폰트 너무 이쁘네요

   저도 저 폰트가 정말 마음에 들어서 사용했는데, 딱 하나 아쉬운 점이 해상도가 낮은 모니터로 보면 또 유난히 이쁘지 않습니다. ㅎㅎ 5K 모니터로 보면 진짜 이쁘더라구요!

   무언가를 비판하는것은 정말 조심스러워야 한다고 생각합니다.

   언어차원의 이슈인지 특정 라이브러리 이슈인지 코드상의 이슈인지도 모호하고, 다른사람이 재현하기에 충분한 정보도 제공하지 않은 상태에서 무언가가 안좋다 라고 공개적으로 주장하는것은

   그러한 의도가 없으셨다 하더라도 해당 생태계에 살아가는 사람들에게 있어 기분이 좋은 내용은 아닌 것 같습니다.

   원문에는 느린 부분에 대한 필자 나름대로의 분석과 그럼에도 불구하고 고를 사용하겠다는 이유가 적혀있는데 무슨 이유로 이 글을 가치판단으로 받아들이신 건지 잘 이해가 안 됩니다

   TMI 이긴 하지만 Go 의 std 라이브러리는 시간이 지날수록 성능이 떨어지고 있습니다. 주된 이유는 RFC 표준 준수를 위해 다양한 기능들이 추가되면서 보고되는 수많은 보안 취약점에 대한 trade off 입니다.

   최근에는 FIPS 인증을 통과하기 위해서 아마 성능적인 손해는 좀 더 커질것으로 예상되는 상황입니다.

   이러한 배경들을 전부 처내고, 가장 간단한 특정 시나리오에 대해서 성능이 안좋다 한마디만 써두는것은 많은 사람들로 하여금 오해를 불러일으키기에 충분할것으로 생각되네요 ㅠ

   안녕하세요! 먼저 소중한 의견 남겨주셔서 감사합니다. 말씀하신 내용에 대해서 어떤 마음으로 의견을 남겨주신 건지 이해가 되며, 행여 Go 언어의 미래나 사용자 등을 비난한 것처럼 느껴지셨다면 그게 아니었다는 점 다시 한 번 말씀드리면서 사과를 드리겠습니다. 그리고 혹시 괜찮으시다면, 글 제목을 클릭해보시면 여러 데이터와 추가적으로 다른 분의 블로그 글도 있사오니 (조금 길긴 하지만) 읽어주시면 보다 확실히 제 의도를 파악하실 수 있으리라 생각합니다.

   저는 언어가 일종의 자동차 같다는 생각이 듭니다. 차마다 여러 장단점이 있고, 구매하는 데 저마다 다른 비용이 들며, 같은 역할을 하는 거 같지만 서로 다른 가치를 추구하는 점 등이 닮았다고 생각하고 있습니다. 물론 해당 차량을 특별히 아끼고 사랑하는 마음을 가지는 것도 당연하다고 생각합니다. 저도 제 차를 사랑하고 차량 제조사를 신뢰하니까요.

   그럼에도, 저 역시 제 차에 대해 가지는 아쉬운 점이나 불만사항들이 있고, 차량 모델들을 주기적으로 리뷰하는 리뷰어들은 늘 경쟁 모델들과 함께 여러 방면에서 비교하면서 내용들을 공유해주고 있습니다. 누군가가 제 차에 대해 변속기 성능이 별로라고 하거나, 연비가 나쁘다고 말하면 저도 사실 기분은 좋지 않습니다만, 그럼에도 운전자인 저와 차는 분리해서 생각하려고 노력하는 편입니다. 또한 제가 운행하는 차에 대해 장점이든 단점이든 더 많이 알아보려고 노력하는 편입니다. 어쩌면 또 다른 차를 탈 수도 있겠지만, 지금의 운전 경험이 그 때도 여전히 도움이 될테니까요.

   요약 버전에서는 언급을 많이 못했지만, 블로그 본문에서는 Go의 아쉬운 점에도 불구하고 여전히 장점이 더 많기 때문에 계속 사용(=운전)해 보려고 한다는 내용으로 마무리를 하였습니다. 저는 언어마다 추구하는 가치나 장점이 서로 다르기 때문에, 최대한 다양한 언어(=차량)를 사용해 보려고 노력하는 편입니다. 잘 쓰던 JS 런타임을 두고 굳이 Go언어로 넘어가려는 이유도 그렇구요.

   최대한 불필요한 언어 논쟁이 벌어지지 않도록 제 나름대로 세심히 글을 썼다고 생각했습니다만, 그럼에도 이 글을 보시고 기분이 언짢으신 Gopher 분들이 계시다면 다시 한 번 마음을 풀어주시기를 바라며, 저는 그렇게 욕먹었던 PHP 언어도 사랑하는 낭만 코더라는 점을 밝히면서 댓글을 마무리 하겠습니다!

   tsboard님 1.0 버전 기다리고 있습니다 ㅎㅎ

   기다려주셔서 감사드립니다! 즐거운 마음으로 작업해 나가겠습니다 ㅎㅎ

   JS가 JIT을 사용하면서 딱히 느릴 이유는 없다고 생각되네요.
   멀티쓰레드, 안정성등등을 제외하면..

   이번 벤치마크를 통해서 저도 새롭게 발견(?)한 것인데, 안정성도 크게 문제 없는 수준이라 감히 말씀드릴 수 있을 것 같습니다. 멀티스레드는 확실히 오케스트레이션(이렇게 쓰는 게 맞나 모르겠네요)이 필요하니까 조금 번거로운 건 사실입니다.

   사이트 접속이 안 되는데 저만 그런가요?

   안녕하세요! 댓글로 알려주셔서 감사드립니다 ㅎㅎ 아직 호스팅으로 사이트를 옮기질 못해서 간혹 접속에 장애가 있습니다! 가급적 빠른 시일 내로 조치해 놓겠습니다. (지금은 집에서 미니PC가 열일중입니다 😂)

   오 지금은 됩니다. 잘 읽겠습니다!

   사이트를 방구석 미니PC에서 단칸방 크기의 가상서버로 옮겼습니다...! 오늘 하루 예상치 못하게 많은 분들께서 와주셨다가 발길을 돌리셔야만 했는데 이제 문제 없음을 알려드립니다!

   github.com/jackc/pgx/v5 드라이버와 PostgreSQL로 실험해보면 다른 결과가 나올지 궁금하네요.

   저도 궁금합니다 이 결과가 mysql에 국한된 문제인지, 아니면 DB를 사용하는 모든 시나리오에 해당되는지. 언젠가 다른 분들이 결과를 공유해 주실거라 생각합니다 ㅎㅎ
"
"https://news.hada.io/topic?id=18008","일반인을 위한 Janet (2023)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          일반인을 위한 Janet (2023)

     * Janet for Mortals
     * 책 _Janet for Mortals_는 Janet이라는 프로그래밍 언어에 관한 내용이며, 무료로 제공됨. 이 블로그 글은 책을 홍보하기 위한 것이며, 책을 읽지 않은 사람에게는 흥미롭지 않을 수 있음.
     * 책 작성 과정
          + 책 작성에 20주가 소요되었으며, 처음에는 12주로 예상했으나, 책과 관련된 코딩 작업이 추가로 필요했음.
          + 최종 책은 44,000단어로, 코드 스니펫을 제외한 영어 산문으로 구성됨.
          + 책 작성 외에도 웹사이트, jimmy, Toodle.Studio, cmd, judge, to do 등의 프로젝트에 시간을 투자했음.
     * 웹사이트 (2주)
          + Janet for Mortals 웹사이트는 내장된 REPL을 제공하여, 사용자가 언제든지 코드를 실행할 수 있음.
          + CodeMirror를 사용하여 Janet 언어에 대한 기본적인 언어 지원을 구현했으며, 문법 강조 기능을 추가함.
          + Remark를 사용하여 책의 소스를 파싱하고, REPL의 자동 완성 기능을 구현함.
     * jimmy (1주)
          + C++ 라이브러리인 immer와의 상호 운용성을 보여주기 위해 일부 바인딩을 작성했으나, 완성하지는 않았음.
     * https://toodle.studio (2주)
          + Janet을 브라우저에 임베딩하는 방법을 연구하여, Bauble이라는 예술 놀이 공간을 만들었음.
          + Toodle.Studio는 Bauble의 확장판으로, JavaScript와의 상호 운용성이 더 복잡함.
     * cmd (2주)
          + Janet의 명령줄 인수 파싱 라이브러리인 cmd를 개발하여, Janet이 스크립팅 언어로서의 장점을 강조함.
     * judge (1주)
          + judge는 Janet에서 테스트를 작성하기 위한 프레임워크로, API와 구현을 개선하여 사용하기 더 편리하게 만듦.
     * to do (2시간)
          + Bash로 작성했던 할 일 목록 관리 앱을 Janet으로 다시 작성하여, 더 많은 기능을 추가함.
     * 책 홍보
          + Hacker News와 Lobsters에 책을 제출했으며, 많은 방문자를 유치함.
          + 실제로 책을 읽은 사람의 수는 적지만, 387명의 사용자가 5개 이상의 챕터를 읽은 것으로 추정됨.
     * 재미있는 사실
          + Janet 언어는 _The Good Place_의 불멸의 존재인 Janet에서 이름을 따옴.
          + 가장 적은 방문을 기록한 챕터는 ""Testing and Debugging""이며, 이는 저자가 가장 흥미롭다고 생각하는 챕터 중 하나임.
          + REPL 보고 기능을 통해 494개의 보고서를 받았으며, 대부분은 긍정적인 피드백이었음.
     * _Janet for Mortals_는 무료로 제공되며, 많은 사람들이 Janet 언어를 즐길 수 있도록 권장함.

        Hacker News 의견

     * Bauble Studio는 재미있는 그래픽을 만들 수 있는 도구임. 오래된 컴퓨터에서는 작동하지 않지만 도서관 컴퓨터에서 사용해보면 흥미로움
          + Janet 언어는 GNU Guile과 비교할 때 흥미로움. Guile은 C와 쉽게 사용할 수 있도록 설계되었지만, 최신 기능은 부족함
          + Guile의 RNRS 표준과의 호환성 설명에 많은 노력을 기울인 점이 좋음
          + Janet이 얼마나 Scheme에 가까운지는 궁금함
     * ""거북이는 은유""라는 표현에 대해 실제로는 거북이가 실제였다는 의견
          + 과거의 하드웨어가 재미있고 귀여웠다는 느낌을 줌
     * Janet을 배우는 데 실용적인 접근 방식을 제공하는 책이 마음에 듦
          + Everybody Codes에서 Janet을 배우고 있음
     * Janet 언어는 ""The Good Place""의 불멸의 존재에서 이름을 따옴
          + PEG(Parsing Expression Grammar)를 기본 제공하는 점이 놀라움
     * TFA의 블로그 포스트를 통해 분리형 기계식 키보드에 관심을 가지게 됨
          + 어깨와 손목 통증에 도움이 되었음
     * Janet을 배우는 데 도움이 된 책이 있음
          + Lisp 계열 언어를 시작하는 데 어려움을 겪었지만, 이 책이 도움이 됨
          + 책의 매크로 예제가 약간 복잡하지만, 이를 넘어서면 쉽게 이해할 수 있음
     * 글쓰기 스타일이 약간 유머러스하고 Douglas Adams를 연상시킴
          + Janet에 큰 관심은 없지만 글쓰기 스타일이 매력적임
     * 글쓰기 스타일 덕분에 함수형 프로그래밍과 Janet 언어에 더 깊이 빠져들게 됨
"
"https://news.hada.io/topic?id=18096","Egoless 엔지니어링","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Egoless 엔지니어링

이고를 배제한 엔지니어링: 교훈과 통찰

  서론

     * 기술 업계에서 이고와 지역주의(파벌주의)는 팀워크를 방해하는 주된 요소로 작용함
     * 엔지니어링 팀을 더 효율적이고 협력적으로 만드는 방법을 고민하며 얻은 통찰을 공유

  책임 분배의 딜레마

     * 직원이 두 명만 있어도 업무 분배는 필수적임
          + 그러나 분배 방식은 즉각적이며 장기적인 영향을 미칠 수 있음
          + 많은 기업이 이러한 문제를 깊이 고민하지 않음

  컴퓨터 과학의 현실

     * 많은 컴퓨터 과학자는 자신이 수학적 추상 작업과 관련된 학문에 발을 들였다는 사실을 나중에 깨달음
          + 이 초기 충격으로 인해 대부분의 경력을 컴퓨터 외의 분야에는 배운 내용을 적용하지 않으려는 태도를 보임
     * 업무 환경을 기술적 접근만큼 깊이 고민한다면 개선될 가능성이 있음

  조직에서의 병폐와 경험

     * 성공적인 회사도 조직 병폐를 피하기 어렵고, 이를 통해 배울 수 있음
     * 초기 경력을 보낸 한 스타트업 사례:
          + 회사가 작은 초기 단계임에도 불구하고 이미 지나치게 관료화된 구조를 채택
          + 웹 요청 속도를 높이겠다는 잘못된 이론으로 ""파이썬 미들레이어""를 추가
               o 결과적으로 더 많은 네트워크 홉이 발생해 성능이 저하됨
          + 하나의 기능을 출시하려면 여러 역할 간의 복잡한 협력이 필요
               o 데이터베이스 작업자는 DDL 작성 및 저장 프로시저 개발
               o 파이썬 개발자는 비효율적인 미들레이어 작업
               o PHP 개발자는 프론트엔드 코드 작성
          + 이러한 분업 구조로 인해 두 해 동안 신규 기능을 전혀 출시하지 못함
          + 결과
               o 비효율적 구조와 워크플로우의 결과로 전 직원이 해고됨
               o 난 아님. 불만 제기로 살아남음

  대규모 회사에서의 역할 분화 문제

     * 배경: 1,000명 이상의 직원을 보유한 B2B 제품 회사에서 근무
          + 초기에 역할이 명확히 나뉜 기능별 팀(Feature Teams)과 공용 서비스 팀(운영, DBA 등) 구조를 운영
          + 초기에는 일반적인 구조처럼 보였음
     * 시간이 지나면서 역할이 과도하게 분화되며 비효율성이 증가
          + ""Release Manager""라는 새로운 역할을 추가해 릴리스를 관리
          + 역할 추가의 이유가 명확하지 않고, 점점 복잡해지는 조직 구조
     * 문제 사례:
          + 프론트엔드 엔지니어는 프론트엔드 작업만, 백엔드 엔지니어는 백엔드 작업만 수행하도록 제한
          + 이러한 분리는 생존 가능했지만, 보안 팀이 모든 보안 작업을 전담하도록 한 정책은 심각한 문제를 초래
     * 결과: 역할을 작업과 동일시하면서 조직 효율성을 저해하게 됨
          + 팀 간 협력 부족과 업무 중복이 발생

분산된 제품 포트폴리오와 감독 구조의 부재

     * 주로 네이티브 클라이언트 애플리케이션을 개발하는 회사에서 근무
          + 초기에는 성공적인 주력 클라이언트 애플리케이션이 있었지만, 2020년대에는 분산되고 일관성 없는 프로젝트들이 병렬적으로 진행됨
     * 제품 포트폴리오 관리의 문제점
          + 전체 제품에 대한 감독 구조가 약함
          + 기술 스택이나 의사결정에서 제품 간 조율이 전혀 이루어지지 않음
          + 각 제품 팀은 독립적으로 CEO에게 보고하며, CEO는 조정 노력을 기울이지 않음
     * 공용 운영 기능 구축 시도
          + 운영 그룹이 아키텍처 결정 과정에 관여하지 않아 어려움이 발생
          + 운영 팀은 과거에 개발 팀이 사용했던 수백 개의 서비스 관리에 바빠 중요한 의사결정에 참여할 시간이 부족
          + 이는 조직적 비효율성의 전형적인 사례로 볼 수 있음

[조직 문제 패턴 일반화 하기]

  패턴 1: 역할과 작업의 혼동

     * 새로운 업무를 위해 새로운 직무 설명을 만드는 경향이 있음
          + 예: AI 관련 업무를 기존 엔지니어가 처리할 수 있음에도 불구하고, AI 엔지니어라는 새로운 역할을 신설
          + 이는 조직 내 갈등을 유발하며, 기존 팀원의 동기를 약화시킬 수 있음
     * 이러한 과도한 역할 분리는 불필요한 관료주의를 초래

  패턴 2: DevOps 혁명의 불완전한 분포

     * 많은 회사가 ""DevOps를 구현했다""고 주장하지만, 실제로는 분업과 갈등이 여전히 존재
          + 운영팀과 개발팀, 혹은 SRE와 개발팀 간의 명확한 경계는 협력을 저해
          + DevOps의 본래 목적은 협력과 공감을 통한 경계 허물기지만, 현실에서는 드물게 실현됨

  패턴 3: 엄격한 업무 분업의 한계

     * 업무를 세분화하고 전문화하는 것이 리더에게는 당연해 보일 수 있음
          + 예: AI 업무는 AI 전문가, 운영 업무는 운영 담당자에게 전담
     * 하지만 이러한 구조는 병목 현상을 야기
          + 추가된 엔지니어가 새로운 작업을 생성해 속도를 높이려 하지만, 결과적으로 분석 대기 시간이 비선형적으로 증가
          + 데이터 과학자나 분석 리소스가 한계에 도달하면 전체 프로세스가 느려짐

  패턴 4: 잘못된 조직 구조는 추가 작업을 초래

     * 조직 경계가 명확하지 않거나 잘못 설정되면 불필요한 작업량이 증가
          + 예: 보안 팀이 모든 보안 문제를 담당하며, 보안 티켓 큐가 생김
          + 개발 팀은 보안을 고려하지 않으면서 작업을 진행, 결과적으로 보안 작업이 늘어남
     * 이는 단기적으로는 무시될 수 있지만, 장기적으로 심각한 문제로 발전

  패턴 5: 인간의 고질적인 편견

     * 자신의 역할을 과대평가하고 타인의 역할을 과소평가하는 경향
          + 일부는 서버 작업이 ""기술적이지 않다""고 잘못 판단
          + 반대로, 제품 작업이 덜 기술적이라고 여기는 경우도 흔함
     * 이러한 태도는 팀 간 신뢰를 약화시키고 협력을 저해
          + ""뛰어난 독단적 인물""은 시스템적 관점에서 실질적인 가치를 제공하지 못함
          + 리더와 조직은 이러한 태도를 ""똑똑하다""거나 ""가치 있다""고 잘못 평가하는 경우가 많음

[파벌주의와 이고]

     * 파벌주의(Parochialism)와 이고(Ego)는 조직 내 주요 비효율성의 원인
          + 파벌주의: 타인의 영역을 침범하지 않으려는 태도나 호기심 부족
          + 이고: 업무에 대한 자부심으로 긍정적 영향을 줄 수도 있지만, 영역 지키기나 타인의 능력을 과소평가하는 부정적 영향으로 나타날 수 있음
     * 이러한 본능적인 행동들은 공감 부족을 야기하고 협력을 저해

더 나은 사례: 성공적인 엔지니어링 팀의 경험

     * 과거 한 스타트업에서 수평적으로 분리된 ""영지(fiefdom)"" 구조를 단순화하고 더 작은 팀으로 재편
     * DevOps를 진지하게 도입한 리더들이 장벽을 허물고 협력을 촉진
          + 약 2년간의 ""창의적 파괴""를 통해 모든 팀원이 다양한 업무에 참여
          + 결과적으로 인프라 안정성과 소프트웨어 출시 역량 회복
     * 조직 재편 후 엔지니어링 팀이 시간과 자율성을 확보
          + 이를 바탕으로 팀의 추가 역량을 어떻게 활용할지 논의

  제안 1: 대규모 리팩터링 (Proposition 1: Boil the Ocean)

     * 종종 팀들은 여유 자원을 사용해 싫어하는 부분을 전면적으로 리팩터링
     * 하지만 이는 이미 시도된 방법으로 인기가 없었음

  제안 2: ""자기 과시"" 활동 (Proposition 2: Dress Like Big Dorks)

     * 팀의 유휴 시간을 사용해 팀 문화를 강조하는 상품 제작 등 시도
          + 그러나 이것은 주요 전략으로는 적합하지 않았음
     * 결정적 사건: 디자이너의 빌드 오류
          + 한밤중 디자이너가 빌드를 깨뜨렸고, 팀은 이를 복구해야 했음
          + 처음에는 디자이너와 코더 간의 역할을 더 명확히 나누자는 의견이 제기
               o 그러나 팀의 한 사람이 디자이너에게 배포 키를 직접 제공하는 과감한 결정을 내림
          + 결과:
               o 디자이너가 코드 작업에 참여하며 협업 수준이 향상
               o 팀은 모니터링, 테스트 스위트 등을 구축해 안전한 작업 환경 조성
               o 작업 효율성과 생산성이 크게 개선

  제안 3: 다른 팀의 역량 강화 (Proposition 3: Empower Everybody Else)

     * 팀의 여유 자원을 활용해 다른 팀을 지원하고 역량을 강화하는 전략 채택
          + 기술적, 비기술적 팀 모두에 적용
          + 조직 전반의 협력을 촉진하고 효과적인 실행으로 연결

  실천 의지

     * 디자이너 사례 이후 다양한 그룹과 협력하며 비슷한 성공을 경험
     * 팀의 자유 시간과 조직적 권한을 활용해 각 팀이 효과적으로 협력할 수 있도록 지원
     * 성공적인 실행은 전사적 협력과 공감이 기반이었음

[성공적인 실행의 느낌]

     * 전문가 vs. 소유자
          + 팀은 도메인 전문가를 두되, 특정 작업이나 도메인의 ""소유자""를 두지 않음
          + 보안 사례: 보안팀이 모든 문제를 처리하는 대신, 팀 전체가 보안을 책임지고 보안팀은 팀원들의 역량을 향상시키는 역할
          + 다른 분야에서도 이 모델이 적용되었어야 했지만, 대부분의 팀은 실현하지 못함
     * 실패 사례
          + 프론트엔드와 백엔드 엔지니어를 철저히 분리
          + 협력 부족으로 인해 GraphQL 같은 불필요한 복잡성을 초래
          + 특정 역할의 전문가는 필요하지만, ""프론트엔드""와 ""백엔드""로 직함을 나누는 것은 비효율적
     * 핵심 원칙:
          + ""도메인 전문가, 소유자는 아님""
          + 전문가가 자신의 업무 외에도 다른 팀원을 도울 시간을 확보하도록 유도

  프로액티브한 협업 촉진

     * 여유 시간 제공
          + 전체적인 팀워크를 유지하기 위해 팀원들에게 여유 시간을 부여
          + 단순히 자연스러운 협력을 기다리지 않고, 의도적으로 시스템에 활력을 불어넣음
     * 심리적 안전과 인그룹 확장
          + 사람들은 자신이 속한 그룹에서 심리적 안전감을 느끼며 실험하거나 새로운 것을 배움
          + 팀원들의 ""인그룹""을 확장하기 위해 시간과 자원을 투자
          + 부트캠프: 다른 팀에서 강제로 근무하게 하여 협업 기회 제공
          + 해커톤: 비슷한 효과를 내는 이벤트로 활용

  의도적인 팀 가치

     * 팀의 철학과 원칙 정립
          + 코드 리뷰, 부트캠프, 해커톤 등 다양한 활동의 높은 목표를 명확히 정의
          + 엘리트주의는 독이라고 선언
          + 모든 구성원이 ""필요한 일을 직접 처리""하는 문화를 조성
     * 상호 신뢰와 개선 기대
          + 다른 사람의 작업물을 다룰 때 항상 더 나은 상태로 남기겠다는 강한 기대 설정
          + 이러한 문화는 팀원들이 기꺼이 협력하도록 유도

마무리 생각

     * 기술 업계의 문제: 엘리트주의와 독단적 리더십
          + 겸손이 결여된 독단적 리더는 팀의 협력을 저해하고 불필요한 잔혹함을 조장
          + 기술 업계는 종종 이러한 독단적 리더를 유용한 존재로 착각하지만, 이는 기생적이고 해로운 현상
          + 타인을 존중하는 행동이 급진적이어야 할 이유가 없지만, 현실적으로 그렇지 않음
     * 협력이 더 나은 결과를 가져옴
          + 협력은 결과를 개선하고, 독단적 리더가 없는 삶은 더 나아짐
          + 파벌주의와 이고를 없애기 위한 노력이 필요
     * 권한 부여의 중요성
          + 팀원들이 호기심을 가지고 협력하도록 격려하려면 리더의 허가와 지지가 필요
          + 예: 배포 작업을 SRE가 아닌 개발자가 직접 처리하도록 변경
               o 초기에는 개발자의 실수에 대한 우려가 있었지만, 대부분의 개발자가 문제를 스스로 해결하며 성공적이었음
               o 제품 엔지니어들이 스스로 문제를 처리하고자 하는 태도를 보여줌
     * 시스템에 여유(slack) 제공
          + 부트캠프나 해커톤 같은 프로그램은 지속적인 헌신이 필요
          + 이러한 프로그램은 시스템의 여유가 없으면 사라지기 쉬움
          + 우리는 컴퓨터를 100%로 가동하지 않지만, 스스로에게는 그렇게 하려는 경향이 있음
     * 가치와 보상의 중요성
          + 리더는 협력과 호기심을 보상하고 이를 팀 문화로 정착시켜야 함
          + CEO들은 종종 긍정적인 프로그램(부트캠프, 해커톤)을 없애려 하지만, 부정적인 프로그램(의무적 코드 리뷰)을 없애려는 노력은 부족함
          + ""고통""이 결과를 가져온다는 잘못된 믿음은 버려야 함
          + 고통은 결과의 대리 지표로 적합하지 않으며, 협력과 신뢰가 더 나은 성과를 가져옴

     팀원들이 호기심을 가지고 협력하도록 격려하려면 리더의 허가와 지지가 필요

   꼭 본인의 영역이 아닌 팀원의 영역에 호기심을 갖도록 격려하는 것이 중요한 것 같습니다!

   현실은...!

   매일같이 진척 쪼아대는 웨자일 스타트업에서는 불가능한 구조군요..
   모든 실무진이 입사 초기의 흥미를 계속 유지할 수 있어야 하는데, 그런 측면에 대한 지원이 보통은 없거나 부족하더라고요.

   구구절절 맞는말이네요..
   하지만 현실은..................ㅠㅠ

   진짜 좋은글 같네요!

   좋은글입니다.

        Hacker News 의견

     * 소프트웨어 개발에서 프로그래머의 자아를 배제하는 것이 중요하다는 의견이 있음. 팀워크를 통해 소프트웨어 제품을 팀의 성과로 보는 것이 바람직함.
          + 그러나 인간의 자아는 자연스러운 것이며, 이를 완전히 배제하기 어려움.
          + 효과적인 시스템은 인간의 기본적인 특성을 인정하고 그 안에서 작동해야 함.
     * 개발 경력에서 얻은 교훈으로, 불필요한 프로세스를 추가하지 말고, 모든 역할에서 제품의 소유권을 요구하며, 반응적인 결정을 피하고, 팀 간의 협력을 장려해야 한다고 조언함.
     * 최고의 팀은 전체 스택을 소유하는 피자 팀과 필요할 때 조언을 제공하는 전문가들로 구성됨.
          + 모든 사람이 온콜 상태일 때 문제를 신속하게 해결할 수 있음.
          + 과거에는 작업이 너무 복잡하고 전문적이어서 이러한 접근이 흔하지 않았음.
     * 스포츠 메타포는 기술 분야에서 인기가 없지만, 스포츠 팀의 역학은 좋은 비즈니스 팀과 유사하다는 의견이 있음.
     * 조직의 성공은 각 구성원이 그룹의 필요를 충족시키기 위해 이타적으로 행동하는 데 달려 있음.
          + 이타심은 에너지와 생산성을 소모하는 기생적 요소임.
          + 연민은 이타심의 치료제이며, 도덕적 나침반의 방향을 맞추는 데 도움을 줌.
     * 의도적인 팀 가치 설정의 중요성을 강조함.
          + 모든 사람이 어떤 작업도 수행할 수 있어야 하며, 환경을 개선하는 것이 중요함.
     * 성장 부서에서 일하면서, 처음에는 매니저가 모든 커밋을 검토하고 병합했지만, 나중에 자신이 직접 프로덕션에 배포할 수 있는 권한이 있었음을 깨달음.
     * 도메인 전문가가 도메인 소유자보다 선호되며, 지나치게 명시적인 전문화는 문제를 일으킬 수 있음.
          + 그러나 모든 사람이 자율성을 가질 수 있는 것은 아니며, 이는 팀의 기술 수준과 동기 부여에 따라 달라짐.
          + 대규모 프로젝트에서는 더 많은 프로세스와 가드레일이 필요할 수 있음.
"
"https://news.hada.io/topic?id=18054","OpenWRT One 출시: OpenWrt 전용으로 설계된 최초의 라우터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                OpenWRT One 출시: OpenWrt 전용으로 설계된 최초의 라우터

     * SFC와 OpenWrt 프로젝트는 OpenWrt One의 출시를 발표
     * 이 라우터는 소프트웨어 자유와 수리 권리를 염두에 두고 설계 및 제작되어 영구적으로 Lock/Brick 되지 않으며, 사용자는 네트워크를 제어하고 소프트웨어를 변경, 수정, 수리할 수 있는 권리를 가짐
     * OpenWrt One의 특징
          + 가격은 케이스 포함 US$89, 케이스 없는 보드 US$68.42로 다양한 용도에 적합함
          + Banana Pi와 협력하여 제조되며, MediaTek MT7981B SoC, MT7976C wifi, 1 GiB DDR4 RAM, 128 MiB SPI NAND + 4 MiB SPI NOR 플래시, 두 개의 이더넷 포트, USB 호스트 포트, M.2 2042, mikroBUS 확장 헤더를 사용
          + PoE 또는 USB-C 전원 포트를 통해 전원 공급 가능하며, USB-C 포트에 USB 시리얼 인터페이스가 내장되어 있음
          + OpenWrt One은 copyleft 라이선스를 준수하며, 소유자는 소프트웨어를 개선하고 수리할 수 있는 권리를 가짐. 이 장치는 완전한 copyleft 준수 소스 코드 릴리스를 제공함.
     * FCC 규정 준수
          + OpenWrt One은 FCC 규정 준수 테스트를 완료함. SFC는 FCC 요구 사항과 소프트웨어 수리 권리가 충돌하지 않는다는 것을 증명함.
     * 구매 및 기부
          + OpenWrt One은 현재 구매 가능하며, 구매 시 US$10가 OpenWrt 기금에 기부됨. 이는 소프트웨어 수리 권리를 개선하고 OpenWrt와 SFC의 발전을 지원함.

        Hacker News 의견

     * GL.iNet의 Flint 2는 더 많은 포트를 가지고 있으며, OpenWrt를 잘 실행할 수 있는 제품임
          + 링크: GL.iNet Flint 2
     * 새로운 라우터보다는 OpenWRT와 잘 작동하는 24/48 포트의 ""레벨3"" 스위치가 더 필요함
          + 가격이 유일하게 좋은 점임
     * 기가비트 이더넷과 2.5GbE 포트가 혼합된 것이 이상함
          + 더 많은 램과 2x2.5Gbe를 가진 제품이 나올 가능성이 있음
     * 라우터에 항상 WiFi가 포함되는 이유가 궁금함
          + 많은 사람들이 별도의 (메시) 네트워크 AP를 운영하고 싶어함
          + WiFi를 끄기 위해 라우터에 포함시키는 것은 낭비임
     * DSL 모뎀이 왜 USB 동글로 제공되지 않는지 의문임
          + DSL 연결을 사용하는 사람들은 제한된 DSL 모뎀/라우터 선택지로 고통받거나, 오래된 펌웨어를 가진 DSL 모뎀 뒤에 Linux/OpenWRT 라우터를 사용해야 함
     * Gl.inet은 OpenWRT에 최적화되어 있으며, 저렴하고 잘 테스트된 제품임
     * Wi-Fi 칩을 부팅하거나 사용하는 데 필요한 바이너리 블롭이 있는지 알고 싶음
     * 배터리로 구동되는 RTC가 있는 점이 마음에 들어 사용을 고려할 것임
     * N100 미니 컴퓨터를 OPNsense로 설정했으며, 라우터로 매우 만족함
     * 100% OSS 스위치와 완전히 OSS 펌웨어를 가진 더 강력한 하드웨어가 필요함
          + 오픈 소스를 하려면 완전히 해야 의미가 있음
          + 1x1Gbps와 1x2.5Gbps 포트 구성은 이해가 안 됨
          + SoC 때문이지만, 조금 더 강력한 것을 사용할 수 없었는지 의문임
"
"https://news.hada.io/topic?id=18055","제프 딘, EDA 업계에 AlphaChip 관련 답변","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     제프 딘, EDA 업계에 AlphaChip 관련 답변

        Hacker News 의견

     * Jeff Dean의 경력은 매우 뛰어나며, 그에 대한 의심보다는 신뢰를 주어야 한다는 의견이 있음
     * AI가 칩 설계에 완전히 준비되지 않았다는 주장이 있으며, 관련 기사들이 있음
          + ""AI Alone Isn’t Ready for Chip Design""라는 기사에서 AI의 한계를 지적함
          + ""That Chip Has Sailed""라는 기사에서는 AI에 대한 근거 없는 회의론을 비판함
     * Google의 AlphaChip이 칩 설계에 미친 영향을 재평가하는 논의가 있음
          + AlphaChip의 훈련 방법론에 대한 비판이 있으며, 높은 계산 비용과 실행 시간이 상업적 솔루션과 비교해 경쟁력이 없다는 의견이 있음
          + Google의 AlphaChip 알고리즘에 대한 반박을 다루는 추가 글이 있음
     * 잘못된 인재 채용이 얼마나 큰 비용을 초래할 수 있는지에 대한 논의가 있음
     * Jeff Dean의 트윗에서 Cheng 등이 Google 연구자들의 작업을 재현하는 데 필요한 단계를 따르지 않았다는 주장이 있음
          + Google의 Circuit Training 저장소에서는 처음부터 훈련한 결과가 논문에 보고된 결과와 비슷하거나 더 낫다고 명시되어 있음
          + UCSD 그룹이 결과를 재현하기 위해 여러 단계를 역설계해야 했다는 점에서 논문의 결과가 자체적으로 재현 가능하지 않았다는 의견이 있음
     * 이 논쟁이 왜 이렇게 감정적이고 불쾌한 방향으로 발전했는지에 대한 궁금증이 있음
     * Google의 궁극적인 증거는 경쟁사보다 더 나은 칩을 만드는 것이지만, 현재로서는 불가능하다는 의견이 있음
     * Jeff Dean이 AlphaChip 관련 사기 및 부정행위로 비난받고 있다는 추가적인 맥락이 있음
"
"https://news.hada.io/topic?id=18085","한국 대통령 계엄령 선포, 국회 해제 표결","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        한국 대통령 계엄령 선포, 국회 해제 표결

     * 한국 대통령의 계엄령 해제
          + 한국의 윤석열 대통령은 화요일 늦게 계엄령을 선포했으나, 수요일 아침 정치적 압력에 굴복하여 이를 해제함.
          + 계엄령은 국회가 군사 통치를 거부하는 투표를 한 후 해제되었으며, 경찰과 군인들이 국회 주변에서 철수함.
          + 계엄령은 약 6시간 동안 유지되었으며, 이는 1980년대 이후 처음 있는 일임.
     * 정치적 배경
          + 윤 대통령은 반대파가 국회를 장악하고 있으며, 이들이 북한과 동조한다고 비난함.
          + 국회 의장 우원식은 계엄령을 무효화하고 민주주의를 지키겠다고 선언함.
          + 계엄령 선포 후, 국회 주변에 군인들이 배치되었고, 시위대가 모여 대통령의 탄핵을 요구함.
     * 국제 반응 및 추가 상황
          + 미국 백악관은 서울에서의 사건에 대해 심각한 우려를 표명함.
          + 한국 군은 의사 파업을 중단하고 복귀할 것을 요구함.
          + 윤 대통령은 계엄령이 국가를 보호하고 헌법적 질서를 지키기 위한 것이라고 주장함.
     * 정치적 결과 및 전망
          + 윤 대통령은 탄핵 가능성에 직면해 있으며, 이는 계엄령 선포 전에도 가능성이 있었음.
          + 전문가들은 윤 대통령의 계엄령 선포가 민주주의의 후퇴라고 평가함.
          + 한국은 정치적 다원주의의 역사를 가지고 있으며, 대규모 시위와 신속한 탄핵에 익숙함.

        Hacker News 의견

     * 한국 국회가 윤석열 대통령에게 계엄령 해제를 요구하는 결의안을 통과시켰음
          + 헌법에 따라 국회의 과반수가 요구하면 계엄령은 해제되어야 함
          + 300명의 국회의원 중 190명이 참석하여 전원 찬성표를 던짐
          + 결의안 통과로 계엄령 선언이 무효화됨
     * 한국 헌법 제77조에 따르면, 전쟁이나 유사한 국가 비상사태 시 대통령이 계엄령을 선포할 수 있음
          + 계엄령은 비상계엄과 경계계엄 두 가지로 나뉨
          + 비상계엄 하에서는 영장, 언론, 집회 및 결사의 자유 등에 특별 조치를 취할 수 있음
          + 대통령이 계엄령을 선포하면 국회에 즉시 통보해야 함
          + 국회가 과반수로 계엄령 해제를 요구하면 대통령은 이를 따라야 함
     * 계엄령 선언이 서구에서의 계엄령 선언처럼 큰 문제인지, 미국의 정부 셧다운과 같은 것인지 궁금해하는 의견이 있음
     * 대통령의 계엄령 선언이 헌법과 법률을 위반한 불법 행위로, 사실상 쿠데타라는 의견이 있음
          + 현재 상황이 헌법 제77조에 명시된 조건에 부합하지 않음
          + 계엄령은 내각 회의가 없었기 때문에 절차상 무효임
          + 계엄군이 국회에 진입하는 것은 불법이며, 즉각적인 해제를 요구함
     * 몇 달 전 미국 국무부 차관이 윤 대통령이 노벨 평화상을 받을 자격이 있다고 언급했으나, 현재 미국 국무부의 입장이 궁금하다는 의견이 있음
     * 자유가 전 세계적으로 감소하고 있다는 의견이 있음
"
"https://news.hada.io/topic?id=18040","GIMP 3.0 출시 예정 소식","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           GIMP 3.0 출시 예정 소식

GIMP 3.0 — 오픈 소스 이미지 편집의 이정표

     * GIMP 3.0 출시 예정
          + GIMP 3.0은 2018년 4월 이후 처음으로 주요 업데이트를 예고함.
          + GTK 3 사용자 인터페이스를 도입하며, 핵심 플랫폼과 플러그인에 큰 변화를 가져옴.
          + 성능과 사용성 개선, Wayland 및 복잡한 입력 소스와의 호환성 증가.
     * 현대화된 인터페이스
          + GTK 3 사용으로 Wayland 호환성과 HiDPI 스케일링 지원.
          + 멀티터치 입력 지원으로 핀치 줌 제스처 가능.
          + CSS 테마 지원으로 UI 새로 고침, 기본적으로 4가지 테마 제공.
          + 전통적인 메뉴 인터페이스도 지원하여 사용자 친숙성 유지.
     * 향상된 워크플로우, 성능 및 색상 관리
          + GEGL 통합으로 비파괴 편집 가능.
          + 필터와 효과를 원본 이미지에 영향을 주지 않고 적용 가능.
          + 색상 관리 개선으로 다양한 장치와 워크플로우 간의 색상 일관성 향상.
     * 레이어 및 파일 형식 개선
          + 레이어 작업을 대량으로 적용 가능하며, 여러 레이어를 선택하고 그룹화 가능.
          + 새로운 확장 시스템과 파일 형식 GEX 도입으로 플러그인, 테마, 브러시 등의 배포 용이.
     * 미래 개발
          + 비파괴 레이어 타입, 애니메이션, 다중 페이지 파일 등 향후 릴리스에서 추가될 예정.
          + 기존 플러그인과의 호환성을 위해 API 변경 필요.
     * 출시 일정
          + GIMP 3.0의 정확한 출시일은 미정이나, 개발 빌드를 통해 새로운 기능을 미리 체험 가능.
          + 첫 번째 릴리스 후보는 이미 출시되었으며, 추가 후보가 필요할 수 있음.
     * 사용자 반응
          + GIMP 3.0의 새로운 기능에 대한 기대감과 긍정적인 반응.
          + GNOME UI에 대한 다양한 의견 존재.

        Hacker News 의견

     * GIMP 3.0은 sRGB 외에도 CMYK 및 CIELAB 색상 팔레트를 지원하게 되어 인쇄 및 출판 작업에 필수적임
          + 그러나 내부적으로는 여전히 sRGB, 그레이스케일, 인덱스 색상을 사용하여 색상 정보를 저장하고 있음
          + 다른 색상 공간으로의 변환은 필요할 때 출력 시에만 수행됨
     * GIMP의 색상 변환 방식에 대한 설명이 혼란스러움
          + 변환이 이미지 변환 파이프라인의 끝에서만 이루어지는 것처럼 들림
          + 이는 RGB가 아닌 다른 색상 공간에서 조작하는 것이 주된 목적이기 때문에 제한적일 수 있음
     * GIMP.org의 블로그 게시물에서는 색상 변환이 필요할 때만 수행되어 정보 손실을 방지한다고 설명함
          + 원래 색상 공간의 정보가 유지되며, 필요할 때만 변환이 적용됨
     * GIMP의 UI가 업데이트되어 더 많은 사람들이 사용할 수 있기를 기대함
          + Blender가 UX를 개편한 후 인기가 급상승한 것처럼 GIMP도 그러기를 바람
     * 비파괴 편집 기능이 더 많이 추가되기를 기대함
          + GEGL의 통합은 GIMP에 큰 이정표임
     * GIMP에서 원을 그리기 위해 세 가지 도구를 조합해야 하는지 궁금함
     * CMYK 지원이 드디어 추가되어 전문 분야에서 더 널리 사용되기를 바람
     * GIMP의 독특한 UI에 불만을 가진 사용자에게는 Photopea 웹사이트를 추천함
          + Photoshop과 유사한 UI로 웹에서 잘 작동함
     * GIMP 3.0과 비파괴 편집을 오랫동안 기다려왔음
          + GIMP 팀에게 축하를 전하며, 3.0이 공식 출시될 때의 감격을 상상할 수 없음
     * GIMP 3.0이 GIF 애니메이션에 대해 동일하게 작동하는지 궁금함
          + 이전 버전과의 차이가 워크플로우에 큰 영향을 미칠 수 있음
     * GIMP를 빠른 편집을 위해 계속 사용하고 있음
     * GIMP가 최신 GTK를 사용하지 않는 것이 이상하다고 생각함
          + GTK는 GIMP 프로젝트에서 시작되었음에도 불구하고 GTK4가 아닌 GTK3을 사용함
"
"https://news.hada.io/topic?id=18006","HN 공개: 종이 같은 느낌의 기술 Feels Like Paper","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  HN 공개: 종이 같은 느낌의 기술 Feels Like Paper

     * 개념
          + ""Feels Like Paper!""는 AI를 통해 물리적 종이를 증강하는 프로토타입 시리즈임.
          + 물리적 종이와 잉크에 디지털 세계의 특성을 주입하면서도 물리적 특성을 유지하는 것을 목표로 함.
          + 세 가지 프로토타입은 종이에 컴퓨팅의 역동성, 에이전시, 보존성을 부여하면서도 종이가 제공하는 유연성, 지속성, 촉감을 유지하려고 함.
     * 영감
          + Keichii Matsuda의 ""GODS""라는 선언문에서 영감을 받음.
          + 증강 현실을 통해 다양한 에이전트나 ""신""을 세계에 배치하여 인간적인 AI 인터페이스를 제공하는 것을 제안함.
          + 일본의 신토주의에서 영감을 받은 다신교적 접근 방식으로, 단일한 진리의 원천이 아닌 여러 작은 도우미를 통해 AI와 상호작용할 수 있는 가능성을 제시함.
     * 디자인
          + 프로젝트는 Apple's ""Math Notes"", Bret Victor의 ""Dynamicland"", Ink & Switch의 ""Inkbase: Programmable Ink""와 유사함.
          + 물리적 종이의 정적 특성을 유지하면서 증강하는 것이 AI의 보호자 역할을 더 강조함.
          + 암시적 상호작용을 우선시하여 경험을 단순하고 직접적으로 유지함.
     * ""Maths & Questions"" 프로토타입
          + 종이를 통한 맥락적 상호작용을 탐구하며 AI의 출력을 사용자 인식에 의미 있고 차분하게 삽입함.
          + 사용자가 물음표나 등호를 쓰면, 위치를 감지하고 LLM에 이미지를 보내 답변을 받음.
          + 사용자의 필체로 종이에 답변이 증강됨.
     * ""Mark & Comment"" 프로토타입
          + ML과 종이를 통해 디지털 트윈과의 구현된 상호작용을 탐구함.
          + 사용자가 텍스트를 하이라이트하면, 디지털 버전에 하이라이트가 저장됨.
          + 하이라이트된 부분에 대한 음성 코멘트를 자동으로 저장함.
     * ""Draw & Dream"" 프로토타입
          + 이미지 확산을 통해 AI와의 공동 창작을 탐구함.
          + 사용자가 그린 작품을 StreamDiffusion에 입력하여 스타일적 ""렌즈""를 적용함.
          + 결과 비디오 피드는 Unity 애플리케이션에 스트리밍됨.
     * 결과 및 학습
          + 프로토타입은 AI가 물리적 세계로 어떻게 가져올 수 있는지를 보여줌.
          + 물리적 객체를 통해 컴퓨팅과 직접 인터페이스할 수 있는 가능성을 탐구함.
          + AI와의 인간 관계를 세 가지 접근 방식으로 다르게 프레이밍함.
"
"https://news.hada.io/topic?id=18078","LinkedIn의 GenAI 애플리케이션 기술 스택 개발 과정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   LinkedIn의 GenAI 애플리케이션 기술 스택 개발 과정

     * 2023년 초, LinkedIn은 GenAI 기능을 활용하는 제품 포트폴리오를 출시하기 시작함
     * 초기 GenAI 제품은 간단한 ""프롬프트 입력, 문자열 출력""에서 시작하여 컨텍스트 메모리를 지원하는 대화형 에이전트 경험으로 발전
     * GenAI 애플리케이션 기술 스택 구축을 통해 타임투마켓 과 장기 레버리지 간의 균형을 유지하는 접근 방식을 구현

Genesis and Evolution

     * 공통 작업을 위한 표준 메커니즘을 제공하는 프레임워크 구축이 필요했음
     * 대부분의 LinkedIn 온라인 서빙 스택이 Java로 프로그래밍되어 있어 초기에는 공유 Java midtier로 시작함
     * 사용 사례가 증가함에 따라 이 midtier가 개발 및 운영 병목 현상이 되어 여러 사용 사례별 Java midtier 서비스로 분할함
     * AI 엔지니어는 오프라인 LLM 기반 워크플로, 프롬프트 엔지니어링 및 평가에 Python을 선호함
     * 단기적으로는 단편화된 온라인 및 오프라인 스택을 유지하되, 장기적으로는 Python을 온라인 서빙에도 사용하기로 결정함
     * LangChain 오픈소스 프로젝트를 기반으로 온라인 서빙용 Python 프레임워크 구축
     * Python에 중점을 두고 핵심 인프라 종속성에 대한 Python 지원 활성화 프로젝트 시작
     * 현재 GenAI 애플리케이션 프레임워크는 LangChain 위에 구축된 얇은 래퍼임

프롬프트 관리

     * 프롬프트 엔지니어링은 LLM을 ""프로그래밍""하는 주요 메커니즘임
     * 초기에는 코드에서 수동 문자열 보간을 사용했지만 오류가 발생하기 쉽고 확장이 불가능했음
     * Prompt Source of Truth 컴포넌트 도입하고 Jinja 템플릿 언어 사용 표준화
     * 프롬프트 해상도 라이브러리를 Java에서 Python으로 다시 작성
     * 대화형 UI가 등장함에 따라 대화에서 인간과 AI의 역할에 대한 더 많은 구조 제공
     * 최종적으로 OpenAI Chat Completions API로 수렴

스킬을 통한 작업 자동화

     * 스킬 추상화를 GenAI 애플리케이션으로 확장하여 작업 자동화 메커니즘으로 사용
     * 초기에는 LLM 친화적인 JSON 스키마를 사용하여 LinkedIn 내부 및 외부 API를 래핑하는 사용자 지정 코드로 구축됨
     * 스킬 중복 구현, 다운스트림 스킬 변경, 개발자의 수동 스킬 지정 등의 문제 발생
     * Skill Inversion 개념 도입하여 다운스트림이 스킬을 정의하고 호출 앱에 노출하도록 함
     * 중앙 집중식 스킬 레지스트리 서비스, 빌드 플러그인, 동적 LangChain 도구 등 스킬 액세스, 개발 및 운영 프로세스 간소화
     * 점진적으로 모든 API에 대한 스킬 추상화를 생성하여 LLM이 원활하게 상호작용할 수 있도록 기술 스택 진화 중

컨텍스트 인식 및 개인화

     * LLM이 기본적으로 stateless하기 때문에 컨텍스트 인식과 개인화가 어려움
     * 초기에는 Couchbase나 Espresso DB를 스토리지로 사용하고 각 팀이 DB 설정, 쓰기/읽기 등을 담당함
     * LLM 컨텍스트 윈도우가 제한적이므로 의미 검색(임베딩 사용)과 요약 기능이 필요해짐
     * LinkedIn 메시징 스택을 활용하여 대화 메모리 인프라 구축
     * 사용자-애플리케이션 상호 작용 경험을 기반으로 파생된 Experiential Memory 개념 도입
     * GenAI 애플리케이션 프레임워크에 통합하여 개발자가 원활하게 사용할 수 있도록 지원

모델 추론 및 미세 조정

     * 초기에는 Azure OpenAI 서비스에서 제공하는 LLM만 사용함
     * LinkedIn 특정 작업을 위해 미세 조정된 Llama와 같은 LLM이 상용 모델과 비슷하거나 더 나은 품질을 보임
     * 외부 및 내부 모델에서 애플리케이션 개발자 경험을 투명하게 하기 위해 노력 중
     * 추론 계층은 모든 LLM에 OpenAI Chat Completions API를 노출함
     * 애플리케이션 프레임워크의 구성 훅을 통해 온프레미스 및 외부 모델 간 쉽게 전환 가능

마이그레이션

     * 레거시 맞춤형 솔루션에서 표준화된 솔루션으로 신속하게 마이그레이션하는 것이 중요함
     * Java 스택과 새로운 스택에 대한 깊은 지식을 가진 엔지니어로 구성된 린 팀이 마이그레이션을 처리함
     * 점진적 접근 방식을 사용하여 개별 구성 요소를 하나씩 마이그레이션함
     * 간단하고 작은 앱부터 시작하여 복잡하고 큰 앱으로 진행
     * 선배 엔지니어와 신입 Python 개발자를 페어링하여 실무에서 Python을 배울 수 있도록 함

최종 생각

     * 새로운 GenAI 애플리케이션 기술 스택은 AI 우선 개발을 수용하고 효율적이고 책임감 있게 GenAI 앱을 구축하기 위한 탄탄한 기반을 마련함
     * 전 세계 인력의 모든 구성원에게 경제적 기회를 제공하려는 비전 달성에 중요한 역할을 할 것임
     * 아직 해결해야 할 과제가 많이 남아 있음
     * 제품 경험의 최첨단이 대화형 어시스턴트에서 AI 에이전트로 이동함에 따라 새로운 기능 및 운영 요구 사항이 급증하고 있음. 이 내용도 추가로 공개 예정
"
"https://news.hada.io/topic?id=18017","Show GN: 홉스 — AI와 대화하면서 어드민을 만들수 있는 서비스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Show GN: 홉스 — AI와 대화하면서 어드민을 만들수 있는 서비스

   스타트업에서 일해보신 개발자들은 아래와 같은 경험해보셨을 것이라고 생각합니다.
     * 핵심 제품 개발에 집중하고 싶은데, 운영에 필요한 어드민 도구 개발과 유지보수에 너무 많은 시간을 뺏기고 있었고
     * 기존 로우코드 도구들은 새로운 개념과 인터페이스를 배워야 해서 오히려 시간이 더 들었습니다.

   그래서 저희 팀이 최근에 만든 홉스 AI를 소개드리고 싶습니다.
   자연어로 원하는 기능을 설명하면 AI가 이해하고 바로 구현해주는 방식을 채택했습니다.

   홉스의 주요 특징은 다음과 같습니다:
     * AI 빌더: 자연어로 원하는 기능을 설명하면 AI가 어드민 페이지와 이를 구성하는 코드를 생성해줍니다.
     * Notion 같은 UI 개발: 노션처럼 ""/""만 입력하면 컴포넌트를 추가할 수 있어서, 익숙한 방식으로 작업할 수 있죠. AI가 만든 결과물을 쉽게 고칠 수 있습니다.
     * 기존 인프라 활용: MySQL, PostgreSQL, MongoDB 등 기존 데이터베이스와 API에 연결할 수 있습니다.

   14일의 무료 트라이얼로 바로 사용해보실 수 있는데, 여기서 깃헙 계정이나 구글로 로그인하실 수 있습니다.

   피드백이나 의견 있으시면 언제든 환영합니다!
"
"https://news.hada.io/topic?id=18128","React v19 - Actions, Server Components, Hydration 에러 개선, Document Metadata 지원 등","                                                                                                                                                                                                                                                                                                                                                                                                                                                                            React v19 - Actions, Server Components, Hydration 에러 개선, Document Metadata 지원 등

    새로운 API 및 기능

     * Actions: 데이터 변경과 상태 업데이트를 자동으로 처리. 대기 상태, 에러, optimistic update 등을 자동 관리
     * useActionState: Actions의 일반적인 사용 사례를 간단히 처리할 수 있는 새로운 훅
     * use API: 렌더링 중 프로미스 및 컨텍스트 읽기 가능
     * useOptimistic: 비동기 요청 중 optimistic UI 업데이트를 쉽게 구현
     * ref as a prop: 함수 컴포넌트에서 직접 ref prop 사용 가능 (forwardRef 불필요)
     * <Context> as a Provider: <Context.Provider> 대신 <Context> 직접 사용 가능

    문서 및 리소스 관리

     * 메타데이터 지원: <title>, <link>, <meta> 태그를 컴포넌트에서 직접 사용 가능
     * 스타일시트 지원: 컴포넌트 내에서 스타일시트 로딩 및 우선순위 관리
     * 비동기 스크립트 지원: 컴포넌트 트리 어디에서나 비동기 스크립트 렌더링 가능
     * 리소스 프리로딩: 성능 최적화를 위한 prefetchDNS, preconnect, preload, preinit API 제공

    개선사항

     * 커스텀 엘리먼트 지원: 커스텀 엘리먼트에 대한 완전한 지원 추가
     * 에러 처리 개선: 중복 에러 제거 및 에러 처리 옵션 추가
     * 서드파티 스크립트/확장 프로그램 호환성: 하이드레이션 과정에서 서드파티 콘텐츠 처리 개선
     * hydration 에러 개선: 더 명확한 에러 메시지와 디버깅 정보 제공

    서버 컴포넌트

     * 안정화된 서버 컴포넌트: Canary 채널의 모든 서버 컴포넌트 기능이 React 19에 포함
     * 서버 액션: 클라이언트 컴포넌트에서 서버 함수 호출 기능 제공

    기타

     * useDeferredValue 초기값: useDeferredValue에 초기값 옵션 추가
     * ref 정리(cleanup) 함수: ref 콜백에서 정리 함수 반환 가능
     * 새로운 Static API: prerender와 prerenderToNodeStream API 추가

   이번 19에서는 논란이 있던 <Suspense>의 동작을 다시 정의했습니다. 이전까지만 해도 한 컴포넌트를 Suspense하면 다음 Suspense 컴포넌트까지 렌더링한 다음 폴백을 생성했지만, 현재는 한 컴포넌트를 Suspense하면 먼저 폴백을 생성하고 다음 Suspense 컴포넌트를 렌더링하는 순으로 바뀌었습니다.

   Improvements to Suspense

   한마디로 첫 렌더링 시간을 줄였다고 보면 됩니다. 잘 해결되어서 다행이군요.
"
"https://news.hada.io/topic?id=18019","내가 OpenBSD 사용을 중단한 이유 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         내가 OpenBSD 사용을 중단한 이유

     * 프리랜서 OpenBSD, FreeBSD, Linux, Qubes OS 컨설턴트인데 최근 OpenBSD 를 떠났고 더 이상 사용하지 않게 됨
     * OpenBSD의 가치를 인정하고 존재의 중요성을 알지만, 개인적 필요와는 더 이상 맞지 않음

문제점

     * 하드웨어 호환성
          + Bluetooth 지원 부재
          + 게임패드 지원 제한적: 일부 프로그램 및 특정 게임패드 미지원
          + 배터리 수명/발열/전력 사용 문제: 다른 OS에 비해 전력 소모가 상당히 높음
     * 소프트웨어 호환성
          + DevOps 분야의 최신 기술 학습이 필요함 : OCI 컨테이너, 머신 러닝 등
          + 하지만 OpenBSD에 가상 머신을 실행하는 것은 정말 제한적임: 단일 코어/저성능은 작업에 집중하지 못하게 함
          + 컨설팅 업무에서 가끔 독점 소프트웨어를 실행할 필요가 있는데, VM에선 문제가 없지만 OpenBSD에서는 골치 아픔. 성능도 나쁘고.
     * 신뢰성
          + OpenBSD 파일 시스템은 정말 불만임. 신뢰할수가 없음.
               o 데스크톱으로 사용 시 잦은 충돌과 데이터 손실이 발생하여 참을 수가 없음
          + 하드웨어 호환성 문제 일수도 있는데, 예전 ThinkPad T400에서는 문제가 없었는데 특정 하드웨어에서 커널 패닉, 프리징 문제 발생
               o ThinkPad X395, t470, t480, Ryzen 5600X + AMD GPU
          + 데이터 손실이 빈번한 OS는 더 이상 사용이 어려움
          + 다른 사람들은 안정적으로 잘 사용하는 것 같은데 나만 왜 그렇게 충돌이 발생하는지 알 수가 없음

Linux로 전환

     * OpenBSD에서 Qubes OS로 대부분 전환해서 작업을 수행함(게임만 빼고)
          + Fedora 가상 머신 사용(평균적으로 대략 20개의 VM을 동시에 실행함)
          + 이게 OpenBSD보다 더 좋은 보안을 제공: 작업을 컨텍스트별로 분리 가능
     * Linux에서 제공하는 다음 기능들로 만족도 향상:
          + 네임스페이스: 프로세스의 범위를 줄이는 기능으로 컨테이너 실행의 기반을 제공. chroot보다 훨씬 강력한 격리 환경을 구현 가능
          + cgroups: 자원 사용량을 모니터링하는 커널 서브시스템. 네트워크, I/O, CPU, 메모리 사용량을 정확히 확인할 수 있어 운영자 입장에서 자원 소비의 원인을 파악하는 데 매우 유용
          + systemd: journald, 타이머, 스크립트 작성 가능성 등 유용한 기능을 제공. 초기 학습 곡선이 있을 수 있으나 매뉴얼 페이지가 잘 정리되어 있음
          + 스왑 압축: lz4 압축 알고리즘을 활용하여 메모리를 절약하면서도 매우 빠른 스왑 성능을 제공. 보통 3:1 또는 4:1의 압축률을 기록
          + 현대적인 스토리지 백엔드: LVM, btrfs, ZFS 등을 활용하여 성능, 신뢰성, 확장성을 극대화 가능. 특히 투명한 데이터 압축으로 하드웨어에 더 많은 데이터를 저장 가능 (압축 가능한 경우)
          + Flatpak: 독립적인 네임스페이스에서 실행되며, 파일 시스템 전체 접근이 제한됨. 이전 버전으로 롤백하거나 다른 기능 활용 가능
          + auditd: 보안 환경에서 필수적인 도구로, 특정 파일 접근 기록 및 수정 기록 등을 로깅 가능. OpenBSD에는 존재하지 않는 기능
          + SELinux: 초기 설정 과정에서 비활성화되는 경우가 많으나, 전체 취약점 클래스를 완화할 수 있는 매우 강력한 보안 메커니즘 제공
     * 데스크탑을 게임용으로 사용할 때는 Fedora Silverblue 사용. 안정적 업그레이드와 소프트웨어 다양성 제공

결론

     * OpenBSD에서 발생한 잦은 충돌과 데이터 손실로 인해 더 이상 사용을 중단함
     * 성능 부족과 작업 효율 저하로 인해 개인 작업에 적합하지 않음
     * 그러나 OpenBSD를 사용하는 사용자들이 시스템의 단순성과 투명성을 즐기는 점은 긍정적으로 평가함
          + 특히, 사용자가 시스템 내부 동작을 이해할 수 있는 점은 OpenBSD의 독특한 장점임 (NetBSD도 비슷할 수 있음)
     * 앞으로도 OpenBSD가 적합한 상황에서 이를 옹호할 예정
     * 오픈 소스 소프트웨어 기여 시 OpenBSD 호환성을 확인하며, 필요시 OpenBSD로 돌아갈 가능성도 염두에 둘 것임

        Hacker News 의견

     * NetBSD는 GPU 컴퓨팅 기능이 없고 브라우저 DRM이 불편하여 macOS를 사용함. 시스템이 충돌하거나 패닉을 일으키지 않아야 하며, 데이터 손실이나 파일 시스템 손상이 없어야 함. OpenBSD는 보안보다 안정성을 우선시해야 한다고 생각함
     * Solène Rapenne의 이직은 아쉽지만, 그녀가 OpenBSD 팀에 큰 기여를 했음. 최근 OpenBSD 7.6에서 패닉이 발생해 데이터 손실을 경험했지만, 여전히 Linux에서 개발한 항목을 테스트하는 데 OpenBSD를 사용할 것임
     * Flatpak의 소프트웨어 배포 방식을 좋아하지만, 여전히 보안상의 취약점이 존재함
     * OpenBSD는 주로 서버 용도로 사용되며, 블루투스나 게임패드 지원은 우선순위가 아님
     * OpenBSD는 네트워크 방화벽으로 사용하기에 적합하며, 설정 파일이 이해하기 쉬움
     * Solène에게 Qubes OS 포럼에서 배운 점이 많음. OpenBSD는 철학적으로 매력적이지만, 개인적인 사용 사례에는 맞지 않음
     * OpenSuse를 사용하면서 파일 시스템 스냅샷 지원이 뛰어나고, Flatpak으로 부족한 부분을 보완할 수 있었음
     * OpenBSD에서 가상화를 사용하면 성능이 매우 나쁘고 큰 문제를 겪음
     * 저널링 파일 시스템 덕분에 데이터 손실을 겪지 않음. 데이터 무결성 작업이 보안에 더 유익할 것이라고 생각함
     * Linux의 루트리스 컨테이너에 실망하고 있으며, Incus와 Firecracker를 사용해보려 함
     * Solène의 주요 문제는 VM 호스팅과 파일 시스템 문제임. 더 나은 VM 호스팅이 보안과 하드웨어 지원 문제를 해결할 수 있을 것이라고 생각함
"
"https://news.hada.io/topic?id=18092","여성 대상 연 2회 HIV 주사, 100% 효과 입증","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     여성 대상 연 2회 HIV 주사, 100% 효과 입증

     * 새로운 HIV 예방 주사
          + Gilead의 새로운 주사제는 AIDS 바이러스 예방에 있어 가장 가까운 백신으로 평가받음
          + 여성 대상 연구에서 100% 효과를 보였으며, 남성에게도 거의 동일한 효과를 보임
          + Gilead는 120개 저소득 국가에 저렴한 제네릭 버전을 제공할 계획이나, 대부분의 라틴 아메리카는 제외됨
     * 세계 AIDS의 날 보고서
          + UNAIDS는 2023년 AIDS 사망자가 2004년 이후 최저치를 기록했다고 보고
          + 이는 세계가 AIDS 종식을 위한 역사적 기로에 서 있음을 시사함
     * Lenacapavir의 중요성
          + Lenacapavir는 미국, 캐나다, 유럽 등에서 이미 판매 중이며, HIV 예방을 위한 승인을 곧 요청할 계획
          + 특히 소외된 사람들에게 유용할 것으로 예상됨
     * 라틴 아메리카의 상황
          + 멕시코, 브라질, 페루, 아르헨티나 등은 제네릭 제공에서 제외됨
          + 멕시코에서는 HIV 예방을 위한 일일 약이 무료로 제공되지만, 주사제의 보급 여부는 불확실함
     * 제네릭 제공의 필요성
          + 15개의 라틴 아메리카 옹호 단체가 Gilead에 제네릭 제공을 요청
          + 기존 예방 방법으로는 매년 100만 건 이상의 새로운 HIV 감염을 막기에 충분하지 않다고 주장
     * 전문가 의견
          + Duke University의 Dr. Chris Beyrer는 아프리카와 아시아에서 Gilead 주사의 가용성이 중요하다고 강조
          + HIV 예방에 있어 Gilead 주사만큼 효과적인 약은 없었다고 언급
     * 결론
          + Gilead 주사의 효과는 입증되었으나, 필요한 사람들에게 어떻게 전달할지가 과제임
"
"https://news.hada.io/topic?id=18119","Ruby의 속도를 높이기 위한 C 코드의 Ruby 재작성","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Ruby의 속도를 높이기 위한 C 코드의 Ruby 재작성

    Ruby의 성능 향상: C를 Ruby로 다시 작성하기

      Ruby의 성능 비교

     * 최근 언어 비교 리포지토리에서 Ruby는 R과 Python보다 빠르지만, 세 번째로 느린 언어로 평가됨.
     * 벤치마크는 ""Loops""와 ""Fibonacci"" 두 가지로 구성되며, 각각 루프와 조건문, 함수 호출 오버헤드 및 재귀 성능을 강조함.

      Ruby와 Node.js의 성능 비교

     * M3 MacBook Pro에서 Ruby 3.3.6은 루프 예제에서 28초, 피보나치 예제에서 12초 소요됨.
     * Node.js는 두 예제 모두 1초 정도 소요됨.
     * M2 MacBook Air에서는 Ruby의 성능이 더 나빠짐.

      벤치마크의 의미

     * 이러한 벤치마크는 실제로 큰 의미가 없을 수 있음.
     * Python은 가장 느린 언어로 평가되었지만, GitHub에서 가장 많이 사용되는 언어임.
     * 프로그래밍 언어는 효율적이어야 하며, 언어의 유용성과 생산성이 성능보다 중요함.

      YJIT의 적용

     * YJIT를 적용하면 피보나치 성능이 크게 향상됨.
     * 루프 예제에서는 성능 향상이 미미함.

      Ruby 코드 최적화

     * Range#each는 C로 작성되어 YJIT 최적화가 불가능함.
     * Integer#times는 Ruby 3.3에서 C에서 Ruby로 변환되어 YJIT 최적화가 가능함.
     * Array#each는 Ruby 3.4에서 C에서 Ruby로 변환됨.

      Integer#times 최적화

     * Integer#succ는 i += 1보다 빠르게 동작함.
     * YJIT는 Integer#times를 최적화하여 성능을 크게 향상시킴.

      Array#each 최적화

     * Array#each는 Ruby 3.4에서 C에서 Ruby로 변환되어 YJIT 최적화가 가능함.
     * Primitive 모듈을 사용하여 C 코드를 Ruby에서 평가함.

      Ruby Microbench 리포지토리

     * 다양한 Ruby 버전과 YJIT를 사용하여 벤치마크를 실행함.
     * Ruby 3.4 YJIT는 성능이 크게 향상됨.

      range#each 최적화

     * Range 클래스를 순수 Ruby로 구현하여 성능을 향상시킬 수 있음.

      YJIT 표준 라이브러리

     * YJIT 팀은 C 코드를 Ruby로 대체하여 성능을 향상시키고 있음.
     * with_yjit 블록을 사용하여 YJIT가 활성화되었을 때 Ruby 구현을 사용함.

      YJIT 최적화 조사

     * YJIT는 Ruby VM 바이트코드를 기계어로 변환하여 성능을 최적화함.
     * Integer#succ의 기계어 코드를 분석하여 YJIT의 최적화 과정을 이해함.

        Hacker News 의견

     * 루프 예제는 10억 번 반복하며 중첩 루프를 사용함. 이 벤치마크는 첫 두 줄에서 99% 이상의 시간을 소비할 것이라고 추측됨
          + 배열 요소에 대한 활력 분석을 통해 전체 외부 루프를 제거할 수 있으며, 프로그램을 간단하게 변환할 수 있음
          + 컴파일러가 이러한 분석을 수행할 수 있는지 궁금함
          + u가 컴파일 시점에 알려지지 않더라도 내부 루프는 몇 가지 명령어로 대체 가능함
     * Ruby의 향후 버전에 대한 언급이 있으며, Ruby 3.4.0은 이번 크리스마스에, Ruby 3.5.0은 다음 크리스마스에 출시될 예정임
          + Python의 최소 JIT가 이러한 루프에 어떤 영향을 미칠지 궁금함
          + Python 3.13은 JIT가 활성화된 상태로 빌드되어야 하며, 이를 통해 벤치마크를 실행해보는 것이 흥미로울 것임
     * Ruby에 대한 애정이 여전히 남아있음. Matz에게 감사함
     * Integer#succ의 성능 개선 PR이 2024년 초에 있었으며, 이를 통해 Integer#succ를 사용하는 이유를 이해하게 됨
          + Integer#succ는 루프 메서드를 재작성할 때 사용되며, 해석기에서 opt_succ (i = i.succ)가 putobject 1; opt_plus (i += 1)보다 더 빠르게 처리됨
          + 개인적으로 #succ를 가독성 때문에 자주 사용하며, UUID 라이브러리의 #bytes 메서드에서 두 번 사용하여 코드 읽기 시 ""비트 슬라이싱 모드""를 유지함
     * TruffleRuby와 관련된 경험을 공유하며, TruffleRuby가 Node.js보다 빠르고 Bun이나 Golang에 근접함
          + 제공된 벤치마크가 변경 후의 TruffleRuby 속도를 보여주는지 확신할 수 없음
          + 벤치마크를 검증하고 메인 저장소에 커밋으로 추가하고 싶음
     * Ruby가 매우 빨라졌으며, TruffleRuby는 더욱 인상적임
     * YJIT가 Rust로 작성되었다는 사실을 몰랐음
     * Python이 벤치마크에서 가장 느린 언어였지만, 2024년 10월 기준으로 Github에서 가장 많이 사용되는 언어임
          + 언어의 느림과 인기가 상관관계가 있는 것 같음
     * 더 많은 언어를 포함한 오래된 언어 비교 저장소가 있음
     * Advent of Code 솔루션에 큰 변화를 가져왔으며, 놀랍도록 유사하게 보임
"
