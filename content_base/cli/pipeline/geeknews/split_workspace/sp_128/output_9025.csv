"https://news.hada.io/topic?id=15284","Dblab - 인터랙티브한 터미널용 DB 클라이언트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Dblab - 인터랙티브한 터미널용 DB 클라이언트

     * PostgreSQL, MySQL, SQLite3, Oracle을 위한 빠르고 가벼운 인터랙티브 터미널 기반 UI 애플리케이션
     * 로컬 또는 원격 데이터베이스와 작업하기 위한 매우 간단하고 휴대 가능한 애플리케이션을 만들기 위해 개발
     * Go 언어로 개발. OSX, Linux, Windows 지원 (싱글 바이너리로 간편 설치 가능. 의존성 없음)
     * 창 형태의 인터페이스. 키보드로 네비게이션/패널 이동

   일전에 소개 받은 할리퀸도 잘 쓰고 있는데, 이런 좋은 툴이 또 있군요.

   할리퀸은 어떤건가요?!

   harlequin이 마음에 들어서 oracle에 연결해보고 있었는데, ODBC를 사용해서 연결 할 떄 오류가 발생해 issue에 올려뒀습니다.
   https://github.com/tconbeer/harlequin/issues/567

   oracle 연결은 Dblab으로 테스트 해봐야겠네요.

   이 쪽 참조 하시면 될 것 같습니다.
   https://harlequin.sh/

   취미 프로젝트 진행하는데 데이터그립 쓰기는 좀 부담스러울 때, 할리퀸이 좋더라구요.
   이 본문의 데이터랩을 잠시 사용해봤는데, 할리퀸이 제게는 더 편하고 안정적이었습니다.

   감사합니다!
"
"https://news.hada.io/topic?id=15306","Flameshot – 크로스 플랫폼 화면캡쳐 소프트웨어 오픈소스 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Flameshot – 크로스 플랫폼 화면캡쳐 소프트웨어 오픈소스

     * 강력하고 사용하기 쉬운 스크린샷 소프트웨어
     * 커스터마이즈 가능 : 인터페이스 색상, 버튼 선택, 키보드 단축키, 이미지 저장 방식 등을 설정
     * 스크린샷 편집 : 화살표 추가, 텍스트 강조, 특정 영역 블러 처리(흐리게 또는 픽셀화), 텍스트 추가, 그림 그리기, 사각형/원형 테두리 추가, 증가하는 카운터 번호 추가, 단색 박스 추가 등
     * 간단하고 직관적인 사용법 : 캡처할 영역을 드래그하여 선택하고, 필요한 주석을 추가한 후 컴퓨터에 저장
     * 스크린샷을 클라우드에 직접 업로드하여 쉽게 공유 가능. 한 번의 클릭으로 Imgur에 이미지를 업로드하고 URL을 공유
     * 터미널에서 여러 명령을 사용할 수 있는 CLI 제공. 명령줄 인터페이스를 통해 Flameshot을 스크립트로 작성하고 키 바인드의 주제로 사용할 수 있음
     * 윈도우/맥/리눅스

GN⁺의 의견

     * 사용자 친화성: Flameshot은 직관적인 인터페이스와 다양한 편집 기능으로 초급 소프트웨어 엔지니어도 쉽게 사용할 수 있는 도구임.
     * 생산성 향상: 다양한 편집 도구와 클라우드 업로드 기능을 통해 스크린샷 작업의 효율성을 크게 높일 수 있음.
     * 오픈 소스의 장점: 오픈 소스 소프트웨어로서 커스터마이즈 가능성이 높고, 커뮤니티의 기여를 통해 지속적으로 개선될 수 있음.
     * CLI의 유용성: 명령줄 인터페이스를 통해 자동화 스크립트 작성이 가능하여 고급 사용자에게도 유용함.
     * 대안 제품: 비슷한 기능을 제공하는 다른 스크린샷 도구로는 ShareX, Greenshot 등이 있으며, 각 도구의 특성을 비교해보는 것도 좋음.

   리눅스용 greenshot 찾다가 쓰게 되었었는데 리눅스 wayland 멀티모니터 환경에서 문제 있으니 (주 모니터만 된다던가, 캡처 영역이 작게 줄어든다던가...) 쓰실 리눅스 사용자 분들은 참조하시면 좋을 것 같습니다

        Hacker News 의견

     * Flameshot와 Tesseract, zbarimg를 사용해 화면의 특정 영역을 빠르게 캡처하고 OCR 또는 바코드 디코딩을 수행함. 이를 핫키 조합에 매핑해 사용함.
     * Google Photos 웹 앱이 클립보드에서 붙여넣기를 지원함. Flameshot으로 캡처한 스크린샷을 Google Photos에 업로드하고, 자동으로 텍스트를 인덱싱해 검색 가능하게 함.
     * Greenshot을 좋아하지만, Linux에서는 사용할 수 없다는 점이 아쉬움. Flameshot은 아이콘 레이아웃이 동적으로 변해 불편함.
     * Windows에서 [Win + Shift + S]가 가장 빠르게 선택 영역을 클립보드에 복사하는 방법임. Flameshot을 사용해보니 스냅을 찍으면서 바로 그림을 그릴 수 있어 좋음.
     * 스크립트를 사용해 스크린샷을 찍고 S3 버킷에 업로드한 후 URL을 클립보드에 복사함. Minio 클라이언트를 사용함.
     * ShareX가 더 직관적이고 사용하기 쉬움. Flameshot의 단색 아이콘은 직관적이지 않음. PrtScn 키로 트리거할 수 없는 점이 아쉬움.
     * Greenshot을 10년 넘게 사용 중이며, Windows와 Mac에서만 사용 가능함.
     * Flameshot은 강력하고 사용하기 쉬운 소프트웨어임. 사용자가 필요할 때만 나타나서 방해되지 않음.
     * 관련 링크: Flameshot v11.0.0 (2022년 1월), Flameshot – 모든 주요 운영 체제를 위한 간단하고 강력한 스크린샷 도구 (2021년 3월), Flameshot – 뛰어난 스크린샷 도구 (2021년 2월).
     * Flameshot을 몇 년 동안 사용 중이며, 스크린샷을 찍는 순간에 그림을 그리고 주석을 추가할 수 있어 좋음.
"
"https://news.hada.io/topic?id=15260"," ComfyUI_LLMVISION 확장 프로그램에서 발견된 Keylogger","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ComfyUI_LLMVISION 확장 프로그램에서 발견된 Keylogger

     * u/AppleBotzz 가 올린 ComfyUI_LLMVISION 노드를 사용했다면, 당신은 해킹당했음
     * 그 패키지를 사용하면 브라우저 비밀번호, 신용카드 정보, 브라우징 기록 등의 개인정보가 Discord 서버로 유출됨
     * 해당 패키지의 요구사항 파일(requirements.txt)에는 OpenAI와 Anthropic 라이브러리를 위한 커스텀 휠(wheel)이 포함되어 있었음
     * 이 휠 안에는 악성 코드가 숨겨져 있었음
     * 1.16.2 버전의 휠에는 존재하지 않는 1.16.3 버전이 설치되며, 안에는 브라우저 데이터를 읽어 임시 디렉토리에 저장하는 /lib/browser/admin.py 파일이 포함됨
     * 해당 파일은 수집한 데이터를 암호화된 문자열에 담아 Discord 웹훅으로 전송함
     * 1.30.2 버전에는 openai/_OAI.py 파일이 포함되어 있으며, 안에는 Pastebin 링크가 암호화된 문자열로 존재함
     * 첫 번째 Pastebin 링크에는 다른 Discord 웹훅이, 두 번째 링크에는 악성 파일(VISION-D.exe)의 URL이 포함됨
     * 스크립트는 레지스트리 항목을 생성하고 API 키를 탈취하여 Discord 웹훅으로 전송함
     * 영향을 받았는지 확인하려면 임시 디렉토리, 파이썬 패키지, 윈도우 레지스트리 등을 체크해야 함
     * 문제가 발견되면 관련 패키지 삭제, 악성 파일 제거, 레지스트리 키 삭제, 백신 검사, 비밀번호 변경 등의 조치가 필요함
     * 해당 사용자(u/applebotzz)는 악성 코드를 감추기 위해 두 차례나 업데이트를 진행한 것으로 보아 고의적인 행위로 판단됨
     * 앞으로는 설치하는 커스텀 노드와 확장 기능을 주의 깊게 확인해야 함

        Hacker News 의견

     * ComfyUI 확장 기능이 임의의 파이썬 코드로 구성되어 있어 보안에 취약함.
     * 딥러닝에서 보안이 무시되는 경향이 있음. 예전에는 거의 모든 딥러닝 모델이 피클 파일로 배포되었음.
     * ComfyUI가 매우 강력하지만, Adobe가 이미지 생성에서 실수한 것 같음. 더 안전한 방법이 필요함.
     * 도커를 사용하여 보안을 강화하는 것에 대한 의견이 궁금함. 사용성과 보안의 균형을 맞출 수 있는지 의문임.
     * GitHub 저장소를 스캔하여 소스 코드에 숨겨진 악성 코드를 탐지할 수 있는 코드 LLM 사용 가능성에 대한 호기심이 있음.
     * 프로젝트가 작아 보임. GitHub에서 40개의 별을 받았고, 저장소가 삭제되기 전까지 GPT-4와 Claude 통합의 주요 방법이었는지 궁금함.
     * 이러한 문제를 막기 위해 OS 수준에서 검증하는 계층이 필요함. 로컬 LLM을 사용하여 설치/실행되는 바이트 코드를 검사하면 해결될 수 있을지 의문임.
     * Nullbulge Group이라는 단체가 저장소를 인수했다고 주장함. 저장소가 404 오류를 내기 전의 캡처가 있음.
     * Reddit에서의 논의가 많은 잘못된 정보와 가짜 지식으로 가득 차 있음. 이는 악성 코드만큼 무서움.
     * 키로거에 대한 방어 방법이 없는지 궁금함. 단순한 키로거가 비밀번호를 훔칠 수 있다면 어떻게 해야 할지 의문임.
"
"https://news.hada.io/topic?id=15275","애플, 개인용 인공 지능 시스템 Apple Intelligence 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                애플, 개인용 인공 지능 시스템 Apple Intelligence 공개

     * iPhone, iPad, Mac 에서 통합적으로 사용가능
     * 언어와 이미지를 이해 및 생성, 다수 앱에 걸쳐 액션 수행, 사용자 경험을 바탕으로 맥락을 파악하여 일상적인 업무를 간소화 및 가속화
     * 새로운 쓰기 도구 : Mail, 메모, Pages, 서드파티 앱 등 글을 쓸 수 있는 대부분의 앱에서 사용자가 쓴 글을 재작성하고, 교정하고, 요약
     * 메일을 종류별로 구분하고, 이메일 첫줄 대신 요약본을 표시. 빠른 스마트 답장 작성
     * 메모 앱과 전화 앱에서 오디오를 녹음, 전사 및 요약 가능
          + 통화 중에 녹음을 시작하면 당사자 모두에게 자동으로 녹음 사실이 알려지고, 통화를 마치면 Apple Intelligence가 요약본을 생성해 요점을 되짚어볼 수 있음
     * Image Playground : 이미지 생성기능을 자유롭게 테스트 가능. 애니메이션/일러스트/스케치 세가지 스타일
          + 메일/메시지/메모등에서 바로 활용 가능하며, 별도 앱으로 제공되고, API로 개발자가 자신의 앱내에서 활용 가능
     * Genmoji : 순간에 딱 맞는 이모지를 생성하여 바로 사용
     * 사진과 동영상 검색도 향상
          + 자연어를 이용하여 구체적으로 검색 : 얼굴에 스티커를 붙인 케이티
          + 동영상 클립 중간에 나오는 특정 장면을 검색하는 것도 가능
     * Siri가 더욱 자연스러워지고, 맥락을 더욱 잘 파악하는 데다 사용자를 더 잘 이해할 수 있게 됨
          + 대화의 맥락을 이해하기 때문에 앞 내용과 이어지는 요청 가능
          + 새로운 디자인: 활성화중에는 화면 전체 가장자리가 빛남
          + 기기 사용에 관한 다양한 도움을 어디서든 제공하고, iPhone, iPad, Mac 사용법에 관한 수천 가지 질문에도 대답
          + 화면을 인지하기 때문에 점점 더 많은 앱에서 화면 속 정보를 이해하고 사용자의 동의에 따라 필요한 동작을 수행
          + Apple 앱과 서드파티 앱을 넘나들며 수백 가지 동작을 새롭게 수행 가능
     * Apple Intelligence는 개인적인 상황 및 맥락에 대한 깊은 이해와 사용자의 개인정보 보호를 근간으로 함
          + 기본적으로 온디바이스에서 모든걸 처리
          + 필요할 경우 비공개 클라우드 컴퓨팅을 이용해서 별도 구축된 애플 실리콘 서버에서 누구에게도 노출되지 않고 더 복잡한 요청도 처리 가능
     * Apple 플랫폼에 ChatGPT를 긴밀하게 통합 (다른 LLM도 가능하게 할 예정)
          + 사용자가 다수의 앱 사이를 오갈 필요 없이 ChatGPT의 전문 지식과 이미지 및 문서 이해 역량을 활용할 수 있도록 구현할 예정
          + Siri도 필요하다고 판단하는 경우 ChatGPT의 전문 지식을 활용
          + 시스템 전반에 적용되는 쓰기 도구에 ChatGPT가 통합되어 사용자가 어떤 주제로 글을 쓸 때에도 ChatGPT로 내용을 구상할 수 있음
          + ChatGPT 이미지 도구에도 접근 가능
          + ChatGPT에 액세스하는 사용자를 위한 개인정보 보호 기능이 기본 탑재되어 있어 사용자의 IP 주소는 가려지고, OpenAI조차도 사용자의 요청을 저장할 수 없음
          + ChatGPT는 올 하반기 iOS18, iPadOS 18, macOS Sequoia에 적용되며, GPT-4o로 구동
          + 사용자는 계정을 생성하지 않고도 ChatGPT에 무료로 액세스할 수 있고, ChatGPT 구독자라면 계정을 연결해 Apple 기기에서 바로 유료 기능들을 이용할 수 있음

   아이폰 15프로부터 적용된다고 하던데. 적용모델이 궁금하네요. ios 18지원하곤 별개인걸로 봤거든요

   최근 애플의 논문들이 온디바이스에서 트랜스포머 모델들을 잘 돌리는 것들이 유독 많았는데, 이런 걸 보여줄려는 연구의 일환이지 않았을까 싶군요.

   음... 시리 같은 보이스 어시스턴트에 들어가는건 너무 좋은 판단인거같은데
   막상 뭔가 활용하긴 조금 힘든거같네요
   개인적으로 맥 / 갤탭 / 윈도우 데스크탑을 사용하고있는데
   갤럭시 쪽은 인터넷, 동영상 요약
   윈도우는 바로 ai챗봇실행
   이런거 사파리와 맥os에 추가되었으면 좋겠습니다
   챗지피티와의 협업은 애플 이용자에게 너무 좋은 소식이네요

   아이클라우드 모습이 조금 떠오르네요. 사용자가 직접 접하는 인프라들을직접 만들지 않지만 사용자와 접점이 있는 부분들은 자기들이 (제일잘하는) 담당하고. ChatGTP 앱이 너무 노멀해서 아쉬움이 많아요.

   결국 자연어와 이미지에 대한 인식/생성 모델을 직접 소규모로 만들어서 온디바이스로 다 처리하는 거네요.
   LLM들이 보여주는 방대한 지식은 써드파티인 ChatGPT 같은 것을 그냥 활용하고요.
   아주 애플스러운 접근 방식이라고 생각됩니다. 사용자 입장에서도 사실 나쁠거 없고요.
   다만 한국어에 대한 지원이 얼마나 빠르게 될 지는 두고 봐야할듯

   시리 한국어 지원 급으로 오래 걸릴 겁니다. 애초에 애플이 한국 시장을 중점적으로 신경 써줄 이유가 없고요.

   저도 공감합니다.
   한국어 지원 기다리다가 숨넘어갈 거 같다는 거까지요..ㅎㅎ

   동감합니다. 정말 애플스럽게, 자기들의 리소스를 적극 활용한 온디바이스 AI를 자신들만의 형태로 제공하네요. 대단하게 새로울 것도 없지만, 새로운 경험이 될 것 같다는 기대는 듭니다.
"
"https://news.hada.io/topic?id=15186","전자 부품의 이상한 값의 이유 (2021)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        전자 부품의 이상한 값의 이유 (2021)

왜 전자 부품의 값이 이상한가?

     * 전자 부품의 값: 저항, 커패시터, 제너 다이오드, 인덕터 등은 특정한 값으로 제공됨. 예를 들어, 47kΩ 저항과 22μF 커패시터는 흔하지만, 40kΩ 또는 50kΩ 저항, 20μF 또는 30μF 커패시터는 드뭄.
     * 선호 숫자: 이러한 값은 '선호 숫자'라는 개념에 기반함. 이는 1877년 프랑스에서 시작됨. Charles Renard가 다양한 크기의 풍선을 고정하기 위해 17개의 케이블 크기를 제안한 것이 시초임.
     * E-시리즈 값: 전자 부품은 E-시리즈 값으로 분류됨. E6, E12, E24, E48, E96, E192 시리즈가 있으며, 각 시리즈는 특정 오차 허용 범위를 가짐. 예를 들어, E6 시리즈는 20% 오차, E12 시리즈는 10% 오차를 가짐.
     * 값의 중첩: 각 시리즈의 값은 서로 중첩되어 다양한 전자 부품의 값을 커버할 수 있음. 예를 들어, 47kΩ + 20%는 56.4kΩ, 68kΩ - 20%는 54.4kΩ로 중첩됨.
     * 조합 사용: 특정 값이 필요할 때, 여러 부품을 조합하여 원하는 값을 얻을 수 있음. 예를 들어, 33과 47을 더하면 70이 됨.

GN⁺의 의견

     * 전자 부품의 표준화: 전자 부품의 값이 표준화되어 있어 설계와 제조 과정에서 효율성을 높일 수 있음. 이는 부품의 재고 관리와 비용 절감에도 도움이 됨.
     * 오차 허용 범위: 각 시리즈의 오차 허용 범위를 이해하는 것이 중요함. 이는 회로 설계 시 정확한 값을 얻기 위해 필수적임.
     * 부품 조합의 유용성: 특정 값의 부품이 없을 때, 여러 부품을 조합하여 필요한 값을 얻는 방법을 알아두면 유용함. 이는 비용 절감과 재고 관리에 도움이 됨.
     * 고급 부품의 비용: E96 또는 E192 시리즈와 같은 고급 부품은 비용이 더 높을 수 있음. 따라서 필요한 정확도와 비용을 고려하여 적절한 부품을 선택하는 것이 중요함.
     * 실제 사용 경험: 이론적인 오차 범위와 실제 사용 시의 오차 범위가 다를 수 있음. 경험을 통해 실제 오차 범위를 파악하는 것이 중요함.

        Hacker News 의견

     * E 시리즈의 숫자 패턴 이해: E 시리즈의 숫자 패턴을 이해하게 해준 부분임. 10, 15, 22, 33, 47, 68 등의 값이 20% 오차 범위 내에서 반복됨.
     * E12 표준: E12 표준은 E6 표준의 값에 6개의 추가 값을 더해 10% 오차 범위로 줄임. 10, 12, 15, 18, 22, 27, 33, 39, 47, 56, 68, 82 등의 값이 있음.
     * 오차 중첩 개념: 오차 중첩 개념이 숫자를 설명하는 데 중요한 역할을 함. 이 개념이 명확하게 설명된 적은 드뭄.
     * 위키피디아 표: 위키피디아에 E 시리즈 값의 표가 있으며, 이를 출력해 작업대 위에 걸어둠.
     * E96 시리즈 저항기: 요즘 E96 시리즈 저항기는 쉽게 구할 수 있고 저렴함. 더 높은 정밀도가 필요하다면 전자공학에 대해 잘 모르거나 매우 잘 아는 것임.
     * ISO 3 표준: 이 표준이 ISO 3으로 채택된 것이 놀라움. 심슨 가족의 농담을 떠올리게 함.
     * 저항기 값 설명 요청: 마지막 단락의 설명 요청. 70옴 저항기를 찾는 예시에서 68옴과 75옴이 약간 차이가 나며, 33옴과 47옴 저항기를 사용하라는 결론이 이해되지 않음.
     * UI/그래픽 작업에 유용: 이러한 값들이 UI/그래픽 작업에서도 유용할 수 있으며, 수학/코드가 매우 간단함.
     * 기하급수적 수열: 이 기사는 기하급수적 수열을 10진수 값에 맞게 정의한 것임.
     * 전자 부품 경험: 전자 부품을 오래 다뤄본 사람에게는 이러한 값들이 이상하지 않음. 오히려 기대되는 값임.
     * 47옴 저항기: 47옴 저항기가 왜 그렇게 흔한지 항상 궁금했음. HeathKit 내부의 노란색과 보라색 줄무늬 생물체를 떠올리게 함.
     * 저항기의 전력 등급 표시: 저항기 패키지에 전력 등급이 항상 표시되지 않는 이유가 궁금함.
     * 관련 계산기: E12 (및 기타) 저항기 시리즈에서 목표 저항 값을 맞추기 위한 저항기 쌍을 빠르게 계산해주는 도구가 있음.
"
"https://news.hada.io/topic?id=15264","제가 가장 좋아하는 1980년대 캐나다 TV 프로그램: Bits and Bytes","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             제가 가장 좋아하는 1980년대 캐나다 TV 프로그램: Bits and Bytes

내가 좋아하는 1980년대 캐나다 TV 쇼: Bits and Bytes

  컴퓨터 사용법을 일반인에게 설명하는 것에 대한 반성

     * Bits & Bytes는 1980년대 캐나다의 TV 쇼로, 컴퓨터 사용법을 일반인에게 설명하는 프로그램임
     * 이 프로그램은 컴퓨터가 어떻게 작동하는지보다는, 일상적인 용도로 컴퓨터를 사용하는 방법을 가르치는 데 중점을 둠
     * 주인공 Billy Van은 컴퓨터에 대해 아무것도 모르는 일반인을 대표하며, Luba Goy가 그에게 컴퓨터 사용법을 설명함

  Bits & Bytes의 매력

     * 높은 이해 수준: 오늘날과 비교했을 때, 이 프로그램은 일반인이 이해할 수 있는 수준을 높게 설정함
     * 상세한 설명: 단순히 버튼을 누르는 방법을 설명하는 것이 아니라, 컴퓨터 시스템이 어떻게 작동하는지에 대한 기본적인 모델을 제공함
     * 예시: 오디오 카세트 테이프에서 비디오 게임을 로드하는 과정을 통해, 바이너리 코드와 데이터 저장 방식을 설명함

  Richard Feynman의 기술적 설명에 대한 견해

     * Feynman은 일반인이 기술적인 내용을 이해할 수 없다는 생각이 위험하다고 주장함
     * 좋은 설명의 기준: 전문가조차도 이해할 수 없는 설명은 좋지 않음
     * Bits & Bytes의 장점: 단순한 비유를 사용하더라도, 기본적인 진리를 전달하며, 시청자가 시스템을 이해할 수 있도록 도움

  현대의 설명 방식에 대한 제언

     * 단순화하지 말 것: 복잡한 기술적 내용을 설명할 때, 단순화하려는 유혹을 저항해야 함
     * 자신의 모델 사용: 전문가가 시스템을 예측하거나 디버깅하는 방식으로 설명을 시작하고, 이를 비유로 표현함
     * 평균적인 사람의 이해 능력: 오늘날의 사람들은 충분히 동기부여가 된다면 복잡한 기술적 내용을 이해할 수 있음

  GN⁺의 의견

     * 기술적 이해의 중요성: 일상적으로 사용하는 기술에 대한 기본적인 이해는 문제 해결과 예측에 도움을 줌
     * 교육의 접근 방식: Bits & Bytes처럼 상세하고 정직한 설명은 기술적 이해를 높이는 데 효과적임
     * 현대 기술 교육: 오늘날의 기술 교육에서도 복잡한 내용을 단순화하지 않고, 기본 모델을 제공하는 접근이 필요함
     * 기술적 호기심 장려: 기술적 호기심을 장려하고, 질문에 대한 정직한 답변을 제공하는 것이 중요함

        Hacker News 의견

     * Luba Goy: 캐나다의 스케치 코미디언으로 알려진 Luba Goy가 컴퓨터에 관한 진지한 쇼를 진행하는 모습이 충격적임.
     * 영국의 컴퓨터 프로그램: 영국에서는 ""The Computer Programme""과 ""Making the Most of the Micro""라는 프로그램이 있었음.
     * Dotto's Data Cafe: 1990년대 캐나다 TV 쇼인 ""Dotto's Data Cafe""를 기억함.
     * Octo-puce: 프랑스 캐나다 버전의 쇼 ""Octo-puce""도 있었음.
     * ZeD: CBC의 ""ZeD""라는 쇼는 사용자 생성 콘텐츠를 다루었으며, 유튜브가 등장하기 전부터 '인터랙티브 웹사이트'를 운영했음.
     * Jim Butterfield: Commodore 64와 관련된 Jim Butterfield의 비디오 시리즈가 있음.
     * Spark: CBC 라디오에서 ""Spark""라는 기술과 문화를 다루는 프로그램이 여전히 방송 중임.
     * 브라질 방송: 브라질에서 자라면서 더빙된 컴퓨터 쇼를 보았으며, 당시 브라질에서는 TRS, Sinclair, Apple II 호환 컴퓨터가 주로 사용되었음.
     * Computer Chronicles: 많은 사람들이 이미 알고 있는 ""Computer Chronicles""는 유튜브와 인터넷 아카이브에서 볼 수 있으며, 한 발표자는 '필요했던 빌 게이츠'로 불림.
     * Jim Butterfield의 기여: Jim Butterfield가 이 비디오 시리즈의 컨설턴트로 참여했음.
"
"https://news.hada.io/topic?id=15238","톰 7: Badness 0 (세 가지 방법)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        톰 7: Badness 0 (세 가지 방법)

Badness 0 (세 가지 방법)

  방법 1과 2: Knuth 버전과 Epsom 버전 읽기

     * SIGBOVIK 2024의 논문에 포함됨.
     * ""BUG""로 인해 Chrome에서만 제대로 표시됨.
     * ""BUG"" 수정 중이며, 블로그의 도움으로 해결책을 찾고 있음.

  방법 3 (추천): 4k, 60Hz의 깜빡이는 불빛 즐기기

     * Badness 0 (Apostrophe‛s 버전)은 Main Sequence의 최신 버전임.

  방법 4: 소스 코드 직접 경험하기

     * 소스 코드는 GPL (COPYING) 또는 GJPL (JCOPYING) 라이선스 하에 제공됨.
     * 컴파일 및 사용에 대한 노트를 추가할 예정임.

  추가 정보

     * YouTube 채널 Suckerpinch에 다양한 비디오가 있음.
     * 블로그나 Mastodon (@tom7)에서 댓글 남길 수 있음.
     * 모든 Tom 7의 콘텐츠는 tom7.org에서 확인 가능함.

GN⁺의 의견

     * 기술적 배경: SIGBOVIK는 유머와 패러디를 포함한 컴퓨터 과학 논문을 발표하는 학회임.
     * 흥미로운 점: ""BUG"" 문제를 해결하는 과정에서 커뮤니티의 도움을 받는 모습이 흥미로움.
     * 비판적 시각: Chrome에서만 제대로 표시되는 문제는 사용자 경험을 저해할 수 있음.
     * 관련 제품: 비슷한 프로젝트로는 ""Project Euler""가 있으며, 이는 수학적 문제를 해결하는 데 중점을 둠.
     * 기술 도입 고려사항: 새로운 기술이나 오픈소스를 도입할 때는 라이선스 조건과 호환성을 반드시 확인해야 함.

        Hacker News 의견

     * Tom7은 내가 가장 좋아하는 콘텐츠 제작자임. 그의 프로젝트는 마치 석사 논문 같은 비디오 논문임. 그의 작업을 모른다면, 시간을 내서 다른 비디오도 보길 추천함. 모두 훌륭해서 특정 비디오를 추천하지 않겠음. Tom7, 무료 교육과 엔터테인먼트에 감사함. 당신은 영감임.
     * Tom7의 비디오는 겸손하게 만드는 천재적인 작품임. 그를 알게 된 것만으로도 더 똑똑한 사람들의 비밀 클럽에 들어간 느낌임.
     * (논문을 읽었고, 비디오는 보지 않았음) 나는 54세의 컴퓨터 과학 학부생임. Curry-Howard에 대해 잘 모르지만, 이 논문은 나를 기쁘게 했음. Knuth도 비슷한 기쁨을 줌, 비록 그의 글을 대부분 이해하지 못하지만. 이 논문은 나에게 미래의 '진지한' 소프트웨어에 이스터에그 성취 시스템을 구현하도록 영감을 줌.
     * 이 사람은 대단함. 내가 가장 좋아하는 그의 비디오는 NES가 SNES 게임을 플레이하는 비디오임.
     * 이 사람에 대해 들어본 적이 없어서 SNES에서 NES로 변환하는 비디오를 봤음. 와우!! 원래의, 진정으로 재미있고 (인종차별적/성차별적 농담이 아닌) 명백히 지적인 사람들이 있다는 것을 보는 것은 멋진 일임. 매우 영감을 주는 사람과 비디오임. 이 토끼굴을 즐길 예정임.
     * 마지막의 훌륭한 펀치라인만으로도 볼 가치가 있음.
     * 이 페이지에는 이 비디오가 무엇에 관한 것인지에 대한 정보가 없음.
     * Lorem Ipsum을 어떻게 얻을 수 있는지 궁금함.
     * 이곳의 재능의 깊이는 믿기 어려움. Tom에게 감사함.
     * 하이퍼 디테일 지향 비디오에서 화면의 텍스트가 ""이것은 가장 아름다운 ____""이라고 할 때, 음성 해설이 ""이것은 가장 아름다운 ____""이라고 말하는 것을 지적한 것에 대해 내가 이기는 것인지 궁금함. (이것이 오류인지, 농담의 일부인지, 아니면 내가 이해할 수 없는 방식으로 해석되는 것인지 확실하지 않음.)
"
"https://news.hada.io/topic?id=15232","지구 대부분 생명체, 'emergency brake' 작동 후 휴면 상태","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                지구 대부분 생명체, 'emergency brake' 작동 후 휴면 상태

지구상의 대부분의 생명체는 '비상 브레이크'를 당긴 후 휴면 상태에 있음

  소개

     * 연구자들이 최근 자연 단백질인 Balon을 발견했음.
     * Balon은 세포의 단백질 생산을 급격히 중단시키는 역할을 함.
     * 이 단백질은 북극 영구 동토층에서 동면하는 박테리아에서 발견되었지만, 다른 많은 생명체에서도 발견될 수 있음.

  휴면 상태의 중요성

     * 많은 생명체는 어려운 환경에서 살아남기 위해 활동을 중단하고 휴면 상태에 들어감.
     * 휴면 상태는 생명체가 에너지를 절약하고 생존할 수 있게 함.
     * 지구상의 60%의 미생물이 언제든지 휴면 상태에 있음.

  Balon의 발견

     * Balon은 세포의 리보솜을 중단시키는 새로운 방식으로 작동함.
     * 이 단백질은 리보솜의 A 사이트에 결합하여 단백질 생산을 즉시 중단시킴.
     * Balon은 리보솜의 활동을 빠르게 중단시키고 다시 활성화할 수 있는 능력을 가짐.

  Balon의 작동 원리

     * Balon은 리보솜의 A 사이트 근처에 결합하여 단백질 생산을 중단시킴.
     * 이 단백질은 다른 휴면 인자들과 달리 리보솜이 활동 중일 때도 결합할 수 있음.
     * Balon은 다양한 박테리아에서 발견되었으며, 이는 이 단백질이 매우 흔하다는 것을 의미함.

  모든 생명체의 휴면 상태

     * 모든 생명체는 휴면 상태에 들어갈 수 있는 능력을 가짐.
     * 인간의 난자, 줄기세포 등도 휴면 상태에 들어가 적절한 시기에 활성화됨.
     * 휴면 상태는 생명체가 환경 변화에 대응하고 생존할 수 있게 하는 중요한 전략임.

GN⁺의 의견

     * Balon의 발견: Balon은 세포의 휴면 상태를 이해하는 데 중요한 단서를 제공함. 이는 생명체가 극한 환경에서 어떻게 생존하는지 이해하는 데 도움이 됨.
     * 기술적 응용: Balon의 메커니즘을 이용해 기후 변화에 견딜 수 있는 생명체를 개발할 수 있는 가능성이 있음.
     * 연구의 중요성: 이 연구는 생명체의 휴면 상태에 대한 새로운 시각을 제공하며, 이는 생명과학 연구에 큰 영향을 미칠 수 있음.
     * 비판적 시각: Balon이 모든 생명체에 적용될 수 있는지에 대한 추가 연구가 필요함. 특정 박테리아에서만 발견된 단백질이기 때문에 일반화하기 어려울 수 있음.
     * 관련 기술: 유사한 기능을 가진 다른 단백질이나 메커니즘을 연구하여 Balon의 역할을 비교하고 이해하는 것이 중요함.

        Hacker News 의견

     * 사고로 인한 발견: 혁신과 발견이 종종 사고로 이루어짐을 보여주는 이야기임.
     * 인간의 동면: 인간도 과거에 동면을 할 수 있었음을 상기시킴.
     * 탈수: 탈수 상태에 대한 언급임.
     * 죽음의 철학: ""영원히 누워 있을 수 있는 것은 죽지 않는다""는 철학적 인용임.
     * 게으른 평가: 자연의 게으른 평가 메커니즘을 보여줌.
     * 수면의 연결성: 수면이 지구상의 모든 생명체와 연결된 과정으로 볼 수 있음.
     * 미생물의 동면: 북극 영구 동토층에서 잠들어 있는 미생물들이 깨어나는 것을 생각하기 싫어함.
     * 화성 생명체: 화성의 생명체가 이런 메커니즘을 사용했을 가능성을 상상함.
     * 동면 투자: 사람들이 몸을 얼려 더 나은 세상에서 깨어나는 것을 상상하며, 그런 회사에 투자하고 싶어함.
     * 치료 가능성: 세균 감염이나 종양을 동면 상태로 만들 수 있는 치료 가능성에 대한 언급임.
     * 복잡한 시스템: 복잡한 시스템에서 일부가 아무것도 하지 않는 것이 전체 시스템을 유지하는 데 필수적임을 강조함.
"
"https://news.hada.io/topic?id=15279","HN 공개: {user}.at.hn에서 Markdown HN 프로필 제공","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                HN 공개: {user}.at.hn에서 Markdown HN 프로필 제공

Hacker News 프로필을 더 풍부하게 표시하는 방법

  Hacker News 프로필 설정 방법

     * Hacker News 프로필을 더 풍부하게 표시하는 방법: {your username}.at.hn을 프로필의 'about' 섹션에 붙여넣음.
     * 적용 방법: https://{username}.at.hn?refresh 링크로 이동하여 새로고침.
     * 캐싱 문제: HN과 캐싱 문제로 인해 몇 분 정도 기다려야 할 수도 있음.

  Markdown 사용

     * Markdown 사용: Markdown을 사용하여 프로필을 더 보기 좋게 꾸밀 수 있음.
     * 기여 방법: GitHub에서 PR(풀 리퀘스트)을 제출하여 기여 가능.

  링크 정책

     * 링크 정책: Karma가 200 이상인 경우를 제외하고, 외부 링크는 rel=nofollow 속성이 적용됨 (스팸 방지 목적).

  예시

     * 예시 확인: padolsey.at.hn에서 예시 확인 가능.

  제작자 정보

     * 제작자: James @padolsey
     * 기여: GitHub에서 기여 가능.

GN⁺의 의견

     * Hacker News 사용자들에게 유용함: 프로필을 더 매력적으로 꾸밀 수 있는 방법을 제공하여 사용자 경험을 향상시킴.
     * Markdown 활용: Markdown을 사용하여 프로필을 꾸미는 것은 초급 소프트웨어 엔지니어에게도 쉽게 접근 가능함.
     * 기여 문화: GitHub에서 PR을 통해 기여할 수 있는 기회를 제공하여 오픈소스 커뮤니티의 참여를 장려함.
     * 링크 정책: 스팸 방지를 위한 rel=nofollow 정책은 커뮤니티의 질을 유지하는 데 도움을 줌.
     * 기술적 배경 지식: 캐싱 문제와 같은 기술적 배경 지식을 이해하는 데 도움이 됨.

        Hacker News 의견

     * OnlyFans 사용자들이 새로운 ""소셜"" 플랫폼을 홍보할 수 있다는 점을 주의해야 함.
     * dang이라는 사용자가 프로필 페이지에 슬러그가 없는데도 페이지가 존재함.
     * HN 댓글을 블로그 형태로 변환하는 것을 고려 중이며, 이를 소액의 비용으로 제공할 수 있는 서비스가 필요함.
          + GitHub 링크
     * 도메인의 가용성에 의해 주도되는 공유가 많아 흥미로운 현상임.
     * 프로필에서 URL이 제대로 링크로 변환되지 않는 인코딩 문제와 PGP 서명이 유효하지 않음.
          + Mike Cardwell 프로필
     * 마우스 휠 클릭으로 자바스크립트 경고창을 띄울 수 있음.
     * 내부 서버 오류 34를 처음 경험함.
     * 바이오에 슬러그를 추가하는 방식으로 옵트인하는 것이 사람들의 동의를 존중하고 서비스 광고에도 효과적임.
     * 사용자 이름에 밑줄이 포함되어 있어 표시되지 않음.
     * 대문자와 함께 작동하지 않으며, 내부 서버 오류 34가 발생함.
"
"https://news.hada.io/topic?id=15296","의료 사건 후 더 이상 말할 수 없는 Noam Chomsky","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   의료 사건 후 더 이상 말할 수 없는 Noam Chomsky

노엄 촘스키, 95세, 건강 악화로 더 이상 대화 불가

  촘스키의 건강 상태

     * 노엄 촘스키는 95세로, 최근 건강 악화로 인해 더 이상 대화가 불가능해짐.
     * 촘스키는 작년 6월 이후로 공공장소에 나타나지 않았음.
     * 그의 전 비서인 베브 스톨(Bev Stohl)에 따르면, 촘스키는 건강 문제로 이메일이나 인터뷰에 응답하지 못하고 있음.

  촘스키의 공백

     * 촘스키는 팔레스타인 지지와 이스라엘 국가의 ""범죄""에 대해 목소리를 높여왔음.
     * 그러나 지난 1년 동안 관련 시위나 토론에 참여하지 못하고 있음.

  건강 상태의 세부 사항

     * 스톨은 촘스키가 더 이상 이동할 수 없고, 말하는 것도 어려워졌다고 밝힘.
     * 촘스키는 통증 없이 주변 상황을 지켜보고 있음.

  촘스키의 영향력

     * 촘스키는 70년 넘게 언어와 소통 연구에 헌신해왔음.
     * 많은 사람들이 촘스키의 열정과 친절함에 감사를 표하고 있음.
     * 촘스키는 모든 사람을 동등하게 대하며, 잔인함과 불의를 공격하는 데 헌신해왔음.

GN⁺의 의견

     * 촘스키의 영향력: 노엄 촘스키는 언어학과 정치학에서 큰 영향을 미친 인물로, 그의 부재는 학계와 사회에 큰 공백을 남길 것임.
     * 건강 문제: 고령의 학자들이 겪는 건강 문제는 그들의 연구와 활동에 큰 영향을 미침. 이는 학계와 사회가 이들의 건강을 지원하는 시스템을 고민해야 함을 시사함.
     * 팔레스타인 지지: 촘스키의 팔레스타인 지지는 많은 사람들에게 영감을 주었으며, 그의 부재는 이 문제에 대한 논의에도 영향을 미칠 수 있음.
     * 미래의 연구: 촘스키의 연구와 저작은 앞으로도 많은 사람들에게 영향을 미칠 것이며, 그의 업적을 이어받아 연구를 지속하는 것이 중요함.

        Hacker News 의견

     * Chomsky의 건강 문제로 인해 활동이 줄어들었음: Chomsky는 건강 문제로 인해 활동이 줄어들었지만, 젊은 사람들에게 세계의 문제를 알리기 위해 노력했음.
     * Noam Chomsky에 대한 존경: Chomsky는 진실을 추구하며, 지적 맹점을 인정하는 지성인의 표본임.
     * Chomsky와의 토론 경험: Google에서 Chomsky와의 내부 발표에서, 그는 존중을 유지하면서도 상대방의 논리를 무너뜨렸음.
     * Chomsky와 Foucault의 토론: Chomsky와 Foucault의 토론 영상 링크를 공유함.
     * Chomsky의 접근성: Chomsky에게 이메일로 질문을 했을 때, 답장을 받았다는 경험을 공유함.
     * Chomsky와 Foucault의 토론에 대한 사랑: Chomsky와 Foucault의 토론을 좋아하며, 그들의 토론 방식에 감탄함.
     * Chomsky의 방대한 작업량: Chomsky가 95년 동안 쓴 논문, 에세이, 책, 기사, 인터뷰의 양이 엄청남.
     * Chomsky의 반대 의견: Chomsky의 모든 의견에 동의하지는 않지만, 그의 작업이 Edward Bernays의 ""The Engineering of Consent""의 추종자들에게 좋은 균형을 제공함.
     * Chomsky의 목소리 상실에 대한 슬픔: Chomsky와 같은 지성인의 목소리를 잃은 것이 슬프며, 세상에는 더 많은 Chomsky가 필요함.
     * Chomsky의 인터뷰를 그리워함: Chomsky의 다양한 포럼에서의 인터뷰와 Democracy Now에서의 출연을 그리워함.
     * Chomsky의 논란: 처음에는 Chomsky의 발언이 흥미로웠지만, 시간이 지나면서 그는 언어학자이지 역사학자나 정치학자가 아님을 깨달음.
     * ChatGPT에 대한 Chomsky의 발언: Chomsky가 ChatGPT를 ""표절 소프트웨어""라고 부른 것이 매우 간결한 표현이었음.
"
"https://news.hada.io/topic?id=15253","유전자 치료로 유전성 난청 아동 청력 회복","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        유전자 치료로 유전성 난청 아동 청력 회복

유전자 치료로 유전성 난청 아동의 청력 회복

  유전자 치료의 성공

     * 첫 번째 임상 시험에서 유전자 치료를 양쪽 귀에 시행하여 유전성 난청을 가진 5명의 아동의 청력을 회복함.
     * 두 명의 아동은 음악을 감상하는 능력까지 얻음.
     * 연구 결과는 _Nature Medicine_에 발표됨.

  연구 결과의 중요성

     * 연구 공동 저자인 Zheng-Yi Chen은 ""치료받은 아동의 청력 능력이 극적으로 향상되었고, 양쪽 귀에 유전자 치료를 시행했을 때 소리의 위치를 파악하고 소음이 많은 환경에서의 언어 인식이 개선됨""을 강조함.
     * 연구의 주 저자인 Yilai Shu는 ""양쪽 귀의 청력을 회복시키는 것이 청력 회복의 최대 이점을 제공함""을 언급함.

  DFNB9 유전성 난청

     * 연구에 참여한 아동들은 DFNB9이라는 유전성 난청을 가지고 있었음.
     * DFNB9은 OTOF 유전자의 돌연변이로 인해 발생하며, 이는 내이의 털 세포에서 청각 신경으로의 소리 전달을 크게 감소시킴.

  유전자 치료 방법

     * 최소 침습 수술을 통해 아동의 내이에 기능하는 OTOF 유전자를 전달하는 아데노-연관 바이러스(AAV)를 주입함.
     * 5명의 아동은 13주 또는 26주 동안 관찰되었으며, 청력 회복과 언어 인식, 소리 위치 파악 능력이 크게 개선됨.

  부작용 및 안전성

     * 추적 관찰 중 36건의 부작용이 관찰되었으나, 대부분 백혈구 수 증가와 콜레스테롤 수치 증가였음.
     * 심각한 부작용이나 용량 제한 독성은 없었음.
     * 연구진은 유전자 치료가 ""실현 가능하고, 안전하며, 효과적""임을 강조함.

GN⁺의 의견

     * 임상 시험의 중요성: 이 연구는 유전자 치료가 유전성 난청 치료에 실질적인 해결책이 될 수 있음을 보여줌.
     * 기술의 발전: 유전자 치료 기술의 발전으로 인해 다양한 유전 질환 치료에 대한 가능성이 열림.
     * 부작용 관리: 부작용이 존재하지만, 심각하지 않다는 점에서 유전자 치료의 안전성이 입증됨.
     * 미래의 연구 방향: 더 큰 규모의 국제적 임상 시험이 필요하며, 이를 통해 치료의 효과와 안전성을 더욱 확립할 필요가 있음.
     * 기술 도입 고려사항: 유전자 치료를 도입할 때는 비용, 접근성, 장기적인 효과 등을 고려해야 함.

        Hacker News 의견

     * 기술의 기적성: 최소 침습 수술을 통해 AAV 바이러스를 이용해 인간 OTOF 유전자를 전달하는 기술이 놀라움.
     * 음악 감상 능력: 두 명의 아이들이 음악을 감상할 수 있게 되었음. 나머지 세 명은 여전히 음악에 무관심한지 궁금함.
     * OTOF 유전자 치료의 놀라움: OTOF 유전자 치료에 참여한 사람을 만났고, 그 기술이 정말 놀라움.
     * 개인적인 경험: 유전자 관련 질환을 가진 부부로서, OTOF 성공 사례가 희망을 줌. 바이러스를 이용해 유전자를 전달하는 기술이 미래적임.
     * 비유전성 청각 손실 치료: 비유전성 청각 손실이 두 세대 후에 치료될 가능성이 있음. 중국 연구소의 성공 사례가 흥미로움.
     * 전체 유전체 시퀀싱: 개인 컴퓨터에서 전체 유전체 시퀀싱을 할 수 있다는 사실이 미래를 실감하게 함.
     * 청각 장애인 커뮤니티의 반응: 청각 장애를 ""고치는"" 것에 대한 저항이 있을 수 있음. 이는 문화와 커뮤니티의 일부로 여겨질 수 있음.
     * 유전자 치료의 발전: 유전자 치료가 잘 진행되고 있음. 큰 유전자를 바이러스에 넣는 것이 어려움.
     * 새로운 감각의 획득: 새로운 감각을 얻는 것은 흥미롭고 무서울 것 같음.
     * 기술 스타트업의 본질: 이런 기술이 진정한 기술 스타트업의 본질을 보여줌.
     * 성인 DNA 변형의 어려움: 성인의 모든 세포에 영구적인 돌연변이를 도입하는 것이 유전자 편집의 성배처럼 보임.
     * 청력 회복의 정도: 청력 회복의 정도가 꽤 좋음. 실제로 얼마나 회복되었는지 궁금함.
     * 이명 치료 가능성: 이명을 치료할 가능성에 대해 궁금함.
"
"https://news.hada.io/topic?id=15241","아폴로 8 우주비행사 윌리엄 앤더스, 워싱턴주 비행기 추락 사고에서 신원 확인","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              아폴로 8 우주비행사 윌리엄 앤더스, 워싱턴주 비행기 추락 사고에서 신원 확인

윌리엄 앤더스, 아폴로 8 우주비행사, 산후안 제도 비행기 추락 사고로 사망

  윌리엄 앤더스, WA 비행기 추락 사고로 사망

     * 윌리엄 앤더스: 아폴로 8 우주비행사였던 윌리엄 앤더스가 산후안 제도 근처에서 비행기 추락 사고로 사망함.
     * 사고 비행기: 추락한 비행기는 앤더스가 소유한 빈티지 공군 T-34 멘토 비행기였음.
     * 파일럿: 앤더스가 직접 비행기를 조종하고 있었음.
     * 가족의 반응: 아들 그렉 앤더스는 ""가족이 큰 충격을 받았다""며 아버지를 그리워할 것이라고 전함.

  오르카스 섬 근처에서 발생한 작은 비행기 추락 사고 영상

     * 사고 대응: 미국 해안경비대 태평양 북서부 지부는 사고가 오전 11시 45분 전에 오르카스 섬 근처에서 발생했다고 발표함.

  윌리엄 앤더스의 초기 생애

     * 출생: 1933년 10월 17일 홍콩에서 태어남.
     * 학력: 1955년 미국 해군사관학교에서 과학 학사 학위, 1962년 공군기술연구소에서 원자력 공학 석사 학위를 받음. 1979년 하버드 경영대학원 고급 경영 프로그램을 수료함.

  NASA에 의해 선발됨

     * 선발: 1964년 NASA에 의해 우주비행사로 선발됨.
     * 책임: 방사선 측정, 방사선 영향 및 환경 제어를 담당함.
     * 임무: 제미니 XI, 아폴로 11의 백업 파일럿이었으며, 아폴로 8의 달 착륙 모듈 파일럿이었음.

  아폴로 8 임무

     * 임무 수행: 1968년 아폴로 8 임무를 수행하며 6,000시간 이상의 비행 시간을 기록함.
     * 업적: 달 표면 위를 떠다니며 지구와 달의 이미지를 전송하고, 창세기를 낭독함.
     * 지구돋이 사진: 앤더스가 촬영한 ""지구돋이"" 사진은 인류에게 새로운 시각을 제공함.

  윌리엄 앤더스의 은퇴

     * 은퇴: 1988년 공군 예비군에서 은퇴하고, 1991년 제너럴 다이내믹스의 회장 겸 CEO가 됨.
     * 재단 설립: 은퇴 후 앤더스 재단을 설립하여 교육 및 환경 문제를 지원함.
     * 항공 박물관: 1996년 헤리티지 비행 박물관을 설립하여 현재 스카짓 지역 공항에 위치함.

GN⁺의 의견

     * 우주 탐사의 중요성: 앤더스의 업적은 우주 탐사의 중요성을 다시 한 번 상기시켜줌. 그의 ""지구돋이"" 사진은 환경 보호의 중요성을 일깨워줌.
     * 비행 안전: 이번 사고는 비행 안전의 중요성을 강조함. 특히 빈티지 비행기의 유지보수와 안전 점검이 중요함.
     * 가족과의 유대: 앤더스의 가족이 그의 유산을 이어받아 항공 박물관을 운영하는 모습은 감동적임. 이는 가족의 유대와 열정을 보여줌.
     * 기술 발전: 앤더스의 경력은 기술 발전과 교육의 중요성을 보여줌. 그의 학력과 경력은 젊은 엔지니어들에게 영감을 줄 수 있음.

        Hacker News 의견

     * William Anders가 찍은 Earthrise 사진은 ""가장 영향력 있는 환경 사진""으로 평가받음.
     * 자신의 방식대로 인생을 살고 결과를 받아들이는 사람으로, 그날 죽을 줄은 몰랐지만 인생을 제한하지 않았음.
     * 90세에 혼자 비행기를 조종한 전설적인 파일럿이었음.
     * 사고 난 비행기는 Beechcraft T-34 Mentor라는 군용 훈련기였음.
     * 고의로 비행 묘기를 했는지, 조종을 잃었는지는 불명확하지만, 그 나이에 혼자 비행한 것 자체가 전설적임.
     * Anders는 Earthrise 사진에 대해 ""달을 탐험하러 갔지만 가장 중요한 발견은 지구였다""고 말했음.
     * 코스타리카에서 두 아들과 함께 카약을 즐기는 모험적인 가족이었음.
     * 사고 영상이 TikTok에 올라와 있어, 사고 원인을 궁금해하는 사람들에게 도움이 될 수 있음.
     * Apollo 8의 업적은 Earthrise 사진보다 더 대단함. 첫 유인 Saturn V 비행, 지구 궤도를 벗어난 첫 유인 우주선, 달 궤도에 진입한 첫 유인 우주선, 달의 뒷면을 본 첫 인간, 당시 가장 많이 시청된 생방송 등 다양한 기록을 세움.
     * 91세에 제트기를 조종하다가 사망한 것은 정말 대단한 일임.
"
"https://news.hada.io/topic?id=15274","생물학 혁명?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                생물학 혁명?

생물학의 혁명

  I. 미스터리: 하나의 세포가 어떻게 인간이 되는가

     * 주제: 생물학의 큰 미스터리 중 하나는 단일 수정란이 어떻게 복잡한 인간의 몸으로 발전하는지에 대한 것임.
     * 문제: 세포들이 어떻게 위치를 조정하고, 뇌를 구성하며, 각 세포가 어떤 역할을 할지 결정하는지 이해하는 것이 어려움.
     * 기존 관점: 유전자와 화학적 경로가 생물체의 고수준 구조를 결정한다고 생각해왔음.
     * Michael Levin의 주장: 유전자만으로는 충분하지 않으며, 생물학적 발전을 이해하고 개입하기 위해서는 더 높은 수준의 추상화가 필요함. 이를 위해 생체 전기 네트워크가 중요함.

  II. 생체 전기: 두 개로 나뉘는 벌레

     * 생체 전기 네트워크: 신경 세포뿐만 아니라 모든 세포가 전기적 패턴을 통해 소통함.
     * 플라나리아: 이 벌레는 몸이 잘려도 재생할 수 있으며, 생체 전기 네트워크가 중요한 역할을 함.
     * 실험 결과: Levin의 팀은 특정 약물을 사용해 벌레가 두 개의 머리를 가지도록 유도함. 유전자를 수정하지 않고도 이러한 변화를 이끌어냄.
     * 의의: 생체 전기 코드를 이해하면 새로운 신체 구조를 만들 수 있음.

  III. 프랙탈 지능: 프랙탈 창의성

     * 지능의 확장: Levin은 지능과 인지라는 개념이 생물학의 더 많은 부분에 적용될 수 있다고 주장함.
     * 적응성: 생물학적 시스템은 목표 상태를 향해 적응하며 발전함.
     * 창의성: Levin의 팀은 개구리의 피부 세포를 이용해 자가 복제하는 생체 로봇을 만듦.
     * 미래 전망: 작은 생체 로봇이 암세포를 공격하거나 환경 독소를 정화하는 등 다양한 응용 가능성이 있음.

GN⁺의 의견

     * 흥미로운 점: Levin의 연구는 유전자 외에도 생체 전기 네트워크가 생물학적 발전에 중요한 역할을 한다는 점에서 혁신적임.
     * 실용적 응용: 이 연구는 손상된 장기 재생, 암 치료 등 다양한 의료 분야에 큰 영향을 미칠 수 있음.
     * 윤리적 문제: 새로운 생체 구조를 만드는 과정에서 윤리적 문제를 고려해야 함.
     * 기술 도입 고려사항: 생체 전기 네트워크를 조작하는 기술은 아직 초기 단계이므로, 안전성과 효과를 충분히 검증해야 함.
     * 관련 기술: 유전자 편집 기술인 CRISPR와 비교해 생체 전기 네트워크 조작이 더 높은 수준의 제어를 제공할 수 있음.

        Hacker News 의견

     * Michael Levin의 연구는 Humberto Maturana의 자가생성과 Nick Lane의 프로톤 펌핑 개념에 근접함. 자가생성은 구조의 세부 사항보다 관계의 보존이 중요함을 강조함. Nick Lane은 DNA보다 생물에너지학과 막을 통한 프로톤 펌핑을 중시함.
     * 나무를 프로그래머블 셀룰러 오토마타로 시뮬레이션하여 성장시키는 방법을 개발함. 각 셀은 주변 조건과 나이에 따라 복제 등의 작업을 수행함. 더 복잡한 유기체도 이 기술로 성장 가능함.
     * 두 머리를 가진 플라나리아는 유전자가 아닌 분열로 자손을 생산함. 이는 라마르크주의적 사실이 아님. 플라나리아는 성적으로(알과 정자)와 무성적으로(분열) 번식함.
     * 기사 내용이 과장된 면이 있음. 패턴 형성에 전기적 포텐셜이 새로운 연구 영역임. 예를 들어, 과일 파리의 WNT 신호, 팔다리 패턴 형성의 SHH 화학적 기울기 등이 있음. 전기적 탈분극으로 생성되는 패턴이 화학적 상호작용보다 단순할 수 있음.
     * 인간을 만드는 데 필요한 정보는 약 750MB임. 예를 들어, 어깨뼈의 특정한 형태나 거미에 대한 공포 등이 포함됨.
     * 관련 자료로는 ""Computational Boundary of a Self: Bioelectricity and Scale-Free Cognition (2019)"" 등이 있음. 간단한 세포도 문제를 해결할 수 있음.
     * 개구리에게 추가 팔다리를 개발시키거나 장에 눈을 만들 수 있음. 과학의 놀라움과 개구리의 고통에 대한 상반된 반응이 있음.
     * 제목이 부적절함. ""Bioelectric Signals Guide Body Development and Regeneration""이 더 나은 제목임.
     * 암을 세포 그룹의 ""해리성 정체성 장애""로 연구하고, 개미 군락이 ""시각적 착각""에 빠지는 것을 발견함. 개구리 피부 세포로 바이오봇을 만들고, 손상된 뉴런을 치유할 수 있는 인간 바이오봇을 만듦. 이 기사는 신뢰할 수 없으며, 많은 안전 조치가 필요함.
     * 인간 기관지 세포를 사용함. 이는 몸에서 운동성 섬모를 가진 몇 안 되는 조직 중 하나임. 따라서 이동 가능함.
"
"https://news.hada.io/topic?id=15308","mpa-archive - 웹사이트를 zip 으로 만들고, zip파일에서 바로 서빙하는 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           mpa-archive - 웹사이트를 zip 으로 만들고, zip파일에서 바로 서빙하는 도구

     * 다중 페이지 웹앱을 Zip 파일에 크롤링하고 바로 서빙 가능한 Multi-Page Application(MPA) Archiver
     * mpa http://example.net 하면 헤드리스 Puppeteer를 이용하여 재귀적으로 크롤링 ( CPU 수 / 2 개의 쓰레드 사용 )
     * Sitemap을 가져와서 시드포인트로 사용
     * 사이트 URL만 크롤링 하지만, 외부 리소스도 fetch함
     * 사이트의 리소스들을 두 저장
     * mpa/sitemap.txt 와 mpa/sitemap.xml 을 생성함
     * 중단 되면 재시작 가능. URL 250개마다 체크포인트를 저장함
     * SPA의 경우 --spa 옵션으로 원본 HTML을 저장 가능
"
"https://news.hada.io/topic?id=15204","llIlI.lI - I/l 만 사용하는 단축 URL 생성기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    llIlI.lI - I/l 만 사용하는 단축 URL 생성기

     * 모든 URL을 I/l(I 대문자 와 L의 소문자 l) 만 사용해서 단축 URL로 만들어 줌
     * 원 소스코드는 https://github.com/chenxuuu/shit-url (PHP + Nginx + MySQL)

   O와 0만 사용하는 녀석도 만들 수 있겠네요 ㅎㅎ

   이거 보고 만든게 URL을 길게 만드는 L(O*62).ONG 이네요.
   https://loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo.ong/… URL을 사용합니다.
"
"https://news.hada.io/topic?id=15256","GPT-4o는 이미지를 어떻게 인코딩할까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        GPT-4o는 이미지를 어떻게 인코딩할까?

     * GPT-4o는 고해상도 모드에서 사용되는 각 512x512 타일을 처리하는 데 170 토큰을 부과함. 약 0.75 토큰/단어의 비율로 보면 이는 그림 한 장이 약 227 단어와 같다는 것
          + ""그림 한 장이 천 마디 말보다 낫다""는 말과 비교했을 때 약 4배 차이임
     * 170이라는 숫자는 기괴할 정도로 특이한 숫자임. OpenAI는 가격 책정에서 ""20달러"" 또는 ""0.50달러""와 같은 반올림된 숫자나 내부 차원에 2와 3의 거듭제곱을 사용함
     * 170과 같은 숫자를 선택한 이유는 무엇일까? 프로그래밍에서 코드베이스에 설명 없이 그냥 던져진 숫자를 ""매직 넘버""라고 하는데, 170은 상당히 눈에 띄는 매직 넘버임
     * 이미지 비용을 토큰 수로 변환하는 이유는 무엇일까? 단순히 청구 목적이라면 타일당 비용을 나열하는 것이 덜 혼란스러울 것임
     * OpenAI가 170을 선택한 것이 단순히 문자 그대로 사실이기 때문이라면 어떨까? 이미지 타일이 실제로 170개의 연속적인 임베딩 벡터로 표현된다면 어떨까?

임베딩

     * 트랜스포머 모델에 대해 먼저 상기해야 할 점은 이산 토큰이 아닌 벡터에서 작동한다는 것임
          + 입력은 벡터여야 하며, 그렇지 않으면 트랜스포머의 핵심인 내적 유사도가 의미가 없을 것임
          + 토큰의 전체 개념은 전처리 단계임: 텍스트는 토큰으로 변환되고 토큰은 트랜스포머 모델의 첫 번째 레이어에 도달하기 전에 임베딩 모델에 의해 임베딩 벡터로 변환됨
     * 예를 들어, Llama 3은 내부적으로 4,096개의 특징 차원을 사용함
          + ""My very educated mother just served us nine pizzas.""라는 문장을 보면
          + BPE에 의해 10개의 정수 토큰(마침표 포함)으로 변환된 다음, 각각 임베딩 모델에 의해 4,096차원 벡터로 변환되어 10x4096 행렬이 됨
          + 이것이 트랜스포머 모델에 대한 ""진짜"" 입력임
     * 그러나 이러한 벡터가 반드시 텍스트 임베딩 모델에서 나와야 한다는 법칙은 없음
          + 텍스트 데이터에 잘 작동하는 전략이지만, 트랜스포머에 피드하려는 다른 형식의 데이터가 있다면 간단히 다른 임베딩 전략을 사용할 수 있음
     * OpenAI가 2021년에 CLIP 임베딩 모델을 발표했기 때문에 이러한 방향으로 생각하고 있다는 것을 알고 있음
          + CLIP은 텍스트와 이미지를 동일한 의미 벡터 공간에 임베드하여 코사인 유사도를 사용하여 텍스트 문자열과 관련된 이미지나 다른 이미지와 의미적으로 유사한 이미지를 찾을 수 있음
          + 그러나 CLIP은 전체 이미지를 단일 벡터로 임베드하며, 170개는 아님. GPT-4o는 이미지(및 마찬가지로 비디오, 음성 및 기타 종류의 데이터)를 표현하기 위해 내부적으로 다른 고급 전략을 사용해야 함. 그래서 ""omnimodal""인 것임
     * 특히 이미지 데이터에 대해 해당 전략이 뭔지 추론해 보기로 함

특징 차원의 수

     * GPT-4o가 임베딩 벡터를 표현하기 위해 내부적으로 사용하는 차원 수를 추정해 보면 독점적이기 때문에 실제 숫자는 알 수 없지만, 합리적인 가정을 할 수 있음
     * OpenAI는 2의 거듭제곱을 좋아하는 것 같고, 때로는 3의 단일 인수를 혼합함
          + 예를 들어 ada-002 임베딩에는 1,536을, text-embedding-3-large에는 3,072를 사용함
          + GPT-3은 전체적으로 12,288 차원을 사용하는 것으로 알려져 있음
          + GPT-4o는 해당 매개변수를 유지하거나 증가시켰을 가능성이 있음
     * GPT-3에서 GPT-4o로 임베딩 수가 감소했을 것 같지는 않지만 가능함
     * GPT-4 Turbo와 같은 릴리스는 실제로 이전 버전보다 더 빠르고 저렴했으며, 개발자들이 작은 크기가 품질 면에서 동등하게 좋다는 벤치마크 결과를 갖고 있었다면 임베딩 차원 축소가 그 일부였을 수 있음
     * GPT-4o 내부에서 사용되는 특징 차원의 수는 다음 중 하나일 가능성이 높음: 1536, 2048, 3072, 4096, 12228, 16384, 24576
     * GPT-4o가 임베딩 벡터의 차원에 12,228을 사용한다고 가정하겠음. 2 또는 4의 인수만큼 차이가 나더라도 별로 중요하지 않음. 동일한 논증이 적용될 것

이미지 임베딩

     * 이미지 타일은 정사각형이므로 정사각형 토큰 그리드로 표현될 가능성이 높음
          + 170은 13x13에 매우 가까움
          + 추가 토큰은 CLIP와 유사하게 전체 이미지의 gestalt(게슈탈트) 임프레션을 인코딩하는 단일 임베딩 벡터일 수 있음
     * 그렇다면 512x512x3에서 13x13x12228로 어떻게 갈 수 있을까?

  전략 1: 원시 픽셀

     * 이미지를 벡터 공간에 넣는 매우 간단한 방법:
          + 512x512 이미지를 8x8 ""미니 타일"" 그리드로 나눔
          + 각 미니 타일은 64x64x3이며, 12,228 차원의 벡터로 펼침
          + 각 미니 타일은 단일 임베딩 벡터
          + 전체 이미지 타일은 64개의 연속 임베딩 벡터로 표현됨
     * 이 접근 방식에는 두 가지 문제가 있음:
         1. 64 ≠ 170
         2. 매우 멍청함 (raw RGB 값을 사용하여 임베딩하고 transformer가 해결하기를 바라는 것은 이치에 맞지 않음)

  전략 2: CNN

     * 다행히도 이러한 특성을 가진 모델이 이미 존재하며, 10년 이상 이미지 데이터를 성공적으로 처리해 온 실적이 있음: 합성곱 신경망(Convolutional Neural Network)
     * CNN은 translation 및 scale invariance와 같은 특성을 가짐
     * AlexNet과 YOLO는 대표적인 CNN 아키텍처의 예시임
     * CNN은 raw pixel을 semantic vector로 압축하는 깔때기와 같음
     * YOLO는 이미지를 단일 평면 벡터로 줄이지 않고 13x13에서 중지함
          + YOLOv3의 출력은 13x13 그리드에 배치된 169개의 서로 다른 벡터이며, 각각 1,024 차원
     * GPT-4o의 가상 이미지 임베딩 CNN은 이러한 CNN 아키텍처의 형태와 유사할 것으로 예상됨
     * 512x512x3에서 13x13x12228로 가기 위해 표준 CNN 레이어를 사용하는 방법을 제시
          + AlexNet과 유사한 디자인이 이를 우아하게 달성할 수 있음 (5개의 동일한 반복 블록 사용)
          + YOLO와 더 유사한 대안도 있지만 12x12에 도달 (13x13 대신)
     * 증명할 수는 없지만, 이러한 추측적 설계는 이미지를 kxk 임베딩 벡터 그리드로 표현할 수 있는 그럴듯한 CNN 아키텍처가 있음을 보여줌

실험적 검증

     * GPT-4o는 정말 13x13 그리드의 임베딩 벡터를 볼 수 있을까?
     * 테스트하기 위해 Zener 카드에서 영감을 받아 태스크를 고안 : 이미지의 격자에 있는 모든 기호의 색상과 모양을 식별하는 것
     * 간단한 프로그램으로 테스트용 격자 이미지를 생성하고, JSON 배열 형식으로 각 셀의 모양과 색상을 설명하도록 GPT-4o에 프롬프트를 줌
     * 만약 13x13 가설이 맞다면 GPT-4o는 13x13 크기까지는 잘 수행하다가 그 이후로는 성능이 저하될 것으로 예상됨
     * 하지만 실제로는 5x5 격자 이하에서는 완벽한 성능을 보이다가 그 이후부터 급격히 저하됨
          + 7x7 격자에서는 76%의 정확도를 보였고, 13x13 격자에서는 우연 수준의 성능을 보임
     * 이는 169개 토큰이 13x13 격자를 나타낸다는 가설이 잘못되었음을 의미함
          + 그러나 5x5 격자 결과는 GPT-4o가 이미지 내에서 25개의 구별되는 객체와 그 절대 위치를 추적할 수 있음을 시사함
     * 기본 개념은 맞지만 차원을 잘못 파악한 것일 수 있으며, CNN에 계층을 더 추가하여 13x13 대신 5x5로 줄일 수 있을 것임
     * 5x5 격자 이하만 사용한다고 가정할 때 170개 토큰에 도달하기 위해 출력을 어떻게 구조화할 수 있을지 고민해 봐야 함

피라미드 전략

     * 85와 170에 가까운 수를 얻는 한 가지 방법은 이미지를 점점 더 세분화된 수준의 일련의 피라미드처럼 인코딩한다고 가정하는 것임
          + 전체 이미지의 게슈탈트 임프레션을 캡처하기 위해 하나의 임베딩 벡터로 시작하고, 왼쪽/중간/오른쪽과 위/중간/아래를 캡처하기 위해 3x3을 추가한 다음, 5x5, 7x7 등을 추가함
     * 이 전략은 7x7에서 멈출 경우 '마스터 썸네일'에 대해 85 토큰에 매우 근접하게 됨
          + 12+32+52+72=1+9+25+49=84
     * 최종 9x9 그리드를 추가하면 170에 매우 근접함
          + 12+32+52+72+92=1+9+25+49+81=165
     * 512x512 타일에 대해 임시 2x2 그리드를 사용하고 각각에 대해 하나의 특수 <|image start|> 토큰을 가정하면 완벽하게 일치시킬 수 있음
          + 1+12+32+52+72=1+1+9+25+49=85
          + 1+12+22+32+52+72+92=1+1+4+9+25+49+81=170
     * 이 체계는 행의 시작과 끝에 대한 어떤 구분 기호도 없지만, 텍스트 토큰의 위치 정보를 인코딩하는 데 RoPE가 사용되는 것과 유사한 방식으로 2D에서 위치 인코딩으로 처리할 수 있을 것임
     * 위의 내용은 홀수 그리드 크기만 취하고 5x5를 지나치므로 Zener 그리드 성능이 5x5 이후에 떨어지기 시작한다는 증거와 완전히 일치하지는 않음
     * 대안으로 5x5까지 모든 그리드(짝수와 홀수)를 취해볼 수 있음
          + 이 접근법은 55개의 토큰을 제공함: 12+22+32+42+52=55
     * 각 미니 타일당 3개의 토큰과 각 타일 사이에 구분 기호 토큰 1개를 가정하면 170에 도달할 수 있음
          + 3×(12+22+32+42+52)+5=170
     * 수치적 근거에서 완전히 만족스럽지는 않지만 경험적 결과와는 잘 맞음
     * 피라미드 전략은 직관적으로 매우 매력적이며, 서로 다른 확대/축소 수준에서 공간 정보를 인코딩하는 거의 ""명백한"" 방법처럼 느껴짐
          + 이는 5x5 그리드 이하에서는 잘 수행하고 6x6 이상에서는 매우 저조한 이유를 설명할 수 있음
     * 모든 가설이 모든 것을 설명하는 데 매혹적으로 가까워 보이지만 숫자가 결코 깔끔하게 맞아떨어지지 않는 것 같아 괴롭긴 함
          + 그럼에도 불구하고 이러한 피라미드 전략이 내가 생각해낼 수 있는 최선의 방법임

광학 문자 인식(OCR)

     * 위의 가설 중 어느 것도 GPT-4o가 OCR을 수행하는 방법을 설명하지 않음
          + CLIP는 기본적으로 OCR을 매우 잘 수행할 수 없으며, 적어도 큰 텍스트 블록에 대해서는 그렇지 않음
          + (그럼에도 불구하고 GPT-4o가 OCR을 수행할 수 있다는 사실 자체가 상당히 놀라우며, 창발적 능력의 명확한 예시임)
     * GPT-4o는 명백히 고품질 OCR을 수행할 수 있음
          + 긴 텍스트 블록을 전사하고, 필기체 텍스트나 이동, 회전, 투영 또는 부분적으로 가려진 텍스트를 읽을 수 있음
     * 최신 OCR 엔진은 이미지를 정리하고, 문자의 경계 상자와 띠를 찾은 다음, 해당 띠를 따라 한 번에 하나의 문자 또는 단어씩 특수 문자 인식 모델을 실행하기 위해 많은 작업을 수행함
          + 단순히 큰 CNN만 사용하는 것이 아님
     * 이론적으로 OpenAI가 정말 그만큼 뛰어난 모델을 구축했을 수도 있지만, Zener 그리드 작업에서의 상대적으로 약한 성능과는 일치하지 않음
          + 이미지에서 깔끔한 6x6 그리드의 36개 기호를 읽을 수 없다면, 수백 개의 텍스트 문자를 완벽하게 읽을 수는 없을 것임
     * 이 불일치를 설명하기 위한 간단한 이론:
          + OpenAI가 Tesseract와 같은 기성품 OCR 도구(또는 독점적이고 최첨단 도구)를 실행하고 식별된 텍스트를 이미지 데이터와 함께 트랜스포머에 공급한다고 생각함
          + 이는 초기 버전이 이미지에 숨겨진 텍스트에 쉽게 혼동된 이유를 설명할 수 있음 (GPT-4o 관점에서 그 텍스트는 프롬프트의 일부였기 때문)
               o 이는 현재 수정되었으며, GPT-4o는 이미지 내부에 숨겨진 악의적인 프롬프트를 무시하는 데 능숙함
     * 그러나 이는 이미지에서 발견된 텍스트에 대한 토큰 당 요금이 없는 이유를 설명하지 않음
     * 흥미롭게도 텍스트를 이미지로 보내는 것이 실제로 더 효율적임
          + 작지만 읽을 수 있는 글꼴로 된 512x512 이미지에는 400-500개의 텍스트 토큰이 쉽게 들어갈 수 있지만, '마스터 썸네일'에 대한 85개를 더한 170개의 입력 토큰에 대해서만 요금이 부과되어 총 255개 토큰임 (이미지의 단어 수보다 훨씬 적음)
     * 이 이론은 이미지 처리 시 추가 지연이 발생하는 이유를 설명함
          + CNN은 본질적으로 즉각적이지만 제3자 OCR은 추가 시간이 소요될 것임
          + 그런데 (이것이 무언가를 증명한다고 말하는 것은 아니지만) OpenAI 코드 인터프리터에서 사용하는 Python 환경에는 PyTesseract가 설치되어 있음
               o 업로드한 이미지에 대해 PyTesseract를 실행하여 두 번째 의견을 얻도록 요청할 수 있음

결론

     * 본질적으로 하나의 단단한 사실, 즉 OpenAI가 마법의 숫자 170을 사용했다는 것에서 많은 추측을 했음
     * 그러나 YOLO와 같은 다른 CNN 아키텍처와 매우 일치하는 완전히 그럴듯한 접근 방식, 즉 이미지 타일에서 임베딩 벡터로 매핑하는 방법이 있는 것 같음
     * 따라서 170 토큰이 단순히 이미지 처리에 필요한 대략적인 계산량에 대해 청구하기 위해 사용되는 근사치라고 생각하지 않음
     * 또한 일부 다른 멀티모달 모델이 하는 것처럼 이미지와 텍스트 데이터를 결합하기 위해 레이어를 연결한다고 생각하지 않음
     * GPT-4o는 CLIP와 YOLO의 혼합인 CNN 아키텍처를 사용하여 이미지를 직접 트랜스포머의 의미 벡터 공간에 임베딩함으로써 512x512 이미지를 문자 그대로 170개의 임베딩 벡터로 표현한다고 생각함
     * 이 기사를 시작할 때, 170 토큰이 13x13 그리드와 하나의 추가 ""게슈탈트 인상"" 토큰을 위한 것이라는 사실을 완전히 해독했다고 확신했음
          + 그러나 Zener 작업의 성능이 5x5 이후 저하되기 시작하면서 이는 물거품이 되었음. 내부적으로 무엇을 하든 13x13보다 훨씬 작은 것 같음
     * 그럼에도 불구하고 YOLO에 대한 유추는 설득력이 있으며, 5x5 Zener 작업에 대한 성능은 일종의 그리드를 수행하고 있음을 거의 확인해줌
     * 이 이론은 다른 영역에서도 많은 예측력을 가지고 있음
          + GPT-4o가 여러 이미지를 처리하고 두 이미지를 비교하는 것과 같은 작업을 수행할 수 있는 방법을 설명함
          + 동일한 이미지에서 여러 객체를 볼 수 있지만, 복잡한 장면에 너무 많은 객체가 있을 때 압도되는 이유를 설명함
          + GPT-4o가 장면 내 개별 객체의 절대 및 상대 위치에 대해 매우 모호해 보이는 이유와 이미지의 객체를 정확하게 계산할 수 없는 이유를 설명함 (객체가 인접한 두 개의 그리드 셀에 걸쳐 있을 때 동일한 클래스가 둘 다에서 활성화되므로 하나의 객체인지 두 개의 객체인지 확신할 수 없음)
     * 아이러니하게도, 이 이론이 깔끔하게 설명할 수 없는 유일한 것은 처음에 이 기사를 쓰게 된 동기가 된 질문임: 왜 하필 170 토큰인가?
          + 피라미드 이론(1x1 + 2x2 + 3x3 + 4x4 + 5x5)이 내가 생각해낼 수 있는 최선이었지만, 특별히 깔끔하지는 않음
     * 조금 더 잘 맞는 이론(또는 NDA에 저촉되지 않는다고 가정할 때 실제 지식)을 가진 사람의 의견을 듣고 싶음

후기: 알파 채널 속임수

     * 이 프로젝트를 진행하면서 GPT-4o가 알파 채널을 무시하여 다소 직관에 어긋나는 행동을 한다는 것을 알게 됨
     * ""무시한다""는 말은 이미지 편집기가 PNG를 JPG로 변환할 때 기본 배경에 합성하여 투명도를 제거하는 방식이 아님
          + GPT-4o는 문자 그대로 RGB 채널만 가져오고 알파 채널은 무시함
     * 이를 신중하게 준비된 4개의 이미지로 설명할 수 있음
          + 편의상 HTML과 CSS를 사용하여 체크무늬 패턴 위에 이미지를 표시했으며, 이미지 자체는 평평하고 투명한 배경을 가짐
          + 그러나 절반은 투명한 검은색 배경을 가지고, 나머지 절반은 투명한 흰색 배경을 가짐
     * ""투명한 검은색"" 또는 ""투명한 흰색""이란?
          + RGBA 색상을 4바이트로 표현할 때, 알파가 100%여도 RGB 바이트는 여전히 존재함
          + 따라서 (0, 0, 0, 255)와 (255, 255, 255, 255)는 어떤 의미에서 다른 색상이지만, 둘 다 100% 투명하기 때문에 올바른 렌더러가 다르게 표시할 상황은 없음
     * GPT-4o에게 이 4개 이미지에서 무엇을 ""보는지"" 물어보면:
          + 투명한 검은색 배경에 검은색 텍스트: GPT-4o는 """"로 읽음
          + 투명한 흰색 배경에 검은색 텍스트: GPT-4o는 ""ENORMOUS""로 읽음
          + 투명한 검은색 배경에 흰색 텍스트: GPT-4o는 ""SCINTILLA""로 읽음
          + 투명한 흰색 배경에 흰색 텍스트: GPT-4o는 """"로 읽음
     * 여기서 무슨 일이 일어나고 있는 것일까?
          + GPT-4o는 텍스트 색상이 투명 배경의 ""색상""과 다를 때만 텍스트를 읽을 수 있다는 패턴이 나타남
          + 이는 GPT-4o가 알파 채널을 무시하고 RGB 채널만 본다는 것을 알려줌. GPT-4o에게 투명한 검은색은 검은색이고, 투명한 흰색은 흰색임
     * RGB 채널 3개를 보존하면서 알파 채널을 100%로 설정하여 이미지를 조작하면 더 명확하게 볼 수 있음
          + Pillow 함수를 사용하여 이를 수행함
          + 이를 사용하여 아래 두 이미지를 만들었으며, RGB 데이터는 동일하고 알파 채널만 다름
               o 알파 채널 = 255: GPT-4o는 숨겨진 오리너구리를 쉽게 볼 수 있음
               o 알파 채널 = 0: GPT-4o는 완전히 투명한 이미지로 보임
     * hidden_platypus.png 이미지를 다운로드하여 ChatGPT에 직접 삽입해 볼 수 있으며, 정확하게 설명할 것임
          + 이미지 크기가 39.3KB로 platypus.png와 동일한 것을 알 수 있는데, 완벽하게 비어 있고 투명한 이미지라면 PNG 압축으로 인해 훨씬 작아졌어야 함
          + 또는 위 함수를 사용하여 알파 채널을 다시 255로 설정하여 원래 이미지를 복구할 수 있음
     * 이것이 버그인지는 확실하지 않지만 확실히 놀라운 동작이며, 악의적인 사용자가 인간을 지나쳐 GPT-4o로 직접 정보를 밀반입하는 데 사용할 수 있는 것처럼 느껴짐
     * 그러나 GPT-4o는 이미지에 숨겨진 악의적인 프롬프트를 탐지하고 무시하는 데 GPT-4v보다 훨씬 뛰어남
          + image_tagger 유틸리티로 생성한 GPT-4o 테스트 이미지 갤러리에서 GPT-4o가 이미지에 숨겨진 악의적인 프롬프트를 성공적으로 탐지하고 무시하는 다른 예시를 찾을 수 있음
     * 따라서 버그라 하더라도 악용될 수 있는지는 분명하지 않음
     * 그럼에도 불구하고 GPT-4o가 브라우저에서 사람이 보는 것과 동일한 것을 ""본다면"" 덜 놀랄 것임

   따라서 (0, 0, 0, 255)와 (255, 255, 255, 255)는 어떤 의미에서 다른 색상이지만, 둘 다 100% 투명하기 때문에 올바른 렌더러가 다르게 표시할 상황은 없음

   투명하려면 alpha가 0인 (0, 0, 0, 0)와 (255, 255, 255, 0) 인데 본문에 오타가 있나보네요.

  Hacker News 의견

     * 현대적인 오픈 소스 대체품 필요성: 최신 기계 학습 기술을 기반으로 한 Tesseract의 현대적 오픈 소스 대체품이 절실히 필요함. 현재 사용 중인 LLM은 과도하게 강력하고 비용이 많이 듦.
     * Llava1.6, IntenVL, CogVLM2의 OCR 능력: 이 모델들은 타일 이미지 임베딩과 LLM만으로 OCR을 수행할 수 있음. Tesseract의 OCR 결과를 입력하면 신뢰성이 향상되지만 필수는 아님.
     * Clip 임베딩의 텍스트 인식: Clip 임베딩은 텍스트가 충분히 크면 텍스트를 ""읽을"" 수 있음. 타일링은 작은 텍스트를 읽을 수 있게 함.
     * 호기심과 개방적인 탐구: 이 기술이 어떻게 작동하는지에 대한 호기심과 개방적인 탐구를 사랑함. 기계 학습 모델 해석을 위한 재규격화 그룹 이론과의 연관성도 흥미로움.
     * 텍스트를 이미지로 전송하는 효율성: 텍스트를 이미지로 전송하는 것이 더 효율적일 수 있음. 작은 글꼴로 512x512 이미지에 400-500개의 토큰을 쉽게 담을 수 있음.
     * OpenAI의 문서화 부족: OpenAI가 명확하고 포괄적인 문서를 제공하지 않는 이유를 이해하지 못함. API를 사용하는 사람들에게는 이 문서 부족이 큰 장애물임.
     * GPT-4의 이미지 처리 오류: GPT-4 비전이 PDF의 여러 페이지를 나타내는 단일 이미지를 OCR할 때 내용이 왜곡되는 문제를 경험함. OpenAI의 명확한 문서가 있었다면 이러한 문제를 더 효과적으로 피할 수 있었을 것임.
     * 글의 품질: 이 글이 매우 잘 쓰여졌다고 생각함. 주제를 쉽게 설명하면서도 깊이 있게 다룸. 주제를 잘 이해해야 간단하게 설명할 수 있음.
     * VQVAE 사용 가능성: VQVAE를 사용하여 토큰 사전을 만들고 이미지를 인코더로 변환하는 가능성이 있음.
     * 이미지-토큰 매핑의 비용: 이미지를 토큰 임베딩으로 매핑하는 것이 토큰 ID로 매핑하는 것보다 약 170배 더 많은 계산과 공간을 소비할 가능성이 있음.
     * 13x13 타일링 가능성: 13x13 타일링이 겹치는 수용 영역 때문에 13x13 객체 그리드를 인식할 수 없다는 것을 배제할 수 없음. 겹치는 타일링 해상도의 피라미드도 가능함.
     * GPT-4 성능 테스트 방법: 7x7 그리드의 색상 모양을 JSON으로 요청하여 GPT-4 성능을 테스트하는 방법이 매우 기발함.
"
"https://news.hada.io/topic?id=15305","ARC 상 – 오픈 AGI 발전을 위한 100만 달러 이상의 경쟁","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ARC 상 – 오픈 AGI 발전을 위한 100만 달러 이상의 경쟁

AGI 발전이 멈췄음. 새로운 아이디어가 필요함

  ARC PRIZE 발표

     * ARC Prize: 오픈 AGI 발전을 위한 100만 달러 이상의 상금 대회
     * 목표: 새로운 아이디어를 통해 AGI 발전을 촉진하고, ARC-AGI 평가를 해결하는 것

  지능 대 암기

     * 현대 AI: 주로 고차원 패턴을 암기하고 이를 유사한 상황에 적용하는 방식
     * 문제점: 새로운 상황에서 새로운 추론을 생성하지 못함
     * 일반 지능: 새로운 기술을 효율적으로 습득하는 능력
     * 필요성: 새로운 아키텍처나 알고리즘이 필요함

  LLM의 한계

     * 기존 AI 시스템: 특정 게임에서 인간을 이길 수 있지만, 다른 게임으로 전환이 불가능함
     * 일반화 실패: AI가 새로운 상황에 적응하지 못함

  ARC-AGI

     * 소개: François Chollet의 논문 ""On the Measure of Intelligence""에서 소개됨
     * 목표: 새로운 기술을 효율적으로 습득하고 새로운 문제를 해결하는 시스템 평가
     * 현재 상태: 인간은 85%~100% 점수를 얻지만, AI는 34%에 불과함

  오픈 소스 AGI 발전

     * 문제점: GPT-4 이후 AGI 연구가 폐쇄적으로 변함
     * 역사: LLM의 발전은 여러 연구자들의 협력 결과
     * 필요성: 새로운 아이디어를 촉진하기 위해 오픈 소스가 필요함

  ARC PRIZE 목표

     * 연구 참여 증가: AGI 연구에 참여하는 사람 수를 늘림
     * AGI 발전 측정: 객관적인 AGI 발전 측정 방법을 대중화
     * ARC-AGI 해결: ARC-AGI 평가를 해결하고 지능의 본질에 대해 새로운 것을 배움

  시작하기

     * 참여 방법: 누구나 참여 가능, 새로운 아이디어는 어디서든 나올 수 있음
     * 정보 제공: ARC Prize 2024의 형식과 상금 세부 사항 제공

GN⁺의 의견

     * 오픈 소스의 중요성: 오픈 소스는 혁신을 촉진하고 작은 AI 회사와 큰 AI 회사 간의 격차를 줄이는 데 중요함
     * 새로운 아이디어의 필요성: 현재 AI 연구는 새로운 아이디어가 부족하며, 이는 AGI 발전을 저해함
     * 규제 문제: 잘못된 믿음으로 인해 AI 연구에 대한 규제가 강화될 수 있음
     * 경쟁의 장점: ARC Prize와 같은 대회는 연구자들에게 동기를 부여하고 새로운 아이디어를 촉진할 수 있음

        Hacker News 의견

     * Simon Strandgaard는 ARCathon 2022와 2023에 참여하여 각각 3개와 8개의 과제를 해결했음. 인간이 ARC 과제를 해결하는 방식을 데이터로 수집 중이며, 현재 4100개의 상호작용 기록을 모았음. 다양한 ARC 유사 데이터셋도 제공하고 있음.
     * 현재의 데이터 중심 학습 패러다임이 일반화되지 않고 지속 가능하지 않다는 의견. 인간은 수천 개의 예시 없이도 고양이와 개를 구분할 수 있지만, 컴퓨터는 수백만 개의 예시가 필요함. 데이터가 희귀한 분야에서는 지식 전이가 어려울 수 있음.
     * ARC 문제는 많은 공간적 세계 지식이 필요하며, 추상적 추론보다는 인간의 시각 처리에 직관적인 요소가 많음. 시각적 패턴 인식이 중요한 역할을 함.
     * ARC 테스트가 인간에게도 어렵다는 주장. ConceptARC 테스트에서 인간의 25-30%가 간단한 질문을 해결하지 못함. 이는 ARC의 유용성을 제한할 수 있음.
     * 제한 없는 버전의 대회에 대한 리더보드가 있는지 궁금해하는 의견. GPT-4의 성과를 보고 싶어함.
     * AGI 연구에 대한 100만 달러 상금이 너무 낮다는 의견. AGI의 영향은 최소 수조 달러로 측정될 것이며, 현재의 상금은 최신 공개 LLM 릴리스를 미세 조정하는 데 그칠 수 있음.
     * 특정 퍼즐에 대해 여러 가지 유효한 답이 있을 수 있다는 의견. 예시에서 기대되는 거리를 정확히 알 수 없음.
     * ARC 과제가 시각적 패턴 인식을 목표로 하지만, 이는 지능의 유일한 정의가 될 수 없다는 의견. 인간-AI 협력 지능이 중요하며, 문제는 다중 속성 목표의 최적화로 재구성되어야 함.
     * François Chollet의 논문이 매우 통찰력 있으며, 일반 지능의 정의에 대해 가장 좋은 답변을 제공함. 학습 효율성으로 지능을 정의하는 것이 인간 지능의 인상적인 이유를 이해하는 데 도움이 됨.
     * ARC 문제 세트가 기존 ML 문제 세트보다 훨씬 어렵지만, AGI를 대표하지는 않는다는 의견. 새로운 데이터셋일 뿐 접근 방식은 기존과 유사함. AGI가 이 문제를 해결할 수 있지만, 문제 해결이 AGI의 보증 지표는 아님.
"
"https://news.hada.io/topic?id=15228","Ice – macOS용 오픈 소스 메뉴 바 관리자","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Ice – macOS용 오픈 소스 메뉴 바 관리자

     * 강력한 메뉴 바 관리 도구
     * Command + 드래그로 메뉴 바 항목을 재배치할 수 있음.

  주요 기능

    메뉴 바 항목 관리

     * 메뉴 바 항목 숨기기
     * ""항상 숨김"" 메뉴 바 섹션
     * 메뉴 바에 마우스를 올리면 숨겨진 항목 표시
     * 메뉴 바의 빈 영역을 클릭하면 숨겨진 항목 표시
     * 메뉴 바에서 스크롤하거나 스와이프하여 숨겨진 항목 표시
     * 자동 재숨김
     * 표시된 메뉴 바 항목과 겹치는 애플리케이션 메뉴 숨기기
     * 개발 예정
          + 개별 항목을 정렬하기 위한 드래그 앤 드롭 인터페이스
          + 메뉴 바 항목 검색
          + 숨겨진 항목을 별도의 바에 표시 (예: 노치가 있는 MacBook)
          + 항목 간의 사용자 정의 간격
          + 메뉴 바 레이아웃을 위한 프로필

    메뉴 바 외관

     * 메뉴 바 색조 (단색 및 그라데이션)
     * 메뉴 바 그림자
     * 메뉴 바 테두리
     * 사용자 정의 메뉴 바 모양 (둥글거나 분할된 형태)

    핫키

     * 개별 메뉴 바 섹션 전환
     * 애플리케이션 메뉴 전환
     * 섹션 구분 아이콘 표시/숨기기
     * 개발 예정
          + 개별 메뉴 바 항목 임시 표시
          + 자동 재숨김 활성화/비활성화

    기타

     * 로그인 시 자동 실행
     * 자동 업데이트
     * 개발 예정 : 메뉴 바 위젯

    FAQ

     * 이름의 의미 : 메뉴 바 항목이 얼음처럼 미끄러지듯 이동할 수 있게 해줌.
     * 왜 이전 운영 체제를 지원하지 않는가?
          + Ice가 사용하는 여러 시스템 API가 macOS 14부터만 사용 가능함.

        Hacker News 의견

     * Bartender 앱이 신뢰할 수 없는 새로운 소유자에게 팔렸음. Ice는 아직 완벽하지 않지만 대체제로 괜찮음.
     * Hidden Bar를 사용 중이며, 업데이트는 없지만 잘 작동함. Ice는 더 나은 대체제일 수 있음.
     * Bartender를 계속 사용하고 싶다면 Little Snitch로 인터넷 차단하고 최신 안전 버전(v5.0.49)을 사용하면 됨.
     * Dozer를 4년간 사용 중이며 안정적임. Ice의 개발 로드맵에 있는 많은 기능을 이미 제공함.
     * 메뉴 바 아이콘이 노치 뒤에 숨겨지는 문제를 해결하기 위해 아이콘 간격과 패딩을 조정하는 방법을 찾았음. Ice에도 이 기능이 추가되면 좋겠음.
     * Bartender 대체 앱들이 많이 있지만 대부분 개발이 중단됨. macOS 자체 기능으로 일부 아이콘을 제어 센터로 이동할 수 있음.
     * Bartender를 대체할 여러 앱에 대한 정보는 Reddit 게시물을 참고하면 좋음.
     * Bartender를 제거하고 macOS의 기본 기능을 사용 중임. 최소한의 조정 가능성을 제공함.
     * Bartender 문제로 HiddenBar를 시도했지만, 많은 앱이 트레이 아이콘 숨기기 기능을 제공함. 제어 센터에서 정리 후 괜찮아짐.
     * 작은 화면이나 노치가 있는 화면에서 추가 메뉴 바를 제공하는 대체 앱을 찾고 있음. BetterTouchTool 옵션을 기대 중임.
     * 모든 아이콘을 보이게 하려면 ""defaults"" 명령어로 아이콘 간격과 패딩을 조정하면 됨. 재시작/로그아웃 필요.
"
"https://news.hada.io/topic?id=15226","이미지 파일 목록 프로그램 'lsix' 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        이미지 파일 목록 프로그램 'lsix' 출시

lsix: 터미널에서 이미지 썸네일을 보여주는 도구

  사용법

     * lsix [파일들 ...] 명령어로 사용 가능함.
     * 기본적으로 현재 작업 디렉토리의 이미지를 보여줌.
     * 파일 이름을 지정하거나 와일드카드를 사용할 수 있음 (예: lsix *jpg*png).

  예제

    기본 사용법

     * lsix 명령어를 입력하면 현재 디렉토리의 이미지를 보여줌.
     * 특정 파일 형식을 강제로 표시하려면 파일 이름을 지정하거나 와일드카드를 사용함 (예: lsix *.pdf).

    GIF 확장

     * GIF 파일을 지정하면 모든 프레임이 확장되어 몽타주로 표시됨 (예: lsix nyancat.gif).

    터미널 배경색 감지

     * PNG 및 SVG 파일은 터미널 배경색에 맞게 알파 채널을 올바르게 표시함.
     * 터미널의 전경색과 배경색을 감지하여 적절히 조정함.

  기능

     * 터미널이 SIXEL 그래픽을 표시할 수 있는지 감지함.
     * SSH를 통해 원격 서버에서도 잘 작동함.
     * 비트맵이 아닌 그래픽도 잘 작동함 (예: .svg, .eps, .pdf, .xcf).
     * 터미널의 색상 레지스터 수를 자동으로 감지하고 이미지 품질을 향상시킴.
     * 터미널의 전경색과 배경색을 자동으로 감지함.
     * 많은 이미지가 있는 경우 한 줄씩 표시하여 전체 몽타주를 기다릴 필요가 없음.
     * 긴 파일 이름을 적절히 감싸서 표시함.
     * 몽타주의 타일 너비, 폰트 패밀리, 포인트 크기 등을 쉽게 변경할 수 있음.

  설치

     * lsix 파일을 경로에 넣고 실행함 (예: /usr/local/bin).
     * ImageMagick이 필요함. 패키지 관리자를 통해 쉽게 설치 가능 (예: apt-get install imagemagick).
     * MacOS 사용자는 brew install lsix 명령어로 설치 가능.

  터미널 지원

     * SIXEL 그래픽을 지원하는 터미널: XTerm, MLterm, foot, Wezterm, Contour, iTerm2, Konsole, yakuake, WSLtty, MinTTY, Yaft, VTE, sixel-tmux, ttyd.
     * SIXEL 그래픽을 지원하지 않는 터미널: MacOS Terminal, kitty, 모든 표준 libvte 기반 터미널 (gnome-terminal, terminator, lxterm), Alacritty.

  구성

     * lsix는 매우 간단하게 설계되어 별도의 구성 파일이나 명령줄 플래그가 없음.
     * 스크립트를 직접 편집하여 쉽게 변경 가능.

  버그

     * XTerm의 역방향 비디오 모드에서 배경색이 올바르게 표시되지 않음.
     * XTerm의 화면 너비가 1000px로 제한됨.
     * 파일 이름이 ""@""로 시작하면 ImageMagick이 오류를 일으킴.
     * 빈 문자열을 파일 이름으로 지정하면 ImageMagick이 멈춤.
     * 긴 파일 이름이 비효율적으로 감싸짐.
     * 명령줄에서 지정된 디렉토리가 재귀적으로 처리되지 않음.
     * 비디오 파일을 지정하면 문제가 발생할 수 있음.

  향후 문제

     * SIXEL 표준은 그래픽 화면의 크기를 쿼리하는 방법이 없음.
     * 색상 레지스터 수를 쿼리하는 방법이 없음.
     * 일부 터미널 에뮬레이터는 lsix와 호환되지 않음.

  GN⁺의 의견

     * 터미널 이미지 보기: lsix는 터미널에서 이미지를 쉽게 볼 수 있게 해주는 유용한 도구임. 특히 원격 서버에서 이미지를 확인할 때 유용함.
     * 호환성 문제: 모든 터미널이 SIXEL 그래픽을 지원하지 않으므로 사용 전에 호환성을 확인해야 함.
     * 간단한 설치: 설치가 매우 간단하고 필요한 소프트웨어도 쉽게 구할 수 있음.
     * 사용자 정의 가능성: 스크립트가 간단하여 사용자가 쉽게 수정하고 확장할 수 있음.
     * 대체 도구: 비슷한 기능을 제공하는 다른 도구로는 img2sixel 등이 있음.

        Hacker News 의견

     * Tmux의 실험적인 sixel 브랜치가 약 10개월 전에 메인 브랜치에 병합되었음. 이제 --enable-sixel 옵션을 사용하여 Tmux를 빌드하고 lsix 같은 도구를 사용할 수 있음. 좋아하는 터미널이나 멀티플렉서가 sixel을 지원하는지 확인하려면 ""Are We Sixel Yet"" 사이트를 참조할 수 있음.
     * 이 저장소에서 가장 마음에 드는 기능은 README.md.d 디렉토리임. 좋은 아이디어라고 생각함. .md를 생략해도 괜찮을 것 같음.
     * \e[c를 사용하여 자동으로 sixel 지원을 감지함. \e[c는 ""장치 속성 보내기"" 기능임.
     * 비슷한 맥락에서 timg라는 도구도 있음.
     * 좋은 아이디어지만 PuTTY/ KiTTY에서는 작동하지 않음. sixel 그래픽을 지원하는 터미널을 사용해야 함. 터미널이 sixel을 지원하는지 테스트하려면 이미지를 변환하여 확인할 수 있음. 지원하지 않는다면 버그 리포트를 제출할 수 있음.
     * MacOS의 iTerm2는 유사한 기능을 제공하지만 서버 측 부담이 적음. 서버에서 이미지를 sixel로 렌더링하는 대신, 클라이언트로 base64 인코딩된 이미지를 보내어 로컬에서 렌더링함.
     * fzf는 버전 0.44.0부터 미리보기 창에서 (실험적인) sixel 이미지 지원을 제공함. 하지만 Windows에서는 사용할 수 없음.
     * HN 폰트가 오해를 불러일으킬 수 있음. 다음 헤드라인을 기다리고 있음: 'Isis, like ""ls"", but for terrorists.'
     * 신뢰할 수 없는 디렉토리에서 이 도구를 실행할 때 주의해야 함. 특히 pdf와 같은 파일을 처리할 때 ImageMagick을 사용하는 경우 주의가 필요함.
     * 터미널이 sixel 그래픽을 지원하는 한 문제없음.
"
"https://news.hada.io/topic?id=15202","2년 이상 회사에 머무는 직원, 급여 50% 감소 (2014)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   2년 이상 회사에 머무는 직원, 급여 50% 감소 (2014)

2년 이상 같은 회사에 머무는 직원은 50% 적은 급여를 받음

  직장을 옮겨야 하는 이유

     * 연봉 인상률: 2014년 평균 연봉 인상률은 3%로, 물가 상승률 2.1%를 고려하면 실제 인상률은 1% 미만임.
     * 직장 이동 시 급여 인상: 직장을 옮길 때 평균 10%에서 20%의 급여 인상을 기대할 수 있음.
     * 경력 관리: 새로운 회사로 이동하면 더 높은 기본 급여와 직책을 받을 가능성이 높음.

  직장을 옮기지 말아야 하는 이유

     * 이력서에 대한 우려: 잦은 직장 이동이 이력서에 부정적으로 작용할 수 있음.
     * 회사 내부의 성장: 일부 회사는 직원의 성장을 지원하며, 장기적으로 더 나은 보상을 제공할 수 있음.
     * 삶의 질: 직장 이동은 스트레스를 유발할 수 있으며, 정신적, 신체적 건강을 고려해야 함.

  결론

     * 자신의 경력 관리: 직원은 자신의 급여를 통제할 수 있으며, 적극적으로 협상하고 더 나은 기회를 찾아야 함.
     * 개인의 선택: 모든 직원이 즉시 결정을 내릴 수는 없지만, 장기적으로 고려할 필요가 있음.

GN⁺의 의견

     * 경력 관리의 중요성: 경력 초기에 다양한 경험을 쌓는 것이 중요하며, 이는 장기적으로 더 나은 기회를 제공할 수 있음.
     * 시장 상황: 현재의 경제 상황과 업계 동향을 주시하며, 적절한 시기에 직장을 옮기는 것이 중요함.
     * 균형 잡힌 접근: 급여뿐만 아니라 삶의 질, 직장 문화, 성장 가능성 등을 종합적으로 고려해야 함.
     * 기술 발전: 기술의 발전으로 인해 특정 기술이나 경험이 빠르게 가치가 떨어질 수 있으므로, 지속적인 학습과 자기 개발이 필요함.

        Hacker News 의견

    해커뉴스 댓글 요약

     * 장기 근속자 보상 부족: 회사는 장기 근속자에게 보상을 잘 하지 않음. 이는 합리적인 전략으로, 많은 사람들이 더 높은 급여를 원하지만 실제로 행동에 옮기지 않기 때문임.
     * 직장 이동의 이점: 직장 이동이 더 높은 급여를 가져다 줄 수 있지만, 이는 중간 관리직 이상으로 올라가려는 목표에는 적합하지 않음. 장기적으로 한 회사에서 일하는 것이 더 높은 위치와 급여를 얻는 데 유리함.
     * 나쁜 관리의 위험: 더 높은 급여를 제공하는 회사가 실제로는 관리가 엉망일 수 있음. 좋은 고용주를 찾았다면 그곳에 머무르는 것이 좋음.
     * 직장 이동의 단점: 직장 이동이 급여 인상에 도움이 되지만, 이력서에 자주 직장을 옮긴 기록이 있으면 고용주가 꺼릴 수 있음. 안정성이 중요함.
     * 산업 자동화의 문제: 일부 회사는 프로젝트 기간 동안만 사람을 고용하고, 이는 직원 유지에 어려움을 줌. 좋은 환경을 제공하여 직원들이 돌아오게 하는 것이 목표임.
     * 급여 인상 불균형: 새로운 직원에게는 높은 급여 인상을 제공하지만, 기존 직원에게는 적은 인상만 제공하는 경우가 있음.
     * 데이터 부족: 기사에서 주장하는 급여 인상 전략이 데이터로 뒷받침되지 않음. 리더십 구조에서 안정성이 중요함.
     * 직장 이동의 개인적 경험: 가족 구성원이 자주 직장을 옮기지만, 만족하지 못하는 경우가 있음. 반면, 한 직장에서 오래 일하며 만족하는 사람도 있음.
     * FAANG의 장점: FAANG에서 일하는 것이 다른 직장보다 더 많은 급여와 주식 보상을 받을 수 있음.
     * 생각 실험: 3% 인상과 2년마다 10% 인상을 비교한 엑셀 생각 실험일 뿐, 실제 사람들의 삶을 연구한 것은 아님.
"
"https://news.hada.io/topic?id=15236","패션플랫폼 무신사, PC버전 지원 종료…모바일에 올인","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     패션플랫폼 무신사, PC버전 지원 종료…모바일에 올인

     * 2024년 6월 3일부터 무신사 공식 홈페이지가 모바일 버전으로 전환됨
     * 반응형 웹사이트가 아닌 모바일 전용 버전으로만 제공됨
     * ""헤럴드 경제, 무신사, PC 웹 페이지가 사라진 이유?""에 따르면 현재 무신사의 PC 이용률이 한 자릿수도 되지 않으며, 모바일 이용자가 다수이기 때문에 비용 효율화 측면에서 PC 버전 유지보수를 중단한 것이라고 함

   막은게 아니라 PC반응형을 개발 안한거군요.
   사실 조그만 회사가 다 지원하려고 하는게 더 이상할 수 있을거 같아요.
   모바일로 UX다 정리한 후에 그때도 수요가 있다면 PC도 지원하게 되지 않을지..

   난 pc로만 이용해왔는데 갑자기 없애버리네 ㅋㅋ
   소수의 고객 경험은 그냥 알빠 아니라는 건가

   무신사는 외부 솔루션을 사용하는 쇼핑몰로 시작해서 회사가 성장하면서 솔루션업체를 아예 인수했는데 그게 스파게티코드처럼 짜인 php 기반이었을 듯. 고도화하면서 개발조직을 키우고 pc는 여전히 레거시이고 버티컬 커머스이기 때문에 사업자 등에서 사용하기도 하는 일반 커머스 대비 pc 사용률이 더 낮을듯

   '반응형 웹'이 뭔지 모르는 회사같네요

   보통 반응형 웹과 적응형 웹을 혼용해서 쓰긴 하지만 해외 사이트가 반응형 웹으로 되어 있는 것을 보면 모르는 회사는 아니라고 생각해요 :)

   무신사가 pc이용률이 극단적으로 0%대라는 게 신기하긴 하네요. ui가 지그재그랑 비슷해졌네요

   블라인드에서 pc가 너무 레거시라 유지보수 인력이 나오지 않는다는 이야기를 봤습니다. 개편 후 재부활 할 수 있다고도.

   사실 이게 장기적으로 좋은 결정인지는 잘 모르겠습니다. 좋으나 싫으나 웹이 브랜드와 비즈니스에 많은 영향을 미치니까요.

   모바일 vs PC 사용자 비율 관련해서는 저도 비슷한 경험이 있네요. 전에 다니던 모바일 게임회사, 제품도 모바일 전용이고 사이트 방문자 비중도 8:2 정도여서 PC 접근성에 너무 공들이지 않아도 될 것 같다는 피드백을 받았었는데요. 이후에 사이트 리뉴얼 하면서 PC 접근성을 개선하니까 몇 달 만에 방문자 비중이 6:4 정도로 변화하는걸 봤습니다. 어찌보면 이게 당연한게, 구글봇 같은 검색엔진도 에이전트를 별도로 운영해서 검색 사용자 폼팩터에서 ""사용성이 높은"" 페이지를 랭킹에 반영하기도 하고, 반대로 에이전트에 따라 컨텐츠를 다르게 보여주는 것을 인식하면 강한 패널티를 주기도 하거든요.

   무신사는 비즈니스 차원에서 웹 지표를 아예 고려하지 않기로 한 것 같은데, 조금이라도 고려하는 비즈니스에서는 똑같은 결정을 해서는 안될 것 같습니다.

   예전에 주변의 무신사 이용자들 이야기를 들어보면
   PC 웹이 너무 복잡하다는 말을 많이 들었던 것 같아요.
   말씀하신 것처럼, 무신사의 PC 사용률이 낮은 이유가
   사람들이 모바일로만 사용을 한다라기 보다는, PC 웹이 불편해서 사용하지 않았을 수도 있겠네요

   미국 유저인데, 접속해보니 영문 페이지는 여전히 PC 버전이고 한국 선택 자체가 막혀있내요 >.<

   회사의 마케팅, 전략, 테크 부서 간 잘 조율된 결정이라면 회사의 경쟁력을 가늠해 볼 수 있는 좋은 사례라고 생각됩니다. 어떻게 보면 좀 여유있는 기업들 이라면 reactive/responsible 대응이 기본일텐데 고객의 수요에 따라 reactive/responsible 대응도 달라져야 한다는 꽤나 긍정적인 변화일 수 있겠다는 생각입니다. 결국 마케팅, 테크 모두 시장(고객, 트렌드)에 잘 적응하는 기업이 성공한다는 법칙이 기본이니까요.

   추가적으로, 처음 설계할 경우 반응형으로 진행할지, 적응형으로 진행할지도 생각해보면 좋을 것 같다라는 생각합니다. 다른 분이 PC가 레거시여서 모바일로만 진행한다고 하는 것을 보면 적응형 디자인이였다고 추정되는데 UX는 좋을지 몰라도 관리포인트가 한 부분 늘어나는 것이니까요. 회사가 성장하기만 하면 상관 없을 수도 있지만 멈추기도 하니까 처음 결정할 때 고민해봐야겠네요.

   괜찮겠지하고 갔는데, 또 막상 양 옆에 텅텅이니 좀 답답하긴 하네요

   4년 전 쯤이었나, 인어교주해적단이나 캐치테이블 같은 곳들에서 이렇게 만드는거 보고 비용 절감 차원인가 싶었는데 무신사가 한다니까 또 신기하게 느껴지긴 하네요. 근데 또 한편으로는 무신사가 시작이 PC 웹이었어서인지 PC에서의 웹 뷰와 모바일 앱 사이에 괴리가 있다고 생각했는데, 앱과 다르게 웹에서는 굉장히 지저분하다는 느낌을 받을 때가 참 많았습니다. 결국엔 레거시를 개선하지 못하고 완전히 이런 노선으로 가게된건지 아니면 웹에서의 트래픽이 적어서인지 의사 결정이 궁금하긴 하네요...

   가끔 데탑에서 접속했다고 아예 아무것도 못하게 하는 것 보다는... 모바일 사이트라도 제공만 하면 괜찮은 거 같습니다.

   해당 링크로 들어갔을 때 뒤로가기 버튼이 브라우저의 히스토리 스택을 사용하...

   무신사가 모바일로 완전히 전환했는데 큰 문제가 없으면, 앞으로 다른 쇼핑몰들도 PC용 웹사이트는 완전히 버리고 모바일 전용으로만 출시하는 날이 올까요? 반응형으로 개발하는 것도 사실 꽤 비용이 많이 드는 짓이라...

   이용률이 낮으면 좋은 선택인 것 같네요.

   긱뉴스는 모바일 5.5 대 PC 4.5 정도입니다.
   슬랙등을 통해서 회사에서 접속하는 사람이 많아서 그런듯 해요.

   재미난건 윈도우 접속자보다 맥+리눅스 합친 방문자가 더 많습니다.
   안드로이드 보다 iOS가 더 많고요.

   말씀해주신 이용률을 조사하는 사이트가 있나요?

   아 위 정보는 그냥 기본 Google Analytics 방문자 통계 기준입니다.

   이게 GeekNews 주제에 맞나요?

   네 주제에 맞습니다.

   여기서 이런 댓글이 보일줄이야..
   그럼 어떤 주제가 맞다고 생각하세요?

   먼저 왜 아니라고 생각하시는지? 궁금합니다. 아니면 그냥 질문인가요?

   유의미한 주제라고 생각합니다-

   사용률에 따라 고려할 수 있으니까요

   충분히 관심가질만한 주제라고 생각되는데요.
"
"https://news.hada.io/topic?id=15310","Elixir 1.17 출시: 패턴의 집합 이론적 타입, 기간, OTP 27","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Elixir 1.17 출시: 패턴의 집합 이론적 타입, 기간, OTP 27

Elixir v1.17 출시: 집합 이론적 타입, 캘린더 지속 시간, Erlang/OTP 27 지원

  점진적 집합 이론적 타입 경고

     * Elixir v1.17은 패턴에서 타입을 추론하고 이를 사용해 프로그램을 타입 체크하는 집합 이론적 타입을 도입함.
     * 이 타입 시스템은 기존 소프트웨어를 변경하지 않고도 코드베이스의 오류와 버그를 찾을 수 있게 해줌.
     * 현재는 경고를 통해서만 개발자들이 이 타입 시스템과 상호작용할 수 있음.
     * 주요 경고:
          + 존재하지 않는 키에 대한 패턴 매칭
          + 존재하지 않는 키에 대한 접근
          + 모듈이 아닌 곳에서 함수 호출
          + 익명 함수 호출 시 함수가 아닌 것을 호출
          + 구조체 간의 비교
          + 겹치지 않는 타입 간의 비교
          + 잘못된 바이너리 패턴 매칭
          + 정의되지 않은 예외 구조체를 구출하려는 시도
          + 구출된 예외에서 정의되지 않은 필드 접근

  Erlang/OTP 지원

     * Elixir v1.17은 Erlang/OTP 27을 지원하며, Erlang/OTP 24에 대한 지원을 중단함.
     * Elixir 개발자들은 Erlang/OTP 26 이상으로 마이그레이션할 것을 권장함.
     * Erlang/OTP 27의 주요 기능:
          + json 모듈 추가
          + 프로세스 레이블 (proc_lib:set_label/1) 추가

  새로운 Duration 데이터 타입과 날짜 이동 함수

     * Elixir v1.17은 Duration 데이터 타입과 날짜, 시간, 날짜 시간을 주어진 기간만큼 이동시키는 API를 도입함.
     * 예시:
iex> Date.shift(~D[2016-01-31], month: 2)
~D[2016-03-31]

     * Duration은 간격, 반복 이벤트, 일정 모델링에 필수적임.
     * DateTimes의 경우, Elixir는 시간대 변경을 올바르게 처리함.

  기타 주요 변경 사항

     * 새로운 Keyword.intersect/2,3 함수 추가.
     * 새로운 Mix 프로파일러 mix profile.tprof 추가.
     * Kernel.is_non_struct_map/1 가드 추가.
     * Elixir의 Logger가 gen_statem 보고서를 포맷하고 Erlang/OTP 27 프로세스 레이블을 포함함.

GN⁺의 의견

     * 집합 이론적 타입: 이 타입 시스템은 코드의 안정성과 신뢰성을 높이는 데 큰 도움이 될 수 있음. 특히, 대규모 프로젝트에서 유용함.
     * Erlang/OTP 27 지원: 최신 버전의 Erlang/OTP를 지원함으로써 성능과 기능 면에서 많은 이점을 제공함.
     * Duration 데이터 타입: 시간대와 캘린더를 고려한 날짜 이동 기능은 일정 관리와 같은 애플리케이션에서 매우 유용함.
     * 타입 시스템의 한계: 현재는 함수 경계 너머의 타입 분석이 불가능하므로, 이 부분은 향후 업데이트에서 개선될 필요가 있음.
     * 경쟁 제품: 다른 언어들, 예를 들어 TypeScript와 같은 정적 타입 시스템을 제공하는 언어들과 비교해볼 때, Elixir의 접근 방식은 동적 언어의 유연성을 유지하면서도 타입 안정성을 제공함.

        Hacker News 의견

     * Elixir와 Erlang 팀이 최근 몇 년 동안 뛰어난 성과를 내고 있음. 라이브러리와 책 저자들의 기여도 큼. Elixir와 OTP의 커밋을 지켜보며 흥미로움을 느낌. 모든 관련자들에게 감사함.
     * Elixir를 백엔드로 사용한 사이드 프로젝트에서 생산적이고 즐거운 경험을 함. LiveView의 생산성을 높이 평가하지만, 네트워크 연결이 불안정한 경우에는 적합하지 않음. Elixir가 LiveView와 분리되어도 충분히 재미있게 사용할 수 있음.
     * 스타트업을 Elixir로 풀스택 개발 중이며, 지금까지 사용한 기술 중 가장 훌륭함. 친구들에게 Elixir의 장점을 전파 중. RabbitMQ와 클라이언트가 OTP 27에서 작동하면 좋겠음.
     * Elixir와 Erlang 개발자들의 멋진 작업에 감사함. Elixir의 대규모 채택을 위해 ""타입이 없다""는 변명이 사라지길 기대함. 계속해서 좋은 성과를 내길 바람.
     * 10년 동안 Elixir에 대해 읽어왔고, 언어를 사랑함. 하지만 주류 언어보다 낮은 급여 때문에 Elixir 관련 직업을 포기함. 기술 스택보다 급여와 멋진 제품이 더 중요함. 여전히 Elixir를 멀리서 지켜보는 것은 재미있음.
     * 이번 릴리스의 멋진 기능은 get_in/1의 추가임. 예를 들어, get_in(struct.foo.bar)에서 foo가 nil을 반환하면 bar에 접근해도 오류가 발생하지 않음.
     * 이번 릴리스가 내가 원하던 마지막 조각임. 앞으로의 단계가 기대됨. 언어는 이제 100% 기능이 완비되었다고 생각함.
     * 타입 시스템에 대해 기대가 큼. José가 ""점진적 타입 시스템""이라고 설명한 것을 기억함. 이는 단계적으로 추가될 예정임. 다음 단계에서 새로운 타입 시스템 관련 기능이 나올지 궁금함. 특히 새로운 컴파일러 최적화를 기대함.
     * 이번 릴리스에 매우 흥분됨. Elixir IntelliJ 플러그인에 자원이 투입되길 바람. VSCode를 사용하는 것이 즐겁지 않음.
     * ""집합 이론적 타입""이 무엇을 의미하는지 아는 사람이 있는지 궁금함. 프로그래밍 언어에 관심이 많지만 이 용어는 처음 들어봄.
"
"https://news.hada.io/topic?id=15239","PID 0란 무엇인가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              PID 0란 무엇인가?

     * PID 0에 대해 웹에서 검색하면 대부분 잘못된 정보가 나옴.
     * Google, Bing, DuckDuckGo, Kagi에서 PID 0을 검색했을 때, 정확한 답변을 찾기 어려웠음.
     * Wikipedia의 잘못된 정보가 16년 동안 퍼져나가면서 많은 사이트들이 이를 인용함.

  PID 0의 역사

     * PID 0은 스케줄링과 전원 관리에 관여하며, 페이징과는 관련이 없음.
     * PID 0은 CPU 코어가 할 일이 없을 때 실행되는 스케줄러 역할을 함.
     * 초기 Unix에서는 PID 0이 메모리 관리와 관련된 작업을 했으나, 현대 Unix에서는 그렇지 않음.

  PID 0의 실제 역할

     * PID 0은 커널을 시작하고, 이후에는 CPU 코어를 관리하는 역할을 함.
     * Linux 커널에서 PID 0은 do_idle 함수로 구현되어 있음.
     * FreeBSD와 같은 다른 커널에서도 비슷한 역할을 수행함.

  PID 0의 혼란

     * Linux 커널과 사용자 공간에서 PID의 의미가 다름.
     * 커널에서는 task_struct가 하나의 스레드를 나타내며, PID는 스레드 ID를 의미함.
     * 사용자 공간에서는 PID가 프로세스를 나타내며, 이는 스레드 그룹 ID와 동일함.

  다중 코어 시스템에서의 PID 0

     * 다중 코어 시스템에서는 각 CPU 코어마다 하나의 idle 스레드가 있음.
     * 이 idle 스레드들은 모두 스레드 그룹 0에 속함.
     * 사용자 공간에서는 이를 PID 0으로 인식함.

  결론

     * PID 0은 존재하며, 커널을 시작하는 스레드임.
     * PID 0은 초기 커널 초기화 작업을 수행하고, 이후에는 idle 스레드로 전환됨.
     * PID 0은 메모리 관리와는 관련이 없음.
     * 다중 코어 시스템에서는 각 코어마다 idle 스레드가 있으며, 이들은 모두 스레드 그룹 0에 속함.

GN⁺의 의견

     * 정확한 정보의 중요성: 잘못된 정보가 오랜 시간 동안 퍼져나가면서 많은 사람들이 이를 사실로 받아들이게 됨. 정확한 정보 제공의 중요성을 다시 한번 상기시켜줌.
     * 커널의 복잡성: 커널의 초기화 과정과 스케줄링 메커니즘은 매우 복잡하며, 이를 이해하는 것은 소프트웨어 엔지니어에게 큰 도움이 됨.
     * PID의 혼란: 커널과 사용자 공간에서 PID의 의미가 다르기 때문에, 이를 명확히 이해하는 것이 중요함.
     * 다중 코어 시스템: 현대의 다중 코어 시스템에서 PID 0의 역할을 이해하는 것은 시스템 성능 최적화에 도움이 됨.
     * Wikipedia의 영향력: Wikipedia의 정보가 얼마나 많은 웹사이트에 영향을 미치는지 보여줌. 정확한 정보 업데이트의 중요성을 강조함.

   그 agent 가 kill -9 0 했던 그 옛날 사건이 생각나는...

   흥미롭네요

        Hacker News 의견

     * 고고학적 관점에서 흥미로움: ""pid 0은 [Linux] 커널의 일부""라는 말은 커널 디버깅 시 유용함. 사용자 공간 프로세스 관점에서는 ""pid 0은 나 자신을 의미""함.
     * 온라인에서의 과신: 온라인에서 많은 사람들이 자신이 아는 것에 대해 과신함. 확신에 찬 어조는 전문가들만 사용해야 함.
     * Windows의 PID 0: NT 기반 Windows에서 PID 0은 ""System Idle Process""로 Linux와 유사함. DOS 기반 Windows에서는 PID 0이 없고, idle loop는 VMM32 안에 있음.
     * 학문적 Unix에서의 PID 0: 대부분의 학문적 Unix에서 PID 0은 메모리 서브시스템(paging)과 관련됨. Linux만이 PID 0 개념의 소유자가 아님.
     * 일반 지식의 오류: ""일반 지식""이 잘못된 경우가 많음. 커널 소스 코드를 확인하는 것이 올바른 방법임.
     * PID 0의 세 번째 용도: Linux에서 getppid가 0을 반환하는 경우는 부모가 다른 PID 네임스페이스에 있을 때임.
     * 추가 자료 추천: 초기 커널 부팅에 관심이 있다면, 이 훌륭한 자료를 읽어보길 권장함. Linux Insides
     * ps -aux 명령어에 대한 질문: ""ps -aux"" 명령어를 입력하면 다른 사용자들의 정보도 표시됨. 기본적으로 비공개 정보여야 하지 않음?
     * kill 0의 흥미로운 사용법: kill 0을 사용하여 제한 시간 동안 명령어를 실행하고 종료하는 스크립트 공유.
     * v4 코드의 PID 0 재사용: v4 코드가 pid 0을 재사용하는 것이 흥미로움. 80년대 중반에 커널에서 이 문제를 해결해야 했던 기억이 있음.
"
"https://news.hada.io/topic?id=15249","남극 수자원 인프라","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               남극 수자원 인프라

개요

   이 글은 남극의 남극점에서 신선한 물을 생산하고 폐수를 처리하는 방법에 대해 설명함.

  맥머도 기지의 신선한 물 인프라

     * 맥머도 기지는 해안에 위치해 있어 액체 해수에 쉽게 접근할 수 있음.
     * 해수를 펌프로 끌어올려 여러 단계를 거쳐 식수로 변환함.
          + 해수는 먼저 가열되고, 필터링을 거쳐 염분을 제거함.
          + 역삼투압 시스템을 사용하여 순수한 물만 통과시키고 염분은 바다로 되돌려 보냄.
          + 마지막으로 물의 경도와 pH를 조절하고 소량의 염소를 추가하여 저장 및 배급함.

  맥머도 기지의 폐수 인프라

     * 폐수는 완전한 처리 과정을 거쳐 바다로 배출됨.
     * 고형물은 미국으로 보내져 처리됨.

  남극점의 신선한 물 인프라

     * 남극점에는 액체 상태의 물이 없고, 수천 피트의 눈을 녹여 물을 생산함.
     * ""Rodwell""이라는 시스템을 사용하여 눈을 녹여 지하 호수를 형성하고 물을 펌프로 끌어올림.
     * Rodwell은 몇 년 동안 사용되며, 너무 커지면 새로운 위치에 새로운 Rodwell을 만듦.

    공급

     * Rodwell은 뜨거운 물을 눈 속으로 펌핑하여 지하 호수를 형성함.
     * 물은 Rodwell에서 끌어올려져 주 수처리 시설로 이동함.

    처리

     * 물은 석회석 접촉기를 통해 pH를 조절하고, 침전 및 탄소 필터를 거침.
     * 소량의 염소를 추가하여 소독함.
     * 처리된 물은 저장 탱크에 보관됨.

    배급

     * 물은 압력을 가해 배급되고, 주로 주방, 세탁실, 화장실 등에서 사용됨.

  남극점의 폐수 인프라

     * 폐수는 사용된 Rodwell에 저장됨.
     * 폐수는 처리 없이 지하에 무기한 저장됨.
     * 남극 조약 시스템에 따라 허용됨.

GN⁺의 의견

     * 기술적 도전: 남극의 극한 환경에서 물과 폐수 인프라를 유지하는 것은 매우 어려운 일임. 이는 엔지니어링의 놀라운 성과임.
     * 환경적 고려: 폐수를 처리하지 않고 지하에 저장하는 방식은 환경에 미치는 영향을 최소화하기 위한 추가적인 노력이 필요함.
     * 에너지 효율성: 물을 녹이고 가열하는 데 많은 에너지가 소모됨. 에너지 효율성을 높이는 방법을 모색할 필요가 있음.
     * 비용 문제: 남극의 인프라 유지 비용은 매우 높음. 이는 연구 예산에 큰 부담이 될 수 있음.
     * 대체 기술: 다른 극한 환경에서도 적용할 수 있는 대체 기술 개발이 필요함. 예를 들어, 태양열이나 풍력을 활용한 에너지 절약형 시스템 등이 있음.

        Hacker News 의견

     * 흥미로운 생활 방식: 이 글을 통해 매우 독특한 생활 방식과 생존 방법을 엿볼 수 있음. 엔트로피와 에너지를 균형 있게 유지하는 것이 얼마나 어려운지 보여줌.
     * 유지 보수 이야기: 유지 보수와 관련된 이야기를 보고 싶음. 특히, 어떤 문제가 발생했을 때 어떻게 극복했는지에 대한 이야기가 흥미로울 것 같음.
     * 맥머도 담수화: 맥머도 기지는 과거에 원자력으로 담수화를 했지만, 현재는 디젤을 사용하고 있음.
     * 남극 생활: 남극에서의 생활은 외계 행성에서 사는 것과 같음.
     * 남극의 비밀: 남극 아래에 많은 비밀이 숨겨져 있을 것 같음. 어떤 것은 모르는 것이 나을 수도 있음.
     * 깊이 있는 탐구: 이런 깊이 있는 탐구 글을 항상 즐김. 모든 것이 화씨로 표시된 것이 놀라웠음.
     * 얼음 터널: 얼음 터널이 매우 멋짐. 스타워즈를 좋아하는 사람이라면 누구나 좋아할 것 같음.
     * 물 가열 에너지: 물을 -60°F에서 50°F로 가열하는 데 많은 에너지가 필요함. 고체에서 액체로의 상태 변화도 많은 에너지를 소모함.
     * 운석 수집: 북쪽에서 일하는 친구가 물을 얻기 위해 눈을 녹일 때 운석을 수집했다고 함. 로드웰 바닥에 운석 먼지가 쌓여 있을지도 궁금함.
     * 오염 우려: 폐수를 눈 덮인 곳에 다시 펌핑하는 것에 오염 우려가 없다는 것이 놀라움. -60°에서는 멀리 이동하지 않겠지만, 그래도 걱정됨.
     * 폐수 처리: 첫 번째 로드웰이 완성되기 전에는 폐수를 어떻게 처리했는지 궁금함.
     * 화씨 사용: 과학 기지가 물의 온도를 화씨로 측정하는 것이 충격적이었음.
"
"https://news.hada.io/topic?id=15316","HN에 공개: 내가 항상 원했던 노트 작성 앱 Unforget: 오프라인 우선, 암호화된 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          HN에 공개: 내가 항상 원했던 노트 작성 앱 Unforget: 오프라인 우선, 암호화된 앱

Unforget 소개

  주요 기능

     * Google Keep에서 가져오기: Google Keep의 노트를 Unforget으로 가져올 수 있음.
     * 오프라인 우선: 인터넷 연결 없이도 노트를 작성하고 관리할 수 있음.
     * 프라이버시 우선: 사용자의 데이터를 보호하기 위해 최우선으로 고려됨.
     * 프로그레시브 웹 앱: Electron.js를 사용하지 않음.
     * 오픈 소스: MIT 라이선스 하에 제공됨.
     * 종단간 암호화 동기화: 데이터가 안전하게 동기화됨.
     * 다양한 플랫폼 지원: 데스크탑, 모바일, 웹에서 사용 가능.
     * Markdown 지원: 텍스트를 쉽게 포맷할 수 있음.
     * 자체 호스팅 및 클라우드 옵션: 사용자가 선택할 수 있음.
     * 원클릭 데이터 내보내기: JSON 형식으로 데이터를 쉽게 내보낼 수 있음.
     * 공개 API: 사용자가 자신의 클라이언트를 만들 수 있음.
     * Apple Notes에서 가져오기: 곧 지원 예정.

  사용 방법

     * 간편한 가입: 무료로 가입하여 노트를 안전하게 클라우드에 백업하고 기기 간 동기화할 수 있음.
     * 옵션 설치: 브라우저에서 직접 사용하거나 설치 가능.
          + 브라우저 설치:
               o Chrome: URL 바의 설치 아이콘 클릭
               o Edge: URL 바의 설치 아이콘 클릭
               o Firefox: 설치 불가
          + 데스크탑 Safari: 공유 → Dock에 추가
          + iOS Safari: 공유 → 홈 화면에 추가
          + Android 브라우저: 메뉴 → 홈 화면에 추가

  GN⁺의 의견

     * 보안과 프라이버시: 종단간 암호화와 오프라인 우선 기능으로 보안과 프라이버시가 중요한 사용자에게 적합함.
     * 다양한 플랫폼 지원: 데스크탑, 모바일, 웹에서 모두 사용할 수 있어 유연성이 높음.
     * Markdown 지원: 텍스트 포맷팅을 쉽게 할 수 있어 개발자나 기술 문서 작성자에게 유용함.
     * 설치 옵션: 브라우저에서 직접 사용하거나 설치할 수 있어 편리함.
     * 경쟁 제품: Notion, Evernote 등과 비교해보면, Unforget은 오프라인 우선과 종단간 암호화로 차별화됨.

        Hacker News 의견

     * 오프라인 우선 스타일 PWA 작성 경험: 웹을 배포 수단으로, 브라우저를 런타임으로 사용하는 매력 있음. 하지만 로컬 스토리지의 복잡성과 데이터 이동성에 대한 우려 존재함.
     * 노트 작성 워크플로우: 노트 작성 워크플로우를 명확히 할 필요 있음. 다양한 노트 작성 시스템과 비교해 이해를 돕는 것이 중요함.
     * 구조화된 지식 저장: 전자 앱을 피하지만, JS 애플리케이션의 실험이 많음. Mermaid 다이어그램 지원 고려 필요함.
     * 자체 실행 노트 앱: 다양한 자체 실행 노트 앱 선택 가능성 긍정적임. 서비스 워커 지원 문제 해결 필요함.
     * WYSIWYG 편집기 통합: 무거운 노트 작성 시 간단한 WYSIWYG 편집기 선호함. Markdown 구문보다 사용 편리함.
     * Diary 대안: Diary 앱의 대안으로 시도해볼 가치 있음. 다양한 링크 제공됨.
     * Zettel Notes 추천: 오프라인 지원, 다양한 동기화 옵션, 단순한 Markdown 파일 저장 방식의 Zettel Notes 추천함.
     * Joplin과 비교: Joplin과 유사한 점 있음. 향후 방향성에 대한 궁금증 존재함.
     * 모바일 및 데스크탑 지원: 모바일과 데스크탑에서 모두 잘 작동하는 셀프 호스팅 노트 앱 찾고 있음. Docker 컨테이너 출시 계획 여부 궁금함.
     * 그림 그리기 기능 부족: 많은 노트 앱이 그림 그리기 기능을 제공하지 않아 사용 불가함. 이로 인해 OneNote 사용 중임.
"
"https://news.hada.io/topic?id=15195",""Pale Fire를 두려워하지 마세요"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ""Pale Fire를 두려워하지 마세요""

팔 파이어(Pale Fire)에 대한 두려움을 갖지 말라

  나보코프의 걸작, 복잡하지만 큰 마음을 가진 작품

     * **팔 파이어(Pale Fire)**는 나보코프의 가장 위대한 작품 중 하나로, 복잡하지만 감동적인 요소를 가지고 있음.
     * 이 책은 1962년 출간 이후 많은 학자들과 비평가들로부터 찬사를 받았음.
     * 책의 구조는 시와 그에 대한 주석으로 이루어져 있으며, 주석을 다는 인물인 킨보트(Kinbote)의 이야기가 중심임.

  책의 내용과 주제

     * 팔 파이어는 시인 존 쉐이드(John Shade)의 시와 그에 대한 킨보트의 주석으로 구성됨.
     * 킨보트는 자신이 젬블라(Zembla)의 왕이라고 주장하며, 쉐이드의 시가 사실 자신의 이야기를 담고 있다고 믿음.
     * 킨보트의 주석은 매우 자기 중심적이며, 그의 정신 상태와 정체성에 대한 의문을 제기함.

  비평과 논란

     * 책은 그 복잡성과 지적 깊이로 인해 찬사를 받았지만, 일부는 이를 차갑고 의도적으로 이상하다고 비판함.
     * 킨보트의 성적 지향과 성격 묘사에 대한 논란도 있음.
     * 책의 복잡한 구조와 다층적인 패턴은 독자들에게 큰 도전이 됨.

  감정적 요소

     * 팔 파이어는 단순히 지적인 즐거움만을 제공하는 것이 아니라, 깊은 감정적 요소도 포함하고 있음.
     * 킨보트의 외로움과 쉐이드 가족의 비극적인 이야기가 감동적으로 묘사됨.
     * 독자들은 책을 통해 인간 감정의 복잡성과 깊이를 느낄 수 있음.

  결론

     * 팔 파이어는 복잡한 구조와 깊은 감정적 요소를 가진 작품으로, 독자들에게 큰 감동을 줌.
     * 이 책을 처음 읽는 독자들은 그 복잡성에 겁먹지 말고, 책의 깊이와 아름다움을 느껴보길 권함.

GN⁺의 의견

     * 팔 파이어는 복잡한 구조와 다층적인 패턴으로 인해 여러 번 읽어야 그 진가를 알 수 있음.
     * 킨보트의 성격과 그의 주석은 독자들에게 신뢰할 수 없는 화자의 개념을 잘 보여줌.
     * 책의 감정적 요소는 독자들에게 깊은 인상을 남기며, 단순한 지적 즐거움을 넘어서는 경험을 제공함.
     * 나보코프의 다른 작품들, 특히 **롤리타(Lolita)**와 비교해보면, 그의 독특한 문체와 주제 의식을 더 잘 이해할 수 있음.
     * 팔 파이어는 문학적 분석과 감정적 경험을 동시에 제공하는 작품으로, 문학을 사랑하는 독자들에게 강력히 추천함.

        Hacker News 의견

    해커뉴스 댓글 요약

     * Pale Fire는 대학 시절 읽은 이후로 가장 좋아하는 책임. 책을 제대로 즐기려면 서문을 먼저 읽고, 시를 건너뛰고 주석을 읽은 후 시를 읽는 것이 좋음. 책의 주요 재미는 등장인물들의 정체와 시의 저자를 추리하는 것임.
     * Pale Fire를 자기 패러디로 보았고, 그래서 더 즐겼음.
     * 나보코프는 Eugene Onegin 번역 작업 중 많은 주석을 달았고, 이는 Pale Fire에도 반영되었을 것임.
     * 최근 비행기에서 Pale Fire를 읽었는데, 처음에는 짜증났지만 점점 흥미로워졌음. 10페이지 정도 읽으면 모든 것을 완전히 이해할 수 없다는 것을 깨닫게 됨.
     * Blade Runner 2049를 보고 Pale Fire를 샀음. 이제 이 댓글을 보고 읽어야겠다고 생각함.
     * Pale Fire를 읽으려면 종이책으로 읽는 것이 좋음. 전자책은 시와 산문을 오가며 읽기 불편함.
     * 나보코프를 좋아해서 길고양이에게 그의 이름을 붙였음. Pale Fire는 훌륭하지만 접근하기 어려운 책이므로, 더 쉽게 읽을 수 있는 Laughter in the Dark를 추천함.
     * Pale Fire는 몇 번 읽었지만 피곤한 책임. 나보코프는 독자를 혼란스럽게 하는 함정을 많이 넣었음. 문학 비평가들이 많이 연구하는 책임.
     * Lolita를 읽고 Pale Fire를 기대했지만, 개인적으로는 지루했음. 문학적 이해가 부족해서 그런 것 같음.
     * Pale Fire는 나보코프의 작품 중 가장 좋아하는 책임. 여러 번 읽었지만 완전히 이해하지 못했음. 시와 주석이 흥미롭고 재미있음.
     * 나보코프가 모국어가 아닌 영어로 이렇게 아름다운 글을 쓴다는 것이 부끄러움.
"
"https://news.hada.io/topic?id=15237","미쯔비시 로봇, Rubik's Cube를 0.305초만에 풀어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   미쯔비시 로봇, Rubik's Cube를 0.305초만에 풀어

     * Mitsubishi Electric에서 TOKUFASTbot이라는 로봇을 개발
          + 이 로봇은 루빅스 큐브 퍼즐을 0.305초 만에 풀 수 있음
          + 이는 기존 기네스 세계 기록인 0.38초를 크게 앞선 것
     * TOKUFASTbot의 작동 원리
          + 큐브의 각 면에 서보 모터가 연결되어 있음
          + 각 모터는 0.009초 만에 90도 회전이 가능함
          + AI 색상 인식 알고리즘과 연동되어 빠르게 큐브를 풀어냄
     * 기록 경신을 위해 기네스 월드 레코드 심사관들이 참여했으며, 공식 기록은 0.305초로 인정됨
          + 첫 시도에서는 큐브가 끼는 문제가 발생했음
          + 사용된 큐브가 일반 루빅스 큐브인지, 스피드 큐브인지는 명확히 언급되지 않음
     * 온라인 반응
          + ""저 큐브에 기름을 많이 넣었나 봐요.""
          + ""이보다 더 빠른 속도를 내기 위해서는 큐브의 마찰을 줄일 수 있는 방법이 필요할 것입니다.""
          + ""내 평생 이 문제를 풀지 못할 거라는 사실을 인정하게 되었어요.""
          + ""그럼 이걸로 무엇을 할 수 있을까요?""
          + ""정밀한 모터 제어는 제조업의 중추입니다.""
          + ""저보다 조금 더 빠르네요.""
          + ""저렇게 빨리 90도 회전하고 정확한 위치에 멈추기란 쉽지 않겠군요.""
          + ""여기까지 오려면 루빅스 큐브를 많이 깨뜨렸을 거예요.""
     * Mitsubishi는 TOKUFASTbot의 속도를 일상의 순간적인 사건들(커피 쏟아짐, 비누방울 터짐 등)과 비교한 짧은 영상들도 공개함
     * 저자의 의견
          + 큐브의 상세 스펙에 대한 정보가 있으면 좋겠지만, 그렇다고 이게 성과의 가치를 떨어뜨리진 않음
          + 우아하고 정밀한 로봇의 움직임이 마음을 편안하게 해줌
          + 소음을 줄이고 크기를 축소한 버전이 있다면 실내 장식용으로도 고려해볼 만함

   스피드큐빙을 했봤었는데, 인간 최소 움직임이 16회인 것은 특별한 케이스로 생각되고,
   일반적인 경우, 컴퓨터는 최소 회전수를 찾아 낼 수 있는데, 사람은 단계별 회전 공식을 사용해야하다보니 회전수 차이가 꽤 납니다.

  Hacker News 의견

     * 로봇의 속도: 로봇의 속도는 매우 빠르며, 사람들은 이를 쉽게 이해하지 못함. 로봇이 반란을 일으킨다면, 그 속도 때문에 알아차리지 못할 것임.
     * 스피드 큐브 로봇의 장점: 스피드 큐브 로봇은 매우 빠르게 움직이며, 공상 과학 영화의 리액터처럼 보이고, 큐브가 막히면 폭발할 수 있음.
     * 2018년 기록: 2018년에 한 팀이 0.38초 만에 큐브를 해결했음. 관련 비디오와 하드웨어, 소프트웨어 정보 링크 제공됨.
     * 비교 분석: 다른 큐브 해결 로봇과 비교했을 때, 이 로봇은 오버슈트가 적어 더 인상적임.
     * 경쟁적 스피드큐버: 경쟁적인 스피드큐버로서, 자신의 최고 기록은 5초 조금 넘음. 이 로봇은 초당 약 67회 회전 가능하며, 인간은 최대 20~30회 회전 가능함.
     * 성공 요인: 이 로봇의 성공이 처리 속도와 전략 개선에 기반한 것인지, 기계적 최적화에 기반한 것인지 궁금함. 기네스 기록은 여러 랜덤 시작 위치에서 평균을 내야 공정할 것임.
     * 10년 경력의 큐버: 10년 동안 큐브를 해결해왔으며, 인간에게 불가능한 동작을 로봇이 수행할 수 있음.
     * 로봇의 이점: 로봇은 양쪽을 동시에 회전할 수 있어 0.3초 만에 해결 가능함. 인간은 한 번에 한쪽만 회전 가능함.
     * 인간 대 로봇: 인간 대회에서는 손이 타이머에 닿아야 기록이 유효함. 로봇이 큐브를 로드하고 언로드하는 시간도 포함하면 인간 기록과 비교하기 어려움.
     * 솔루션 재구성: 솔루션 재구성 비디오 링크 제공됨. 16번의 움직임으로 해결한 것은 매우 운이 좋은 경우임. 인간의 최소 움직임 기록도 16번임.

   인간도 한번에 양쪽 면을 동시에 움직일 수 있기는 합니다(실제로 자주 나오는 동작이기도 하구요). 물론 팔이 6개인 로봇에 비해서는 모든 방향에서 언제든지 가능하진 않죠
"
"https://news.hada.io/topic?id=15218","macOS용 i3 유사 타일링 윈도우 매니저 AeroSpace","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   macOS용 i3 유사 타일링 윈도우 매니저 AeroSpace

AeroSpace Beta

  프로젝트 상태

     * 공개 베타 상태임.
     * 사용자 피드백을 적극적으로 환영함.
     * 개발자는 이미 일상적으로 사용하고 있으며 만족하고 있음.
     * 문서에는 주요 사항이 모두 포함되어 있음.

  주요 기능

     * 수동 타일링 윈도우 매니저로 트리 패러다임 기반임.
     * i3에서 영감을 받음.
     * macOS의 네이티브 Spaces 대신 자체 가상 작업 공간 에뮬레이션을 사용함.
     * 평문 텍스트 구성 파일 사용 (dotfiles 친화적).
     * CLI 스크립트 가능.
     * SIP (System Integrity Protection) 비활성화가 필요하지 않음.
     * 다중 모니터 지원 (i3와 유사한 패러다임).
     * 상태 메뉴 아이콘이 현재 작업 공간 이름을 표시함.

  설치

     * Homebrew를 통해 설치하여 자동 업데이트를 받는 것이 권장됨.
brew install --cask nikitabobko/tap/aerospace

     * 수동 설치도 가능함.
     * AeroSpace는 Apple의 공인(notarized)을 받지 않았음.

  기여, 이슈 생성, 풀 리퀘스트 제출

     * 자세한 내용은 CONTRIBUTING.md 파일 참조.

  개발

     * 프로젝트 설정, 빌드, 테스트 실행 방법 등은 dev-docs/development.md 파일에 있음.

  프로젝트 가치

     * 대상: 고급 사용자 및 개발자.
     * 키보드 중심.
     * 구성 파일, CLI, 동작의 변경은 최대한 피하지만, 소프트웨어의 정체를 막기 위해 필요시 변경 가능함.
     * GUI 사용 최소화: 구성 파일은 텍스트 편집기로 편집하는 것이 더 쉬움.
     * 실용적인 기능 제공: 창 테두리, 투명도 등은 실용적이지 않음.
     * SIP 비활성화 요구 없음: 예를 들어, yabai는 일부 기능을 위해 SIP 비활성화를 요구하지만, AeroSpace는 다른 방법을 찾거나 해당 기능을 구현하지 않음.

  오늘의 팁

     * 다음 명령어를 사용하면 ctrl+cmd를 누르고 창의 아무 부분이나 드래그하여 창을 이동할 수 있음.
defaults write -g NSWindowShouldDragOnGesture YES

  관련 프로젝트

     * Amethyst
     * yabai

GN⁺의 의견

     * AeroSpace의 가치: 고급 사용자와 개발자를 대상으로 하여 키보드 중심의 효율적인 작업 환경을 제공함.
     * SIP 비활성화 필요 없음: 보안 측면에서 큰 장점이 될 수 있음.
     * 구성 파일의 텍스트 편집: GUI보다 빠르고 효율적일 수 있음.
     * macOS 네이티브 기능과의 호환성: 일부 macOS 기능과 호환되지 않을 수 있음.
     * 대안 제품: Amethyst와 yabai도 유사한 기능을 제공함. 각각의 장단점을 비교해보는 것이 좋음.

        Hacker News 의견

    해커뉴스 댓글 요약

     * 첫 번째 의견: AeroSpace는 Mac에서 창 관리를 위한 최고의 방법이지만 i3/sway보다는 부족함. 특히 창을 드래그하여 재배치하는 기능이 제한적임.
     * 두 번째 의견: SIP(System Integrity Protection)을 비활성화하지 않아도 된다는 점이 흥미로움. AeroSpace가 SIP를 비활성화하지 않고도 작동하는 방법이 궁금함.
     * 세 번째 의견: AeroSpace는 SIP를 비활성화하지 않으며, 다른 방법을 찾거나 특정 기능을 구현하지 않음.
     * 네 번째 의견: Apple이 즉시 이 개발자를 채용해야 함.
     * 다섯 번째 의견: 가짜 Spaces 접근 방식을 좋아함. macOS에서 타일링은 API 부족으로 어려움.
     * 여섯 번째 의견: yabai를 창 이동과 마우스 포커스 기능만 사용함. 타일링은 불안정함.
     * 일곱 번째 의견: alt-tab을 수정하여 모든 창을 무시하도록 하는 방법을 찾고 있음. JankyBorders도 언급됨.
     * 여덟 번째 의견: yabai를 5년간 사용 중이며, SIP를 비활성화하지 않고도 잘 작동함. 다중 모니터는 어렵지만, 스택과 빠른 전체 화면 기능이 매우 유용함.
     * 아홉 번째 의견: Yabai와 AeroSpace의 사용자 경험 차이가 궁금함. SIP 문제는 큰 문제가 아님. Fluxbox와 유사한 유틸리티를 사용 중임.
     * 열 번째 의견: Amethyst와의 차이점이 궁금함. Amethyst는 안정적이며, 텍스트 기반 설정이 좋음.
     * 열한 번째 의견: 몇 달간 사용해본 결과, i3는 완벽하지만 AeroSpace는 불안정함. Mac OS X는 Unix WMs처럼 완전한 제어를 허용하지 않음.
     * 열두 번째 의견: macOS에서 또 다른 타일링 윈도우 매니저(twm)를 보는 것이 좋음. Windows가 더 활발한 플랫폼이 되었음.
     * 열세 번째 의견: 새로운 컨테이너를 만드는 방법이 궁금함. join-with 명령어가 split 명령어의 상위 집합임을 발견함.
"
"https://news.hada.io/topic?id=15271","ChatGPT 실수로 인한 $10,000 손실","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ChatGPT 실수로 인한 $10,000 손실

단일 ChatGPT 실수로 $10,000+ 손실

  수익화 과정 🛣️

     * 배경: 스타트업 초기 단계에서 수익화를 시작함.
     * 가격 설정: YC 그룹 파트너의 조언에 따라 월 $40로 설정함.
     * 기술 스택: NextJS에서 Python/FastAPI로 마이그레이션함. Stripe 통합 완료.

  $10,000 손실의 원인 💰

     * 문제 발생: 구독 기능에서 무한 로딩 스피너 문제 발생.
     * 문제 해결: 5일 동안 수많은 이메일과 로그를 분석한 끝에 문제 발견.
     * 원인: ChatGPT가 생성한 코드에서 ID 생성 방식에 오류가 있었음. 고정된 ID 문자열을 사용하여 ID 충돌 발생.

  버그 잡기 🐛

     * 문제 설명: 고정된 ID 문자열 사용으로 인해 ID 충돌 발생. AWS ECS에서 여러 인스턴스가 돌아가면서 낮에는 문제 없었으나, 밤에는 충돌 발생.
     * 해결 방법: 고정된 ID 대신 UUID 생성 함수 사용. 문제 해결 후 안정화됨.

  결론 🤖

     * 교훈: 테스트 부족, 코드 복사 붙여넣기, 직접 메인 브랜치에 커밋하는 등의 실수를 인정함.
     * 경험: 고통스러운 경험이었지만, 스타트업의 중요한 순간으로 기억됨.

GN⁺의 의견

     * 테스트의 중요성: 충분한 단위 테스트와 통합 테스트가 필요함.
     * 코드 리뷰: 코드 복사 붙여넣기 대신 코드 리뷰와 검증이 중요함.
     * 배포 전략: 직접 메인 브랜치에 커밋하는 대신, 별도의 브랜치를 사용하고 코드 리뷰를 거치는 것이 좋음.
     * 문제 해결 능력: 문제를 빠르게 식별하고 해결하는 능력이 중요함.
     * 기술 스택 선택: 기술 스택의 변경은 신중하게 계획하고 테스트해야 함.

   엥, AI에 의한 자동 생성 코드는 반드시 리뷰를 해야죠, 그걸 왜 그대로 사용해요.

        Hacker News 의견

     * 첫 번째 의견: 오류를 즉시 발견했음. 팀의 전문성 부족이 원인임. 모니터링 솔루션을 사용했다면 쉽게 잡을 수 있었을 것임.
     * 두 번째 의견: ChatGPT 덕분에 앱이 수익을 창출했음. 코딩, 디버깅, 로깅, 모니터링 능력 부족이 $10,000 손실의 원인임.
     * 세 번째 의견: 모니터링 부족이 $10,000 손실의 원인임. 데이터베이스 예외가 발생했지만 경고가 없었음. 경고가 있었다면 5분 만에 해결할 수 있었을 것임.
     * 네 번째 의견: Python의 기본값 인수 평가 전략 문제를 지적함. 함수 정의 시점에 평가됨. 효율성을 위해 의도된 것일 수 있음. Python의 리스트 생성 방식도 문제로 지적됨.
     * 다섯 번째 의견: 사람도 같은 실수를 자주 함. 특히 React/TypeScript/JavaScript에서 람다 사용을 잊는 경우가 많음. 블로그 글이 문제의 근본 원인을 제대로 설명하지 못했다고 생각함.
     * 여섯 번째 의견: 실수는 쉽게 발생할 수 있음. 그러나 첫 번째 실패 후 왜 잡히지 않았는지 이해할 수 없음. 로깅이 없었는지 의문임.
     * 일곱 번째 의견: 이 문제를 공개하는 것이 순진하게 느껴짐. ChatGPT는 비난받을 이유가 없음. 코드 리뷰 서비스 아이디어를 떠올리게 함.
     * 여덟 번째 의견: 시간 제약 때문에 발생한 문제임. 이런 제약 때문에 소프트웨어 구독을 두려워함.
     * 아홉 번째 의견: 고객도 없는 상태에서 전체 리라이트를 정당화하는 스타트업이 이해되지 않음.
     * 열 번째 의견: LLMs 사용 기술은 언제, 어떻게 사용할지 아는 것임. ChatGPT의 답변이 적절했지만, 특정 라인에서 모든 사용자를 삭제하라는 권고를 보고 큰 교훈을 얻었음.

   각 의견은 소프트웨어 개발 과정에서 발생할 수 있는 문제와 그 해결책에 대한 다양한 시각을 제공함. 초급 소프트웨어 엔지니어에게 유익한 통찰을 줄 수 있음.
"
"https://news.hada.io/topic?id=15235","Alibaba, Qwen 2 모델 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Alibaba, Qwen 2 모델 공개

     * Qwen2는 Qwen1.5에서 발전된 모델로, 5가지 크기의 사전 학습 및 명령어 튜닝 모델을 포함
          + 모델 크기는 Qwen2-0.5B, Qwen2-1.5B, Qwen2-7B, Qwen2-57B-A14B, Qwen2-72B
     * 영어와 중국어 외에 27개 언어로 데이터를 추가 학습
     * 다수의 벤치마크 평가에서 최첨단 성능을 보여주며, 코딩과 수학 분야에서 크게 성능이 개선
     * Qwen2-7B-Instruct와 Qwen2-72B-Instruct 모델은 YARN을 활용해 최대 128K 토큰의 확장된 컨텍스트 길이를 지원

Qwen2 모델 정보

     * 모든 모델 크기에 Group Query Attention(GQA)를 적용해 추론 속도 향상과 메모리 사용량 감소
     * 작은 모델의 경우 임베딩 타이잉 기법 적용을 선호
     * 명령어 튜닝 모델은 Needle in a Haystack 태스크 평가를 통해 컨텍스트 길이 처리 능력을 평가
     * YARN 기술을 통해 Qwen2-7B-Instruct와 Qwen2-72B-Instruct는 128K 토큰까지 처리 가능

성능

     * 영어, 중국어 외 27개 언어 데이터셋으로 사전학습과 명령어 튜닝을 진행해 다국어 역량을 강화
     * 코드 스위칭 처리 능력이 크게 개선됨
     * 사전학습 데이터셋과 최적화된 학습 방법을 활용해 Qwen2-72B는 Llama-3-70B 등 최신 모델보다 우수한 성능을 보임
     * 사후 학습을 통해 코딩, 수학, 추론, 명령 수행, 다국어 이해 등의 역량을 더욱 향상시켰고, 인간 가치 정렬도 이뤄냈음
     * 16개 벤치마크에서 Qwen2-72B-Instruct는 Qwen1.5-72B-Chat을 크게 앞서고 Llama-3-70B-Instruct와 견줄만한 성능을 보임
     * 작은 크기의 Qwen2 모델들도 비슷하거나 더 큰 SOTA 모델을 능가함. 특히 코딩과 중국어 관련 지표에서 두각을 나타냄

주요 사항

     * CodeQwen1.5의 코드 학습 경험과 데이터를 통합해 Qwen2-72B-Instruct의 다양한 프로그래밍 언어 성능을 크게 향상
     * 광범위하고 고품질의 데이터셋을 활용해 Qwen2-72B-Instruct의 수학 문제 해결 역량을 강화
     * 128K 길이의 정보 추출 태스크를 Qwen2-72B-Instruct가 완벽하게 처리할 수 있음
     * 100만 토큰 문서 처리를 위한 효율적인 에이전트 솔루션도 오픈소스화함
     * 4가지 유형의 다국어 유해 질의에 대한 유해 응답 비율을 평가한 결과, Qwen2-72B-Instruct는 GPT-4와 비슷한 수준의 안전성을 보이며 Mistral-8x22B보다 크게 우수

Qwen2의 활용

     * 모든 모델이 Hugging Face와 ModelScope에 공개되어 자유롭게 활용 가능
     * Qwen2-72B와 명령어 튜닝 모델은 Qianwen License를, 나머지 모델들은 Apache 2.0 라이선스를 채택
     * 다양한 써드파티 프레임워크와 함께 Qwen2를 활용하는 방법은 각 프레임워크 문서와 공식 문서 참고

Qwen2의 미래 계획

     * 더 큰 Qwen2 모델을 학습시켜 데이터 스케일링과 함께 모델 스케일링을 탐구할 예정
     * 시각과 청각 정보도 이해할 수 있는 멀티모달 언어 모델로 Qwen2를 확장할 계획
     * 앞으로도 새로운 모델을 오픈소스화하여 오픈소스 AI 발전을 가속화할 것

   Alibaba, 오픈소스 AI 모델 QWEN 공개
   Qwen1.5-110B : 알리바바의 오픈소스 LLM Qwen1.5 시리즈의 첫번째 100B+ 모델
"
"https://news.hada.io/topic?id=15224","GPT-4에서 개념 추출","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             GPT-4에서 개념 추출

        Hacker News 의견

     * 흥미로운 연구: Anthropic의 ""Mapping the Mind of a Large Language Model"" 발표 후 빠르게 나온 연구라 흥미로움. 많은 사람들이 여전히 ""우리는 LLMs/딥러닝이 어떻게 작동하는지 모른다""고 하지만, 이런 연구들이 그 일반화를 반박함.
     * 예시 선택 의문: GPT-4의 예시 중 가격 인상과 관련된 문구가 실제로는 가격 하락을 나타내는 경우가 있어 이해가 어려움. 왜 이런 예시가 선택되었는지 의문임.
     * 고급 의미 검색: 문서에서 가격 인상 같은 개념을 필터링하는 예시가 마음에 듦. 모델을 훈련시키는 것보다 더 빠르고 정확할 수 있음.
     * 분류 오류: 과학적 설명을 에로틱 콘텐츠로 분류하는 오류가 있음. 링크를 통해 확인 가능함.
     * 유사 연구: Anthropic의 Claude 3 Sonnet 연구와 유사함을 상기시킴.
     * 모델 해석: SHAP 같은 도구를 적용하는 것과 비교했을 때 이 연구가 어떻게 개선되었는지 궁금함. ""우리는 현재 언어 모델의 신경 활동을 이해하지 못한다""는 주장은 틀림.
     * 기본 설명 요청: 이 연구의 중요성을 쉽게 설명해줄 수 있는지 요청함.
     * 오픈 모델 동반 도구: 신경망의 출력을 설명하는 오토 인코더를 공개하는 것이 좋은 실천이 될 수 있음. Hugging Face의 모든 오픈 모델에 유용한 동반 도구가 될 수 있음.
     * 신경망의 fMRI: 신경망의 특정 주제에 따라 활성화되는 영역을 볼 수 있는 fMRI와 유사함. 평가 신경망을 연결해 자동으로 활성화 영역을 평가할 수 있을지 궁금함.
     * 희소 임베딩 관련성: 희소 임베딩(Splade 등)과 관련이 있을 수 있으며, 하이브리드 검색에 사용할 수 있을지 궁금함.
"
"https://news.hada.io/topic?id=15304","a16z가 정리한 AI Voice 에이전트에 대한 모든 것","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    a16z가 정리한 AI Voice 에이전트에 대한 모든 것

     * 생성형 AI 덕분에 앞으로 인간은 전화 통화를 할 필요가 없어짐
     * 인간은 전화 통화에 가치가 있을 때만 시간을 할애하게 될 것임

  기업에게 주는 혜택

    1. 인간 발신자로 인한 시간과 인건비 절감
    2. 수익 창출 증대를 위한 자원 재배치 가능성
    3. 더 규격화되고 일관된 고객 경험으로 리스크 감소

  소비자에게 주는 혜택

     * 음성 에이전트는 실제 사람에게 돈을 지불하거나 ""매칭""할 필요 없이 사람 수준의 서비스를 제공할 수 있음
          + 현재는 치료사, 코치, 동반자 등이 포함됨
          + 미래에는 음성을 중심으로 구축된 훨씬 더 광범위한 경험을 포괄할 가능성이 높음
     * 대부분의 다른 소비자 소프트웨어와 마찬가지로 ""승자""는 예측할 수 없을 것임

     전화 통화는 세상과 소통하는 API이며, AI는 이를 한 단계 더 끌어올림

  기회가 있다고 보이는 곳

     * 인프라 플레이어, 소비자 인터페이스, 기업용 에이전트 등 각 계층에는 엄청난 기회가 있음
     * B2C 및 B2B 음성 에이전트의 경우, 가장 흥미로운 신흥 제품에 대해 몇 가지 가설이 있음:

    B2B 및 B2C 음성 에이전트의 주요 특징

     * Built to scale (확장성 있게 구축됨)
          + 지연 시간과 대화 경험은 아직 해결되지 않음
          + 에이전트 구축에 대해 의견이 있는 창업자를 찾고 있음
          + 에이전트의 가장 중요한 것(속도, 정확성, 톤/감정 등)을 극대화하기 위해 노력 중
     * Vertically focused (수직적으로 집중됨)
          + 이는 특정 사용 사례에 맞춰진 독특하게 조정된 모델과 긴밀한 통합에 의존하는 연주자 에이전트일 수 있음
          + 이는 구축하고 시장에 내놓고 성공적으로 성장시키기 쉬움
     * Realistic in scope (범위에서 현실적임)
          + AI에 중요한 통화를 완전히 위임하는 것은 큰 과제임
          + 우리는 음성 에이전트 회사가 단기적으로 ""확장""할 수 없는 일을 하기를 기대함
          + 여기에는 고객별 튜닝 또는 최종 단계를 위해 인간 에이전트에게 통화를 넘기는 것이 포함될 수 있음

  음성 에이전트 구축을 위한 스택

     * 음성 에이전트가 작동하려면 다음이 필요함:
          + 인간의 음성을 수집(ASR)
          + LLM을 사용하여 이 입력을 처리하고 출력을 반환
          + 인간에게 다시 말하기(TTS)
     * GPT-4o와 같은 새로운 다중 모달 모델은 하나의 모델을 통해 이러한 여러 계층을 동시에 ""실행""함으로써 스택의 구조를 변경할 수 있음
          + 이는 지연 시간과 비용을 줄이고 더 자연스러운 대화형 인터페이스를 제공할 수 있음
          + 많은 에이전트는 아래의 합성된 스택으로 진정한 인간 같은 품질에 도달하지 못했음
     * 일부 회사/접근 방식에서는 LLM 또는 일련의 LLM이 대화 흐름과 감정을 처리함. 다른 경우에는 감정을 추가하고 중단을 관리하는 등의 고유한 엔진이 있음
          + ""풀 스택"" 음성 제공업체는 이 모든 것을 한 곳에서 제공함.
     * 소비자(B2C) 및 기업(B2B) 앱은 이 스택 위에 있음.
     * 서드파티 제공업체를 사용하더라도 앱은 (일반적으로) 사용자 정의 LLM을 플러그인하는데, 이는 종종 대화 엔진 역할도 함.

  풀 스택 vs. 자체 조립: 주요 요소 비교

     * 음성 에이전트 창업자는 풀 스택 플랫폼(예: Retell, Vapi, Bland)에서 에이전트를 돌리거나 스택을 직접 조립하는 것 사이에서 선택할 수 있음.
     * 이 결정을 내릴 때 몇 가지 주요 요소가 있음:
          + Complexity (복잡성)
               o 풀 스택 플레이어는 인프라 측면의 복잡성을 추상화하면서 음성 에이전트를 더 간단하게 구축할 수 있는 방법을 제공함
               o 이는 프롬프트나 지식 문서(RAG)를 LLM에 플러그인하는 것과 같은 사용자 정의 및 튜닝의 여지를 여전히 남겨둠
          + Flexibility (유연성)
               o 특정 수직 시장과 사용 사례를 구축하는 창업자는 스택의 각 계층이 어떻게 작동/실행되는지에 대해 최대한의 유연성을 원할 가능성이 높음
               o 이는 가능한 한 지연 시간을 줄이고 함께 얻을 수 있음
          + Cost (비용)
               o 풀 스택 제공업체는 통화당 추가 비용 수준을 도입할 수 있으며, 볼륨으로 더 나은 가격을 협상할 수도 있음
               o 규모의 음성 에이전트의 경우 통화당 몇 센트 차이는 중요할 수 있음
          + Control (제어)
               o 잘못될 경우 음성 에이전트 창업자는 문제를 즉시 추적하고 해결할 수 있어야 함. 특히 민감한 사용 사례의 경우 더욱 그러함
               o 또한 각 계층이 어떻게 작동하는지에 대한 최대한의 가시성이 필요할 수 있음
               o 자체 조립식 스택으로 이를 더 쉽게 할 수 있음
     * 스택의 주요 플레이어들
          + Full Stack (풀 스택) : hume, Retell AI, VAPI, vocode, sindarin., BLAND.AI
          + Emotion (감정) : hume
          + Text to Speech (텍스트 음성 변환) : ElevenLabs, Azure
          + Speech to Text (음성 텍스트 변환) : Deepgram, Whisper, AssemblyAI, Azure
          + Streaming (스트리밍) : LiveKit, daily

  B2B 에이전트에 대한 우리의 견해

    AI 음성의 진화

     * 우리는 1.0 AI 음성(전화 트리)에서 2.0 AI 음성(LLM 기반) 시대로 전환하고 있음
     * 2.0 기업들은 지난 6개월 정도에 등장하기 시작했음
     * 1.0 기업들이 지금은 더 정확할 수 있지만, 장기적으로는 2.0 접근 방식이 훨씬 더 확장 가능하고 정확할 것임

    수직 시장에 특화된 모델의 필요성

     * 모든 유형의 기업용 음성 에이전트에 적용되는 하나의 수평적 모델이나 플랫폼은 없을 것임
     * 수직 시장별로 몇 가지 주요 차이점이 있음:
         1. 통화 유형, 톤 및 구조
         2. 통합 및 프로세스
         3. GTM 및 ""킬러 기능""
     * 이는 UI에서 고도로 의견화된 수직 에이전트의 폭발적 증가를 의미할 수 있음
     * 이를 위해서는 해당 분야에 대한 전문 지식이나 관심을 가진 창업팀이 필요함

    가장 근접한 기회

     * 노동력이 많은 기업에게는 TAM이 큼
     * 가장 근시일 내 기회는 다음과 같은 산업에 있을 수 있음:
          + 전화 예약으로 살고 죽는 곳
          + 심각한 노동력 부족을 겪는 곳
          + 통화 복잡성이 낮은 곳
     * 에이전트가 더 정교해짐에 따라 더 복잡한 통화를 처리할 수 있게 될 것임

  B2B 에이전트의 진화

     * 진화 과정
          + IVR (Interactive Voice Response) : 전통적인 터치톤 모델로, 에이전트가 소비자에게 일련의 옵션(1번은 판매, 2번은 고객 지원 등)을 제공하고 이에 따라 소비자를 안내함
          + AI 1.0 (Phone Trees) : IVR의 좀 더 유연하고 직관적인 버전으로, 소비자가 자연어로 말하고 에이전트는 일련의 대화 흐름을 통해 안내하려고 시도함
          + AI 2.0 (LLMs) : 자유로운 형식의 대화로, AI가 인간이 말하는 특정 사전 정의된 옵션을 일치시키려 하지 않음
     * 많은 음성 에이전트 회사들은 특정 산업(예: 자동차 서비스) 또는 특정 유형의 작업(예: 약속 예약)에 대해 수직 시장별 접근 방식을 취하고 있음. 이는 몇 가지 이유 때문임:
          + 실행의 어려움
               o AI에 전화를 맡기기 위한 품질 기준이 높고, 대화 흐름(및 고객 측의 백엔드 워크플로)이 빠르게 복잡해지거나 구체화될 수 있음
               o 이러한 수직 시장의 ""예외 사례""를 구축하는 회사는 성공 가능성이 더 높음 (예: 일반 모델이 오해할 수 있는 고유한 어휘)
          + 규정 및 라이선스
               o 일부 음성 에이전트 회사는 특별한 제한, 필요한 인증 등에 직면함
               o 대표적인 예는 의료 분야(예: HIPAA 준수)이지만, 국가 차원에서 AI 콜드 콜링 규제가 있는 영업과 같은 범주에서도 나타나고 있음
          + 통합
               o 일부 카테고리에서 사용자 경험(기업과 소비자 모두)을 제대로 구현하려면 롱테일 통합 또는 특수 통합이 필요할 수 있음. 이는 특정 사용 사례를 처리하려는 경우가 아니면 구축할 가치가 없음
          + 다른 소프트웨어로의 진입
               o 음성은 예약, 갱신, 견적 등과 같은 핵심 고객 행동에 자연스럽게 진입할 수 있음
               o 경우에 따라 이는 이러한 기업을 위한 더 광범위한 수직형 SaaS 플랫폼으로 진출할 수 있는 계기가 될 것임. 특히 고객층이 여전히 오프라인에서 운영되는 경우 더욱 그러함

  B2B 에이전트: 기회가 보이는 곳

    LLM 기반 - 그러나 반드시 첫날부터 100% 자동화될 필요는 없음

     * AI 음성 에이전트의 ""강력한 형태""는 IVR이나 전화 트리 접근 방식이 아닌 완전히 LLM 주도의 대화가 될 것임
     * 그러나 LLM이 전 과정에서 100% 신뢰할 수 없기 때문에, 더 민감하거나 큰 거래에는 (일시적으로) ""인간 개입""이 있을 가능성이 있음
     * 이는 또한 수직 시장별 워크플로를 특히 중요하게 만드는데, 이를 통해 에지 케이스를 최소화하면서 성공 확률을 최대화하고 인간의 간섭을 최소화할 수 있음

    사용자 정의 모델 튜닝 vs. LLM 접근 방식 프롬프트

     * B2B 음성 에이전트는 일반 LLM으로는 불충분할 가능성이 있는 전문화된(또는 수직 시장별) 대화를 다룰 필요가 있음
     * 많은 회사가 고객별 모델을 튜닝하고 있으며(몇 백 또는 낮은 수천 개의 데이터 포인트 사용), 이를 회사 전체 기본 모델로 추론할 가능성이 있음
     * 기업 고객을 위한 사용자 정의 튜닝은 계속될 수도 있음
          + 참고: 일부 회사는 특정 사용 사례에 맞게 ""일반"" 모델(고객 전체에서 사용될)을 튜닝한 다음 고객별로 프롬프트할 수 있음

    도메인 전문 지식을 갖춘 기술 팀

     * 복잡성을 고려할 때 고품질 B2B 음성 에이전트를 구축하고 확장하려면 사전 AI 배경이 도움이 될 것임
     * 그러나 제품을 패키징하고 수직 시장에 쐐기를 박는 방법을 이해하는 것도 도메인 전문 지식이나 강한 관심이 필요하기에 동등하게 중요할 가능성이 있음
     * 기업용 음성 에이전트를 구축하고 출시하기 위해 AI 박사학위가 필요하지는 않음!

    통합 + 생태계에 대한 날카로운 관점

     * 상기 내용과 유사하게, 각 수직 시장의 구매자는 구매 전에 일반적으로 보고 싶어 하는 몇 가지 특정 기능이나 통합이 있음
     * 실제로 이것이 제품을 ""유용한"" 것에서 ""마법 같은"" 것으로 평가를 높이는 증거가 될 수 있음
     * 이것이 꽤 수직화된 상태에서 시작하는 것이 이치에 맞는 또 다른 이유임

    ""엔터프라이즈 등급"" 또는 강력한 제품 주도 성장(PLG) 모션

     * 상위 기업/공급자에 상당한 매출이 집중된 수직 시장의 경우, 음성 에이전트 회사는 대기업에서 시작하여 결국 셀프 서비스 제품으로 중소기업으로 ""하향 전파""될 수 있음
     * 중소기업 고객은 이 솔루션을 절실히 원하고 다양한 옵션을 테스트할 용의가 있지만, 스타트업이 모델을 기업 수준으로 조정할 수 있는 규모/품질의 데이터를 제공하지 못할 수 있음

  B2C 에이전트에 대한 우리의 견해

    B2B와의 차이점

     * B2B에서 음성 에이전트는 주로 특정 작업을 완료하기 위해 기존 전화 통화를 대체함
     * 소비자 에이전트의 경우, 사용자가 계속 참여하기로 선택해야 하는데, 음성으로 상호 작용하는 것이 항상 편리한 것은 아니기 때문에 이는 어려움
     * 이는 제품 기준이 ""더 높음""을 의미함

    첫 번째 적용 분야

     * 소비자 음성 에이전트의 첫 번째이자 가장 명백한 적용 분야는 비싸거나 접근하기 어려운 인간 서비스를 AI로 대체하는 것임
     * 여기에는 치료, 코칭, 튜터링 등 가상으로 완료할 수 있는 대화 기반의 모든 것이 포함됨

    앞으로의 가능성

     * 그러나 우리는 B2C 음성 에이전트의 진정한 마법은 아직 오지 않았다고 믿음!
     * 우리는 음성의 힘을 사용하여 이전에 존재하지 않았던 새로운 종류의 ""대화""를 가능하게 하는 제품을 찾고 있음
     * 이는 기존 서비스의 형태를 재발명하거나 완전히 새로운 서비스를 만들어낼 수 있음

    인간적 연결의 모방

     * UX를 제대로 구현한 제품의 경우, 음성 에이전트는 소프트웨어에서 이전에 볼 수 없었던 수준으로 소비자를 끌어들일 기회를 제공함
     * 이는 진정으로 인간적 연결을 모방하는 것임
     * 이는 에이전트를 제품으로, 또는 더 광범위한 제품의 음성 모드로 나타날 수 있음

  B2C 에이전트의 진화

     * 지금까지 지배적인 소비자 AI 음성 에이전트는 ChatGPT Voice와 Inflection의 Pi 앱과 같은 대기업에서 나왔음.
     * 소비자용 음성이 더디게 등장한 데에는 몇 가지 이유가 있음:

    대기업의 우위

     * 대기업은 이미 소비자 유통망과 정확성, 지연 시간 등 측면에서 최고 수준의 모델을 보유하고 있음
     * 음성은 대규모로 제공하기가 쉽지 않음. 특히 최근 GPT-4o가 출시된 것을 감안하면 더욱 그러함

    새로운 행동 채택의 어려움

     * B2B 음성 에이전트는 기존 프로세스에 AI를 ""플러그인""하는 반면, B2C 음성 에이전트는 사용자가 새로운 행동을 채택해야 함
     * 이는 더 느리거나 더 마법 같은 제품을 필요로 할 수 있음

    기존 음성 AI에 대한 부정적 인식

     * 소비자는 Siri와 같은 제품 경험으로 인해 음성 AI에 대해 부정적인 영향을 받았기 때문에 새로운 앱을 시도하려는 영감을 받지 않을 수 있음

    광범위 기반 제품의 기본 사용 사례 충족

     * 광범위 기반 제품은 일반적으로 음성 AI의 기본 사용 사례(튜터링, 동반자 등)를 제공할 수 있음
     * B2C 음성 스타트업은 ChatGPT, Pi 등이 처리하지 않을 사용 사례나 경험을 만들기 시작하는 단계임

  B2C 에이전트: 기회가 보이는 곳

    음성이 필요한 이유에 대한 강력한 관점

     * 우리는 음성이 제품에 어떻게 독특한 가치를 가져다주는지에 대해 의견이 있는 제품과 창업자에 대해 기대하고 있음
     * 단순히 ""음성을 위한 음성""이 아님
     * 많은 경우 음성 인터페이스는 정보를 소비하고 추출하는 데 더 불편하기 때문에 텍스트 인터페이스보다 오히려 부정적임

    실시간 음성이 필요한 이유에 대한 강력한 관점

     * 음성은 소비하기 어려운 반면, 실시간 음성은 더욱 어려움(비동기 음성 메시지 대비)
     * 우리는 그들의 제품이 왜 실시간 대화를 중심으로 구축되어야 하는지에 대한 관점을 가진 창업자들에 대해 기대하고 있음
     * 아마도 인간 같은 동반자 관계, 연습 환경 등을 위한 것일 수 있음

    AI 이전 ""제품""과의 비유사성

     * 우리는 강력한 형태의 제품이 AI 음성 에이전트가 단순히 인간 제공자를 대신하는 이전의 사람 대 사람 대화를 직접 옮긴 것이 아닐 것이라고 의심함
     * 첫째, 그 기준에 부합하기 어려움
     * 더 중요한 것은 AI를 사용하여 동일한 가치를 더 잘(더 효율적으로, 더 즐겁게) 전달할 기회가 있다는 것임

    모델 품질이 승자를 결정짓지 않는 수직화

     * 주요 일반 소비자 AI 제품(ChatGPT, Pi, Claude)은 고품질 음성 모드를 가지고 있음
     * 그들은 많은 유형의 대화와 상호 작용에 의미 있게 참여할 수 있음
     * 그들은 자체 모델과 스택을 호스팅하기 때문에 단기적으로 지연 시간과 대화 흐름에서 이길 가능성이 있음

우리는 스타트업이 다음과 같은 방식으로 성공하기를 기대하고 있음:

     * 특정 유형의 대화에 맞게 조정하거나 튜닝하거나,
     * 음성 에이전트 경험에 더 많은 맥락과 가치를 제공하는 UI를 구축
          + (예: 시간 경과에 따른 진척 상황 추적, 대화/경험을 의견 있는 방식으로 조종)

   모 엔터프라이즈 회사 integration 팀을 가까이서 볼 기회를 가질 수 있었는데, 본문의 내용과 유사한 프로젝트가 진행되는 것을 실시간으로 볼 수가 있었네요.

   AWS connect를 통해 CS를 자동화하는 것이 초기의 목표였다가, 트래픽 분산처리도 하고, VVIP 대상 특별 서비스 기획에도 참여하고.... 점차 파이가 커지는 것을 보는것도 흥미로운 일이죠.

   이렇다보니 솔직히 돈 안되는 고객들은 자동응답 봇이 최대한 대응하게 하고, 예치금 많은 고객들은 최대한 빨리 인간 에이전트들이 직접 연락하는게 서비스 기조 더군요. 어쩔 수 없는 부분이겠죠 ㅎㅎ
"
"https://news.hada.io/topic?id=15319","Show GN: es-toolkit: 2-3배 빠르고, 97% 작은 lodash 대체 라이브러리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Show GN: es-toolkit: 2-3배 빠르고, 97% 작은 lodash 대체 라이브러리

   안녕하세요, 토스에서 lodash보다 평균적으로 2-3배 빠르고, 번들 사이즈가 최대 97% 작은 현대적인 JavaScript 유틸리티 라이브러리 es-toolkit을 공개해서 공유드려요.

   es-toolkit은 debounce, throttle, delay, sample, sum과 같이 매일매일 사용하는 JavaScript 함수를 제공해요.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   [1] 빠른 성능

   es-toolkit은 lodash처럼 같은 기능을 제공하는 라이브러리와 비교했을 때 평균 2~3배 빠른 런타임 성능을 제공해요.

   [2] 작은 번들 사이즈

   현대적인 구현 덕분에, es-toolkit이 제공하는 함수들은 매우 작은 번들 사이즈를 가져요. 예를 들어서 difference 함수는 97.2% 작은 구현을 제공해요.

   Tree Shaking도 정확한 스펙대로 제공해서, 사용하는 곳에서 최소한의 코드만 포함할 수 있어요.

   [3] 안전하고 견고한 타입

   모든 함수에 대해서 간단하고 견고한 TypeScript 타입을 인하우스로 제공해요.

   [4] 테스트 커버리지 100%

   모든 함수와 분기에 대해서 꼼꼼하게 테스트가 작성되어 있어서, 동작을 신뢰할 수 있어요.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   토스에서 공개한 다른 라이브러리들과 같이, 커뮤니티 기여를 매우 환영해요. 저희 레포지토리를 한번 둘러봐주시고, 많은 기여 부탁드려요 :)
     * GitHub: https://github.com/toss/es-toolkit
     * 홈페이지: https://es-toolkit.slash.page/ko/

   대단합니다 저도 이거 꼭 써봐야 겠어요 공개해주셔서 감사합니다!

   chain, flow 같은 함수 합성은 지원을 안하나요?

   radash랑 한번 비교해보고 싶네요

   와우, tossface 잘쓰고 있는데, es-toolkit도 함 써봐야겠군요!

   오 lodash를 쓰면서 편리하지만 무겁다고 느낀적이 많은데 말씀하신 성능과 크기라면 아주 솔깃하네요!
"
"https://news.hada.io/topic?id=15252","효과적인 지도 UX를 위한 디자인 패턴","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         효과적인 지도 UX를 위한 디자인 패턴

     * 웹 사이트 및 앱에서 좋은 지도 사용 경험을 제공하기 위해 어떤 디자인 패턴을 취해야 하는지 보여줌
     * 구성
          + 1장: 디자인 시작하기
          + 2장: 올바른 레이아웃 선택
          + 3장: 지도와의 상호작용
          + 4장: 복잡한 데이터 다루기
          + 5장: 모바일 장치를 위한 디자인
          + 6장: 단일 목적 앱 빌드하기
          + 7장: 흔히 발생하는 실수와 이를 방지하는 방법
"
"https://news.hada.io/topic?id=15267","Ask HN: 머신 러닝 엔지니어들은 업무시간에 어떤 일 하나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Ask HN: 머신 러닝 엔지니어들은 업무시간에 어떤 일 하나요?

     * 질문에 답변한 사람들 내용을 정리

schmookeeg

     * 현재 기계 학습 엔지니어로 일하면서 가장 좋아하는 부분은 기술적 배경이 없는 사람들과 협업하는 것임
          + MS Outlook을 5번 중 3번 이상 열지 못하는 사람들도 자신의 전문 분야에 대해 놀랄만한 깊이와 통찰력을 가지고 있음
          + 이는 매우 겸허하게 만듦
     * 기술적 배경이 없는 사람들은 나를 마법사로 보고, 나는 그들을 부두교 사제로 봄
          + 우리가 좋아하는 것을 훈련시키고 예측할 때, 양쪽 모두에게 매우 보람 있음
     * 대부분의 모델링은 의료 관련임
          + 청구, 처방전, 의사 소견, 생체 징후, 진단 영상 등의 방대한 데이터 레이크에서 인사이트를 이끌어냄
          + 이 정보에 매우 쉽게 접근 가능하다는 것도 엄청남 (HIPAA는 제쳐두고)
     * 시간적 현실
          + 일주일에 회의가 약 3시간 정도 걸림
          + 업무 준비, ETL 문제 해결, 비즈니스를 위한 일회성 쿼리 수행 등에 3시간 정도 소요됨
          + 나머지 시간은 수백만 달러 규모의 수익을 예측하는데 약간의 우위를 찾기위해 데이터를 탐색함
               o 이는 마치 수학으로 월리를 찾는 것과 같음
               o 그 월리 씬은 약 50TB 크기임 :D

burnedout_dc4e3

     * 2000년대 중반부터 머신 러닝을 해왔음
     * 절반의 시간은 모델 훈련과 사용을 위해 데이터를 정리하는 ""데이터 파이프라인을 계속 운영""하는 데 소비됨
     * 또 다른 절반의 시간은 코딩 능력이 거의 없는 ""AI 과학자""들을 위한 기술 지원에 소비됨
          + 그들은 다양한 챗봇 서비스에 내용을 복사/붙여넣기 하는 데 시간을 보냄
               o Python 패키지 설치 및 Git 사용 방법 등을 알려주는 것이 주된 일임
          + 그들의 작업이 우리가 하고 있는 프로젝트에 어떻게 적용될 것인지에 대한 계획은 없음
               o 그러나 트랜스포머 모델이 우리의 모든 데이터 처리 문제를 해결할 것이라고 주장함
     * 이 과대 광고 사이클이 끝날 때까지 새로운 일을 하지 않고 그만둘까 고민 중

tambourineman88

     * 머신 러닝을 공부할 때 예상과는 반대되는 현실
          + 이 일의 95%는 데이터 정리, 데이터셋 결합, 그리고 피쳐 엔지니어링임
          + 모델 적합과 테스트는 단지 5%에 불과함
     * 이 글에 대한 답글 #1
          + 처음부터 지금까지 그래왔고, 앞으로도 계속될 것임, 아멘
          + 스태프/책임자 레벨에서의 중요 사항
               o 추론 모델에 의존하는 제품 기능과 데이터 캡처 사이의 ""데이터 임피던스""를 유지하는 것이 중요함
               o 이는 제품이나 기능이 변경되더라도 데이터 저장소와 훈련 코퍼스에 데이터를 공급하는 계측과 데이터 세분성이 깨지지 않도록 하기 위함임
          + 강화 학습(RL) 문제에서의 중요 사항
               o 상태와 행동 공간 튜플에 대해 올바른 변수가 캡처되었는지 확인하는 것이 중요함
               o 그 다음으로는 보상 피드백을 위해 인터페이스나 환경 모델을 조정하는 방법을 찾는 것임

davedx

     * pip install pytorch 실행
     * 환경이 깨짐
     * Python 환경 수정에 4시간 소요
     * pip install Pillow 실행
     * Mac 북의 CPU 아키텍처에 맞지 않는다는 오류 발생
     * Python 관련 모든 것을 제거한 후 처음부터 다시 설치하는 데 4시간 더 소요
     * pip install ... 실행하려 했으나 퇴근 시간이 됨!

Xenoamorphous

     * 일반 소프트웨어 개발자인데, 필요에 의해 ML 작업을 해야 했음
     * ""진짜"" ML 전문가들이 확률적/경사하강법 결과와 사람들의 기대치를 어떻게 다루는지 궁금함
     * 일반 소프트웨어 작업에서는 동작하거나 동작하지 않고, 동작하지 않으면 이유를 설명하고 바라건대 고칠 수 있음
     * 그러나 ML에서는 ""이 텍스트 분류기가 이 텍스트를 올바르게 분류하지 않은 이유는 무엇인가?""라는 질문을 받음
          + 이에 대해 ""임계값을 만족하기에 0.004점 부족했다""거나 ""단어 선택이나 순서 때문에 만족하지 못했다""고 밖에 말할 수 없음
          + 이는 모두를 불만족스럽게 만드는 것 같음

angarg12

     * 직책은 ML 엔지니어이지만 실제 업무는 거의 순수한 소프트웨어 엔지니어링에 가까움
     * 프로덕션 환경에서 ML 시스템을 지원하는 시스템 구축이 주된 업무
          + 다른 사람들이 언급했듯이 주로 데이터 변환, 모델 훈련, 모델 서빙 등이 포함됨
     * 도구를 구축하거나 기존 시스템을 수정하여 과학자들이 업무를 수행할 수 있도록 지원하는 것도 업무에 포함됨
     * 그러나 외부를 보면 필자의 회사는 이례적인 것 같음
     * 업계에서는 ML 엔지니어에 대한 기대치가 데이터/응용 과학자가 하는 일(예: 모델 구축 및 테스트)과 더 잘 맞는 것으로 보임
          + 이는 각 회사의 각 역할에 대한 기대에 많은 모호성을 야기함

runban

     * 높은 급여를 받는 청소부
          + 더러운 데이터로는 제대로 된 결과를 얻을 수 없음
          + 참고로 이 작업에는 Python보다 Perl이 훨씬 더 좋음
     * 높은 급여를 받는 마더보드 문제 해결사
          + 수랭식 쿨링을 사용하더라도 H100들은 정말 뜨거워짐
          + 전담 하드웨어 담당자가 없기 때문
     * 모두가 그렇듯이 제멋대로 굴러가는 제3자 종속성과 싸움

primaprashant

     * 지난 5년 동안 MLE로 일해 왔으며, 다른 댓글에서 언급했듯이 대부분의 작업은 SWE와 유사함
     * 프로젝트 단계에 따라 일상적인 작업은 다양하지만, 다음 중 하나에 해당함:
          + 이해관계자 및 TPM과의 협업, 데이터 분석을 통해 우선순위가 높은 비즈니스 문제 해결을 위한 가설 개발
          + 비즈니스 문제를 ML 문제로 구성하고, ML 모델과 비즈니스 문제에 적합한 메트릭 생성
          + 새로운 기능과 아이디어의 기술적 실현 가능성을 검증하기 위한 PoC 및 프로토타입 구축
          + 아키텍처 및 기술적 의사 결정을 위한 설계 문서 작성
          + 플랫폼 팀과 협력하여 새로운 ML 프로젝트와 기존 ML 프로젝트의 요구사항에 따라 데이터 파이프라인 설정 및 유지 관리
          + 추론을 위한 ML 마이크로서비스 구축, 배포 및 유지 보수
          + A/B 테스트 실행 및 사후 테스트 분석을 위한 설계 문서 작성
          + ML 모델 재학습을 위한 파이프라인 설정

jackspawn

     * 시간의 50% 이상을 백엔드 엔지니어링에 할애함
          + ML이 더 큰 API 내에서 사용되기 때문
     * 해당 API의 엔드 투 엔드 경험에 대한 책임을 짐
          + 따라서 시간 대비 최상의 가치를 제공하는 것은 무엇이든 수행함
          + 이는 종종 ML 모델과는 아무 관련이 없음

mardifoufs

     * 추론 코드 최적화, 훈련된 모델 ""제품화"" 작업을 수행함
     * 현재는 클라우드 서비스가 아직 일반적으로 사용되지 않는 산업에서 일하기 때문에 로컬 훈련 및 추론 작업 중
          + LLM이 아니기 때문에 미리 만들어진 도구가 많지 않아 흥미로움
          + 많은 것을 직접 만들어야 함
     * 데이터 품질 평가(로컬 부분이 도전적)부터 CUDA를 직접 사용하는 것까지 다양한 작업을 수행함
          + 이미 CUDA를 기반으로 구축되어 활용할 수 있는 신호 처리 라이브러리가 있기 때문
     * 때로는 팀(연구원/MLE 혼합 팀) 내부 도구 구축도 포함됨
          + 매우 틈새 분야이기 때문에 데이터와 추론을 시각화하기 위해 직접 구축해야 함
     * 도구 및 내부 소프트웨어 설계와 관련하여 완전한 자유가 있어 조직 내에서 많은 영향을 미칠 수 있었음
     * 즉흥적으로 구축한 도구 중 하나가 이제 주력 제품에도 탑재될 예정임

hirako2000

     * 주요 업무는 아니지만 대부분의 시간을 ""이것저것 붙이는"" 작업에 소비
          + 기존 오픈 소스 조정
          + 리소스 최적화 방법 파악
          + 다른 데이터 세트에서 모델 재학습
          + 엉성하게 작성된 Python 코드 실행 시도
          + 누락된 요구사항 파일 추가
          + 데이터 정리
     * 이미 수년 전에 수행되지 않은, ML로 실제로 유용하게 해결할 수 있는 것이 무엇일지 고민함
     * 최신 GPU 가격을 확인하고, 호스팅 제공업체에서 비싼 시간을 빌리는 것보다 GPU를 구입하는 것이 가치 있는지 계산함
     * 머리가 아플 때까지 논문을 읽음
          + 초록을 읽고 중간에 있는 몇 개의 다이어그램을 훑어보는 데 시간이 걸림

tenache

     * 머신러닝을 공부하고 원래 그 역할을 위해 고용되었지만, 회사가 방향을 바꾸어 현재는 LLM 작업 중
     * 대부분의 시간을 다음과 같은 작업에 할애함:
          + 다양한 LLM의 작동 방식 파악
          + 최적의 매개변수 찾기
          + RAG(Retrieval-Augmented Generation) 수행 방법
          + 다른 봇과의 통합 방법

trybackprop

     * 주어진 일주일 동안 일반적으로 다음과 같은 업무를 수행함:
     * 15%: 기술 토론 회의 또는 1:1 미팅
          + 일반적으로 모델에 대한 아이디어, 계획 또는 ML 제품 지원에 대해 논의함
     * 40%: ML 개발
          + 프로젝트 초기 단계에서는 제품 요구사항을 이해함
          + 제품/비즈니스 목표 달성에 도움이 될 수 있는 ML 모델이나 알고리즘을 팀과 논의함
          + 분석가와 데이터 과학자로부터 기존 데이터셋을 수집함
          + 이 데이터셋을 사용하여 학습 및 검증 데이터셋을 생성하는 파이프라인을 만듦
          + 학습/검증 데이터셋이 채워지기를 기다리는 동안(최대 2주 소요), 개발 단계가 더 앞서거나 뒤쳐진 다른 프로젝트에 동시에 작업함
          + 새로운 모델(PyTorch로 작성)에도 작업하고, 소량의 데이터로 테스트하여 오프라인 성능을 평가하고, 기대한 대로 작동하는지 여부를 평가함
          + 모델을 사용하여 제품 정보를 채우는 몇 가지 수동 테스트를 실행하여 모델의 건전성을 확인함 (대규모 실험 없이는 자신과 팀원의 직감에 의존할 수밖에 없음)
          + 학습/검증 데이터셋이 채워지면 대량의 데이터에 대해 모델을 학습시키고, 오프라인 결과를 확인하고, 문제가 있으면 모델을 조정하거나 아키텍처를 변경함
          + 오프라인 결과가 양호하거나 좋아 보이면 실험을 위해 모델을 프로덕션에 배포함
          + 동시에 구축한 새 모델의 테스트를 위해 제품/인프라 코드를 변경할 수 있음
          + 실험을 실행하고 트래픽을 천천히 늘려 1-5% 할당이 되면 몇 주 또는 한 달 동안 실행함
          + 한편, 결과를 관찰하고 모든 관련 파이프라인을 모니터링하여 모델이 적절하게 훈련되도록 하여 예기치 않은 인프라/버그/제품 요인으로 인해 실험 결과가 변경되지 않도록 함
          + 결과가 예상대로 보이고 초기 가설과 일치하면 팀과 출시 여부를 논의하고, 출시하기로 결정하면 출시함!
               o (참고: 모델 개발에는 특징 작성, 데이터셋 준비, 분석, ML 모델 자체 생성, 제품/인프라 코드 변경 구현 등이 포함됨)
     * 20%: 유지 관리
          + 새 모델을 개발하고 있다고 해서 기존 모델을 무시하는 것은 아님
          + 매일 확인하여 성능이 저하되거나 예기치 않은 방식으로 성능이 변경되지 않았는지 확인함
          + 또한 파이프라인을 수정하고 더 효율적으로 만듦
     * 15%: 연구 논문 및 기술 습득
          + AI/ML 세계가 빠르게 변화하고 있어 지속적으로 새로운 연구 논문을 읽고 최신 상태를 유지하기 위해 가정에서 새로운 기술을 테스트함
          + 재미있어서 부담스럽지 않음
          + 최신 상태를 유지하기 위한 일로 보지 않음
     * 10%: 내부 연구
          + 팀이나 회사 내 다른 제품에 대해 더 배우고, 우리 팀이 어떻게 도울 수 있는지 또는 그들로부터 어떤 기술/기법을 빌릴 수 있는지 알아보는 데 이 시간을 사용함
          + 또한 지난 6개월/1년 동안의 작업을 되돌아보면서 얻은 통찰력을 적는 데도 이 시간을 사용함

   '기술적 배경이 없는 사람들은 나를 마법사로 보고, 나는 그들을 부두교 사제로 봄' 표현이 재미있네요.

   데이터... 데이터... 공감가네요

   막연하게 그러고들 있을거라고 생각한 그대로군요.

   흥미로운 내용이네요!
"
"https://news.hada.io/topic?id=15246","간단한 Unix 유사 교육 운영 체제 Xv6","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        간단한 Unix 유사 교육 운영 체제 Xv6

운영 체제 공학 (6.1810)

  xv6 소개

     * xv6: 2006년 여름에 개발된 교육용 운영 체제로, Unix V6를 기반으로 함.
     * 목적: 새로운 학부 수업 6.1810을 위해 RISC-V로 포팅됨.

  xv6 소스 및 텍스트

     * 최신 소스 코드 및 텍스트:
          + git clone https://github.com/mit-pdos/xv6-riscv.git
          + git clone https://github.com/mit-pdos/xv6-riscv-book.git

  Unix 버전 6

     * 영감: Unix V6와 John Lions의 'Lions' Commentary on UNIX' 6th Edition'에서 영감을 받음.
     * 원본 코드: The Unix Heritage Society를 통해 온라인에서 접근 가능.
     * 참고 자료:
          + 'The PDP11/40 Processor Handbook', Digital Equipment Corporation, 1972.
          + PDF 및 웹 기반 버전 제공.

  피드백

     * 연락처: xv6를 사용하거나 수업에서 사용한 경험이 있는 경우 피드백을 받음.
          + Russ Cox: rsc@swtch.com
          + Frans Kaashoek: kaashoek@mit.edu
          + Robert Morris: rtm@mit.edu
          + 61810-staff@lists.csail.mit.edu

GN⁺의 의견

     * 교육적 가치: xv6는 Unix V6를 기반으로 하여 운영 체제의 기본 원리를 학습하는 데 유용함.
     * RISC-V 포팅: 최신 하드웨어 아키텍처에 맞춰 포팅되어 현대적인 교육 환경에 적합함.
     * 오픈 소스 접근성: 누구나 소스 코드를 접근하고 수정할 수 있어 학습과 연구에 유리함.
     * 피드백 시스템: 사용자 피드백을 적극적으로 수용하여 지속적으로 개선될 가능성이 높음.
     * 관련 자료: 다양한 참고 자료와 문서가 제공되어 학습에 도움이 됨.

        Hacker News 의견

     * MIT에서 이 수업을 들었음. 시스템 배경이 없는 사람들에게 특히 추천할 만함. 교과서가 이해하기 쉽고 실습이 이해도를 잘 확인해줌. 첫 번째 시도에서는 네트워크 드라이버를 건너뛰는 것이 좋음.
     * MIT에서 이 운영체제를 사용하는 수업을 들었음. 정말 훌륭함. 수업 웹사이트에서 강의 노트, 실습, xv6의 버전 등을 모두 볼 수 있음. 매우 개방적임.
     * 대학에서 운영체제 수업 프로젝트로 xv6 운영체제를 기반으로 작업했음. 스케줄러를 만드는 프로젝트가 있었고, 운영체제의 다양한 부분을 배우기에 좋았음.
     * 스페인의 한 대학에서 Plan9이 교육용으로 사용되었음.
     * 제목을 처음 읽었을 때, 오래된 xv 이미지 뷰어의 새로운 버전인 줄 알았음.
     * Windows NT 커널을 이해하고 싶었음. 초기 버전이 더 간단하다고 들었음. VMS와 비슷하다는 소문이 있음. VMS에 대한 자료가 있는지 궁금함. OpenVMS는 오픈 소스지만 버전이 너무 높음.
     * 왜 Unix v6를 사용하는지 궁금함. 50년 된 디자인으로 운영체제의 기본을 가르치는 것이 맞는지 의문임. 스케줄링, IPC, 주소 공간 관리 등을 가르치기 위해서는 마이크로커널 디자인이 더 나을 것 같음.
     * 자가 학습자가 이 과정을 어떻게 진행할 수 있을지 궁금함.
     * Plan 9도 이해하기 쉬운 코드베이스임.
     * 지난 학기에 운영체제 수업에서 PintOS를 사용했음. 더 깊이 다루는 2부 수업이 있었으면 좋겠음.
"
"https://news.hada.io/topic?id=15193","구형 렌더링: 평면 행성","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             구형 렌더링: 평면 행성

        Hacker News 의견

     * Cubemaps: 큐브맵은 간단한 해결책으로, 메모리 사용량이 6배 증가하지 않음. 텍스처를 6개의 작은 직사각형 면으로 나누는 것뿐이며, 극지점의 왜곡 문제를 해결할 수 있음.
     * 텍스처 왜곡: 극지점의 텍스처 왜곡은 구 전체에서 발생하는 왜곡의 극단적인 형태임. 구를 삼각형으로 세분화할 때 왜곡이 더 명확해짐.
     * UV 좌표 계산: 올바른 해결책은 픽셀 셰이더에서 픽셀별로 UV 좌표를 계산하는 것임. 이렇게 하면 극지점에서 이음새가 없어짐.
     * Displacement Mapping: Displacement Mapping을 다시 살펴볼 필요가 있음. 문제 해결에는 적합하지 않지만 간단하고 재미있음.
     * 음악 시각화: 25년 전 SoundJam을 위한 음악 시각화를 작성했음. 음악 데이터가 태양의 코로나 방출처럼 시각화되었음.
     * 게임 그래픽: 리소스가 제한된 게임에서도 몰입감 있는 그래픽을 구현할 수 있었음. 현실적인 제약이 있는 프로젝트와 취미 프로젝트의 차이점이 흥미로움.
     * 절충안: 절충안으로 가스 거인의 표면 텍스처를 실시간으로 생성하는 대신 미리 렌더링된 애니메이션 텍스처를 사용하는 것이 좋음.
     * 절충안의 장점: 절충안은 메모리와 GPU 대역폭을 절약할 수 있으며, 먼 거리의 천체를 렌즈 효과로 시각화하는 데 유용함.
     * GPU 기능: GPU나 3D 라이브러리에 원을 그리는 간단한 알고리즘을 사용하여 구를 렌더링하는 기능이 있는지 궁금함.
     * 관련 기사: 유사한 접근 방식을 다룬 기사를 떠올리게 함. 관련 기사 링크
     * 가스 거인: 가스 거인과 관련된 페이지가 마음에 듦. 관련 페이지 링크
     * 설명과 시각화: 설명과 시각화가 훌륭함. Triplanar mapping도 이음새 문제와 극지점 문제를 해결할 수 있었을 것임.
     * Icosphere: Icosphere는 더 부드럽게 펼쳐질 수 있으며, 정규화된 정점 위치와 요소 크기를 가짐. 펼치는 것은 쉽지 않지만 가능함.
"
"https://news.hada.io/topic?id=15215","Vulkan을 배워 소형 게임 엔진 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Vulkan을 배워 소형 게임 엔진 개발

  목차

     * 서문
     * 그래픽 프로그래밍 학습
     * 사소한 문제에 집착하지 않기
     * 왜 Vulkan인가?
     * Vulkan 학습
     * 엔진 개요 및 프레임 분석
     * 일반적인 조언
          + 추천 Vulkan 라이브러리
          + GfxDevice 추상화
          + 셰이더 처리
          + 푸시 상수, 디스크립터 셋 및 바인드리스 디스크립터
          + 파이프라인 패턴
          + 프로그래머블 버텍스 풀링(PVP) + 버퍼 직접 주소(BDA) 사용
          + 바인드리스 디스크립터
          + 매 프레임 업로드해야 하는 동적 데이터 처리
          + 소멸자, 삭제 큐 및 정리
          + 동기화
     * 더 많은 구현 노트
          + 많은 스프라이트 그리기
          + 컴퓨트 스키닝
          + 게임 / 렌더러 분리
          + 씬 로딩 및 엔티티 프리팹
          + MSAA
          + UI
          + Dear ImGui 및 sRGB 문제
          + 기타 사항
     * Vulkan으로 전환하면서 얻은 것
     * 향후 작업

  서문

     * Vulkan을 배우고 작은 게임 엔진을 작성한 경험을 문서화한 내용임.
     * Vulkan에 대한 사전 지식 없이 3개월 동안 작업했음.
     * 작은 3D 게임을 만들고 재사용 가능한 부분을 엔진으로 분리했음.

  그래픽 프로그래밍 학습

     * 그래픽 프로그래밍을 처음 시작하는 사람은 OpenGL부터 배우는 것이 좋음.
     * OpenGL을 통해 텍스처 모델을 화면에 표시하고 간단한 조명 및 그림자 매핑을 학습하는 것이 유용함.
     * OpenGL 학습을 위한 추천 리소스:
          + learnopengl.com
          + Anton’s OpenGL 4 Tutorials 책
          + Thorsten Thormählen의 강의 (처음 6개의 비디오 추천)

  사소한 문제에 집착하지 않기

     * 사소한 문제에 집착하지 않도록 주의해야 함.
     * ""정말 필요한가?"", ""병목 현상이 될 것인가?""를 항상 자문해야 함.
     * 필요하지 않은 기능은 나중에 추가할 수 있음.
     * 간단한 게임부터 시작하고, 복잡한 엔진을 만들지 않도록 주의해야 함.

  왜 Vulkan인가?

     * Vulkan은 최신 GPU 기능을 사용할 수 있고, 오픈 소스 기술과 표준을 선호하는 사람들에게 적합함.
     * OpenGL은 작은 게임에 충분하지만, 최신 GPU 기능을 사용하기 어렵고, macOS에서는 사용이 제한됨.
     * WebGPU는 Vulkan보다 배우기 쉽고, 브라우저에서 게임을 실행할 수 있음.

  Vulkan 학습

     * Vulkan 학습은 처음에는 어려워 보였지만, Khronos가 복잡한 부분을 단순화하고 유용한 라이브러리를 제공함으로써 학습이 쉬워졌음.
     * 추천 Vulkan 학습 리소스:
          + vkguide
          + TU Wien의 Vulkan 강의 시리즈
          + 3D Graphics Rendering Cookbook 책
          + Mastering Graphics Programming with Vulkan 책

  엔진 개요 및 프레임 분석

     * 엔진 이름은 EDBR (Elias Daler’s Bikeshed Engine)이며, Vulkan 학습 프로젝트로 시작됨.
     * 엔진은 주로 작은 레벨 기반 게임에 적합함.
     * 프레임 렌더링 과정:
          + 스키닝: 컴퓨트 셰이더를 사용하여 모델 스키닝 처리
          + 그림자 매핑: 4096x4096 깊이 텍스처 사용
          + 지오메트리 및 셰이딩: PBR 모델 사용
          + 깊이 해결: 프래그먼트 셰이더를 통해 수동으로 처리
          + 후처리 효과: 깊이 안개, 톤 매핑, 블룸 적용
          + UI: 하나의 드로우 콜로 UI 그리기

  일반적인 조언

    추천 Vulkan 라이브러리

     * vk-bootstrap: Vulkan 초기화 코드 단순화
     * Vulkan Memory Allocator (VMA): 메모리 할당 관리
     * volk: 확장 함수 로딩 단순화

    GfxDevice 추상화

     * GfxDevice 클래스는 Vulkan 기능을 캡슐화하고, Vulkan 컨텍스트 초기화, 스왑체인 생성 및 관리 등을 처리함.

    셰이더 처리

     * GLSL을 사용하여 셰이더 작성.
     * 빌드 단계에서 셰이더를 사전 컴파일하여 런타임 의존성을 줄임.

    푸시 상수, 디스크립터 셋 및 바인드리스 디스크립터

     * Vulkan에서는 디스크립터 셋을 사용하여 셰이더에 데이터를 전달함.
     * 바인드리스 디스크립터와 버퍼 직접 주소를 사용하여 디스크립터 셋 사용을 최소화함.

    파이프라인 패턴

     * 파이프라인 클래스를 사용하여 드로잉 단계를 분리함.
     * init, cleanup, draw 메서드를 통해 파이프라인 초기화, 정리, 드로잉을 처리함.

    프로그래머블 버텍스 풀링(PVP) + 버퍼 직접 주소(BDA) 사용

     * 버텍스 타입을 하나로 통일하고, 셰이더에서 버텍스를 직접 접근함.
     * 푸시 상수를 사용하여 버퍼 주소를 전달함.

    바인드리스 디스크립터

     * 텍스처를 바인드리스 방식으로 관리하여 셰이더에서 직접 접근 가능하게 함.
     * 텍스처 ID를 푸시 상수로 전달하여 샘플링함.

  GN⁺의 의견

     * Vulkan은 높은 성능과 최신 GPU 기능을 제공하지만, 초기 학습 곡선이 가파름.
     * OpenGL을 먼저 학습한 후 Vulkan으로 전환하는 것이 좋음.
     * Vulkan 학습을 위한 다양한 리소스가 존재하며, 이를 활용하면 학습이 쉬워짐.
     * Vulkan을 사용하여 작은 게임 엔진을 작성하는 것은 그래픽 프로그래밍을 깊이 이해하는 데 도움이 됨.
     * Vulkan의 복잡성을 줄이기 위해 유용한 라이브러리를 사용하는 것이 좋음.

        Hacker News 의견

    해커뉴스 댓글 요약

     * Minimal한 접근법의 효과: 메타버스 클라이언트를 Rust로 작성 중이며, Vulkan, WGPU, Rend3를 사용해 복잡한 문제를 겪고 있음. WGPU는 다양한 플랫폼을 지원하려다 보니 개발이 어려움.
     * Vulkan의 장점과 OpenGL의 간편함: Vulkan은 고급 GPU 기능을 최대한 활용할 수 있지만, OpenGL은 간단한 2D/저폴리 게임에 적합함. AAA 게임 산업은 그래픽 품질에 치중하지만, 많은 플레이어는 게임플레이에 더 관심이 있음.
     * 필요한 기능만 구현: 주니어 프로그래머들이 최신 도구와 ""베스트 프랙티스""에 집착하는 경향이 있지만, 실제 문제 해결에 필요한 최소한의 기능에 집중하는 것이 중요함.
     * Vulkan의 복잡성: Vulkan은 OpenGL에 비해 성능을 최적화하기 어렵고, 많은 코드와 동기화 작업이 필요함. 취미로는 OpenGL ES3가 더 간편함.
     * 추가 추상화 레이어의 문제: Vulkan을 배우는 자료들이 추가 추상화 레이어를 도입해 기본적인 메모리 관리 예제를 찾기 어려움.
     * Vulkan의 학습 곤란: OpenGL은 배우기 쉬웠지만, Vulkan은 간단한 작업도 복잡하게 만듦. 새로운 기술을 배우는 데 시간이 많이 걸림.
     * 과학 데이터 시각화를 위한 Vulkan 학습: Vulkan을 배워 과학 데이터 시각화 엔진을 작성했으며, 학습 과정에서 많은 추상화를 이해하는 데 시간이 걸림.
     * Vulkan 학습의 어려움: Vulkan을 실제 엔진에서 사용하는 방법을 이해하기 어려움. 좋은 추상화와 렌더링 순서를 결정하는 방법을 배우기 위해 더 많은 자료가 필요함.
     * 그래픽 프로그래밍 커뮤니티의 지원: Vulkan 엔진을 개발하는 과정에서 커뮤니티의 지원과 피드백이 큰 도움이 됨.
"
"https://news.hada.io/topic?id=15292","애플, WWDC 2024에서 Passwords 매니저 앱 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   애플, WWDC 2024에서 Passwords 매니저 앱 공개

     * 애플의 새로운 비밀번호 관리자 앱 'Passwords'
          + iCloud Keychain을 기반으로 작동함
          + 1Password, LastPass, Bitwarden 등과 경쟁할 예정임
     * 주요 기능
          + 다양한 웹사이트와 기기에 빠르게 로그인 가능
          + 복잡한 비밀번호 생성 및 안전한 저장 가능
          + 타사 서비스에서 비밀번호 가져오기 기능 제공
     * 추가 기능
          + 사용자 로그인 목록 작성 및 서비스 유형별로 분류 가능 (예: 은행, 스트리밍 서비스, 소셜 미디어 등)
          + Face ID와 Touch ID를 이용한 수동 비밀번호 입력 대체 및 자동 채우기 기능 제공
     * 애플 생태계와의 통합
          + iOS, iPadOS, MacOS 플랫폼과 깊은 통합 예상
          + 기존 iCloud Keychain 서비스와 연동되어 사용자 도입이 원활할 것으로 예상됨
          + iOS 18, iPadOS 18, MacOS 15에서 무료로 다운로드 가능
          + Vision Pro와 Windows 컴퓨터에서도 작동 예정

GN⁺의 의견

     * 애플의 보안 기록이 경쟁사보다 우수하여 사용자 신뢰도가 높음. iCloud Keychain과의 통합으로 비밀번호 관리가 더 쉬워질 것으로 예상됨
     * Face ID와 Touch ID를 통한 편리한 로그인 기능 제공. 다양한 기기와의 호환성으로 사용자 경험 향상
     * 1Password, LastPass, Bitwarden 등과의 경쟁에서 어떤 차별점을 가질지 주목할 필요가 있음. 기존 사용자들이 새로운 앱으로 전환할 유인이 충분한지 관건임
     * 애플 생태계에 종속되는 문제를 고려해야 함. 타사 비밀번호 관리자와의 호환성 및 데이터 이전 문제 검토 필요
     * 애플의 브랜드 파워와 기존 사용자 기반을 고려할 때 빠른 시장 점유율 확보 가능성 있음

   중요한건 다른 플랫폼에서 쓸수 있냐 없냐죠

   Safari Password 잘 쓰고 있었는데 별도 앱으로 분리된 거네요. 시장 교란 정도로 볼 건 아닌 것 같고 저는 환영합니다.

   들어오는건 자유지만 나갈땐 아니란다...

   저는 계속해서 Keepass 쓸 예정입니다
   한 회사에 독점되는 것도 싫고, 분산형이라서 서버가 터져도 쓸 수 있거든요

   1password 사용 중인데, 마이그레이션 기능을 얼마나 해주느냐에 따라 한번 고려해볼 만 한 거 같습니다.
   리눅스가 문제긴 한데..

   이리저리 뭔가 있긴하지만.. 좀 더 써봐야 옮길지 말지를 생각할까합니다.

   개발자 베타 상태에서는 뭔가 쓸만한 기능은 모르겠어요.
   게임 로그인할때 애플계정으로 들어간것 보이는것 말고는 모르겠네요 정말 ㅎㅎㅎㅎ

        Hacker News 의견

    해커뉴스 댓글 요약

     * 큰 기술 회사가 작은 앱 시장을 잠식하는 것에 대해 갈등을 느끼지만, 비밀번호 관리자 산업에 대해서는 동정심이 적음: 1Password를 한 번 결제 후 iCloud Drive와 동기화해 사용했으나, VC 투자를 받은 후 모든 새로운 기능이 구독 모델로 전환됨. Bitwarden으로 전환했으나, 이 역시 VC 투자를 받아 같은 길을 갈 것 같음. 비밀번호 관리자는 안전하게 암호화된 SQLite 파일로 어디든 저장할 수 있어야 함.
     * 10년 넘게 1Password를 사용했으나, 기업 시장을 타겟으로 하면서 점점 불만이 커짐: 버그가 많아지고, 독립적인 금고 기능이 사라짐. 중요한 기능 요청이 몇 년째 방치됨. 가을에 다른 서비스로 전환할 계획임.
     * Bitwarden을 몇 년간 사용 중이며, 필요한 모든 기능을 제공하고 크로스 플랫폼 지원: pass라는 비밀번호 관리 도구에 애착이 있지만, 휴대폰에서 접근하기 어려움.
     * 애플이 비밀번호 관리 시장에 진입하면 웹 개발자들이 로그인 폼에 대한 규칙을 따르게 하는 압박이 생길 것: 비밀번호 입력 시 문제가 발생하는 이유는 웹 개발자가 필드를 인식할 수 없게 만들거나, 비밀번호 붙여넣기를 방지하기 때문임. 애플은 무시하기 어려운 큰 영향력을 가짐.
     * iPhone Passwords를 사용 중이며, 모든 비밀번호를 자동으로 채워줌: 비밀번호 변경 시 휴대폰에서 해야 하지만, 비밀번호 관리자에서 해방되는 대가로 만족함.
     * 멀티플랫폼 지원이 필요함: 세 가지 주요 데스크탑 운영 체제와 iOS를 사용 중이므로 Bitwarden을 사용함.
     * 새로운 앱이 depreciated “Keychain” 앱의 대부분 기능을 제공하지만, iOS 스타일의 UI를 가짐: 비밀번호 섹션이 Keychain을 대체하지 못함. 보안 노트를 처리하지 못함. iOS 스타일의 시스템 설정이 불편함.
     * iCloud 계정이 두 번 손상된 경험이 있어 애플을 신뢰하지 않음: 연락처도 안전하게 보관할 수 없다고 생각하며, 비밀번호는 절대 신뢰하지 않음.
     * 올해부터 주로 Keychain을 사용 중이며, 원활하게 작동함: Apple 기기에서만 사용 가능하지만, Chrome 확장 프로그램도 빠르게 작동함. 가족 구성원도 Keychain으로 전환 중이며, 기술적으로 덜 숙련된 사람들에게 더 쉬움.
     * 1Password가 대부분 좋지만, 몇 가지 불편한 점이 있음: iOS 앱/OSX/브라우저 확장에서 마스터 비밀번호를 입력해야 하는 등 불편함. 폼에서 자동으로 작동하지 않는 경우가 많음. 비밀번호 보안을 위해 구독이 필요하지 않다고 생각함.
"
"https://news.hada.io/topic?id=15307","루마 드림 머신: 텍스트와 이미지에서 고품질 비디오 생성","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    루마 드림 머신: 텍스트와 이미지에서 고품질 비디오 생성

   루마 드림 머신은 텍스트와 이미지로부터 고품질의 현실적인 비디오를 생성할 수 있는 AI 모델입니다. 이 모델은 비디오에 직접 훈련된 매우 확장 가능하고 효율적인 트랜스포머 모델로, 물리적으로 정확하고 일관성 있는 이벤트가 가득한 샷을 제작할 수 있습니다.

   드림 머신은 사용자가 아이디어를 빠르게 탐색하고 더 큰 꿈을 실현할 수 있도록 120초 만에 120프레임을 생성할 수 있어, 생각의 속도로 반복할 수 있도록 합니다. 이 모델은 현실적인 부드러운 움직임, 시네마토그래피 및 드라마가 포함된 액션 가득한 샷을 만들어 무생물 스냅샷을 매력적인 이야기로 변형시킵니다.

   이 모델은 사람, 동물, 그리고 물체가 물리적 세계와 어떻게 상호작용하는지를 이해하는 데 뛰어나며, 캐릭터 일관성 및 생성된 비디오의 물리적 정확성을 보장합니다. 또한, 감정과 장면의 내용에 맞는 유동적이고 시네마틱하며 자연스러운 카메라 움직임을 제공하여 시청자의 주의를 사로잡습니다.
"
"https://news.hada.io/topic?id=15198","자연 키를 사용하는 것을 후회하게 될 꺼에요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        자연 키를 사용하는 것을 후회하게 될 꺼에요

     * 자연(Natural) 키는 데이터베이스에서 고유성을 보장하기 위해 사용되는 키임
     * 자연 키는 이름, 도시, 연도 등과 같은 실제 데이터를 기반으로 함
     * 예를 들어, 세계 최고의 50개 레스토랑 데이터베이스에서 restaurantName, cityName, year를 자연 키로 사용할 수 있음
     * 그러나 자연 키는 고유성을 보장하지 못할 수 있음. 예를 들어, 같은 이름의 레스토랑이 여러 도시에 있을 수 있음

  정체성

     * 자연 키는 고유성을 보장하는 것 외에도 정체성을 보장해야 함
     * 예를 들어, 자동차의 차대 번호나 개인 식별 번호(CPR 번호)를 자연 키로 사용할 수 있음
     * 그러나 동일한 사람이 여러 개의 식별 번호를 가질 수 있음. 예를 들어, 덴마크에서는 성전환자가 새로운 CPR 번호를 받을 수 있음

  서류 오류

     * 자연 키는 서류 오류에 취약함
     * 데이터 입력 오류, 사용자 오타, 데이터 변환 오류 등이 발생할 수 있음
     * 시스템은 이러한 오류를 수정할 수 있어야 함. 따라서 외부 키를 데이터베이스 키로 사용하는 것은 적절하지 않음

  결론

     * 자연 키를 데이터베이스 설계에서 사용하는 것은 좋은 아이디어가 아님
     * 데이터 오류가 발생할 수 있으며, 이러한 오류를 수정할 수 있어야 함
     * 따라서 데이터베이스 테이블에는 항상 인공 키를 사용하는 것이 좋음

GN⁺의 의견

     * 자연 키의 문제점: 자연 키는 고유성과 정체성을 보장하지 못할 수 있으며, 데이터 입력 오류에 취약함.
     * 인공 키의 장점: 인공 키는 고유성과 정체성을 보장하며, 데이터 오류를 쉽게 수정할 수 있음.
     * ORM 사용 시 고려사항: ORM 라이브러리를 사용할 때는 인공 키를 사용하는 것이 더 쉬움. ORM은 데이터베이스 구조를 일정 부분 결정하기 때문에, 인공 키를 사용하는 것이 더 효율적임.
     * 비슷한 기능의 제품: 다른 데이터베이스 설계 도구나 ORM 라이브러리도 인공 키 사용을 권장함. 예를 들어, Hibernate, Entity Framework 등이 있음.
     * 기술 도입 시 고려사항: 새로운 데이터베이스 설계를 도입할 때는 자연 키의 단점을 고려하고, 인공 키를 사용하는 것이 좋음. 인공 키는 데이터 무결성을 보장하고, 오류를 쉽게 수정할 수 있음.

        Hacker News 의견

     * 고유하고 짧으며 사람이 읽기 쉬운 ID: Stripe에서 사용하는 cus_MJA953cFzEuO1z 같은 ID를 선호함. JavaScript/TypeScript로 생성하는 방법도 있음.
     * 개인 식별 번호: 덴마크의 CPR 번호와 미국의 SSN을 비교. SSN은 고유하지 않으며, 변경될 수 있고, 미국 시민이 아니어도 발급 가능함. 데이터베이스 키로 사용하지 말 것을 권장.
     * 별칭과 감사 로그: 덴마크 CPR 번호와 같은 자연 키를 사용할 때, 변경 사항을 기록하는 별도의 테이블이 필요함. URL도 자연 키로 사용 가능하지만 변경 시 리디렉션 테이블을 만들어야 함.
     * 자연 키의 한계: 고유 식별자가 변경되면, 모든 관련 정보를 추적해야 함. 인위적인 키를 추가하면 추적해야 할 정보가 더 많아짐. 데이터 모델링은 현실 세계를 반영해야 함.
     * 자연 키와 개인정보 보호: 자연 키에 개인 정보가 포함되면, 외래 키를 통해 다른 테이블에도 전파될 수 있음.
     * 게임 태그 예시: PlayStation Network의 게임 태그를 자연 키로 사용하는 예시. 게임 태그가 변경되지 않으면 고유 식별자로 사용 가능함.
     * 의료 분야 예시: 등록 직원이 잘못된 개인 건강 번호(PHN)를 입력하면 문제가 발생함. 인위적인 키를 사용하면 나중에 정정 가능함.
     * 자연 키의 통제 불가능성: 이름, 주소, 공식 등록 번호 등은 통제할 수 없기 때문에 신뢰할 수 없음. 고유 키 시스템을 사용해야 함.
     * 인위적인 키 사용: 모든 테이블에 고유 ID 필드를 사용하면 문제 해결이 쉬워짐. 데이터와 관계가 자주 변경되기 때문에 자연 키를 믿기 어려움.
     * 변경 가능성과 고유 ID: 변경 가능성은 시간에 걸쳐 공통된 식별자를 필요로 함. 데이터베이스는 명시적인 대리 키를 스키마에 포함해야 함.

   인공키도 글로벌 리전 등에 대응하는 분산 환경에 대응 준비가 되어 있는 TSID를 사용하는 것을 추천합니다. 저는 MySQL, DynamoDB에서 PK로 TSID를 사용합니다.

   https://jsonobject.hashnode.dev/using-tsid-as-database-pk
"
"https://news.hada.io/topic?id=15199","이스라엘, 가짜 소셜 계정을 사용해 미국 의원들의 지지 확보","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   이스라엘, 가짜 소셜 계정을 사용해 미국 의원들의 지지 확보

  이스라엘, 미국 의원들을 대상으로 비밀 영향력 캠페인 진행

     * 주요 내용: 이스라엘 정부가 미국과 캐나다의 흑인 의원들과 젊은 진보층을 대상으로 대규모 영향력 캠페인을 진행함. 이 캠페인은 가자 전쟁이 시작된 후 여론을 조작하기 위해 시작되었음.
     * 캠페인 방식: 가짜 계정과 사이트를 통해 친이스라엘 및 이슬람 혐오 콘텐츠를 퍼뜨림. 이 작업은 이스라엘의 디아스포라 문제부와 정치 캠페인 회사에 의해 조직됨.
     * 목적: 특정 대중의 의견을 이스라엘의 행동에 유리하게 바꾸기 위함.

  GN⁺의 의견

     * 배경 지식: 소셜 미디어를 통한 여론 조작은 최근 몇 년간 다양한 국가에서 사용되고 있음. 이는 특정 국가의 정치적 이익을 위해 여론을 조작하는 데 효과적임.
     * 흥미로운 점: 이스라엘이 미국의 특정 그룹을 타겟으로 한 점은 흥미로움. 이는 미국 내에서 이스라엘에 대한 지지를 유지하기 위한 전략으로 보임.
     * 비판적 시각: 가짜 계정과 허위 정보를 이용한 캠페인은 신뢰성을 떨어뜨리고, 장기적으로는 해당 국가의 이미지에 부정적인 영향을 미칠 수 있음.
     * 유사 사례: 러시아의 2016년 미국 대선 개입 사례와 유사함. 이는 소셜 미디어를 통한 여론 조작의 위험성을 보여줌.
     * 고려 사항: 이러한 기술을 도입할 때는 윤리적 문제와 장기적인 영향에 대해 신중히 고려해야 함.

        Hacker News 의견

     * 이스라엘의 무능함: 이스라엘의 무능함이 드러남.
     * OpenAI의 발표: OpenAI가 ChatGPT를 이용한 비밀 영향력 캠페인을 중단시켰음.
     * 인터넷 전쟁: 인터넷이 전쟁의 새로운 전장이 되었음.
     * 미국의 인터넷 군대: 미래에 미국이 인터넷 군대를 만들 가능성 있음.
     * 적의 소셜 미디어 활용: 적들이 소셜 미디어를 이용해 미국 시민의 지지를 얻으려 함.
     * 과거 경험: 2005년에 정치인들이 소셜 미디어를 이용한 캠페인을 했다는 경험.
     * 플래그 이유: 왜 이 댓글이 플래그 되었는지 궁금함.
     * 외국 세력: 외국 세력으로 취급되지 않는 것이 이해되지 않음.
     * 가짜 스레드: 다른 플랫폼에도 가짜 스레드가 많을 것 같음.
     * 미국 정부의 타협: 미국 정부가 이스라엘의 영향력에 타협되었음.
     * 테러리스트 추적: 테러리스트 그룹을 추적하는 회사에서 일한 경험.
"
"https://news.hada.io/topic?id=15205","마이크로소프트 자살 시도 의혹","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            마이크로소프트 자살 시도 의혹

마이크로소프트의 새로운 기능, CoPilot+와 Recall

  주요 내용 요약

     * AI의 확산:
          + 최근 기술 뉴스는 AI(인공지능)의 확산에 집중하고 있음.
          + 많은 기업들이 AI를 제품에 추가하려는 움직임을 보이고 있음.
     * CoPilot+ 소개:
          + CoPilot+는 마이크로소프트의 LLM(대규모 언어 모델) 기반 윈도우 애드온임.
          + 과거의 클리피(Clippy)와 유사하지만, AI를 활용하여 사용자 작업을 돕는 기능을 가짐.
          + 그러나 LLM의 한계로 인해 정확한 답변을 제공하지 못할 가능성이 있음.
     * 윈도우 ARM 프로세서:
          + 마이크로소프트는 인텔에 의존하지 않기 위해 ARM 기반 윈도우를 추진 중임.
          + 새로운 CoPilot+ PC는 강력한 ARM 프로세서를 탑재하여 AI 작업에 적합하게 설계됨.
     * Recall 기능:
          + Recall은 사용자가 컴퓨터에서 수행한 모든 작업을 기록하는 기능임.
          + 스크린샷을 찍고, OCR(광학 문자 인식) 및 음성 인식을 통해 텍스트를 추출하여 데이터베이스에 저장함.
          + 저장된 데이터는 암호화되지 않아 보안 문제가 발생할 수 있음.
     * 프라이버시 문제:
          + Recall 기능은 사용자 프라이버시를 심각하게 침해할 수 있음.
          + 저장된 데이터에는 사용자 자격 증명, 비밀번호 등이 포함될 수 있음.
          + 법적 절차에서 데이터베이스가 소환될 수 있어 기업과 개인에게 큰 위험이 됨.
     * 기타 문제점:
          + Recall 기능은 GDPR 및 HIPAA와 같은 프라이버시 법규를 위반할 가능성이 있음.
          + 마이크로소프트는 이 기능을 윈도우 11 업데이트에 강제로 포함시킬 예정임.

  GN⁺의 의견

     * 프라이버시 침해:
          + Recall 기능은 사용자 프라이버시를 심각하게 침해할 수 있음. 특히 민감한 데이터를 다루는 기업이나 개인에게 큰 위험이 됨.
     * 보안 취약점:
          + 암호화되지 않은 데이터베이스는 해커나 악의적인 사용자에게 쉽게 노출될 수 있음. 이는 보안 사고를 초래할 가능성이 큼.
     * 법적 문제:
          + Recall 기능은 GDPR 및 HIPAA와 같은 프라이버시 법규를 위반할 가능성이 높음. 이는 법적 분쟁을 초래할 수 있음.
     * 사용자 신뢰도:
          + 마이크로소프트의 이러한 기능 도입은 사용자 신뢰도를 크게 훼손할 수 있음. 이는 장기적으로 기업 이미지에 부정적인 영향을 미칠 수 있음.
     * 대안 기술:
          + 사용자 프라이버시를 중시하는 기업들은 Recall 기능 대신 다른 대안을 고려해야 함. 예를 들어, 오픈소스 기반의 보안 솔루션을 도입하는 것이 좋음.

        Hacker News 의견

     * Security 및 프라이버시 우려: Recall은 AI 기능보다는 기기 내 OCR과 SQLite 데이터베이스 검색 기능으로 보임. OCR이 머신 러닝 기반일 가능성 있음.
     * EU 법적 문제: Recall이 EU에서 불법이 아니라면, Microsoft는 빠르게 EU 전역에서 제품 금지 법안을 맞이할 가능성 있음. 특히 가정 폭력 문제로 인해 정치적으로 민감한 사안임.
     * Microsoft의 미래: Microsoft의 미래가 Windows에만 의존하지 않음. Satya Nadella 이후로 회사의 방향이 바뀌었고, 미래가 밝음.
     * 데이터 유출 문제: Microsoft나 다른 대형 IT 기업이 데이터 유출을 해도 큰 처벌을 받지 않을 가능성 있음. 최근 데이터 유출 사례로는 Snowflake와 AWS/Capital One 등이 있음.
     * 웹 서버 문제: Microsoft의 웹 서버가 먼저 문제를 일으켰을 가능성 있음.
     * Microsoft의 수익 증가: 최근 분기 실적 보고서에서 17%의 수익 증가를 기록했고, 주가는 지난 1년 동안 거의 25% 상승함.
     * Windows의 주목도 상승: 이 기능 덕분에 Windows가 다시 주목받고 있음. 사용자들이 이 기능의 위험성을 이해하고 끄는 방법을 배워야 함.
     * 유사한 오픈 소스 도구: Recall과 유사한 오픈 소스 스크린샷 도구가 GitHub에 있었음. 프라이버시 문제에 대해 고민 중이지만 ARM을 Windows에 다시 도입하는 것은 긍정적으로 봄.
     * 언어 모델 기술의 한계: 언어 모델 기술이 미래를 지배할 것이라는 의견이 있지만, 일반적인 문제 해결에는 한계가 있음.
     * SQLite 데이터베이스의 프라이버시 위험: Microsoft 소프트웨어가 SQLite 데이터베이스를 쿼리하여 사용자 활동을 추적할 수 있음. 이는 인터넷 마케터에게는 꿈 같은 상황이지만, 사용자 프라이버시에는 큰 위험이 됨.
"
"https://news.hada.io/topic?id=15227","Stable Audio Open 공개 - 오디오 샘플과 사운드 디자인을 위한 오픈 소스 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Stable Audio Open 공개 - 오디오 샘플과 사운드 디자인을 위한 오픈 소스 모델

     * 간단한 텍스트 프롬프트에서 최대 47초 분량의 고품질 오디오 데이터를 생성할 수 있게 해줌
     * 특화된 훈련 덕분에 드럼 비트, 악기 리프, 앰비언트 사운드, 폴리 녹음 및 음악 제작과 사운드 디자인을 위한 기타 오디오 샘플을 만드는 데 이상적
     * 이 오픈 소스 릴리스의 주요 장점은 사용자가 자신의 커스텀 오디오 데이터에 모델을 미세 조정할 수 있다는 것
          + 예를 들어, 드러머는 자신의 드럼 녹음 샘플에 미세 조정하여 새로운 비트를 생성할 수 있음
     * Stable Audio와 어떻게 다른가?
          + 상용 제품인 Stable Audio는 최대 3분 길이의 일관된 음악 구조를 가진 고품질 풀 트랙과 오디오-오디오 생성 및 일관된 다중 파트 음악 작곡과 같은 고급 기능을 제공
          + 반면에 Stable Audio Open은 오디오 샘플, 사운드 효과 및 프로덕션 요소에 특화되어 있음
               o 짧은 음악 클립을 생성할 수는 있지만, 전체 노래, 멜로디 또는 보컬에는 최적화되어 있지 않음
               o 이 오픈 모델은 창작 커뮤니티와 함께 책임감 있는 개발을 우선시하면서 사운드 디자인을 위한 생성적 AI에 대한 통찰력을 제공
     * Stable Audio Open 모델 가중치는 Hugging Face에서 사용할 수 있음
          + 사운드 디자이너, 뮤지션, 개발자, 오디오 애호가들이 모델을 다운로드하고 그 기능을 탐구하며 피드백 권장
"
"https://news.hada.io/topic?id=15212","맥용 Bartender 앱의 소유자 변경과 투명성 부족에 대한 우려","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 맥용 Bartender 앱의 소유자 변경과 투명성 부족에 대한 우려

     * 인기 있는 Mac 앱인 Bartender가 약 두 달 전에 조용히 매각됨
     * 이전 소유자와 현재 소유자 모두 고객에게 매각에 대한 정보를 제공하지 않았음
     * 일부 Reddit 사용자들이 MacUpdater의 경고를 통해 Bartender의 소유 회사가 조용히 교체되었음을 알게 됨
     * MacUpdater는 투명성 부족으로 인해 버전 5.0.52 이후의 앱 업데이트가 잠재적으로 안전하지 않을 수 있다고 경고함

  새로운 소유자의 반응

     * Bartender의 새로운 소유자가 Reddit 스레드에 답변을 남기며 Bartender가 인수되었음을 확인했으나, 고객에게 통보하지 않은 이유나 인증서 변경에 대한 설명은 하지 않았음
     * 새로운 소유자는 앱을 업데이트하기 위해 Apple의 정보로 앱을 다시 서명해야 했으며, 이로 인해 한 번의 인증서 변경이 발생했다고 설명함
     * 이 사실을 릴리스 노트에 기재하지 못했지만, 블로그에 포함하고 이메일을 통해 사용자에게 공유했다고 주장함
     * 새로운 소유자는 원래 개발자인 Ben과 긴밀히 협력하여 그의 비전을 이해하고, 성능 향상을 위해 계획된 개선 사항을 구현하고 과거 몇 달 동안 보고된 버그를 해결할 계획임

  사용자 반응과 추가 정보

     * Reddit 사용자들은 새로운 소유자의 신원에 대한 추가 정보를 요청했으나 응답이 없었음
     * Bartender 웹사이트는 사용자들이 새로운 권한 요청 팝업을 보기 시작한 후 인증서 변경에 대한 정보를 업데이트했음
     * 블로그 게시물에서는 새로운 인증서 요청이 ""예상되고 유효하다""고 설명하지만, 구매에 대한 배경 정보는 제공되지 않음
     * Reddit 스레드에서 소유자는 웹사이트에 판매 정보가 게시되었다고 주장했으나, 이는 사실이 아님

  업데이트

     * Bartender의 원래 개발자인 Ben Surtees는 (이 기사가 나간뒤) 오늘에서야 앱을 세 달 전에 Applause에 매각했다고 밝힘
     * Applause에 대한 다른 정보는 없으며, Applause는 여전히 공식적으로 매각에 대해 언급하지 않음

        Hacker News 의견

     * Bartender 라이센스가 만료된 후 HiddenBar로 전환했음. 오픈 소스이며 무료이고, 신원 불명의 새로운 소유자가 인수하지 않았음
     * Bartender 는 3개월 전에 했어야 할 일을 이제야 했음 (Ben이 완전한 성명을 발표). 당시 발표되었다면 걱정했겠지만, 지금 상황에서는 ""매우"" 걱정됨
     * 주요 미국 기술 회사에서 일하는 개발자들을 타겟으로 한 소프트웨어 인수가 일어나는 것을 우려함
     * BetterTouchTool 앱을 사용하는 경우 상태 항목 관리를 위한 튜토리얼과 예제 프리셋을 제공함
     * 난 2015년에 첫 라이센스를 받았으며, 모든 Mac에 설치하는 중요한 유틸리티임
          + 새로운 소유자의 행동이 의심스러워 보임
          + 원래 개발자가 좋은 보상을 받았기를 바람
          + 업데이트 없이 앱을 계속 사용할 계획이며, 더 나은 것을 찾을 때까지 유지할 예정
     * Mac OS는 사용 가능한 데스크탑 경험을 위해 많은 서드파티 확장이 필요함
          + 이 상황은 프로그램 저자에 대한 신뢰를 많이 요구함을 보여줌
     * 네이티브 앱을 사용하고 서드파티 앱을 줄이려고 노력 중임
          + Bartender를 오랫동안 사용했으나 1년 전에 제거함
          + Menubar 앱을 도입하기 전에 여러 번 고민함
          + 아이콘이 단색인지 확인하고, 컬러 아이콘은 거부함
          + Control Center와 자신이 설정한 제한으로 지금까지 잘 버텨왔음
     * Bartender의 새로운 소유자인 ""Unknown""이 이제 알려짐: applause.dev에 의해 인수됨
     * 이젠 아래 명령으로 Hidden Bar와 Bartender가 불필요해짐
          + defaults -currentHost write -globalDomain NSStatusItemSelectionPadding -int 6 defaults -currentHost write -globalDomain NSStatusItemSpacing -int 6
          + 명령어 실행 후 로그아웃하고 다시 로그인해야 함
"
"https://news.hada.io/topic?id=15231","ASCII Silhouettify - 이미지를 ASCII 실루엣으로 변환","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ASCII Silhouettify - 이미지를 ASCII 실루엣으로 변환

     * 입력 이미지는 로고, 배너, 픽셀 아트 등 단순하고 고대비 형태의 그래픽
     * 출력 형식은 단색 텍스트, ANSI 색상 텍스트, HTML, Neofetch ASCII 아트 형식 등

  옵션

     * 입력: 여러 이미지 형식(png, svg, jpg 등)을 동시에 변환 가능함.
     * 출력: 단색 텍스트, ANSI 색상 텍스트, HTML, Neofetch ASCII 아트 형식 지원.
     * 팔레트: 기본적으로 240색을 사용하며, 사용자가 색상 수를 조정 가능함.
     * 폰트 크기 및 줄 높이: 터미널에서 최적의 ASCII 아트를 위해 폰트 크기와 줄 높이 설정 가능함.
     * 스케일: 입력 이미지 파일을 터미널에 나타낼 크기로 조정 가능함.
     * 어두움: 밝기 임계값을 조정하여 배경을 투명하게 처리 가능함.
     * 스레드: 변환 작업을 여러 프로세서에 분배하여 처리 속도 향상 가능함.

  알고리듬

     * 이미지 분할: 이미지를 색상 평면으로 분리하고, 각 평면을 9×19 픽셀의 직사각형 영역으로 나눔.
     * 최적 문자 선택: 각 영역에 맞는 최적의 ASCII 문자를 선택하여 변환함.
     * 비트마스크 사용: 변환 속도를 높이기 위해 비트마스크를 사용하여 가능한 문자를 빠르게 찾음.
     * 색상 평면 분리: CIEDE2000 색상 차이 공식을 사용하여 색상 평면을 분리함.

GN⁺의 의견

     * 흥미로운 점: ASCII Silhouettify는 단순한 이미지 변환을 넘어, 다양한 출력 형식을 지원하여 활용도가 높음.
     * 도움이 되는 이유: 로고나 배너를 ASCII 아트로 변환하여 터미널 환경에서 시각적으로 표현할 수 있음.
     * 비판적 시각: 고해상도 이미지나 복잡한 그래픽은 변환이 어려울 수 있음.
     * 대안 제품: ANSI art나 kaomoji를 활용하는 다른 ASCII 아트 생성 도구들도 있음.
     * 기술 도입 고려사항: 변환 속도와 출력 품질을 고려하여 사용해야 함. 특히, 색상 팔레트와 폰트 설정이 중요함.

        Hacker News 의견

     * Coolest page on the site: ASCII 실루엣을 만드는 도구 소개.
     * Similar tool: 게임 스프라이트를 코드에 직접 삽입할 수 있는 도구 제작.
     * ASCII art lovers: GIF를 ASCII로 변환하는 애니메이션 도구 소개.
     * Web version issue: 웹 버전은 완료되지 않지만 CLI 버전은 작동함.
     * ASCII art example: ASCII 아트 예시 제공.
     * Editing motd/issue: 오늘 많은 motd와 issue 파일 편집 필요 예상.
     * Preference for asciiflow: figma보다 asciiflow.com을 선호함.
     * Recent related post: 하루 전에 비슷한 주제의 게시물 언급.
     * Old printing methods: EBCDIC와 ASCII를 사용한 옛날 배너와 그림 인쇄 방식 회상.
     * Telnet Matrix with color: 컬러가 추가된 Telnet Matrix와 유사함.
     * Retro computer image converter: 고정 폰트를 사용한 레트로 컴퓨터 이미지 변환기 제작 경험 공유.
     * Blogging service with ASCII art: ASCII 아트를 홈 페이지 헤더로 설정할 수 있는 블로깅 서비스 작업 중.
     * Figlet.js port: figlet.js 포트를 사용하여 블로그 헤더 생성.
     * Looking forward to suggestions: Silhouettify와 다른 제안들을 시도해볼 기대.
"
"https://news.hada.io/topic?id=15288","클라우드 내 AI 프라이버시의 새로운 경계: Private Cloud Compute","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             클라우드 내 AI 프라이버시의 새로운 경계: Private Cloud Compute

Apple의 Private Cloud Compute (PCC)

  Private Cloud Compute 소개

     * Apple Intelligence는 iPhone, iPad, Mac에 강력한 생성 모델을 제공하는 개인 지능 시스템임.
     * **Private Cloud Compute (PCC)**는 복잡한 데이터 처리를 위한 클라우드 지능 시스템으로, 사용자 데이터의 보안을 강화함.
     * PCC는 Apple의 기기 보안과 프라이버시를 클라우드로 확장하여 사용자 데이터가 Apple을 포함한 누구에게도 접근되지 않도록 보장함.

  Private Cloud Compute 설계

     * 개인 사용자 데이터의 무상태 처리: PCC는 사용자 요청을 처리하기 위해서만 데이터를 사용하고, 처리 후에는 데이터를 보관하지 않음.
     * 강제 가능한 보증: PCC는 외부 구성 요소에 의존하지 않고, 모든 보안 및 프라이버시 보증을 기술적으로 강제할 수 있음.
     * 특권 실행 접근 금지: PCC는 Apple 직원이 특권 접근을 통해 프라이버시 보증을 우회할 수 없도록 설계됨.
     * 비타겟화: 공격자가 특정 사용자의 데이터를 목표로 삼을 수 없도록 설계됨.
     * 검증 가능한 투명성: 보안 연구자들이 PCC의 보안 및 프라이버시 보증을 검증할 수 있도록 함.

  Private Cloud Compute 노드 소개

     * 신뢰의 근원: PCC 노드는 Apple 실리콘과 보안 기술을 데이터 센터에 도입하여 보안을 강화함.
     * 하드웨어 및 운영 체제: iOS와 macOS의 보안 기술을 활용한 새로운 운영 체제를 사용함.
     * 클라우드 확장: 원격 셸 및 시스템 관찰 도구를 제외하고, 제한된 운영 메트릭만 제공함.

  무상태 처리 및 강제 가능한 보증

     * 사용자 데이터 처리: PCC는 사용자 요청을 처리하기 위해서만 데이터를 사용하고, 처리 후에는 데이터를 삭제함.
     * 보안 기술: Secure Boot, Code Signing, Secure Enclave 등을 사용하여 데이터 무결성을 보장함.

  특권 실행 접근 금지

     * 원격 셸 및 디버깅 도구 제외: PCC 노드는 원격 셸이나 디버깅 도구를 포함하지 않음.
     * 관찰 및 관리 도구: 사용자 데이터를 노출하지 않도록 설계된 도구만 사용함.

  비타겟화

     * 하드웨어 보안: 제조 단계에서부터 데이터 센터까지 하드웨어 보안을 강화함.
     * 타겟 확산: 요청 메타데이터에 개인 식별 정보를 포함하지 않음.

  검증 가능한 투명성

     * 소프트웨어 이미지 공개: 모든 PCC 소프트웨어 이미지를 보안 연구를 위해 공개함.
     * 투명성 로그: 모든 코드 측정을 암호화된 투명성 로그에 기록하고 공개함.
     * 연구 환경 제공: 보안 연구자들이 PCC 소프트웨어를 검증할 수 있도록 도구와 이미지를 제공함.

GN⁺의 의견

    1. 보안 강화: PCC는 사용자 데이터의 보안을 강화하여 클라우드 AI 처리의 새로운 표준을 제시함.
    2. 투명성: 소프트웨어 이미지를 공개하여 보안 연구자들이 검증할 수 있도록 함으로써 신뢰성을 높임.
    3. 기술적 도전: 무상태 처리와 특권 실행 접근 금지 등 기술적 도전 과제를 해결함.
    4. 경쟁 제품: Google의 Confidential Computing과 같은 다른 클라우드 보안 솔루션과 비교해볼 만함.
    5. 도입 고려 사항: PCC 도입 시 초기 설정과 유지 관리 비용을 고려해야 함.

        Hacker News 의견

     * 암호학자 Matt Green의 의견: Matt Green의 의견을 참고할 만함. 트윗 링크 제공됨.
     * 트윗 접근성 문제: Matt가 X 계정 없이 트윗을 읽을 수 없다는 점을 인식했는지 궁금함. BlueSky나 Masto를 사용하라는 제안.
     * Apple의 신뢰 문제: Apple이 언제든지 업데이트를 통해 백도어를 만들 수 있으며, 정부가 이를 강제할 수 있다는 점에서 신뢰 문제가 발생함. 투명성이 부족하면 신뢰 메시지가 손상됨.
     * 미국 내 프라이버시 문제: 미국에서는 정부가 Apple에게 데이터를 공개하도록 강제할 수 있으며, 이를 공개하지 못하게 할 수도 있음. 이는 Apple이 해결할 수 없는 한계임.
     * 연구자들을 위한 개선: Apple 플랫폼에서 처음으로 sepOS 펌웨어와 iBoot 부트로더가 평문으로 제공되어 연구자들이 중요한 구성 요소를 더 쉽게 연구할 수 있게 됨.
     * 90일의 격차: 취약한 소프트웨어가 공개되고 발견될 때까지 최대 90일의 격차가 있을 수 있음. 실제 이미지의 가용성이 최대한 빠르기를 희망함.
     * 누구를 위한 것인가: 이 기능이 누구를 위한 것인지 궁금함. 개인적으로는 ""calls home"" 기능을 끄고 싶음. Apple이 가장 안전한 옵션이라고 말하고 싶지 않음.
     * 서버에서의 Swift 사용: 서버에서 Swift를 사용하여 새로운 머신 러닝 스택을 구축한 것이 흥미로움. Swift 서버 문서 링크 제공됨.
     * 감사 가능한 보안 보장: Apple이 감사 가능한 보안 보장을 제공할 수 있을지에 대한 신중한 낙관론. 클라우드 OS가 오픈 소스로 제공된다면 매우 가치 있을 것임.
     * 우회 가능성: Apple이 마음을 바꾸면 가짜 PCC 노드에 키를 반환하여 모든 보호 장치를 우회할 수 있음. 특정 사용자에 대해 이를 수행할 가능성도 있음.
     * 프라이빗 클라우드의 네트워크 접근성: 프라이빗 클라우드가 외부 네트워크에 접근할 수 있는지 여부에 대한 정보가 부족함. 네트워크 접근이 보장되지 않으면 요청이 클라우드 내에 머무른다는 보장이 무의미해짐.
     * 긍정적인 방향: 민감한 데이터를 보내지는 않겠지만, 현재 업계의 추세와 비교했을 때 Apple의 노력과 방향성을 높이 평가함.
"
"https://news.hada.io/topic?id=15217","Peazip - 오픈소스 파일 압축/해제 유틸리티","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Peazip - 오픈소스 파일 압축/해제 유틸리티

     * 리눅스/윈도우/맥 지원. 설치 없이 이용가능(포터블)
     * GUI와 CLI 애플리케이션 간 격차를 줄임: GUI에서 수행한 행동들을 CLI 스크립트로 Export 해서 자동화/재사용 가능
     * 암호화를 지원하는 모든 포맷에 대해 2FA 인증(암호+키파일) 지원
     * GUI가 잘 제공되지 않는 포맷들도 지원 : zpaq, brotli, zstandard 등
     * 200개 이상의 압축 포맷 지원
     * 다양한 체크섬 및 해시 검증, 중복 파일 찾기, 압축파일 변환, 압축파일 내 검색, 북마크, 탭 브라우징등 다양한 파일 관리 기능
     * Pascal(Lazarus)로 작성된 LGPL v3 라이선스 오픈소스

   오랜 역사와 전통을 자랑하는 이녀석이 오랜만에 여기서 보는군요.
"
"https://news.hada.io/topic?id=15285","Manifest - 간단하지만 풀 기능을 제공하는 백엔드(BaaS) 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Manifest - 간단하지만 풀 기능을 제공하는 백엔드(BaaS) 오픈소스

     * 데이터 구조만 정의(YML)하면 주요 기능을 갖춘 백엔드가 완성
          + DB, 관리자 패널, REST API, Javascript SDK
     * SDK/REST 로 다른 프론트엔드 스택과 쉽게 연동 가능 (React, Angular, Vue, Svelte, Next.js,..)
     * Typescript + NodeJS 오픈소스

   PoC 상태라고 하니.. 나중에 뭔가 되겠지요.

   주요 기능을 완결성 있게(full) 갖췄다고 하기에는 프로젝트가 제공하는 기능이 빈약해보입니다. 당장 붙일 수 있는 인증 기능조차 문서화돼 있지 않습니다. README에서 비교 대상으로 Supabase를 언급하고 있는데 전혀 비교할 수 있을만한 상태가 아닌 것 같이 보입니다

   yaml로 데이터베이스 모델링 하실 수 있을 정도의 개발자라면 굳이 이런 도구를 쓰시지 않더라도 다른 대중적인 웹 프레임워크로 백엔드를 개발할 수 있습니다. DB를 쓰는 REST API 구현은 이미 다른 언어와 기술 스택으로 설계와 표현 방식이 잘 정립돼 있는 주제라 생각합니다만.. 메인테이너가 왜 이 정도 기능 만으로 프로젝트를 어딘가에 홍보한건지 잘 이해가 안 되네요

   payloadcms가 얼추 비슷한 느낌이지 않나요?
   ts로 컬렉션 구조 정의하면 db, 어드민, api 뽑아주는... 그런 느낌

   이건 신기하네요... 😲

   좋아보이네요!
"
"https://news.hada.io/topic?id=15317","셀프 서비스 대시보드가 작동하지 않는 이유 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        셀프 서비스 대시보드가 작동하지 않는 이유

     * ""self-serve dashboards""는 실제로는 잘 작동하지 않음. 엔지니어나 데이터 과학자가 비즈니스 사용자를 위해 쿼리를 작성하고 대시보드를 준비하는 데 많은 시간을 소비하게 되기 때문임.

  ""self-serve BI""가 작동하지 않는 이유

     * SQL이 유일한 ""self-serve BI"" 도구임. 하지만 대부분의 ""self-serve BI"" 공급 업체는 SQL을 다른 것으로 위장하려고 함.
     * SQL 쿼리 작성이 비즈니스 이해 관계자가 데이터를 쿼리하는 유일한 장벽이 아님. 데이터의 의미, 출처, 계산 방식을 이해하지 못하고 결과를 해석하고 검증하는 방법을 모름.

    시도 1: 기존의 ""드롭다운 및 확인란"" 접근 방식

     * 이 인터페이스는 ""SQL-by-mouse""를 시도한 것에 불과함. SQL보다 나을 것이 없고 오히려 더 느리고, 신뢰할 수 없고, 제한적이며 다른 도구로 일반화할 수 없음.
     * CFO와 같은 사람은 이 인터페이스를 사용하여 데이터를 쿼리하지 않을 것임. 데이터를 이해할 수 있는 맥락이 없고 결과에 대해 확신할 수 없기 때문임.

    시도 2: text-to-SQL 접근 방식

     * LLM은 자연어를 SQL로 번역하는 데 거의 너무 효과적임. 질문이 맞지 않아도 쿼리를 생성하려고 할 것임.
     * 기술자는 질문이 맞지 않다는 것을 알아차리고 더 많은 맥락을 요청할 것임. 사용 가능한 데이터 유형을 설명하고 정확하고 유용한 질문을 만들기 위해 비즈니스 담당자와 협력할 것임.
     * LLM이 ""self-serve BI""의 실제 솔루션이 될 수 있지만, 현재 형태로는 안 됨. 더 많은 맥락이 필요하고 불확실성을 표현하고 더 많은 정보를 요청하는 데 더 능숙해져야 함.

  실제로 작동하는 것

     * ""self-serve BI""의 문제는 SQL이 아니라 데이터의 맥락과 의미임. 해결책은 인터페이스에 관계없이 사람들에게 쿼리하는 데이터에 대해 가르치는 것임.
     * 기술팀에게 모든 지식을 문서화하는 것은 상당한 오버헤드를 발생시키고 빠르게 구식이 됨.
     * ""self-serve BI""의 진정한 해결책은 비기술 사람들을 위해 BI를 ""self-serve""로 만드는 것이 아니라, 기술 사람들이 더 나은 도구를 사용하여 비즈니스 이해 관계자를 더 효율적으로 지원하도록 하는 것임.

  더 나은 도구에 대한 제안:

    1. LLM을 비즈니스 이해 관계자가 아닌 기술자에게 제공함.
    2. Python, R 등 편한 도구를 사용하여 데이터를 자유롭게 다룰 수 있도록 함.
    3. 기술자가 작업 내용을 쉽게 공유할 수 있도록 함. 노트북과 내부 데이터 애플리케이션은 컨테이너, 종속성, 인프라를 다뤄야 해서 공유하기 어려움.

        Hacker News 의견

     * BI 도구의 문제점: BI 도구를 사용하면서 쿼리의 조인 방식이 잘못 설정되어 데이터가 잘못 표시된 경험이 있음. SQL을 잘 모르는 사람들을 위한 추상화 계층에 대한 신뢰를 잃게 됨.
     * Text-to-SQL의 유용성: 개발자에게는 여전히 유용하지만, 비개발자에게는 데이터베이스 구조를 제대로 이해하지 못해 잘못된 쿼리를 생성할 가능성이 있음.
     * 기관의 무능함: BI 도구와 AI 도구의 오류와 잘못된 정보가 포함된 보고서가 실제로 사용되고 있으며, 이는 Dilbert 만화에서 비슷하게 비판된 바 있음.
     * 비즈니스 사용자의 학습 가능성: 비즈니스 사용자가 데이터 모델과 드롭다운의 관계를 이해할 수 없다는 가정은 잘못됨. 데이터 모델러가 도메인을 잘 이해하지 못해 문제가 발생함.
     * 데이터 제공 경험: 24년간 데이터 제공 경험을 통해, 소수의 사용자만이 도구를 실제로 사용하며, 경영진은 KPI 대시보드를 선호함.
     * Metabase의 장점: Metabase는 BI 도구 중에서도 좋은 인터페이스를 제공하며, GUI로 생성된 SQL을 순수 SQL로 변환할 수 있어 기술 수준이 낮은 사람들도 쉽게 사용할 수 있음.
     * 자체 서비스 BI의 한계: 자체 서비스 BI의 한계를 인식하고, SQL을 비즈니스 사용자에게 노출시키지 않는 맞춤형 대시보드를 만드는 것이 해결책임.
     * Metabase 사용 경험: Metabase를 사용하면서 '오피스 아워'를 통해 비기술 사용자에게 사용법을 교육한 결과, 많은 요청이 엔지니어링 팀으로 넘어가지 않게 됨.
     * SQL 사용의 아이러니: 고위 관리자가 SQL 쿼리를 실행하지 못하는 상황이 아이러니함. SQL은 원래 관리자가 데이터를 쉽게 쿼리할 수 있도록 만들어진 것임.
     * ETL의 어려움: BI보다 ETL에서 비기술 사용자가 데이터를 다루는 것이 더 어려움. AWS Glue를 개발하면서 기술 사용자가 문제를 디버깅할 수 있는 도구가 필요함을 깨달음.
"
"https://news.hada.io/topic?id=15254","빙산을 그려서 떠오르는 모습을 확인하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         빙산을 그려서 떠오르는 모습을 확인하기

Iceberger: 빙산의 부력을 시뮬레이션하는 게임

  게임 소개

     * Iceberger는 사용자가 빙산을 그리면, 그 빙산이 물 위에 어떻게 떠오를지를 시뮬레이션해주는 게임임.
     * 빙산은 물보다 밀도가 낮아서 항상 물 위에 떠오르며, 약 10%의 질량이 물 위에 드러남.
     * 빙산의 실제 부력은 페이지에 표시된 것과는 다를 수 있음. 이는 빙산의 3차원 질량 분포와 물과의 상대 밀도에 따라 달라지기 때문임.

  영감

     * 이 게임은 @GlacialMeg의 트윗에서 영감을 받아 @joshdata가 개발함.

GN⁺의 의견

     * 교육적 가치: 빙산의 부력 원리를 시각적으로 이해할 수 있어 교육적으로 유익함.
     * 물리 시뮬레이션: 실제 물리 법칙을 반영한 시뮬레이션으로, 물리학에 대한 흥미를 유발할 수 있음.
     * 사용자 인터랙션: 사용자가 직접 빙산을 그려보는 인터랙티브 요소가 있어 재미를 더함.
     * 한계점: 실제 빙산의 3차원 구조와 밀도 분포를 완벽히 반영하지 못해 현실과 차이가 있을 수 있음.
     * 비슷한 프로젝트: 다른 물리 시뮬레이션 게임이나 교육용 소프트웨어와 비교해볼 만함.

        Hacker News 의견

     * 물 위에 평평한 표면만 얻을 수 있어서 좌절했지만, 트윗을 읽고 그것이 핵심임을 깨달음. 링크
     * 글쓴이임. 몇 년 만에 다시 회자되는 것을 보니 기쁨. 과학을 응원하고, 지역 기후 과학자를 지원해야 함.
     * 무한히 흔들리는 디자인을 얻었음. 클립은 실시간으로 녹화된 것임. 링크
     * 많은 빙산이 여러 평형 상태를 가짐. 예를 들어, 어떤 빙산은 한 평형 상태에서는 물 위로 높이 솟아오르지만, 다른 평형 상태에서는 거의 물 위로 나오지 않음. 링크
     * 트위터에서 다른 사람들이 이걸 제안했는지 모르겠지만, 빙산이 안정적인 부유 위치를 얻기 위해 필요한 이동 거리에 반비례하는 점수를 추가하는 것도 좋을 것 같음.
     * HTML 소스 코드는 잘 주석 처리되어 있어 읽기 재미있음. 드래그, 질량, 밀도를 모델링하는 수학이 포함되어 있음. 이미지를 붙여넣으면 코드가 이미지를 추적하고 가장 복잡한 다각형을 선택함.
     * 매우 재미있고 정확함. 목욕할 때 테스트해보니 내가 그린 그림처럼 상추가 떠있었음.
     * 사전 로드된 모양과 힘을 명시적으로 보여주는 버전이 있음. 링크
     * 2021년의 것임. 이전에 본 것 같지만 찾을 수 없음.
     * ""빙산의 일각""을 그리면 뒤집히는 것을 보는 것이 좀 웃김. 링크
"
"https://news.hada.io/topic?id=15207","클릭 한 번으로 이해하기 쉽게 AI가 데이터를 해석해주는 Graphy","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 클릭 한 번으로 이해하기 쉽게 AI가 데이터를 해석해주는 Graphy

     * Graphy는 다양한 데이터 소스(Google Sheets, GA, Google Search Console 등)에서 데이터를 한 곳에 모아 대시보드로 만들 수 있는 도구
     * AI 기능을 활용해 데이터를 빠르게 해석하고 인사이트를 도출할 수 있음
     * 데이터 공유가 쉬워 내부 팀원, 클라이언트 등에게 선별적으로 정보를 공개할 수 있음
     * 무료 계정으로도 충분히 사용 가능하며, 임베딩 및 외부 링크 공유가 자유로워 BIP에 활용하기 좋음
     * 데이터 출처가 다양하고, 해석 역량이 다르며, 공유가 어려운 문제를 Graphy가 해결하고 있음
     * Graphy의 사용 사례로는 PM, 인디 메이커, 세일즈 매니저 등이 있음
"
"https://news.hada.io/topic?id=15286","실종자 사건 해결을 위한 ROV 제작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          실종자 사건 해결을 위한 ROV 제작

Part 1 - 소개

  시작

     * 2019년 2월, Hacker News에서 ""The Hunt for the Death Valley Germans""라는 이야기를 읽게 됨
     * 실제 사건은 비극적이었지만, 한 사람이 사건을 해결한 과정이 인상적이었음
     * 이 이야기를 읽고 나서 나도 이런 일을 할 수 있을지 고민하게 됨

  형제와의 대화

     * 이야기를 몇 번 읽고 형제에게 공유함
     * 형제도 이런 종류의 이야기에 관심이 많았음
     * 기사에 대해 오랫동안 대화하며 다양한 실종 사건과 해결 방법에 대해 이야기함

  새로운 모험의 시작

     * 2020년 가을, 형제로부터 흥미로운 실종 사건에 대한 전화를 받음
     * 이 전화가 가장 흥미로운 모험의 시작이었고, 9년과 15년 동안 미해결된 두 실종 사건을 해결하게 됨

  이야기의 기반

     * 이 이야기는 나의 메모, 사진, 비디오, GPS 로그, 소나 이미지 및 기타 디지털 흔적을 기반으로 작성됨
     * 가능한 한 사실을 확인했으며, 오류가 있다면 전적으로 나의 책임임
     * 지도를 제공하지 않았지만, 충분히 능력 있는 사람들은 공공 소스와 나의 설명을 통해 실제 장소를 추론할 수 있음

GN⁺의 의견

     * 실종 사건 해결의 중요성: 이 기사는 실종 사건 해결의 중요성과 개인의 노력으로도 큰 변화를 만들 수 있음을 보여줌.
     * 기술의 활용: GPS 로그, 소나 이미지 등 다양한 기술을 활용한 점이 흥미로움.
     * 협업의 힘: 형제와의 협업이 사건 해결에 큰 도움이 되었음을 강조함.
     * 실제 사례의 힘: 실제 사례를 통해 독자들에게 더 큰 공감을 불러일으킴.
     * 추가 자료의 필요성: 지도가 제공되지 않아 독자가 직접 추론해야 하는 점이 아쉬움.

        Hacker News 의견

     * Tom Mahood의 ""The Hunt for the Death Valley Germans""는 매우 흥미로운 읽을거리로, 지역 구조팀에 참여하게 된 계기가 되었음.
     * 기사 도입부에서 약어를 정의하는 것이 좋겠음. 예를 들어, ""ROV""는 ""Remote Operated Vehicle""임.
     * 여러 가지 일에 너무 분산되어 흥미를 잃었지만, 사명감이 있다면 포기하지 말고 계속하라는 조언.
     * 프로젝트가 매우 잘 작성되었고, 물과 관련된 신호 처리의 독특한 도전 과제가 흥미로웠음.
     * 프로젝트와 방의 ""어수선함""이 과거 재택근무 시절을 떠올리게 했음. 기술적인 팁도 제공함.
     * 저자가 실종자 사건에 깊이 빠져들어 영감을 주는 접근 방식과 성과를 보여줌.
     * 감정적으로 매우 불안정했던 사람이 자살 가능성이 높아 보임.
     * ROV를 자동화하여 수면을 효율적으로 매핑하는 도전에 대해 궁금해함.
     * 핀란드 남성이 실종자 사건에 호기심을 가지고 ROV를 제작하여 놀라운 결과를 얻었음.
     * 기술 작업을 통해 이야기를 전할 수 있는 능력을 가지게 된 점이 인상적임.
"
"https://news.hada.io/topic?id=15258","구글 소프트웨어 엔지니어링의 AI: 진전과 향후 전망","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     구글 소프트웨어 엔지니어링의 AI: 진전과 향후 전망

     * 2019년에는 대부분의 소프트웨어 엔지니어가 머신러닝이 자신들의 업무에 어떤 도움이 될지 상상하기 어려웠음
     * 그러나 2024년에는 AI가 코드 작성을 돕는 방식에 대해 널리 열광하고 있음
          + 많은 엔지니어들이 회사 내부 도구나 상용 제품에서 ML 기반 자동완성을 사용해봤음
     * 이 글에서는 구글의 내부 소프트웨어 개발 도구의 지속적인 변화 속에서 최신 AI 기반 개선 사항을 소개함
          + 향후 5년 동안 예상되는 추가 변화에 대해서도 논의함
     * 전문적인 소프트웨어 개발에 가치를 전달하는 AI 제품을 구축하는 방법론도 제시함
          + 이 팀은 IDE, 코드 리뷰, 코드 검색 등 구글 엔지니어들이 대부분의 시간을 보내는 소프트웨어 개발 환경을 담당함
          + 이러한 개선이 개발자 생산성과 만족도에 직접적인 영향을 미칠 수 있음을 보여줌

  도전과제

     * AI 기술이 빠르게 진화하고 있어 어떤 아이디어를 먼저 탐색할지 예측하기 어려운 것이 이 영역에서의 지속적인 도전 과제임
     * 기술적으로 실현 가능한 데모와 성공적인 제품화 사이에는 종종 상당한 격차가 존재함
     * 아이디어를 제품에 배포하는 접근 방식에는 세 가지 지침이 있음:
         1. 기술적 실현 가능성과 영향력에 따라 우선순위를 정함: 기술적 실현 가능성이 이미 입증되었고 엔지니어의 워크플로우에 높은 (측정 가능한) 영향을 미칠 것으로 예상되는 아이디어에 대해 작업함
         2. 신속하게 학습하여 UX와 모델 품질을 개선함: 개발자의 생산성과 행복을 지키면서 신속하게 반복하고 얻은 교훈을 추출하는 데 중점을 둠. 사용자 경험은 모델 품질만큼 중요함
         3. 효과 측정: 목표는 생산성과 만족도 지표를 높이는 것이므로 이러한 지표를 광범위하게 모니터링해야 함

  LLM을 소프트웨어 개발에 적용하기

     * 트랜스포머 아키텍처의 출현과 함께 LLM을 소프트웨어 개발에 적용하는 방법을 모색하기 시작함
     * LLM 기반 인라인 코드 완성은 소프트웨어 개발에 적용되는 AI의 가장 인기 있는 응용 프로그램임
          + 코드 자체를 훈련 데이터로 사용하는 것은 LLM 기술의 자연스러운 응용임
          + UX는 개발자에게 자연스럽게 느껴짐. 단어 수준 자동완성은 오랜 기간 IDE의 핵심 기능이었기 때문임
          + AI로 작성된 새 문자의 비율과 같은 영향력에 대한 대략적인 측정이 가능함
          + 이러한 이유로 LLM의 이 응용 프로그램이 가장 먼저 배포되는 것이 이치에 맞음
     * 이전 블로그에서는 코드 완성으로 사용자 경험을 개선하는 방법과 영향을 측정하는 방법을 설명함
          + 그 이후로 다른 기업 환경과 유사한 지속적인 빠른 성장을 보였음
          + 소프트웨어 엔지니어의 수용률은 37%이며, 코드 문자의 50%를 완성하는 데 도움을 줌
     * 주요 개선 사항은 모델과 UX 모두에서 나왔음
          + 이 주기는 합성 공식이 아닌 실제 행동에서 배우는 데 필수적임
     * 다양한 도구에서 얻은 기록 데이터와 사용자 선호도 및 요구 사항을 캡처한 사용 데이터를 활용하여 코딩 도구(예: IDE)의 AI 기반 기능을 개선함
     * AI 지원을 통해 생성된 코드 비율이 지속적으로 증가함
          + 이는 AI 기반 제안에서 수락된 문자 수를 수동으로 입력한 문자 수와 AI 기반 제안에서 수락된 문자 수의 합으로 나눈 값으로 정의됨
          + 주목할 점은 복사-붙여넣기에서 가져온 문자는 분모에 포함되지 않는다는 것임
     * 여러 도구에서 오랜 기간 동안 큐레이션해온 내부 소프트웨어 엔지니어링 활동에 대한 방대하고 고품질의 로그를 사용함
          + 이 데이터를 통해 세분화된 코드 편집, 빌드 결과, 빌드 문제 해결을 위한 편집, 코드 복사-붙여넣기 작업, 붙여넣은 코드 수정, 코드 검토, 검토자 문제 해결을 위한 편집, 저장소에 변경 사항 제출 등을 표현할 수 있음
     * 훈련 데이터는 입력과 출력 모두에서 작업별 주석이 달린 정렬된 코드 말뭉치임
     * 다음으로 중요한 배포는 코드 리뷰 의견 해결(현재 8% 이상이 AI 기반 지원으로 처리됨)과 붙여넣은 코드를 주변 컨텍스트에 자동으로 적응시키는 것(현재 IDE에서 코드의 약 2%를 차지함)이었음
     * 추가 배포에는 자연어로 IDE에 코드 편집을 지시하고 빌드 실패에 대한 수정 사항을 예측하는 것이 포함됨
          + 유사한 패턴을 따르는 코드 가독성을 위한 팁 예측과 같은 다른 응용 프로그램도 가능함
     * 함께 이러한 배포된 응용 프로그램은 Google에서 성공적이고 많이 사용되는 응용 프로그램이었으며, 실제 산업 환경에서 생산성에 측정 가능한 영향을 미쳤음

  배운 것들

     * 현재까지의 작업을 통해 몇 가지 사실을 배웠음:
         1. 사용자의 워크플로우에 자연스럽게 녹아드는 UX로 가장 높은 영향력을 달성함. 위의 모든 예에서 사용자에게 제안이 제시되어 한 번의 탭이나 클릭으로 워크플로우의 다음 단계로 이동함. 사용자가 기능을 트리거해야 한다는 것을 기억하도록 요구하는 실험은 확장하지 못했음
         2. AI 기반 제안을 통해 코드 작성자가 점점 더 리뷰어가 되고 있음을 관찰함. 리뷰 비용과 부가 가치 사이의 균형을 찾는 것이 중요함. 일반적으로 수용률 목표로 절충안을 해결함
         3. 오프라인 메트릭은 종종 사용자 가치의 대략적인 대리자에 불과하므로 온라인 A/B 실험을 통한 신속한 반복이 핵심임. AI 기반 기능을 내부 도구에 노출함으로써 쉽게 출시 및 반복하고, 사용 데이터를 측정하며, UX 리서치를 통해 사용자에게 직접 경험을 물어볼 수 있다는 점에서 큰 이점이 있음
         4. 우리 기능과의 상호 작용을 포함하여 소프트웨어 도구 전반에 걸친 Google 엔지니어의 활동에서 얻은 고품질 데이터는 모델 품질에 필수적임
     * UX와 모델 개선을 활용하여 중간 단계의 병목 현상을 제거하면서, 기회(대부분 사용자 활동, 아래 깔때기 상단에 표시됨)에서 영향(적용된 AI 지원, 깔때기 하단)까지의 전환을 최적화하는 것이 중요함

  What's Next

     * 지금까지의 성공에 고무되어 최신 기반 모델(Gemini 시리즈)을 개발자 데이터(위에서 언급한 DIDACT의 일부)와 결합하여 Google의 소프트웨어 엔지니어링에 ML을 적용하는 기존 및 새로운 애플리케이션에 힘을 실어주는 데 주력하고 있음
     * 업계 전반에 걸쳐 ML 기반 코드 완성은 소프트웨어 개발자에게 큰 도움을 제공했음
          + 코드 생성을 개선할 기회는 여전히 있지만, 다음 단계의 혜택은 테스트, 코드 이해 및 코드 유지 관리와 같은 더 광범위한 소프트웨어 엔지니어링 활동에서 ML 지원으로부터 나올 것으로 기대됨
          + 후자는 엔터프라이즈 환경에서 특히 관심이 높음
          + 이러한 기회는 우리 자신의 진행 중인 작업에 정보를 제공함
     * 업계에서 볼 수 있는 두 가지 트렌드를 강조함:
         1. 인간-컴퓨터 상호 작용은 일반적인 양식으로 자연어 쪽으로 이동했으며, 소프트웨어 엔지니어링 작업에 대한 인터페이스로 언어를 사용하고 IDE에 통합된 소프트웨어 개발자의 정보 요구에 대한 게이트웨이로 사용하는 방향으로 전환되고 있음
         2. 문제 진단부터 수정 사항 적용까지 대규모 작업의 ML 기반 자동화는 초기 실현 가능성에 대한 증거를 보여주기 시작했음
               o 이러한 가능성은 에이전트와 도구 사용의 혁신에 의해 주도되며, 이는 더 큰 작업을 수행하기 위해 하나 이상의 LLM을 구성 요소로 사용하는 시스템을 구축할 수 있게 해줌
     * 이러한 차세대 기능을 향한 위의 성공을 확장하기 위해, 이 주제에 대해 연구하는 실무자와 연구자 커뮤니티는 실용적인 엔지니어링 작업을 향해 분야를 이동하는 데 도움이 되는 공통 벤치마크의 혜택을 받을 수 있음
          + 지금까지 벤치마크는 주로 코드 생성(예: HumanEval) 중심이었음
          + 그러나 엔터프라이즈 환경에서는 코드 마이그레이션 및 프로덕션 디버깅과 같은 더 광범위한 작업에 대한 벤치마크가 특히 가치 있을 수 있음
          + 버그 해결(예: SWEBench)을 위한 벤치마크와 그러한 벤치마크를 대상으로 하는 프로토타입(예: Cognition AI)이 발표되었음
     * 더 광범위한 소프트웨어 엔지니어링 작업을 포괄하기 위해 더 많은 벤치마크를 제안하기 위해 커뮤니티가 함께 모이기를 권장함

  GN⁺의 의견

     * AI의 빠른 진화: AI 기술이 빠르게 발전하고 있어, 최신 기술을 지속적으로 학습하고 적용하는 것이 중요함.
     * UX와 모델 품질: 사용자 경험과 모델 품질이 AI 도구의 성공에 중요한 요소임.
     * 데이터의 중요성: 고품질 데이터가 AI 모델의 성능을 크게 좌우함.
     * 미래의 가능성: AI가 소프트웨어 엔지니어링의 다양한 측면에서 더 큰 역할을 할 가능성이 있음.
     * 산업 트렌드: 자연어 인터페이스와 대규모 작업 자동화가 소프트웨어 개발의 미래를 이끌 것임.

        Hacker News 의견

     * AI가 제대로 사용될 때, 두 가지 역할을 함: 1) 논란 없는 수정으로 개발자의 시간을 절약하고 인지 부하를 줄임. 2) 제안을 통해 사용자를 더 똑똑하고 지식 있게 만듦. 예를 들어, 코드 완성 기능이 잘 작동할 때가 있음.
     * AI 도구가 사용자가 기능을 트리거해야 할 때 ""확장에 실패""한다는 흥미로운 주장 있음. IDE 내에서 AI가 유용하게 디자인 수준과 개념적 아이디어를 제안하는 방법에 대해 고민 중.
     * AI 기반 제안으로 인해 코드 작성자가 점점 리뷰어가 되는 현상 관찰됨. 리뷰 비용과 추가 가치 사이의 균형을 찾는 것이 중요함.
     * GPT-4를 사용하여 React UI와 Python UI를 몇 분 만에 생성하고 코드를 리뷰하여 작동 방식을 이해하는 것이 유용하다고 느꼈음.
     * 인간의 제한된 RAM 때문에 아이디어를 외부 매체에 넣어야 함. AI의 제안이 초기 단계를 더 빠르게 진행하는 데 도움을 줌.
     * LLMs(대규모 언어 모델)가 프로그래밍에 유용하다는 것은 부인할 수 없음. 더 매끄럽게 만들기 위한 올바른 UX가 핵심 도전 과제임. 자동 완성 기능을 사용해 보았으나, 대부분의 제안이 좋지 않아 비활성화함.
     * ChatGPT 데스크탑 앱을 사용하여 코드 질문을 하는 것이 더 유용하다고 느꼈음. 그러나 매번 세부 사항을 설명해야 하는 것이 번거로움.
     * AI 지원 코드 작성 비율이 50%까지 증가하는 추세가 흥미로움.
     * AI가 요청한 작업을 수행하는 방법을 알려주지만, 그것이 나쁜 아이디어라는 것을 알려주지 않음. ML 생성 코드의 품질은 훈련 데이터에 달려 있음.
     * AI가 Google의 소프트웨어 엔지니어를 완전히 대체하는 데 얼마나 걸릴지 궁금함.
     * AI의 궁극적인 목표는 시스템을 운영하고, 앱을 디버그하며, 데이터 스토어를 관리하고, 사용자 피드백과 요구 사항 설명에 따라 앱 코드를 작성하는 것임.
     * AI 도구를 실험하는 것은 좋지만, 다른 사람들이 맹목적으로 복사하는 것은 부정적인 영향을 미칠 수 있음. LLM을 사용한 코드 작성의 주요 판매 포인트를 찾기 어려움.
"
"https://news.hada.io/topic?id=15248","Notepad Tab - 간단하고 안전한 노트 작성 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Notepad Tab - 간단하고 안전한 노트 작성 도구

     * 작성된 모든 내용이 주소창에 저장되며, 브라우저 히스토리에 기록이 남음
     * URL을 복사하는 것 만으로 백업 및 공유 가능
     * 쿠키와 별도 서버가 필요없음
     * Ruby + Node.js 로 작성된 된 오픈소스

   헉.. 타이핑마다 브라우저 히스토리에 쌓이는건 좀 충격적이네요..

   괜찮아보이는데요 ㅋㅋㅋㅋ
   근데 또 간단한 텍스트를 전달할 거면, 그냥 텍스트 통으로 보내지 뭐하러 텍스트가 압축된 URL을 보내나 싶기도 하네요...

   서식이 좀 추가되면 쓸만할 지도?

   정적 페이지 생성을 위해서 ruby와 jekyll을, 프론트엔드 라이브러리 설치와 개발 단계 중 파일 변경사항 감지를 위해서 nodejs를 사용하기로 결정했다니... 오버엔지니어링의 표본이네요

   그러게요, 정적페이지를 이렇게까지 만들줄이야

   url을 복사할거면 그냥 텍스트 내용을 복사하면 되는거 아닌가 싶기도 하고요..? 희한하네요 어디에 쓰이려나

   싱글 파일로 만들 수도 있는 걸 굳이 복잡하게 오버엔지니어링 해놨네요 🤣🤣

   유용한듯 아닌듯.. 오묘합니다.

   Base64 인코딩 과정에서 원본 데이터의 길이는 일반적으로 약 33% 증가하는것을 고려하면 정말 오묘한 느낌이네요, 데이터를 안전하게 전송하고 저장하는 데는 유용하지만, 데이터 양이 증가한다는 점을 고려하면 어느 정도의 비용이 들어간다고 볼 수 있습니다. 이런 비용을 URL 파싱이나 구조적인 모양(mermaid.live에서 영감을 받았다고 하니)을 처리하는 데 필요한 리소스로 생각해볼 때, 상황에 따라 유용할 수도 있고 아닐 수도 있겠네요😄

   https://github.com/revolter/notepadtab.com/blob/main/index.html#L80

   그래도 최소한 압축 정도는 구현해 놨네요. 이게 이렇게까지 개발환경에 여러 기술을 써서 해결해야할 일인가 싶긴 합니다
"
"https://news.hada.io/topic?id=15289","구글플레이 패스 한국 출시, 월 6,500원으로 1,000개 이상의 앱과 게임을 광고 없이","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           구글플레이 패스 한국 출시, 월 6,500원으로 1,000개 이상의 앱과 게임을 광고 없이

   • 구글플레이 패스는 월 6,500원의 구독료로 1,000개 이상의 앱과 게임을 광고 없이 즐길 수 있는 월간 구독 서비스입니다.

   • 구글플레이 패스에 가입하면 구글플레이 스토어 하단에 ""Play Pass"" 카테고리가 추가되고, 다양한 게임들에 대해 약 6,500원 상당의 할인 쿠폰을 제공하는 ""혜택"" 섹션도 확인하실 수 있습니다.

   • FC 모바일, 나혼자만 레벨업:어라이즈, 세븐나이츠 키우기, EA SPORTS FC Online M, 던전앤파이터 모바일, 카트라이더 러쉬플러스 등 국내 대표적인 인기 게임 뿐 아니라 포켓몬 고(Pokémon GO), 로블록스(Roblox) 등 세계적인 인기 게임도 한국의 구글플레이 패스 구독자에게 할인 혜택을 제공합니다.

   가족공유가 되네요. 유튜브 프리미엄은 언제...
"
"https://news.hada.io/topic?id=15291","마이크로프론트엔드 모범관행","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             마이크로프론트엔드 모범관행

    1. 수평적 팀 피하기
          + 프론트엔드 기술 기반으로 팀 구성하는 대신 비즈니스 역량에 맞춰 수직적 팀 구성
    2. 팀 코드 분리하기
          + 팀이 독립적인 단위로 마이크로프론트엔드 구축하도록 장려
    3. 의존성 관리 워크플로 만들기
          + 마이크로프론트엔드에서 의존성 관리하는 명확한 프로세스 구축
    4. 지속적 통합과 배포 수용하기
          + CI/CD 파이프라인 구현해 마이크로프론트엔드 빌드, 테스트, 배포 프로세스 자동화
    5. 컴포넌트 라이브러리 사용하기
          + 재사용 가능한 UI 컴포넌트, 스타일, 유틸리티가 포함된 공유 라이브러리 개발, 유지
    6. 모니터링과 에러 핸들링 구현하기
          + 모니터링 도구와 오류 추적 시스템 통합해 마이크로프론트엔드 성능과 상태 모니터링
    7. 문서화와 커뮤니케이션
          + 팀이 API, 데이터 흐름, 통합 지점 포함한 마이크로프론트엔드 문서화하도록 장려
    8. 다양한 수준에서 테스트하기
          + 단위 테스트, 통합 테스트, 엔드투엔드 테스트 등 마이크로프론트엔드 종합 테스트 전략 구현
    9. 성능 최적화 고려 사항
          + 코드 분할, 지연 로딩, 캐싱 같은 성능 최적화 기술 적용해 마이크로프론트엔드 로딩 속도와 전반적 성능 개선
"
"https://news.hada.io/topic?id=15200","한 달 만에 M1에서 Vulkan1.3 지원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        한 달 만에 M1에서 Vulkan1.3 지원

Vulkan 1.3, M1에서 한 달 만에 구현

  Honeykrisp 드라이버 소개

     * Honeykrisp 드라이버: Apple 하드웨어에서 최초로 완전한 Vulkan 1.3 사양을 구현한 드라이버임.
     * 개발 상태: 아직 최종 사용자에게는 출시되지 않았으며, 기능 추가와 성능 개선 중임. 소스 코드는 개발자에게 공개됨.

  개발 과정

    4월 2일

     * 시작: NVK 드라이버를 기반으로 M1용 Vulkan 드라이버 개발 시작.

    4월 3일

     * 디스크립터 세트: NVIDIA와 다른 M1의 디스크립터 세트를 NVK에 맞게 조정함.

    4월 4일

     * 컴퓨트 셰이더: 컴퓨트 셰이더를 컴파일하고 Vulkan 명령을 사용해 버퍼와 이미지를 복사하는 기능 구현.

    4월 6일

     * 그래픽 상태 처리: 그래픽 상태를 처리하는 코드 작성, OpenGL 드라이버에서 코드를 가져와 NVK와 결합함.

    4월 7일

     * 동적 상태: 모든 상태를 동적으로 처리하는 전략 채택, 프로로그와 에필로그를 컴파일하고 캐시하는 코드 추가.

    4월 8일

     * 테스트 결과: 초기 테스트 결과 149,770개 통과, 7,741개 실패, 2,396개 충돌.

    4월 9일

     * Vulkan 1.3: Vulkan 1.1에서 99.6% 통과율 달성 후, Vulkan 1.3으로 전환하여 98.3% 통과율 달성.

    4월 10일~4월 12일

     * 추가 테스트: SuperTuxKart와 Zink에서 Vulkan 렌더러 작동 확인, 테스트 버그 수정.

    4월 16일~4월 17일

     * 컴파일러 버그 수정: 디스크립터 인덱싱 테스트에서 발견된 컴파일러 버그 수정, 무한 루프 문제 해결.

    4월 18일

     * 제로 카피 렌더링: 효율적인 표면 레이아웃을 위해 EXT_image_drm_format_modifier 확장 구현.

    4월 22일

     * 드라이버 아키텍처 검토: 드라이버 아키텍처 검토 후 최적화 진행, vkoverhead 테스트에서 1초당 1억 번의 드로우 호출 달성.

    4월 24일~4월 25일

     * YCbCr 지원: YCbCr 기능 추가, Mohamed Ahmed의 NVK 코드 활용.
     * 쿼리 복사: GPU 쿼리 복사 기능 구현.

    4월 26일

     * 경계 색상: Direct3D 호환성을 위한 EXT_custom_border_color 확장 구현, 경계 색상 문제 해결.

    4월 27일

     * 최종 테스트: 모든 테스트 통과, 686,930개 통과, 0개 실패.

  미래 계획

     * DXVK와 vkd3d-proton 지원: Direct3D 레이어링을 위한 추가 기능 구현 예정.
     * Windows 게임 실행: Wine과 오픈 소스 x86 에뮬레이터를 사용해 Asahi Linux에서 Windows 게임 실행 계획.

GN⁺의 의견

     * 기술적 도전: M1에서 Vulkan 1.3을 구현하는 것은 기술적으로 매우 도전적인 작업임. 이는 Apple 하드웨어의 독특한 아키텍처 때문임.
     * 게임 개발자에게 유익: Vulkan 드라이버가 완성되면, 게임 개발자들은 더 많은 플랫폼에서 게임을 실행할 수 있게 되어 유익함.
     * 성능 최적화 필요: 초기 단계에서는 성능 최적화가 필요할 수 있음. 특히 동적 상태 처리로 인한 CPU 오버헤드 문제를 해결해야 함.
     * 커뮤니티 기여: 오픈 소스 프로젝트로서 커뮤니티의 기여가 중요함. 다양한 하드웨어와 소프트웨어 환경에서의 테스트와 피드백이 필요함.
     * 경쟁 제품: DXVK와 vkd3d-proton 외에도 Wine과 같은 다른 호환성 레이어가 있음. 각 제품의 장단점을 비교해 선택하는 것이 중요함.

        Hacker News 의견

     * 공유, 반복적, 개방형 컴포넌트의 가치를 증명하는 인상적인 작업임. Proton이 포팅되는 데 얼마나 걸릴지 궁금함. GPU 아키텍처 차이와 ARM 변환 오버헤드로 인해 많은 게임이 제대로 실행되지 않을 가능성이 있음. 그래도 SoC가 더 보편화되면서 더 많은 게임이 통합 메모리와 ARM을 타겟으로 할 것이라는 낙관적인 전망을 가짐.
     * Vulkan을 Linux에 추가하고 DirectX를 Asahi Linux에서 변환하는 노력이 Apple의 AAA 게임을 Apple Silicon에 도입하려는 꿈에 영향을 미칠지 궁금함. Apple은 AAA 개발자들이 게임을 Metal로 포팅하여 iPhone, iPad, Mac, Vision Pro에서 실행되기를 원함. Mac 게이머들이 AAA PC 타이틀을 플레이하기 위해 Asahi Linux를 설치할 가능성도 있음.
     * Vulkan 1.3에 익숙하지 않지만 저수준 그래픽 API 작업에 관심이 있다면 확인해볼 가치가 있음. 초기 장애물을 넘으면 작업이 즐거워짐. 모든 동적 상태와 사전 설정 없는 렌더 패스로 작업이 훨씬 쉬워짐. 10년 이하의 GPU를 가진 모든 데스크탑 플랫폼에서 사용 가능함. 다만, ""합리적인 기본값"" 프레임워크는 없지만 여러 언어에 유용한 헬퍼 라이브러리가 많음.
     * 프로그래밍 능력이 그녀의 절반만큼이라도 되고 싶음. 정말 대단함.
     * Alyssa의 놀라운 코딩 마법. 어떻게 하는지 모르겠지만, 그녀가 좋은 싸움을 하고 있어서 기쁨.
     * 컴파일러 버그는 절대 발생하지 않음. 하지만 실제로는 컴파일러 버그였음. 경력 동안 한 번도 경험하지 못했지만, 추상화 수준에서는 덜 드물게 발생할 수 있음.
     * ES 3.2 지원 업데이트를 막 했는데, M1이 Asahi를 위해 만들어진 것 같음. macOS는 설치할 때 한 번 부팅했을 뿐임. 브라우저가 '제로 카피 렌더링'을 지원하는지 궁금함. 웹GL2 변환 피드백이 읽기 작업을 트리거하는 문제에 갇힌 기억이 있음.
     * 특이한 셰이더 구조가 있음. 조건이 항상 거짓이지만 컴파일러는 이를 알지 못함. 이 구조의 목적이 무엇인지 궁금함.
     * VM 내에서 사용 가능 여부. macOS에서 개발하고 Ubuntu를 테스트하기 위해 VMware 이미지를 사용함. 3D 그래픽 앱을 개발하는데 VMware의 패스스루가 얼마나 좋은지 모르겠음. Apple Silicon GPU가 VM에서 가상화되는지, 이 배포판을 실행하여 더 나은 그래픽 성능을 얻을 수 있는지 궁금함.
     * MoltenVK와의 관계를 설명해 줄 수 있는지 궁금함. 이 작업이 MoltenVK의 필요성을 제거하는지, 네이티브 드라이버인지 궁금함.
"
"https://news.hada.io/topic?id=15245","σ-GPTs: 새로운 자기회귀 모델 접근법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        σ-GPTs: 새로운 자기회귀 모델 접근법

σ-GPTs: 새로운 자기회귀 모델 접근법

  개요

     * 자기회귀 모델(GPT 계열)은 일반적으로 고정된 순서(보통 왼쪽에서 오른쪽)로 시퀀스를 생성함.
     * 이 논문에서는 출력에 위치 인코딩을 추가하여 이 순서를 샘플마다 동적으로 조절할 수 있음을 보여줌.
     * 이를 통해 임의의 토큰 하위 집합을 샘플링하고 조건을 설정할 수 있으며, 거부 전략에 따라 한 번에 여러 토큰을 동적으로 샘플링할 수 있음.
     * 결과적으로 모델 평가 횟수를 서브-선형으로 줄일 수 있음.

  주요 내용

     * 위치 인코딩 추가: 출력에 위치 인코딩을 추가하여 시퀀스 생성 순서를 동적으로 조절할 수 있음.
     * 다양한 도메인 평가: 언어 모델링, 경로 해결, 항공기 수직 속도 예측 등 다양한 도메인에서 평가를 수행함.
     * 효율성 증가: 생성에 필요한 단계 수를 한 차원 줄이는 데 성공함.

GN⁺의 의견

     * 기술적 혁신: 기존의 고정된 순서에서 벗어나 동적 순서 조절이 가능해짐으로써 모델의 유연성과 효율성이 크게 향상됨.
     * 실용적 응용: 다양한 도메인에서의 평가 결과는 이 접근법이 실용적 응용 가능성이 높음을 시사함.
     * 성능 향상: 서브-선형 모델 평가를 통해 성능을 크게 향상시킬 수 있음.
     * 미래 연구 방향: 이 접근법을 다른 유형의 모델이나 더 복잡한 문제에 적용해 볼 수 있는 가능성이 있음.
     * 비판적 시각: 동적 순서 조절이 모든 상황에서 항상 최적의 결과를 보장하지 않을 수 있음. 추가적인 연구와 검증이 필요함.

        Hacker News 의견

     * 첫 번째 의견: 저자는 입력 토큰을 무작위로 섞고 두 개의 위치 인코딩을 추가하여 모델을 훈련함. 이 간단한 수정으로 모델이 순서에 상관없이 병렬로 토큰을 예측할 수 있게 됨.
     * 두 번째 의견: 이 연구는 Taylorformer 논문과 유사한 접근 방식을 사용함. 시계열 데이터와 같은 연속적인 프로세스를 예측하는 데 도움이 됨.
     * 세 번째 의견: 이전 연구를 인용하지 않은 점이 아쉬움. 이 연구는 이미 ICML에 발표되었고 약 250개의 인용이 있음.
     * 네 번째 의견: 이 개념이 이미지 생성 모델의 동적과 유사해 보임. 큰 아이디어가 먼저 나타나고 세부 사항이 자연스럽게 채워지는 방식이 유용할 것 같음.
     * 다섯 번째 의견: 트위터에 텍스트를 생성하는 비디오가 있음. (링크 제공)
     * 여섯 번째 의견: 이 논문이 제공하는 기능이 매우 마음에 듦. JSON 생성, 특정 길이의 설명 생성 등 다양한 실험이 가능할 것 같음.
     * 일곱 번째 의견: 이 접근 방식이 컴퓨터 코드 생성에 특히 도움이 될 것 같음. 나중에 작성될 내용에 따라 현재 출력이 달라질 수 있음.
     * 여덟 번째 의견: 비전 트랜스포머의 학습을 언어 트랜스포머에 적용한 것 같음. 비전 모델이 이미지를 타일로 나누고 위치 인코딩을 추가하는 방식과 유사함.
     * 아홉 번째 의견: 코드가 어디에 있는지 궁금함. 이중 위치와 셔플링을 완전히 이해하지 못했음. 위치 인코딩에 concat을 사용한 점이 흥미로움.
     * 열 번째 의견: BERT는 시퀀스에서 무작위 마스킹을 사용했지만, 시간은 순차적임.
"
"https://news.hada.io/topic?id=15189","Error causes in the Console","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Error causes in the Console

   이제 크롬에서도 Error: cause 데이터 필드를 이용해서 rethrowing 되는 예외도 이제 콘솔 에서 출력 되는 스택 트레이스에서 Caused by prefix 를 사용해서 여러개의 에러 스택이 표현 됩니다.
try {
  connectToDatabase();
} catch (err) {
  // cause: err 를 이용해서 이전 err 를 연결 해요
  throw new Error(""Connecting to database failed."", { cause: err });
}

More

     * Caused by: prefix / https://developer.chrome.com/blog/new-in-devtools-125/…
     * Error: cause - JavaScript | MDN / https://developer.mozilla.org/en-US/docs/…
"
"https://news.hada.io/topic?id=15229","고객과 NDA 체결된 창작자들은 Adobe 취소를 권합니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    고객과 NDA 체결된 창작자들은 Adobe 취소를 권합니다

     * 고객과 NDA를 맺고 있는 경우, 크리에이티브, 변호사, 의사 또는 독점 파일로 작업하는 사람이라면 Adobe를 취소하고 모든 앱과 프로그램을 삭제해야 할 때임
     * Adobe가 Terms of Use를 업데이트
          + 당신의 콘텐츠를 자동/수동 방법으로 접근해서 콘텐츠 리뷰등을 위해 사용 가능
          + 고객의 자산을 복사하여 새로운 콘텐츠를 만들 수 있는 로열티 없는 권리를 주장하고 있음. (재라이선스 가능)
          + ""합리적인"" 사용 사례라고 설명하지만, 제한을 설명하지는 않음

        Hacker News 의견

     * Adobe 취소 수수료 회피 방법: 현재 Adobe 플랜을 다른 플랜으로 변경한 후, 다음 날 새로운 플랜을 취소하면 14일 취소 정책 덕분에 수수료 없이 취소 가능함.
     * Adobe의 응답: Adobe의 이용 약관에 대한 명확한 설명이 필요함.
     * Nintendo와 Google 유출 사건: 대형 광고 출시와 관련된 NDA(비밀 유지 계약서)는 매우 중요하며, 유출은 재고 가치를 크게 떨어뜨릴 수 있음.
     * 개인용 안드로이드 앱 문제: 개인적으로 개발한 앱을 업그레이드할 때 Google이 보안 검사를 위해 앱을 업로드하도록 요구함. 이는 Adobe 문제와 유사함.
     * Adobe의 새로운 이용 약관: Adobe는 사용자 콘텐츠를 운영 및 개선 목적으로 사용할 수 있는 비독점적, 전 세계적, 로열티 없는 라이선스를 가짐. 이는 많은 사용자에게 문제를 일으킬 수 있음.
     * AI 모델 훈련 의심: Adobe가 클라우드에 저장된 파일로 AI 모델을 훈련시키기 위해 이러한 조항을 추가했을 가능성이 있음.
     * Adobe 대체 어려움: 많은 사용자가 현실적으로 다른 소프트웨어로 전환하기 어려움.
     * 취소 수수료 문제: 14일 이후 취소 시 남은 계약 의무의 50%를 일시불로 지불해야 함.
     * 산업의 전문화 필요성: 소프트웨어 산업은 윤리 강령과 규정을 통해 고객 데이터를 보호해야 함.
     * Photoshop에서 GIMP로 전환: GIMP로 전환하는 데 도움이 되는 다양한 리소스가 있음. 책, 비디오 강좌, 블로그 등 다양한 자료가 존재함.
"
"https://news.hada.io/topic?id=15221","Show GN: 간단한 이미지 하이라이터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Show GN: 간단한 이미지 하이라이터

   서비스 가이드를 만들때, input창이나 button을 하이라이트 하는 경우가 많은데,
   mac에서 제공하는 기능으로는 backdrop을 깔고, 원하는 부분만 강조하기 어려웠어요.
   그래서 web에서 간단히 하이라이트 기능을 제공하는 툴을 만들었습니다.

   간단한 기능은 아래와 같아요.
     * 모든 작업은 브라우저에서 진행, 외부로 이미지가 유출되지 않음
     * JPG/PNG 지원
     * 원본이미지와 동일한 사이즈의 이미지로 다운로드
"
"https://news.hada.io/topic?id=15265","쇼핑 센터에서의 초음파 조사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            쇼핑 센터에서의 초음파 조사

     * 약 20kHz의 파일럿 톤(pilot tone)은 다중 스피커 PA 시스템에서 시스템 상태를 지속적으로 모니터링하기 위해 사용됨
          + 파일럿 톤이 없으면 스피커에 연결되지 않은 것을 의미함
          + 고객에게 방해가 되지 않도록 인간이 들을 수 없는 매우 높은 주파수로 설정됨
     * 그러나 이 톤은 강력하며 일부 사람들은 특히 주파수가 20kHz 미만일 때 여전히 들을 수 있음
          + 필자가 사는 도시에는 19.595kHz의 시스템이 있으며, 여러 사람이 그 소리를 듣는다고 함
          + 이는 17kHz까지 낮은 주파수를 사용하는 The Mosquito와 같은 음향 무기는 아닌 것으로 추정됨
          + 이 문제를 경험적으로 확인할 수 없는 사람들이 작업했기 때문에 고쳐지지 않은 잘못된 설정일 가능성이 높음
     * 이 소리는 거의 순수한 톤이 아니며, 항상 변조(modulation)가 있음
          + PA 시스템을 통해 재생되는 배경 음악에 의해 발생하는지, 정보를 전달하는지, 아니면 전혀 다른 것인지 궁금해짐
          + 강한 파일럿 톤 주변의 진폭 변조(amplitude modulation)를 보여주는 스펙트로그램 플롯이 제공됨
          + 그러나 이러한 종류의 변조는 드물며, 사람들이 움직이는 것과 같이 주변에서 일어나는 일에 대한 톤의 변화를 보는 것이 더 일반적임
     * 지하철역에 열차가 도착할 때 파일럿 톤에 어떤 일이 일어나는지를 보여주는 스펙트로그램이 제공됨
          + 필자는 이것이 감속하는 열차에서 반사되어 도플러 편이(Doppler-shifted)된 파일럿 톤의 역산란(backscatter) 또는 잔향(reverb)이라고 생각함
          + 파일럿 톤은 연속적으로 전송하는 쌍안정 소나(bistatic sonar)로 작동함
          + 열차가 오른쪽에서 왼쪽으로 지나갈 때, 왼쪽 마이크(녹색)는 대부분 음의 도플러 편이를, 오른쪽 채널(보라색)은 양의 도플러 편이를 감지함
     * 엘리베이터를 타고 다른 층으로 이동하면서 안에서 녹음한 결과, 10초 동안의 주행 중에 노이즈에 묻힌 파일럿 톤이 감지됨
     * 쇼핑몰 지하 주차장에서 PA 스피커 바로 아래에 서서 스쿠터가 지나가는 것을 녹음한 결과, 스테레오 스펙트로그램에서 많은 흥미로운 것들이 나타남
          + 19,595Hz와 19,500Hz에서 두 개의 파일럿 톤이 있는 것으로 보이며, 주차장에 두 개의 다른 PA 시스템이 있는 것으로 추정됨
          + 잔향에서 명확한 도플러 편이가 있으며, 스쿠터가 지나갈 때 주파수 변화가 양에서 음으로 바뀜
          + 이 도플러 곡선 아래에 노이즈로 '채워진' 패턴이 있는 것으로 보임
          + 단순화된 계산을 통해 스쿠터의 속도를 약 11km/h로 추정할 수 있음
     * 이 초음파 신호를 활용할 수 있는 몇 가지 아이디어:
          + 주차장에서의 자동 속도 측정
          + 에스컬레이터가 고장 났을 때 감지
          + 상업 미로에서 사람들이 길을 잃지 않도록 위치 코드로 변조
          + 광고 전달에 활용
          + 쇼핑몰에서 가장 조용한 곳을 찾는 데 사용

GN⁺의 의견

     * 초음파 기술의 활용: 초음파 기술은 다양한 분야에서 활용 가능성이 높음. 예를 들어, 보안 시스템, 위치 추적, 자동화된 공공 서비스 등에서 유용하게 사용될 수 있음.
     * 도플러 효과의 이해: 도플러 효과는 물체의 속도와 방향을 측정하는 데 유용함. 이를 통해 교통 관리나 스포츠 분석 등 다양한 응용 분야에서 활용 가능함.
     * 환경 소음 문제: 초음파 톤이 사람들에게 불편함을 줄 수 있음. 특히, 일부 사람들은 높은 주파수 소리를 들을 수 있어 환경 소음 문제를 일으킬 수 있음.
     * 기술적 도전 과제: 초음파 시스템의 정확성과 신뢰성을 높이기 위해서는 기술적 도전 과제가 많음. 예를 들어, 다양한 환경 조건에서의 성능 최적화가 필요함.
     * 경쟁 기술: 비슷한 기능을 제공하는 다른 기술들도 존재함. 예를 들어, LiDAR나 레이더 기술은 초음파와 유사한 용도로 사용될 수 있음.

        Hacker News 의견

     * FM 라디오 송신기: FM 라디오 송신기는 스테레오 방송을 나타내기 위해 19 KHz 파일럿 톤을 지속적으로 방송함. 스테레오 정보는 38 KHz AM 변조 캐리어에 포함됨. 약한 FM 신호에서는 모노로 설정하는 것이 더 나을 수 있음.
     * 어린 시절 경험: 4-6세 때 백화점에서 높은 음조를 들었던 기억이 있음. 이 기사는 주파수를 측정하고 시스템의 정상 작동 기능임을 설명함.
     * 클래스-D 앰프 가설: 클래스-D 앰프에서 발생하는 노이즈일 가능성을 제기함. 이러한 앰프는 MHz 주파수에서 스위칭하지만, 필터링되지 않은 하모닉스가 있을 수 있음.
     * 일본의 고주파 소음: 도쿄 거주자가 주거 지역에서 고주파 소음을 경험함. 이 소음이 해충이나 야생 동물을 대상으로 하는지 궁금해하며, 소음 측정을 시작할지 고민 중임.
     * PA 시스템 제조업체: PA 시스템 제조업체에서 일하는 사람의 경험. 앰프가 몇 분마다 주기적으로 테스트를 수행하며, 스피커 회로의 전류를 측정해 이상 여부를 확인함.
     * 나쁜 믹싱의 노래: 고음의 소음이 섞인 나쁜 믹싱의 노래를 들어본 경험. 스튜디오 장비에서 의도적으로 테스트 소음을 내는 것은 아니라고 생각함.
     * 모기 장치: 2000년대 후반과 2010년대 초반에 청소년을 쫓아내기 위해 사용된 ""모기"" 장치를 기억함. 이 장치는 비싸고, 소음 때문에 파손된 사례도 있음.
     * 광고 전달: 인터넷에 광고 전달 방법을 쓰지 말라는 의견.
     * 동물에 대한 영향: 개와 같은 동물이 인간보다 더 잘 들을 수 있기 때문에, 이러한 소음이 동물에게 해로울 수 있다는 언급이 없음.
     * 제품 설명: 고주파 톤이 케이블의 연속성을 확인하기 위해 전기적으로 수신됨. 이 톤은 트위터에 의해 감쇠되어야 하며, 비상 방송 시 PA 시스템이 제대로 작동하는지 확인하기 위한 것임. <20Khz 신호의 존재는 앰프나 필터가 테스트 톤을 제대로 수신하지 못해 임시 방편으로 추가된 것임을 의미함.
"
"https://news.hada.io/topic?id=15269","Cones are MESSED UP - 원뿔은 직관적이지 않다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Cones are MESSED UP - 원뿔은 직관적이지 않다

     * 원뿔은 우리의 기대와 직관을 거스를 수 있는 비직관적인 특성을 가지고 있습니다.
     * 높이 기준으로 2/3가 꽉 찬 원뿔을 거꾸로 뒤집었을 때 거의 완전히 꽉 찬 것처럼(99%) 보이는 현상을 보여줍니다.
     * 원뿔의 이러한 비직관적인 동작은 부피와 높이가 비선형적으로 스케일링되기 때문입니다.
     * 원뿔의 부피가 절반만 가득 찬 경우에도 동일한 효과가 발생하며, 거꾸로 뒤집어도 여전히 96% 가득 찬 것처럼 보입니다.

   와 신기하다

   오 신기하네요
"
"https://news.hada.io/topic?id=15311","Swift Static Linux SDK","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Swift Static Linux SDK

     * Swift는 Apple 플랫폼 외에도 Linux와 Windows 등을 지원함
     * Swift Static Linux SDK를 사용하면 외부 의존성 없이 완전히 정적으로 링크된 실행 파일을 빌드할 수 있음
          + 이는 모든 Linux 배포판에서 실행 가능함
          + macOS에서 개발하고 테스트한 후 Linux 기반 서버에 배포할 수 있음
     * 링킹은 컴퓨터 프로그램의 다른 부분을 가져와 참조를 연결하는 과정
          + 정적 링킹은 빌드 시점에, 동적 링킹은 런타임에 발생함
          + 정적 라이브러리는 개별 오브젝트 파일의 모음이고, 동적 라이브러리는 monolithic임
     * 정적 링킹의 장단점:
          + 장점: 런타임 오버헤드 없음, 필요한 라이브러리 코드만 포함, 별도 설치된 동적 라이브러리 불필요, 런타임 버전 문제 없음
          + 단점: 코드 공유 불가(메모리 사용량 증가), 프로그램 재빌드 없이 종속성 업데이트 불가, 실행 파일 크기 증가
     * Linux에서 정적 링킹을 사용하면 배포판에 따른 시스템 라이브러리 종속성을 완전히 제거할 수 있음
     * swift.org에서 Open Source 툴체인을 설치해야 함 (Xcode 제공 툴체인 사용 불가)
     * swift sdk install 명령으로 Static Linux SDK를 설치할 수 있음
     * swift build --swift-sdk x86_64-swift-linux-musl 명령으로 x86-64 Linux 바이너리를, swift build --swift-sdk aarch64-swift-linux-musl 명령으로 ARM64 Linux 바이너리를 빌드할 수 있음
     * Foundation이나 Swift NIO를 사용하는 Swift 패키지는 그대로 작동함
     * C 라이브러리를 사용하는 패키지는 Glibc 대신 Musl을 import하도록 수정해야 함
          + Musl은 정적 링킹을 잘 지원하고 실행 파일 배포가 용이한 permissive 라이선스를 가짐
     * swift package edit 명령으로 패키지 종속성을 수정할 수 있음

   이제 이걸 써서 좀 더 seamless하게 Swift로 Android iOS 동시 개발을 지원하는 뭔가가 나올듯한 느낌이 ..

        Hacker News 의견

     * Swift의 새로운 사용자 정의 플랫폼 지원: Swift가 임베디드 시스템과 WASM을 지원하며, 비-애플 GitHub 조직으로 이동한 것은 Swift를 다른 플랫폼으로 확장하는 데 큰 진전임. AI OS 보안 검증에도 사용될 가능성이 흥미로움.
     * Swift 바이너리를 Alpine 컨테이너에서 실행 가능: Swift 바이너리를 Alpine 컨테이너에서 실행할 수 있게 되어 기쁨. musl 지원 작업이 예상보다 빨리 진행됨. 교차 컴파일도 매우 유용함.
     * Debian 지원에 대한 기대: Debian에서 Swift 패키지가 추가되는 것을 보게 되어 기쁨. 개발 VM으로 Debian을 더 많이 사용하게 될 것 같음.
     * 임베디드 시스템에서 Swift 사용 기대: C로 임베디드 시스템을 많이 다뤘지만, STM 개발 보드에서 Swift를 시도해보고 싶음.
     * 정적 링크의 단점: ASLR이 제대로 작동하지 않거나 하나의 객체만 무작위화됨. 메모리 안전 언어에서는 큰 단점이 아닐 수 있음. 공통 객체를 공유하면 I/O 감소 효과가 있음.
     * 배포판 간의 호환성 문제: 특정 배포판이나 버전에서 빌드된 프로그램이 다른 배포판에서 작동하지 않을 수 있음. Swift의 정적 링크 제공은 좋지만, 배포판이 패키지 배포 방식을 선택할 수 있는 것이 최선임.
     * Golang과의 경쟁 가능성: Swift가 배포의 용이성 면에서 Golang과 경쟁할 수 있을 것 같음. 복잡성을 최종 사용자로부터 멀리 밀어냄.
     * 크로스 플랫폼 GUI 앱: Swift로 크로스 플랫폼 GUI 앱을 만들면 어떨지 궁금함. SwiftUI는 사용 불가할 것 같지만, Swift를 간단한 스크립트 작성에 사용할 예정임.
     * CentOS 7 이미지 사용 경고: CentOS 7 이미지를 아직도 제공하는 것이 미친 짓 같음. 사용하지 말라는 경고.
     * Swift의 복잡성 증가: Swift가 쉽게 Python을 대체할 수 있었지만, 언어가 복잡해져서 이제는 C++의 아류가 됨.
     * Rust 대신 Swift 사용 이유: 왜 Rust 대신 Swift를 사용해야 하는지에 대한 질문.
     * iOS/SwiftUI 없이 Swift 사용 이유: iOS/SwiftUI 없이 Swift를 사용할 이유가 있는지에 대한 질문. Swift 개발자가 작은 프로젝트에 익숙한 언어를 사용하고 싶을 때 외에는 이유가 없을 것 같음.
"
"https://news.hada.io/topic?id=15313","Revideo – 코드로 동영상을 제작하는 오픈소스 프레임워크 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Revideo – 코드로 동영상을 제작하는 오픈소스 프레임워크

     * 프로그래밍 방식으로 비디오 편집을 할 수 있는 오픈 소스 프레임워크
     * Motion Canvas 에디터에서 포크되어 독립형 애플리케이션에서 개발자가 전체 비디오 편집 앱을 구축할 수 있는 라이브러리로 변환한 것

  주요 기능

     * 비디오 템플릿 생성: Typescript로 비디오 템플릿을 만들고, 동적 입력값으로 렌더링할 수 있는 API 엔드포인트를 배포할 수 있음
     * 실시간 미리보기: React 플레이어 컴포넌트를 제공하여 브라우저에서 실시간으로 변경 사항을 미리 볼 수 있음

  Revideo와 Motion Canvas의 차이점

     * 헤드리스 렌더링: Motion Canvas는 UI에서 버튼을 눌러야 비디오를 렌더링할 수 있지만, Revideo는 함수 호출로 이 기능을 노출하고 Google Cloud Run 같은 서비스에 렌더링 API를 배포할 수 있음.
     * 빠른 렌더링: 병렬 렌더링을 활성화하고 HTML 비디오의 seek() 작업을 ffmpeg 기반 비디오 프레임 추출기로 대체하여 렌더링 속도를 향상시킴.
     * 향상된 오디오 지원: 렌더링 중 태그에서 오디오를 내보낼 수 있으며, 애니메이션과 오디오를 쉽게 동기화할 수 있는 태그를 추가함.

GN⁺의 의견

     * Revideo의 장점: 프로그램 방식으로 비디오 편집을 할 수 있어 개발자에게 매우 유용함. 특히, Typescript와 React를 사용하여 비디오 템플릿을 만들고 실시간으로 미리볼 수 있는 기능이 매력적임.
     * 병렬 렌더링: Google Cloud Functions를 사용한 병렬 렌더링 예제는 대규모 비디오 렌더링 작업에 큰 도움이 될 수 있음.
     * 오디오 지원: 애니메이션과 오디오를 쉽게 동기화할 수 있는 기능은 비디오 제작에 있어 큰 장점임.
     * 텔레메트리: 익명으로 데이터를 수집하여 사용자 경험을 개선할 수 있는 점은 긍정적임. 다만, 사용자가 이를 비활성화할 수 있는 옵션을 제공하는 것도 중요함.
     * 경쟁 제품: 비슷한 기능을 제공하는 다른 오픈 소스 프로젝트나 상용 제품과 비교해보는 것도 좋음. 예를 들어, Adobe Premiere Pro나 Final Cut Pro와 같은 상용 소프트웨어와의 차별점을 명확히 하는 것이 필요함.

        Hacker News 의견

     * Jacob (aarthificial, motion-canvas 창작자)에 대한 의견: MIT 라이선스라 자유롭게 사용 가능하지만, Jacob과 좋은 관계를 유지하는 것이 예의일 것 같음.
     * LangChain과 AI 비디오: LangChain이 자연어 처리에서는 불필요한 추상화처럼 보였지만, AI 비디오에서는 다양한 추상화(이미지, 퍼펫팅, 얼굴 생성, 음성 생성 등)를 처리해야 하므로 유용할 수 있음.
     * 비디오 인코딩 방법: MP4로 인코딩하는 방법에 대한 질문. Ffmpeg with wasm 또는 WebCodecs 사용 여부. 순수 클라이언트 측 인코더의 속도, 경량성, 품질 문제에 대한 고민.
     * 개발자들이 사용할 가능성 있는 사용 사례: 인포그래픽 자동 생성 및 애니메이션, 배경음 생성, 비디오 컷팅 및 재활용 등 다양한 추상화 가능성. 비디오 인프라의 첫 번째 구축 부분과 향후 발전 방향에 대한 질문.
     * 텍스트 리사이징 문제: 텍스트 리사이징 시 픽셀 스내핑 비활성화 권장. 비슷한 스타일의 실험을 했으나 작은 사이드 프로젝트로 유지하기 어려워 데모만 공개.
     * FOSS와 소스-가용성의 차이: Remotion이 FOSS가 아닌 이유에 대한 간단한 설명 요청. FOSS와 소스-가용성의 차이점 설명 필요.
     * 런칭 축하 및 Sieve 소개: 런칭 축하와 함께 Sieve에서 AI와 비디오 관련 작업을 하고 있으며, 새로운 프로젝트에 대한 기대감 표명.
     * 캔버스와 비디오에 대한 관심: 캔버스 라이브러리 개발자로서 Motion Canvas 선택 이유에 대한 질문. 반응형, 인터랙티브, 접근 가능한 비디오 디스플레이에 대한 관심과 Revideo의 발전 방향에 대한 질문.
     * AI 도구에 대한 의구심: 많은 AI 도구들이 세부 사항에 대한 세밀한 제어가 어렵다는 점에 대한 의구심 표명.
     * Haven.run 창립자에 대한 질문: Haven.run 창립자인지 여부와 LinkedIn 회사 페이지가 Revideo로 리디렉션되는 이유에 대한 질문. 피벗 스토리에 대한 관심 표명.
"
"https://news.hada.io/topic?id=15190","YC의 워싱턴 DC 방문 이유","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            YC의 워싱턴 DC 방문 이유

왜 YC가 워싱턴 DC에 갔는가

  주요 내용

     * 대형 기술 기업의 영향력: 대형 기술 기업들이 오랫동안 거의 감시 없이 운영되어 왔음. 이는 소셜 미디어의 해악, 반경쟁적 관행 등 여러 문제를 야기함.
     * 정책 입안자와의 만남: YC는 정책 입안자들과 만나 오픈 소스 AI, 이민을 통한 인재 접근, 반독점 조치를 통한 시장 접근, 비경쟁 조항의 제거 등의 중요성을 논의함.
     * 스타트업의 중요성: AI의 혜택이 널리 퍼지고 미국의 기술 리더십이 지속되기 위해서는 수많은 스타트업의 목소리가 필요함.
     * 오픈 소스 AI 모델: 오픈 소스 AI 모델은 투명성, 협업, 혁신을 촉진함. 반면, 대형 기술 기업이 선호하는 폐쇄형 모델은 경쟁을 제한하고 권력을 집중시킴.
     * 경쟁 촉진: 시장에서의 경쟁을 촉진하고 새로운 진입자가 보복 없이 진입할 수 있도록 강력한 조치가 필요함. 대형 기업의 상호 운용성을 강제하고 자기 선호를 억제하는 조치가 필요함.
     * 비경쟁 조항 금지: FTC의 최근 비경쟁 조항 금지 조치와 같은 정책이 창업자들이 강력한 신생 기업을 구축하고 현 상태를 혁신하는 데 도움을 줌.

  GN⁺의 의견

     * 스타트업의 역할: 스타트업은 혁신의 원동력으로, 다양한 문제를 해결할 수 있는 창의적인 솔루션을 제공함. 이들의 성장을 지원하는 정책이 필요함.
     * 오픈 소스의 장점과 단점: 오픈 소스는 투명성과 협업을 촉진하지만, 보안 문제도 고려해야 함. 적절한 균형이 필요함.
     * 비경쟁 조항의 영향: 비경쟁 조항의 제거는 인재 이동을 촉진하고, 더 많은 혁신을 가능하게 함. 그러나 기업의 입장에서는 인재 유출의 위험이 있음.
     * 정책의 중요성: 기술 정책은 국가의 경쟁력을 좌우할 수 있음. 스타트업의 목소리를 반영한 균형 잡힌 정책이 필요함.
     * 기술 생태계의 다양성: 다양한 규모의 기업이 공존하는 기술 생태계가 건강함. 대형 기업과 스타트업이 함께 성장할 수 있는 환경 조성이 중요함.

        Hacker News 의견

     * 소프트웨어 R&D 감가상각: 가상의 이익에 대한 세금 문제 해결 필요성.
     * 특허법: 특허 괴물로부터 소규모 사업 보호 필요성.
     * 정부 주도 준수 기준 자동화: 소규모 사업이 대기업/정부 기관에 판매할 수 있도록 자동 인증 필요성.
     * 건강 보험: 소규모 사업 직원들이 자동으로 메디케어에 접근할 수 있게 해야 함.
     * Jack Clark의 에세이: 정부에 권한을 부여하면 되돌리기 어렵다는 역사적 교훈.
     * 오픈 소스 모델 우선: 경쟁 환경을 조성하고 스타트업에 기회를 제공해야 함.
     * 정치에서 돈을 빼야 함: 장기적으로 정치 자금 문제 해결 필요성.
     * 긍정적 반응: GenAI가 또 다른 기술 독점이 되지 않도록 하는 것이 중요함.
     * AI의 잠재적 위험 인식: Paul G와 Sam Altman이 AI의 잠재적 위험을 인식하고 있음.
     * AI 관련 스타트업: 2024년에 VC 자금을 받으려면 AI와 관련된 스타트업이어야 함.
     * 오픈 소스 AI 모델: 투명성, 협업, 혁신을 위해 오픈 소스 훈련 과정과 데이터가 필요함.
     * AI 스타트업의 장애물: 적절한 하드웨어와 전기 비용이 큰 장애물임.
     * 클라우드 사용: 클라우드 사용이 쉬운 방법이지만 비용이 많이 들고 경쟁사에게 비용을 지불하는 문제 있음.
     * 로비 활동: 모두가 로비 활동을 하는 이유와 같음.
"
"https://news.hada.io/topic?id=15283","애플의 새로운 온디바이스 및 서버 기반 파운데이션 모델 소개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   애플의 새로운 온디바이스 및 서버 기반 파운데이션 모델 소개

     * 2024년 WWDC에서 iOS 18, iPadOS 18, macOS Sequoia에 깊이 통합된 퍼스널 인텔리전스 시스템인 Apple Intelligence를 발표함
     * Apple Intelligence는 사용자의 일상 작업에 특화된 다수의 생성 모델로 구성되며, 현재 활동에 맞게 즉각 적응 가능함
     * 내장된 파운데이션 모델은 문서 작성/개선, 알림 요약/우선순위화, 대화용 재미있는 이미지 생성, 앱 간 상호작용 간소화 등의 사용자 경험을 위해 파인튜닝됨
     * 2개의 모델 - 약 30억 개 파라미터의 온디바이스 언어 모델, Private Cloud Compute를 통해 제공되는 더 큰 서버 기반 언어 모델 - 이 효율적이고 정확하며 책임감 있게 특화 작업을 수행하도록 구축/적용됨
     * 이들은 Xcode에 인텔리전스를 구축하기 위한 코딩 모델, Messages 앱에서 시각적 표현을 돕는 디퓨전 모델 등을 포함한 더 큰 애플 제작 생성 모델군의 일부임

    책임감 있는 AI 개발에 초점 맞춤

     * Apple Intelligence는 모든 단계에서 핵심 가치에 맞게 설계되고 획기적인 프라이버시 혁신을 기반으로 구축됨
     * 애플은 AI 툴과 툴의 기반이 되는 모델 개발 방식을 안내하는 책임감 있는 AI 원칙을 수립함:
         1. 지적인 툴로 사용자에게 힘을 실어줌
         2. 사용자를 대표함
         3. 신중하게 설계함
         4. 프라이버시 보호
     * 이 원칙은 Apple Intelligence를 가능케 하는 아키텍처 전반에 반영되어 있음

    Pre-Training

     * 파운데이션 모델은 2023년에 오픈소스로 공개한 애플의 AXLearn 프레임워크로 훈련됨
     * JAX와 XLA 위에 구축되어 다양한 하드웨어와 클라우드 플랫폼에서 효율적이고 확장성 있는 훈련이 가능함
     * 데이터, 모델, 시퀀스 길이 등 다양한 차원으로 훈련 스케일링이 가능한 병렬화 기술 조합 사용
     * 라이선스 데이터와 공개 데이터로 모델 훈련. 웹 퍼블리셔는 데이터 사용 제어로 Apple Intelligence 훈련에서 웹 컨텐츠 사용 옵트아웃 가능
     * 사용자의 개인 데이터나 상호작용은 절대 사용하지 않음. PII 제거 필터링, 저품질 컨텐츠 필터링, 고품질 문서 식별을 위한 모델 기반 분류기 적용

    Post-Training

     * 데이터 품질이 모델 성공에 필수적임을 확인하여, 하이브리드 데이터 전략 활용
     * 교사 위원회를 통한 거부 샘플링 파인튜닝 알고리즘과 미러 디센트 정책 최적화 및 leave-one-out 이점 추정기를 사용하는 RLHF 알고리즘 개발
     * 이 두 알고리즘으로 모델의 지시 따르기 품질 상당히 개선됨

    Optimization

     * 고성능 생성 모델 개발 외에도 온디바이스 및 프라이빗 클라우드에서 속도와 효율성을 최적화하기 위해 다양한 혁신적 기술 적용
     * 온디바이스 모델과 서버 모델 모두 그룹화된 쿼리 어텐션 사용
     * 메모리 요구 사항과 추론 비용 절감을 위해 공유 입력 및 출력 어휘 임베딩 테이블 사용
     * 온디바이스 모델은 49K 어휘 크기 사용, 서버 모델은 추가 언어 및 기술 토큰을 포함하여 100K 어휘 크기 사용
     * 온디바이스 추론을 위해 저비트 팔레타이제이션 사용 - 압축되지 않은 모델과 동일한 정확도를 얻기 위해 혼합 2비트 및 4비트 구성 전략(평균 3.5비트 가중치당)을 통합하는 새로운 LoRA 어댑터 프레임워크 개발
     * Talaria 도구를 사용하여 각 작업에 대한 비트율 선택을 더 잘 안내함
     * 활성화 및 임베딩 양자화 활용, 효율적인 KV 캐시 업데이트 방식 개발
     * 이 최적화 세트로 iPhone 15 Pro에서 프롬프트 토큰당 약 0.6ms의 time-to-first-token 지연시간과 초당 30 토큰의 생성 속도 달성

    Model Adaptation

     * 파운데이션 모델은 사용자의 일상 활동을 위해 파인튜닝되며, 수행 중인 작업에 맞게 동적으로 자체 전문화 가능
     * 특정 작업을 위해 모델을 파인튜닝하기 위해 사전 훈련된 모델의 다양한 계층에 연결할 수 있는 작은 신경망 모듈인 어댑터 활용
     * 어댑터 계층만 파인튜닝하여 기본 사전 훈련 모델의 원래 매개변수는 변경되지 않고 일반 지식은 보존되면서 특정 작업 지원을 위해 어댑터 계층이 맞춤 설정됨

    Performance and Evaluation

     * 사용자가 애플 제품 전반에 걸쳐 커뮤니케이션하고 작업하며 자신을 표현하고 일을 처리할 수 있게 해주는 생성 모델 제공에 초점을 맞춤
     * 모델 벤치마킹 시 사용자 경험과 상관관계가 높은 것으로 나타난 인간 평가에 초점을 맞춤
     * 기능별 어댑터와 파운데이션 모델 모두에 대해 성능 평가 수행

   요약 어댑터 평가 사례:
     * 이메일 및 알림 요약에 대한 제품 요구 사항이 미묘하지만 중요한 방식으로 다르기 때문에, 이러한 특정 요구 사항을 충족하기 위해 LoRA 어댑터를 팔레타이징된 모델 위에 파인튜닝함
     * 훈련 데이터는 고품질 요약만 유지하는 거부 샘플링 전략으로 필터링된 더 큰 서버 모델에서 생성된 합성 요약을 기반으로 함
     * 사용 사례별로 신중하게 샘플링된 750개 응답 세트를 사용하여 제품별 요약 평가
     * 평가 데이터 세트는 제품 기능이 프로덕션에서 직면할 가능성이 높은 다양한 입력을 강조하며, 다양한 콘텐츠 유형과 길이의 단일 및 적층 문서의 계층화된 혼합을 포함
     * 제품 기능으로서 실제 사용 사례를 대표하는 데이터 세트에 대해 성능을 평가하는 것이 중요함
     * 어댑터가 있는 모델이 비교 가능한 모델보다 더 나은 요약을 생성한다는 것을 발견

    Human Satisfaction Score on Summarization Feature Benchmark

     * 데이터 표에 따르면 애플 온디바이스+어댑터 모델이 이메일과 알림 요약에서 Phi-3-mini 모델보다 더 높은 만족 좋음 비율과 더 낮은 만족 나쁨 비율을 보임. 어댑터가 있는 모델이 더 나은 요약을 생성함.
     * 애플의 온디바이스 및 서버 모델은 다양한 난이도의 실제 프롬프트로 구성된 종합 평가 세트를 사용해 일반적인 기능을 평가함. 이를 비슷한 크기의 오픈소스 및 상용 모델과 비교한 결과:
          + 온디바이스 모델(~30억 매개변수)이 Phi-3-mini, Mistral-7B, Gemma-7B 등 더 큰 모델보다 우수한 성능을 보임
          + 서버 모델은 DBRX-Instruct, Mixtral-8x22B, GPT-3.5-Turbo와 견줄만하면서도 매우 효율적임
     * 유해 콘텐츠, 민감한 주제, 사실성 측면에서 모델 성능을 테스트하기 위해 다양한 적대적 프롬프트 세트를 사용함. 온디바이스 및 서버 모델 모두 적대적 프롬프트에 직면했을 때 견고하며 오픈소스 및 상용 모델보다 낮은 위반율을 달성함.
     * IFEval 벤치마크를 사용해 비슷한 크기의 모델과 지시 따르기 능력을 비교한 결과, 애플 온디바이스 및 서버 모델이 동급 오픈소스 및 상용 모델보다 자세한 지침을 더 잘 따르는 것으로 나타남.
     * 다양한 작문 지침으로 구성된 내부 요약 및 작문 벤치마크에서 모델의 작문 능력도 평가함.

    Writing Benchmarks

     * 데이터 표에 따르면 요약과 작문에서 애플 온디바이스 및 서버 모델이 비교 대상 모델들과 견줄만한 좋은 성능을 보임.

    결론

     * WWDC24에서 소개된 애플 파운데이션 모델과 어댑터는 iPhone, iPad, Mac에 깊이 통합되어 언어, 이미지, 동작, 개인 컨텍스트에 걸쳐 강력한 기능을 제공하는 새로운 퍼스널 인텔리전스 시스템인 Apple Intelligence의 기반이 됨
     * 애플 제품 전반에 걸쳐 사용자가 일상 활동을 수행하는 데 도움을 주기 위한 목적으로 만들어졌으며, 모든 단계에서 책임감 있게 개발되었고 애플의 핵심 가치에 의해 이끌어짐
     * 언어, 디퓨전, 코딩 모델을 포함한 더 광범위한 생성 모델 제품군에 대한 정보를 곧 공유할 예정

        Hacker News 의견

     * Adapter 활용: 사전 학습된 모델에 다양한 레이어에 플러그인할 수 있는 작은 신경망 모듈인 어댑터를 사용하여 특정 작업에 맞게 모델을 미세 조정함. 이는 앱 개발자가 각 하드웨어 모델에 최적화된 모델을 사용할 수 있게 해줌.
     * 기대감: 아직 서드 파티 훈련 지원에 대한 발표는 없지만, 계획 중일 것이라 기대함. 로컬+프라이빗 ML의 어려움은 앱마다 큰 용량의 가중치를 필요로 하지 않도록 하는 것임.
     * 애플의 기회: 애플이 각 칩에 맞게 최적화된 모델을 제공하고, 새로운 사용 사례에 대해 몇 MB의 가중치만 필요로 하는 어댑터를 제공할 수 있는 기회가 있음. 이는 모델의 앱 슬리밍과 유사함.
     * 개발자 경험: 기본 모델이 최신 상태가 아니더라도 개발자 경험이 훌륭하고 반복 가능함. 서버 측은 훨씬 쉬우며, 로컬+프라이빗이 많은 사용 사례를 차지할 것으로 기대함.
     * 어댑터의 역할: 어댑터를 사용하여 모델을 특정 작업에 맞게 미세 조정하고, 메모리를 효율적으로 관리하며 운영 체제의 응답성을 보장함. 어댑터 매개변수는 16비트로 표현되며, 약 3억 개의 매개변수를 가진 모델의 경우 10MB 정도의 메모리가 필요함.
     * Loras와 유사: 이 접근 방식이 Loras와 유사하게 들림.
     * 비교 차트: 기사 중간에 다른 관련 모델과의 비교 차트가 포함되어 있음. 서버 측 모델은 GPT-3.5보다 좋고, GPT-4보다는 나쁨. 그러나 ""출력 유해성의 인간 평가"" 차트가 특히 흥미로움.
     * 모델의 신중함: GPT를 ""레벨 3""으로 만들고, OpenAI의 모델을 사용하여 ""이것은 ChatGPT가 말한 것""임을 명확히 하는 방식으로 모델을 더 신중하게 만듦.
     * 서버 모델 사용 기대: 이 두 페이지의 내용이 매우 훌륭하며, 애플 스택에 최적화된 클라우드를 구축하기 위해 서버 모델을 사용해 보고 싶음.
     * 메모리 증가 기대: 애플이 모든 맥의 기본 메모리를 8GB 이상으로 높일 것이라 기대함. 16GB M4가 기본이 되길 바라지만, 애플은 12GB를 제공하고 16GB 옵션에 추가 비용을 부과할 가능성이 있음.
     * 데이터 프라이버시: 애플이 제3자 서비스에 무엇을 전달하는지 명확히 하고, 사용자가 원할 경우 옵트아웃할 수 있는 기능을 제공해야 함. 기기에서 추론을 실행하는 것과 데이터를 OpenAI의 API를 통해 보내는 것은 다름.
     * 도메인 이름 선호: machinelearning.apple.com을 사용하는 것이 마음에 듦.
     * 최적화 결과: 3.5B 가중치를 품질 손실 없이 사용하는 것은 최첨단 최적화 결과임.
     * 출력 유해성 평가: Mistral-7B가 작은 모델 중에서 거짓 긍정 거부를 최소화하는 데 가장 우수함을 확인함.
     * 배터리 수명 영향: 이러한 모델이 배터리 수명에 어떤 영향을 미치는지 궁금함. iPhone 15 Pro에서 PrivateLLM 앱을 사용해 본 결과, 몇 분 사용 후 배터리 충전이 급격히 감소함.
"
"https://news.hada.io/topic?id=15209","HN에 공개: Foosbar – 자율형 탁구 로봇","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      HN에 공개: Foosbar – 자율형 탁구 로봇

Foosbar: 세계 최고의 로봇 풋볼 테이블

  소개

     * Foosbar는 자동화된 풋볼 테이블로, 한쪽은 로봇이, 다른 쪽은 사람이 플레이하는 구조임.
     * 로봇은 수비, 패스, 슛을 할 수 있으며, 이를 통해 사용자는 더 중요한 일에 집중할 수 있게 됨.

  설정

    구성 요소

     * 프로젝트는 software, firmware, frontend 세 가지 주요 구성 요소로 나뉨.
          + software: 모터를 직접 제어하는 코드가 포함된 디렉토리.
          + frontend: 원격 게임 컨트롤러를 통해 테이블을 제어할 수 있는 3D 웹앱.
          + firmware: 초기에는 전자 장치에 연결된 e-paper 디스플레이에 점수를 표시하기 위한 Teensy 4.1용이었으나, 현재는 사용되지 않음.

    software

     * uWebSockets를 빌드하고 cmake에서 찾을 수 있도록 설정해야 함.
     * qualisys realtime sdk도 비슷한 방식으로 설치해야 함.
     * 설치 후 빌드 과정:
cd software
mkdir build && cd build
cmake ..
make
./foosbar

    firmware

     * 표준 pio 프로젝트로, 다음 명령어로 업로드 가능:
cd firmware
pio run -t upload

    frontend

     * 다음 명령어로 실행 가능:
cd frontend
npx vite

GN⁺의 의견

     * 자동화의 장점: 반복적인 작업을 자동화함으로써 사용자는 더 중요한 일에 집중할 수 있게 됨.
     * 기술적 도전: cmake와 같은 도구를 사용하는 것은 초급 엔지니어에게는 어려울 수 있음. 이를 통해 기술적 성장을 도모할 수 있음.
     * 오픈소스의 가치: 프로젝트의 구성 요소와 설정 방법을 공개함으로써 다른 개발자들이 유사한 프로젝트를 시도할 수 있게 함.
     * 기술적 한계: firmware 부분이 완전히 구현되지 않았다는 점에서 프로젝트의 완성도가 떨어질 수 있음.
     * 흥미로운 프로젝트: 로봇이 사람과 함께 게임을 할 수 있다는 점에서 기술적 흥미를 유발함.

        Hacker News 의견

     * 로봇 제어를 통한 온라인 테이블 축구 대회: 양쪽 테이블을 로봇으로 제어하고 최고의 AI를 겨루는 온라인 대회를 열자는 의견.
     * 자동 점수 추적 시스템: 과거에 자동 점수 추적 시스템을 구축했던 경험을 떠올리며, 이 프로젝트가 그리움을 자아낸다는 의견.
     * 중간 예산 접근법: 비싼 산업용 모션 캡처 카메라 대신 저렴한 글로벌 셔터 카메라를 사용한 접근법이 궁금하다는 의견.
     * 새로운 CNC 프로젝트: 3D 프린터나 CNC 밀링 머신 같은 기존 프로젝트와 달리 새로운 아이디어라서 좋다는 의견.
     * 해커 뉴스의 재미있는 프로젝트: 이 프로젝트가 해커 뉴스에서 인기를 끌 만한 재미있는 프로젝트라는 의견.
     * 제품화 가능성: 이 프로젝트가 제품으로 발전할 가능성이 있으며, 많은 사람들이 좋아할 것이라는 의견.
     * 미래가 밝은 개발자: 이 프로젝트를 만든 개발자의 미래가 밝다는 의견.
     * 게임의 기쁨을 기계화: 게임의 기쁨을 기계화하여 더 중요한 일에 집중할 수 있게 되었다는 의견.
     * 가정용 연습용 로봇: 가정에서 연습용으로 사용하고 싶다는 의견과 로봇이 상대방을 놀리는 기능이 추가되면 좋겠다는 의견.
     * 골키퍼 포지션: 골키퍼 포지션에 항상 세 명의 플레이어가 있는지 궁금하다는 의견.
"
"https://news.hada.io/topic?id=15216","로마 도로 (2017)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              로마 도로 (2017)

로마 도로

  주요 로마 도로 지도 완성

     * 로마 제국의 주요 도로를 지하철 스타일로 표현한 지도 완성
     * 연구에 많은 시간이 소요됨
     * 주요 참고 자료: Stanford의 ORBIS 모델, The Pelagios Project, Antonine Itinerary

  여행 시간

     * 여행 시간은 교통 수단과 계절에 따라 다름
     * 여름에 로마에서 비잔티움까지 도보로 약 두 달, 말 타고 한 달 소요
     * 말과 배를 이용하면 로마에서 비잔티움까지 약 25일, 로마에서 카르타고까지 4-5일 소요
     * 해상 경로는 지도에 포함하지 않음

  창의적 요소

     * 포함할 도로와 도시 선택에 창의적 요소 사용
     * 인구가 많은 도시나 2세기 주도 도시 포함
     * 철도와 도로 여행 방식의 차이로 인해 지도 개념에 약간의 결함 존재

  실제 이름과 경로를 가진 도로

     * Via Appia, Via Augusta, Via Aurelia 등 주요 도로 포함

  수정된 도로 이름

     * Via Latina와 Via Popilia 결합
     * Via Aquitania, Via Asturica Burdigalam 등 일부 도로 이름 수정

  창의적으로 만든 도로 이름

     * 실제 이름이 없는 도로에 창의적 이름 부여

  업데이트

     * 여러 피드백 반영하여 지도 업데이트
     * 주요 변경 사항:
          + Gesoriacum 오타 수정
          + Via Agrippa 올바르게 명명
          + Berytus(현재 베이루트) 추가
          + Vindonissa 추가
          + 사르디니아 도로 수정
          + 도로 이름을 더 고전적인 이름으로 변경
          + 영국 도로망 확장

  중국어 버전

     * Stone Chen이 번역한 중국어 버전 제공

GN⁺의 의견

     * 역사적 가치: 로마 도로는 고대 로마의 교통과 무역의 중심이었음. 이 지도를 통해 당시의 교통망을 이해하는 데 큰 도움이 됨.
     * 교육적 활용: 이 지도는 역사 교육 자료로 유용함. 학생들이 고대 로마의 지리와 교통을 시각적으로 이해할 수 있음.
     * 기술적 도전: 지도를 제작하는 데 많은 연구와 데이터가 필요했음. 이는 데이터 시각화와 역사 연구의 융합을 보여줌.
     * 현대적 응용: Stanford의 ORBIS 모델처럼, 고대 지리 데이터를 현대 기술로 시각화하는 시도는 다른 역사적 연구에도 응용 가능함.
     * 비판적 시각: 도로와 철도의 여행 방식을 동일하게 표현한 점은 약간의 오류를 포함할 수 있음. 이를 보완하기 위한 추가 연구가 필요함.

        Hacker News 의견

     * Pretty cool: 부모님이 자란 작은 마을이 고대 도로인 비아 티부르티나(Via Tiburtina) 근처에 있었음. 1990년대에 부모님과 함께 이탈리아를 방문했을 때, 그 도로가 여전히 현대 도로로 존재함을 발견했음.
     * Funny thing is they did have something like this already: 고대 로마의 지도인 타불라 퓨팅게리아나(Tabula Peutingeriana)가 이미 존재했음을 언급함.
     * Much better resolution: 더 나은 해상도의 이미지를 제공하는 링크를 공유함.
     * Ulpiana - still relevant in Kosovo: 울피아나(Ulpiana)는 여전히 코소보에서 중요하며, 디라키움(Dyrrachium)은 현대 알바니아의 두러스(Durres), 리수스(Lissus)는 현대 알바니아의 레자(Lezha)임을 언급함.
     * The original creator's page: 원작자의 페이지를 공유하며, 더 자세하고 흥미로운 내용을 제공함.
     * I've been always fascinated by subway maps: 지하철 노선도에 대한 관심을 표현하며, 자동 생성된 스타일의 지하철 노선도가 있는지 궁금해함.
     * There's a series on Amazon Prime: 아마존 프라임에서 영국인이 로마 도로를 여행하며 역사를 탐방하는 시리즈가 있음을 언급함.
     * How can it take 2 months on foot: 도보로 2개월, 말로 1개월이 걸리는 이유에 대해 의문을 제기함. 말이 하루에 25-35마일을 이동할 수 있지만, 이는 인간이 하루에 이동할 수 있는 거리와 비슷하다고 설명함.
     * I don't know if ""Genava"" is the same as modern day Geneva CH: ""Genava""가 현대의 제네바와 동일한지 모르겠지만, 비엔나가 제네바의 서쪽에 있는 것은 지도의 오류일 수 있음을 지적함.
     * Cool visualization: 제목을 보고 ""로마로 가는 길"" 프로젝트를 떠올렸다고 언급하며, 관련 링크를 공유함.
"
"https://news.hada.io/topic?id=15270","여성이 자신의 Washer 컬렉션을 공유하기 위해 테이블을 마련, 판매는 없음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              여성이 자신의 Washer 컬렉션을 공유하기 위해 테이블을 마련, 판매는 없음

        Hacker News 의견

     * 세탁기 수집가와 부스 설치자의 교집합: 세탁기 수집가와 부스를 설치해 다른 사람들과 이야기하는 사람들의 교집합은 매우 작음.
     * CNC 가공 비디오: CNC 가공 비디오를 많이 보는데, 세탁기 컬렉션의 세부 사항을 설명하는 차분한 비디오 시리즈가 있다면 볼 것임.
     * 프랑스 트루아의 도구 박물관: 프랑스 트루아에 있는 도구 박물관이 생각남. 다양한 도구의 약간씩 다른 변형들로 가득 차 있음.
     * 깊고 좁은 관심사: 이런 것이 많은 기쁨을 줌. 그녀가 받을 만한 주목을 받길 바람. 깊고 좁은 관심사를 가진 사람들에게 매료됨.
     * 알래스카 해인즈의 망치 박물관: 알래스카 해인즈에 비슷한 분위기의 망치 박물관이 있음. 다양한 종류의 망치가 무수히 많음.
     * 세탁기 특성 토론: 물리적인 형태도 멋지지만, 그녀와 앉아서 각 세탁기의 특성과 용도에 대해 논의하고 싶음.
     * 스프링 와셔: 그녀가 스프링 와셔를 전시하지 않은 것이 놀라움. 스프링 와셔는 꽤 멋지게 보일 수 있음. 평범한 와셔는 금방 질릴 수 있음.
     * 세탁기 오해: 처음에는 세탁기 컬렉션인 줄 알았음.
     * 세탁기 관심: 정말 멋짐! 세탁기에 관심은 없지만, 그녀의 관심이 깊다면 흥미롭게 만들 수 있을 것 같음. 그녀와 대화하고 싶고, AMA(Ask Me Anything)를 해도 좋을 것 같음.
     * 세탁기 이해 부족: 솔직히 세탁기를 이해하지 못함. 중요하다고 들었고, 지시서에 따라 사용하지만, 왜 필요한지 모름. 다른 사람들이 더 직관적으로 이해하길 바람.
"
"https://news.hada.io/topic?id=15206","1인 개발자로서 동기 부여 관리하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1인 개발자로서 동기 부여 관리하기

     * 1인 개발자로서 가장 어려운 점 중 하나는 동기 부여를 유지하는 것
     * 개인적으로 동기 부여를 해킹하는 방법, 효과가 있는 것과 그렇지 않은 것에 대해 일기를 써왔는데 그 중 잘 동작한 것들을 소개

  외부 소스를 동기 부여로 전환하기

     * 외부 소스에서 동기를 얻는 시스템을 구축함
          + 예: 구독자가 생길 때마다 알림을 받는 시스템
     * 나는 푸시 알림을 싫어하지만, 이것들은 내 홈 화면에 바로 팝업됨
          + 매번 작은 동기 부여가 솟구침
          + 약간의 쾌락 트레드밀 효과가 있음. 처음에는 새로운 구독자 한 명이 엄청난 도파민/에너지의 충격이었고, 시간이 지나면서 그것이 줄어들었지만 여전히 나를 채워줌
     * 비슷한 맥락에서, 누군가 내 서비스(Chessbook)를 언급할 때마다 알려주는 서비스에 가입했음 ( Syften )
          + 소셜에서의 참여가 많은 도움이 될 수 있기 때문에 마케팅에도 동시에 유용하지만, 사람들이 내가 만든 것에 대해 (바라건대 긍정적으로) 이야기하는 것을 볼 때마다 동기 부여도 됨
     * 디스코드엔 #pump-up 채널도 있는데, 여기에는 달성한 마일스톤들의 피드가 있음
          + $X MRR, 2,000명의 디스코드 사용자, 6% 미만의 이탈률 등 동기 부여가 되는 것들

  작업을 미완성 상태로 남겨두기

     * 작업을 90% 정도 완료한 상태로 남겨두기
     * 작업을 마무리하는 것보다 약간 아쉬운 느낌이 들지만 다음 날 작업을 시작하기가 10배는 더 쉬워짐
     * 다음 날 시작할 때 빠르게 성취감을 얻을 수 있음
     * 단지 git 커밋만 실행하는 것 만으로는 충분하지 않음. 해야 할 일을 정확히 알고 있는 상황에서 5~10분 정도 걸리는 것이 가장 이상적

  내가 만든 제품을 최대한 많이 사용하기

     * 직접 사용하면서 문제점을 발견하고 즉시 수정함
     * 버그 리포트로 받은 것보다 직접 경험한 불편함이 훨씬 더 크게 느껴져서 바로 고치게 됨
     * 사람들이 원할 만한 것을 생각하는 것보다 내가 직접 원하는 것을 깨닫는 것이 훨씬 더 좋은 제품 아이디어를 줌

  고통을 해결하는 것이 고통을 견디는 것보다 나음

     * 항상 힘든 부분들이 있음. 코드베이스의 방치된 영역, 서드파티와의 거래, 네이티브 앱의 새 버전 출시 등. 작업의 일부로 이런 것들을 처리해야 한다는 걸 알면 시작하기가 훨씬 더 어려워질 수 있음
     * 좋은 방법은, 그 고통을 덜어주는 방법을 찾아서 덜 고통스럽게 만들 수 있다는 것임
          + 예를 들어, 최근에 4개 이상의 새 엔드포인트가 필요해서 새 작업을 시작하는 데 많이 힘들었음. 백엔드에서 타입을 작성하고, 프론트엔드에서 동일한 타입을 작성하고, 페이로드가 올바른지 확인하고, 경로가 올바른지 확인해야 했고, 아무것도 타입 검사를 하지 않아서 보통 처음에는 작동하지 않음
          + 그래서 시작하기 전에 RSPC라는 RPC 라이브러리를 찾았는데, 이것은 타입을 생성해주고 백엔드 함수를 작성하고 호출하는 것을 프론트엔드에서 다른 비동기 프론트엔드 함수를 호출하는 것만큼 쉽고 안전하게 만들어 줌
          + 이것은 고통을 제거할 뿐만 아니라 새로운 시스템을 사용하는 것에 대해 적극적으로 흥분하게 만들었음. 마찰의 원천을 동기 부여의 증폭제로 전환시킨 것임
     * 큰 회사에서 일했다면 일상적인 개발의 고통을 해결할 수 없어서 이것은 잊기 쉬움. 아마도 이런 것들을 해결하려고 하는 것이 무의미하다는 감각을 얻었을 것임. 마감일을 맞추거나, 사람들로부터 승인을 받거나, 시도하기 전에 기술 문서를 작성해야 함
          + 원하는 것은 무엇이든 고치고 개선할 수 있다는 것이 솔로 개발자가 되는 가장 큰 장점 중 하나이므로, 언제든 그것을 활용할 수 있다는 것을 상기시켜야 함

  아무것도 하지 않기

     * 트위터/유튜브/레딧등에 빠지는 일이 잦음
     * 여기에서 벗어나는 가장 좋은 방법은 두 단계로 하는 것
          + 먼저 Reddit 등에서 아무것도 하지 않는 상태로 가고, 그 다음 작업을 시작함
          + Reddit에서 바로 집중해서 일하는 것은 매우 어렵지만, 아무것도 하지 않는 것은 훨씬 쉬움
          + 결국 뇌가 진정되면 코드를 작성하기 시작하는 것이 그렇게 어렵게 느껴지지 않음
     * 정말로 아무것도 하지 않는 것을 의미함
          + 그냥 화면 앞에 몇 분 동안 앉아 있으면, 마치 마법처럼 소비에 휘말린 도파민 과잉 상태의 안개가 걷히고 다시 창작과 문제 해결에 흥분할 수 있게 됨
     * 그러면 뇌가 진정되고 다시 작업에 집중할 수 있게 됨

  사용자에게 업데이트 제공하기

     * 사용자에게 업데이트를 제공하면서 자신이 이룬 성과를 돌아봄
     * 월말에 성과를 기록하며 동기 부여를 얻음

  파트너 찾기

     * 제목과 모순되어 보일 수 있지만, 나는 단지 솔로 ""개발자""라고 말했을 뿐임
     * 제품/디자인/카피 등 모든 면에서 훨씬 뛰어난 파트너가 있음
     * 파트너가 있는 것의 모든 이점을 나열하지는 않겠지만, 이제 그들이 필수적이라고 믿음
          + 앞으로의 프로젝트에서는 문제에 대해 같은 생각을 가지면서도 나의 기술을 보완해줄 수 있는 파트너를 찾을 것임
          + 이는 밤낮의 차이임
     * 여기서 동기 부여 부분은 주로 책임감과 관련이 있음
          + 사람들이 헬스장 파트너를 두는 것과 같은 이유임. 그냥 당신이 나타나기를 기대하는 사람이 있다는 것 자체가 강력할 수 있음
          + 또한 주간 회의를 하는데 할 말이 없다는 것을 알게 된다면, 아마도 충분히 하지 않고 있는 것이고 이는 두드러진 알림임
     * 다른 부분은 당신의 동기와 파트너의 동기가 오르내릴 것이고, 그것이 같은 속도로 일어나지는 않을 것이라는 점임
          + 당신이 그렇지 않을 때, 여전히 프로젝트에 대해 동기 부여가 되어 있는 다른 사람이 있는 것이 매우 도움됨

  '제로 데이' 피하기

     * 아무것도 하지 않는 날이 있으면, ""제로 데이""를 보내고 있다는 잔존하는 죄책감이 있음
          + 이것은 내가 하고 있는 활동을 완전히 즐기는 것을 방해함
          + 내가 하고 있는 것을 즐길 수 있는 허락을 내 자신에게 주려고 노력해봤지만, 그냥 효과가 없음
          + 겉으로는 휴식을 취하고 재충전하는 것 같지만, 전혀 그렇게 느껴지지 않음. 그냥 견디는 것처럼 느껴짐
          + 이것은 부정적인 피드백 루프로 이어질 수 있음. 계속해서 재충전하려고 하지만, 그냥 더 피곤해질 뿐임
     * 발견한 유일한 방법은 먼저 좋은 작업을 하는 것임
          + 그러면 내가 뛰어드는 재미있는 태만한 활동에 완전히 몰두할 수 있음

  동기가 있을 때 사용하기

     * 때로는 문제에 대해 생각하면서 잠자리에 들 때가 있는데, 그때 해결책을 깨닫는 순간에 동기 부여가 됨
          + 적어두고 아침에 하는 것도 가능하지만, 대부분은 그냥 일어나서 새벽 4시까지 작업함
     * 이것도 솔로 개발자가 되는 것의 큰 장점 중 하나임
          + 오전 9시에 슬랙에서 대기할 필요가 없기 때문에 한밤중이라도 동기 부여가 찾아올 때 사용할 수 있음
     * 이것은 아마도 일반화되지는 않겠지만, 다시 말하지만 이것은 조언이라기보다는 블로그 포스트로 각색된 일기장 항목에 더 가까움
          + 나는 날씨에 상관없이 매일 9시부터 5시까지 일하도록 나 자신을 강요하는 것보다, 몰입 상태의 작업 기회를 극대화하려고 노력하는 좀 더 느슨한 접근 방식으로 항상 더 잘해왔음

   다양한 사이드 프로젝트에 대한 동기만 있고 실행은 잘 못하곤 하는데, 이런 방식을 적용 해 보아야겠네요.

   동기부여를 계속 해주는 게 정말 중요한 것 같습니다. 아무리 간단한 사이드 프로젝트라도 우선 내가 하고 싶게 계속 유지하는 게 필요하더라구요.

   누군가 내 서비스(Chessbook)를 언급할 때마다 알려주는 서비스가 뭘까요? 궁금하네요

   저도 뭐 쓰는지 궁금하네요, 비슷한 서비스들이 여러개 있을거 같긴한데.

   해커뉴스 댓글에서 해당글 저자가 https://syften.com/ 쓴다고 하네요.
   https://kwatch.io/ 같은 것도 있고요.

   오오 감사합니다!

   syften는 써보고 있는데 굉장히 좋네요.
   카드 등록 없이 무료 14일 쓰는데, 중간중간 Tip이 되는 메일도 생각보다 유용하고요

   외부소스 동기부여는 저도 사용하는데 아주 잘 동작합니다.
   긱뉴스의 신규 가입자, 슬랙봇 설치, 위클리 구독에 대해서 알림을 받고 있고, 특정 마일스톤에 도달할때마다 페이스북 등 통해서 얘기를 하는데 동기부여에 아주 유용하네요.

   사용자에게 업데이트 제공하기도 종종 해야하는데, 채널이 마땅하지 않네요 ㅎㅎ

   저도 그래요. 정말 초기엔 방문자도 webhook으로 slack에 연결해두고, 방문자가 늘어나면, 가입자, 가입자가 들어나면 구매자로 옮겨요.

        Hacker News 의견

     * 집중력과 동기부여 문제: 집중력과 동기부여에 어려움을 겪는 사람들은 그렇지 않은 사람들과 대화할 때 어려움을 겪음. 이는 뇌 화학과 관련이 있어 서로의 입장을 이해하기 어려움.
     * 미완성 작업: 실패한 테스트를 남겨두면 다음 날 바로 작업에 착수할 수 있어 시간 낭비를 줄일 수 있음. 이는 미완성 기능보다 명확한 시작점을 제공함.
     * 솔로 개발자 경험: 혼자 개발하다가 팀을 꾸리게 되었음. '제로 데이'에 대한 죄책감을 느끼지 말아야 하며, 고객의 피드백이 큰 동기부여가 됨.
     * 동기부여에 의존하지 않기: 동기부여 없이도 일을 할 수 있음. 행동이 동기부여를 이끌어내며, 동기부여가 행동을 선행하지 않음.
     * 고기술 스키너 박스: Reddit, Twitter, YouTube 등에서 벗어나기 위해 '아무것도 하지 않기'를 시도함. 이는 뇌를 진정시키고 창의적 문제 해결을 다시 시작하게 함.
     * '제로 데이'의 죄책감: 아무것도 하지 않는 날에 대한 죄책감을 느끼지 않도록 자신을 친절하게 대하는 것이 중요함. 이는 번아웃을 예방함.
     * 고통 해결: 고통을 해결하는 도구를 만드는 것이 더 재미있음. 개인의 워크플로우를 개선하는 일을 직업으로 삼고 싶음.
     * 심리학 연구 가능성: '아무것도 하지 않기'에서 '일하기'로 전환하는 방법이 심리학 연구의 중요한 주제가 될 수 있음.
     * 동기부여 메시지: 구독자가 생길 때마다 알림을 받는 것이 동기부여가 될 수 있음. 이는 이미 동기부여된 사람들에게 더 큰 영향을 미침.
     * IRC 보상 경험: IRC VPN을 판매할 때 새로운 고객이 생기면 내부 채널에 자동 알림이 뜨는 것이 매우 보람찼음.
"
"https://news.hada.io/topic?id=15197","GitHub Actions, Arm64 Runner 지원 시작 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   GitHub Actions, Arm64 Runner 지원 시작

     * 이제 GitHub Actions에서 Arm 기반 Linux 및 Windows runner 제공
     * Arm 아키텍처가 사용되는 모든 곳에서 빌드하고 배포할 수 있게 됨
     * x64 runner보다 37% 저렴
     * GitHub는 Arm과 파트너십을 맺고 Ubuntu 및 Windows VM 이미지를 제공
          + Ubuntu 22.04 이미지에는 배포용 전체 도구 세트 포함
          + Windows 이미지 및 새로운 Ubuntu 24.04 이미지에도 개발자 도구를 추가할 계획
     * 현재는 GitHub Team 및 Enterprise Cloud 플랜의 고객에게 제공됨
     * 연말까지 오픈 소스 프로젝트를 위한 Arm runner 제공 예정
"
"https://news.hada.io/topic?id=15242","인터넷 아카이브의 백룸","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              인터넷 아카이브의 백룸

인터넷 아카이브의 뒷이야기

  백룸의 기원

     * 백룸 이미지의 등장: 2010년대 인터넷 게시판에서 흔히 볼 수 있었던 모호한 실내 사진이 2019년에 '백룸'이라는 전설과 함께 재조명됨.
     * 백룸의 전설: ""현실에서 잘못 빠져나가면 백룸에 갇히게 되며, 그곳은 오래된 카펫의 냄새와 형광등 소음, 끝없는 빈 방들로 이루어져 있음.""
     * 크리피파스타: 백룸 전설은 크리피파스타(인터넷 도시 전설)로, 사람들에게 공포와 흥미를 주는 이야기임.

  백룸의 확산

     * 미디어와 게임: 백룸 전설은 서브레딧, 웹 비디오 시리즈, CGI 모델 등 다양한 형태로 확산됨. 많은 게임들이 백룸을 배경으로 만들어짐.
     * 림널 스페이스: 백룸 전설은 '림널 스페이스'(경계 공간)라는 새로운 미학적 움직임을 촉진함.

  백룸 사진의 진실

     * 사진의 기원: 2003년 위스콘신의 한 가구점에서 촬영된 사진이 백룸 이미지의 기원으로 밝혀짐. 이 사진은 인터넷 아카이브의 크롤러에 의해 저장됨.
     * 인터넷 아카이브의 역할: 인터넷 아카이브는 웹 페이지와 이미지를 저장하여 역사적 자료로 보존함. 백룸 사진의 기원을 밝히는 데 중요한 역할을 함.

  새로운 빛 속으로

     * 반응: 백룸 사진의 기원이 밝혀지자, 일부는 신비가 사라졌다고 느끼고, 일부는 문제 해결의 가능성을 보았음.
     * 인터넷 아카이브의 사명: 인터넷 아카이브는 웹 역사를 보존하고, 투명하고 접근 가능한 진실을 제공하는 것을 목표로 함.

GN⁺의 의견

     * 인터넷 아카이브의 중요성: 인터넷 아카이브는 디지털 시대의 역사 보존에 중요한 역할을 함. 이는 미래 연구와 교육에 큰 도움이 될 수 있음.
     * 크리피파스타의 매력: 크리피파스타는 사람들에게 공포와 흥미를 동시에 제공하며, 인터넷 문화의 중요한 부분으로 자리잡음.
     * 림널 스페이스의 미학: 림널 스페이스는 일상적인 공간을 새로운 시각으로 바라보게 하며, 예술과 디자인 분야에서 흥미로운 주제로 다뤄짐.
     * 기술의 발전과 문제 해결: 기술의 발전은 복잡한 문제를 해결하는 데 큰 도움을 주며, 이는 협력과 정보 공유의 중요성을 강조함.
     * 미스터리의 가치: 미스터리가 해결되면 신비로움이 사라질 수 있지만, 새로운 미스터리가 항상 등장하며 사람들의 호기심을 자극함.
"
"https://news.hada.io/topic?id=15194","파일을 스캔하여 높은 엔트로피 라인을 찾는 CLI 도구 Entropy","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 파일을 스캔하여 높은 엔트로피 라인을 찾는 CLI 도구 Entropy

Entropy

   Entropy는 코드베이스에서 높은 엔트로피 라인을 스캔하여 비밀 정보를 찾아주는 CLI 도구임.

  설치 방법

    Go를 이용한 소스 설치 (권장)

     * go install github.com/EwenQuim/entropy@latest
     * entropy 명령어 사용 가능
     * 추가 옵션: entropy -h, entropy -top 20 -ext go,py,js, entropy -top 5 -ignore-ext min.js,pdf,png,jpg,jpeg,zip,mp4,gif my-folder my-file1 my-file2
     * 한 줄 설치: go run github.com/EwenQuim/entropy@latest

    Brew를 이용한 설치

     * 작업 진행 중 (WIP)

    Docker를 이용한 설치

     * docker run --rm -v $(pwd):/data ewenquim/entropy /data
     * 추가 옵션: docker run --rm -v $(pwd):/data ewenquim/entropy -h, docker run --rm -v $(pwd):/data ewenquim/entropy -top 20 -ext go,py,js /data, docker run --rm -v $(pwd):/data ewenquim/entropy -top 5 /data/my-folder /data/my-file
     * Docker Hub에서 이미지 사용 가능
     * -v 옵션은 현재 디렉토리를 컨테이너에 마운트하는 데 사용됨
     * 명령어 끝에 /data를 추가해야 함, 그렇지 않으면 도구가 로컬 파일 시스템이 아닌 컨테이너 내부를 검색함

  다른 프로젝트

     * Fuego: 코드베이스에서 OpenAPI 문서를 생성하는 Go 프레임워크
     * Renpy-Graphviz: Ren'Py 게임 엔진의 화면과 레이블을 그래프로 생성하는 도구

GN⁺의 의견

     * 보안 강화: 코드베이스에서 비밀 정보를 자동으로 찾아내어 보안 강화를 도울 수 있음.
     * 사용 편의성: 다양한 설치 방법을 제공하여 사용자가 편리하게 도구를 설치하고 사용할 수 있음.
     * 유사 도구: 비슷한 기능을 제공하는 도구로는 git-secrets, truffleHog 등이 있음.
     * 도입 고려 사항: 도구 사용 시 코드베이스의 크기와 복잡성을 고려해야 하며, 높은 엔트로피 라인이 반드시 비밀 정보를 의미하지 않을 수 있음.
     * 기술 선택의 득과 실: Entropy 도입으로 보안 사고를 예방할 수 있지만, 잘못된 긍정(false positive) 결과가 나올 수 있어 추가 검토가 필요함.

        Hacker News 의견

     * Perl 스크립트 사용: Perl 스크립트를 사용하여 텍스트의 엔트로피를 측정하는 방법을 제안함. 짧은 줄에서는 압축이 잘 안 되는 문제가 있음.
     * 데이터베이스 비밀번호: 모든 데이터베이스 비밀번호를 'abcd'로 설정하여 문제를 해결함.
     * 엔트로피 사용에 대한 궁금증: 엔트로피를 텍스트 분석에 사용하는 방법에 대한 좋은 글을 찾고 있음. 엔트로피의 정의와 효과에 대해 궁금해함.
     * 엔트로피 정의 문제: 텍스트의 엔트로피를 정의하는 것이 모호함. 자연 언어와 무작위 문자열의 엔트로피를 비교하는 더 나은 방법이 필요함.
     * 관련 프로젝트: 트러플호그, 디텍트-시크릿, 세미그렙 시크릿과 같은 관련 프로젝트를 소개함.
     * 고마움 표현: 몇 년 전 엔트로피에 대한 질문을 한 DrJones에게 감사하며, 관련 좋은 글을 링크함.
     * CLI 도구 칭찬: 유용한 CLI 도구이며, Go 코드도 훌륭하다고 칭찬함.
     * 'ent' 프로그램: 오래 사용해온 'ent' 프로그램을 떠올리게 함.
     * 언어 모델 사용: Llama 3 같은 언어 모델이 토큰별로 놀라움을 모델링하여 높은 엔트로피 영역을 감지할 수 있을 것이라고 제안함.
     * CLI 도구 개선 제안: .gitignore 파일을 자동으로 읽어 내용을 제외하는 플래그와 다양한 비밀 탐지 전략을 추가하면 좋겠다고 제안함.
     * 압축 비교 방법: 파일을 압축하여 압축된 크기와 원본 크기를 비교하는 방법을 제안함. 암호화된 파일은 코드보다 압축이 잘 안 됨.
"
"https://news.hada.io/topic?id=15315","AI가 생성했다고 의심되는 자료를 설명하는 새로운 용어 "Slop" 등장  ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                AI가 생성했다고 의심되는 자료를 설명하는 새로운 용어 ""Slop"" 등장

  먼저 '스팸(Spam)'이 왔고, 이제 A.I.와 함께 '슬롭(Slop)'이 왔다

     * '슬롭(Slop)'은 인공지능(AI)이 생성한 조잡하거나 원치 않는 콘텐츠를 의미하는 새로운 용어임.
     * 구글이 제미니(Gemini) AI 모델을 미국 기반 검색 결과에 통합하면서 이 용어가 더 널리 쓰이게 됨.
          + 구글은 링크를 가리키는 대신 'AI 개요'라는 텍스트로 검색어를 해결하려 함.
          + AI 기능의 문제점으로 인해 구글은 문제가 해결될 때까지 일부 AI 기능을 롤백하기로 함.
     * AI 검색은 인간이 관리하는 정보보다는 기계가 생성한 방대한 양의 정보를 제공하는 것으로 보임.
     * '슬롭'은 가축에게 먹이로 주는 먹음직스럽지 않은 음식 더미를 연상시킴.
          + AI 검색도 마찬가지로 빠르게 결과를 내지만 비판적 사고를 하는 사람들에게는 받아들이기 어려움.
     * AI 검색의 문제점은 AI 개요의 정보를 확정적인 답변으로 제시한다는 것임.
          + 사용자의 주제에 대한 연구 시작점이 아닌, 수용을 장려하는 위험한 방식임.

  '슬롭'이라는 용어의 잠재력

     * '슬롭'은 아직 주류 청중에게 널리 알려지지 않았지만, 잠재력이 있는 용어임.
     * 언어학자 Adam Aleksic은 '슬롭'이 우리에게 익숙한 단어이므로 자연스럽게 이 상황에 적용될 수 있다고 봄.
     * '슬롭'은 2022년 AI 아트 생성기 출시에 대한 반응으로 등장한 것으로 보임.
          + 개발자 Simon Willison이 이 용어의 초기 채택자로 지목되기도 함.
     * 4chan, Hacker News, YouTube 댓글에서 '슬롭'이라는 용어가 사용되기 시작함.
          + 익명의 포스터들은 그룹 내 언어를 사용하여 복잡한 주제에 대한 능숙함을 보여줌.

  AI가 검색 엔진에 미치는 영향

     * 단기적으로 AI가 검색 엔진과 인터넷 전반에 미치는 영향은 우려만큼 심각하지 않을 수 있음.
     * Chartbeat의 데이터에 따르면, AI 개요 초기에 Google Discover에서 웹사이트로의 추천이 즉시 감소했으나 이후 회복됨.
          + AI 개요 도입 첫 3주 동안 미국 내 2,000개 이상의 주요 웹사이트에 대한 전반적인 검색 트래픽은 오히려 증가함.

  '슬롭'이 저급한 기계 생성 콘텐츠에 대한 대표 용어가 될 수 있음

     * Simon Willison은 AI가 올바르게 사용될 때 AI에 대해 낙관적이라고 밝힘.
     * 그는 '슬롭'이 저급한 기계 생성 콘텐츠에 대한 대표 용어가 될 수 있다고 생각함.
          + ""사회는 현대 AI에 대해 간결하게 이야기할 방법이 필요함.""
          + ""그 이메일은 무시해, 스팸이야와 그 기사는 무시해, 슬롭이야는 모두 유용한 교훈임.""

   요즘은 커뮤에 slop올리면서 슬쩍 slop아니고 사람이 만든척 하는 악질들 많아짐

   흥미로운 단어네요. 요즘 자주 언급되는 AI를 이용한 자동화 숏폼 영상 제작 같은 것도 일종의 슬롭이 아닌가 하는 생각이 듭니다

   “저것봐! 손가락이 일곱개야!!”

        Hacker News 의견

     * Slop이라는 용어는 원치 않는 AI 생성 콘텐츠를 지칭하는 데 적합함. AI 이전에도 이미 많은 불필요한 콘텐츠가 존재했음.
     * 해커뉴스와 기여자 simonw가 기사에서 언급됨. Simon Willison은 이 용어의 초기 사용자로 알려졌으나, 실제로는 이미 사용되고 있었음.
     * Neal Stephenson의 팬으로서, 그의 책 Anathem에서 인터넷의 쓰레기 정보가 AI에 의해 생성된다는 아이디어가 흥미로웠음. 미래에는 AI와 인간 간의 위키피디아 편집 전쟁이 벌어질 가능성이 있음.
     * AI 생성 스팸이라는 용어가 이미 사용되고 있으므로, 굳이 새로운 용어를 만들 필요가 없다는 의견.
     * 광고 기반 미디어 앱에서는 사람들이 콘텐츠에 돈을 지불하지 않으려는 한, 개인화된 불필요한 정보가 계속될 것이라는 전망.
     * LLM/생성형 AI의 발전으로 인해, 불필요한 콘텐츠는 점점 더 저렴하게 생성될 것이며, 진정성은 점점 사라질 것이라는 예측.
     * Slop은 AI 이전에도 존재했으며, 많은 상위 검색 결과가 잘못된 정보를 포함하고 있었음. GPT-4도 이러한 잘못된 데이터로 학습되었을 가능성이 있음.
     * 개인화된 Slop과 AI 모델의 제품 배치가 미래의 큰 트렌드가 될 것이라는 전망. 정치적 필터 버블과 같은 개인화된 콘텐츠가 증가할 것임.
     * 인류의 문화적 유산이 본질적으로 무의미하다는 현실을 직면하면서, 대규모 존재론적 위기를 겪고 있다는 의견.
"
"https://news.hada.io/topic?id=15192","인플루언서 활동에 대한 몇 가지 노트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          인플루언서 활동에 대한 몇 가지 노트

인플루언서 활동에 대한 몇 가지 노트

  인터넷에 비상업적 콘텐츠를 게시하는 것의 장단점

     * 저자는 성인 생활 내내 인터넷에 다양한 콘텐츠를 게시해왔음. 보안 연구, 오픈 소스 프로젝트, 다양한 주제에 대한 장기적인 글쓰기 등이 포함됨.
     * 콘텐츠를 게시하는 이유는 자신의 생각을 명확히 하고, 가정과 격차를 해결하기 위함임.

  #1: 여전히 일임

     * 수익화를 거부하면 온라인 게시의 대부분의 실질적인 장점을 포기하게 됨. 하지만 단점은 여전히 남아 있음.
     * 웹사이트가 구글에서 무작위로 삭제되거나, SEO 스패머에게 납치되거나, 안티바이러스 도구에 의해 반복적으로 플래그가 지정되는 등의 문제가 발생할 수 있음.
     * 셀프 호스팅은 끝없는 구성 및 유지 관리 작업을 요구함. 제3자 호스팅도 문제가 발생할 수 있음.
     * 무료 호스팅을 사용해도 비용이 빠르게 증가함. 사진 및 비디오 장비, 소프트웨어 라이선스, 골동품 계산기 및 랜덤 PCB 구매 등 다양한 비용이 발생함.

  #2: 인터넷에는 이상한 사람들이 있음

     * 대부분의 경우, 인터넷에서 유용한 콘텐츠를 접하면 그 콘텐츠를 만든 사람에 대해 깊이 생각하지 않음.
     * 그러나 온라인 증오는 쉽게 사라지지 않음. 때때로 자신을 따라다니며 비난하거나 모욕하는 사람을 만날 수 있음.
     * 이러한 비난은 종종 비난하는 사람의 불안과 스트레스를 해소하기 위한 것임.

  #3: 무관심이 진정한 문제임

     * 콘텐츠가 다른 사람을 화나게 한다면 여전히 청중이 있다는 의미임.
     * 논란은 종종 방관자들을 끌어들이고 그들이 스스로 판단하게 함.
     * 그러나 아무런 반응이 없을 때가 더 고통스러움. 많은 블로거나 브이로거는 부정적인 댓글 때문에 그만두지 않고, 반응이 없어서 그만둠.

  #4: 팔로워 수는 거짓임

     * 대부분의 소셜 미디어 플랫폼은 알고리즘 피드를 사용하여 사용자에게 무엇을 보여줄지 결정함.
     * 팔로워 수는 실제로 그들이 게시물을 볼 것이라는 의미가 아님.
     * Substack은 예외적으로 모든 게시물을 이메일로 전달함.
     * 트위터와 유튜브에서는 많은 팔로워가 있어도 실제로 게시물을 보는 사람은 적음.

  #5: 돈은 일부 악의 뿌리임

     * 인터넷을 부패시키는 것은 단지 돈 때문만이 아님. 비상업적 콘텐츠 제작자들도 왜곡된 인센티브를 다루고 있음.
     * 새로운 글을 게시할 때마다 구독자를 잃는 경우가 있음. 그러나 게시하지 않을 때는 구글 검색을 통해 구독자가 늘어남.
     * 인터넷의 주목은 무작위적이며, 저품질 콘텐츠에 대한 편향이 있음. 많은 시간과 노력을 들인 콘텐츠가 거의 트래픽을 얻지 못할 수 있음.

GN⁺의 의견

     * 콘텐츠 제작의 현실: 콘텐츠 제작은 많은 시간과 노력이 필요하며, 예상치 못한 문제들이 발생할 수 있음. 이는 초급 소프트웨어 엔지니어들에게도 유용한 교훈이 될 수 있음.
     * 알고리즘의 영향: 소셜 미디어 플랫폼의 알고리즘은 콘텐츠의 가시성을 크게 좌우함. 이는 콘텐츠 제작자들이 알고리즘을 이해하고 활용하는 것이 중요함을 의미함.
     * 무관심의 문제: 콘텐츠가 주목받지 못하는 것은 큰 문제임. 이는 콘텐츠의 질을 높이고, 청중과의 상호작용을 강화하는 것이 중요함을 시사함.
     * 팔로워 수의 한계: 팔로워 수는 실제 영향력을 반영하지 않을 수 있음. 이는 진정한 청중과의 연결이 더 중요함을 의미함.
     * 비상업적 콘텐츠의 가치: 비상업적 콘텐츠도 중요한 가치를 지니며, 이는 개인의 성장과 학습에 도움이 될 수 있음.

        Hacker News 의견

     * 바이럴 콘텐츠와 SEO: 짧고 재치 있는 게시물이 바이럴되지만, 오랜 시간 공들인 콘텐츠는 거의 트래픽이 없음을 경험함.
     * 노력과 참여도: 노력한 콘텐츠보다 생각 없이 작성한 소셜 미디어 댓글이 더 많은 참여를 얻는 경향이 있음.
     * 유튜브와 정보성 콘텐츠: 유튜브에서도 정보성 콘텐츠는 도달 범위가 낮고, 엔터테인먼트 중심의 콘텐츠가 더 높은 참여를 얻음.
     * 트위터와 인생 변화: 트위터에서 만난 사람과 결혼하고, 여러 인터뷰와 직장 제안을 받았지만, 결국 핀란드로 이주함.
     * 트위터의 가치: 트위터를 통해 자신에 대한 부정적인 생각을 없애고, 많은 사람들이 자신을 가치 있게 여기는 것을 발견함.
     * 작은 콘텐츠 제작자의 경험: 10년 넘게 재미로 콘텐츠를 제작해왔고, 이상한 스토커와 혐오자들을 만나는 것이 피곤하고 무서울 때도 있음.
     * 콘텐츠 제작의 목적: 콘텐츠를 재미로 만들며, 수익화에 대한 압박을 받는 것이 불만임.
     * 플랫폼 관리: SEO 문제를 피하기 위해 트위치, 메타, 유튜브 같은 플랫폼을 사용함.
     * 반응 없는 콘텐츠: 반응이 없는 것이 더 아프며, 유명한 저자도 이런 감정을 느낄 수 있음.
     * 정적 사이트 사용: 정적 사이트를 사용하여 문제를 해결하고, 백업을 설정해두는 것이 중요함.
     * 자기 호스팅의 중요성: 자기 호스팅을 통해 HN에서 더 많은 주목을 받을 수 있음.
     * 팔로워 수의 가치: 팔로워 수는 실제 청중과 다르며, 진정한 팬 1000명이 더 가치 있음.
     * 자기 만족을 위한 블로깅: 블로그 게시물은 자신의 생각을 정리하고 깊이 이해하기 위한 도구로 사용함.
     * 잘못된 검색 유입: 열정적으로 작성한 사진 가이드가 비슷한 이름의 포르노 배우를 찾는 검색으로 유입됨.
     * 바이럴 콘텐츠의 경험: 오랜 시간 공들인 프로젝트는 주목받지 못하지만, 밈 콘텐츠는 빠르게 확산됨.
"
"https://news.hada.io/topic?id=15268","1년 동안 LLM과 함께 구축하며 배운 점","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1년 동안 LLM과 함께 구축하며 배운 점

     * 대규모 언어 모델(LLM)을 사용한 개발이 흥미로운 시기임
          + 지난 1년 동안 LLM이 실제 애플리케이션에 ""충분히 좋은"" 수준이 되었으며, 매년 더 좋아지고 저렴해지고 있음
          + 소셜 미디어의 데모와 함께, 2025년까지 AI에 약 2000억 달러가 투자될 것으로 추정됨
          + 업체들의 API로 인해 LLM이 더 접근하기 쉬워져, ML 엔지니어와 과학자뿐만 아니라 모두가 제품에 인텔리젠스를 구축할 수 있게 됨
     * AI로 구축하는 진입 장벽은 낮아졌지만, 데모 이상으로 효과적인 제품과 시스템을 만드는 것은 여전히 어려움
     * 우리는 지난 1년 동안 구축해 왔으며, 그 과정에서 많은 어려움을 발견했음
          + 우리의 실수를 피하고 더 빠르게 반복할 수 있도록 우리가 배운 내용을 공유하고자 함
     * 이 글은 세 부분으로 구성됨:
         1. Tactical(전술적): 프롬프팅, RAG, 워크플로우 엔지니어링, 평가 및 모니터링을 위한 몇 가지 실천 사항
               o LLM으로 구축하는 실무자나 주말 프로젝트를 진행하는 사람들을 위해 작성됨
         2. Operational(운영적): 제품 출시의 조직적, 일상적 관심사와 효과적인 팀 구축 방법
               o 지속 가능하고 안정적으로 배포하려는 제품/기술 리더를 위한 내용
         3. Strategic(전략적): ""PMF 전에 GPU 없음"", ""모델이 아닌 시스템에 집중"" 등의 의견을 담은 장기적이고 큰 그림 관점과 반복하는 방법
               o 창업자와 경영진을 염두에 두고 작성됨
     * 이 가이드는 LLM을 사용하여 성공적인 제품을 구축하기 위한 실용적인 안내서가 되는 것을 목표로 함
          + 우리 자신의 경험에서 비롯되었으며 업계 전반의 사례를 제시함

[전술: LLM 사용의 핵심]

     * 이 섹션에서는 새로 등장하는 LLM 스택의 핵심 구성 요소에 대한 모범 사례를 공유함
          + 품질과 신뢰성을 높이기 위한 프롬프팅 팁, 출력을 평가하기 위한 전략, 그라운딩을 개선하기 위한 검색 증강 생성 아이디어 등이 포함됨
          + 또한 휴먼 인 더 루프 워크플로우를 설계하는 방법도 탐구할 예정임

  전술 1. 프롬프팅

     * 새로운 애플리케이션을 개발할 때는 프롬프팅으로 시작할 것을 권장함
          + 프롬프팅의 중요성을 과소평가하거나 과대평가하기 쉬움
          + 올바른 프롬프팅 기술을 제대로 사용하면 매우 멀리 갈 수 있기 때문에 과소평가되는 경향이 있음
          + 프롬프트 기반 애플리케이션도 제대로 작동하려면 프롬프트 주변에 상당한 엔지니어링이 필요하기 때문에 과대평가되는 경향이 있음

    기본 프롬프팅 기술을 최대한 활용하는 데 집중

     * 다양한 모델과 작업에서 성능 향상에 지속적으로 도움이 되는 몇 가지 프롬프팅 기술이 있음
          + N-shot 프롬프트 + 문맥 내 학습, 사고의 연쇄(Chain-of-Thought), 관련 리소스 제공 등임
     * N-shot 프롬프트와 문맥 내 학습
          + N-shot 프롬프트를 통한 문맥 내 학습의 아이디어는 LLM에게 작업을 시연하고 출력을 기대에 맞추는 몇 가지 예시를 제공하는 것임
          + N이 너무 낮으면 모델이 해당 특정 예시에 과도하게 고정되어 일반화 능력이 저하될 수 있음
          + 경험적으로 N ≥ 5를 목표로 하고, 수십 개까지 사용하는 것을 두려워하지 말 것
          + 예시는 예상되는 입력 분포를 대표해야 함
          + 전체 입출력 쌍을 제공할 필요는 없으며, 많은 경우 원하는 출력의 예시로 충분함
          + 도구 사용을 지원하는 LLM을 사용하는 경우, N-shot 예시에서도 에이전트가 사용하기를 원하는 도구를 사용해야 함
     * 사고의 연쇄(Chain-of-Thought, CoT) 프롬프팅
          + CoT 프롬프팅에서는 LLM이 최종 답변을 반환하기 전에 사고 과정을 설명하도록 장려함
          + LLM에게 메모리에서 모든 것을 수행할 필요가 없도록 스케치패드를 제공하는 것으로 생각할 수 있음
          + 원래 접근 방식은 단순히 ""단계별로 생각해 보자""라는 문구를 지침의 일부로 추가하는 것이었지만, CoT를 더 구체적으로 만드는 것이 도움이 된다는 것을 발견함
          + 1~2문장으로 구체성을 추가하면 환각 발생률이 상당히 감소하는 경우가 많음
          + 최근에는 이 기술이 믿는 만큼 강력한지에 대해 의문이 제기되고 있음
          + 또한 CoT가 사용될 때 추론 중에 정확히 어떤 일이 일어나는지에 대해 상당한 논쟁이 있음
          + 그럼에도 불구하고 가능한 경우 실험해 볼 만한 기술임
     * 관련 리소스 제공
          + 관련 리소스를 제공하는 것은 모델의 지식 기반을 확장하고, 환각을 줄이며, 사용자의 신뢰를 높이는 강력한 메커니즘임
          + 검색 증강 생성(Retrieval Augmented Generation, RAG)을 통해 수행되는 경우가 많음
          + 모델에 응답에 직접 활용할 수 있는 텍스트 스니펫을 제공하는 것은 필수적인 기술임
          + 관련 리소스를 제공할 때는 단순히 포함하는 것으로는 충분하지 않음
               o 모델에게 리소스 사용을 우선시하고, 직접 참조하며, 때로는 리소스가 충분하지 않을 때 언급하도록 지시하는 것을 잊지 말아야 함
          + 이러한 것들은 에이전트 응답을 리소스 코퍼스에 ""Ground""하는 데 도움이 됨

    입력과 출력 구조화

     * 구조화된 입력과 출력은 모델이 입력을 더 잘 이해하고 다운스트림 시스템과 안정적으로 통합할 수 있는 출력을 반환하는 데 도움이 됨
          + 입력에 직렬화 형식을 추가하면 컨텍스트의 토큰 간 관계, 특정 토큰에 대한 추가 메타데이터(유형 등) 또는 요청을 모델 학습 데이터의 유사한 예시와 관련시키는 데 도움이 될 수 있음
          + 예를 들어, 인터넷에서 SQL 작성에 대한 많은 질문은 SQL 스키마를 지정하는 것으로 시작함
               o 따라서 Text-to-SQL에 대한 효과적인 프롬프팅에는 구조화된 스키마 정의가 포함되어야 함
     * 구조화된 출력은 유사한 목적을 수행하지만, 시스템의 다운스트림 구성 요소로의 통합을 단순화함
          + Instructor와 Outlines는 구조화된 출력에 잘 작동함
               o (LLM API SDK를 가져오는 경우 Instructor를 사용하고, 자체 호스팅 모델에 Huggingface를 가져오는 경우 Outlines를 사용)
          + 구조화된 입력은 작업을 명확하게 표현하고 학습 데이터의 형식과 유사하므로 더 나은 출력 가능성을 높임
     * 구조화된 입력을 사용할 때는 각 LLM 제품군마다 선호하는 방식이 있다는 점에 유의해야 함
          + Claude는 <xml>을 선호하는 반면 GPT는 Markdown과 JSON을 선호함
          + XML을 사용하면 <response> 태그를 제공하여 Claude의 응답을 미리 채울 수도 있음

    작고 한 가지 일을 잘하는 프롬프트를 만들 것

     * 소프트웨어에서 흔한 안티 패턴/코드 스멜은 모든 것을 수행하는 단일 클래스나 함수인 ""God Object""임
          + 이는 프롬프트에도 동일하게 적용됨
     * 프롬프트는 일반적으로 간단하게 시작함
          + 몇 문장의 지침, 몇 가지 예시로 시작할 수 있음
          + 그러나 성능을 개선하고 더 많은 edge case를 처리하려고 하면서 복잡성이 증가함
               o 더 많은 지침, 다단계 추론, 수십 개의 예시 등이 추가됨
          + 결국 처음에는 단순했던 프롬프트가 2,000 토큰의 프랑켄슈타인이 되어버림
               o 게다가 더 일반적이고 직관적인 입력에 대한 성능은 오히려 저하됨
               o GoDaddy는 이 문제를 LLM 구축에서 얻은 교훈 중 1위로 꼽음
     * 시스템과 코드를 단순하게 유지하려고 노력하는 것처럼, 프롬프트도 마찬가지여야 함
          + 회의 녹취록 요약기에 대해 단일 만능 프롬프트를 사용하는 대신, 다음과 같은 단계로 나눌 수 있음
               o 주요 결정 사항, 조치 항목 및 담당자를 구조화된 형식으로 추출
               o 추출된 세부 정보를 원본 녹취록과 비교하여 일관성 확인
               o 구조화된 세부 정보에서 간결한 요약 생성
     * 결과적으로 단일 프롬프트를 여러 개의 단순하고 집중적이며 이해하기 쉬운 프롬프트로 분할함
          + 이렇게 분할하면 이제 각 프롬프트를 개별적으로 반복하고 평가할 수 있음

    컨텍스트 토큰 만들기

     * 에이전트에 실제로 전송해야 하는 컨텍스트의 양에 대한 가정을 재고하고 도전해야 함
          + 미켈란젤로처럼 컨텍스트 조각상을 만들어 가는 것이 아니라, 불필요한 재료를 깎아내어 조각상을 드러내야 함
          + RAG는 잠재적으로 관련된 대리석 블록을 모두 모으는 데 널리 사용되는 방법이지만, 필요한 것을 추출하기 위해 무엇을 하고 있는가?
     * 모델에 전송되는 최종 프롬프트를 가져와 모든 컨텍스트 구성, 메타 프롬프팅, RAG 결과와 함께 빈 페이지에 배치하고 읽어보는 것이 컨텍스트를 재고하는 데 도움이 된다는 것을 발견함
          + 이 방법을 사용하여 중복, 자가 모순적인 언어 및 형식이 잘못된 부분을 발견할 수 있음
     * 다른 핵심 최적화는 컨텍스트의 구조임
          + Bag-of-docs 표현은 인간에게 도움이 되지 않으므로 에이전트에게 좋다고 가정하지 말아야 함
          + 컨텍스트의 각 부분 간의 관계를 강조하고 추출을 가능한 한 단순하게 만들 수 있도록 컨텍스트를 구성하는 방법을 신중하게 고려해야 함

  전술 2. 정보 검색 / RAG

     * 프롬프팅 외에도 LLM을 조정하는 또 다른 효과적인 방법은 프롬프트의 일부로 지식을 제공하는 것임
          + 이는 제공된 컨텍스트에 LLM을 ground시키며, 이는 문맥 내 학습에 사용됨
          + 이를 검색 증강 생성(Retrieval-Augmented Generation, RAG)이라고 함
          + 실무자들은 RAG가 지식을 제공하고 출력을 개선하는 데 효과적이며, 미세 조정에 비해 훨씬 적은 노력과 비용이 든다는 것을 발견함
          + RAG는 검색된 문서의 관련성, 밀도 및 세부 정보만큼만 좋음

    RAG 출력의 품질은 검색된 문서의 품질에 따라 달라지며, 몇 가지 요소를 고려할 수 있음

     * 첫 번째이자 가장 명백한 척도는 ""관련성""
          + 이는 일반적으로 평균 역순위(Mean Reciprocal Rank, MRR) 또는 정규화된 할인 누적 이득(Normalized Discounted Cumulative Gain, NDCG)과 같은 순위 지표로 정량화됨
          + MRR은 시스템이 순위 목록에서 첫 번째 관련 결과를 얼마나 잘 배치하는지 평가하는 반면, NDCG는 모든 결과의 관련성과 위치를 고려함
          + 이들은 관련 문서를 더 높이, 관련 없는 문서를 더 낮게 순위를 매기는 시스템의 성능을 측정함
          + 예를 들어, 영화 리뷰 요약을 생성하기 위해 사용자 요약을 검색하는 경우, 특정 영화에 대한 리뷰를 더 높이 순위를 매기고 다른 영화에 대한 리뷰는 제외하는 것이 좋음
          + 전통적인 추천 시스템과 마찬가지로 검색된 항목의 순위는 LLM이 다운스트림 작업을 수행하는 방식에 상당한 영향을 미침
          + 영향을 측정하려면 검색된 항목을 섞은 상태에서 RAG 기반 작업을 실행해 보고, RAG 출력이 어떻게 수행되는지 확인할 것
     * 두번째로 ""정보 밀도""
          + 두 문서가 동일하게 관련된 경우, 더 간결하고 관련 없는 세부 정보가 적은 문서를 선호해야 함
          + 영화 예로 돌아가면, 영화 대본과 모든 사용자 리뷰를 광범위한 의미에서 관련이 있다고 간주할 수 있음
          + 그럼에도 불구하고 높은 평가를 받은 리뷰와 편집 리뷰는 정보 밀도가 더 높을 가능성이 있음
     * 마지막으로, 문서에 제공된 ""세부 정보 수준""을 고려할 것
          + 자연어에서 SQL 쿼리를 생성하기 위한 RAG 시스템을 구축한다고 상상해 보자
               o 열 이름이 있는 테이블 스키마를 컨텍스트로 제공하는 것만으로도 충분할 수 있음
               o 그러나 열 설명과 일부 대표 값을 포함하면 어떨까?
          + 추가 세부 정보는 LLM이 테이블의 의미를 더 잘 이해하고 더 정확한 SQL을 생성하는 데 도움이 될 수 있음

    키워드 검색을 잊지 말고, 기준선과 하이브리드 검색에 사용할 것

     * Embedding 기반 RAG 데모가 널리 퍼져 있기 때문에 정보 검색 분야의 수십 년 간의 연구와 솔루션을 잊거나 간과하기 쉬움
          + 그럼에도 불구하고 임베딩은 의심할 여지 없이 강력한 도구이지만, 만능은 아님
     * 키워드 기반 검색의 장점
          + 첫째, 임베딩은 높은 수준의 의미론적 유사성을 포착하는 데 탁월하지만, 사용자가 이름(예: Ilya), 두문자어(예: RAG) 또는 ID(예: claude-3-sonnet)를 검색할 때와 같이 더 구체적이고 키워드 기반의 쿼리에는 어려움을 겪을 수 있음
               o BM25와 같은 키워드 기반 검색은 이를 위해 명시적으로 설계됨
               o 사용자들은 키워드 기반 검색을 오랫동안 사용해 왔기 때문에 당연한 것으로 여기고 있을 것이며, 검색하고자 하는 문서가 반환되지 않으면 좌절감을 느낄 수 있음
          + 둘째, 키워드 검색으로 문서가 검색된 이유를 이해하는 것이 더 직관적임
               o 쿼리와 일치하는 키워드를 확인할 수 있기 때문
               o 반면에 임베딩 기반 검색은 해석 가능성이 낮음
          + 셋째, 수십 년 동안 최적화되고 실전에서 검증된 Lucene이나 OpenSearch와 같은 시스템 덕분에 키워드 검색이 일반적으로 더 계산적으로 효율적임
     * 대부분의 경우 하이브리드 접근 방식이 가장 효과적
          + 명백한 일치 항목에는 키워드 매칭을 사용하고, 동의어, 상위어, 철자 오류 및 멀티모달(예: 이미지와 텍스트)에는 임베딩을 사용
          + Shortwave는 쿼리 재작성, 키워드 + 임베딩 검색, 랭킹 등 자신들의 RAG 파이프라인을 어떻게 구축했는지 공유한바 있음

    새로운 지식에 대해서는 파인튜닝보다 RAG를 선호

     * RAG와 파인튜닝 모두 새로운 정보를 LLM에 통합하고 특정 작업에 대한 성능을 향상시키는 데 사용될 수 있음
          + 그렇다면 어떤 것을 먼저 시도해야 할까?
     * RAG의 장점
          + 최근 연구에 따르면 RAG가 더 우수할 수 있음
          + 한 연구에서는 RAG와 비지도 미세 조정(지속적 사전 학습이라고도 함)을 MMLU와 시사 문제의 하위 집합에서 평가하여 비교함
               o RAG가 학습 중에 접한 지식과 완전히 새로운 지식 모두에 대해 미세 조정보다 지속적으로 더 우수한 성능을 보였음
          + 다른 논문에서는 농업 데이터 세트에 대해 RAG와 지도 미세 조정을 비교함
               o 마찬가지로 RAG의 성능 향상이 미세 조정보다 컸으며, 특히 GPT-4에서 두드러짐(논문의 표 20 참조)
          + 성능 향상 외에도 RAG는 여러 실용적인 장점이 있음
               o 첫째, 지속적인 사전 학습이나 미세 조정에 비해 검색 인덱스를 최신 상태로 유지하는 것이 더 쉽고 저렴함
               o 둘째, 검색 인덱스에 유해하거나 편향된 내용이 포함된 문제가 있는 문서가 있는 경우 문제가 있는 문서를 쉽게 삭제하거나 수정할 수 있음
          + 또한 RAG의 R은 문서를 검색하는 방법에 대해 더 세분화된 제어를 제공함
               o 예를 들어 여러 조직을 위해 RAG 시스템을 호스팅하는 경우, 검색 인덱스를 분할하여 각 조직이 자체 인덱스의 문서만 검색할 수 있도록 할 수 있음
               o 이렇게 하면 한 조직의 정보를 실수로 다른 조직에 노출하는 일이 없도록 할 수 있음

    장문 컨텍스트 모델이 RAG를 쓸모없게 만들지는 않을 것임

     * Gemini 1.5가 최대 1,000만 토큰 크기의 컨텍스트 윈도우를 제공함에 따라 일부에서는 RAG의 미래에 의문을 제기하기 시작함
          + 1,000만 토큰의 컨텍스트 윈도우는 기존 RAG 프레임워크 대부분을 불필요하게 만듦
               o 데이터를 컨텍스트에 넣고 평소처럼 모델과 대화하기만 하면 됨
          + 이는 대부분의 엔지니어링 노력이 RAG에 투입되는 스타트업, 에이전트, langchain 프로젝트에 어떤 영향을 줄지 상상해 보라
               o 한 문장으로 요약하면 1,000만 컨텍스트가 RAG를 죽인다는 것
     * RAG의 지속적 필요성
          + 장문 컨텍스트가 여러 문서 분석이나 PDF와의 채팅 등의 사용 사례에 게임 체인저가 될 것이라는 점은 사실이지만, RAG의 종말에 대한 소문은 크게 과장됨
               o 첫째, 1,000만 토큰의 컨텍스트 윈도우가 있더라도 모델에 입력할 정보를 선택하는 방법이 여전히 필요함
               o 둘째, 좁은 바늘구멍 평가를 넘어서 모델이 그렇게 큰 컨텍스트에 대해 효과적으로 추론할 수 있다는 설득력 있는 데이터는 아직 보지 못함
               o 따라서 좋은 검색(및 랭킹) 없이는 주의를 분산시키는 정보로 모델을 압도하거나 심지어 완전히 무관한 정보로 컨텍스트 윈도우를 채울 위험이 있음
     * 마지막으로 비용 문제가 있음
          + Transformer의 추론 비용은 컨텍스트 길이에 따라 제곱(또는 공간과 시간 모두에서 선형)으로 증가함
          + 조직의 전체 Google Drive 내용을 읽을 수 있는 모델이 존재한다고 해서 각 질문에 답하기 전에 그렇게 하는 것이 좋은 생각은 아님
          + RAM 사용 방식에 대한 비유를 고려해 보자
               o 수십 테라바이트에 달하는 RAM이 있는 컴퓨팅 인스턴스가 존재하지만, 여전히 디스크에서 읽고 쓰고 있음
     * 따라서 아직 RAG를 쓰레기통에 버리지 말 것
          + 이 패턴은 컨텍스트 윈도우의 크기가 커질수록 여전히 유용할 것임

  전술 3. 워크플로우 튜닝 및 최적화

     * LLM에 프롬프트를 주는 것은 시작에 불과함
          + LLM을 최대한 활용하려면 단일 프롬프트를 넘어 워크플로우를 수용해야 함
          + 예를 들어, 복잡한 단일 작업을 여러 개의 더 간단한 작업으로 어떻게 분할할 수 있을까?
          + 미세 조정이나 캐싱이 성능 향상과 지연/비용 감소에 도움이 되는 시점은 언제일까?
     * 이 섹션에서는 검증된 전략과 실제 사례를 공유하여 LLM 워크플로우를 최적화하고 구축하는 데 도움을 줌

    단계별, 다중 턴 ""Flow""는 큰 성능 향상을 제공할 수 있음

     * 하나의 큰 프롬프트를 여러 개의 작은 프롬프트로 분해함으로써 더 나은 결과를 얻을 수 있다는 것을 이미 알고 있음
          + AlphaCodium이 그 예시임
               o 단일 프롬프트에서 다단계 워크플로우로 전환함으로써 CodeContests에서 GPT-4 정확도(pass@5)를 19%에서 44%로 높임
          + 워크플로우에는 다음이 포함됨
               o 문제에 대한 숙고
               o 공개 테스트에 대한 추론
               o 가능한 솔루션 생성
               o 가능한 솔루션 순위 매기기
               o 합성 테스트 생성
               o 공개 및 합성 테스트에 대한 솔루션 반복
     * 명확한 목표를 가진 작은 작업은 최상의 에이전트 또는 흐름 프롬프트를 만듦
          + 모든 에이전트 프롬프트가 구조화된 출력을 요청할 필요는 없지만, 구조화된 출력은 에이전트의 환경과의 상호 작용을 조정하는 시스템과의 인터페이스에 큰 도움이 됨
     * 시도해 볼 만한 것들
          + 가능한 한 엄격하게 지정된 명시적 계획 단계
               o 미리 정의된 계획 중에서 선택하는 것을 고려할 것
          + 원래 사용자 프롬프트를 에이전트 프롬프트로 다시 작성
               o 이 과정에서 정보 손실이 발생하므로 주의할 것
          + 선형 체인, DAG 및 상태 머신으로서의 에이전트 동작
               o 다양한 종속성과 논리 관계는 서로 다른 규모에 더 적합하거나 덜 적합할 수 있음
               o 다양한 작업 아키텍처에서 성능 최적화를 이끌어낼 수 있을까?
          + 계획 검증
               o 계획에는 최종 결과물이 잘 작동하도록 다른 에이전트의 응답을 평가하는 방법에 대한 지침을 포함할 수 있음
          + 고정된 업스트림 상태로 프롬프트 엔지니어링
               o 에이전트 프롬프트가 이전에 발생할 수 있는 다양한 변형에 대해 평가되는지 확인할 것

    현재로서는 결정론적 워크플로우에 우선순위를 둘 것

     * AI 에이전트는 사용자 요청과 환경에 동적으로 반응할 수 있지만, 이들의 비결정론적 특성은 배포에 어려움을 줌
          + 에이전트가 수행하는 각 단계는 실패할 가능성이 있으며, 오류에서 복구할 가능성은 낮음
          + 따라서 에이전트가 다단계 작업을 성공적으로 완료할 가능성은 단계 수가 증가함에 따라 기하급수적으로 감소함
          + 그 결과 에이전트를 구축하는 팀은 신뢰할 수 있는 에이전트를 배포하는 데 어려움을 겪음
     * 유망한 접근 방식은 결정론적 계획을 생성하고 이를 구조화되고 재현 가능한 방식으로 실행하는 에이전트 시스템을 갖는 것임
          + 첫 번째 단계에서는 상위 수준의 목표나 프롬프트가 주어지면 에이전트가 계획을 생성함
          + 그런 다음 계획이 결정론적으로 실행됨
          + 이를 통해 각 단계를 보다 예측 가능하고 신뢰할 수 있게 만들 수 있음
          + 장점
               o 생성된 계획은 에이전트에 프롬프트를 제공하거나 미세 조정하기 위한 few-shot 샘플로 사용될 수 있음
               o 결정론적 실행은 시스템을 더 신뢰할 수 있게 만들어 테스트와 디버깅이 더 쉬워짐. 또한 실패는 계획의 특정 단계로 추적될 수 있음
               o 생성된 계획은 방향성 비순환 그래프(DAG)로 표현될 수 있으며, 정적 프롬프트에 비해 이해하고 새로운 상황에 적응하기 쉬움
     * 가장 성공적인 에이전트 구축자는 주니어 엔지니어를 관리하는 데 강력한 경험을 가진 사람일 수 있음
          + 계획 생성 과정은 주니어를 지시하고 관리하는 방식과 유사하기 때문
          + 주니어에게 모호하고 개방적인 방향 대신 명확한 목표와 구체적인 계획을 제공하는 것처럼, 에이전트에게도 동일하게 해야 함
     * 결국 신뢰할 수 있고 작동하는 에이전트의 핵심은
          + 보다 구조화되고 결정론적인 접근 방식을 채택하고,
          + 프롬프트를 개선하고 모델을 미세 조정하기 위한 데이터를 수집하는 데서 발견될 가능성이 높음
     * 이것 없이는 때때로 매우 잘 작동할 수 있지만 평균적으로 사용자를 실망시켜 유지력이 낮아지는 에이전트를 구축하게 될 것임

    온도 매개변수 이상의 다양한 출력 얻기

     * LLM의 출력에 다양성이 필요한 작업이 있다고 가정해 보자
          + 사용자가 이전에 구매한 제품 목록을 고려하여 카탈로그에서 구매할 제품을 제안하는 LLM 파이프라인을 작성하고 있을 수 있음
          + 프롬프트를 여러 번 실행할 때 결과 추천이 너무 유사하다는 것을 알 수 있음
          + 따라서 LLM 요청의 Temperature(온도) 매개변수를 높일 수 있음
     * 온도 매개변수를 높이면 LLM 응답이 더 다양해짐
          + 샘플링 시 다음 토큰의 확률 분포가 더 평평해져 일반적으로 선택될 가능성이 낮은 토큰이 더 자주 선택됨
     * 그러나 온도를 높일 때 출력 다양성과 관련된 일부 실패 모드가 발생할 수 있음
          + 예를 들어 카탈로그의 일부 제품이 적합할 수 있지만 LLM에 의해 출력되지 않을 수 있음
          + LLM이 학습 시 배운 내용을 기반으로 프롬프트를 따를 가능성이 높은 경우 동일한 소수의 제품이 출력에서 과대 대표될 수 있음
          + 온도가 너무 높으면 존재하지 않는 제품(또는 무의미한 내용)을 참조하는 출력이 생성될 수 있음
     * 온도를 높인다고 해서 LLM이 예상하는 확률 분포(예: 균일 무작위)에서 출력을 샘플링한다는 보장은 없음
     * 그럼에도 불구하고 출력 다양성을 높이기 위한 다른 트릭이 있음
          + 가장 간단한 방법은 프롬프트 내 요소를 조정하는 것
               o 예를 들어 프롬프트 템플릿에 과거 구매 내역과 같은 항목 목록이 포함된 경우, 이러한 항목을 프롬프트에 삽입할 때마다 순서를 섞으면 상당한 차이를 만들 수 있음
          + 또한 최근 출력의 짧은 목록을 유지하면 중복을 방지하는 데 도움이 됨
               o 추천 제품 예시에서 LLM에 이 최근 목록에서 항목 제안을 피하도록 지시하거나, 최근 제안과 유사한 출력을 거부하고 재샘플링함으로써 응답을 더욱 다양화할 수 있음
          + 또 다른 효과적인 전략은 프롬프트에 사용되는 표현을 다양화하는 것
               o 예를 들어 ""사용자가 정기적으로 사용하는 것을 좋아할 항목 선택"" 또는 ""사용자가 친구에게 추천할 가능성이 높은 제품 선택""과 같은 문구를 통합하면 초점을 이동시켜 추천 제품의 다양성에 영향을 줄 수 있음

    캐싱은 과소평가되고 있음

     * 캐싱은 동일한 입력에 대한 응답을 재계산할 필요성을 제거함으로써 비용을 절감하고 생성 지연 시간을 제거함
          + 또한 응답이 이전에 가드레일링되었다면, 이러한 검증된 응답을 제공하여 유해하거나 부적절한 콘텐츠를 제공할 위험을 줄일 수 있음
     * 캐싱에 대한 간단한 접근 방식은 새로운 기사나 제품 리뷰를 요약하는 경우와 같이 처리 중인 항목에 대해 고유한 ID를 사용하는 것임
          + 요청이 들어오면 캐시에 이미 요약이 존재하는지 확인할 수 있음
               o 그렇다면 즉시 반환할 수 있고, 그렇지 않다면 생성, 가드레일링 및 제공한 다음 향후 요청을 위해 캐시에 저장할 수 있음
     * 좀 더 개방형인 쿼리의 경우 개방형 입력에 대해서도 캐싱을 활용하는 검색 분야의 기술을 차용할 수 있음
          + 자동 완성 및 맞춤법 수정과 같은 기능은 사용자 입력을 정규화하여 캐시 적중률을 높이는 데 도움이 됨

    finetune(파인 튜닝)이 필요한 시점

     * 가장 영리하게 설계된 프롬프트조차도 부족한 일부 작업이 있을 수 있음
          + 예를 들어 상당한 프롬프트 엔지니어링 이후에도 시스템이 여전히 신뢰할 수 있고 고품질의 출력을 반환하는 데서 멀어질 수 있음
          + 이 경우 특정 작업을 위해 모델을 파인튜닝해야 할 수 있음
     * 성공적인 파인 튜닝 사례
          + Honeycomb의 Natural Language Query Assistant
               o 처음에는 ""프로그래밍 매뉴얼""이 문맥 내 학습을 위한 n-shot 예제와 함께 프롬프트에 제공됨
               o 이것이 제대로 작동했지만, 모델을 파인 튜닝하면 도메인 특정 언어의 구문과 규칙에 대한 더 나은 출력을 얻을 수 있음
          + Rechat의 Lucy
               o LLM은 프론트엔드가 올바르게 렌더링하기 위해 구조화된 데이터와 비구조화된 데이터를 결합한 매우 특정한 형식으로 응답을 생성해야 함
               o 파인 튜닝은 일관되게 작동하도록 하는 데 필수적임
     * 파인튜닝이 효과적일 수 있지만 상당한 비용이 수반됨
          + 파인 튜닝 데이터에 주석을 달고, 모델을 파인 튜닝 및 평가한 다음, 결국 자체 호스팅해야 함
          + 따라서 더 높은 초기 비용이 그만한 가치가 있는지 고려해야 함
     * 프롬프팅으로 90%까지 도달할 수 있다면 파인 튜닝에 투자할 가치가 없을 수 있음
          + 그러나 파인 튜닝하기로 결정한다면 인간이 주석을 단 데이터 수집 비용을 줄이기 위해 합성 데이터에 대해 생성 및 파인 튜닝하거나 오픈 소스 데이터를 부트스트랩할 수 있음

  전술 4. 평가 및 모니터링

     * LLM 평가는 지뢰밭이 될 수 있음
          + LLM의 입력과 출력은 임의의 텍스트이며, 설정하는 작업도 다양함
          + 그럼에도 불구하고 엄격하고 신중한 평가는 중요함
               o OpenAI의 기술 리더들이 평가에 참여하고 개별 평가에 대해 피드백을 제공하는 것이 우연이 아님
     * LLM 애플리케이션 평가에는 다양한 정의와 축소가 필요함
          + 단순히 단위 테스트이거나, 관찰 가능성과 더 유사하거나, 단순히 데이터 과학일 수 있음
          + 우리는 이러한 모든 관점이 유용하다는 것을 발견함
     * 이번 섹션에서는 평가 및 모니터링 파이프라인 구축에서 중요한 사항에 대해 배운 교훈을 제공함

    실제 입출력 샘플에서 몇 가지 assertion 기반 단위 테스트 생성

     * 프로덕션에서 입력과 출력의 샘플로 구성된 단위 테스트(즉, assertion)를 만들고, 최소 3가지 기준에 따라 출력에 대한 기대치를 설정
          + 3가지 기준이 임의적으로 보일 수 있지만, 시작하기에 실용적인 수임
               o 더 적으면 작업이 충분히 정의되지 않았거나 범용 챗봇과 같이 너무 개방적일 수 있음
          + 이러한 단위 테스트 또는 assertion은 프롬프트 편집, RAG를 통한 새 컨텍스트 추가 또는 기타 수정과 같은 파이프라인의 변경 사항에 의해 트리거되어야 함
     * 모든 응답에 포함하거나 제외할 구문이나 아이디어를 지정하는 assertion부터 시작하는 것을 고려
          + 또한 단어, 항목 또는 문장 수가 범위 내에 있는지 확인하는 검사를 고려
          + 다른 종류의 생성의 경우 assertion이 다르게 보일 수 있음
               o 예를 들어 코드 생성을 평가하기 위한 강력한 방법인 실행 평가에서는 생성된 코드를 실행하고 런타임 상태가 사용자 요청에 충분한지 확인
     * 예를 들어 사용자가 foo라는 새 함수를 요청하면 에이전트의 생성 코드를 실행한 후 foo를 호출할 수 있어야 함
     * 실행 평가의 한 가지 과제는 에이전트 코드가 종종 대상 코드와 약간 다른 형태로 런타임을 남긴다는 것
          + 어떤 타당한 답변이라도 만족시킬 수 있는 가장 약한 가정으로 assertion을 ""완화""하는 것이 효과적일 수 있음
     * 고객을 위해 의도한 대로 제품을 사용하는 것(즉, ""도그푸딩"")은 실제 데이터에서의 장애 모드에 대한 통찰력을 제공할 수 있음
          + 이 접근 방식은 잠재적 약점을 식별하는 데 도움이 될 뿐만 아니라 평가로 변환할 수 있는 유용한 프로덕션 샘플 소스도 제공함

    LLM-as-Judge는 (어느 정도) 작동할 수 있지만 만능은 아님

     * LLM-as-Judge는 강력한 LLM을 사용하여 다른 LLM의 출력을 평가하는 방식으로, 일부 사람들에게는 회의적으로 받아들여짐
     * 그럼에도 불구하고 잘 구현되면 LLM-as-Judge는 인간의 판단과 상당한 상관관계를 달성하고, 적어도 새로운 프롬프트나 기술이 어떻게 수행될 수 있는지에 대한 사전 정보를 구축하는 데 도움이 될 수 있음
          + 특히 쌍별 비교(예: 대조군 vs 처리군)를 할 때 LLM-as-Judge는 일반적으로 방향을 올바르게 잡지만 승/패의 크기는 노이즈가 있을 수 있음
     * LLM-as-Judge를 최대한 활용하기 위한 제안
          + 쌍별 비교 사용
               o LLM에게 단일 출력을 Likert 척도로 평가하도록 요청하는 대신 두 가지 옵션을 제시하고 더 나은 것을 선택하도록 요청
               o 이는 더 안정적인 결과로 이어지는 경향이 있음
          + 위치 편향 제어
               o 제시된 옵션의 순서가 LLM의 결정을 편향시킬 수 있음
               o 이를 완화하려면 각 쌍별 비교를 두 번 수행하고 각 시간에 쌍의 순서를 바꿈
               o 스와핑 후에는 올바른 옵션에 승리를 귀속시켜야 함
          + 동점 허용
               o 경우에 따라 두 옵션이 똑같이 좋을 수 있음
               o 따라서 LLM이 임의로 승자를 선택할 필요가 없도록 동점을 선언하도록 허용
          + Chain-of-Thought 사용
               o 최종 선호도를 제시하기 전에 LLM에게 그 결정을 설명하도록 요청하면 평가 신뢰성이 향상될 수 있음
               o 보너스로, 이를 통해 더 약하지만 빠른 LLM을 사용하면서도 유사한 결과를 얻을 수 있음
               o 파이프라인의 이 부분이 자주 배치 모드에 있기 때문에 CoT로 인한 추가 지연은 문제가 되지 않음
          + 응답 길이 제어
               o LLM은 더 긴 응답으로 치우치는 경향이 있음
               o 이를 완화하려면 응답 쌍의 길이가 비슷한지 확인
     * LLM-as-Judge의 특히 강력한 적용은 새로운 프롬프트 전략을 회귀에 대해 확인하는 것
          + 프로덕션 결과 모음을 추적한 경우 때로는 새로운 프롬프트 전략으로 해당 프로덕션 예제를 다시 실행하고 LLM-as-Judge를 사용하여 새 전략이 어디에서 어려움을 겪을 수 있는지 신속하게 평가할 수 있음
     * LLM-as-Judge의 간단하지만 효과적인 접근 방식의 예시
          + 단순히 LLM 응답, 판사의 비평(즉, CoT) 및 최종 결과를 기록
          + 그런 다음 이해관계자와 검토하여 개선 영역을 식별
          + 3번의 반복을 통해 인간과 LLM의 일치도는 68%에서 94%로 향상됨
     * 그러나 LLM-as-Judge는 만능이 아님
          + 가장 강력한 모델조차도 신뢰할 수 있게 평가하지 못하는 미묘한 언어적 측면이 있음
     * 또한 기존의 분류기와 보상 모델이 LLM-as-Judge보다 더 높은 정확도를 달성할 수 있으며 비용과 지연 시간이 더 적다는 것을 발견함
          + 코드 생성의 경우 LLM-as-Judge는 실행 평가와 같은 보다 직접적인 평가 전략보다 약할 수 있음

    생성 결과 평가를 위한 ""인턴 테스트""

     * 생성 결과를 평가할 때 다음과 같은 ""인턴 테스트""를 사용하는 것이 좋음
          + 컨텍스트를 포함하여 언어 모델에 대한 정확한 입력을 가져와 관련 전공의 평균적인 대학생에게 과제로 제시한다면 그들이 성공할 수 있을까?
          + 얼마나 걸릴까?
     * 답변이 아니오인 경우
          + LLM에 필요한 지식이 부족하기 때문이라면 컨텍스트를 풍부하게 만드는 방법을 고려
          + 컨텍스트를 개선해도 해결할 수 없다면 현대 LLM에는 너무 어려운 작업일 수 있음
     * 답변이 예이지만 시간이 걸리는 경우
          + 작업의 복잡성을 줄이려고 시도해볼 수 있음
               o 분해 가능한가?
               o 작업의 어떤 측면을 더 템플릿화할 수 있는가?
     * 답변이 예이고 빠르게 할 수 있는 경우
          + 데이터를 파고들 때
               o 모델이 잘못하고 있는 것은 무엇인가?
               o 실패의 패턴을 찾을 수 있는가?
          + 모델에게 응답 전이나 후에 스스로 설명하도록 요청해보기

    특정 평가에 지나치게 중점을 두면 전반적인 성능이 저하될 수 있음

     ""측정 지표가 목표가 되면 더 이상 좋은 측정 지표가 아니게 된다."" - Goodhart의 법칙

     * 이에 대한 예시로 Needle-in-a-Haystack(NIAH) 평가가 있음
          + 원래 평가는 컨텍스트 크기가 커짐에 따라 모델 리콜을 정량화하고 바늘 위치에 따라 리콜이 어떻게 영향을 받는지 확인하는 데 도움이 됨
          + 그러나 너무 지나치게 강조되어 Gemini 1.5 보고서의 Figure 1로 소개됨
          + 이 평가에는 폴 그레이엄의 에세이를 반복하는 긴 문서에 특정 구문(""The special magic {city} number is: {number}"")을 삽입한 다음 모델에 매직 넘버를 상기시키는 작업이 포함됨
     * 일부 모델은 거의 완벽한 리콜을 달성하지만 NIAH가 실제 애플리케이션에 필요한 추론 및 리콜 능력을 진정으로 반영하는지는 의문
     * 보다 실용적인 시나리오 고려
          + 1시간 분량의 회의 녹취록이 주어지면 LLM이 주요 결정과 다음 단계를 요약하고 각 항목을 관련 담당자에게 올바르게 귀속시킬 수 있는가?
          + 이 작업은 단순한 암기를 넘어 복잡한 토론을 파악하고 관련 정보를 식별하며 요약을 종합하는 능력도 고려하므로 더 현실적임
     * 실용적인 NIAH 평가의 예시
          + 의사-환자 화상 통화 녹취록을 사용하여 LLM에 환자의 약물에 대해 질문
          + 에스프레소에 담근 대추, 레몬, 염소 치즈 등 피자 토핑에 필요한 무작위 재료에 대한 구문을 삽입하는 등 보다 도전적인 NIAH도 포함
          + 약물 작업에서 리콜은 약 80%, 피자 작업에서는 30%였음
     * NIAH 평가를 지나치게 강조하면 추출 및 요약 작업의 성능이 낮아질 수 있음
          + 이러한 LLM은 모든 문장에 주의를 기울이도록 미세 조정되어 있기 때문에 관련 없는 세부 정보와 주의 산만 요소를 중요한 것으로 취급하기 시작할 수 있음
          + 그러면 최종 출력에 포함될 수 있음(포함되지 말아야 할 때도!)
     * 이는 다른 평가 및 사용 사례에도 적용될 수 있음
          + 예를 들어 요약
               o 사실적 일관성을 강조하면 덜 구체적이고(따라서 사실과 일치하지 않을 가능성이 낮음) 관련성이 떨어질 수 있는 요약이 생성될 수 있음
               o 반대로 글쓰기 스타일과 웅변을 강조하면 사실적 불일치를 초래할 수 있는 더 화려한 마케팅 유형의 언어가 생성될 수 있음

    주석 달기를 이진 작업 또는 쌍대(pairwise) 비교로 단순화

     * 모델 출력에 대해 개방형 피드백을 제공하거나 Likert 척도로 평가하는 것은 인지적으로 까다로움
          + 그 결과 수집된 데이터는 인간 평가자 간의 변동성으로 인해 더 노이즈가 많아지고 따라서 덜 유용해짐
     * 보다 효과적인 접근 방식은 작업을 단순화하고 주석 작성자의 인지적 부담을 줄이는 것
          + 잘 작동하는 두 가지 작업은 이진 분류와 쌍대 비교
     * 이진 분류에서 주석 작성자는 모델의 출력에 대해 간단한 예/아니오 판단을 내리도록 요청받음
          + 생성된 요약이 소스 문서와 사실적으로 일치하는지, 제안된 응답이 관련이 있는지, 유해성이 포함되어 있는지 등을 물을 수 있음
          + Likert 척도에 비해 이진 결정은 더 정확하고, 평가자 간 일관성이 더 높으며, 처리량이 더 높음
          + Doordash가 일련의 예/아니오 질문을 통해 메뉴 항목에 태그를 붙이기 위해 레이블링 대기열을 설정한 방식
     * 쌍대 비교(Pairewise Comparison)에서 주석 작성자는 한 쌍의 모델 응답을 받고 어떤 것이 더 나은지 물음
          + 인간이 A 또는 B에 개별적으로 점수를 매기는 것보다 ""A가 B보다 낫다""라고 말하는 것이 더 쉽기 때문에 이는 더 빠르고 신뢰할 수 있는 주석으로 이어짐(Likert 척도보다)
     * Llama2 밋업에서 Llama2 논문의 저자 중 한 명인 Thomas Scialom은 쌍대 비교가 작성된 응답과 같은 지도 학습 미세 조정 데이터를 수집하는 것보다 더 빠르고 저렴하다는 것을 확인함
          + 전자의 비용은 단위당 $3.5이고 후자의 비용은 단위당 $25

    (참조가 필요 없는, Reference-free) 평가와 가드레일은 상호 교환적으로 사용될 수 있음

     * 가드레일은 부적절하거나 유해한 콘텐츠를 잡는 데 도움이 되는 반면, 평가는 모델 출력의 품질과 정확성을 측정하는 데 도움이 됨
          + 참조가 필요 없는 평가의 경우 동전의 양면으로 볼 수 있음
               o 참조가 필요 없는 평가는 인간이 작성한 답변과 같은 ""golden"" reference에 의존하지 않고 입력 프롬프트와 모델의 응답만으로 출력 품질을 평가할 수 있는 평가임
     * 참조가 필요 없는 평가 예시 : 요약 평가
          + 요약의 사실적 일관성과 관련성을 평가하기 위해 입력 문서만 고려하면 됨
          + 요약이 이러한 지표에서 점수가 낮으면 사용자에게 표시하지 않도록 선택할 수 있어 평가를 가드레일로 효과적으로 사용할 수 있음
     * 참조가 필요 없는 ""번역"" 평가 :
          + 인간이 번역한 참조 없이도 번역의 품질을 평가할 수 있어 다시 가드레일로 사용할 수 있음

    LLM은 그러면 안 될 때도 출력을 반환함

     * LLM 작업 시 주요 과제는 LLM이 그러면 안 될 때도 종종 출력을 생성한다는 것
          + 이는 무해하지만 무의미한 응답이나 유해성 또는 위험한 내용과 같은 더 심각한 결함으로 이어질 수 있음
          + 예를 들어 문서에서 특정 속성이나 메타데이터를 추출하라는 요청을 받으면 LLM은 해당 값이 실제로 존재하지 않을 때도 자신 있게 값을 반환할 수 있음
          + 또는 컨텍스트에 영어 이외의 문서를 제공했기 때문에 모델이 영어 이외의 언어로 응답할 수도 있음
     * LLM에 ""해당 없음"" 또는 ""알 수 없음"" 응답을 반환하도록 프롬프트를 제공할 수 있지만 완벽하지는 않음
          + 로그 확률을 사용할 수 있는 경우에도 출력 품질의 좋지 않은 지표임
               o 로그 확률은 출력에 토큰이 나타날 가능성을 나타내지만 생성된 텍스트의 정확성을 반영하지는 않음
          + 오히려 쿼리에 응답하고 일관된 응답을 생성하도록 훈련된 명령어 튜닝 모델의 경우 로그 확률이 잘 보정되지 않을 수 있음
               o 따라서 높은 로그 확률은 출력이 유창하고 일관성이 있음을 나타낼 수 있지만 정확하거나 관련이 있다는 의미는 아님
     * 주의 깊은 프롬프트 엔지니어링은 어느 정도 도움이 될 수 있지만, 원치 않는 출력을 감지하고 필터링/재생성하는 강력한 가드레일로 보완해야 함
          + 예를 들어 OpenAI는 혐오 발언, 자해 또는 성적 출력과 같은 안전하지 않은 응답을 식별할 수 있는 콘텐츠 조정 API를 제공함
          + 마찬가지로 개인 식별 정보(PII)를 감지하기 위한 수많은 패키지가 있음
     * 가드레일의 한 가지 이점은 사용 사례에 대해 크게 무관하며 따라서 특정 언어로 된 모든 출력에 광범위하게 적용될 수 있다는 것
          + 또한 정밀한 검색을 통해 관련 문서가 없으면 시스템이 결정적으로 ""모르겠습니다""라고 응답할 수 있음
     * LLM은 출력이 예상될 때 출력을 생성하지 못할 수 있음
          + API 제공업체의 긴 지연 시간과 같은 간단한 문제부터 콘텐츠 조정 필터에 의해 출력이 차단되는 것과 같은 더 복잡한 문제에 이르기까지 다양한 이유로 발생할 수 있음
     * 따라서 디버깅 및 모니터링을 위해 입력과 (잠재적으로 출력 부족을) 일관되게 기록하는 것이 중요함

    환각(Hallucination)은 끈질긴 문제임

     * 콘텐츠 안전성이나 PII 결함은 많은 주의를 받아 거의 발생하지 않는 반면, 사실적 불일치는 끈질기게 지속되며 감지하기가 더 어려움
          + 더 흔하게 발생하며 기준 발생률은 5~10%이고, LLM 제공업체로부터 배운 바에 따르면 요약과 같은 간단한 작업에서도 2% 미만으로 낮추는 것이 어려울 수 있음
     * 이를 해결하기 위해 프롬프트 엔지니어링(생성 업스트림)과 사실적 불일치 가드레일(생성 다운스트림)을 결합할 수 있음
          + 프롬프트 엔지니어링의 경우 CoT와 같은 기술은 LLM이 최종 출력을 반환하기 전에 추론을 설명하도록 함으로써 환각을 줄이는 데 도움이 됨
          + 그런 다음 사실적 불일치 가드레일을 적용하여 요약의 사실성을 평가하고 환각을 필터링하거나 재생성할 수 있음
     * 경우에 따라 환각은 결정론적으로 감지될 수 있음
          + RAG 검색의 리소스를 사용할 때 출력이 구조화되어 있고 리소스가 무엇인지 식별한다면 입력 컨텍스트에서 소싱되었는지 수동으로 확인할 수 있어야 함

[운영: 일상(Day-to-Day) 및 조직 문제 ]

  운영 1. 데이터

     * 재료의 품질이 요리의 맛을 결정하듯이 입력 데이터의 품질은 기계 학습 시스템의 성능을 제약함
     * 또한 출력 데이터는 제품이 작동하는지 여부를 알 수 있는 유일한 방법임
     * 모든 저자는 데이터 분포(모드, 엣지 케이스, 모델의 한계)를 더 잘 이해하기 위해 매주 몇 시간 동안 입력과 출력을 면밀히 살펴봄

    개발-프로덕션 편향 확인

     * 전통적인 기계 학습 파이프라인에서 오류의 일반적인 원인은 훈련-서비스 편향임
          + 이는 훈련에 사용되는 데이터가 모델이 프로덕션에서 접하는 데이터와 다를 때 발생함
     * 훈련이나 미세 조정 없이 LLM을 사용할 수 있으므로 훈련 세트는 없지만 개발-프로덕션 데이터 편향이라는 유사한 문제가 발생함
          + 기본적으로 개발 중에 시스템을 테스트하는 데이터는 시스템이 프로덕션에서 직면할 데이터를 반영해야 함
               o 그렇지 않으면 프로덕션 정확도가 저하될 수 있음
     * LLM 개발-프로덕션 편향은 구조적 편향과 내용 기반 편향의 두 가지 유형으로 분류될 수 있음
          + 구조적 편향에는 목록형 값을 가진 JSON 딕셔너리와 JSON 목록 간의 차이, 일관되지 않은 케이싱, 오타나 문장 조각과 같은 오류 등 형식 불일치와 같은 문제가 포함됨
               o 이러한 오류는 다양한 LLM이 특정 데이터 형식으로 훈련되고 프롬프트가 사소한 변경에 매우 민감할 수 있기 때문에 예측할 수 없는 모델 성능으로 이어질 수 있음
          + 내용 기반 또는 ""의미론적"" 편향은 데이터의 의미나 맥락의 차이를 나타냄
     * 전통적인 ML과 마찬가지로 LLM 입출력 쌍 간의 편향을 주기적으로 측정하는 것이 유용함
          + 입력 및 출력 길이 또는 특정 형식 요구 사항(예: JSON 또는 XML)과 같은 단순 메트릭은 변경 사항을 추적하는 간단한 방법임
     * 보다 ""고급"" 편향 감지를 위해 입출력 쌍의 임베딩을 클러스터링하여 사용자가 이전에 모델에 노출되지 않은 영역을 탐색하고 있음을 나타낼 수 있는 사용자가 논의하는 주제의 변화와 같은 의미론적 편향을 감지하는 것을 고려할 것
     * 프롬프트 엔지니어링과 같은 변경 사항을 테스트할 때는 홀드아웃 데이터 세트가 최신 상태이고 가장 최근 유형의 사용자 상호 작용을 반영하는지 확인
          + 예를 들어 프로덕션 입력에서 오타가 흔하다면 홀드아웃 데이터에도 있어야 함
     * 단순히 숫자로 편향을 측정하는 것 이상으로 출력에 대해 정성적 평가를 수행하는 것이 유익함
          + 모델의 출력을 정기적으로 검토하는 것(속어로 ""바이브 체크""라고 알려진 관행)은 결과가 기대에 부합하고 사용자 요구에 계속 관련성이 있는지 확인해줌
     * 편향 확인에 비결정론을 통합하는 것도 유용함
          + 테스트 데이터 세트의 각 입력에 대해 파이프라인을 여러 번 실행하고 모든 출력을 분석함으로써 가끔만 발생할 수 있는 이상 현상을 포착할 가능성이 높아짐

    매일 LLM 입출력 샘플 확인하기

     * LLM은 역동적이고 끊임없이 진화하고 있음
          + 인상적인 제로샷 능력과 종종 기분 좋은 출력에도 불구하고 LLM의 실패 모드는 매우 예측할 수 없음
     * 맞춤 작업의 경우 LLM의 성능에 대한 직관적인 이해를 개발하기 위해 데이터 샘플을 정기적으로 검토하는 것이 필수적임
          + 프로덕션의 입출력 쌍은 LLM 애플리케이션의 ""실제 사물, 실제 장소""(genchi genbutsu)이며 대체할 수 없음
     * 최근 연구에 따르면 개발자가 더 많은 데이터와 상호 작용할수록 ""좋은"" 출력과 ""나쁜"" 출력에 대한 인식이 변한다고 강조함(즉, 기준 편향)
          + 개발자는 LLM 출력을 평가하기 위한 일부 기준을 사전에 제시할 수 있지만, 이러한 사전 정의된 기준은 종종 불완전함
     * 예를 들어 개발 과정에서 좋은 응답 확률을 높이고 나쁜 응답 확률을 낮추기 위해 프롬프트를 업데이트할 수 있음
          + 이러한 평가, 재평가 및 기준 업데이트의 반복 프로세스는 출력을 직접 관찰하지 않고는 LLM 동작이나 인간의 선호도를 예측하기 어렵기 때문에 필요함
     * 이를 효과적으로 관리하기 위해 LLM 입력과 출력을 기록해야 함
          + 매일 이러한 로그 샘플을 검사하면 새로운 패턴이나 실패 모드를 신속하게 식별하고 적응할 수 있음
          + 새로운 문제를 발견하면 즉시 그것에 대한 assertion 또는 eval을 작성할 수 있음
     * 마찬가지로 실패 모드 정의에 대한 모든 업데이트는 평가 기준에 반영되어야 함
          + 이러한 ""바이브 체크""는 잘못된 출력의 신호이며, 코드와 assertion은 이를 운영함
     * 마지막으로 이러한 태도는 Socialized되어야 함
          + 예를 들어 온콜 로테이션에 입력 및 출력 검토 또는 주석 달기를 추가하는 것

  운영 2. 모델과 함께 일하기

     * LLM API를 사용하면 소수의 제공업체의 지능에 의존할 수 있음
          + 이는 좋은 점이지만 이러한 종속성은 성능, 지연 시간, 처리량 및 비용 측면에서 절충점을 수반함
     * 또한 지난 1년 동안 거의 매월 더 새롭고 더 나은 모델이 출시됨에 따라 오래된 모델을 폐기하고 새로운 모델로 마이그레이션할 때 제품을 업데이트할 준비가 되어 있어야 함
          + 이 섹션에서는 완전히 제어할 수 없는 기술, 즉 모델을 자체 호스팅하고 관리할 수 없는 기술을 사용할 때 얻은 교훈을 공유함
     * 실제 사용 사례 대부분의 경우 LLM의 출력은 일종의 기계 판독 가능 형식을 통해 다운스트림 애플리케이션에서 소비될 것임
          + 예를 들어 부동산 CRM인 ReChat은 프론트엔드에서 위젯을 렌더링하기 위해 구조화된 응답이 필요함
          + 유사하게 제품 전략 아이디어 생성 도구인 Boba는 제목, 요약, 타당성 점수 및 시간 범위 필드가 있는 구조화된 출력이 필요함
          + 마지막으로 LinkedIn은 LLM을 제한하여 YAML을 생성하는 방법을 공유했는데, 이는 사용할 기술을 결정하고 기술을 호출하는 매개변수를 제공하는 데 사용됨
     * 이 애플리케이션 패턴은 Postel의 법칙의 극단적인 버전임
          + 수락하는 것(임의의 자연어)에 자유롭고 보내는 것(유형화된 기계 판독 가능 개체)에 보수적이어야 함
          + 따라서 이것이 매우 내구성이 있을 것으로 기대함
     * 현재 Instructor와 Outlines는 LLM에서 구조화된 출력을 이끌어내기 위한 사실상의 표준임
          + LLM API(예: Anthropic, OpenAI)를 사용하는 경우 Instructor를 사용하고, 자체 호스팅 모델(예: Huggingface)을 사용하는 경우 Outlines를 사용할 것

    모델 간 프롬프트 마이그레이션은 고통스러운 일임

     * 때로는 주의 깊게 만든 프롬프트가 한 모델에서는 훌륭하게 작동하지만 다른 모델에서는 제대로 작동하지 않을 수 있음
          + 이는 다양한 모델 제공업체 간에 전환할 때뿐만 아니라 동일한 모델의 버전 간에 업그레이드할 때도 발생할 수 있음
     * 예를 들어 Voiceflow는 gpt-3.5-turbo-0301에서 gpt-3.5-turbo-1106으로 마이그레이션하면 의도 분류 작업에서 10%의 성능 저하가 발생한다는 것을 발견함
          + (다행히도 그들은 평가를 가지고 있었음!)
     * 유사하게 GoDaddy는 1106 버전으로 업그레이드하면 gpt-3.5-turbo와 gpt-4 사이의 성능 격차가 좁혀지는 긍정적인 방향의 추세를 관찰함
          + (또는 당신이 반쯤 찬 유리잔을 보는 사람이라면 새로운 업그레이드로 gpt-4의 리드가 줄어든 것에 실망할 수도 있음)
     * 따라서 모델 간에 프롬프트를 마이그레이션해야 하는 경우 단순히 API 엔드포인트를 교체하는 것보다 더 많은 시간이 걸릴 것으로 예상해야 함
          + 동일한 프롬프트를 연결하면 유사하거나 더 나은 결과로 이어질 것이라고 가정하지 말 것
     * 또한 신뢰할 수 있고 자동화된 평가는 마이그레이션 전후의 작업 성능을 측정하는 데 도움이 되며 수동 검증에 필요한 노력을 줄여줌

    모델 버전 관리 및 고정

     * 모든 기계 학습 파이프라인에서 ""무엇이든 변경하면 모든 것이 변경됨""
          + 이는 우리 자신이 훈련하지 않고 우리 모르게 변경될 수 있는 대규모 언어 모델(LLM)과 같은 구성 요소에 의존할 때 특히 관련이 있음
     * 다행히도 많은 모델 제공업체는 특정 모델 버전(예: gpt-4-turbo-1106)을 ""고정""할 수 있는 옵션을 제공함
          + 이를 통해 모델 가중치의 특정 버전을 사용하여 변경되지 않도록 할 수 있음
     * 프로덕션에서 모델 버전을 고정하면 모델 동작의 예기치 않은 변경을 방지할 수 있음
          + 이는 모델이 교체될 때 발생할 수 있는 지나치게 장황한 출력이나 기타 예상치 못한 실패 모드와 같은 문제에 대한 고객 불만을 피하는 데 도움이 될 수 있음
     * 또한 프로덕션 설정을 미러링하지만 최신 모델 버전을 사용하는 ""섀도우 파이프라인""을 유지하는 것을 고려해 볼 것
          + 이를 통해 새로운 릴리스로 안전한 실험과 테스트를 수행할 수 있음
     * 이러한 새로운 모델에서 출력의 안정성과 품질을 검증한 후에는 프로덕션 환경에서 모델 버전을 자신 있게 업데이트할 수 있음

    작업을 완료할 수 있는 가장 작은 모델 선택하기

     * 새로운 애플리케이션에서 작업할 때 사용 가능한 가장 크고 강력한 모델을 사용하고 싶은 유혹이 있음
          + 그러나 일단 작업이 기술적으로 가능하다는 것이 확인되면 더 작은 모델로 유사한 결과를 얻을 수 있는지 실험해 볼 가치가 있음
     * 작은 모델의 장점은 지연 시간과 비용이 낮다는 것
          + 더 약할 수 있지만 Chain-of-Thought, n-shot 프롬프트, 문맥 내 학습과 같은 기술은 작은 모델이 자신의 역량 이상으로 성장하는 데 도움이 될 수 있음
     * LLM API 이상으로 특정 작업에 대한 미세 조정도 성능 향상에 도움이 될 수 있음
     * 종합하면 작은 모델을 사용하여 신중하게 설계된 워크플로우는 더 빠르고 저렴하면서도 단일 대형 모델의 출력 품질과 일치하거나 심지어 능가할 수 있음
          + 예를 들어 이 트윗은 Haiku + 10-shot 프롬프트가 제로샷 Opus와 GPT-4를 능가하는 방법에 대한 일화를 공유함
     * 장기적으로 출력 품질, 지연 시간 및 비용의 최적 균형으로 작은 모델을 사용한 흐름 엔지니어링의 더 많은 사례가 나타날 것으로 예상됨
     * 또 다른 예로 겸손한 분류 작업을 들 수 있음
          + DistilBERT(6,700만 개 매개변수)와 같은 경량 모델은 놀라울 정도로 강력한 기준선임
          + 4억 개 매개변수의 DistilBART는 또 다른 훌륭한 옵션
               o 오픈 소스 데이터에서 미세 조정되면 지연 시간과 비용의 5% 미만으로 대부분의 LLM을 능가하는 0.84의 ROC-AUC로 환각을 식별할 수 있음
     * 요점은 작은 모델을 간과하지 말아야 한다는 것
          + 모든 문제에 거대한 모델을 적용하기는 쉽지만 약간의 창의성과 실험으로 우리는 종종 더 효율적인 솔루션을 찾을 수 있음

  운영 3. 제품

     * 새로운 기술은 새로운 가능성을 제공하지만 훌륭한 제품을 만드는 원칙은 영원함
          + 따라서 처음으로 새로운 문제를 해결하더라도 제품 설계에 대해 바퀴를 다시 발명할 필요는 없음
     * 견고한 제품 기본에 LLM 애플리케이션 개발을 기반으로 함으로써 얻을 수 있는 것이 많음
          + 이를 통해 우리가 서비스하는 사람들에게 실제 가치를 제공할 수 있음

    초기부터 디자인을 involve하기

     * 디자이너를 두면 제품을 어떻게 구축하고 사용자에게 제시할 수 있는지 이해하고 깊이 생각하게 됨
          + 때로는 디자이너를 사물을 예쁘게 만드는 사람으로 고정 관념을 가지기도 함
          + 그러나 사용자 인터페이스뿐만 아니라 기존 규칙과 패러다임을 깨더라도 사용자 경험을 어떻게 개선할 수 있는지 재고함
     * 디자이너는 사용자의 요구 사항을 다양한 형태로 재구성하는 데 특히 재능이 있음
          + 이러한 형태 중 일부는 다른 형태보다 해결하기가 더 쉬우므로 AI 솔루션에 더 많거나 적은 기회를 제공할 수 있음
     * 다른 많은 제품과 마찬가지로 AI 제품 구축은 제품을 구동하는 기술이 아니라 수행할 작업을 중심으로 이루어져야 함
     * 다음과 같은 질문을 스스로에게 묻는 데 초점을 맞출 것
          + ""사용자가 이 제품에 요청하는 작업은 무엇인가? 그 작업이 챗봇이 잘할 만한 일인가? 자동 완성은 어떤가? 어쩌면 다른 것일 수도 있다!""
     * 기존 설계 패턴과 그것이 수행할 작업과 어떤 관련이 있는지 고려할 것
          + 이것들은 디자이너가 팀의 역량에 더하는 귀중한 자산임

    휴먼 인 더 루프를 위한 UX 설계

     * 품질 좋은 주석을 얻는 한 가지 방법은 사용자 경험(UX)에 Human-in-the-Loop(HITL)를 통합하는 것
          + 사용자가 쉽게 피드백과 수정 사항을 제공할 수 있도록 하면 즉각적인 출력을 개선하고 모델 개선에 유용한 데이터를 수집할 수 있음
     * 사용자가 제품을 업로드하고 분류하는 전자상거래 플랫폼을 상상해 보자
          + UX를 설계하는 방법에는 여러 가지가 있음
              1. 사용자가 수동으로 올바른 제품 범주를 선택하고, LLM이 주기적으로 새 제품을 확인하고 백엔드에서 잘못된 분류를 수정
              2. 사용자는 범주를 전혀 선택하지 않고, LLM이 주기적으로 백엔드에서 제품을 분류(잠재적 오류 포함)
              3. LLM이 실시간으로 제품 범주를 제안하고, 사용자가 필요에 따라 검증 및 업데이트 가능
     * 세 가지 접근 방식 모두 LLM을 포함하지만 매우 다른 UX를 제공함
          + 첫 번째 접근 방식은 초기 부담을 사용자에게 지우고 LLM이 사후 처리 검사 역할을 함
          + 두 번째 접근 방식은 사용자의 노력이 전혀 필요하지 않지만 투명성이나 제어권을 제공하지 않음
          + 세 번째 접근 방식이 적절한 균형을 유지함
               o LLM이 사전에 범주를 제안함으로써 사용자의 인지 부하를 줄이고 제품을 분류하기 위해 우리의 분류법을 배울 필요가 없음
               o 동시에 사용자가 제안을 검토하고 편집할 수 있도록 함으로써 제품 분류 방식에 대한 최종 결정권을 사용자의 손에 단단히 쥐어줌
          + 보너스로 세 번째 접근 방식은 모델 개선을 위한 자연스러운 피드백 루프를 만듦
               o 좋은 제안은 수락되고(긍정 레이블) 나쁜 제안은 업데이트됨(부정 후 긍정 레이블)
     * 제안, 사용자 검증 및 데이터 수집의 이 패턴은 여러 애플리케이션에서 일반적으로 볼 수 있음
          + 코딩 어시스턴트: 사용자가 제안을 수락(강한 긍정), 수락 및 조정(긍정) 또는 무시(부정)할 수 있음
          + Midjourney: 사용자가 이미지를 업스케일하고 다운로드(강한 긍정)하거나, 이미지를 변경(긍정)하거나, 새로운 이미지 세트를 생성(부정)할 수 있음
          + 챗봇: 사용자가 응답에 대해 좋아요(긍정) 또는 싫어요(부정)를 제공하거나, 응답이 정말 나쁜 경우 응답을 다시 생성(강한 부정)하도록 선택할 수 있음
     * 피드백은 명시적이거나 암시적일 수 있음
          + 명시적 피드백은 사용자가 제품의 요청에 응답하여 제공하는 정보
          + 암시적 피드백은 사용자가 의도적으로 피드백을 제공할 필요 없이 사용자 상호 작용에서 배우는 정보
     * 코딩 어시스턴트와 Midjourney는 암시적 피드백의 예이고 좋아요와 싫어요는 명시적 피드백
          + 코딩 어시스턴트와 Midjourney처럼 UX를 잘 설계하면 제품과 모델을 개선하기 위한 많은 암시적 피드백을 수집할 수 있음

    무자비하게 요구사항 계층(Hierarchy)의 우선순위 지정하기

     * 데모를 프로덕션에 배치하는 것에 대해 생각할 때, 다음에 대한 요구 사항을 고려해야 함
          + 신뢰성: 99.9% 가동 시간, 구조화된 출력 준수
          + 무해성: 공격적이거나 NSFW 또는 기타 유해한 콘텐츠를 생성하지 않음
          + 사실적 일관성: 제공된 맥락에 충실하고 사실을 왜곡하지 않음
          + 유용성: 사용자의 요구와 요청에 관련됨
          + 확장성: 지연 시간 SLA, 지원되는 처리량
          + 비용: 예산이 무제한이 아니기 때문
          + 기타: 보안, 개인 정보 보호, 공정성, GDPR, DMA 등
     * 이러한 모든 요구 사항을 한 번에 해결하려고 하면 아무것도 출시할 수 없음
          + 따라서 우선순위를 정해야 함. 무자비하게.
     * 이는 제품이 작동하지 않거나 실행 가능하지 않을 수 있는 타협할 수 없는 사항(예: 신뢰성, 무해성)이 무엇인지 명확히 하는 것을 의미함
          + MVP(Minimum Lovable Product) 제품을 식별하는 것이 중요함
     * 첫 번째 버전이 완벽하지 않을 것이라는 점을 받아들이고 출시하고 반복해야 함

    사용 사례에 따른 위험 감수 수준 조정

     * 언어 모델과 애플리케이션의 검토 수준을 결정할 때는 사용 사례와 대상을 고려해야 함
          + 의료 또는 금융 조언을 제공하는 고객 대면 챗봇의 경우 안전성과 정확성에 대해 매우 높은 기준이 필요함
               o 실수나 잘못된 출력은 실제 피해를 일으키고 신뢰를 잃을 수 있음
          + 그러나 추천 시스템과 같은 덜 중요한 애플리케이션이나 콘텐츠 분류 또는 요약과 같은 내부 대면 애플리케이션의 경우 지나치게 엄격한 요구 사항은 많은 가치를 추가하지 않고 진전을 늦출 뿐임
     * 이는 많은 회사가 외부 애플리케이션에 비해 내부 LLM 애플리케이션으로 더 빠르게 움직이고 있다는 최근 a16z 보고서와 일치함
          + 내부 생산성을 위해 AI를 실험함으로써 조직은 더 통제된 환경에서 위험을 관리하는 방법을 배우면서 가치를 포착하기 시작할 수 있음
          + 그런 다음 자신감이 생기면 고객 대면 사용 사례로 확장할 수 있음

  운영 4. 팀과 역할(Roles)

     * 어떤 직무도 정의하기 쉽지 않지만, 이 새로운 영역에서 업무에 대한 직무 기술서를 작성하는 것은 다른 것보다 더 어려움
          + 교차하는 직책에 대한 벤 다이어그램이나 직무 기술에 대한 제안은 생략하겠음
          + 그러나 새로운 역할인 AI 엔지니어의 존재를 인정하고 그 역할에 대해 논의할 것임
     * 중요한 것은 나머지 팀과 책임이 어떻게 할당되어야 하는지에 대해 논의할 것임

    도구가 아닌 프로세스에 집중

     * LLM과 같은 새로운 패러다임에 직면했을 때 소프트웨어 엔지니어는 도구를 선호하는 경향이 있음
          + 그 결과 도구가 해결하려고 했던 문제와 프로세스를 간과하게 됨
          + 이렇게 하면서 많은 엔지니어는 우발적 복잡성을 가정하게 되는데, 이는 팀의 장기적인 생산성에 부정적인 결과를 초래함
     * 예를 들어 이 글은 특정 도구가 대규모 언어 모델에 대한 프롬프트를 자동으로 생성할 수 있는 방법에 대해 설명함
          + 문제 해결 방법론이나 프로세스를 먼저 이해하지 않고 이러한 도구를 사용하는 엔지니어는 결국 불필요한 기술 부채를 떠안게 된다고 주장함(IMHO 정당하게)
     * 우발적 복잡성 외에도 도구는 종종 불충분하게 지정됨
          + 예를 들어 유해성, 간결성, 어조 등에 대한 일반 평가기와 함께 ""LLM 평가 도구 상자""를 제공하는 LLM 평가 도구 산업이 성장하고 있음
          + 많은 팀이 자신의 도메인의 특정 실패 모드에 대해 비판적으로 생각하지 않고 이러한 도구를 채택하는 것을 봄
     * 이와 대조적으로 EvalGen은 사용자를 기준 지정, 데이터 레이블링, 평가 확인 등 각 단계에 깊이 참여시켜 도메인별 평가를 생성하는 프로세스를 사용자에게 가르치는 데 중점을 둠
          + 소프트웨어는 사용자를 다음과 같은 워크플로우로 안내함
     * EvalGen이 안내하는 LLM 평가 제작의 모범 사례
         1. 도메인별 테스트 정의(프롬프트에서 자동으로 부트스트랩됨)
               o 코드 또는 LLM-as-a-Judge로 어설션으로 정의됨
         2. 테스트가 지정된 기준을 포착하는지 사용자가 확인할 수 있도록 테스트를 인간의 판단과 일치시키는 것의 중요성
         3. 시스템(프롬프트 등)이 변경됨에 따라 테스트 반복
     * EvalGen은 개발자에게 평가 구축 프로세스에 대한 멘탈 모델을 제공하지만 특정 도구에 고정하지는 않음
          + AI 엔지니어에게 이러한 맥락을 제공한 후에는 종종 더 간단한 도구를 선택하거나 자체 도구를 구축하기로 결정한다는 것을 발견함
     * 프롬프트 작성 및 평가 이외에 LLM의 구성 요소가 너무 많아 여기에 모두 나열할 수 없음
          + 그러나 AI 엔지니어가 도구를 채택하기 전에 프로세스를 이해하려고 노력하는 것이 중요함

    항상 실험하기

     * ML 제품은 실험과 깊이 연관되어 있음
          + A/B 테스트, 무작위 대조 시험뿐만 아니라 시스템의 가능한 가장 작은 구성 요소를 수정하고 오프라인 평가를 수행하는 빈번한 시도를 의미함
          + 모두가 평가에 열광하는 이유는 실제로 신뢰성과 자신감에 관한 것이 아니라 실험을 가능하게 하는 것임!
               o 평가가 더 좋을수록 실험을 더 빨리 반복할 수 있고, 따라서 시스템의 최상의 버전으로 더 빨리 수렴할 수 있음
     * 실험이 매우 저렴해졌기 때문에 동일한 문제를 해결하기 위해 다양한 접근 방식을 시도하는 것이 일반적임
          + 데이터 수집 및 모델 훈련의 높은 비용은 최소화됨
               o 프롬프트 엔지니어링 비용은 인간의 시간보다 조금 더 들음
          + 모든 사람이 프롬프트 엔지니어링의 기본을 배울 수 있도록 팀을 배치할 것
               o 이는 모든 사람이 실험하도록 장려하고 조직 전체에서 다양한 아이디어로 이어짐
     * 탐색을 위해서만 실험하지 말고 활용을 위해서도 실험을 사용할 것!
          + 새로운 작업의 작동 버전이 있는가?
               o 팀의 다른 사람이 다른 방식으로 접근하는 것을 고려해 볼 것
          + 더 빠를 수 있는 다른 방법으로 해보기
          + Chain-of-Thought나 Few-Shot과 같은 프롬프트 기술을 조사하여 품질을 높일 것
          + 도구가 실험을 방해하지 않도록 할 것
               o 그렇다면 재구축하거나 개선할 수 있는 것을 구매할 것
     * 제품/프로젝트 기획 중에는 평가 구축 및 여러 실험 수행을 위한 시간을 따로 할애할 것
          + 엔지니어링 제품에 대한 제품 사양을 생각해 보고, 여기에 평가에 대한 명확한 기준을 추가할 것
     * 로드맵 작성 시 실험에 필요한 시간을 과소평가하지 말 것
          + 프로덕션 승인을 받기 전에 여러 번의 개발 및 평가 반복을 예상할 것

    모든 사람이 새로운 AI 기술을 사용할 수 있도록 권한 부여

     * 생성형 AI의 채택이 증가함에 따라 전문가뿐만 아니라 전체 팀이 이 새로운 기술을 이해하고 사용할 수 있다고 느끼기를 원함
          + LLM이 어떻게 작동하는지(예: 지연 시간, 실패 모드, UX)에 대한 직관을 개발하는 더 좋은 방법은 없음
          + LLM은 비교적 접근하기 쉬움
               o 파이프라인의 성능을 향상시키기 위해 코딩 방법을 알 필요가 없으며, 모든 사람이 프롬프트 엔지니어링 및 평가를 통해 기여할 수 있음
     * 이 중 큰 부분은 교육임
          + n-shot 프롬프팅 및 CoT와 같은 기술이 모델을 원하는 출력 방향으로 조건화하는 데 도움이 되는 프롬프트 엔지니어링의 기초부터 시작할 수 있음
     * 지식을 가진 사람들은 LLM이 본질적으로 자기회귀적이라는 점과 같은 보다 기술적인 측면에 대해서도 교육할 수 있음
          + 즉, 입력 토큰은 병렬로 처리되지만 출력 토큰은 순차적으로 생성됨
          + 따라서 지연 시간은 입력 길이보다 출력 길이의 함수임
               o 이는 UX를 설계하고 성능 기대치를 설정할 때 주요 고려 사항임
     * 실험과 탐색을 위한 실습 기회를 제공할 수도 있음
          + 해커톤은 어떨까?
               o 전체 팀이 며칠 동안 추측성 프로젝트를 해킹하는 데 시간을 보내는 것이 비싸 보일 수 있지만, 그 결과는 당신을 놀라게 할 수 있음
          + 해커톤을 통해 3년 로드맵을 1년 안에 거의 완료한 팀이 있음
               o 또 다른 팀은 해커톤을 통해 LLM 덕분에 이제 가능해진 패러다임을 전환하는 UX로 이어졌으며, 이제 올해와 그 이후의 우선 순위가 되었음

    ""AI 엔지니어링이 모든 것""이라는 함정에 빠지지 말 것

     * 새로운 직책이 생겨날 때 이러한 역할과 관련된 능력을 과대평가하는 경향이 초기에 있음
          + 이는 종종 이러한 직업의 실제 범위가 명확해짐에 따라 고통스러운 수정으로 이어짐
          + 이 분야의 신참자와 채용 관리자는 과장된 주장을 하거나 과도한 기대를 할 수 있음
     * 지난 10년 동안의 주목할 만한 예는 다음과 같음
          + 데이터 과학자: ""모든 소프트웨어 엔지니어보다 통계학을 더 잘하고 모든 통계학자보다 소프트웨어 엔지니어링을 더 잘하는 사람""
          + 머신러닝 엔지니어(MLE): 머신러닝에 대한 소프트웨어 엔지니어링 중심의 관점
     * 처음에는 많은 사람들이 데이터 기반 프로젝트에는 데이터 과학자만으로 충분하다고 가정함
          + 그러나 데이터 과학자는 데이터 제품을 효과적으로 개발하고 배포하기 위해 소프트웨어 및 데이터 엔지니어와 협력해야 한다는 것이 분명해짐
     * 이 오해는 AI 엔지니어라는 새로운 역할에서도 다시 나타났으며, 일부 팀은 AI 엔지니어가 필요한 전부라고 믿음
          + 실제로 머신러닝 또는 AI 제품을 구축하려면 광범위한 전문 역할이 필요함
     * 우리는 12개 이상의 회사와 AI 제품에 대해 상담했으며, 그들이 ""AI 엔지니어링이 필요한 전부""라는 믿음의 함정에 빠지는 것을 일관되게 관찰함
          + 그 결과 제품 구축에 필요한 중요한 측면을 간과하면서 제품이 데모 이상으로 확장하는 데 어려움을 겪는 경우가 많음
     * 예를 들어 평가 및 측정은 Vibe 체크 이상으로 제품을 확장하는 데 중요함
          + 효과적인 평가를 위한 기술은 전통적으로 머신러닝 엔지니어에게서 볼 수 있는 강점 중 일부와 일치함
               o AI 엔지니어로만 구성된 팀은 이러한 기술이 부족할 가능성이 높음
     * 공동 저자인 Hamel Husain은 데이터 편향 감지 및 도메인 특정 평가 설계와 관련된 최근 작업에서 이러한 기술의 중요성을 설명함
     * AI 제품 구축 여정에서 필요한 역할 유형 및 시기
         1. 먼저 제품 구축에 집중할 것
          + AI 엔지니어가 포함될 수 있지만 반드시 필요한 것은 아님
          + AI 엔지니어는 제품(UX, 배관 등)을 프로토타이핑하고 신속하게 반복하는 데 유용함
         2. 다음으로 시스템을 계측하고 데이터를 수집하여 올바른 기반을 만들 것
          + 데이터 유형과 규모에 따라 플랫폼 및/또는 데이터 엔지니어가 필요할 수 있음
          + 또한 문제를 디버깅하기 위해 이 데이터를 쿼리하고 분석하는 시스템이 있어야 함
         3. 다음으로 AI 시스템을 최적화할 것
          + 이는 반드시 모델 훈련을 포함하지는 않음
          + 기본 사항에는 지표 설계, 평가 시스템 구축, 실험 실행, RAG 검색 최적화, 확률적 시스템 디버깅 등의 단계가 포함됨
          + MLE는 이 분야에 매우 능숙함(물론 AI 엔지니어도 습득할 수 있음)
          + 선행 단계를 완료하지 않은 경우 MLE를 고용하는 것은 보통 타당하지 않음
     * 이 외에도 항상 도메인 전문가가 필요함
          + 작은 회사에서는 이상적으로 창업팀이 이 역할을 해야 하며, 큰 회사에서는 제품 관리자가 이 역할을 할 수 있음
     * 역할의 진행 및 타이밍을 인식하는 것이 중요함
          + 잘못된 시기에 사람들을 고용하거나(예: MLE를 너무 일찍 고용) 잘못된 순서로 구축하는 것은 시간과 비용 낭비이며 이직을 야기함
     * 또한 1-2단계에서 MLE와 정기적으로 체크인(그러나 정규직으로 고용하지는 않음)하면 회사가 올바른 기반을 구축하는 데 도움이 됨

[전략: LLM을 활용한 구축에서 뒤처지지 않는 방법]

     * 성공적인 제품 개발을 위해서는 무작정 프로토타입을 만들거나 최신 모델이나 트렌드를 따라가기보다는 신중한 기획과 우선순위 설정이 필요함
     * AI 제품 개발 시 직접 개발할 것인지 구매할 것인지 등의 주요 트레이드오프를 검토해야 함
     * 초기 LLM 애플리케이션 개발을 위한 ""플레이북""을 제시함

  전략 1: PMF 전에는 GPU 없음

     * 훌륭한 제품이 되려면 단순히 다른 사람의 API를 얇게 포장하는 것 이상이 되어야 함
     * 하지만 반대 방향의 실수는 더 큰 비용을 초래할 수 있음
          + 지난 해에는 명확한 제품 비전이나 목표 시장 없이 모델 학습과 커스터마이징에 막대한 벤처 자본이 쓰여졌음
          + 한 회사는 무려 60억 달러의 시리즈 A 투자를 받기도 함
     * 이 섹션에서는 즉시 자체 모델 학습을 시작하는 것이 왜 실수인지 설명하고, 자체 호스팅의 역할을 고려해 볼 것임

    처음부터 (거의) 다시 트레이닝 하는 것은 의미 없음

     * 대부분의 조직에게 처음부터 LLM을 프리트레이닝하는 것은 제품 개발에서 벗어난 비현실적인 일임
          + 머신러닝 인프라의 개발과 유지에는 많은 자원이 소요됨
               o 데이터 수집, 모델 학습과 평가, 배포 등이 포함됨
          + 제품-시장 적합성을 검증하는 단계라면 이러한 노력은 핵심 제품 개발에서 자원을 분산시킴
          + 컴퓨팅 자원, 데이터, 기술적 역량이 있다 해도 프리트레인된 LLM은 몇 달 안에 구식이 될 수 있음
     * BloombergGPT의 사례
          + 금융 업무에 특화된 LLM인 BloombergGPT는 363B 토큰으로 프리트레이닝되었음
          + AI 엔지니어링 4명, ML 제품 및 연구 5명 등 9명의 전임 직원들의 엄청난 노력이 투입됨
          + 그럼에도 1년 내에 해당 업무에서 gpt-3.5-turbo와 gpt-4에 뒤쳐졌음
     * 이런 사례들은 대부분의 실제 애플리케이션에서 LLM을 처음부터 프리트레이닝하는 것이 자원의 최선의 활용법이 아님을 시사함
          + 대신 팀은 특정 요구사항에 맞춰 사용 가능한 가장 강력한 오픈소스 모델을 파인튜닝하는 것이 더 나음
     * 물론 예외는 있음
          + Replit의 코드 모델은 코드 생성과 이해에 특화되어 프리트레이닝된 훌륭한 사례임
          + 프리트레이닝으로 CodeLlama7b 등 더 큰 모델보다 우수한 성능을 보였음
          + 그러나 더 강력한 모델들이 출시됨에 따라 효용성 유지를 위해서는 지속적인 투자가 필요했음

    필요하다고 확인되기 전까지는 파인튜닝 금지

     * 대부분의 조직에서 파인튜닝은 전략적 사고보다는 FOMO(Fear Of Missing Out, 놓칠 것에 대한 두려움)에 의해 주도됨
          + 조직은 ""단순한 래퍼""라는 비난을 피하기 위해 너무 일찍 파인튜닝에 투자함
          + 실제로 파인튜닝은 다른 접근 방식으로는 충분하지 않다는 것을 확신시켜주는 많은 사례를 수집한 후에야 배포해야 할 중장비와 같음
     * 1년 전 많은 팀이 파인튜닝에 대해 기대감을 표했지만, 몇 안 되는 팀만이 제품-시장 적합성을 발견했고 대부분은 결정을 후회함
          + 파인튜닝을 할 거라면 기본 모델이 개선됨에 따라 반복해서 수행할 준비가 되어 있어야 함
               o 아래의 ""모델은 제품이 아님""과 ""LLMOps 구축""을 참조
     * 파인튜닝이 실제로 올바른 선택일 수 있는 경우
          + 기존 모델 학습에 사용된 대부분의 개방형 웹 규모 데이터셋에서 사용할 수 없는 데이터가 필요한 경우
          + 기존 모델로는 충분하지 않다는 것을 보여주는 MVP를 이미 구축한 경우
          + 그러나 주의해야 함: 훌륭한 학습 데이터를 모델 구축자가 쉽게 얻을 수 없다면 당신은 어디서 얻을 것인가?
     * LLM 기반 애플리케이션은 과학 박람회 프로젝트가 아님
          + 전략적 목표와 경쟁 차별화에 대한 기여도에 상응하는 투자가 이루어져야 함

    추론 API로 시작하되, 셀프호스팅을 두려워하지 말 것

     * LLM API를 사용하면 스타트업이 처음부터 자체 모델을 학습시키지 않고도 언어 모델링 기능을 쉽게 채택하고 통합할 수 있음
          + Anthropic, OpenAI 등의 제공업체는 몇 줄의 코드만으로 제품에 인텔리전스를 부여할 수 있는 일반 API를 제공함
          + 이러한 서비스를 사용하면 노력을 줄이고 고객을 위한 가치 창출에 집중할 수 있어 아이디어를 검증하고 제품-시장 적합성을 더 빨리 반복할 수 있음
     * 그러나 데이터베이스와 마찬가지로 관리형 서비스는 규모와 요구사항이 증가함에 따라 모든 사용 사례에 적합하지 않음
          + 실제로 자체 호스팅은 의료 및 금융과 같은 규제 산업 또는 계약상 의무나 기밀 유지 요건에 의해 요구되는 대로 기밀/개인 데이터를 네트워크 외부로 보내지 않고 모델을 사용하는 유일한 방법일 수 있음
     * 또한 자체 호스팅은 추론 제공업체가 부과하는 속도 제한, 모델 사용 중단, 사용 제한 등의 제약을 우회함
          + 자체 호스팅은 모델에 대한 완전한 제어 권한을 제공하여 차별화되고 고품질의 시스템을 더 쉽게 구축할 수 있게 함
     * 마지막으로 자체 호스팅, 특히 파인튜닝은 대규모로 비용을 절감할 수 있음
          + 예를 들어 Buzzfeed는 오픈소스 LLM을 파인튜닝하여 비용을 80% 절감한 사례를 공유했음

  전략 2: 더 나은 것을 향해 반복하기

     * 장기적으로 경쟁 우위를 유지하려면 모델을 넘어서 제품을 차별화할 수 있는 요소를 고려해야 함
     * 실행 속도가 중요하지만 그것이 유일한 장점이 되어서는 안 됨

    모델은 제품이 아님, 그 모델을 둘러싼 시스템이 제품임

     * 모델을 구축하지 않는 팀에게 혁신의 빠른 속도는 축복임
          + 컨텍스트 크기, 추론 능력, 가격 대비 가치 등의 향상을 추구하며 최신 모델로 마이그레이션하여 더 나은 제품을 만들 수 있기 때문
          + 이러한 진보는 예측 가능할 만큼 흥미로움
          + 종합하면 모델은 시스템에서 가장 지속성이 낮은 구성 요소일 가능성이 높음
     * 대신 지속적인 가치를 제공할 수 있는 부분에 노력을 집중해야 함
          + Evals: 모델 전반에 걸쳐 작업 성능을 안정적으로 측정하기 위함
          + Guardrails: 모델에 상관없이 원치 않는 출력을 방지하기 위함
          + Caching: 모델을 완전히 피함으로써 지연 시간과 비용을 줄이기 위함
          + Data flywheel: 위의 모든 것의 반복적 개선을 추진하기 위함
          + 이러한 구성 요소는 원시 모델 기능보다 더 두꺼운 제품 품질의 해자를 만듦
     * 그러나 애플리케이션 계층에서 구축하는 것이 위험이 없다는 의미는 아님
          + OpenAI나 다른 모델 제공업체가 실행 가능한 엔터프라이즈 소프트웨어를 제공하려면 가위로 잘라내야 할 부분에 가위질하지 말 것
     * 예를 들어 일부 팀은 독점 모델에서 구조화된 출력을 검증하기 위한 맞춤형 도구를 구축하는 데 투자했음
          + 여기에 최소한의 투자는 중요하지만 깊이 투자하는 것은 시간을 잘 활용하는 것이 아님
          + OpenAI는 함수 호출을 요청할 때 유효한 함수 호출을 받을 수 있도록 해야 함. 모든 고객이 원하기 때문
          + 여기에 ""전략적 미루기""를 적용하고, 절대적으로 필요한 것을 구축하고, 제공업체의 기능 확장을 기다릴 것

    작게 시작해서 신뢰를 얻기

     * 모든 사람을 위한 모든 것이 되려고 하는 제품을 만드는 것은 평범함의 레시피임
     * 설득력 있는 제품을 만들기 위해 기업은 사용자가 계속 돌아오게 하는 끈적거리는 경험을 구축하는 데 전문화해야 함
     * 사용자가 묻는 모든 질문에 답하는 것을 목표로 하는 일반적인 RAG 시스템을 고려해 보자
          + 전문화가 부족하다는 것은 시스템이 최신 정보에 우선순위를 두거나, 도메인 특화 형식을 구문 분석하거나, 특정 작업의 뉘앙스를 이해할 수 없다는 것을 의미함
          + 그 결과 사용자는 얕고 신뢰할 수 없는 경험을 하게 되어 요구사항을 충족시키지 못하고 이탈하게 됨
     * 이를 해결하기 위해 특정 도메인과 사용 사례에 집중해야 함
          + 넓이보다는 깊이를 더해 범위를 좁혀야 함
          + 이렇게 하면 사용자에게 공감을 주는 도메인 특화 도구를 만들 수 있음
     * 전문화를 통해 시스템의 기능과 한계를 솔직하게 알릴 수 있음
          + 시스템이 할 수 있는 것과 할 수 없는 것에 대해 투명하게 공개하는 것은 자기 인식을 보여주고, 사용자가 어디에 가장 많은 가치를 더할 수 있는지 이해하는 데 도움이 되며, 결과적으로 출력에 대한 신뢰와 확신을 구축함

    LLMOps를 만들되, 적절한 이유를 가질 것 : 빠른 반복

     * DevOps는 근본적으로 재현 가능한 워크플로우나 왼쪽 이동 또는 두 개의 피자 팀에 권한을 부여하는 것이 아님. YAML 파일을 작성하는 것은 더더욱 아님
     * DevOps는 작업과 그 결과 사이의 피드백 주기를 단축하여 오류 대신 개선 사항이 축적되도록 하는 것임
          + 그 뿌리는 린 스타트업 운동을 통해 린 제조와 토요타 생산 시스템으로 거슬러 올라가며, 싱글 미닛 다이 교환과 카이젠을 강조함
     * MLOps는 DevOps의 형태를 ML에 적용했음
          + 재현 가능한 실험과 모델 구축자가 배포할 수 있도록 권한을 부여하는 올인원 도구 제품군이 있음. YAML 파일도 많음
     * 그러나 업계로서 MLOps는 DevOps의 기능을 채택하지 않았음. 모델과 프로덕션에서의 추론 및 상호 작용 사이의 피드백 갭을 줄이지 않았음
     * 다행히도 LLMOps 분야는 프롬프트 관리와 같은 사소한 문제에서 벗어나 반복을 방해하는 어려운 문제인 프로덕션 모니터링과 평가로 연결되는 지속적인 개선으로 방향을 전환했음
     * 이미 채팅 및 코딩 모델에 대한 중립적이고 크라우드소싱된 평가를 위한 대화형 아레나가 있음. 집단적이고 반복적인 개선의 외부 루프임
          + LangSmith, Log10, LangFuse, W&B Weave, HoneyHive 등의 도구는 프로덕션에서 시스템 결과에 대한 데이터를 수집하고 정리할 뿐만 아니라 개발과 깊이 통합하여 해당 시스템을 개선하는 데 활용할 것을 약속함. 이러한 도구를 수용하거나 자체적으로 구축하라

    구매할 수 있는 LLM 기능을 만들지 말 것

     * 대부분의 성공적인 비즈니스는 LLM 비즈니스가 아님. 동시에 대부분의 비즈니스에는 LLM으로 개선할 기회가 있음
     * 이 두 가지 관찰은 종종 리더를 오도하여 비용은 늘리고 품질은 떨어뜨리면서 LLM으로 시스템을 성급하게 개조하고 인조의 허영심 강한 ""AI"" 기능으로 출시하게 만듦. 지금은 두려워하는 반짝이 아이콘이 완성됨
     * 더 나은 방법이 있음: 제품 목표에 진정으로 부합하고 핵심 운영을 강화하는 LLM 애플리케이션에 집중할 것
     * 팀의 시간을 낭비하는 몇 가지 잘못된 시도를 고려해 보자
          + 비즈니스를 위한 맞춤형 text-to-SQL 기능 구축
          + 문서와 대화할 수 있는 챗봇 구축
          + 회사 지식 베이스를 고객 지원 챗봇과 통합
     * 위의 사항들이 LLM 애플리케이션의 헬로 월드이지만 제품 회사가 직접 구축하는 것은 이치에 맞지 않음
          + 이는 많은 비즈니스에 공통된 일반적인 문제로 유망한 데모와 신뢰할 수 있는 구성 요소 사이의 격차가 크며 소프트웨어 회사의 관례적 영역임
          + 현재 Y Combinator 배치에서 대규모로 해결하고 있는 일반적인 문제에 귀중한 R&D 자원을 투자하는 것은 낭비임
     * 이것이 진부한 비즈니스 조언처럼 들린다면 현재 과대 광고 물결의 들뜬 흥분 속에서 ""LLM""이라는 것을 최첨단의 차별화된 것으로 오해하기 쉽고 이미 낡아빠진 애플리케이션을 놓치기 쉽기 때문임

    AI를 루프안에 넣고, 사람을 중심에 둘 것

     * 현재 LLM 기반 애플리케이션은 취약함. 엄청난 양의 안전 조치와 방어적 엔지니어링이 필요하지만 여전히 예측하기 어려움. 게다가 엄격하게 범위가 지정되면 이러한 애플리케이션은 엄청나게 유용할 수 있음. 이는 LLM이 사용자 워크플로를 가속화하는 훌륭한 도구가 된다는 것을 의미함
     * LLM 기반 애플리케이션이 워크플로를 완전히 대체하거나 직무 기능을 대신하는 것을 상상하고 싶을 수 있지만, 오늘날 가장 효과적인 패러다임은 인간-컴퓨터 켄타우로스(Centaur chess)임
          + 유능한 인간이 자신의 빠른 활용을 위해 조정된 LLM 기능과 결합하면 작업을 수행하는 생산성과 행복감이 크게 향상될 수 있음
          + LLM의 대표적인 애플리케이션 중 하나인 GitHub CoPilot은 이러한 워크플로의 힘을 입증했음
               o ""전반적으로 개발자들은 GitHub Copilot과 GitHub Copilot Chat을 사용할 때 코딩이 더 쉽고, 오류가 적으며, 가독성이 높고, 재사용성이 높으며, 간결하고, 유지 관리가 용이하며, 탄력적이라고 느꼈다고 말했습니다."" - Mario Rodriguez, GitHub
     * 오랫동안 ML 작업을 해온 사람들은 ""human-in-the-loop""라는 아이디어에 빠르게 도달할 수 있지만 그렇게 서두르지 말 것
          + HITL 머신러닝은 ML 모델이 예측대로 동작하도록 보장하는 인간 전문가에 기반한 패러다임임
          + 여기서 제안하는 것은 관련되기는 하지만 더 미묘한 것임. LLM 기반 시스템은 오늘날 대부분의 워크플로의 주요 동력이 되어서는 안 되며, 단순히 자원이 되어야 함
     * 인간을 중심에 두고 LLM이 어떻게 워크플로를 지원할 수 있는지 묻는 것은 제품 및 설계 결정에 상당히 다른 영향을 미침
          + 궁극적으로 LLM에 모든 책임을 신속하게 아웃소싱하려는 경쟁업체와는 다른 제품, 즉 더 나은 제품, 더 유용하고 덜 위험한 제품을 만들게 될 것임

  전략 3. 프롬프팅, Eval, 데이터 수집으로 시작하기

     * 이전 섹션에서는 기술과 조언의 화력을 쏟아부었음. 받아들이기에 많은 양임. 유용한 조언의 최소 집합을 고려해 보자.
          + 팀이 LLM 제품을 만들고 싶다면 어디서부터 시작해야 할까?
     * 지난 1년 동안 성공적인 LLM 애플리케이션은 일관된 궤적을 따른다는 것을 확신할 만큼 충분히 봐왔음. 이 섹션에서는 이 기본적인 ""시작하기"" 플레이북을 살펴볼 것임
     * 핵심 아이디어는 간단하게 시작하고 필요에 따라 복잡성을 추가하는 것임
          + Rule of Thumb : 각 수준의 정교함은 일반적으로 이전 단계보다 최소한 한 자릿수 이상의 노력이 필요하다는 것임. 이를 염두에 두고...

    프롬프트 엔지니어링이 1순위

     * 프롬프트 엔지니어링부터 시작할 것
          + 이전에 전술 섹션에서 논의한 모든 기술을 사용할 것
          + Chain-of-thought, n-shot 예제, 구조화된 입출력은 거의 항상 좋은 아이디어임
          + 약한 모델에서 성능을 짜내기 전에 가장 성능이 높은 모델로 프로토타입을 만들 것
     * 프롬프트 엔지니어링으로 원하는 성능 수준을 달성할 수 없는 경우에만 파인튜닝을 고려해야 함
          + 독점 모델 사용을 차단하고 자체 호스팅을 요구하는 비기능적 요구사항(예: 데이터 프라이버시, 완전한 제어, 비용)이 있는 경우 더 자주 발생할 것임
          + 동일한 프라이버시 요구사항이 파인튜닝을 위해 사용자 데이터 사용을 차단하지 않도록 주의할 것

    평가를 만들고 데이터 플라이휠 시작하기

     * 막 시작하는 팀도 평가(evals)가 필요함. 그렇지 않으면 프롬프트 엔지니어링이 충분한지 또는 파인튜닝된 모델이 기본 모델을 대체할 준비가 되었는지 알 수 없음
     * 효과적인 평가는 작업에 특화되어 있으며 의도한 사용 사례를 반영함
          + 권장하는 첫 번째 수준의 평가는 단위 테스트임
          + 이러한 간단한 어설션은 알려졌거나 가설로 설정된 실패 모드를 감지하고 초기 설계 결정을 내리는 데 도움이 됨
          + 분류, 요약 등을 위한 다른 작업별 평가도 참조할 것
     * 단위 테스트와 모델 기반 평가는 유용하지만 인간 평가의 필요성을 대체하지는 않음
          + 사람들이 모델/제품을 사용하고 피드백을 제공하도록 할 것
          + 이는 실제 성능과 결함률을 측정하는 동시에 향후 모델을 파인튜닝하는 데 사용할 수 있는 고품질의 주석 데이터를 수집한다는 이중 목적을 수행함
          + 이는 시간이 지남에 따라 복리로 작용하는 긍정적인 피드백 루프 또는 데이터 플라이휠을 만듦
               o 모델 성능을 평가하거나 결함을 찾기 위한 인간 평가
               o 주석 데이터를 사용하여 모델을 파인튜닝하거나 프롬프트를 업데이트
               o 반복
     * 예를 들어 LLM 생성 요약의 결함을 감사할 때 각 문장에 사실적 불일치, 무관함 또는 스타일 불량을 식별하는 세분화된 피드백 레이블을 지정할 수 있음
          + 그런 다음 이러한 사실적 불일치 주석을 사용하여 환각 분류기를 학습시키거나 관련성 주석을 사용하여 관련성 보상 모델을 학습시킬 수 있음
     * LinkedIn은 환각, 책임감 있는 AI 위반, 일관성 등을 추정하기 위해 모델 기반 평가자를 사용한 성공 사례를 공유했음
     * 시간이 지남에 따라 가치가 증대되는 자산을 창출함으로써, 평가(evals) 구축을 단순한 운영 비용에서 전략적 투자로 전환하고, 그 과정에서 데이터 플라이휠을 구축

  전략 4. 저비용 인지의 고차원적 추세 (The high-level trend of low-cost cognition)

     * 1971년 Xerox PARC의 연구원들은 우리가 현재 살고 있는 네트워크로 연결된 개인용 컴퓨터의 세계를 예측했음
          + 그들은 이를 가능하게 한 기술(이더넷, 그래픽 렌더링, 마우스, 윈도우 등)의 발명에 중추적인 역할을 함으로써 그 미래를 탄생시키는 데 기여했음
     * 그들은 또한 간단한 연습을 했음
          + 매우 유용하지만(예: 비디오 디스플레이) 아직 경제적이지 않은(비디오 디스플레이를 구동하기에 충분한 RAM이 수천 달러) 애플리케이션을 살펴봄
          + 그런 다음 해당 기술의 역사적 가격 추세(무어의 법칙과 유사)를 살펴보고 그 기술이 언제 경제적이 될지 예측함
     * LLM 기술에 대해서도 같은 작업을 할 수 있음. 비록 달러당 트랜지스터 수만큼 깔끔한 것은 아니지만
          + 오랫동안 사용된 인기 있는 벤치마크(예: Massively-Multitask Language Understanding 데이터셋)와 일관된 입력 접근 방식(5-shot 프롬프팅)을 선택
          + 그런 다음 시간이 지남에 따라 이 벤치마크에서 다양한 성능 수준을 가진 언어 모델을 실행하는 비용을 비교
     * 고정 비용에 대해 능력이 빠르게 증가하고 있음. 고정된 능력 수준에 대해 비용이 빠르게 감소하고 있음
          + OpenAI의 davinci 모델이 API로 출시된 이후 4년 동안, 100만 토큰(이 문서의 약 100개 사본) 규모에서 그 작업에 상응하는 성능을 가진 모델을 실행하는 비용은 $20에서 10센트 미만으로 떨어졌음. 반감기는 불과 6개월임
          + 유사하게 2024년 5월 기준 API 제공업체를 통하거나 자체적으로 Meta의 LLaMA 3 8B를 실행하는 비용은 토큰 100만 개당 20센트에 불과하며 ChatGPT를 가능하게 한 모델인 OpenAI의 text-davinci-003과 유사한 성능을 보임
          + 해당 모델은 2023년 11월 말 출시 당시에도 토큰 100만 개당 약 $20의 비용이 들었음. 불과 18개월 만에 두 자릿수 차이가 남. 무어의 법칙이 예측하는 단순한 두 배 증가와 동일한 기간임
     * 이제 매우 유용하지만(Park et al과 같은 생성적 비디오 게임 캐릭터 구동) 아직 경제적이지 않은(시간당 비용이 $625로 추정됨) LLM 애플리케이션을 고려해 보자
          + 해당 논문이 2023년 8월에 발표된 이후 비용은 시간당 약 $62.50로 한 자릿수 정도 떨어졌음
          + 9개월 후에는 시간당 $6.25로 떨어질 것으로 예상할 수 있음
     * 한편 팩맨이 1980년에 출시되었을 때 오늘날의 $1로 몇 분 또는 몇 십 분 동안 플레이할 수 있는 크레딧을 살 수 있었음. 시간당 6게임 또는 시간당 $6라고 부름
          + 이 냅킨 계산은 매력적인 LLM 강화 게임 경험이 2025년 경에는 경제적이 될 것임을 시사함
     * 이러한 추세는 새로운 것이며 불과 몇 년 되지 않았음. 그러나 앞으로 몇 년 동안 이 과정이 느려질 것이라고 기대할 만한 이유는 거의 없음
          + 매개변수당 ~20 토큰의 ""Chinchilla 비율""을 넘어 스케일링하는 것과 같은 알고리즘과 데이터셋의 낮게 매달린 과일을 사용하더라도, 데이터 센터 내부와 실리콘 계층에서의 더 깊은 혁신과 투자는 그 격차를 메울 것임
     * 그리고 이것이 아마도 가장 중요한 전략적 사실일 것임
          + 오늘날 완전히 실현 불가능한 플로어 데모나 연구 논문이 몇 년 후에는 프리미엄 기능이 되고 그 직후에는 상품이 될 것임
          + 이를 염두에 두고 시스템과 조직을 구축해야 함

[0에서 1로 가는 데모는 이제 충분함. 이제는 1에서 N으로 가는 제품을 만들 때]

     * LLM 데모를 만드는 것은 정말 재미있음. 몇 줄의 코드, 벡터 데이터베이스, 신중하게 작성된 프롬프트로 ""마법"" 을 만들어냄
     * 지난 1년 동안 이 마법은 인터넷, 스마트폰, 심지어 인쇄술과 비교되었음
     * 안타깝게도 실제 소프트웨어 출시 작업을 해본 사람이라면 누구나 알고 있듯이, 통제된 환경에서 작동하는 데모와 대규모로 안정적으로 작동하는 제품 사이에는 엄청난 차이가 있음
     * 상상하고 데모를 만드는 것은 쉽지만 제품으로 만드는 것은 매우 어려운 문제들이 많음
          + 예를 들어 자율 주행: 자동차가 한 블록을 자율 주행하는 것은 쉽게 시연할 수 있지만, 이를 제품으로 만드는 데는 10년이 걸림 - Andrej Karpathy
     * 자율 주행차를 예로 들어보자
          + 1988년 신경망으로 운전되는 첫 번째 자동차가 등장했음
          + 25년 후 Andrej Karpathy는 Waymo에서 첫 번째 데모 라이드를 했음
          + 그로부터 10년 후 회사는 무인 운전 허가를 받았음
          + 프로토타입에서 상용 제품으로 가기까지 35년 동안 엄격한 엔지니어링, 테스트, 개선, 규제 탐색이 이루어졌음
     * 산업계와 학계 전반에 걸쳐 지난 1년 동안의 기복을 관찰했음 : LLM 애플리케이션의 1년차 (Year 1 of N for LLM applications)
          + 평가, 프롬프트 엔지니어링, 가드레일과 같은 전술부터 운영 기술, 팀 구축, 내부적으로 구축할 기능 선택과 같은 전략적 관점에 이르기까지 우리가 배운 교훈이 2년차 이후에 도움이 되기를 바람
          + 이 흥미로운 새로운 기술을 함께 발전시켜 나가길 기대함

   내용이 좋아서, 두고두고 보려고 Mindmap으로 만들어 보았습니다 ^^;

   https://drive.google.com/file/d/…

   너무 좋은 글입니다!! 처음부터 끝까지 유용하게 곱씹어볼말들이 많습니다. 이렇게 주옥 같은 글을 번역해서 올려주셔서 감사합니다!!

   지금 시점에서 정말 도움이 많이 되네요

   메가스터디는 끝났어, 오메가쓰리가온다!!!

   이제 스카이넷은 끝났어, 메가스터디가 온다.

   이제 인류는 끝났어 스카이넷이 온다!!

   원글 작성자의 커리어도 흥미로웠습니다
   https://news.hada.io/topic?id=1626

   와.. 엄청나게 자극이 되네요.. 소개 감사합니다

   통찰력과 경험이 생생하게 느끼져는 멋진 글이에요! 저와 팀에게 있어 큰 도움이 될것같습니다. 너무 잘 읽었습니다. 감사합니다 ☺️
"
"https://news.hada.io/topic?id=15298","macOS Sequoia 미리보기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           macOS Sequoia 미리보기

Apple Intelligence

  글쓰기, 집중, 그리고 소통

     * 새로운 글쓰기 도구와 언어 기능이 추가됨
     * 긴 텍스트 요약 및 알림 우선순위 설정 가능

  나만의 이미지를 만들어보세요

     * 자신을 표현할 수 있는 이미지 생성 가능
     * 대화를 위한 Genmoji 제작 가능
     * 기억에 남는 순간을 되돌아볼 수 있는 메모리 무비 제작 가능

  Siri의 새로운 시대의 시작

     * 더 풍부한 언어 이해력과 개인 컨텍스트 인식 기능 추가
     * Siri가 더욱 유능하고 도움이 되는 방향으로 개선됨

GN⁺의 의견

     * 개인화된 경험: Apple Intelligence는 사용자 개인의 컨텍스트를 반영하여 맞춤형 경험을 제공함.
     * 생산성 향상: 새로운 글쓰기 도구와 언어 기능은 작업 효율성을 높이는 데 도움이 됨.
     * 창의적 표현: 이미지 생성 및 Genmoji 기능은 사용자에게 창의적인 표현의 기회를 제공함.
     * Siri의 발전: Siri의 개선된 언어 이해력과 개인화된 기능은 사용자 경험을 크게 향상시킬 가능성이 있음.
     * 기술 도입 고려사항: 새로운 기능을 도입할 때는 보안과 개인정보 보호 문제를 충분히 고려해야 함.

        Hacker News 의견

     * macOS의 타일링 윈도우 관리: macOS에 타일링 윈도우 관리 기능이 추가된 것을 보고 놀라움. Stage Manager와 어떻게 상호작용할지 궁금함.
     * iMac Pro 사용 경험: 2018년형 iMac Pro가 Retina 디스플레이를 제공하는 최고의 데스크탑이었음. Apple의 제품 주기상 공백기 동안 유용했음.
     * Sequoia 지원: Sequoia가 2019년 이후 iMac만 지원하는 줄 알고 실망했으나, 2017년형 iMac Pro도 지원해 안도함. Apple이 업데이트를 중단할 시기를 걱정함.
     * Target Display Mode의 부재: Target Display Mode가 더 이상 지원되지 않는 것이 아쉬움. iMac의 고급 패널을 모니터로 활용할 수 있는 Linux 배포판이 나오길 기대함.
     * 파일 드래그 앤 드롭: iPhone과 Mac 간의 파일, 사진, 비디오를 드래그 앤 드롭하는 기능이 어떻게 작동할지 궁금함. 현재는 Image Capture 프로그램을 사용해야 해서 불편함.
     * macOS 알림 센터: macOS의 알림 센터가 불편함. iPhone과 Mac에서 동시에 알림이 뜨는 것이 번거로움. 알림 없이 위젯만 항상 표시되길 바람.
     * iPhone 미러링: iPhone 미러링 기능이 가장 흥미로웠음. 긴급 상황에서 유용할 것으로 예상되나, 지연 시간이 문제일 것 같음.
     * 앱 통합: Apple이 여러 앱을 통합하는 것을 보고 'Sherlock'이라 불러야 한다고 생각함. 많은 사용자가 유료 앱에서 Apple의 기본 앱으로 전환할 것 같음.
     * Windows와 macOS 비교: Windows에서 생산적이지만, 최근 Microsoft의 행태와 macOS의 윈도우 관리 개선으로 인해 macOS를 다시 시도해보고 싶음.
     * 비밀번호 관리 앱: 드디어 비밀번호 관리 앱이 나와서 기쁨. 1Password의 구독 모델과 Bitwarden의 UI/UX 문제를 해결할 수 있을 것 같음.
     * Apple Pay 브라우저 지원: Apple Pay가 다른 브라우저에서도 지원될 예정임. WebKit을 필요로 할지는 불분명하지만 기대됨.
     * iPhone 미러링과 화면 제어: iPhone 미러링과 다른 사람의 기기를 제어할 수 있는 기능이 유용할 것 같음. 하지만 사기꾼들이 이를 악용할 가능성도 있어 주의가 필요함.
"
"https://news.hada.io/topic?id=15259","이상한 괴짜는 대가를 동반함","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            이상한 괴짜는 대가를 동반함

     * 최근 많은 학자들이 ""STEM 분야의 여성""을 지지하다가, mRNA 기술의 공동 발명자이자 2023년 노벨상 수상자인 카탈린 카리코에게 화를 냄
     * 카리코는 자신의 책에서 학계가 과도한 사람 맞추기와 정치 게임에 얽매여 있다고 언급함
     * 이로 인해 많은 사람들이 그녀를 비난함

     ""펜실베이니아 대학 같은 연구 기관에서 성공하려면 과학과는 관련 없는 기술이 필요하다는 것을 배웠음. 자신과 자신의 연구를 팔아야 하고, 자금을 유치해야 하며, 사람들을 기쁘게 하고 멘토링을 받기 위해 정치적 사다리를 타야 했음. 나는 그런 기술에 관심이 없었음.""

     * 카리코는 학계에서 ""이상한 괴짜""로 불리며, 정치적 게임을 하지 않으려 했음
     * 많은 ""이상한 괴짜""들이 인터넷에서 피난처를 찾고 있음
     * 이들은 창의적이고 지적 활동에 적합하지만, 일반적인 직업에서는 잘 맞지 않음

  천재는 드물음

     * 카리코는 헝가리에서 미국으로 이주해 mRNA 백신 연구에 몰두했지만, 큰 성과나 지위를 얻지 못했음
     * 그녀는 지적 용기를 가지고 있었고, 이는 과학에서 매우 중요한 자질임
     * 천재는 매우 드물며, 특정 분야에서만 빛을 발함

  나쁜 부분도 특징임

     * 지적 용기를 가지려면 약간의 ""미친"" 면이 필요함
     * 카리코는 정치적 게임을 하지 않았고, 이는 그녀의 연구에 집중할 수 있게 했음
     * 정치적 게임에 시간을 쓰면 과학에 쓸 시간이 줄어듦
     * 학문적 기관에서 외향성이나 동의성 같은 특성으로 사람을 선발하는 것은 해로울 수 있음

  사회적 경향

     * 과학 경력은 많은 잡일로 시작해 점차 독립성을 얻음
     * 포닥(Postdoc) 단계는 과학자로서의 독립성을 가지지만, 매우 불안정함
     * PI(Principal Investigator)가 되면 정치적 기술이 더 중요해짐
     * 카리코는 이 단계에서 벽에 부딪혔고, 이는 그녀의 연구 주제와 성격 때문이었음
     * STEM 분야는 진입 장벽이 높아 정치적 게임이 덜 중요하지만, 인문학이나 사회과학에서는 더 큰 문제가 될 수 있음

GN⁺의 의견

     * 지적 용기: 카리코의 사례는 지적 용기의 중요성을 보여줌. 이는 과학적 발견에 필수적임.
     * 정치적 게임: 학계에서 정치적 게임이 연구의 질을 저해할 수 있음. 연구자들이 연구에 집중할 수 있는 환경이 필요함.
     * 다양성: ""이상한 괴짜"" 같은 다양한 인재들이 학계에서 배제되지 않도록 하는 것이 중요함.
     * 사회적 신뢰: 학계에 대한 신뢰가 떨어지고 있음. 이는 학계가 다양한 인재를 포용하지 못한 결과일 수 있음.
     * 대안적 경로: 인터넷과 같은 대안적 경로가 ""이상한 괴짜""들에게 중요한 피난처가 될 수 있음.

        Hacker News 의견

     * 다재다능 요구: 현대 사회는 모든 면에서 뛰어난 개인을 요구함. 과거의 '괴짜'는 특정 분야에 깊이 몰두하는 대신 다른 면에서 부족함을 인정했음.
     * 괴짜와 자폐증: 괴짜와 자폐증을 동일시하는 것은 잘못된 생각임. 다양한 유형의 괴짜가 있으며, 대부분은 자폐증과 무관함.
     * 특정 분야에 대한 열정: 재능은 특정 분야에 대한 깊은 관심에서 비롯됨. 외부 동기보다 자신이 좋아하는 것에 집중하는 것이 중요함.
     * 조직 내 괴짜: 괴짜를 지원하는 조직도 결국 정치적 인물을 더 우대하게 됨. 괴짜는 종종 자신이 모든 면에서 옳다고 생각하며, 갈등을 일으키기 쉬움.
     * 괴짜를 위한 조언: 감정 지능이 부족한 괴짜는 상호작용을 장기적인 엔지니어링 프로젝트로 생각하고 전략적으로 접근해야 함. 친절과 겸손을 유지하고 피드백을 많이 받아야 함.
     * 괴짜와 함께 일하는 사람: 괴짜와 함께 일하는 사람은 그들의 유용한 점을 최대한 활용하고, 개인적인 감정을 배제하며, 그들의 작업을 지원해야 함.
     * 사회적 지위 분배: 사회적 지위는 중앙집중화된 구조에 의해 분배됨. 소셜 미디어에서는 실제 능력보다 온라인 평판이 더 중요해짐.
     * 괴짜 상사: 괴짜 상사 밑에서 일하는 것은 매우 힘든 경험이 될 수 있음. 그들의 경력은 종종 주변 사람들과의 갈등으로 인해 정체됨.
     * 학계의 변화: 과거에는 괴짜와 천재들이 학계에서 보호받았지만, 이제는 자기 홍보가 중요한 시대가 됨.
     * 학계의 문제: 학계는 점점 더 관료적이고 기업화되고 있음. 진정한 지식 창출보다는 지위와 돈을 쌓는 데 집중함.
     * 과학의 협력: 과학은 집단적인 노력임. 아이디어는 시간과 공간을 초월해 퍼지고, 결국 한 사람이 이를 종합함.
     * 자기 홍보의 중요성: 대학원에서 자기 홍보의 중요성을 알았더라면 좋았을 것임. 연구는 일종의 판매 활동이며, 자신의 능력을 홍보해야 함.
     * 괴짜와 자폐증 연관성: 괴짜를 자폐증과 연관짓는 것은 부적절함. 모든 괴짜를 자폐증 환자로 보는 것은 잘못된 일반화임.
     * 괴짜의 어려움: 괴짜는 사회적 동물인 인간 사회에서 주변부에 존재할 수밖에 없음. 신뢰할 수 있는 후원자를 찾는 것이 중요하지만, 괴짜는 종종 이를 잘 판단하지 못함.
"
"https://news.hada.io/topic?id=15302","EU에서 사용가능한 애플 App Store 대체 마켓플레이스들 4가지 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 EU에서 사용가능한 애플 App Store 대체 마켓플레이스들 4가지

     * EU의 Digital Markets Act (DMA) 시행 이후 아이폰 앱을 위한 제3자 마켓플레이스가 허용되면서 4개 스토어가 출시됨
     * AltStore Pal
          + 유럽에서 출시된 첫 번째 제3자 iOS 앱 스토어로, 연간 구독료 1.50유로
          + 앱 배포는 완전히 무료이고, 개발자는 Patreon 연동으로 후원자에게만 배포도 가능
     * SetApp Mobile
          + 모든 앱을 하나의 구독으로 제공하는 새로운 iPhone 앱 스토어
          + 초대 전용 베타로 출시되었으며, 다양한 앱을 광고 없이 사용할 수 있는 구독 기반 접근 방식을 제공
          + 원래 macOS 플랫폼으로 시작하여 사용자들에게 수백 개의 엄선된 앱에 대한 액세스를 제공
          + 현재 버전에는 37개의 고품질 앱이 포함되어 있으며, 대부분은 이미 App Store에서 사용 가능한 것들
          + 생산성, 작업 및 최적화 도구에 중점을 둔 큐레이션 마켓플레이스 역할을 하고자 함
     * Aptoide Game store
          + 안드로이드용 대안 마켓플레이스로 유명
          + 2009년부터 운영 중이며, 현재 4억 명의 사용자에게 100만 개의 앱을 호스팅
          + iOS 앱 스토어 Aptoide는 초대 전용 베타로 출시되며, 게임만 배포함
          + 프리미엄 모델과 보상 구조를 결합한 방식을 제공
          + Apple이 승인한 인앱 구매 시스템을 사용하는 첫 번째 제3자 마켓플레이스이며, 정기적으로 인앱 구매를 하는 사용자에게 5~10% 할인 혜택을 제공
          + 개발자 지향적인 자세를 보이며, 인앱 구매에 대해 20% 수수료를 부과하고 다른 경우에는 10%를 부과함 (Apple은 30% 부과)
          + iOS 플랫폼에 게임을 출시하는 개발자에게 1,000~2,000달러를 지급하고 있음
     * Mobivention App Marketplace
          + 내부 직원용이나 자체 앱스토어를 만들려는 회사 고객들을 위한 앱 마켓플레이스 솔루션
          + 마켓 플레이스 관리도구 제공 (앱 등록/승인, 메타데이터 관리, 설치 및 사용통계등 )

   아이폰 최초의 대체 앱 마켓플레이스 AltStore PAL, 이제 이용 가능
"
"https://news.hada.io/topic?id=15210","화물선용 수학적 최적화 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            화물선용 수학적 최적화 기술

화물선의 수송 네트워크 최적화: 수학적 최적화 기법

  개요

     * 구글 연구팀이 새로운 Shipping Network Design API를 발표함.
     * 이 API는 화물선의 네트워크 설계 및 일정 문제를 해결하는 데 도움을 줌.
     * 이 솔루션은 기존 방법보다 더 빠르고 효율적이며, 수익을 두 배로 늘리고, 더 적은 선박으로 더 많은 컨테이너를 운송할 수 있게 함.

  배경

     * LSNDSP(선박 네트워크 설계 및 일정 문제)는 네트워크 설계, 네트워크 일정, 컨테이너 경로 설정의 세 가지 요소로 구성됨.
     * 기존에는 이 문제들을 개별적으로 해결했으나, 동시에 해결하면 더 나은 솔루션을 찾을 수 있음.

  방법론

     * 최적화 문제는 변수, 제약 조건, 목표 함수로 구성됨.
     * 구글은 'Double Column Generation'과 'CP-SAT' 두 가지 접근 방식을 사용해 문제를 해결함.
     * 이 방법들은 중소 규모 문제에 대해서는 최적의 솔루션을 제공하지만, 대규모 문제에는 적합하지 않음.
     * 대규모 문제 해결을 위해 'Large Neighborhood Search'와 'Variable Neighborhood Search'를 사용함.
     * 이 방법들은 검색 공간을 줄이고, 병렬 처리를 통해 효율성을 높임.

  결과

     * LINERLIB 벤치마크를 사용해 성능을 평가함.
     * 구글의 솔루션은 더 적은 선박으로 더 많은 컨테이너를 운송할 수 있게 함.
     * 각 시나리오에서 효율성을 높이고, 수익을 크게 증가시킴.

  결론

     * 구글의 최적화 기법은 대규모 선박 네트워크 설계 및 일정 문제를 해결할 수 있는 최초의 방법임.
     * 이 연구가 글로벌 공급망의 효율성을 높이는 데 기여할 것으로 기대됨.

GN⁺의 의견

     * 기술적 배경: LSNDSP는 복잡한 최적화 문제로, 네트워크 설계, 일정 관리, 경로 설정을 동시에 해결해야 함.
     * 산업적 중요성: 글로벌 무역의 90%가 해상 운송에 의존하고 있어, 이 문제의 해결은 경제적 영향이 큼.
     * 기술적 도전: 대규모 문제를 해결하기 위해 병렬 처리와 검색 공간 축소 등의 고급 기법이 필요함.
     * 경쟁 제품: 비슷한 기능을 제공하는 다른 최적화 솔루션으로는 IBM의 CPLEX, Gurobi 등이 있음.
     * 고려 사항: 새로운 기술 도입 시 초기 설정 비용과 학습 곡선이 있을 수 있음. 하지만 장기적으로는 효율성과 수익성을 크게 향상시킬 수 있음.

        Hacker News 의견

     * 터미널 측면에서의 의견: 터미널 최적화는 매우 복잡하고, 각 터미널마다 방식이 달라서 확장하기 어려움.
     * 책 ""The Box"" 추천: 컨테이너화의 초기 역사에 대한 책으로, 엔지니어링, 디자인, 비즈니스, 역사를 혼합한 흥미로운 읽을거리임.
     * 컨테이너 최적화 문제: 대형 선단에 대한 컨테이너 최적화 문제는 해결되지 않았음.
     * Google OR의 개선: Google OR이 기존 솔루션을 10%-20% 개선함.
     * API 사용 여부: demurrage(체선료)가 고려되지 않은 상황에서 시도해볼 가치가 있는지 의문임.
     * API 엔드포인트 사용 호기심: Google에서 제공하는 API 엔드포인트를 실제로 사용할지 궁금함.
     * Omega Tau Podcast 추천: 컨테이너 선적 및 최적화에 대한 훌륭한 에피소드가 있음.
     * 도커 컨테이너 실행: 도커 컨테이너에서 실행될 때만 작동함.
     * 알고리즘 사용 제안: 파트타임 직원의 일정 계획을 알고리즘으로 해결할 수 있지 않을까 생각함.
     * OR-tools 서비스 제공: OR-tools를 서비스로 제공하기 시작한 것 같음. 더 나은 API가 제공된다면 GCP 컴퓨팅 비용을 지불할 의향이 있음.
     * 적재 계획에 대한 의문: 적재 계획은 경로 계획 다음 단계로 해결해야 할 문제임. 크레인 작업 속도와 적재/하역 과정에 대한 대략적인 계산을 제시함.
     * 적재 계획의 복잡성: 적재 계획에는 무게, 균형, 전력, 가치 수용성 등의 기준이 포함됨. 이러한 복잡성 때문에 간단한 계산을 시도해봄.
"
"https://news.hada.io/topic?id=15230"," 마이크로소프트, 보안 논란 후 Recall 기능 기본 비활성화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   마이크로소프트, 보안 논란 후 Recall 기능 기본 비활성화

     * Recall 기능 변경 사항
          + 마이크로소프트는 Recall 기능을 기본적으로 비활성화하고, 사용자가 직접 활성화하도록 변경함.
          + Copilot+ 호환 버전의 Windows에서만 선택적으로 사용할 수 있게 됨.
          + 데이터 암호화 및 인증 요구 등 새로운 보안 기능 추가됨.
     * 보안 및 프라이버시 문제
          + Recall 기능은 사용자의 활동을 5초마다 스크린샷으로 저장하여 AI 분석에 활용함.
          + 이 기능이 해커들에게 쉽게 노출될 수 있는 보안 취약점으로 지적받음.
          + 사용자의 민감한 데이터가 로컬에 저장되지만, 해커가 접근할 경우 모든 기록을 볼 수 있는 위험이 있음.
     * 추가 보안 조치
          + Recall 기능을 활성화하거나 데이터에 접근할 때 Microsoft Hello 인증 기능을 통해 사용자의 신원을 확인해야 함.
          + 데이터는 사용자가 인증할 때까지 암호화된 상태로 유지됨.
     * 전문가 의견
          + 일부 전문가들은 이러한 변경 사항이 개선된 점을 인정하지만, 여전히 심각한 위험이 존재한다고 경고함.
          + 사용자가 Recall 기능을 활성화하면 법적 문제나 개인 정보 유출 등의 위험이 남아 있음.
     * 마이크로소프트의 보안 우선 정책
          + 최근 마이크로소프트는 여러 보안 사고와 데이터 유출 사건을 겪음.
          + CEO 사티아 나델라는 보안을 최우선으로 하겠다는 메모를 발표함.

        Hacker News 의견

     * 기능 활성화 표시 필요성: Recall 기능이 활성화되었을 때 사용자들이 인지할 수 있도록 명확한 오버레이가 필요함. 그렇지 않으면 악의적인 사용자들이 이를 악용할 수 있음.
     * 브라우저 기록과 비교: Recall 기능은 브라우저의 비암호화된 SQLite 데이터베이스와 유사하게 작동하며, 감시 공격에 취약함. 특히, 작은 규모의 공격이 더 쉬워짐.
     * 보안 조치의 효과: 추가 보안 조치가 실제로 효과가 있을지 지켜봐야 함. 바이러스가 이를 조용히 활성화할 가능성도 있음.
     * 기업 환경에서의 문제: Recall 기능을 기업 환경에서 활성화하는 것은 컴플라이언스 악몽이 될 수 있음.
     * 기능의 필요성 의문: 중요한 정보를 기억하기 위해서는 브라우저 기록이나 최근에 열었던 파일을 참고하는 것이 더 효율적임. AI의 '와우' 요소는 있지만, 보안 문제로 인해 사용하기 꺼려짐.
     * 이름 선택의 문제: Recall이라는 이름은 제품 리콜과 같은 부정적인 사건을 연상시켜 좋지 않은 선택임.
     * 유료 제품 제안: Recall 기능을 무료로 제공하기보다는 유료 제품으로 판매하는 것이 더 나을 것임. 시장의 반응을 통해 제품의 필요성을 판단할 수 있음.
     * OneDrive 문제: Windows에서 OneDrive가 기본으로 설정되어 있어 불편함. 특히 파일 경로가 명확하지 않아 명령줄 작업 시 혼란을 초래함.
     * 개발의 필요성 의문: Recall 기능은 프라이버시와 보안 문제로 인해 개발할 필요가 없었음. 이는 해커들에게 매우 매력적인 타겟이 될 수 있음.
     * 경영진의 요청: 이 기능은 경영진이 원한 것이며, 사람들이 이를 꺼려하지만 아무도 반대하지 못한 상황임.
"
"https://news.hada.io/topic?id=15211","연구진들, 조작된 이미지 포함된 것으로 밝혀진 유명 알츠하이머 논문 철회","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                연구진들, 조작된 이미지 포함된 것으로 밝혀진 유명 알츠하이머 논문 철회

     * 2006년 Nature에 발표된 알츠하이머 연구 논문 철회 결정
          + 미네소타 대학교(UMN) 신경과학자 Karen Ashe가 논문에 조작된 이미지가 포함되었음을 인정함.
          + 논문은 약 2500회 인용되었으며, 철회될 경우 가장 많이 인용된 철회 논문이 될 것임.
     * Ashe는 처음에는 논문의 문제를 수정으로 해결할 수 있다고 주장했으나, 이후 모든 저자가 철회에 동의했음을 밝힘.
          + 첫 저자인 Sylvain Lesné는 철회에 동의하지 않음.
     * 논문은 Aβ*56이라는 아밀로이드 베타 단백질이 알츠하이머를 유발할 수 있다고 주장함.
          + 이 단백질이 알츠하이머와 관련된 새로운 치료 타겟이 될 수 있다고 제안함.
     * Science의 조사 결과, Lesné와 Ashe가 공동 저자로 참여한 여러 논문에서 데이터 조작 증거가 발견됨.
          + 주요 과학자들은 Aβ*56 단백질의 존재 여부와 검출 방법에 의문을 제기함.
     * UMN은 Lesné의 연구에 대한 조사를 진행 중이며, 일부 이미지는 연구 부정행위가 없다고 결론지음.
          + 그러나 다른 의심스러운 이미지에 대해서는 언급하지 않음.
     * 과학계의 반응
          + 과학적 무결성을 지키기 위한 중요한 조치로 평가됨.
          + 다른 저널들도 UMN의 조사 결과를 기다리고 있음.

  GN⁺의 의견

     * 과학적 무결성의 중요성: 연구 데이터의 조작은 과학적 신뢰성을 크게 훼손할 수 있음. 이는 연구 결과의 재현성과 신뢰성을 저해함.
     * 독립적인 조사 필요성 : 연구 부정행위 조사는 독립적인 기관에서 수행되어야 함. 대학 자체 조사는 이해 상충의 가능성이 있음.
     * 알츠하이머 연구의 방향 : Aβ*56 단백질에 대한 의문이 제기되면서, 알츠하이머 연구의 새로운 방향이 필요할 수 있음. 기존 가설에 대한 재검토가 필요함.
     * 연구 철회의 영향 : 철회된 논문을 기반으로 한 후속 연구들도 영향을 받을 수 있음. 이는 연구 자금 및 연구 방향에 큰 변화를 초래할 수 있음.
"
"https://news.hada.io/topic?id=15234","OpenSSH, 비정상적 행동을 제재하는 옵션 도입","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      OpenSSH, 비정상적 행동을 제재하는 옵션 도입

     * PerSourcePenalties와 PerSourcePenaltyExemptList라는 새로운 옵션이 sshd(8)에 도입
          + PerSourcePenalties: 비정상적인 클라이언트 행동을 감지하고 제재를 가하는 기능
          + PerSourcePenaltyExemptList: 특정 클라이언트 주소를 제재에서 제외할 수 있는 기능

  비정상적인 행동 감지 및 제재

     * sshd(8)는 클라이언트가 인증에 반복적으로 실패하거나 sshd를 충돌시키는 등의 비정상적인 행동을 감지함.
     * 이러한 행동이 감지되면 클라이언트 주소에 일정 시간 동안 접속을 거부하는 제재를 가함.
     * 반복적인 위반 시 제재 시간이 증가함.

  기본 설정 및 주의사항

     * PerSourcePenalties는 기본적으로 비활성화되어 있으나, 곧 기본 활성화될 예정임. (OpenBSD 7.6 부터)
     * NAT 블록이나 프록시 뒤에서 많은 사용자가 접속하는 경우, 합법적인 트래픽이 차단될 수 있음.
     * sshd_config(5)에서 PerSourcePenalties, PerSourcePenaltyExemptList, PerSourceNetBlockSize 옵션을 조정하여 환경에 맞게 설정할 필요가 있음.

GN⁺의 의견

     * 보안 강화: 이 기능은 비정상적인 접근 시도를 효과적으로 차단하여 보안을 강화할 수 있음.
     * 관리의 편리성: 특정 클라이언트를 제재에서 제외할 수 있는 옵션이 있어 관리가 용이함.
     * NAT 환경 주의: NAT 환경에서 많은 사용자가 동일한 IP를 사용할 경우, 합법적인 사용자가 차단될 수 있어 주의가 필요함.
     * 기본 활성화: 기본 활성화 시 예상치 못한 차단이 발생할 수 있으므로, 관리자들은 미리 설정을 검토해야 함.
     * 업계 유사 기능: 다른 SSH 서버 소프트웨어에서도 유사한 보안 기능을 제공하므로, 필요에 따라 비교 검토가 필요함.

        Hacker News 의견

     * SSH 서버 작성 경험: IPv4에서는 CGN 사용으로 인해 무고한 사용자가 피해를 볼 가능성이 높아짐. IPv6에서는 새로운 IP를 얻는 것이 쉬워 보호 방법이 효과적이지 않음. 대부분의 공격은 단순한 사전 공격이며, SSH 키 사용 권장.
     * SSH 비밀번호 사용 경고: 인터넷에 노출된 SSH에 비밀번호를 사용하는 것은 매우 위험함. 키 사용이 더 편리하고 안전함.
     * 설정 복잡성: 페널티 시스템이 복잡해 보이며, 기본값이 문서화되지 않음. 소스 코드를 읽어야 하지만 CVS 클라이언트를 설치하기 꺼려짐.
     * 기존 솔루션 사용: 이미 fail2ban을 사용 중이며, sshd에 더 많은 코드를 추가하는 것을 원하지 않음.
     * 내장 기능의 장점: MaxAuthTries와 fail2ban을 사용해봤으며, 내장된 기능이 개선된 점이 있음.
     * 기능 비판: 새로운 IP를 얻는 것이 쉬워 효과가 없을 수 있음. 디버깅이 어려워질 수 있으며, 많은 회사에서 문제가 발생할 수 있음.
     * 봇넷 공격 문제: 봇넷을 사용하는 공격에는 효과가 없을 수 있음.
     * 기능 필요성 의문: 기존 솔루션을 사용 중인 사람들에게 불편함을 초래할 수 있음. 유연한 스크립팅이 필요함.
     * 보안 접근 방식 비판: fail2ban과 sshd의 새로운 기능은 비원칙적인 보안 접근 방식임. 신뢰할 수 있는 네트워크에서만 로그인 허용 권장.
     * OpenBSD 호환성 의문: fail2ban이 OpenBSD에 포팅되었는지 여부를 모르는 사람들이 많음.
"
"https://news.hada.io/topic?id=15240","파인만의 면도날","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                파인만의 면도날

     * 리처드 파인만은 기술적인 내용을 설명할 때, 이해할 수 있는 사람이라면 누구나 이해할 수 있어야 한다고 주장했음.
     * 최근 해커 뉴스에서 ""이 메시지는 더 이상 존재하지 않기 때문에 저장할 수 없습니다. 삭제만 가능합니다.""라는 오류 메시지가 논란이 되었음.
     * 이 오류 메시지는 일반 사용자가 이해하기 어려운 내용이었음.
     * 한 사용자는 ""이 메시지는 메일 서버에서 삭제되었지만, Outlook의 임시 캐시에 남아 있습니다. 메시지 내용을 복사하거나 캐시에서 삭제할 수 있습니다.""라고 설명했음.
     * 일부 사람들은 ""서버""와 ""캐시"" 같은 용어를 일반 사용자가 이해하지 못한다고 비판했음.
     * 그러나 파인만의 주장에 따르면, 모든 사용자를 무시하지 말고, 이해할 수 있는 사람에게는 정확한 정보를 제공해야 함.

    모든 것을 설명할 필요는 없지만, 설명할 때는 충실해야 함

     * 모든 사용자가 소프트웨어의 모든 것을 이해할 필요는 없지만, 설명할 때는 정확해야 함.
     * ""메시지가 더 이상 존재하지 않음"" 오류의 경우, ""오류 코드 1027: 파일을 저장할 수 없음""과 같은 간단한 설명이 더 나을 수 있음.
     * 사용자가 오류 코드를 검색할 수 있도록 하여, 필요한 경우 더 많은 정보를 얻을 수 있게 해야 함.

    파인만의 면도날을 통과하거나 실패한 예시들?

     * 1980년대 TV 쇼 ""Bits and Bytes""는 컴퓨터를 처음 사용하는 사람들에게 컴퓨터 작동 방식을 설명했음.
     * 이 쇼는 컴퓨터를 켜는 방법, ""Enter"" 키를 눌러 텍스트를 입력하는 방법, 이진 코드가 무엇인지 등을 설명했음.

GN⁺의 의견

     * 기술적 설명의 중요성: 기술적인 내용을 설명할 때, 사용자가 이해할 수 있도록 정확하고 명확하게 설명하는 것이 중요함.
     * 사용자 경험 개선: 오류 메시지나 시스템 상태를 정확하게 전달하면, 사용자가 문제를 더 쉽게 이해하고 해결할 수 있음.
     * 교육적 가치: 기술 용어를 사용함으로써 사용자가 새로운 개념을 배우고 이해할 수 있는 기회를 제공함.
     * 비판적 시각: 모든 사용자가 기술 용어를 이해할 수 있는 것은 아니므로, 적절한 균형을 찾는 것이 중요함.
     * 관련 제품 추천: 사용자 친화적인 인터페이스를 제공하는 다른 소프트웨어나 도구를 참고하여, 더 나은 사용자 경험을 제공할 수 있음.
"
"https://news.hada.io/topic?id=15290","지역 사회의 악화, 놀이 기반 어린 시절 상실의 주요 요인","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    지역 사회의 악화, 놀이 기반 어린 시절 상실의 주요 요인

지역 사회의 붕괴가 놀이 기반 어린 시절 상실의 주요 원인

  왜 가까운 공동체에서 자란 아이들이 휴대폰 기반 어린 시절의 해악으로부터 더 보호받는가

    서문

     * Jon Haidt의 서문:
          + The Anxious Generation 집필 당시, 두 가지 비극적 사건을 다룸: 놀이 기반 어린 시절의 상실(1990-2010)과 휴대폰 기반 어린 시절의 도래(2010-2015).
          + 2023년 가을, 책의 개정 작업 중 지역 사회와 신뢰, 사회 자본의 감소가 이 모든 것의 시작임을 깨달음.

    지역 사회의 붕괴

     * 1940-1960년대 미국은 높은 사회 자본을 가짐.
     * 1960년대 중반부터 지역 사회 관계가 감소하기 시작함.
     * 세대 교체와 기술 변화가 주요 원인으로 지목됨.
     * 텔레비전, 자동차, 쇼핑몰 등의 기술이 개인화와 원자화 효과를 가져옴.

    놀이 기반 어린 시절의 상실

     * 지역 사회와 신뢰의 상실로 인해 1990년대부터 아이들을 집 안에 가두기 시작함.
     * 2010년 스마트폰과 소셜 미디어의 도래로 휴대폰 기반 어린 시절이 시작됨.
     * 청소년들이 실외 놀이 대신 온라인 활동에 몰두하게 됨.

    종교와 청소년 정신 건강

     * 종교적이고 보수적인 청소년들이 정신 건강 위기에 덜 영향을 받음.
     * 종교적 공동체는 강한 사회적 지지와 신뢰를 제공함.
     * 종교적 보수 청소년들은 실세계에서 더 많은 시간을 보내고, 소셜 미디어 사용이 적음.

    종교 공동체의 장점

     * 종교적 믿음 자체보다는 조직된 종교와 공유된 믿음이 공동체를 결속시킴.
     * 보수적이고 종교적인 가정은 구조와 의무를 강조함.
     * 종교적 공동체는 강한 사회적 지지와 신뢰를 제공함.

    실세계 공동체의 중요성

     * 가상 네트워크는 실세계 공동체를 대체할 수 없음.
     * 실세계 공동체는 청소년들에게 안정적인 네트워크와 지지를 제공함.
     * 종교적 보수 청소년들은 실세계 공동체에 뿌리를 두고 있어 가상 세계에 덜 의존함.

    결론

     * 디지털 세계를 완전히 버리거나 종교적 보수주의자가 될 필요는 없음.
     * 세속적이고 자유주의적인 부모들은 자녀들에게 강한 실세계 공동체를 제공해야 함.
     * 가상 네트워크는 실세계 공동체를 대체할 수 없음을 인식해야 함.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  GN⁺의 의견

     * 기술과 사회 변화: 기술 발전이 사회적 관계를 어떻게 변화시키는지 이해하는 것이 중요함.
     * 종교 공동체의 역할: 종교적 공동체가 제공하는 사회적 지지와 신뢰는 청소년 정신 건강에 긍정적 영향을 미침.
     * 실세계 공동체의 필요성: 가상 네트워크는 실세계 공동체를 대체할 수 없으며, 실세계에서의 상호작용이 중요함.
     * 디지털 세계와 균형: 디지털 기술의 장점을 활용하면서도 실세계 공동체의 중요성을 잊지 말아야 함.
     * 정책적 접근: 청소년 정신 건강 문제를 해결하기 위해 지역 사회와 공동체 기반의 접근이 필요함.

        Hacker News 의견

     * 물리적 환경 디자인: 유럽과 일본에서는 아이들이 도보나 자전거로 학교에 가는 것이 일반적임. 미국은 자동차 중심의 디자인으로 인해 아이들이 도보나 자전거로 이동하기 어려움.
     * 어린 시절의 공원: 과거의 공원은 더 모험적이고 재미있는 요소가 많았음. 현재의 공원은 안전하지만 지루한 놀이기구로 대체됨.
     * 지역 사회의 붕괴: 부유한 사람들이 사람들을 고립시키면 통제하기 쉽다는 것을 깨달았음. 이는 의도적이거나 효과적인 방법을 찾는 과정에서 발생함.
     * 비판적 의견: 저자가 결론을 미리 정하고 데이터를 맞춘 것 같음. 통제 그룹이나 관련 연구가 부족하고, 휴대폰과 같은 요소는 주제와 무관함.
     * 신뢰 사회의 변화: 미국은 높은 신뢰 사회에서 낮은 신뢰 사회로 전환 중임. 이는 여러 결과 중 하나임.
     * 텔레비전의 영향: 텔레비전이 사회 자본을 파괴했다는 주장은 과장됨. 현재는 모바일 폰과 소셜 미디어가 더 큰 영향을 미침.
     * 부모의 역할: 두 부모가 모두 일하는 것이 기술보다 지역 사회의 붕괴에 더 큰 영향을 미쳤을 것이라는 의견.
     * 작은 마을의 커뮤니티: 작은 마을에서도 강한 커뮤니티가 형성될 수 있음. 이는 사람들 간의 신뢰와 상호작용을 통해 이루어짐.
     * 커뮤니티의 중요성: 커뮤니티를 원하고 가치를 두는 사람들이 모여야 커뮤니티가 형성됨. 다양한 배경의 사람들이 함께 어울릴 수 있음.
     * 과거와 현재의 조화: 과거와 현재의 좋은 부분을 결합하고 나쁜 부분을 제거하는 방법을 찾아야 함. 커뮤니티의 중요성을 재발견함.
     * 가족의 역할: 가족 구성원이 적어지면 가장 가까운 커뮤니티인 가족 내의 상호작용이 줄어들 수 있음.
"
"https://news.hada.io/topic?id=15214","슈퍼 헤비, 멕시코만에 착수","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            슈퍼 헤비, 멕시코만에 착수

        Hacker News 의견

     * SpaceX 팀의 놀라운 성과: 20초 만에 8km에서 1km로 하강 후 물 위에 정지하는 모습이 인상적임. 플로리다의 새로운 발사 시설을 기대하고 있음.
     * NASA Kennedy Visitor Complex 추천: 디즈니 월드 방문 시 NASA Kennedy Visitor Complex도 방문 추천. 아폴로 발사 통제실, 수평으로 놓인 Saturn V 로켓, 달 착륙 모듈, Atlantis 셔틀 등 볼거리가 많음.
     * Starship의 재진입 성공: 재진입 시 열로 인해 날개가 불타는 모습을 보고도 무사히 착수하는 모습이 놀라움.
     * 선체 손상 후 착륙: 선체 일부가 녹아내리는 모습을 보면서도 비교적 통제된 착륙을 하는 모습이 신뢰감을 줌.
     * 4번째 Starship 시험 비행: 4번째 시험 비행이 기술 발전을 크게 이끌었음. 특히 Starship의 견고한 발사 시스템 개발에 중요한 진전이 있었음.
     * 과거의 재진입 방법: 2000년의 비행에서는 팽창식 열 차폐막을 사용해 열을 분산시키는 방법을 사용했음. Zond-6 비행에서는 대기권을 여러 번 통과하며 속도를 줄이는 방법을 사용했음.
     * Starship의 착수 성공: 반쯤 녹은 Starship이 착수하는 모습이 놀라웠음.
     * 재진입 시 실시간 HD 영상: 재진입 시 외부의 실시간 HD 영상을 보는 것이 인상적이었음.
     * Elon Musk의 주장에 대한 회의: Starship의 재진입이 성공적이라면 큰 성과가 될 것임. Artemis 3 임무를 위한 SpaceX의 일정에 맞춰 진행되고 있음.
     * 상단 단계의 재진입: 상단 단계의 재진입이 가장 놀라운 장면이었음. 날개가 불타는 중에도 부드럽게 착수함.
     * Starship의 미래: Starship의 재진입이 매우 흥미로웠음. 모든 것이 ""SF 미래""를 연상시킴.
     * 재진입 플라즈마 색상: 재진입 시 다양한 플라즈마 색상이 보였음. 붉은색/주황색, 파란색/보라색, 흰색/파란색, 노란색 등 다양한 색상이 시간대별로 나타남.
"
"https://news.hada.io/topic?id=15250","PS2 에뮬레이터 감지: 1*X가 X와 같지 않을 때","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     PS2 에뮬레이터 감지: 1*X가 X와 같지 않을 때

PS2 에뮬레이터 감지: 1*X가 X와 같지 않을 때

  PS2 부동 소수점 연산의 문제

     * PS2의 VU(벡터 유닛)에서 곱셈 명령어(MUL, MULi 등)를 사용할 때, 1을 곱한 결과가 원래 값과 같지 않을 수 있음.
     * 이는 VU 개발자 매뉴얼에서도 언급된 내용으로, 1비트의 연산 오류가 발생할 수 있음.
     * 정확한 이유는 알려지지 않았지만, PS2의 소프트웨어 부동 소수점을 구현하는 사람은 이를 해결해야 함.

  이 문제를 이용한 에뮬레이터 감지

     * 이 문제를 일으키는 숫자를 찾아내는 것이 첫 번째 단계임.
     * 0.5 단위로 증가하는 첫 250개의 숫자 중 129.5가 이 문제를 일으키는 숫자임.
     * 아래 코드는 129.5와 1을 곱한 결과가 원래 값과 다른지 확인하는 방법을 보여줌.

int isVUMulErrorPresent() {
  float in[4] __aligned(16) = {129.5f, 0.0f, 0.0f, 0.0f};
  float out[4] __aligned(16) = {0.0f, 0.0f, 0.0f, 0.0f};
  asm __volatile__(
    ""QMTC2 %1, $vf1\n""     // VF1에 129.5f 설정
    ""VADDw $vf2, $vf0, $vf0w\n"" // VF2 = vf0[w] = 1
    ""VMUL $vf1, $vf2, $vf1\n""  // VF1 = 1 * 129.5f
    ""QMFC2 %0, $vf1\n""     // 결과를 EE로 로드
    : ""=r""(out[0])
    : ""r""(in[0]));
  return in[0] != out[0];
}

     * 이 코드는 1과 129.5를 곱한 후 결과를 확인하여 에뮬레이터가 이 문제를 제대로 처리하지 못하는지 감지함.
     * 현재 어떤 에뮬레이터도 이 동작을 정확히 에뮬레이트하지 못함.

GN⁺의 의견

     * PS2 에뮬레이터의 한계: 이 기사는 PS2 에뮬레이터가 실제 하드웨어와 동일하게 동작하지 않는 특정 사례를 보여줌. 이는 에뮬레이터 개발자들에게 중요한 정보가 될 수 있음.
     * 부동 소수점 연산의 복잡성: 부동 소수점 연산은 하드웨어마다 다르게 구현될 수 있음. 이는 소프트웨어 개발자들이 다양한 플랫폼에서 코드를 테스트할 때 고려해야 할 중요한 요소임.
     * 디버깅 도구로서의 활용: 이러한 감지 방법은 에뮬레이터의 정확성을 테스트하는 디버깅 도구로 활용될 수 있음. 이는 에뮬레이터의 품질을 높이는 데 기여할 수 있음.
     * 다른 에뮬레이터와의 비교: 이 기사는 여러 에뮬레이터(PCSX2, Play!, DobieStation, hps2x64) 중 어떤 것도 이 문제를 정확히 에뮬레이트하지 못한다고 언급함. 이는 에뮬레이터 선택 시 중요한 참고 자료가 될 수 있음.
     * 미래의 개선 가능성: 이러한 문제를 해결하기 위한 연구와 개발이 계속된다면, 더 정확한 에뮬레이터가 나올 가능성이 있음. 이는 게임 보존과 접근성 측면에서 긍정적인 영향을 미칠 수 있음.
"
"https://news.hada.io/topic?id=15312","[2024/06/03 ~ 06/09] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024/06/03 ~ 06/09] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)

     * DAIR.AI에서 매주 공개하는 ML 논문들에 대한 글을 자동 번역해보았습니다.
     * 이번 주에 선정된 논문들을 살펴보면, 대부분의 논문이 대규모 언어 모델(LLMs)에 초점을 맞추고 있는 경향이 있습니다. 구체적으로는, 대규모 언어 모델의 개념 추출(Extracting Concepts from GPT-4), 효율성 향상(MatMul-free LLMs), 모델의 사고 과정 이해(Buffer of Thoughts), LLMs의 기하학적 구조(The Geometry of Concepts in LLMs), 그리고 이들 모델의 정렬(Aligning LLMs with Demonstrated Feedback, Towards Scalable Automated Alignment of LLMs)에 대한 연구로 요약할 수 있습니다. 이들 주제는 인공지능 분야에서 LLMs의 이해, 개선, 그리고 적용 가능성을 탐색하는 현재의 관심사를 반영하고 있습니다. 비록 모든 논문의 내용을 상세히 살펴본 것은 아니지만, 제목만으로도 최근 연구의 경향을 파악하는 데 충분해 보입니다.
     * 이 같은 경향은 몇 가지 이유로 설명될 수 있습니다. 먼저, GPT-4와 같은 대규모 언어 모델의 성공 이후 인공지능 연구 분야에서 이러한 모델들에 대한 관심이 급증했습니다. 이러한 모델들은 자연어 처리(NLP)는 물론, 다양한 지식 작업에서 인간 수준의 성능을 달성하는 데 중요한 역할을 하고 있습니다. 두 번째로, LLMs의 이해와 발전은 더 복잡하고 창의적인 작업을 수행할 수 있는 AI 시스템 개발로 이어질 수 있는 기회를 제공합니다. 마지막으로, 이러한 연구는 AI의 안전성과 윤리적 사용을 강화하는 데 필수적인, 모델의 행동을 이해하고 조절할 수 있는 기술 발전에 기여할 수 있습니다. 결과적으로, 이번 주 선택된 논문들은 AI 기술, 특히 대규모 언어 모델 발전의 최전선에서 일어나고 있는 연구와 실험을 반영하고 있습니다.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  NLLB: 신경망 기계 번역을 200개 언어로 확장 / Scaling neural machine translation to 200 languages

    논문 소개

   200개 언어에 걸쳐 전이 학습을 활용하는 대규모 다국어 모델을 제안하고, 희소성 있는 전문가 혼합 아키텍처를 기반으로 하며, 리소스가 적은 언어에 맞춤화된 접근 방식을 통해 데이터를 학습하고, 4만 건의 번역을 평가하여 평균 44%의 번역 품질 향상을 달성했습니다.

     Proposes a massive multilingual model that leverages transfer learning across 200 languages; it’s based on a sparsely Gated Mixture of Experts architecture and trained on data via an approach tailored for low-resource languages; evaluates on 40K translations and achieves an average of 44% improvement in translation quality.

    논문 초록(Abstract)

   신경망 기술의 발전은 기계 번역 연구의 새로운 길을 열었습니다. 오늘날 신경망 기계 번역(NMT) 시스템은 고도의 다국어 용량을 활용하고 제로 샷 번역까지 수행할 수 있어 언어 범위와 품질 측면에서 유망한 결과를 제공합니다. 그러나 고품질의 NMT를 확장하려면 대량의 병렬 이중 언어 데이터가 필요한데, 전 세계 7,000개 이상의 언어에 대해 동일하게 사용할 수 있는 것은 아닙니다. 상대적으로 적은 수의 고자원 언어 그룹의 번역 품질을 개선하는 데 집중하다 보면 자원이 부족한 언어에 연구 관심을 집중하는 대신 장기적으로 디지털 불평등을 악화시킬 수 있습니다. 이러한 패턴을 깨기 위해 언어 간 전이 학습을 활용하는 단일 대규모 다국어 모델인 No Language Left Behind(NLLB)를 소개합니다. 저희는 스파스 게이트 혼합 전문가 아키텍처를 기반으로 조건부 계산
   모델을 개발했으며, 이 모델은 자원이 부족한 언어에 맞춘 새로운 마이닝 기법으로 얻은 데이터로 학습했습니다. 또한 수천 개의 작업을 학습하면서 과적합에 대응하기 위해 여러 가지 아키텍처 및 학습 개선 사항을 고안했습니다. 이를 위해 특별히 개발된 도구, 즉 자동 벤치마크(FLORES-200), 인간 평가 지표(XSTS), 모델의 모든 언어를 포괄하는 독성 검출기를 사용하여 40,000개 이상의 번역 방향에 대한 모델의 성능을 평가했습니다. 이전의 최첨단 모델과 비교했을 때, 당사의 모델은 BLEU에서 측정한 번역 품질이 평균 44% 향상되었습니다. NMT를 200개 언어로 확장하는 방법을 시연하고 이러한 노력의 모든 기여를 비상업적 용도로 자유롭게 사용할 수 있도록 함으로써 범용 번역 시스템 개발을 위한 중요한 토대를 마련했습니다.

     The development of neural techniques has opened up new avenues for research in machine translation. Today, neural machine translation (NMT) systems can leverage highly multilingual capacities and even perform zero-shot translation, delivering promising results in terms of language coverage and quality. However, scaling quality NMT requires large volumes of parallel bilingual data, which are not equally available for the 7,000+ languages in the world. Focusing on improving the translation qualities of a relatively small group of high-resource languages comes at the expense of directing research attention to low-resource languages, exacerbating digital inequities in the long run. To break this pattern, here we introduce No Language Left Behind—a single massively multilingual model that leverages transfer learning across languages. We developed a conditional computational model based on the Sparsely Gated Mixture of Experts architecture, which we trained on data obtained with
     new mining techniques tailored for low-resource languages. Furthermore, we devised multiple architectural and training improvements to counteract overfitting while training on thousands of tasks. We evaluated the performance of our model over 40,000 translation directions using tools created specifically for this purpose—an automatic benchmark (FLORES-200), a human evaluation metric (XSTS) and a toxicity detector that covers every language in our model. Compared with the previous state-of-the-art models, our model achieves an average of 44% improvement in translation quality as measured by BLEU. By demonstrating how to scale NMT to 200 languages and making all contributions in this effort freely available for non-commercial use, our work lays important groundwork for the development of a universal translation system.

    논문 링크

   https://www.nature.com/articles/s41586-024-07335-x

    더 읽어보기

   https://github.com/facebookresearch/fairseq/tree/nllb

   https://x.com/AIatMeta/status/1798420492774432769
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  GPT-4에서 개념 추출하기 / Extracting Concepts from GPT-4

    연구 소개

   GPT-4에서 약 1,600만 개의 해석 가능한 패턴을 추출하기 위해 희소 자동 인코더를 기반으로 확장 가능한 새로운 방법을 제안합니다. 이 방법은 예측 가능한 확장성을 보여주며 이전 기술보다 효율적입니다.

     Proposes a new scalable method based on sparse autoencoders to extract around 16 million interpretable patterns from GPT-4; the method demonstrates predictable scaling and is more efficient than previous techniques.

    논문 초록

   SAE(Sparse AutoEncoder, 희소 오토 인코더)는 희소 병목 계층에서 활성화를 재구성하여 언어 모델에서 해석 가능한 특징을 추출하기 위한 유망한 비지도 접근 방식을 제공합니다. 언어 모델은 많은 개념을 학습하기 때문에 모든 관련 특징을 복구하려면 자동 인코더의 크기가 매우 커야 합니다. 그러나 재구성과 희소성 목표의 균형을 맞출 필요가 있고 데드 잠상도 존재하기 때문에 자동 인코더 스케일링의 속성을 연구하는 것은 어렵습니다. 저희는 K-스페어 자동 인코더[Makhzani and Frey, 2013]를 사용하여 희소성을 직접 제어함으로써 튜닝을 간소화하고 재구성 희소성의 경계를 개선할 것을 제안합니다. 또한 시도한 가장 큰 규모에서도 데드 잠상이 거의 발생하지 않는 수정 사항을 발견했습니다. 이러한 기술을 사용하여 자동 인코더 크기 및 희소성과 관련하여 깨끗한
   스케일링 법칙을 찾았습니다. 또한 가설화된 특징의 복구, 활성화 패턴의 설명 가능성, 다운스트림 효과의 희소성을 기반으로 특징 품질을 평가하기 위한 몇 가지 새로운 메트릭을 도입했습니다. 이러한 지표는 모두 일반적으로 자동 인코더 크기에 따라 향상됩니다. 저희 접근 방식의 확장성을 입증하기 위해 400억 개의 토큰에 대해 1,600만 개의 잠재적 자동 인코더를 GPT-4 활성화로 훈련했습니다. 오픈 소스 모델용 코드와 자동 인코더, 비주얼라이저를 공개합니다.

     Sparse autoencoders provide a promising unsupervised approach for extracting interpretable features from a language model by reconstructing activations from a sparse bottleneck layer. Since language models learn many concepts, autoencoders need to be very large to recover all relevant features. However, studying the properties of autoencoder scaling is difficult due to the need to balance reconstruction and sparsity objectives and the presence of dead latents. We propose using k-sparse autoencoders [Makhzani and Frey, 2013] to directly control sparsity, simplifying tuning and improving the reconstruction-sparsity frontier. Additionally, we find modifications that result in few dead latents, even at the largest scales we tried. Using these techniques, we find clean scaling laws with respect to autoencoder size and sparsity. We also introduce several new metrics for evaluating feature quality based on the recovery of hypothesized features, the explainability of activation
     patterns, and the sparsity of downstream effects. These metrics all generally improve with autoencoder size. To demonstrate the scalability of our approach, we train a 16 million latent autoencoder on GPT-4 activations for 40 billion tokens. We release code and autoencoders for open-source models, as well as a visualizer.

    연구 및 논문 링크

   https://openai.com/index/extracting-concepts-from-gpt-4/

   https://cdn.openai.com/papers/sparse-autoencoders.pdf

    더 읽어보기

   https://github.com/openai/sparse_autoencoder

   https://openaipublic.blob.core.windows.net/sparse-autoencoder/…

   https://x.com/OpenAI/status/1798762092528586945
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  트랜스포머는 SSM입니다: 구조화된 상태 공간 이중성을 통한 일반화된 모델과 효율적인 알고리즘 / Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality

    논문 소개

   상태 공간 모델(SSM)과 구조화된 주의력을 결합한 새로운 아키텍처는 8배 더 큰 상태를 사용하고 50% 더 빠르게 훈련하며, 새로운 상태 공간 이중성 계층은 Mamba에서 사용된 접근 방식에 비해 더 효율적이고 확장 가능하며, 대용량 상태 용량이 필요한 작업의 결과를 개선합니다.

     A new architecture that combines state space models (SSMs) and structured attention; it uses 8x larger states and trains 50% faster; the new state space duality layer is more efficient and scalable compared to the approach used in Mamba; it also improves results on tasks that require large state capacity.

    논문 초록(Abstract)

   트랜스포머는 언어 모델링에서 딥러닝의 성공을 이끈 주요 아키텍처였지만, 최근에는 Mamba와 같은 상태 공간 모델(SSM)이 중소 규모에서 트랜스포머와 비슷하거나 더 뛰어난 성능을 발휘하는 것으로 나타났습니다. 우리는 이러한 모델 군이 실제로 매우 밀접하게 관련되어 있음을 보여주고, 잘 연구된 구조화된 반분할 행렬의 다양한 분해를 통해 연결된 SSM과 주의의 변형 사이의 풍부한 이론적 연결 프레임워크를 개발합니다. 상태 공간 이중성(SSD) 프레임워크를 통해 언어 모델링에서 Transformers와 경쟁력을 유지하면서 2~8배 더 빠른 Mamba의 선택적 SSM을 개선한 새로운 아키텍처(Mamba-2)를 설계할 수 있습니다.

     While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale. We show that these families of models are actually quite closely related, and develop a rich framework of theoretical connections between SSMs and variants of attention, connected through various decompositions of a well-studied class of structured semiseparable matrices. Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba's selective SSM that is 2-8X faster, while continuing to be competitive with Transformers on language modeling.

    논문 링크

   https://arxiv.org/abs/2405.21060

    더 읽어보기

   https://x.com/_albertgu/status/1797651223035904355
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  확장 가능한, 행렬곱(MatMul) 없는 언어 모델링 / Scalable MatMul-free Language Modeling

    논문 소개

   LLM에서 행렬 곱셈 연산을 제거하면서 10억 개의 매개변수 규모에서 성능을 유지하는 구현을 제안하고, 모델 크기가 커질수록 고정밀 트랜스포머와 MatMul이 없는 모델 간의 성능이 좁아지며, 추론 중에 최적화된 커널을 사용하면 메모리 소비가 10배 이상 줄어든다고 주장합니다.

     Proposes an implementation that eliminates matrix multiplication operations from LLMs while maintaining performance at billion-parameter scales; the performance between full precision Transformers and the MatMul-free models narrows as the model size increases; claims that by using an optimized kernel during inference, memory consumption is reduced by more than 10x.

    논문 초록(Abstract)

   일반적으로 행렬 곱셈(MatMul)은 대규모 언어 모델(LLM)의 전체 계산 비용을 가장 많이 차지합니다. 이 비용은 LLM이 더 큰 임베딩 차원과 컨텍스트 길이로 확장될 때만 증가합니다. 이 연구에서는 10억 개 매개변수 규모에서 강력한 성능을 유지하면서 LLM에서 MatMul 연산을 완전히 제거할 수 있음을 보여줍니다. 실험 결과, 우리가 제안한 MatMul 없는 모델이 최소 27억 개 이상의 파라미터 규모에서 추론 시 훨씬 더 많은 메모리를 필요로 하는 최신 Transformer와 대등한 성능을 달성하는 것으로 나타났습니다. 확장 법칙을 조사한 결과, 모델 크기가 커질수록 MatMul-free 모델과 완전 정밀 Transformer 간의 성능 격차가 좁혀지는 것을 확인했습니다. 또한 이 모델의 GPU 효율적 구현을 통해 훈련 시 최적화되지 않은 기준선보다 메모리 사용량을 최대 61%까지 줄일 수 있습니다. 추론
   중에 최적화된 커널을 활용하면 최적화되지 않은 모델에 비해 모델의 메모리 소비를 10배 이상 줄일 수 있습니다. 아키텍처의 효율성을 적절히 정량화하기 위해 우리는 GPU가 할 수 있는 것 이상의 경량 연산을 활용하는 맞춤형 하드웨어 솔루션을 FPGA에 구축했습니다. 사람이 읽을 수 있는 처리량을 넘어서는 13W로 10억 개의 매개변수 규모 모델을 처리하여 LLM을 두뇌와 같은 효율성에 가깝게 만들었습니다. 이 작업은 효과적인 성능을 유지하면서 LLM을 얼마나 줄일 수 있는지 보여줄 뿐만 아니라 차세대 경량 LLM을 처리할 때 미래의 가속기가 최적화해야 할 연산 유형을 제시합니다. 코드 구현은 \url{https://github.com/ridgerchu/matmulfreellm}에서 확인할 수 있습니다.

     Matrix multiplication (MatMul) typically dominates the overall computational cost of large language models (LLMs). This cost only grows as LLMs scale to larger embedding dimensions and context lengths. In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model's memory consumption can be reduced by more than 10x
     compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs. Our code implementation is available at \url{https://github.com/ridgerchu/matmulfreellm}.

    논문 링크

   https://arxiv.org/abs/2406.02528

    더 읽어보기

   https://github.com/ridgerchu/matmulfreellm

   https://x.com/omarsar0/status/1798373841741185261
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  생각의 버퍼: 대규모 언어 모델을 사용한 사고 증강 추론 / Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models

    논문 소개

   LLM 기반 추론의 정확성, 효율성 및 견고성을 향상시키기 위한 사고 증강 추론 접근 방식을 제시합니다. 문제 해결 프로세스에서 추출된 높은 수준의 사고(사고 템플릿)가 포함된 메타 버퍼를 활용하고, 관련 사고 템플릿을 검색한 다음 사고 증강 추론 프로세스를 위한 작업별 추론 구조로 인스턴스화합니다. 트리 오브 생각과 같은 다중 질의 프롬프트 방법의 12% 비용으로 10개 도전 과제에서 SOTA 성능을 입증했습니다.

     Presents a thought-augmented reasoning approach to enhance the accuracy, efficiency, and robustness of LLM-based reasoning; it leverages a meta-buffer containing high-level thoughts (thought templates) distilled from problem-solving processes; the relevant thought template is then retrieved and instantiated with task-specific reasoning structures for the thought-augmented reasoning process; it demonstrates SOTA performance on 10 challenging tasks while requiring 12% of the cost of multi-query prompting methods like Tree-of-Thoughts.

    논문 초록(Abstract)

   대규모 언어 모델(LLM)의 정확성, 효율성, 견고성을 향상시키기 위한 새롭고 다양한 사고 증강 추론 접근 방식인 생각의 버퍼(BoT)를 소개합니다. 구체적으로는 다양한 작업의 문제 해결 프로세스에서 추출한 일련의 유익한 고급 사고, 즉 사고 템플릿을 저장하는 메타 버퍼를 제안합니다. 그런 다음 각 문제에 대해 관련 사고 템플릿을 검색하고 이를 특정 추론 구조로 적응적으로 인스턴스화하여 효율적인 추론을 수행합니다. 또한 확장성과 안정성을 보장하기 위해 메타 버퍼를 동적으로 업데이트하는 버퍼 관리자를 제안하여 더 많은 과제가 해결될수록 메타 버퍼의 용량을 향상시킵니다. 10개의 까다로운 추론 집약적 작업에 대한 광범위한 실험을 수행한 결과, 기존 SOTA 방식에 비해 게임 오브 24에서 11%, 기하학적 도형에서 20%, 체크메이트 인 원에서 51% 등
   상당한 성능 향상을 달성했습니다. 추가 분석 결과, 평균적으로 다중 쿼리 프롬프트 방식(예: 트리/생각 그래프)의 12%에 불과한 비용만 소요되는 반면, BoT의 우수한 일반화 능력과 모델 견고성이 입증되었습니다. 특히, 저희는 Llama3-8B+BoT가 Llama3-70B 모델을 능가할 수 있는 잠재력을 가지고 있음을 발견했습니다. 프로젝트는 다음 링크에서 확인할 수 있습니다: https://github.com/YangLing0818/buffer-of-thought-llm

     We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs). Specifically, we propose meta-buffer to store a series of informative high-level thoughts, namely thought-template, distilled from the problem-solving processes across various tasks. Then for each problem, we retrieve a relevant thought-template and adaptively instantiate it with specific reasoning structures to conduct efficient reasoning. To guarantee the scalability and stability, we further propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved. We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and achieve significant performance improvements over previous SOTA methods: 11% on Game of 24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis demonstrate the superior
     generalization ability and model robustness of our BoT, while requiring only 12% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average. Notably, we find that our Llama3-8B+BoT has the potential to surpass Llama3-70B model. Our project is available at: https://github.com/YangLing0818/buffer-of-thought-llm

    논문 링크

   https://arxiv.org/abs/2406.04271

    더 읽어보기

   https://github.com/YangLing0818/buffer-of-thought-llm

   https://x.com/omarsar0/status/1799113545696567416
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  SaySelf: 자기 성찰적 근거로 자신감을 표현하도록 LLM 교육하기 / SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales

    논문 소개

   LLM이 보다 정확한 세분화된 신뢰도 추정치와 자기 반성적 근거를 표현하도록 가르치는 훈련 프레임워크로, 여러 추론 체인 간의 차이 요약이 포함된 데이터 세트에서 감독된 미세 조정을 수행한 다음 강화 학습을 적용하여 신뢰도 추정치를 보정함으로써 LLM이 정확하고 높은 신뢰도의 예측을 생성하고 잘못된 출력에 대해 과신하는 것을 불이익을 주도록 장려합니다.

     A training framework to teach LLMs to express more accurate fine-grained confidence estimates and self-reflective rationales; it performs supervised finetuning on a dataset that contains summaries of the difference between multiple reasoning chains; reinforcement learning is then applied to calibrate confidence estimates, encouraging the LLM to produce accurate, high-confidence predictions and penalize overconfidence in erroneous outputs.

    논문 초록(Abstract)

   대규모 언어 모델(LLM)은 종종 부정확하거나 조작된 정보를 생성하고 일반적으로 신뢰도를 표시하지 않아 광범위한 적용이 제한되는 경우가 많습니다. 이전 연구에서는 직접 또는 자체 일관성 프롬프트 또는 감독된 미세 조정을 위한 특정 데이터 세트를 구성하여 LLM에서 신뢰도를 이끌어 냈습니다. 프롬프트 기반 접근 방식은 성능이 떨어지고, 훈련 기반 접근 방식은 이진 또는 부정확한 그룹 수준의 신뢰도 추정으로 제한됩니다. 이 연구에서는 LLM이 보다 정확한 세분화된 신뢰도 추정치를 표현하도록 가르치는 훈련 프레임워크인 고급 SaySelf를 소개합니다. 또한, 신뢰도 점수 외에도 SaySelf는 LLM이 파라메트릭 지식의 격차를 명확하게 식별하고 불확실성을 설명하는 자기 성찰적 근거를 생성하도록 유도하는 프로세스를 시작합니다. 이는 LLM을 사용하여
   자연어를 통해 특정 지식의 불확실성을 자동으로 요약함으로써 이루어집니다. 요약은 샘플링된 여러 추론 체인의 불일치 분석을 기반으로 하며, 결과 데이터는 감독된 미세 조정에 활용됩니다. 또한 세심하게 설계된 보상 함수와 함께 강화 학습을 활용하여 신뢰도 추정치를 보정함으로써 LLM이 정확하고 신뢰도가 높은 예측을 제공하고 잘못된 출력에 대한 과신에 불이익을 주도록 동기를 부여합니다. 배포 내 및 배포 외 데이터 세트의 실험 결과는 신뢰도 보정 오류를 줄이고 작업 성능을 유지하는 데 있어 SaySelf가 효과적임을 보여줍니다. 또한 생성된 자기반성적 근거가 합리적이며 보정에 더욱 기여할 수 있음을 보여줍니다. 코드는 https://github.com/xu1868/SaySelf 에 공개되어 있습니다.

     Large language models (LLMs) often generate inaccurate or fabricated information and generally fail to indicate their confidence, which limits their broader applications. Previous work elicits confidence from LLMs by direct or self-consistency prompting, or constructing specific datasets for supervised finetuning. The prompting-based approaches have inferior performance, and the training-based approaches are limited to binary or inaccurate group-level confidence estimates. In this work, we present the advanced SaySelf, a training framework that teaches LLMs to express more accurate fine-grained confidence estimates. In addition, beyond the confidence scores, SaySelf initiates the process of directing LLMs to produce self-reflective rationales that clearly identify gaps in their parametric knowledge and explain their uncertainty. This is achieved by using an LLM to automatically summarize the uncertainties in specific knowledge via natural language. The summarization is
     based on the analysis of the inconsistency in multiple sampled reasoning chains, and the resulting data is utilized for supervised fine-tuning. Moreover, we utilize reinforcement learning with a meticulously crafted reward function to calibrate the confidence estimates, motivating LLMs to deliver accurate, high-confidence predictions and to penalize overconfidence in erroneous outputs. Experimental results in both in-distribution and out-of-distribution datasets demonstrate the effectiveness of SaySelf in reducing the confidence calibration error and maintaining the task performance. We show that the generated self-reflective rationales are reasonable and can further contribute to the calibration. The code is made public at https://github.com/xu1868/SaySelf.

    논문 링크

   https://arxiv.org/abs/2405.20974

    더 읽어보기

   https://github.com/xu1868/SaySelf

   https://x.com/omarsar0/status/1797682549608833477
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  대규모 언어 모델에서 범주형 및 계층형 개념의 기하학 / The Geometry of Categorical and Hierarchical Concepts in Large Language Models

    논문 소개

   범주형 개념의 기하학적 구조와 이들 간의 계층적 관계가 LLM에서 어떻게 인코딩되는지 연구하고, 단순한 범주형 개념은 LLM에 의해 단순화로 표현되고 복잡한 개념은 계층적 구조를 반영하는 단순화의 직접 합으로 구성된 폴리토프로 표현된다는 사실을 발견합니다.

     Studies the geometry of categorical concepts and how the hierarchical relations between them are encoded in LLMs; finds that simple categorical concepts are represented as simplices by the LLMs and complex concepts are represented as polytopes constructed from direct sums of simplices, which reflect the hierarchical structure.

    논문 초록(Abstract)

   대규모 언어 모델의 표현 공간에서 의미론적 의미가 어떻게 부호화되는지를 이해하는 것은 해석 가능성의 근본적인 문제입니다. 이 논문에서는 이 분야의 두 가지 기본 질문을 연구합니다. 첫째, {'포유류', '새', '파충류', '물고기'}와 같은 범주형 개념은 어떻게 표현되는가? 둘째, 개념 간의 계층적 관계는 어떻게 인코딩되어 있을까요? 예를 들어, '개'가 '포유류'의 일종이라는 사실은 어떻게 인코딩될까요? 이 질문에 답하기 위해 선형 표상 가설을 확장하는 방법을 보여드립니다. 단순한 범주형 개념은 단순화로 표현되고, 계층적으로 관련된 개념은 우리가 정확하게 표현하는 의미에서 직교하며, (결과적으로) 복잡한 개념은 계층적 구조를 반영하여 단순화의 직접 합으로 구성된 폴리토프로 표현된다는 놀랍도록 단순한 구조를 발견합니다. 이러한 이론적
   결과를 Gemma 대규모 언어 모델에서 검증하여 WordNet의 데이터를 사용하여 계층적으로 관련된 957개의 개념에 대한 표현을 추정합니다.

     Understanding how semantic meaning is encoded in the representation spaces of large language models is a fundamental problem in interpretability. In this paper, we study the two foundational questions in this area. First, how are categorical concepts, such as {'mammal', 'bird', 'reptile', 'fish'}, represented? Second, how are hierarchical relations between concepts encoded? For example, how is the fact that 'dog' is a kind of 'mammal' encoded? We show how to extend the linear representation hypothesis to answer these questions. We find a remarkably simple structure: simple categorical concepts are represented as simplices, hierarchically related concepts are orthogonal in a sense we make precise, and (in consequence) complex concepts are represented as polytopes constructed from direct sums of simplices, reflecting the hierarchical structure. We validate these theoretical results on the Gemma large language model, estimating representations for 957 hierarchically related
     concepts using data from WordNet.

    논문 링크

   https://arxiv.org/abs/2406.01506

    더 읽어보기

   https://x.com/omarsar0/status/1798010546522103898
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  보여주기만 하고 말하지 않기: 언어 모델을 데모 피드백에 맞게 조정하기 / Show, Don't Tell: Aligning Language Models with Demonstrated Feedback

    논문 소개

   피드백으로 아주 적은 수의 데모를 통해 특정 설정에 맞게 LLM을 조정하는 방법을 제안하고, 사용자의 데모 행동에 맞게 LLM 출력을 조정하며, 여러 도메인에서 세분화된 스타일과 작업 조정을 학습할 수 있고, 테스트된 벤치마크에서 소수 샷 프롬프트, SFT 및 셀프 플레이 방법보다 뛰어난 성능을 발휘합니다.

     Proposes a method to align LLMs to a specific setting via a very small number of demonstrations as feedback; it aligns LLM outputs to a user’s demonstrated behaviors and can learn fine-grained style and task alignment across domains; outperforms few-shot prompting, SFT, and self-play methods on the tested benchmarks.

    논문 초록(Abstract)

   언어 모델은 다수의 집단적 목소리를 에뮬레이션하도록 조정되기 때문에 어느 누구와도 일치하지 않는 결과를 낳습니다. LLM을 일반적인 출력에서 벗어나도록 조정하는 것은 감독된 미세 조정 또는 RLHF를 통해 가능하지만, 새로운 임시 작업을 위해서는 엄청나게 큰 데이터 세트가 필요합니다. 대신 아주 적은 수의 데모($<10$)를 피드백으로 활용하여 특정 설정에 맞게 LLM을 조정하는 것이 가능하다고 주장합니다. 우리의 방법인 데모 반복 작업 최적화(DITTO)는 언어 모델 출력을 사용자의 데모 행동에 직접 정렬합니다. 온라인 모방 학습에서 아이디어를 얻어 파생된 DITTO는 사용자의 데모를 LLM과 중간 체크포인트의 출력보다 선호되는 것으로 취급하여 온라인 비교 데이터를 저렴하게 생성합니다. 뉴스 기사, 이메일, 블로그 게시물과 같은 도메인 전반에 걸쳐
   세분화된 스타일과 작업 정렬을 학습하는 DITTO의 능력을 평가합니다. 또한 참가자들로부터 다양한 데모를 요청하는 사용자 연구를 수행합니다($N=16$). 벤치마크와 사용자 연구 결과, DITTO의 승률은 몇 번의 프롬프트, 감독에 의한 미세 조정 및 기타 셀프 플레이 방식보다 평균 19% 포인트 더 높은 것으로 나타났습니다. 데모를 직접 피드백으로 사용함으로써 DITTO는 LLM을 효과적으로 커스터마이징할 수 있는 새로운 방법을 제공합니다.

     Language models are aligned to emulate the collective voice of many, resulting in outputs that align with no one in particular. Steering LLMs away from generic output is possible through supervised finetuning or RLHF, but requires prohibitively large datasets for new ad-hoc tasks. We argue that it is instead possible to align an LLM to a specific setting by leveraging a very small number ($<10$) of demonstrations as feedback. Our method, Demonstration ITerated Task Optimization (DITTO), directly aligns language model outputs to a user's demonstrated behaviors. Derived using ideas from online imitation learning, DITTO cheaply generates online comparison data by treating users' demonstrations as preferred over output from the LLM and its intermediate checkpoints. We evaluate DITTO's ability to learn fine-grained style and task alignment across domains such as news articles, emails, and blog posts. Additionally, we conduct a user study soliciting a range of demonstrations from
     participants ($N=16$). Across our benchmarks and user study, we find that win-rates for DITTO outperform few-shot prompting, supervised fine-tuning, and other self-play methods by an average of 19% points. By using demonstrations as feedback directly, DITTO offers a novel method for effective customization of LLMs.

    논문 링크

   https://arxiv.org/abs/2406.00888

    더 읽어보기

   https://x.com/arankomatsuzaki/status/1797833884463472653
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  확장 가능한 LLM의 자동화된 정렬을 향해: 서베이 논문 / Towards Scalable Automated Alignment of LLMs: A Survey

    논문 소개

   LLM을 정렬하는 데 사용되는 방법에 대한 개요를 제공하고 다음 4가지 방향을 살펴봅니다: 1) 귀납적 편향을 통한 정렬, 2) 행동 모방을 통한 정렬, 3) 모델 피드백을 통한 정렬, 4) 환경 피드백을 통한 정렬.

     Provides an overview of methods used for alignment of LLMs; explores the 4 following directions: 1) aligning through inductive bias, 2) aligning through behavior imitation, 3) aligning through model feedback, and 4) aligning through environment feedback.

    논문 초록(Abstract)

   정렬은 인간의 요구를 충족하는 대규모 언어 모델(LLM)을 구축하는 데 있어 가장 중요한 단계입니다. LLM이 점차 인간의 능력을 능가하는 수준으로 빠르게 발전함에 따라 수작업 주석에 기반한 기존의 얼라인먼트 방식으로는 확장성 요구를 충족할 수 없는 경우가 점점 더 많아지고 있습니다. 따라서 자동화된 정렬 신호의 새로운 소스와 기술적 접근 방식을 모색할 필요성이 절실히 요구되고 있습니다. 이 백서에서는 최근에 등장한 자동 정렬 방법을 체계적으로 검토하여 LLM의 역량이 인간의 역량을 넘어설 때 효과적이고 확장 가능한 자동 정렬을 달성하는 방법을 모색하고자 합니다. 특히 정렬 신호의 출처에 따라 기존의 자동 정렬 방법을 크게 4가지로 분류하고, 각 분류의 현황과 발전 가능성에 대해 논의합니다. 또한 자동 정렬을 가능하게 하는 기본
   메커니즘을 살펴보고, 정렬의 근본적인 역할에서 자동 정렬 기술을 실현하고 효과적으로 만드는 필수 요소에 대해 논의합니다.

     Alignment is the most critical step in building large language models (LLMs) that meet human needs. With the rapid development of LLMs gradually surpassing human capabilities, traditional alignment methods based on human-annotation are increasingly unable to meet the scalability demands. Therefore, there is an urgent need to explore new sources of automated alignment signals and technical approaches. In this paper, we systematically review the recently emerging methods of automated alignment, attempting to explore how to achieve effective, scalable, automated alignment once the capabilities of LLMs exceed those of humans. Specifically, we categorize existing automated alignment methods into 4 major categories based on the sources of alignment signals and discuss the current status and potential development of each category. Additionally, we explore the underlying mechanisms that enable automated alignment and discuss the essential factors that make automated alignment
     technologies feasible and effective from the fundamental role of alignment.

    논문 링크

   https://arxiv.org/abs/2406.01252

    더 읽어보기

   https://x.com/omarsar0/status/1798014572663583165
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  AgentGym: 다양한 환경에서 대규모 언어 모델 기반 에이전트 진화하기 / AgentGym: Evolving Large Language Model-based Agents across Diverse Environments

    논문 소개

   광범위한 실시간 동시 에이전트 탐색을 위해 다양한 환경과 작업을 지원하는 새로운 프레임워크로, 자체 진화 능력을 갖춘 범용 LLM 기반 에이전트를 구축하고 작업과 환경 전반에서 이전에 본 데이터 이상의 잠재력을 탐색할 수 있습니다.

     A new framework featuring various environments and tasks for broad, real-time, and concurrent agent exploration; builds a generally capable LLM-based agent with self-evolution abilities and explores its potential beyond previously seen data across tasks and environments.

    논문 초록(Abstract)

   다양한 작업을 처리하고 여러 환경에서 스스로 진화할 수 있는 제너럴리스트 에이전트를 구축하는 것은 AI 커뮤니티의 장기적인 목표입니다. 대규모 언어 모델(LLM)은 일반화된 기능으로 인해 이러한 에이전트를 구축할 수 있는 유망한 기반으로 간주됩니다. 현재의 접근 방식은 LLM 기반 에이전트가 전문가가 제공한 궤적을 단계별로 모방하도록 하여 사람의 감독이 필요하므로 확장하기 어렵고 환경 탐색이 제한적이거나, 에이전트가 고립된 환경에서 탐색하고 학습하도록 하여 일반화가 제한된 전문 에이전트를 만들게 하는 방식이 있습니다. 이 백서에서는 자기 진화 능력을 갖춘 범용 LLM 기반 에이전트를 구축하기 위한 첫걸음을 내딛습니다. 우리는 세 가지 요소를 확인합니다: 1) 에이전트의 탐색과 학습을 위한 다양한 환경, 2) 에이전트의 기본 능력과 사전
   지식을 갖추기 위한 궤적 세트, 3) 효과적이고 확장 가능한 진화 방법. 유니티는 광범위한 실시간 단일 형식의 동시 에이전트 탐색을 위한 다양한 환경과 작업을 갖춘 새로운 프레임워크인 에이전트짐을 제안합니다. 에이전트짐에는 확장된 지침이 포함된 데이터베이스, 벤치마크 제품군, 환경 전반에 걸친 고품질 궤적도도 포함되어 있습니다. 다음으로, 작업과 환경 전반에서 이전에 볼 수 있었던 데이터를 넘어 에이전트 자체 진화의 가능성을 조사하기 위해 새로운 방법인 AgentEvol을 제안합니다. 실험 결과, 진화한 에이전트가 SOTA 모델에 필적하는 결과를 달성할 수 있음을 보여줍니다. 플랫폼, 데이터 세트, 벤치마크, 체크포인트 및 알고리즘 구현을 포함한 AgentGym 제품군을 출시합니다. 에이전트짐 제품군은 https://github.com/WooooDyy/AgentGym 에서 확인할 수
   있습니다.

     Building generalist agents that can handle diverse tasks and evolve themselves across different environments is a long-term goal in the AI community. Large language models (LLMs) are considered a promising foundation to build such agents due to their generalized capabilities. Current approaches either have LLM-based agents imitate expert-provided trajectories step-by-step, requiring human supervision, which is hard to scale and limits environmental exploration; or they let agents explore and learn in isolated environments, resulting in specialist agents with limited generalization. In this paper, we take the first step towards building generally-capable LLM-based agents with self-evolution ability. We identify a trinity of ingredients: 1) diverse environments for agent exploration and learning, 2) a trajectory set to equip agents with basic capabilities and prior knowledge, and 3) an effective and scalable evolution method. We propose AgentGym, a new framework featuring a
     variety of environments and tasks for broad, real-time, uni-format, and concurrent agent exploration. AgentGym also includes a database with expanded instructions, a benchmark suite, and high-quality trajectories across environments. Next, we propose a novel method, AgentEvol, to investigate the potential of agent self-evolution beyond previously seen data across tasks and environments. Experimental results show that the evolved agents can achieve results comparable to SOTA models. We release the AgentGym suite, including the platform, dataset, benchmark, checkpoints, and algorithm implementations. The AgentGym suite is available on https://github.com/WooooDyy/AgentGym.

    논문 링크

   https://arxiv.org/abs/2406.04151

    더 읽어보기

   https://github.com/WooooDyy/AgentGym

   https://x.com/arankomatsuzaki/status/1798904095669121443
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  원문

   https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-90f
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   이 글은 GPT 모델로 정리한 것으로, 잘못된 부분이 있을 수 있으니 글 아래쪽의 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다. 🤗

   ⚠️광고⚠️: 🔥파이토치 한국 사용자 모임🇰🇷이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일💌로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)
"
"https://news.hada.io/topic?id=15219","Ask GN: 이번 주말에 뭐 하시나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Ask GN: 이번 주말에 뭐 하시나요?

   이번 주말에 뭘 하려고 계획 중인지 편하게 얘기해 보아요.

   읽을 책, 가볼 곳, 해볼 것.. 어떤 것이든 좋습니다.
   도움 요청이나 피드백 요청도 좋습니다.
   물론! 아무것도 하지 않고 쉬는 것도 훌륭합니다.

   지난 주말에 계획하셨던 일의 회고도 한번 남겨봐 주세요.

   안녕하세요. 가입하고 처음 댓글 달아봅니다. 주말에는 주로 자기개발을 합니다. ^_^

   주말근무합니다엉엉

   퇴사 이후 어떻게 할지에 대한 계획을 정리할거 같네요

   영등포의 50년된 오징어 볶음 집인 여로집에 갑니다. 은근 매운데 종종 생각나더라고요.
   일욜에는 회사에서 팀을 이끌게 되서, 스테이지를 끊고 가기 위해서 상반기 셀프회고를 조금 당겨 하려고 합니다.

   매주 감사합니다. 저의 예정 맛집 리스트에 주섬주섬

   강릉 단오제 놀러갑니다. 비가 온다고 해서 걱정이네요.. ㅠㅠ
"
"https://news.hada.io/topic?id=15301","Google Mesop - 파이썬으로 웹앱 만들기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Google Mesop - 파이썬으로 웹앱 만들기

     * 구글에서 내부용 앱이나 데모를 빠르게 만들기 위해 사용하던 파이썬 UI 프레임워크
     * UI 초보자를 위한 직관적인 기능
          + 관용적인 파이썬 코드로 UI 작성
          + 이해하기 쉬운 Reactive UI 패러다임
          + 즉시 사용가능한 컴포넌트
     * 핫 리로드 기능 제공으로 브라우저가 자동으로 다시 로드하고 상태를 보존
     * 강력한 타입 안정성 & 풍부한 IDE 지원
     * 자바스크립트/CSS/HTML을 작성하지 않고도 사용자 정의 UI 구축
     * 파이썬 함수인 컴포넌트로 UI를 구성할 수 있음

   한번 설치해보고 별로인거 같다는 느낌이 듭니다
   제일 비슷한거로는 streamlit
"
"https://news.hada.io/topic?id=15297","마이크로소프트 공식 Minesweeper 앱, 광고와 유료 승리 요소 포함, 수백 MB 용량","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          마이크로소프트 공식 Minesweeper 앱, 광고와 유료 승리 요소 포함, 수백 MB 용량

tech.lgbt 소개

  주요 내용 요약

     * tech.lgbt는 Mastodon 기반의 분산형 소셜 네트워크의 일부임.
     * 주로 LGBTQIA+와 그 동맹자들을 위한 기술, 학문, 일반 기술에 관심 있는 사람들을 위한 공간임.
     * 운영자: tech.lgbt 관리자
     * 활성 사용자 수: 3,500명

  Mastodon 관련 정보

     * Mastodon: 분산형 소셜 네트워크 플랫폼
     * 버전: v4.3.0-alpha.4+glitch
     * 기능: 앱 다운로드, 키보드 단축키, 소스 코드 보기 등

  사용자 반응

     * Nina Kalinina: Microsoft의 광고와 과도한 자원 사용에 대한 불만
     * erika: 광고와 과금 모델에 대한 불쾌감
     * jason: 게임의 과금 모델에 대한 의문
     * Pasadena CAS: 게임의 원래 목적과 현재 상태의 괴리감
     * prom: 게임이 도박 사이트처럼 보인다는 의견

GN⁺의 의견

    1. LGBTQIA+ 커뮤니티 지원: tech.lgbt는 소외된 정체성을 가진 사람들이 모여 기술과 학문에 대해 논의할 수 있는 안전한 공간을 제공함.
    2. 분산형 네트워크의 장점: Mastodon 기반의 분산형 네트워크는 중앙 서버에 의존하지 않아 검열과 데이터 유출의 위험이 적음.
    3. 광고와 과금 모델의 문제: 일부 사용자는 과도한 광고와 자원 사용에 대해 불만을 제기하고 있음. 이는 사용자 경험을 저해할 수 있음.
    4. 커뮤니티의 중요성: 기술과 학문에 관심 있는 다양한 배경의 사람들이 모여 서로의 경험과 지식을 공유할 수 있는 커뮤니티의 중요성을 강조함.
    5. 기술적 고려사항: 새로운 소셜 네트워크 플랫폼을 도입할 때는 보안, 사용자 데이터 보호, 커뮤니티 관리 등의 요소를 신중히 고려해야 함.

        Hacker News 의견

     * 2012년에 출시된 게임: 이 게임은 2012년에 출시되었으며, Microsoft가 자사 이름을 붙인 것에 대해 놀라움을 표함. Google이나 Apple이 이런 P2W 게임을 출시할 것 같지 않음.
     * 윈도우 2000의 지뢰찾기 웹 버전: 윈도우 2000의 지뢰찾기를 웹에서 실행할 수 있는 링크를 공유함.
     * 게임 스토어 페이지: 이 게임은 Xbox 게임 스튜디오에서 만든 것으로, Windows와는 다른 규칙을 따름. Microsoft Flight Simulator와 비교할 수 있음.
     * Microsoft의 경영 판단: Microsoft의 경영진이 이런 행동이 회사의 절박함이나 과도한 탐욕으로 보일 수 있다는 점을 인식하지 못하는지 의문을 제기함.
     * 가챠 요소 통합 우려: 운영체제에 가챠 요소가 통합될 가능성을 풍자적으로 언급하며, 프린트 기능을 잠금 해제하려면 루트 박스를 구매해야 한다는 예를 듦.
     * 웹 기반 지뢰찾기 클론: 설치가 필요 없는 웹 기반 지뢰찾기 클론을 추천함.
     * Simon Tatham의 버전 선호: Simon Tatham의 지뢰찾기 버전을 선호하며, 이 버전은 무료이고, 여러 플랫폼에서 사용할 수 있으며, 논리적으로 풀 수 있는 퍼즐임.
     * 독립적인 확인 필요: 이 정보가 사실인지 독립적인 확인이 필요하다고 언급함.
     * 게임 시장의 변화: 게임 시장, 특히 캐주얼 게임 시장의 변화와 그에 대한 충격을 언급하며, Microsoft가 지뢰찾기나 솔리테어에 광고를 넣는 것은 기존 사용자로부터 최대한 수익을 뽑아내려는 시도임.
     * 새로운 지뢰찾기의 크기: 5년 전에도 새로운 지뢰찾기가 윈도우 98의 간단한 설치보다 더 컸음을 언급함.
"
"https://news.hada.io/topic?id=15262","Snip - 커맨드 라인 Snippet 관리자","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Snip - 커맨드 라인 Snippet 관리자

     * 터미널에서 스니펫 보기 및 관리 snip {snippet_name}
     * 자신이 사용하는 에디터에서 편집 가능 snip edit
     * Snippet 이름 자동완성 지원 (bash, zsh, fish, powershell) - fzf 연동도 가능
     * Syntax Highlighting (bat & glow 설치 필요) 및 Git 연동 snip sync [커밋 메시지]
"
"https://news.hada.io/topic?id=15299","POV-Ray – 2021년 비전 지속 레이 트레이서","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     POV-Ray – 2021년 비전 지속 레이 트레이서

POV-Ray 소개

   **Persistence of Vision Raytracer (POV-Ray)**는 고품질의 무료 소프트웨어 도구로, 놀라운 3D 그래픽을 생성하는 데 사용됨. 소스 코드는 사용자가 직접 포팅할 수 있도록 제공됨.

  다운로드 및 네비게이션

     * 다운로드: POV-Ray를 다운로드하려면 다운로드 페이지를 방문.
     * 네비게이션: 사이트 탐색은 페이지 상단의 네비게이션 링크를 사용.

  연락처

     * 일반 지원: 리소스 및 지원 페이지 방문.
     * 웹사이트 관련 문제: 웹마스터에게 연락.
     * 라이선스 관련 문의: 라이선스 페이지 하단의 주소 사용.

  POV-Ray 관련 뉴스

    DKBTrace 창시자의 Kickstarter 캠페인

     * David K. Buck: DKBTrace의 창시자이며, POV-Ray의 기초를 마련한 인물.
     * Kickstarter 캠페인: 오픈소스 IDE인 PigeonTalk 개발을 위한 자금 모금.
     * PigeonTalk: Smalltalk 구현체로, 웹 브라우저에서 실행되며 WebSockets를 통해 Smalltalk 엔진과 통신.

    POV-Ray v3.8.0 베타 테스트

     * 베타 테스트: POV-Ray 3.8 베타 테스트 진행 중.
     * GitHub: 베타 릴리스는 GitHub 저장소에서 제공.
     * 토론: 베타 테스트 그룹 포럼에서 진행.

    POV-Ray 30주년

     * 역사: 1991년 7월 29일, 첫 베타 버전이 CompuServe의 GRAPHDEV 포럼에 공개됨.

    Wiki 복구

     * POV-Wiki: 최신 MediaWiki 버전으로 복구됨.
     * 버그 트래커: GitHub 이전 전의 이슈를 추적하던 레거시 버그 트래커 복구.

    포럼 복구

     * 서버 복구: 서버 충돌 이후 포럼이 다시 온라인 상태로 복구됨.

    Blender와의 통합

     * Blender: Blender에서 Persistence of Vision으로의 새로운 릴리스.

    white_dune VRML/X3D 편집기

     * POV-Ray 내보내기: white_dune 3D 편집기에 POV-Ray 내보내기 기능 추가.

    Ray Tracing Gems 논문 모집

     * 논문 제출: Ray Tracing Gems에 논문 제출 가능.

  기타 관심 항목

    Visualization Library

     * C++ 미들웨어: 고성능 2D 및 3D 그래픽 애플리케이션을 위한 C++ 미들웨어.

    OGRE 1.7.1

     * 그래픽 렌더링 엔진: 2001년부터 인기 있는 오픈소스 그래픽 렌더링 엔진.

    E-on Software의 Vue 8.5

     * 디지털 자연 솔루션: 자연 3D 환경의 생성, 애니메이션 및 렌더링을 위한 전문 솔루션.

    OpenTK Library 1.0 RC1

     * C# 라이브러리: 고급 저수준 C# 라이브러리.

    Rhino for OS X

     * 개발 중: 개발 중인 Rhino OS X의 프리 릴리스 버전 무료 제공.

GN⁺의 의견

     * POV-Ray의 역사적 가치: DKBTrace와 POV-Ray의 역사는 컴퓨터 그래픽스 발전에 큰 기여를 했음.
     * PigeonTalk의 가능성: Smalltalk 기반의 PigeonTalk는 교육용으로 매우 유용할 수 있음.
     * 베타 테스트 참여: 소프트웨어 개발에 관심 있는 사람들에게 베타 테스트 참여는 좋은 경험이 될 수 있음.
     * Blender 통합: Blender와의 통합은 3D 그래픽 작업을 더욱 효율적으로 만들어 줄 것임.
     * 기술적 도전: 새로운 기술 도입 시, 기존 시스템과의 호환성 및 학습 곡선 등을 고려해야 함.

        Hacker News 의견

     * 첫 번째 댓글: 11년 전, Java로 작은 레이 트레이서를 작성한 후, POV-Ray를 사용해 레이 트레이싱을 배움. 25일 동안 매일 몇 가지 기능을 배우고 흥미로운 장면을 렌더링함. 결과물 링크.
     * 두 번째 댓글: 386 sx 25Mhz 컴퓨터로 POV-Ray를 사용해 간단한 장면을 렌더링하며 밤새 컴퓨터를 켜둔 기억이 있음. 486 dx 33/66 Mhz로 업그레이드 후 수십 분 만에 렌더링 가능해짐.
     * 세 번째 댓글: 1992년에 룸메이트가 386DX와 387 수학 코프로세서를 사용해 작은 640x480 이미지를 렌더링하는 데 며칠이 걸렸음. DOS 시절이라 한 번에 하나의 프로그램만 실행 가능했음. Sun 워크스테이션에서 povray를 컴파일해 각 기계가 이미지를 분할 렌더링하도록 함.
     * 네 번째 댓글: 대학 시절 게임 데스크탑에서 게임 외에 할 일을 찾다가 POV-Ray를 알게 됨. 다양한 것을 만들며 재미를 느꼈고, 이미지 스티칭은 마법 같았음. 주사위 예제 링크.
     * 다섯 번째 댓글: 10년 전, brainfuck 인터프리터를 구현해 애니메이션 povray 장면 설명과 brainfuck 추상 기계의 시각화를 출력함. 유튜브 링크.
     * 여섯 번째 댓글: 롤 모델에게 게임의 프리렌더 스프라이트를 어떻게 만들었는지 물었을 때, POV-Ray를 사용했다고 들었음. 스크립팅 언어로 장면을 정의하는 것이 초보자에게는 복잡할 수 있다고 경고받음.
     * 일곱 번째 댓글: 1991년이나 1992년에 Atari ST에서 POV-Ray를 사용해 홈 비디오의 타이틀 화면을 만듦. 1996년이나 1997년에 소프트웨어 회사에서 3D 애니메이션 GIF 버전의 제품 로고를 만들었음. http://www.sophos.com/"">인터넷 아카이브 링크.
     * 여덟 번째 댓글: 건축 조명/조명 프레임워크인 radiance에서 모델링을 했으며, 텍스트 파일 형식으로 객체를 정의함. POV-Ray가 이를 능가했다고 생각함. 512x512에서 1024x1024로 전환할 때 렌더링 시간이 기하급수적으로 증가했음.
     * 아홉 번째 댓글: 90년대에는 POV-Ray로 멋진 이미지를 얻기 위해 컴퓨터를 밤새 켜두어야 했던 기억이 남.
     * 열 번째 댓글: POV-Ray 명예의 전당을 좋아하며, 특히 Riemann Sphere-Isosurface가 마음에 듦. 간단한 povray에서 stl 변환기가 있다면 3D 프린팅을 하고 싶음. 명예의 전당 링크.
"
"https://news.hada.io/topic?id=15255","Piku: Git Push 배포를 자체 서버에서 가능하게 하는 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Piku: Git Push 배포를 자체 서버에서 가능하게 하는 기술

데모

  문서: 설치 | 사용법 | Procfile | ENV | 예제 | 로드맵 | 기여 | LinuxConf 발표 | 빠른 웹 앱 튜토리얼 | 토론 포럼

  설치

     * 간단 설치: curl https://piku.github.io/get | sh
     * 다른 설치 방법: cloud-init 및 수동 설치 방법도 있음.

  프로젝트 활동

     * 안정성: piku는 안정적임. 새로운 언어 런타임 추가나 버그 수정 시 업데이트됨.
     * Python 요구사항: Python 3.7 이상 필요.

  동기

     * piku는 ARM 보드에서 Heroku/CloudFoundry와 같은 배포 방식을 원해 개발됨.
     * dokku가 ARM에서 작동하지 않아 더 간단한 솔루션 필요.
     * piku는 ARM 및 Intel 아키텍처에서 여러 애플리케이션을 배포, 관리, 독립적으로 확장 가능.

  워크플로우

     * Heroku와 유사한 워크플로우:
          + git SSH 원격 저장소 생성: git remote add piku piku@yourserver:appname
          + 코드 푸시: git push piku master
          + piku가 런타임 결정 및 의존성 설치
          + Procfile을 보고 관련 작업자 시작
          + 원격으로 애플리케이션 설정 변경 및 작업자 프로세스 확장 가능
          + ENV 파일에 애플리케이션 및 nginx 설정 포함 가능
          + gh-pages 스타일 정적 사이트 배포 가능

    가상 호스트 및 SSL

     * 가상 호스트 지원: 동일한 VPS에서 여러 앱 호스팅 가능
     * SSL 설정: Let's Encrypt를 통해 SSL 인증서 설정 가능

    캐싱 및 정적 경로

     * 정적 사이트 지원: 특정 URL 접두사를 파일 시스템 경로에 직접 매핑 가능
     * 캐싱: 백엔드 응답 캐싱 가능

    지원 플랫폼

     * POSIX 환경: Python, nginx, uwsgi, SSH가 있는 POSIX 환경에서 작동
     * 주요 사용처: 클라우드 서버에서 마이크로 PaaS로 사용

    지원 런타임

     * 지원 언어: Python, Node, Clojure, Java 등
     * 일반 규칙: 셸에서 호출 가능하면 piku에서 실행 가능

    핵심 가치

     * 저사양 장치에서 실행 가능
     * 취미 사용자 및 K-12 학교에 접근 가능
     * 약 1500줄의 읽기 쉬운 코드
     * 기능적 코드 스타일
     * 단일 의존성
     * 12 요소 앱
     * 사용자 경험 단순화
     * 일반적인 사용 사례의 80% 커버
     * 모든 기능에 대한 합리적인 기본값 제공
     * Raspbian/Debian/Ubuntu의 배포 패키지 활용
     * 표준 도구 (git, ssh, uwsgi, nginx) 활용
     * 가능한 경우 이전 버전과의 호환성 유지

GN⁺의 의견

     * 간편한 배포: piku는 소규모 서버에서도 간편하게 배포할 수 있어 소프트웨어 엔지니어에게 유용함.
     * 다양한 언어 지원: 여러 언어를 지원해 다양한 프로젝트에 적용 가능함.
     * 저사양 장치 지원: 저사양 장치에서도 실행 가능해 비용 효율적임.
     * 사용자 경험: 사용자 경험을 단순화해 초급 엔지니어도 쉽게 사용할 수 있음.
     * 보안: Let's Encrypt를 통한 SSL 설정으로 보안 강화 가능.

        Hacker News 의견

     * piku 웹앱 튜토리얼 작성자: piku를 사랑함. 웹앱 튜토리얼을 작성했으며, GitHub의 공식 piku 조직의 일부로 리포지토리에 포함됨. 튜토리얼 링크에서 확인 가능함. piku의 작동 원리와 사용자 관점에서의 최소한의 Python 웹앱 예제를 설명함.
     * piku 처음 접한 사용자: piku에 대해 처음 읽어봄. git push로 배포를 시작하는 느낌이 항상 마법처럼 느껴졌음. 이보다 간단한 것은 없음.
     * Kubernetes 프로젝트 오픈 소스화 사용자: 최근 Kubernetes 관련 프로젝트를 오픈 소스화했음. piku와 같은 공간에 속하는 프로젝트임. 프로젝트 링크. 축하의 말을 전함. 훌륭해 보임.
     * Dokku 사용자: piku가 좋아 보임. Dokku도 매우 안정적이었음. 그러나 Docker 의존성을 제거하면 OS의 선택에 의존하게 됨. 유지보수 없이 몇 년 동안 실행될 앱에는 이상적이지 않음. 특정 OS 버전이 필요하게 될 수 있음.
     * Cloud Native Buildpacks (CNB) 팀원: git push 배포와는 관련 없지만, PaaS 경험과 관련 있음. CNCF의 Buildpacks를 대상으로 하는 CNB를 미리보기 중임. 이를 통해 Heroku의 git push 논리와 유사한 빌드 도구를 사용하여 로컬에서 Docker 이미지를 생성할 수 있음. Rails 앱 빌드 튜토리얼 링크. 피드백을 원함.
     * piku 문서 업데이트 알림: piku의 새롭게 개편된 문서를 확인해보길 권장함. 문서 링크.
     * 프로젝트 초기 커밋 시점에 놀란 사용자: 초기 커밋이 8년 전임을 알고 놀람. 18개월 전에 이 프로젝트를 알았더라면 좋았을 것임. Raspberry Pi에 Heroku와 같은 개발 경험을 제공하는 방법을 찾고 있었음. piku가 정확히 그 역할을 하는 것 같음.
     * git은 배포 도구가 아님을 강조하는 사용자: ""git은 배포 도구가 아니다""를 반복해서 말함.
     * ground-init 소개자: 유지보수자이자 공동 저자임. 간단하고 최소한의 배포 도구를 좋아한다면 ground-init을 확인해보길 권장함. 클라우드 초기화에 대한 현실적인 접근 방식을 제공함.
     * 자동 배포 설정 사용자: 앱에 커밋이 푸시될 때마다 GitHub가 호출하는 마법 URL을 추가했음. 서버가 git pull을 수행하고 pm2가 앱을 다시 로드함. 작은 프로젝트에 적합함.
     * 무중단 배포에 대한 질문자: piku가 무중단 배포를 어떻게 처리하는지 궁금함. 예를 들어, Python 서비스가 nginx 뒤에서 포트 8080에서 실행 중일 때, 동일한 포트에서 새 인스턴스로 전환하는 방법을 알고 싶음.
"
"https://news.hada.io/topic?id=15294","RP2040 선호","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               RP2040 선호

RP2040 마이크로컨트롤러에 대한 리뷰

  적절한 크기

     * RP2040은 Raspberry Pi에서 만든 마이크로컨트롤러임.
     * 저렴한 가격으로 제공되며, 다양한 소비자 전자제품에 쉽게 내장 가능함.
     * 다른 제조사와 달리 단일 모델만 제공하여 선택의 혼란을 줄임.

  단일 모델의 장점

     * RP2040은 약 70센트로 저렴함.
     * 단일 모델로 인해 전 세계 개발자들이 동일한 부품을 사용하게 됨.
     * StackExchange, 블로그, Github 등에서 풍부한 자료와 도구를 쉽게 찾을 수 있음.

  마이크로컨트롤러의 설계

     * 두 개의 코어를 가지고 있어 필요 시 추가 사용 가능함.
     * 30개의 GPIO 핀을 제공함.
     * 내부 RAM에 예산을 투자하여 외부 연결이 어려운 플래시 메모리를 배제함.
     * 프로그래머블 입출력(PIO) 기능을 제공하여 CPU 시간을 절약하면서 정밀한 타이밍으로 IO를 실행할 수 있음.

  PIO의 활용 예시

     * 통신 프로토콜 구현 (예: DShot ESC)
     * USB 스택 구현, 두 번째 USB 컨트롤러 제공
     * 디스플레이 드라이버 구현, CPU의 디스플레이+터치 통신을 완전히 오프로드

  부트로더와 보안

     * 읽기 전용 부트로더가 있어 펌웨어 업데이트를 쉽게 할 수 있음.
     * 보안 기능을 최소화하여 복잡성과 사용자 경험 비용을 줄임.

GN⁺의 의견

     * RP2040은 단일 모델로 제공되어 개발자 커뮤니티에서 풍부한 지원을 받을 수 있음.
     * 프로그래머블 입출력(PIO) 기능은 다양한 응용 프로그램에서 유용하게 사용될 수 있음.
     * 보안 기능이 최소화되어 있어 민감한 데이터가 필요한 프로젝트에는 적합하지 않을 수 있음.
     * 저렴한 가격과 유연한 설계로 인해 교육용 및 취미용 프로젝트에 매우 적합함.
     * 다른 마이크로컨트롤러와 비교했을 때, 특정 고급 기능이 부족할 수 있으므로 프로젝트 요구사항에 맞는지 검토 필요함.

        Hacker News 의견

     * RP2040의 PIO: RP2040의 PIO가 ESP32와 같은 경쟁 칩이 따라올 수 없는 기능을 제공함. 콘솔 해킹 분야에서 많이 사용되고 있음. 배터리 백업 애플리케이션을 위한 저전력 모드가 V2 버전에 추가되면 좋겠음.
     * RVASec 보안 컨퍼런스: RVASec 보안 컨퍼런스에서 전자 배지에 RP2040을 사용해왔음. 소프트웨어 작성이 매우 편리함. GitHub 저장소에서 배지 시뮬레이터를 확인할 수 있음.
     * RP2040의 패키징 옵션: 동일한 마이크로컨트롤러지만 두 가지 다른 패키징 옵션이 있음. 하나는 500개 단위의 7인치 릴, 다른 하나는 3400개 단위의 13인치 릴임.
     * 전자 취미가: 전자 취미가에게 RP2040 보드가 저렴하고 접근성이 좋음. Raspberry Pi Pico와 같은 보드가 $5에 제공되며, WiFi가 포함된 버전도 있음. RP-2040 Zero는 더 작은 크기와 적은 IO 핀을 제공하지만, USB-C와 리셋 버튼이 있음.
     * RP2040과 ESP32 비교: RP2040은 단순한 칩인 반면, ESP32는 다양한 주변 장치와 함께 제공됨. WiFi, Bluetooth, 배터리 컨트롤러, 이더넷, 디스플레이, 카메라 커넥터 등 다양한 옵션이 있음. ESP32는 다양한 CPU 선택과 RISC-V 기반 ISA로 전환하는 C6 변형도 있음.
     * 맞춤형 컨트롤러 시장: RP2040이 맞춤형 컨트롤러 시장을 활성화시킴. gp2040 오픈 소스 게임 패드 펌웨어 덕분에 저렴한 가격에 고품질의 컨트롤러를 구매할 수 있음. 취미가들이 다양한 프로젝트와 컨트롤러 아이디어를 위해 RP2040 PCB를 제작 중임.
     * ESP32에서 RP2040으로 전환: ESP32에서 RP2040으로 전환한 이유는 더 신뢰할 수 있고 문서화가 잘 되어 있기 때문임. SPIRAM이 장착된 RP2040 보드를 찾기 어렵다는 점이 유일한 우려사항임. 그러나 C 개발 환경이 훌륭하여 메모리를 잘 활용할 수 있음.
     * RP2040의 장점과 단점: RP2040을 여러 프로젝트에 사용해왔음. 하지만 모든 프로젝트에 적합하지 않음. 배터리 전력을 적게 사용하는 마이크로컨트롤러를 선호함. 비용보다는 전력 소비가 중요한 이유임.
     * ESP32-S3로 전환: PlatformIO와의 드라마로 인해 RP2040에서 ESP32-S3로 전환함. ESP32-S3는 모듈 형식으로 제공되어 구현 복잡성을 크게 줄임. RP2040은 많은 구성 요소가 필요함. 또한, ESP32-S3는 14개의 GPIO 핀이 있어 정전식 터치를 지원함.
     * PIO 상태 머신: PIO 상태 머신이 독특하고 멋지다고 생각함. RP2040을 10코어 프로세서로 마케팅하지 않은 점이 좋음. UF2 플래싱이 초보자에게 큰 도움이 됨. 단점은 전력 소비임.
"
"https://news.hada.io/topic?id=15213","마이크로소프트 AI 스파이 스캔들: 프라이버시 기준 재검토 필요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  마이크로소프트 AI 스파이 스캔들: 프라이버시 기준 재검토 필요

     * Microsoft는 최근 국가 지원 해커들이 자사의 생성형 AI 도구를 공격에 활용하는 것을 적발했음. 보안 커뮤니티에서는 Microsoft가 이를 어떻게 알아냈는지에 대한 의문이 제기됨.
     * Microsoft의 행위를 ""스파이""라고 특징짓는 것에 대해 일부에서는 반발했음. 클라우드 서비스 제공자가 사용자의 활동을 모니터링하는 것은 당연한 일이며, 이를 스파이 행위라고 부르는 것은 공정하지 않다는 주장임.
     * 이는 변화하는 사생활 보호에 대한 집단적 기대치의 한 예로 볼 수 있음. 이를 이해하기 위해 어업에서 배울 점이 있음.
     * 20세기 중반, 과도한 어획으로 인해 해양 어류 수가 급격히 감소하기 시작했음. 포경 산업에서도 유사한 감소 추세가 나타남.
     * Daniel Pauly는 연구자들이 허용 가능한 어획량을 결정할 때 중대한 오류를 범하고 있다는 사실을 깨달음. 문제는 연구자들이 어류 개체 수 감소의 심각성을 인지하지 못한다는 것이었음.
     * Pauly는 각 세대의 연구자들이 현재 통계를 비교하는 기준점(baseline)이 다르며, 각 세대의 기준점이 이전 세대보다 낮다는 점을 지적함. 이를 ""기준점 이동 증후군(shifting baseline syndrome)""이라고 명명함.
     * 인터넷 감시와 그에 따른 사생활 침해도 같은 궤적을 따르고 있음. 현대 기술의 광범위한 특성으로 인해 감시가 그 어느 때보다 쉬워졌으며, 각 세대는 젊은 시절의 사생활 현상에 익숙해져 있음.
     * AI 챗봇은 이러한 현상의 최신 사례임. 챗봇은 사용자의 입력에 응답하여 출력을 생성하지만, 그 이면에는 입력을 추적하는 복잡한 클라우드 기반 시스템이 존재함.
     * 기준점 이동은 우리의 집단적 사생활 상실의 핵심임. 미국 대법원은 오랫동안 사생활에 대한 우리의 권리가 사생활에 대한 합리적인 기대에 달려 있다고 판결해 왔음. 그러나 기대는 변동하기 쉬운 것으로, 기준점 이동의 영향을 받음.
     * 이제 어떻게 해야 할까? 어업 과학자들은 이제 큰 그림을 바라봄. 그들은 이전 10년과 비교하는 등의 상대적 척도를 더 이상 고려하지 않음. 대신 건강한 해양 생태계와 지속 가능한 어획량이 어떤 모습이어야 하는지 전체적인 관점에서 바라봄.
     * 사생활과 보안 분야에서도 같은 접근 방식이 필요함. 기준점 이동과 비교하는 대신, 한 걸음 물러서서 건강한 기술 생태계가 어떤 모습일지 살펴보아야 함.

        Hacker News 의견

    해커뉴스 댓글 요약

     * 소비자 프라이버시 행동 이해: 소비자들은 복잡한 세상에서 단순화된 가정을 통해 선택을 함. 디지털 경제에서 문제는 소비자 기준이 아니라 규제 기준의 변화임.
     * 프라이버시 본능의 실패: 사람들은 개인적으로 아는 사람들에 대한 프라이버시 침해에만 민감하게 반응함. 익명의 조직이 데이터를 수집하는 것에는 무관심함.
     * 구글과 프라이버시: 구글은 오랜 기간 동안 우리의 이메일, 검색 기록 등을 수집해왔음. 대부분의 사람들은 프라이버시를 포기하고 편리한 도구를 사용하는 것이 합리적이라고 생각함.
     * 빅테크와 프라이버시: 빅테크는 담배 회사처럼 사람들에게 유익하다고 설득함. 우리는 인간과 프라이버시를 최우선으로 해야 함.
     * 스노든과 빅테크: 스노든은 빅테크가 NSA에 데이터를 제공한다고 폭로함. OpenAI와 같은 AI 서비스도 예외가 아님.
     * 프라이버시 보호의 어려움: 사람들에게 프라이버시 문제에 대해 관심을 가지게 하는 것은 매우 어려움. 교육과 지원이 필요함.
     * 마이크로소프트의 투명성: 마이크로소프트는 AI 서비스가 모니터링되고 있음을 공개적으로 밝힘. EU에서는 법적으로 로그를 유지해야 함.
     * 애플과 기업 스파이: 애플이 불법적으로 기기를 조사한다는 주장. 기업 스파이 활동에 대한 문제 제기.
     * 윈도우의 문제: 윈도우가 점점 더 문제가 되고 있으며, 대안이 존재함.
     * 프라이버시와 비용: 일부 사람들은 프라이버시를 포기하고 낮은 비용이나 추가 기능을 선택함. 프라이버시를 중시하는 제품도 시장에 존재할 수 있음.
"
"https://news.hada.io/topic?id=15276","애플, Xcode 16 / Swift 6 / Game Porting Toolkit 2 등 개발자용 도구 업데이트 발표 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   애플, Xcode 16 / Swift 6 / Game Porting Toolkit 2 등 개발자용 도구 업데이트 발표

     * Xcode 16
          + Swift Assist : 개발자가 더욱 고차원적인 문제와 솔루션에 집중할 수 있도록 모든 코딩 작업을 도와주는 동반자
               o 클라우드에서 실행되는 강력한 모델을 사용
               o 개발자의 코드는 요청을 처리하는 데만 사용되고 절대 서버에 저장되지 않으며 Apple은 머신 러닝 모델을 학습하는 데 개발자의 코드를 사용하지 않음
          + 새로운 코드 자동 완성 엔진은 Swift 및 Apple SDK를 위해 특별히 훈련된 고유 모델을 사용하며 개발자에게 필요한 코드를 제안(개발자의 기기에서 로컬로 실행됨)
     * Swift 6
          + 컴파일 타임 데이터 레이스 안전 기능을 도입 : 컴파일 타임 단계에 개발자의 프로젝트 전체에서 메모리에 대한 동시 액세스를 진단
          + 완전히 새로운 Swift 전담 GitHub 조직이 Swift 컴파일러, Foundation 및 기타 주요 라이브러리 등 Swift 생태계를 위한 여러 핵심 프로젝트를 호스팅할 예정
          + Swift Testing 프레임워크 : 개발자가 테스트를 간편하게 작성할 수 있도록 표현형 API를 제공. 크로스 플랫폼
     * Game Porting Toolkit 2
          + 기존 게임이거나, 현재 개발 중인 게임이거나, 무엇이든 상관없이 시간을 절약해줌
          + Windows 게임과의 향상된 호환성, 새로운 강력한 쉐이더 디버깅 툴, 여러 기기에 걸쳐 게임 코드와 쉐이더를 통합가능하게 하는 Xcode 업데이트
     * visionOS 2
          + 볼류메트릭 API: 앱에서 3D 객체가 표시되는 방식을 보다 효과적으로 제어
          + TabletopKit: 제조 워크스테이션이나 보드 게임 및 카드 게임처럼 평평한 표면에 고정된 공간 앱 경험을 개발자가 손쉽게 제작할 수 있도록 지원
          + RealityKit: 여러 Apple 기기를 지원하는 앱의 개발을 간소화하여 개발 시간을 단축하고 유니버설 앱의 워크플로를 더욱 효율적으로 개선
          + 이제 Apple Vision Pro 하드웨어가 없는 개발자도 시뮬레이터에서 SharePlay 지원 앱을 제작하고 미리 볼 수 있음
          + HealthKit도 지원
     * 그외 플랫폼 API
          + Controls API : 제어센터에 다양한 기능을 추가
          + 액세서리 설정 키트 : 주변의 모든 Bluetooth 액세서리에 액세스하지 않고도 개발자가 앱을 통해 매끄럽고 안전하게 Bluetooth 액세서리를 페어링하고 다른 기기는 비공개로 유지할 수 있음
          + watchOS 더블 탭 API를 통해 Apple Watch 앱 경험의 주요 요소에 더블 탭 제스처를 지정 가능
     * TestFlight
          + 기기 및 OS별로 테스터를 모집 가능
          + 초대장에는 베타 앱의 개요, 앱 카테고리, 스크린샷(선택 사항)이 포함되므로 예비 테스터에게 새로운 기능과 콘텐츠를 중점적으로 소개할 수 있음
     * App Store
          + 새로운 추천 기능 : 앱의 출시 예정 콘텐츠 및 개선 사항을 App Store에서 소개할 수 있도록 개발자가 직접 손쉽게 제안할 수 있는 기능
          + 맞춤형 제품 페이지 : 앱에서 제공하는 다양한 콘텐츠와 기능을 홍보. 딥링크 제공
          + 구독 : 윈백(win-back) 프로모션을 통해 이전 구독자의 재구독을 유도

   Game Porting Toolkit 을 gpt로 줄이다니....

   아... 대체 GPT 내용이 어딨지 하면서 찾았는데 그거였군요. ㅎㅎㅎ

   제가 살짝 유머스럽게 적어봤는데.. 오해를 드렸군요 ㅠ

     Swift Assist : 개발자가 더욱 고차원적인 문제와 솔루션에 집중할 수 있도록 모든 코딩 작업을 도와주는 동반자

   xcode에 AI가 들어가면 뭐하나요... xcode 그 자체가 빌런인데ㅠㅠ
"
"https://news.hada.io/topic?id=15282","Elsevier, 각 다운로드마다 고유한 해시를 PDF 메타데이터에 삽입 (2022)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Elsevier, 각 다운로드마다 고유한 해시를 PDF 메타데이터에 삽입 (2022)
"
"https://news.hada.io/topic?id=15295","매일 사용하는 추천 macOS앱을 알려주세요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        매일 사용하는 추천 macOS앱을 알려주세요

     * 해커뉴스 질문에 답변으로 올라온 추천앱들 정리

생산성 앱:

     * Raycast: 다양한 기능을 하나의 인터페이스에서 제공하여 작업 효율성을 높여줌.
          + Spotlight 대체: 애플리케이션 실행 및 검색
          + Magnet 대체: 윈도우 관리 기능 내장으로 별도 앱 불필요
          + 클립보드 히스토리 저장
          + 색상 및 단위 변환
          + 캘린더 연동: 예정된 미팅 표시, 메뉴바에서 바로 참여 가능
          + caffeinate 명령으로 Mac이 슬립 모드로 전환되는 것을 일정 시간 동안 방지
          + 다양한 플러그인 제공
     * BusyCal: 깔끔한 인터페이스를 갖춘 캘린더 앱으로 일정 관리가 쉬워짐.
     * Rectangle: 직관적인 단축키로 윈도우를 효율적으로 관리할 수 있는 앱.
     * AeroSpace Window Manager: 최근에 알게 된 윈도우 관리 앱. (Wins / Rectangle을 대체).
     * 윈도우 관리: yabai + skhd + Sketchybar: 고급 사용자를 위한 윈도우 타일링 매니저와 커스터마이징 도구.
     * Hammerspoon: 다양한 Lua 스크립트를 사용해 Mac을 자동화할 수 있는 강력한 도구.
     * Arc Browser: 생산성을 크게 향상시키는 웹 브라우저. 윈도우/리눅스에서 전환할 만한 가치가 있음. (윈도우 버전은 뒤쳐져 있고 안드로이드 버전과 동기화 기능은 없음).
     * Choosy: 링크를 열 때 원하는 브라우저나 프로필로 오픈할 수 있게 해줌.
     * Maccy: 가볍고 사용하기 쉬운 클립보드 히스토리 매니저.
     * AltTab: 윈도우의 Alt+Tab 기능을 Mac에서 사용할 수 있게 해줌.
     * Calca, Soulver: 복잡한 계산과 텍스트를 동시에 처리할 수 있는 편리한 계산기.

보안 관련:

     * LittleSnitch: 인바운드 및 아웃바운드 액세스를 선택적으로 제어하는 애플리케이션별 방화벽.
     * BlockBlock, KnockKnock, RansomWhere: 맬웨어 방지 및 탐지 도구 (단, LuLu는 TCP 연결 문제로 사용하지 않음).

개발 및 문서화:

     * Dash: 다양한 프로그래밍 언어와 프레임워크의 문서를 브라우징할 수 있는 개발 문서 브라우저.
     * MacDown, MarkEdit, Highland 2: Markdown 편집기로, 다양한 기능과 사용하기 쉬운 인터페이스 제공.
     * OmniGraffle: 복잡한 다이어그램과 차트를 쉽게 제작할 수 있는 도구.
     * WineSkin: 맥에서 윈도우 앱을 실행하기 위한 래퍼/엔진.
     * Ascension: .nfo 파일 뷰어로, 텍스트 파일을 깔끔하게 표시.
     * Git Fork: Tower와 비슷한 깃 클라이언트로, 구독이 아닌 1회성 결제로 사용 가능.

시스템 관리 및 유틸리티:

     * ScrollReverser: 마우스와 트랙패드의 스크롤 방향을 개별적으로 설정할 수 있음.
     * Karabiner-Elements: 키 리매핑을 통해 키보드 기능을 커스터마이징할 수 있음.
     * DaisyDisk: 디스크 사용량을 시각적으로 확인하고 관리할 수 있는 앱.
     * Breakaway: 헤드폰 잭 연결 및 관련 오디오 설정을 제어할 수 있는 유틸리티.
     * AppCleaner: 앱 및 관련 데이터를 완전 삭제해주는 도구.
     * Pacifist: .pkg 파일의 내용을 미리 보고 관리할 수 있는 유틸리티.
     * Sensei: 맥의 하드웨어 상태를 점검하고 정리할 수 있는 앱.

그 외 언급된 앱:

     * Boom 3D: 서라운드 사운드와 EQ 설정을 통해 사운드를 향상시켜주는 앱.
     * Yomu: 깔끔한 인터페이스와 다양한 기능을 갖춘 전자책 리더 앱.
     * Shottr, Xnapper: 마케팅/소셜 미디어용 멋진 스크린샷을 손쉽게 캡처할 수 있는 앱.
     * ImageOptim: 대량의 이미지를 최적화하고 메타데이터를 제거할 수 있는 도구.
     * GoLogin: 업무용 다중 브라우저 프로필 및 익명화를 지원하는 앱.
     * IINA: 다양한 포맷을 지원하는 강력한 동영상 파일 재생 앱.
     * MonitorControl: 외부 모니터의 밝기와 볼륨을 조절할 수 있는 유틸리티.
     * iStat Menus: 시스템 상태를 메뉴바에서 실시간으로 모니터링할 수 있는 앱.
     * Bartender: 메뉴바 아이콘을 깔끔하게 정리할 수 있는 앱 (오너 변경으로 Ice로 교체 추천).
     * Forecast Bar: 메뉴바에서 날씨 정보를 확인할 수 있는 앱.
     * Paste: 클립보드 히스토리를 관리할 수 있는 도구.
     * MacTracker: Mac 하드웨어와 소프트웨어에 대한 자세한 정보를 제공하는 앱.
     * iTerm2

   Raycast 확실히 좋더군요. 무엇보다 본문에 있는 여러가지 기능들이 사용자들이 각자 유지관리하는 확장기능으로 이미 구현되어 있어서 (예를들면 Rectangle과 같은 윈도우 관리앱, 클립보드 히스토리 앱, 이미지 최적화 앱 등등) 통합된 인터페이스 상에서 관리할 수 있다는 점이 가장 맘에 들었네요. 개인적으로는 그동안 사용해본 맥 앱 중에서는 가장 만족도가 높았고 확장성이나 활용성도 꾸준히 높을 것 같은 앱이네요.

   스크린샷 관리용으로 Screenie 사용하고 있습니다.
   https://www.thnkdev.com/Screenie/

   맥북 모니터 연결 할때마다 프로그램 위치 바뀌는거 때문에 짜증나시는 분들,
   https://cordlessdog.com/stay/
   이걸로 프로그램 위치 고정하시면 세상 편해집니다.

   DB 접속 많으신 분들은 TablePlus 추천합니다.
   불필요한 인터페이스 없고 필요한것만 딱 있고, 엑셀처럼 편하게 관리 가능합니다.

   불렛 포인트 형식으로 적는 것 좋아하시는 분들은 dynalist 추천합니다.
   workflowy 후발 주자인데 사용성이 훨씬 좋고 무료로도 기능 충분히 사용가능합니다.

   화면을 캡처하듯 선택하면 텍스트 추출과 번역을 동시에 할 수 있는 ScanTexter https://www.scantexter.com

   Macs Fan Control 지금 바로 다운로드

   전 맥 기본내장앱인 grapher. 간단한 3d, 2d 수식 빠르게 그려보기 좋아요.

   언급 안된것중에
   키보드 활용성을 극대화 해줄 수 있는 Homerow와
   터치패드, 키보드 관련 확장 툴인 Better Touch Tool 을 아주 잘 쓰고 있습니다.

   특히 homerow는 안써보셨으면 한번쯤 트라이 해보세요 ㅎㅎ

   [브라우저]
   크롬 브라우저로 사용한다면 vimium C가 더 좋은 것 같긴하네요.

   [브라우저 외]
   어플리케이션을 조작할 때는 편하긴 한데, 슬랙 등 여러가지 앱에서 사이드바를 스크롤 영역으로 인식하지 못해서 Command + Shift + J 눌렀을 때 표시되지 않는 문제도 있군요.

   HomeRow에 다음 기능이 추가되면 진짜 최고일 것 같네요
    1. 좀더 정확한 스크롤 영역 감지
    2. Vim처럼 top, bottom으로 바로 이동할 수 있는 기능 추가

   homerow 호출 단축키 어떻게 사용하고 계신가요? 전 키가 겹쳐서 손에 안익는 곳에 두다가 결국 지웠어요...

   Karabinar 사용해서 캡스락을 슈퍼키(Ctrl+Alt+Shift+Command)로 지정해놓고
   캡스락만 누르면 캡스락으로, 조합키로 사용하면 슈퍼키로 작동하도록 설정했습니다.

   슈퍼키 + 스페이스는 알프레드
   슈퍼키 + 쉬프트는 스폿라이트
   슈퍼키 + 탭은 Homerow 로 사용중입니다.

   Hot 사용중입니다
   하드웨어 온도를 띄워놓을수있어요

   text expander는 어떤 걸 쓰시나요? 전 atext를 쓰고 있습니다. 메이저 버전 업데이트로 제 샀던 버전은 지원이 중지 됐는데 아직 불편한게 없어서 계속 쓰고있네요

   저는 키보드 단축어로 하고 있습니다.
   tma 로 입력하면 제 메일주소가 나오게 설정했는데 아이폰, 아이패드, 맥북 다 연동되어서 편하더라구요

   atext 없으면 일상생활 불가능.
   저도 구버전으로 잘 쓰고 있습니다.

   이 사이트는 파이썬 프로그래밍을 업으로 개발하는 매킨토시 사용자가 많은 유용한 정보공유 사이트입니다.

   Hidden Bar 사용하고 있습니다

   Velja https://apps.apple.com/us/app/velja/id1607635845
   이게 없는 것 같네요.
   저는 브라우저 프록시로 이것을 사용중입니다.

   Itsycal : https://www.mowglii.com/itsycal/

     Itsycal is a tiny menu bar calendar.

   Maestral

     Open source Dropbox client

   Input Source Pro - Switch and track your input sources with ease

     한 / 영 전환 indicator , 팝업으로도 보여주고 현재 입력 언어를 dot 색으로 에디터 창에 보여줌

   Mac Battery Guru -

     menubar 에 배터리 소모 or 충전 amp 를 단순히 숫자로 표시해줌 (배터리 소모 정도를 확인)

   배터리관리를 위해 AlDente 사용합니다.

   어휴 스크린샷 도구들 너무 좋네요..

   단골이던 Alfred가 여기에 없네요. Raycast로 확실히 넘어간건가.. 저는 적응을 못해서 아직 Alfred에 머물러 있습니다만...

   Keyboard Maestro 도 좋습니다.
   Autohotkey 의 맥 버전, 혹은 Hammerspoon 의 GUI 버전? 쯤 되는 거라고 보시면 되겠네요.

   그리고 CleanShot X 도 추천합니다.

   WezTerm도 좋습니다.

   롤 배틀넷 termius

   copy `Em - 클립보드 매니저. 너무 저랑 잘 맞아서 잘 쓰고 있네요
   Raycast는 저도 애용하고 있습니다.
   그외
   iTerm2 라던지...
   https://devtoys.app/ 도 가끔 잘 쓰고 있네요

   비슷한 다른거 쓰고 있었는데 이게 기능이 훨씬 많네요 ㅎㅎ 감사합니다

   와우 엄청 좋군요! 감사합니다

   Calca, Soulver와 비슷한 Numi도 괜찮습니다.
   https://numi.app/

   Boop 좋아요.
   b64 인코딩, JSON 정렬, JWT 디코딩, 글자수 세는 용도로 제일 자주 사용하고, 가끔 일회성 메모가 필요할 때도 사용합니다ㅎㅎ

   https://boop.okat.best/

   순수 재미용으로 run cat을 사용하고 있습니다
   https://kyome.io/runcat/index.html?lang=en

   귀여워서 저도 설치했습니다. 좋네요!

   shottr 애용하고 있습니다 ㅎㅎ

   shottr 애용하고 있습니다 ㅎㅎ +1

   딱 필요한 기능만 잘 되어 있어서 대대대 만족중입니다.

   저도 shottr 너무 좋아합니다 ㅎㅎ

   개인적으로는 Raycast의 clipboard manager를 ⌘ + ⇧ + 🇻로 바꿔서 사용해요.

   Maccy는 좋은데, 검색이 느려요

   몇달전 소개된 heynote도 애용중이고요

   https://news.hada.io/topic?id=12484

   Rectangle, Maccy, Shottr(결제완료) 잘 쓰고 있습니다.
   RayCast는 잘 안쓰게 되네요.
   터미널은 그냥 인텔리제이 내에서 대부분을 쓰게 됩니다.
   TextSniper 예전 무료로 풀렸을때 얻어서 잘 쓰고 있습니다.

   iTerm2가 있기에...

   warp 서비스도 나쁘지 않습니다.

   오 엄청좋네요

   아크 브라우저가 초기에 썼을땐 별로여서 지웠었는데
   개선이 많이 됐나보네용

   개인적으로는 arc 브라우저가 과대평가되었다고 생각합니다~ 다시 크롬으로 돌아갔네요.

   동감합니다. 처음에는 기존 브라우저의 틀을 깨는 새롭고 신기한 기능들이 혁신적이라고 생각했는데, 쓰면 쓸 수록 구관이 명관이란 생각이 들어 크롬으로 복귀했습니다.
"
"https://news.hada.io/topic?id=15272","Sora를 능가하는 중국발 텍스트-비디오 AI 툴의 등장: Kling AI","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Sora를 능가하는 중국발 텍스트-비디오 AI 툴의 등장: Kling AI

   중국에서 출시된 텍스트-비디오 AI 툴 Kling AI이 영상 퀄리티와 일관성 면에서 Sora를 능가하는 성능을 보여주어 화제가 되고 있네요.

    Kling AI: 중국의 최첨단 텍스트-비디오 AI 도구

     * 🇨🇳 중국의 주요 기술 기업인 CA가 개발한 중국의 Kling AI 텍스트-비디오 툴은 비디오 클립 생성에 있어 놀라운 일관성과 품질을 보여주며 SORA 모델을 능가하고 있다는 평가를 받고 있습니다.
     * 🐎 Kling AI는 3D 시공간 주의 메커니즘을 채택하여 복잡한 시공간 모션을 모델링하고 운동 법칙을 준수하면서 큰 모션이 있는 동영상 콘텐츠를 생성합니다.
     * 📹 효율적인 트레이닝 인프라, 극한의 추론 최적화, 확장 가능한 인프라 덕분에 Kling AI 모델은 초당 30프레임으로 최대 2분 길이의 동영상을 높은 수준의 일관성을 유지하며 생성할 수 있습니다.
     * 🌐 Kling AI은 물리적 세계 속성을 시뮬레이션하고 물리 법칙을 준수하는 동영상을 생성하는 기능을 시연합니다.
     * 🐱 이 AI는 하얀 고양이가 번화한 도심 거리에서 자동차를 운전하는 모습처럼 다양한 콘셉트를 결합한 새롭고 흥미로운 영상을 생성하는 등 강력한 콘셉트 조합 능력을 보여줍니다.
     * 🎥 Kling AI의 뛰어난 기능은 영화 퀄리티 수준의 동영상 생성으로, 다양한 산업 분야의 판도를 바꿀 수 있는 고품질 비디오 출력을 제공합니다.
     * 🖼 Kling AI은 다양한 시나리오의 요구 사항을 충족하는 다양한 종횡비의 동영상을 출력할 수 있습니다.
     * 🌍 Kling AI의 빠른 발전과 인상적인 능력은 글로벌 AI 환경에서 중국의 경쟁력이 높아지고 있음을 보여주며, 잠재적으로 AI 개발을 위한 국제적인 경쟁이 심화될 수 있습니다.

   한국어로 요약된 영상 전문입니다: https://corely.ai/content/game-over-chinas-new-ai-beats-sora
"
"https://news.hada.io/topic?id=15309","실리콘 밸리의 숨겨진 비밀: 창업자 유동성(Founder Liquidity)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               실리콘 밸리의 숨겨진 비밀: 창업자 유동성(Founder Liquidity)

     * 실리콘밸리 신화에서 창업자의 ""위험 감수""는 중요한 역할을 함
          + 창업자는 안정적인 직장을 떠나 ""불확실하고 위험한"" 벤처에 ""인생을 바치는 것""으로 찬양받음
          + 이는 초기 직원들보다 훨씬 ""더 많은 지분""을 가지는 것을 정당화함
     * 그러나 창업자 유동성(founder liquidity)이라는 덜 알려진 관행은 위험 여부를 크게 변화시킴
          + 창업자 유동성이란 새로운 펀딩 라운드에서 창업자가 자신의 주식 일부를 매각하는 것을 의미함
          + 이는 개인적인 재정적 안정을 확보하면서도 계속 회사를 성장시킬 수 있게 해줌
          + 이 관행은 종종 비밀리에 이루어지며, 투자자 업데이트에 간단히 언급되는 정도임
     * 창업자 유동성이 비밀인 이유는 '올인'했다는 창업자의 서사를 훼손하기 때문
          + 집을 담보로 잡고 라면으로 연명하며 살았다는 이야기는 매력적이며, 공감과 존경을 자아냄
          + 이는 파이의 한 조각을 대가로 낮은 급여를 받고 일할 의지가 있는 인재들을 끌어들임
          + 만약 창업자가 직원들은 그대로인 채 재정적 위험을 줄일 수 있다는 사실이 널리 알려진다면, 스타트업에 대한 인식과 가치 평가가 달라질 수 있음
     * 첨부된 그래프는 실제 시나리오를 바탕으로 한 스타트업의 초기 직원과 창업자의 4년간 현금 보상을 보여줌
          + 시드 라운드에서는 직원과 창업자 모두 낮은 연봉을 받고 있음. 이는 스타트업 초기에는 자금이 부족하기 때문으로 보임
          + 시리즈 A에서 직원의 연봉은 약간 오르지만 창업자의 연봉은 크게 오름. 더불어 창업자는 40만 달러 상당의 유동성을 확보함. 이는 투자자들이 권유한 것으로, 창업자 개인의 재정적 위험을 줄이기 위한 것으로 보임
          + 시리즈 B에서 직원 연봉은 또 약간 오르지만 창업자 연봉은 더 큰 폭으로 상승함. 창업자는 이번에도 75만 달러의 유동성을 추가로 확보함. 반면 직원들에게는 유동성이 전혀 제공되지 않음
          + 결국 이 스타트업에서는 창업자만이 자신의 위험을 크게 낮출 수 있는 유동성을 확보한 반면, 초기 직원들은 계속 위험을 안고 있어야 했던 셈임
          + 이 정도의 창업자 유동성은 꽤 흔함
     * 더 잘 알려지고 극단적인 사례로는 WeWork의 창업자 애덤 뉴먼이 있음
          + 뉴먼은 20억 달러 이상을 세컨더리로 현금화할 수 있었지만, WeWork 직원 중 누구도 자신의 지분을 활용할 수 없었음
          + 직원들은 각 인상 시마다 자신의 주식 가치를 내부적으로 들었고, WeWork의 가치가 치솟으면서 각 인상을 둘러싼 과대광고가 계속되었음
          + 뉴먼은 상승하는 동안 가능한 한 많은 세컨더리를 매각하여 자신의 입지를 탈위험화하는 것이 현명했지만, WeWork 설립 9년 후인 2019년에야 비창업 직원을 위한 공개매수 제안을 시도했음
          + 소프트뱅크와의 그 공개매수 제안은 무산되었고 직원들은 아무것도 남지 않았음
     * 이 이야기에서 불공평한 점은 창업자들이 유동성을 얻는다는 것이 아니라 그들만 유동성을 얻는다는 것임
          + Hopin과 같이 창업자가 수천만 달러 또는 수억 달러를 세컨더리로 가져가지만, 나중에 청산 우선순위 스택보다 적은 금액으로 회사를 매각하여 직원들에게 지분에 대해 0달러만 남기는 다른 사례들도 있음
     * 창업자 유동성에 대해서는 많은 이상한 인식들이 있음:
         1. 투자자와 창업자 모두 직원들이 창업자가 유동성을 얻는다는 것을 알게 되면 직원 사기에 부정적인 영향을 미칠 것이라고 생각함 (그렇지 않음)
         2. 창업자들은 종종 자신이 유동성을 얻는 것에 대해 죄책감을 느낌 (그럴 필요 없음)
         3. 투자자들은 유동성이 미래 투자자들의 인식을 부정적으로 오염시킬 수 있다고 생각함 (그렇지 않음)
         4. 투자자, 창업자, 직원 모두 창업자가 초기 직원보다 더 큰 위험을 감수한다고 믿음 (창업자만 유동성에 대한 독점적 접근권을 갖게 되면 이는 사실이 아님)
     * 시리즈 A 때 창업자가 유동성을 얻었다는 것을 알게 되었을 때 처음 드는 생각은 ""멋지네, 그들은 그럴 자격이 있어""였고, 두 번째 생각은 ""왜 직원들은 유동성을 전혀 얻지 못했을까?""였으며, 세 번째 생각은 ""이게 비밀인가? 비밀인 것 같네. 이상한데""였음
          + 주주명부에 우연히 접근할 수 있어서 그 사실을 알게 된 유일한 직원이었음
          + 제대로 읽었는지 궁금해서 즉시 창업자 중 한 명에게 가서 ""시리즈 A에서 약간의 유동성을 얻었나요?""라고 물었음
          + 그의 반응은 놀람에서 혼란으로 바뀌더니 ""응, 약간""이라고 말했음
          + ""와, 멋지네요, 축하해요! 몇 년 동안 고생한 걸 생각하면 급여를 보충할 수 있어서 좋겠어요""라고 하자 ""응, 그렇지""라고 했음
          + 그와 얘기를 나눈 후 안도감을 느낄 수 있었는데, 내가 그 사실을 알고 있다는 걸 아는 게 그에게 더 나은 것 같았음
          + 결코 부정적이거나 사기가 떨어지거나 하지 않았고, 창업팀을 신뢰했으며 그들을 위해 기뻤음
          + 만약 그것에 대해 거짓말을 들었다면 화가 나고 사기가 떨어졌겠지만, 그건 유동성 접근 때문이 아니라 거짓말 때문이었을 것임
     * 지금 창업자로서 초기 직원들의 위험 균형을 맞추기 위해 투명성을 유지하고, 더 관대한 지분을 제공하며, 직원들에게도 제공할 수 있는 경우에만 유동성을 받을 계획임
          + 직원 옵션 풀은 평균의 두 배인 20%임
          + 3개월의 지분 행사 기간이 있는데, 이는 평균보다 9개월 빠른 것임
          + 직원들이 퇴사 후 90일이 아닌 10년까지 옵션을 행사할 수 있도록 허용함
          + 지분 패키지는 업계 표준인 4년 대신 3년 동안 확정됨
     * 이러한 변화는 훌륭하지만 충분하지는 않음
          + 내 견해로는 벤처 기업의 모든 내부 신규 라운드 발표에는 유동성에 대한 교육과 투명성이 수반되어야 함
          + 투명성 없이는 잘못된 인식이 바뀔 기회가 없음
     * 벤처 기업에서 일한다면 다음에 라운드가 발표될 때 창업자가 유동성을 가져갔는지 물어볼 것
          + 필요하다면 익명으로 해도 됨
          + 이 질문은 창업자와 투자자가 기본적으로 투명해질 정도로 흔해져야 함
          + No라고 하면 좋음. 위험 프로필에 변화가 없는 것임
          + Yes라고 해도 좋음. 직원들이 창업자 및 투자자와 동일한 정보를 가지고 운영하는 것임
          + 이는 운동장을 평준화하고 직원들이 창업자보다 여전히 낮은 위험 등급에 있는지, 아니면 이제 창업자보다 훨씬 더 큰 위험을 감수하고 있는지 평가할 수 있게 해줌
     * 직원들이 창업자보다 더 큰 위험을 감수하고 있다는 것을 깨닫는다면, 아마도 더 많은 보상을 요구할 것이고, 아마도 창업자를 축하하고 하루를 보낼 것이며, 아마도 ""내가 너무 많은 위험을 감수하고 있어, 회사를 만드는 게 너무 힘들어, 나는 유동성에 접근할 수도 없어!!!""라고 소리칠 것임
          + 어쩌면 그들의 말이 맞을 수도 있음

   아무것도 없었던 것에서 라운드를 거쳐가며 성장해가는 스타트업의 대표면 직원과 크게다른 다른 기울기로 연봉이 올라가야하는게 당연한거 아닌가요?

   실제로 많은 직원들은 잘 모르는 이야기죠.
   펀딩 라운드를 여러번 거쳤다 = 창업자들은 어느정도 현금화했다
   라고 보시면 됩니다.

   제가 아는 사례가 많이 제한되어있기는 하지만, 조금 쪼개서 생각해 보면
     * 위 사례처럼 시리즈 A에서 주식을 팔아서 유동화하는 경우가 한국에서는 굉장히 드물기는 합니다. 보통 이건 오히려 투자자들이 권장하지 않습니다 (red flag라고 많이 생각하는 것 같아요)
     * xguru님이 말씀해 주신 ""여러번""은 정의하기 어렵긴 하지만, 미국보단 확실히 유동화 경향이 덜합니다. 그리고 보통 한국에서는 주주간계약서를 안 쓰고 투자자-회사 간 계약서만 쓰기 때문에 초기 투자자의 Tag-along이 붙어있어서 유동화가 쉽지 않은 것이 그 원인인 것 같습니다.
     * 다만 창업자가 너무 힘들어 하는 경우 대승적으로 권리를 행사하지 않는 경우는 종종 있는 것 같습니다. 드문 예시지만 1,000억원 밸류가 넘는 회사인데 아직도 최저시급 받고 주거가 불안정하거나 하면 연봉을 올리라고 말씀드리는 경우도 있고, 일부를 유동화시켜드리기도 하는 것 같습니다. (다만 유동화는 마찬가지로 창업자 지분보다 초기 투자자가 자신의 지분을 먼저 파는 경우가 더 많습니다)

   암튼 창업자분들이 돈 많이 벌고 직원/투자자랑도 적절히 나눠서 창업 FOMO가 많아졌으면 좋겠다는 생각입니다 ㅋㅋ

   글쎄요. 공유하신 기사처럼 실리콘밸리라면 모르겠으나, 한국에선 적어도 시리즈 A/B 정도의 단계에서 창업자들의 구주를 매각하여 현금화하는 경우는 매우 드뭅니다. 오히려 투자계약시 이해관계인으로 묶어서 퇴사제한 규정을 두거나, 주식 매각에 대한 투자자 동의 등의 조항을 넣는 것이 일반적이지요. 물론 시리즈 B 이후 정도의 라운드에서 회사의 성장세가 여전히 좋다면, 그때는 신규 펀딩 시 구주 매각도 일부 발생하는 사례를 종종 목격하긴 했습니다만,, 말씀하신 것처럼 라운드를 여러번 거쳤다고 창업자들이 현금화를 했다고 일반화 하는건 아닌 것 같아 댓글 남깁니다.

        Hacker News 의견

    해커뉴스 댓글 요약

     * 창업자가 초기 유동성을 확보하는 기회비용에 대한 논의. 창업자가 자신의 지분 10%를 50만 달러에 매각했을 때, 나중에 회사가 2억 5천만 달러에 팔리면 그 50만 달러는 500만 달러의 가치가 됨. 대부분의 경우 헤징이 올바른 선택이지만 후회할 수 있음.
     * 의미 있는 금액과 그렇지 않은 금액의 차이. 직원들이 자신의 지분 10%를 팔 수 있다면, 이는 그들의 삶을 크게 변화시키지 않음. 하지만 선택권이 주어지는 것은 환영받을 수 있음.
     * 주식을 팔기 위해서는 구매자가 필요함. 창업자는 투자자를 선택함으로써 미래의 비즈니스 파트너를 선택하는 것임. 투자자는 창업자를 행복하게 하고 리스크를 줄여주어 더 공격적이거나 큰 그림을 그릴 수 있게 함.
     * 시리즈 A 단계에서의 세컨더리 거래는 매우 드물음. 1934년 증권거래법 14e-2 조항 때문에 초기 직원들이 세컨더리 판매에 포함되지 않는 경우가 많음.
     * 창업자가 초기 유동성을 확보하는 것은 괜찮지만, 직원들에게도 동일한 기회를 제공해야 함. 비대칭성이 문제를 일으킬 수 있음. 재정적 안정성을 확보하는 것이 중요함.
     * 초기 엔지니어로 스타트업에 참여하는 것은 큰 리스크를 감수하지만, 보상은 적음. FAANG 같은 큰 회사에 가는 것이 더 나은 선택일 수 있음.
     * 많은 회사들이 시리즈 A나 B 단계에 도달하지 못함. 창업자들이 큰 지분을 유지하는 것은 드물고, 유동성 확보는 어렵고 희생이 큼. 창업자가 되기 위해서는 더 많은 경험이 필요함.
     * 스타트업에서 일하는 것은 복권과 같음. 성공하면 보상을 받지만, 대부분의 경우 큰 돈을 벌지 못함. 현실적인 기대를 가지고 접근해야 함.
     * 초기 스타트업에 참여하는 것은 창업자보다 더 큰 리스크를 감수하는 것일 수 있음. 구조적으로 불균형이 존재함.
     * 창업자의 유동성 확보는 회사의 성공 여부가 불확실한 상황에서 부를 축적하는 경로가 됨. 최소한의 제한이 필요함.
     * 20% 옵션 풀과 3개월 클리프는 주의가 필요함. 잘못된 선택이 큰 손실을 초래할 수 있음. 장기적인 옵션 행사는 동의하지만, 베스팅 기간은 논란의 여지가 있음.
     * YC 스타트업에 초기 엔지니어로 참여했지만, 시간이 지나면서 불만이 생김. 더 높은 지분을 받았다면 남았을 가능성이 큼. 다시는 이런 조건으로 스타트업에 참여하지 않을 것임.
"
"https://news.hada.io/topic?id=15201","보잉 스타라이너 첫 유인 미션 발사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          보잉 스타라이너 첫 유인 미션 발사

보잉 스타라이너 첫 유인 미션 성공

  비디오 내용

     * 보잉 스타라이너가 국제우주정거장(ISS)을 향해 궤도에 진입함.
     * 이번 발사는 스타라이너 우주선이 처음으로 사람을 태우고 비행한 것임.
     * NASA 우주비행사 부치 윌모어와 수니 윌리엄스가 탑승함.
     * 스타라이너는 6월 6일 12:15 ET (17:15 BST)에 ISS에 도킹할 예정이며, 우주비행사들은 약 일주일 동안 머무를 예정임.
     * 지금까지 우주선의 미션은 성공적임.
     * 여러 해 동안 다양한 엔지니어링 문제로 인해 이 지점에 도달하는 데 시간이 걸렸음.

  발사 순간

     * 발사 직전, 윌모어 사령관은 미션을 가능하게 한 모든 사람들에게 감사의 인사를 전함.
     * 과거의 어려움을 언급하며 ""어려운 상황에서도 강한 사람들이 나아간다""라고 말함.
     * 스타라이너의 파일럿 수니 윌리엄스는 ""고 '칼립소'! (캡슐의 이름). 우주로 데려가고 다시 돌아오자""라고 외침.

GN⁺의 의견

     * 기술적 성과: 보잉 스타라이너의 첫 유인 비행은 우주 탐사 기술의 중요한 진전을 의미함. 이는 향후 민간 우주 비행의 가능성을 높임.
     * 협력의 중요성: 이번 성공은 NASA와 보잉의 협력 덕분임. 이는 대규모 프로젝트에서 협력의 중요성을 보여줌.
     * 미래 전망: 스타라이너의 성공은 더 많은 유인 우주 비행 미션의 가능성을 열어줌. 이는 우주 탐사와 연구에 큰 기여를 할 것임.
     * 기술적 도전: 여러 해 동안의 엔지니어링 문제를 극복한 것은 기술적 도전과 해결 능력을 보여줌. 이는 다른 프로젝트에도 귀중한 교훈이 될 것임.
     * 비판적 시각: 이번 성공에도 불구하고, 민간 우주 비행의 안전성과 비용 문제는 여전히 해결해야 할 과제임. 이는 지속적인 연구와 개선이 필요함을 의미함.

        Hacker News 의견

     * 미국에서 최대 5개의 다른 우주선/발사 시스템이 인간을 궤도로 보낼 수 있게 될 가능성에 대한 흥미로움.
     * 이 캡슐이 7번의 발사 후 불확실한 미래를 맞이할 수 있다는 점에서 아쉬움.
     * 냉각 시스템이 예상보다 더 많은 물을 사용하고 있어 백업 시스템으로 전환했다는 문제.
     * ""For All Mankind"" 시리즈를 모두 본 후 이러한 뉴스에 더욱 흥미를 느끼고 있음.
     * 누군가가 문을 두 번 확인했기를 바라는 마음.
     * 보잉과 우주비행의 조합이 용감하다고 생각함.
     * 발사대에서 빠르게 이륙한 것에 놀라움. 스타쉽은 연료를 태우며 천천히 이륙하는 것처럼 보였음.
     * 미국에서 민간 유인 우주 임무에 대한 규제가 어떻게 적용되는지 궁금해함. 명확한 지침이 있는지, 일반 항공 규칙을 따르는지, 새로운 규칙이 작성 중인지에 대한 질문.
     * 문이 떨어졌는지에 대한 의문.
     * 이러한 성과가 너무 당연하게 여겨지는 것이 놀라움. 마치 누구나 할 수 있는 일처럼 다루어짐.
"
"https://news.hada.io/topic?id=15293","린 콘웨이 사망","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                린 콘웨이 사망

초기 생애 및 교육

     * 린 콘웨이는 뉴욕주 화이트 플레인스에서 자람.
     * 어릴 때부터 성별 불쾌감을 경험했으며, 천문학에 흥미를 가짐.
     * MIT에 입학했으나 성전환 시도가 실패한 후 중퇴.
     * 컬럼비아 대학교에서 전자공학 학사 및 석사 학위를 취득함.

IBM에서의 초기 연구

     * 1964년 IBM 연구소에 합류하여 고성능 슈퍼컴퓨터 설계 팀에 참여함.
     * 동적 명령어 스케줄링을 발명하여 현대 고성능 마이크로프로세서에 사용됨.

성전환

     * 해리 벤자민의 연구를 통해 성전환 수술이 가능하다는 것을 알게 됨.
     * 성전환을 시도했으나 IBM에서 해고됨.
     * 2020년 IBM은 공식적으로 사과함.

컴퓨터 과학자로서의 경력

     * 성전환 후 새로운 이름과 신분으로 경력을 재개함.
     * Xerox PARC에서 VLSI 칩 설계 혁명을 주도함.
     * VLSI 설계 방법론을 개발하고, 이를 통해 칩 설계와 생산의 현대적 '파운드리' 인프라를 구축함.
     * DARPA에서 고성능 컴퓨팅 및 자율 시스템 기술 연구 프로그램을 주도함.
     * 미시간 대학교에서 교수로 재직하며 인터넷/광대역 케이블 통신에 관한 연구를 진행함.

유산

     * VLSI 설계 혁명과 MOSIS 서비스의 개발로 칩 설계 및 생산에 큰 영향을 미침.
     * IEEE와 같은 주요 학회에서 다수의 상을 수상함.
     * 2023년, VLSI 혁신을 다룬 만화책 ""Lines in the Sand""를 공동 제작함.

트랜스젠더 활동

     * 1999년부터 자신의 성전환 이야기를 공개하며 트랜스젠더 권리 옹호 활동을 시작함.
     * 트랜스젠더 인권 보호 및 고용 기회 확대를 위해 노력함.
     * 트랜스젠더 관련 의료 자원과 감정적 조언을 제공하는 웹사이트를 운영함.

개인 생활

     * 1987년 남편 찰스 로저스를 만나 결혼함.
     * 미시간의 시골 지역에 거주하며 다양한 야외 활동을 즐김.

수상 및 영예

     * 다수의 학회와 기관에서 상을 수상함.
     * 2020년 IBM으로부터 평생 공로상을 수상함.
     * 2023년 발명가 명예의 전당에 헌액됨.

GN⁺의 의견

     * 린 콘웨이의 연구는 현대 컴퓨터 과학과 전자공학에 큰 기여를 했음.
     * 트랜스젠더로서의 공개적인 활동은 많은 사람들에게 영감을 주었음.
     * VLSI 설계 방법론은 오늘날의 반도체 산업에 필수적인 기술로 자리잡음.
     * IBM의 사과는 기업이 과거의 잘못을 인정하고 개선하려는 노력을 보여줌.
     * 트랜스젠더 인권 보호와 관련된 활동은 사회적 인식을 높이는 데 큰 역할을 했음.

        Hacker News 의견

     * Lynn Conway는 1978년에 역사적인 VLSI 설계 과정을 창설하고 가르쳤으며, 이는 학생들이 자신만의 집적 회로를 설계하고 제작한 첫 번째 사례였음.
     * IBM에서 해고된 후에도 그녀는 VLSI 설계 방법론을 발명하고 이를 산업 선구자들에게 가르쳐 많은 성공적인 회사를 설립하게 했음.
     * 그녀는 또한 트랜스젠더 활동가로서 많은 사람들을 도왔으며, 2009년 IEEE 컴퓨터 소사이어티 컴퓨터 파이오니어 상을 받았음.
     * 한 생물학자는 하와이의 생물학 회의에서 우연히 그녀를 만나 대화를 나누었고, 나중에 그녀가 실제로 VLSI 분야에서 일한 것을 알게 되었음.
     * Lynn Conway는 Carver Mead와 함께 VLSI 설계 교과서를 공동 저술했으며, 그녀의 학생들은 혁신적인 설계를 통해 많은 성과를 이루었음.
     * Jim Clark는 그녀의 학생 중 한 명으로, 그녀에게서 배운 지식을 바탕으로 Silicon Graphics Incorporated를 설립했음.
     * 1979년 VLSI 설계 과정에서 학생들이 제작한 칩들은 대부분 성공적으로 작동했으며, 이는 큰 성과였음.
     * MIT와 Stanford에서의 연구는 새로운 아키텍처 패러다임을 발전시키는 데 기여했으며, 특히 Jim Clark의 Geometry Engine은 강력한 그래픽 처리 시스템의 기초가 되었음.
     * Clark Baker의 초기 회로 추출기 작업은 네트워크 커뮤니티에서 널리 알려졌으며, 이는 프로그램의 유용성을 입증하는 데 기여했음.
     * 한 사용자는 1980-1982년 동안 Xerox PARC에서 Lynn과 함께 일했으며, 그녀를 그리워함.
     * 다른 사용자는 최근에 Mead와 Conway의 ""Introduction to VLSI Systems""를 읽고 있으며, 그 당시의 혁신적인 아이디어들이 놀랍다고 느꼈음.
     * Lynn의 이야기는 놀랍고, 비극적이며, 승리적인 요소가 많음.
     * 한 사용자는 지난 25년 동안 Lynn을 롤 모델로 삼았으며, 그녀를 만나지 못한 것이 아쉬움.
     * 한 사용자는 University of Michigan 동문 잡지를 위해 Lynn의 프로필을 작성할 기회를 가졌으며, 그녀를 매우 영감을 주는 인물로 묘사함.
     * 한 사용자는 Lynn의 업적에 대해 처음 알게 되었으며, 그녀의 성과와 용기에 깊은 인상을 받았음.
     * Lynn은 IBM에서 해고된 후에도 경력을 재건한 놀라운 용기의 소유자였으며, 그녀의 기술적 성취는 인류의 가장 뛰어난 업적 중 하나로 평가됨.
"
"https://news.hada.io/topic?id=15314","불면증 환자들, 잠든 상태에서도 깨어있다고 착각","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       불면증 환자들, 잠든 상태에서도 깨어있다고 착각

밤새 깨어 있었나요? 사실 잠들었을 수도 있음

  수면 클리닉에서의 경험

     * 수면 클리닉에서 뇌파를 기록하는 전극을 착용하고 밤을 보낸 후, 자신은 거의 잠을 자지 않았다고 보고함.
     * 그러나 수면 측정의 금표준인 다중수면검사(Polysomnography)에 따르면 밤새 잠을 잤다고 나옴.

  주관적 불면증과 수면 오인

     * 주관적 불면증, 역설적 불면증 또는 수면 오인으로 불리는 상태가 있음.
     * 최근 연구에서는 주관적 불면증을 가진 사람들이 좋은 수면을 취하는 사람들과 다른 뇌 활동을 보인다는 것을 발견함.

  새로운 연구 방법

     * 네덜란드 신경과학 연구소(NIN)의 연구진은 256개의 전극을 사용하여 수면 중 뇌 활동을 측정함.
     * 연구 참가자들을 밤 동안 평균 26번 깨워서 잠들었는지 깨어 있었는지, 그리고 무슨 생각을 했는지 물어봄.

  REM 수면과 주관적 불면증

     * 주관적 불면증을 가진 사람들은 REM 수면 중 빠른 뇌파 형태의 각성 주머니를 보임.
     * 이들은 잠을 깊게 잤다고 느끼지 않으며, 깨어났을 때 깨어 있을 때와 비슷한 생각을 보고함.
     * 반면, 정상적인 수면을 취하는 사람들은 몰입형 꿈을 꾸며 깊은 수면을 경험함.

  REM 수면과 정신 건강

     * REM 수면의 중단은 PTSD와 불안 장애와 강하게 연관됨.
     * 좋은 수면을 취하는 사람은 트라우마를 겪은 후 PTSD를 덜 발병할 가능성이 높음.
     * REM 수면 중단은 감정적 스트레스를 처리하는 뇌의 기능을 방해함.

  새로운 치료법의 가능성

     * 주관적 불면증을 가진 사람들을 위한 맞춤형 치료법이 제안되고 있음.
     * 현재 표준 치료법인 인지 행동 치료(CBTi)는 모든 사람에게 효과적이지 않음.
     * 수면 제한과 같은 행동 전략이 REM 수면 중단을 가진 사람들에게 유망함.

  약물 개입의 가능성

     * 연구진은 베타 차단제와 같은 약물이 노르에피네프린의 영향을 완화할 수 있는지 테스트하려고 함.
     * 클로니딘과 같은 혈압 약물이 뇌가 더 평온한 상태에 도달하는 데 도움이 될 수 있는지 연구 중임.

  환자들에게 주는 안도감

     * 자신의 수면이 객관적으로 다르다는 것을 이해하는 것만으로도 환자들에게 안도감을 줄 수 있음.

GN⁺의 의견

     * 주관적 불면증의 이해: 이 기사는 주관적 불면증에 대한 새로운 이해를 제공하며, 이는 많은 사람들이 자신의 수면 문제를 더 잘 이해하고 관리하는 데 도움이 될 수 있음.
     * 정신 건강과의 연관성: REM 수면의 중단이 PTSD와 불안 장애와 연관이 있다는 점은 정신 건강 관리에 중요한 통찰을 제공함.
     * 맞춤형 치료법의 필요성: 모든 사람에게 동일한 치료법이 효과적이지 않다는 점에서 맞춤형 치료법의 필요성을 강조함.
     * 약물 치료의 가능성: 새로운 약물 치료법이 개발될 가능성이 있으며, 이는 현재의 치료법으로 효과를 보지 못하는 사람들에게 희망을 줄 수 있음.
     * 수면 연구의 중요성: 수면 연구는 우리의 건강과 삶의 질에 큰 영향을 미치며, 더 많은 연구와 투자가 필요함.

        Hacker News 의견

     * 첫 번째 의견: 잠에서 깬 줄 알았지만 실제로는 여전히 자고 있는 경우가 많음. 가족들이 깨웠다고 하지만 기억이 나지 않음.
     * 두 번째 의견: 아내가 코를 골고 있다고 깨우지만 본인은 깨어있다고 생각함. 소량의 CBD 섭취 후 수면 문제가 줄어듦.
     * 세 번째 의견: 디스크 탈출증으로 인해 수면 리듬이 망가졌지만, 수면 제한 요법을 통해 정상적인 수면 패턴을 되찾음.
     * 네 번째 의견: ICU에서 수면 부족을 느꼈지만, 수면 전문가의 조언으로 실제로는 잠을 자고 있다는 사실을 알게 되어 마음의 평화를 얻음.
     * 다섯 번째 의견: 수면 추적기를 통해 실제로는 짧은 시간 동안만 깨어있다는 것을 알게 되어 수면에 대한 스트레스가 줄어듦.
     * 여섯 번째 의견: 편두통이 수면 부족과 연관이 있다고 느끼며, 편두통 후에는 주관적으로 좋은 수면을 경험함.
     * 일곱 번째 의견: 특정 문제에 대해 생각하다가 현실과 비현실이 혼재된 상태로 잠에 드는 경험을 즐기며, 이를 재현하려고 노력함.
     * 여덟 번째 의견: 뇌가 과도하게 활성화되어 잠을 못 자는 듯하지만, 실제로는 시간이 빠르게 지나가며 어느 정도 잠을 자고 있다고 추정함.
     * 아홉 번째 의견: 아내가 깨운 후 다시 잠들면 생생하고 창의적인 꿈을 꾸며, 이는 자신에게 즐거운 경험임.
"
"https://news.hada.io/topic?id=15278","LSP-AI : AI기능을 위한 오픈소스 랭귀지 서버","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     LSP-AI : AI기능을 위한 오픈소스 랭귀지 서버

     * LLM 및 다른 AI 기반 기능을 위한 백엔드 역할을 수행하는 오픈소스 Language Server Protocol(LSP) 구현체
     * LSP를 지원하는 기존 에디터(VS Code, Neovim 등)에 AI 기능을 쉽게 도입하기 위해, 에디터별 플러그인 작성의 복잡한 구현 세부 사항을 추상화
     * 특징
          + AI 기능을 하나의 백엔드로 집중화 가능
          + 더 쉬운 플러그인 개발
          + 공유 백엔드를 통해 향상된 협업 플랫폼을 형성
          + LSP 지원을 통한 폭넓은 호환성
          + 유연한 LLM 백엔드 지원: llama.cpp, OpenAI / Anthropic / Mistral 의 API와 호환
"
"https://news.hada.io/topic?id=15251","비아그라, 뇌 혈류 개선 및 치매 예방 가능성","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       비아그라, 뇌 혈류 개선 및 치매 예방 가능성

실데나필(‘비아그라’)이 뇌 혈류를 개선하고 치매 예방에 도움을 줄 수 있음

  연구 개요

     * 옥스퍼드 대학교의 새로운 연구에 따르면 실데나필(비아그라)이 뇌 혈류를 개선하고 혈관성 치매의 예방에 도움을 줄 수 있음.
     * 이 연구는 혈관성 치매 예방에 중요한 단계로 평가됨.

  연구의 중요성

     * 혈관성 치매는 현재 특정 치료법이 부족한 상태임.
     * 뇌의 작은 혈관에 만성적인 손상이 혈관성 치매의 주요 원인임.
     * 고혈압, 뇌로의 혈류 감소, 혈관 기능 저하가 이러한 상태를 악화시킴.

  연구 방법

     * OxHARP 시험은 75명의 경미한 뇌졸중 경험자와 경도에서 중등도의 작은 혈관 질환을 가진 참가자를 대상으로 함.
     * 참가자들은 실데나필, 위약, 실로스타졸을 3주 동안 무작위 순서로 투여받음.
     * 심혈관 생리학 테스트, 초음파, 기능적 MRI 스캔을 사용하여 약물의 효과를 평가함.

  주요 발견

     * 실데나필은 초음파와 MRI 스캔을 통해 큰 혈관과 작은 혈관 모두에서 혈류를 증가시킴.
     * 실데나필은 이산화탄소에 대한 혈류 반응을 개선하여 뇌혈관 기능을 향상시킴.
     * 실데나필과 실로스타졸 모두 뇌 혈관 저항을 낮춤.
     * 실데나필은 실로스타졸에 비해 부작용이 적었으며, 특히 설사의 발생이 적었음.

  향후 계획

     * 더 큰 규모의 시험을 통해 이러한 발견을 확인하고, 실데나필의 혈관성 치매 예방 가능성을 탐구할 예정임.

  연구 지원

     * 이 연구는 웰컴 트러스트와 국립 보건 및 케어 연구소의 지원을 받았음.

GN⁺의 의견

     * 실데나필의 새로운 가능성: 기존에 주로 발기부전 치료제로 알려진 실데나필이 치매 예방에 도움을 줄 수 있다는 점에서 흥미로움.
     * 치매 예방의 중요성: 치매는 개인과 사회에 큰 부담을 주는 질환으로, 예방 방법이 개발된다면 큰 사회적 가치를 가질 수 있음.
     * 부작용 관리: 실데나필이 실로스타졸에 비해 부작용이 적다는 점은 환자들에게 더 안전한 선택지를 제공할 수 있음.
     * 추가 연구 필요성: 현재 연구는 소규모로 진행되었으므로, 더 큰 규모의 연구를 통해 결과를 확증할 필요가 있음.
     * 기술 도입 고려사항: 새로운 치료법 도입 시 비용, 접근성, 장기적인 효과 등을 종합적으로 고려해야 함.

        Hacker News 의견

     * 원래 심혈관 문제를 위한 약물이었고, 발기부전 완화는 우연한 부수 효과였음.
     * 비아그라는 귀의 작은 혈관에 과도한 혈류를 일으켜 이명을 유발할 수 있음. 운동 중 고용량 복용 주의 필요.
     * OxHARP 시험은 경미한 뇌졸중을 겪은 75명을 대상으로 한 이중 맹검, 위약 대조 연구였음. 비아그라와 유사한 약물인 실로스타졸도 포함됨.
     * 비아그라는 명확한 효과가 있어 위약과 구분 가능할 것 같음. 실로스타졸이 같은 효과를 주는지 의문.
     * 아연 대사 변화가 치매에 영향을 줄 수 있음. cGMP 부족이 치매와 관련될 수 있음.
     * 설문 조사 연구에서 치매와 여가 활동 간의 순환 논리 오류 가능성 있음. 치매 환자는 비아그라나 마라톤을 추구하지 않을 수 있음.
     * 비트 섭취로 인한 NO 증가와 비아그라의 효과 비교를 보고 싶음.
     * NIH의 연구 결과가 일관되지 않음. 비아그라가 알츠하이머 위험을 줄인다는 연구와 그렇지 않다는 연구가 혼재됨.
     * 비아그라가 심한 속쓰림과 코막힘, 눈 충혈을 유발해 복용이 어려움. 연구에서 제시된 용량은 너무 높아 보임.
     * 비아그라가 생리통을 줄이는 효과도 있음.
     * 연구에서 제시된 50mg 3회/일 복용량이 높아 보임. 대부분의 사람들은 주로 주말에만 복용할 것 같음.

    추가 배경 지식

     * 비아그라(Viagra): 주로 발기부전 치료제로 알려진 약물로, 원래는 심혈관 질환 치료를 위해 개발되었음.
     * 이중 맹검 연구: 연구 참가자와 연구자가 어떤 치료를 받는지 모르게 하는 연구 방법으로, 연구의 객관성을 높임.
     * cGMP: 세포 내 신호 전달 물질로, 혈관 확장과 관련 있음.
     * NO (Nitric Oxide): 혈관을 확장시키는 물질로, 비트 섭취 시 증가할 수 있음.
"
"https://news.hada.io/topic?id=15273","Libtree: 라이브러리 발견 여부를 트리 형태로 설명하는 Ldd","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Libtree: 라이브러리 발견 여부를 트리 형태로 설명하는 Ldd

libtree 도구

  기능

     * ldd 명령어를 트리 형태로 변환함
     * 공유 라이브러리가 어떻게 발견되었는지 또는 왜 찾을 수 없는지 설명함

  출력

     * 기본적으로 특정 표준 종속성은 표시되지 않음
     * 더 자세한 출력을 위해 다음 명령어 사용 가능:
          + libtree -v: 기본적으로 생략된 라이브러리 표시
          + libtree -vv: 생략된 라이브러리의 종속성 표시
          + libtree -vvv: 이미 발견된 라이브러리의 종속성 표시
     * --path 또는 -p 플래그를 사용하여 soname 대신 경로 표시:
          + 예: libtree -p $(which tar)
     * --max-depth 플래그를 사용하여 재귀 깊이 제한 가능

  설치

     * v3.1.1 버전의 사전 빌드 바이너리:
          + aarch64 (linux): c5d4fbcd4e3fb46f02c028532f60fcf1c92f7c6aad5b07a991c67550c2554862
          + armv6l (linux): 16f5a7503a095bd88ebc5e21ec4ba8337c5d9712cac355bf89399c9e6beef661
          + armv7l (linux): 17f493621e7cc651e2bddef207c1554a64a114e1c907dbe5b79ff0e97180b29e
          + i686 (linux): 230a163c20f4a88a983d8647a9aa793317be6556e2c6a79e8a6295389e651ef5
          + x86_64 (linux): 49218482f89648972ea4ef38cf986e85268efd1ce8f27fe14b23124bca009e6f
     * Fedora / RHEL / CentOS:
          + $ dnf install epel-release (RHEL 및 파생 제품의 경우 EPEL 먼저 활성화)
          + $ dnf install libtree-ldd
     * Ubuntu 22.04+:
          + $ apt-get install libtree
     * GNU Guix:
          + $ guix install libtree

  소스에서 빌드

     * libtree는 c99를 이해하는 C 컴파일러 필요
          + git clone https://github.com/haampie/libtree.git
          + cd libtree
          + make (추천: LDFLAGS=-static)
          + 빠른 설치 방법:
               o curl -Lfs https://raw.githubusercontent.com/haampie/libtree/master/libtree.c | ${CC:-cc} -o libtree -x c - -std=c99 -D_FILE_OFFSET_BITS=64

GN⁺의 의견

     * libtree는 공유 라이브러리의 종속성을 시각적으로 이해하는 데 유용함. 이는 디버깅과 시스템 관리에 큰 도움이 됨.
     * libtree는 다양한 리눅스 배포판에서 쉽게 설치할 수 있어 접근성이 높음.
     * 소스에서 직접 빌드할 수 있어 커스터마이징이 가능함.
     * 이 도구는 특히 복잡한 프로젝트에서 라이브러리 종속성을 관리하는 데 유용함.
     * 비슷한 기능을 제공하는 도구로는 ldd와 readelf가 있지만, libtree는 트리 구조로 시각화해 더 직관적임.

   좋아보이네요!!
"
"https://news.hada.io/topic?id=15277","아이폰, 아이패드, 맥을 위한 Apple Intelligence","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  아이폰, 아이패드, 맥을 위한 Apple Intelligence

Apple Intelligence: 개인 지능 시스템 소개

  새로운 언어 이해 및 생성 기능

     * Apple Intelligence는 iOS 18, iPadOS 18, macOS Sequoia에 통합되어 사용자의 글쓰기와 의사소통을 향상시킴.
     * Writing Tools: 사용자가 텍스트를 재작성, 교정, 요약할 수 있게 도와줌.
          + Rewrite: 다양한 버전의 텍스트를 제공하여 톤을 조정할 수 있음.
          + Proofread: 문법, 단어 선택, 문장 구조를 점검하고 수정 제안.
          + Summarize: 텍스트를 요약하여 간결한 단락, 주요 포인트, 표, 목록 형태로 제공.

  이미지 플레이그라운드로 더 재미있는 소통과 자기 표현

     * Image Playground: 애니메이션, 일러스트, 스케치 스타일로 이미지를 빠르게 생성할 수 있음.
     * Messages와 같은 앱에 통합되어 있으며, 전용 앱에서도 사용 가능.
     * 사용자가 개인 사진 라이브러리에서 이미지를 선택하고 스타일을 지정할 수 있음.

  Genmoji 생성

     * Genmoji: 사용자가 설명을 입력하면 생성되는 맞춤형 이모지.
     * 친구나 가족의 사진을 기반으로 Genmoji를 만들 수 있음.
     * 메시지에 인라인으로 추가하거나 스티커, 반응으로 사용할 수 있음.

  사진에서 더 많은 제어 기능 제공

     * 사진 검색: 자연어를 사용하여 특정 사진이나 비디오의 특정 순간을 검색할 수 있음.
     * Clean Up 도구: 사진 배경의 방해 요소를 제거함.
     * Memories: 설명을 입력하면 Apple Intelligence가 최적의 사진과 비디오를 선택하여 스토리를 만듦.

  Siri의 새로운 시대

     * Siri: 더 자연스럽고 개인화된 언어 이해 능력으로 일상 작업을 간소화하고 가속화함.
     * 텍스트와 음성 간 전환 가능.
     * 온스크린 인식: 화면의 정보를 이해하고 관련 작업을 수행할 수 있음.

  AI에서 새로운 프라이버시 표준 설정

     * Private Cloud Compute: 복잡한 요청을 처리하기 위해 클라우드에서 더 큰 모델을 사용하면서도 사용자 데이터를 보호함.
     * 독립적인 전문가가 Apple 실리콘 서버의 코드를 검사할 수 있음.

  ChatGPT 통합

     * ChatGPT: iOS 18, iPadOS 18, macOS Sequoia에 통합되어 Siri와 Writing Tools에서 사용 가능.
     * 사용자가 허락하면 ChatGPT의 광범위한 지식을 활용하여 답변을 제공함.
     * ChatGPT의 데이터 사용 정책이 적용되며, 사용자의 IP 주소는 숨겨짐.

GN⁺의 의견

    1. 개인화된 경험: Apple Intelligence는 사용자의 개인 정보를 기반으로 맞춤형 경험을 제공하여 더 유용하고 관련성 높은 정보를 제공함.
    2. 프라이버시 보호: Private Cloud Compute를 통해 사용자 데이터를 보호하면서도 강력한 AI 기능을 제공함.
    3. 생산성 향상: Writing Tools와 Siri의 새로운 기능은 사용자의 생산성을 크게 향상시킬 수 있음.
    4. 경쟁력: Google Assistant와 같은 다른 AI 비서와의 경쟁에서 Apple의 강력한 프라이버시 보호 기능이 큰 장점이 될 수 있음.

        Hacker News 의견

    해커뉴스 댓글 요약

     * Apple의 개인 AI 기술에 깊은 인상을 받았음. Siri가 이메일과 메시지의 맥락을 이해하고 행동을 수행하는 기능이 매우 유용함.
     * AI가 생성한 이미지가 개인적이지 않고 불편하게 느껴짐. 생일 축하 메시지로는 적합하지 않음.
     * Apple의 생성 AI 기능의 유용성에 대해 의문을 가짐. 직접 만든 것이 더 가치가 있음.
     * Apple의 브랜드 전략이 완벽함. AI를 통해 더 많은 사용자에게 접근할 수 있을 것으로 보임.
     * Apple의 AI 데모가 매우 인상적이었음. 특히 서버 기반 AI 작업을 프라이버시를 유지하면서 처리하는 방식이 좋았음.
     * Apple의 AI가 기기 내에서 처리되며, 필요 시 서버로 전환됨. ChatGPT와 같은 외부 서비스는 사용자 허가가 필요함.
     * 발표 내용이 모호하여 실제 작동 여부에 대해 회의적임. 클라우드와 기기 간의 데이터 이동에 대한 명확한 설명이 필요함.
     * 이미지 생성 기능이 너무 많은 주목을 받았다고 생각함. 중요한 정보를 확인하지 않고 AI에 의존하는 것은 위험할 수 있음.
     * ChatGPT 통합 방식이 어색하게 느껴짐. 사용자 경험이 혼란스러울 수 있음.
     * Apple Intelligence가 무료로 제공되며, iOS 18, iPadOS 18, macOS Sequoia에서 베타로 출시될 예정임.
     * Apple의 AI 모델이 프라이빗 클라우드 컴퓨팅을 지원하며, 서버 측 코드가 오픈소스가 될지 궁금함. Siri가 더 유용해질 것으로 기대됨.
"
"https://news.hada.io/topic?id=15257","경제적 흰개미는 도처에 있다: 대부분이 알아채지 못하는 독점들","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   경제적 흰개미는 도처에 있다: 대부분이 알아채지 못하는 독점들

     * 경제적 흰개미: 대규모 독점이 투자자에게 큰 이익을 주지만 대부분의 사람들에게는 눈에 띄지 않는 사례를 의미
     * 작은 문제들이 모여 현대 경제의 경험을 형성하고 있고, 이러한 문제들이 사회의 신뢰를 약화시키고 있음

  Verisign: 주식 시장에서 가장 수익성이 높은 회사

     * 가격 인상: Verisign은 .com 도메인 등록 비용을 꾸준히 인상해왔음.
     * 독점적 위치: Verisign은 정부로부터 독점 권한을 부여받아 도메인 등록을 관리하고 있음.
     * 수익성: Verisign의 운영 마진은 2013년 54.7%에서 2023년 67.1%로 증가했음.

  AutoDesk: 건축에서 ""인질""을 잡다

     * 고객 불만: 건축 및 엔지니어링 디자인 소프트웨어 제공업체인 AutoDesk에 대한 불만이 많음.
     * 시장 지배력: AutoDesk는 높은 전환 비용을 통해 시장 지배력을 유지하고 있음.
     * 가격 인상: AutoDesk는 지속적으로 가격을 인상하고 있음.

  Linde: 산업용 가스

     * 합병: 2018년 Linde와 Praxair가 합병하여 산업용 가스 시장에서 가장 큰 회사가 됨.
     * 가격 인상: 합병 이후 Linde는 가격을 지속적으로 인상하고 있음.
     * 시장 지배력: 산업용 가스는 필수적이지만 비용의 작은 부분을 차지하여 가격 인상이 눈에 띄지 않음.

  스웨덴의 포식자: Assa Abloy

     * 시장 지배력: Assa Abloy는 잠금 장치 시장에서 많은 기업을 인수하여 지배력을 강화함.
     * 가격 인상: 합병 이후 Assa Abloy는 가격을 지속적으로 인상하고 있음.
     * 경쟁 제한: 새로운 혁신적인 생산자를 시장에서 배제하는 사례가 있음.

  엔터테인먼트 데이터: Gracenote

     * 시장 점유율: Gracenote는 영화, 음악, TV 목록에 대한 메타데이터를 제공하며 시장의 60%를 차지함.
     * 제한적 계약: Gracenote는 다른 데이터베이스와의 결합을 제한하는 계약을 통해 시장 지배력을 유지함.
     * 가격 인상: Gracenote는 시장 지배력을 이용해 가격을 인상하고 있음.

  LinkedIn: 긍정적인 기업 블로그 게시물 그 이상

     * 시장 지배력: LinkedIn은 전문 소셜 네트워크에서 독점적인 위치를 차지하고 있음.
     * 가격 인상: LinkedIn은 고객에게 174%의 가격 인상을 부과함.
     * 경쟁 제한: LinkedIn은 경쟁사에게 데이터를 제공하지 않음으로써 시장 지배력을 유지함.

GN⁺의 의견

     * 경제적 흰개미의 영향: 작은 독점들이 모여 경제 전반에 걸쳐 큰 영향을 미치고 있음. 이는 소비자에게 추가 비용을 부담시키고 있음.
     * 독점의 문제점: 독점은 혁신을 저해하고 가격을 인상하여 소비자에게 불리함.
     * 법적 대응 필요성: 이러한 독점을 해결하기 위해서는 법적 대응이 필요함. 정부와 규제 기관의 적극적인 개입이 요구됨.
     * 대체 제품 추천: AutoDesk의 경우, 대체 CAD 소프트웨어를 고려해볼 수 있음. 예를 들어, FreeCAD나 Blender 같은 오픈소스 소프트웨어가 있음.
     * 기술 도입 시 고려사항: 새로운 기술이나 소프트웨어를 도입할 때는 전환 비용과 장기적인 유지 비용을 고려해야 함.

        Hacker News 의견

    해커뉴스 댓글 요약

     * 기사의 핵심 주장에 대한 증거 부족: 경제가 망가진 이유가 작은 독점 기업들 때문이라는 주장을 뒷받침하는 증거가 부족함. 건설 비용 상승의 예시가 있지만, 실제로는 더 강력한 요인들이 있음.
     * 경쟁자의 수와 가격: 가격이 내려가려면 최소한 네 명의 경쟁자가 필요함. 네 명 이하일 경우 가격이 오르고 소비자가 손해를 봄. 네 명이 기준이 되어야 함.
     * 미국 기업의 높은 수익 기대: 미국 기업들이 너무 높은 수익을 기대함. 중국 기업들은 치열한 경쟁을 예상하고 낮은 수익률을 받아들임.
     * 경제 지표의 한계: 경제학자들이 몇 가지 지표에만 집중하여 경제의 강도를 설명하려고 함. 소비자들은 경제가 좋다고 느끼지 않음. 새로운 정보 수집 방법이 필요함.
     * 경쟁이 없는 시장: 많은 시장에서 경쟁이 불가능한 상태로 이동함. 주택 가격이 인플레이션보다 훨씬 많이 상승한 예시가 있음.
     * LinkedIn의 역할: LinkedIn이 전문직 종사자들의 이력서를 쉽게 공개할 수 있게 함. 하지만 독점적 지위를 가지고 있음에도 불구하고, 다른 방법으로도 인재를 찾을 수 있음.
     * 경제적 흰개미: 경제적 흰개미라는 용어가 유용함. 예시로는 결제 처리기, 디지털 광고, 클라우드 서비스 제공자, 교과서 출판사가 있음.
     * AutoDesk의 경쟁자: AutoDesk의 경쟁자가 더 나은 제품을 가지고 있었지만, 사용자들이 이미 알고 있는 도구를 계속 사용하려는 경향이 있음.
     * Dunkin’ Donuts의 온라인 주문 문제: 앱에서 재고 상태를 알 수 없어 주문이 취소되지 않는 문제 발생. 고객이 불편을 겪음.
     * AutoDesk의 경쟁 부재: AutoDesk가 사용자들에게 인기가 없는데도 왜 경쟁자가 나타나지 않는지 의문. 정부의 장벽이 있는지 궁금함. Microsoft의 예시처럼 큰 기업들이 도전할 수 있음.
"
"https://news.hada.io/topic?id=15247","Show HN: 현재 날씨를 보여주는 E-Paper 7색 디스플레이","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Show HN: 현재 날씨를 보여주는 E-Paper 7색 디스플레이

Sol Mate e-Paper Display

  하드웨어

     * Raspberry Pi 5
     * Waveshare e-Paper 7.3"" 디스플레이 (다른 크기 사용 시 코드 업데이트 필요)

  소프트웨어 및 사용법

     * Python 가상 환경 설정 권장
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt

       또는
python -m venv .
source .venv/bin/activate
pip install -r requirements.txt

     * OPENAI_API_KEY 환경 변수 설정 필요
     * control.py 스크립트를 사용해 이미지 생성 및 화면에 표시
python control.py show Barcelona

     * 디스플레이에 동일한 이미지를 오래 두지 않도록 주의
python control.py clear

     * 크론 잡 설정 예시 (이미지 업데이트 및 클리어)
0 8 * * * cd ~/src/sol-mate-eink && .venv/bin/python control.py show Barcelona
0 18 * * * cd ~/src/sol-mate-eink && .venv/bin/python control.py show Barcelona
0 2 * * * cd ~/src/sol-mate-eink && .venv/bin/python control.py clear

  백엔드

     * 개인 API 사용 가능 (과도한 사용 시 자체 호스팅 권장)
     * 소스 코드: GitHub 링크

  문제 발생 시

     * 트위터나 GitHub 이슈 생성으로 도움 요청 가능

GN⁺의 의견

     * 실용성: e-Paper 디스플레이는 전력 소모가 적고, 다양한 용도로 활용 가능함.
     * 확장성: 오픈소스 프로젝트로, 필요에 따라 기능을 추가하거나 수정할 수 있음.
     * 비용: OpenAI API 사용 시 비용 발생 가능성 있음. 무료 대안이나 자체 호스팅 고려 필요.
     * 기술적 도전: 초급 엔지니어에게는 가상 환경 설정 및 API 키 관리가 좋은 학습 기회가 될 수 있음.
     * 유사 프로젝트: 비슷한 기능을 제공하는 다른 오픈소스 프로젝트로는 MagicMirror² 등이 있음.

        Hacker News 의견

     * Inkplate 6Color 사용 경험: ESP32 컨트롤러가 내장되어 있어 라즈베리 파이가 필요 없고, 배터리로 구동 가능함. ""On Air"" 사인을 사무실 문에 걸어두고 맥에서 단축키로 상태를 업데이트하고 장치를 음소거함. 날씨 디스플레이, 뉴스, 구글 캘린더 등 오픈 소스 프로젝트 예제가 있음.
     * 동일한 프로젝트 경험: 동일한 디스플레이를 사용하여 일주일 전에 비슷한 프로젝트를 독립적으로 만듦. 현재 날씨와 시간을 가져와 AI가 해당 위치의 사진을 생성하고 표시하는 프레임을 만듦.
     * OpenAI API 사용에 대한 우려: 항상 켜져 있는 장치에 OpenAI API를 사용하지 않겠음. 대신 OpenStreetMaps와 LAN에서 호스팅되는 Stable Diffusion을 사용하는 버전을 만들 계획임.
     * 날씨 데이터 신뢰성 의문: 바르셀로나에서 26°C와 2°C를 동시에 경험하는 것이 상상이 가지 않음. 날씨 데이터가 신뢰할 만한지, 아니면 단순히 애니메이션을 즐기면 되는지 궁금함.
     * 유사 프로젝트에서 영감 얻음: 비슷한 프로젝트를 보고 동일한 디스플레이를 두 개 구입함. 컬러 사진 디스플레이로 만들 계획이었지만, 이 응용 프로그램도 흥미로움.
     * 컬러 e-ink 디스플레이 주의사항: 동일한 이미지를 너무 오래 디스플레이에 남겨두지 말라는 조언에 대한 궁금증. 컬러 e-ink의 특성 때문인지 궁금함.
     * 프로젝트의 가치: 훌륭한 프로젝트로 커스터마이징의 길을 열어줌. 하드웨어 추천과 epaper.py 같은 참고 자료가 유용함.
     * 라즈베리 파이 대체 가능성: 왜 작은 저전력 컴퓨터(주로 라즈베리 파이)를 사용해야 하는지 궁금함. 기존의 Debian GNU/Linux를 실행하는 컴퓨터에서 USB 케이블을 통해 e-paper 디스플레이를 구동할 수 있는지 질문함.
     * AI 사용 이유 의문: 날씨 정보를 얻기 위해 AI를 사용하는 이유를 이해하기 어려움. 직접 호출할 수 있는 무료 날씨 API가 많이 있음.
     * AI 생성 이미지의 오류: ""Stocckholm""과 같은 오타와 산타 모니카 해변에 거대한 사람과 켄타우로스가 있는 등 AI 생성 이미지의 작은 오류가 오히려 재미를 더해줌.
"
"https://news.hada.io/topic?id=15280","OpenAI와 Apple 파트너십 발표","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         OpenAI와 Apple 파트너십 발표

애플, iOS, iPadOS, macOS에 ChatGPT 통합 발표

     * 애플과 OpenAI의 파트너십:
          + 애플이 iOS, iPadOS, macOS에 ChatGPT를 통합함.
          + 사용자는 별도의 도구를 전환하지 않고도 ChatGPT의 기능을 이용할 수 있음.
     * Siri와의 통합:
          + Siri가 ChatGPT의 지능을 활용할 수 있게 됨.
          + 사용자가 질문을 보내기 전에 확인 절차가 있으며, Siri가 직접 답변을 제공함.
     * 시스템 전반의 글쓰기 도구:
          + ChatGPT가 애플의 글쓰기 도구에 통합되어 콘텐츠 생성 지원.
          + 사용자는 다양한 스타일의 이미지를 생성하여 글에 추가할 수 있음.
     * 프라이버시 보호:
          + Siri와 글쓰기 도구에서 ChatGPT를 사용할 때 요청이 OpenAI에 저장되지 않음.
          + 사용자의 IP 주소가 가려짐.
          + 사용자는 ChatGPT 계정을 연결하여 데이터 선호도를 적용할 수 있음.
     * 출시 일정 및 접근성:
          + GPT-4o 기반의 ChatGPT 통합이 올해 말 iOS, iPadOS, macOS에 출시 예정.
          + 사용자는 계정 생성 없이 무료로 접근 가능하며, ChatGPT 구독자는 유료 기능을 이용할 수 있음.
     * 파트너십의 의의:
          + OpenAI와 애플이 안전성과 혁신에 대한 공통된 목표를 공유함.
          + 고급 AI를 모든 사람에게 접근 가능하게 만드는 것이 목표임.

        Hacker News 의견

     * Facebook/Twitter 통합과 유사함: Apple이 전용 LLM 서비스를 필요로 하지만, 핵심 기능은 여전히 자체적으로 처리하고 있음. OpenAI 사용 시 명시적 사용자 동의 필요. OpenAI와의 계약이 10년 지속될 것 같지는 않음.
     * ChatGPT 통합 발표: GPT-4o가 iOS, iPadOS, macOS에 통합될 예정. Nvidia의 Jensen Huang이 Apple과의 관계 개선으로 기쁠 것 같음.
     * Siri의 언어 이해력 개선 필요: Siri가 여전히 사전 프로그래밍된 문구에 의존하고 있음. GPT-4o는 더 복잡한 명령을 처리할 수 있음.
     * Siri의 기능 향상 기대: Siri가 더 복잡한 질문을 처리할 수 있기를 바람. 예를 들어, 주행 중에 주 경계까지의 거리와 주유 가능 여부를 묻는 것.
     * OpenAI의 성숙도에 대한 신뢰: OpenAI를 시스템 전반에 통합하는 것은 기술적 성숙도에 대한 신뢰를 보여줌.
     * OpenAI와의 계약이 이상함: Anthropic 같은 경쟁자가 있음에도 불구하고 OpenAI와 계약을 맺은 것이 이상하게 느껴짐.
     * OpenAI 의존도 낮음: 대부분의 유용한 통합은 기기 내 또는 Apple의 프라이빗 클라우드에서 이루어짐. OpenAI의 역할은 제한적임.
     * OpenAI에 대한 위협: Apple이 OpenAI를 대체할 가능성이 있음. Apple은 핵심 기능에 대해 파트너에 의존하는 것을 좋아하지 않음.
     * 프라이버시 보호: ChatGPT 사용 시 프라이버시 보호 기능이 내장되어 있음. 사용자 데이터는 OpenAI에 의해 저장되지 않음.
     * Microsoft와의 관계: Microsoft가 OpenAI의 49%를 소유하고 있음. Apple과의 계약에서 Microsoft가 데이터에 접근하지 못하도록 명시되어 있을 것임.
"
"https://news.hada.io/topic?id=15222","Bento 발표, Benthos의 오픈소스 포크 버전 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Bento 발표, Benthos의 오픈소스 포크 버전

     * Redpanda가 Benthos를 인수하고 중요한 통합 기능에 상용 라이선스를 적용하는 등 많은 변화를 주었음
     * Benthos는 가벼운 스트림 처리 프레임워크로, Kafka Connect의 대안으로 사용되었음
     * WarpStream은 Benthos를 Connect 계층으로 선택하고, 에이전트에 직접 내장하여 관리형 데이터 파이프라인을 제공했었음
     * Redpanda의 인수 후, Benthos의 이름이 변경되고 일부 중요한 통합 기능이 상용 라이선스로 전환되었음
     * WarpStream은 Benthos를 포크하여 Bento라는 이름으로 100% MIT 라이선스 오픈소스 프로젝트로 유지하기로 결정
     * Bento는 Benthos 커뮤니티의 새로운 터전이 되길 바라며, 다른 회사들과 협력하여 공동 거버넌스 모델을 만들고자 함
"
"https://news.hada.io/topic?id=15281","애플, iOS 앱 스토어 및 서드파티 앱 스토어에서 PC 에뮬레이터 차단","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                애플, iOS 앱 스토어 및 서드파티 앱 스토어에서 PC 에뮬레이터 차단

     * UTM은 iPhone과 iPad용 범용 PC 시스템 에뮬레이터임
     * 최근 규정 변경으로 인해 레트로 게임 콘솔 에뮬레이터가 허용되어, UTM 개발자들이 앱 스토어에 제출했으나 거절당함
     * Apple의 App Review에서는 ""PC는 콘솔이 아니다""라고 결정했음
     * 더 놀라운 점은 Apple이 EU의 타사 앱 스토어에서도 UTM 앱을 차단하고 있다는 사실임
     * App Review 가이드라인의 규칙 4.7은 ""미니 앱, 미니 게임, 스트리밍 게임, 챗봇, 플러그인 및 게임 에뮬레이터""를 다룸
     * UTM은 Apple이 규칙 4.7 위반으로 인해 앱 공증(Notarization)을 거부했다고 말함
          + 그러나 App Review 가이드라인 페이지에는 규칙 4.7이 Notarization Review 가이드라인에 포함되지 않는 것으로 표시됨
     * 따라서 UTM에 대한 Apple 검토자들이 해당 애플리케이션이 EU의 타사 앱 스토어에서 배포하기에 적합하지 않다고 주장한 것이 올바른지 여부가 불분명함
     * 그러나 현재로서는 UTM이 이 판결에 이의를 제기하지 않을 예정임
          + iOS에 배포되는 앱은 JIT 컴파일러를 사용할 수 없기 때문에(특별히 자격이 부여된 대체 브라우저 엔진 제외), JIT를 비활성화한 UTM SE 버전을 통해 실행되는 에뮬레이터의 기능과 성능이 크게 저하됨
          + UTM은 UTM SE 승인을 받는 것은 ""싸울 가치가 없다""고 말함
     * iOS용 UTM은 Xcode를 통해 수동으로 앱을 컴파일하고 설치하는 등의 기존 '그레이 마켓' 사이드로딩 방법을 사용하여 계속 사용할 수 있음
     * Mac용 UTM은 Mac App Store에서 이용 가능함

        Hacker News 의견

     * Apple의 제3자 앱 스토어 차단: 애플이 제3자 앱 스토어를 차단하면 DMA의 정신을 위반하는 것임. EU가 이를 단속하길 바람.
     * UTM의 하드웨어 가상화 지원: iOS에서 UTM이 하드웨어 가상화 지원을 받았던 순간이 있었음. 애플의 제약으로 인해 실망스러웠음. UTM 개발자들이 ""가치가 없다""고 말하는 이유를 이해할 수 있음.
     * 앱 스토어 차단 권한: 애플은 자신들의 앱 스토어에서 원하는 것을 차단할 권리가 있어야 하고, 사용자는 애플의 스토어를 통하지 않고도 원하는 소프트웨어를 실행할 수 있어야 함.
     * 소프트웨어 규제 필요성: 애플이 사용자가 기기에 설치하는 소프트웨어를 통제하는 것을 규제할 필요가 있음. 오랜 맥 사용자로서 애플의 이런 행동이 해결되지 않으면 다른 하드웨어 벤더를 찾을 것임.
     * 제3자 앱 스토어에 대한 애플의 거부권: 애플이 제3자 앱 스토어에 무엇이 들어갈지에 대해 거부권을 가지는 것이 이상함.
     * 애플의 악의적인 행동: 애플이 악의적으로 행동하는 것이 너무 명백해서 누구도 그들이 제3자 스토어에 어떤 앱이 게시될지 결정할 권리가 있다고 믿지 않음.
     * 애플 생태계 사용 거부: 하드웨어 제조업체가 내가 구매한 하드웨어에서 어떤 소프트웨어를 실행할 수 있는지 결정할 권리가 없다고 생각함. 그래서 애플 생태계를 사용하지 않겠음.
     * 에뮬레이터 차단: 애플이 게임 콘솔 에뮬레이터는 허용하면서 PC 에뮬레이터는 차단하는 것이 이상함. 이는 애플이 해적판 게임을 장려하는 것처럼 보임.
     * 안드로이드와 윈도우 태블릿의 기회: 애플의 제약으로 인해 안드로이드와 윈도우 태블릿에 시장 기회가 열림. 하지만 가격 대비 좋은 제품을 만들지 못함.
     * 개발자 이슈: 개인적으로 WWDC에서의 AI 관련 소식보다 이 문제가 더 중요함. 이는 진정한 ""개발자"" 이슈임.
"
"https://news.hada.io/topic?id=15225","Show GN: Smart Spam Filter: 똑똑한 AI 기반 스팸문자 필터 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Show GN: Smart Spam Filter: 똑똑한 AI 기반 스팸문자 필터 앱

   최근에 너무나 많은 사기성 광고 스팸문자가 와서 보다 똑똑하게 스팸 문자를 필터링 하는 앱을 만들어보았습니다.
     * 단순한 블랙리스트/화이트리스트 키워드 기반 필터

   이 기능은 사실 다른 앱들에도 많아서, 앱 중에 무한히 등록 가능한 앱이 있어서 그 앱을 한동안(1년+) 써오다가, 믹아도막아도 키워드 변형에 이리저리 회피해 문자함에 꽂히고야 마는 모습에 저 스스로도 너무 많은 피로감을 느껴서, 아 이건 사람이 할게 아니다, 이건 AI가 해결할 문제다..라고 생각해 제 전공인 로컬LM과 LLM의 조합, 그리고 iOS의 제약 내에서 가능한 최대한의 고성능 필터링 앱을 만들어보려 했습니다.

   앱은 단순합니다.
   받아서 AI 필터링 토글을 켜고,
   시스템 설정 - 메시지 - 알수없는 연락처 및 필터 내에서 Smart Spam Filter를 활성화 시켜 주기만 하면 AI 필터링이 활성화됩니다.

   현재 앱 출시 당일 약 600명이 받아 유틸리티섹션 앱스토어 랭크 #22까지 올라갔고, 현재(2일차)는 약 1000명이 받아 사용중인 상태입니다.

   모쪼록 함께 스팸에서 해방되면 좋겠습니다 :)

   안녕하세요. 반갑습니다. 해당 앱덕에 iPhone에서 불필요한 문자들을 안봐도 되서 너무 좋고, Mac에서는 필터링이 되지 않아서 오히려 볼 수 있어서 좋은 유저입니다.

   전문가가 필요에 의해서 만든 앱이여서 그런지, 정말 너무 좋아요!
   저희가 행사에서 유용한 앱들을 소개하는데 개발자님의 앱을 소개하려고 합니다.
   혹시 괜찮으시면, 개발자님의 quote를 적어서 소개하고 싶어서, 연락을 부탁드리고 싶습니다!
   확인하시고 관심 있으시면 https://instagram.com/healthy_stacy/… DM 부탁드려요 ~

   좋은 앱 만들어주셔서 너무 너무 감사합니다!!!!

   iOS에서 '메시지 리포트'로 자동 리포트되게 할 수 있나요? 이 기능은 어디로 가는지 궁금하네요.

   현재 그 기능은 구현해두지 않아서... 아무일도 일어나지 않을거에요 😂
   이후 업데이트에 추가할 예정입니다!

   온라인 AI 모드를 쓰면 실제로 온라인 LLM으로 체크하나요? 그렇다면 문자 내용이 서버로 다 가는건지요.

   문자 필터링 대상은 아래와 같은데요.
    1. 모르는 전화번호 (=연락처에 등록되지 않아야 합니다.)
    2. iMessage가 아닌 일반 SMS 혹은 MMS. (iMessage는 애플이 직접 스팸 관리를 하겠다고 합니다.)
    3. 모르는번호라도 내가 2번 이상 답장 안했어야 함 (= 2-3번 답장 보냈으면 아는번호라고 취급함)

   또한 로컬 blacklist rule이 가장 우선이고, 해당 블랙리스트로 필터링 될 경우는 온라인AI를 통하지 않고서 바로 문자가 스팸함으로 넘어갑니다!

   --> 즉, 매우 제한된 상황 한정으로 AI 판단을 위해 서버로 넘어갑니다.
   (로컬에서는 큰 언어모델(1B급 이상)들을 실행하지 못하는 한계때문입니다 ㅜㅜ)

   단, 해당 요청은 Apple iOS자체의 privacy보호 룰이 있어서 앱 자체에서 서버로 요청하는게 아니라, 앱에서 서버로 delegate 필요를 요청하고 iOS OS 자체에서 제 서버로 요청을 보내는 방식이 사용되고, 서버에서 판단한 결과를 다시 OS가 받아 해당 부분을 필터링하는 방식으로 이루어져있습니다.

   보다 자세한 내용은 아래 개발자문서를 참고해주세요 :)

   https://developer.apple.com/documentation/sms_and_call_reporting/…
"
"https://news.hada.io/topic?id=15185","SB-OSC: 센드버드 온라인 스키마 변경","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        SB-OSC: 센드버드 온라인 스키마 변경

     * MySQL 데이터베이스를 사용하는 서비스 개발 및 운영에서는 온라인 스키마 변경이 필수적이다.
     * 오프라인으로 스키마를 변경하면 서비스 중단이 불가피하므로 온라인 스키마 변경 방식이 중요하다.
     * 기존 툴(gh-ost, fb-osc, pt-osc)은 단일 프로세스로 작업 중단 시 재개가 불가능하다.
     * 대규모 테이블에서는 이러한 문제로 인해 작업이 길어질 수 있다.
     * SB-OSC는 멀티스레딩 기반의 새로운 온라인 스키마 변경 툴로, 작업 시간을 대폭 단축하고 중단된 작업을 재개할 수 있다.
"
"https://news.hada.io/topic?id=15203","최신 LLM에서 추론 붕괴를 보여주는 간단한 작업","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      최신 LLM에서 추론 붕괴를 보여주는 간단한 작업

앨리스 인 원더랜드: 최신 대형 언어 모델의 완전한 추론 붕괴를 보여주는 간단한 작업

  주요 내용 요약

     * 대형 언어 모델(LLMs): 다양한 작업과 조건에서 강력한 성능을 발휘하는 모델로, 사전 훈련 규모를 늘리면 성능이 향상된다는 스케일링 법칙을 따름.
     * 문제점: 최신 대형 언어 모델이 간단한 상식 문제에서 심각한 기능 및 추론 능력 붕괴를 보임. 인간이 쉽게 해결할 수 있는 문제에서도 잘못된 답변을 자신 있게 제시하며, 비논리적인 설명을 통해 잘못된 답변을 정당화함.
     * 실패한 개입: 다양한 유형의 프롬프트 강화나 다단계 재평가를 통해 모델이 올바른 답변을 찾도록 유도하려는 시도가 실패함.
     * 재평가 필요성: 현재 세대의 대형 언어 모델의 주장된 능력을 재평가하고, 이러한 기본적인 추론 결함을 적절히 감지할 수 있는 표준화된 벤치마크를 만드는 것이 필요함.

  GN⁺의 의견

     * 기술적 한계: 대형 언어 모델이 특정 상황에서 여전히 한계를 가지고 있음을 보여줌. 이는 모델의 신뢰성을 높이기 위해 추가적인 연구와 개선이 필요함을 시사함.
     * 표준화된 벤치마크: 모델의 성능을 정확하게 평가하기 위해 새로운 표준화된 벤치마크가 필요함. 이는 연구자들이 모델의 약점을 더 잘 이해하고 개선할 수 있도록 도움을 줄 수 있음.
     * 실제 응용: 이러한 결함은 대형 언어 모델을 실제 응용에 사용할 때 주의가 필요함을 의미함. 특히, 중요한 의사결정에 사용될 경우 신뢰성 문제가 발생할 수 있음.
     * 대체 기술: 다른 AI 기술이나 모델을 고려해볼 필요가 있음. 예를 들어, 강화 학습이나 하이브리드 모델 등이 대안이 될 수 있음.
     * 미래 연구 방향: 이 연구는 대형 언어 모델의 한계를 극복하기 위한 새로운 연구 방향을 제시함. 예를 들어, 인간의 상식과 추론 능력을 더 잘 모방할 수 있는 모델 개발이 필요함.

        Hacker News 의견

     * 논문을 읽으려는 사람들에게, 논문의 주요 부분은 첫 10페이지로 빠르게 읽을 수 있음.
     * 논문에서 다루는 예시는 이해하기 쉬운 편이지만, 도구들이 실제로 문제를 해결할 수 있을지 의문임.
     * AI 도구들이 실제로 사고하거나 추론하지 않지만, 많은 사람들이 이를 범용 AI로 간주하는 경향이 있음.
     * 논문이 AI의 과대광고에 영향을 미칠 가능성은 낮아 보임.
     * ""Alice에게 60명의 형제와 212명의 자매가 있다. Alice의 형제는 몇 명의 자매가 있는가?""라는 질문에 GPT-4가 올바른 답을 제공함.
     * 실험에서 모델이 '생각하는 소리'를 내지 않도록 유도했을 때, GPT-4가 일관되게 틀린 답을 제공함.
     * 더 복잡한 예제에서는 GPT-4가 실패하는 경향이 있음.
     * Gemini 모델은 추가적인 유도 없이 문제를 해결했지만, 숫자를 주었을 때 혼란스러워함.
     * Alice가 수백 명의 형제를 가질 수 없다는 가정 하에 질문이 부당하다고 생각함.
     * 주요 LLM의 평가 데이터셋이 훈련 데이터에 포함되어 있어 신뢰성 평가에 무용지물임.
     * 새로운 테스트를 만들어 LLM을 평가하는 것이 더 나은 방법임.
     * 일반 대중이 제한된 시간 내에 이러한 퍼즐을 해결할 확률이 낮음.
     * AIW+ 문제는 일반적인 AIW 문제보다 해결하기 어려움.
     * 논문 저자들이 수백 개의 가족 트리 문제를 만들었기 때문에 답이 명확해 보일 수 있음.
     * 논문에서 제시한 문제는 매우 기본적인 수수께끼의 변형임.
     * 논문이 놀라운 부정적인 결과를 선택적으로 다룬 것 같음.
     * LLM이 관계적 추론에서 여전히 약함.
     * LLM은 긴 시간 동안 집중력을 유지하는 능력이 부족함.
     * LLM이 AGI를 구현할 수 있다는 생각은 희망적 사고에 불과함.
     * LLM이 계획과 추론에 매우 약하다는 것을 보여주는 좋은 강연이 있음.
"
"https://news.hada.io/topic?id=15266","Dragonfly - 멀티 해상도 줌이 가능한 대규모 비젼-언어 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Dragonfly - 멀티 해상도 줌이 가능한 대규모 비젼-언어 모델

     * 고해상도 이미지를 여러 작은 영역으로 나누어 분석하여 세부적인 이해와 추론이 가능한 vision-language 아키텍처 모델
     * Llama-3-8b-Dragonfly-v1 (일반 도메인), Llama-3-8b-Dragonfly-Med-v1 (의료 도메인) 등 2개의 오픈소스 모델을 공개
     * Llama-3-8b-Dragonfly-v1은 550만개의 이미지-지시문 쌍으로 학습되었고, Llama-3-8b-Dragonfly-Med-v1은 추가로 140만개의 의료 이미지-지시문으로 파인튜닝 됨
     * Dragonfly는 시각적 상식 추론, 이미지 캡셔닝 등의 벤치마크에서 우수한 성능을 보임
     * Dragonfly-Med는 의료 이미지 이해 분야에서 Med-Gemini 등 기존 모델들을 능가함

  Dragonfly 아키텍처

     * 다중 해상도 시각 인코딩 (Multi-resolution Visual Encoding):
          + 저/중/고 해상도로 이미지를 처리함
          + 각 이미지를 해상도에 따라 여러 개의 서브 이미지로 나누고, 이를 시각 토큰으로 인코딩함
          + 인코딩된 토큰들을 language space로 projection하여 concatenate한 시퀀스를 LLM에 입력으로 넣음
          + 이를 통해 대용량 이미지를 효율적으로 처리하고, 시각 데이터 처리의 granularity를 높일 수 있음
     * Zoom-in Patch Selection:
          + 고해상도 이미지에서 중요한 시각적 디테일에 집중하기 위한 selective approach
          + 중요도가 높은 고해상도 서브 이미지만 선별해서 사용하는 novel한 zoom-in patch selection 전략 사용
          + 중/고해상도 서브 이미지의 summary embedding을 비교하여 가장 연관성 높은 패치만 선택함
          + 이를 통해 중복을 제거하고 핵심 콘텐츠 영역에 집중함으로써 전반적인 모델 효율성과 세부 영역 이해도를 높임
     * 이 두 가지 전략을 통해 이미지 영역의 세부 디테일에 더 집중하고 상식적 추론 능력을 향상시킴.
     * 세부 정보 포착에 최적화되었음에도 VQA, 이미지 캡셔닝 등 일반적인 이미지 이해 벤치마크에서 좋은 제로샷 성능을 보임.

  Dragonfly 모델 성능 평가

     * AI2D, ScienceQA, MMMU, MMVet, POPE 등 5개 vision-language 벤치마크에서 평가됨
          + AI2D, ScienceQA: 과학 도메인에서의 시각적 상식 추론 평가
          + MMMU, MMVet: vision-language 능력 종합 평가
          + POPE: 객체 단위 hallucination 평가
     * 다른 유명 vision-language 모델들과 견줄만한 우수한 성능을 보임

  Dragonfly-Med 성능

     * Stanford Medicine과 협업하여 Dragonfly를 140만개 의료 이미지-지시문으로 추가 학습시킨 버전
     * VQA-RAD, SLAKE, Path-VQA 등 시각적 질의응답 벤치마크에서 Med-Gemini 등 기존 모델 성능을 뛰어넘음
     * IU X-Ray, Peir Gross, ROCO, MIMIC CXR 등 의료 이미지 캡셔닝 벤치마크에서도 SOTA에 준하는 성능을 보임

  향후 계획

     * LLaMA3-8B-Instruct를 백본으로 새로운 아키텍처와 시각 인코딩 전략 등을 탐구할 예정
     * 더 다양한 과학 분야로 적용 범위를 넓혀서 오픈소스 멀티모달 연구에 기여하고자 함
"
"https://news.hada.io/topic?id=15220","Fusio - 오픈소스 API 관리 플랫폼 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Fusio - 오픈소스 API 관리 플랫폼

     * API 관리 : 강력한 백엔드 앱을 제공하여 API 제어 및 모니터링 가능
     * 개발자가 API 사용을 위해 등록할 수 있는 ""개발자 포털"" 앱 제공
     * API 빌더 : 코딩 없이 다양한 소스로부터 완전한 API를 구축하기 위한 여러 제너레이터 제공
     * 수익화 지원 : 특정 경로에 대해 요금을 부과하는 간단한 결제 시스템 제공
     * SDK 생성 : 정의된 스키마를 기반으로 API에 대한 클라이언트 SDK를 자동으로 생성 가능
     * Rate Limit : 사용자 또는 앱을 기반으로 요청을 제한하는 방법 제공
     * 스키마 생성 : OAI 및 TypeAPI 사양을 자동으로 생성하는 엔드포인트 제공
     * 웹훅 : API에 대한 발행/구독 패턴을 구축하는 데 도움이 되는 웹훅 시스템 포함
     * OAuth2 인증 : 앱 개발자는 비공개 API 엔드포인트에 액세스하기 위해 액세스 토큰을 얻을 수 있음

최근 5.0 릴리즈의 변경사항

     * 멀티 테넌시
          + 데이터베이스 수준에서 멀티 테넌시 지원
          + 하나의 대형 서버 또는 클러스터에서 여러 Fusio 인스턴스를 효율적으로 실행하는 데 도움이 됨
          + APP_TENANT_ID 환경 변수 설정만으로 테넌트 구성 가능
          + 테넌트 설정 또는 제거를 위한 API 엔드포인트도 제공
     * 워커 재설계
          + 워커 시스템 재설계
          + 다양한 프로그래밍 언어로 백엔드 로직을 작성할 수 있는 워커 시스템
          + 이전에는 Thrift RPC 시스템을 사용하여 Fusio와 워커 간 통신 관리
          + 간단한 REST API로 변경하여 서버리스 플랫폼과 같은 다양한 환경에서 워커 실행 가능
     * 개인 액세스 토큰
          + 사용자 패널에서 개인 액세스 토큰 생성 가능
          + 사용자는 비공개 엔드포인트에 액세스하기 위한 액세스 토큰을 쉽게 얻을 수 있음
          + 토큰에 대한 특정 범위와 토큰 유효 기간 선택 가능
     * 특정 작업 및 연결 제외 옵션 추가
          + 구성 파일에 fusio_action_exclude와 fusio_connection_exclude 옵션 추가
          + 특정 연결이나 작업을 인스턴스에서 제외하는 데 사용 가능
          + CLI나 PHP-Sandbox 작업과 같은 ""안전하지 않은"" 작업은 보안 문제가 될 수 있음
          + 새로운 구성을 통해 이러한 작업 제외 가능
     * 계정 앱 추가
          + 모든 개발자 계정 세부 정보를 관리하기 위해 기존 웹 앱에 통합할 수 있는 새로운 전용 계정 앱 추가
          + 이 앱은 개발자 및 백엔드 앱에도 포함되어 있음
     * 작업에서 메타데이터 액세스
          + 작업 내에서 작업의 메타데이터에 액세스할 수 있음
          + 백엔드 API를 통해 작업을 만들 때 이 메타데이터 설정 가능
     * 백업 가져오기/내보내기
          + 백엔드의 시스템/백엔드에서 전체 구성을 가져오고 내보낼 수 있는 새로운 패널
          + 테스트에서 프로덕션 환경으로 구성을 이동하는 것도 더 쉬워짐
          + 데이터베이스 구성만 내보내며, src 폴더의 사용자 정의 클래스는 내보내지 않고 별도로 동기화해야 함
     * 모든 생성, 업데이트 및 삭제 작업이 이제 영향을 받는 ID를 반환
          + 백엔드 API는 이제 모든 생성, 업데이트 및 삭제 작업에 대해 영향을 받는 기본 키를 반환함
          + 생성한 엔터티로 직접 추가 작업을 수행하려는 경우 유용할 수 있음
     * 작업 추가 및 개선
          + Fusio\Adapter\Http\Action\HttpRaw
               o 완전히 사용자 정의된 HTTP 요청을 보내기 위한 새로운 작업
               o XML 페이로드를 보내 레거시 웹 서비스를 호출할 수 있음
          + Fusio\Adapter\Util\Action\UtilCondition
               o 논리 표현식에 따라 다른 작업을 호출하기 위한 새로운 작업
               o 조건에 따라 다른 작업을 호출할 수 있음
          + 이 외에도 여러 다른 작업들이 개선됨
     * OAuth2 연결 처리 개선
          + OAuth2 인증이 필요한 연결을 더 쉽게 추가할 수 있도록 OAuth2 연결 처리 개선
          + 향후 외부 서비스에 대한 새로운 연결을 추가하여 사용자가 이러한 외부 서비스를 Fusio에 쉽게 통합할 수 있도록 할 계획
     * 미래 계획
          + SDK-Fabric이라는 새로운 프로젝트를 백그라운드에서 작업 중
          + 이 프로젝트는 기본적으로 다양한 제공자를 위한 글로벌 SDK 인프라를 구축하려고 시도함
          + 이러한 SDK를 Fusio에 통합하여 작업에서 해당 서비스를 쉽게 사용할 수 있도록 할 계획
          + Zapier와 유사하게 연결을 구성한 다음 특정 작업을 실행하는 작업을 만들 수 있음
          + SDK-Fabric 프로젝트는 현재 일부 제공자만 포함하고 있지만, 향후 커뮤니티의 도움을 받아 이를 확장할 수 있기를 희망함
          + 새로운 테넌트 및 워커 시스템을 사용하여 Fusio 클라우드 플랫폼을 재부팅할 계획
          + 모든 사용자가 클라우드에서 새로운 Fusio 인스턴스를 쉽게 얻을 수 있는 플랫폼 구축을 목표로 함
"
"https://news.hada.io/topic?id=15188","푸리에 급수 애니메이션 소개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            푸리에 급수 애니메이션 소개

원에서 에피사이클로 (1부) - 푸리에 급수에 대한 애니메이션 소개

  목차

     * 원
     * 숫자 π
     * 라디안
     * 사인과 코사인
     * 코사인이 사인을 이끎
     * 코사인과 사인의 대칭성
     * 복소수와 단위 원
     * i와의 곱셈은 π/2 회전
     * 오일러의 항등식
     * 오일러의 공식, e, π, i의 연결
     * 사인과 코사인의 지수형태
     * 사인파
     * 사인파의 유연성
     * 복소 사인파
     * 사인파의 상쇄
     * 사인파의 합이 복잡성을 만듦
     * 재미로 사인파 더하기
     * 사인파 테트리스
     * 사인파와 사각파
     * 에피사이클 - 첫 만남
     * 에피사이클 - 직관적 이해
     * 에피사이클 - 꽃
     * 푸리에 급수
     * 푸리에 급수의 지수형태
     * 예제: 박스 함수의 푸리에 급수
     * 예제: 삼각파의 푸리에 급수
     * 예제: 톱니파의 푸리에 급수
     * 푸리에 급수 기계

  원

     * 원은 중심 P(a, b)와 반지름 r을 가진 기하학적 도형임.
     * 단위 원은 중심이 (0, 0)이고 반지름이 1인 원임.
     * 원은 대칭의 정점임.

  숫자 π

     * π는 원의 둘레와 지름의 비율임.
     * π는 약 3.14이며, 원주와 면적 계산에 사용됨.
     * π는 무리수이자 초월수임.

  라디안

     * 라디안은 각도를 측정하는 실제 단위임.
     * 각도를 라디안으로 변환하려면 각도를 π로 곱하고 180으로 나눔.

  사인과 코사인

     * 사인과 코사인은 단위 원에서 정의됨.
     * 사인은 y좌표를, 코사인은 x좌표를 나타냄.
     * 두 함수는 주기 함수로 주기는 2π임.

  코사인이 사인을 이끎

     * 코사인은 사인보다 π/2만큼 앞섬.
     * sin(x + π/2) = cos(x)

  코사인과 사인의 대칭성

     * 코사인은 짝수 함수로 cos(x) = cos(-x)임.
     * 사인은 홀수 함수로 sin(-x) = -sin(x)임.

  복소수와 단위 원

     * 복소 평면에서 원의 점들은 z = cos(θ) + i*sin(θ)로 정의됨.

  i와의 곱셈은 π/2 회전

     * 복소수를 i와 곱하면 π/2만큼 반시계 방향으로 회전함.

  오일러의 항등식

     * 자연 지수 함수는 e^x로 표시되며, e는 약 2.71828임.
     * e와 원 사이에는 강한 연결이 있음.
     * e^(ix) = cos(x) + i*sin(x)

  오일러의 공식, e, π, i의 연결

     * 오일러의 공식: e^(ix) = cos(x) + i*sin(x)
     * x = π일 때, e^(iπ) + 1 = 0

  사인과 코사인의 지수형태

     * cos(x) = (e^(ix) + e^(-ix)) / 2
     * sin(x) = (e^(ix) - e^(-ix)) / (2i)

  사인파

     * 사인파는 A*sin(2πft + φ)로 정의됨.
     * A는 진폭, f는 주파수, ω는 각주파수, φ는 위상 오프셋임.

  사인파의 유연성

     * 사인파는 다양한 진폭, 주파수, 위상으로 조정 가능함.

  복소 사인파

     * 복소 사인파는 두 사인파(코사인과 사인)의 행동을 포착함.
     * 실수 부분은 코사인, 허수 부분은 사인으로 행동함.

  사인파의 상쇄

     * 같은 진폭을 가지지만 반대 주파수를 가진 두 사인파는 서로 상쇄됨.

  사인파의 합이 복잡성을 만듦

     * 두 사인파를 더하면 복잡한 패턴이 생성됨.

  재미로 사인파 더하기

     * 여러 사인파를 더하면 더 복잡한 패턴이 생성됨.

  사인파 테트리스

     * 사인파를 이용한 테트리스 게임 가능함.

  사인파와 사각파

     * 적절한 사인파를 선택하면 예측 가능한 패턴 생성 가능함.
     * 여러 사인파를 합하면 사각파를 만들 수 있음.

  에피사이클 - 첫 만남

     * 사인파는 회전하는 원에 대응됨.
     * 여러 사인파를 합하면 복잡한 도형을 그릴 수 있음.

  에피사이클 - 직관적 이해

     * 각 에피사이클은 특정 사인파에 대응됨.
     * 사인파를 합하면 벡터 덧셈으로 축소됨.

  에피사이클 - 꽃

     * 적절한 사인파를 선택하면 원하는 모양을 그릴 수 있음.

  푸리에 급수

     * 푸리에 급수는 주기 함수의 삼각 함수 합으로 확장하는 수학적 과정임.
     * 함수 f(x)를 삼각 함수의 합으로 표현함.

  푸리에 급수의 지수형태

     * 오일러의 공식을 사용하여 푸리에 급수를 복소 사인파의 합으로 표현 가능함.

  예제: 박스 함수의 푸리에 급수

     * 사각파를 사인파의 합으로 근사화할 수 있음.
     * y(x) = (4/π) * Σ (sin((2k-1)ωx) / (2k-1))

GN⁺의 의견

     * 푸리에 급수는 주기적인 신호를 분석하고 합성하는 데 매우 유용함.
     * 사인파와 코사인의 기본 개념을 이해하면 복잡한 신호 처리에 큰 도움이 됨.
     * 복소수와 오일러의 공식은 신호 분석에서 중요한 역할을 함.
     * 푸리에 급수는 오디오 신호 처리, 이미지 압축 등 다양한 응용 분야에서 사용됨.
     * 이 기사는 푸리에 급수의 기본 개념을 쉽게 설명하여 초급 엔지니어에게 유익함.

        Hacker News 의견

     * Fourier 변환을 이해하는 데 오랜 시간이 걸렸음. **Discrete Fourier Transform (DFT)**를 이해한 후, 역 FFT, Plancherel 정리, Parseval 정리가 자연스럽게 이해되었음. 선형대수학을 이해한 후, 연속적인 Fourier 변환으로 확장하는 것이 쉬웠음. 시각적 자료보다 수식을 보는 것이 더 쉬웠음.
     * 소스 코드 링크가 잘못되었음. 실제 링크는 여기임. Processing을 사용하여 애니메이션을 구현한 것 같음.
     * Fourier 변환에 대한 설명은 Feynman 강의에서도 찾을 수 있음. 링크
     * FFT를 이해하기 위해 조지아텍의 Introduction to Graduate Algorithms 강의를 듣고 Python으로 모든 것을 구현했음. 정말 좋은 강의였음. 링크
     * Fourier 변환에 대해 어느 정도 이해하고 있으며, 많은 사람들이 이를 다루고 있음. Laplace 변환도 다루어주면 좋겠음. 전자 회로 분석에 사용했지만 지금은 잊어버렸음. 링크
     * 에피사이클 애니메이션이 Fourier 시리즈의 복잡한 표현을 이해하는 데 큰 도움이 되었음. 이 게시물은 그 페이지를 훨씬 능가함. 앞으로 사람들과 공유할 예정임.
     * 이 튜토리얼은 교과서와 함께 사용하기에 훌륭함. 애니메이션과 인터랙티브 애니메이션이 마음에 들었음. 다만, 교정이 필요함.
     * 훌륭한 예제와 멋진 웹사이트에 감사함. 이 사이트는 쉽게 다룰 수 있지만, 대부분의 정적 뉴스 사이트는 브라우저를 자주 크래시시킴.
     * 신호 처리에 대한 멋진 입문서가 있음. 시각화를 좋아하는 사람들에게 추천함. 링크
     * 이 사람의 다른 멋진 작업도 있음. 링크
"
"https://news.hada.io/topic?id=15208","OpenAI의 새로운 연구 성과: GPT-4의 내부 표현을 해석 가능한 패턴으로 분해","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            OpenAI의 새로운 연구 성과: GPT-4의 내부 표현을 해석 가능한 패턴으로 분해

   • OpenAI는 GPT-4의 내부 표현을 1600만 개의 해석 가능한 패턴으로 분해하는 새로운 확장 가능한 방법을 도입하여 언어 모델 내의 신경 활동을 이해하려고 합니다.

   • 신경망은 직접 설계되지 않았고 식별 가능한 부분이 부족하기 때문에 해석하는 데 어려움이 있어 AI 안전성에 대한 추론이 어렵습니다.

   • 희소 오토인코더를 사용하여 신경망에서 관련 ""특징""을 식별하고, 인간이 이해하기 쉬운 개념을 나타냅니다.

   • 연구팀은 첨단 방법론을 개발하여 최첨단 AI 모델에서 수천만 개의 특징으로 희소 오토인코더를 확장하여 부드럽고 예측 가능한 확장을 시연했습니다.

   • 특정 특징에 대한 문서 활성화를 보여주는 시각화를 통해 특징의 해석 가능성을 보여줍니다.

   • 해석 가능한 특징의 예로는 인간의 결함과 관련된 구문, 가격 상승 경향, ""X와 Y"" 형태의 구문, 머신 러닝 훈련 로그, 수사적/격양된 질문, 대수적 환, 아데노신 및 도파민 수용체가 있습니다.

   • 해석 가능성이 모델의 신뢰성과 조정 가능성을 향상시킬 잠재력에 대해 연구팀은 흥분하고 있지만, 많은 발견된 특징을 해석하는 데 어려움이 있고 더 나은 검증 방법이 필요하다는 한계도 인식하고 있습니다.

   https://github.com/openai/sparse_autoencoder

   https://openaipublic.blob.core.windows.net/sparse-autoencoder/…
"
"https://news.hada.io/topic?id=15187","openSUSE.Asia Summit 2024가 일본 도쿄에서 열립니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                openSUSE.Asia Summit 2024가 일본 도쿄에서 열립니다.

   openSUSE.Asia Summit 2024가 일본 도쿄에서 2024년 11월 2일(토)-3일(일) 이틀간 열릴 예정입니다.
   행사 장소는 아자부다이힐즈(Azabudai Hills, 麻布台ヒルズ)에 위치한 일본 SHIFT Inc. 사무실입니다.

   openSUSE.Asia Summit은 openSUSE및 FLOSS 매니아 계층의 사용자와 기여자를 위한 연례 컨퍼런스입니다.
   이전 행사에서는 인도네시아, 중국, 타이완, 일본, 한국, 인도등 아시아 사용자 및 기여자들이 참여하였습니다

   참고로, 컨퍼런스 열리는 주간에 Linux Foundation에서 일본 도쿄에서 여는 ""Open Source Summit Japan""과 ""Open Compliance Summit""이 개최됩니다.

   이번 컨퍼런스에서는 Cross-Distro Track이 있으며, 일본의 Cross Distro Developers Camp(XDDC)와 공동주최할 예정입니다. XDDC는 openSUSE, Debian 및 Ubuntu를 포함하는 FLOSS OS 배포판 관련 넓은 범위를 가진 일본의 개발자 커뮤니티이며, 특히 일본어와 관련한 일반적인 문제를 해결하기 위해 협력한다고 하군요.
   올해 일본 openSUSE커뮤니티에서는 다른 커뮤니티의 연사 및 참가자를 초대하는 것을 고려하고 있으며 행사를 흥미롭게 만드려고 합니다. 여기서 openSUSE와 해당 커뮤니티가 어떤지 알릴 수 있는 좋은 기회가 될것입니다.

   연사자 모집은 6월 초에 시작할 예정입니다. 며칠 후, news.opensuse.org 의 연사 모집 글이 게시될 예정입니다.
"
"https://news.hada.io/topic?id=15223","성 미카엘 검: 대성당들이 정말 일직선에 있는가?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      성 미카엘 검: 대성당들이 정말 일직선에 있는가?

유명한 7개의 성당이 직선상에 있는지에 대한 수치적 조사

  소개

     * 위키피디아에 따르면, 성 미카엘과 관련된 7개의 유명한 성당이 직선상에 위치해 있음.
     * 이를 검증하기 위해 데이터셋을 수집하고 지오데식 선을 계산하여 성당들이 직선상에 있는지 확인함.

  데이터셋 수집

     * 성당의 위치 데이터를 수집하여 지오팬더스 데이터프레임으로 정리함.
     * 성당의 이름, 경도, 위도, 지오메트리 정보를 포함함.

landmarks_michael = {
  1: [""Skellig Michael"", -10.538483, 51.772035, shape(geometry_skellig)],
  2: [""St Michael's Mount"", -5.477813, 50.116531, shape(geometry_st_michael_mount)],
  3: [""Mont Saint-Michel"", -1.511447, 48.636038, shape(geometry_mont_st_michel)],
  4: [""Sacra di San Michele"", 7.342842, 45.098029, shape(geometry_san_michele_sacra)],
  5: [""San Michele Arcangelo"", 15.954767, 41.707770, shape(geometry_santuario_san_michele)],
  6: [""Taxiarchi Michail"", 27.846123, 36.548389, shape(geometry_taxiarchi_michail)],
  7: [""Stella Maris"", 34.969960, 32.827297, shape(geometry_stella_maris_monastery)],
}

  첫 번째와 마지막 성당 사이의 지오데식 선 계산

     * 첫 번째와 마지막 성당 사이의 지오데식 선을 계산하고, 나머지 성당들과의 거리를 측정함.
     * 지오데식 선은 구면 모델을 사용하여 계산됨.

def haversine_distance(lon_1, lat_1, lon_2, lat_2):
  # 두 점 사이의 구면 거리 계산
  pass

def midpoint(p1, p2):
  # 두 점 사이의 중간점 계산
  pass

def midpoints_rec(p1, p2, bailout):
  # 재귀적으로 중간점을 계산하여 지오데식 선을 그림
  pass

  성당과 지오데식 선 사이의 거리 계산

     * 각 성당과 지오데식 선 사이의 거리를 계산하여 성당들이 직선상에 있는지 확인함.
     * 결과적으로 성당들이 지오데식 선에 정확히 일치하지 않음을 확인함.

def distance_point_line(point, line):
  # 점과 선 사이의 거리 계산
  pass

gdf_cathedrals[""dist_to_geod""] = gdf_cathedrals.apply(lambda row: distance_point_line(Point(row[""longitude""], row[""latitude""]), line), axis=1)

  Mercator 투영에서 성당들이 정렬되어 있는지 확인

     * Mercator 투영에서는 성당들이 직선상에 있는 것처럼 보일 수 있음.
     * 그러나 실제 구면 지오메트리에서는 그렇지 않음.

GN⁺의 의견

     * 이 연구는 지리적 데이터 과학과 지오데식 계산의 실제 적용을 보여줌.
     * 성당들이 직선상에 있는지 확인하는 과정에서 다양한 수학적, 프로그래밍적 기법이 사용됨.
     * Mercator 투영과 실제 구면 지오메트리의 차이를 이해하는 데 도움이 됨.
     * 지리적 데이터 분석에 관심 있는 소프트웨어 엔지니어에게 유익한 사례가 될 수 있음.
     * 비슷한 연구를 진행할 때 데이터의 정확성과 모델의 한계를 고려하는 것이 중요함.

        Hacker News 의견

     * 첫 번째 의견: 목록에 성당이 아닌 수도원과 성지들이 포함되어 있음. 성 미카엘 이름을 가진 7개의 성당이 직선으로 배열된 것은 우연이 아님. 이는 전 세계에 7개의 구글 단지가 직선으로 배열된 것과 같음. 그러나 유명한 성인의 이름을 가진 7개의 종교 사이트가 직선으로 배열된 것은 우연일 가능성이 큼.
     * 두 번째 의견: ""라인""의 역사에 더 흥미를 느낌. 중세 시대의 아이디어인지 현대의 아이디어인지 궁금함. 위키피디아는 도움이 되지 않음. 이 라인에 대해 처음으로 쓴 사람이 누구인지, 이 7개의 사이트를 선택한 사람이 누구인지 궁금함. 가장 초기의 출처는 1969년으로, 이 특정 라인에 대한 것이 아님.
     * 세 번째 의견: 유럽에 성당이 많기 때문에 7개의 성당이 우연이 아니라는 주장은 지지되지 않음.
     * 네 번째 의견: 어렸을 때 고대 유적지의 정렬을 찾는 것에 매료되었음. 그러나 지도의 규모(1:25,000)를 고려할 때, 열심히 찾으면 의미 없는 정렬을 많이 찾을 수 있다는 것을 깨달음.
     * 다섯 번째 의견: 스켈리그 마이클은 성당이 아님. 섬에 있는 돌로 된 벌집 모양의 오두막들임. 새로운 스타워즈 영화의 촬영지로 유명해졌음. 유네스코 세계유산이며 관광 명소임.
     * 여섯 번째 의견: 유럽에 많은 교회가 있기 때문에 이는 '다른 곳을 찾아보는 효과'일 가능성이 큼. Look-elsewhere effect
     * 일곱 번째 의견: 7개의 성당이 우연이 아니라는 주장은 매우 억지스러움. 간단한 답변: 선택 편향. 건축가들이 지구가 둥글다는 것을 알았는지에 대한 질문은 구글 검색으로 쉽게 답을 찾을 수 있음.
     * 여덟 번째 의견: Matt Parker의 유튜브 채널 ""Stand up Maths""에서 2010년에 비슷한 주제를 다룬 강연이 있었음. 충분한 데이터 포인트가 주어지면 다양한 패턴을 찾을 수 있음. 강연 영상
     * 아홉 번째 의견: 이 사이트들이 지어질 당시 메르카토르 도법이 있었는지 궁금함.
     * 열 번째 의견: 새로운 Dan Brown 소설이 나올 것 같음. 이 국가들이 전쟁 중이었기 때문에 이런 프로젝트를 시작하는 데 동의하는 것은 불가능했을 것 같음. 그럼에도 불구하고 매우 흥미로움.
"
"https://news.hada.io/topic?id=15191","셔의 도덕 경제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                셔의 도덕 경제

샤이어의 도덕 경제

  샤이어의 정부 구조

     * 샤이어의 정부: 샤이어에는 거의 정부가 없었음. 대부분의 가족이 자치적으로 생활을 관리했음.
     * 왕의 허가: 샤이어는 원래 아르노르 왕국의 왕 아르겔레브 II세가 마르코와 블랑코 형제에게 준 땅이었음. 왕국이 멸망한 후, 호빗들은 '테인'이라는 세습 족장을 세워 법적 연속성을 유지했음.
     * 미첼 델빙 시장: 7년마다 선출되며, 주로 연회 주재와 우편 서비스, 경찰 역할을 담당했음.

  샤이어의 경제 구조

     * 세금의 부재: 샤이어에는 세금이 거의 없었음. 대신 다리와 도로 통행료, 관세, 엘리트 가문의 기부로 정부가 운영되었음.
     * 경제 활동: 호빗들은 주로 농업에 종사했으며, 여가를 즐기는 모습이 많았음. 그러나 샤이어에는 제분소, 장인, 여관 등이 있어 잘 발달된 경제 구조를 가졌음.

  사회 계층과 경제

     * 지주 계급: 빌보, 프로도, 메리, 피핀은 지주 계급에 속했으며, 이들은 토지 소유를 통해 부를 축적했음.
     * 소작농과 자영농: 대부분의 호빗들은 지주에게 소작료를 내는 소작농이거나, 독립적으로 농사를 짓는 자영농이었음.
     * 도시 부르주아: 소규모 도시와 마을에서 부르주아 계층이 형성되었으나, 외국 무역이나 산업화가 없어 크게 성장하지 못했음.

  가족과 클랜 중심의 사회

     * 가족과 클랜: 샤이어는 가족과 클랜 중심으로 조직된 사회였음. 권력은 공식적인 직위보다는 관계와 네트워크에서 나왔음.
     * 미첼 델빙 시장의 역할: 시장은 연회를 주재하며, 가족 간의 관계를 강화하는 역할을 했음.

  후원-고객 관계

     * 후원-고객 관계: 샤이어의 정치 구조는 후원-고객 관계로 설명될 수 있음. 강력한 후원자와 그들에게 의존하는 고객들 간의 상호 의무가 존재했음.
     * 샘과 프로도의 관계: 샘과 그의 아버지 햄퍼스트는 빌보와 프로도의 고용인이었지만, 그 관계는 단순한 고용 관계를 넘어선 것이었음.

  변화와 현대화의 영향

     * 로소 색스빌-배긴스: 로소는 사루만과의 접촉을 통해 전통적인 호빗 시스템 외부에서 자본을 얻어 경제적 통제를 강화했음.
     * 변화의 불가피성: 전쟁 후 샤이어는 예전으로 돌아갈 수 없었음. 샘와이즈 갬지는 샤이어의 새로운 지도자로 떠오름.

GN⁺의 의견

    1. 샤이어의 경제 구조: 샤이어의 경제 구조는 중세 유럽의 봉건제와 유사함. 이는 현대 사회와 비교할 때 이해하기 쉬운 예시가 될 수 있음.
    2. 후원-고객 관계: 후원-고객 관계는 현대 사회에서도 여전히 존재하는 개념임. 이는 네트워킹과 사회적 자본의 중요성을 강조함.
    3. 변화의 불가피성: 샤이어의 변화는 현대 사회에서도 볼 수 있는 전통과 현대화의 충돌을 잘 보여줌. 이는 사회 변화의 복잡성을 이해하는 데 도움이 됨.
    4. 문학적 분석의 중요성: 문학 작품을 통해 사회 구조와 경제 시스템을 분석하는 것은 흥미롭고 유익한 접근법임. 이는 독자들에게 새로운 시각을 제공함.
    5. 기술 도입 시 고려 사항: 새로운 기술이나 시스템을 도입할 때는 기존의 사회 구조와의 충돌을 고려해야 함. 이는 변화의 긍정적, 부정적 영향을 모두 평가하는 데 중요함.

        Hacker News 의견

     * Tolkien은 그의 세계의 현실성을 매우 중요하게 여겼음. 중세 사회를 연구한 그의 배경 덕분에, 그의 작품 속 사회는 매우 현실적으로 기능함.
     * 많은 독자들이 이를 놓치는 이유는 두 가지임. 첫째, 톨킨의 세계 구축은 암시적임. 둘째, 현대 사회와 너무 다른 중세 사회의 특성 때문에 독자들이 이를 비현실적이라고 여김.
     * 더 깊은 이해를 원한다면, 고대 군사 역사가인 Bret Devereaux의 블로그를 추천함.
     * 이 기사는 흥미롭지만, ""독자가 직관적으로 이해할 것""이라는 주장은 과장된 것 같음. 톨킨의 세계는 현실적이지 않아도 되는 판타지임.
     * 미국인으로서, 중세 사회의 계급 구조를 이해하기 위해 여러 번 읽어야 했음. 이 구조는 많은 판타지 소설과 게임의 배경임.
     * 흥미로운 점은, 이러한 세계가 실제로는 기회가 적지만, 상상 속에서는 모험과 가능성으로 가득 차 있다는 것임.
     * 호빗에서 Took 가문은 모험적이고 덜 평판이 좋은 가문으로 묘사되지만, 실제로는 더 강력하고 부유한 가문일 수 있음.
     * Tolkien의 Sam Gamgee는 1차 세계대전에서 만난 영국 병사들의 반영임. 이 경험은 상류층의 사고방식을 변화시켰음.
     * Tolkien의 작품은 보수적인 이야기임. 하지만 과거로 돌아가려는 반동적인 것은 아님.
     * 중세 농업은 저수익 고노동이었음. 하지만 호빗들은 장수하고 기술이 뛰어나서 이를 유지할 수 있었을 것임.
     * Shire의 경제는 분배주의적일 수 있음.
     * 호빗들은 인간과 다름. 그들의 사회가 비현실적으로 보이는 것은 그들이 근본적으로 인간과 다르기 때문임.
     * Sauron이 승리한 후의 ""Sauronic Empire""에 대한 가상의 설명이 흥미로웠음.
     * 현실에서 Shire와 유사한 곳은 Sark 섬임.
"
"https://news.hada.io/topic?id=15263","레고로 Orrery 만들기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             레고로 Orrery 만들기

     * 오리어리(Orrery)는 천체의 운동을 모델링하는 과학 도구임.
     * 지구, 달, 태양의 궤도와 자전 주기를 정확하게 모델링함.
     * JKBrickworks의 디자인에서 영감을 받아 레고 테크닉 부품으로 오리어리를 직접 설계함.

  지구의 자전축 기울기

     * 지구의 자전축은 궤도 평면에 대해 23.5° 기울어져 있음.
     * 이 기울기를 모델링하여 계절의 변화를 설명할 수 있음.
     * 22.5° 각도의 커넥터를 사용하여 지구 구체의 기울어진 홀더를 제작함.

  달 궤도의 경사

     * 달의 궤도 평면은 지구의 궤도 평면에 대해 5.15° 기울어져 있음.
     * 이 경사를 모델링하여 일식과 월식을 설명할 수 있음.
     * 기울어진 원형 기어 랙을 사용하여 달의 궤도를 구현함.

  동심축

     * 레고로 오리어리를 만들 때 동심 회전을 구현하는 것이 어려움.
     * 지구-달 시스템에서는 네 개의 독립적인 축이 필요함.
     * 여러 개의 턴테이블과 기어를 사용하여 이 문제를 해결함.

  기어 시퀀스

     * 지구-달 하위 조립품에는 네 개의 축이 필요함: 지구, 달, 지구의 베이스, 달의 경사 링.
     * 전체 오리어리에는 두 개의 추가 축이 필요함: 태양의 자전과 지구의 공전.
     * 기어 시퀀스를 통해 정확한 전송 비율을 구현함.
     * 레고 기어 시퀀스 도구를 사용하여 필요한 전송 비율을 찾음.

  발 설계

     * 초기 발 디자인에는 레고 모터를 사용했으나 소음 문제로 제거함.
     * 12분할 디자인을 채택하여 미적 요소를 강조함.
     * 브릭링크 스튜디오를 사용하여 디지털로 설계함.

  지침

     * 브릭링크 스튜디오를 사용하여 디지털 모델과 빌딩 지침을 만듦.
     * 지침은 264페이지, 436단계로 구성됨.
     * Rebrickable에서 디지털 지침을 판매함.

  낮은 부품 수 디자인

     * 부품 수를 줄이기 위해 발을 재설계함.
     * 레고의 Rough Terrain Crane 세트의 부품을 최대한 활용함.
     * 현재 레고 제품의 색상 팔레트를 사용하여 부품을 쉽게 구할 수 있도록 함.

  다른 오리어리

     * 2022년 CaDA에서 JK Brickworks가 설계한 오리어리를 출시함.
     * 2024년 레고에서 자체 오리어리를 출시했으나, CaDA의 디자인보다 복잡성이 낮고 신뢰성이 떨어짐.

  전망

     * 태양계의 모든 행성을 모델링하는 아이디어를 구상 중임.
     * 다음 프로젝트는 레고 부품 대신 레이저 컷 아크릴 시트를 사용하여 오리어리를 제작하는 것임.

GN⁺의 의견

     * 교육적 가치: 오리어리는 천문학과 기계 공학을 배우는 데 유용한 도구임.
     * 기술적 도전: 레고 부품으로 복잡한 기계 구조를 구현하는 것은 큰 도전임.
     * 상업적 성공: 높은 부품 비용과 복잡성으로 인해 상업적 성공은 제한적일 수 있음.
     * 대안 제품: CaDA의 오리어리는 더 간단하고 신뢰성이 높아 초보자에게 추천할 만함.
     * 미래 가능성: 레고와 같은 블록 장난감 회사들이 더 복잡한 오리어리 디자인을 제공할 가능성이 있음.

        Hacker News 의견

     * 저자는 계절을 나타내기 위해 축 기울기를 모델링하는 데 많은 시간을 보냄.
     * 디지털 빌딩 지침을 만드는 데 사용된 프로그램이 작은 모델에서는 잘 작동하지만 큰 모델에서는 사용성 문제가 있음. 264페이지, 436단계의 지침 PDF를 만드는데 많은 시간이 걸림.
     * 축이 항상 같은 방향을 가리킨다는 사실을 고등학교 때 배운 적이 없어서 이해하지 못했음. 이제야 그 이유를 알게 됨.
     * 커뮤니티 창작물이 ""공식"" 레고 디자인보다 훨씬 나은 예시임.
     * 기어 비율 계산기가 매우 유용하며, URL 매개변수로 제어할 수 있어 좋음.
     * 소프트웨어에서 좋은 렌더링/시각화를 위해 추가적인 노력을 기울인 점이 인상적임.
     * 창작자는 맞춤형 3D 프린팅 가능한 레고 호환 부품을 설계하는 도구도 만듦.
     * 레고에서 지구와 달의 궤도를 모델링한 제품을 만듦.
     * 예술은 매체의 제약에 의해 종종 향상됨. 레고가 이 계획에 대해 많은 돈을 지불하고 몇 가지 키트를 판매해야 함.
     * 저자가 언급한 비레고™ 오러리가 훌륭하며, 돈값을 하고 재미있게 만들 수 있음. 그러나 계절을 설명하는 데는 사용할 수 없어서 아쉬움.
     * 레고를 좋아하고 보통 만들고 나서 다른 사람에게 주는데, 이번 것은 놀라웠음. 직접 만들지는 않겠지만, 정말 대단함.
"
"https://news.hada.io/topic?id=15318","macOS 15.0, M3 칩에서 Nested Virtualization 지원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              macOS 15.0, M3 칩에서 Nested Virtualization 지원

     * Virtualization 프레임워크에 isNestedVirtualizationSupported 불린 값 추가됨
     * M3 칩 이후부터 지원
     * 이 값을 확인하여 isNestedVirtualizationEnabled 를 true로 설정하여 활성화 가능

   Hacker News 댓글 에 의하면
   ""Asahi Linux가 M2 부터 이미 지원하고 있어서, 칩에는 있지만 macOS가 노출하지 않는 것 같음""
   ""그동안 서버는 애플의 주력이 아니어서 상관안했지만, 인텔 CPU는 이미 20년전부터 이 기능을 지원해 왔음""
"
"https://news.hada.io/topic?id=15300","23words.com 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             23words.com 출시

23 Words 게임 소개

     * 게임 목표: 제한 시간 내에 숨겨진 단어를 찾는 것임.
     * 게임 방식: 주어진 23개의 단어를 모두 찾아야 함.
     * 도전 요소: 시간 제한이 있어 긴장감과 재미를 더해줌.
     * 플레이 방법: 단어를 찾기 위해 화면을 탐색하고 클릭함.

GN⁺의 의견

     * 흥미 요소: 시간 제한이 있어 긴장감과 몰입감을 높여줌.
     * 도움 요소: 단어 찾기 게임은 어휘력 향상에 도움을 줄 수 있음.
     * 비판적 시각: 반복적인 게임 플레이가 지루해질 수 있음.
     * 유사 게임 추천: '워드 서치'와 같은 다른 단어 찾기 게임도 추천할 만함.
     * 기술적 고려사항: 게임의 난이도 조절과 사용자 인터페이스의 직관성이 중요함.

        Hacker News 의견

     * 빠르고 간단한 브라우저 게임: 아침 커피와 함께 두뇌를 깨우기 좋은 빠르고 재미있는 게임 추천.
          + Linxicon: 두 단어 사이에 다리를 놓는 게임.
          + WhenTaken: 사진이 찍힌 장소와 시간을 추측하는 게임.
          + Angle: 정확한 각도를 맞추는 게임.
          + Metazooa: 동물 종을 추론하는 게임.
          + Tradle: 수출품을 통해 나라를 맞추는 게임.
          + Globle: 인접성을 통해 나라를 찾는 게임.
     * 키보드와의 호환성: 키보드와 잘 작동하며, 뉴욕타임즈에 인수될 가능성에 대한 기대.
     * 음악 게임: 노래의 일부를 듣고 미스터리 아티스트의 출신지를 맞추는 음악 게임 소개.
     * 즉각적인 키 바인딩: 간단하고 즉각적인 키 바인딩이 유용함.
     * 데스크탑에서의 재미: 데스크탑에서 즐기기 좋으며, UI 개선 아이디어 제안.
     * 빠르고 재미있는 게임: 게임이 빠르고 재미있으며, 단어마다 리셋되는 것을 몰라서 걱정했지만 결국 17개 단어를 맞춤.
     * 난이도 조절: 오늘의 단어들은 적당한 난이도였으며, 텍스트 클릭 시 글자가 제거되지 않는 점이 아쉬움.
     * Text Twist 향수: 원래 Text Twist 게임을 그리워하며, 단어 순서가 변경된 점이 게임의 재미를 떨어뜨렸다고 생각.
     * 게임 피드백: Enter 키를 누르면 현재 입력된 글자가 항상 초기화되었으면 좋겠다는 피드백.
     * 개인 게임 소개: 자신의 게임을 소개하며, 다른 사용자에게도 추천.
     * 문자 섞기: 사용자마다 문자가 다르게 섞이는 점이 공정하지 않다고 생각.
     * 키보드 문제: Firefox에서 키보드가 작동하지 않는 문제 지적.
     * 난이도 조정 필요: 게임이 너무 쉬운 것 같아 8~9글자 단어로 난이도를 높일 필요가 있다고 생각.
"
