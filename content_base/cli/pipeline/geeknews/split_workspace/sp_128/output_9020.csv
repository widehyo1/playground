"https://news.hada.io/topic?id=14502","Unsloth : Finetune Llama 3 with 2x 빠르고 6x 긴 Context, 68% 적은 VRAM","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Unsloth : Finetune Llama 3 with 2x 빠르고 6x 긴 Context, 68% 적은 VRAM

   • 대형 언어 모델을 미세 조정하는 도구인 언슬로스는 이제 메타의 최신 라마 3 모델을 지원하여 플래시 어텐션 2(FA2) 및 허깅 페이스(HF)에 비해 2배 더 빠른 미세 조정과 VRAM 사용을 63% 줄일 수 있다.

   • 언슬로스를 사용하면 라마 3의 70B 버전이 1.8배 빠르고 VRAM을 68% 적게 사용하여 미세 조정 중 훨씬 더 긴 컨텍스트 길이를 허용합니다. 이는 질문 답변이나 텍스트 생성과 같이 광범위한 맥락이 필요한 작업에 특히 유용하다.

   • 언슬로스는 또한 라마 3 모델의 4비트 양자화를 지원하여 4배 더 빠른 다운로드와 메모리 요구 사항을 줄입니다. 라마 3의 70B 인스트럭트 및 베이스 버전 모두에 대한 사전 양자화된 4비트 모델은 허깅 페이스 페이지에서 사용할 수 있다.

   • 또한 언슬로스는 토큰타이저에 BOS 토큰이 없고 기본 모델에 훈련되지 않은 토큰이 있는 것과 같은 라마 3의 특정 기벽과 ""벌레""를 다룬다. 언슬로스는 미세 조정 중에 이러한 문제를 자동으로 해결하여 정확하고 효율적인 교육을 보장합니다.
"
"https://news.hada.io/topic?id=14605","멀티 토큰 예측을 통한 더 나은 성능과 더 빠른 속도의 Large Language Models","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          멀티 토큰 예측을 통한 더 나은 성능과 더 빠른 속도의 Large Language Models

다중 토큰 예측을 통한 더 나은 대규모 언어 모델 학습

     * GPT와 Llama 같은 대규모 언어 모델은 다음 토큰 예측 손실로 학습됨
     * 본 연구에서는 언어 모델이 한 번에 여러 개의 미래 토큰을 예측하도록 학습시키면 샘플 효율성이 높아짐을 제안함
     * 구체적으로, 학습 코퍼스의 각 위치에서 공유 모델 트렁크 위에서 동작하는 n개의 독립적인 출력 헤드를 사용하여 다음 n개의 토큰을 예측하도록 모델에 요청함
     * 다중 토큰 예측을 보조 학습 작업으로 고려하여, 코드와 자연어 모델 모두에 대해 학습 시간에 오버헤드 없이 하위 작업 능력이 향상되는 것을 측정함

    모델 크기가 클수록 효과적이며 다중 에포크 학습에도 매력적임

     * 이 방법은 모델 크기가 클수록 더 유용하며, 여러 에포크 동안 학습할 때도 매력을 유지함
     * 특히 코딩과 같은 생성 벤치마크에서 이점이 두드러지며, 본 모델은 강력한 베이스라인보다 지속적으로 몇 퍼센트 포인트 더 우수한 성능을 보임
     * 13B 파라미터 모델은 HumanEval에서 12%, MBPP에서 17% 더 많은 문제를 해결함

    유도 헤드 개발과 알고리즘 추론 능력에 유리함

     * 작은 알고리즘 작업에 대한 실험은 다중 토큰 예측이 유도 헤드 개발과 알고리즘 추론 능력에 유리함을 보여줌
     * 추가적인 이점으로, 4-토큰 예측으로 학습된 모델은 큰 배치 크기에서도 추론 속도가 최대 3배 빠름

GN⁺의 의견

     * 언어 모델의 효율성 향상을 위해 새로운 학습 방법을 제안한 흥미로운 연구임. 특히 대규모 모델일수록 성능 향상이 뚜렷하다는 점이 주목할 만함
     * 다중 토큰 예측이 장기 의존성 학습에 어떤 영향을 미치는지에 대한 추가 실험이 있으면 좋을 듯함. 예를 들어 문장 간 참조 해결 같은 장거리 의존성 테스크에서의 성능 변화를 살펴보는 것도 의미 있을 것 같음
     * 코딩이나 수학 문제 풀이 등 특정 도메인의 생성 태스크에서 성능 향상이 컸다고 하는데, 일반적인 자연어 이해나 QA 태스크 등에서는 어떤 효과가 있을지 궁금함. 다양한 벤치마크에서의 실험 결과가 보완되면 좋겠음
     * 추론 속도 향상은 실용적인 측면에서 큰 메리트가 될 수 있음. 특히 실시간성이 요구되는 챗봇이나 질의응답 시스템 등에 적용하기에 유리해 보임
     * Anthropic의 Constitutional AI나 OpenAI의 InstructGPT 등 RLHF 기반 모델들이 주목받고 있는 상황에서, 이 연구는 지도학습만으로도 언어 모델의 성능을 높일 수 있는 방안을 제시했다는 점에서 의의가 있어 보임. 물론 윤리적 가치 정렬 등의 문제는 여전히 해결 과제로 남아있겠지만, 학습 효율성 측면에서는 충분히 경쟁력 있는 접근법으로 보임

        Hacker News 의견

   요약:
     * LLM에서 다양한 용어(데이터, 사전 학습, 학습, 추론, 전문가 혼합, RAG 등)가 어떤 맥락에서 사용되는지 이해하기 쉬운 설명이 필요함
     * 자기 추론 디코딩(Self-speculative decoding)은 예측한 레이블 시퀀스를 다시 네트워크에 피드하여 일치하는 지점까지만 예측을 유지하는 방식으로, 성능 저하 없이 속도를 높일 수 있음
     * LLM은 현재 출력 토큰 수 까지의 모든 토큰 조합에 대한 확률 분포를 고려하지 않고 있는데, 이를 고려한다면 더 좋은 성능을 보일 것으로 예상됨
     * LLM의 교차 엔트로피 손실 함수를 수정하여 훈련 데이터에서 n번째 미래 토큰만 고려하도록 하고, n에 따른 LLM 성능을 분석하는 것이 흥미로운 연구 주제가 될 수 있음
     * LLM이 출력한 토큰의 상태를 다음 답변에 활용할 수 있는 방법이 있는지 궁금함
     * 문장 전체의 의미를 인코딩하는 벡터를 예측하도록 LLM을 학습시키는 것은 어떨지 질문함
     * 논문의 5.2절 설명이 다소 부족한 면이 있음. 특히 H(Y|X)를 버리는 것에 대한 설명이 불명확함
     * LLM이 다음 N개 토큰에 대해 작은 PixelCNN과 같은 모델을 출력하게 하여 향후 토큰에 대한 조건부 확률을 설명할 수 있게 하는 방안을 고려해 볼 수 있음
     * 다음 n개 토큰뿐 아니라 128, 512, 2048 등 더 먼 미래의 토큰도 예측하여 장기적인 담화 구조를 학습하게 하면 어떨지 궁금해 함
     * 여러 토큰을 예측할 때 서로 간섭이 발생하는 경우 이를 어떻게 해결할 수 있을지 의문을 제기함
"
"https://news.hada.io/topic?id=14519","자신만의 ISP 사업 시작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             자신만의 ISP 사업 시작

자신만의 ISP 시작하기

   이 사이트는 자신만의 인터넷 서비스 제공자(ISP)를 시작하는 것을 돕기 위해 만들어졌음. 특히 이 가이드는 무선 ISP(WISP)를 구축하는 것에 중점을 둠.
     * WISP 구축의 초기 단계에 초점을 맞춤
          + 타당성 평가부터 첫 번째 고객 연결까지
     * 고객이 100명, 1,000명, 10,000명일 때 발생하는 많은 과제는 아직 이 가이드에서 다루지 않음

  최근 웨비나: ISP를 위한 수직 부동산

   2023년 8월 30일 오후 12시(태평양 표준시)에 Outpost Plus와 협력하여 진행한 최신 웨비나 녹화본을 확인하세요.
     * MDU 소유자 및 관리자 접근, MDU 사이트 설치 및 구축, 주민을 가입자로 전환하는 전략과 솔루션에 대해 알아보기

  커뮤니티

     * 프로젝트에 대한 개인화된 지원이 필요하면 저자와 시간을 예약하세요.
     * SYOISP Discord 서버에서 저자 및 관심 있는 다른 사람들과 채팅하며 토론에 참여하세요.
     * 트위터 @syoisp를 팔로우하세요.

  시작하기

     * WISP란 무엇이며 왜 구축하려고 하는지 설명하고 일부 용어를 정의함
     * 무선 ISP 구축 비용은 얼마인지 (Google Sheet 링크 제공)
     * 저자 소개와 이 일을 하는 이유

  단계별 가이드

    1. 지역 평가 : 무선 인터넷 네트워크에 적합한 후보지인지 확인
    2. 광섬유 제공업체 찾기 : 광섬유 연결을 구매하고 옥상을 무선 네트워크 시작점으로 사용할 건물 찾기
    3. 중계 사이트 찾기 : 고객을 향해 네트워크를 무선으로 확장
    4. 하드웨어 플랫폼 선택 : 무선 하드웨어의 사용 가능한 옵션 평가
    5. 청구 및 고객 관리 : 결제 받고 고객 지원하는 방법 확인
    6. 네트워크 토폴로지 : 네트워크를 안정적이고 확장 가능하도록 설계 (라우터, 스위치, IP 주소, VLAN 등)
    7. 인프라 구축 : 광섬유 연결 및 중계 사이트용 하드웨어 설치
    8. 고객 설치 : 첫 번째 고객 온라인 연결
    9. 마케팅 : 더 나은 인터넷 연결을 경험할 수 있도록 서비스를 알리기
   10. 유지 보수 : 악천후에도 네트워크를 원활하게 유지

  기타

     * FCC에 제출할 Form 477 준비 및 제출 방법
     * 필요한 도구 목록
     * 백홀 목록
     * RF 기초 및 채널 계획
     * MDU(다가구 주택) 모범 사례
     * Google Earth 사용 팁과 요령
     * 지붕 및 사다리 안전

GN⁺의 의견

     * 초기 투자 비용이 상당할 것으로 보이는데, 이를 줄이기 위한 다양한 방안을 모색해 볼 필요가 있어 보임. 예를 들어 중고 장비 활용, 클라우드 서비스 이용 등
     * 네트워크 토폴로지 설계 시 확장성을 고려하는 것이 매우 중요해 보임. 추후 가입자가 크게 늘어날 경우를 대비해야 함
     * 기존 ISP 대비 차별화된 서비스를 제공하는 것이 관건일 듯함. 예를 들어 보안이나 속도, 가격 면에서의 경쟁력 확보가 필요해 보임
     * 인프라 구축이나 고객 설치 시 안전 문제를 간과하지 말아야 할 것임. 사고가 나면 사업에 큰 타격이 될 수 있음
     * 고객 지원 체계를 갖추는 것도 잊지 말아야 할 부분임. 네트워크 장애 시 신속한 대응이 가능해야 고객 이탈을 막을 수 있을 것임

        Hacker News 의견

     * Jared Mauch의 사례를 참고하면 직접 ISP를 구축하는 것이 가능함. 그는 Comcast에 5만 달러를 지불하는 대신 자체 ISP를 구축하여 수백 가구로 확장함.
     * WISP(무선 인터넷 서비스 제공업체)가 Starlink와 경쟁할 수 있으나, WISP 운영자들이 좋은 관행을 따르지 않아 기술 부채로 어려움을 겪는 경우가 많음.
     * WISP 운영자는 다음과 같은 전략으로 경쟁력을 가질 수 있음:
         1. 광섬유를 끌어와 60GHz로 분배
         2. 좋은 MIMO AP로 더 먼 거리까지 광섬유 제공
         3. 수익을 활용해 광섬유를 더 가까이 끌어오고 밀도가 높은 지역을 오버빌드
         4. 다른 옵션이 없는 깊은 시골 고객에게 서비스 제공
         5. 건물로 60GHz, 아파트로 광섬유를 사용하는 역모델로 MDU 서비스
     * 그러나 실제로는 5GHz 타워 바운싱보다 복잡한 것은 너무 어려워 대부분 작은 WISP가 큰 WISP에 매각되거나 도산함.
     * 이 사이트의 조언에 대해서는 다소 회의적임. 모회사 사이트가 만료된 SSL 인증서를 제공하고 있어 다른 것들도 놓치고 있을 수 있음.
     * Starlink는 가입자 수에 하드 캡이 있어 공급에 제한이 있음.
     * WISP보다는 동네에 광섬유를 직접 가져오는 경험에 대해 읽고 싶었음. 지역 ISP가 최소한의 하드웨어로 기가비트 광섬유를 제공하는 지역에 살고 있음.
     * Starlink와 5G 제공업체 때문에 수익을 내기 어려울 수 있음.
     * 캐나다에서는 이런 것이 불가능함.
     * ""ISP로 작은 재산을 모으는 방법은? 큰 재산으로 시작하는 것""이라는 오래된 농담이 있음.
"
"https://news.hada.io/topic?id=14591","ExecuTorch Alpha: 커뮤니티 협업과 함께 대형 언어 모델 및 AI의 에지 배치 권한 부여","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ExecuTorch Alpha: 커뮤니티 협업과 함께 대형 언어 모델 및 AI의 에지 배치 권한 부여

   • PyTorch는 대형 언어 모델(LLM)과 대형 ML 모델을 에지 장치에 배치하고 API를 안정화하며 설치 프로세스를 강화하는 데 중점을 둔 ExecuTorch Alpha를 도입합니다.

   • ExecuTorch Alpha는 Meta의 Llama 2에 대한 지원과 Llama 3에 대한 조기 지원을 제공하여 아이폰, 삼성 갤럭시 폰 등과 같은 에지 장치에서 이러한 LLM을 효율적으로 실행할 수 있습니다.

   • 제한된 에지 장치에서 성능을 최적화하기 위해 ExecuTorch Alpha는 양자화 기술을 사용하고 광범위한 CPU 장치 지원을 위해 XNNPack의 동적 형상 지원 및 새로운 dtype을 활용합니다.

   • ExecuTorch SDK는 향상된 디버깅 및 프로파일링 도구를 제공하여 개발자가 효율적인 이상 해상도 및 성능 튜닝을 위해 운영자 노드를 원래 파이썬 소스 코드로 다시 매핑할 수 있다.

   • 암, 애플, 퀄컴 테크놀로지스, 구글, 유니티, 메타와 같은 파트너들과의 협력은 이미 메타가 핸드 트래킹과 기기의 다양한 모델에 이를 활용하고 있는 이그제큐토치를 발전시키는 데 중요한 역할을 했다.
"
"https://news.hada.io/topic?id=14551","일본 포로수용소에서 제작된 소형 lathe(선반)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      일본 포로수용소에서 제작된 소형 lathe(선반)

포로 수용소에서 직접 만든 R. Bradley 선반

     * 집에서 선반을 만드는 것이 어렵다고 생각한다면, 이 이야기가 여러분에게 도전할 용기를 줄 수 있음
     * 이것은 인간의 독창성에 대한 진정한 증거임

GN⁺의 의견

     * 극한의 상황에서도 인간의 창의력과 의지가 발휘될 수 있음을 보여주는 감동적인 사례임. 이런 이야기를 통해 우리는 많은 교훈과 영감을 얻을 수 있음
     * 현대 사회에서는 DIY 문화가 활성화되어 있지만, 당시의 상황을 고려하면 정말 놀라운 업적임. 어려운 환경일수록 창의적 사고와 도전 정신이 빛을 발할 수 있음을 시사함
     * 구체적으로 어떤 재료와 도구를 사용해서 어떻게 만들었는지에 대한 세부 내용이 있다면 제작 과정을 이해하는데 도움이 될 것 같음. 하지만 전시 상황을 감안하면 상세한 기록을 남기기 어려웠을 것으로 추정됨

        Hacker News 의견

     * 포로들이 감시를 피해 선반을 숨기는 것에 지쳐서, 막사 위에 ""작업장""이라는 간판을 걸어놓고 새로 온 감시병들이 그것이 원래부터 있었다고 생각하도록 함.
     * Changi 수용소 내부 사진들이 공유됨. 수용소에서 만든 의수족을 착용한 포로들의 사진과 죄수의 샌들 밑창에 숨겨진 무선 장비 사진 등.
     * Vintage 공작 기계를 사랑하는 한 댓글 작성자가 Monarch 10EE 선반을 소유하고 있으며, 이 사이트가 다른 어디에서도 찾을 수 없는 정보를 제공한다고 언급함.
     * 1937년부터 지금까지 같은 선반을 제작해온 SpaceX나 제약회사의 고객을 둔 장인의 사례가 소개됨.
     * 스캔된 PDF의 품질과 가독성을 향상시키는 AI 솔루션이 있는지에 대한 질문이 제기됨.
     * 누군가 누락된 페이지의 사본을 가지고 있는지 궁금해 함.
     * 이러한 도구들을 처음부터 만드는 방법을 보여주는 자료가 있는지, 제조업을 시작하려면 어떤 것이 필요한지에 대한 의문이 제기됨.
"
"https://news.hada.io/topic?id=14594","CSS Grid로 악보 출력 하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           CSS Grid로 악보 출력 하기

     * 작은 모바일 화면에서 A4 PDF를 확대하며 연주하는 음악가들을 위해, 웹에서 유동적이고 반응형인 악보 렌더링이 필요함

Scribe 프로토타입

     * 과거에 JSON에서 SVG를 출력하는 Scribe라는 음악 렌더러를 프로토타입으로 제작했음
     * 원래 목표는 반응형 음악 렌더러를 제작하는 것이었으나 복잡한 다중 패스 레이아웃 엔진을 작성해야 해서 진전이 어려웠음
     * 이후 CSS Grid를 프로젝트에 도입하면서 Scribe에서 다루던 레이아웃 문제의 해답이 될 수 있을 것 같았음

.stave 클래스

     * 오선지는 그리드와 비슷함. 수직 축은 음높이, 수평 축은 시간임
     * .stave 클래스에서는 수직 축인 그리드 행을 정의
     * 표준 음높이 이름으로 고정 크기 그리드 행을 만들고 오선지를 그리는 배경 이미지를 사용
     * 트레블 음자리 오선에 대한 행 맵 예시:
.stave {
  display: grid;
  row-gap: 0;
  grid-template-rows:
    [A5] 0.25em [G5] 0.25em [F5] 0.25em [E5] 0.25em
    [D5] 0.25em [C5] 0.25em [B4] 0.25em [A4] 0.25em
    [G4] 0.25em [F4] 0.25em [E4] 0.25em [D4] 0.25em
    [C4] 0.25em ;
  background-image: url('/path/to/stave.svg');
  background-repeat: no-repeat;
  background-size: 100% 2.25em;
  background-position: 0 50%;
}

     * 각 오선과 간격에 음높이 이름의 그리드 선이 생김

  오선에 음높이 배치

     * 오선의 각 행에는 여러 음높이가 위치할 수 있음
     * DOM 요소가 올바른 행에 위치하도록 하기 위해 data-pitch 속성에 음높이 이름을 넣고 CSS로 data-pitch 값을 오선 행에 매핑
.stave > [data-pitch^=""G""][data-pitch$=""4""] { grid-row-start: G4; }

     * 이 규칙은 'G'로 시작하고 '4'로 끝나는 음높이를 캡처해서 'G♭4', 'G4', 'G♯4' 등을 G4 행에 할당
     * 모든 오선 행에 대해 이를 수행해야 함
     * 이제 몇 가지 기호를 오선에 배치할 수 있음

.bar 클래스와 박자

     * 리듬을 처리하는 것은 좀 더 까다로움
     * 모든 종류의 리듬을 지원하는 명확한 최소 리듬 분할이 없음
     * 24열 당 1박자 접근법은 8분 음표, 16분 음표, 32분 음표 및 3연음표를 균등하게 배치할 수 있어 좋은 출발점임
     * 4박자를 4 × 24 = 96 그리드 열로 정의하고 시작과 끝에 열을 추가:
.bar {
  column-gap: 0.03125em;
  grid-template-columns:
    [bar-begin]
    max-content
    repeat(96, minmax(max-content, auto))
    max-content
    [bar-end];
}

     * ::before와 ::after로 마디선을 추가하고 data-pitch=""B4""로 음자리 기호를 중앙에 배치

  박자에 기호 배치

     * 이번에는 data-beat 속성을 사용하여 요소에 박자를 할당하고 CSS 규칙을 사용하여 박자를 그리드 열에 매핑
     * CSS 맵은 1/24박자마다 하나의 규칙으로 구성
     * 속성 ^= 시작 선택기를 사용하면 규칙이 오차 허용이 됨
     * .stave 클래스와 함께 사용하면 data-beat를 1~5 사이의 박자로, data-pitch를 음 이름으로 설정하여 박자와 음높이별로 기호를 배치할 수 있음

유동적이고 반응형인 악보

     * 이러한 여러 마디를 flexbox 컨테이너에 넣으면 반응형 악보를 볼 수 있음
     * 아직 누락된 것들이 많지만 시작하기에 좋은 기반임
     * 이미 온라인 음악 렌더러보다 훨씬 우아하게 줄 바꿈이 됨

  음표 사이의 공간

     * 서로 더 가까운 시간에 발생하는 음표 머리는 약간 더 가깝게 렌더링됨
     * 작은 column-gap에 의해 만들어진 미묘하고 의도적인 효과로, 기호 요소가 슬롯에 들어가는 일종의 시간 '에테르' 역할을 함
     * 열 자체는 음표 머리가 없으면 너비가 0이지만 박자가 더 멀리 떨어진 이벤트 사이에는 더 많은 열 간격(박자당 24개)이 있어 더 많은 거리가 생김
     * 기호의 여백을 조정하여 일정한 간격을 제어할 수 있음

음자리와 박자 기호

     * 수직 및 수평 간격에 대해 별도 클래스를 사용한 이유는 다른 것을 건드리지 않고 하나를 교체할 수 있기 때문
     * 같은 멜로디를 베이스 음자리에 표시하려면 .stave 클래스를 같은 data-pitch 속성을 베이스 오선 행에 매핑하는 bass-stave 클래스로 교체하면 됨
     * CSS로 data-duration=""5""를 .bar의 120 그리드 템플릿 열에 매핑하면 같은 오선에 5/4 박자 기호를 줄 수 있음

코드와 가사

     * CSS Grid를 사용하면 악보 그리드 내에서 다른 기호도 정렬할 수 있음
     * 코드와 가사, 다이내믹 등을 시간이 지정된 이벤트와 정렬하고 확장할 수 있음

음표 꼬리

     * 음표 꼬리, 코드, 일부 긴 쉼표는 data-duration 속성을 grid-column-end 범위 값에 매핑하여 열에 걸치게 만듦

크기 조정

     * 전체 시스템은 em 단위로 크기가 지정되므로 font-size를 변경하는 것만으로 크기를 조정할 수 있음

Flex와 Grid의 한계

     * 완벽한 시스템은 아님. 한계점:
         1. CSS는 줄 바꿈시 새 음자리/조표를 자동으로 배치할 수 없음
         2. 새 줄의 새 음표에 묶음줄을 연결할 수 없음
         3. 기울어진 음표 꼬리는 Grid가 배치한 후에야 정확한 위치를 알 수 있어 정렬이 어려움
     * 완전히 마무리하려면 약간의 정리 JavaScript가 필요하지만 CSS가 레이아웃 작업의 대부분을 처리하므로 JavaScript에서 할 레이아웃 작업이 훨씬 줄어듦

사용자 정의 요소

     * 이 새로운 CSS 시스템을 중심으로 인터프리터를 작성하고 요소에 래핑함
     * 아직 프로덕션 준비는 안되었지만 반응형 리드 시트를 렌더링하고 드럼을 표기할 수 있어 흥미롭고 유용함
     * 콘텐츠의 데이터, src 속성으로 가져온 파일, 요소의 .data 속성에 설정된 JS 객체에서 악보를 렌더링함
     * 현재 개발 빌드는 웹 페이지에 파일을 가져와서 사용해 볼 수 있음

앞으로 계획

     * Scribe 0.3의 개선사항 외에 장기적으로 조사하고 싶은 기능:
          + SMuFL 글꼴 지원 - 악보 기호에 사용되는 글꼴 변경
          + 중첩 시퀀스 지원 - 다중 파트 곡 활성화
          + 분할 오선 렌더링 - 한 오선에 여러 파트 배치
          + 다중 오선 렌더링 - 여러 개의 정렬된 오선에 여러 파트 배치

GN⁺의 의견

     * 웹에서 악보를 유동적이고 반응형으로 렌더링하는 것은 음악가와 음악 애호가 모두에게 매우 유용할 것 같음. PDF 악보를 작은 화면에서 확대/축소하며 보는 불편함을 해소해 줄 수 있을 것
     * CSS의 Grid와 Flex 레이아웃을 활용한 접근 방식이 흥미로움. 복잡한 레이아웃 엔진 없이도 CSS만으로 꽤 많은 부분을 해결할 수 있다는 것을 보여주는 좋은 예시
     * 하지만 악보의 특성상 CSS만으로는 한계가 있는 부분들도 있음. 줄 바꿈 시 자동으로 음자리나 조표를 배치한다든지, 묶음줄을 자동 연결하는 것 같이 음악적 문맥을 이해해야 하는 부분은 자바스크립트의 도움이 필요할 것
     * 리드 악보 렌더링과 드럼 악보 지원 등 이미 꽤 많은 부분을 구현했다고 하니, 조만간 충분히 쓸만한 수준으로 개선될 수 있을 것 같음. 오픈소스화 해서 개발이 지속된다면 MuseScore 같은 기존 악보 편집기의 좋은 대안이 될 수 있을 것
     * 앞으로 계획하고 있는 SMuFL 글꼴 지원, 다중 파트 및 다중 오선 렌더링 지원 등의 기능이 구현된다면 악보 표현의 완성도가 크게 높아질 것 같음. 기대가 되는 프로젝트

   이러시는 이유가 있을거 아니예요

        Hacker News 의견

     * Sheet music 소프트웨어 개발자로부터 CSS 그리드를 이용한 악보 렌더링 방식에 대해 찬사가 있음
          + Soundslice라는 웹 기반 악보 렌더링 서비스를 10년 넘게 개발해 왔으며, 2014년에 최초로 ""반응형"" 웹 악보 렌더링을 구현했음
          + 관련 기술 상세 내용은 발표 영상 링크 참고: https://www.youtube.com/watch?v=XH5EtQge_Bg
          + Soundslice의 반응형 악보 예시 링크: https://www.soundslice.com/slices/zzNlc/
          + 웹 기반 편집기, 연습 기능, 사진/PDF에서 악보 데이터 추출하는 스캔 기능 등 다양한 툴을 제공함
          + CSS 그리드 방식은 가벼운 프로젝트에는 유용할 수 있지만, 풀 스코어의 복잡하고 미묘한 표현을 다 구현하기는 어려울 것임
     * JavaScript 없이 CSS만으로 구현할 수 있도록 CSS 커뮤니티에 제안해보는 것도 좋을 듯함
          + 예를 들어 줄바꿈 시 음자리표 반복 표시는 sticky table header와 유사한데, 악보 외에도 활용될 수 있음
     * CSS의 attribute selector([...]) 문법이 인상 깊었음. 예: .stave > [data-pitch^=""A""][data-pitch$=""5""] { grid-row-start: A5; }
     * 음악 조판사 입장에서는 시각적으로 개선이 많이 필요해 보임. CSS만으로는 정밀도에 한계가 있어 어려울 듯함
          + 음표 기둥, 활, 붙임줄 등의 표현에 문제가 있음
          + 대부분의 브라우저 악보는 SVG나 Canvas로 벡터 렌더링하여 핀포인트 정밀도를 구현함
          + CSS 외에 이미 Soundslice, Sibelius Cloud Publishing 등 브라우저에서 스케일러블한 악보를 구현하는 다른 도구들이 있음
     * 처음에는 CSS로 악보를 표현하는 게 잘 안 될 것 같았는데, 간단한 방식으로 타이포그래피 품질이 인상적임. 작성자에게 찬사를 보냄
          + 다만 화음, 8/16분음표 간격, 파트 간 정렬 등 특수한 경우 잘 작동할지 우려됨. Lilypond는 이런 복잡한 표현에서 유연성이 입증됨
     * CSS 그리드가 흥미로움. 예전에 가구 디자이너를 pure frontend JS로 CSS 그리드 활용해 구현한 적 있음: https://alnvdl.github.io/2023/01/…
     * <scribe-music> 커스텀 엘리먼트도 기대됨
          + 몇 년 전 인턴이 VexFlow를 웹 컴포넌트로 래핑한 프로젝트 진행했었는데 유지보수 안 됨: https://github.com/PolymerLabs/vexflow-elements/…
          + 잘 관리되고 사용하기 쉬운 라이브러리가 웹 음악 표기법에 큰 도움이 될 것임
     * Lilypond(lilypond.org)의 대안이 나온 것은 좋지만, 표기법이 매우 복잡해서 간결성의 이점은 오래가지 않을 듯함
          + Asciidoc 매니아라면 Lilypond를 Asciidoc 툴체인에 통합하기 쉬움. DocBook PDF 파이프라인에서 사용 중이며, 출력물이 꽤 괜찮음. TeX과 유사함
     * https://www.musicxml.com과 https://opensheetmusicdisplay.org 를 상기시켜 줌. 훨씬 큰 비용이 들지만 완전한 솔루션임
     * Impro-Visor(https://github.com/Impro-Visor/Impro-Visor)의 어설픈 악보 기능을 이것으로 대체할 수 있을지 궁금함
     * CSS 벤치마크 같은 느낌
"
"https://news.hada.io/topic?id=14552","유전 알고리즘을 활용한 자동차 진화 과정 관찰","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       유전 알고리즘을 활용한 자동차 진화 과정 관찰

     * 유전 알고리즘을 활용한 자동차 진화 시뮬레이션 프로그램
          + 유전 알고리즘을 사용하여 무작위 2륜 모양을 세대를 거쳐 자동차로 진화시키는 것이 목적임
          + BoxCar2D를 기반으로 하되 처음부터 작성되었으며, 동일한 물리 엔진 (box2d) 만 사용함
          + David Bau의 seedrandom.js 라이브러리 사용함
     * 컨트롤과 설정
          + 현재 모집단을 로컬에 저장하고 복원할 수 있는 Save/Restore Population 기능이 있음
          + Surprise 토글을 통해 드로잉을 껐다 켜서 시뮬레이션 속도를 높일 수 있음
          + New Population은 트랙은 유지한 채 자동차 모집단만 재시작함
          + 동일한 시드로 언제나 같은 트랙이 생성되어 친구들과 경쟁이 가능함
          + Mutation rate는 새 세대가 태어날 때 각 개체의 각 유전자가 무작위 값으로 변이될 확률임
          + Mutation size는 각 유전자가 변이될 수 있는 범위로, 숫자가 작을수록 원래 값에 가까움
          + Elite clones은 다음 세대로 복사될 상위 n대의 자동차를 의미함
          + View top replay는 현재 시뮬레이션을 일시 중지하고 최고 성능 자동차를 보여줌
     * 그래프
          + 빨간색: 각 세대의 최고 점수
          + 녹색: 각 세대의 상위 10대 자동차 평균
          + 파란색: 전체 세대 평균
     * 게놈 구성
          + 모양 (꼭짓점 당 1개, 총 8개 유전자)
          + 바퀴 크기 (바퀴 당 1개, 총 2개 유전자)
          + 바퀴 위치 (바퀴 당 1개, 총 2개 유전자)
          + 바퀴 밀도 (바퀴 당 1개, 총 2개 유전자) - 어두울수록 밀도 높음
          + 섀시 밀도 (1개 유전자) - 어두울수록 밀도 높음
     * 추가 사항
          + 시뮬레이션이 결정론적이지 않아 최고의 자동차가 일관된 성능을 보이지 않을 수 있음
          + 거리에 따라 지형 복잡도가 증가함
          + 이제 코드가 GitHub에서 커뮤니티 기여와 함께 사용 가능함

        Hacker News 의견

   요약하면 다음과 같음:
     * 이 프로젝트는 20년 전에 만들어졌으며, Ruffle 덕분에 여전히 브라우저에서 실행 가능함
     * 유전 알고리즘의 특성상, 어느 시점에 우수한 디자인이 나타나면 이후 세대에서 계속 지배적인 경향을 보임. 돌연변이율과 돌연변이 크기 설정을 조정해 볼 필요가 있음
     * 280m 이후로는 도로가 없어 차들이 끝없는 구덩이로 떨어지는 작은 버그가 있음
     * ""Surprise"" 버튼을 눌러 빠르게 여러 세대를 거칠 수 있음. 돌연변이율과 돌연변이 크기를 조정하며 시간에 따른 진화 과정을 관찰하는 것이 흥미로움
     * 차량에 ""컴플라이언스""에 대한 유전자가 있어 서스펜션을 구현할 수 있다면 흥미로울 것임. 대부분의 실행에서 트론 바이크 모양으로 수렴하는 경향을 보임
     * 세대가 바뀌어도 지형은 변하지 않음
     * 이전 HN 토론에서도 여러 번 소개되었음 (boxcar2d와 유사하나 Flash 없이 구현)
     * 어릴 적 Boxcar 2D로 수 시간을 보냈던 추억이 떠오름
     * 3D 물리 기반 시뮬레이션 환경에서도 이와 같은 것이 가능할지 궁금함. 시뮬레이션에서 드론 등의 새로운 공기역학적 형상을 발견하는 데 유전 알고리즘이 사용될 수 있을지 흥미로움
"
"https://news.hada.io/topic?id=14568","유럽 전역 폭탄 테러와 독살 사건 연루된 GRU 스파이 부부 신분 탄로","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                유럽 전역 폭탄 테러와 독살 사건 연루된 GRU 스파이 부부 신분 탄로

   죄송하지만 현재 주어진 내용으로는 요약문을 작성하기에 충분한 정보가 없습니다. 해당 기사의 본문 전체 내용이 필요할 것 같습니다. 기사 제목만으로는 중요한 내용을 파악하고 요약하기 어려운 점 양해 부탁드립니다.

        Hacker News 의견

   다음은 해커뉴스 댓글들을 요약한 내용임:
     * The Americans 드라마 추천: 1980년대 워싱턴 DC를 배경으로 여행사를 가장한 KGB 불법체류자들에 관한 스파이 드라마로, 기본 케이블 TV 수준을 뛰어넘는 훌륭한 작품. Hulu에서 모든 시즌 스트리밍 가능.
     * 실제 스파이 활동의 정교함:
          + 그리스 항공사에는 체코 여권으로만 등록하고, 러시아 국경 통과시에는 비밀 러시아 여권을 사용해 비자 신청 없이 출입국 기록을 남기지 않음.
          + 그러나 그리스 항공사와 출입국 관리소에서 러시아 비자 확인을 하지 않았는지, 러시아 여권 스캔으로 시스템에 기록되지 않았는지 의문.
     * GRU의 불법체류자 프로그램: SVR이 아닌 GRU에서도 운영 중인 것으로 보이며, 최근의 변화인지 궁금증 제기됨.
     * 여권번호의 치명적 실수: 극비 작전팀용으로 예약된 일련번호를 사용한 것은 매우 큰 실수로 보임. 증거 조작 가능성도 제기됨.
     * 불법적 여권 사용: 자국 내에서 다른 나라 여권을 사용하는 것은 대부분의 국가에서 불법이며, 출입국 시 같은 여권을 사용해야 함.
     * NATO에 대한 공격으로 간주되지 않은 이유 궁금증 제기됨.
     * 도메인 압수 가능성: 라트비아에 기반을 둔 것으로 보이는 .ru 도메인 사이트에 대해, 물리적으로 러시아에 있진 않겠지만 국가에 의해 도메인이 압수될 수 있다는 추측.
     * HBO 시리즈화 기대 제기됨.
"
"https://news.hada.io/topic?id=14498","Jina AI Reader - URL을 LLM 친화적인 입력으로 바꿔주는 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Jina AI Reader - URL을 LLM 친화적인 입력으로 바꿔주는 도구

     * URL의 내용을 읽어서 LLM에 입력하기 좋은 형태로 만들어주는 오픈소스
     * https://r.jina.ai/https://news.hada.io 처럼 Prefix 를 붙여서 쉽게 이용 가능 (무료 사용)
     * 모든 이미지를 읽어서 Image [idx]: [caption] 형태의 설명도 붙여줌
     * 스탠다드/스트리밍/JSON 세가지 모드로 사용 가능
     * 헤더를 추가로 보내서 추가 기능 이용
          + x-respond-with: html : documentElement.outerHTML 리턴
          + x-respond-with: text : document.body.innerText 리턴
          + x-respond-with: screenshot : 웹페이지 스크린샷 URL을 리턴
          + 기본 값은 x-respond-with: markdown

   한 달 동안 특정 URL의 컨텐츠를 GPT에 전달해야하는 상황에서, 내부 브라우저를 사용하는 GPT 에이전트보다 jina를 통해 내용을 직접 전달하는 편이 훨씬 더 효과적이고 똑똑하게 처리된다는 느낌을 받았습니다. 매번 URL을 직접 입력하고 처리하는 게 번거로워 Mac의 컨텍스트 메뉴(오른쪽 클릭 메뉴)에 Automator를 통해 사용자 정의 서비스를 등록하고 사용 중인데, 이 방법이 매우 편리합니다. 작성한 스크립트를 공유하니 참고 필요하시다면 사용해보세요. 해당 스크립트를 등록하면 브라우저 URL에서 오른쪽 클릭 후 서비스 항목에서 바로 선택할 수 있습니다.
on run {input, parameters}
        try
                set selectedURL to item 1 of input
                set finalURL to ""https://r.jina.ai/""; & selectedURL

                tell application ""System Events""
                        open location finalURL
                end tell
        on error errMsg
                display dialog ""Error: "" & errMsg
        end try
        return input
end run

   원래는 SpotLight에 등록하고 싶었는데, SpotLight는 커스터마이징을 지원하지 않는듯 해서 그냥 이렇게 만들었습니다.

   저는 북마클릿에 넣어서 이용합니다.

   javascript:(function()%7Bwindow.location.href %3D ""https%3A%2F%2Fr.jina.ai%2F"" %2B document.URL %3B%7D)()%3B

   wow
"
"https://news.hada.io/topic?id=14534","Moviecart - 아타리 2600용 풀 컬러 영화 및 오디오 카트리지 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Moviecart - 아타리 2600용 풀 컬러 영화 및 오디오 카트리지 출시

Atari 2600용 풀 컬러 영화 및 오디오 카트리지 제작을 위한 MovieCart 소프트웨어 및 하드웨어 소개

  기술 사양

     * 60fps로 교차되는 두 개의 필드로 구성
     * 각 필드는 10 x 262 셀의 체커보드 패턴으로 구성
     * 각 셀은 128가지 색상 중 하나를 포함하며 가로 8픽셀, 세로 1픽셀 크기
     * 30fps에서 80 x 262의 효과적인 해상도를 제공하며, 라인당 10가지 색상 지원
     * 15.720KHz에서 생성되는 4비트 모노 사운드
     * 조이스틱으로 밝기, 볼륨 및 셔틀 위치 제어 가능
     * 콘솔 스위치로 흑백, 10초 뒤로 감기 및 전체 뒤로 감기 제어
     * 각 필드는 2.5K의 데이터가 필요
     * 1초에 75.5개의 Combat 카트리지 또는 2시간 분량의 영화 제작에 50만 개 이상의 카트리지가 필요

  주요 특징

     * 집에서 직접 은막의 기쁨을 경험할 수 있는 최초의 제품
     * 인상적인 80 x 192 해상도, 7비트 컬러 및 4비트 모노 오디오 제공
     * 풀 렝스 영화 라이브러리 구축 가능

  구매 정보

     * Tindie에서 키트 사전 주문 가능: https://www.tindie.com/products/lodefmode/moviecart-atari-2600/

GN⁺의 의견

     * Atari 2600은 게임기지만, 이를 활용해 풀 컬러 영화를 감상할 수 있게 하는 획기적인 제품임. 당시로서는 상당히 혁신적인 아이디어라고 볼 수 있음.
     * 해상도나 프레임 레이트 등 성능이 제한적이긴 하지만, 80년대 초반 기술 수준에서는 괄목할만한 것으로 보임. 시대를 앞서간 제품이라 할 수 있음.
     * 영화 한편을 저장하려면 50만개가 넘는 카트리지가 필요하다는 점은 현실성이 떨어져 보임. 실제 사용하기에는 무리가 있어 보임.
     * 일반 사용자들이 직접 영화를 인코딩해서 카트리지에 담기는 쉽지 않아 보임. 영화 라이브러리 구축을 위한 전용 서비스 등이 필요해 보임.
     * 게임기의 성능을 최대한 활용해 새로운 미디어 경험을 제공하려 했다는 점에서 의의가 있음. 당시 기술로는 한계가 있었겠지만, 게임기의 가능성을 확장했다는 점에서 가치가 있어 보임.

        Hacker News 의견

     * 레트로 컴퓨팅 분야에서 현재 엄청난 일들이 일어나고 있음. 매우 저렴한 가격에 엄청난 컴퓨팅 파워를 가진 칩들을 오래된 기기에 끼워넣어 재미를 보는 것이 대세임.
     * 카트리지에 많은 연산을 넣고 ""실제"" 컴퓨터를 매우 안 좋은 GPU로 사용하는 것은 재미있는 아이디어임.
     * 일부 카트리지 기반 콘솔을 상당히 확장할 수 있을지 궁금해 함. ARM 칩을 카트리지에 넣고 H.264로 보내는 것이 가능할지 실험해보고 싶어함.
     * 돈을 위해서가 아니라 도전이 있었기에 누군가는 해내야만 했던 프로젝트임.
     * 카트리지가 컴퓨터 역할을 하고 콘솔은 멍청한 디스플레이로 취급하는 것 같아서 기대만큼 흥미롭진 않음.
     * 작가가 이를 위해 만든 2600 스타일 설명서가 훌륭함. 스티브 마틴의 ""The Jerk"" 표지, ""당신의 컬렉션에 추가할 멋진 타이틀들"" 등 세세한 부분까지 신경썼음.
     * 슬롯의 압축 기술을 더한다면 하나의 카트리지에 전체 영화 라이브러리를 담을 수 있을 것임.
     * 2600의 그래픽 방식을 고려하면 불가능할 것 같았는데 해냈다는 점이 인상적임.
     * 4GB에서 약 4시간의 콘텐츠를 뽑아낸 것은 정말 멋짐. 카트리지는 $25에 판매되는 듯. 탐험해볼만한 흥미로운 매체임.
     * 개조된 Atari Flashback 2에서도 제대로 작동할지 궁금해 함.
"
"https://news.hada.io/topic?id=14497","목성을 시뮬레이션하는 Jupiter Simulation 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   목성을 시뮬레이션하는 Jupiter Simulation 기술

        Hacker News 의견

   Here are the key points from the Hacker News comments, summarized in a bullet list format:

   • Asteroseismology simulation at university:
     * A commenter shared their experience of running a Jupiter simulation during university, where a comet hit the planet, and the observations were used in asteroseismology models to study Jupiter's interior.

   • Praise for the article's explanations and visuals:
     * Several commenters expressed their joy and appreciation for the well-written explanations and stunning visuals in the article.

   • Suggestions for extending the method:
     * A commenter wondered about other potential uses of the technique, such as:
          + Coupling different shapes to create large-scale transitions like a large vortex following a sigmoid over other zones.
          + Subtle ways to make the visuals follow the envelope of an audio background.

   • Author's response to feedback:
     * The article's author thanked the Hacker News community for sharing the article and providing feedback.
     * They took note of the suggestions, particularly regarding contrast and UX issues, and welcomed further feedback.

   • Related work on simulating Jupiter's bands:
     * A commenter shared their own experiment using fluids in Maya to create a closeup of Jupiter's bands while working at a planetarium.

   • Questions about the technical implementation:
     * A commenter wondered if there's a direct way to save Unreal Engine 4 material shaders to Shadertoy or an easy conversion tool, given the examples were displayed in Shadertoy embeds.

   • Praise for the site's performance and mobile readability:
     * Despite the visual complexity, the site was praised for its performance, visual appeal, and excellent readability on mobile devices.

   • Appreciation for the immersive visuals and other articles on the site:
     * Commenters expressed their awe at the immersive visuals, with one jokingly saying they could almost feel the drops in their hair.
     * The other articles on the site were also praised as fascinating and a treasure trove of content.

   • Performance concerns:
     * One commenter noted the low frame rate of 0.3 fps, hinting at potential performance issues.
"
"https://news.hada.io/topic?id=14515","DOS 4 오픈 소스화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              DOS 4 오픈 소스화

MS-DOS 4.0 소스 코드 오픈소스 공개

     * Microsoft는 IBM과 협력하여 오픈 이노베이션 정신으로 MS-DOS 4.00의 소스 코드를 MIT 라이선스로 공개함
     * 10년 전 MS-DOS 1.25와 2.0의 소스 코드를 Computer History Museum에 공개하고 참조용으로 재배포한 바 있음
     * 이 코드는 거의 45년 전 8086 어셈블리 코드로 전체가 작성된 운영 체제로서 역사적으로 중요한 위치를 차지하며 흥미로운 내용임

  DOS 4.0의 복잡하고 흥미로운 역사

     * DOS 4.0에는 Microsoft가 IBM과 코드 일부를 함께 개발했지만, 널리 배포되지 않은 Multitasking DOS라는 DOS 브랜치도 만들었기에 버전 역사가 다소 복잡하고 흥미로움

  영국 연구원 Connor ""Starfrost"" Hyde의 발견

     * 영국 연구원 Connor ""Starfrost"" Hyde가 최근 전 Microsoft CTO Ray Ozzie와 연락하여 그의 소프트웨어 컬렉션 중 일부에 대해 논의함
     * Ray는 플로피 디스크 중에서 Lotus 재직 시절 받았던 DOS 4.0 미공개 베타 바이너리를 발견함
     * Starfrost는 Microsoft OSPO에 연락하여 DOS 4, MT-DOS, 그리고 추후 OS/2가 될 것들 사이의 관계를 문서화하는 작업의 일환으로 DOS 4 소스 공개를 타진함
     * 이 새로운 Ozzie 베타 바이너리는 인터넷에서 찾을 수 있는 Multitasking DOS 바이너리의 후기 버전들보다 훨씬 이전 버전이며 미공개 버전이고, ibmbio.com 소스도 포함하고 있음

  Microsoft의 추가 노력

     * Microsoft의 Scott Hanselman은 인터넷 아키비스트이자 애호가인 Jeff Sponaugle의 도움을 받아 이 원본 디스크를 이미징하고 ""Ozzie Drop""의 원본 인쇄 문서를 주의 깊게 스캔함
     * Microsoft는 IBM 친구들과 함께 이것이 공유할 만한 가치가 있는 운영 체제 역사의 흥미로운 부분이라고 생각함
     * Jeff Wilcox와 OSPO는 Microsoft 아카이브를 조사했지만, MT-DOS의 전체 소스 코드는 찾을 수 없었고, 오늘 공개하는 MS-DOS 4.00과 추가 베타 바이너리, 문서의 PDF, 디스크 이미지 등을 발견함
     * 더 발견되는 것이 있다면 이 릴리스를 업데이트할 예정임

감사의 말

     * Ray Ozzie, Starfrost, Jeff Sponaugle, Larry Osterman, IBM OSPO의 친구들, Greaseweazle, Fluxengine, Aaru Data Preservation Suite, HxC Floppy Emulator 등 디지털 고고학 소프트웨어 제작자들에게 감사를 표함
     * 무엇보다 이 코드의 원저자들에게 감사하며, 그 중 일부는 여전히 Microsoft와 IBM에서 일하고 있음

  직접 실행해보기

     * 이 소프트웨어를 직접 실행하고 탐색하려면, 원래의 IBM PC XT나 새로운 Pentium에서 직접 실행하거나 오픈소스 PCem과 86box 에뮬레이터에서 실행할 수 있음

GN⁺의 의견

     * 이번 소스 코드 공개는 역사적 가치가 큰 의미 있는 일로 보임. MS-DOS는 PC 역사에서 중요한 위치를 차지하는 만큼 많은 사람들에게 흥미로운 자료가 될 것임
     * 하지만 DOS 4.0은 완성되지 않은 버전이고 실제 널리 사용되지는 않았기에, 실제 사용된 DOS인 3.x나 5.0, 6.x 버전 소스도 공개되면 좋을 것 같음
     * 미완성 버전의 소스라도 당시의 OS 개발 방식이나 코드 스타일 등을 엿볼 수 있어 의미가 있겠지만, 실제 제품에 쓰인 코드를 보는 것은 또 다른 가치가 있을 것임
     * 오래된 플로피 디스크의 내용을 복원하는 작업이 쉽지 않았을텐데, 관련 도구들이 발전해 왔기에 가능했던 것 같음. 앞으로도 과거 유물을 디지털 고고학으로 복원하는 시도가 많아지길 기대함
     * 소스와 함께 빌드 가능한 환경도 함께 제공해준다면 MS-DOS를 직접 빌드하고 수정해볼 수 있는 기회도 될 것 같음. 레거시 OS를 공부하는데 큰 도움이 될 것임

        Hacker News 의견

     * 오리지널 IBM XT와 모노크롬 디스플레이 어댑터에서 MS-DOS 4.0을 실행시키는데 성공함. 작은 게임, Turbo Pascal, DOS 프롬프트 사이를 한 키로 전환할 수 있어서 멋졌음.
     * MS-DOS 소스코드에서 개발자들이 좌절할 때 자주 사용한 욕은 ""brain damaged""였던 것으로 보임.
     * IBM XT에서 MS-DOS 4.0이 실행되는 짧은 동영상이 공유됨. Scott가 플로피 디스크를 구하고 공개 허가를 받은 것에 대해 크게 칭찬받음.
     * 소스코드에 ""Dam multiplan!""이라는 주석이 있는데, 스프레드시트 애플리케이션인 Multiplan을 욕하는 것으로 추정됨.
     * 정책이 시행되기 전에 소스코드에 욕설이 포함된 것으로 보임.
     * MS-DOS 소스코드가 오픈소스화 된 것은 좋지만, 외부의 동기부여로 이뤄진 것은 아쉬움. 기업 내부적으로 역사적 소스코드를 공개하려는 움직임이 부족해 보임.
     * MS-DOS 5.11부터는 TSR, 메모리 관리자 등이 안정화되었던 것으로 기억됨. 5.x, 6.x 버전의 소스코드도 공개되면 흥미로울 것임.
     * MS-DOS 4.0 출시(1986년)로부터 오픈소스화(2024년)까지 37년이 걸림. 이 속도라면 Windows XP는 2038년쯤 오픈소스화 될 것으로 예상됨.
     * MS-DOS 4.x는 대부분의 빈티지 DOS 소프트웨어를 실행할 수 있어서 소스코드 공개가 큰 의미가 있음.
     * MS-DOS 4는 전반적으로 좋지 않은 버전이었고 널리 사용되지 않았음. 3.3이나 5.0이 더 흔했음. MUF(Microsofts Undocumented Features) 리스트를 기억하는 사람이 있는지 궁금해 함.
"
"https://news.hada.io/topic?id=14496","IBM, HashiCorp 인수 계약 체결, 인수가 64억 달러","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  IBM, HashiCorp 인수 계약 체결, 인수가 64억 달러

     * IBM과 HashiCorp는 IBM이 주당 $35에 HashiCorp를 인수하는 최종 계약을 체결했음. 이는 기업 가치 $64억에 해당함.
     * HashiCorp의 제품군은 기업이 하이브리드 및 멀티 클라우드 환경을 자동화할 수 있는 광범위한 인프라 및 보안 라이프사이클 관리 기능을 제공함.
     * 이 발표는 IBM이 하이브리드 클라우드와 AI에 깊이 집중하고 투자하고 있음을 보여줌.

기업의 복잡성 대응을 위한 통합

     * 기업 고객은 퍼블릭, 프라이빗 클라우드 및 온프레미스 환경에서 인프라와 애플리케이션이 전례 없이 확장되는 상황에 직면해 있음.
     * 생성형 AI에 대한 전 세계적 관심으로 이러한 과제가 더욱 심화되었으며, CIO와 개발자는 기술 전략에서 극적인 복잡성에 직면해 있음.
     * HashiCorp는 고객이 오늘날의 인프라 및 애플리케이션 확산의 복잡성을 관리할 수 있도록 지원하는 입증된 실적을 보유하고 있음.
     * IBM의 포트폴리오와 전문성을 HashiCorp의 역량 및 인재와 결합하여 AI 시대를 위한 포괄적인 하이브리드 클라우드 플랫폼을 만들 것임.

HashiCorp의 기술

     * HashiCorp의 기능을 통해 기업은 자동화를 사용하여 하이브리드 및 멀티 클라우드 환경에 필요한 중요한 워크플로에 대한 시스템을 제공하여 인프라 및 보안에 대한 라이프사이클 관리를 제공할 수 있음.
     * HashiCorp의 Terraform은 이러한 환경에서 인프라 프로비저닝을 위한 업계 표준임.
     * HashiCorp의 제품은 고객이 클라우드에 구애받지 않고 상호 운용성이 뛰어난 멀티 클라우드 관리 방식을 취할 수 있도록 지원함.

전략적 시너지 기대

     * IBM에 의한 HashiCorp 인수는 AI 기반 복잡성을 위해 구축된 포괄적인 엔드투엔드 하이브리드 클라우드 플랫폼을 만들어냄.
     * 양사의 포트폴리오와 인재의 조합은 광범위한 애플리케이션, 인프라 및 보안 라이프사이클 관리 기능을 고객에게 제공할 것임.
     * HashiCorp는 레드햇, watsonx, 데이터 보안, IT 자동화 및 컨설팅 등 IBM의 여러 전략적 성장 영역에서 시너지 효과를 낼 것으로 기대됨.
     * 또한 전 세계 175개국 이상에서 사업을 펼치고 있는 IBM의 세계적 수준의 마케팅 전략과 규모, 범위를 활용하여 HashiCorp의 성장 계획이 가속화될 것으로 예상함.

인수 거래 세부사항

     * 이사회 승인: IBM과 HashiCorp의 이사회는 모두 이번 거래를 승인함.
     * 규제 승인 및 HashiCorp 주주 승인 등 관례적인 마무리 조건에 따라 인수가 이뤄질 예정임.
     * HashiCorp의 지분 43%를 보유한 최대 주주와 투자자들은 IBM과의 의결권 계약을 체결했음.
     * 거래는 2024년 말까지 종료될 것으로 예상됨.

GN⁺의 의견

     * IBM의 하이브리드 클라우드 및 AI 역량과 HashiCorp의 인프라 자동화 기술이 결합되어 기업의 멀티 클라우드 및 온프레미스 환경 관리에 강력한 통합 솔루션을 제공할 수 있을 것으로 보임.
     * 특히 HashiCorp의 Terraform은 코드형 인프라(IaC) 분야의 사실상 표준으로 자리잡고 있어, 이를 통해 IBM의 하이브리드 클라우드 플랫폼이 더욱 경쟁력을 갖출 것으로 예상됨.
     * 다만 $64억이라는 인수가는 다소 높아보이며, 양사의 기술과 제품을 얼마나 효과적으로 통합하고 시너지를 낼 수 있을지가 관건이 될 것임.
     * 경쟁사로는 VMware, Nutanix, Morpheus Data 등 멀티 클라우드 관리 플랫폼 기업들이 있음. IBM은 이들과의 차별화를 위해 Red Hat 및 AI 역량과의 결합이 중요할 것임.

   요즘 opentofu와 해시콥의 분쟁이 심화 되고 있는 상황인데.... IBM까지 참잔하겠군요.

   IT계의 마이너스 손으로 알려진 IBM, 과연 미래는 어떨 것인가 촉각이 곤두세워지는 인수 소식입니다.
"
"https://news.hada.io/topic?id=14492","CoreNet: 심층 신경망 학습을 위한 라이브러리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      CoreNet: 심층 신경망 학습을 위한 라이브러리

Apple에서 개발한 딥러닝 프레임워크 CoreNet 소개

     * CoreNet은 Apple에서 개발한 딥러닝 프레임워크로, 표준적이거나 새로운 대규모 모델을 다양한 태스크에 훈련시킬 수 있음
          + Foundation Model (CLIP, LLM), 객체 분류, 객체 검출, Semantic Segmentation 등의 태스크 지원
     * 최근 업데이트된 v0.1.0에는 OpenELM, CatLIP, MLX 예제 등이 포함됨

CoreNet을 활용한 Apple의 연구 성과

     * OpenELM: 효율적이고 오픈소스로 학습/추론이 가능한 Language Model
     * CatLIP: Web-scale의 이미지-텍스트 데이터로 2.7배 빠른 사전학습으로 CLIP 수준의 성능 달성
     * FastVit: 구조적 재매개변수화를 활용한 빠른 하이브리드 Vision Transformer
     * Bytes Are All You Need: 파일의 바이트 단위로 직접 동작하는 Transformer
     * MobileOne: 1ms 지연의 모바일용 백본 네트워크
     * RangeAugment: Range Learning을 활용한 효율적인 Online Augmentation 기법
     * MobileViT: 모바일 친화적인 경량 Vision Transformer
     * 그 외 다수의 연구 성과 소개

설치 및 개발 환경 구성

     * Git LFS 설치 필요 (테스트, Jupyter Notebook 실행, 기여를 위해 필요)
     * Linux에서는 Python 3.10+, PyTorch v2.1.0+ 추천
     * macOS에서는 Python 3.9+로 충분
     * 선택적 종속성 패키지는 기여나 테스트 실행시 필요
     * 상세한 Linux, macOS 설치 방법 및 오디오/비디오 처리를 위한 패키지 설치 방법 설명

CoreNet의 디렉토리 구조

     * tutorials: 입문용 예제
          + 새로운 데이터셋으로 처음부터 모델 훈련하기
          + SLURM과 멀티 노드 훈련 가이드
          + CLIP, Semantic Segmentation, Object Detection 예제
     * projects: 각 태스크별 훈련 레시피와 사전 학습된 가중치 및 체크포인트 제공
          + README.md에 문서화, 사전학습 가중치 링크, 인용 정보 포함
          + <task_name>/<model_name>.yaml 파일로 재현 가능한 훈련/평가 설정 제공
     * mlx_example: Apple Silicon에서 효율적으로 CoreNet 모델 실행하는 예제
     * corenet/modeling/models: 태스크별로 구성된 모델 구현체
          + 데코레이터로 태스크 이름과 모델 이름 지정
          + YAML 설정 파일에서 사용할 모델 클래스 지정 방법 설명
     * corenet/data/datasets: 태스크별로 구성된 데이터셋
     * 기타 YAML 설정에서 참조되는 클래스 구현 디렉토리 설명
          + loss_fn, metrics, optims, data 등

CoreNet 프로젝트 정보

     * Sachin이 개발을 시작했고, 현재는 Sachin, Maxwell Horton, Mohammad Sekhavat, Yanzi Jin이 유지보수
     * 커뮤니티의 Pull Request 기여 환영. 기여 문서 참고.
     * CoreNet은 CVNets에서 발전된 프로젝트로, Vision 이외에 LLM 등의 Foundation Model 훈련을 지원하기 위해 확장됨

GN⁺의 의견

     * CoreNet은 최신 SOTA 모델들을 아우르는 포괄적인 딥러닝 프레임워크로 보임. SOTA 모델의 구현체 제공과 함께 학습 파이프라인까지 제공하여 기존 연구 결과 재현이 용이할 것으로 보임.
     * Apple에서 개발한 프레임워크인 만큼 Apple Silicon 기기에서의 최적화된 구동을 기대해 볼 수 있음. 특히 MLX 예제를 통해 Apple Silicon에서의 최적화 방안을 엿볼 수 있음.
     * 비전 태스크 뿐만 아니라 LLM 등의 Foundation Model 훈련까지 지원한다는 점이 특징. 다만 현재 공개된 버전은 0.1.0으로 아직 초기 단계인 듯 함. 향후 업데이트 계획과 로드맵이 궁금해짐.
     * PyTorch 기반의 프레임워크라는 점에서 PyTorch 생태계의 다양한 기능을 활용할 수 있을 것으로 보임. 다만 현재 프로젝트의 구조상 다른 프레임워크와의 상호 운용은 어려울 것으로 보임.
     * ONNX나 TorchScript를 통한 모델 Export 기능이 제공되면 좋을 것 같음. 또한 iOS, macOS 앱 개발시 CoreML로의 변환 등 Apple 생태계와의 연계 방안도 고려해 볼만 함.

        Hacker News 의견

     * CoreNet은 CVNets에서 발전한 것으로, 컴퓨터 비전을 넘어 더 광범위한 애플리케이션을 포괄하게 됨. 이는 LLM을 포함한 기반 모델 학습을 용이하게 함.
     * CoreNet의 default_trainer.py를 보면 PyTorch의 Tensor를 사용하지만 자체 학습 방법을 구현하고 있음. 자체 LR 스케줄러와 옵티마이저를 구현하고, 호출자는 선택적으로 PyTorch의 Adam을 사용할 수 있음.
     * 기존 프레임워크와 협력하는 대신 처음부터 구축하는 것은 흥미로운(아마도 매우 Apple스러운) 선택임.
     * MLX 예제는 현재 추론만 가능한 것 같음. MLX 특화 구현을 위한 착륙장이 될 수 있을 것으로 보임.
     * 최근 Datakalab과 DarwinAI 인수를 고려할 때 앞으로 1년 동안 어떻게 진행될지 흥미로움.
     * Apple은 Jax 위에 구축된 axlearn 라이브러리도 적극적으로 개발 중. Apple의 ML 팀 중 절반은 PyTorch를, 나머지 절반은 Jax를 사용하는 것으로 보임.
     * README에서 CatLIP이라는 새로운 모델도 언급되었지만 링크는 깨져있음.
     * CoreNet은 PyTorch 기반으로 구축됨.
     * MLX는 Apple Silicon에 최적화된 PyTorch와 동등한 것으로 이해됨. CoreNet이 MLX 모델을 분산 학습하기 위한 것인지, 아니면 그 목적이 무엇인지 궁금함.
     * 이 저장소에서 다양한 모델과 사용 방법에 대한 작은 API 예제를 생성할 수 있는 LLM 에이전트가 있으면 좋겠음.
     * Apple M1에서 신경망 학습과 추론을 위해 어떤 라이브러리를 추천하는지? C++ 또는 Rust에서 사용하고 싶고, 신경망은 최대 5M 파라미터를 가질 것임.
     * MPS 백엔드를 사용하는 Huggingface Transformers 대신 이것을 사용하는 이점은 무엇인지?
     * Apple Silicon에서의 학습을 지원하는지 README에서 놓친 것이 아니라면 명확하지 않음.
     * Apple이 LLM 학습에 대한 개방형 정보를 추진하고 있다는 점이 흥미로움. 세상이 변하고 있음.
"
"https://news.hada.io/topic?id=14621","Fluent - 자연스러운 번역을 위한 로컬라이제이션 시스템","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Fluent - 자연스러운 번역을 위한 로컬라이제이션 시스템

     * 비대칭 로컬라이제이션 : 필요한 경우에만 성별/대소문자를 사용하여 자연스러운 번역을 추구. 표현력은 원어의 문법에 제한되지 않음
     * 점진적 향상 : 각 번역은 독립적으로 관리되어 다른 로케일에 영향을 주지 않음. 다른 언어에 영향을 주지 않고 반복적으로 번역을 개선할 수 있음
     * 다양한 기능 : 날짜, 시간 및 숫자 서식. 복수 카테고리. 양방향 지원. 사용자 서식. 읽기 쉬운 문법. 런타임 번역 및 재번역. 강력한 오류 처리
     * 아파치 라이센스 오픈소스. 서버 구현체는 JS, Python, Rust로 제공되며 React 바인딩도 제공

Fluent를 만든 이유

     * 소프트웨어 로컬라이제이션은 영어 사본에 일대일로 매핑하는 번역이라는 낡은 패러다임이 지배해 왔음
     * 원어의 문법은 번역의 표현력에 제한을 가함
     * 이러한 패러다임을 바꾸기 위해 Fluent를 만들었음
          + 번역가는 개발자에게 허락을 구하지 않고도 언어의 모든 표현력을 사용할 수 있어야 함
          + Fluent에서는 번역이 비대칭적. 영어로 된 간단한 문자열이 다른 언어로 된 복잡한 다중 변형 번역으로 매핑될 수 있음
     * Fluent를 사용하면 소스 언어와 관계없이 다양한 언어의 문법과 스타일을 충족할 수 있음
     * 독립적임
          + 한 언어가 고급 로직의 이점을 활용한다고 해서 이를 적용하기 위해 다른 로컬라이제이션이 필요하지 않음
          + 각 로컬라이제이션은 번역이 얼마나 복잡해지는지를 각각 제어함

   오 예전 1:1 매칭 패러다임에서 벗어난다는게 되게 신기하네요

   자바스크립트 전용 gettext 열화 버전.

   https://github.com/projectfluent/fluent/wiki/Fluent-vs-gettext

   그렇게 말해버리면 이 프로젝트를 너무 가볍게 보는거네요.

   답변이 너무 성의(?)없어서 그렇게 보실수도 있겠네요. 좀 더 성의있게 써보겠습니다.

   비교표는 어차피 비교주체가 누구냐에 따라 정해져있는거라 큰 의미 없지만,

   제가 열화버전이라고 느낀 이유는... 긴 세월동안 많은 사람들에 걸쳐 gettext에 쌓인 노하우들을 존중하지 않는다는 느낌이 들어서 입니다.

   gettext는 C언어만 된다고 했는데 메이저 언어중에 gettext를 지원하지 않는 언어가 뭐가 있죠?
   어순의 문제를 고려해서 키-기반 파라메터를 사용했다는데, 모든 언어가 딕셔너리를 기본으로 내장하고 있는게 아닌데, 그런 언어들은 추가적인 방법(예: 자바라면 Map같은)이 필요해 지는 거죠. gettext는 위치기반이지만 어순 변경에 대해 고려가 되어 있죠.

   주절주절 적었지만,
   사실... 시작부터 맘에 안들었던 이유는 ${...}가 아니라 {$...}였기 때문입니다^^

   개인적으로 ""바퀴를 재발명""하는 걸 몹시 좋아합니다만, 세상에 없던 바퀴를 발명한것처럼 떠벌리는 것은 별로 좋아보이지 않네요.
"
"https://news.hada.io/topic?id=14599","Captable - 스타트업을 위한 지분 관리 플랫폼 오픈소스 (Carta/Pulley의 대체제)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Captable - 스타트업을 위한 지분 관리 플랫폼 오픈소스 (Carta/Pulley의 대체제)

     * Cap Table 관리 플랫폼
          + 직원, 계약자 및 기타 이해관계자에게 주식을 쉽게 발행 및 일정 관리
          + 누가 회사의 지분을 몇 퍼센트 소유하고 있는지, 발행된 주식은 얼마나 되는지 등 회사의 소유 구조를 추적
     * 투자 라운드를 관리하고, 투자자 계약을 트래킹
     * 회사 상황에 대해서 투자자 및 팀원에게 정기적인 업데이트 보내기
     * 전자 서명기능으로 문서에 사인 받기 (SAFE, NDA 등의 문서등)
     * 가상 데이터 룸 : 팀, 투자자, 고문, 이사회 구성원과 프레젠테이션 자료, 재무 정보 및 기타 중요한 문서를 공유
     * Open Cap Table Format(OCF)을 따름
     * Next.js + NextAuth.js + Prisma + Tailwind CSS + tRPC + @shadcn/ui
"
"https://news.hada.io/topic?id=14578","실수로 아이슬란드 대통령 출마 사태","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          실수로 아이슬란드 대통령 출마 사태

아이슬란드 대통령 후보 등록 과정의 사용자 경험 문제

  디지털 후보 등록 과정의 문제점

     * 아이슬란드 대통령 후보가 되기 위해서는 아이슬란드 국적자이며 35세 이상이어야 하고, 1,500명의 지지자를 확보해야 함
     * 역사상 처음으로 디지털 방식으로 후보 등록 과정이 진행됨
     * 많은 사람들이 실수로 후보 등록을 하게 되는 문제가 발생

  실수로 후보 등록을 하게 된 사람들

     * 82명의 사람들이 현재 후보 등록을 위한 지지자를 모으고 있음
          + 코미디언, 모델, 세계 최초 양팔 이식 수술을 받은 사람 등이 포함됨
     * 이 중 11명 이상이 실수로 후보 등록을 했다는 사실을 알게 됨
     * 한 사람은 기자와의 인터뷰에서 ""나는 절대 대통령 후보로 출마할 생각이 없었다. 이건 그냥 실수였다""라고 말함

  실수로 후보 등록을 하게 된 원인

     * 콘텐츠 디자인의 문제가 주요 원인으로 지적됨
     * 후보 등록 페이지가 후보 등록과 후보 지지를 위한 두 가지 목적으로 사용되고 있었음
     * 후보 등록을 위한 기준과 ""로그인"" 버튼이 페이지 상단에 눈에 띄게 배치되어 있었음
     * 사람들은 페이지 상단의 긴 텍스트를 건너뛰고 ""로그인"" 버튼을 클릭하여 실수로 후보 등록을 하게 됨

  개선된 후보 등록 페이지

     * 40명 이상의 후보가 등록되자 의심을 품은 사람들이 생겨남
     * 디지털 아이슬란드는 빠르게 페이지를 재설계하고 후보 등록을 위한 별도의 페이지를 만듦
     * 개선된 페이지에서는 후보 목록과 후보 지지를 위한 링크가 명확하게 보임
     * 후보 등록을 위한 링크는 페이지 하단으로 이동됨
     * ""로그인"" 버튼 대신 ""후보 등록을 위한 지지자 모으기""라는 명확한 링크로 대체됨

주요 교훈

     * Generic한 버튼 사용에 주의할 것
     * CTA는 명확하고 설명적이어야 함
     * 너무 많은 정보로 사람들을 압도하지 말 것
     * 시각적 계층 구조와 명확한 제목을 사용하여 페이지를 섹션으로 나눌 것

GN⁺의 의견

     * 사용자 경험 디자인이 민주주의에도 영향을 줄 수 있다는 점이 흥미로움. 웹사이트나 앱 뿐 아니라 정부나 공공기관의 서비스 설계 시에도 사용자 중심 디자인이 중요함을 보여주는 사례임.
     * 복잡한 절차를 갖는 서비스일수록 사용자의 액션 플로우를 명확히 파악하고 그에 맞게 UI를 설계하는 것이 중요함. 사용자가 의도치 않게 잘못된 행동을 할 수 있는 여지를 최소화해야 함.
     * 정부 서비스 이용이 점점 온라인으로 확대되고 있는 만큼, 공공 서비스 부문의 UX 디자이너 수요가 커질 것으로 보임. 정부 서비스의 디지털 전환을 위해서는 기술 개발과 함께 UX 설계 역량 확보도 필수적일 것임.

   초보 디자이너가 하기 쉬운 실수: 배경과 잘 조화되는 CTA버튼

        Hacker News 의견

     * 후보 등록 과정과 실제 사용 과정이 분리되지 않은 것이 문제임. 등록 과정은 완전히 분리되어야 하며, 서면 양식도 받는 경우 후보자로부터 더 많은 추적이 필요함.
     * 아이슬란드 대통령이 일반 승객처럼 상업용 항공편을 이용한다는 TV 방송을 보고 의아해했으나, 나중에 터크스 케이커스 제도 대통령이 상업용 항공편에 탑승한 것을 보고 자신의 생각이 잘못되었음을 깨달음.
     * 이는 분명 나쁘고 혼란스러운 디자인임. 이와 유사한 사례로는 하와이에서 발생한 UX 오류와 2000년 선거의 ""나비 투표"" 문제 등이 있음.
     * Medium에서 모바일 핀치-투-줌 기능을 차단하는 것은 성가신 디자인 선택이며, 데스크톱 스크린샷이 포함된 기사에서는 특히 나쁨.
     * 페이지가 영어로 되어 있다는 점이 가장 놀라움. 아이슬란드 사람들은 영어에 능통하지만, 모두 아이슬란드어로 말하고 읽음.
     * ""Register to collect endorsements""라는 문구는 누구의 지지를 수집하는지 명시하지 않아 오해의 소지가 있음. ""후보로 등록하여 지지를 모으세요""라고 하는 것이 더 명확했을 것임.
     * 이 나라에서 누구나 대통령 후보로 등록할 수 있다는 사실에 주목해야 함. 우리 나라에서도 리더십 직책에 서로를 자유롭게 지명하고 지지할 수 있는 권리를 위해 싸워야 함.
     * 후보 지지 목록의 시작 부분에 나타나는 것과 성이 ""A""로 시작하는 것 사이에 상관관계가 있는 것으로 보임.
     * ""사람들은 읽지 않는다""는 문구를 모든 디자이너의 손등에 새겨야 함. 물론 그들은 읽기를 통한 깊은 참여가 필요한 무언가를 설계하기 전에 그것을 읽지 않을 것임.
"
"https://news.hada.io/topic?id=14574","효율적인 소프트웨어 개발에서 길을 잃어버린 것일까?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      효율적인 소프트웨어 개발에서 길을 잃어버린 것일까?

Microsoft Word 파일을 Google Docs에서 여는 것의 어려움

     * 필자의 아버지가 Microsoft Word 문서 파일을 작업하기 위해 노트북에 Word를 설치해야 했음
     * 필자는 아버지에게 Google Docs를 제안함
          + 아버지가 이미 Google 계정을 가지고 있고, 사용하기 쉬우며, 클라우드 기반이고 자동 동기화되기 때문
     * 그러나 약 30MB 크기의 문서 파일을 Google Docs에서 열었을 때 타이핑한 내용이 화면에 표시되는데 수 초가 걸리는 등 Chrome이나 Google Docs가 감당하기 어려웠음
     * 결국 LibreOffice를 설치했고, 그 곳에서는 매우 빠르게 작동함

오늘날 소프트웨어 표준에 대한 고찰

     * 성능 면에서 소프트웨어 개발이 퇴보하고 있는 것은 아닌지 의문이 듦
          + 최신의 멋진 모던한 도구, 프레임워크, 언어들이 효율성 면에서 우리를 퇴보시키고 있는 것은 아닌지
     * 웹앱과 브라우저를 다루기 위해 하드웨어 사양이 증가하고 있음
          + 순수 네이티브 앱만 있었다면 불필요했을 것
          + 모바일 폰이 8GB나 16GB의 RAM을 필요로 하는 이유가 무엇인지
     * 웹은 UI 렌더링 엔진 래퍼 대신 네이티브 렌더링이 필요함
          + 사양이 좋은 노트북에서도 30MB 크기의 Word 파일을 Google Docs에서 열 수 없는 이유는 브라우저가 더 많은 메모리와 CPU 사용량을 필요로 하기 때문
     * 우리는 최적화되고 효율적이며 성능이 좋은 애플리케이션을 개발하는 방법을 잃어버린 것 같음. 이 문제를 해결해야 함
          + 1966년의 2KB RAM Apollo 컴퓨터는 인류를 달에 보냈지만, 2024년에는 브라우저에서 30MB 문서 파일을 다룰 수 없음
     * 오늘날 업계의 모든 사람들이 미래를 위해 PWA 애플리케이션에 집중하고 있기에 웹에 초점을 맞추고 있음

API 최적화의 중요성

     * API 성능이 앱의 성능에 기여할 수 있기에 웹과 네이티브 앱 모두에서 API 최적화가 중요함
     * 필자의 제품인 Onradar(https://onradar.io)는 API 모니터링을 통해 최적화에 도움을 줌
          + Onradar는 API에 대한 가동 시간 모니터링과 플로우 기반 모니터링을 제공
          + 플로우 에디터에서 관련 API로 가능한 사용자 시나리오를 만들고 Onradar가 24/7 테스트하도록 할 수 있음
          + 인시던트 발생 시 알림을 제공함

GN⁺의 의견

     * 구글 독스와 MS 오피스 간 호환성 문제는 오랫동안 지적되어 온 이슈임. 아직도 완벽하게 해결되지 않고 있어 사용자들에게 불편을 주고 있음. 두 회사가 좀 더 적극적으로 협력하여 이 문제를 해결했으면 함
     * 웹앱의 성능 문제가 하드웨어 스펙의 증가로 해결되는 것은 근본적인 해결책이 아님. 한정된 자원을 효율적으로 사용하는 소프트웨어 개발이 필요함
     * 네이티브 앱을 주장하는 것도 한 방법이지만, 웹의 장점을 살리면서 웹앱의 성능을 개선하는 것이 더 나은 방향일 것임. 웹앱의 휴대성과 접근성은 포기하기 어려운 장점임
     * API 최적화와 모니터링은 전체 시스템 성능 향상에 기여할 수 있는 중요한 요소임. 특히 마이크로서비스 아키텍처가 대세가 되고 있는 요즈음 API 레이어에 대한 관심은 더욱 커질 수 밖에 없을 것임
     * Apollo 시절과 비교하는 것은 적절치 않아 보임. 우주선 제어와 워드 프로세싱을 같은 선상에 놓기는 어려움. 요즘 소프트웨어는 워낙 방대하고 복잡해졌기에 Apollo 시절의 효율성을 기대하기는 힘들 것임

        Hacker News 의견

   요약:
     * Apple과 Microsoft는 개발자 계정 필요, 바이너리 서명용 인증서 구매, 수익 공유 등으로 native app 개발을 방해하고 있음. 웹은 훨씬 간단하고 저렴한 대안임.
     * Moore의 법칙 덕분에 소프트웨어는 수십 년 동안 하드웨어 발전에 무임승차해왔음. 이는 축복이자 저주였음.
     * 개발자들은 완전히 통합되고 연결된 보편적 컴퓨팅 플랫폼(웹)을 좋아함. 사용자들은 성능이 충분히 좋으면 크게 신경 쓰지 않음. 좋은 소프트웨어를 만드는 것은 중요하지 않음.
     * 비즈니스 결정들이 주요 원인임:
         1. 클라우드로 이동 - 기업은 정기 결제를 선호하고, 고객은 직접 IT 팀을 고용하지 않아도 됨
         2. 고객들이 온프레미스 SW 업그레이드를 거부하여 유지보수 주기가 길어지고 패치가 끝없이 이어짐
         3. 웹 개발은 여러 플랫폼 대응 개발에 비해 비용이 적게 듦
     * 90년대 초 MS Word는 플로피 디스크로 배포되었고 실행 파일은 2MB였음. 지금은 GB 단위로 측정되지만 무엇이 개선되었는지 모호함.
     * 경량 SW는 있지만 잘 선택되지 않음. Lua, SQLite, Fennel, Althttpd, Fossil, Mako Server 등 훌륭한 경량 SW가 있음.
     * 프론트엔드의 경우 네이티브 앱과 웹 페이지를 선호하지만, Tiddlywiki 같은 웹앱도 나름의 장점이 있음. 하지만 여전히 Emacs보다는 리소스를 더 사용함.
     * React 페이지 전환 시 드롭다운 렌더링이 오래 걸리는 사례가 있었음. 결국 리액트 코드를 수정하여 해결함.
     * 회사에서 개발자에게 고성능 장비를 지원하다 보니, 오래된 일반 PC에서는 테스트를 충분히 하지 않게 되는 문제가 있음.
     * ""관용적 코드"", ""성능 최적화는 악의 근원"" 같은 블로그 글을 많이 보고 개발 시간을 더 중요하게 여김. 예전엔 더 빨리 더 나은 코드를 작성하는 개발자들이 있었음.
"
"https://news.hada.io/topic?id=14573","제 가정용 NAS를 위한 새로운 backplane 제작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     제 가정용 NAS를 위한 새로운 backplane 제작

     * PCIe 백플레인 개발 동기
          + Terramaster F2-221 NAS에 NixOS를 설치하면서 운영체제 저장용 외장 USB SSD 연결이 번거로워 내장형 저장장치 설치 방안을 고민함
          + NAS 메인보드에 PCIe x4 슬롯이 있어 이를 활용할 방안을 찾아봄
     * PCIe 백플레인 분석
          + 동일 제조사의 5베이 모델인 F5-422의 리뷰 사진을 분석해 ASMedia ASM1061 PCIe-SATA 컨트롤러 2개로 SATA 포트 수를 확장한 것을 확인함
          + F2-221 메인보드의 PCIe 핀배열을 역추적해 ASM1061용 PCIe 레인이 배선되어 있음을 확인함
          + PCIe 신호 분석을 통해 TX, RX, REFCLK 페어를 식별하고 핀배열표를 작성함
          + 백플레인의 전원부 회로를 분석해 핫플러그용 로드스위치와 슬로우스타터로 구성되어 있음을 파악함
     * 프로토타입 제작
          + PCIe 1레인을 활용해 NVMe M.2 SSD를 장착하기로 결정함. SATA보다 저렴하고 구현이 간단함
          + 기존 백플레인의 크기와 나사 위치 제약사항을 고려해 커넥터와 컴포넌트를 배치하고 PCB를 설계함
          + JLCPCB에 주문 제작한 PCB에 부품을 실장하고 NAS에 장착해 테스트한 결과 부팅 가능함을 확인함
     * 최종 버전 제작
          + 프로토타입의 문제점을 수정하고 불필요한 테스트 포인트를 제거한 최종 버전 PCB를 제작함
          + NAS에 장착 후 문제없이 동작하는 것을 확인하고 오랫동안 안정적으로 사용 중
          + 최종 설계 파일을 GitHub에 공개함

GN⁺의 의견

     * Terramaster NAS의 내부 구조와 백플레인 설계에 대해 상세히 분석한 흥미로운 사례임. 제조사에서 제공하는 정보가 부족한 상황에서 리버스엔지니어링을 통해 원하는 기능을 구현한 노력이 돋보임
     * 기존 PCIe 레인을 활용해 저렴하고 빠른 NVMe SSD를 OS 부팅 드라이브로 활용한 것이 인상적임. SATA 컨트롤러를 추가하는 것보다 구현이 간단하면서도 충분한 성능을 얻을 수 있는 합리적인 선택으로 보임
     * 핫플러그 기능을 위한 로드스위치와 슬로우스타터 회로 분석 내용이 인상적임. 전원부 설계에서 고려해야 할 사항을 잘 짚어주는 사례임
     * 이 글의 PCB 설계 과정이 유사한 니즈를 가진 다른 NAS 사용자들에게 좋은 참고가 될 것 같음. 다만 Terramaster의 보증 문제나 NAS 운영체제 호환성 등 함께 고려해야 할 요소도 있을 것으로 보임
     * 저자의 PCB 설계 경험이 많지 않은 것으로 보이는데 단계적인 프로토타이핑과 문제 해결 과정이 인상적임. 이러한 시행착오를 통한 학습이 전자 설계 실력 향상에 도움이 될 것으로 보임

        Hacker News 의견

   요약:
     * DFN 패키지 납땜 시 현미경 없이 전원과 접지 사이의 단락만 확인하고 휴대폰 카메라로 근접 촬영함. 스텐실 없이 DFN 패키지를 납땜하기 위해 패드에 과량의 솔더 페이스트를 올리고 IC를 눌러 넣으면 Hot Air Station의 열로 솔더가 녹고 IC가 위로 뜨면서 집게로 눌러 과량의 솔더가 솔더 마스크 위로 밀려나오게 하는 방법이 효과적이었음. 이는 미친 듯하지만 재미있는 방법론임.
     * 소비자용 NAS 제작에 더 많은 표준화가 이루어지길 바람. 몇 년 후 백플레인을 교체할 수 있도록 ASUSTOR에 Mini ITX 호환 백플레인/어댑터 제작을 제안함. 마더보드를 교체하여 1Gbps NAS를 2.5Gbps 또는 10Gbps로 업그레이드할 수 있다면 섀시의 수명을 연장할 수 있음.
     * 기타나 하드웨어를 개조할 때처럼 실제 돈을 잃을 위험이 있는 프로젝트에 사람들이 기꺼이 깊이 파고드는 것에 감탄함. 하드웨어나 소프트웨어를 더 쉽게 수정할 수 있는 해킹 가능한 소형 박스에 대한 시장이 별로 없는 이유가 궁금함.
     * NAS의 외장 드라이브 문제를 벨크로로 NAS 위에 부착하여 해결함.
     * 레고로 만든 사제 NAS 케이스보다 이 프로젝트가 훨씬 멋져 보임. USB 하드 드라이브를 허브에 연결하고 Nvidia Jetson에 연결하여 자체 제작함.
     * 5베이 버전의 동일한 NAS에 Samsung USB 스틱을 사용하여 TrueNAS Scale을 설치함. Tesla 대시캠에 널리 사용되는 제품을 선택하여 내구성을 어느 정도 확보함. CPU 성능이 부족하여 더 강력한 것으로 업그레이드할 계획임.
     * Mac에 ZFS를 설치하여 단일 USB 드라이브에서 사용해 보았으나, 파일 복사 시 시스템이 응답하지 않고 마우스, 키보드가 끊기는 등 I/O 성능이 크게 저하됨. CPU 사용량이 400%까지 치솟았으나 정확한 원인은 알 수 없었음.
     * 추측, 시행착오, 회로 검사, 로드 스위치 IC의 대체 등을 통해 놀랍고 우아한 결과를 얻어냄.
     * 아두이노를 모든 것에 접착제로 붙이는 것이 아닌 훌륭한 프로젝트임.
"
"https://news.hada.io/topic?id=14533","SVG 뷰어 - SVG 파일 조회, 편집 및 최적화 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    SVG 뷰어 - SVG 파일 조회, 편집 및 최적화 도구

SVG 이미지 파일 분석

     * 가로 400px, 세로 400px 크기의 SVG 이미지 파일
     * 기본 구조:
          + 가장 바깥쪽에 width=""124"", height=""124"" 의 사각형이 있음
          + rx=""24"" 속성으로 둥근 모서리 처리
          + fill=""#F97316"" 속성으로 주황색 배경으로 칠해짐
     * 주요 도형들:
          + <path> 태그로 흰색의 다각형 모양이 그려짐
               o d 속성에 패스 좌표 정보가 들어있음
               o fill=""white"" 로 흰색으로 채워짐
          + <circle> 태그로 검은색 원이 그려짐
               o cx=""63.2109"" cy=""37.5391"" r=""18.1641"" 로 위치와 크기 지정
               o fill=""black"" 으로 검은색으로 채워짐
          + <rect> 태그로 반투명한 직사각형이 45도 회전되어 그려짐
               o opacity=""0.4"" 로 투명도 설정
               o fill=""#FDBA74"" 로 옅은 주황색으로 채워짐
               o transform=""rotate(-45 81.1328 80.7198)"" 로 회전 변환
     * 파일 크기 최적화:
          + 원본 578 bytes에서 493 bytes로 15% 감소

GN⁺의 의견

     * SVG는 벡터 그래픽 포맷이라 확대/축소에도 깨짐 없이 선명한 장점이 있음. 반면 JPEG, PNG 등의 비트맵 이미지에 비해 복잡도가 높으면 파일 크기가 커지는 단점.
     * 파일 사이즈가 작아 웹에서 로딩 속도가 빠를 것 같음. 그러나 복잡한 그림이라면 오히려 PNG가 유리할 수 있음.
     * rx, circle, rotate 등 다양한 기능을 활용해 단순함 속에서도 입체감을 표현한 것이 인상적.
     * 주황색 배경에 흰색, 검정색을 사용해 색상 대비를 주어 가독성 높임.
     * 아이콘, 로고 등의 용도로 제작된 듯. 옅은 주황색 도형의 의미나 용도가 궁금함.

        Hacker News 의견

     * SVG 최적화 도구인 SVGOMG가 또 다른 유용한 웹 기반 SVG 도구로 소개됨
     * Checker Software라는 밴쿠버 소재의 작은 회사에서 이 도구를 포함한 여러 소프트웨어 도구를 개발함
     * UI가 이해하기 쉽고, 변경사항에 대한 명확한 피드백을 제공하여 SVG 사용 시 발생하는 작은 문제들을 해결하는데 유용할 것으로 보임
          + 예를 들어, 로딩 시 SVG가 의도한 크기보다 순간적으로 늘어났다 줄어드는 문제 등
     * 캔버스의 줌 기능이 무한대로 가는 재미있는 버그(?)가 있음
     * SVG는 매우 강력한 도구로, 최근 Safari와 iOS에서 filter: drop-shadow를 사용한 parallax 투명 이미지 렌더링 문제를 SVG 필터와 feGaussianBlur를 활용해 해결한 사례도 있음
     * SVG를 위한 더 많고 더 나은 도구가 필요한 상황에서, 이 도구의 등장을 반기는 분위기임
     * 텍스트에서 SVG를 생성할 때 이 에디터가 생성된 콘텐츠를 파싱하지 못했지만, CodeBeautify의 SVG 뷰어는 잘 작동했다는 의견도 있음
     * 이런 작은 도구들이 해커 뉴스(HN)의 정신에 잘 부합한다는 평가를 받음
"
"https://news.hada.io/topic?id=14507","FCC, 망 중립성 규칙 복원 투표","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          FCC, 망 중립성 규칙 복원 투표

   요약:

FCC가 망 중립성 규칙 복원을 위해 투표

     * FCC는 브로드밴드 제공업체에 대한 정부 감독을 확대하고 소비자의 인터넷 접근을 보호하는 규정을 복원하기 위해 투표했음.
     * 이른바 망 중립성 규칙은 거의 10년 전 오바마 행정부에서 처음 도입되었으며, Verizon이나 Comcast 같은 인터넷 서비스 제공업체가 Netflix나 YouTube 같은 경쟁사의 서비스 전송을 차단하거나 저하시키는 것을 방지하는 것을 목표로 함.
     * 바이든 대통령이 임명한 5인 위원회는 3대 2로 당 노선을 따라 투표를 통해, 브로드밴드를 전화나 수도처럼 규제되는 공공재적 서비스로 선언하는 규칙을 부활시켰음.
     * 이 규칙은 또한 FCC에게 브로드밴드 제공업체에게 장애 보고 및 대응을 요구하고, 제공업체의 보안 문제에 대한 FCC의 감독을 확대할 수 있는 능력을 부여함.

브로드밴드 제공업체의 반발 예상

     * 브로드밴드 제공업체들은 복원된 규칙을 뒤집기 위해 소송을 제기할 것으로 예상됨.
     * 브로드밴드 로비 단체인 USTelecom의 대표는 브로드밴드 소비자들이 수십 년 동안 개방된 인터넷을 누려왔기에 이는 문제가 되지 않는다고 주장하며, 법원을 포함한 모든 가능한 방안을 모색할 것이라고 말함.

망 중립성 규칙의 핵심 목적

     * 이 규제의 핵심 목적은 인터넷 서비스 제공업체가 소비자들이 웹사이트를 방문하고 온라인 서비스를 이용할 때 경험의 품질을 제어하는 것을 방지하는 것임.
     * 규칙이 제정될 당시 Google, Netflix 등 온라인 서비스 업체들은 브로드밴드 제공업체들이 자사 서비스에 대한 접근을 늦추거나 차단할 동기가 있다고 경고했었음.
     * 소비자 및 언론 자유 단체들은 이러한 견해를 지지함.

GN⁺의 의견

     * 망 중립성은 인터넷 생태계의 공정성과 개방성을 위해 중요한 원칙임. 하지만 정부 규제가 혁신을 저해할 수 있다는 우려도 있음.
     * 기술이 빠르게 발전하는 상황에서 10년 전의 규제가 여전히 유효할지는 의문임. 메타버스, Web3 등 새로운 인터넷 기술 환경에 맞는 규제 체계를 고민해 볼 필요가 있어 보임.
     * 한편 국내에서도 망 중립성 논의가 필요해 보임. 통신사의 자회사인 CP들에게 특혜를 주는 등의 문제가 있어왔기 때문. 투명하고 공정한 인터넷 생태계를 위한 제도적 장치 마련이 시급함.

        Hacker News 의견

     * Net Neutrality 복원에 대한 의문점: 복원에 따른 실질적인 변화가 없었던 것으로 보이며, 이슈에 대한 관심도 사라진 상황에서 갑작스러운 복원 결정에 대한 의문이 제기됨
     * TikTok 등 외국계 소셜미디어 금지 권한 부여 법안과의 연관성 추측: FCC의 ISP 규제 권한이 있음에도 불구하고 새로운 법안이 통과된 것에 대한 의문이 제기됨
     * FCC 발표문(PDF)에 대한 링크 공유: https://www.fcc.gov/document/fcc-restores-net-neutrality
     * Net Neutrality 이슈의 장기 지속성: 10년 넘게 반복되는 Net Neutrality 논쟁의 양상에 대한 언급
     * FCC의 국가안보 조항에 대한 우려:
          + 모호한 조항 내용과 TikTok 강제 매각 시점과 맞물려 나온 것에 대한 우려 표명
     * Net Neutrality 복원 가치에 의문을 제기하는 의견에 대한 놀라움 표현
     * 새 정부 출범 시 번복 가능성에 대한 우려
     * 민주주의의 한계와 Net Neutrality 수호의 어려움:
          + Net Neutrality를 위해 많은 노력을 기울여도 쉽게 번복될 수 있음을 지적
          + 시간이 지날수록 더 힘든 싸움이 될 것으로 예상
     * 미국 법 제정 절차에 대한 문제 제기:
          + FCC, FTC 등 기관 결정과 대통령령 위주의 정책 결정이 민주공화국 운영 방식으로 적절치 않다는 의견 개진
"
"https://news.hada.io/topic?id=14564","Ollama v0.1.33 - Llama 3 + Phi 3 + Qwen 110B 지원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Ollama v0.1.33 - Llama 3 + Phi 3 + Qwen 110B 지원

     * 신규 모델 지원
          + Llama 3: Meta의 새로운 모델이자 현재까지 가장 성능이 뛰어난 개방형 LLM
          + Phi 3 Mini: Microsoft의 새로운 38억 개의 파라미터를 갖춘 가벼운 오픈형 모델
          + Moondream: 엣지 디바이스에서 효율적으로 실행되도록 설계된 소형 비전 언어 모델
          + Dolphin Llama 3: 라마 3 기반으로 에릭 하트포드가 훈련한 무수정 모델. 다양한 교육, 대화, 코딩 기술 포함
          + Qwen 110B: 평가에서 뛰어난 성능을 보인 100B 매개변수 크기의 모델(알리바바)
     * 버그들 수정
          + 모델이 종료되지 않아 API가 중단되던 문제 수정
          + 애플실리콘 맥에서 메모리 부족 오류 수정
          + Mixtral 아키텍처 모델 실행시 메모리 부족 오류 수정
     * 실험적인 동시성 기능
          + OLLAMA_NUM_PARALLEL: 단일 모델에 대해 여러 요청을 동시에 처리
          + OLLAMA_MAX_LOADED_MODELS: 여러 모델을 동시에 로드
          + 환경 변수 설정 필요
               o OLLAMA_NUM_PARALLEL=4 OLLAMA_MAX_LOADED_MODELS=4 ollama serve

   다중 모델 사용이 필요했는데 가능해졌네요. ^^=b
"
"https://news.hada.io/topic?id=14617","Jane Street 채권 투자설명서의 주요 내용과 시사점","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Jane Street 채권 투자설명서의 주요 내용과 시사점

     * Jane Street의 규모가 엄청나게 크고 계속 성장하고 있음
          + 2023년 북미 주식 거래의 10.4%를 차지하며 Citadel Securities에 근접하고 있음
          + 전세계 20개국 이상에서 모든 거래량의 2% 이상 차지
          + 작년 $32조 규모의 옵션을 거래하며 Options Clearing Corporation 계약량의 7.6%를 차지
          + ETF 시장조성에 특히 강점을 보이며, 월평균 ETF 거래량이 $5,270억에 달해 미국과 유럽 ETF 거래량의 상당 부분을 차지
          + 특히 채권 ETF에서 41%의 1차 시장 활동을 차지하며 은행이 오랫동안 지배해온 회사채 거래 영역에 진입
     * Jane Street의 수익성이 엄청남
          + 1분기에 $44억의 순거래수익을 기록하고, 작년에는 $105억을 기록하며 순이익률이 70% 이상
          + 2023년 총수익이 $219억으로 전년 대비 34% 증가하여, 작년 주요 글로벌 투자은행의 주식, 채권, 통화, 상품 거래 수익을 모두 합친 것의 1/7 수준
          + 직원 1인당 평균 $400만의 순수익을 내며, 트레이더 1인당 평균 $2,200만의 조정 EBITDA 기록
     * Jane Street의 대차대조표 규모가 엄청나게 커짐
          + 2024년 말 총자산이 34% 증가한 $1조 4,020억에 달해, ""순수"" 초고빈도 거래회사와는 차이를 보임
          + 자본금의 80%가 직원 지분에서 나오며, 작년 말 $2조 1,300억에 달함
          + 1분기 호실적으로 현재 회원 자본이 $2조 4,000억 이상
     * Jane Street 직원들이 엄청난 보수를 받음
          + 작년 공개된 보상 및 복리후생비 $24억을 기준으로 직원 1인당 평균 $90만 이상
          + 지난 2년간 이직률이 6%에 불과한 것도 업계 최고 수준의 급여 때문일 것으로 추정됨
          + 파트너 40명의 평균 근속연수가 16년이며, 그 중 몇 명은 억만장자일 것으로 보임
     * Jane Street는 매우 신중함
          + 중앙집중식 위험 관리, 꼬리 위험 헤지를 위한 옵션 활용 등 재난을 피하는데 초점
          + 개인 P&L이 아닌 회사 전체 기여도에 따라 보상하여 위험 관리 중시
          + 위험 관리 시스템이 오히려 수익 기회를 제한할 수도 있다고 경고
     * Jane Street는 거의 모든 분야에서 성장하기를 원함
          + 전반적인 속도 향상, 주식 도매 사업 성장, 옵션 도매 사업 진출, 채권 거래 확대 등을 계획 중

GN⁺의 의견

     * Jane Street의 성장세와 수익성이 매우 인상적이며, 특히 ETF 시장조성과 채권 거래 부문에서의 성과가 돋보임. 다만 이런 성장이 지속가능할지, 자본시장의 변동성에 어떻게 대응할지 주목됨
     * 직원들에 대한 파격적인 보상이 우수 인재 유치와 유지에 크게 기여하는 것으로 보이나, 장기적으로는 인건비 부담이 될 수도 있음
     * 중앙화된 위험 관리와 꼬리 위험 헤지 등 신중한 접근 방식이 인상적이며, 회사 차원의 위험 통제가 잘 작동하고 있는 듯함. 다만 지나친 통제가 오히려 투자 기회를 제한할 수 있다는 점은 주의해야 함
     * 기존 투자은행들이 Jane Street의 성장을 견제하려 할 것이므로, 향후 경쟁 구도 변화에 따른 수익성 변화를 면밀히 살펴볼 필요가 있음
     * 특히 전통적인 금융기관들이 Jane Street의 장점을 배우고 모방하려 할 것이므로, 이에 대한 차별화 전략이 필요해 보임. 새로운 데이터, 알고리즘, 기술에 대한 지속적인 투자가 경쟁력 유지에 중요할 것으로 예상됨

        Hacker News 의견

     * Jane Street의 직원 브랜딩이 훌륭한 모델로 언급됨. 잘 배치된 광고/스폰서십, 양질의 팟캐스트 제작, 매월 일관된 퍼즐 게시 등의 브랜딩 투자는 큰 규모의 회사에서만 가능할 것으로 보임
     * Jane Street의 런던 오피스 카페테리아 위 ""Food Bar"" 간판에서 ""d""자가 꺼져있다는 사소한 정보 공유됨
     * 계량 금융 분야에서 일하는 한 댓글러는 오랫동안 업무에 OCaml을 사용하고 싶어했으나, Jane Street처럼 잘 개발된 사유 코드 베이스와 내부 개발 도구 등이 없으면 계량 개발 분야에서 널리 사용되는 다른 언어만큼 생산적일 수 없다는 점이 아쉽다고 언급함
     * 2023년 말 기준 Jane Street의 직원 수는 2631명이며, 회사 자본의 약 80%가 2023년 말 213억 달러로 증가한 직원 지분에서 나온다는 것에 많은 이들이 놀라워함
     * FT 기사 댓글란에서 한 독자가 ""코스 플로팅(연구)과 브레이킹(리스크 관리)이 성공적인 레이스의 필수 요소""라는 친구의 조언을 인용하며, 기업들이 이를 잊을 때 재앙이 발생한다고 덧붙임 (보잉 사례 언급)
     * Jane Street가 OCaml의 꿈을 이어가는 것을 좋아하지만, 그 어떤 회사도 특히 자동화 영역에서 이런 영향력을 가져서는 안 된다는 우려 표명. 한편 그들의 강점이 궁금하다는 의견도 있음
     * Jane Street 관련 OCaml 이야기가 나올 때마다 직원 수를 30-40명 정도로 생각했는데 2613명이라는 사실에 놀라움 표시
     * Jane Street가 OCaml의 가장 큰 포스터 차일드라는 점에서 Blub Paradox가 작용하는 것 아니냐는 의견 제기됨
     * 어제 Reddit의 한 스레드에서 ""어느 회사가 최고의 엔지니어를 보유한 것으로 알려져 있는가?""라는 질문에 Jane St.이 언급되었으며, 그들이 훌륭한 엔지니어를 배출한다는 답변이 있었음
"
"https://news.hada.io/topic?id=14523","HTML 속성(Attributes)과 DOM 프로퍼티(Properties)의 차이점","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             HTML 속성(Attributes)과 DOM 프로퍼티(Properties)의 차이점

HTML 속성과 DOM 속성의 차이점

   HTML 속성과 DOM 속성은 근본적으로 다른 것들임. 같은 이름의 속성과 속성을 가질 수 있지만 서로 다른 값으로 설정할 수 있음.
     * 속성과 속성의 주요 차이점
          + HTML 직렬화: 속성은 HTML로 직렬화되지만 속성은 그렇지 않음
          + 값 타입: 속성 값은 항상 문자열이지만 속성은 모든 타입이 될 수 있음
          + 대소문자 구분: 속성 이름은 대소문자를 구분하지 않지만 속성 이름은 대소문자를 구분함. 하지만 속성 값은 대소문자를 구분함
     * 반영(Reflection)
          + 편의를 위해 대부분의 스펙은 정의된 모든 속성에 대해 속성 등가물을 만듦
          + 속성이 속성을 반영할 때 속성은 데이터의 소스임. 속성을 설정하면 속성이 업데이트되고, 속성에서 읽으면 속성을 읽음
          + 하지만 일부 반사체는 더 복잡함. 때로는 속성 이름과 반영하는 속성 이름이 다르기도 함
     * 유효성 검사, 타입 강제 변환 및 기본값
          + 속성에는 유효성 검사와 기본값이 있지만 속성에는 없음
          + 일부 속성은 타입 강제 변환을 수행함
     * input 필드의 value
          + value 속성과 value 속성이 있지만 value 속성은 value 속성을 반영하지 않음. 대신 defaultValue 속성이 value 속성을 반영함
          + value 속성은 어떤 속성도 반영하지 않음. 이는 드문 일이 아니며 offsetWidth, parentNode 등 많은 속성이 그러함
          + value 속성은 처음에는 defaultValue 속성을 따름. 그런 다음 JavaScript나 사용자 상호작용을 통해 value 속성이 설정되면 내부 값으로 전환됨
     * 속성은 구성을 위한 것이어야 함
          + 속성은 구성을 위한 것이어야 하고, 속성은 상태를 포함할 수 있어야 함
          + light-DOM 트리는 단일 소유자를 가져야 함
          + <details>와 <dialog> 요소는 open 상태를 open 속성으로 표시하고, 브라우저는 사용자 상호작용에 대한 응답으로 이 속성을 자체적으로 추가/제거함. 이는 설계상 실수라고 봄
     * 프레임워크의 차이점 처리
          + Preact와 VueJS는 propName in element이면 prop을 속성으로 설정하고, 그렇지 않으면 속성을 설정함. 속성보다 속성을 선호함
          + React는 그 반대로 함. 속성을 선호하는 미리 정의된 경우를 제외하고는 속성을 설정함.
          + lit-html은 속성과 속성의 구분을 유지하며, 속성 대신 속성을 설정하려면 이름 앞에 .을 붙여야 함

GN⁺의 의견

     * HTML 속성과 DOM 속성의 차이점을 아는 것은 저수준의 DOM 작업 시 중요함. 대부분의 경우에는 큰 차이가 없지만, 프레임워크 사용 시 주의가 필요함
     * 속성은 설정(configuration)을, 속성은 상태(state)를 나타내는 것으로 구분하는 것이 바람직해 보임. 최근 일부 HTML 요소에서는 이를 지키지 않고 있어 아쉬움
     * 특히 React에서 사용자 정의 엘리먼트를 사용할 때는 주의가 필요함. React는 사용자 정의 엘리먼트의 속성을 속성 대신 속성으로 설정하기 때문에, 속성 전용인 것들은 작동하지 않을 수 있음. 이는 React 19에서 개선될 예정
     * Preact, Vue, React, lit-html 등 주요 프레임워크들이 속성과 속성을 어떻게 처리하는지 비교해 보는 것도 흥미로움. 각 프레임워크의 철학과 디자인 결정이 반영되어 있음
     * 웹 표준과 브라우저의 구현이 항상 개발자 친화적이지는 않음. <input> 요소의 value 속성과 속성 같은 경우가 대표적. 하위 호환성 때문에 쉽게 바꾸기는 어려울 것 같지만, 앞으로는 좀 더 일관성 있는 설계가 되었으면 함

   https://emewjin.github.io/html-attribute-dom-property/

   attribute 와 property를 같은 ""속성"" 으로 번역해 버렸네요..
"
"https://news.hada.io/topic?id=14514","React 19 Beta","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             React 19 Beta

   새로운 기능
     * useActionState: 범용적인 Actions 케이스 대응
     * <form> Action Function 지원
     * useFormStatus: 폼 상태 정보 제공
     * useOptimistic: 낙관적 업데이트 제공
     * use: 렌더링 관련 비동기 지원

   주요 개선 사항
     * ref를 props로 사용할 수 있음
     * hyrdation 오류에 대한 더 나은 오류 보고가 가능
     * <Context>를 provider로 사용할 수 있음
     * ref 콜백에 cleanup 함수를 반환할 수 있음
     * useDeferredValue에 초기값을 지정할 수 있음
     * 문서 메타데이터 및 컴포넌트 내에서 스타일시트, 비동기 스크립트 등을 지원

   드디어 웹 컴포넌트 표준이 지원되는군요.
"
"https://news.hada.io/topic?id=14537","OpenVoice: 즉각적인 음성 복제 기술","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        OpenVoice: 즉각적인 음성 복제 기술

OpenVoice V1 소개

     * OpenVoice의 장점은 다음과 같음:
          + 정확한 음색 복제: OpenVoice는 참조 음색을 정확하게 복제하고 여러 언어와 억양으로 음성을 생성할 수 있음.
          + 유연한 음성 스타일 제어: OpenVoice는 감정과 억양 같은 음성 스타일과 리듬, 휴지, 억양 등 다른 스타일 파라미터를 세부적으로 제어할 수 있음.
          + Zero-shot 다국어 음성 복제: 생성된 음성의 언어와 참조 음성의 언어 모두 대규모 화자 다국어 학습 데이터셋에 제시될 필요가 없음.

OpenVoice V2 소개

     * 2024년 4월 OpenVoice V2가 출시되었으며, V1의 모든 기능을 포함하고 다음과 같은 기능이 추가됨:
          + 더 나은 오디오 품질: OpenVoice V2는 더 나은 오디오 품질을 제공하는 다른 학습 전략을 채택함.
          + 기본 다국어 지원: 영어, 스페인어, 프랑스어, 중국어, 일본어, 한국어가 OpenVoice V2에서 기본적으로 지원됨.
          + 무료 상업적 사용: 2024년 4월부터 V2와 V1은 MIT 라이선스에 따라 출시되었으며, 상업적 사용이 무료임.

OpenVoice 사용 현황

     * OpenVoice는 2023년 5월부터 myshell.ai의 즉각적인 음성 복제 기능을 제공해 왔음.
     * 2023년 11월까지 음성 복제 모델은 전 세계 사용자가 수천만 번 사용했으며, 플랫폼에서 폭발적인 사용자 증가를 목격함.

주요 기여자

     * Zengyi Qin (MIT, MyShell)
     * Wenliang Zhao (Tsinghua University)
     * Xumin Yu (Tsinghua University)
     * Ethan Sun (MyShell)

사용법

     * 자세한 사용 방법은 usage를 참조.

일반적인 이슈

     * 일반적인 질문과 답변은 QA를 참조.
     * 질문과 답변 목록은 정기적으로 업데이트 될 예정.

커뮤니티 참여

     * Discord 커뮤니티에 가입하고 가입 시 'Developer' 역할을 선택하면 개발자 전용 채널에 대한 독점적 액세스 권한을 얻을 수 있음.
     * 유익한 토론과 협업 기회를 놓치지 말 것.

인용

     * 해당 구현은 TTS, VITS, VITS2와 같은 몇 가지 우수한 프로젝트를 기반으로 함.
     * 그들의 훌륭한 작업에 감사.

라이선스

     * OpenVoice V1과 V2는 MIT 라이선스이며, 상업적 사용과 연구 사용 모두 무료임.

GN⁺의 의견

     * OpenVoice는 다양한 언어와 감정을 가진 목소리를 쉽게 생성할 수 있는 강력한 도구임. 이는 영화, 애니메이션, 게임 등 다양한 분야에서 활용될 수 있을 것으로 보임.
     * 다만 목소리를 너무 쉽게 복제할 수 있다는 점에서 악용의 소지가 있음. 예를 들어 허락 없이 유명인의 목소리를 사용하여 deepfake 영상을 만드는 등의 문제가 발생할 수 있음. 이에 대한 대책 마련이 필요해 보임.
     * OpenVoice와 유사한 기능을 가진 상용 제품으로는 Lyrebird, Resemble.ai, Descript 등이 있음. 이들은 주로 고객 지원, 콜센터, 영상 더빙 등에 활용되고 있음.
     * OpenVoice를 도입할 때는 데이터 보안과 저작권 문제에 유의해야 함. 또한 생성된 음성의 자연스러움과 발음의 정확성도 꼭 확인이 필요함.
     * 오픈소스로 공개된 만큼 다양한 개발자들의 참여로 지속적인 성능 향상이 기대됨. 상용 제품 수준의 음질과 기능을 제공할 수 있을지 귀추가 주목됨.

        Hacker News 의견

     * 최근 운동부 감독이 AI를 이용해 교장의 인종차별 발언을 조작한 오디오 클립을 만들어 모함한 사건이 발생함. 이는 법과 법 집행이 AI 기술의 발전 속도를 따라잡기 위해 노력해야 함을 시사함.
     * 가짜 역사 증거, 가짜 유출, 가짜 지지, 가짜 광고 등의 문제가 심각해질 것으로 예상됨. 단순한 텍스트 기사도 제대로 확인하지 않는 상황에서 AI 기술로 인한 피해는 더욱 클 것임.
     * 해당 기술은 목소리의 톤만 모방할 뿐 실제 목소리를 복제하는 것은 아님. 문서에는 이를 명시하고 있으나 여전히 '음성 복제'라고 부르고 있어 혼란을 야기함.
     * 이 기술의 정당한 사용 사례를 찾기 어려움. 타인을 기만하는 데 악용될 소지가 많음.
     * AI 기술을 활용해 흥미로운 것들을 만들고 싶은 사람들을 위해, 관련 정보를 얻을 수 있는 좋은 곳을 찾는 것이 중요함. 단순히 AI 기술 자체보다는 이를 활용하는 흥미로운 워크플로우와 사람들에 더 관심이 있음.
     * 기존에 공개된 음성 복제 AI 기술과 비교했을 때 이번 릴리스가 특별히 나쁜 점은 없어 보임. 지나친 비관론과 과장된 반응이 많음.
     * 음성 복제 기술을 통해 작가 본인의 목소리로 오디오북을 만들 수 있게 되기를 기대함. 직접 읽는 것만큼 좋진 않겠지만 성우보다는 작가의 목소리가 더 매력적일 것임.
     * README에 예제 코드가 포함되면 좋겠음.
     * 직접 자신의 목소리를 ""복제""해 봤으나 결과물이 전혀 비슷하지 않았음. 프랑스어로 말하는 자신의 목소리를 들을 줄 알았는데 그렇지 않았음. ""즉각적인 음성 복제""라는 제목이 다소 오해의 소지가 있음.
"
"https://news.hada.io/topic?id=14543","Keep Out - WebGL 게임","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Keep Out - WebGL 게임

   이 내용은 게임에 대한 짧은 소개 문구로 보입니다. 게임 요약을 하기에는 정보가 부족하므로 요약 내용을 생성하지 않겠습니다.

        Hacker News 의견

   몇 가지 피드백을 정리해보면:
     * 크로미움 기반 브라우저에서는 getLayoutMap()을 사용하여 키보드 레이아웃을 감지할 수 있음. 그 외 브라우저에서는 수동 대체 방법에 의존해야 함.
     * 전반적으로 게임이 훌륭하고 브라우저에서 즐길 수 있어 좋음.
     * 체력 시스템이 마음에 들지 않음. 포션으로 회복되는 체력량을 더 명확히 했으면 함.
     * R 키가 이동키 근처에 있어서 혼란스러움.
     * 엄격한 90도 움직임에 익숙해지기 어려웠음. FPS 스타일 움직임에 더 익숙함.
     * 맵을 보기 위해 TAB 키를 누르는 것이 더 나을 것 같음.
     * 레벨 8까지 플레이했는데, 소품의 다양성이 조금 더 있으면 좋겠음. 새로운 적 유형은 계속 등장해서 좋았음.
     * 이 스타일 게임의 완성된 경험을 원한다면 Legend Of Grimrock 시리즈를 추천함.
     * 모든 것이 직관적이고 재미있으며 많은 고민을 했음이 느껴짐. 변경할 것이 없어 보임.
     * 제작 과정에 대해 궁금함. 팀 작업인지, 어떤 도구로 텍스처와 캐릭터를 만들었는지 등.
     * WebGL을 사용한 게임 배포가 마찰이 적어 좋음.
     * Three.js를 사용했다고 함.
     * 2015년에 출시된 오래된 게임임.
     * Legend of Grimrock 2를 다시 하고 싶어짐.
     * 지팡이의 쿨다운이 너무 짧음. 적을 계속 기절시키고 공격하는 식으로 악용 가능함.
     * 드래곤의 공격 속도가 거의 즉시 발동됨. 공격 애니메이션이 먼저 나와야 할 것 같음.
     * 던전 크롤러에는 함정이 필요함. 바닥 가시, 벽 도끼, 굴러오는 돌 등.
     * ""이 프로젝트에 대해 더 읽어보기"" 링크가 404 페이지로 이동함. 오래된 프로젝트인 듯.
     * 안드로이드 파이어폭스에서 게임이 잘 작동했으나 특정 시점에서 멈춤.
     * 레벨 12까지 도달하고 모든 것을 구매한 후에는 더 이상 목표가 없어 보임.
     * 다양한 적과 공격, 무기의 진화가 좋았음.
     * 얼음 지팡이가 화염구를 무력화시키면 좋을 것 같음.
     * 기본 무기를 모두 잠금 해제한 후에는 ""에픽"" 세트에 접근할 수 있으면 재미있을 것 같음.
     * 숨겨진 보물방이 있을 거라 예상했으나 폭탄으로도 벽이 부서지지 않았음.
     * 5레벨마다 보스전이 있으면 좋겠음.
     * 목표(공주 구출, 지구 중심 도달 등)가 있었다면 계속 플레이했을 것임.
     * 전반적인 경험이 즐거웠음. 그래픽도 훌륭했으나 레벨 클리어 텍스트의 품질이 다소 떨어져 보임.
     * 매우 세련되고 부드러우나 약간 얕게 느껴짐. 점점 더 길어지는 던전을 앞으로 이동하고 옆으로 이동하는 것으로 게임플레이가 제한될 것 같음.
     * 1인칭 시점과 격자 이동 제한이 매력적이지만, 컨트롤이 FPS나 탑다운 액션 RPG에 비해 느리고 답답함. 걷기/회전/옆으로 이동 애니메이션 사이를 번갈아 기다리는 게 짜증남.
"
"https://news.hada.io/topic?id=14622","Cria - Python으로 간단히 LLM 구동하기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Cria - Python으로 간단히 LLM 구동하기

     * Python을 이용해서 LLM을 프로그래밍 방식으로 실행하기 위한 라이브러리
     * 최대한 적은 설정으로도, 쉽게 LLM을 고급기능으로 실행할 수 있게 제작
          + 기본 설정이 필요없이 5줄의 코드만으로 시작 가능
          + 자신만의 Ollama 인스턴스 또는 서브프로세스에서 고급 기능 이용
     * 기본 시작 코드

import cria

ai = cria.Cria()

prompt = ""Who is the CEO of OpenAI?""
for chunk in ai.chat(prompt):
    print(chunk, end="""")
"
"https://news.hada.io/topic?id=14518","Show HN: NAND 게이트로 만든 프로그래밍 가능한 컴퓨터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Show HN: NAND 게이트로 만든 프로그래밍 가능한 컴퓨터

NAND: 웹으로 구현된 완전한 Turing 등가의 16비트 컴퓨터

     * NAND는 NAND 게이트와 클럭만으로 웹에서 에뮬레이션 된 Turing 등가의 16비트 컴퓨터
     * NAND는 자체 CPU, 기계어, 어셈블리어, 어셈블러, VM 언어, VM 트랜슬레이터, 프로그래밍 언어, 컴파일러, IDE, UI를 가짐
     * NAND는 Nand to Tetris 코스와 관련 책에서 명시된 Jack-VM-Hack 플랫폼을 기반으로 함

프로그램 예제

  Average

     * 숫자들을 입력 받고 평균을 계산하는 간단한 프로그램
     * 제어 흐름, 산술 연산, I/O, 동적 메모리 할당을 보여줌

  Pong

     * Pong 게임으로 언어의 객체지향 모델을 보여줌
     * 화살표 키로 패들을 좌우로 움직여 공을 튕김
     * 매번 튕길때마다 패들이 작아지고, 공이 화면 아래로 떨어지면 게임 끝

  2048

     * 2048 게임으로 재귀와 복잡한 애플리케이션 로직을 보여줌
     * 화살표 키로 숫자들을 4x4 그리드에서 움직임
     * 같은 숫자들이 합쳐질 때 서로 합쳐짐
     * 2048 타일에 도달하면 이기는 것이지만 계속해서 더 모을 수 있음
     * 보드가 가득차고 움직일 수 없을 때 게임 끝

  Overflow

     * 무한 재귀로 스택 오버플로우를 의도적으로 발생시켜 가상 머신에서 탈출하는 프로그램
     * 스택 오버플로우를 방지할 런타임 검사가 없다는 점을 활용
     * 실행 시 스택 포인터 값을 계속 출력함
     * 스택이 의도된 메모리 공간 끝까지 도달하여 힙 메모리로 넘어가면 프린트문이 폭발적으로 오작동함

  SecretPassword

     * 런타임이 스택 스매싱을 방지하지 않는다는 점을 활용하여 접근할 수 없는 함수를 호출하는 프로그램
     * NAND의 스택프레임 레이아웃을 이해하고 있어야 함
     * 사용자가 임의의 메모리 주소를 임의의 값으로 덮어쓸 수 있도록 허용
     * 함수의 반환 주소를 다른 함수의 주소로 덮어쓰면 임의의 코드를 실행할 수 있음
     * 스택 주소와 어셈블러를 수동으로 검사하여 얻은 특정 메모리 위치와 덮어쓸 값을 입력하면 이 아이디어가 동작하는 것을 볼 수 있음

  GeneticAlgorithm

     * NAND의 많은 컴포넌트들 중 개발에 가장 오래 걸린 부분
     * 간단한 기계 학습을 사용하는 생물 시뮬레이션
     * 각 점의 ""뇌""는 가속 벡터들이며, 목표까지 자연 선택을 통해 진화함
     * 매 세대에서, 목표에 더 가까이 ""죽은"" 점들이 다음 세대의 부모로 선택될 확률이 높음
     * 재생산이 뇌를 돌연변이 시키고, 자연 진화를 효과적으로 시뮬레이션 함
     * 성능상 제한으로 인해 많은 최적화 기법들을 활용하여 하드웨어 제한을 우회하고 이를 가능하게 함

잭으로 프로그래밍 하기

     * 잭으로 프로그래밍할 때 가장 중요한 점은 연산자 우선순위가 없다는 것임. 이것이 프로그램이 제대로 동작하지 않는 이유일 수 있음.
     * 4 * 2 + 3 → (4 * 2) + 3, if (~x & y) → if ((~x) & y) 처럼 괄호로 우선순위를 명시해야 함

  잭 소개

     * NAND는 자체 기술 스택 전체를 자랑
     * Jack은 약한 타입의 객체지향 언어. 쉽게 말해 Java 문법을 가진 C언어
     * 한 예제를 통해 배워보자

  커스텀 데이터 타입

     * 잭은 세가지 기본 타입 int, char, boolean을 지원
     * 필요에 따라 추상 데이터 타입으로 이를 확장할 수 있음
     * 객체지향 프로그래밍 지식이 바로 적용 가능함
     * 예제를 보면, Point 클래스로 추상적인 공간의 점을 정의
     * field 변수로 데이터 타입의 인스턴스별 속성을 선언
     * 점을 조작하는 공개 method 함수들을 제공하여 호출자가 점을 더하거나 두 점 사이 거리를 계산할 수 있게 함
     * 모든 field 변수는 비공개로 범위가 지정됨. 이 변수들을 접근하려면 method 함수로 제공되어야 함
     * 데이터 클래스는 dispose 메소드를 정의하는 것이 관례
     * function, method 호출 문법 참조

  약한 타입 변환

     * 잭은 자바에 크게 영감을 받았다고 했지만 단순한 파사드일 뿐
     * 자바는 강력한 타입 언어이고 다운 캐스팅, 다형성, 상속 등의 복잡한 타입 기능을 지원
     * 반면 잭은 실제로는 signed 16-bit integer 하나만 지원함
     * 이것이 잭이 약한 타입인 주된 이유임
     * 그래서 잭 컴파일러는 할당 및 연산에서 다른 타입을 혼용해도 신경쓰지 않음
     * 잭은 여전히 강력하고 기능적인 객체지향 모델을 제공함
     * 타입 변환을 언제 어떻게 해야할지 이해하는데 도움이 될 것임

  수동 메모리 관리

     * 잭은 수동으로 메모리를 관리하는 언어
     * 더 이상 필요하지 않은 메모리를 적절히 해제하는데 주의해야함
     * 그렇지 않으면 잭 OS가 메모리 누수가 있다고 생각할 것임
     * 모범 사례는 각 클래스마다 할당 해제를 제대로 캡슐화 하는 dispose 메소드를 작성하는 것
     * 객체가 더 이상 필요없을 때 이 메소드를 호출하면 힙 메모리가 부족해지는 것을 방지할 수 있음
     * C 같은 다른 수동 메모리 관리 언어를 해봤다면 익숙할 것
     * 차이점은 잭 OS가 배열과 문자열을 스택이 아닌 힙에 저장한다는 것
     * String.dispose를 보면 어떻게 dispose 메서드를 작성할지 알 수 있을 것

  미정의 동작

    연산자 우선순위

     * 너무 중요해서 앞으로 옮김

    작거나 큰 연산자

     * 잭의 비교식 a > b, a < b는 단순해 보이지만 수학적으로 항상 옳지는 않음
     * 가상 머신이 이를 a - b > 0로 바꿈. 그런데 a - b가 overflow될 수 있음
     * 20000 > -20000가 어떻게 평가될까? 20000 - (-20000) > 0 즉 -25336 > 0가 되어 false가 됨
     * 하지만 20000 > -10000는 30000 > 0 즉 true가 됨
     * a와 b의 절대값 차이가 32767보다 크면 a > b와 a < b가 틀려짐. 아니라면 괜찮음
     * 이는 버그가 아니라 Nand to Tetris과의 비호환성임. 호환성을 위해 이 동작은 고쳐지지 않을 것임

    -32768

     * -32768은 -(-32768) = -32768 라는 독특한 속성을 가진 유일한 숫자. 양의 짝꿍이 없는 싱글톤임
     * 이로 인해 타당하지 않은 로직 오류가 발생할 수 있음
     * -x가 내부적으로 ~(x-1)로 처리되기 때문
     * x에 -32768을 대입하면 x-1 = ~x 를 만족. ~(~x)는 x와 같아짐
     * 무슨 일이 있었나? NAND가 16비트 머신이어서 -32768에서 1을 빼면 비트들을 뒤집은 결과가 나옴
     * 중요한 것은 음수 연산자 처리에서 로직 오류를 다루는 것임
     * -32768 케이스를 확인하고 적절히 처리하는 것은 프로그래머의 책임임

    인자가 부족한 함수 호출

     * 설명이 필요 없는 명백한 미정의 동작

    부적절한 타입 캐스팅

     * Array로 변수를 아무 타입으로나 캐스팅할 수 있음
     * 존재하지 않는 인스턴스 메소드를 호출하면 미정의 동작이 발생
     * 컴파일러는 이를 감지할 만큼 똑똑하지 못함

    스택 오버플로우

     * Overflow 프로그램 참조

    스택 프레임이나 내부 레지스터 수정

     * 스택 프레임이나 256~2047, 1~15번 주소에 있는 내부 레지스터를 수정하면 미정의 동작이 발생할 수 있음
     * 보통 Memory.poke나 음수 배열 인덱스를 오용하지 않는 한 불가능함
     * SecretPassword 프로그램 참조

  하드웨어 사양

     * 1970년대 이후 16비트 컴퓨팅이 도태된 이유가 있음
     * 32비트나 64비트에 비해 처리 능력과 메모리 용량이 제한되어 현대 소프트웨어의 요구사항을 충족시키지 못함
     * NAND도 예외는 아님
     * 16GiB 맥북과 비교하면 NAND는 4KiB RAM밖에 없음. 0.00002%에 불과
     * 그럼에도 우리를 달에 데려다 줄 만큼은 됨
     * 잭 OS는 4KiB 중 14,336 메모리 주소를 힙에 예약. 비정상적으로 작은 수
     * 그래서 잭 애플리케이션이 메모리를 효율적으로 할당 해제 하는게 매우 중요
     * 너무 야심찬 계획이라면 힙 메모리가 부족해져서 데이터 타입과 로직을 완전히 다시 작성해야 할 수도 있음
     * 4KiB 중 8,192 메모리 주소는 화면에 예약
     * 각 주소의 각 비트는 512x256 화면의 픽셀에 선형으로 매핑. LSb 0 비트 넘버링 사용
     * 24,576번 메모리 주소는 키보드에 예약
     * 눌린 키의 ASCII 코드값이 반영됨
     * 하지만 사용자 입력 처리를 위해 직접 접근하면 안됨. 잭 OS가 제공하는 Keyboard 클래스와 관련 함수 사용해야 함
     * NAND 키보드는 ASCII와 특수키들을 인식함
     * 정적 클래스 변수에는 240개, 전역 스택에는 1,792개 메모리 주소 예약
     * 깊은 재귀를 하지 않는 한 이 제한은 문제 없을 것임

        Hacker News 의견

     * Nand to Tetris 프로젝트를 통해 컴퓨터의 추상화 레벨을 깊이 이해할 수 있음
     * Ben Eater의 6502 컴퓨터 키트도 비슷한 교육적 가치가 있음
     * 이 프로젝트는 여러 대학 수업으로 만들 수 있을 정도로 잘 정리된 자료임
     * 1990년대 초 UC Berkeley의 컴퓨터 하드웨어 자격시험에서는 이와 유사하게 NAND 게이트만으로 마이크로코드화되고 파이프라인된 RISC 프로세서를 설계하는 문제가 출제되었음
          + 당시에는 실제 제작까지는 요구되지 않았고, 상세 설계만 종이에 작성하면 되었음
     * 이 프로젝트는 MarquisdeGeek/gates 와 유사해 보임
     * Nand2Tetris 과정을 수강하면서 가상으로 이와 비슷한 것을 만들고 싶었는데, 실제로 구현한 것이 인상적임
          + 이를 통해 컴퓨터 동작 원리에 대한 이해도가 크게 향상되었을 것임
     * NAND 게이트 외에 클럭도 사용했다는 지적이 있음
     * Nand2Tetris를 완주하진 못했지만 팬으로서 이 프로젝트를 깊이 살펴보고 싶음
     * 총 몇 개의 NAND 게이트가 사용되었는지 궁금함
     * 근본 원리에 충실한 접근에 감사를 표함
"
"https://news.hada.io/topic?id=14521","Rust로 게임 개발을 한 3년 후에 떠나며","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Rust로 게임 개발을 한 3년 후에 떠나며

     * Rust에 익숙해지면 모든 문제가 사라질 것이라는 주장에 대해
          + Rust에 익숙해져도 근본적인 문제는 사라지지 않음
          + 게임은 복잡한 상태 머신이고 요구사항이 계속 바뀌기 때문에 Rust의 정적이고 과도하게 검사하는 특성과 맞지 않음
          + 코드를 계속 리팩토링해야 하는 문제는 self-inflicted임
     * Borrow checker로 인해 발생하는 대규모 리팩토링 문제
          + Rust는 다른 언어보다 더 자주 리팩토링을 강제함
          + 게임 요구사항이 자주 바뀌는 상황에서 borrow checker와 싸우게 되고 코드 재구조화가 필요해짐
          + 리팩토링이 좋은 코드를 만든다는 주장에 대해선 동의하기 어려움. 좋은 코드는 아이디어를 반복하고 시도해보면서 만들어지는 것
     * 간접화(Indirection)는 일부 문제만 해결하고 개발 생산성을 떨어뜨림
          + Borrow checker 이슈를 해결하기 위해 간접화를 사용하면 코드 로직이 분리되고 복잡해짐
          + 게임에선 연결된 이벤트, 특정 타이밍, 많은 상태 관리가 필요한데 간접화는 이를 어렵게 함
          + Rust에선 간단한 코드도 간접화를 위해 장황하게 써야함
     * ECS(Entity-Component-System)는 잘못된 문제를 해결함
          + ECS의 장점은 사실 generational arena의 장점임
          + ECS를 dynamic composition, structure of arrays, Rust borrow checker 해결책, dynamically created generational arenas 등 다양한 관점에서 봄
          + 하지만 게임 개발에서 ECS가 가장 적합한 방식인지는 의문. 퍼포먼스나 컴포지션보다는 게임 로직에 더 신경써야 함
     * 일반화된 시스템(Generalized systems)은 재미있는 게임플레이로 이어지지 않음
          + 너무 일반화된 시스템을 사용하면 지루한 게임플레이가 만들어짐
          + 좋은 게임은 세부적인 상호작용을 주의깊게 설계하고, VFX를 동기화하며, 플레이테스트와 실험을 반복하고, 빨리 출시해서 피드백 받는 것이 중요함
          + Rust는 빠른 프로토타이핑과 반복(iteration)에 적합하지 않은 가치를 추구함
     * 게임 개발에서 중요한 것은 신속한 프로토타이핑과 반복이지만 Rust의 가치는 그 반대임
          + 게임 개발의 핵심은 게임 자체와 플레이 경험이지 크래시 없는 코드가 아님
          + 게임 코드의 유지보수성은 인디 게임에선 그다지 중요한 가치가 아님. 중요한 건 반복 속도(iteration speed)
          + Rust는 문제를 피하는데 집착한 나머지 정작 중요한 것을 놓치고 있음
     * Procedural macros는 리플렉션에 훨씬 못 미침
          + 게임 개발에선 시스템 코드, 게임플레이 코드, UI, VFX, 오디오, 툴 등 다양한 영역의 코드를 작성해야 함
          + Rust에선 간단한 ""객체 출력""도 코드를 직접 짜거나 procedural macros를 만들어야 함
          + Procedural macros는 선언적 매크로에 비해 훨씬 제한적이고 컴파일 시간도 오래 걸림
          + C#의 리플렉션은 매우 사용하기 쉽고 퍼포먼스가 중요하지 않은 경우 빠르게 개발할 수 있게 해줌
     * Hot reloading이 반복 속도 향상에 중요한 역할을 함
          + Hot reloading은 즉시 모드 UI/그리기, 디버깅, 게임플레이 상수 튜닝 등에 매우 유용함
          + Rust에도 hot-lib-reloader가 있지만 완벽하진 않고 계획과 선견지명이 필요해서 창의적 사용이 제한됨
          + 게임 개발자는 단순한 struct 리로딩 이상의 고차원적인 툴링을 원함
     * 추상화는 선택이 아니라 필수
          + 실제 예시) UI 상태에 따라 다른 동작을 해야하는 경우 Rust에선 리팩토링이 필요하거나 클론을 남발하게 됨
          + 비즈니스 로직이 바뀌는 게 아니라 컴파일러를 만족시키기 위해 코드를 바꾸는 경우가 많음
          + Rust는 ""이 필드들을 가진 타입""같은 구조적 타입 시스템이 없어서 리팩토링시 코드 여러군데를 수정해야함
     * Rust의 GUI 상황은 최악임
          + 게임 UI에서 중요한 건 데이터 바인딩이나 반응형 업데이트가 아니라 외관을 커스텀하는 것
          + 게임 UI에 필요한 건 이쁜 GUI, 커스텀 스프라이트, 애니메이션, 벡터 쉐입, 파티클, 효과, 플래쉬 등
          + 현재 게임 GUI에 특화된 Rust 라이브러리는 없음
     * Orphan rule은 옵셔널이어야 함
          + Orphan rule은 안전을 위해 개발 생산성을 크게 떨어뜨림
          + 라이브러리가 아닌 어플리케이션 코드에선 orphan rule을 끌 수 있어야함
     * 컴파일 시간은 개선되었지만 proc macros를 쓰면 여전히 느림
          + serde와 같은 proc macros는 컴파일 시간을 크게 증가시킴
          + 20-30초 이상 걸리는 incremental build에선 세부 튜닝이 매우 어려움
     * Rust 게임 개발 생태계는 과대 포장된 느낌
          + 실제 게임을 만들고 있는 사람은 많지 않음
          + 웹사이트나 README가 화려하고 유명해 보이는 프로젝트가 실제로는 그렇지 않은 경우가 많음
          + 실제 게임을 만들고 싶다면 godot-rust를 추천. 퓨어 Rust 솔루션에 집착하지 말고 성숙한 엔진의 도움을 받는 게 좋음
     * 게임은 싱글 스레드라서 전역 상태가 불편한 이유가 잘못됨
          + Rust에서 전역 상태를 사용하는 건 매우 불편함 (static mut, AtomicRefCell, Rc 등)
          + 하지만 게임은 백엔드 서비스와 달리 모든게 싱글 스레드라서 이런 불편함이 필요하지 않음
          + Bevy가 병렬 시스템을 도입한 건 실수라고 봄. 빠른 퍼포먼스를 위해 했지만 사용자가 순서를 계속 명시해야 하는 등 오히려 불편함만 가중됨
     * 동적 borrow 체킹은 리팩토링 후에 예상치 못한 크래시를 일으킴
          + hecs를 2년간 사용하면서 query가 겹치면서 크래시가 발생하는 사례를 자주 봄
          + RefCell을 쓸 때도 두 곳에서 .borrow_mut()하면 예상치 못한 크래시 발생
          + 코드가 나쁘다기보다는 Rust가 불필요한 리팩토링을 강제하는 것
          + 게임에선 RefCell이 유용한데 Rust는 이를 너무 어렵게 만듦
     * Context 객체의 유연성이 부족함
          + Rust에선 전역 상태를 쓰기 어려워서 context 객체에 레퍼런스를 모아 전달하는 패턴을 씀
          + 하지만 이 때 일부 필드만 빌려쓰면 partial borrow 때문에 컴파일 에러가 발생함
          + Context를 쪼개서 구조를 바꾸라고 하지만 정작 하고픈 건 게임 로직인데 컴파일러 만족을 위해 구조를 바꾸는 건 시간 낭비임

Rust의 장점

     * 컴파일 되면 보통은 잘 동작함. 특히 CLI 도구나 데이터 처리, 알고리즘 작성시 유용함
     * 별다른 노력없이 좋은 퍼포먼스를 보여줌. C#보다 1.5~2.5배 정도 빠른 경험이 있음
     * Enum이 잘 구현되어 있음
     * Rust analyzer 덕분에 IDE 사용성이 크게 개선됨
     * Trait 시스템이 잘 되어 있음. Orphan rule만 좀 완화된다면 훨씬 활용도가 높아질 것

GN⁺의 의견

     * Rust에 대한 의견이 대체로 부정적이긴 하지만, 저자가 다양한 시도를 해보고 내린 결론인 만큼 진지하게 받아들일 필요가 있어 보임. 특히 게임 개발이란 도메인에서 실용성과 개발 속도가 얼마나 중요한지, 그리고 Rust가 그런 부분에선 아직 부족한 면이 있다는 지적은 일리가 있음.
     * Rust가 지향하는 안전성이 때로는 개발 생산성을 심각하게 저하시킬 수 있다는 것에 동의. Rust 코드를 짜다보면 로직 자체보다는 컴파일러를 만족시키는데 더 많은 시간을 쓰게 되는 경우가 많고, 이는 Rust가 근본적으로 시스템 프로그래밍에 특화된 언어라는 점에서 기인하는 것 같음
     * 반면 게임 개발은 대부분 싱글 스레드 환경이고 빠른 프로토타이핑과 반복이 중요한 영역이라, 지나친 안전성 검사는 오히려 독이 될 수 있을 것. 특히 Rust 초창기에 게임 개발을 시도했다가 좌절한 경험들을 많이 들어봤는데, 아직도 근본적인 문제점들은 크게 개선되지 않은 듯.
     * 물론 Bevy 등 최근에 나온 게임 엔진들이 Rust 게임 개발의 편의성을 높여주긴 했지만, 아직 Unity나 Godot같은 성숙한 엔진들의 수준에는 한참 못 미치는 것 같음. 이 글에서처럼 Rust로 퓨어하게 모든 걸 만들기보다는 기존 엔진들과 함께 사용하는 게 현실적인 대안이 될 수 있음
     * 저자가 언급한 장점들은 게임이 아닌 다른 분야에서 Rust를 사용할 때 크게 와닿음. 특히 시스템 프로그래밍이나 웹 서버 개발 같은 영역에서 Rust의 안전성과 높은 퍼포먼스는 큰 무기가 되지만 그런 장점들도 게임 개발에선 그다지 큰 메리트로 작용하지 않는 듯
     * 결국 Rust는 만능 언어가 아니라 특정 도메인에 특화된 언어인 만큼, 자신의 프로젝트 성격에 맞는지 신중히 고려해봐야 할 것 같음

   rust 는 코어 레벨에서 무결성 있는 코드를 짤 수 있는 개발자들이 적어지고,
   다양한 개발자 폴트에 의해서 발생하는 문제들을 해결하기 위한 언어라고 생각합니다.

   빠르게 개발하는게 아니라,
   정확하게 개발하는데 더 적합하기 때문에,
   사용자 추가 요구사항이 빈번하게 발생하고, 실행해야하는 프로젝트에는 적합하지 않습니다.

   그럼에도 불구하고, UI 라이브러리가 나오길 소망하는 것은
   견고한 코드 위에 동작하는 작고 심플한 UI만 있어도 더 활용성이 좋아질 것이라는 기대감 때문일 것 같아요.

   게임 개발을 해본적이 없어서 잘 모르겠지만,
   처음부터 언어를 잘못 골랐거나, (개발 iteration이 중요했으면 script수준언어를 택했어야..)
   시스템에대한 깊은 이해가 없거나 한거같아요.
   c++을 선택했어도 비슷한 문제를 격지 않았을까 하네요.

   맞습니다. 뭐 C++을 선택했다면 언리얼이라는 선택지가 있긴 했겠지만요...

   요즘 시대에 Rust, C++ 같은 네이티브 언어들은 게임 클라이언트 개발 보다는 게임 엔진 같은 미들웨어 개발이 더 적절해보인다는 생각이 드네요.
   네이티브 언어로 풀스택 웹 개발하는 사례가 거의 없듯이요.

   처음부터 그런 용도로 나온언어죠. C++대체용으로.
   글은 언어를 비판하는 글이 되버린거 같아요.

   그렇죠. 원래 파폭 내부 엔진 개선용으로 시작되었던가요?
   글 내용은 만병통치약 같은 느낌으로 러스트와 잘 안 맞는 분야에서 개발을 해봤다가 고생한 그런 느낌이네요 ㅋㅋ

   100% 동의합니다. 게임 로직에는 생산성이 좋은 언어가 사용 사례에 맞아 보입니다.

   Rust를 시작하는 단계라 조금 공감이 가네요.
   Borrowing 변경으로 코드가 너무 많이 수정되어서 고통스럽더라구요.
   암시적 표현이 많은 python, javascript과 달리 rust는 명시적인 경향이 있어서 장황한 코드가 만들어지기도 하고, 프로그래머에게 많은 선택을 하게 만드니 피곤하기도 하고요.
   그럼에도 다른 언어에 없는 개념들이 신선하고 재밌어요.

   Rust Analyzer나 GitHub Copilot이 없었더라면 일찍 포기했을 거 같아요.

   역시 게임개발은 하드코어군요...

   러스트로 코어부터 프론트까지 짜는 것 보다는
   유니티나 다른 게임 엔진 처럼 코어는 러스트로 작성하고 생산성 높은 언어를 결합해서 쓰게 되면 어떨까요?

   아무래도 틀을 굉장히 강제하는 면이 있다보니 어쩔 수 없겠죠.

   결론: Rust는 '익숙'함보다 '성숙'함이 필요하다.

        Hacker News 의견

   메타버스 클라이언트 개발 경험을 공유하며 러스트의 문제점들을 제시함
     * 러스트로 대규모 3D 게임을 개발하는 사례가 거의 없음
     * 리팩토링과 프로그램 각 부분을 연결하는 작업이 고통스러움
     * 렌더링은 거의 적절하지만 스택이 완성되지 않았고 신뢰할 수 없음
     * 2D GUI 시스템은 약하고 다이얼로그 박스당 너무 많은 코드가 필요함
     * async 시스템이 불필요한 영역까지 확산되는 문제에 동의함

   20년 경력의 게임 개발자로서 러스트가 게임 개발에 적합하지 않다고 봄
     * 게임플레이 코드는 유연해야 하고 흥미로운 게임을 만들기 위해 엣지 케이스가 많아야 함
     * 컴파일 시간이 중요하고 구조 변경이 자주 필요함
     * ECS는 일부 시스템에 유용하지만 게임플레이나 UI 코드에는 사용하기 힘듦

   러스트 게임 개발 생태계는 과대광고에 의존하고 있음
     * 러스트로 게임 개발을 시도했지만 즉시 끔찍한 경험을 함
     * 느린 컴파일 시간, 거대한 패키지 다운로드, 러스트 자체의 어려움 등
     * 다른 도구들이 러스트처럼 안전하지 않다고 주장하지만 게임에서 메모리 안전성이 큰 문제였던 적이 거의 없음

   비비와 유니티, 고도로 게임 개발 경험을 비교함
     * 현재 러스트로 게임 개발을 선택하는 것이 이해하기 어려움
     * ECS에 모든 것을 우겨넣으면 재미있는 게임플레이 개발에 방해가 됨
     * 현대 PC의 성능을 고려하면 다중 스레딩 최적화를 과도하게 걱정할 필요가 없음

   님(Nim) 언어가 러스트보다 게임 개발에 더 적합할 수 있음
     * 개발자를 방해하지 않고 핫 리로딩을 지원함

   러스트는 특정한 방식의 프로그래밍을 강요하는 독선적인 언어로 보임
     * 메모리 안전성을 모든 것보다 우선시 하는데 게임 개발에서는 그다지 유용하지 않음
     * 게임 개발에 이상적인 언어는 생산성이 높고 성능이 적절하며 위험을 감수할 줄 아는 숙련된 프로그래머를 위한 것이어야 함

   Allen Blomquist의 툴링 데모는 개발 피드백 루프가 중요함을 보여줌
     * 러스트가 원하는 작업 환경을 제공하지 못해 Unity로 다시 전환함

   러스트의 근본적 문제는 객체지향을 버리고 함수형 프로그래밍을 선호하는 것
     * 최하위 코어에서는 도움이 될 수 있지만 상위 레벨에서는 적합하지 않음

   게임 개발에 있어 러스트는 최악의 선택
     * 정확성과 안전성, 완벽한 코드를 추구하는 러스트의 가치는 게임 개발과 맞지 않음
     * 게임은 수명이 짧고 개발 주기도 짧아 코드 품질이 그리 중요하지 않음
     * 게임 엔진 개발에는 도움이 될 수 있지만 높은 유연성의 스크립팅 언어와 함께 사용해야 함

   D언어로 코딩하면서 C에 비해 데이터 레이아웃 변경이 훨씬 쉬움을 깨달음
     * 참조 타입과 값 타입 간 전환이 C에서는 어렵지만 D에서는 쉬움
"
"https://news.hada.io/topic?id=14526","Tiny GPU: Verilog으로 구현한 최소한의 GPU","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Tiny GPU: Verilog으로 구현한 최소한의 GPU

tiny-gpu 아키텍처 개요

  GPU

     * 한 번에 하나의 커널을 실행하도록 구축됨
     * 커널을 실행하기 위해서는 다음 작업 필요:
         1. 커널 코드로 전역 프로그램 메모리 로드
         2. 필요한 데이터로 데이터 메모리 로드
         3. 디바이스 제어 레지스터에서 실행할 스레드 수 지정
         4. 시작 신호를 HIGH로 설정하여 커널 실행
     * GPU는 다음 유닛으로 구성:
         1. 디바이스 제어 레지스터
         2. 디스패처
         3. 가변 수의 컴퓨팅 코어
         4. 데이터 메모리 및 프로그램 메모리용 메모리 컨트롤러
         5. 캐시

  메모리

     * GPU는 외부 글로벌 메모리와 인터페이스하도록 구축됨
     * 데이터 메모리와 프로그램 메모리가 단순화를 위해 분리됨
     * 글로벌 메모리는 고정된 읽기/쓰기 대역폭을 가짐
     * 메모리 컨트롤러는 컴퓨팅 코어에서 메모리로의 아웃고잉 요청을 모두 추적하고, 실제 외부 메모리 대역폭에 따라 요청을 조절하며, 외부 메모리에서 적절한 리소스로 응답을 릴레이함
     * 캐시는 반복적으로 요청되는 데이터를 저장하여 메모리 대역폭 사용을 줄임

  코어

     * 각 코어는 컴퓨팅 리소스 보유
     * 단순화된 GPU에서 각 코어는 한 번에 하나의 블록을 처리하고, 블록의 각 스레드에 대해 전용 ALU, LSU, PC 및 레지스터 파일을 가짐
     * 스케줄러는 스레드 실행을 관리하고, 블록을 완료하기 전에 새 블록을 선택하지 않음
     * 페쳐는 현재 프로그램 카운터에서 명령어를 비동기적으로 가져옴
     * 디코더는 페치된 명령어를 스레드 실행을 위한 제어 신호로 디코딩함
     * 각 스레드는 전용 레지스터 파일 세트를 가짐
     * ALU는 스레드별 전용 연산 논리 장치
     * LSU는 전역 데이터 메모리에 액세스하기 위한 스레드별 전용 로드-스토어 유닛
     * PC는 각 스레드에서 실행할 다음 명령어를 결정하는 전용 프로그램 카운터

  ISA

     * 간단한 11개 명령어 ISA 구현
     * 행렬 덧셈 및 곱셈 등의 간단한 커널을 위해 구축됨
     * 기본 산술 연산, 메모리 로드/스토어, 분기, 상수 로드 등 지원

  실행

     * 각 코어는 명령어를 실행하기 위해 페치, 디코드, 요청, 대기, 실행, 업데이트의 단계를 거침
     * 각 스레드는 레지스터 파일의 데이터에 대한 계산을 수행하기 위해 실행 경로를 따름
     * SIMD 기능을 위해 읽기 전용 레지스터에 블록 인덱스, 차원, 스레드 인덱스 값이 있음

  커널

     * 행렬 덧셈 및 곱셈 커널을 ISA로 작성하여 SIMD 프로그래밍과 GPU 실행을 입증
     * 테스트 파일로 GPU에서 커널 실행을 완전히 시뮬레이션하고 데이터 메모리 상태와 실행 추적을 생성할 수 있음

  시뮬레이션

     * iverilog와 cocotb 설치 후 make 명령으로 커널 시뮬레이션 실행 가능
     * 로그 파일에 초기/최종 데이터 메모리 상태와 커널의 완전한 실행 추적이 출력됨

  고급 기능

     * 성능 및 기능을 크게 향상시키는 현대 GPU의 많은 추가 기능들이 단순화를 위해 생략됨
     * 다중 계층 캐시 및 공유 메모리, 메모리 병합, 파이프라이닝, Warp 스케줄링, 분기 분기, 동기화 및 장벽 등의 기능 논의

GN⁺의 의견

     * 간단하고 이해하기 쉽게 GPU 아키텍처와 SIMD 프로그래밍 모델의 핵심을 잘 설명하고 있음. 특히 행렬 연산 커널 예제를 통해 실제 GPU에서 어떻게 병렬 처리가 이루어지는지 잘 보여줌.
     * 현대 GPU에서 사용되는 고급 기능들도 잘 정리되어 있어, tiny-gpu를 이해한 후에는 좀 더 복잡한 GPU 아키텍처를 공부하는데 도움이 될 것 같음.
     * 다만 실제 그래픽스 파이프라인 기능은 빠져있어서, 그래픽스에 특화된 하드웨어가 어떻게 동작하는지는 다루지 않음. 그래픽스에 관심있는 사람은 아쉬울 수 있음.
     * 오픈소스로 공개된 다른 GPU 아키텍처인 MIAOW나 GPGPU-Sim 등과 비교해보면, 좀 더 현실적인 GPU를 이해하는데 도움이 될 것 같음.
     * 앞으로 분기 분기, 메모리 병합, 파이프라이닝 등의 기능이 추가된다면 더욱 실용적인 학습 자료가 될 것으로 기대됨. 개발에 기여할 수 있는 오픈소스 프로젝트라는 점도 매력적임.

        Hacker News 의견

     * Intel은 GPU에 대한 많은 기술 문서를 공개하고 있음. 810/815 매뉴얼도 온라인에서 찾을 수 있음. 855/910/915/945를 제외하고는 문서화가 일관성 있게 이루어지고 있음.
     * 오픈 코어 GPU 작업을 격려함.
     * NyuziProcessor라는 또 다른 오픈소스 GPU 프로젝트가 있음. (https://github.com/jbush001/NyuziProcessor)
     * FPGA에 입문하고 싶지만, 어디서부터 시작해야 할지 파악하기 어렵고 분야 자체가 위압적으로 느껴짐.
     * 최종 목표는 LLM(Large Language Model)을 위한 가속 카드를 만드는 것임. 메모리 오프로딩 부분을 제외하고는 이 프로젝트와 유사한 부분이 많을 것임.
     * 순차적인 always 블록에서 non-blocking과 blocking 할당 연산자를 혼합하는 이유에 대해 질문함.
     * 예전에 VHDL로 비슷한 작업을 했었음. opencores라는 사이트에 다양한 오픈소스 HDL 프로젝트가 있었음. 오늘날 HPC 수준의 대규모 분산 HDL 시뮬레이터가 있는지 궁금함. 최신 GPU를 활용하여 RTL 수준 시뮬레이션을 수행하는 것이 합리적임.
     * 하드웨어 프로젝트가 오픈되는 것을 좋아함. 하지만 이것은 SIMD 코프로세서라고 주장할 수 있음. GPU가 되려면 적어도 일종의 디스플레이 출력이 있어야 함. 최근 Nvidia 등이 그래픽 아키텍처의 서버 전용 변종을 GPU로 판매하면서 용어가 다소 느슨해졌지만, GPU 설계의 ""그래픽"" 부분은 여전히 복잡성의 상당 부분을 차지함.
     * ALU가 하드웨어 수준에서 DIV 명령어를 직접 구현하는 것은 일반적인지 의문. 현대 CUDA 코어와 같은 곳에서 실제 명령어로 사용되는 것인지, 아니면 일반적으로 소프트웨어 에뮬레이션인지 궁금함. 실제 하드웨어 나누기 회로는 많은 공간을 차지하므로 GPU ALU에서는 기대하지 않았음. Verilog에서 ""DIV: begin alu_out_reg <= rs / rt; end""라고 쓰기는 쉽지만 실리콘에서는 많은 공간을 차지함. 하지만 Verilog만 시뮬레이션하는 사람은 이를 알지 못할 수 있음.
     * 그래픽 기능을 제공하지 않는 또 다른 ""GPU"". 이런 것들은 다른 이름으로 불려야 한다는 의견.
     * 스레드가 병렬로 처리된다고 가정하고, 각 명령어 후에 모든 스레드가 동일한 프로그램 카운터로 ""수렴""한다고 단순화했음. 실제 GPU에서는 개별 스레드가 다른 PC로 분기할 수 있어 branch divergence가 발생함. 실리콘으로 GPU를 만들기 전에 GPU 프로그래밍을 해보는 게 좋겠음. SIMD도 아님. (LED를 깜박이는 회로를 조립해 CPU를 만들었다고 주장한 사람과 동일)
"
"https://news.hada.io/topic?id=14577","SB-1047으로 인한 오픈소스 AI 위축과 안전성 저하 우려","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   SB-1047으로 인한 오픈소스 AI 위축과 안전성 저하 우려

오픈소스 개발에 대한 우려사항들

     * 과도하게 광범위한 정의: 법안 내 ""적용 대상 모델""에 대한 정의가 매우 광범위하여, 최소한의 위험만 내포하고 있는 다양한 오픈소스 모델들까지 포괄할 수 있음. 이는 의도치 않게 유익한 AI 프로젝트에 종사하는 선의의 개발자들의 활동을 범죄화할 수 있음.
     * 이중 용도: AI 모델은 워드 프로세서, 계산기, 웹브라우저와 같이 컴퓨터에서 실행되는 일반적인 소프트웨어임. 모델의 제작자는 모델이 해로운 일에 사용되지 않도록 보장할 수 없음. 이는 웹브라우저, 계산기, 워드프로세서의 개발자도 마찬가지임. 이러한 범용 도구의 제작자에게 책임을 묻는 것은 실제로 대기업의 법무팀을 제외하고는 그러한 도구를 만들 수 없다는 것을 의미함.
     * 제한적 요구사항: 이 법안은 의무적인 폐쇄, 광범위한 보고, 잠재적으로 모호한 ""적용 대상 지침"" 준수 등 개발자에게 상당한 부담을 부과함. 이러한 요구사항은 복잡한 규제 프로세스를 탐색할 자원이 부족한 오픈소스 개발자들에게 불균형적인 영향을 미칠 수 있음.
     * 개방성 저해: 법적 제재와 관료주의적 장애물에 대한 우려로 인해 오픈소스 개발이 위축될 수 있으며, AI 발전의 원동력이었던 협업 정신을 저해할 수 있음. 이러한 투명성 감소는 잠재적 안전 문제를 식별하고 해결하는 것을 더 어렵게 만들 수 있음.

중소기업과 혁신에 미치는 영향

     * 진입장벽: 컴플라이언스와 관련된 상당한 비용(수수료, 감사, 법률 자문 등)은 중소기업과 스타트업에 상당한 진입장벽을 만들 수 있음. 이는 경쟁을 제한하고 기존 대기업에 권력을 집중시켜 궁극적으로 혁신을 저해함.
     * 연구에 대한 위축 효과: 의도치 않게 법안 조항을 위반할 것에 대한 두려움은 연구자와 개발자들이 자기 검열을 하거나 유망한 AI 연구 분야를 탐구하는 것을 회피하도록 만들 수 있음. 이는 과학적 진보를 저해하고 사회적 문제를 해결하기 위한 AI의 잠재력을 제한할 것임.
     * 인재 유출: 이 법안으로 인해 조성된 제한적 환경은 유능한 AI 연구자와 개발자들을 캘리포니아 주에서 밀어낼 수 있으며, 주 경제에 해를 끼치고 AI 혁신을 주도하는 입지를 약화시킬 수 있음.

대안적 접근 방식

     * 오픈소스 개발 지원: 협업, 투명성, 더욱 다양하고 탄력적인 AI 생태계 조성을 위해 AI 모델의 오픈소스 개발을 장려하고 촉진할 것.
     * 개발이 아닌 사용에 초점: AI 모델 개발을 규제하는 대신, 특히 공공 안전과 보안에 높은 위험을 초래하는 애플리케이션에 초점을 맞출 것. 건강관리, 형사사법, 중요 인프라 등 피해 가능성이 가장 높은 고위험 영역에서의 AI 사용을 규제하여 유해한 사용에 대한 책임을 묻되, AI 기술의 지속적인 발전은 허용할 것.
     * 투명성과 협업 촉진: 산업계, 학계, 정부 간 협력을 통해 책임감 있는 AI 개발을 위한 모범사례 개발과 채택을 장려할 것. 여기에는 산업 표준 수립, 오픈소스 개발 육성, AI 안전 연구에 대한 투자 등이 포함될 수 있음.
     * AI 전문성에 투자: 정부 기관이 AI에 대한 전문 지식을 개발하고 잠재적 위험을 효과적으로 모니터링하고 해결할 수 있는 역량을 구축할 수 있도록 자원을 제공할 것. 이를 통해 안전과 혁신의 균형을 이루는 더욱 정보에 입각하고 미묘한 AI 규제 접근법이 가능할 것임.

GN⁺의 의견

     * 오픈소스 모델의 개발을 규제하는 대신 규제 당국은 오픈소스 개발을 장려하고 감독하는 역할을 해야 함. 오픈소스는 투명성과 협업을 증진시킬 뿐만 아니라 다양한 관점을 제공하므로 오히려 안전성을 높이는 데 도움이 될 수 있음.
     * AI 모델 자체를 규제하기보다는 고위험 분야에서의 AI 활용에 대해 감독하고 규제하는 것이 더 효과적일 것임. 건강, 사법, 공공 안전 등 위험도가 높은 분야에서의 AI 활용에 대해서는 엄격한 가이드라인과 규제가 필요하지만, 저위험 분야에서는 AI 기술 발전을 저해하지 않는 선에서 규제해야 함.
     * 이 법안이 AI 개발에 지나친 부담을 줌으로써 캘리포니아가 AI 분야에서 선도적 위치를 잃을 위험이 있음. 혁신을 저해하지 않으면서도 유해한 사용에 대해서는 책임을 물을 수 있는 대안적 접근 방식을 모색해야 할 것임.
     * 정부는 AI에 대한 전문성을 키우고 AI 생태계에 대한 이해를 높여 보다 현명한 규제 정책을 펼칠 필요가 있음. 단순히 규제를 강화하기보다는 산학연 협력을 통해 바람직한 방향으로 유도해 나가는 노력이 필요해 보임.

        Hacker News 의견

     * 모델 개발자는 웹 브라우저, 계산기, 워드 프로세서 개발자와 마찬가지로 모델이 해로운 용도로 사용되지 않도록 완벽히 보장할 수 없음. 이런 범용 도구 제작자에게 책임을 지우는 것은 사실상 대기업의 법무팀만 가능하게 만듦.
     * 정치인들은 오픈소스 AI에 강력히 대응 중임. 소로스는 기업과 정부의 AI 프로젝트 시너지가 냉전시대 독재자들보다 더 큰 위협이 될 수 있다고 말함. ""독재 정권과 IT 독점 기업의 결합은 개방 사회에 내재적 우위를 부여하며 치명적 위협""이라고 함.
     * 블로그에는 언급되지 않았지만, 2024년 2월 7일 캘리포니아 주의회에서 SB-1047 법안이 소개됨. 선진 AI 모델 개발과 사용을 규제하기 위한 것으로, 개발자에게 안전성 평가, 안전 요구사항 준수, 사고 보고 등을 의무화하고 기술부 산하에 감독 기구를 신설함.
     * 이런 규제로 기존 선두 AI 기업에 유리하고 신규 진입은 불가능해질까 우려됨. 스콧 위너의 주택 정책은 좋았으나 이 법안은 정부의 과도한 간섭임.
     * 정부가 허용한 것만 학습할 수 있고, 새로운 부서와 수수료 부과 권한이 생기며, 당연히 컨설턴트 고용도 의무화됨.
     * 장기적으로 AI 스타트업에 유리한 주는 어디일까? 캘리포니아는 아닐 듯. 워싱턴이나 텍사스는 아직 규제 움직임이 없고 장점도 있어 보임.
     * '적용 대상 모델'의 정의가 모호함. Int와 float 연산은 계산량이 크게 다른데 법정에서 문구 해석 여지가 있음. 현재 벤치마크 기준으로 미래까지 고정시켜 알고리즘 발전과 무관하게 제한하려 함.
     * 이 기사는 LLM이 생성한 것 같은 수준 낮은 내용임. 법안을 제대로 이해하려면 Zvi의 분석을 읽어보는 게 좋음.
     * 이 기사 전체가 ChatGPT가 쓴 것처럼 느껴짐. 막연히 오픈소스의 가치를 언급하면서 원 법안은 인용조차 안 함.
     * ""AI 모델 개발 대신 활용, 특히 공공 안전에 위험한 분야를 규제하자""는 의견이 있음. 의료, 형사사법, 핵심 인프라 등 위험이 큰 분야에서의 AI 사용을 규제해 유해한 사용에 책임을 묻되 AI 기술 발전은 허용하자는 것인데, 이에 대한 반론이 있을까?
"
"https://news.hada.io/topic?id=14611","새로운 발견, 고대 화성에 지구와 유사한 환경 존재 가능성 시사","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  새로운 발견, 고대 화성에 지구와 유사한 환경 존재 가능성 시사

화성 Gale 분화구에서 발견된 망간 농집 사암층

     * NASA의 Curiosity 로버는 화성 Gale 분화구에서 미생물 생명체를 지탱할 수 있는 환경에 대한 증거를 계속 찾고 있음
     * 로버에 탑재된 ChemCam 장비를 이용한 연구팀이 Gale 분화구 내 호수 바닥 암석에서 평소보다 높은 농도의 망간을 발견함
          + 이는 퇴적물이 고대 호수의 강, 삼각주 또는 해안가에서 형성되었음을 시사함
          + Journal of Geophysical Research: Planets 저널에 연구 결과 게재됨

화성 표면에서 망간 산화물 형성의 어려움

     * 연구를 주도한 로스앨러모스 국립연구소의 Patrick Gasda는 화성 표면에서 망간 산화물이 형성되기 어렵기 때문에 해안가 퇴적물에서 이렇게 높은 농도로 발견될 것으로 예상하지 않았다고 설명함
          + 지구에서는 광합성 생명체가 만들어내는 높은 대기 중 산소 농도와 망간 산화 반응을 촉진시키는 미생물 때문에 이런 종류의 퇴적물이 흔히 발생함
     * 화성에는 생명체의 증거가 없고, 고대 대기에서 산소를 생성하는 메커니즘이 불분명하기 때문에 망간 산화물이 어떻게 형성되고 농축되었는지가 수수께끼임
          + 이번 발견은 화성 대기나 지표수에서 더 큰 규모의 과정이 일어났음을 시사하며, 화성에서의 산화 작용을 이해하기 위해서는 더 많은 연구가 필요함을 보여줌

망간이 풍부한 사암층의 형성 과정

     * 연구팀은 호수 해안이나 삼각주 어귀의 모래를 통해 지하수가 스며드는 것과 같이 망간이 이 모래에 어떻게 농축되었는지, 그리고 어떤 산화제가 암석 내 망간의 침전에 영향을 미쳤을지 조사함
          + 지구에서는 대기 중 산소로 인해 망간이 풍부해지며, 이 과정은 미생물에 의해 가속화되는 경우가 많음
          + 미생물은 망간의 다양한 산화 상태를 에너지 대사에 이용할 수 있음
          + 고대 화성에 생명체가 존재했다면 호숫가 암석의 망간 함량 증가는 생명체에게 도움이 되는 에너지원이 되었을 것임

화성 Gale 분화구의 고대 호수 환경

     * ChemCam 장비의 책임자인 Nina Lanza는 이 고대 암석이 보여주는 Gale 호수 환경이 오늘날 지구의 장소와 놀라울 정도로 유사한 서식 가능한 환경을 엿볼 수 있게 해준다고 설명함
          + 망간 광물은 지구 호숫가의 얕고 산소가 많은 물에서 흔히 발견되며, 고대 화성에서 이런 유사한 특징을 발견하는 것은 주목할 만함
     * 이번 연구 결과는 Journal of Geophysical Research: Planets 저널에 게재되었으며, 연구비는 NASA 제트추진연구소가 지원함

GN⁺의 의견

     * 이번 연구 결과는 고대 화성에 지구와 유사한 호수 환경이 존재했으며, 생명체가 살기에 적합한 조건이 갖춰져 있었을 가능성을 시사함. 하지만 실제 생명체의 흔적은 아직 발견되지 않았기에 단정 짓기는 어려움.
     * 화성 표면에서 망간 산화물의 농축이 발견된 것은 매우 이례적인 일로, 이를 설명하기 위해서는 화성 고대 대기와 표면에 대한 이해가 더 필요해 보임. 산소 농도가 높았을 가능성, 망간 산화를 촉진하는 화학반응 등 다양한 시나리오를 검토해봐야 할 것으로 보임.
     * 이번 발견이 화성 생명체 탐사에 직접적인 단서를 제공하지는 않지만, 적어도 화성에도 지구와 유사한 환경이 존재했음을 보여주는 것이라 흥미로움. 앞으로의 추가적인 탐사를 통해 생명체 존재 가능성에 대한 실마리를 찾을 수 있기를 기대해 봄.
     * 망간을 에너지원으로 사용하는 미생물이 지구에 존재한다는 점, 그리고 화성 암석에서 망간이 농축된 것이 발견되었다는 점은 고대 화성에서 비슷한 미생물이 존재했을 가능성을 완전히 배제하기 어렵게 만듦. 물론 추측일 뿐이지만 상상력을 자극하는 발견임.

        Hacker News 의견

     * ""Two Planets""은 1897년에 쓰인 SF 소설로, 화성인들은 인간과 육체적으로는 비슷하지만 윤리, 지성, 과학, 사회적으로 이상적인 인간의 원형임. 그들은 인간을 교육시키고 대신 공기와 에너지를 요구함.
     * 이 소설을 읽은 젊은 독일인 베르너 폰 브라운은 후에 독일과 미국에서 탄도 미사일을 개발하고, 최초의 미국 인공위성과 아폴로 계획에 사용된 NASA 발사체의 로켓을 만듦.
     * 헝가리 출신 과학자들을 가리켜 ""화성에서 온 외계인""이라고 농담 삼아 부른 일화가 있음. 이는 페르미 역설에 대한 실러드의 대답이기도 함.
     * SF 소설이 오히려 해로운 영향을 끼쳤을 수도 있음. 사람들은 SF에서 읽은 내용을 입증하기 위해 근거가 빈약해도 증거를 찾으려 하고, 기술 발전 방향에도 영향을 미쳐 세상을 더 나쁘게 만들기도 함.
     * 화성에 생명체가 있었을 가능성은 있지만, 광합성 이전의 지구는 환원 환경이었음. 산화 환경에서는 복잡한 분자가 안정적으로 유지되기 어려워 생명체가 출현하기 힘듦.
     * 화성이 지구와 비슷했다는 것은 이미 알려진 사실임. 화성에는 한때 지구에서 가장 큰 폭포가 있었고, 바다와 강이 있었음. 핵이 식기 전 4억 년 동안은 작은 지구와 같았을 것으로 이해되고 있음.
     * 1960년대까지만 해도 화성에 생명체가 있을 것이라고 믿을 만했음. 당시에는 화성 표면의 상태가 largely 알려지지 않았기 때문.
     * 태양계 행성들의 나이를 확실히 알 수는 없음. 우주의 나이에 대한 불확실성이 최근 제기되었고, 행성들의 나이가 우리가 생각하는 것보다 더 오래되었을 가능성도 있음.
     * 화성에 일어난 일이 지구에도 일어날 수 있다는 점, 그리고 그렇다면 ""거대 필터""가 우리의 미래에 있을 것이라는 점이 두려움. 우리 은하에는 지구와 같은 행성이 많이 있어야 하는데 외계인과 접촉하지 못한 것은 페르미 역설을 낳음.
     * 지구에서 가장 부유한 사람이 화성인 조상들이 원래 출발했던 곳으로 돌아가려 한다는 것이 역설적임.
     * 19세기 문명이 자신들의 행성이 죽어가고 있음을 깨닫고 탈출하기 위해 경주를 벌이는 상상을 해 볼 수 있음. 그러나 지구와 같은 상태에서 현재의 상태로의 전환은 매우 느려서 수 세기에 걸쳐서도 알아채기 어려웠을 것임.
"
"https://news.hada.io/topic?id=14511","좋아하는 Tech 유튜버가 있나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          좋아하는 Tech 유튜버가 있나요?

     * Lobsters에 올라온 여러 추천 답변의 링크들 모음

프로그래밍 및 컴퓨터 과학:

     * PrimeTimeagen Primeagen: 프로그래밍 언어와 도구에 대한 재미있고 좋은 해설을 제공함.
     * ArjanCodes: Python 코딩을 다룸.
     * Theo: JS/TS 프로그래밍을 다룸.
     * Hynek: Python 프로그래밍을 다룸.
     * Ben Awad: 재미있는 프로그래밍 관점을 제시함.
     * Chris Titus: Linux 튜토리얼을 제공함.
     * Tweag: 프로그래밍과 NixOS를 다룸.
     * Matt Pocock: TypeScript를 다룸.
     * Func Prog Sweden: 함수형 프로그래밍 강연을 제공함.
     * ByteByteGo: 시스템 설계를 다룸.
     * SystemCrafters: Emacs를 다룸.
     * RockTheJVM: Scala를 다룸.
     * FunctionalTV: 프로그래밍/AI 컨퍼런스 강연을 제공함.
     * InfoQ: 프로그래밍 컨퍼런스 강연을 제공함.
     * leddoo: Rust 언어 채널.
     * Daniel Amber: Clojure를 다룸.
     * Marco Codes: Java와 JVM을 다룸.
     * Nader Dabit: Web3와 AI를 다룸.
     * Protesilaos Stavrou: Emacs를 다룸.
     * System Crafters: Emacs, Scheme, Guix를 다룸.
     * Dreams of Code
     * ThePrimeTimeagen
     * Asahi Lina: Apple M 플랫폼에 Linux를 가져오는 것을 다룸.
     * CharmCLI: 많은 명령줄 Go 및 관련 동영상을 제공함.
     * CMU Database Group: 데이터베이스에 대한 훌륭한 동영상을 제공함.
     * Computerphile: 복잡한 컴퓨터 주제를 설명하는 짧은 동영상을 제공함.
     * DepthBuffer: 훌륭한 시각 자료와 함께 저수준 컴퓨터 과학을 다룸.
     * Fasterthanlime: Rust를 다룸.
     * javidx9: 특별한 관점에서 프로그래밍 튜토리얼을 제공하며, 보통 매력적임 (예: 처음부터 올드스쿨 둠 같은 FPS 만들기).
     * Jon Gjengset: 아마도 YouTube에서 최고의 Rust 콘텐츠를 제공함.
     * Low Level Learning: 훌륭한 시각 자료와 저수준 주제를 다룸.
     * marcan: Apple M 시리즈에서 작업 중인 Asahi Linux의 리드 개발자.
     * Retro Game Mechanics Explained: 오래된 게임 시스템의 작동 방식에 대한 최고의 시각 자료와 설명을 제공하며, 절대적으로 매력적임!
     * Dave Ackley: 컴퓨팅의 미래에 대한 독특한 아이디어를 가진 사람 중 한 명으로, 이를 증명하기 위해 노력함. 독특한 계산 관점과 함께 제시되는 극단적인 주장보다 훨씬 낫음.
     * Maxime Chevalier: 자주 게시하지는 않지만, 항상 흥미로운 것을 하고 있음. 언젠가 우리 모두의 삶을 개선할 무언가를 발명하거나 우연히 발견할 수 있는 사람 중 한 명임.

개별 프로그래머

     * Chris Penner: ""Optics by Example""의 저자.
     * Jon Gjengset: Rust를 다룸.
     * Andrei Alexandrescu: C++와 D로 유명함.
     * Molly Rocket: Casey Muratori가 진행하는 게임 개발.
     * Jonathan Blow: The Witness로 유명한 게임 개발자.
     * Edward Kmett: Haskell/C++를 다룸.
     * Oliver Charles
     * Ville-Matias Heikkilä: 80년대 Geek 라이프를 묘사하는 향수를 불러일으키는 CGA/EGA 애니메이션.

수학 및 인접 분야:

     * 3Blue1Brown: 훌륭한 시각 자료와 함께 수학 또는 수학 인접 분야를 다룸.
     * Numberphile: Computerphile과 정확히 같지만 수학에 초점을 맞춤.

AI:

     * Yannick Kilcher: AI 논문 리뷰를 제공함.
     * DeepLearningAI
     * Jay Alammar: AI 튜토리얼을 제공함.

기술 하드웨어:

     * Jeff Geerling: 훌륭한 라즈베리 파이 프로젝트를 소개함.
     * GamersNexus: PC 기술 리뷰를 제공함.
     * Optimum: 게이밍 PC 구축에 대한 정말 잘 만들어진 동영상을 제공함.
     * DisplayGuy: 디스플레이에 대한 리뷰와 프리뷰를 제공함.
     * JayzTwoCents: PC 게이밍 기술 리뷰를 제공함.

Nix:

     * NixCon: Nix 컨퍼런스 채널.
     * vimjoyer: Vim 관련 채널.
     * tweag: Tweag 회사 채널.
     * ChrisMcDonough: Chris McDonough의 채널.

소비자 또는 PC 기술:

     * The Verge: 소비자 기술 리뷰를 제공함.
     * MKBHD: 소비자 기술 리뷰를 제공함.
     * Dave2D: 소비자 기술 리뷰를 제공함.
     * DCRainmaker: 피트니스 기술 리뷰를 제공함.

기술적 내용(광의):

     * Allen Millyard: 뒷마당 창고에서 인상적인 것들(주로 오토바이 엔진 관련)을 하고 차를 마심.
     * Applied Science: 자주 있지는 않지만 물건을 만드는 것에 대한 좋은 동영상을 제공함.
     * Chronova Engineering: 개미를 위한 금속 가공.
     * Clickspring: 놀라운 품질의 금속 세공으로, 주로 시대에 맞는 도구를 사용하여 안티키테라 메커니즘을 장기간 제작하는 것을 중심으로 함.
     * Cutting Edge Engineering: 기계 및 기계 작업을 다루지만, 광업 산업 때문에 모든 것이 우리가 익숙한 것의 4배 크기임. 훌륭한 채널.
     * Easy composites: 제품을 홍보하지만, 물건을 만드는 방법도 의미 있게 보여줌.
     * Explosions & Fire: 변두리 어딘가의 창고에서 흥미로운 화학 실험을 하는 미친 과학자 박사과정 학생.
     * Nile Red: 실험실에서 더 많은 화학을 다루며, 보통 재미있는 것을 만드는 것을 목표로 함.
     * Great Scott: 집에서 전자 제품을 만드는 것을 다룸. 좋은 내용이 있음.
     * Inheritance Machining: 주로 선반과 밀링 머신을 사용한 구식 기계 작업.
     * Integza: 포르투갈 출신의 미친 과학자 콘텐츠로, 가끔 과일에 대한 편견이 섞여 있음.
     * Lottie the Tank Whisperer: 오지의 창고에서 낡은 탱크를 복원하는 재미있는 젊은 여성.
     * Not an Engineer: 새로운 채널이지만, 기계 작업에 대해 유망함.
     * Practical Engineering: 튜토리얼보다는 다큐멘터리에 가까우며, 좋은 설명과 모델을 제공함.
     * Tech Ingredients: 이 사람이 캐나다 국방부의 연구개발 부서라고 생각함.

자동차 및 차체 작업:

     * Astill Design: 자동차 쇼에서의 워크어라운드와 호주 자동차 업계의 전설로부터 배우는 실용적인 자동차 제작 튜토리얼이 혼합되어 있음. 범죄적으로 과소평가되고 있음.
     * Backshed: 제 의견으로는 최고의 자동차 채널임. 이 사람은 고물상과 초원에서 오래된 클래식 자동차와 고물 차량을 픽업하여 어떻게든 등록 가능한 상태로 복원함(여기서는 쉬운 일이 아님). 호주 특유의 개성과 작업에 항상 적합한 도구가 없을 수 있는 창고에서 살아남기 위한 유용한 팁들로 가득함. 쇼 작업보다는 실용적인 작업에 초점을 맞춤.
     * Bad Obsession: 이 사람들은 불쾌할 정도로 영국적이지만, 다른 누구보다도 그들의 프로세스에 대해 더 자세히 보여주고 모든 것을 과도하게 설계함. 안타깝게도 이로 인해 자동차 제작에 5년이 걸림.
     * Bennetts Customs Co: 호주에 위치한 캐나다 출신으로 추정되는 사람이 로드를 제작함. 주로 차체 및 금속 작업 내용임.
     * Fitzee's Fabrications: 또 다른 캐나다 출신으로, 차체 작업과 녹 수리에 대한 우수한 튜토리얼 지향 콘텐츠를 제공함.
     * I Do Cars: 애덤 샌들러가 고물상으로 위장하여 불량 엔진을 분해하여 작동 원리와 고장 원인을 보여줌.
     * Make it Kustom: 이 사람(또 다른 캐나다 출신)은 기본적으로 금속 마법사임. 전통적인 핫로드 기술뿐만 아니라 전통적인 금속 성형 및 맞춤 툴링에 대한 튜토리얼을 제공함.

Haskell

     * Well-Typed: GHC Haskell에 대한 30분 분량의 교육 동영상.
     * Berlin Functional Programming Group
     * Boston Haskell
     * NYC User's Group

기타:

     * The Cosmonaut Variety Hour: 영화, 게임, TV에 대한 재미있는 해설을 제공함.
     * Fixing Furniture: 그대로 가구를 수리하는 것을 다룸.
     * Nerdforge: 젊은 북유럽 출신들이 훌륭한(보통 조각적인) 예술 작품을 만들고 이를 기록함.
     * Townsends: 다음에 1785년이 되었을 때를 위한 실용적인 팁을 제공함. 훌륭한 제작 품질과 흥미로운 내용으로 꾸준히 제공되어 왔음. YouTube 최고의 채널 중 하나임.

기타 기술 채널

     * Lexie Flores: 콘크리트 운송 기술.
     * blancolirio: 최근 이벤트에 초점을 맞춘 항공 사고.
     * Jago Hazzard: 역사적 관점에서의 영국 철도.
     * Laurie Wired: 리버싱/어셈블리, 훌륭한 제작 품질.
     * City Beautiful: 도시 계획.
     * Asianometry: 대만 편향의 역사.
     * Mental Outlaw: 컴퓨터 보안(Linux).
     * Dave's Garage: Microsoft 전직 직원이 자부심을 가지고 옛 MS 이야기를 들려줌.
     * Money and Macro: 거시 경제학.
     * Vivek Haldar: 컴퓨터 과학 논문 요약.
     * OPLSS: 오리건 프로그래밍 언어 여름 학교로, 프로그래밍 언어 원리 교육에 전념함.
     * HoTT Lectures: Robert Harper가 출연.
     * Developer Voices: 프로그래밍 분야 사람들과의 인터뷰.
     * Jonas Winkler: 독일어로 목공을 다룸.
     * Dr Geoff Lindsey: 영어 언어학.
     * Topos Institute: 범주 이론.
     * Stewart Hicks: 미국 편향의 건축 강의.
     * Jane Street: Richard Eisenberg와 함께한 최근 OCaml 동영상.
     * Jörn Loviscach: 독일어로 된 학부 수학.
     * Bitcoin Optech: 비트코인.
     * decino: Doom.
     * Bahnwelten: 독일어 철도 뉴스.
     * Kennys Film: 덴마크어 철도 뉴스.

게임 및 게임 개발:

     * Acerola: 주로 그래픽 기술적인 내용에 초점을 맞춘 게임 개발자.
     * Pirate Software: 지혜를 전하는 게임 개발자.
     * Shounic: 기술적으로 포함될 수 있음 (TF2/Source 엔진의 내부 구조와 버그 작동 방식을 다룸).
     * Core-A Gaming: 격투 게임의 ""과학""과 역사에 대한 훌륭한 시각 자료를 제공함.
     * Jonathan Blow
     * videogamedunkey: 재미있는 짧은 게임 해설을 제공함.

DIY:

     * Hyperspace Pirate: 주로 DIY 화학 물질 생산을 다룸.
     * Technology Connections: 가전제품의 작동 원리를 설명함.
     * NightHawkInLight: DIY 화학/기계/열역학 관련 내용을 다룸.
     * Plasma Channel: DIY 플라즈마 관련 내용을 다룸.
     * CNC Kitchen: 3D 프린팅을 다룸.
     * Makers Muse: 3D 프린팅을 다룸.

자동차:

     * The Limiting Factor: 전기 자동차 관련 내용을 심도 있게 다룸 (마그네슘 티크시몰딩 등). 트위터를 ""X""라고 부르지만 머스크 추종자는 아님.
     * Aging Wheels: 희귀 자동차와 그 내부를 다룸.

무기 및 군사:

     * Forgotten Weapons: 기술적으로 포함될 수 있음 (역사적인 총기, 그 역사, 작동 방식을 다룸).
     * C&Rsenal: 기술적으로 포함될 수 있음 (역사적인 총기, 그 역사, 작동 방식을 다루며, 모든 동영상이 여러 시간 분량임).
     * Perun: 기술적으로 포함될 수 있음 (주로 우크라이나 전쟁을 다루며 군사 기술을 파고들지만, 군사 경제학 등도 다룸).

보안 및 펜 테스팅:

     * John Hammond: 보안 및 펜 테스팅을 다룸.
     * Shannon Morse: 보통 보안 또는 오픈 소스 관련 콘텐츠를 제공함.

기술 경력 / 관리:

     * Namanh Kapur: 채용/면접 및 경력 조언을 제공함.
     * A Life Engineered: 경력 조언을 제공함.
     * Rahul Pandey: 경력 조언을 제공함.

팟캐스트:

     * More or Less Podcast: 기술 산업에 대한 흥미로운 해설을 제공함.
     * Dwarkesh Patel: 다양한 분야의 게스트와 정말 흥미로운 토론을 진행하지만, 대부분 기술 및 AI에 대한 내용임.

기술 채널:

     * rctestflight: 흥미로운 RC 및 자율 주행 차량을 제작함.
     * bigclivedotcom: 보통 이베이나 알리익스프레스에서 구매한 저렴한 전자 제품, 주로 가짜 제품을 분해함.
     * ConnectionsMuseum: 사설 전화망에서 작동하는 역사적인 전화 장비 박물관. 획득한 괴상한 기계와 그것을 연결하는 방법에 대한 동영상을 제공함. 일요일에 시애틀에 있다면 직접 방문하는 것도 추천함.
     * DeviantOllam: 주로 물리적 보안에 관심이 있음. ""기술 유튜버""로 분류해야 할지는 불분명하지만 포함시켜도 될 것 같음.
     * Andreas Kling (예: Let's port Diablo to SerenityOS!)
     * t3ssel8r (예: Giving Personality to Procedural Animations using Math)
     * SimonDev (예: When Optimisations Work, But for the Wrong Reasons)
     * Bisqwit (예: How I got Mario in That Editor — And how Norton Got )
     * Posy (예: Segmented Displays)
     * Marco Reps: 높은 정밀도 측정 장비와 기준 소스에 대한 감각이 있는 전자 제품 채널.
     * mikeconleytoronto: Mozilla 직원이 매주 자신의 일상 업무 1시간을 공유함.
     * mitxela: 예술적인 기술(또는 기술적인 예술) 프로젝트.
     * RECESSIM: 이전에는 스마트 미터 관련 내용이 많았지만, 현재는 기술 뉴스 쇼를 진행 중.
     * Stuff Made Here: 정교한 로봇 공학과 바보 같은 아이디어가 결합되어 있으며, 약간 유튜버스러움.
     * styropyro: 광기에 대한 성향이 있는 화학 전공자.
     * The Serial Port: 당대의 정확한 기술을 사용하여 레트로 ISP를 재건함.
     * there oughta be: 극도로 잘 촬영된 심도 있는 전자 제품 및 프로그래밍 프로젝트.

   파이썬 주제의 유튜브 채널 추천합니다. Sentry 재직자가 운영하는 채널입니다 https://youtube.com/@anthonywritescode

   Joma는 없네요 몇년전부터 활동을 안하는거 같긴 합니다

   가전주부, Colorscale 자주 봅니다 ㅎㅎ

   CSS의 마술사 Kevin Powell이 목록에 없다니! 제가 좋아하는 분들 중엔 이 분만 없네요

   확실히 이런거 정리할때는 LLM이 편하네요. 마크 다운으로 링크 포함해서 카테고리로 정리해달라고 한 결과입니다.

   저도 되게 단순한 반복 텍스트 작업(?)은 LLM이 너무 편하더라구요.
   대충 예시 보여주면 쫘아아아악 적용해주니까 좋습니다....!
"
"https://news.hada.io/topic?id=14618","유럽에 드리는 당부의 말, "제발 깨어나시길"","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       유럽에 드리는 당부의 말, ""제발 깨어나시길""

     * ProductHunt의 CTO 이자 앤젤 투자자인 Andreas Klinger가 적은 글 (독일 출신)
     * 유럽 출신임을 자랑스럽게 생각하지만, 유럽이 하향세를 가고 있다는 것에 동의
     * 하지만, 미국 사람들이 얘기하는 것처럼 파멸수준이라고는 생각하지 않음

유럽은 변화가 필요함

     * 미국 프로파간다에 현혹되어 유럽에 대한 부정적 인식을 갖게 됨
          + 유럽인들은 열심히 일하지 않는다는 것은 사실이 아님. 오히려 동유럽 사람들은 미국인보다 더 열심히 일함
          + 유럽인들이 위험 기피적이라는 것도 사실이 아님. 미국 유니콘 기업 창업자의 1/5이 유럽 출신임
          + 세금이 높아 사람들의 동기부여가 안된다는 것도 사실이 아님. 미국 캘리포니아주의 세금과 큰 차이 없음
     * 문제는 마음가짐이나 세금이 아니라 시작 초기 가속화에 생기는 마찰(friction)에 있음
          + 매일 경쟁자보다 1% 더 어렵다면 결국 경쟁에서 이길 수 없음

변화를 위해 필요한 두 가지 제안

    1. EU Inc. 설립이 절실함

     * 미국은 델라웨어주가 스타트업의 법인 설립을 위한 사실상 표준임
          + 이를 기반으로 YC SAFE나 AngelList 같은 표준 문서와 소프트웨어 개발이 가능해짐
     * EU에 투자하려면 30개 이상의 법체계를 이해해야 함
          + 초기 투자 딜에서 변호사 비용 등 추가 비용 발생으로 딜 성사에 방해됨
     * 단일 시장을 넘어 법인 통합을 위한 노력이 필요함

    2. 조기 영어 교육 실시

     * 남부 유럽에서는 간단한 영어도 통하지 않는 경우가 많음
     * 영어를 제대로 구사하지 못하면 취업 기회가 제한되고 고립될 수 있음
     * EU 전역의 미디어와 네트워크 활성화에도 영어가 필수적임

GN⁺ 의견

     * 제안이 지나치게 단순해 보일 수 있지만, 이는 문화적 정체성 문제를 피하기 위한 것임. 완전히 동질화된 유럽을 지향하는게 아니라, 비즈니스를 위한 단일 시장 구축이 목표임.
     * 인도의 DPI(Digital Public Infrastructure) 사례처럼, 표준화를 통해 국가 차원의 문제 해결과 함께 프로토콜 기반의 제품 개발이 가능해짐. 우리에게 노하우가 없다고 생각할 수 있지만 에스토니아가 인도와 협력한 사례가 있음.
     * 추가로 언급하고 싶은 내용들이 더 있지만, 의도적으로 단순한 제안을 하는 것임. 이 두 가지 제안에 대해 어떻게 생각하는지 의견을 듣고 싶음.

   정말 흥미롭습니다. 미국처럼 공교육을 파괴하고, 반지성주의가 만연하고, 탈산업화하고, 정치적 양극화가 심화되면 2021년의 내란 시도를 유럽에서도 볼 수 있을까요? 엔젤투자자면 단순히 특정 분야에 한정 되지 않는 거시적 시야가 요구되야 마땅한데 황당합니다. 팔레스타인인 수백만 명을 노예화하고 사법부를 무력화 하려는 정부에 원리주의자들이 날뛰는 이스라엘 정도면 Mr. Klinger가 바라는 이상적인 국가겠네요. 이스라엘의 스타트업은 대단하니까요!

   사회적인 문제와 경제 제도 변경은 따로 봐야 하지 않을까요...?

   그저 부러운 소리긴 하네요 ... ㅋㅋㅋ 만약 한국에서 한중일 통합 비즈니스 얼라이언스 만들자고 하면 여론이 어떨지

   영국이 Brexit하면서 EU에서 나갔는데, 영어를 공통 언어로 쓰는 상황도 웃프긴 하네요.

   한국도 똑같죠 ㅋㅋ
   뭐 새로운거 시작하면 법으로 . 다때려잡고..
   영어도 네이티브가 아니고
   통합된 VC인프라도 없고.

   심지어 언어 장벽도 더 높고
   시장도 작고...

        Hacker News 의견

   요약:
     * EU의 경제 성장이 미국보다 뒤쳐졌다는 주장은 사실이 아님. 구매력 평가 기준(PPP) 및 1인당 GDP로 보면 EU 경제는 수십 년 동안 미국과 비슷하거나 더 빠른 속도로 성장해 왔음.
     * 실리콘밸리 기술 세계만 보고 미국 전체의 직업윤리를 추정하는 것은 바람직하지 않음. 실리콘밸리는 미국에서 매우 작고 특권층인 소우주에 불과함.
     * 동유럽과 중부 유럽 국가들은 항상 훨씬 더 역동적이고 열심히 일하는 데 개방적이었음. 앞으로 10~15년 내에 진정한 선진국이 될 것으로 확신함.
     * EU는 미국 상무조항 판례에 해당하는 것이 없음. EU에는 우위조항에 해당하는 것이 있지만 문화적, 정치적 영향력으로 인해 미국처럼 같은 효과를 낼 수 없음.
     * 유럽 국가들을 미국 연방정부의 감독하에 자치령으로 편입시키는 것이 더 나은 제안이 될 수 있음.
     * 미국 기술 근로자, 특히 시니어 소프트웨어 엔지니어 이상의 급여는 유럽이나 영국의 절반 정도임. 최고의 인재들은 모두 미국으로 가서 큰 연봉을 받음.
     * EU 국가들, 특히 북유럽 국가들의 세금은 전문직 임금 구간에서 매우 높음. 창업자나 개인 기여자, 관리자들은 이 점들이 EU의 우수 인재와 창업자들이 미국으로 와서 돈을 벌고 회사를 설립하는 이유라고 지적함.
     * 유럽은 ""최고의 기술 허브""라는 근시안적 순위에서 어디에 있는지에 신경 쓸 필요가 없음. 서유럽은 살기 좋고, 가족을 키우고, 은퇴하기에 좋은 곳임.
     * EU 시민으로서 EU가 세계 4위 경제 대국이 되는 것은 정상임. 문제는 수십억 명이 가난한 것임. 인도와 중국이 따라잡는 것을 기쁘게 생각함.
     * 유럽에서의 유럽인과 미국에서의 유럽인 사이에는 큰 차이가 있음. 유럽인들이 유전적으로 기술 기업을 만드는 데 적합하지 않다는 생각은 명백한 허수아비 논증임.
     * EU는 새로운 규제를 만들어 문제를 해결하려 함. 법률 개정 대신 많은 새로운 규제를 추가하고 있음.
     * EU의 단일시장은 ""단일 시장""이지 ""단일 마켓플레이스""가 아님. 시장은 고객이지 기업, 은행, 법원이 아님.

     유럽 국가들을 미국 연방정부의 감독하에 자치령으로 편입시키는 것이 더 나은 제안이 될 수 있음.

   이거 비꼬는 의견이죠?

   거기 댓글에도 이거 농담이지? 너무 미국입장인데 라고 뭐라 하는 사람들이 있네요.

   그런데.. LLM에 프롬프트로 요약하면서 저런 비꼬는 문장은 빼라고 지시했는데 못뺐군요. 흑
"
"https://news.hada.io/topic?id=14603","파일 시스템 'File Filesystem' 공개 (2021)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   파일 시스템 'File Filesystem' 공개 (2021)

ffs: UNIX 파일시스템으로 JSON 같은 반정형 데이터를 마운트하는 도구

     * ffs는 File Filesystem의 약자로, 반정형 데이터를 파일시스템으로 마운트해서 익숙한 셸 도구로 JSON, YAML 등 트리 구조의 현대적 포맷을 다룰 수 있게 해주는 도구
     * sed 같은 문자열 처리로 JSON을 편집하는 것은 좋은 방법이 아니므로, ffs를 사용하면 좋음
     * 현재 ffs는 JSON, YAML, TOML을 지원하고 있으며, 더 많은 포맷을 지원할 예정

  ffs 사용 예제

     * ffs [file] 명령으로 file.blah를 file이란 마운트 포인트에 마운트하고, 수정된 최종 버전의 파일은 stdout으로 출력됨
     * ffs -m MOUNT file로 명시적인 마운트포인트를 지정할 수 있음
     * ffs -o OUTPUT으로 출력 파일을 지정할 수 있음
     * ffs -i file로 파일을 직접 편집할 수 있으며, 볼륨 마운트 해제시 결과가 file에 다시 쓰여짐
     * 편집시 nose 키의 값이 문자열이 아닌 숫자로 되고, pockets 디렉토리가 오브젝트로 변환되는 것을 확인할 수 있음

  ffs 설치 방법

     * Linux에서는 FUSE가, macOS에서는 macFUSE가 필요
     * 단일 실행파일을 다운로드 받을 수 있음
     * 소스에서 빌드도 가능

  ffs에 대해 더 알아보기

     * PLOS 2021에서 ""Files-as-Filesystems for POSIX Shell Data Processing"" 논문 참고
     * 데모 영상과 발표 영상 제공

  관련 도구 비교

     * jq, gron 등은 CLI에서 JSON을 다루기 위한 좋은 도구
     * ffs는 다양한 포맷 지원, 익숙한 셸 도구로 편집 가능, 새로운 언어 학습 불필요 등의 장점
     * 단, Windows 미지원, FUSE 사용 불가, 검색만 필요할 때, 매우 큰 파일인 경우 등은 ffs가 적합하지 않을 수 있음

GN⁺의 의견

     * JSON, YAML, TOML 등 현대 웹 개발에서 많이 사용되는 반정형 데이터를 다루는데 유용해 보임. 특히 셸 스크립트로 자동화 작업을 하는 경우 강력할 듯
     * 단, FUSE 기반이라 성능 이슈가 있을 수 있고, 윈도우 미지원이 아쉬움. WSL에서는 사용 가능할지 모르겠음
     * 오픈소스인 만큼 다양한 포맷을 지원하도록 기여할 수 있다는 것이 장점. 사용자 입장에서는 편의성과 생산성 향상에 도움이 될 듯
     * sed나 awk 같은 고전적인 텍스트 처리 도구에 익숙한 엔지니어라면 학습 비용 없이 바로 적용 가능
     * API 응답을 로컬에 저장해서 디버깅하거나, 반정형 설정파일을 자주 수정해야 하는 경우 유용할 듯

        Hacker News 의견

     * 사용자가 직접 개발한 libfuse를 Nim으로 래핑하여 'hello' 파일 시스템 예제를 포팅하고, 데이터를 파이프로 전달하고 마운트 포인트를 제공하는 버전을 만듦. 완료되면 stdout을 통해 결과를 씀. 이를 통해 파이프 체인에 인라인으로 사용할 수 있지만 출력을 확실히 가져와야 함.
     * 현재 파일 시스템으로 만들 수 있는 다른 것들을 모색 중임. Nimdow 윈도우 매니저용 상태 표시줄을 만들어 개별 파일에 내용을 쓰면 블록이 있는 막대를 출력으로 만듦. 상태 표시줄에 있는 내용을 쉽게 교체할 수 있어 매우 편리함.
     * libvlc를 사용하는 음악 플레이어도 만듦. ID3 태그가 있는 미디어를 읽고 '아티스트별', '앨범별' 등의 폴더를 설정함. 각 파일은 '<트랙 번호> - <노래 제목>'으로 명명되고 실제 파일의 전체 경로를 포함함. 노래를 재생하려면 이러한 파일 중 하나를 'control/current'에 캣하고 'control/command'에 play라는 단어를 씀. 재생 목록 기능과 더 많은 명령어 등이 있지만 기본 아이디어는 이것임. 목표는 초강력 스크립팅 가능한 음악 플레이어를 만드는 것임.
     * Unix 계열 OS는 디스크 이미지를 마운트하여 내용을 탐색할 수 있음. 그러나 파일 내부 파일 탐색에 유용한 파일 형식은 더 많음. 압축 아카이브가 그 중 하나임. 일부 파일 관리자는 이를 지원하지만 애플리케이션 수준은 이 기능을 넣기에 최적의 계층이 아님. 파일 유형별 드라이버로 구현할 수 있음.
     * 마운트되는 동안 메모리 내에서 실행되다가(tmpfs처럼) 마운트 해제되면 디스크의 단일 파일로 직렬화되는 FUSE 파일 시스템을 찾고 있음. 아카이브 파일을 마운트하는 FUSE 드라이버가 가장 유사하지만 심볼릭 링크와 같은 것은 얻을 수 없음.
     * Git 커밋을 파일 시스템으로 마운트할 수도 있음. (링크 참조)
     * Parts-of-file File System도 있음. (Usenix 링크 참조)
     * Omar Rizwan의 TabFS를 연상시킴. (링크 참조)
     * 2003년에 이런 것을 해봤음. 놀랍게도 빠르고 세분화된 잠금을 쉽게 만듦. 거대한 웹사이트 구축 도구를 위한 웹 템플릿 언어의 사용자별 데이터베이스로 사용했음.
     * JSON 키에 슬래시가 있으면 어떻게 되는지에 대한 질문.
     * 이를 통해 파일을 디렉토리 구조로 커밋할 가능성이 열림. 이것이 병합 및 충돌에 어떤 영향을 미칠지 궁금해 함.
     * 멋져 보이며 가능한 한 빨리 시도해 봐야겠다는 의견. JSON 파일 내부를 검색하고 탐색하는 데 유용할 것 같음.
"
"https://news.hada.io/topic?id=14549","Zilog Z80 CPU - 현대적이고 무료이며 오픈 소스인 실리콘 클론","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Zilog Z80 CPU - 현대적이고 무료이며 오픈 소스인 실리콘 클론

Zilog Z80 CPU의 오픈소스 실리콘 클론 개발

     * 2024년 4월 15일, Zilog사는 역사상 가장 유명한 8비트 CPU 중 하나인 Z80의 단종을 발표함
     * 오픈소스 및 하드웨어 보존 커뮤니티가 Zilog Z80을 대체할 수 있는 자유 오픈소스 실리콘(FOSS) 개발에 착수할 시기임
     * FOSS Z80의 첫 번째 제작은 2024년 6월로 예정되어 있음

  FOSS Z80의 첫 번째 실리콘 버전

     * 첫 번째 버전은 Tiny Tapeout 07을 사용하여 130nm 공정으로 개발되었으며, 0.064mm² 다이 면적에 맞춰짐
     * 첫 번째 제작은 2024년 6월 CI 2406 셔틀의 일부로 예정되어 있음
     * 구현은 Guy Hutchison의 TV80 Verilog 코어를 기반으로 함
     * OpenROAD의 자동 배치 및 배선 플로우를 사용하여 130nm ""게이트"" 로직 요소로 생성된 FOSS Z80의 GDSII 집적 회로 레이아웃 이미지가 제시됨

  향후 계획 및 할 일

     * 테스트 벤치에 '불법' 명령어 실행 테스트 ZEXALL 추가
     * A-Z80, Z80Explorer 등 다양한 Verilog 코어 구현 비교
     * ChipIgnite에서 QFN44 패키지로 제작
     * DIP40 패키지로 제작
     * 원래 Z80 레이아웃과 유사한 게이트 레벨 레이아웃 생성 (Zilog은 Z80을 설계할 때 각 트랜지스터를 수작업으로 배치함)

Z80 CPU 정보

  핀 배치도

     * Z80 CPU의 40개 핀에 대한 배치도 제시

  문서

     * Z80 사용 설명서 (Zilog, Mostek 버전)
     * Zilog 데이터 북
     * Z80에 대한 모든 정보
     * 문서화되지 않은 명령어
     * 명령어 테이블 및 타이밍

  Z80 개발에 대한 구술 역사

     * Z80 마이크로프로세서 개발 및 회사 설립에 대한 구술 역사 패널
     * M. Shima의 마이크로프로세서 설계 해설

  Z80 특허

     * 입력 전압 스파이크 보호에 대한 특허 (US4605980, 만료됨)
     * 리셋 회로에 대한 특허 (US4486827A, 만료됨)
     * 기타 특허 (US4332008A, 만료됨)

  Z80 다이 사진

     * 다이 사진 읽는 법
     * 다양한 Z80 버전 및 클론 칩들의 다이 사진 (Zilog, Nintendo, Mostek, National Semiconductor, Soviet 등)

  Z80 역설계

     * Z80 명령 레지스터 해독
     * Z80 데이터 및 주소 버스 게이트의 3상 동작
     * Z80의 (비)문서화된 동작
     * Z80 마이크로프로세서의 명령어 디코딩 PLA
     * Z80의 데이터 핀이 뒤섞여 있는 이유
     * Z80 레지스터의 구현 방식
     * Z80의 16비트 증감 회로 역설계
     * Z80의 4비트 ALU
     * XOR 게이트 및 흥미로운 두 가지 게이트의 실리콘 설명
     * WZ (MEMPTR) 레지스터 - Z80의 난해한 레지스터

  기존 Z80 구현체

     * TV80 (Verilog) - Guy Hutchison 버전
     * TV80 (Verilog) - Obijuan 버전
     * A-Z80 (Verilog)
     * Z80 네트리스트 레벨 에뮬레이터 (Z80Explorer)

Tiny Tapeout 소개

     * Tiny Tapeout은 디지털 설계를 실제 칩으로 제조하는 것을 더 쉽고 저렴하게 만드는 것을 목표로 하는 교육 프로젝트
     * 자세한 내용 및 시작 방법은 https://tinytapeout.com 참조

  관련 리소스

     * FAQ
     * 디지털 설계 강의
     * 반도체 동작 원리 학습
     * 커뮤니티 참여
     * 로컬에서 설계 구축

GN⁺의 의견

     * Z80은 8비트 CPU의 역사에서 큰 역할을 했던 프로세서로, FOSS 버전 개발은 의미있는 시도임
     * 특히 Skywater 130nm PDK를 사용해 실제 실리콘으로 제작하는 것은 오픈소스 하드웨어 생태계 발전에 기여할 수 있음
     * 다만 Z80의 명령어셋이 现代的인 관점에서 다소 구식이며, 실용성 측면에서는 의문
     * 레트로 컴퓨팅이나 교육용으로는 가치가 있겠지만, 상용 제품에 사용되기는 어려울 것으로 보임
     * 역설계를 통해 Z80의 설계 디테일을 파악하는 것은 프로세서 아키텍처를 학습하는데 매우 유익할 것
     * FPGA 등을 통해 쉽게 에뮬레이션 할 수 있는 Verilog 코어들이 잘 준비되어 있어, 접근성이 높음
     * RISC-V, OpenPOWER 등 최신 오픈소스 프로세서들과의 비교 분석도 흥미로운 연구 주제가 될 수 있을 것

        Hacker News 의견

     * Tiny Tapeout이 메이커와 학생들에게 저렴한 가격에 자신만의 칩 설계를 실현할 수 있게 해준 것이 놀라움
     * 130nm 공정으로는 차세대 Intel CPU를 설계할 수는 없겠지만, Z80이 0.064 mm2에 들어간다는 것 자체가 대단함
     * 공식 칩 생산이 중단되는 상황에서 대안이 생겨난 것은 기쁜 일임
     * 금으로 도금된 커버와 화려한 자주색 세라믹 패키지를 갖고 싶어 함
     * Z80의 라이벌인 6502와 그 파생 제품들은 원래 제작자 중 한 명에 의해 여전히 생산되고 있음
          + 따라서 Z80 진영에서 비슷한 일이 벌어질 가능성은 당분간 없어 보임
          + 관련 링크: Western Design Center의 6502 칩 목록
     * Z80은 ZX 스펙트럼의 CPU였음
          + 관련 링크: ZX 스펙트럼 - 위키백과
     * 원본 Z80과의 호환성에 대한 의문
          + Z80은 문서화되지 않은 명령어와 ""트랩 게이트""가 있었는데, 이는 일부 명령어 시퀀스에 영향을 미칠 수 있었음
          + 이는 Z80과 클론을 구별하기 위한 것이었음
     * 회로 레이아웃이 일반적인 다이 사진에서 볼 수 있는 커스텀 레이아웃이 아니라 균일한 게이트 어레이처럼 보임
     * ""마지막 구매"" 기회로 Z80 칩에 전 재산을 쏟아부은 것이 후회됨 (농담)
     * Z80의 4비트 ALU(8비트 연산 시 2개 사용)가 주요 병목으로 여겨지는지, 이후 확장을 통해 고비트 정수 연산이 추가되었는지 궁금함
     * 오픈 소스 버전의 칩이 새로운 기능과 변종을 가능하게 할지 궁금함
     * (초기 efabless.com 팀에 있었던 사람의 코멘트) 오픈 소스 EDA가 멋져 보임
     * Z80이 출시된 지 50년이나 되었다는 사실에 놀라움
     * 시중에 넘쳐나는 중고 Z80 칩과 가격 경쟁력 면에서 어떨지 궁금해 함
"
"https://news.hada.io/topic?id=14585","미국 마약단속국, 마리화나 재분류 추진 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        미국 마약단속국, 마리화나 재분류 추진 예정

   Here is a summary of the key points from the news article, organized into bullet points using Markdown:

美 마리화나 규제 완화 추진, 역사적 전환점

     * 미국 마약단속국(DEA)이 마리화나를 덜 위험한 약물로 재분류하는 방안을 추진 중임. 이는 수십 년간 이어진 미국 마약 정책의 역사적 전환점이 될 전망.
          + 백악관 예산관리국(OMB)의 검토를 거쳐야 하며, 오락용 마리화나 합법화는 아님.
          + 현재 헤로인, LSD와 같은 Schedule I 약물에서 케타민, 일부 동화 스테로이드제와 같은 Schedule III로 재분류 예정.
          + 연방 보건복지부(HHS)의 권고에 따른 조치로, 대중의 의견 수렴과 행정법 판사의 검토 후 최종 발표될 것임.
     * 조 바이든 대통령은 2022년 10월 연방 마리화나법 검토를 지시하고, 단순 소지 혐의로 기소된 수천 명을 사면하는 등 마리화나 정책 변화를 주도해 옴.
          + 마리화나 전과로 인한 고용, 주거, 교육 기회 제한 등의 불필요한 장벽을 제거하겠다는 입장.
          + 여론조사 결과 성인의 70%가 마리화나 합법화를 지지하는 등 여론의 변화가 뒷받침되고 있음.
     * Schedule III 약물도 규제 대상이며, 허가 없이 거래하면 연방 형사 기소 대상이 될 수 있음.
          + 마리화나를 여전히 게이트웨이 약물로 보는 비판적 시각도 있음.
          + 반면 의료용 마리화나를 합법화한 주는 38개, 오락용을 합법화한 주는 24개에 달해 주 정부 정책을 연방 정부가 따라잡는 모습.
     * 마리화나 산업은 약 300억 달러 규모로 성장했으며, 연방 규제 완화는 세금 부담 경감과 연구 활성화에 기여할 것으로 보임.
          + 다만 국제 조약상 의무 준수, 마약과의 전쟁에서의 의도치 않은 결과 등은 우려 사항으로 제기됨.

GN⁺의 의견

     * 마리화나 재분류가 연방 정부 차원에서 추진되는 것은 매우 상징적인 변화임. 다만 실질적인 파급력은 제한적일 수 있음.
          + 주 정부 차원의 합법화가 이미 상당히 진행된 상황이며, 단순 소지 혐의에 대한 연방 기소는 많지 않았기 때문.
          + Schedule III로 분류되어도 통제 물질로서 DEA의 규제를 받게 되는데, 수만 개의 마리화나 판매점들이 엄격한 보고 의무를 감당하기는 쉽지 않아 보임.
     * 산업적으로는 마리화나 관련 투자와 연구 활성화에 도움이 될 것으로 보임. 그러나 과도한 상업화로 인한 부작용은 없을지 우려됨.
          + 미국의 마리화나 정책이 전 세계에 상당한 영향력을 미치는 만큼, 국제 사회와의 공조도 필요해 보임.
     * 한편으로는 미국의 마약과의 전쟁이 패배를 인정하는 것 아니냐는 비판도 제기될 수 있음.
          + 펜타닐 중독 사망자가 연 10만 명을 넘는 상황에서 마리화나 단속에 쏟아붓는 행정력의 재배분은 필요해 보이나,
          + 국민 건강 증진이라는 큰 방향성 속에서 종합적인 마약 정책 수립이 요구됨.

        Hacker News 의견

   주요 내용을 다음과 같이 요약해 볼 수 있음:
     * 대마초 상점들이 은행과 결제 프로세서를 합법적으로 이용할 수 있게 됨. 연방 차원에서 불법이었기 때문에 주 내에서만 재배, 가공, 판매가 이루어져야 했고, 이로 인해 지역 고용이 창출되기도 함.
     * 연방 제한이 풀리는 것은 긍정적이지만, 중소기업들이 대기업에 흡수될 것을 우려하는 의견도 있음.
     * DEA 전 부국장은 대마초가 ""게이트웨이 약물""이 될 수 있다는 우려를 표명함. 반면 펜타닐로 인한 사망자가 연간 10만 명 이상임을 지적하며 자원을 펜타닐 퇴치에 사용하는 것이 긍정적이라고 봄.
     * 새 정부가 들어서면 정책 변화가 번복될 가능성이 있음. 의회가 움직이지 않는 상황에서 행정부 조치가 최선일 수 있음.
     * 1961년 마약에 관한 단일협약에 따르면 대마초를 범죄화해야 함. 미국이 협약에서 탈퇴하더라도 동맹국들이 크게 반발하진 않을 것으로 보임.
     * 피해자가 없는 ""범죄""에 대한 제한은 사법 제도에 대한 신뢰를 떨어뜨림. 알코올도 스케줄 III로 재분류되어야 한다는 의견 있음.
     * 향후 사이키델릭 약물도 재분류되기를 바라는 의견과, 카트(khat)와 같은 덜 해로운 각성제도 함께 합법화되어야 한다는 의견도 있음.
     * 연방 공무원들이 합법화된 주에서 대마초를 사용할 수 있을지에 대한 궁금증 제기됨.
     * 기존의 소규모 대마초 상점들이 어떤 영향을 받을지에 대한 우려와, 대기업들이 브랜드 등록 등을 선제적으로 진행하고 있을 것이라는 추측도 나옴.
"
"https://news.hada.io/topic?id=14616","보잉 협력사 Spirit AeroSystems 내부고발자 조시 딘 사망","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                보잉 협력사 Spirit AeroSystems 내부고발자 조시 딘 사망

        Hacker News 의견

     * 보잉의 문제점을 지적한 사람들이 사망한 것에 대해 처음에는 충격을 받았지만, 많은 사람들이 보잉의 문제를 알고 있는 상황에서 몇 명의 사망자가 발생하는 것은 그렇게 놀랍지 않음
     * 폐렴과 뇌졸중은 은폐를 위해 의도적으로 유발되기 어려운 질병이므로, 이는 불행한 질병으로 보임
     * 보잉 엔지니어들이 암살을 정당화할 만큼 민감한 일을 하고 있는지 의문이며, 핵 코드 같은 것을 다루는 것은 아닌지 궁금함
     * 다른 내부고발자들이 있다면 그들의 심정이 궁금함
     * MSRA가 아니라 MRSA(메티실린 내성 황색포도상구균)의 오타였음. 이는 형편없는 팩트 체크를 보여줌
     * 한 여성이 지역 공항의 안전 위반 사항을 보고했지만 무시당하자 FAA에 신고했고, 이후 위협 전화, 자녀 사진 받기, 총격 사건, 개 살해 등을 겪었으나 경찰은 아무 조치도 취하지 않아 결국 직장을 그만두고 이사를 가야 했음
     * 지난 50년간의 주요 내부고발자들을 살펴본 결과, 심각한 괴롭힘과 위험을 느꼈지만 민간 기업에 의해 살해당한 경우는 플루토늄 취급과 관련된 1970년대 사례 단 한 건뿐이었음. 정부에 의한 내부고발자 살해는 자주 일어남
     * 폐렴에 걸리고 MRSA 감염 후 뇌졸중을 겪었다는 것이 갑작스러운 일인지 아닌지 불분명함
     * 보잉의 내부고발자가 많을 수도 있음
     * 내부고발이 스트레스가 크고 건강에 해로울 수 있다는 설명이 가능함
"
"https://news.hada.io/topic?id=14499","IBM, HashiCorp 64억 달러 인수 계약 체결","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     IBM, HashiCorp 64억 달러 인수 계약 체결

        Hacker News 의견

     * Hashicorp가 IBM에 인수되면서, 기존의 엔지니어 중심 문화가 사라지고 IBM의 관료주의에 휩쓸려 RedHat이나 CentOS처럼 매력을 잃게 될 것이라는 우려가 있음
     * 한편 이를 계기로 IaC(Infrastructure as Code) 분야에 새로운 혁신의 물결이 일어나 Hashicorp의 독점을 대체할 만한 것들이 나올 것이라는 기대감도 있음
     * Hashicorp 제품들의 통합이 부족했던 점이 선택에 걸림돌이 되었음. Kubernetes의 등장 이후로는 컴퓨팅 플랫폼을 장악하는 것이 Vault 등을 활용하는데 핵심이 되었음
     * 개발에서 프로덕션까지 Hashicorp 제품들을 한번에 통합 환경으로 구성하는 ""원클릭"" 방식이 없었기에, 각자 맞춤 구성을 하게 되고 개별 컴포넌트 단위로 채택 여부를 결정하게 됨. 이를 표준화해서 신생 기업들이 빠르게 시작할 수 있게 하고, 기존 기업들은 필요한 부분만 선택할 수 있게 하며 지원 계약을 팔 수 있었을 것
     * IBM의 클라우드 전략은 통합 플랫폼을 만드는 것이니, Hashicorp 제품들이 마땅히 받아야 할 통합을 이뤄낼 기회는 있음
     * 테라폼 라이선스 변경 때부터 이런 일이 예상되었고, IBM으로의 매각은 아니더라도 창업 비전을 유지하기 어려워 보였음
     * 이미 테라폼에서 OpenTofu로 이전하는 사람들이 있고, 머지않아 다른 제품들도 IBM의 비즈니스 모델에 얽매이지 않은 오픈소스 프로젝트들이 나올 것. 결과적으로는 오픈소스의 또 다른 승리가 될 듯
     * Hashicorp를 거쳐간 사람에게 온 일화. 2015년 델 소프트웨어 취약점을 발견하고 블로그에 올렸더니 이상한 이름의 회사에서 연락이 왔는데, 당시 50명 규모의 series A 투자를 받은 곳이었음. 너무 어려서 기회를 제대로 평가하지 못하고 겁먹어 연락을 끊었지만, 완벽한 결말은 아니더라도 업계에 큰 영향을 미쳤고 그건 축하받을 일이지 슬퍼할 일은 아님
"
"https://news.hada.io/topic?id=14505","프론트엔드 개발자/엔지니어 핸드북 2024","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        프론트엔드 개발자/엔지니어 핸드북 2024

     * 온라인 교육 사이트인 FrontendMasters 가 정리하여 오픈소스로 공개(CC BY-NC-ND)
     * 9개의 챕터로 구성되어 프론트엔드 초보자 부터 전문가까지 참고 가능한 실무 리소스를 종합한 핸드북

챕터별 주요 내용들

    1. 업무 분야 개요 : 프론트엔드 개발자/엔지니어란?, 캐리어 레벨과 보상,..
    2. 분야 : 웹사이트 개발, 웹앱 개발, UX/UI, 테스트, 퍼포먼스, 접근성, 웹 게임
    3. 학습/교육/훈련 : 초기 단계, 학습 코스, 학습 사이트들
    4. 기본 개념: WWW, 인터넷, IP 주소, 도메인, DNS, URL, 서버와 웹호스팅, CDN, HTTP/HTTPS, 웹브라우저, 자바스크립트 엔진
    5. 핵심 역량: 코드 편집기, HTML, CSS, JS, DOM, TypeScript, JS Web API, JSON, ESM, CLI, Node.js, 패키지 매니저, NPM Registry, Git, WCAG & ARIA, 웹 이미지/파일 타입/Data URL, 개발도구
    6. 기타 역량 및 패러다임: A/B 테스팅, AI 개발도구, 알고리듬, 비동기, BaaS, CI/CD, CMS, CSS in JS, 디자인 시스템, DOM 스크립팅, 풀스택 웹 개발, FP, GraphQL, Headless CMS, JAM 스택, JSX, MPA, OOP, Polyfill, PWA, RWD, REST, SEO, SSR, SPA, SSG, Stream SSR, UI 디자인 패턴, Unit Testing, UX, Virtual DOM, WASM, 웹 컴포넌트, 웹 폰트, 웹소켓, 웹 워커, 와이어프레이밍,..
    7. 프론트엔드 개발 툴박스/스택
    8. 전문 경력 준비: 온라인 Presence 만들기, 개발하기, 레쥬메 작성, 인터뷰 준비, 구직 활동
    9. 커뮤니티, 팟캐스트 및 이메일 뉴스레터

   챕터 2에 있는 세분화 항목이 좋네요. 한국은 그냥 두루뭉실하게 프론트엔드 개발자 N년차 이렇게만 JD 있는 곳이 대부분이던데.
"
"https://news.hada.io/topic?id=14556","2024년 AI 스타트업을 위한 데이터 수집 전략","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2024년 AI 스타트업을 위한 데이터 수집 전략

[ #1 대규모 생성형 모델(Large Generative Models) ]

  LLM과 LMM을 활용한 합성 데이터 생성

     * Large Language Model(LLM)은 텍스트 출력을 생성하는 반면, Large Multi-Modal Model(LMM)은 텍스트, 코드, 이미지 등 다양한 형태의 합성 데이터를 생성할 수 있음
     * 실제 데이터가 부족하거나, 개인정보 보호에 민감하거나, 수집 및 레이블링 비용이 높은 분야에서 특히 널리 사용됨 (예: NLP, 컴퓨터 비전, 자율 주행 시스템 개발 등)
     * 합성 데이터는 일반적으로 실제 데이터를 보완하거나 미세 조정(fine-tuning)에 사용되며, 전체를 대체하는 용도로는 사용되지 않음
     * 아무리 정교하더라도 문제 영역에 대한 근사치만 생성할 수 있으며, 과도하게 의존하면 합성 데이터 생성 과정에 존재하는 특성에 모델이 과적합될 위험이 있음
     * 합성 데이터 생성 방법
         1. 자기 개선(Self-improvement): 모델이 지침, 입력 컨텍스트 및 응답을 생성하고, 유효하지 않거나 기존 데이터와 너무 유사한 예제는 필터링되며, 남은 데이터는 원래 모델을 미세 조정하는 데 사용됨
         2. 증류(Distillation): 더 강력한 교사 모델의 지식을 덜 강력하지만 더 효율적인 학생 모델로 전달하는 과정. 합성 데이터가 종종 부정확하더라도 지침 조정(instruction-tuning) 과정에 효과적으로 기여할 수 있음
     * Microsoft는 주로 다른 LLM에서 생성된 합성 데이터로 학습된 Phi라는 일련의 작은 모델을 출시했으며, 대부분의 비전방 모델보다 우수한 성능을 보임
     * Hugging Face는 Microsoft가 사용한 합성 학습 데이터셋의 큐레이션에 대한 정보 부족에 대응하여 이를 재현하는 것을 목표로 Cosmopedia를 만들었음

  LLM을 활용한 데이터 레이블링 및 데이터셋 통합

     * 최신 LLM은 인간 주석자와 동등하거나 더 높은 수준으로 텍스트 데이터셋에 레이블을 지정할 수 있음
     * 인간 주석자와 달리 LLM은 피로나 편견 없이 대규모 데이터셋에 동일한 주석 기준을 일관되게 적용할 수 있음
     * Segment Anything과 같은 대규모 데이터셋으로 학습된 대형 생성 모델은 의미론적 분할(semantic segmentation)과 같은 작업에 전통적으로 사용되는 전문화된 비생성 컴퓨터 비전 모델보다 종종 제로샷 능력으로 더 나은 성능을 보임
     * LLM은 다양한 데이터 소스를 통합하여 통합 데이터셋을 생성하는 데이터셋 스티칭(Dataset Stitching)을 통해 사용 가능한 실제 데이터 풀을 확장하는 데에도 사용될 수 있음

  Grader로서의 LLM

     * 인간 피드백으로부터의 강화 학습(RLHF)은 GPT-3를 채팅을 통해 사용자와의 대화형 상호 작용에 최적화된 획기적인 시스템으로 만든 핵심 미세 조정 기술이었음
     * 이제 인간 대신 LLM을 사용하여 피드백을 제공하는 AI 피드백으로부터의 강화 학습(RLAIF)이라는 접근 방식이 등장했음
     * RLAIF의 주요 장점은 인간을 기계로 전환함으로써 확장성과 비용 절감이 가능하다는 점임

[ #2 데이터 레이블링 플랫폼 ]

     * 초기에는 Amazon Mechanical Turk와 같은 크라우드소싱 및 작업 아웃소싱 플랫폼을 활용하여 저렴한 온라인 인력을 통해 데이터 레이블링이나 정제 작업을 수행했음
     * 최근에는 V7, Scale AI 등 자동화된 데이터 레이블링 및 관리 기능을 제공하는 플랫폼이 발전하고 인기를 끌고 있음
     * 이러한 플랫폼은 규정 준수 및 품질 보증 조치와 함께 대규모 데이터 수요가 있는 기업이 더 효율적으로 확장하고 더 높은 수준의 일관성을 제공할 수 있게 해줌

  플랫폼별 특징 및 신규 플레이어

     * V7은 의료 영상과 같이 높은 수준의 전문성이 요구되는 작업에 중점을 두는 경향이 있는 반면, Scale은 자율 주행 분야에서 성장하여 국방 분야로 확장했음
     * Invisible과 같은 신규 플레이어는 LLM 특화 워크플로우(예: 지도 학습 기반 미세 조정, RLHF, 인간 평가, 레드 티밍 등)를 위한 전문 인력에 대한 수요를 충족시키고 있음
     * 인기 있는 데이터 레이블링 서비스로는 CVAT, Dataloop, Invisible, Labelbox, Scale AI, V7 등이 있음

  인간 주석 데이터 품질 개선 방안

     * 많은 플랫폼이 여전히 어느 정도 인간 주석자에 의존하고 있어, 복잡하고 주관적이며 사회적으로 관련성이 높은 영역에서 AI 적용이 확대됨에 따라 출력 품질 평가에 더 많은 노력이 필요함
     * 다수결, 일치율, 확률 모델링 접근 방식 등을 사용하여 여러 평가자 입력에서 실제 레이블을 추정하고 신뢰할 수 없는 ""스패머"" 평가자를 식별할 수 있음
     * 평가자 간 체계적인 불일치를 포착하고 이를 활용하여 학습을 개선하는 기술(예: 불일치 디컨볼루션, 다중 주석자 모델링 등)이 있음
     * 영향 함수, 학습 중 예측 변화 추적 등을 통해 잘못 레이블된 데이터 포인트를 탐지할 수 있음

[ #3 개방형 데이터셋 ]

     * 2016년 이후 개방형 데이터 운동과 업계, 학계, 정부 간 데이터 공유의 가치 인식으로 인해 개방형 데이터셋이 급증했음
     * 개방형 데이터셋은 대부분의 영역에 존재하지만 특히 컴퓨터 비전, NLP, 음성/오디오 처리, 로봇 제어 및 내비게이션 분야에서 접근성이 높음
     * 이는 커뮤니티 노력(예: Hugging Face, PyTorch, TensorFlow, Kaggle 등)과 대기업의 대규모 데이터셋 공개가 결합되어 발전했음

  개방형 데이터셋 활용 시 고려사항

     * 무료이고 벤치마킹에 도움이 된다는 장점이 있지만 특정 고려사항이 있음
     * 민감하거나 규제가 많은 분야에서는 개방형 데이터셋이 더 희소하고 오래되었으며 규모가 작은 경향이 있음
     * 개방형 데이터의 품질과 최신성은 크게 다를 수 있어 빠르게 변화하는 분야에서는 관련성 문제가 발생할 수 있음
     * 과도한 사용은 인기 있는 데이터셋에 지나치게 의존하여 모델이 벤치마크에서는 잘 수행되지만 실제 응용에서는 성능이 떨어지는 과적합 위험이 있음

  유용한 개방형 데이터셋 리소스

     * Amazon, Google, Microsoft 등 대기업은 다양한 개방형 데이터 허브와 검색 엔진을 보유하고 있음
     * Hugging Face는 관련 도구와 함께 사용 준비가 된 데이터셋 허브를 만들었음
     * Kaggle의 데이터셋 검색 기능
     * VisualData: 컴퓨터 비전 데이터셋을 위한 허브
     * V7은 500개 이상의 개방형 데이터셋 목록을 공개했음

[ #4 시뮬레이션 환경 ]

     * 시뮬레이션 환경은 AI 모델이나 에이전트가 통제된 환경에서 학습하여 합성 데이터를 생성하고, 실제 배포 전에 시스템을 테스트할 수 있게 해줌
     * 실제 데이터를 보완하고 현실에서 접하기 어렵거나 비용이 많이 드는 에지 케이스를 탐색하는 데 특히 도움이 됨
     * 이는 시스템을 안전하게 훈련하고 실제 세계에서 발생할 수 있는 수많은 변수를 고려해야 하는 로보틱스나 자율 주행차 등의 분야에서 특히 인기가 있음

  시뮬레이션 환경 구축 시 고려사항

     * 풍부하고 정확한 물리 모델링이 가능한 3D 시뮬레이션을 처음부터 만들고 검증하는 것은 상당한 자원과 인프라를 필요로 할 수 있음
     * NVIDIA는 Omniverse라는 통합 3D 그래픽 및 물리 기반 워크플로우 플랫폼을 기반으로 하는 시뮬레이션 환경을 포함한 강력한 GPU 가속 로보틱스 플랫폼 ISAAC을 만들었음
     * 비용 부담을 줄이기 위해 오픈 소스 시뮬레이션 환경을 활용할 수 있음
     * Epic Games의 Unreal Engine은 높은 충실도의 그래픽, 사실적인 물리 시뮬레이션, 유연한 프로그래밍 인터페이스 등으로 인해 시뮬레이션 환경 구축을 위한 강력한 도구로 자리잡았음

  활용 사례 및 오픈소스 환경

     * Applied Intuition: 자율 주행 시스템 개발자를 위한 시뮬레이션 및 검증 솔루션 제공
     * Sereact: 창고에서 픽앤팩 자동화를 위해 공간 및 물리적 뉘앙스를 이해할 수 있도록 시뮬레이션 환경을 기반으로 하는 소프트웨어 개발
     * Wayve: 여러 개의 4D 시뮬레이션 환경을 만든 영국 기반 자율 주행 스타트업
     * 자율 주행 분야: CARLA, LG SVL Simulator, AirSim 등
     * 로보틱스 분야: Gazebo, CoppeliaSim, PyBullet, MuJoCo 등

[ #5 웹/책 및 다른 자료들의 스크래핑 ]

     * 대량의 텍스트, 오디오, 비디오 스크래핑은 파운데이션 모델 개발의 핵심 요소였음
     * 대기업은 자체 독점 시스템을 사용하는 반면, 스타트업은 다양한 기성품 및 오픈소스 도구를 활용할 수 있음
     * Apache Nutch와 같은 분산 크롤링 프레임워크, Puppeteer나 Selenium과 같은 헤드리스 브라우저, Beautiful Soup과 같은 파싱 라이브러리, Luminati와 같은 프록시 및 IP 관리 서비스, 저렴하고 효과적인 OCR 기술 등이 발전했음

  데이터 품질과 양의 트레이드오프

     * 도메인과 애플리케이션에 따라 데이터 품질과 양 사이의 트레이드오프가 달라짐
     * 언어 모델은 충분한 양이 제공되는 경우 비교적 노이즈가 많고 큐레이션되지 않은 데이터에서도 효과적으로 학습할 수 있음
     * 반면 컴퓨터 비전에서는 작은 고품질 데이터셋을 이미지 변형(예: 자르기, 회전, 노이즈 추가 등)을 통해 확장하여 좋은 결과를 얻을 수 있음

  커리큘럼 러닝과 데이터셋 큐레이션

     * 커리큘럼 러닝은 단순한 예제에서 복잡한 예제로 이동하며 모델에 데이터를 의미 있는 순서로 제시하는 학습 전략임
     * 사람의 학습 방식을 모방하여 모델이 어려운 예제에 도전하기 전에 좋은 초기 파라미터를 학습하도록 하여 효율성을 높임

  사례

     * Databricks의 최근 SOTA 오픈 LLM인 DBRX는 이를 활용하여 모델 품질을 상당히 개선했음
     * Sync Labs는 상대적으로 품질이 낮은 대량의 비디오를 사용하여 비디오의 입술을 새로운 오디오에 맞게 재동기화할 수 있는 모델을 학습시켰음
     * Metalware는 전문 교과서에서 스캔한 비교적 작은 이미지 세트와 GPT-2를 결합하여 펌웨어 엔지니어를 위한 코파일럿을 만들었음

[ #6 저작권 문제와 라이선싱 가능성 ]

     * 2016년 이후 AI 생태계의 성숙은 창업자에게 긍정적인 영향을 미쳤지만, 추가적인 복잡성도 야기했음
     * 파운데이션 모델 제공업체의 대량 웹 스크래핑으로 인해 미디어 기업, 작가, 예술가들이 다양한 저작권 소송을 제기하고 있음
     * 이러한 소송은 현재 유럽과 미국의 법원 시스템을 통해 진행 중이며, 대기업(예: Meta, OpenAI)이나 점점 더 확립된 연구소(예: Midjourney, Stability)를 대상으로 하고 있음
     * 이는 스타트업이 데이터 수집 방식에 신중해야 함을 강조함
     * 만약 기업들이 패소할 경우, 학습 데이터에서 저작권이 있는 자료를 식별하고 창작자에게 보상하거나 이러한 결과물을 파기하고 처음부터 다시 시작해야 할 수 있음
     * 이에 따라 일부 기업은 미디어 조직과 파트너십을 맺거나 콘텐츠나 음성 사용에 대해 예술가에게 직접 보상하는 등 창작자 친화적인 데이터 수집 전략을 선제적으로 추진하고 있음

윤리적 데이터 소싱 인증 체계의 등장

     * 전 Stability 임원 등이 주도하는 윤리적으로 소싱된 학습 데이터에 대한 인증 체계가 등장하고 있음
     * 이러한 인증 체계는 아직 초기 단계이지만 흥미로운 방안이며 지켜볼 만한 가치가 있음

  사례

     * ElevenLabs: 성우에 대한 페이아웃과 음성 데이터 파트너십
     * Google: Gemini 학습을 위해 Reddit 데이터를 사용할 수 있도록 하는 계약 체결
     * OpenAI: Shutterstock의 이미지, 비디오, 음악, 메타데이터 라이브러리로 DALL-E를 학습시키기 위한 파트너십과 Associate Press의 뉴스 아카이브 라이선스 계약

[ #7 레이블링된 대규모 데이터셋의 필요성 감소 ]

     * 2016년 이후 비지도 학습과 준지도 학습 기술이 크게 발전하면서, 스타트업이 전통적으로 필수적이라고 여겨졌던 대규모 레이블링된 데이터셋 없이도 강력한 모델을 구축할 수 있게 되었음
     * 이러한 접근 방식은 2016년 이전에도 연구자들에게 알려져 있었지만, 최근 몇 년 동안 접근성, 정교함, 실용성이 크게 향상되었음
     * 비지도 학습은 데이터에 내재된 통계적 패턴과 구조를 학습하는 데 중점을 두며, 전통적으로 대규모 데이터셋 탐색(예: 비지도 클러스터링)에 유용했고 현재는 LLM 사전 학습의 핵심임
     * 준지도 학습은 소량의 레이블링된 데이터와 함께 대량의 레이블링되지 않은 데이터를 사용하며, 모델의 성능을 개선하고 향상시키는 데 가장 효과적임
     * 대조 학습과 소량 샷 학습과 같은 기법을 통해 이러한 접근 방식을 강화할 수 있음
          + 대조 학습(Contrastive Learning)은 유사한 데이터 포인트와 유사하지 않은 데이터 포인트를 구분함으로써 모델이 풍부한 표현을 학습할 수 있게 하며, 컴퓨터 비전 작업에 유용함 (예: OpenAI의 CLIP)
          + 퓨-샷 학습(Few-shot learning)은 모델이 매우 적은 수의 예제로 새로운 작업에 적응할 수 있게 해줌
     * 원래의 스케일링 법칙 논문은 더 큰 모델이 소량 샷 학습에 더 능숙하다는 것을 보여주었음
     * 비지도 사전 학습에 더 많은 양의 레이블링되지 않은 데이터가 필요하지만, 이 단계는 작은 비생성 모델보다 더 적은 레이블링된 예제로 다운스트림 작업을 해결할 수 있는 능력을 부여함

  한계점과 고려사항

     * 레이블링되지 않은 데이터를 활용하는 모델은 종종 더 복잡한 아키텍처를 필요로 함
     * 레이블링에 소비되는 비용을 연산에 소비되는 비용으로 교환하는 것을 의미함
     * 구현과 확장이 더 어려울 뿐만 아니라 해석 가능성이 떨어져 결정 과정을 이해하는 것이 중요한 민감한 분야에서 단점으로 작용할 수 있음
     * 이러한 복잡성은 더 많은 계산 자원을 필요로 하며, 지도 학습 방법보다 성능 상한이 낮은 경우가 많음

[ #8 아직 이른 것들 ]

  데이터 마켓플레이스

     * 2016년 이후 데이터를 수집, 저장, 처리, 공유하는 것이 쉽고 저렴해짐에 따라 몇 가지 데이터 마켓플레이스가 생겨났지만, 이 분야는 크게 활성화되지 않았음
     * Datarade, Dawex, AWS Data Exchange, Snowflake 등의 마켓플레이스와 플랫폼은 다양한 일반적인 사용 사례에 걸쳐 이미지, 텍스트, 오디오, 비디오 데이터를 쉽게 찾을 수 있게 해주었지만, 이는 주로 고객이 데이터를 호스팅하기로 선택한 것에 대한 추가 가치를 제공하기 위한 것임
     * 이러한 마켓플레이스 외에도 Appen, Scale AI, Invisible, Surge 등 숙련된 아웃소싱 인력을 통해 맞춤형 데이터셋 생성 및 레이블링을 제공하는 회사들이 있음
     * 그러나 전문화와 독점 데이터의 경쟁 우위에 대한 주의사항이 여전히 유효하며, AI 스타트업이 이러한 마켓플레이스에 크게 의존한다는 증거는 거의 없음
     * 초기에는 편리할 수 있지만, 정제, 맞춤화, 필터링, 하위 샘플링에 상당한 노력이 여전히 필요함
     * 많은 스타트업이 처음부터 자체 독점 데이터셋을 구축하고 이를 경쟁 우위로 활용하는 것을 선호함

  게이미피케이션

     * 게이미피케이션은 크라우드소싱 및 시민 과학 이니셔티브의 맥락에서 다양한 기업과 조직에 의해 데이터 수집 전략으로 탐구되었음 (예: Folding@Home)
     * 그러나 소수의 사례를 제외하고는 게이미피케이션은 상대적으로 틈새 시장에 머물러 있음
     * 게임과 같은 경쟁에 동기를 부여받고 여유 시간이 있는 특정 사용자 하위 집합에만 어필하므로 기여자 수의 잠재력에 상대적으로 낮은 상한선이 있음
     * 동기 부여된 사람들 사이에서도 기여된 데이터의 품질과 정확성은 여전히 문제가 되며, 특히 에지 케이스를 처리할 때 추가적인 검증 및 통제 조치가 필요함

  연합 학습

     * 2016년 Google이 도입한 연합 학습(Federated learning, FL)은 데이터를 로컬에 그대로 두면서 여러 분산 서버나 모바일 기기에서 모델을 학습시킬 수 있다는 약속을 제시했음
     * 이론적으로 의료나 금융 같은 민감한 분야에서 일하는 스타트업이 전통적인 프라이버시 문제를 피하면서 파트너십을 통해 중요한 학습 데이터에 접근할 수 있게 해줄 수 있음
     * 그러나 FL은 책임, 데이터 소유권, 국경 간 데이터 전송 문제로 인해 설계된 민감한 분야에서 채택이 저해되었고, 모델과 데이터셋이 복잡해짐에 따라 분산 학습 및 집계와 관련된 계산 및 통신 오버헤드가 상당한 병목 현상이 되었으며, 데이터 소유자가 가치 제안을 보장하는 상당히 복잡한 기술을 받아들여야 한다는 인식이 남아 있음

[ ## 결론 ]

     * 2016년 이후 상당한 진전에도 불구하고 데이터 수집은 여전히 스타트업에게 고충으로 남아 있음
     * 커뮤니티나 시장이 이 문제를 해결할 것으로 보이지는 않음
     * 대부분의 AI 스타트업은 여전히 설립 시점에서 데이터 수집의 어려움에 직면하겠지만, 이는 차별화의 기회가 될 수 있음
     * 창의적으로 올바른 기반을 구축하는 것은 여전히 매우 실질적인 경쟁 우위의 원천임
     * 데이터 자체는 결코 해자(Moat)가 될 수 없음
     * 시간이 지나면 경쟁사들은 자체 데이터를 확보하거나 동일한 결과를 달성하기 위한 보다 효율적인 기술을 찾는 데 성공할 것임
     * 지난 1년 동안 작은 모델과 큰 모델 간의 성능 격차가 점진적으로 줄어든 LLM 평가에서 이를 명확히 볼 수 있음
     * 훌륭한 데이터 수집은 궁극적으로 필요하지만 충분하지는 않음
     * 킬러 제품 및 진정한 고객 통찰력과 함께 성공을 위한 한 가지 요소임

   감사합니다 엄청난 정보네요~
"
"https://news.hada.io/topic?id=14619","자동차 제조사, 경찰과의 위치 데이터 공유 약속 위반","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     자동차 제조사, 경찰과의 위치 데이터 공유 약속 위반

자동차 제조사들이 영장 없이 차량 위치 정보를 법 집행기관에 제공하고 있으며 차주에게 이를 거의 알리지 않음

     * 론 와이든 상원의원과 에드워드 마키 상원의원은 연방거래위원회(FTC)에 주요 자동차 제조사들이 고객 위치 데이터를 보호하겠다는 약속을 어긴 것에 대해 조사해 줄 것을 요청함.
     * 자동차 제조사들은 인터넷에 연결된 자동차에서 수집한 위치 데이터를 법 집행기관에 제공하기 전에 영장이나 법원 명령을 요구할 것이라고 기만적으로 약속했었음.
     * 와이든 의원실의 조사에 따르면 GM, Ford, Honda, Stellantis, Tesla 등 5개사만 법 집행기관에 위치 데이터를 제공하기 위해 영장을 요구하고 있으며, Tesla만 정부의 요구에 대해 자동차 소유자에게 알리고 있음.

대부분의 자동차사는 영장 없이도 법원 명령으로 위치 정보 제공 중

     * Toyota, Nissan, Subaru, Volkswagen, BMW, Mazda, Mercedes-Benz, Kia 등은 판사의 승인이 필요 없는 소환장에 응답하여 미국 정부 기관에 위치 데이터를 공개할 것이라고 확인함.
     * Volkswagen은 7일 이상의 위치 데이터에 대해서는 영장을 요구하지만, 6일 이하의 경우 소환장에 응답하여 공개할 것이라고 밝힘.
     * 중국 기업 Geely가 소유한 Volvo는 요청에 응답하지 않았음.
     * 이는 긴급 상황이나 소유자의 동의가 있는 경우를 제외하고는 ""지리적 위치 정보에 대한 정부 기관의 요청이나 요구는 영장이나 법원 명령의 형태여야 한다""는 자동차 업계의 공개 서약에 직접적으로 모순됨.

자동차사의 개인정보 보호 실패의 위험성 경고

     * 와이든과 마키 의원은 미국인들의 사생활을 보호하지 못하면 특히 대법원의 Dobbs 판결에 이어 위험한 결과를 초래할 수 있다고 경고함.
     * Dobbs 판결로 인해 주정부가 낙태를 범죄화하고 기타 생식 건강 선택권이 범죄화될 위험에 처함.
     * 차량 위치 데이터는 주 경계를 넘나들며 치료를 받거나, 시위에 참여하거나, 정신 건강 전문가를 방문하거나, 약물 사용 장애 치료를 받는 등 개인 생활의 세부 사항을 드러낼 수 있음.

GN⁺의 의견

     * 최근 개인정보 보호에 대한 관심이 높아지고 있는 상황에서 자동차 제조사들이 고객의 위치 정보를 보호하지 않는 것은 심각한 문제로 보임. 특히 차량에서 수집되는 위치 정보는 매우 민감할 수 있어 주의가 필요함.
     * 자동차사들이 자발적 서약을 했음에도 이를 지키지 않은 것은 소비자 신뢰 측면에서도 큰 타격이 될 수 있음. 향후 이에 대한 제재나 보완 조치가 마련되어야 할 것임.
     * 개인정보 보호와 법집행기관의 수사 사이에 균형을 맞추는 것은 쉽지 않은 과제이나, 최소한 영장 등 법적 절차는 반드시 준수되어야 할 것임. 이에 대한 자동차사의 자발적인 노력과 정부 차원의 감독이 필요해 보임.
     * 이번 사태로 인해 커넥티드카 시대에 개인정보 침해 가능성에 대한 경각심이 높아질 것으로 예상됨. 차량 제조사들은 이를 반면교사 삼아 고객 프라이버시 보호를 위한 기술적, 제도적 방안을 강구해야 할 것임.
     * 장기적으로는 개인정보 활용과 보호의 조화를 위한 사회적 합의와 법제도 정비가 필요해 보임. 특히 이번 사례처럼 기업들의 자발적 서약만으로는 한계가 있으므로, 위반시 제재 등 실효성 확보 방안이 뒷받침되어야 할 것임.

        Hacker News 의견

     * 일부 자동차 제조사들이 위치 정보 제공에 영장을 요구하지 않아 소비자 보호 약속을 어기고 있음
          + GM, Ford, Honda, Stellantis, Tesla만 위치 정보 제공 시 영장 필요
          + Tesla만 정부 요구사항을 차주에게 통지함
     * 이런 남용으로 인해 중고차 운전을 더 오래 하게 될 것임
          + 배기가스와 안전기준은 낮지만 빅브라더를 동승자로 피하기 위한 절충안
          + 비슷한 생각을 가진 운전자가 충분히 많아 큰 영향을 미칠지는 모르겠음
     * 최신 자동차 소유는 불편함. 인터넷 연결이 없는 2016년식 차량을 가능한 한 오래 유지할 것임
          + 백업 카메라가 유일한 좋은 기능
     * 소비자와 수리점은 차량 기능을 제어하는 펌웨어에 접근할 수 있어야 함
          + 호환 가능한 대체품으로 펌웨어를 다시 설치하고 사용할 수 있어야 함
     * 모델별로 추적 기술이 구현된 연도 목록이 있는지?
          + 제조사가 뭐라 해도 의도적이든 그렇지 않든 데이터는 유출될 것으로 보임
     * Hyundai는 Volkswagen과 비슷한 범주에 속함
          + 48시간 이상 실시간 정보 접근 요청 시 적절한 법적 절차나 고객 동의 필요
     * 자동차 제조사가 위치 데이터를 보관할 자격이 있는지가 첫 번째 문제
     * 구두 계약은 쓰여진 종이만큼의 가치밖에 없음
     * 2023 Corolla에서 DCM(Data Communication Module)을 제거하는 방법을 보여주는 동영상 링크
     * 2019 Subaru Outback에서 연결 기능 비활성화 조사
          + DCM 퓨즈(#9)를 뽑으면 비활성화 가능하지만 프론트 스피커와 마이크도 작동 안 함
          + 대시보드를 분해하고 DCM을 제거한 후 스피커와 마이크를 연결하는 더미 플러그로 교체 가능
          + 일부 차량은 마이크용 5V 전원이 없어 DCM에서 생성됨
          + 독립 자동차 수리점에 DCM 제거 및 더미 플러그 교체 비용 문의 예정
     * Wyden 상원의원은 기술이 일상에 미치는 영향을 신경 쓰는 유일한 정치인으로 다시 한번 입증됨
"
"https://news.hada.io/topic?id=14608","Llama3-gradient - LLAMA의 컨텍스트 길이를 8k에서 1m으로 확장한 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Llama3-gradient - LLAMA의 컨텍스트 길이를 8k에서 1m으로 확장한 모델

     * Gradient가 개발한 이 모델은 LLama-3 8B의 컨텍스트 길이를 8k에서 1040K 이상으로 확장
     * SOTA LLM이 RoPE theta를 적절히 조정하여 최소한의 훈련으로 긴 컨텍스트에서 작동하는 방법을 학습할 수 있음을 보여줌
     * 이 단계는 830M 토큰으로 훈련했으며 모든 단계에서 총 1.4B개의 토큰으로 Llama3의 오리지널 사전 훈련데이터의 0.1%에 불과함
     * 참고: 256k 컨텍스트를 사용하려면 최소 64GB의 메모리 필요. 1M 이상의 컨텍스트를 사용하려면 100GB 이상이 필요

   컨텍스트 윈도가 늘어난 덕분에 성능은 원래 LLaMa 3에 비해 현저히 떨어져서 못쓸 지경이라는 댓글이 있네요.

   https://twitter.com/ArkaPal999/status/1785611161540378707
"
"https://news.hada.io/topic?id=14509","인터넷 서비스의 KYC 요구사항에 대한 4일간의 이의제기 기간","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   인터넷 서비스의 KYC 요구사항에 대한 4일간의 이의제기 기간

IaaS 제공자의 고객 식별 프로그램 및 면제 관련 규정 요약

     * 모든 미국 IaaS 제공자는 반드시 최소한의 요구사항을 충족하는 서면 고객 식별 프로그램(CIP)을 수립하고 이행해야 함
     * CIP에는 고객 및 실소유자 식별 정보 수집, 외국인 고객 및 실소유자 신원 확인, 정보 보관, 정보 공개 관련 고객 통지 등의 절차가 포함되어야 함
     * IaaS 제공자는 잠재 외국인 고객과 실소유자로부터 최소한 이름, 주소, 계정 결제 수단/출처, 이메일, 전화번호, IP 주소 등의 정보를 수집해야 함
     * IaaS 제공자는 문서 또는 비문서 방식으로 외국인 고객과 실소유자의 신원을 확인하는 위험 기반 절차를 수립해야 함
     * 고객 신원을 확인할 수 없는 상황에 대한 대응 절차도 CIP에 포함되어야 함
     * 고객 정보 확인 과정에서 얻은 모든 정보의 기록을 최소 2년간 안전하게 보관하고, 제3자 접근을 제한하는 절차를 마련해야 함
     * IaaS 제공자는 외국 리셀러에게도 CIP 유지와 이행을 요구하고, 리셀러의 CIP 사본을 요청시 10일 이내 상무부에 제공해야 함
     * 미준수 외국 리셀러와의 거래는 30일 이내 중단해야 함

CIP 보고 요건 요약

     * 모든 IaaS 제공자는 자사와 외국 리셀러의 CIP 이행을 상무부에 통보하기 위해 CIP 인증 양식을 제출해야 함
     * 매년 CIP를 검토하고 업데이트하여 재인증해야 하며, 중간에 중대한 변경사항이 있을 경우 상무부에 통보해야 함
     * 새로운 IaaS 제공자는 서비스 제공 전에 CIP 인증 양식을 제출하고, 새 외국 리셀러 추가시에도 통보해야 함
     * 외국 리셀러로부터 CIP 정보를 수집하여 매년 상무부에 제출해야 함

CIP 준수 평가 요약

     * 상무부는 IaaS 제공자의 CIP 사본을 요청하여 검사할 수 있으며, 미흡한 부분을 시정하도록 통보할 수 있음
     * 상무부는 자체 평가나 IaaS 제공자 제출 정보 등을 바탕으로 위험도를 평가하고 준수 평가를 수행함
     * 준법감시 결과에 따라 위험 완화 조치나 특별 조치 등을 권고할 수 있음

CIP 면제 규정 요약

     * 상무부 장관은 IaaS 제공자, 계정 유형, 임차인, 외국 리셀러 등에 대해 CIP 요건 준수 면제를 부여할 수 있음
     * IaaS 제공자는 IaaS 제품 악용 방지 프로그램(ADP) 수립을 통해 CIP 요건 면제를 신청할 수 있음
     * ADP에는 위험 지표 식별, 탐지, 대응, 정기 업데이트 등의 정책과 절차가 포함되어야 함
     * 면제 유지를 위해 ADP 변경사항을 상무부에 매년 통보해야 하며, 면제는 언제든 취소될 수 있음

특정 국가나 외국인에 대한 특별 조치 요약

     * 상무부 장관은 특정 국가나 외국인이 미국 IaaS 제품을 악용한 사이버 활동에 연루되었다고 판단되면 특별 조치를 부과할 수 있음
     * 해당 국가 내 외국인의 계정 개설을 금지하거나 조건을 부과하는 조치, 특정 외국인의 계정 개설을 금지하거나 제한하는 조치 등이 있음
     * 특별 조치 부과 여부와 종류는 관련 요인을 종합적으로 평가하여 결정함

대규모 AI 모델 학습 보고 요건 요약

     * IaaS 제공자는 외국인의 악의적 사이버 활동에 악용될 수 있는 대규모 AI 모델 학습 거래를 인지한 경우 15일 이내에 상무부에 보고해야 함
     * 외국 리셀러도 동일한 보고 의무가 있으며, IaaS 제공자는 이를 30일 이내에 상무부에 제출해야 함
     * 상무부 요청시 15일 이내에 추가 정보를 제공하는 후속 보고서를 제출해야 함
     * 오류 발견시 15일 이내에 수정 보고서를 제출해야 함
     * 보고서에는 외국인 고객 정보, 학습 관련 정보 등이 포함되어야 함
     * IaaS 제공자는 외국 리셀러가 이 요건을 준수하도록 합당한 노력을 기울여야 함

규정 위반에 대한 집행 요약

     * 금지 행위에는 CIP 미수립/미유지, 리셀러 CIP 미준수, 대규모 AI 모델 학습 금지/정지 미이행 등이 있음
     * 상무부에 허위 진술을 하는 것도 위반 행위에 해당함
     * IEEPA에 따라 건당 최대 25만 달러 또는 위반 거래액의 2배 중 큰 금액의 민사 제재금이 부과될 수 있음
     * 고의 위반시에는 최대 100만 달러 벌금이나 20년 이하 징역형에 처해질 수 있음
     * 이 외에도 미국법에 따른 다른 민사/형사 처벌이 가능함

GN⁺의 의견

   이 규정은 미국 IaaS 제공자들에게 외국인 고객 식별과 검증을 의무화하여 악의적인 사이버 활동에 악용되는 것을 방지하려는 목적으로 보입니다. 특히 대규모 AI 모델 학습에 IaaS가 사용되는 것에 대한 우려도 반영된 것 같네요.

   IaaS 제공자 입장에서는 고객 정보 수집과 검증, 기록 보관 등의 부담이 커질 것 같습니다. 외국 고객 확인이 쉽지 않을 수 있고, 프라이버시 이슈도 예상됩니다. 외국 리셀러와의 계약 관계도 영향을 받겠죠.

   한편 정부는 이를 통해 IaaS 시장에 대한 통제력을 높이고 국가안보 위협을 차단하려 하는 것으로 보입니다. 특정 국가나 행위자를 타겟으로 한 특별 조치 조항이 눈에 띄는데, 지정학적 갈등을 반영한 것 같습니다.

   대규모 AI 모델 관련 조항은 AI의 이중용도성에 대한 인식이 높아진 결과로 보입니다. 정부가 IaaS를 통한 AI 개발 활동을 감시하려는 의도가 엿보이네요. 기술 발전에 따른 새로운 위험에 대응하려는 시도로 해석됩니다.

   이 규정은 국가안보와 기술혁신 간의 균형을 모색하는 과정으로 보입니다. IaaS 제공자들에겐 부담이겠지만, 장기적으로는 시장의 건전성과 신뢰도 향상에 기여할 수 있을 것 같습니다. 다만 과도한 규제로 인한 혁신 저해 우려도 있어 신중한 이행이 필요해 보입니다.

        Hacker News 의견

     * 이 법안은 IaaS(인프라) 제공자들이 AI 훈련에 자신들의 서비스를 사용하는 사람들의 신원을 확인하도록 요구하는 것으로 보임. 제재 대상이거나 악의적인 행위자들이 AI를 훈련시키고, 서비스 간 이동하거나 가명을 사용하여 모델 훈련을 계속하는 것을 막으려는 시도임.
     * 이는 다소 무해해 보이며, HN 토론에서 다른 사람들이 만드는 유사점을 이해하기 어려움. 미끄러운 경사로인지, 아니면 법안의 범위에 대해 순진한 것인지 의문임.
     * IaaS 제공자들이 격렬히 반대할 것이며, AWS가 KYC 문서를 요구하기 시작하면 즉시 모든 클라우드 리소스를 다른 곳으로 이전할 것임. 이를 위한 노력은 거의 없음.
     * KYC는 ""고객 알기(know your customer)""를 의미함. 약어를 처음 사용할 때는 풀어 쓰는 것이 좋음. 특히 연결된 기사에 약어 자체가 사용되지 않았기 때문임. 또한 이 제안은 일반적인 ""인터넷 서비스""가 아닌 미국 IaaS 제품에 대한 것임을 주목할 가치가 있음.
     * 만약 은행들이 그들의 고객을 안다면, 우리는 그럴 필요가 없음. KYC의 길은 항상 지불과 금융으로 이어짐. 우리가 표준 은행 카드 거래나 송금 등으로 서비스 대금을 받아들인다면, 고객에 대한 인지는 은행에서 중앙 집중화될 수 있음.
     * KYC 요구 사항을 점점 더 많은 온라인 서비스에 추가하는 추세가 걱정됨. KYC는 서비스를 제공하려는 사람에게 큰 부담을 줌.
     * KYC 시스템은 범죄자를 잘 걸러내지 못하는 경향이 있음. 대부분의 KYC 시스템은 데이터 집계자(개인 데이터를 구매하는 사람)에 의존하며, 젊거나 가난하거나 프라이버시를 중시하는 사람은 의심을 받게 됨.
"
"https://news.hada.io/topic?id=14586","Pyinfra: 파이썬을 활용한 인프라 자동화 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Pyinfra: 파이썬을 활용한 인프라 자동화 도구

     * 파이썬을 사용하여 인프라를 자동화하는 도구
     * 단일 서버에서 수천 대의 서버까지 빠르게 확장 가능
     * 임시 명령 실행, 서비스 배포, 구성 관리 등에 적합

pyinfra를 사용해야 하는 이유

     * 수천 개의 대상에 대해 예측 가능한 성능으로 초고속 실행 가능
     * 실시간 stdin/stdout/stderr 출력(-vvv)으로 즉각적인 디버깅 가능
     * 변경 사항 적용 전에 diff와 dry run을 지원하여 멱등성 제공( Idempotent operations)
     * 전체 Python 패키지 생태계로 확장성 제공
     * SSH가 가능한 모든 기기에서 에이전트 없이 실행 가능
     * Docker, Terraform, Vagrant 등과 같은 커넥터와 통합됨

  빠른 시작

     * pip install pyinfra 명령으로 pyinfra 설치
     * SSH를 통해 명령 실행 가능
          + pyinfra my-server.net exec -- echo ""hello world""
     * Docker, 로컬 머신 및 기타 커넥터 대상 지정 가능
          + pyinfra @docker/ubuntu exec -- echo ""Hello world""
          + pyinfra @local exec -- echo ""Hello world""
     * 명령 실행 외에도 작업을 사용하여 상태 정의 가능
          + pyinfra @docker/ubuntu apt.packages iftop update=true _sudo=true
     * 이를 deploy.py와 같은 Python 파일로 저장하고 실행 가능
     * 인벤토리, 작업 및 Python 코드를 결합하여 모든 것을 배포할 수 있음

   자세한 내용은 시작 가이드, 작업 사용법 가이드, 인벤토리 및 데이터 사용법, 전역 인수 및 CLI 사용법을 참조하거나 문서화된 예제를 확인할 것.

GN⁺의 의견

     * 배포 도구로서 안전성과 통제력이 중요한데, 인프라 관리 도구로서의 기능에 초점이 맞추어져 있어 배포 프로세스에서 문제가 생길 가능성이 있음
     * pyinfra 자체는 배포 베스트 프랙티스를 강제하지 않기 때문에 팀 내에서 별도로 규칙을 정하고 관리해야 함
     * 언어로 Python을 사용하므로 Python 생태계를 활용할 수 있고 개발자에게 친숙한 것은 장점이지만, 다른 일반적인 배포 도구에 비해 진입 장벽이 있음
     * 단순하고 유연한 배포 시나리오에 적합한 도구로 보이며, 복잡한 엔터프라이즈급 배포에는 Ansible, Puppet 등의 성숙한 도구가 더 적합할 수 있음
     * Terraform이나 Pulumi 같은 IaC 도구와 통합되는 점은 좋으나, 이들만으로도 불가능한 작업이 많지 않은지 의문임

   Ansible에 YAML 이외의 플레이북 정의 방법이 필요하다고 생각합니다. Ansible이 데이터 가공을 위해 파이썬 기능을 jinja 필터로 다시 구현해서 제공하고 있는데 엄청난 낭비라고 생각합니다. 플레이북 fact의 스키마가 task의 입력과 일치하는 상황이라면 상관이 없겠지만 현실적으로는 중간 데이터 가공이 필연적인 상황이 더 많습니다. 데이터 가공에 Jinja를 이용한 것도 근시안적인 기술 결정이 아니었나 싶습니다

   pyinfra - 파이썬 기반의 인프라 자동화 도구

   예전 1.0 릴리즈 했을때 한번 올리긴 했는데, 계속 활발히 업데이트 중입니다.
   지금은 2.92 버전인데 현재 베타인 3.0이 곧 릴리즈 예정입니다.

        Hacker News 의견

   요약:
     * Ansible은 대상 시스템에 Python 인터프리터가 필요하지만, Pyinfra는 셸만 있으면 됨. Pyinfra는 과소평가된 소프트웨어임.
     * Ansible은 좋지만 결국 YAML 문자열로 Python을 작성하게 됨. 그렇다면 처음부터 Python을 직접 사용하는 게 나음.
     * Pyinfra 개발자가 댓글을 달았는데, 현재 베타인 v3을 사용하는 것을 추천함. 안정적이며 공식 릴리스 준비 중이라고 함.
     * Pyinfra 관련 과거 HN 게시물들이 여러 개 링크되어 있음.
     * 한 사용자는 Ansible에서 Pyinfra로 전환했는데, Pyinfra가 훨씬 깔끔하다고 평가함. Python이 없는 Fedora CoreOS 환경에서도 Pyinfra를 사용할 수 있어 좋았다고 함.
     * Puppet이 이 분야에서 가장 적절한 도구라는 의견도 있음. 단순하면서도 필요하면 프로그래밍 언어로서의 기능을 제공함. 다만 사용성 측면에서 개선이 필요함.
     * CM(구성 관리) 도구 사용이 매우 힘들 수 있음. 전문가들도 유지보수 비용이 높다는 데 동의함. 컨테이너와 더 밀접하게 통합되는 방향으로 발전되어야 함.
     * Python은 인프라 관리에 적합하지 않을 수 있음. 바이너리 빌드, 패키지 재현성, 정적 타입 부재 등의 한계가 있음.
     * Pyinfra와 Docker, Tailscale을 조합해서 간편하게 서비스를 배포하는 방법이 소개됨. 과거에는 쿠버네티스를 사용했겠지만, 너무 과하고 디버깅도 어려움.
     * Pyinfra 덕분에 Ansible의 고질적인 문제들을 피할 수 있었음. Pyinfra는 Python 스크립트로 인벤토리와 변수를 유연하게 정의할 수 있어 편리함.
"
"https://news.hada.io/topic?id=14525","No Abstractions: 우리의 API 설계 원칙","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     No Abstractions: 우리의 API 설계 원칙

     * API 리소스 네이밍과 모델링 결정은 API 설계에서 가장 어렵고 중요한 부분임. 리소스는 사용자의 제품 작동 방식과 기능에 대한 멘탈 모델을 구성함.
     * Increase 팀은 ""추상화 없음"" 원칙을 사용하여 API 설계를 지원함.

Stripe의 API 설계 접근 방식

     * Stripe 팀의 상당수는 이전에 Stripe에서 근무했으며, Stripe의 성공적인 API 설계 가치를 고려함.
     * Stripe은 복잡한 도메인의 핵심 기능을 사용자가 쉽게 이해하고 사용할 수 있는 추상화로 추출하는 데 탁월함. (예: Visa와 Mastercard의 차이를 추상화한 PaymentIntent)
     * Stripe의 사용자 대부분은 결제와 무관한 제품을 개발하는 초기 스타트업으로, 신용카드의 세부 사항을 알 필요가 없음. 이들은 Stripe를 빠르게 통합하고 제품 개발에 집중하기를 원함.

Increase 사용자와 API 설계 원칙

     * 반면에 Increase의 사용자는 결제 네트워크에 대한 깊은 지식이 있으며, Increase를 선택한 이유가 직접적인 네트워크 연결과 통합 깊이 때문임.
     * 이들은 FedACH 창구가 닫히는 시점과 이체 시점을 정확히 알기를 원하며, ACH 이체에서 다른 SEC 코드 설정이 반환 타이밍에 영향을 줄 수 있다는 것을 이해함.
     * 이러한 네트워크의 근본적인 복잡성을 숨기려는 시도는 사용자를 짜증나게 할 뿐 삶을 단순화하지 않음.
     * 초기 사용자와의 대화를 통해 ""추상화 없음"" 원칙을 도출하고 API 설계에 적용함.

""추상화 없음"" 원칙이 API 설계에 미친 영향

     * 실제 사용되는 용어 사용: API 리소스와 속성에 자체 이름을 만드는 대신 기본 네트워크의 어휘를 사용함. (예: ACH 이체 파라미터는 Nacha 사양의 필드명을 사용)
     * 불변성: 실제 이벤트를 모델로 사용하여 더 많은 API 리소스가 불변하도록 함. 불변 리소스 클러스터를 상태 머신 ""수명 주기 객체""로 그룹화하는 것이 효과적임. (예: ach_transfer 객체의 status 필드와 전송 수명 주기에 따라 생성되는 몇 가지 불변 하위 객체)
     * 사용 사례별 리소스 분리: 리소스 인스턴스에 따라 사용자가 취할 수 있는 작업 집합이 크게 다른 경우 여러 리소스로 분할함. (예: 발신 ACH 이체와 수신 ACH 이체는 별도의 리소스로 분리)

엔지니어링 팀의 접근 방식 준수

     * 엔지니어링 팀이 이 접근 방식을 준수하기로 약속함.
     * 복잡한 API를 몇 년 동안 설계할 때 작은 증분 결정을 항상 내려야 하는데, 사전에 기본 원칙을 준수하기로 약속하면 이러한 결정에 대한 인지 부하가 줄어듦.
     * 예를 들어 연방준비제도로 송금할 때 필요한 Input Message Accountability Data 필드의 경우 추상화가 많은 API에서는 이 필드의 이름을 ""사용자 친화적""으로 지정하는 방법을 고민해야 하지만, Increase에서는 엔지니어가 필드 이름을 input_message_accountability_data로 지정하고 넘어감.

GN⁺의 의견

     * API의 추상화 수준은 해당 제품 도메인에 대한 개발자의 경험 수준과 통합에 투입할 에너지 등에 따라 달라질 수 있음. 따라서 API를 설계할 때 통합할 개발자에게 적절한 추상화 수준을 고려하는 것이 중요함.
     * 추상화 수준이 높은 API를 구축한다면 새로운 기능을 추가하기 전에 신중하게 생각해야 함. 반면 추상화 수준이 낮은 API를 구축한다면 이를 준수하고 추상화를 추가하고 싶은 유혹에 저항해야 함.
     * 기본 네트워크나 프로토콜의 용어를 그대로 사용하는 것은 개발자들이 underlying system을 이해하는데 도움이 될 수 있지만, 반대로 처음 접하는 개발자에게는 진입장벽이 될 수도 있음. 따라서 주석이나 문서화를 잘 해두는 것이 중요할 것 같음.
     * API 설계 시 immutable 객체를 활용하는 것은 데이터의 정합성 유지와 side-effect 방지에 효과적일 수 있음. 하지만 반대로 데이터 갱신이 필요한 경우 불편할 수도 있으므로 trade-off를 잘 고려해야 함.
     * 사용 사례별로 리소스를 분리하는 것은 API의 복잡도를 높일 수 있지만, 장기적으로는 예측 가능성을 높일 수 있음. 하지만 너무 세분화되면 사용성이 떨어질 수 있으므로 적절한 수준을 찾는 것이 중요함.

        Hacker News 의견

     * 낮은 수준의 추상화가 적용된 API와 높은 수준의 추상화가 적용된 API를 모두 제공하는 것이 좋음
          + 낮은 수준의 API는 세밀한 제어가 가능하지만 전문 지식이 필요함
          + 높은 수준의 API는 일반적인 사용 사례에 맞춰 단순화된 작업을 제공함
          + 두 API 사이에 명확한 구분을 유지하면, 각 API에 추상화나 특수 사례를 추가하려는 압박이 줄어듦
          + 클라이언트가 한 API에서 다른 API로 이동하는 방법을 배울 수 있도록 자료를 제공하는 것이 좋음
     * Increase가 다른 접근 방식을 선택한 이유를 설명한 부분이 마음에 듦
          + 근본적인 것을 설계할 때 상황이 많이 중요하지만, 사람들은 보통 이를 충분히 인식하지 못함
     * Stripe의 진정한 능력은 고객을 알고 고객이 원하는 단순함을 제공하는 것임
          + Increase도 고객이 필요로 하는 것을 잘 파악하고 있으며, 훌륭한 제품을 만들기 위한 설계 지침을 만드는 데 유사한 집중력을 발휘함
     * 도메인 전문가가 사용하는 실제 용어와 동일한 용어를 구현에 사용하는 Domain-Driven Design의 ""보편 언어(Ubiquitous Language)"" 설계 패턴과 유사함
     * 도메인 전문가가 이해할 수 있는 언어를 사용해야 함
          + 사용자가 NACHA 파일에 대해 알고 있다면, 다른 용어를 사용하면 머릿속에서 매핑을 유지해야 함
          + Stripe의 경우 사용자가 도메인 전문가가 아니므로, 이해 가능하면서도 불필요한 세부 사항을 숨기는 추상화를 만드는 것이 가치 있음
     * POSIX와 같은 추상화가 없다면, 애플리케이션은 지원되는 모든 파일 시스템에 대해 어댑터를 작성해야 함
     * 외부에서 제어되는 사양을 기반으로 API 구조의 일부가 1:1로 구축된다고 함
          + 이러한 사양이 발전하거나 변경되면 어떻게 되는가? 새로운 API인가?
     * 지불 API에서 깔끔하게 모델링하기 어려운 한 가지는 지불 체계가 지불 반환 시 지급인과 수취인의 역할을 다른 방식으로 나타낸다는 것임
          + 예를 들어, 특정 체계에서는 지급인과 수취인이 초기 지불과 동일한 위치에 유지될 수 있음
          + 반면 다른 체계에서는 전환됨
"
"https://news.hada.io/topic?id=14495","Meta, OpenAI가 해야 할 모든 것을 하다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Meta, OpenAI가 해야 할 모든 것을 하다

   ""이런 말을 하는 것이 놀라울 수도 있고 아닐 수도 있지만, 원래 이러한 목적으로 설립되고 주로 자금을 지원받았던 OpenAI보다 Meta(또는 Facebook)가 훨씬 더 AI/ML을 대중화 하고 있음. OpenAI는 대부분 영리만을 위한 상업적 프로젝트가 되었습니다. 아직까지 Llama 모델이 GPT4 기능에 도달하지 못했지만, 이는 시간 문제라고 생각합니다. 여러분은 이에 대해 어떻게 생각하시나요?""

        Hacker News 의견

     * Yann LeCun, 메타 연구책임자의 공로가 크다는 의견
          + 오픈소스의 중요성을 일찍부터 강조해왔으며, 마크 저커버그에게도 이를 주장함
          + 벨 연구소에서의 경험과 학계에서의 오픈 자료 활용이 연구에 큰 도움이 되었기 때문
          + 오픈소스가 더 나은 선택임을 계속 강조해왔고, ""AI 규제""에 대해 강하게 반대 의사를 표명해옴
          + 이 점에서 메타는 다른 빅테크 AI 주류 의견과 대조적임
     * 메타는 자사 제품의 보완재를 상품화하고 있음
          + OpenAI는 모델(API) 자체가 제품이기에 그럴 수 없음
     * 메타는 AI 사업이 아닌 관심(attention) 사업을 하기에 ""관대할"" 수 있음
          + 다른 회사 제품의 경쟁력을 약화시키기 위해 사업 일부를 공격적으로 보조하는 것은 좋은 행동은 아님
          + 메타가 핵심 자산을 오픈하고 관대해진다면 칭찬할 만하지만, 그럴 일은 없을 것임
     * 메타가 오픈소스를 하는 것은 수단이지 목적이 아님
          + 경쟁을 약화시켜 경제적 입지를 강화하기 위한 것이지, 오픈AI의 설립 취지처럼 ""개방성"" 자체를 위한 것은 아님
     * Yann LeCun의 역할을 더 주목해야 함
          + 마크 저커버그가 이 전략을 스스로 생각했을 수도 있지만, Yann이 오픈 모델을 적극 추진했고 마크에게 영향력이 있어 실현될 수 있었을 것임
     * Hinton은 ""너무 강력한 것을 오픈소스화하는 것은 미친 짓""이라고 말함
          + OpenAI가 책임감 있는 행동을 하는 것이고, LeCun은 여전히 AI가 고양이만도 못하다고 생각하며 저커버그를 놀아나게 하고 있음
          + Hinton과 Sutskever는 이 LLM 기술의 발명자로 볼 수 있는데, 둘 다 오픈소스화되어서는 안 된다는 데 동의함. 시사하는 바가 큼
     * 내 아이들이 왓츠앱에 내장된 ""Meta AI""에 중독되어 있어 복잡한 심경임
          + 한계를 이해시키려 노력 중이지만, 왓츠앱을 포기하지 않고서는 비활성화할 방법이 없어 보임
     * OpenAI의 영향력을 인정하는 것이 중요함
          + 그들이 없었다면 ChatGPT가 존재하지 않았을 것이고, 다른 기관이 이렇게 일찍 고급 LLM을 개발하고 무료로 공개했을 가능성은 낮음
          + 뒤따라오면서 무료로 공개해 ""관대해"" 보이는 것이 더 쉬움
     * Whisper처럼 TTS 시스템도 오픈소스로 공개해주길 바람
"
"https://news.hada.io/topic?id=14546","대기업들처럼 웹 스크레이핑(Web Scraping)을 하고 싶다면 (2021)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              대기업들처럼 웹 스크레이핑(Web Scraping)을 하고 싶다면 (2021)

   Here is a summary of the key points from the article in Korean, formatted as a markdown bullet list:

대규모 스크레이핑 인프라 구축하기

     * AWS Lambda로 Headless Chrome을 실행하여 Google SERP를 주당 수백만 건 스크레이핑함
          + 3번 Lambda 함수를 호출하면 새로운 public IP를 받을 수 있음
          + 1000개의 Lambda 함수를 동시에 호출하면 약 250개의 public IP를 사용할 수 있음
          + 16개 리전을 사용하면 약 4000개의 public IP 주소 사용 가능
     * 하지만 이 방법은 Google, Bing, Amazon 같은 사이트에서만 동작함. DataDome, Akamai, Imperva 등의 안티봇 솔루션을 사용하는 사이트에서는 작동하지 않음
     * 안티봇 솔루션은 브라우저 핑거프린팅, 거짓말 탐지, 사람과 다른 동작 감지 등 다양한 기술 사용
     * 봇 탐지를 피하기 어려운 이유는 대부분 Docker나 Kubernetes로 클라우드에서 돌리기 때문

탐지되기 어려운 확장 가능한 스크레이핑 인프라 제안

     * 500대의 저렴한 안드로이드 기기를 5개 제조사에서 구매
     * 저렴한 데이터 요금제 사용, DeviceFarmer/stf로 기기 제어
     * 런던, 파리, 보스턴, 프랑크푸르트, LA 등 5개 주요 도시에 각각 100대씩 배치
     * 경량 Android Go 설치, 5분마다 비행기 모드 껐다 켜서 IP 주소 변경
     * 4G/5G/LTE의 모바일 IP는 차단 불가능. 많은 사용자가 공유하므로 Instagram도 LA의 20만명을 차단 못함
     * 기기 방향, 움직임 등의 이벤트를 커널 레벨에서 조작 필요

    개선안: 안드로이드 에뮬레이션

     * Android-x86 on VirtualBox, Bluestacks, Android Studio 등의 에뮬레이터 사용
     * 하지만 에뮬레이션 탐지 기술이 많이 있음 (브라우저 기반 레드필, adb 포트 스캔, 광고ID 탐지, 소셜 로그인 탐지 등)
     * 4G 동글을 서버에 연결하여 안드로이드 에뮬레이터에서 직접 사용
     * 5개 주요 도시에 각각 50개 동글이 연결된 강력한 스크레이핑 서버 1대씩 배치
     * 각 서버에서 50~100개의 안드로이드 에뮬레이터 실행
     * 단순한 명령 제어 서버로 5개 스크레이핑 스테이션 조율

GN⁺의 의견

     * 실제 기기를 사용하는 것은 관리 비용이 높고 확장성에 한계가 있어 보임. 에뮬레이터 사용이 현실적인 대안이 될 것 같음.
     * 하지만 에뮬레이터 탐지 기술도 계속 발전하고 있어서, 단순히 에뮬레이터를 사용한다고 해서 안전할 것으로 보이지는 않음. 지속적인 업데이트와 개선이 필요할 것임.
     * 4G/5G 모바일 IP를 사용하는 것은 좋은 아이디어임. 하지만 통신사에서 특정 기기를 차단하거나 요금제를 조정할 가능성도 배제할 수 없음.
     * 데이터센터 IP 사용을 피하는 것 외에도, 사람과 유사한 행동 패턴을 만드는 것이 봇 탐지를 피하는데 도움이 될 것 같음. 자동화를 통한 대규모 수집이 아니라 제한된 Concurrency로 천천히 수집하는 방식을 고려해볼 만함.
     * Multilogin 이나 GoLogin 같은 상용 안티 디텍션 브라우저를 활용하는 것도 고려해볼 만함. 단, 라이선스 비용 문제가 있음.
"
"https://news.hada.io/topic?id=14547","Ubuntu 24.04 Noble Numbat 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Ubuntu 24.04 Noble Numbat 출시

   확장된 지원: Ubuntu 24.04 LTS는 12년 동안 업데이트를 제공받을 예정이며, Ubuntu Pro 구독을 통한 확장 기간도 포함됩니다. 이는 개인 사용자의 경우 최대 다섯 시스템까지 무료입니다​.

   설치 프로세스 개선: 설치 경험이 Flutter 기반 설치 프로그램으로 간소화되고 미화되어 더욱 개선되었습니다. 최소 설치 또는 전체 설치 옵션을 선택할 수 있으며, 제3자 소프트웨어 및 미디어 코덱 설치 옵션도 제공됩니다​.

   소프트웨어 센터 업데이트: 소프트웨어 관리 경험이 새로운 Flutter 기반의 소프트웨어 센터로 전면 개편되어 사용자 친화적인 인터페이스와 애플리케이션의 더 나은 조직화를 제공합니다​.

   GNOME 46 통합: GNOME 46이 포함될 예정으로, 사용성과 성능 개선이 많이 이루어졌습니다. 예를 들어, 설정 레이아웃 개선과 더 나은 알림 관리 등이 있습니다​.

   보안 강화: Ubuntu 24.04 LTS는 AppArmor 구성 업데이트, 애플리케이션 샌드박싱 개선을 위한 특권 없는 사용자 네임스페이스 제한, 기본적으로 오래된 TLS 버전 사용 중지 등을 통해 보안을 강화했습니다​.

   리눅스 커널 6.8: 최신 리눅스 커널 6.8을 포함하며, 다양한 하드웨어에서의 성능 및 호환성 향상을 포함한 중요한 개선 사항을 제공합니다​.

   펌웨어 관리 개선: 펌웨어 관리를 위한 전용 애플리케이션을 포함하여, 백그라운드 서비스를 계속 실행할 필요 없이 장치 펌웨어를 최신 상태로 유지할 수 있게 되었습니다​.

   https://www.theregister.com/2024/04/29/google_python_flutter_layoffs/

   flutter 간당간당한데요. 소프트웨어 센터는 리메이크할 수도 있겠네요.

   와 드디어 ...! Ubuntu 22.04로 운영하던 서버들은 한 반년 지켜보고나서 업데이트 도전해봐야겠습니다. ㅎㅎ

   지금 깔아서 그걸로 접속해보고 있는데, GNOME 46 사용자경험이 진짜 많이 좋아졌네요 많이 정리되고...다른 OS들이 많이 복잡해졌다보니... 비교하니까 깔끔하고 기분이 좋네요ㅋㅋㅋ

   설치해보고 깜짝 놀랐습니다 ㅎㅎ
"
"https://news.hada.io/topic?id=14557","파이썬을 위한 스프레드시트 UI, PySheets","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      파이썬을 위한 스프레드시트 UI, PySheets

PySheets 소개

     * PySheets는 Python을 위한 스프레드시트 UI를 제공하여 사용자가 탐색적 데이터 과학을 수행하고, Pandas를 사용하며, matplotlib로 차트를 작성하고, Excel 시트를 가져오고, 데이터를 분석하고, 보고서를 작성할 수 있게 함
     * 모든 Python 코드는 브라우저에서 실행되며 PySheets 자체도 Python으로 작성됨
     * PySheets를 사용하면 사용자는 많은 코드를 작성할 필요 없이 방대한 데이터 과학 생태계를 활용하기 위해 모든 Python 패키지와 JS 모듈을 로드할 수 있음

PySheets의 주요 기능

     * Excel 시트를 빠르게 가져오고 내보낼 수 있음
     * Pandas로 데이터를 탐색하고 분석할 수 있음
     * Matplotlib를 사용하여 AI 기반 시각화를 쉽게 수행할 수 있음
     * 최소한의 코딩으로 즉각적인 결과를 얻을 수 있음
     * 팀 구성원과 공유 시트에서 협업할 수 있음
     * 설정, 커널, 비싼 클라우드 비용이 필요 없음
     * 전체 Python 및 JS 생태계를 활용할 수 있음

PySheets 이용 현황

     * PySheets는 2024년 4월 27일에 공개 베타 버전으로 출시됨
     * 4월 21일과 23일에는 초기 베타 테스터인 Bruno가 재미있게 사용한 것으로 나타남
     * 차트는 PySheets에서 생성되고 ""embed"" 기능을 사용하여 제공됨

사용자 피드백

     * ""내장된 Python으로 클라이언트 측 스프레드시트를 사용할 수 있다니 좋네요!"" - JG
     * ""Python의 유연성과 뚜렷한 스프레드시트 인터페이스 및 시각화가 마음에 듭니다."" - *****@google.com
     * ""PySheets는 내가 좋아하는 배열 기반 코딩을 가능하게 합니다!"" - FK
     * ""셀과 Python을 결합하는 것은 멋집니다!"" - FG
     * ""PySheets는 사용하기 쉽고 사용자 정의할 수 있습니다."" - IT
     * ""Jupyter 노트북과 스프레드시트의 독특한 융합."" - FE
     * ""프로세스 흐름도, 스프레드시트, 스크립트를 한 번에 얻을 수 있습니다."" - B2
     * ""PySheets는 오픈 소스 LTK를 사용하므로 흥미롭습니다."" - AL
     * ""브라우저를 떠나지 않고 상호 작용, Excel, 모든 것을 할 수 있어요!"" - PZ
     * ""PySheet는 비기술 분석가와 데이터 과학자 사이의 격차를 좁혀줍니다."" - *****@miracalml.com
     * ""PyScript에 대한 훌륭한 작업입니다. 플랫폼을 최대한 활용하고 있습니다."" - *****@anaconda.com
     * ""PySheets는 Python을 먼저 코딩하는 사람들을 위한 Excel입니다."" - NA

가격 정책

     * 무료: 5개 시트의 무제한 편집, 100개 AI 생성, Excel 가져오기/내보내기
     * Pro ($19.99/월): 협업, 무제한 시트, 커뮤니티 지원, 무제한 AI 생성
     * Enterprise: Single Sign-On, 온프레미스 설치, 로컬 스토리지, 전담 지원, 감사 대시보드

팀 소개

     * 수석 개발자 Chris Laffra는 개발 도구 구축에 30년 이상의 경험을 보유하고 있으며, IBM, Google, Uber에서 근무했고 Morgan Stanley, Bank of America, JP Morgan에서 혁신적인 금융 상품을 구축하기 위해 엔지니어링 팀을 이끌었음
     * 제품 리더인 Kurt Vile은 월스트리트 출신의 글로벌 기술 임원이자 전략적 IT 비전을 가진 사람으로, 기술 플랫폼, 소프트웨어 엔지니어링, 데이터, 데이터 과학, 일반 AI 및 금융에 전문 지식을 보유하고 있으며, 스프레드시트와 데이터 분석에 대한 타고난 이해력을 가지고 있음
     * Chris와 Kurt는 기술적, 재무적 전문 지식과 훌륭한 사용자 경험에 대한 열정을 결합하고 있음

GN+의 의견

     * PySheets는 Python을 브라우저에서 직접 실행하고 데이터 분석을 위한 친숙한 스프레드시트 인터페이스를 제공함으로써 데이터 과학자와 비개발자 간의 간극을 좁히는 흥미로운 제품으로 보임
     * 기존의 Jupyter Notebook이나 Google Colab과 유사한 면이 있지만, 스프레드시트 UI를 제공한다는 점에서 차별화됨. 다만 고급 분석을 위해서는 여전히 Python 코딩 능력이 필요할 것으로 보임
     * 가격이 다소 높은 편이라 개인 사용자 유치는 쉽지 않을 것 같고, 기업 고객을 대상으로 한 엔터프라이즈 기능에 좀 더 포커스를 맞추는 것이 나을 것 같음
     * 금융, 회계 분야에서의 활용 가능성이 클 것으로 보이며, 경영진/의사결정권자와 데이터 분석가 간 소통 및 협업 도구로서의 가치도 기대됨
     * 스프레드시트에 머신러닝, 시각화 등의 기능을 추가한 제품으로는 MS의 Excel Ideas나 Google Sheets의 Explore 기능 등이 있는데, 여기에 비해 PySheets는 보다 유연하고 강력한 Python 기반 분석 환경을 제공한다는 장점이 있음

   이런거 좋네요

        Hacker News 의견

     * PySheets는 Python으로 작성된 웹 앱으로, PyScript와 PyScript-LTK를 사용하여 브라우저에서 실행되며, MicroPython과 PyOdide의 두 가지 Python VM을 활용함
     * 저자는 브라우저에서 Python으로 웹 앱을 작성하는 것에 대한 의견을 듣고 싶어함
     * 처음에는 Python을 수식 언어로 사용하는 PySheets와 유사한 것을 구현했지만, 대량 CSV 가져오기 시 Python 인터프리터가 병목이 되고 GIL이 병렬 처리를 막는 등의 성능 문제가 있었음
     * 또한 Python과 Excel 수식 언어 간의 작은 구문 차이로 인해 비즈니스 사용자가 채택하기 어려웠음
     * 그래서 스프레드시트 엔진과 수식 언어를 Rust로 구현하고, Python 코드 창을 통해 임의의 Python 함수를 작성하여 스프레드시트 셀에서 수식으로 호출할 수 있게 했음. Pandas 데이터프레임을 Python과 스프레드시트 간에 매끄럽게 마샬링할 수 있어 성능 저하 없이 순수 Python의 90% 이점을 얻을 수 있음
     * PySheets 워크플로와 사용 사례를 알아보기 위해 동영상 연습이나 자습서가 있으면 좋겠음. 계정 등록 없이도 알 수 있으면 좋겠음
     * 비기술 사용자를 위한 쉬운 GUI와 데이터 지향적인 Pandas를 동시에 제공하는 좋은 아이디어임
     * 건강 관련 데이터를 외부 서비스에 업로드하는 것이 불편할 수 있으므로, 자체 호스팅되는 유사한 프로젝트가 있는지 궁금함
     * Excel, Sheets, Numbers가 Python 같은 좋은 언어로 코딩하고 시각화/쿼리할 수 있게 해주지 않아 짜증나는 사람에게는 꽤 멋진 프로젝트임
     * 그러나 ""AI 기반""이라는 문구가 눈에 띄는데, 홈페이지에서 이에 대한 자세한 설명이 없어 우려됨. 데이터가 ""환각""될 수 있다는 점이 걱정되므로 정확히 무엇을 의미하는지 설명이 필요해 보임
     * 2000년대 초반 런던의 스타트업 Resolver Systems가 Python과 스프레드시트를 결합하려 했으나 실패했는데, 당시에는 Python의 인지도가 훨씬 낮았기 때문일 수 있음
     * PySheets로 Excel 파일을 가져올 때 원래 Excel 파일의 수식도 인식하는지, PySheets의 기능을 보여주는 동영상이 있는지 궁금함
     * Python을 스프레드시트에 활용하는 것은 훌륭한 아이디어이며, Excel에서도 이미 하고 있지만 PySheets처럼 명확하고 사용하기 쉬운 구현체를 보는 것은 반가움
     * 스프레드시트가 좀 더 제한적이어서(예: 시트를 테이블 형식으로 강제) 조직 내에서 스프레드시트를 만들 때 이해하기 어려운 엉망진창을 만들지 않도록 하면 좋겠음
     * Python은 새로운 Excel이고, 이제 PySheets는 새로운 Python임
"
"https://news.hada.io/topic?id=14539","뉴욕주 법원, ISP에 15달러 broadband 제공 의무화하는 법률 합헌 판결","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             뉴욕주 법원, ISP에 15달러 broadband 제공 의무화하는 법률 합헌 판결

뉴욕주의 저소득층 대상 $15 브로드밴드 법안 유효 판결

     * 연방 항소법원은 인터넷 서비스 제공업체(ISP)들이 저소득 소비자들에게 $15의 브로드밴드 요금제를 제공하도록 하는 뉴욕주 법의 시행을 막았던 판결을 뒤집음
     * 이는 ISP들을 대표하는 6개 무역단체에게는 패배이지만, 현재로서는 이 법이 시행될지는 불분명함

  뉴욕주의 Affordable Broadband Act (ABA) 개요

     * 저소득층 정부 지원 대상자들에게 ISP가 월 $15에 25Mbps, 월 $20에 200Mbps 브로드밴드를 제공하도록 함
     * 몇 년마다 가격 인상을 허용하고, 고객 2만명 미만 ISP에는 면제 조항이 있음

  연방법에 의한 주법 선점 여부에 대한 판단

     * 1934년 통신법(1996년 개정)은 주정부의 요금 규제 진입을 배제할 정도로 포괄적이지 않아 ABA가 연방법에 선점되지 않음
     * 2018년 FCC의 브로드밴드를 정보서비스로 분류한 명령으로 ABA가 상충 선점되지 않음. FCC가 브로드밴드 요금에 대한 규제 권한을 박탈당했기에 주정부 규제를 배제할 수 없음

  ISP들이 선택할 수 있는 대안들

     * 뉴욕주 의회에 이의 제기
     * 의회에 통신법상 FCC의 권한 변경 요청
     * FCC에 브로드밴드 분류 재검토 요청
     * 행정법과 연방주의 원칙의 왜곡을 법원에 요구할 순 없음

GN⁺의 의견

     * FCC가 최근 브로드밴드를 다시 분류해 망중립성 규칙을 복원함에 따라, ISP들이 뉴욕주 법을 선점할 더 나은 근거를 가질 수도 있음. 하지만 FCC 자체가 연방 차원의 요금 규제는 명시적으로 거부하고 있어 주법 선점을 시도하지 않을 수도 있음.
     * 저소득층 지원과 보편적 서비스 제공이라는 공익적 목적에도 불구하고, 주정부의 개입이 시장 왜곡과 혁신 저해 등의 부작용을 낳을 수 있다는 우려가 제기될 수 있음. 요금 규제보다는 바우처 등 수요자 지원 방식이 더 효과적일 수 있음.
     * 미국의 통신정책이 정권에 따라 너무 자주 바뀌는 것은 산업계에 불확실성을 높이는 요인임. 기술 발전과 시장 상황에 따른 유연한 접근이 필요하지만, 보편적 서비스 등 일관된 정책 기조는 유지되어야 할 것임.
     * 주정부 차원의 망중립성이나 요금규제 시도가 연방정부와 갈등을 빚고 사법부까지 개입하게 되는 상황은 바람직하지 않음. 연방-주정부간, 입법-행정-사법부간 역할 정립이 필요해보임.

        Hacker News 의견

   요약해보면 다음과 같음:
     * 인터넷 서비스가 기본권이라면 정부가 서비스를 제공하거나 저소득층을 위해 시장가격을 지불해야 한다는 의견
     * 25Mb/s에 $15인데도 ISP들이 불만을 제기하는 것에 대한 의아함 표현
     * 독일 공공도서관에서 무료 인터넷을 제공하지만 잘 활용되지 않는다는 언급
     * 가격 통제가 장기적으로 작동한 사례가 있는지에 대한 의문 제기
     * $15에 불과하니 그냥 무료로 제공하는 게 낫지 않겠냐는 반문
     * ISP의 서비스 품질 저하나 주에서의 철수 가능성에 대한 우려
     * 모든 인터넷은 주나 지자체가 보조금을 주거나 무료로 제공해야 한다는 주장
     * 정부 보조금으로 만들어진 브로드밴드 인프라를 ISP가 반환해야 한다는 견해
     * 인플레이션을 고려하지 않은 점이 흥미롭다는 언급
     * 브로드밴드는 이제 필수 인프라라는 인식
     * ISP들이 신청 과정을 고통스럽게 만들거나, 2만명 미만의 고객을 대상으로 하는 페이퍼컴퍼니를 만들 것이라는 전망
"
"https://news.hada.io/topic?id=14506","읽은 내용이 당신을 만든다, 기억하지 못한다 해도","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      읽은 내용이 당신을 만든다, 기억하지 못한다 해도

독서는 기억하지 못하더라도 자신을 만드는 것

     * Dave Rupert의 말에 따르면, ""책을 읽는 목표는 마지막 페이지에 도달하는 것이 아니라 자신의 사고를 확장하는 것""임
     * 개인의 생산성을 최적화하고 극대화하는 것을 우선시하는 환경에서는 책의 영향을 측정하거나 기억할 수 없다면 읽을 가치가 없는 것처럼 보일 수 있음
     * 하지만 저자는 그렇게 생각하지 않으며, 그 이유를 표현할 적절한 단어를 찾지 못했음
     * Dave의 표현이 저자의 생각과 매우 유사했음

Ralph Waldo Emerson의 인용

     * 며칠 후 저자의 아내가 Ralph Waldo Emerson의 인용구를 보내줌
     * ""내가 읽은 책들을 내가 먹은 식사만큼 기억할 수는 없지만, 그럼에도 불구하고 그것들은 나를 만들었다""
     * Emerson은 저자 자신의 생각 속에서 파악할 수 없었던 것을, 말로 표현할 수 없었던 것을 간결하게 표현함

온라인 세계에서의 유사한 관점

     * 블로그 포스트도 마찬가지로, 읽은 것을 항상 기억하지는 못하더라도 자신을 만드는 데 기여함
     * 콘텐츠 다이어트에 주의를 기울일 필요가 있음
     * 읽는 것이 자신을 만든다는 것을 상기시켜 줌

독자의 반응

     * @halas@mastodon.social이 공유한 이야기
          + 대학 교수가 1학년 때 수업을 하고 2학년 때 다시 수업을 함
          + 2학년 초에 전년도 수업 내용에 대해 질문했을 때 침묵에 빠진 학생들을 보고 ""교육은 아무것도 기억나지 않더라도 가지고 있는 것""이라고 말함
     * 저자는 이처럼 사람들과 함께 오래 기억에 남는 이야기를 좋아함
     * 어떤 영향은 측정할 수 없음

GN⁺의 의견

     * 이 글은 단순히 책을 읽는 것 자체가 중요하다는 메시지를 전달하고 있음. 책을 읽는 것은 단순히 지식을 쌓는 것 이상의 의미가 있음을 강조하고 있음
     * 하지만 책을 읽는 것만으로는 부족할 수 있음. 책에서 얻은 지식을 실제로 활용하고 적용하는 과정이 필요함. 그래야 진정으로 자신의 성장에 도움이 될 수 있음
     * 또한 읽는 책의 종류와 질도 중요함. 자신에게 필요하고 도움이 되는 책을 선택해서 읽는 것이 중요함. 무작정 많은 책을 읽는 것보다는 자신에게 맞는 책을 선별해서 읽는 것이 더 효과적일 수 있음
     * 온라인 콘텐츠도 마찬가지임. 블로그나 SNS에서 접하는 정보들이 자신에게 어떤 영향을 미치는지 인지하고, 건강한 콘텐츠를 선별해서 접하는 것이 중요함
     * 교육의 진정한 가치는 단순히 지식을 습득하는 것이 아니라, 그 과정을 통해 성장하고 발전하는 것에 있음. 이는 학교 교육뿐만 아니라 평생 교육의 관점에서도 중요한 메시지라고 생각함

   저에겐 정말 위안이 되는 글이네요. 수 많은 책들을 사서 다 읽어보진 못하는 것에 대해 일종의 죄책감 같은 것이 있었는데... 댓글들의 인용들도 많은 생각이 드네요.

   좋아하는 소설가가 쓴 글이 생각나네요.
   그게 어떤 소설이 되었든, 소설을 읽는 동안 우리는 그것이 모두 허튼소리라는 것을 숙지해야만 하며, 그러면서도 읽는 동안에는 그 안에 담긴 모든 것을 믿어야 한다. 그래서 마침내 그 소설을 다 읽었을 때, 훌륭한 소설이라면 우리는 그것을 읽기 전과 조금은 달라졌음을, 조금은 바뀌었음을 깨닫게 되리라. 이전에 전혀 가본 적 없는 낯선 거리를 지나다 새로운 사람을 만나 달라지듯 말이다. 하지만 우리가 무엇을 배웠는지, 어떻게 달라졌는지를 '말하기'란 아주 어렵다. - 어슐러 르 귄 어둠의 왼손 서문

   책을 읽는다고 해서 당장의 큰 변화는 이루기 어렵지만, 시간이 지나면 자연스레 우리의 사고력을 더 키워주는 것 같습니다. 그런 점에서 보면 운동과 같네요. 하루 바짝 한다고 티는 안나는데 조금씩 꾸준하게 하면 결국 몸이 바뀌는 것처럼요. ㅎㅎ

   덧글 요약까지 생각이 많아지는 내용이네요.
   저를 건강한 컨텐츠에 많이 노출시키는 전략을 사용해야 겠어요.
   물론 덧글의 조언도 잊지 말고요 ㅎ

     우리가 섭취하는 콘텐츠에 대해 신중해야 하지만, 때로는 정크푸드나 졸작 드라마를 보는 것처럼 자기 위안이 되는 것도 필요함. 지나친 죄책감을 가질 필요는 없음.

   ""영화가 술이라면 책은 물이다""라고 말해주는 이동진 평론가의 책에 대한 이야기를 추천 드립니다.

        Hacker News 의견

     * 우리는 평생 경험한 감각적 상호작용, 만난 사람들, 읽은 책, 광고, 노래, 뉴스 헤드라인 등 모든 것의 결과물이며, 이는 무의식중에 우리의 뇌에 처리되어 이후의 결정에 영향을 미쳐 현재의 우리를 만들어냄. 이를 깨달은 후로는 무엇을 할지 말지 더 신중해짐.
     * 최근 ""내 대화를 엿듣고 광고/기사를 보여주는 것 같다""는 생각의 근본 현상을 깨달음. 언젠가 내적 대화에서 ""외계인이 피라미드를 만들었다""는 프린지 이론을 예로 들었는데, 나중에 ""피라미드는 어떻게 지어졌을까?""라는 기사를 봄. 사실 평소에는 ""지구가 평평하다""는 것을 프린지 이론의 예시로 사용했기에, 갑자기 피라미드를 예로 든 것은 무의식중에 기사 제목을 보고 영향을 받은 것으로 보임. 이는 내 생각이 피드에 의해 어느 정도 쓰여진다는 점에서 더 충격적인 설명임.
     * 책을 읽은 것을 기억하지 못한다고 해서 책이 나에게 영향을 미치지 않은 것은 아님. 책을 읽고 얻은 관점은 내 안에 남아있음. 모든 출처를 인용할 수 있을 정도로 기억하지 못한다고 자책할 필요는 없음.
     * 하지만 안 좋은 것을 읽는 것도 흔적을 남기며, 정크푸드처럼 정크 리딩도 존재함. 이는 정보 다이어트의 주제를 생각하게 함.
     * 시인이 되고 싶은 사람에 대한 오래된 아랍 이야기가 떠오름. 그 사람은 시 수만 편을 암기한 후 시인의 칭호를 받고 싶어 했지만, 시인왕은 그에게 시를 잊으라고 함. 몇 년 후 시를 잊은 후에야 그는 시인의 칭호를 받을 수 있었음. 이는 LLM이 처음에는 텍스트를 ""암기""하지만 데이터가 쌓일수록 정확한 텍스트를 ""잊어버리는"" 것과도 유사함.
     * 하지만 모든 감각 입력이 동등한 것은 아님. 우리 뇌에는 이전 입력을 바탕으로 감각 입력에 더 많거나 적은 가중치를 부여하는 메커니즘이 있음. 어떤 책은 잘 공명하여 오래 기억에 남지만, 어떤 책은 그렇지 않음.
     * 우리가 섭취하는 콘텐츠에 대해 신중해야 하지만, 때로는 정크푸드나 졸작 드라마를 보는 것처럼 자기 위안이 되는 것도 필요함. 지나친 죄책감을 가질 필요는 없음.
     * 세부사항은 잊어버려도 주제의 대략적인 모양은 기억에 남음. XYZ에 대한 모든 세부사항은 기억나지 않을 수 있지만, 적어도 XYZ가 존재한다는 것을 알게 됨. 내적 세계지도가 확장되고 수정됨.
     * 책의 목표는 마지막 페이지에 도달하는 것이 아니라 사고를 확장하는 것임. 이는 소설에도 적용됨. 어떤 이들은 소설 읽기를 시간 낭비로 여기지만, 소설도 비소설에서는 쉽게 혹은 전혀 탐구할 수 없는 방식으로 아이디어를 탐구할 수 있음.
     * 좋은 책은 처음에는 빠르게 읽고, 필기는 하지 않는 것이 좋음. 좋다면 주기적으로 다시 읽되, 그렇지 않다면 그냥 넘어가는 것도 좋은 접근법. 이는 좋은 것에 자연스러운 간격 반복을 주고, 읽을 때마다 다른 것을 배울 수 있게 해줌.

    1.

   ""평생 경험한 감각적 상호작용, 만난 사람들, 읽은 책, 광고, 노래, 뉴스 헤드라인 등 모든 것""을 데이터 삼아 우리 뇌 속의 신경망 학습을 하는 것이라 보고 있습니다.
   사람 고쳐쓰지 못한다는 말은 한 번 학습된 신경망은 변경이 불가능한 것은 아니지만 매우 어렵다는 걸 이야기한다 생각합니다.
    2.

   시인이 되는 것에 대한 이야기는 비슷한 이야기도 많이 떠오르네요. 바둑에서 정석을 외운다음 잊어버리라거나, 야구 타자가 타격폼의 정석을 열심히 배운다음 잊어버리고 자신만의 타법을 완성한다거나 하는 이야기
"
"https://news.hada.io/topic?id=14494","Piet: 추상화 같은 프로그램을 만드는 프로그래밍 언어 (2002년 개발)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Piet: 추상화 같은 프로그램을 만드는 프로그래밍 언어 (2002년 개발)

Piet 프로그래밍 언어 소개

     * Piet는 추상화된 그림처럼 보이는 프로그램을 작성하는 프로그래밍 언어
     * 기하학적 추상 예술 분야를 개척한 Piet Mondrian의 이름을 따서 명명됨

Piet 언어 설계 원칙

     * 프로그램 코드는 추상 예술의 형태를 띰

Piet에서 사용하는 색상

     * Piet는 20가지 고유한 색상을 사용
          + 색조 순환: 빨강 -> 노랑 -> 초록 -> 청록 -> 파랑 -> 자홍 -> 빨강
          + 밝기 순환: 밝음 -> 보통 -> 어두움 -> 밝음
     * 흰색과 검은색은 두 순환에 포함되지 않음
     * 추가 색상(주황, 갈색 등)은 사용할 수 있지만 효과는 구현에 따라 다름
          + 가장 단순한 경우 흰색과 동일하게 처리

Codel (코델)

     * Piet 코드의 기본 단위는 색상 블록
          + 하나 이상의 인접한 동일 색상 코델로 구성
          + 대각선으로만 인접한 색상 블록은 연속적이지 않음
          + 모양에 제한이 없고 내부에 다른 색상의 ""구멍""이 있을 수 있음

스택

     * Piet는 모든 데이터 값 저장에 스택을 사용
     * 데이터 값은 정수로만 존재하지만 유니코드 문자 값으로 읽거나 출력될 수 있음
     * 스택은 개념적으로 무한히 깊지만, 구현시 유한한 최대 크기 제공 가능

프로그램 실행

     * Piet 인터프리터는 프로그램의 왼쪽 상단 코델을 포함하는 색상 블록에서 실행 시작
     * 방향 포인터(DP)와 코델 선택기(CC)를 유지하며 다음 규칙에 따라 색상 블록 이동:
          + 현재 색상 블록의 가장자리 중 DP 방향으로 가장 먼 가장자리 찾기
          + 해당 가장자리에서 CC 방향으로 가장 먼 코델 찾기
          + 해당 코델에서 DP 방향의 인접 색상 블록으로 이동
     * 프로그램이 종료될 때까지 위 과정 반복

문법 요소

  숫자

     * 검은색, 흰색이 아닌 각 색상 블록은 해당 블록의 코델 수와 같은 정수 나타냄
     * 양수만 표현 가능하지만 연산자로 음수 생성 가능
     * 인터프리터가 숫자를 만나도 자동으로 스택에 푸시하지 않음

  검은색 블록과 가장자리

     * 검은색 블록과 프로그램 가장자리는 프로그램 흐름 제한
     * 검은색 블록이나 가장자리로 이동하려고 하면 CC 토글되고 DP 시계방향 회전
     * 8번 시도 후에도 이동할 수 없으면 프로그램 종료

  흰색 블록

     * 흰색 블록은 인터프리터가 아무런 제한 없이 통과하는 ""자유"" 영역
     * 흰색 코델을 DP 방향으로 ""미끄러지듯"" 이동하여 비흰색 블록 도달
     * 흰색 블록을 가로질러 새로운 색상으로 이동해도 명령 실행 안함
     * 흰색 블록 내에서 경로를 완전히 되짚으면 프로그램 종료

명령

     * 인터프리터가 한 색상 블록에서 다른 색상 블록으로 이동할 때 색상 변화에 의해 정의
     * 색조 순환과 밝기 순환의 단계 수에 따라 실행할 명령 결정
     * 흰색 블록을 가로질러 이동하면 명령 실행 안함
     * 주요 명령:
          + push, pop, add, subtract, multiply, divide, mod, not, greater
          + pointer, switch, duplicate, roll
          + in(number), in(char), out(number), out(char)

GN⁺의 의견

     * Piet는 시각적으로 매력적인 프로그래밍 언어로, 추상 예술과 프로그래밍의 독특한 결합을 보여줌
     * 그러나 실용성 측면에서는 한계가 있어 보임. 복잡한 프로그램 작성이 쉽지 않을 것으로 예상됨
     * 주로 프로그래밍 언어 설계에 대한 실험이나 퍼즐, 예술 작품 제작 등에 활용될 수 있을 것 같음
     * 비주얼 프로그래밍 언어로는 구글의 Blockly나 MIT의 Scratch가 좀 더 실용적인 대안이 될 수 있음
     * 아무래도 Piet가 지나치게 deep한 언어라, 실제 초보자들이 프로그래밍 학습용으로 사용하긴 어려울 것 같다는 생각이 듦

        Hacker News 의견

     * Piet 언어의 예제 페이지에 있는 마지막 프로그램이 정말 놀라움. 한 사람(Piet라 불리는)이 Piet 언어를 연상시키는 작품을 보고 실행해 보았는데, 실제로 작동했음. 그래픽 아티스트가 우연히 실행 가능한 프로그램을 그린 역사상 처음 있는 일임.
     * Piet는 에소테릭 프로그래밍 언어 중에서 획기적인 실험이지만, 개발자가 의도적으로 하지 않는 한 몬드리안 그림처럼 보이게 하려는 목표 달성에는 미흡함. 언어 구조 자체가 작성된 것이 몬드리안 그림처럼 보이도록 설계되었으면 함.
     * 이는 ""알고리즘이 어떻게 생겼는가?""라는 질문을 제기함. 헤르만 헤세의 소설 '유리알 유희'(Magister Ludi)와 같은 것을 현실에서 만들 수 있을까? 시각적 지향적인 사람으로서 그렇게 생각하고 싶고, 실제로 그런 도구를 사용해 보려 했으나, 모호한 답변으로 인해 시각적 표현력과 모듈성 사이의 균형을 맞추기 어려움.
     * 이런 류의 것들은 범죄 스릴러에서 주인공/수사관들을 혼란스럽게 하다가 누군가 그것이 코드라는 것을 알아채는 식으로 등장할 것 같음. 우리는 QR 코드가 유용하다고 생각했는데...
     * Piet를 발견하는 것은 경외감, 혼란, 경이로움의 특별한 순간임. 이는 CS 팟캐스트에서 친구 Oz와의 대화에 포착되어 있음.
     * 한 사람이 Piet로 퀸(Quine)을 만들었음. 이미지는 깨졌지만 CodeGolf에 복사본이 있음.
     * 대학에서 에소테릭 프로그래밍 언어에 대한 작은 과정이 있었고, 각자 언어를 선택해 가지고 놀았음. Piet를 선택했는데 재미있었지만 솔직히 작은 예제 애플리케이션은 미적으로 만족스럽지 않았음. Piet로 예술을 만들려면 전문가가 되어야 할 듯.
     * 대학 시절 이것을 접하고 밤늦게까지 간단한 프로그램을 작성했는데, 정말 재미있는 경험이었음. 사람들이 한 번쯤 시도해 보기를 추천함!
     * 예제 페이지가 놀라움. 캔버스가 점점 더 정교하고 아름답게 발전하는 것을 볼 수 있음.
     * 정말 멋짐! Piet 작품을 모아서 주어진 텍스트를 반환하는 프로그램을 만드는 것이 가능할지 궁금함. Piet 코드 생성기 같은 것 말임. 인쇄물로 멋진 선물이 될 것 같음!
"
"https://news.hada.io/topic?id=14587","EU, "애플은 6개월 내에 iPadOS에 사이드로딩 허용하라" 요구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 EU, ""애플은 6개월 내에 iPadOS에 사이드로딩 허용하라"" 요구

EU, iPadOS를 ""게이트키퍼""로 규정하여 DMA 규정 준수 의무화

     * EU 규제당국은 iPadOS를 ""게이트키퍼""로 분류하기로 결정함. 이는 아이패드가 곧 아이폰과 동일한 규정을 적용받게 됨을 의미함.
     * 3월 iOS 17.4 출시와 함께 EU의 아이폰은 DMA(Digital Markets Act) 규정을 적용받기 시작했음. 이 규정은 애플이 대체 앱스토어, 앱 사이드로딩, 서드파티 브라우저 엔진 등을 iOS에서 처음으로 지원하도록 강제하는 내용을 포함함.
     * EU는 2023년 9월 iPadOS가 게이트키퍼 자격이 있는지 조사하기 시작했으며, 이는 iOS, 사파리 브라우저, 앱스토어가 모두 게이트키퍼로 결정된 날과 같음.
     * EU 블로그 포스트에 따르면 ""애플은 이제 6개월 안에 iPadOS가 DMA 의무사항을 완전히 준수하도록 해야 함"".

iOS와 iPadOS의 유사성

     * 애플은 2019년 태블릿 OS를 ""iPadOS""라고 부르기 시작하면서 아이패드의 OS를 아이폰과 기술적으로 분리했음.
     * 그러나 실질적으로 두 OS를 구분하는 것은 거의 없음. iOS와 iPadOS는 동일한 소프트웨어 빌드 번호를 공유하고, 거의 동시에 업데이트되며, DMA 준수 목적상 가장 중요한 것은 동일한 잠금 상태의 앱스토어에서 소프트웨어를 가져오며 동일한 애플 제한 사항이 적용된다는 점임.

DMA 준수에 따른 변화 예상

     * 대체 앱스토어나 서드파티 웹사이트를 통해 배포되는 앱은 애플의 많은 규칙을 따라야 하며, 여전히 애플의 공용 API 사용에 제한을 받을 것임.
     * 그러나 아이패드의 큰 화면(데스크톱급 M 시리즈 칩)에서 대체 앱스토어와 브라우저 엔진을 사용할 수 있게 되면, Mac 사용자들이 시스템에서 할 수 있는 일을 더 많이 할 수 있게 되어 태블릿이 더 나은 노트북 대체품이 될 수 있음.

EU의 추가 조사와 영향

     * 애플은 DMA 준수를 위해 EU에서 iOS에 여러 변경을 가했지만, EU 규제 당국은 이미 애플(구글 및 메타와 함께)에 대해 ""비준수""로 조사 중임.
     * 조사 결과에 따라 EU는 iOS에서 서드파티 앱 설치 방식과 서드파티 개발자의 애플 이외 앱스토어 및 결제 옵션 광고 방식에 대해 애플에 더 많은 변경을 요구할 수 있음.
     * 애플이 조사 결과에 따라 iOS 준수를 위해 변경한 사항은 아이패드에도 그대로 적용될 것으로 보임.
     * 물론 이는 미국 기반 아이폰이나 아이패드 사용자에게 직접적인 영향을 미치지 않음. 이들 기기는 여전히 애플의 앱스토어와 WebKit 브라우징 엔진으로 제한됨.
     * 그러나 최근 애플의 DMA 준수 시도에서 비롯된 것으로 보이는 일부 앱스토어 규칙 변경이 관찰되고 있음. 특히 처음으로 (일부는 아니지만) 레트로 게임 콘솔 에뮬레이터를 앱스토어에서 허용하는 정책 변경이 주목할 만함.

GN+의 의견

     * 이번 EU의 결정은 Apple의 독점적인 생태계에 큰 타격이 될 것으로 보임. 앱스토어 수수료 수입 감소는 불가피해 보이며, 사용자들이 iOS/iPadOS 밖에서도 앱을 자유롭게 설치할 수 있게 되면서 Apple의 통제력이 많이 약화될 것임.
     * 하지만 DMA가 적용되더라도 일반 사용자들이 바로 체감할 수 있는 변화는 크지 않을 것임. 기존 앱스토어에 익숙한 대부분의 사용자들은 계속 앱스토어를 이용할 것이고, 개발자들도 앱스토어 심사를 통과해야 더 많은 사용자에게 도달할 수 있기 때문임.
     * 그럼에도 DMA는 모바일 생태계의 독점 해소와 개방성 확대라는 면에서 획기적인 규제임. 구글의 안드로이드에 비해 폐쇄적이던 iOS와 iPadOS가 상당 부분 개방될 수밖에 없게 되었고, 이는 장기적으로 모바일 플랫폼 시장의 경쟁 활성화로 이어질 것으로 전망됨.
     * 한편 EU의 이번 결정이 미국이나 다른 국가에는 영향을 미치지 않는다는 점에서, 글로벌 시장에서 iOS/iPadOS의 파편화 가능성도 제기됨. 지역마다 다른 정책을 적용해야 하는 부담이 애플에게 있는 만큼, 애플이 어떻게 대응할지 주목됨.
     * 요컨대 DMA는 디지털 시장에서 거대 플랫폼 기업의 지배력을 견제하려는 EU의 강력한 의지를 보여주는 사례임. 최종 소비자에게 더 많은 선택권을 주고 경쟁을 촉진한다는 명분은 충분하지만, 한편으로 과도한 규제가 오히려 혁신을 저해할 수 있다는 우려도 있음. 향후 DMA의 실제 효과와 글로벌 파급력이 주목됨.
"
"https://news.hada.io/topic?id=14582","Show HN: Svelte와 Three.js 기반의 웹용 3D 프레임워크","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Show HN: Svelte와 Three.js 기반의 웹용 3D 프레임워크

Threlte 소개

     * Threlte는 Svelte와 Three.js 위에 구축된 웹용 3D 프레임워크
     * Threlte를 사용하면 Three.js의 모든 기능을 선언적인 방식으로 사용 가능
     * Threlte의 렌더링 컴포넌트로 장면을 구성하고 나머지는 Threlte가 처리
     * Svelte 컴포넌트의 라이프사이클을 활용하여 이벤트 구독, 상태 변경 처리 등이 가능

Threlte 생태계

     * Threlte는 최고 수준의 물리 엔진인 Rapier, 전문적인 모션 디자인 도구 세트가 있는 애니메이션 라이브러리인 Theatre.js, GLTF 파일을 Threlte 컴포넌트로 변환하는 도구인 @threlte/gltf와 같은 통합 기능 제공
     * @threlte/extras는 시작하는 데 유용한 컴포넌트 및 유틸리티 모음 제공

Threlte 플러그인

     * Threlte의 핵심에는 <T> 컴포넌트 하나가 있음
     * 플러그인을 사용하여 <T>에 사용자 정의 props와 이벤트를 추가할 수 있음

GN⁺의 의견

     * Threlte는 Three.js와 Svelte를 결합한 웹 3D 프레임워크로, 선언적이고 사용하기 쉬운 API를 제공하여 웹에서 3D 앱 개발을 간소화함
     * 물리 엔진, 애니메이션 라이브러리, GLTF 변환 도구 등 강력한 통합 기능과 유용한 컴포넌트를 제공하여 개발자 경험을 향상시킴
     * 다만 Three.js에 의존하므로 성능 문제가 발생할 수 있고, Svelte 생태계에 한정되어 있어 다른 프레임워크 사용자는 사용하기 어려울 수 있음
     * 웹에서 3D를 사용하는 프로젝트를 고려 중이라면 Threlte를 검토해 볼만한 가치가 있어 보이며, 특히 Svelte 사용자라면 더욱 매력적인 선택지가 될 것으로 보임
"
"https://news.hada.io/topic?id=14569","레이저로 들뜬 원자핵: 수십 년 만의 획기적 돌파구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      레이저로 들뜬 원자핵: 수십 년 만의 획기적 돌파구

수십 년 만에 획기적인 성과: 레이저로 원자핵 여기

     * 물리학자들이 수십 년 동안 찾아온 ""토륨 전이""가 레이저를 사용하여 처음으로 여기되었음
     * 이는 핵시계를 포함한 혁명적인 고정밀 기술에 길을 열어줌

GN⁺의 의견

     * 레이저와 원자핵의 상호작용에 대한 연구는 양자 광학, 양자 정보 처리, 정밀 측정 등 다양한 분야에서 중요한 역할을 할 것으로 보임
     * 토륨은 안정적이고 독성이 적은 원소로 알려져 있어, 실용적인 측면에서도 활용 가능성이 높음
     * 다만 토륨을 다루기 위해서는 방사능 안전에 대한 고려가 필요할 것임
     * 레이저와 원자핵의 상호작용을 더 잘 이해하기 위해서는 이론적인 연구와 함께 다양한 실험적 검증이 뒷받침되어야 할 것으로 보임
     * 이 연구 성과가 핵시계 개발로 이어진다면, GPS 등 위치 기반 서비스의 정확도를 크게 향상시킬 수 있을 것으로 기대됨

        Hacker News 의견

     * 두 개의 연구 그룹이 서로 다른 토륨 도핑 결정에서 동일한 신호를 관찰함으로써 실제 핵 전이를 발견했다는 것이 매우 설득력 있음.
     * 기사에서 토륨 전이의 정확한 파장(148.3821 nm)을 언급하지 않아 독자를 궁금하게 만듦. 일반인에게는 의미 없는 숫자일 수 있지만, 중요한 정보임.
     * 양성자나 핵자의 내부 구조에 대해 아직 정확히 알지 못하는 부분이 많음. 거대 에너지로 ""탐침""하는 것의 한계가 있음. 광자와 레이저의 정밀성을 이 분야에 도입하는 것은 큰 발전이 될 것임.
     * 저자 중 한 명은 과거 Th(232) 3+ 이온을 포획하고 레이저 냉각하는 연구를 선도했었음.
     * 이 기술은 정밀 시간 측정 외에도 지구의 중력장을 분석하여 광물 자원이나 지진을 탐지하는 등 군사적 응용(핵잠수함용 GPS 대체 등)도 가능함.
     * 토륨 전이를 일으키려면 140nm 부근의 매우 정밀한 에너지의 자외선이 필요함.
     * 비엔나는 최근 물리학 분야에서 눈부신 성과(2022, 2023년 노벨상 등)를 내고 있음.
"
"https://news.hada.io/topic?id=14558","Show GN: 개발자라면 알고 있으면 좋을 사이트","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Show GN: 개발자라면 알고 있으면 좋을 사이트

   개발 콘텐츠 중 검증되고 핫한 콘텐츠를 모아 볼 수 있는 2장의 웹사이트

   오 이런거 만들고싶었는데 감사합니다!
"
"https://news.hada.io/topic?id=14596","Run0 - sudo를 대체하는 systemd 기반 도구 발표 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Run0 - sudo를 대체하는 systemd 기반 도구 발표

run0: systemd의 sudo 대체 도구

     * v256에 포함된 새로운 도구 (실제로는 기존 systemd-run 을 symlink 한것)
     * sudo와 유사하게 동작하지만, SUID가 아님
     * 서비스 매니저에 타겟 사용자의 UID로 명령이나 셸을 호출하도록 요청함
          + 클라이언트에서 컨텍스트를 상속하지 않고 PID 1에서 새로 포크된 격리된 실행 컨텍스트에서 타겟 명령을 호출
     * run0는 자체 설정 언어를 구현하지 않고, 권한 부여에 polkit을 사용함.
     * 권한 상승 중에는 터미널 배경을 붉은 색조로 바꾸어 특권으로 동작중임을 알려줌. 윈도우 타이틀에도 권한 상승 여부를 나타내는 붉은 점을 표시함.
     * systemd-run의 --property= 스위치를 지원해서 호출된 특권 명령/세션에 대해 원하는 서비스 설정을 지정할 수 있음.

  sudo의 문제점

     * sudo는 상대적으로 큰 SUID 바이너리로, 비특권 사용자가 자신의 컨텍스트에서 호출할 수 있는 특권 코드임.
     * 복잡한 설정 언어, 로드 가능한 플러그인(LDAP 등), 호스트 이름 매칭 등 공격 표면이 큼.
     * SUID 바이너리라는 점이 가장 큰 문제. 비특권 코드에 의해 호출되고, 비특권 코드가 제어하는 실행 컨텍스트(환경변수, 프로세스 스케줄링 속성, cgroup 할당, 보안 컨텍스트, 전달된 파일 디스크립터 등)를 상속함. SUID 바이너리는 이를 매우 주의깊게 정리해야 하지만 잘 하지 못하는 경우가 많음.

  그외

     * run0로 셸 뿐 아니라 루트 권한으로 다른 명령도 실행할 수 있음. 프로그램 종료시 터미널 색상이 원래대로 돌아옴.
     * 배경색 자동 변경이 불편할 수 있지만 --background= 스위치로 변경하거나 비활성화 할 수 있음.
     * sudo를 run0로 완전히 교체하는 것도 가능해 보이지만, 배포판마다 선호하는 바가 다를 수 있음.
     * LDAP 지원 등 sudo의 플러그인 방식은 문제가 많음. polkit은 systemd에서 안전하게 관리되는 방식으로 확장 가능함.
     * run0의 bash 스크립트 실행 여부는 sudo와 호환되는 SUDO_xxx 환경변수로 확인 가능함.

GN⁺의 의견

     * 자주 사용되는 sudo의 대안으로 run0를 제시한 점이 인상적임. SUID의 위험성을 피하면서도 sudo의 장점은 계승한 것으로 보임.
     * 특권 상승 여부를 시각적으로 명확히 알려주는 것은 실수로 인한 피해를 줄이는데 도움이 될 것 같음. 터미널 배경색을 바꾸는 것이 거슬릴 수도 있겠지만 옵션으로 조정할 수 있어 큰 문제는 아닐 듯함.
     * polkit을 통한 권한 설정이 sudo보다는 덜 유연할 수 있지만, 오히려 단순해지고 공격 표면을 줄일 수 있을 것임. polkit의 설정 예시를 잘 문서화 해주는 것이 중요해 보임.
     * sudo에 의존하는 기존 스크립트 등의 마이그레이션을 위해서는 당분간 sudo도 함께 제공되어야 할 것 같음. 하지만 신규 환경이라면 처음부터 run0를 사용하는 것이 좋겠음.
     * 장기적으로는 run0 도입을 계기로 SUID를 과감히 제거하고, 시스템 권한을 시스템 서비스에서 집중 관리하는 아키텍처로의 전환을 기대해 봄. 보안과 견고성 측면에서 바람직한 방향이라 생각함.

        Hacker News 의견

     * run0은 sudo와 달리 클라이언트로부터 어떤 컨텍스트도 상속받지 않고 PID 1에서 새로 포크된 격리된 exec 컨텍스트에서 대상 명령을 호출함. 이는 shell 명령의 일반적인 사용 사례와 맞지 않아 실제로는 문제의 원인이 될 것이며 널리 채택되기 어려울 것임.
     * run0이 광범위하게 사용된다면 sudo처럼 동작하는 플래그가 추가되고, 사람들은 항상 그 플래그를 사용하게 될 것임. 이것이 문제를 일으킬 때 systemd 프로젝트는 sudo를 제거하려 할 수 있음.
     * run0은 권한 레벨 간에 엄격한 IPC 경계를 가짐으로써 sudo와 다른 접근 방식을 취하고 있음. systemd를 사용하고 싶은 사람들에게는 좋은 방법이 될 수 있음.
     * sudo는 대부분 한 명에 의해 관리되고 있음.
     * run0의 동작은 여러모로 sudo보다는 ssh에 가까움. localhost에 SSH로 연결하는 것으로 유사한 도구를 구현할 수 있음.
     * 1980년대 중반 Berkeley의 실험적 BSD 클론에서 비슷한 아이디어가 테스트되었으나, 모든 것을 파이프로 전달하는 복잡성 때문에 거부되었음. 대신 상속된 환경 검사가 강화됨.
     * run0에는 로깅, 전달되는 환경변수, 시그널 처리, sudoedit 대체 방안 등에 대한 의문점들이 있음.
     * run0 외에도 Rust로 작성된 메모리 안전하고 버그가 적은 sudo 구현체가 있음.
     * 최근에는 한 물리 머신에 한 사용자만 있는 경우가 많아 유닉스 권한 시스템을 간소화할 필요가 있음.
     * 권한 상승 시 터미널 배경색을 붉게 변경하는 것은 중요한 부분이 아님.
"
"https://news.hada.io/topic?id=14513","JSR은 또 다른 패키지 관리자가 아닌 새로운 도구입니다","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    JSR은 또 다른 패키지 관리자가 아닌 새로운 도구입니다

JSR - 자바스크립트 패키지 공유를 위한 새로운 레지스트리

     * 지난 몇 년 동안 yarn이나 pnpm 같은 새로운 패키지 매니저가 등장하며 패키지 다운로드 방식을 개선해 왔음
     * 하지만 자바스크립트 생태계의 핵심인 npm 패키지 레지스트리는 거의 진화하지 않았음
          + 마지막 주목할 만한 업데이트는 수년 전에 추가된 ""files"" 탭이었음
     * 활발히 진화하는 것으로 알려진 자바스크립트 언어가 역설적이게도 시대에 뒤떨어진 배포 모델에 발목 잡혀 있는 것처럼 보임

자바스크립트 모듈 시스템의 문제점

     * Node를 만들 당시에는 자바스크립트용 표준 모듈 시스템이 없었기에, npm 레지스트리와 Node는 근본적인 결함이 있는 CommonJS(require) 시스템을 기본으로 채택했음
          + 이는 브라우저에서는 작동하지 않는 시스템이었음
     * 거의 10년 전인 2015년에 언어 자체적으로 ES 모듈(import) 문법을 채택함
     * 오늘날 대부분의 자바스크립트는 ES 모듈을 사용해 작성되지만, 이러한 모듈을 배포하는 경로는 여전히 복잡함
          + 특히 TypeScript가 관련된 경우 더욱 그러함
     * 이러한 생태계의 명백한 격차로 인해 JSR이 탄생하게 됨
          + JSR은 또 다른 패키지 매니저가 아니라 서버 사이드 런타임, 브라우저, 다양한 도구에서 자바스크립트와 타입스크립트를 공유하는 방식을 혁신하기 위해 설계된 변혁적인 레지스트리임

JSR의 특징과 이점

     * JSR은 오랫동안 개발자들을 괴롭혔던 복잡성을 간소화함으로써 코드 배포 프로세스를 근본적으로 개선함
     * ESM 전용이고 TypeScript 우선인 JSR은 package.json 설정과 미궁 같은 tsconfig 컴파일러 옵션의 불편한 조정을 제거함
     * 패키지 스코어링 시스템을 통해 JSR은 코드 배포의 모범 사례를 장려함
          + Dart 커뮤니티의 pub.dev와 유사하게, 내보내는 각 심볼에 대한 포괄적인 JSDoc 문서를 포함하는 패키지에 더 높은 점수를 부여함
     * Go나 Rust 같은 다른 최신 프로그래밍 생태계에서 볼 수 있듯이, JSR은 기본적으로 자동 문서 생성 기능을 제공함

npm과의 관계

     * JSR은 레지스트리이지, npm 레지스트리용 또 다른 클라이언트가 아님
          + 하지만 이는 npm의 모든 것을 포기하거나 분리된 자바스크립트 모듈 생태계로 전환해야 한다는 의미는 아님
     * JSR은 npm 레지스트리를 보완하도록 설계되었지 npm을 대체하려는 것이 아님
          + JSR 패키지는 npm 패키지에 의존할 수 있음 (예: 이 패키지 참조)
     * 또한 JSR 패키지는 기존의 npm 중심 소프트웨어에서 사용될 수 있음
          + JSR 자체가 npm 호환 tarball을 배포하는 npm 레지스트리(npm.jsr.io에서 접근 가능)로 작동하기 때문
          + 이를 통해 JSR 패키지를 npm, yarn 또는 pnpm을 사용하는 모든 소프트웨어에 포함하고 프라이빗 레지스트리와 통합할 수 있음
     * JSR이 배포하는 npm tarball은 최적화되어 있음

보안 중시

     * Deno에서는 자바스크립트 개발에서 보안을 최우선 과제로 삼음
     * 어떤 레지스트리도 게시된 모든 코드를 포괄적으로 감시할 수는 없지만, JSR은 발행자에 대한 투명성을 제공하고 발행 프로세스를 보호함
     * GitHub Actions와 OIDC 토큰을 통합함으로써 JSR은 소프트웨어 아티팩트를 위한 공급망 수준을 사용하여 고급의 검증 가능한 출처 증명을 생성하고 이를 Sigstore에 저장함
          + 이는 코드의 진위를 보장할 뿐만 아니라 개발자가 구현하는 내용에 대한 신뢰와 책임을 확립함

자바스크립트 개발의 중심지

     * 자바스크립트는 많은 프로그래머의 공통 언어로 보편적이고 접근성이 뛰어남
     * 이 언어는 개발자들이 불필요한 복잡성 없이 작업물을 공유할 수 있는 중앙 허브, 즉 타운스퀘어가 필요함
     * 우리는 자바스크립트가 앞으로 많은 세월 동안 소프트웨어 개발의 중심이 될 것이라 믿으며, JSR은 이러한 지속적인 연관성을 지원하는 것을 목표로 함
     * JSR은 단순히 생태계의 또 다른 도구가 아니라 우리가 자바스크립트와 타입스크립트 배포에 대해 생각하는 방식의 근본적인 변화를 나타냄

   jsr은 npm에서 다운받을 수 있었던 것 같은딩,, ㅋㅋㅋ

   망해라 php

   JS글에서 왜 PHP을??
   PHP 플젝 하고 있는 입장에서 맘이 쓰립니다.
"
"https://news.hada.io/topic?id=14541","PEP 686 - UTF-8 모드의 기본 설정화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       PEP 686 - UTF-8 모드의 기본 설정화

PEP 686 - Python 3.15부터 UTF-8 모드를 기본값으로 설정

     * UTF-8이 사실상 표준 텍스트 인코딩이 되어감
          + Python 소스 파일의 기본 인코딩은 UTF-8
          + JSON, TOML, YAML은 UTF-8 사용
          + Visual Studio Code, Windows 메모장 등 대부분의 텍스트 편집기는 기본적으로 UTF-8 사용
          + 대부분의 웹사이트와 인터넷 상의 텍스트 데이터는 UTF-8 사용
          + Node.js, Go, Rust, Java 등 많은 다른 인기 프로그래밍 언어도 기본적으로 UTF-8 사용
     * 기본 인코딩을 UTF-8로 변경하면 Python이 다른 언어와 상호 운용하기가 더 쉬워짐
     * 많은 Unix 사용 Python 개발자들은 기본 인코딩이 플랫폼에 따라 다르다는 사실을 잊어버림
          + UTF-8로 인코딩된 텍스트 파일(JSON, TOML, Markdown, Python 소스 파일 등)을 읽을 때 encoding=""utf-8""을 지정하지 않음
          + 일관되지 않은 기본 인코딩으로 인해 많은 버그가 발생함

PEP 686의 주요 변경 사항

     * Python 3.15부터 UTF-8 모드가 기본적으로 활성화됨
          + 사용자는 여전히 PYTHONUTF8=0 또는 -X utf8=0을 설정하여 UTF-8 모드를 비활성화할 수 있음
     * locale.getencoding() 추가
          + UTF-8 모드에 관계없이 로케일 인코딩을 얻기 위한 API
          + warn_default_encoding 옵션이 지정되면 locale.getpreferredencoding()은 open()과 마찬가지로 EncodingWarning을 발생시킴 (PEP 597 참조)
     * encoding=""locale"" 옵션 수정
          + TextIOWrapper는 encoding=""locale""이 지정된 경우 UTF-8 모드에서도 로케일 인코딩을 사용해야 함

하위 호환성

     * 대부분의 Unix 시스템은 UTF-8 로케일을 사용하고 Python은 로케일이 C 또는 POSIX일 때 UTF-8 모드를 활성화하므로 이 변경은 주로 Windows 사용자에게 영향을 줌
     * Python 프로그램이 기본 인코딩에 의존하는 경우 이 변경으로 인해 UnicodeError, 문자화け 또는 조용한 데이터 손상이 발생할 수 있음
     * 하위 호환성 문제를 해결하기 위한 지침:
         1. UTF-8 모드를 비활성화
         2. EncodingWarning (PEP 597)을 사용하여 UTF-8 모드가 영향을 미치는 모든 위치 찾기
               o encoding 옵션이 생략된 경우 encoding=""utf-8"" 또는 encoding=""locale"" 사용 고려
               o locale.getpreferredencoding()이 사용되는 경우 ""utf-8"" 또는 locale.getencoding() 사용 고려
         3. UTF-8 모드로 애플리케이션 테스트

GN⁺의 의견

     * 이 PEP은 Python의 기본 인코딩을 UTF-8로 통일하여 다른 언어 및 시스템과의 상호 운용성을 높이는 것을 목표로 함. 이는 Python이 글로벌 개발 환경에서 더욱 원활하게 사용될 수 있도록 도와줄 것임
     * 그러나 이러한 변경은 기존 Python 프로그램의 하위 호환성에 영향을 줄 수 있음. 특히 Windows 환경에서 실행되는 프로그램의 경우 주의가 필요함
     * 개발자들은 EncodingWarning을 활용하여 영향받는 부분을 식별하고, encoding 옵션을 명시적으로 지정하는 등의 방법으로 대응해야 함
     * 장기적으로는 이 변경이 Python 생태계에 긍정적인 영향을 미칠 것으로 예상됨. 그러나 단기적으로는 일부 프로젝트에서 마이그레이션 비용이 발생할 수 있음
     * 개발자들은 Python 3.15로의 업그레이드를 계획할 때 이 변경 사항을 고려해야 하며, 필요한 경우 하위 호환성을 위한 적절한 조치를 취해야 함

        Hacker News 의견

     * Python의 기본 텍스트 파일 인코딩이 플랫폼에 따라 다른 것은 오랫동안 문제였음
     * 파일 시스템 인코딩 문제는 별개이며, 이번 변경에서는 다루지 않음
     * 시스템 기본값에 의존하는 것은 좋지 않음. 가정과 달라질 수 있기 때문
     * 과거 우분투와 init.d 스크립트에서 문제가 있었음. 루트로 실행되는 Java 실행 스크립트가 일반 사용자와 다른 인코딩을 사용하여 문제 발생
     * 요즘은 덜 문제지만, OS에 이를 맡기는 것은 피해야 함. UTF-8 외 인코딩 사용은 의도치 않은 경우일 가능성이 높음
     * 명시적으로 지정하지 않고 OS 설정에 의존하는 것은 좋지 않음
     * 이번 변경은 좋은 방향. 깨지는 코드는 간단히 수정하는 게 나음
     * 내용 손상 버그의 가능성이 있는 상태로 두는 것보다 낫다고 봄

     최근 수십 년 동안 점점 더 사실이 되어 가는 경험칙: ""charset"" 설정이 UTF-8이 아니라면 잘못된 것임

     * Python 2는 charset에 구애받지 않아 항상 잘 동작했지만, Python 3의 개선은 개선 그 이상이었음
     * Python 3 스크립트와 Python 2 스크립트를 구분하는 방법:
          + ""utf-8"" 문자열이 있으면 Python 3
          + C.UTF-8 로케일에서만 동작하면 Python 3
     * 이번 변경은 환영할 만한 것이며, Python 3를 ""개선""할 것으로 보임
     * Python 3부터 기본값이었다고 생각했음

     Node.js, Go, Rust, Java를 포함한 많은 인기 언어들이 기본적으로 UTF-8을 사용함

     * Java가 UTF-16에서 UTF-8로 옮겨간 것은 몰랐음
     * CPython의 내부 인코딩이 UTF-8인지는 모르겠음
     * Python 문자열은 인덱싱이 가능하지만 임의 접근은 드물기에 필요할 때 지연 인덱싱하는 게 좋을 듯
     * 한 칸씩 앞뒤로 이동만 하면 인덱스가 필요 없음
     * 따라서 내부적으로 UTF-8 표현이 가능할 것으로 보임
     * 왜 utf-8-sig가 아닌지? BOM을 선택적으로 처리해주는데 유용함
     * UTF-8과 관련하여, 리눅스 프레임버퍼는 오래전부터 제대로 된 UTF-8 지원이 있었어야 함
     * GNU Hurd는 2007년경부터 UTF-8을 지원하는 더 나은 '터미널 콘솔'을 가지고 있었음
     * 2024년인 지금에야 이런 변화가 오다니
     * 좋은 변화. 이제 JS만 UTF-8로 전환하면 되는데, 1995년에 쓰인 코드와 호환되어야 하기에 개선이 어려움

     많은 유닉스 Python 개발자들이 기본 인코딩이 플랫폼마다 다르다는 걸 잊고, UTF-8 텍스트 파일을 읽을 때 encoding=""utf-8""을 명시하지 않음

     * ""잊는다""라기보다는 제대로 인지하지 못하는 것 같음
     * 명시적으로 요청하지 않는 한 Python이 모든 곳에서 UTF-8만 사용할 거라 생각했음
"
"https://news.hada.io/topic?id=14593","다중 토큰 예측은 대규모 언어 모델의 샘플 효율성과 성능을 향상시킵니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                다중 토큰 예측은 대규모 언어 모델의 샘플 효율성과 성능을 향상시킵니다.

   • 본 논문은 다중 토큰 예측이라는 대형 언어 모델(LLM)에 대한 새로운 훈련 방법을 제안하며, 이는 모델을 훈련하여 여러 미래 토큰을 동시에 예측하는 것을 포함한다. 저자들은 이 접근법이 더 높은 표본 효율성으로 이어지며, 이는 모델이 주어진 양의 훈련 데이터에서 더 효과적으로 학습할 수 있음을 의미한다고 주장한다.

   • 그들은 코드 생성 및 자연어 처리를 포함한 다양한 다운스트림 작업에 대한 방법의 효과를 보여주고 다중 토큰 예측이 강력한 기준선을 몇 퍼센트 포인트 지속적으로 능가한다는 것을 보여준다. 특히, 그들의 13B 매개변수 모델은 HumanEval 및 MBPP와 같은 도전적인 코딩 벤치마크에서 상당한 개선을 달성한다.

   • 향상된 성능 외에도 다중 토큰 예측은 계산 이점도 제공합니다. 4토큰 예측으로 훈련된 모델은 배치 크기가 큰 경우에도 추론 속도가 최대 3배 빨라 실제 응용 프로그램에 더 효율적이다.
"
"https://news.hada.io/topic?id=14581","기술 문서 번역용 GPT 프롬프트 작성 방법","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        기술 문서 번역용 GPT 프롬프트 작성 방법

     * GitLab 공식 기술 문서를 영어에서 우리말로 번역하기 위해 번역용 GPT 프롬프트를 작성한 방법.
     * 효과적인 프롬프트 작성 요건:
          + 프롬프트 작성에 앞서 여러 강의와 매체 자료에서 배운 내용.
          + Examples:
               o 사용자가 기대하는 결과 예시 작성.
               o GPT는 간단한 예시만 봐도 복잡한 작업을 일관성 있게 처리.
          + Direction:
               o 작업 순서나 규칙 상세히 작성.
               o 절차가 있는 작업을 ‘1번’, ‘2번’으로 번호 매겨 지시하면 GPT가 잘 수행.
          + Parameters:
               o 생성형 AI에 여러 파라미터 설정 가능.
               o 파라미터는 ‘같은 질문에 다양하게 답변할지(temperature)’, ‘얼마만큼 확률이 높은 답변을 제시할지(top-p)’ 등임.
          + Format:
               o 답변 형식 지정.
               o Markdown, JSON, CSV 형식을 원하면 그렇게 만들어달라고 요구할 것.
          + Chaining:
               o 프롬프트나 생성형 AI 연결해 사용.
               o 예를 들어, ChatGPT에 이미지 생성용 프롬프트를 요청, 이미지는 Midjourney에서 얻는 방식.
               o 각 영역에 특화된 AI를 엮어서 사용.
     * ‘번역용 GPT’ 프롬프트 작성 방법:
          + 위 요건에 따라 GPTs에서 ‘번역용 GPT’ 프롬프트를 작성.
          + 원하는 방식대로 동작하는, 나만의 GPT 만들려면 Instructions, Responses, Examples를 프롬프트에 포함.
          + 프롬프트에 GPT 역할, 목표, 답변 요건, 답변 예시 등 제시.
          + Instructions:
               o GPT 역할과 궁극적 목표 작성.
               o 맞춤형 AI를 설계할 때 ‘AI에 역할을 부여(roleplay)하는 행위가 중요하다’는 연구 결과 많음.
               o 번역가, 선생님, 의사 등 원하는 답변자의 직업, 정체성을 AI에 부여.
               o 번역용 GPT에는 AI 역할을 ’영한 번역가’, 궁극적 목표를 ’텍스트의 한국어 번역’으로 설정.
          + Responses:
               o 답변 요건 기재.
               o AI가 흔히 말하는 “알겠습니다”나 “~하겠습니다”와 같은 사족 없애려 함.
               o 번역용 GPT에는 ‘추가 설명이나 맥락 없이 간결하게 답변만 해달라’고 요청 넣음.
               o ‘번역 작업에만 집중해 모든 상호작용에서 정확성과 간결함을 유지해달라’고 주문.
          + Examples:
               o AI가 이해하도록 짧은 답변을 예시로 보여줌.
               o 여기서 ‘질문과 답변은 ---로 구분된다’고 명확히 알려줘야 함.
               o 그렇지 않으면 AI는 ‘어디까지가 예시 질문이고, 어디까지가 예시 답변인지’ 파악 못하고, 엉뚱한 답변을 내놓을 수 있음.
               o 번역용 GPT Examples에 ’Q: apple A: 사과 , Q: Hello, who are you? A: 안녕, 넌 누구야?’를 각각 작성.
     * 특수 문법 GPT 적용 방법:
          + GitLab 공식 기술 문서의 특수한 마크다운 문법도 프롬프트로 입력.
          + 그러려면 개발자가 ‘GitLab 기술 문서의 특수한 마크다운 문법이 뭔지’ 먼저 파악해야 함.
          + GitLab 기술 문서의 프로젝트를 분석해 빌드 방법과 특수한 마크다운 문법 찾음.
               o GitLab은 Ruby 기반 정적 사이트 생성기 Nanoc을 사용해 기술 문서 사이트를 서비스함.
               o 이는 문서를 마크다운 문법에 맞춰 작성하고, HTML로 렌더링하는 구조.
          + 단순한 마크다운 구조라면 앞서 언급한 프롬프트를 조금만 변형하면 됨.
               o GPT는 일반적인 마크다운 문법을 이미 알고 있고, 문법을 깨뜨리지 않고 번역할 수 있음.
          + GitLab은 일반적인 마크다운 문법으로 사용할 수 없는 탭이나 배지를 기술 문서에 적용.
               o GPT는 ‘GitLab 기술 문서의 특수한 마크다운 문법이 뭔지’ 모름.
          + 이에 번역용 GPT를 설계할 때 이 내용을 프롬프트에 상세히 작성.
               o GitLab 기술 문서의 특수한 마크다운 문법을 번역하는 구체적인 방법과 예제, 제약 조건을 프롬프트에 작성.

   명령, 응답, 예시
"
"https://news.hada.io/topic?id=14503","새로운 음악 발견의 한계","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             새로운 음악 발견의 한계

     * 사람들은 평균적으로 24세에 새로운 음악을 가장 많이 발견하고, 31세부터 음악 취향이 정체되기 시작함
          + Deezer의 설문조사에 따르면 새 음악 발견은 24세에 정점을 찍고, 30대 초반부터 크게 감소함
          + Spotify 데이터 분석에서도 33세가 대중적인 음악에서 벗어나기 시작하는 전환점으로 확인됨
     * 음악 취향 정체의 주요 원인으로는 과도한 선택의 폭, 요구가 많은 직장, 어린 자녀 돌봄 등 일상의 제약이 꼽힘
          + 특히 무한한 콘텐츠로 넘쳐나는 스트리밍 환경이 선택의 역설을 불러일으키는 것으로 보임
     * 하지만 근본적으로는 음악에 대한 관계와 태도가 연령에 따라 drastically 변화하기 때문
          + 청소년기에 비해 성인기에는 음악의 중요도가 낮아지고, 음악을 듣는 시간과 맥락이 크게 줄어듦
          + 음악 선호도는 심리사회적 발달 추세와 밀접한 관련이 있음
     * 음악 취향 정체는 predetermined truth처럼 보이지만 확실한 것은 아님. 시간과 노력을 들이면 새 음악 발견이 가능함
     * 음악 탐색과 기존 음악 고수 사이의 딜레마(explore-exploit tradeoff)와 관련해 흥미로운 통계가 있음
          + 37% rule에 따르면 탐색에 전체 시간의 37%를 쓰고 이후엔 선호하는 것을 고수하는 것이 최적
          + 미국인 평균 수명 80세의 37%는 30세로, 음악 취향이 정체되기 시작하는 연령과 우연히 일치함
     * 결국 음악 취향 정체는 버그가 아니라 feature일 수 있음. 끊임없이 새 음악을 찾느라 불만족스러울 필요는 없을 듯

GN⁺의 의견

     * 음악 취향의 정체를 나쁘게만 볼 필요는 없어 보임. 오히려 그동안 충분히 음악을 탐색했기에 선호가 확고해진 것일 수 있음
     * 다만 너무 일찍 정체되는 것 같다는 생각도 듬. 새로운 음악을 찾으려는 노력을 게을리 하지 않는 것이 중요할 듯
     * 개인의 성향에 따라 적정 균형점은 다를 수 있음. 단순히 나이로 정해지기보다는 음악이 삶에서 차지하는 비중에 따라 달라질 것
     * 음악 이외에도 책, 영화 등 다양한 문화 콘텐츠 소비에서 비슷한 정체 현상이 나타날 것 같음. 이에 대한 추가 연구도 흥미로울 듯
     * 한편으로 시대에 뒤떨어진다는 강박에서 벗어나, 자신이 좋아하는 음악을 당당히 즐기는 태도도 필요해 보임

   저도 어제 예전에 듣던 노래들 플레이리스트 만들었는데.. ㅡ.ㅡ;

        Hacker News 의견

     * 나이가 들어도 새로운 것을 좋아하는 능력이 정체되는 것이 아니라, 단지 새로운 것에 노출되는 것을 멈추고 알고리즘이 좋아하는 것에만 집중하는 경향이 있음
     * 의도적으로 새로운 것에 노출되려고 노력하면 나이에 상관없이 좋아하는 것을 발견할 수 있음. 예를 들어 친구와 함께 새로운 장르의 콘서트에 가면 전체 디스코그래피를 구매하게 되는 경우가 많음
     * 비싼 경험의 경우 비용 대비 보상이 크지 않아 안전한 선택을 하는 경향이 있지만, 음악의 경우 스트리밍으로 인해 거의 모든 것을 탐색할 수 있게 됨. 하지만 흥미로운 경로를 따라가는 음악 검색이 필요함
     * Z세대와 밀레니얼 세대는 자신들 세대의 음악에 대한 선호도가 훨씬 작게 나타남. 1980년대 음악은 여전히 모든 세대에서 인기가 있음
     * 음악이 기업화, 통합화, 컴퓨터화되면서 실제로 악화되고 있을 가능성이 있음. 할리우드에서도 속편, 프리퀄, 리메이크, 리부트, 각색 작품만 넘쳐나고 있음
     * 30-50년대 흑인 음악가들의 스윙 스타일 음악을 좋아하는데, 서비스들이 그 스타일을 제대로 재생해주지 않고 백인 음악가들의 음악으로 전환해버리는 문제가 있음
     * 음악의 새로움이 중요하다면 이런 일은 일어나지 않을 것임. 60대인 아버지도 여전히 새로운 음악을 적극적으로 찾아 듣고 있음
     * 어릴 때 클래식 록을 들었지만 지금은 더 이상 견딜 수 없게 됨. 20대에는 클래식과 재즈를, 90년대에는 그런지를, 2000년대에는 트랜스를, 그 후에는 앰비언트, 테크노, IDM 등 다양한 장르를 즐기게 됨
     * outlier로서 음악을 찾는 전략으로는 공간적 근접성(함께 공연하는 아티스트), 출판 근접성(같은 레이블), 아티스트 근접성(아티스트가 기여한 다른 프로젝트), 팬 근접성(팬이 좋아하는 다른 아티스트) 등이 있음
     * 30대 중반 이상의 사람들이 현재 유행하는 음악이 형편없다고 생각하는 이유는 과거 음악의 아주 작은 부분만 듣기 때문임. 당시의 빌보드 차트나 라디오 방송을 들으면 지금과 비슷할 것임
"
"https://news.hada.io/topic?id=14572","미국 연방통신위원회(FCC), 위치 데이터 공유로 최대 이동통신사에 과징금 부과","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              미국 연방통신위원회(FCC), 위치 데이터 공유로 최대 이동통신사에 과징금 부과

     * FCC는 AT&T, Sprint, T-Mobile, Verizon에게 고객 동의 없이 위치 정보를 제3자에게 불법적으로 공유한 것에 대해 총 2억 달러에 가까운 벌금을 부과함
          + Sprint와 T-Mobile은 조사가 시작된 이후 합병되었으며, 각각 1,200만 달러와 8,000만 달러의 벌금을 직면함
          + AT&T는 5,700만 달러 이상, Verizon은 4,700만 달러 가량의 벌금이 부과됨

고객 데이터 보호 의무 위반

     * FCC 집행국 조사 결과, 각 통신사는 고객의 위치 정보에 대한 액세스를 ""집계자""에게 판매했고, 이들은 다시 제3자 위치 기반 서비스 제공업체에 액세스를 재판매함
     * 각 통신사는 고객 동의를 얻을 의무를 위치 정보의 하류 수신자에게 전가하려 했으며, 이는 대부분의 경우 유효한 고객 동의를 얻지 않았음을 의미함
     * 이러한 초기 실패는 안전장치가 효과가 없다는 것을 인식한 후에도 통신사가 무단 액세스로부터 보호하기 위한 합리적인 조치를 취하지 않고 계속해서 위치 정보에 대한 액세스를 판매했을 때 더욱 악화됨

통신법 222조에 따른 고객 정보 보호 의무

     * 통신법 222조를 포함한 법률에 따라 통신사는 위치 정보를 포함한 특정 고객 정보를 보호하기 위해 합리적인 조치를 취해야 함
     * 또한 통신사는 고객 정보의 기밀성을 유지하고, 해당 정보를 사용, 공개 또는 액세스를 허용하기 전에 적극적이고 명시적인 고객 동의를 얻어야 함
     * 이러한 의무는 통신사가 제3자와 고객 정보를 공유할 때도 동일하게 적용됨

FCC 집행국장 Loyaan A. Egal의 발언

     * ""위치 정보와 같은 민감한 개인 데이터의 보호와 사용은 신성불가침한 것""
     * ""잘못된 사람의 손에 넘어가거나 악의적인 목적으로 사용되면 우리 모두를 위험에 빠뜨림""
     * ""해외 적대세력과 사이버 범죄자들은 이 정보를 손에 넣는 것을 우선시 해왔기 때문에 서비스 제공업체가 고객 위치 데이터를 보호하고 그 사용에 대한 유효한 동의를 얻기 위한 합리적인 보호 장치를 갖추도록 하는 것이 집행국의 최우선 과제""

2020년 2월 발행된 Notices of Apparent Liability (NAL) 최종 확정

     * 오늘 발표된 Forfeiture Orders는 2020년 2월 이들 통신사에 발행된 Forfeiture Orders를 최종 확정함
     * AT&T와 Sprint의 벌금 금액은 NAL 단계 이후 변경되지 않았음
     * T-Mobile과 Verizon의 벌금은 NAL에 대한 당사자의 제출물을 추가 검토한 후 감액되었음
     * 법률은 NAL 발행 후 특정 위반에 대한 벌금 금액이 상향 조정되는 것을 허용하지 않음

GN⁺의 의견

     * 통신사들이 고객의 민감한 위치정보를 무단으로 유출하고 이를 막기 위한 안전장치도 제대로 마련하지 않은 것은 매우 심각한 문제라고 봄. 특히 해외 적대세력과 사이버 범죄자들이 이런 정보를 노리고 있다는 점에서 더욱 그러함
     * 다만 이번 조치가 너무 늦은 감이 있음. 이미 2020년에 벌금 부과가 예고되었던 것으로 보이는데 4년이나 지난 시점에서야 최종 결정이 났다는 것은 문제가 있어 보임. 고객 정보 유출에 대한 신속하고 엄중한 조치가 필요해 보임
     * 한편 벌금 금액이 이 정도 규모의 통신사들에게는 큰 타격이 되지 않을 수 있음. 고객 정보 유출 재발 방지를 위해서는 더 강력한 제재 수단이 필요할 수 있음
     * 국내 통신사들은 이번 사례를 타산지석으로 삼아, 고객 정보 보호를 위한 안전장치를 더욱 강화하고 관련 법규를 철저히 준수하려는 노력이 필요해 보임. 특히 위치정보와 같은 민감한 정보의 경우 더욱 신중을 기해야 할 것임

        Hacker News 의견

   Here is a summary of the key points from the Hacker News comments, formatted as a bullet list using Markdown:
     * The core issue is transparency:
          + Users want to see who companies have sold or given their information to and what limitations that sale has.
          + If a company collects user data and allows another entity access, they should inform users and make it easy to block.
          + Most abuse of personal data would go away if people knew it was happening.
     * The $200M fine is insignificant for these carriers:
          + It would only take the combined daily revenue of T-Mobile, AT&T, and Verizon approximately 9 hours to generate $196 million in revenue.
          + Nothing will likely change beyond adding a footnote to the privacy policy.
     * Concerns about the effectiveness of the FCC's action:
          + Without requiring a separate opt-out, carriers could just add ""sharing location data"" to the EULA/privacy policy and continue with ""consent"".
          + This seems like a temporary roadblock that changes nothing in the long run.
     * Positive reactions to the FCC's action:
          + Some are happy to see the FCC taking action and encourage them to keep it up.
     * Questions about law enforcement bypassing warrants:
          + There are concerns that US law enforcement may purchase this type of commercial data to get around having to obtain a warrant.
     * Related startup offering mobile service without personal data:
          + Cape raised $61M from A16Z and others for a mobile service that doesn't use personal data.
     * Comparison to the AT&T/NSA surveillance scandal:
          + Some question if anyone was fined over AT&T letting the NSA tap into all decrypted network data, which seems more egregious.
     * Questions about the impact on location data aggregators:
          + Some are curious if anyone using vendors like Zumigo, LocationSmart, or Microbilt has noticed weaker data signals/availability related to this.
          + There are expectations that tracking sources will still be available but with new ""more transparent"" disclosures.
     * Questioning if Google Fi sells user location data:
          + One commenter is curious if Google's own mobile service, Google Fi, sells users' real-time location data.
"
"https://news.hada.io/topic?id=14607","TypeSpec: API 중심 개발을 위한 새로운 언어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     TypeSpec: API 중심 개발을 위한 새로운 언어

     * TypeSpec은 API 중심 개발을 위한 새로운 언어로, API 개발자, 설계자, 매니저의 요구사항을 충족시키기 위해 설계됨
          + 일관되게 높은 품질의 API와 관련 경험을 제공하는 것이 점점 더 복잡해지고 중요해지는 환경에서 개발됨
          + TypeSpec은 단순한 언어 이상이며, 추상화를 가능하게 하고 코드 재사용을 장려하며 신속한 개발을 위해 최신 도구를 활용하는 플랫폼임

TypeSpec의 주요 특징

     * 상호 운용성
          + TypeSpec은 단순한 API 설명 언어가 아니라 API를 정의하고 다양한 프로토콜, 클라이언트, 서버, 문서 등을 동시에 출력할 수 있는 고수준 정의 언어임
          + 업계 표준 API 정의 언어와 상호 운용 가능하여 다양한 선택 사항 간의 격차를 해소함
     * 생산성
          + TypeSpec은 데이터와 API 정의 프로세스를 즐겁고 생산적으로 만드는 우수한 개발자 경험을 제공함
          + 언어는 간결하고 최소한의 입력으로 복잡한 데이터와 API 모양을 정의할 수 있음
     * API 패턴
          + TypeSpec은 일반적인 데이터 유형, API 패턴 및 지침을 팀 또는 에코시스템 전체에서 공유할 수 있는 고수준의 재사용 가능한 구성 요소로 캡슐화하여 API 품질을 향상시킴
     * 익숙함
          + TypeSpec은 TypeScript와 C#에서 영감을 받아 배우기 쉽고 많은 개발자에게 친숙하게 느껴짐
     * 확장성
          + TypeSpec은 사용자 정의 데코레이터 어휘 및 유형 템플릿으로 확장할 수 있어 비즈니스 또는 애플리케이션 로직 도메인에서 API를 모델링할 수 있음
     * 생태계
          + TypeSpec을 사용하면 공통 유형, 언어 확장, 린터 및 에미터를 패키지로 묶어 조직 내부 또는 에코시스템 전반에 걸쳐 NPM에 배포할 수 있음

커뮤니티와 협업

     * Microsoft에서 사용 중
          + Microsoft에서는 TypeSpec을 사용하여 API 개발 프로세스를 혁신하고 있음
          + 많은 Azure 서비스에서 TypeSpec을 채택하고 있으며, 그 수는 매일 증가하고 있음
          + Microsoft Graph 팀은 TypeSpec의 잠재력을 활용하여 생산성을 높이고 맞춤 설정을 단순화함
     * 참여 요청
          + TypeSpec은 단순한 언어 이상이며 커뮤니티임
          + 모든 배경을 가진 개발자가 공개 베타에 참여하여 TypeSpec의 힘을 직접 경험할 수 있도록 초대함

GN⁺의 의견

     * TypeSpec은 추상화 레벨이 높은 API 정의 언어로, API 개발 방식을 혁신적으로 개선할 수 있을 것으로 보임
          + ""API First"" 접근 방식을 지원하여 개발 효율성과 최종 제품 품질 향상에 도움이 될 것임
          + 다양한 프로토콜 지원, 확장성, 강력한 생태계 등으로 폭넓은 개발 시나리오에 적용 가능할 것으로 예상됨
     * 하지만 새로운 언어 도입에는 항상 학습 비용이 발생하므로, 팀 내 도입 시 충분한 교육이 선행되어야 할 것임
          + TypeScript와 C#의 문법을 차용해 학습 곡선을 낮추려 노력한 점은 긍정적임
     * 유사한 역할을 하는 기존 API 정의 언어들(Swagger, RAML, API Blueprint 등)과의 차별화 포인트를 좀 더 명확히 할 필요가 있어 보임
          + 기존 언어의 한계를 어떻게 극복하는지, 마이그레이션은 용이한지 등
     * Microsoft 내부에서 먼저 사용하며 개선해 나가는 독푸딩 방식은 신뢰감을 줌
          + 하지만 아직 오픈소스 프로젝트로 공개된 지 얼마 되지 않았으므로, 향후 몇 년간 지속적인 발전과 커뮤니티 지원이 관건이 될 것으로 보임
     * API 설계의 표준화와 재사용성 향상이라는 방향성은 올바르나, 너무 많은 것을 한꺼번에 해결하려 한다는 인상도 있음
          + 우선순위를 두고 단계적으로 기능을 강화해 나가는 것이 좋겠음

        Hacker News 의견

     * TypeScript를 이미 API 타이핑에 사용 중이라면, TypeScript에서 직접 JSON 스키마를 생성하는 ts-json-schema-generator가 대안이 될 수 있음
     * OpenAPI의 YAML에 비하면 어떤 것이든 좋아 보이겠지만, 그럼에도 OpenAPI는 최고의 발전 중 하나로 여겨짐
     * TypeScript가 스키마 언어로 돌파구를 마련하기를 기대해 왔는데, TypeSpec은 JavaScript를 제거하고 JSON을 위한 타이핑만 남긴 것처럼 보임
     * TypeSpec을 최신 API에 사용하면서 GraphQL과 유사하게 API를 설명하고 디자인 우선 방식으로 개발하는 도구를 찾았는데, OpenAPI 편집기들은 너무 투박하고 API 내 데이터 관계를 불명확하게 만든 반면 TypeSpec은 큰 도움이 되었음
     * Microsoft에서 만든 것이므로 GraphQL에 대한 그들의 대답이 될 것으로 추정되며, 내부적으로 사용된다면 오픈소스 컨소시엄이 만드는 것에 비해 도구가 괜찮을 수 있음
     * WSDL의 TypeScript 버전처럼 보이는데, WSDL보다 오래 지속될지 모르겠음
     * 주요 의문점인 지원되는 출력 언어를 찾지 못했고, OpenAPI를 내보내고 형편없는 생성기를 사용하는 것 외에는 방법이 없어 보임
     * TypeSpec 파일을 TypeScript로 가져와서 자동으로 타입을 얻을 수 있다면 좋겠지만, 코드 생성은 성가시고 오류가 발생하기 쉬움
     * Smithy의 경쟁자/대안으로 보이며, TypeSpec 팀의 누군가가 여기 있다면 어떻게 비교되는지 의견을 듣고 싶음
     * YAML을 원하는 도구 체인으로 변환될 수 있을지 궁금함
     * 25년 전 CORBA IDL이 제공했던 것과 같은 스키마와 다중 언어를 위한 스텁 생성을 제공하는 고수준 IDL이 있으면 기쁠 것임
"
"https://news.hada.io/topic?id=14567","웹망원경, 전례 없이 상세한 말머리성운 포착","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        웹망원경, 전례 없이 상세한 말머리성운 포착

Webb 망원경이 전례 없이 상세하게 촬영한 말머리성운

     * NASA/ESA/CSA James Webb 우주 망원경이 지금까지 말머리성운의 가장 선명한 적외선 이미지를 포착함
     * 이번 관측으로 상징적인 성운의 일부를 전혀 새로운 방식으로 보여주며, 전례 없는 공간 해상도로 복잡성을 포착함
     * Webb의 새로운 이미지는 오리온자리에 있는 하늘의 일부와 오리온 B 분자운의 서쪽을 보여줌
     * 약 1300광년 거리에 있는 말머리성운(바나드 33)은 먼지와 가스의 격동하는 파도에서 떠오름

말머리성운의 형성과 구조

     * 이 성운은 붕괴하는 성간 물질 구름에서 형성되었으며, 근처의 뜨거운 별에 의해 밝혀짐
     * 말머리성운을 둘러싼 가스 구름은 이미 흩어졌지만, 튀어나온 기둥은 침식되기 어려운 두꺼운 물질 덩어리로 구성됨
     * 천문학자들은 말머리성운이 해체되기까지 약 500만 년이 남았다고 추정함
     * Webb의 새로운 관측은 성운의 독특한 먼지와 가스 구조의 상단 가장자리에 초점을 맞춤

광자 지배 영역과 성간물질 연구

     * 말머리성운은 잘 알려진 광자 지배 영역(PDR)임
     * 이러한 영역에서는 젊고 거대한 별에서 나오는 자외선이 주로 중성이고 따뜻한 가스와 먼지 영역을 만듦
     * 이 자외선 복사는 이 영역의 가스 화학에 강한 영향을 미치며 가장 중요한 열원 역할을 함
     * PDR에서 방출되는 빛은 은하와 우주 전체에서 성간물질의 진화를 주도하는 물리적, 화학적 과정을 연구하는 독특한 도구를 제공함
     * 근접성과 거의 모서리 방향의 기하학적 구조 때문에 말머리성운은 PDR의 물리적 구조와 각 환경 내 가스 및 먼지의 화학적 특성 진화, 그리고 그 사이의 전이 영역을 연구하기에 이상적인 대상임

새로운 발견과 앞으로의 연구 계획

     * Webb의 MIRI와 NIRCam 기기 덕분에 국제 천문학자팀은 처음으로 말머리성운의 가장자리에 있는 소규모 구조를 밝혀냄
     * 또한 PDR 전면에 수직으로 뻗은 줄무늬 형태의 네트워크를 발견했으며, 여기에는 성운의 광증발 흐름에 동반된 먼지 입자와 이온화된 가스가 포함되어 있음
     * 이번 관측을 통해 천문학자들은 먼지 감쇠와 방출의 영향을 조사하고 성운의 다차원 형태를 더 잘 이해할 수 있게 됨
     * 다음으로 천문학자들은 성운에서 관찰된 물질의 물리적, 화학적 특성의 진화를 입증하기 위해 얻은 분광 데이터를 연구할 계획임

GN⁺의 의견

     * Webb 망원경은 적외선 영역에서 전례 없는 고해상도 이미지를 제공하여 천문학 연구에 큰 도움이 될 것으로 보임. 기존의 허블 망원경과 함께 사용하면 더욱 다양한 파장대의 정보를 얻을 수 있을 것임.
     * 성간물질의 진화와 별 형성 과정을 이해하는데 있어 PDR의 연구가 중요한 역할을 할 것으로 기대됨. 특히 먼지 입자와 이온화 가스의 상호작용에 대한 이해가 깊어질 것으로 보임.
     * 말머리성운은 대중들에게도 잘 알려진 천체이기에 Webb 망원경의 이런 고품질 이미지는 천문학 대중화에도 기여할 수 있을 것임. 천문학 연구 성과를 일반인들과 공유하는 것이 중요함.
     * 다만 Webb 망원경의 관측 시간이 제한적이므로, 말머리성운 이외에도 PDR 연구에 적합한 다른 성운들에 대한 관측도 체계적으로 수행될 필요가 있어 보임.

        Hacker News 의견

     * Webb 망원경의 Horsehead Nebula 이미지가 소비자용 8인치 뉴턴식 망원경으로 찍은 이미지보다 훨씬 인상적임
     * NIRCam 이미지가 가장 흥미로운 새 사진이 될 것 같지만, MIRI가 성운의 내부 구조를 얼마나 잘 보여주는지 놀라움
     * 최종 이미지의 디테일뿐 아니라, 그 뒤에 있는 측면 나선 은하들이 수십억 광년 떨어져 있다는 것이 정말 흥미로움
     * 우주의 크기와 시간에 대해 철학적으로 생각하게 되고, 지구가 얼마나 작고 우리의 일상적인 문제가 얼마나 insignificant한지 깨닫게 됨
     * 우주에 대한 우리의 지식이 크게 진전되지 않는다면 실망스러울 것임
     * 시편 19편의 다윗의 노래가 생각남. 수천 년이 지났지만, 우리는 여전히 창조의 아름다움과 깊이를 관찰하는 데 겨우 표면만 긁고 있음
     * 규모감을 느끼기 위해, Horsehead Nebula의 지름은 7광년으로 우리에서 프록시마 센타우리까지의 거리인 4광년보다 큼
     * 수백만 개의 다른 생명체가 존재할 가능성이 매우 높음
     * 줌인 영상은 정말 믿을 수 없을 정도로 대단함. 엔지니어링과 과학의 승리임
     * 이런 이미지를 보면 우주에 관심을 갖는 이유를 완전히 이해할 수 있음. 정말 놀라운 것임
     * 아름답지만 직접 방문할 수 없다는 것이 슬픔. 은하의 영광을 경험할 수 없다는 것이 아쉬움
"
"https://news.hada.io/topic?id=14493","바이든, TikTok 법안 서명으로 ByteDance의 지분 매각 절차 시작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               바이든, TikTok 법안 서명으로 ByteDance의 지분 매각 절차 시작

     * Biden이 TikTok을 금지하는 법안에 서명함으로써 ByteDance가 TikTok을 매각해야 하는 시간이 시작됨
          + 이 법안은 중국 기반 모회사 ByteDance가 9개월에서 1년 이내에 TikTok을 매각하지 않으면 미국에서 사실상 금지되는 것을 요구함
          + 이 법안은 하원에서 단독 법안으로 통과된 후 상원에서 표류할 것 같았지만, 정치적 책략으로 인해 Biden의 책상까지 무사히 도달함
          + 하원은 TikTok 법안을 미국 동맹국에 대한 해외 원조와 묶어 상원이 두 조치를 함께 고려하도록 사실상 강요함
          + 매각 기간이 길어진 것도 일부 의원들이 법안을 지지하는 데 도움이 된 것으로 보임
     * TikTok은 이 금지령에 법적으로 도전할 계획이라고 밝힘
          + TikTok 대변인 Alex Haurek은 성명을 통해 이 법을 법정에서 다툴 계획이라고 밝힘
          + 이는 결과적으로 법원이 해결을 보류하는 동안 시행을 지연시킬 수 있음
          + 중국이 어떻게 대응할 것이며, ByteDance가 TikTok과 사용자들을 계속 앱으로 유도하는 탐낼만한 알고리즘을 매각하도록 허용할 것인지도 여전히 의문임
     * TikTok CEO Shou Chew는 ""이는 금지""라며 일부 의원들의 주장에 반박함
          + 일부 의원들은 단지 이 플랫폼이 중국 소유권과 단절되기를 원한다고 주장했지만 TikTok CEO는 TikTok 금지는 곧 사용자들의 목소리 금지라고 주장함
          + 그는 ""우리는 이 위헌적인 금지에 계속 도전하면서, TikTok이 모든 계층의 미국인들이 안전하게 경험을 공유하고, 기쁨을 찾고, 영감을 받을 수 있는 공간으로 남을 수 있도록 계속 투자하고 혁신할 것""이라고 말함

GN⁺의 의견

     * 중국과 미국의 갈등이 고조되는 가운데 TikTok이 정치적 희생양이 된 측면이 있어 보임. 물론 중국 정부의 개입 가능성 때문에 합당한 우려도 있지만, 실제 그런 일이 있었다는 증거는 아직 불충분함
     * TikTok의 영향력이 급격히 커지면서 Meta 등 기존 빅테크 기업들이 로비를 통해 견제하려는 의도도 있어 보임. 이는 반독점 문제로 고심하는 기존 기업들에게는 호재일 수 있음
     * 하지만 TikTok이 매각된다고 해도 중국발 앱에 대한 불신은 쉽게 가라앉지 않을 것임. 이는 글로벌 IT 기업의 성장에 장애물이 될 수 있음
     * 만약 중국 정부가 보복 조치로 애플 등 미국 IT기업들의 중국 내 영업을 제한한다면 또 다른 무역분쟁으로 번질 수 있음. 양국간 디커플링이 심화되는 계기가 될 수 있음
     * 결국 이런 조치는 자국 IT기업 보호주의로 이어질 가능성이 높음. 글로벌 IT 생태계의 발전을 저해하고 소비자의 선택권을 제한할 수 있어 우려됨

        Hacker News 의견

     * WTO의 ""공중도덕"" 예외 조항으로 인해 중국이 미국 소셜 네트워크를 차단할 수 있음. 그러나 해당 예외 조항은 존재해서는 안 되며, 오직 무역 상호주의 원칙에 따라 차단해야 함.
     * ""차단(ban)""이라는 단어는 따옴표로 묶인 이유가 있음. 이 법은 TikTok 자체를 금지하는 것이 아니라 TikTok의 중국 소유주를 금지하는 것임. 결국 TikTok이 사라지기보다는 미국 소유주에게 매각될 가능성이 높음.
     * TikTok과 같은 것의 무역 금수 조치 측면에 대해 많은 사람들이 언급하지 않는 것이 놀라움. 미국 소셜 미디어는 중국에서 차단되므로, 경제 정책 관점에서 무역 금수 조치가 상호적이어야 함.
     * 민주주의는 대중의 여론을 대규모로 바꿀 수 있는 도구에 매우 취약함. 이는 서구 소셜 미디어와 TikTok 모두에 해당되며, 모든 소셜 미디어 알고리즘이 편향되지 않도록 규제하는 것이 바람직함. TikTok을 통해 중국이 미국 선거에 영향을 미칠 수 있는 실질적인 위협에 대응하기 위한 좋은 시작이 될 수 있음.
     * 중국에 가보면 페이스북, 구글 등 모든 서구 제품을 금지하고 자체 변종으로 대체한다는 것을 알 수 있음. 중국이 자국 제품에 대해 아무런 제한 없이 자유롭게 활보하려면 자국 내 제한을 완화해야 함.
     * TikTok이 2020년부터 중국 본토에서 차단되었다는 사실이 흥미로움.
     * TikTok이 의회 앞에서 CEO가 위증하지 않았다면 이런 일이 일어나지 않았을 것임.
     * 피드백이 압도적으로 부정적인 것 같음. 가장 큰 문제는 너무 좁게 타겟팅된다는 것임. 중국 정부 관리들이 예고 없이 나타나 우리 네트워크에 장비를 연결하고 암호화 키, 계정 데이터베이스, 직원 및 고객 목록 등에 대한 액세스를 요구함. 중국이 자국의 이익을 위해 그렇게 한다면 우리도 우리의 이익을 위해 호의를 돌려줄 수 있어야 함.
     * 이 법안은 국가가 소셜 미디어로부터 직면하는 위협의 심각성을 보여주고, 더 이상 평상시와 같지 않다는 것을 보여줄 것으로 기대됨. 모든 유럽 국가 및 EU/ECC를 비롯한 다른 모든 국가 또는 블록은 외국에서 운영하는 모든 소셜 미디어 앱에 동일한 법률이 적용되도록 해야 함.
"
"https://news.hada.io/topic?id=14501","McKinsey, 오피오이드 관련 컨설팅으로 형사 조사 받아","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   McKinsey, 오피오이드 관련 컨설팅으로 형사 조사 받아

        Hacker News 의견

     * McKinsey의 명성이 추락하고 있으며, 지난 10년간 스캔들을 거듭하면서 한때 높이 평가되던 평판이 추락한 상태임. 그들은 현재 닥친 상황에 마땅한 대가를 치를 것으로 보임.
     * 한 해커뉴스 사용자는 과거에 알고 지내던 McKinsey 컨설턴트를 통해, 내부자 거래와 이해 상충 등 언론에 보도되지 않은 부정적인 내용들이 사실이라는 것을 알게 되었다고 함.
     * McKinsey는 재향군인부(VA)에 자사 제품을 판매하기 위해 Purdue와 Endo에 조언했는데, 이는 McKinsey가 동시에 VA의 컨설턴트로 일하는 동안 발생한 일이었음. 정부 서비스를 위해 이러한 컨설팅 회사를 활용하는 데에는 이해 상충이 만연함.
     * ""When McKinsey Comes to Town""이라는 책은 McKinsey의 수십 년에 걸친 부정행위를 자세히 살펴보고 있음.
     * 아편유사제 사건뿐만 아니라, McKinsey는 많은 사람들이 실패로 여기는 최근 캐나다 이민 정책에 대해서도 Trudeau로부터 관대한 계약을 수주하며 직접적인 책임이 있음. 이민과 같은 주요 정책을 논란이 많은 외국 컨설팅 회사에 맡기는 것은 다소 기괴한 일임.
     * 펜실베이니아에서도 McKinsey가 Purdue의 마케팅 계획을 실행한 이사들을 주가 고소하자, 관련 문서와 이메일을 삭제하는 것에 대해 이메일을 주고받기 시작했다는 내용의 유사한 사례가 있었음.
     * McKinsey는 이미 다른 여러 청구에 대해 거의 10억 달러를 지불했기 때문에, 이번 건도 그들에게 좋지 않을 것으로 보임. 이것이 그들이 세상에 끼친 다른 모든 해로운 조언에 대한 확대 조사로 이어지기를 바람.
     * 한 연구에 따르면 McKinsey의 '다양성의 중요성(Diversity Matters)' 보고서의 통계적 주장이 의심스러운 것으로 나타났음.
     * 결국 McKinsey는 벌금을 내겠지만, 그 액수는 OxyContin과 관련된 컨설팅으로 그들이 얻은 이익에 비하면 매우 적을 것이며, 누구도 해고되거나 감옥에 가지 않을 것임. 그 외의 다른 일이 일어나면 매우 충격적일 것임.
"
"https://news.hada.io/topic?id=14508","Pico.sh - 모든 것을 SSH를 이용해서 웹서비스를 관리하는 오픈소스 모음","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Pico.sh - 모든 것을 SSH를 이용해서 웹서비스를 관리하는 오픈소스 모음

     * SSH 기반 서비스를 이용하여 모든 것을 처리
     * 포함된 도구들
          + pgs.sh: 사이트 배포를 위해 SSH를 사용하는 스태틱 사이트 호스팅 플랫폼
          + tuns.sh: SSH로 로컬 호스트와 연결하는 https/wss/tcp 터널
          + imgs.sh: 인증에 SSH를 사용하는 Docker 이미지 레지스트리
          + prose.sh: 콘텐츠 관리를 위해 SSH를 사용하는 블로그 플랫폼
          + pastes.sh: rsync, scp 및 sftp를 사용하여 코드 스니펫을 업로드
          + feeds.sh: SSH를 사용하는 RSS 이메일 알림 서비스

   ssh로 접속하는 채팅 서비스가 생각나네요.

   Devzat - SSH 기반의 디스코드 비슷한 채팅 오픈소스
"
"https://news.hada.io/topic?id=14555","Apple, 기기 내 사용을 목표로 하는 8개의 소형 AI 언어 모델 릴리즈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Apple, 기기 내 사용을 목표로 하는 8개의 소형 AI 언어 모델 릴리즈

     * Apple이 스마트폰에서 직접 실행할 수 있을 정도로 작은 크기의 AI 언어 모델인 OpenELM을 공개
     * OpenELM은 ""Open-source Efficient Language Models""의 약자로, Hugging Face에서 Apple Sample Code License로 사용 가능
     * 소스 코드는 공개되었으나 라이선스에 일부 제한이 있어 일반적인 ""오픈 소스"" 정의에는 맞지 않을 수 있음

OpenELM 모델의 특징

     * OpenELM은 2억 7천만에서 30억 개의 매개변수를 가진 8개의 모델로 구성됨
     * 최근 연구는 몇 년 전의 대규모 AI 언어 모델만큼 능력 있는 작은 AI 언어 모델 만들기에 초점을 맞추고 있음
     * OpenELM 모델은 사전 학습된(pretrained) 버전과 명령어 학습된(instruction-tuned) 버전, 두 가지 유형으로 제공됨
          + OpenELM-270M, OpenELM-450M, OpenELM-1_1B, OpenELM-3B
          + OpenELM-270M-Instruct, OpenELM-450M-Instruct, OpenELM-1_1B-Instruct, OpenELM-3B-Instruct

OpenELM 모델의 학습 데이터와 성능

     * OpenELM은 최대 2048 토큰의 컨텍스트 윈도우를 가지고 있음
     * 약 1.8조 개의 토큰 데이터로 학습되었으며, 이는 공개적으로 사용 가능한 RefinedWeb, PILE의 중복 제거 버전, RedPajama의 하위 집합, Dolma v1.6의 하위 집합 데이터셋을 포함
     * Apple의 ""layer-wise scaling strategy""를 통해 매개변수를 각 레이어에 더 효율적으로 할당하여 계산 자원을 절약하고 모델 성능을 향상
     * OpenELM은 Allen AI의 OLMo 1B보다 절반의 사전 학습 토큰으로도 2.36% 더 정확한 성능을 보임

공개된 추가 자료와 Apple의 목표

     * Apple은 OpenELM 학습에 사용된 CoreNet 라이브러리의 코드와 재현 가능한 학습 레시피를 공개
     * 주요 기술 기업으로서는 이례적으로 가중치까지 공개하여 투명성을 강조
     * 소스 코드, 모델 가중치, 학습 자료를 공개함으로써 ""개방형 연구 커뮤니티를 강화하고 풍부하게 만드는 것""이 목표
     * 그러나 공개 데이터셋으로 학습되었기에 부정확하거나 유해하거나 편향되거나 반감을 살만한 출력물이 나올 가능성이 있음을 경고

향후 전망

     * Apple은 아직 새로운 AI 언어 모델 기능을 소비자 기기에 통합하지는 않았음
     * 그러나 6월 WWDC에서 공개될 것으로 예상되는 iOS 18 업데이트에는 사용자 개인 정보 보호를 위해 기기 내 처리를 활용하는 새로운 AI 기능이 포함될 것으로 추측됨
     * 더 복잡한 기기 외부 AI 처리를 위해 Google이나 OpenAI를 고용하여 Siri를 업그레이드할 가능성도 있음

   AI 돌릴려면 아이폰 15부터 되겠죠 아머?

   iOS 18 업데이트 과연 얼마나 크게 바뀔지 궁금합니다. AI 기능 보강된 M4도 기대기대!
"
"https://news.hada.io/topic?id=14610","Show GN: iPhone을 위한 다기능 계산기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Show GN: iPhone을 위한 다기능 계산기

   안녕하세요!

   iPhone에 잘 어울리는 다기능 계산기를 한번 만들어봤습니다.
   기본계산기가 워낙 마음에 드는데 사소하게 불편한 것들이 있어서
   고쳐보고자 시작한 프로젝트입니다.

   특징은
    1. 계산 과정이 보입니다.
       기본 계산기는 계산 기호 누르면 그 전 입력값이 사라짐
    2. 계산 기록, 지우는 버튼, 괄호 도입
       되게 사소한 건데 있으면 편합니다
    3. 간단한 부가 기능
       날짜계산기, 단위변환기, 팁계산기 등을 넣어봤습니다.
    4. 다이얼 숫자 배열 (123이 맨 위에 있는)
       계산기와 전화 키패드 배열이 다르다는 사실을 아셨나요? 사실 모바일의 모든 숫자 키패드는 계산기를 제외하면 전화기 배열(123이 맨 위에 있는 배열)입니다. 그래서 넣어봤습니다. 더 편한지 확인해보세요!

   많은 관심 부탁드리고, 궁금한 점이나 피드백 항상 환영입니다!
   감사합니다.
"
"https://news.hada.io/topic?id=14575","GitHub Copilot Workspace 기술 시험판 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   GitHub Copilot Workspace 기술 시험판 공개

     * 자연어를 사용하여 코드를 브레인스토밍, 계획, 빌드, 테스트 및 실행할 수 있는 Copilot 기반의 개발 환경
     * 개발 프로세스의 모든 단계에서 다양한 Copilot 기반 에이전트를 활용하면서도 개발자에게 완전한 제어권을 부여함
     * 자연어를 사용하여 소프트웨어를 구축하는 혁신적인 방식을 제시
     * 개발자의 창의성을 대체하는 것이 아니라, 더 빠르고 쉽게 발휘할 수 있도록 설계됨
     * 경험 있는 개발자가 시스템 씽커로 활동할 수 있도록 지원하며, 소프트웨어를 구축할 수 있는 사람의 진입 장벽을 크게 낮출 것임

GitHub Copilot Workspace의 동작 방식

     * 개발자에게 가장 큰 진입 장벽은 대부분 시작 단계에 있음
     * 큰 프로젝트, 기능 요청 또는 버그 보고서의 첫 단계에서 벽에 부딪히는 경우가 많음
     * GitHub Copilot Workspace는 그 원점인 ""GitHub Repo 또는 GitHub Issue""에서 개발자와 만나게 됨
     * Copilot 에이전트를 제2의 두뇌로 활용하여 아이디어 시작 단계부터 AI 지원을 받을 수 있음
     * Copilot Workspace가 단계별 계획 수립하여 제시
          + 코드베이스, 이슈 답변 등에 대한 깊은 이해를 바탕으로 이슈 해결을 위한 단계별 계획을 제시함
          + 계획을 검증하고 코드를 테스트하는 데 필요한 모든 것을 자연어로 간소화된 목록으로 제공함
     * 제안 내용은 전체 편집 가능함
          + Copilot Workspace가 제안하는 계획부터 코드까지 모든 것을 완전히 편집할 수 있음
          + 개발자는 모든 자율성을 유지하면서 Copilot Workspace가 인지적 부담을 덜어줌
          + 계획에 만족하면 Copilot Workspace에서 직접 코드를 실행할 수 있음
          + 기본 GitHub Codespace로 이동하여 최종 결과에 만족할 때까지 모든 코드 변경 사항을 조정할 수 있음
          + 링크를 통해 워크스페이스를 팀과 즉시 공유하여 작업 내용을 보고 반복을 시도해볼 수 있음
          + Pull Request를 제출하고 GitHub Actions, 보안 코드 스캐닝을 실행한 후 팀 구성원에게 사람이 하는 코드 검토를 요청하면 됨
          + 팀원들은 Copilot Workspace를 활용하여 아이디어에서 코드로 어떻게 전개되었는지 확인할 수 있음
     * 모바일 호환성도 제공
          + 아이디어는 어디서나 발생할 수 있으므로 GitHub Copilot Workspace는 모든 장치에서 사용할 수 있도록 설계됨
          + 데스크톱, 노트북 또는 이동 중에도 실제 개발 환경에서 작업할 수 있음
     * 개발 환경의 미래에 대한 GitHub의 비전은
          + 직관적이고 Copilot 기반의 인프라를 통해 시작, 학습 및 궁극적으로 실행이 더 쉬워지도록 하는 것

  Hacker News 의견

     * 개발자들이 LLM 기반 코드 생성 도구에 대해 다양한 의견을 제시함
          + 프롬프트 디버깅이 코드 디버깅보다 더 번거로워 결국 전통적인 방식으로 코딩하는 것이 나음
          + Copilot은 작은 규모에서는 유용하지만 대규모 복잡한 코드베이스에는 적합하지 않음
          + 도메인 전문성, 사용자 경험, 기술 부채 등 큰 그림을 보는 맥락 인식 능력이 부족함
          + 경험 부족한 개발자들이 이런 도구에 의존하면 일관성 없는 코드를 양산할 우려가 있음
     * 반면, 학생 입장에서는 최근 3년간 LLM 도구의 급격한 발전 속도를 보면서 이를 무시하기 어려움
          + 생산성 향상으로 인한 일자리 감소 우려도 제기됨
     * 코드 생성보다는 개발자의 생각을 정리하는 '개발자를 위한 프로젝트 관리' 도구로서의 가치를 봄
     * 브라우저 기반 Codespaces보다는 익숙한 로컬 개발 환경인 VS Code에서 사용하길 원함
     * Copilot Workspace와 유사한 오픈소스 도구인 aider를 소개함
     * Plandex라는 터미널 기반의 오픈소스 AI 프로젝트 관리 도구도 소개됨
          + 개발자와 LLM 간의 빠른 피드백 루프를 제공하고, 모델과의 상호작용을 버전 관리함
"
"https://news.hada.io/topic?id=14520","Kamal - 모든 곳에 웹앱을 쉽게 배포하고 관리해주는 도구","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Kamal - 모든 곳에 웹앱을 쉽게 배포하고 관리해주는 도구

     * 베어 메탈 부터 클라우드 VM까지 상관없이 동일하게 SSH 키만 있으면 관리 가능
     * 프로덕션 환경에서 웹 앱을 배포하고 관리하는 데 필요한 모든 것을 Docker로 제공
          + 다운타임 없는 배포, 롤링 재시작, 자산 브리징, 원격 빌드, 액세서리 서비스 관리 등
          + 새 앱 컨테이너가 시작되고 기존 컨테이너가 중지되는 동안 동적 역방향 프록시인 Traefik이 요청을 보류
     * 원래 Rails 앱용으로 구축되었으너, 컨테이너화할 수 있는 모든 유형의 웹 앱에서 작동
     * ""Capistrano for Container""
"
"https://news.hada.io/topic?id=14612","KAN: 정확성과 해석성을 위한 MLP에 보다 나은 대안","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    KAN: 정확성과 해석성을 위한 MLP에 보다 나은 대안

   • 콜모고로프-아놀드 표현 정리에서 영감을 받은 다층 지각자(MLP)의 대안으로 콜모고로프-아놀드 네트워크(KAN)가 제안된다.

   • 노드에 고정된 활성화 함수를 갖는 MLP와 달리 KAN은 에지에 학습 가능한 활성화 함수를 갖기 때문에 선형 가중치 행렬이 없다.

   • KAN은 MLP에 비해 우수한 정확도를 보여 데이터 피팅 및 PDE 해결에서 네트워크 크기가 작을수록 비교 가능하거나 더 나은 결과를 얻을 수 있다.

   • KAN은 이론적으로나 경험적으로 MLP보다 더 빠른 신경 스케일링 법칙을 가지고 있다.

   • KAN은 향상된 해석성을 제공하여 직관적인 시각화 및 인간 사용자와의 상호 작용을 허용한다.

   • 수학과 물리학의 예를 통해 KAN은 과학자들이 수학적, 물리적 법칙을 (재) 발견하는 데 도움이 되는 ""협력자""로서 유용하다는 것을 증명한다.

   • KAN은 MLP에 크게 의존하는 딥러닝 모델을 향상시켜 정확성과 해석성을 더욱 발전시킬 수 있는 기회를 열어주는 유망한 방법을 제시한다.
"
"https://news.hada.io/topic?id=14592","Borgo - Go로 컴파일되는 정적 타입 언어","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Borgo - Go로 컴파일되는 정적 타입 언어

Borgo 프로그래밍 언어 소개

     * Go보다는 표현력이 좋지만 Rust보다는 복잡하지 않은 애플리케이션 작성 언어를 원함
          + Go는 단순하고 직관적이지만, 종종 더 많은 타입 안전성을 제공했으면 함
          + Rust는 작업하기 좋지만(적어도 단일 스레드 코드의 경우) 너무 광범위하고 복잡하며, 때로는 고통스러움
     * Borgo는 Go로 트랜스파일되는 새로운 언어로, 기존 Go 패키지와 완벽하게 호환됨
     * Borgo 구문은 세미콜론이 선택사항인 Rust와 유사함

주요 기능

     * 대수적 데이터 유형 및 패턴 매칭
     * nil 대신 Option 사용
     * 여러 반환 값 대신 Result 사용
     * ? 연산자를 사용한 오류 처리

로컬에서 실행하기

     * Borgo는 Rust로 작성되었으므로 cargo가 필요함
     * 현재 폴더의 모든 .brg 파일을 컴파일하려면:
          + $ cargo run -- build
     * 컴파일러는 .go 파일을 생성하고, 이를 정상적으로 실행할 수 있음

GN⁺의 의견

     * Rust는 강력한 언어지만 러닝커브가 가파르고 도입 장벽이 높은 편인데, Borgo는 Rust의 장점을 Go의 생태계에서 활용할 수 있게 해주는 흥미로운 시도로 보임. 다만 아직 초기 단계라 생태계가 부족할 것으로 예상됨
     * Option과 Result로 nil과 에러 처리를 개선한 것, ? 연산자로 에러 핸들링을 간편하게 한 부분 등은 Go 개발자들이 종종 불편해하던 부분을 해소해줄 것 같음
     * 기존 Go 라이브러리를 그대로 사용할 수 있다는 것은 큰 장점. 하지만 Rust 문법을 차용한만큼 Go 개발자들이 적응하는데 시간이 걸릴 수 있음
     * Transpile 방식이다보니 디버깅이나 런타임 퍼포먼스 등에서 네이티브 Go 코드 대비 불리할 가능성이 있음. 큰 규모의 프로덕션 코드에 적용하기에는 아직 이른 감이 있음
     * Kotlin이 JVM 생태계에서 점유율을 높여가는 것처럼, Borgo도 Go의 솔루션이 되기 위해서는 코드 품질, 개발 생산성, 러닝커브 등 여러면에서 지속적인 개선이 필요해보임. 계속 발전해나간다면 Go 진영의 매력적인 대안이 될 수 있을 것으로 기대됨

        Hacker News 의견

   요약:
     * Go 언어의 부족한 점을 보완한 Borgo 언어에 대한 긍정적 반응들
          + Enum, Optional 타입 등 Go에서 아쉬웠던 기능들이 추가됨
          + Go 개발자들이 바라던 기능들이 대부분 포함됨
     * Borgo의 일부 디자인 결정은 Go의 특징보다는 Rust를 닮은 느낌
          + impl을 이용한 메서드 정의, 채널과 고루틴 문법, zeroValue() 내장 함수 등
          + 그럼에도 불구하고 Go보다는 Borgo로 개발하는 것을 선호할 것으로 보임
     * 비슷한 시도를 했던 다른 프로젝트들에 대한 소개
          + braid, have, oden 등 Go로 트랜스파일되는 언어를 만들려는 시도들이 있었음
     * Rust의 장점 중 하나인 Borrow Checker를 제외하고 타입 시스템과 에러 핸들링 등의 장점은 가져온 듯함
     * 동적 타이핑과 정적 타이핑의 장단점을 모두 가진 언어가 있으면 좋겠다는 의견
          + 초기 개발 시에는 Python 같은 동적 타이핑의 장점을, 이후에는 점진적으로 정적 타이핑으로 전환할 수 있으면 좋을 것
     * Go의 런타임과 도구 생태계의 장점에 Rust의 Enum 같은 타입 안정성이 더해진 느낌
     * Struct의 필드 가시성을 대소문자로 구분하는 Go의 방식 대신 pub/private 키워드를 도입한 점도 긍정적
     * Gleam 언어와 비슷한 타입 안정성과 복잡도 간의 절충안을 찾은 듯하지만, Erlang이나 JS가 아닌 Go로 컴파일 된다는 점이 성능상 이점
          + 다만 컴파일 에러 메시지가 Rust나 Gleam만큼 친절할지는 의문
"
"https://news.hada.io/topic?id=14544","구글이 나에게 완벽한 웹사이트를 망치게 한 사건 (2023)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   구글이 나에게 완벽한 웹사이트를 망치게 한 사건 (2023)

광고로 인한 사이트 품질 저하 사례 연구

     * 저자는 오랫동안 운영해온 사이드 프로젝트 사이트인 ""Apportionment Calculator""에 광고를 달기로 결정함.
     * Apportionment Calculator는 10년간 구글 검색 결과 최상위를 유지하고 있던 간단하고 유용한 사이트였음.

구글의 광고 정책으로 인해 발생한 문제들

     * 구글은 광고를 게재하기 위해서는 사이트에 많은 양의 콘텐츠가 있어야 한다고 요구함.
     * 하지만 콘텐츠의 질은 중요하지 않았음.
     * 저자는 ChatGPT를 이용해 역사, 시, 수수께끼, 블로그 등 엄청난 양의 쓰레기 콘텐츠를 생성함.
     * 예를 들어 블로그에는 국회의원 정수 배분에 집착하는 커플과 그들의 애완동물에 관한 황당한 이야기가 담겨 있었음.
     * 이런 과정을 거친 후에야 겨우 구글은 사이트에 광고를 허락해줌.

사례 연구의 결론

     * 구글의 광고 정책은 사이트들로 하여금 엄청난 양의 쓰레기 콘텐츠를 만들도록 유도함.
     * 사이트 운영자 입장에서는 유용한 콘텐츠보다 많은 양의 콘텐츠 생산에 치중하게 됨.
     * 결과적으로 인터넷은 광고와 저품질 콘텐츠로 넘쳐나게 되었음.
     * ""한 가지 일을 잘하자(DOTADIW)"" 원칙을 따르던 유용한 사이트들이 설 자리를 잃어가고 있음.

GN⁺의 의견

     * 광고 수익 모델은 결국 콘텐츠의 질을 떨어뜨리는 결과를 초래하는 것 같습니다. 광고에 의존하지 않는 수익 모델을 고민해봐야 할 것 같네요.
     * 이런 문제를 해결하기 위해서는 사용자가 직접 원하는 콘텐츠에 비용을 지불하는 구독형 모델을 도입하는 것도 한 방법이 될 수 있겠어요. Substack이나 Patreon 같은 서비스가 대안이 될 수 있을 거예요.
     * ChatGPT가 엄청난 잠재력을 가졌지만, 이를 악용해 쓰레기 콘텐츠를 양산하는 데 사용될 수 있다는 점은 경계해야 할 것 같아요. AI 윤리에 대한 사회적 합의와 가이드라인 마련이 시급해 보입니다.
     * 콘텐츠 검색과 랭킹에 있어 단순히 양보다는 질을 평가할 수 있는 알고리즘 개발이 필요해 보여요. 구글도 검색 품질 개선을 위해 지속적으로 노력해야 할 것 같네요.
     * 궁극적으로는 건강한 인터넷 생태계 조성을 위해 크리에이터를 지원하고 양질의 콘텐츠가 정당한 보상을 받을 수 있는 다양한 수익 구조 마련이 필요할 거예요. 광고 중심의 단선적 접근에서 벗어나, 창의적인 대안들이 나올 수 있기를 기대합니다.

        Hacker News 의견

     * 한 개발자가 자신의 웹사이트에 광고를 추가하여 운영 비용을 충당하려 했으나, 광고 추가 후 사이트 사용성이 크게 저하됨. 이는 Google의 잘못이 아니라 개발자 자신의 선택에 따른 것임.
     * 웹사이트의 사용자 맥락을 고려하지 않은 광고 게재는 사용자 경험을 해칠 수 있음. 특정 작업을 수행하기 위해 방문한 사용자는 광고에 현혹될 가능성이 낮음.
     * 웹 수익화 모델이 광고에 편중되어 있어, 실제 작업을 수행하는 사이트는 수익 창출에 어려움을 겪음. 대안적 수익 모델 마련이 시급함.
     * Google 검색 결과 중 일부 사이트는 신뢰할 만한 출처임에도 불구하고, 과도한 광고로 인해 사용성이 크게 저하됨.
     * Google, Apple, Microsoft 등 거대 기업들의 독점적 지위를 견제하기 위해, 시가총액 상한제 도입 등의 규제 방안이 제시됨.
     * 웹사이트 운영자는 Buy Me A Coffee 등 대안적인 수익 모델을 모색해볼 필요가 있음. 광고 수익에만 의존하기 어려운 경우, 사이트 매각도 고려해볼 만함.
     * 광고차단 플러그인을 사용하지 않으면 웹 콘텐츠 대비 광고의 비중이 지나치게 높아, 사용자 경험이 크게 저하됨. 웹 생태계 전반의 문제로 인식됨.
     * 광고 게재량을 조절할 수 있는 옵션 제공 여부가 불분명함. 수익은 줄더라도 최소한의 광고만 노출하는 것이 바람직해 보임.
     * 시 생성 사이트에서도 유사한 문제 발생. Google Adsense 승인 거부로 제휴 링크 사용 검토 중.
"
"https://news.hada.io/topic?id=14584","SQLite가 Bytecode를 사용하는 이유 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       SQLite가 Bytecode를 사용하는 이유

SQL 데이터베이스 엔진의 일반적인 작동 방식

     * 모든 SQL 데이터베이스 엔진은 비슷한 방식으로 동작함
          + 입력된 SQL 문을 ""준비된 문장(Prepared Statement)""으로 변환
          + 준비된 문장을 ""실행""해서 결과를 생성
     * SQLite에서 준비된 문장은 sqlite3_stmt 객체의 인스턴스로 표현됨
     * 준비된 문장을 표현하는 방법은 크게 두 가지
          + 바이트코드 방식: SQLite에서 사용
          + 객체 트리 방식: MySQL, PostgreSQL에서 사용

바이트코드 방식의 장점

     * 이해하기 쉬움
          + 단순한 명령어들의 나열로 구성되어 쉽게 출력 가능
          + EXPLAIN 키워드를 사용하면 SQL 문장의 바이트코드 확인 가능
     * 디버깅이 용이함
          + 파싱/분석 단계와 실행 단계를 명확히 구분
          + 디버깅 빌드에서 PRAGMA vdbe_trace=ON 명령으로 바이트코드 실행 추적 가능
     * 증분식으로 실행 가능
          + 바이트코드로 작성된 SQL 문은 한 행씩 실행하고 중지했다 재개 가능
          + 객체 트리 방식은 전체 트리를 한번에 실행하므로 증분 실행이 어려움
     * 메모리 사용량이 적음
          + 바이트코드는 AST보다 크기가 작음
          + Prepared Statement는 오래 메모리에 캐싱되므로 메모리 사용량이 중요
     * 실행 속도가 빠름
          + 각 단계에서 결정해야 할 사항이 적어 실행이 빠름

객체 트리 방식의 장점

     * 런타임에 쿼리 계획을 수정할 수 있음
          + 객체 트리는 실행 중에도 수정이 용이함
          + 쿼리의 진행 상황에 따라 동적으로 최적화 가능
     * 병렬화하기 쉬움
          + 각 처리 노드를 별도 스레드에 할당 가능
          + 노드 간 데이터 전달만 동기화하면 됨
          + 대용량 분석 쿼리(OLAP)를 다중 코어에서 실행할 때 유리

GN⁺의 의견

     * SQLite의 주요 목표는 사물인터넷 환경에서의 트랜잭션 처리(OLTP)이므로, 바이트코드 방식이 적합해 보임. 간단하고 가벼우면서도 빠른 성능을 제공할 수 있기 때문임.
     * 반면 MySQL이나 PostgreSQL은 대용량 데이터 분석에도 많이 사용되므로, 쿼리 실행 계획을 동적으로 최적화하고 병렬화할 수 있는 객체 트리 방식의 장점이 더 부각될 수 있음.
     * 다만 객체 트리 방식도 디버깅이나 성능 분석이 어렵다는 단점이 있음. 또한 트리 순회 비용 등으로 인해 간단한 쿼리의 경우 오히려 바이트코드보다 느릴 가능성도 있음.
     * 중요한 점은 용도와 목적에 맞는 적절한 방식을 선택하는 것. 범용 RDBMS의 경우 두 방식의 장단점을 절충한 하이브리드 방식을 사용하는 것도 고려해볼 만함.

        Hacker News 의견

     * SQLite가 SQL 쿼리 실행을 위해 추상 구문 트리(AST) 대신 바이트코드 가상 머신(VM)을 사용하는 것은 데이터베이스에 있어 흥미로운 설계 선택임. 바이트코드가 AST보다 갖는 장점은 다음과 같음:
          + 컴팩트함: 바이트코드는 하위 표현식에 대한 숨겨진 malloc/객체 헤더와 포인터가 필요하지 않아 AST보다 더 컴팩트함.
          + 성능: 캐시 활용도가 높고 포인터 추적으로 인한 캐시 미스가 적어 바이트코드 실행이 더 빠름.
          + 증분 실행: 명시적 스택을 사용하여 기본 스택을 풀지 않고도 실행을 일시 중지하고 재개하는 것이 바이트코드로 더 쉬움.
     * 바이트코드 VM과 인터프리터는 종종 범용 프로그래밍 언어와 연관되지만, 다음과 같은 다른 맥락에서도 놀랍도록 유용할 수 있음:
          + eBPF: Linux 커널의 확장 메커니즘.
          + DWARF 표현 언어: GDB, LLDB 같은 디버거에서 사용됨.
          + RAR 파일 포맷: 사용자 정의 데이터 변환을 위한 바이트코드 인코딩을 포함함.
     * Microsoft SQL Server는 내부적으로 객체 트리를 사용하지만, 쿼리 플랜 출력은 여전히 테이블 형태로, 객체 트리를 테이블로 렌더링하는 것이 어려움을 보여줌.
     * 프로그래머는 종종 어떤 인덱스 조회가 루프에서 일어나야 하는지 정확히 알고 있으므로, 경우에 따라 SQL 대신 바이트코드를 직접 작성하거나 고수준의 명령형 언어를 사용하는 것이 유리할 수 있음. SQL로 이를 표현하는 것은 부담이 될 수 있음.
     * 병목현상이 바이트코드 실행에 있지 않다면(예: 메모리나 디스크 속도), JIT 컴파일을 통해 네이티브 코드로 변환하는 것이 꼭 필요하지 않을 수 있음.
     * Python, Ruby, Lua 등 많은 프로그래밍 언어가 내부적으로 바이트코드나 AST를 사용함. 데이터베이스 설계 결정으로 인해 오류가 발생하기 쉬운 서드파티 라이브러리나 ORM 구현에 쉽게 파싱 가능한 명령문이 유용할 수 있음.
"
"https://news.hada.io/topic?id=14531","하이퍼클로바X, 속도 높이고 비용 낮춘 ‘대시(DASH)’ 모델 출시","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 하이퍼클로바X, 속도 높이고 비용 낮춘 ‘대시(DASH)’ 모델 출시

     * 네이버가 초대규모 AI ‘하이퍼클로바X(HyperCLOVA X)’의 신규 모델 ‘HCX-DASH’를 공개
     * HCX-DASH는 하이퍼클로바X의 기존 모델(HCX-003)보다 저렴
          + 클로바 스튜디오에서 기존 대비 5분의 1 수준의 가격으로 신규 모델을 이용가능
     * 하이퍼클로바X는 대부분의 학습 데이터가 영어로 구성된 AI보다 더 적은 비용으로, 더 빠르게 한국어를 처리할 수 있어 이미 국내 사용자에게 상대적으로 우수한 비용 효율성 및 사용성을 갖추고 있었으며, HCX-DASH는 이러한 장점을 한층 강화함
     * 작업의 종류, 비용 등 고려한 맞춤형 선택지 제공할 수 있도록 모델 라인업 확대 예정
"
"https://news.hada.io/topic?id=14517","제프 로손, The Onion 인수","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          제프 로손, The Onion 인수

     * G/O Media는 풍자 뉴스 사이트인 The Onion을 디지털 미디어 전문가 그룹에 매각했음. The Onion은 1988년 위스콘신에서 주간 풍자 신문으로 시작되었고 나중에 웹사이트가 되었음. 매스 슈팅이 있을 때마다 거의 같은 헤드라인을 반복해서 게시하는 것으로 유명함.
     * The Onion을 인수한 새로운 시카고 기반 회사는 Global Tetrahedron이라는 이름인데, 이는 The Onion 직원들이 쓴 책 ""Our Dumb Century""에 등장하는 악의적인 가상 회사 이름에서 영감을 받았음.
     * Global Tetrahedron의 소유주는 통신기술 회사 Twilio의 공동 창업자이자 전 CEO인 Jeff Lawson이고, CEO는 최근까지 NBC News의 선임 기자였던 Ben Collins임. TikTok 전 임원 Leila Brillson과 Tumblr 출신 Danielle Strle가 경영진을 구성함.
     * 새 소유주는 The Onion의 전 직원을 시카고에 그대로 유지하기로 했음. 이는 G/O Media가 거래의 일부로 포함시키기를 주장한 사항이었음.

GN⁺의 의견

     * 풍자 뉴스 사이트인 The Onion이 디지털 미디어 전문가 그룹에 인수되었다는 점이 흥미로움. The Onion은 오랫동안 미국 사회와 미디어에 대한 신랄한 풍자로 사랑받아 왔기에 앞으로도 그 정신을 잘 이어갈 수 있을지 관심이 됨.
     * 새 회사 이름을 The Onion 책에 나오는 가상의 악의적 회사명에서 따왔다는 것이 The Onion 특유의 유머 감각을 보여줌. 앞으로도 이런 위트 있는 접근이 이어질 것으로 보임.
     * 통신기술, 소셜미디어 출신의 경영진 구성이 The Onion의 디지털 경쟁력 강화에 도움이 될 것으로 보임. 하지만 너무 상업적으로 변모하지 않고 고유한 풍자 정신을 잃지 않기를 바람.
     * 풍자 뉴스는 가짜뉴스와는 다르게 사회 비판의 역할을 하므로 민주주의 사회에 꼭 필요함. The Onion이 앞으로도 권력을 감시하고 사회의 어두운 면을 꼬집는 날카로운 풍자를 이어가길 기대함.

        Hacker News 의견

   요약:
     * The Onion이 Twilio의 창립자인 Jeff Lawson에 의해 인수됨. Lawson은 인수 여부에 대해 모호한 반응을 보임.
     * The Onion은 과거 하버드 스퀘어에서 무료로 배포되던 실물 신문이었음. ""Point/Counterpoints"" 등의 코너가 인기였음.
     * The Onion의 소유주였던 G/O Media의 웹사이트 품질이 좋지 않아 이번 인수가 긍정적으로 평가됨.
     * The Onion은 위스콘신 매디슨 대학에서 시작되었고, 작가들이 다른 학생 신문에도 만화를 연재함.
     * ""Christ Returns to NBA"" 등 인상 깊은 헤드라인들이 많았음.
     * The Onion은 최근 연방대법원에 유머러스한 법정조언서를 제출하기도 함.
     * Onion News Network의 동영상들은 시사적이면서도 재미있다는 평가를 받음.
     * G/O Media가 The Onion을 포기한 것은 다행으로 여겨짐.
     * ""Situation in Nigeria Seems Pretty Complex"", ""Prague's Kafka International Named Most Alienating Airport"" 등의 동영상이 재미있었음.
     * 최근에는 예전만큼 재미있지는 않지만, 새 소유주 하에 다시 좋아지길 기대함.
"
"https://news.hada.io/topic?id=14570","인터넷 아카이브의 절체절명의 순간에 살아남기 위한 최후의 노력","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   인터넷 아카이브의 절체절명의 순간에 살아남기 위한 최후의 노력

인터넷 아카이브의 마지막 노력

     * 4월 19일, 인터넷 아카이브는 작년에 패소한 ""Hachette v. Internet Archive"" 소송에 대한 항소의 최종 변론서를 제출함
     * 이 최종 변론서는 소송의 핵심 쟁점을 합리적으로 다루지 못하고 있음
     * 인터넷 아카이브의 후속 공개 성명은 사건의 핵심을 오도하여 대중의 동정심을 불러일으키기 위해 만들어진 것으로 보임
     * 이는 인터넷 아카이브가 이 항소에서 패할 가능성이 높다는 것을 잘 알고 있음을 시사함

""Hachette v. Internet Archive"" 소송 개요

     * 인터넷 아카이브는 ""제어된 디지털 대출(CDL)"" 프로그램을 만들어 실물 책을 스캔하여 디지털 파일로 만들고 이를 인터넷에서 ""대출""함
     * 2020년, 인터넷 아카이브는 디지털 대출 프로그램의 제한을 제거하여 무제한으로 책의 디지털 사본을 다운로드 할 수 있게 함
     * 이에 출판사 그룹이 ""Hachette v. Internet Archive"" 소송을 제기함
          + 저작권 소유자(출판사, 작가 등)의 허락 없이 책을 디지털화하여 배포함
          + 인터넷 아카이브가 저작권자 허락없이 무료로 배포한 저작물로 기부금 등 금전적 이득을 얻음. 사실상 해적판 배포의 상업적 기업이 됨
     * 2023년 인터넷 아카이브에 불리한 판결이 내려졌고, 판사는 ""공정 사용"" 주장을 뒷받침할 사례나 법률 원칙이 없다고 선언함
     * 이에 인터넷 아카이브는 항소함

인터넷 아카이브의 최종 변론

     * 인터넷 아카이브의 ""제어된 디지털 대출""은 ""공정 사용""에 해당하므로 합법이라는 것이 기본 변론임
     * 주요 주장 중 일부:
          + ""제어된 디지털 대출은 누구나 읽을 수 있도록 전자책을 온라인에 게시하는 것과 같지 않다""
               o 그러나 2020년 3월부터 ""국가 비상사태 도서관""으로 대규모 책 아카이브를 온라인에 공개했음
          + ""합법적인 제어된 대출 시스템을 운영하는 데 막대한 투자가 필요하기 때문에... 공정 사용을 인정한다고 해서 출판사들이 우려하는 최악의 결과가 일어나지는 않을 것""
               o 요약하면 ""저작권자 허락 없이 책을 디지털화하고 배포하는 데 많은 비용이 들기 때문에 우리가 할 수 있어야 한다""는 황당한 주장임
     * 이 외에도 32쪽 분량의 많은 주장이 있지만 핵심 소송과 판결에 관련 없는 것들이 대부분임

여론의 법정에서

     * 인터넷 아카이브는 이 법정 싸움에서 질 운명으로 보임. 한 번 졌고 항소 이유도 약함
     * 사실과 관계없이 감정에 호소하는 공개 성명을 내고 있음
     * 인터넷 아카이브 설립자 Brewster Kahle은 이를 ""도서관의 권리를 위한 싸움""으로 포장하며 말함:
          + ""해결책은 간단합니다. 도서관에 전자책을 팔아 소유, 보존하고 한 번에 한 사람에게 빌려줄 수 있게 하면 됩니다. 이것은 디지털 시대 도서관의 혼을 위한 싸움입니다""
          + 그러나 실제 소송은 실물 책을 디지털화하여 저작권자 허락 없이 배포하는 것이 쟁점이지, 전자책을 도서관에 파는 것과는 큰 관련이 없음
     * 대중을 설득하기 위해 화려한 언어를 사용하고 있지만 이 사건의 사실을 왜곡하고 있음

GN⁺의 의견

     * 인터넷 아카이브가 제기하는 일부 근본적인 질문들은 생각해 볼 가치가 있음
          + 도서관이 책의 공식 디지털 판을 대출할 수 있어야 하는가?
          + 출판사, 작가 등이 도서관에 디지털 판을 제공하도록 강제할 수 있는가?
          + 도서관에서 빌린 디지털 저작물이 허용된 권리 이상으로 복사/배포될 경우 누구의 책임인가?
          + 출판된 디지털 저작물을 도서관이나 출판사가 검열하거나 수정할 수 있어야 하는가?
     * 그러나 이런 문제들은 ""Hachette v. Internet Archive"" 판결의 일부가 아님. 이 사건이 대답한 질문은 단순히 ""물리적 매체를 구매하면 저작권자 허락 없이 디지털화하여 배포할 수 있는가?""이며 대답은 ""아니오""임
     * 이 판결이 유지될 경우:
          + 저작권자들이 인터넷 아카이브에 손해배상을 청구할 수 있음
          + 다른 저작권 문제가 있는 콘텐츠 삭제를 강제당할 수 있음
          + 다른 아카이빙 프로젝트들도 감시가 강화되어 리스크가 높아질 수 있음
     * 물론 인터넷 아카이브가 항소에서 이길 가능성도 있지만 희박해 보임. 설사 이긴다 해도 저작권 정책에 혼란을 가져올 수 있음
     * 인터넷 아카이브는 문화적으로 중요한 자료를 보존하는 귀중한 역할을 하고 있지만, 저작권 문제에 있어서는 무책임한 태도를 보이고 있음. 패소가 유감스럽지만 어쩔 수 없어 보임

        Hacker News 의견

     * 도서관은 전자책 구독에 많은 예산을 사용하고 있음. 출판사들은 전자책을 인쇄본보다 2-3배 비싼 가격에 제공하고, 대여 횟수도 4-6회로 제한하는 등 약탈적인 행태를 보임. 인터넷 아카이브의 도전이 공정 이용에 대한 대중의 인식을 개선하기를 기대함.
     * 인터넷 아카이브의 ""국가 비상사태 도서관"" 프로젝트는 명백한 실수였음. 하지만 계속 싸우다가는 온라인 도서 대여뿐 아니라 훨씬 중요한 나머지 아카이브까지 잃을 위험이 있음.
     * 인터넷 아카이브는 희귀하고 중요한 자료들을 업로드하는 사실상의 기본 저장소가 되었음. 소송에서 패소하면 엄청난 양의 역사가 사라질 수 있음.
     * 기사의 제목과 부제는 인터넷 아카이브의 위기를 암시하고 있지만, 실제로 소송에서 지는 것이 인터넷 아카이브에 어떤 영향을 미칠지는 언급하지 않음. 이것이 가장 중요한 부분인데 아쉬움.
     * 2023년 8월, 소송 당사자들은 인터넷 아카이브가 감당할 수 있는 수준으로 잠재적 비용을 제한하는 합의에 도달했음. 이번 항소로 상황이 악화되지 않기를 바람.
     * 법적 근거와 상관없이, 인터넷 아카이브와 다른 도서관들은 소장 중인 실물 도서를 디지털 사본으로 대여할 수 있어야 함. 특히 공식 전자책 버전이 없는 책들의 경우 더욱 그러함.
     * 인터넷 아카이브의 ""국가 비상사태 도서관"" 무제한 대여 주장이 공정 이용에 해당한다는 주장은 처음부터 설득력이 없었음. 하지만 이 주장이 받아들여지지 않은 것은 사회에 나쁜 선례를 남김.
     * 인터넷 아카이브를 옹호하는 사람들은 감정에 휩싸여 사실을 무시하는 경향이 있음. 하지만 다른 활동과 무관하게 이번 건만 놓고 보면 인터넷 아카이브가 법을 어기고 비웃은 것이 분명함.
     * 인터넷 아카이브에 디스크 공간을 기부하고 싶어하는 사람들이 많을 것임. 하지만 아카이빙 조직들의 관심은 적었음. 아쉬운 일임.
     * 아카이브 사이트 없는 인터넷은 검열된 인터넷임. 브라질 정부가 크리에이터 삭제를 요구하자 한 아카이브 사이트가 브라질에서 접근 불가능해짐.
     * 인터넷 아카이브가 이번 무모한 도전으로 인해 웨이백 머신 등 논란의 여지가 없는 중요한 서비스까지 잃게 될까 우려됨. 법정 밖에서 치명적이지 않은 수준으로 합의할 수 있기를 바람.
     * 인터넷 아카이브의 도서관 프로젝트는 사용하지 않음. 하지만 이 때문에 웹 아카이빙 서비스를 잃을 수도 있다는 점이 우려됨. 두 가지가 분리되어 있으면 좋겠지만, 다른 스냅샷 제공 기관들도 있으니 큰 문제는 아닐 수도 있음.
"
"https://news.hada.io/topic?id=14550","Meta Llama 3 발표후, 첫 일주일간 생긴 일","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Meta Llama 3 발표후, 첫 일주일간 생긴 일

     * 4/18일 Llama 3 모델 공개 이후 개발자 커뮤니티의 반응이 엄청났음
          + 모델이 120만회 이상 다운로드되었고, Hugging Face에서 개발자들이 600개 이상의 파생 모델을 공유했음
          + Llama 3 GitHub 레포지토리가 17,000개 이상의 별을 받았음
          + LMSYS Chatbot Arena 리더보드에서 Llama 3 70B Instruct 모델이 영어 전용 평가에서 1위를 차지했고, 전체적으로는 6위를 기록해 공개된 모델 중 가장 높은 순위를 차지했음 (폐쇄적인 독점 모델에 이어)

Llama 3의 초기 적용 사례

     * 실리콘, 하드웨어, 클라우드 제공업체 파트너들이 Llama 3를 사용자에게 배포하기 시작했음
     * 예일대학교 의과대학에서는 EPFL 컴퓨터 및 통신 과학 학교와 함께 Llama 3 출시 24시간 만에 Llama 3를 파인튜닝해 의학 분야 최초의 Llama 3 8B 모델인 Llama-3[8B]-MeditronV1.0을 소개했음
          + 이 새로운 모델은 MedQA, MedMCQA 등의 표준 벤치마크에서 동일한 파라미터 등급의 모든 최신 오픈 모델을 능가했음
          + 예일대학교와 EPFL이 Llama 2를 기반으로 Meditron의 첫 번째 버전을 구축한 방법에 대한 자세한 내용은 해당 링크에서 확인할 수 있음

Llama 3의 향후 계획

     * 향후 몇 달 동안 멀티모달, 다국어 대화, 더 긴 컨텍스트 창, 전반적인 기능 향상 등 새로운 기능을 갖춘 모델을 공개할 예정임
     * 곧 더 많은 내용을 공유하고 커뮤니티 주도의 혁신의 다음 물결을 볼 수 있기를 기대함

   갈수록 국내 대기업 LLM들은 경쟁력을 잃어 가는군요. 폐쇄형이 전략이라면 성능에서 충분히 경쟁력을 갖추던가, 성능이 떨어져도 활용처 확대가 전략이라면 한글 중심을 내새우지 말던가 해야 하는데 정 반대로 하는 상황이니까요.

   한국어 리더보드에서 의미없는 가중치 경쟁만 하고 그걸로 뉴스 띄워서 주가방어나 하고 있으니 ㅋㅋㅋ

   ㄹㅇㅋㅋ
"
"https://news.hada.io/topic?id=14500","항공사, 취소되거나 지연된 항공편에 대해 승객들에게 환불 의무화","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  항공사, 취소되거나 지연된 항공편에 대해 승객들에게 환불 의무화

항공사, 취소되거나 지연된 항공편에 대해 승객에게 환불 의무화

     * 교통부 장관 Pete Buttigieg는 수요일 새로운 규정을 발표함
     * 이는 교통부 역사상 가장 큰 승객 권리 확대로, 항공사는 더 이상 환불 발급 전 지연 시간을 결정할 수 없음
          + 국내선은 3시간 이상, 국제선은 6시간 이상 지연 시 적용
          + 항공사, 여행사, Expedia나 Travelocity 같은 제3자 사이트에서 구매한 항공권 모두 포함
     * 승객이 대체 교통편이나 여행 크레딧을 수락하지 않고 항공편이 취소되거나 크게 변경되면 환불 받을 자격이 주어짐
     * 수하물이 분실되어 12시간 내 배달되지 않으면 현금 환불해야 함
     * 새 규정에 따르면 7일 이내 환불해야 하며, 승객이 다른 보상 형태를 선택하지 않는 한 현금으로 환불해야 함
     * 항공사는 새 규정을 준수하는데 6개월의 기간이 주어짐

교통부, 승객 보호 강화 중

     * 교통부는 가족 좌석 요금, 휠체어 승객의 안전하고 존엄한 여행 권리 강화, 항공사 사정으로 지연/취소 시 보상 등에 대한 규정도 마련 중
     * Buttigieg 장관은 숨겨진 수수료로 인한 승객 피해 방지로 매년 수십억 달러 절약 예상
     * 지불했으나 제공받지 못한 Wi-Fi, 좌석 선택, 기내 엔터테인먼트 등 부가 서비스 환불 포함

2022년 연말 대규모 운항 중단에 1억 4천만 달러 과징금 부과한 사우스웨스트 항공 사례 언급

     * Buttigieg 장관은 사우스웨스트의 과징금이 항공사와 승객 권리에 대한 ""새로운 기준""을 세웠다고 말함
     * 항공사들이 더 높은 기준을 준수하도록 하는 것이 목표이며, 환불 요건은 이미 항공사의 기준이지만 새 규정으로 승객의 정당한 환불을 보장한다고 강조

미국 항공사 협회의 입장

     * 회원사들은 완전 환불 가능한 항공권 등 다양한 옵션을 제공하며, 소비자는 필요에 가장 적합한 약관의 환불 가능 항공권 옵션을 선택할 수 있다고 밝힘
     * 2020년부터 2023년까지 미국 11대 항공사가 430억 달러 고객 환불을 처리했으며, 작년에만 약 110억 달러를 환불했다고 함

GN⁺의 의견

     * 코로나19 팬데믹 이후 급증한 항공편 지연과 결항으로 인한 승객 불편을 해소하고 권리를 보호하기 위한 조치로 보임. 특히 사우스웨스트 항공 사태 이후 정부 차원의 대응이 필요했던 상황
     * 다만 항공사 입장에서는 추가 비용 부담이 커질 수 있어 반발이 예상됨. 불가피한 결항까지 일률적으로 환불해야 하는 부분은 항공사 경영에 부담이 될 수 있음
     * 유럽연합(EU)은 이미 2004년부터 유사한 규정을 시행 중이며, 3시간 이상 지연 시 최대 600유로의 보상금 지급을 의무화하고 있음. 미국의 이번 조치가 다른 국가로 확대될 지 주목됨
     * 항공 여행객 입장에서는 예기치 못한 지연과 결항으로 인한 금전적 피해를 보상받을 수 있게 되어 환영할 만한 소식. 다만 항공사가 환불 회피를 위해 편법을 쓰지 않을지, 제도의 실효성이 관건이 될 것으로 보임

        Hacker News 의견

   요약해보자면:
     * 최근 항공편 취소로 인해 큰 불편을 겪은 사례들이 많음. 항공사가 제공하는 보상은 제한적이고 고객에게 불리한 조건이 많음.
          + 3개월 내 사용해야 하는 바우처, 동일한 동반자와 함께 여행해야 하는 조건 등
     * 항공사의 고객 응대 미흡과 불친절함도 문제.
          + 연착과 결항 시 숙박과 식사 제공 없이 앱으로 새 항공편 예약하라는 안내만 함.
     * 부당한 대우에 대해 소액재판을 통해 배상 받은 사례도 있음.
     * JetBlue 항공은 제공할 수 없는 서비스를 예약 받고 환불을 거부하다가 신용카드사의 차지백 처리로 환불해준 사례도 있음.
     * 공항 공사로 인한 연착에 대해서도 보상이 필요함.
          + 항공사가 예정된 공사 상황을 알면서도 비현실적인 출발 및 도착 시간을 판매하는 것은 부당함.
     * EU는 연착과 결항에 대해 최대 600유로까지 보상하도록 하고 있음.
          + 기상 상황 등 불가항력은 제외되나 그 범위가 매우 좁음.
     * 이번 규정 변경으로 지방 항공사 일부가 폐업할 수도 있음.
          + 환불보다는 탑승률이 낮은 비행기를 운항하는 것이 손해가 적기 때문.
     * 앞으로 항공사들이 연착을 계속 연장하는 방식으로 대응할 것으로 보임.
     * 유럽은 거리에 따른 의무적 환불 및 보상 규정을 시행 중임.
     * 단거리는 좌석 간격 최소 32인치, 중장거리는 34인치 의무화가 필요함.
"
"https://news.hada.io/topic?id=14512","Ask GN: 이번 주말에 뭐 하시나요?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Ask GN: 이번 주말에 뭐 하시나요?

   이번 주말에 뭘 하려고 계획 중인지 편하게 얘기해 보아요.

   읽을 책, 가볼 곳, 해볼 것.. 어떤 것이든 좋습니다.
   도움 요청이나 피드백 요청도 좋습니다.
   물론! 아무것도 하지 않고 쉬는 것도 훌륭합니다.

   지난 주말에 계획하셨던 일의 회고도 한번 남겨봐 주세요.

   고등학교 친구들과 글램핑 갑니다. 가끔 만나서 고기 굽고 불멍하니까 좋아요 ㅎㅎ

   공연 티켓에 당첨되어서 주말에 공연을 보러갑니다. +_+
"
"https://news.hada.io/topic?id=14554","IRS, 높은 사용자 만족도 주장하며 무료 세금 사이트 갱신 여부 결정 예정","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               IRS, 높은 사용자 만족도 주장하며 무료 세금 사이트 갱신 여부 결정 예정

미국 국세청(IRS)의 무료 세금 신고 웹사이트 '다이렉트 파일(Direct File)' 시범 운영 결과

     * 바이든 행정부는 금요일 국세청(IRS)의 최초 무료 세금 신고 웹사이트가 예산 내에서 개발되었고, 사용자들로부터 높은 평가를 받았다고 발표함
     * 이 소프트웨어는 Intuit나 H&R Block 같은 상용 제품과 유사하며, 납세자가 무료로 정부에 직접 신고할 수 있게 해줌
     * 전문가들은 전국적인 도입이 이뤄지면 수십억 달러 규모의 세금 신고 산업에 혼란을 줄 수 있다고 예상함

다이렉트 파일의 성과

     * IRS 국세청장 대니 워펠은 140,803 가구가 12개 주에서 제한된 소득과 세금 환경을 가진 사람들을 대상으로 한 시범 서비스를 통해 세금 신고를 완료했다고 밝힘
     * 개발 및 운영 기간 동안 Direct File에 1,050만 달러의 개발비와 240만 달러의 운영비가 들었으며, 신고서 처리 당 운영 비용은 17달러, 총 비용은 92달러 수준
     * 하지만 미국 디지털서비스(USDS)나 다른 정부 기관, 소프트웨어 개발에 투입된 인력 비용과 Direct File 외 다른 세금 신고 개선에 필요한 IRS 기술 변경 비용은 포함되지 않음

공화당의 반대와 향후 계획

     * 의회의 공화당 의원들은 이미 반대 의사를 표명함. 상원 재무위원회 청문회에서 공화당 지도부 의원은 Direct File을 ""낭비적이고 중복적""이라고 비판함
     * 행정부 고위 관리는 11월 선거 결과에 상관없이 내년 세금 신고 시즌 갱신 여부를 몇 주 내로 결정할 것이라고 밝힘
     * 워펠 국세청장은 프로그램 갱신 여부를 결정하기 전, 비용과 납세자, 주정부 관리, 소프트웨어 회사와의 인터뷰 내용을 담은 보다 상세한 보고서를 약속함

사용자 반응

     * GSA에 따르면 조사에 응한 Direct File 사용자의 90% 이상이 ""우수"" 또는 ""평균 이상""으로 평가함
     * Economic Security Project에 따르면 사용자의 60%가 1시간 이내에 세금 신고를 완료했다고 하며, 61%는 작년에 사용한 방식보다 더 간단하다고 평가함

GN⁺의 의견

     * 무료 세금 신고 서비스의 도입은 세금 신고의 진입장벽을 낮추고 국민의 세금 납부 부담을 줄이는데 기여할 수 있음. 하지만 세무 소프트웨어 산업 종사자들의 일자리와 관련 산업에 부정적 영향을 미칠 수도 있음
     * IRS의 시스템 개선이 필요하고, 예산과 인력 지원 확대가 뒷받침 되어야 할 것임. 보안과 개인정보 보호에 대한 우려도 해소되어야 함
     * 상용 세무 소프트웨어 업체들은 고급 기능과 자문 서비스 등으로 차별화를 모색해야 할 것임. 오히려 정부 서비스와의 연계를 통해 새로운 사업 기회를 만들 수도 있음
     * 단순히 무료라는 이유로 정부 서비스를 이용하기 보다는, 신뢰성과 안정성, 사용성 등을 종합적으로 고려해 본인에게 맞는 최선의 방법을 선택하는 것이 바람직함

        Hacker News 의견

     * 미국 성인의 54%가 6학년 수준 이하의 문해력을 가지고 있음에도 불구하고, 동일한 인구가 세금을 정확하게 신고할 수 있는 금융 문해력을 갖추고 있을 것으로 기대되는 것이 놀랍다는 의견
     * 미국 의회의 ""토론""을 듣는 것은 화가 났으며, 세금 신고 서비스로부터 금전적 이익을 받은 정치인은 발언권이 없어야 한다는 주장
     * 캐나다에서는 무료 세금 신고 사이트를 통해 2시간 이내에 무료로 부부 세금을 신고할 수 있으며, 대부분의 정보가 사전에 입력되어 있어 편리하다는 경험 공유
     * 모든 사람들은 다른 국가와 마찬가지로 세금 신고가 무료이고 쉬워야 한다는 데 동의한다는 견해
     * 미국 연방 서비스를 이용하려면 id.me 계정이 필요한데, 이는 login.gov의 가치를 인식한 익명의 그룹이 정부가 아닌 자유 자본 시장에 개방되어야 한다고 로비한 결과라는 주장
     * id.me 사이트에서는 비디오 통화, 문서 스캔 등을 요구하며, 계정 생성 후에는 광고주들이 사용자 데이터를 구매할 수 있는 방법에 대한 백서 링크가 있는 쿠폰 클리핑 페이지로 이동한다는 점을 지적
     * 정부가 국민을 위해 일하지 않는다는 것을 상기시키는 많은 것들 중 하나가 세금 신고 시기라는 의견
     * 세금 자동화는 해결된 문제이며, 이 상태가 오랫동안 지속된 유일한 이유는 Intuit의 로비스트들 때문이라는 주장
     * 미국 정부는 삶을 통해 우선순위가 국민이 아님을 반복적으로 보여주었으며, 다음 세대가 선출된 대표들에 대해 훨씬 덜 냉소적으로 자랄 수 있기를 희망한다는 의견
     * 뉴저지 주에는 무료 온라인 사이트가 있지만 뉴욕 주에는 비거주자를 위한 사이트가 없어 우편으로 신고서를 보내야 하는 것이 어리석다는 견해
     * 무료 파일 작성 가능 양식이 영향을 받지 않기를 바라며, 실제로 세금을 신고하기 위해 종이 양식을 우편으로 보내야 하는 것을 원하지 않는다는 의견
     * 종이 세금 양식을 없앨 경우의 절감액을 고려해야 하며, 웹사이트 운영 비용을 상쇄하는지 여부를 묻는 질문
     * 올해 세금 신고에 이 서비스를 사용했으며, 복잡한 오류를 발견하고 수정을 요청했고, 세 번째 제출 후 오류 없이 신고가 수락되었다는 경험 공유
"
"https://news.hada.io/topic?id=14522","Passkeys: 산산조각 난 꿈","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Passkeys: 산산조각 난 꿈

Passkeys에 대한 꿈이 깨진 이유

  꿈

     * 2019년 저자는 Rust를 위한 Webauthn 라이브러리 개발을 시작함
     * 당시에는 이 기술이 암호를 대체할 수 있을 것이라는 낙관론이 있었음
          + 2단계 인증, 암호 없는 인증, 사용자 이름 없는 인증 등을 지원할 수 있을 것으로 기대됨
     * 저자가 개발한 라이브러리는 업계에 큰 영향을 미쳤음

  경고 신호

     * 크롬이 시장을 장악하고 있어서, 크롬이 지원하지 않으면 표준에서 제외되는 문제가 있음
          + Authenticator Selection Extension이 대표적인 예시
     * 미국에서 열리는 대면 회의에서 주요 결정이 이뤄지는 것도 문제
          + 국제적인 참여자들이 배제되는 상황

  하락세

     * 2022년 Apple이 Passkeys를 발표함
          + 초기에는 잘 설계된 것처럼 보였으나, 이후 리더의 발표로 인해 Passkey가 Resident Key로 정의됨
          + 이는 저장 공간이 작은 보안 키를 배제하는 결과를 가져옴
     * 이후 Passkey는 사용자를 플랫폼에 가두는 수단으로 변질됨

  악화되는 상황

     * Chrome과 Safari는 보안 키 대신 caBLE 사용을 강요함
          + 사용성이 매우 떨어지는 방식
     * Android는 Passkey 지원 웹사이트에서 보안 키 사용을 막음
          + 개발자 예제는 구글 Passkey만 사용하도록 유도
     * 사용자들이 Passkey 사용에 많은 어려움을 겪고 있음
          + 버그, 복잡한 과정, 키 유실 등의 문제 발생
     * Apple Keychain에서 Passkey가 삭제되는 일이 빈번히 발생

  전망

     * 저자는 Passkey가 일반 소비자에게는 실패할 것으로 예상함
          + 기업의 이익 추구로 인해 사용자 경험이 훼손됨
     * 심지어 저자의 파트너는 암호 방식이 Passkey보다 낫다고 말함
     * 기업에서는 여전히 보안 키가 필요하지만, 사용성 문제는 남아있음
     * 저자는 webauthn-rs 프로젝트는 계속 유지할 예정이지만, Passkey 대신 다른 방안을 모색 중

GN⁺의 의견

     * Passkey가 보안 키를 배제하고 플랫폼 종속성을 심화시키는 방향으로 흘러가는 것은 우려스러운 지점임. 사용자의 선택권을 제한하는 것은 바람직하지 않아 보임.
     * 기술을 발전시키면서도 사용성을 개선하는 것이 필요해 보임. 지나치게 복잡해지거나 제한적이 되어서는 안될 것 같음.
     * 소수 기업의 영향력이 커지면서 표준화 과정에서 문제가 발생하는 것도 해결이 시급해 보임. 보다 개방적이고 투명한 의사결정 구조가 마련되어야 할 듯함.
     * 대안으로 제시된 디바이스 인증서나 스마트카드 방식은 흥미로워 보임. 기존 Passkey의 한계를 극복하면서도 사용성을 개선할 수 있는 방안이 될 수 있을 것 같음.
     * 아직은 과도기적 단계인 만큼 앞으로도 지속적인 기술 발전과 사용자 피드백 수렴이 이뤄져야 할 것으로 보임. 다양한 이해관계자가 협력하여 보다 나은 인증 체계를 만들어가기를 기대함.

   MICROSOFT INTERNET EXPLORER
   ACTIVE-X

   패스워드 없는 미래가 오고 있다
   크롬에서의 Passkey를 소개합니다

        Hacker News 의견

     * Passkeys에 대한 가장 큰 이슈는 그것들을 제공하는 회사들을 신뢰할 수 없다는 것임. 보안상의 이유로 플랫폼에 잠겨있지만 플랫폼 잠금과 구분하기 어려운 경우가 많음. Apple 기기에서 Passkey를 만들면 해당 기기에서 절대 벗어날 수 없으며 이를 변경할 방법이 없음. 이는 피싱으로부터 안전하지만 Apple이 키를 삭제하거나 iPhone을 버리려면 어떻게 해야 할지 모르겠음.
     * Passkeys에 대한 긴 토론에서는 보안의 ""알고 있는 것"" 부분에 대한 이상한 회피가 보임. 미국에서는 법원과 법 집행기관이 사용자 이름, 지문, 망막 스캔, Face ID 등을 합법적으로 얻을 수 있지만, 뇌에서 무언가를 추출할 권리는 없음. Passkeys는 ""알고 있는 것""을 ""가지고 있는 것""으로 대체하는 것을 선호하는데, 이는 보안에 악몽임.
     * 반대 의견: Passkeys를 사랑함. Firefox 브라우저와 1Password 매니저를 사용하며, iPhone에서는 1Password + Firefox를 사용함. passkeys.directory를 보고 GitHub, Google, Microsoft 등의 로그인을 Passkeys로 전환함. ""Passkey로 로그인""이 아닌 ""Touch ID로 로그인"" 등의 용어가 혼란스러움. 1Password가 기기 간에 Passkeys를 동기화함. 공용 컴퓨터에서 로그인이 필요하면 불편할 수 있지만 그렇게 자주 하지 않음.
     * Passkeys는 아직 명확한 멘탈 모델이 없어서 피하고 있음. 기존 비밀번호 관리자로 생성된 임의의 비밀번호를 사용 중이라 전환할 필요성을 느끼지 못함. 사용자 이름/이메일 + 비밀번호는 이해하지만 ""앱 전용 비밀번호""의 고통을 기억하면 일부 오픈소스/CLI 도구가 Passkeys와 잘 통합되지 않을까 걱정되어 상황이 안정될 때까지 기다리는 게 좋음.
     * Apple Keychain 생태계에 전적으로 투자했으며 여러 Apple 기기를 가지고 있어 Passkeys가 훌륭함. 개발자로서 취약한 SMS 2FA의 한계를 매일 겪고 있음. 사용자들이 쉽게 사회공학적으로 속아 2FA 코드를 넘겨줄 수 있음. Passkeys는 더 안전한 솔루션을 제공해 개발자가 사용자가 CS에 전화해 크게 읽어주는 걸 걱정하지 않아도 됨. SIM 스와핑으로 Passkey가 손상되지 않고, 사기꾼과 Passkey를 공유할 수 없음.
     * 기술자로서 Passkeys가 어떻게 작동하고 더 나은지, 정확히 무엇인지 잘 모르겠음. 보안 기능이 사용자 이름과 비밀번호를 기억하고 안전한 곳에 저장하는 것만큼 간단하지 않으면 작동하지 않음. 장치에 있는 키에 대해 언급되는데 휴대폰과 PC를 모두 사용할 때 어떻게 액세스하는지, 처음에 사용자 이름/비밀번호가 필요한지, 장치에 플러그인해야 하는 키가 필요한지 궁금함.
     * Usernameless는 최적화가 지나친 것 같음. 사용자가 로그인 시 사용자 이름을 사용하는 것이 합리적이고 좋은 일임. 어떤 사용자 이름을 사용하는지 상기시켜 줌. 사용자가 Usernameless Passkey를 사용해 서비스에 액세스하다가 어떤 이유로 Passkey를 잃어버리고 서비스용 사용자 이름도 잊어버려 계정 복구 프로세스를 시작할 수 없는 상황이 발생할 수 있음.
     * Passkeys의 기술적 작동 방식을 모르는 사람들은 다음 구현 가이드를 참고하면 좋음: https://webauthn.guide/ Passkeys에 대한 혐오감이 이해되지 않음. 인증을 위해 공개키 챌린지로 이동하는 것은 웹 보안을 위한 큰 발전임. 각 브라우저/OS는 개인키를 보호하고 백업함. 키를 잃어버려도 ""비밀번호 찾기"" 흐름을 사용해 인증 자격 증명을 재설정할 수 있음.
     * Passkeys 사용을 고려하려면 다음 요구 사항이 충족되어야 함:

    1. 소프트웨어에서 Passkey를 가질 수 있어야 함(보안 문제가 있더라도)
    2. attestation 기능을 비활성화할 수 있어야 함

   Firefox나 Linux의 Chrome에서 WebAuthn 구현이 이러한 요구 사항을 충족하는지는 확인해보지 않았음.
     * 2FA 공간의 발전 상황을 따라가려 노력 중인데 Passkeys가 가장 혼란스러웠음. Passkeys가 차세대 기술이라는 과대광고는 많이 봤지만 실제로 무엇이고 어떻게 작동하는지에 대한 설명은 찾기 어려웠음. 보안키에 저장된 키라는 걸 알고 실망함. 도메인 이름 기반으로 키를 즉석에서 생성하는 아이디어가 마음에 듦. Passkeys의 장점은 웹사이트에서 사용하는 사용자 이름을 기억할 필요가 없다는 것이지만 사소한 장점임.
     * 도메인 이름 기반으로 키를 즉석에서 계산하고 재구성하는 (FIDO2 기반? WebAuthn 기반?) 기술의 공식 이름이 무엇인지 묻는 관련 질문에 대한 답변: https://fy.blackhats.net.au/blog/… 에서 찾았음. 즉석에서 재구성된 키를 ""non-resident credential""이라고 함.
"
"https://news.hada.io/topic?id=14604","Show HN: 영화와 TV 프로그램 스트리밍 서비스 찾기를 도와주는 앱 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Show HN: 영화와 TV 프로그램 스트리밍 서비스 찾기를 도와주는 앱 개발

   이 내용은 현재 상영중이거나 개봉 예정인 영화 목록으로 보입니다. 각 영화마다 어느 국가에서 스트리밍 서비스로 볼 수 있는지에 대한 정보가 포함되어 있습니다. 소프트웨어 엔지니어링과는 직접적인 연관성은 없어 보이므로 별도로 요약할 내용은 없습니다.

        Hacker News 의견

     * 사용자가 국가를 설정할 수 있게 하는 개선 아이디어가 제안됨. 독일에 살면서 VPN을 사용하지 않으려는 사용자에게 아르헨티나 등 다른 국가에서의 시청 가능 여부는 중요하지 않을 수 있음.
     * 시즌 중 일부만 시청 가능한 경우를 처리하지 못하는 문제와 일부 사례에서의 거짓 부정(false negative) 문제도 언급됨.
     * 자막과 오디오 언어로 검색할 수 있는 기능도 제안됨. 이는 다국어 사용 가정과 언어 학습에 유용할 수 있음.
     * 모바일 뷰의 정보 밀도가 낮아서 스크롤이 많이 필요한 점, 타일 탭 시 배경색만 변경되는 점, ""시트콤"" 같은 사전 설정 선택지 부족, 시청 중인 콘텐츠와 유사한 추천 부재 등의 개선점도 지적됨.
"
"https://news.hada.io/topic?id=14563",""제2의 기회"라는 미신","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ""제2의 기회""라는 미신

     * Ian McEwan(이언 매큐언)의 소설에서는 주인공이 단 한 번의 실수를 저지르고, 그것이 영원히 주인공을 따라다니는 패턴이 반복됨
          + 한 소녀가 강간범을 잘못 지목하여 자신을 포함한 세 사람의 인생을 망가뜨림 (Atonement)
          + 한 남자가 다른 사람과 눈길을 주고받았는데, 그 사람이 끈질긴 스토커가 됨 (Enduring Love)
          + 갓 결혼한 부부가 섹스를 제대로 하지 못하거나 못하게 되어, 개인으로서나 부부로서 다시는 예전으로 돌아가지 못함 (On Chesil Beach)
          + 종종 이 실수는 20세기 대부분을 통틀어 반향을 일으킴
     * 이러한 플롯 기법은 진지한 예술가에게 어울리지 않는 것으로 여겨짐
          + McEwan은 현실 생활의 점진성과 난잡함을 반영하지 않는 사건에 집착한다는 비난을 받음
          + Proust가 인간 경험의 느린 축적을 즐기는 반면, McEwan은 단일 사건에 집중함
          + 이는 너무 깔끔하고, 영화화되기 위해 쓰여진 것임
     * 필자는 이제 중년의 또래들을 관찰할 만큼 나이가 들었는데, 그 중에는 실망하고 상처받은 사람들도 있음
          + 필자는 McEwan이 삶을 제대로 묘사한다고 주장함
          + 중년의 놀라움이자 공포는 한 사람의 운명이 하나의 잘못된 판단으로 귀결될 수 있다는 것
     * 젊은이들이 특히 알아야 할 것은 무엇인가?
          + 잘못 결혼하거나, 결혼 자체가 자신에게 맞지 않는데 결혼한 경우, 그 피해가 회복 가능하다고 가정하지 말 것
          + 잘못된 직업을 선택하고 30세 정도에 그것을 깨달은 경우, 돌아갈 길이 있으리라 기대하지 말 것
          + 학교에서 과학 트랙을 선택했는데, 인문학이 자신의 적성이라는 것이 밝혀진 경우에도 인생을 망칠 수 있음
          + 이러한 실수들이 반드시 영원하고 극심한 고통을 야기하는 것은 아니지만, 인생은 경로 의존적이기에 각각의 실수는 다음 선택의 폭을 좁힘
          + 큰 실수나 조기의 실수는 원하는 삶에 대한 모든 희망을 앗아갈 수 있음
     * 조언을 구하는(그리고 돈을 내는) 사람들에게 이에 대해 더 솔직해야 함
          + 조언 산업(자기계발 팟캐스트, CEO 코치, 남성 컨퍼런스 등)의 부상은 대체로 유익했지만, 그 내용의 대부분은 미국적이며 그 나라의 낙관주의를 반영함
          + 만회 불가능한 실수라는 개념은 이 두 번째 기회의 나라에서는 거의 금기시됨
     * 또한 명백한 상업적 이유로, 청중들에게는 모든 것이 잃어버린 것이 아니며, 성인기까지도 여전히 인생을 개척할 수 있다고 말해야 함
          + 연사가 아무리 유명한 사람이라도, ""생각 없이 아이를 낳았나요? 이봐요, 끝났네요""라고 말하는 동기부여 캠프에는 아무도 등록하지 않음
     * 현대적인 이야기에서 실수는 실수가 아니라 ""성장""할 기회이고 ""회복력""을 형성하는 것임
          + 그것은 궁극적인 성공으로 가는 단순한 다리일 뿐이며, 대부분의 경우 그렇게 됨
          + 그러나 40세 사람의 인생은 대부분의 결정의 총합이 아님
          + 때로는 직업적, 때로는 낭만적인 결정 등 불균형적으로 중요한 소수의 결정에 의해 왜곡됨
          + 이러한 것들을 잘못 선택하면, 상황을 만회할 여지는 제로는 아니더라도, 나쁜 소식을 전하기 어려운 문화에 의해 과장될수 있음
     * 축구의 국제적 인기에 대해 Martin Amis는 이렇게 설명함
          + 축구는 보통 한 골로 승부가 결정되는 유일한 스포츠이기에, 순간에 대한 압박이 다른 스포츠보다 더 강렬함
          + 이는 유럽에서 매주 말 입증됨
               o 한 팀이 공을 독점하고, 더 좋은 기회를 만들고, 더 많은 경기를 이기지만, 한 실수로 경기에서 질 수 있음
          + 통계학자들이 말하듯, 축구는 ""어리석은"" 스포츠임
     * 경기장 밖의 삶과 가장 유사하기도 함
          + 나는 인생이라는 또 다른 저득점(Low-scoring) 게임의 중반에 있음
          + 주위 사람들의 고통과 후회를 보면서 동정심을 느끼지만, 그들이 큰 인생의 선택을 얼마나 무심코 했는지에 대해 놀라움을 느낌
          + 이는 아마도 구원과 부활(""궁극적인 두 번째 기회"")의 개념이 문화의 역사적 신앙에 내재되어 있기 때문일 것임
          + 그것을 꿰뚫어 보려면 좀 더 불경스러운 마음이 필요함

GN⁺의 의견

     * 이 기사는 사람들이 인생의 중요한 선택을 할 때 얼마나 무모할 수 있는지에 대해 잘 지적하고 있음. 실수의 영향력이 과소평가되는 경향이 있음을 보여줌
     * 그러나 모든 실수가 치명적이거나 되돌릴 수 없는 것은 아님. 실수로부터 배우고 성장할 수 있는 기회도 있음. 균형 잡힌 시각이 필요함
     * '두 번째 기회'에 대한 맹목적 믿음 대신, 현실적으로 실수의 영향을 인식하고 신중하게 선택하는 것이 중요함
     * 특히 결혼이나 커리어 같은 인생의 큰 결정에서는 더욱 신중해야 함. 이는 개인의 행복뿐 아니라 주변 사람들에게도 큰 영향을 미치기 때문
     * 실수를 하더라도 좌절하거나 포기하기보다는, 그 경험에서 배우고 더 나은 선택을 하기 위해 노력하는 것이 중요함. 필자가 언급한 것처럼 '만회 불가능한' 실수는 많지 않을 것임

   첫 단락에 소개 된 소설 어톤먼트는 사실 키이라 나이틀리가 나왔던 영화로 더 유명하지 않나 싶습니다. 고구마 백개 먹이는 영화....

   경제 위기 후에 가정에서 일어난 일을 자식세대들이 보고 배운 게 있을텐데 현실과 동떨어진 조언이라 생각합니다

  Hacker News 의견

     * 많은 기회를 얻는 사람들이 성공할 가능성이 더 높음. 안전망이 있는 사람들은 사업을 시작할 때 실패하고 다시 시도할 수 있지만, 그렇지 않은 사람들은 ""열심히 노력하지 않았다""고 여겨짐.
     * 하지만 각 결정을 잠재적 실수로 너무 걱정하면 공포에 기반한 마비가 올 수 있음. Sylvia Plath의 ""The Bell Jar""에서 설명된 무화과나무의 비유처럼, 모든 선택지를 원하지만 하나를 선택하면 나머지를 잃게 되는 딜레마에 빠질 수 있음.
     * 대학시절 잘못된 결정을 내렸다고 생각하는 한 친구의 사례가 소개됨. 주변 사람들은 그의 이야기를 성공적인 분야 전환으로 보지만, 친구 자신은 과거의 결정이 영원히 자신을 쫓아다닐 것이라고 생각함.
     * Michael Pollan의 책 ""How to Change Your Mind""에서는 우울증이 자기 처벌의 일종이며, 반복적 사고의 고리에 빠져 파괴적이 될 수 있다고 설명함. 자신에 대한 이야기를 조정하여 더 힘 있는 이해를 갖는 것이 중요함.
     * 과거의 삶의 선택에 의해 불행의 감옥에 갇힌다는 암시는 패배주의적이고 비겁한 말임. 용기를 내어 과거를 놓아주어야 함.
     * 인생에는 행복으로 이끄는 최적의 경로가 있고, 이에서 벗어나면 행복을 잃는다는 것은 신화임. 실수는 예상치 못한 길로 인도할 수 있지만, 새로운 기회의 문을 열어줄 수도 있음.
     * 우리는 한 번의 인생만 살기에 어떤 결정이 최선인지 확신할 수 없음. 큰 실수도 있지만, 대개 사소한 결정들이 모여 ""큰 순간""을 만듦. 운명을 사랑하는 법을 배워야 함.
     * 결국 이런 생각들은 도움이 되지 않음. 앞으로 더 많은 생산적인 시간이 있음. 원하는 것을 찾아 매진하는 것이 중요함.
     * Robert Frost의 ""The Road Not Taken""은 충동을 의도적 결정으로 바꾸는 시인의 사후 내러티브에 관한 것임. 삶은 극적인 행동보다는 구성된 내러티브를 통해 펼쳐짐.
     * 경험상 삶에서 기회의 수는 제한 요인이 아님. 사람들은 같은 실수를 반복하는 경향이 있는데, 문제는 외부 요인에 대한 반응 패턴임. 이 패턴을 깨는 것이 어려움.
"
"https://news.hada.io/topic?id=14589","Rabbit R1: 안드로이드를 후드 아래에서 실행하는 AI 구동 장치","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Rabbit R1: 안드로이드를 후드 아래에서 실행하는 AI 구동 장치

   • 래빗 R1은 AI로 구동되는 휴대용 기기로 스마트폰에 비해 기능이 제한적이라는 비판을 받아왔다. 많은 리뷰어들은 그러한 가제트들이 별도의 하드웨어 장치 대신 앱으로 출시되어야 한다고 주장한다.

   • 래빗 R1은 AI 기능에도 불구하고 질문에 답하기, 정보를 위한 사진 찍기, 음악 재생, 우박 놀이기구, 음식 주문 등 안드로이드 앱으로 복제할 수 있는 작업만 수행할 수 있다.

   • 래빗 R1은 실제로 안드로이드를 실행하고 전체 인터페이스는 단일 안드로이드 앱으로 구동되는 것으로 나타났다. 이 폭로는 기업들이 단순히 앱을 출시할 수 있는데 왜 기능이 제한된 고가의 하드웨어를 만드는지에 대한 의문을 제기한다.

   • 래빗 R1의 런처 APK를 안드로이드 폰에 설치하면 스마트폰에 기기의 기능을 복제할 수 있어 많은 틈새 하드웨어 제품이 안드로이드의 수정된 버전을 기반으로 한다는 사실을 강조한다.
"
"https://news.hada.io/topic?id=14529","애플의 폐쇄적 생태계(walled garden) 붕괴 조짐","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    애플의 폐쇄적 생태계(walled garden) 붕괴 조짐

아이폰의 몰락

     * 아이폰 초기(2008년경)에는 모바일폰 시장에서 점진적으로 지배적인 위치를 차지하게 된 흥미롭고 강력한 새로운 기술이었음
     * 그러나 최근 몇 년 동안 새로운 아이폰 출시에 대한 흥분은 혁신적인 기기라기보다는 그저 또 다른 범용 휴대폰으로 여겨지면서 사그라들었음
     * IDC에 따르면 지난 7년 동안 6년 동안 스마트폰 판매량이 감소했는데, 이는 기기 내구성 향상과 사람들이 2~3년마다 휴대폰을 교체해야 한다는 절박함을 덜 느끼게 된 것 등이 원인임

아이폰 매출에 대한 애플의 의존

     * 다각화 노력에도 불구하고, 애플은 여전히 다른 제품 및 서비스에 비해 아이폰 판매에서 불균형적으로 많은 매출(절반 이상)을 올리고 있음
     * 2024년 1분기 애플의 총 매출 1,196억 달러 중 아이폰 판매액은 697억 달러였음
     * 이는 전반적인 스마트폰 시장이 하락할 때 애플이 다각화된 다른 대형 기술 기업에 비해 취약할 수 있음을 의미함

애플의 폐쇄적 접근 방식

     * 아이폰이 지배력을 확보함에 따라 애플은 독점적인 기능과 서비스(앱스토어, iMessage, FaceTime, Apple Wallet 등)의 생태계 구축에 주력했음
     * 애플은 사용자를 자사 플랫폼에 묶어두기 위해 의도적으로 상호운용성을 제한했음(예: 안드로이드에서 iMessage 사용 불가)
     * 앱스토어도 강력하게 통제되어 애플이 앱 판매 및 인앱 구매에 대해 30%의 수수료를 받는 한편 개발자에게 제한을 두었음
     * 시간이 지나면서 애플은 비판에 대응하여 부분적인 정책 변화를 만들었지만, 개발자들은 이를 혼란스럽고 불공정하다고 생각함

반독점 압력 증가

     * 애플의 제한적 관행으로 인해 미국과 EU에서 반독점 소송과 조사가 이루어졌음
     * 에픽게임즈는 2020년 앱스토어 수수료 구조에 대해 애플을 고소했고, EU의 규제 당국은 대형 기술 기업을 규제하는 법안을 통과시켰음
     * 2023년 미국 법무부는 애플이 스마트폰 시장에서 불법적인 독점 행위를 했다며 반독점 소송을 제기했음
     * 애플은 제3자 앱스토어와 결제 방식을 허용하는 등 일부 변화를 시작했지만, 개발자와 규제 당국의 반발은 계속되고 있음
     * 1990년대 후반과 2000년대 초반 마이크로소프트의 반독점 분쟁과 법적 분쟁이 엄청난 방해물이 된 것에 비유됨

GN⁺의 의견

     * 애플의 폐쇄적 생태계 전략은 단기적으로는 매출 증대에 도움이 되었지만, 장기적으로는 반독점 소송 등의 위험 요인이 되고 있음. 구글의 안드로이드 진영처럼 개방형 플랫폼으로 전환하는 것도 하나의 대안이 될 수 있을 것 같음.
     * 아이폰의 혁신성이 약해지면서 소비자들의 관심도 예전같지 않음. AR/VR 등 미래 기술에 대한 투자를 늘리고, 애플카 등 새로운 제품군 개발에도 더욱 박차를 가할 필요가 있어 보임.
     * 아이폰에 편중된 매출 구조는 리스크가 큼. 애플워치, 에어팟 등의 웨어러블 기기나 Apple TV+ 등의 구독형 서비스를 더욱 강화해 아이폰 의존도를 낮추는 것이 중요해 보임.
     * MS의 90년대 반독점 사례에서 보듯 플랫폼 기업에 대한 규제 압박은 더욱 거세질 것으로 보임. 개발자 친화적인 정책 변화, 인터넷 표준 준수 등을 통해 선제적으로 대응해 나가는 것이 바람직할 것 같음.

  Hacker News 의견

     * 아이폰의 성공은 북미 이동통신 산업의 신뢰할 수 없는 재앙과 AT&T와의 계약에 일부 기인함
     * 안드로이드는 초기에 통신사 맞춤화를 위해 설계되었지만, 통신사의 수정을 배제하는 것이 최종 사용자를 위한 적극적인 기능이 되었음
     * 기술 산업의 탐욕에 몰두하는 일부 개발자는 신뢰할 수 없음
     * 네이티브 스마트폰 앱은 실수였을 수 있으며, PWA 패키지가 유통 독점 문제를 해결하고 기기 간 일관된 앱 표준을 만들 수 있음
     * 규제 당국은 애플과 같은 회사에 대해 조치를 취하는 데 느리며, 이는 폐쇄적 생태계 구축에 효과적으로 기여함
     * 기사는 애플의 고객 묶어두기 효과를 과장했을 수 있음. iOS나 안드로이드 생태계에 많이 투자한 사용자는 전환에 필요한 노력 때문에 주저함
     * 에픽과 스포티파이가 제기한 문제에 대해 기술 산업 외부의 대부분의 사람들은 모르거나 신경 쓰지 않으며, 이들은 이타적인 목표가 아닌 자신의 이익을 추구하고 있음
     * 아이폰은 평균 소비자에게 일관되고 안정적인 경험을 제공하며, 애플의 앱은 오래되고 지원되지 않는 기기에서도 작동함
     * 통신 기술에서의 중앙 집중식 시장 지배력은 잠재적인 미래 정치적 검열과 정보 통제에 대한 우려를 제기함
     * 안드로이드/윈도우에서 애플 기기로 전환하는 것은 두려워할 만큼 어렵지 않을 수 있으며, 구글 서비스와 기타 익숙한 앱을 계속 사용할 수 있음
     * 소셜 네트워크, 3D 프린팅, VR/AR 등의 아이디어가 사그라들거나 성숙 단계에 이르면서 ""기술의 시대정신""이 끝나가는 것일 수 있음. AI는 절박함에 의해 추진될 수 있는 주요 예외임
     * 아이폰이 상품화됨에 따라 초점은 앱으로 이동함. 애플이 휴대폰 수명주기를 넘어설 수 있는 킬러 소셜미디어나 검색 앱을 만드는 데 투자하지 않은 것은 놀라운 일임
"
"https://news.hada.io/topic?id=14601","Kolmogorov-Arnold 네트워크 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Kolmogorov-Arnold 네트워크 개발

Kolmogorov-Arnold Networks (KANs) 소개

  KAN의 정의와 특징

     * Kolmogorov-Arnold Networks (KANs)는 Multi-Layer Perceptrons (MLPs)의 유망한 대안임
     * KANs는 MLPs와 마찬가지로 강력한 수학적 기반을 가지고 있음
          + MLPs는 universal approximation theorem에 기반함
          + KANs는 Kolmogorov-Arnold representation theorem에 기반함
     * KANs와 MLPs는 서로 쌍대(dual)임
          + KANs는 엣지(edge)에 활성화 함수(activation function)를 가짐
          + MLPs는 노드(node)에 활성화 함수를 가짐
     * 이러한 단순한 변화로 인해 KANs는 모델의 **정확도(accuracy)**와 해석력(interpretability) 측면에서 MLPs보다 더 나은 (때로는 훨씬 더 나은) 성능을 보임

  KAN의 정확도

     * KANs는 MLPs보다 더 빠른 스케일링(scaling)을 보임
     * KANs는 더 적은 매개변수로도 MLPs보다 더 나은 정확도를 보임
     * 예제
          + 기호식(symbolic formula) 피팅
          + 특수 함수(special function) 피팅
          + 편미분 방정식(PDE) 해결
          + catastrophic forgetting 회피

  KAN의 해석력

     * KANs는 직관적으로 시각화될 수 있음
     * KANs는 MLPs가 제공할 수 없는 해석력과 상호작용성을 제공함
     * KANs를 사용하면 잠재적으로 새로운 과학 법칙을 발견할 수 있음
     * 예제
          + 기호식 해석
          + 노트(knot)의 수학적 법칙 발견
          + Anderson localization의 물리 법칙 발견
          + 3계층 KAN 학습 과정 해석

  설치 방법

     * pypi 또는 github를 통해 pykan을 설치할 수 있음
     * github를 통한 설치 방법 제공
     * pypi를 통한 설치 방법 제공
     * 요구사항 명시 및 요구사항 설치 방법 제공

  계산 요구 사항

     * 튜토리얼의 예제는 일반적으로 10분 미만의 단일 CPU에서 실행 가능함
     * 논문의 모든 예제는 하루 미만의 단일 CPU에서 실행 가능함
     * PDE를 위한 KANs 학습은 가장 계산 비용이 크며 단일 CPU에서 수 시간에서 수 일이 걸릴 수 있음
     * 매개변수 스윕(sweep)을 수행하여 파레토 프런티어(Pareto Frontier)를 얻기 위해 CPU를 사용하여 모델을 학습시킴
     * 작업 규모가 큰 경우 GPU 사용이 권장됨

  문서

     * 문서는 링크된 URL에서 찾을 수 있음

  튜토리얼

     * 퀵스타트: hellokan.ipynb 노트북으로 시작
     * 더 많은 데모: tutorials에서 더 많은 노트북 튜토리얼을 찾을 수 있음

  인용

     * 논문 인용 방법 제공

  연락처

     * 질문이 있는 경우 zmliu@mit.edu로 연락 가능

GN⁺의 의견

     * KAN은 MLPs의 대안으로서 수학적 기반이 있고, 정확도와 해석력 측면에서 이점을 가지는 흥미로운 신경망 구조임. 다만 아직 초기 연구 단계로 보이며, 대규모 데이터셋이나 복잡한 태스크에서의 성능 검증이 더 필요해 보임.
     * MLPs에서는 노드에 활성화 함수를 두는 반면, KANs에서는 엣지에 활성화 함수를 두는 것이 핵심적인 차이점임. 이로 인해 네트워크 구조와 학습 방식에서 어떤 변화가 생기는지 자세히 분석해 볼 필요가 있음.
     * KANs의 해석력은 인공지능의 블랙박스 문제를 해결하는데 도움이 될 수 있음. 새로운 과학 법칙 발견에 활용 가능성도 흥미로운 부분임. 다만 해석 가능한 인공지능 분야에서 이미 다양한 연구가 진행 중이므로, 차별화된 접근 방식의 강점을 부각할 필요가 있어 보임.
     * 논문에서 제시된 예제는 주로 수학/과학 분야에 국한되어 있음. KANs가 이미지, 자연어 등 다양한 도메인에서도 MLPs를 대체할 수 있을지는 추가 연구가 필요해 보임.
     * KANs와 유사한 접근 방식으로 Capsule Networks, Graph Neural Networks 등이 있음. 이들과의 비교 연구를 통해 KANs만의 강점을 확인해 볼 필요가 있음.

        Hacker News 의견

     * 한 사용자가 PyTorch를 이용해 논문의 아이디어를 간단히 구현한 것을 소개함. 핵심은 단 몇 줄의 코드로 구성되며, 1차원 함수를 보간하기 위해 스플라인 대신 푸리에 계수를 사용함. 이는 Kolmogorov-Arnold 네트워크의 표현력을 보여주며, 논문의 스플라인 버전보다 수렴이 쉬울 수 있으나 연산량은 더 많음.
     * 다른 사용자가 제공된 주피터 노트북을 실험해 본 결과를 공유함. 분류 문제에서 네트워크 구조를 (2, 2)에서 (2, 2, 2)로 변경하자 일반화에 실패했으며, 훈련 데이터 크기를 100배로 늘리면 과적합은 개선되나 훈련 손실이 1e-2 아래로 내려가지 않음. 더 큰 규모의 예제와 데이터로 실험해 보고 싶어함.
     * 최근 트랜스포머의 점진적 개선에 지친 분위기 속에서, 이 연구가 기존 DNN의 표현력을 높일 수 있는 신선한 아이디어를 제시했다는 점을 높이 평가함. 실제 성능 향상 여부는 앞으로 검증이 필요함.
     * 알고리즘 자체의 확장성(더 많은 레이어로도 잘 학습되는지)과 하드웨어 가속 활용 가능성(가중치별 활성화 함수 구조가 빠른 행렬 곱 가속을 활용할 수 있을지) 측면에서 대규모 적용 시 어떤 결과를 보일지 아직 불분명함. 작은 규모에서는 흥미로운 특성을 보이나 ImageNet이나 LLM 같은 태스크에 적합한 구조인지는 추가 연구가 필요함.
     * Kolmogorov-Arnold 표현 정리와 MLP가 거의 동시기인 1957년과 1958년에 발견/발명되었다는 점이 흥미로움. 이 접근법은 MLP의 가중치, 편향, 전역 활성화 함수 대비 오직 하나의 파라미터 종류(국소 활성화 함수의 계수)만 가진다는 장점도 있음. Transformer 일색인 요즘, 이 접근법을 Diffusion Model에 적용해 보고 싶어 하는 의견도 있음.
     * Kolmogorov 신경망이 불연속 함수도 표현할 수 있다는 점은 흥미롭지만, 실제 적용 가능성에 대해서는 의문이 있었음. 이 레포지토리는 어느 정도 활용 가능성이 있음을 보여줌.
     * 성급한 의견일 수 있으나, B-spline의 선형 조합이 더 높은 차수의 B-spline이 되므로, 이는 단순히 고차 B-spline을 함수에 피팅하는 것이 아닌가 하는 견해도 있음.
     * Preprint에서 입력 차원이 100인 것을 ""고차원""으로 간주하고, 대부분의 문제가 5차원 이하인 것은 ML에서 고려되는 물리 영감 환경의 전형적인 모습임. 현대적 기준으로는 매우 작은 784차원에 불과한 MNIST에서의 성능 검증이 다음 단계가 될 것임.
     * 스플라인을 의사결정 트리에 쑤셔 넣은 것 같다는 느낌을 주기도 함.
     * 유한 요소법과 개념적으로 매우 유사해 보이며, 이렇게 분야 간 유사 패턴을 발견하는 것이 반가움.
"
"https://news.hada.io/topic?id=14583","Memary - 자동화 에이전트를 위한 롱텀 메모리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Memary - 자동화 에이전트를 위한 롱텀 메모리

     * 현재 에이전트는 정해진 컨텍스트 윈도우로 제한된 LLM을 사용함
     * Memary는 에이전트가 지식 그래프에 대량의 정보를 저장하고 메모리 모듈을 통해 사용자 지식을 추론하며 의미 있는 응답을 위해 관련 정보만 검색할 수 있도록 함으로써 이러한 한계를 극복
     * 제공 기능
          + 라우팅 에이전트: ReAct 에이전트를 활용하여 여러 도구에서 실행할 쿼리를 라우팅
          + 지식 그래프 생성 및 검색: Neo4j를 활용하여 나중에 검색할 수 있도록 에이전트 응답을 저장하는 지식 그래프를 생성
          + 메모리 스트림: 엔티티 추출을 사용하여 지식 그래프에 저장된 모든 엔티티를 추적. 이 스트림은 사용자의 폭넓은 지식을 반영
          + 엔티티 지식 저장소: 메모리 스트림의 모든 엔티티를 그룹화하고 순서를 지정하여 상위 N개의 엔티티를 컨텍스트 창으로 전달. 이 지식 저장소는 사용자의 지식의 깊이를 반영

   메인 컨트리뷰터가 한국분이시군요 ;)
"
"https://news.hada.io/topic?id=14598","Freeter - 모두를 위한 오거나이저 앱 오픈소스","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Freeter - 모두를 위한 오거나이저 앱 오픈소스

     * 프로젝트 기반의 할일 관리 도구. 프로젝트와 태스크간 빠른 전환
     * 맥,윈,리눅스 바이너리 제공 (Typescript + Electron)
     * 위젯으로 필요한 모든 것들을 빠르게 접근
          + 파일 오프너 : 프로젝트에 관한 모든 파일과 폴더를 한번에 열기
          + 웹 쿼리 : 템플릿 기반의 쿼리로 검색엔진 및 다른 웹사이트에서 검색
          + 웹페이지 위젯 : 다양한 웹앱과 연동하고 워크플로우에 임베드 가능
               o 구글 캘린더/드라이브/닥스, 드랍박스, Jira, Trello, Mixpanel, Hootsuite, Ghost, Medium, Wordpress 등
          + Commander 위젯 : 터미널에 자주 입력하는 명령을 한번 클릭으로
          + ToDo, Timer, Note
     * 탭기반 멀티 워크플로우 관리
     * Shelf 기능으로 자주 쓰는 프로젝트, 워크플로우, 위젯등 올려놓기
     * 글로벌 핫키 지원 : Ctrl/⌘ + Shift + F

   그냥 트렐로건 슬래이건 임베딩해버리네요..??

   처음보면 이게 뭘까 싶었는데.. 실제 구성을 해보니.

   아...! 아...! 아...!

   뭔가 괜찬을거 같기도 한데.. 뭔가.. 뭔가.. 뭔가.. 실제 사용 예시가 많이 필요할거 같습니다.
"
"https://news.hada.io/topic?id=14532","애플, 아무런 설명 없이 사용자들의 애플 ID 접속 차단","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    애플, 아무런 설명 없이 사용자들의 애플 ID 접속 차단

Apple ID 로그아웃 및 계정 잠금 문제 발생

     * 4월 28일 금요일 저녁, 다수의 Apple 사용자들이 여러 기기에서 동시에 Apple ID에서 로그아웃되고 계정이 잠기는 문제가 발생함
     * 로그아웃된 후 기존 Apple ID 비밀번호로 로그인을 시도하면 계정에 접근할 수 없게 되며, 비밀번호 재설정 후에야 다시 로그인이 가능함
     * 이 문제가 발생하는 원인은 아직 명확하지 않음

  문제 현황

     * 9to5Mac에서는 오후 8시경 첫 제보를 받았으며, 이후 소셜 미디어에서 관련 보고가 크게 증가함
     * Apple의 시스템 상태 웹페이지에는 현재 서비스 이상이 표시되지 않고 있음
     * 9to5Mac 내부에서도 일부 직원이 직접 영향을 받음

  관련 이슈 및 우려사항

     * 최근 몇 주 동안 발생한 지속적인 비밀번호 재설정 공격 문제와의 연관성은 현재로서는 불분명함
     * 도난 기기 보호(Stolen Device Protection) 기능을 사용 중인 경우, 신뢰할 수 있는 위치에서 멀리 떨어져 있을 때 Apple ID에서 갑자기 로그아웃되면 특히 큰 문제가 될 수 있음
     * Apple ID 비밀번호를 재설정하면 iCloud를 통해 이전에 설정한 모든 앱 전용 비밀번호도 함께 재설정됨

  추가 정보

     * 이 문제에 대해 Apple에 더 자세한 정보를 요청했으며, 답변이 오면 업데이트할 예정임
     * 독자 여러분도 오늘 밤 기기에서 Apple ID 로그아웃을 경험했는지 댓글로 알려주시기 바람

   이 글의 요약은 다른 글과 섞인걸까요? 전혀 다른 내용이 요약으로 들어가 있네요
   아무튼 전에 구글 계정 잠겨서 일상이 난리난 사람 이야기도 읽은 적이 있는데 제대로 된 대응 고객센터가 없는건 진짜 문제 같습니다

   크롤링할때 잠시 오류가 있었나 보네요. 수정해두었습니다. 감사합니다.

        Hacker News 의견

     * 여러 사용자들이 iPhone을 구매하고 앱을 다운로드한 후 갑자기 계정이 잠기는 문제를 겪음. 고객 지원에 연락해도 제대로 해결되지 않고 오히려 영구 차단당하는 경우도 있음.
     * Apple, Google, Facebook 등 대형 인터넷 기업들이 고객 지원 서비스를 거의 제공하지 않는 점이 놀랍고, 사용자들은 이를 받아들일 수밖에 없는 상황임. 이런 플랫폼에서 차단당하면 큰 영향을 받을 수 있음.
     * 기업들이 계정 잠금 프로세스를 더 투명하게 공개하고 도움을 받을 수 있는 방법을 제공하도록 강제할 필요가 있음. Google이나 Facebook의 경우 직접 연락할 방법을 찾기 어려움.
     * iPad의 인증기가 고장 나서 Apple에 연락했지만 3주 뒤에나 지원 전화를 준다고 하고, 막상 전화해도 자동 음성 메시지만 나오는 등 제대로 지원받기 힘듦.
     * Apple 개발자 프로그램 등록도 3개월 넘게 진행 중인데 진척이 없고, 고객 서비스에 연락해도 딱히 도움이 안 됨. 잘못한 게 없어도 해결책이 없다는 걸 깨달으니 의욕이 떨어짐.
     * @icloud.com을 주 이메일로 사용하는 사람들의 계정이 자주 잠기는데, 비밀번호 대입 공격 때문으로 보임. 복구 연락처와 복구 키를 미리 설정해 두는 게 좋음.
     * Apple의 고객 지원이 형편없다는 건 다들 경험으로 알고 있지만, 세계 최고 부자 기업이 의도적으로 이런 결정을 내린 걸 옹호하는 사람들이 이해가 안 됨.
"
"https://news.hada.io/topic?id=14536","Mac에서의 멀티 디스플레이 사용 불편","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Mac에서의 멀티 디스플레이 사용 불편

Mac 운영 체제의 멀티 디스플레이 지원 문제점

  앱 재실행 시 윈도우 위치 기억 못함

     * Mac 운영 체제는 앱을 다시 실행할 때 윈도우가 있던 위치를 기억하지 못하는 문제가 30년간 계속되고 있음
     * 한 달 정도는 괜찮았으나 그 후로는 부팅할 때마다 모든 윈도우가 메인 디스플레이에 겹쳐서 열리는 현상 발생
     * 수동으로 윈도우들을 옮겨줘야 하는 불편함이 반복됨

  전체화면 앱의 보조 디스플레이 처리 미흡

     * 게임 등 전체화면 앱 실행 시 보조 디스플레이를 무시하고 밝기 그대로 두는 문제
     * 앱 실행/종료 때마다 보조 디스플레이 밝기를 수동 조정해야 함
     * 보조 디스플레이 전원을 껐다 켜면 macOS가 혼란스러워 하고 앱이 크래시되기도 함

  Dock을 화면 옆에 두기 어려움

     * 여러 개 디스플레이에서는 Dock이 맨 끝에 있는 디스플레이에만 나타나 사용이 불편함
     * 하단에 Dock을 두면 윈도우 크기 조절, 툴바, 스크롤바 등을 가려 작업이 방해됨

  멀티 디스플레이에서 메뉴바 사용성 저하

     * 자동 숨김 설정한 메뉴바가 활성화된 디스플레이에서만 나타나 마우스 이동이 잦아짐
     * 앱 실행 중일 때는 메뉴바가 나타나지 않아 커서 위치 때문인지 앱 때문인지 혼동

  윈도우가 엉뚱한 화면에 나타나는 문제

     * 모달 다이얼로그가 기존 윈도우 뒤에 가려지는 등의 버그가 있음

  멀티 디스플레이 사용 시 인체공학적 불편함

     * 두 디스플레이 사이 공간이 시선을 자연스럽게 방해
     * 키보드, 마우스와 디스플레이 불일치로 타이핑, 마우스 정확도 저하
     * 중앙을 벗어난 곳을 계속 봐야해서 목이 아픔

  여러 디스플레이에 작업 분할의 어려움

     * 한 화면의 나란한 두 윈도우와 달리 분리된 디스플레이 간 작업은 훨씬 불편
     * 눈과 고개 움직임의 차이가 원인으로 보임
     * 중요한 작업은 주 디스플레이에 놓게 되고 보조 디스플레이는 잘 안쓰는 것들 모아두는 곳이 됨
     * 보조 디스플레이가 오히려 주의를 산만하게 할 수 있음

GN⁺의 의견

     * 필자가 35년 넘게 맥 사용자였다는 점에서 이런 불편함이 단순히 사용법 문제가 아님을 알 수 있음. 애플이 멀티 디스플레이 사용성 개선에 소홀했던 것으로 보임.
     * 해상도나 컬러 정확도 같은 디스플레이 자체 성능도 중요하지만, 운영체제 레벨에서의 안정성과 편의성이 사용자 경험에 큰 영향을 미침. 고가의 하드웨어를 갖추는 것 만으로는 부족함.
     * 맥 사용자들이 개발한 써드파티 윈도우/디스플레이 관리 유틸리티들이 많다는 건 이 부분에 대한 니즈가 크다는 반증. 근본적인 문제 해결을 위해서는 애플의 노력이 필요해보임.
     * 자신에게 맞는 최적의 작업 환경을 찾기 위해서는 시행착오가 불가피함. 필자처럼 다양한 레이아웃을 시도해보고 장단점을 파악하는 과정이 도움될 듯.
     * 고해상도 울트라 와이드 디스플레이가 대안이 될 수 있을 것 같은데, 아직 픽셀 밀도가 부족한 게 아쉬움. 앞으로 관련 기술이 발전하면 멀티 디스플레이의 불편함을 해소하는데 기여할 것으로 기대됨.

        Hacker News 의견

     * Mac OS의 멀티 디스플레이 지원이 예전보다 후퇴한 것 같음. 20년 전에는 서로 다른 해상도와 색심도의 모니터 간에도 윈도우가 자연스럽게 이동할 수 있도록 많은 노력을 기울였지만, 지금은 윈도우가 하나의 디스플레이에만 표시됨.
     * 멀티 디스플레이 문제는 OS만의 문제는 아님. 예기치 않은 이벤트로 화면이 켜지고 꺼질 수 있고, 앱 개발자들이 OS에 책임을 떠넘기는 경우도 있어서 해결하기 어려운 제약 조건이 있음.
     * 모니터 대기 모드 후에도 윈도우 위치가 이동하는 문제를 해결하기 위해 AppleScript로 작업 상황별로 윈도우 위치를 설정하는 스크립트를 만들어 단축키로 호출하는 방법이 제안됨.
     * 화면이 뒤바뀌는 문제, 배경화면이 계속 바뀌는 문제, 기본 해상도 사용의 어려움 등 다양한 불만 사항이 제기됨.
     * displayplacer, Phoenix, Rectangle 등의 서드파티 도구를 활용하면 모니터 배치 설정, 윈도우 이동과 크기 조정 등을 자동화할 수 있음.
     * 프로모션 디스플레이에서 데스크탑 전환 애니메이션 속도가 느린 문제는 애플에 1년 넘게 알려졌지만 아직 해결되지 않음.
     * 결국 Mac, Windows, Linux 모두 멀티 디스플레이 지원에 어려움을 겪고 있음. AI와 LLM으로 기술 노동자들을 대규모로 대체할 수 있을지 모르지만, 디스플레이 2개만 연결해도 컴퓨터가 제대로 작동하지 않는 상황임.
"
"https://news.hada.io/topic?id=14516","TSMC, 백사이드 전력 공급을 도입한 1.6nm 공정 기술 공개","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  TSMC, 백사이드 전력 공급을 도입한 1.6nm 공정 기술 공개

     * TSMC가 최첨단 1.6nm급 공정 기술 발표함. 앵스트롬급 첫 양산 공정으로, 전 세대 N2P 대비 큰 폭의 성능 개선 약속함. 가장 중요한 혁신은 BSPDN(Backside Power Delivery Network)이 될 것임.

TSMC 1.6nm 공정의 주요 특징

     * 2nm급 노드와 마찬가지로 GAA(Gate-All-Around) 나노시트 트랜지스터 사용
     * 백사이드 파워 딜리버리 기술인 Super Power Rail 도입
     * 트랜지스터와 BSPDN 혁신으로 N2P 대비 동일 전압에서 최대 10% 높은 클럭, 동일 클럭/복잡도에서 15~20% 낮은 전력 소모 가능
     * 실제 설계에 따라 N2P 대비 7~10% 높은 트랜지스터 밀도 구현 가능

SPR(Super Power Rail)의 특징

     * AI/HPC 프로세서에 최적화된 정교한 BSPDN 기술
     * 트랜지스터 소스/드레인에 특수 컨택트로 연결해 저항 감소시켜 최대 성능/효율 달성
     * 인텔 Power Via보다 더 복잡한 BSPDN 구현 방식 중 하나

TSMC의 공정 전략

     * BSPDN 도입으로 공정 비용 크게 상승해, N2P/N2X에는 미적용
     * GAA 적용한 2nm급 노드와 GAA+SPR 적용 1.6nm급 노드로 서로 경쟁하지 않으면서 장점 차별화한 포트폴리오 구성

양산 일정

     * A16 양산은 2026년 하반기 시작 예정. 실제 제품은 2027년 출시 전망
     * 인텔 14A 노드와 경쟁 구도 예상

GN⁺의 의견

     * 1.6nm 공정은 트랜지스터 밀도 향상 외에 백사이드 전력 공급 기술로 성능/효율 개선에 초점을 맞춘 것으로 보임. 특히 AI/HPC 프로세서 등 고성능/저전력이 중요한 제품군에 최적화된 기술임.
     * 단, 복잡한 BSPDN 구현으로 공정 비용이 크게 오를 것으로 예상됨. 이에 TSMC는 2nm급과 1.6nm급 노드를 차별화해 고객 니즈에 맞는 포트폴리오를 제시하는 전략으로 보임.
     * 인텔도 비슷한 시기 14A 노드 도입 예정이라 선두 경쟁이 치열해질 전망. 두 회사의 기술 혁신 속도와 생산 능력 확충이 시장 주도권 확보에 중요한 변수가 될 것으로 보임.
     * 다만 최첨단 공정일수록 개발 지연 리스크가 높고, 일정 연기가 잦았던 만큼 실제 양산 시기는 좀 더 지켜봐야 할 것 같음. 초기 수율과 생산 능력 확보도 관건이 될 것임.

  Hacker News 의견

     * TSMC의 1.6nm 공정은 2026년까지 트랜지스터 밀도 230 MTr/mm2 수준에 도달할 것으로 보임. 현재 TSMC는 197 MTr/mm2로 Samsung(150 MTr/mm2)과 Intel(123 MTr/mm2)보다 크게 앞서 있음.
     * nm 단위 측정은 마케팅에 의해 주도되고 있어서 그 의미가 불분명해지고 있음.
     * TSMC의 이번 발표는 인텔의 2026년 18A 공정에 대한 대응으로 보임.
     * Backside Power Delivery:
          + CPU에 전력을 공급하는 방식의 변화를 의미함.
          + 기존에는 CPU 아래쪽의 핀을 통해 전력을 공급했으나, 새로운 방식은 히트싱크가 있는 CPU 위쪽으로 전력을 공급하는 것으로 추측됨.
     * TSMC의 A16 공정이 2027년인 반면, 인텔 18A는 2026년부터 본격 가동 예정이라 TSMC에게 불리할 수 있음. 이는 팹리스 기업들이 인텔의 파운드리 서비스를 시도할 수 있는 기회가 될 수 있음.
     * 관련 주제로 Chip War라는 책을 추천함. 사실에 기반한 서술이 압축적으로 잘 담겨있다고 함.
     * 같은 N2 복잡도/속도에서 15~20% 전력 소모 감소가 이번 발표의 가장 인상적인 부분으로 보임.
     * 애플 제품에는 이번 성탄절 즈음 적용되고, 다른 업체 제품은 10년 후반에나 적용될 듯함.
     * PCB의 뒷면을 이제야 사용하는 것처럼, 반도체에서도 Backside를 활용하게 된 점이 흥미로움.
"
"https://news.hada.io/topic?id=14527","수학에 능통해지기 위해 뇌를 재배선한 사례 (2014)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     수학에 능통해지기 위해 뇌를 재배선한 사례 (2014)

     * 저자는 어린 시절 수학과 과학을 피하고 문학 쪽으로 성장했으나, 현재는 공학 교수가 되어 수학을 매일 다루고 있음. 성인기에 수학과 과학을 배운 것이 저자에게 공학의 세계로 들어갈 통로를 제공했고, 성인 학습에 내재된 신경 가소성에 대한 통찰력을 줌.
     * 미국에서는 때로 이해에 초점을 맞추는 것이 기억과 반복 같은 뇌의 자연스러운 학습 과정과 함께 작용하는 오래된 교수법을 대체하는 것처럼 보임. 이해에만 집중하는 문제는 학생들이 중요한 개념을 파악할 수 있지만, 연습과 반복을 통한 강화 없이는 이해가 빠르게 사라질 수 있다는 것임.
     * 언어 학습과 수학/과학 학습 사이에는 흥미로운 연관성이 있음. 전문성 개발의 핵심은 청킹(chunking)인데, 전문가들은 장기 기억에 수많은 청크를 저장하고 있어 새로운 학습 상황을 분석하고 대응할 때 이를 의식에 불러올 수 있음.
     * 저자는 러시아어를 배울 때처럼 수학/공학을 배우면서 유창함에 초점을 맞추는 전략을 사용함. 공식을 암기하고 가지고 다니며 연습했고, 시간이 지나면서 천천히 단단한 신경 서브루틴을 구축해 나감.
     * 복잡한 주제에 대한 진정한 이해는 유창함을 통해서만 온다고 믿음. 수학과 과학 교육에서 유창함의 기반이 되는 반복과 연습을 피하고 이해만 강조하는 교수법에 빠지기 쉬움. 유창함이 있으면 필요할 때 이해가 배어나올 수 있음.

GN⁺의 의견

     * 새로운 언어나 수학/과학 학습에서 이해보다 유창함의 중요성을 강조하는 것은 시사하는 바가 큼. 반복 연습이 중요하다는 것은 알고 있지만, 성인 학습자에게도 동일하게 적용된다는 점, 그리고 신경과학적 근거가 있다는 점이 흥미로움.
     * 다만 유창함만 강조할 경우 맥락을 벗어난 기계적 반복이 될 수 있으므로, 개념 이해와 유창함, 실제 활용을 균형있게 발전시켜 나가는 것이 중요해 보임. 언어든 수학이든 실제 활용 기회가 많을수록 학습 동기부여가 잘 될 것 같음.
     * 교육 현장에서 성적 위주의 암기식 교육에서 벗어나 토론과 프로젝트 중심 수업을 강조하는 것은 바람직하나, 연습과 반복을 통한 유창함의 중요성 역시 간과해서는 안될 것 같음. 학생 개개인의 수준과 학습 스타일에 맞는 균형잡힌 접근이 필요해 보임.
     * 저자처럼 문과에서 이과로, 또는 그 반대로 전공을 바꾸는 것이 쉽지 않은 일이지만, 도전해볼만한 가치가 있어보임. 새로운 분야에 입문하는 것은 두뇌에 자극을 주고 새로운 사고방식을 경험하게 해줄 수 있기 때문임. 물론 적절한 학습 전략이 필요할 것임.

        Hacker News 의견

   여기 주요 의견들을 요약해보았음:

   • ""이해력은 유창함을 만들어내지 않고, 유창함이 이해력을 만들어낸다""는 저자의 견해에 공감함. 피타고라스 정리도 유클리드 공간에 대한 깊은 통찰로 직관적으로 느껴지는 게 아니라, 많은 연습 후 직각삼각형을 보자마자 세 가지 증명이 즉각 떠오를 때 직관적으로 맞다고 느껴짐.

   • 수학에는 두 가지 범주가 있음: A. 엔지니어, 과학자 등이 사용하는 실용 수학 B. 수학 전공자와 수학자들이 사용하는 추상적이고 이론적인 수학 저자의 접근법이 수학 B를 배우는 데도 가능할지 의문임. 수학 B는 하스켈이나 순수 함수형 프로그래밍처럼 이해하기 어려움. 유전적 요인, 어린 나이에 배워야 하는 것, 또는 정규 교육 과정이 필요한 것일 수 있음.

   • 의대에 진학한 후, 암기의 가치에 대해 비슷한 결론에 도달함. 컴퓨터 공학에서는 사실 암기에 중점을 두지 않았지만, 의대에서는 대량 암기가 개념 이해를 대체하기보다는 오히려 강화한다는 것을 인식하게 됨.

   • 저자가 자신에 대해 너무 많이 이야기해서 말만 길고 결론이 없는 글처럼 느껴짐. 수학에 능숙해지고 뇌를 재구성하는 방법에 대해서는 이 글을 읽어도 잘 모를 것임.

   • 교육 개혁가들에게 ""여전히 필요한 것은 암기와 반복""이라는 부제에 대해 어떻게 생각하는지 궁금함. 불필요하게 대립적이며 이 글의 요지를 놓치고 있음. 수학 교육 개혁은 바쁜 일에서 벗어나 실제 수학을 사용하는 데 초점을 맞추는 것이 아닐까?

   • 대학 수학 수업에서 내가 이해했다고 생각한 것과 문제가 얼마나 혼란스러운지 사이의 엄청난 격차를 항상 느꼈음. 실제로 문제를 푸는 것이야말로 수학을 이해하는 유일한 방법임.

   • 수학사와 철학이 수학 교육에 더 많이 포함되면 좋겠음. 어릴 때 계산과 공식에만 초점을 맞추는 수학 수업이 지루하고 흥미로운 것들과 동떨어져 있다고 느꼈음. 회계학도 마찬가지로 고립되어 있을 때는 지루했지만 이탈리아의 복식부기 역사, 1500년대 이후 세계 무역과 연결되면 매력적으로 느껴짐.

   • FAANG 면접을 준비하고 떨어진 후, 합격하려면 리트코드를 보고 그래프 검색 패턴, BFS, DFS, 재귀 패턴 등을 암기하는 것이 유일한 방법인 것 같음. 자연스러운 문제 해결 기술을 사용하면 리트코드 문제를 풀기까지 며칠씩 걸림. 기사와 기술 업계에 따르면 암기가 곧 지능이라고 함. 항상 주제를 이해하고 암기를 피해왔는데, 이제는 가짜 증후군이 심함. 기존 기술 직종을 자진 사퇴하는 것을 고려 중. 면접에 합격한 더 똑똑한 사람들 주변에 있으면 안 될까봐서임. 과연 기술 업계의 면접 방식이 옳은 것일까?
"
"https://news.hada.io/topic?id=14561","Postgres에서 흔히 발생하는 DB 스키마 변경 실수","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Postgres에서 흔히 발생하는 DB 스키마 변경 실수

   Here is a summary of the common database schema change mistakes, translated and structured in Korean:

동시성 관련 실수

     * 락 획득 실패
     * 한 번에 너무 많은 행 업데이트
     * 배타적 락 획득 후 트랜잭션을 오래 열어두기

단계의 정확성 관련 실수 - 논리적 이슈

     * 예상치 못한 스키마 편차
     * 스키마/앱 코드 불일치
     * 예상치 못한 데이터

기타 실수

     * statement_timeout 도달
     * 증가할 수 있는 테이블에 4바이트 정수 기본키 사용
     * VACUUM 동작과 bloat 위험 무시

Case 1. 스키마 불일치

     * 개발/테스트 환경에서는 동작했지만 QA/Staging/Production에서는 실패
     * 원인 파악 후 워크플로우 개선으로 해결해야 함

Case 2. IF [NOT] EXISTS 오용

     * 스키마 불일치 에러를 IF NOT EXISTS로 무시하려 하지 말 것
     * 문제의 근본 원인을 파악하고 해결해야 함

Case 3. statement_timeout 도달

     * 모든 변경 사항을 대용량 데이터로 테스트해서 미리 파악할 것

Case 4. 무제한 대규모 변경

     * 너무 많은 행을 한 트랜잭션에서 변경하면 다른 트랜잭션에 영향
     * Checkpointer 튜닝 안되어있으면 WAL 데이터 과도 생성
     * 디스크 쓰기 포화로 전반적인 성능 저하 발생 가능
     * VACUUM/Bloat 이슈 발생 가능
     * 배치로 쪼개서 처리하고 VACUUM 관리할 것

Case 5. 배타적 락 획득 후 트랜잭션 내 대기

     * BEGIN/ALTER TABLE/COMMIT 사이에 다른 작업하면 락이 오래 유지됨
     * 배타적 락 획득 후에는 가능한 한 빨리 트랜잭션을 마쳐야 함

Case 6. DDL + 대량 DML이 포함된 트랜잭션

     * DDL 단계에서 획득한 락이 DML 단계까지 오래 유지됨
     * DDL과 DML을 별도 트랜잭션/마이그레이션 단계로 분리할 것

Case 7. 배타적 락 획득 대기로 인한 다른 세션 블로킹

     * 오토베큠이 wraparound 방지 모드일 때 DDL에 yield 안함
     * 락 획득 대기 중에 SELECT마저 블로킹됨
     * lock_timeout을 낮게 설정하고 재시도 로직 만들 것

Case 8. FK 생성시 주의사항

     * 큰 테이블에 FK 생성시 referenced 테이블 스캔으로 시간 소요
     * not valid 옵션으로 FK 정의 후 별도 트랜잭션에서 validate

Case 9. FK 삭제시 주의사항

     * 두 테이블 락 필요하므로 lock_timeout 재시도 로직 필요

Case 10. CHECK 제약 조건 추가시 주의사항

     * 전체 테이블 스캔 발생하므로 FK와 유사한 2단계 접근법 사용

Case 11. NOT NULL 추가시 주의사항

     * Postgres 11 미만에서 새 컬럼에 NOT NULL 추가시 테이블 스캔 발생
     * Postgres 11부터는 NOT NULL DEFAULT 컬럼 추가로 해결 가능
     * Postgres 12부터는 CHECK 제약조건 추가로 NOT NULL 설정 가능

Case 12. 컬럼 데이터 타입 변경시 주의사항

     * 전체 테이블 재작성 발생할 수 있음
     * 새 컬럼 추가 후 트리거로 데이터 복사하는 접근법 필요

Case 13. CREATE INDEX시 주의사항

     * OLTP에서는 CREATE INDEX CONCURRENTLY 사용해야 함
     * 유니크 인덱스 생성이 실패하면 invalid 인덱스 정리 필요

Case 14. DROP INDEX시 주의사항

     * 락 획득 이슈 있으므로 DROP INDEX CONCURRENLTY 사용

Case 15. 객체 이름 변경시 주의사항

     * 앱 코드와 DB 스키마 간 불일치 피하도록 배포 순서 조정 필요

Case 16. DEFAULT 값이 있는 컬럼 추가

     * PG 11 이전엔 전체 테이블 재작성 발생
     * PG 11부터는 DEFAULT 값 있는 컬럼 추가가 빨라짐

Case 17. CREATE INDEX CONCURRENTLY 실패시 잔여물 처리

     * 실패하면 invalid 인덱스가 남으므로 재시도 전에 정리 필요

Case 18. 큰 테이블에 4바이트 정수 기본키 사용

     * int8을 써야 함. 대부분의 프레임워크가 이미 int8 사용중.

권장사항

     * 현실적인 데이터 크기로 테스트하기
     * 배타적 락 유지 시간 체크하기
     * 배포 자동화 개선하기
     * 다른 사람에게 배우고 지식 공유하기

GN⁺의 의견

   이 글은 실제 DB 스키마 변경 시 겪을 수 있는 여러 실수와 주의사항을 잘 정리해주고 있습니다. 특히 배타적 락과 관련된 이슈가 많이 언급되는데, 이는 대용량 데이터베이스일수록 더 심각한 문제를 일으킬 수 있는 사안입니다.

   개발자들이 흔히 간과하기 쉬운 FK, NOT NULL, 인덱스 등을 다룰 때 주의사항도 구체적으로 잘 설명하고 있습니다. Postgres의 버전별 개선 사항을 이해하고 활용하는 것도 도움이 될 것 같네요.

   무엇보다 현실적인 데이터 크기로 철저히 테스트하고, 배포 자동화를 개선해나가는 것이 스키마 변경의 위험을 최소화하는데 핵심이라는 점에 공감합니다. 테스트와 배포 자동화를 위해 Database Lab Engine 같은 도구를 활용해보는 것도 좋겠습니다.

   이런 유용한 팁들을 공유해주는 기술 블로그 글들이 더 많아지면 좋겠습니다. 이런 정보가 널리 퍼질수록 데이터베이스를 다루는 개발자들의 역량 향상에 분명 도움이 될 것 같네요.
"
"https://news.hada.io/topic?id=14510","유용한 프론트엔드 confetti 애니메이션 라이브러리","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     유용한 프론트엔드 confetti 애니메이션 라이브러리

     * 설치 방법
          + NPM을 통해 모듈로 설치 가능
npm install --save canvas-confetti

          + require('canvas-confetti')로 프로젝트에서 사용 가능
          + 클라이언트 컴포넌트이므로 Node에서는 동작하지 않음. webpack 등을 이용해 프로젝트를 빌드해야 함
          + CDN을 통해 HTML 페이지에 직접 포함 가능
<script src=""https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/…;

          + 프로젝트에 포함할 때는 releases 페이지에서 최신 버전 사용 권장
     * 애니메이션 감소 모드
          + 일부 사용자는 모션을 선호하지 않으므로 이를 고려해야 함
          + disableForReducedMotion 옵션으로 혼란스러운 애니메이션을 원하지 않는 사용자를 배려할 수 있음
          + 기본적으로 비활성화되어 있지만, 향후 메이저 릴리즈에서 기본값 변경 예정

API

     * confetti([options {Object}]) → Promise|null
          + 단일 옵션 객체를 매개변수로 받음
          + window.Promise를 사용할 수 있으면 Promise를 반환하고, 사용할 수 없으면(IE 등) null 반환
          + Polyfill이나 confetti.Promise를 통해 Promise 구현체 제공 가능
          + 완료되기 전 confetti 여러번 호출하면 같은 Promise 반환. 내부적으로 같은 canvas 요소 재사용
          + 모든 애니메이션이 완료되면 각 호출에서 반환된 Promise 해결(resolve)
          + options 객체의 주요 속성
               o particleCount, angle, spread, startVelocity, decay, gravity, drift, ticks, origin, colors, shapes, scalar, zIndex 등
     * confetti.shapeFromPath({ path, matrix? }) → Shape
          + SVG Path 문자열을 사용해 사용자 정의 confetti 모양 생성
          + 단색만 지원하며 Stroke는 미구현
          + 변환 행렬 필요. 직접 전달하거나 helper를 사용해 계산 가능
          + Path2D를 지원하는 브라우저로 제한
          + Shape 객체 반환
     * confetti.shapeFromText({ text, scalar?, color?, fontFamily? }) → Shape
          + 이모지 confetti 렌더링을 위한 기능
          + 단일 문자, 특히 이모지 사용 권장
          + 텍스트를 래스터화하므로 생성 후 크기 조정에 적합하지 않음
          + scalar로 크기 조정시 여기서도 같은 값 사용 필요
          + text, scalar, color, fontFamily 옵션
     * confetti.create(canvas, [globalOptions]) → function
          + 사용자 정의 canvas를 사용하는 confetti 함수의 인스턴스 생성
          + canvas의 크기 제한 가능
          + 글로벌 옵션
               o resize : canvas 이미지 크기 설정 및 창 크기 변경시 유지 여부
               o useWorker : 가능한 경우 비동기 웹 워커를 사용해 렌더링할지 여부
               o disableForReducedMotion : 애니메이션 감소 모드 사용자의 경우 confetti 완전 비활성화 여부
          + useWorker: true 사용시 주의사항
               o canvas를 직접 조작하면 안됨. 웹 워커로 제어권 이전
     * confetti.reset()
          + 애니메이션 중지 및 모든 confetti 제거
          + 미해결 Promise 즉시 해결
          + confetti.create로 생성한 인스턴스는 자체 reset 메서드 보유

사용 예제

     * 기본 사용법
confetti();

     * 다량의 confetti 사용
confetti({
  particleCount: 150
});

     * 넓게 퍼뜨리기
confetti({
  spread: 180
});

     * 랜덤한 위치에서 소량 발사
confetti({
  particleCount: 100,
  startVelocity: 30,
  spread: 360,
  origin: {
    x: Math.random(),
    y: Math.random() - 0.2
  }
});

     * 30초 동안 여러 방향에서 연속 발사
var duration = 30 * 1000;
var end = Date.now() + duration;

(function frame() {
  confetti({
    particleCount: 7,
    angle: 60,
    spread: 55,
    origin: { x: 0 }
  });

  confetti({
    particleCount: 7,
    angle: 120,
    spread: 55,
    origin: { x: 1 }
  });

  if (Date.now() < end) {
    requestAnimationFrame(frame);
  }
}());

GN⁺의 의견

     * canvas-confetti는 웹 페이지에서 쉽게 콘페티 효과를 적용할 수 있는 가벼운 라이브러리로 보입니다. NPM을 통한 설치나 CDN 방식 모두 지원해 개발자 편의성이 높아 보입니다.
     * 콘페티 효과의 다양한 설정을 지원해 유연성이 높습니다. 콘페티 개수, 퍼짐 정도, 크기, 모양, 색상 등을 자유롭게 조절할 수 있어 다양한 분위기 연출이 가능할 것 같습니다.
     * 텍스트나 SVG 패스를 이용해 사용자 정의 모양의 콘페티도 만들 수 있는 것이 흥미롭습니다. 특히 이모지를 활용한 콘페티는 재미있는 아이디어라고 생각합니다.
     * Web Worker를 활용해 메인 스레드를 블로킹하지 않고 애니메이션을 실행할 수 있는 것도 장점으로 보입니다. 다만 이 경우 canvas 직접 제어가 불가능해지므로 trade-off가 있습니다.
     * 애니메이션에 민감한 일부 사용자를 배려해 모션 감소 모드를 지원하는 것은 웹 접근성 측면에서 긍정적입니다. 향후 버전에서는 이 모드가 기본으로 활성화 될 예정이라고 하니 참고가 필요합니다.
     * 전반적으로 사용이 쉽고 다양한 옵션을 제공하는 라이브러리로 보입니다. 경쾌한 분위기 연출이 필요한 축하 페이지나 게임 등에 적합할 것 같습니다. 다만 지나친 사용은 사용자 경험을 해칠 수 있으므로 적정선에서 활용하는 것이 바람직해 보입니다.

        Hacker News 의견

     * 캔버스에 그리고 캔버스를 다른 모든 요소 앞에 두되, 캔버스에서 포인터 이벤트를 비활성화하여 페이지와 상호작용할 수 있게 하는 것이 성능 좋은 애니메이션의 트릭임
     * 2015년 고등학교 시절 웹 개발을 하면서 즐거운 시간을 보냈던 기억이 남. 홈커밍 파티에 여자아이를 초대하기 위해 작은 웹사이트에 색종이 뿌리는 애니메이션을 만들었음 (지금 생각하면 너드스러워 보임). 어린 시절 웹사이트 만드는 것이 초능력처럼 느껴졌던 때가 있었음
     * 순수하게 재미를 위한 작은 프로젝트를 사랑함. 그것이 프로그래밍을 시작한 이유이고 여전히 원동력이 되고 있음
     * 데모 페이지에서 입자 수를 400개 정도로 변경하면 색종이가 균일한 ""평평한 원뿔"" 모양으로 보이는 실망스러운 광경을 목격할 수 있음. 이는 너무 완벽해 보여서 환상을 깨뜨림
     * 통계 시각화, 영화 소품, 웹사이트 색종이 등 세상에서 이런 종류의 디테일에 대한 관심이 드문데, 어디서든 발견하면 소중히 여김
     * 실제 분포는 가우시안에 근사할 것으로 추측되며, 해결책으로는 무작위 분포를 직접 변경하는 것이 좋을 듯함
     * 쿨하고 유용한 라이브러리일 뿐만 아니라, John Ousterhout가 '소프트웨어 설계 철학'에서 말하는 ""딥 모듈""의 좋은 예시이기도 함
     * 가장 기본 버전의 라이브러리(색종이 소환)는 사용하기 매우 쉽지만, 제시된 옵션(눈, 특정 색상, 다양한 색종이 효과 등)을 탐색하면서 많은 것을 얻을 수 있음
     * 영업사원들의 관리자 대시보드에 판매 시 색종이 효과를 추가했는데, 놀랍게도 즐겁고 동기부여가 됨
     * 인상적이고 멋진 반면, 내가 사용하는 웹사이트에서 실행되는 것은 보고 싶지 않음. 특히 뉴스레터 팝업이나 장바구니에 상품을 추가할 때 색종이가 나오는 것은 원치 않음
     * 리셋 함수의 이름을 confetti.resetti()로 지었으면 함
     * 몇 년 전 제품의 일부로 유사한 애니메이션을 만들었음. 새로운 사용자가 가입하고 처음으로 제품을 사용하여 특정 결과물을 만들면 색종이 애니메이션이 표시되는 흐름이었음. 제품 관리자들은 이를 즐겁고 신선한 것으로 여겨 임원들에게 자랑했으나, 이후 UX 리뷰와 접근성 테스트를 거친 후 결국 제품에서 제거됨. 데모에서 보여주기에는 재미있었으나 사용자에게는 성가실 수 있음
     * Party.js 라이브러리도 있음: https://party.js.org/
     * 2005년경 전자상거래 사이트에 눈 내리는 효과를 넣었을 때의 놀라운 느낌이 기억남. 우리가 얼마나 멀리 왔는지 보여줌 (어떤 면에서는!)
"
"https://news.hada.io/topic?id=14530","Qwen1.5-110B : 알리바바의 오픈소스 LLM Qwen1.5 시리즈의 첫번째 100B+ 모델","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Qwen1.5-110B : 알리바바의 오픈소스 LLM Qwen1.5 시리즈의 첫번째 100B+ 모델

     * 오픈소스 커뮤니티에서 최근 1000억 개 이상의 매개변수를 가진 대규모 모델들이 쏟아져 나오고 있으며, 벤치마크 평가와 챗봇 분야에서 놀라운 성능을 보여주고 있음
     * 알리바바도 Qwen1.5 시리즈의 첫 번째 100B+ 모델인 Qwen1.5-110B를 공개
     * 기본 모델 평가에서 Meta-Llama3-70B와 견줄 만한 성능을 달성하였고, MT-Bench와 AlpacaEval 2.0을 포함한 채팅 평가에서 뛰어난 성능을 보여줌

Qwen1.5-110B 모델의 특징

     * Qwen1.5-110B는 다른 Qwen1.5 모델들과 유사하며 동일한 Transformer 디코더 아키텍처로 구축됨
     * 그룹화된 쿼리 어텐션(GQA)으로 구성되어 모델 서빙에 효율적임
     * 32K 토큰의 컨텍스트 길이를 지원하며, 영어, 중국어, 프랑스어, 스페인어, 독일어, 러시아어, 한국어, 일본어, 베트남어, 아랍어 등 다수의 언어를 지원하는 다국어 모델

기본 언어 모델 평가 결과

     * 기본 언어 모델에 대한 일련의 평가와 최근 SOTA 언어 모델인 Meta-Llama3-70B 및 Mixtral-8x22B와 비교
     * 결과에 따르면 새로운 110B 모델은 기본 능력 면에서 Llama-3-70B 모델과 적어도 경쟁력이 있음
     * 이 모델의 경우 사전 학습 및 사후 학습 레시피를 급격히 변경하지 않았으므로, 72B 대비 성능 향상은 모델 크기 증가에서 비롯된 것으로 보임

채팅 모델 평가 결과

     * MT-Bench와 AlpacaEval 2.0에서 채팅 모델을 테스트함
     * 이전에 공개된 72B 모델에 비해 110B는 두 가지 벤치마크 평가에서 현저히 우수한 성능을 보임
     * 평가에서의 일관된 개선은 사후 학습 레시피를 크게 변경하지 않더라도 더 강력하고 큰 기본 언어 모델이 더 나은 채팅 모델로 이어질 수 있음을 나타냄

Qwen1.5-110B로 개발하기

     * Transformers, vLLM, llama.cpp, Ollama, LMStudio, SkyPilot, Axolotl, LLaMA-Factory 등과의 사용법을 파악하려면 Qwen1.5 블로그를 읽어볼 것을 권장

결론

     * Qwen1.5-110B는 Qwen1.5 시리즈 중 가장 큰 모델이며, 시리즈 중 첫 번째로 1000억 개 이상의 매개변수를 가진 모델임
     * 최근 공개된 SOTA 모델인 Llama-3-70B와 경쟁력 있는 성능을 보여주며, 72B 모델보다 크게 우수함
     * 이는 더 나은 성능을 위해 모델 크기 확장에 여전히 많은 가능성이 있음을 나타냄
     * Llama-3의 공개는 데이터를 극도로 큰 규모로 확장하는 것의 중요성을 보여주지만, 향후 공개에서 데이터와 모델 크기를 모두 확장하여 두 세계의 장점을 모두 얻을 수 있을 것이라 믿음

   Alibaba, 오픈소스 AI 모델 QWEN 공개
"
"https://news.hada.io/topic?id=14609","당신이 바로, 당신이 찾던 기술 코파운더에요","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        당신이 바로, 당신이 찾던 기술 코파운더에요

     * Exit한 창업자로서, 세상을 바꿀 다음 아이디어를 가지고 있다고 믿는 야심찬 기업가들이 종종 찾아옴
          + 그들은 아이디어를 단순한 개념 이상으로 만들어 시작하고 싶어함
     * 일반적으로 그들이 해결하고자 하는 문제에 대해 이야기하는 것으로 시작함
          + 초기 창업자들에게 주는 조언: 대부분의 가정이 틀릴 것이므로, 빠르게 반복하고 확장되지 않는 일을 하는 것이 중요함
     * 대화는 보통 다음과 같이 진행됨:

     기업가: ...그래서 제 스타트업이 혁신적일 거예요.
     나: 좋아요, 지금까지 어디까지 왔나요?
     기업가: 와이어프레임을 만들었어요. MVP를 만들기 위해 계약자를 고용했는데, 비용이 많이 들었어요. 그래서 자금 조달이 필요할 것 같아요.
     나: 하지만 계속 외주 개발자에게 의존하고 싶진 않죠? 당신처럼 이 일에 전념할 사람이 필요해요. 소프트웨어 스타트업은 창업팀에 소프트웨어 엔지니어가 필요해요.
     기업가: 맞아요. 기술 공동창업자를 찾는 게 답일 수 있다고 생각했어요. 어떻게 해야 할까요?
     * 이 때 나는 보통 안 좋은 소식을 전해야 함
          + 아이디어를 가지고 기술 공동창업자를 찾는 사람이, 아이디어를 찾는 기술 공동창업자보다 훨씬 많음
          + 아이디어만 가진 사람이 엔지니어 파트너를 성공적으로 찾는 경우는 거의 없음
          + 기술 공동창업자를 기다리는 대부분의 사업은 시작조차 못하거나, 내부 역량 부족으로 실패함
     * 하지만 희망이 없는 건 아님
          + 이 시점에서 나는 도움이 되는 조언을 해주는데, 창업자로서 성공하는데 필수적인 태도에 뿌리를 두고 있음
          + 열정적인 초기 창업자들에게 기술 공동창업자 찾기를 그만두고, 그 에너지를 기술 공동창업자가 되려고 노력하는 데 쏟으라고 조언함

늦었다고 생각할 때가 가장 빠른 때

     * 2010년에 나는 공식적인 기술 교육을 받지 않은 2학년 법대생이었지만, 나만의 스타트업 아이디어가 있었음
          + 많은 동세대처럼 The Social Network 영화를 보고 자신의 회사를 시작하여 세상을 바꾸고 싶어했음
     * 한 아이디어는 법대생들이 서로의 질문을 돕는 커뮤니티 포럼(법률 개념을 위한 StackOverflow)이었음
          + 다른 아이디어는 웹사이트 추천 도구(""이것을 읽는 것을 좋아했다면 이것도 좋아할거야"")였음
          + 문제는 어떻게 만들어야 할지 몰랐다는 것임
     * 기술 파트너를 찾으려 했지만, 소용없었음
          + 친형이 프로그래밍을 배우기에 너무 늦지 않았다고 조언해줌
          + 사실, 무엇이든 배우기에 결코 늦은 것은 없음
          + 서점에서 프로그래밍 언어 C# 입문서를 찾았고, 진정한 기업가 정신의 여정이 시작됨
     * 법대 사이트 아이디어를 위해 C# 지식을 활용하여 데이터를 호스팅하는 서버를 만들었음
          + HTML과 자바스크립트에 대해 배워 웹사이트를 만들었음(no-code, low-code 옵션이 존재하기 전이라)
          + 데이터베이스에 대한 책을 사서 변경사항을 저장하고 추적함
          + 필요성이 발명(교육)의 어머니임
     * 물론 아이디어는 단순한 프로토타입을 넘어서지 못했지만, 소프트웨어 엔지니어링 직업을 얻을 만큼 충분한 경험을 쌓음
          + Aviary와 Adobe에서 하루에 수백만 명의 사용자에게 서비스를 제공하는 백엔드 시스템을 구축함
          + 내가 찾고 있던 소프트웨어 엔지니어가 됨
     * 동료와 함께 Adobe를 떠나 팟캐스팅 플랫폼 Anchor를 시작함
          + 누구나 팟캐스트를 쉽게 만들고 편집하고 공유할 수 있게 하는 것이 목표였음
          + 이 아이디어는 현실화되기 위해 진정한 기술 실행이 필요했음
          + 오디오 프로세싱, 라이브 레코딩, 비디오 생성, 전사 서비스 등에 대해 직무 중 학습함
          + 매일 매 순간 전 세계 사용자에게 콘텐츠를 제공하는 빠르고 신뢰할 수 있는 시스템을 구축한 적이 없었지만, 일하면서 배웠음

야심찬 목표는 배움의 이유임

     * 야심 찬 창업자는 어느 날 아침 꿈에 그리던 아이디어를 떠올리며 이를 만들고 싶어하지만, 정식 기술 교육을 받은 적이 없어 막막하기만 함
          + 그들은 혼자선 할 수 없다고 믿음
          + 어떻게 시작해야 할지, 누가 안내해 줄지, 배우고 만들 시간을 어떻게 찾을지 모름
          + 이런 딜레마는 판매, 마케팅, 성장 등 많은 분야에서 발생하지만, 특히 프로그래밍에서 그러함
     * 그러나 달성하고자 하는 야심찬 흥미로운 목표보다 새로운 것을 배울 동기가 더 큰 것은 없음
          + 큰 아이디어를 가진 창업자들에게: ""축하합니다. 가장 어려운 부분을 해냈습니다. 배울 이유를 찾은거에요.""
     * 야심찬 기업가와의 대화로 돌아가면:

     나: 당신처럼 이 일에 전념할 사람이 필요해요. 소프트웨어 스타트업은 창업팀에 소프트웨어 엔지니어가 필요해요.
     기업가: 맞아요. 기술 공동창업자를 찾는 게 답일 수 있다고 생각했어요. 어떻게 해야 할까요?
     나: 기술 공동창업자 찾기를 그만두세요. 당신이 기술 공동창업자가 되어야 합니다.
     * 14년 전 프로그래밍을 시작했을 때는 서점에서 산 물리적 책이나 도서관에서 빌린 커피 얼룩진 입문서에 의존해야 했음
          + 반면 오늘날은 인공지능의 황금기로, 기술적 질문에 대한 모든 답변이 손끝에 있음
          + ""어떻게 하면 X 또는 Y를 할 수 있을까요?""와 같은 질문뿐만 아니라 ""어떻게 시작하죠?""와 같은 높은 수준의 질문도 가능함

     ""[아이디어]를 만들고 출시하기 위해 어떤 기술을 이해해야 하나요?""
     관계형 데이터베이스요?
     ""관계형 데이터베이스가 뭐예요?""
     아, 자세히 설명하는 좋은 유튜브 영상이 있네요. ""제 아이디어에 맞는 데이터베이스를 설계해주세요.""
     그렇게 진행하다 보면...
     * 누구나 어떤 주제든 배울 수 있고, 그렇게 하기에 결코 늦지 않다고 믿음
          + 중요한 것은 배울 필요가 있다는 것임
          + 내 인생에서 배운 것의 대부분은 정식 교육이나 전문 학위가 필요하지 않았고 전적으로 제 열망에 의해 이루어졌기 때문에 그렇게 믿음
          + 10년 전에는 멘토와 자원에 접근할 수 있었지만, 오늘날 여러분에게 제공되는 멘토와 자원의 일부에 불과함
          + 내가 할 수 있었다면, 당신도 할 수 있음
     * 할 수 없다고 생각한다면 자문해 볼 것: 무엇이 두려운가요?
          + 노력인가요, 시간 투자인가요, 실패 가능성인가요?
          + 그런 것들 중 하나라도 해당 된다면, 기업가 정신은 당신에게 너무 벅찬 여정일 수 있음
          + 스타트업에 온 마음을 쏟고, 밤낮으로 일하고, 많은 실수를 하는 데 기술적일 필요는 없음
          + 단순히 배우는 것에 개방적이기만 하면 됨

그럼 왜 공동창업자는 그래도 필요할까 ?

     * 기술 공동창업자 찾기를 그만두고 스스로 그렇게 되라고 조언하지만, 함께 일할 어떤 종류의 공동창업자가 있는 것은 매우 가치 있음
     * 혼자 창업의 길을 가지 않았으면 하는 솔로 창업자들을 정기적으로 만남
          + 스타트업은 어려운 일임
          + 오르막은 적고 내리막은 훨씬 더 많으며, 다년간의 마라톤에서 흔들리지 않는 종류의 인내와 끈기가 필요함
          + 다른 사람 없이 그 여정을 떠나는 것은 외로운 경험임
     * 그런 파트너를 찾는 것 자체가 충분히 어려움
          + 소프트웨어 공학을 공식적으로 훈련받은 사람이어야 한다는 요구 사항이 추가되면 검색이 엄청나게 어려워짐
     * 우리 사회는 엔지니어를 받들어 모시는데, 그럴 만한 이유가 있음
          + 프로그래밍은 엄청나게 가치 있는 기술임
          + 엔지니어는 무에서 유를 창조할 수 있는 사람들
          + 그러나 공개적으로 얘기하지 않는 큰 비밀은 엔지니어와 비엔지니어의 유일한 실제 차이점은 전자가 엔지니어가 되는 법을 배우는 데 시간을 할애 했다는 것임
          + 프로그래밍은 누구나 이해할 수 있는 것이며, 솔직히 말해서 누구나 어릴 때부터 배워야 한다고 생각함
     * 가장 큰 장벽은 학습이 아니라, 애초에 거의 모든 것을 배울 수 있다는 것을 이해하는 것임

   너무 재밌고 좋은 글이네요.
   저도 그렇고 주변 분들이 이렇게 프로그래밍 학습을 시작하신 분들이 꽤나 있었는데, 직업을 it 관련 업종으로 발전시키지 않더라도 넓은 인사이트를 얻게 된다는 점에서 너무 좋은 경험이었다고 하셨습니다.
   무엇이든 배워 둔다면 다 써먹을 곳이 있는 것 같아요ㅎㅎ

   제 주변에도 이렇게 시작하신 분들이 꽤 있어요. 저 한테 매번 프로그래밍 물으시면서 MVP까지 만드셨는데, 사실 그 결과물보다 그 과정에서 아이디어가 발전하고, 구체화 되는 것이 큰 역할을 하는 것 같더라고요.

   제가 바로 이렇게 개발을 시작했지요.
   예전 개발과 달라진건 난이도보다는 한명의 개발자가 만들어낼수 있는 결과의 사이즈인것 같습니다.

   예전에도 쉬운 코딩은 쉬웠죠. 지금은 그 쉬운 코딩으로 훨씬 많은 것들을 만들어낼수 있다보니 이전이라면 여러명이 합심해서 개발해야했던 것들을 한명이 모두 만들수 있게되고 그래서 알아야하는 것들이 더 늘어나 결국 난이도는 비슷하지 않나 싶습니다.

   저는 이 글에 완전히 동의합니다.

   지난주에 얘기했던 당신이 기술 코파운더를 찾을 수 없는 이유 에 대한 또 다른 해답 같은 글이네요.
   위 글에 있던 것처럼 비용을 지불하고 개발자를 찾는 것도 가능하겠지만, 가장 좋은 것은 본인이 어느정도 엔지니어링 역량을 가져야 한다는 것에 동의합니다.
   하지만 프로그래밍이 누구나 이해할 수 있는 것인지에는 살짝 의구심이 들어요. 모든 사람에게 쉽게 가능한 스킬은 아니라고 봅니다.
   물론 몸치들도 엄청 노력하면 댄서가 될 수 있겠지만, 훨씬 더 많이 노력해야 하는 것처럼요.

   그래도 예전보다는 프로그래밍 학습이 쉬워졌으니, 가능하면 창업자들이 소프트웨어 개발에 대한 기본 개념은 가지고 시작하면 좋겠습니다.

   그런 비유라면 몸치가 간단한 율동도 못하면서, 고난이도의 브레이킹을 시도하고 있는거죠..
    1. 수십억 인구 중 아무도 생각하지 못한 좋은 아이디어 떠올리기
    2. 생각을 알수없는 다수의 사람을 설득하기
    3. 모든게 약속되어있는 프로그래밍하기(MVP 수준이라면 엑셀함수 수준으로 만들수있음.)

   gpt로 급격히 배우는 난이도가 내려갔는데
   정해진 반응이 나오는 프로그래밍도 못할 능력을 가진 사람이라면, 다수의 사람 설득은 더 어렵고, 그사람이수십억 중 아무도 생각못한 좋은 아이디어 떠올리기는 더욱 더 어렵죠.

   이 글을 바탕으로 해석해보자면, MVP수준의 앱을 만들정도의 프로그래밍학습에 대한 열정이 없다면, 앱서비스를 창업하면 안됩니다.

   누구나 할 수 있지만 얼마나 잘 하느냐는 사람마다 다르지 않을까 싶어요. 우리나라에서 누구나 기초수학을 배우지만 모두가 100점을 받지는 못하니까요.
   물론 프로그래밍을 모두가 어릴때부터 배워야하느냐는 저도 굳이? 글쎄? 쪽입니다
"
"https://news.hada.io/topic?id=14588","레딧, 봇 천지: 10개월 전 게시물 댓글까지 그대로 옮겨간 봇 출몰","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 레딧, 봇 천지: 10개월 전 게시물 댓글까지 그대로 옮겨간 봇 출몰

레딧은 봇들로 가득함: 10개월 전 게시물과 댓글이 완전히 동일하게 재게시됨

     * Imgur에 게시된 이미지는 레딧의 한 게시물이 10개월 전과 정확히 동일한 내용으로 재게시된 것을 보여주고 있음
     * 원본 게시물과 재게시된 게시물의 댓글들도 정확히 일치함
     * 이는 레딧에 봇들이 활개치고 있으며, 과거 인기있던 게시물을 그대로 복사해서 재게시하는 식으로 활동하고 있음을 시사함

GN⁺의 의견

     * 봇들에 의한 게시물 재게시는 커뮤니티의 신뢰도와 진정성을 떨어뜨릴 수 있음. 레딧은 이에 대한 대책 마련이 필요해 보임
     * 다만 단순히 인기있는 게시물을 재게시하는 봇들의 행위가 실제로 어떤 피해를 주는지에 대해서는 추가적인 논의가 필요함
     * 봇들의 활동을 막기 위한 기술적 조치도 중요하지만, 근본적으로는 건전한 커뮤니티 문화 조성을 통해 봇들이 활동할 틈을 주지 않는 것이 바람직해 보임
     * 최근 ChatGPT 등 대화형 AI의 발전으로 봇들도 더욱 정교해질 것으로 예상됨. 레딧 뿐만 아니라 다른 소셜 플랫폼들도 AI 봇 활동에 대한 대비책 마련이 시급해 보임

        Hacker News 의견

     * 404Media의 기사에 따르면, ""Reply Guy""라는 제품이 Reddit에서 실제 사용자를 모방하여 댓글로 제품을 홍보하도록 설계된 새로운 LLM 제품임
     * Google 검색 결과의 질 저하로 사용자들이 ""Reddit""을 검색어 끝에 추가하기 시작했는데, Reddit마저 AI 생성 쓰레기로 가득 차면 어디로 가야할지에 대한 우려가 제기됨
     * 정보 웹에는 실패 지점이 많으며, Wikipedia를 제외하고는 대부분 훼손되고 있음
     * ""정보화 시대""가 끝날 수도 있다는 의견도 있음
     * 그러나 최근 Sherwood News의 기사에 따르면 Reddit의 인기 게시물이 ""카르마 농부""의 재활용 콘텐츠에서 소규모 커뮤니티의 독창적인 콘텐츠로 전환되고 있다고 함
     * 하지만 일부 사용자의 경험으로는 여전히 새로운(또는 갑자기 활성화된) 계정이 특정 패턴을 가지고 프론트 페이지에 도달하는 것으로 보임
     * Reddit을 여전히 훌륭한 자원으로 만드는 핵심은 자신의 관심사에 맞는 틈새 subreddit을 찾는 것임. 광범위한 subreddit은 스팸과 쓰레기로 가득 차 있지만, 특정 비디오 게임 같은 subreddit은 관련성 높고 스팸이 적은 콘텐츠로 가득 차 있음
     * 일부 사용자들은 Reddit 전체 게시판이 사용자의 주의를 끌기 위해 권위주의적이고 도덕적 우월감을 조장하는 방식으로 설계되어 있다고 지적함
     * 이러한 현상은 수년 동안 지속되어 왔으며, 봇 운영자들이 과거에 인기 있었던 게시물과 댓글을 재활용하여 한꺼번에 많은 upvote를 얻는 전략을 사용하고 있다는 이론도 있음
     * 최근 몇 년 동안 Reddit의 쇠퇴가 가속화되고 있으며, 작년 중재자 커뮤니티와의 갈등 이후 더욱 심해졌음
     * 일부 사용자들은 인터넷이 ""언데드 활동""으로 가득 차 있다는 사실과 이 특정 사례의 단순함에 분노를 표출함
     * 한 사용자는 자신의 게시물이 월 단위로 복제되어 등장하고, 자신의 말을 그대로 인용하며 댓글을 달고 있다고 증언함
     * ""데드 인터넷 이론""이 단순한 이론 이상으로 입증되고 있다는 의견도 있음
     * SEO 전문가들이 ""Reddit만 추가하면 된다""는 추세를 파악하고 Reddit에 직접 게시하기 시작했다는 지적도 있음
"
"https://news.hada.io/topic?id=14540","월드 와이드 웹(World Wide Web) 탄생 (1991년)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  월드 와이드 웹(World Wide Web) 탄생 (1991년)

WorldWideWeb (W3) 프로젝트 소개

     * W3는 광역 하이퍼미디어 정보 검색을 위한 프로젝트로, 방대한 문서에 대한 보편적인 접근을 제공하는 것을 목표로 함
     * 이 문서에는 프로젝트 요약, 메일링 리스트, 정책, 최신 뉴스, FAQ 등 W3에 대한 모든 것이 직간접적으로 연결되어 있음

W3 프로젝트 관련 정보

     * 온라인 정보, 주제, W3 서버 등에 대한 포인터 제공
     * 사용 중인 브라우저에 대한 도움말 제공
     * Line Mode, X11 Viola, NeXTStep, 서버, 도구, 메일 로봇, 라이브러리 등 W3 프로젝트 구성 요소와 현재 상태 목록 제공
     * 프로토콜, 형식, 프로그램 내부 등에 대한 기술적 세부 정보 제공
     * W3에 대한 문서 및 참조 문헌 제공
     * 프로젝트에 참여한 사람들의 목록 제공
     * 프로젝트의 역사 요약 제공

W3 프로젝트 참여 방법

     * 웹을 지원하고 싶다면 익명 FTP 등을 통해 코드를 얻을 수 있음

GN⁺의 의견

     * 이 문서는 초기 웹의 모습을 볼 수 있는 귀중한 자료임. 웹이 어떻게 발전해 왔는지 그 역사를 되돌아 볼 수 있음
     * 현재의 웹과 비교해 보면 기술적으로는 많이 발전했지만, 웹의 본질적인 목표인 ""보편적 접근""이라는 측면에서는 아직 갈 길이 멀어 보임. 개인정보 보호, 검열, 접근성 등 해결해야 할 이슈가 여전히 남아있음
     * 초기 웹 개발에 참여했던 사람들의 열정과 비전에서 배울 점이 많음. 사용자 중심, 개방성, 협력이라는 가치는 현재도 유효함
     * 웹 표준화와 브라우저 간 호환성 문제는 초기부터 있어왔던 이슈로 보임. 웹 기술을 다룰 때는 표준 준수가 중요함
     * 코드를 공개하고 참여를 독려하는 부분에서 오픈소스 프로젝트의 모습이 엿보임. 초기 웹 개발자들은 오픈소스의 가치를 잘 이해하고 있었던 듯

        Hacker News 의견

   요약해 드리겠습니다:
     * 1994년에 UCL CS 웹서버를 CERN/3.0으로 업그레이드했는데, 그 이후로 계속 운영 중임. 하드웨어는 교체되었지만 소프트웨어는 그대로 30년째 사용 중임.
     * 초기 웹을 경험한 사람은 당시에는 Gopher보다 크게 나은 점이 없어 보였지만, 곧 웹의 잠재력을 알아차렸음. 하지만 웹 브라우저가 컴퓨터 사용의 중심이 될 줄은 몰랐음.
     * WWW의 초기 문서를 돌에 새기면 좋겠다는 의견도 있음. HTML 태그까지 포함해서 말이죠.
     * CERN의 한 웹페이지는 아직도 ""공사중""이라고 되어있는데, 언제 완성될지 궁금하다는 농담도 있음.
     * CERN 같이 오픈 사이언스와 오픈 소스를 추구하는 기관에 감사해야 한다는 의견과, 현대 웹은 너무 비대해졌으니 뿌리로 돌아가야 한다는 의견도 있음.
     * 초기 CERN에서 일했던 사람은 데모 사이트를 보고도 점심시간이나 떠올릴 정도로 웹의 잠재력을 알아차리지 못했다고 함.
     * 초기 웹 개발에 참여한 사람들이 지난 30년간 어떤 일을 해왔는지 궁금하다는 의견도 있음.
     * 저작권 문제로 가사 서비스가 중단된 것을 보면 초기부터 저작권 이슈가 있었음을 알 수 있음.
"
"https://news.hada.io/topic?id=14579","Ozempic, 담배ㆍ제과ㆍ주류 산업 위협하는 게임 체인저","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Ozempic, 담배ㆍ제과ㆍ주류 산업 위협하는 게임 체인저

GLP-1 계열 약물이 가공식품 및 주류 산업에 실질적 위협이 될까?

     * 모건 스탠리는 오젬픽이나 마운자로 같은 GLP-1 약물 복용자 300명을 대상으로 소비 습관 변화에 대해 설문조사를 실시함
     * GLP-1 복용자의 40%가 약물 복용 전에는 담배를 매주 피웠으나, 복용 후에는 24%로 감소함
     * 전자담배 사용률도 30%에서 16%로 감소
     * 알코올 소비자 중 56-62%가 GLP-1 복용 후 음주량이 줄었다고 응답하였고, 14-18%는 완전히 금주하게 되었다고 함

식품 및 주류 업계에 대한 우려

     * 도리토스, 오레오, 허쉬 키스 같은 포장 간식 제조사와 대형 레스토랑 체인의 매출에 타격이 우려됨
     * GLP-1 약물 수요는 당분간 줄어들지 않을 것으로 예상됨
     * 모건 스탠리는 2030년까지 GLP-1 시장 규모가 1,050억 달러에 이를 것이며, 2035년까지 미국 인구의 9%인 3,150만 명이 GLP-1을 복용할 것으로 추정함
     * GLP-1 약물이 식료품 및 외식에 대한 소비자 행동과 지출에 상당한 영향을 미친다는 증거가 늘어나고 있음

GLP-1의 잠재적 효능과 전망

     * GLP-1이 각종 중독, 알츠하이머병, 우울증, 불안증에 효과적이라는 연구 결과가 나오고 있어 복용 인구 비율이 9%를 훨씬 넘어설 가능성이 있음
     * 식품 브랜드 의존에서 제약회사 의존으로 바뀌는 것은 양날의 검이 될 수 있으나, 건강, 수명, 사망률 개선 효과가 압도적으로 클 것으로 보임
     * GLP-1 약물 경쟁이 치열해지고 가격이 하락하면 대중에 대한 혜택이 비용을 능가할 것임

GN⁺의 의견

     * GLP-1 약물이 비만, 당뇨병 뿐 아니라 각종 중독과 정신 질환 치료에도 효과가 있다는 연구 결과들이 계속 나오고 있어 주목할 만함. 특히 식욕과 중독 물질에 대한 갈망을 전반적으로 감소시킨다는 점이 흥미로움
     * 그러나 GLP-1 약물은 고가이며, 장기간 복용해야 하는 만성질환 치료제임. 의료보험 적용 범위와 약가 통제가 중요한 이슈가 될 것임. 미국에서는 이미 일부 주정부가 비만 치료 목적의 GLP-1 약물에 대해 메디케이드 보장을 제한하고 있어, 계층/인종간 건강 불평등을 심화시킬 수 있다는 우려가 제기됨
     * 기업의 입장에서 보면 식품업계의 매출 감소는 우려되는 부분이겠지만, 국가 보건 측면에서는 바람직한 변화로 보임. 그러나 식품회사들도 GLP-1 열풍에 편승하여 '다이어트', '건강' 컨셉의 제품을 출시하는 등 마케팅 전략을 수정할 가능성이 있음
     * 현재 GLP-1 계열 약물로는 노보노디스크의 오젬픽/웨고비, 일라이릴리의 트루시티/마운자로 등이 시판 중이며, 다수의 제약사들이 후발 약물을 개발 중임. 향후 GLP-1 의약품 시장에서의 경쟁 상황에 주목할 필요가 있음

   스콧 갤러웨이의 2024년 예상 에서 ""2023년이 GPT-4의 해라면 2024년은 GLP-1의 해가 될 것"" 이라고 했었죠.

        Hacker News 의견

     * Ozempic의 제조 원가는 $5/월이지만 미국에서는 $1000/월에 판매되고 있음. 이 약이 다른 기업에 유의미한 반소비 효과를 미치려면 접근성이 크게 높아져야 하며, 이는 미국의 의료 접근성 개선을 전제로 함. 그러나 이는 쉽지 않아 보임.
     * Ozempic은 주사제이기 때문에 접근 장벽이 높음. 이런 약들이 경구용으로 개발되고 OTC로 전환된다면 긍정적 효과를 미칠 수 있겠지만, 현재로선 미국에서 접근/구매 가능한 사람이 많지 않아 보임.
     * 신약 승인 과정에 대해선 잘 모르지만, 안전성과 효능을 평가하는 초기 단계가 있는 것으로 알고 있음. 하지만 이는 장기(5년 이상) 프로세스는 아닌 것 같음.
     * 많은 사람들이 장기 효과를 모른 채 Ozempic에 열광하는 것이 걱정됨. Ozempic 부작용 서브레딧이 있다고 하는데, 이는 단기 부작용일 뿐임. 내 우려가 승인 과정이나 약물 작용 메커니즘에 대한 무지에서 비롯된 것일 수도 있음.
     * 가공식품 및 담배 회사의 이익에 대한 ""우려가 커지고"" 있음. 2018년 골드만삭스는 ""환자를 치료하는 것이 지속 가능한 비즈니스 모델인가?""라고 질문함.
     * 이러한 약물들이 기존 방식보다 중독 치료에 훨씬 더 효과적인 것으로 밝혀진다면 사회에 큰 변화가 있을 것임.
          + 지금 당장은 시도하고 싶지 않지만, 보험이 알코올 중독 치료제를 보장한다면 기꺼이 시도해 볼 것임.
          + 효과가 있다면 내 삶의 질뿐 아니라 생산성도 향상되어 내가 영향을 미치는 다른 이들의 삶도 개선될 것임. 멋진 생각임.
     * Scott Galloway 등은 오래전부터 이를 주장해 왔고 완전히 맞는 말임. 중독 치료에 대한 연구는 아직 부족하지만 GLP1이 식욕과 음식 갈망(일화적으로는 ""food noise"")을 줄이는 데 효과적이라는 점은 분명함.
          + ""GLP1 Agonist""가 무엇인지 간단히 알아보려면 이 링크를 참고하면 됨.
          + 이는 중독성 물질을 판매하는 기업들에게 엄청난 영향을 미칠 것임. 변화를 가로막는 유일한 것은 약물의 접근성/가격임.
          + 이의 다음 단계는 유전자 치료인 것 같음.
     * Curing Addiction 서브스택 블로그의 6개 게시물 중 4개가 Ozempic에 관한 것인 점이 흥미로움.
     * 중독 위기는 신약 개발에 충분한 자원을 투입한다면 해결할 수 있음. GLP-1 중독 치료제, Vertex의 강력한 비아편계 진통제 등이 여기에 해당함.
          + 중독은 아편유사제, 각성제, 알코올, 담배 등을 포함할 경우 미국에서 DALY의 가장 큰 원인임.
          + 올바른 정책을 통해 막대한 공공 비용이나 인센티브 왜곡 없이 신규 치료법을 신속히 제공할 수 있음. 그러나 현재 추세라면 10년 이상 엄청난 피해가 계속될 것임. 함께 노력합시다!
     * 이러한 효과는 작년부터 시장에 반영되기 시작했음. Citrini는 트위터에서 이를 예측하고 롱/숏 플레이로 많은 돈을 벌었음. 감자칩이나 패스트푸드 회사에 숏을 거는 데는 아직 여지가 있지만 비밀을 발견했다고 생각하면 조심해야 함.
     * 한 매니저의 말에 따르면 $10짜리 HDMI 케이블을 사러 온 고객이 계산대에서 $2짜리 사탕을 충동구매하면 순식간에 20%의 추가 매출이 발생한다고 함. 주유소, 약국 등 모두 이렇게 한다고 함.
     * 카지노에서도 마찬가지라고 함.
"
"https://news.hada.io/topic?id=14548","OpenVoice v2 - 다재다능한 인스턴트 음성 복제","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    OpenVoice v2 - 다재다능한 인스턴트 음성 복제

     * v2 출시되면서 더 나은 오디오 품질, 한국어를 포함한 다국어 지원, 상업적 사용도 무료
     * 화자의 짧은 오디오 클립만으로 음성을 복제하고 여러 언어로 음성을 생성 가능
     * 레퍼런스 화자의 음색을 복제할 뿐만 아니라 감정, 억양, 리듬, 일시 정지, 억양 등 음성 스타일을 세밀하게 제어
     * 훈련 세트에 포함되지 않은 언어에 대해서도 제로 샷(zero-shot) 교차 언어 음성 복제를 실현
     * 상업적으로 사용 가능한 API보다 수십 배 더 적은 계산 비용으로 우수한 성능을 제공
     * V1의 모든 기능이 포함된 V2 의 변경점 (2024/04 출시)
          + 더 나은 오디오 품질: V2는 더 나은 오디오 품질을 제공하는 다른 트레이닝 전략을 채택
          + 기본 다국어 지원: 영어, 스페인어, 프랑스어, 중국어, 일본어, 한국어가 OpenVoice V2에서 기본적으로 지원
          + 무료 상업적 사용 가능: 2024년 4월부터 V2와 V1은 모두 MIT 라이선스 하에 출시되어 상업적 사용도 무료

   GN⁺: OpenVoice : 다재다능한 즉각적인 음성 복제 기술
   GN⁺: OpenVoice - 다재다능한 인스턴트 음성 복제 기술

   GN+를 통해서 몇번 올라왔는데, 이번에 V2가 나오면서 다국어가 지원되고 한국어도 추가되었습니다.
"
"https://news.hada.io/topic?id=14538","서버의 폭력성 선택","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               서버의 폭력성 선택

Hubris IPC의 개요

     * Hubris는 작고 애플리케이션에 의존적이지 않은 커널을 사용하며, 대부분의 코드(드라이버, 애플리케이션 로직, 네트워크 스택 등)는 별도로 컴파일된 격리된 태스크에 존재함
     * 이러한 태스크들은 크로스-태스크 메시징 시스템(IPC)을 사용하여 서로 통신할 수 있음
     * Hubris의 IPC는 커널에 구현된 3가지 핵심 연산(RECV, SEND, REPLY)으로 구성됨
          + RECV: 들어오는 가장 높은 우선순위 메시지를 수집하거나, 메시지가 도착할 때까지 블록함
          + SEND: 메시지와 제어를 수신 태스크로 전송하고 호출자를 중지시킴. 호출자는 응답을 받을 때까지 대기상태로 전환됨
          + REPLY: 이전에 SEND를 사용한 태스크에 응답을 전달하여 계속 진행할 수 있도록 함

새롭고 흥미로운 실패 모드

     * IPC는 태스크 경계를 넘나들고 Hubris의 태스크는 별도로 컴파일되는 프로그램이기 때문에, 컴파일러가 함수 호출 시 가정하는 것과 같은 가정을 IPC에서 할 때는 주의해야 함
     * Hubris에서 IPC 서버 역할을 하는 모든 태스크는 다음과 같은 잠재적 오류를 처리해야 함:
          + 인터페이스와 부적절한 오퍼레이션 코드를 가진 메시지를 받는 경우
          + 기대한 메시지 유형 대신 해석할 수 없는 바이트 묶음을 받거나, 너무 짧거나 긴 메시지를 받는 경우
          + 필요한 메모리(쓰기 가능한 메모리 등)를 받지 못하는 경우

정상적이고 올바른 프로그램에서는 이러한 상황이 발생하지 않음

     * 정상적인 Hubris 프로그램에서는 위에서 언급한 상황들이 발생하지 않음
     * 태스크는 빌드 시스템의 구성에 의해 서로 연결되므로 서로 혼동하기 어려움
     * 클라이언트와 서버는 생성된 Rust 코드를 사용하므로 유형 시스템이 태스크 경계를 넘어 동작하는 것처럼 가정할 수 있음

커널은 어떠한 말도 안되는 상황도 허용하지 않음

     * Unix에서는 시스템 콜의 전제조건을 위반하면 호출자에게 오류 코드를 반환하지만, Hubris에서는 태스크가 즉시 파괴됨
     * Hubris 커널은 합성 오류(Synthetic Fault)라는 개념을 통해 커널 규칙을 위반하는 태스크에 오류를 전달함
     * Hubris에서는 하드웨어 또는 합성 오류가 발생하면 태스크가 즉시 중단되며 복구할 수 없음

서버도 어떠한 말도 안되는 상황을 허용하지 않음

     * REPLY_FAULT라는 13번째이자 가장 특이한 시스템 콜을 통해 서버가 클라이언트에게 오류를 전달할 수 있음
     * REPLY_FAULT는 REPLY와 유사하지만, 메시지를 전달하고 태스크를 실행 가능한 상태로 만드는 대신 오류를 전달하고 태스크를 중단시킴
     * REPLY_FAULT를 통해 필요 없는 IPC 오류 처리를 피할 수 있음. 정상 프로그램은 문제가 발생할 수 없는 것처럼 동작하고, 비정상 프로그램은 오류를 처리할 기회조차 갖지 못함
     * REPLY_FAULT는 액세스 제어 규칙과 같은 애플리케이션별 오류를 정의하고 구현하는 새로운 방법을 제공함

GN⁺의 의견

     * REPLY_FAULT는 서버가 클라이언트 측의 협조 없이도 클라이언트에서 크로스-프로세스 panic!을 발생시킬 수 있는 강력한 메커니즘임. 이를 통해 Hubris는 악의적인 프로그램에 대해 매우 적대적인 시스템이 됨
     * REPLY_FAULT의 단점은 퍼징 테스트가 매우 어려워진다는 것임. 랜덤한 IPC나 시스템 콜을 생성하는 카오스 엔지니어링 태스크는 거의 모든 동작에서 즉시 재설정됨
     * 그러나 정상적인 Hubris 태스크는 동적으로 IPC 메시지를 생성하지 않기 때문에 REPLY_FAULT의 존재 자체를 인식하지 못한 채 작동할 수 있음
     * REPLY_FAULT를 통해 서버는 클라이언트에게 무작위로 오류를 발생시킬 수 있지만, 이에 대한 평가는 아직 완전히 이루어지지 않음
     * Hubris의 공격적인 오류 처리는 개발 초기에 오류를 발견하는 데 도움이 되며, 오류 코드와 달리 오류를 무시할 수 없게 만듦
     * IPC 오류를 처리하는 보편적인 방법을 사용하면 정상적인 프로그램에도 불필요한 오버헤드가 발생할 수 있음. REPLY_FAULT는 이를 피하면서도 비정상적인 프로그램에 대해서는 엄격하게 대응할 수 있는 우아한 해결책으로 보임

        Hacker News 의견

   요약하면 다음과 같습니다:
     * REPLY_FAULT가 연쇄적으로 전파되는지 여부와 그로 인한 취약점에 대한 우려가 제기됨
          + A가 B를 기다리고, B가 C를 기다리는 상황에서 C가 REPLY_FAULT를 하면 A도 함께 종료되는지 확인 필요
          + 만약 그렇다면 전체 시스템이 취약해질 수 있음
          + SEND가 순환 구조라면 의도치 않게 자기 자신을 종료시킬 수도 있음
     * REPLY_FAULT는 접근 제어 등 애플리케이션 특화 오류를 정의하고 구현하는 방법을 제공함
          + 이는 시스템이 작고 밀접하며 대부분 시스템 설계자가 애플리케이션을 작성할 때 유용함
          + 그러나 제3자 코드와 연동할 때는 상대방이 언제든 프로세스를 즉시 종료시킬 수 있어 우려됨
          + 세상에는 관리자에게 시달리는 개발자들이 작성한 많은 열악한 드라이버와 백그라운드 프로세스가 존재함
     * 한 팀이 모든 코드를 작성하는 시스템에서는 의심스러운 클라이언트를 제거하는 것이 반복 속도를 높일 수 있음
     * Hubris는 서버가 클라이언트가 처리할 수 없는 효과를 수행하도록 하는 커널로 볼 수 있음
          + 이는 코드 재사용과 구성을 어렵게 만들지만 실행 모델을 단순화함
          + 정적 임베디드 시스템에서는 올바른 절충안이 될 수 있음
     * Hubris와 Humility는 깊이 몰두하고 싶은 기술이지만 시간과 의무의 한계로 어려움
     * HTTP에 대한 만우절 RFC로 ""당신이 부끄러워해야 합니다""라는 의미의 HTTP 499 상태 코드를 제안함
          + 이는 ""뭐야... 그런데 사실 괜찮네"" 같은 맥락에 어울림
     * 아인슈타인의 명언 ""가능한 한 단순하게, 그러나 지나치게 단순하지 않게""를 인용하며 Hubris의 설계가 후자를 위반했다고 지적함
          + 실제 세계의 혼란을 전혀 허용하지 않는 운영 환경에는 관심이 없음
     * Humility는 디버거로서 훌륭한 이름임
          + 많은 프로그래머들이 ""좋은"" 코드는 디버깅이 필요 없다고 가정하고 디버거 사용을 거부함
     * Linux에서는 소켓만으로 다른 프로그램을 직접 종료시킬 수는 없지만, root 권한으로 다른 프로세스를 종료시키거나 심지어 재부팅할 수 있음
          + 컨테이너에서는 root 권한이 일반적이라 이런 위험성이 존재함
     * ""받아들일 때는 관대하고 내보낼 때는 엄격하라""는 기존 네트워크 시스템의 지혜와는 다소 상충됨
          + 그러나 API를 변경하면서 기존 프로그램의 호환성을 유지하려면 받아들일 때 관대해야 할 수밖에 없음
"
"https://news.hada.io/topic?id=14528","Bun의 새로운 크래시 리포터","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Bun의 새로운 크래시 리포터

Bun의 새로운 Crash Reporter

     * Bun v1.1.5에서는 Zig과 C++을 위한 새로운 크래시 리포트 형식을 만듦
     * 크래시 리포트는 개인 정보가 전혀 없는 약 150바이트 URL에 들어감

  왜 OS 크래시 리포터를 사용하지 않는가?

     * macOS 같은 일부 OS는 내장 크래시 리포터가 있지만, 보통 디버그 심볼을 애플리케이션과 함께 제공해야 함
     * Linux용 디버그 심볼은 약 30MB, macOS는 약 9MB
     * Windows에서 .pdb 파일은 250MB 이상
     * Bun의 모든 설치 파일에 추가하기에는 너무 큰 용량임
     * 하지만 디버그 심볼이 없으면 크래시 정보가 매우 제한적이고, ASLR로 인해 모든 함수 주소가 쓸모없게 됨

  새로운 크래시 리포터

     * Bun v1.1.5에서는 크래시나 패닉이 발생하면 메시지를 출력함
     * bun.report 링크를 클릭하면 스택 트레이스가 URL에 인코딩된 사전 작성된 GitHub 이슈 양식으로 리다이렉션됨

  주소를 유용하게 만들기

     * 함수 주소는 보안상의 이유로 랜덤화된 오프셋을 포함한 애플리케이션 코드가 로드되는 메모리의 포인터
     * 트릭은 단순히 바이너리의 기본 주소에서 주소를 빼는 것
     * 각 플랫폼마다 다른 API가 있어 실제로는 이 함수가 훨씬 더 복잡함
     * 결과 주소에는 여전히 이미지에 대한 오프셋이 포함되어 있음
     * 더 짧은 URL을 인코딩하기 위해 이 오프셋은 제거되지만 remapping하기 전에 다시 추가해야 함

  bun.report의 URL 구조

     * URL이 어떻게 인코딩되었는지 분석해 보면:
          + 플랫폼 : 플랫폼을 나타내는 단일 문자. w는 x86_64 Windows, M은 aarch64 macOS 등
          + 서브커맨드 : bun test, bun install, bun run 등의 서브커맨드를 나타내는 단일 문자
          + 커밋 SHA : 현재 Bun 버전의 커밋 SHA. 나중에 디버그 심볼을 가져오는 데 사용됨
          + Feature Flags : Bun이 크래시되기 전에 사용된 API와 기능에 대한 표시
          + 스택 트레이스 주소 : 앞서 계산된 주소
          + 크래시 타입 : 크래시 유형을 나타내는 단일 문자
          + 크래시 메시지 : 크래시의 메시지로 타입에 따라 형식이 다름

  VLQ는 재미있다

     * URL을 적당히 짧게 유지하기 위해 스택 트레이스 주소는 base64 가변 길이 수량 숫자를 사용하여 인코딩됨
     * 작은 숫자는 더 적은 문자로 인코딩할 수 있으면서도 여전히 큰 숫자를 인코딩할 수 있게 해줌
     * JavaScript 소스 맵에서 행 번호를 저장하는 데 사용되는 것과 동일한 기술

  ""Feature""는 무엇인가?

     * URL은 또한 각 비트가 Bun의 특정 기능 사용 여부에 해당하는 64비트 정수를 인코딩함
     * 이러한 플래그는 크래시를 이끌 수 있는 API와 시스템에 대한 힌트를 제공함
     * Zig의 컴파일 타임 메타프로그래밍은 이 비트필드를 쉽게 만들 수 있게 해줌
     * 기능 추적을 위한 전역 변수의 컨테이너가 이미 있었음
     * std.meta를 사용하여 기능 목록을 반복하고 리스트를 만들 수 있음
     * 그런 다음 기능당 하나의 비트를 사용하도록 동적으로 파생된 팩 구조체를 만들 수 있음

  이것은 코어 덤프와 어떻게 비교되는가?

     * 코어 덤프에는 훨씬 더 많은 정보가 있지만 크기가 크고, 디버그 심볼이 있어야 유용하며, 잠재적으로 민감하거나 기밀 정보를 많이 포함함
     * JavaScript/TypeScript 소스 코드, 환경 변수 또는 기타 중요한 정보를 보고서에 보낼 가능성을 피하고 싶었음
     * 이것이 Zig/C++ 스택 트레이스와 몇 가지 다른 세부 정보만 보내는 이유임
     * 모든 것을 기본적으로 보내는 대신 이 접근 방식은 (아마도) 문제를 진단하는 데 필요한 것만 보냄

  데모

     * 크래시 리포터를 테스트할 수 있는 작은 웹앱을 bun.report 홈페이지에서 사용할 수 있음
     * 크래시 리포트 URL 끝에 /view를 추가하면 이곳에 도착함

  Bun은 샌프란시스코에서 채용 중

     * 이와 같은 프로젝트에 관심이 있다면 샌프란시스코에서 엔지니어를 채용하고 있음
     * JavaScript의 미래를 만드는 데 도움이 될 시스템 엔지니어를 찾고 있음

GN+의 의견

     * 개인 정보 등 민감한 정보를 포함할 수 있는 크래시 덤프 파일 전체를 보내는 대신 최소한의 필요한 정보만으로 구성된 크래시 리포트를 보내는 방식은 좋은 접근법으로 보입니다.
     * 코어 덤프에 비해 훨씬 적은 용량으로 필요한 정보를 제공할 수 있는 것은 장점이지만, 디버깅에 필요한 정보가 부족할 수 있다는 단점도 있을 것 같네요. 필요에 따라 사용자에게 추가 정보를 요청할 수 있다는 점에서 이런 단점은 어느정도 커버할 수 있겠죠.
     * VLQ를 이용해 스택 트레이스 주소를 인코딩하는 아이디어가 인상적이에요. 작은 크기로 많은 정보를 전달할 수 있는 효율적인 방법이네요. JavaScript 소스맵에서 사용되는 기술이라니 재미있는 활용 사례인 것 같아요.
     * 전체적으로 크래시 리포팅 시스템 설계에 많은 고민과 창의적인 아이디어가 녹아 있는 것 같아요. 실제 크래시 리포트를 통해 Bun의 안정성과 사용성 개선에 크게 기여할 수 있을 것 같네요.
     * 기본 리포트에서는 제공되지 않는 추가 정보가 필요한 경우 사용자가 직접 크래시 리포트의 각 필드에 대한 정보를 파악하고 제공해야 할 것 같은데, 고급 사용자가 아니라면 이해하기 어려울 수도 있겠어요. 이를 사용자 친화적으로 개선할 수 있는 방안도 고려해 볼만 합니다.
"
"https://news.hada.io/topic?id=14542","LLM이 결코 할 수 없는 것","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            LLM이 결코 할 수 없는 것

[ LLM의 한계 ]

     * LLM의 목표 이탈과 낮은 신뢰도에 대하여, 또는 LLM이 왜 Conway's Game of Life를 못하는가
     * 지난 몇 년 동안 LLM이 해결할 수 없다고 생각했던 문제들을 훌륭하게 해결했음에도 불구하고, 여전히 간단해 보이는 질문에 답하지 못하는 이유가 불분명함
     * 지난 몇 주간 LLM의 실패 모드를 파악하려고 노력함. 이상한 내용이긴 하지만 흥미로운 주제로 생각됨. AI의 실패는 그 성공보다 더 많은 것을 가르쳐줌
     * 근본적으로 LLM이 결국 수행하게 될 많은 작업을 위해서는 일일이 평가가 필요하다는 점에서 출발했지만, 추론 능력의 한계를 파악해서 학습 능력을 신뢰할 수 있는 방법을 찾는 데 집중함
     * LLM의 추론 능력을 평가하는 것은 어려움
          + 추론 능력을 학습 데이터와 분리하는 것이 어려움
          + 반복적으로 추론하고 질문에 답할 수 있는 능력을 테스트할 방법을 찾고자 함
     * 만족할 만한 기준을 충족하는 가장 간단한 버전으로 시작
          + 3x3, 4x4, 5x5 크기의 단어 그리드를 연속적으로 만들 수 있는지 여부
          + 평가는 쉽게 만들 수 있고, 쉽게 평가할 수 있으면서도 수행하기 어려워야 함
     * 모든 최신 대형 언어 모델(Opus, GPT-4 포함)이 이 작업에 실패함
          + 이 모델들은 경제학, 양자역학 등 난해한 질문에 답하고, 코딩, 그림, 음악, 비디오 제작, 전체 애플리케이션 생성, 심지어 높은 수준의 체스 게임도 가능함
          + 그러나 스도쿠는 할 수 없음

  Reversal Curse

     * LLM에는 모델이 ""A는 B다""라는 형식으로 학습하면, ""B는 A다""라는 역방향으로 일반화하지 못한다는 Reversal Curse가 있음
          + 예를 들어 모델이 ""Valentina Tereshkova는 우주여행을 한 최초의 여성""이라고 학습하면, ""우주여행을 한 최초의 여성은 누구인가?""라는 질문에 자동으로 대답하지 못함
          + 게다가 정답(""Valentina Tereshkova"")의 가능성이 무작위 이름보다 높지 않음
     * 모델은 사람들 사이의 관계를 이해하도록 잘 일반화하지 못함
     * 최고 수준의 모델도 여전히 이 문제를 겪고 있음

  학습 데이터 분포의 문제는 아닐까?

     * 문제가 학습 데이터 분포의 이상함 때문인지 궁금해짐. 우리가 충분한 예제를 보여주지 않은 것 같아서 결정론적인 무언가를 시도해봄
     * Cellular Automata를 예측하도록 transformer를 학습시키는 것으로 테스트해봄
     * 번역 문제는 없어 보이지만 여전히 실패함!
     * 최소한 두 가지 다른 문제가 있음
         1. LLM이 훈련 데이터에 정보가 없고 수행하도록 훈련되지 않아서 수행할 수 없는 문제
         2. LLM이 구축 방식 때문에 수행할 수 없는 문제
     * 우리가 보는 거의 모든 것이 문제 1보다는 문제 2를 상기시킴

  LLM이 근본적으로 할 수 없는 이유

     * 모델이 목표 이탈(goal drift) 문제가 있어서, 한 토큰씩 만들도록 강제되기 때문에 프롬프트 내 문맥을 넘어 일반화하지 못하고 주의를 어디에 둬야할지 모른다고 생각함
          + 이는 프롬프트 주입이 동작하는 이유이기도 함. 주의 메커니즘을 왜곡시키기 때문 ( _### Instruction: ...`과 같은 것을 말함으로써 모델을 탈옥 )
     * LLM에서나 인간에서나 문맥은 부족한 자원임
     * 요약하자면,
         1. LLM은 계산을 모방하는 확률적 모델이며, 때로는 임의로 밀접하게 모방함
         2. 더 큰 모델을 훈련할수록 데이터 내에서 더 많은 암시적 연관성을 학습하여 더 나은 추론에 도움이 될 것임
          + 학습한 연관성이 항상 우리의 아이디어와 깨끗하게 맵핑되는 것은 아님
         3. 추론은 항상 단일 패스임
          + LLM은 훈련 데이터에 해당 프로세스가 자세히 설명되어 있지 않는 한 멈추고, 월드 상태를 수집하고, 추론하고, 이전 답변을 다시 검토하거나 미래 답변을 예측할 수 없음
          + 이전 프롬프트와 응답을 포함하더라도 다음 추론은 여전히 처음부터 단일 패스로 시작됨
         4. 이는 추론의 신뢰성이 떨어지는 일종의 '목표 표류'가 불가피하게 발생하는 문제를 만듦
          + 프롬프트 주입이 작동하는 이유이기도 함 (주의 메커니즘을 왜곡시키기 때문)
          + 이 '목표 표류'는 에이전트나 반복적으로 순차적으로 수행되는 작업의 신뢰성이 떨어진다는 것을 의미함
          + 주의가 선택적이거나 동적이지 않기 때문에 어디에 집중해야 할지 '잊어버림'
         5. LLM은 컨텍스트를 동적으로 재설정할 수 없음
          + 튜링 머신은 테이프를 메모리로 사용하는 반면, 트랜스포머는 내부 상태(self-attention을 통해 관리)를 사용하여 중간 계산을 추적함
          + 이는 트랜스포머가 잘 수행하지 못하는 많은 유형의 계산이 있다는 것을 의미함
         6. 이는 사고의 연쇄(chain of thought)나 다른 LLM을 사용하여 출력을 검토하고 수정하는 등의 방법을 통해 부분적으로 해결할 수 있음
          + 본질적으로 추론을 정상 궤도에 올려놓는 방법을 찾는 것
          + 충분히 영리한 프롬프트와 단계별 반복을 통해 LLM은 훈련 데이터에 있는 거의 모든 것을 이끌어낼 수 있음
          + 모델이 개선됨에 따라 각 추론도 개선되어 신뢰성이 높아지고 더 나은 에이전트를 가능하게 할 것임
         7. 많은 노력을 기울이면 연결된 GPT 시스템, 여러 내부 반복, 지속적인 오류 검사 및 수정, 외부화된 메모리 등 기능 구성 요소를 갖추게 될 것임
          + 그러나 이것은 여러 영역에서 AGI에 접근하기 위해 무차별적으로 강행하더라도 훈련 데이터를 넘어 진정으로 일반화할 수는 없음
          + 그럼에도 불구하고 여전히 기적적인 일임

[ 실험 - GPT가 Wordle을 학습할 수 없는 이유 ]

     * LLM은 Wordle을 할 수 없음
          + 스도쿠나 단어 그리드(가장 간단한 형태의 크로스워드)도 마찬가지
     * 이는 놀라운 일인데, 이러한 문제들이 어려운 문제가 아니기 때문
          + 초등학생도 시도할 수 있지만, 최고의 LLM조차도 이를 수행하는 데 실패함
     * 첫 번째 가정은 훈련 데이터의 부족일 것
          + 하지만 여기서는 그렇지 않을 것임
          + 규칙은 분명히 데이터에 있기 때문
          + Wordle이 현재 LLM의 훈련 데이터셋에서 어쩔 수 없이 누락된 것은 아님
     * 또 다른 가정은 토큰화 문제 때문이라는 것
          + 하지만 이것도 사실이 아님
          + 여러 기회를 제공하고 이전 답변을 제공하여 반복할 수 있는 여지를 주더라도, 여전히 올바른 해결책을 생각해내는 데 어려움을 겪음
          + 문자 사이에 공백을 주어도 운이 좋지 않음
     * 이전 답변과 컨텍스트, 질문을 다시 제공하더라도 종종 [3,4] 셀에서 무언가를 편집하는 대신 전체 답변 시퀀스를 다시 시작함
     * 대신 그 본질상 각 단계는 어떤 모델도 수행할 수 없는 것으로 보이는 서로 다른 수준의 반복적 계산을 필요로 하는 것 같음
          + 어떤 면에서 이것은 이해가 되는데, 자동 회귀 모델은 한 번에 하나의 정방향 패스만 수행할 수 있기 때문
               o 기존 토큰 저장소와 출력을 스크래치 패드로 사용하여 계속 생각을 말할 수 있지만, 너무 빨리 추적을 잃어버림
     * 여기서의 결론은 각 단계가 메모리와 계산을 모두 필요로 할 때, 그것은 트랜스포머가 현재 가지고 있는 레이어 수와 어텐션 헤드 내에서 해결할 수 없는 것으로 보인다는 것
          + 심지어 조 단위 토큰의 GPT-4와 같은 매우 큰 모델에서도 마찬가지
     * 아이러니하게도 어디에 주의를 집중해야 할지 파악하지 못함
          + 현재 주의(attention)가 수행되는 방식이 정적이고 시퀀스의 모든 부분을 동시에 처리하기 때문
          + 여러 휴리스틱을 사용하여 더 선택적이고 컨텍스트를 동적으로 재설정하여 대안을 시도하는 대신
     * 이는 현재 측정되는 주의(attention)가 우리가 하는 방식처럼 실제로 다중 스레드 계층 분석이 아니기 때문
          + 아니면 암시적으로 그럴 수 있지만, 그것이 만드는 확률적 평가는 그 컨텍스트를 개별 문제에 번역하지 않음

[ 실험 - LLM에 Cellular Automata 가르치기 ]

     * 학습하면서 원하는 결과를 얻을 때까지 무한 데이터를 생성할 수 있어서 기본기는 가르칠 수 있을 거라 생각했음
     * 토이 transformer를 만들어서 예측해보려 함
     * 왼쪽은 CA, 오른쪽은 Transformer 출력인데 구별할 수 있는지 보라는 요청이 있음
     * 결과를 예측하도록 학습시킬 수 없었고 이유를 알아내지 못함
     * 토이 모델이긴 했지만 시도해본 여러 방정식을 학습할 정도로 동작했고 약간의 일반화도 했음
     * 그리드 크기를 줄이고, 하이퍼파라미터 최적화를 해봤지만 여전히 안됨
     * 물리적 레이아웃에 대한 정보가 더 필요해서 그런가 싶어 CNN 레이어를 추가하고 positional embedding이 X, Y 축을 명시적으로 다루도록 바꿔봄. 그래도 안됨
     * 절망에 빠진 채 간단한 방정식 하나라도 가르쳐보려 함
     * 처음엔 전혀 동작 안했는데 시작/종료 토큰을 추가하자 갑자기 되기 시작함. Transformer는 이상함
     * 크기는 완벽하진 않지만 거의 학습하는 중이었음. 머리나 레이어가 거의 없고 max_iter가 1000이었음에도 불구하고 말이죠.
     * 아이디어는 분명 여러 상태를 학습하고 이력을 유지해야한다는 거라 그 기능을 어떻게든 추가해야겠다 싶었음. 그래서 출력 이후에 다른 입력을 추가하도록 디코더를 바꿔봄. 이는 또 다른 RNN 레이어를 추가하거나 이전에 무슨 단계를 거쳤는지에 대한 메모리를 제공하는 것과 동일함
     * 하지만 여전히 안됨. Cellular automata로 돌아가서 기초적인 것부터 해봐도 동작 안함. 1차원인데다가 정말 쉬운 규칙도 있는데 말이죠. 튜링 완전한 110 뿐 아니라 0 같은 것 말입니다.
     * 일련의 문제에서 정확한 답을 내는 걸 학습했다고 해서, 근본 규칙을 학습했다는 뜻일까요? 아니면 그 규칙의 유사체를 학습해서 주어진 분포 내에서는 결과를 흉내낼 수 있게 된 걸까요? 잘못된 방식으로 틀리기 쉬운 상태로요?
     * 토이 모델이나 GPT 3.5 뿐 아니라 GPT-4, Claude, Gemini 같은 더 큰 LLM에서도 동일한 문제를 보임. 최소한 챗 모드에서는요.
     * fine-tuning을 하든 특수 학습을 하든, LLM은 Conway의 Game of Life를 할 수 없어 보임
     * 누군가 이걸 해결한다면 굉장히 흥미로울 것임. 적어도 왜 이런 문제가 있는지 설명할 수 있다면

[ 지금까지 이 문제를 어떻게 해결해왔나 ]

     * 이 시스템을 설계할 때 우리의 지능을 더 많이 반영할수록, 최종 출력물이 필요한 변환을 더 잘 모방할 수 있음
     * 개별 퍼즐을 하나씩 가르치고 추론이 전이되기를 바랄 수 있지만, 일반화를 정말 학습했는지 어떻게 알 수 있을까? 최근까지만 해도 덧셈과 곱셈조차 이 모델에겐 어려웠음
     * Victor Taelin은 ""GPT는 A::B 문제를 절대 풀 수 없다""고 주장함. transformer 기반 모델이 학습 집합 밖의 새로운 문제를 진정으로 학습하거나 장기 추론을 수행할 수 없다는 예시였음
          + 그는 ""강력한 GPT는 기본적으로 가중치 안에 회로 설계자를 진화시킨 것""이라며 ""하지만 계산 모델로서 attention의 경직성 때문에 그런 진화된 회로가 충분히 유연해질 수 없다""고 말함
          + ""AGI가 그 안에서 자라려 하지만, 부과된 계산 및 통신 제약 때문에 할 수 없는 것 같다. 인간 두뇌는 항상 시냅스 가소성을 겪는다는 걸 기억하라. 훨씬 작은 규모로 학습되더라도 AGI로 이어질 가능성이 더 높은 유연한 아키텍처가 존재한다. 하지만 우리는 아직 그걸 모른다.""
     * 그는 이 문제에 1만 달러의 현상금을 걸었고, 하루 만에 해결됨.

[ LLM은 정말 얼마나 학습 가능할까? ]

  LLM의 학습 능력에 대한 의문점들

     * LLM은 단순한 반복 상호작용이나 제약 조건 선택과 같은 아동용 게임에서조차 실패하는 경우가 많음
     * 그러나 LLM은 어려운 수학 문제, 경쟁적인 경제학 추론, 페르미 추정, 심지어 명시적으로 학습하지 않은 언어로 된 물리학 문제도 해결할 수 있음
     * LLM의 답변은 프롬프트 방식에 크게 의존함
     * LLM은 뛰어난 직관을 보여주지만 제한된 지능을 가짐
     * 추론 단계가 늘어날수록 LLM은 목표를 파악하고 집중하는 데 어려움을 겪음

  외부 메모리를 추가한 신경망의 성능 향상

     * RNN 유형의 연결을 추가하면 약간의 차이는 있지만 문제를 완전히 해결하기에는 충분하지 않음
     * 신경망에 외부 메모리를 추가하면 다양한 불규칙한 패턴을 학습할 수 있음
     * 구조화된 메모리(스택이나 메모리 테이프)를 추가한 네트워크만이 문맥 자유 및 문맥 민감 작업에 성공적으로 일반화할 수 있음

  연쇄 사고 프롬프팅과 스크래치패드의 한계

     * 연쇄 사고 프롬프팅, 스크래치패드 사용, 중간 생각을 종이에 적는 것 등은 모두 목표 표류를 줄이기 위한 사고 과정의 예시임
     * 그러나 이러한 방법들은 여전히 원죄(original sin)에 의해 방해를 받음
     * 이전 입력에 의존하는 출력, 특히 각 단계에서 계산이 필요한 경우에는 현재의 트랜스포머 기반 모델에는 너무 복잡하고 길어서 처리하기 어려움

  자기회귀(autoregression)의 저주

     * 모델의 규모가 커질수록 장기 연쇄 사고에서 더 나은 성능을 보이지만, 추론 체인의 임의의 지점에서 다른 능력과는 무관해 보이는 오류를 지속적으로 보임
     * 동일한 작업을 여러 단계에 걸쳐 해결하더라도 단계 수가 길어질수록 실수를 하게 됨
     * GPT-4는 GPT-3.5보다 환각과 오류가 적음
     * 워들(Wordle) 게임에서 실패하는 GPT-4나 Opus와 같은 대규모 모델을 만드는 것이 정답일까?

  인지의 본질에 대한 질문

     * 초등학생도 쉽게 해결할 수 있지만 수조 토큰과 수십억 달러가 투입된 정교한 모델은 해결하지 못하는 문제 유형이 존재한다면, 이는 우리의 인지 본질에 대해 무엇을 말해주는가?
     * AGI에서 G(일반화) 부분이 가장 어려운 부분이며, 이는 쉽게 분포를 넘어 일반화될 수 없음
     * 우리가 가진 것은 바벨의 도서관 중 일부분에 더 가까우며, 이미 쓰여진 책뿐만 아니라 그 책들 사이의 간격에 존재하는 정보도 읽을 수 있음

  인간과 LLM의 학습 데이터 차이

     * 인간은 평생 3만~5만 권의 책을 읽을 수 있지만, 대부분의 사람들은 그 중 1%도 채 읽지 못함 (최대 1GB 데이터)
     * 반면 LLM은 인터넷에 있는 모든 것과 그 외에도 많은 것을 흡수했으며, 모든 영역과 학문 분야에 걸쳐 수천억 단어를 학습함 (GPT-3는 45TB 데이터로 학습)
     * 누군가 200만 권의 책을 읽는다면 어떤 모습일지, 단순한 패턴 인식기가 200만 권의 책을 읽는다면 무엇을 할 수 있을지에 대한 답은 쉽게 나오지 않음
     * LLM은 학습 데이터의 패턴과 암시적 규칙을 학습하지만 이를 명시적으로 만들기는 쉽지 않음
     * LLM이 패턴 일치와 관련된 방정식을 알 수 있는 방법이 없다면 일반화하는 법을 배울 수 없기 때문에 여전히 역전의 저주(Reversal Curse)가 존재함

[ LLM은 컨텍스트 재설정이 불가능함 ]

     * LLM이 실체, 뉴런, 신피질의 일부와 같다는 것은 특정 시점에서는 유용한 비유이지만, 우리가 LLM에서 보는 행동을 완전히 포착하지는 못함
     * 패턴을 학습할 수 있는 모델의 흥미로운 점은 데이터 세트에 명시적으로 포함되지 않았을 수 있는 패턴을 학습한다는 것
     * LLM은 언어를 학습하는 과정에서 데이터에 내재된 여러 연결고리를 파악하여 폰 노이만과 찰스 디킨스를 연결하고 우리가 했을 만한 충분히 사실적인 모사물을 출력할 수 있음

  데이터 세트의 복잡성과 모델 크기의 한계

     * 데이터 세트가 인류의 모든 복잡성을 인코딩한다고 가정하더라도, 작은 데이터 세트 내에서조차 존재하는 그러한 패턴의 수는 모델의 크기를 빠르게 압도할 것임
     * 이는 거의 수학적 필연성임
     * 셀룰러 오토마타 문제에서 LLM이 진정으로 방법을 학습했는지, 얼마나 신뢰할 수 있는지는 불분명함
     * LLM의 실수는 성공보다 그들이 모르는 것에 대한 더 나은 지표임

  학습하는 법을 학습하는 LLM의 한계

     * 더 큰 신경망은 데이터에서 학습할 뿐만 아니라 학습하는 법도 학습할 것임
     * 이는 LLM이 몇 가지 예시를 제공받고 학습 세트에서 보지 못한 문제를 수행할 수 있는 이유임
     * 그러나 LLM이 사용하는 방법은 충분히 일반화되지 않는 것 같으며, 특히 어디에 주의를 기울여야 하는지 학습하는 측면에서는 그러함
     * 학습하는 법을 학습하는 것은 우리에게도 단일한 전역 알고리즘이 아님
     * 어떤 것들에는 더 잘 작동하고 다른 것들에는 덜 작동함
     * 다른 유형의 문제에 대해 다른 방식으로 작동함
     * 이 모든 것은 동일한 수의 매개변수로 작성되어야 하므로, 이러한 가중치를 통해 수행될 수 있는 계산은 머펫에 대해 답할 수 있을 뿐만 아니라 현 이론을 파괴할 다음 최고의 물리학 발견에 대해서도 말해줄 수 있음

  상호작용하는 기호 시퀀스의 복잡성

     * 기호 시퀀스에서 한 기호의 존재나 위치가 다음 기호의 정보 내용에 영향을 미치는 방식으로 상호작용하면, 데이터 세트의 전체 섀넌 엔트로피가 개별 기호만 보고 제안되는 것보다 더 높을 수 있음
     * 이는 콘웨이의 라이프 게임과 같이 상태에 의존하는 것들을 정말 어렵게 만듦
     * 이것이 라이프 게임 데이터 세트에 대해 미세 조정되었음에도 불구하고 GPT가 실제로 패턴을 학습할 수 없는 것처럼 보이는 이유이기도 함
     * 대신 GPT는 질문에 답할 수 있을 만큼 충분히 학습함 (일종의 굿하트 법칙)

  간단한 테스트로 LLM을 정의하는 것의 어려움

     * LLM에 대해 실행할 수 있는 간단한 테스트로 이들 중 하나를 정의하라는 고차 질문을 하는 것은 어리석은 행동임
     * 이들 중 하나를 정의하는 것은 아마도 반세기 이상의 과학 연구 개요를 효과적으로 정의하는 것이기 때문

[ 더 많은 에이전트가 필요함 ]

     * 현재 이론과 유사하게, LLM 모델에 더 많은 재귀를 추가하면 당연히 더 좋아질 것임
     * 그러나 원래의 목표와 지금까지의 경로를 염두에 둘 수 있는 한에서만 단계별로 더 복잡한 계획 문제를 해결할 수 있을 것임
     * LLM이 왜 신뢰할 수 없는지는 여전히 불분명함
     * GPT-4가 GPT-3.5에 비해 더 신뢰할 수 있는데, 이는 단순히 학습에 더 능숙해졌기 때문인지 아니면 규모 확장으로 인해 신뢰성이 증가하고 환각이 감소하기 때문인지 알 수 없음

  에이전트: 강력한 활용 사례

     * 에이전트, 즉 우리를 위해 전체 작업을 수행할 수 있는 자율적인 실체가 LLM의 꿈의 사용 사례임
     * 실제로 많은 작업에서 더 많은 에이전트가 필요함
     * 일부 작업에서 조금 더 잘 작동한다면, 충분한 수의 에이전트가 있으면 모든 작업에서 더 잘 작동할까? 가능성은 있지만 현재로서는 그럴 것 같지 않음
     * Cognition Labs의 Devin과 같은 옵션에서 우리는 그것이 얼마나 강력할 수 있는지 엿볼 수 있었음 (실제 사용 사례 제시)

  향후 몇 년 동안 상당 부분의 일자리로 확장 가능성

     * 이러한 행동이 향후 몇 년 동안 상당 부분의 일자리로 확장될 수 있을까? 그럴 수 있을 것 같음
     * 일자리마다 개별적으로 접근해야 할 것이며, 이는 쉽게 확장되지 않는 전문 모델이 될 것임 (모든 것을 지배하는 하나의 모델이 아님)
     * 오픈 소스 버전은 이미 핵심 요소의 일부를 알려주고 있음
          + 정보가 기본 모델에 도달하는 순서와 양을 신중하게 검토하고, 이전에 본 것처럼 그들의 한계를 고려하여 번창할 수 있는 환경을 만드는 것

  GPT의 한계와 해결책

     * GPT가 라이프 게임과 같은 문제를 스스로 해결할 수 없거나 단계를 생각해 볼 때조차 해결할 수 없다는 것은 중요하지 않음
     * 중요한 것은 GPT가 그것을 해결하기 위한 프로그램을 작성할 수 있다는 것임
     * 즉, 모든 프로그램에서 프로그램을 작성하는 것이 타당한 상황을 인식하도록 GPT를 훈련시킬 수 있다면 AGI에 가까워질 수 있음 (내가 가진 견해)

  모델 용량의 한계와 시각-언어 양식 간 경쟁 관계

     * 적어도 작은 모델에서는 학습되는 내용에 대해 가중치 간에 경쟁이 존재함
     * DeepSeek 논문에서 본 최고의 코멘트:
          + DeepSeek-VL-7B는 수학(GSM8K)에서 어느 정도 감소를 보여줌
          + 이는 시각과 언어 양식 간의 조화를 촉진하려는 노력에도 불구하고, 여전히 둘 사이에 경쟁 관계가 존재함을 시사함
          + 이는 제한된 모델 용량(7B)에 기인할 수 있으며, 더 큰 모델이 이 문제를 상당히 완화시킬 수 있음

[ 결론 ]

     * 앞의 사례를 통해 배운 것들
          + LLM(Large Language Model)은 현재로서는 해결할 수 없는 특정 유형의 문제들이 존재함
               o 특히 이전 상태에 의존하거나 미래 상태를 예측해야 하는 등 더 긴 추론 단계가 필요한 문제들이 이에 해당함
               o Wordle 게임을 하는 것이나 CA(Cellular Automata)를 예측하는 것 등이 그 예시임
          + 더 큰 LLM을 사용하면 문제에 대한 단계별 정보와 따라야 할 여러 예시를 제공함으로써 어느 정도 추론을 가르칠 수 있음
               o 그러나 이는 실제 문제를 추상화하고 답을 생각하는 방식을 프롬프트에 넣는 것임
          + 이는 다음과 같은 방법으로 개선될 수 있음
              1. 더 나은 프롬프팅
              2. 중간 단계에서 메모리, 계산, 도구에 대한 접근성 향상
               o 그러나 인간과 관련하여 사용하는 일반화 가능한 의식 수준에는 도달하지 못할 것임
               o LLM에 입력한 모든 정보는 아마도 적절한 프롬프트가 주어지면 이끌어낼 수 있을 것임
          + 따라서 모델을 적절하게 사용하는 데 있어 엄청난 부분은 수행할 작업에 따라 적절하게 프롬프트를 만드는 것임
               o 이는 외부 가드레일과 함께 적절하게 응답하도록 모델을 프라이밍하기 위해 계산 문제에 대한 정답과 오답의 긴 시퀀스를 신중하게 구성해야 할 수 있음
          + '관심(Attention)'은 목표 편향(Goal Drift)의 영향을 받기 쉬우므로 상당한 외부 스캐폴딩 없이는 신뢰할 수 있게 만들기 매우 어려움
               o LLM이 범하는 실수는 성공보다 **훨씬 더 유익한 정보를 제공**함
     * AGI(Artificial General Intelligence)에 도달하고 충분한 수준의 일반화를 달성하기 위해서는 근본적인 아키텍처 개선이 필요함
          + 기존 모델의 규모를 확장하고 Jamba 등의 새로운 아키텍처를 추가하면 더 효율적이고 빠르고 안정적으로 작동하게 되겠지만, 일반화 부족이나 '목표 편향'과 같은 근본적인 문제를 해결하지는 못함
     * 특화된 에이전트를 추가하여 ""프롬프트 엔지니어링""을 수행하고 17개의 GPT가 서로 대화하도록 하는 것만으로는 충분하지 않음
          + 그러나 충분한 임시방편을 사용하면 우리가 관심 있는 영역에서는 결과를 구분할 수 없을 수도 있음
     * 초기 AI 시대에 체스 엔진이 처음 등장했을 때, 제한된 처리 능력과 거의 쓸모없는 검색 또는 평가 기능만 있었음
          + 그래서 하드코딩된 오프닝이나 엔드게임, 더 나은 검색을 위한 반복 심화(Iterative Deepening), 알파-베타 가지치기(Alpha-Beta Pruning) 등과 같은 임시방편에 의존해야 했음
          + 결국 점진적인 개선을 통해 극복되었지만, LLM에서도 마찬가지로 그렇게 함
     * 저자가 선호하는 아이디어는 신뢰성이 다소 향상되면 서로 연결된 자체 하위 에이전트를 가진 다른 전문 에이전트를 지시할 수 있는 다양한 수준의 계층 구조에서 여러 계획 에이전트를 두는 것임
     * 우리는 추론, 반복을 위한 모듈을 추가하고, 영구 및 무작위 액세스 메모리를 추가하며, 심지어 물리적 세계에 대한 이해를 제공할 수 있음
          + 이 시점에서 동물에서 얻는 것과 같은 방식으로 LLM에서 의식의 근사치를 얻을 수 있을 것 같지만, 과연 그럴까?
          + 분포를 벗어나면서 우리가 필요로 하는 것을 모방하는 매우 설득력 있는 통계 모델로 끝날 수도 있음
     * 이것이 저자가 LLM을 퍼지 프로세서(Fuzzy Processor)라고 부르는 이유이며, ""LLM이 되는 것이 어떤 것인가""와 같은 질문의 끝이 순환 대화로 끝나는 이유임
     * 오늘날 우리가 가진 것이 기적적이지 않다는 어떤 징후로도 받아들여서는 안 됨
          + 비터 레슨(Bitter Lesson)이 AGI까지 모두 외삽되지 않을 것이라고 생각한다고 해서 우리가 이미 가진 결실이 대단하지 않다는 의미는 아님
     * 저자는 LLM이 보는 데이터에서 ""학습""한다고 확신함
          + 단순한 압축기도 앵무새도 아님
          + 학습 데이터셋이나 프롬프트의 서로 다른 부분에서 뉘앙스 있는 데이터를 연결하고 지능적인 응답을 제공할 수 있음
     * 토마스 네이글(Thomas Nagel)은 아마도 LLM이 되는 것이 어떤 것인지에 대한 질문을 했을 것임
          + 포유류로서 박쥐는 LLM보다 우리에게 더 가까우며, 그들의 내부가 우리에게 흐릿하다면 새로운 모델의 내부 기능을 이해할 가능성은 얼마나 될까?
          + 아니면 반대로, LLM에서는 모든 가중치와 회로를 자유롭게 검사할 수 있기 때문에 우리가 사용하는 이러한 모델에 대해 어떤 수준의 통찰력을 가질 수 있을까?
     * 이것이 저자가 공식적으로 총알을 물 용의가 있는 이유임
          + 충분히 확장된 통계는 학습 데이터의 분포 내에서 지능과 구별할 수 없음
          + 모든 것에 대해서도, 모든 것을 할 만큼 충분하지도 않지만, 신기루도 아님
          + 그렇기 때문에 성공보다는 테스트에서의 실수가 진단에 훨씬 더 유용함
     * LLM이 무엇이든 할 수 있는 기계라면, 결국 대부분의 일을 할 수 있어야 함
          + 많은 자극과 찌르기를 통해서 가능함
          + 바흐나 폰 노이만의 천재성에 영감을 주지는 못하겠지만, 보다 평범하지만 중요성이 떨어지지 않는 혁신과 발견은 가능함
          + 그리고 의식이나 도덕적 인격을 필요로 하지 않고도 그렇게 할 수 있음
          + 쿤(Kuhn)이 말한 패러다임 내의 도약을 자동화하거나 빠르게 진행할 수 있다면, 패러다임 사이를 자유롭게 도약할 수 있게 됨

        Hacker News 의견

   요약:
     * 현재 LLM(대형 언어 모델)은 Wordle이나 Rule 110과 같은 셀룰러 오토마타 예측 등 인간에게는 쉽지만 LLM에게는 어려운 (또는 불가능할 수도 있는) 문제들이 존재함. 그 이유는 아직 완전히 밝혀지지 않음.
     * 프롬프트에 예시와 단계별 지침을 제공하는 것은 LLM 스스로 ""추론 단계""를 파악하는 것이 아니라 사용자가 그것을 LLM에 건네주는 것임. 우리는 지능적이지만 근본적인 한계에 부딪히는 것 같은 ""추론 기계""를 가지고 있음.
     * 현재의 Attention 메커니즘을 사용하는 더 큰 모델과 더 나은 프롬프팅으로 AGI를 달성할 수 있을지는 불분명함. Attention은 매우 경직된 반면 인간의 뇌는 항상 시냅스 가소성을 겪고 있음. AGI가 가능한 더 유연한 아키텍처가 존재할 수 있지만, 우리는 아직 그것을 모름.
     * 현재로서는 계산 문제에 대한 올바른 답과 잘못된 답을 신중하게 구성하고, 모델이 적절하게 응답하도록 프라이밍하며, 외부 가드레일을 많이 적용하는 등 현재 AI 모델을 사용하려면 긴 프롬프트를 신중하게 구성해야 함.
     * Attention은 ""목표 표류""로 고통받는 것 같아서 모든 외부 지지대 없이는 신뢰성을 확보하기 어려움.
     * LLM의 한계를 이론적으로 정량화하려면 현재 할 수 없는 것들의 경험적 증거 목록이 아니라 이론적 결과에 의존해야 할 것임. 관련 문헌에서는 ""expressibility""라는 용어를 찾아볼 수 있음.
     * 숫자 표기 규칙 같은 간단한 규칙조차도 많은 예제에서 실패하고, 프롬프트를 어떻게 구성해도 제대로 동작하지 않는 경우가 많음. 놀랍지만 여전히 많은 제한이 있음.
     * ""흥미로운 사실을 언급하되 흥미롭다고 말하지 말라""는 지시를 제대로 따르지 못하는 등 특정 행동을 하지 말라고 지시받는 것이 서툰 편임. 오히려 하지 말라고 하면 할 가능성이 높아짐.
     * LLM이 ""추론""한다고 가정하더라도 세계에 대해서가 아니라 문서에 포함된 사실, 개체, 인과관계에 비추어 환각에 대처하는 Agentic AI를 구축함. 또한 매우 큰 토큰 거리로 교차 추론에 대처함.
     * 사람 간의 관계, 원한, 동맹 등의 이차 복잡성을 잘 처리해야 하는 필요성이 더 높은 수준의 지능으로 이어졌다고 생각됨.
     * Wordl/Sudoku 같은 일부 ""절대 못하는"" 것들은 텍스트 표현의 아티팩트일 뿐이며, 다른 도메인으로 변환하면 동일한 Transformer 아키텍처를 사용해도 성공률이 훨씬 높아질 것임.
     * 모든 도메인에 맞춤형 AGI를 만들 필요는 없고, 문제를 분해하여 전문 도구에 할당한 다음 재조립하여 답을 만들 수 있을 만큼 잘 추론할 수 있는 에이전트와 모델/도구 카탈로그만 있으면 됨.
"
"https://news.hada.io/topic?id=14620","BASIC 프로그래밍 언어 60주년","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          BASIC 프로그래밍 언어 60주년

     * BASIC은 1964년 데뷔한 쉽고 사용하기 편한 언어로 Apple, TRS-80, IBM, Commodore PC 등을 이끌어옴

BASIC이란?

     * 전통적인 형태로는 한 줄씩 실행되는 인터프리터 방식의 프로그래밍 언어
     * GOTO 같은 명령어로 줄 사이를 이동할 수 있어 초심자들이 반복문을 쉽게 만들 수 있음
     * 오늘날 대부분의 언어는 함수나 객체지향 등 다른 패러다임을 사용하지만, BASIC의 쉬운 문법과 영어 키워드는 초심자에게 인기가 있고 사용하기 쉬웠음

BASIC으로 가는 여정

     * BASIC 이전에는 Fortran, Algol, COBOL 등 복잡한 언어가 전문가용으로 주로 사용됨
     * Kemeny와 Kurtz는 아마추어도 컴퓨터를 사용할 수 있는 사용자 친화적 언어의 필요성을 봄
     * 1956년 DARSIMSCO(Dartmouth Simplified Code), DOPE(Dartmouth Oversimplified Programming Experiment) 등을 거쳐 1963년 BASIC 개발 시작
     * Kemeny는 NSF 지원금으로 GE-225 컴퓨터를 데트모스대에 도입하고 첫 범용 시분할 시스템 구축
     * Kemeny와 Kurtz 그리고 학부생들이 시분할 시스템을 만들어 데트모스 모두에게 컴퓨터 접근을 개방함
     * BASIC의 단순함과 강력함으로 인해 학생과 교수진에게 빠르게 인기를 얻음

BASIC이 PC로 진출

     * GE 225 컴퓨터 구매 계약의 일환으로 GE용 시분할 OS도 개발했었음
     * 이 OS에서 실행되는 BASIC으로 전국의 대학, 고교, 개인들이 메인프레임에 접속해 프로그래밍이 가능해짐
     * 1975년 Paul Allen과 Bill Gates가 Altair 8800 등 개인용 컴퓨터를 위해 BASIC을 적용하며 Microsoft 설립
     * 1976년 Steve Wozniak이 최소한의 자원으로 Apple I용 BASIC 인터프리터를 직접 개발함
     * 이는 이듬해 Apple II의 Integer BASIC이 되었고, Applesoft BASIC으로 Apple II 전체 수명에 걸쳐 핵심 역할을 함
     * 1970년대 후반~1980년대 초, Atari 800, TRS-80, Commodore VIC-20, C64, TI-99/4A, BBC Micro, IBM PC 등의 인기 가정용 컴퓨터에서 ROM에 내장되거나 쉽게 접근 가능한 프로그래밍 환경으로 제공되며 BASIC은 계속 주요 역할을 함
     * Compute! 같은 초기 컴퓨터 잡지에서는 한 줄씩 입력할 수 있는 BASIC 코드를 게재하기도 함

오늘날의 BASIC

     * 오늘날 BASIC은 레트로컴퓨팅 취미 분야에서는 여전히 인기지만, 실용적인 언어로는 거의 사용되지 않음
     * 그러나 진화를 계속하며 완전히 사라지지는 않음
     * 다양한 플랫폼용 BASIC 방언이 존재하지만 Microsoft 것이 가장 널리 사용됨
     * GW-BASIC, QuickBasic에 이어 Visual Basic, VBA, MS Small Basic 등이 이어받음
     * 1991년 출시된 Visual Basic은 Windows 앱 개발에 인기를, VBA는 MS Office 자동화에 널리 사용됨
     * 2008년 출시된 MS Small Basic은 초보자 프로그래밍 교육용으로 사용됨
     * 한편 Python이나 JavaScript 같은 현대 언어들이 BASIC의 역할을 대신하고 있음
     * 이들은 단순성, 가독성, 사용 편의성을 우선시해 입문 프로그래밍 과정이나 신속한 앱 개발에 인기

GN⁺의 의견

     * BASIC은 텔레타이프 시대 라인 번호를 사용해 프로그램을 편집하고 삽입/삭제하는 방식으로 설계되었다는 점이 중요함. 펀치카드로는 할 수 없던 것을 가능케 했음.
     * BASIC은 실용성이 떨어지면서도 Visual Basic 등으로 계속 진화하며 명맥을 이어왔음. 한편으로는 Python 같은 친숙한 문법의 언어들이 BASIC의 역할을 대신하고 있음. 즉, BASIC 정신은 계속 이어지고 있다고 볼 수 있음.
     * 개인용 컴퓨터 초기 시절, ROM에 내장된 BASIC은 사용자들이 컴퓨터를 배우고 활용하는데 결정적 역할을 했음. 하지만 GUI 환경이 일반화되면서 command line 기반의 BASIC은 자연스럽게 인기를 잃을 수 밖에 없었음.
     * 오늘날 교육용 프로그래밍 언어로는 Scratch, Python 등이 주로 사용되고 있음. BASIC처럼 쉽고 재미있게 프로그래밍을 배울 수 있지만, 실제 활용도 측면에서는 BASIC보다 더 강력함.

   베이직에 멜로디를 넣어 반주시키고 노래연습했던 아주 오래전 기억..

   저는 컴퓨터 처음을 GW-BASIC으로 배워서 그런지, 베이직에 대한 향수가 있네요
   처음에 For 문을 배워서 *로 피라미드 출력했던게 아직도 기억이 납니다.
   비쥬얼베이직은 꽤 오래동안 사용하기도 했고요. VBA도 한참 썼네요.

   사실 뭔가 컴퓨터에게 안익숙해도 일을 시킬수 있어! 라는걸 배우기에는 아직도 베이직이 괜찮지않나? 생각이 듭니다.
   파이썬으로 시작하면 좋다지만, 제가 친하지 않아서 그런걸수도 ㅎㅎ

   BASIC으로 했던 별찍기에 대한 추억이 새록새록하네요 ㅎㅎ

        Hacker News 의견

     * 한 댓글러는 대학 시절 호텔 야간 감사로 일했는데, BASIC을 이용해 호텔 객실 관리 시스템을 자동화하여 업무 효율을 크게 높였음. 당시에는 더 좋은 언어가 없었지만 BASIC으로도 충분히 작업을 해낼 수 있었음.
     * BASIC은 RAM이 극도로 제한된 기기에서 유용한 언어로, 기계어에 비해서도 프로그램 공간을 최소화하도록 설계되었음. 어떤 이는 RAM이 3KB밖에 없는 컴퓨터에서 BASIC 덕분에 그렇지 않으면 RAM에 맞출 수 없었을 유용한 프로그램을 만들 수 있었다며 BASIC에 대한 새로운 존경심을 갖게 되었음.
     * 과거 잡지에는 독자들이 직접 입력하여 저장하고 실행할 수 있는 BASIC 프로그램 리스팅이 종종 실렸음. BASIC은 영어 키워드를 많이 사용해 이에 적합했음. 네덜란드에서는 BASICODE라는 시도가 있었는데, 여러 기종이 해석하거나 자신의 BASIC으로 변환할 수 있는 표준 방언을 만들고자 한 것임. 심야 라디오 프로그램에서 테이프 로딩용 사운드를 송출하기도 했는데, 청취자들은 이를 녹음한 뒤 변환 프로그램을 통해 C64, ZX 스펙트럼, MSX, 암스트래드 CPC 등 자신의 기기에서 실행할 수 있었음.
     * 대부분은 MS BASIC을 떠올리지만, 원조 다트머스 BASIC은 행렬 프리미티브를 내장하고 있었음. 행렬 읽기/쓰기/입력부터 역행렬, 전치, 항등행렬, 영행렬, 상수행렬 등의 함수를 지원했음. Wang 2200 BASIC은 확장된 다트머스 BASIC으로 행렬에 대한 검색, 정렬, 병합 등 강력한 기능이 더해졌음. 하지만 변수명이 한 글자 또는 한 글자와 숫자 조합으로 제한되고, GOTO/GOSUB 레이블이 0~255뿐이며, 문자열 길이가 64자로 제한되는 등 한계도 있었음.
     * BASIC이 퍼스널 컴퓨팅 도입에 미친 영향력은 과소평가하기 어려움. 수많은 홈 컴퓨터에서 프로그래밍을 가능케 하고 무수한 커리어를 시작하게 해주었음.
     * 한 댓글러에게 호기심 많은 11살 때 프로그래밍을 처음 접하게 해준 것이 QBASIC이었음. PRINT문으로 종이를 낭비하기 싫어 화면에 쓰는 방법을 찾아 도움말을 샅샅이 읽었다고 함. 레이블을 쓰라는 설명을 봤지만 GOTO 문법을 이해 못해 번호 범위를 색인 카드에 적어 관리했는데, 한번은 O를 0으로 잘못 적어 디버깅하느라 하루를 보냈다고 함. .BAS를 .EXE로 바꾸면 클릭으로 실행할 수 있을 거라 생각한 것도 의문이었다고 함.
     * SQL도 오늘 50주년인데 동시대 언어들보다 훨씬 널리 쓰이고 있음.
     * 다트머스에서 제작한 BASIC 탄생에 관한 훌륭한 다큐멘터리가 유튜브에 있음. 짧은 팟캐스트 에피소드로도 다뤄졌음.
     * 어떤 이에게 BASIC은 여전히 약간 야한 언어임. 어릴 때 Pascal로 프로그래밍을 배웠는데, 선생님이 나쁜 습관이 든다며 BASIC을 배우지 말라고 했음. 금기된 것이 매력적으로 느껴져 친구들과 몰래 배웠는데 잘못된 것 같으면서도 즐거운 기분이었음. 그렇게 BASIC은 두 번째로 배운 고급 언어가 되었음.
     * 'A People's History of Computing in the United States'라는 책은 제목에 비해 내용이 과장되어 있고 그저 다트머스 BASIC과 그 문화에 대한 역사를 다룸. 하지만 누구나 프로그래밍할 수 있다는 철학과 아마추어들이 자신의 필요에 부응하는 프로그램을 만드는 문화를 구축했다는 점이 흥미로웠음. 필스베리 도우 회사가 이상한 이유로 중서부 지역 학교들이 자사 대형 메인프레임을 시분할로 이용할 수 있게 하는 등 BASIC 문화가 의외의 방식으로 전파되기도 했음.
"
"https://news.hada.io/topic?id=14560","MSA 환경의 수많은 API 문서 자동으로 통합하기 ","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      MSA 환경의 수많은 API 문서 자동으로 통합하기

     * MSA 환경에서는 서비스 도메인만큼 API 명세가 생기는 문제 발생
     * 이러한 문제를 해결하기 위해,
          + MSA 환경에서 다양한 서비스 문서를 하나의 URL에서 보여주고.
          + API 문서 페이지를 자동으로 생성하는 방법을 고민
     * 요구사항 정의와 아키텍쳐
     * API 문서 통합에 사용한 도구와 스팩
     * API 문서 통합 구현
          + OpenAPI 스펙을 충족하기 위한 기본 코드 작업
          + API 문서를 JSON 형태로 추출
          + GitHub Pages로 웹 호스팅
          + GitHub Actions를 이용해 자동화
     * 다중 레포 환경에서 API 문서 통합 적용하는 법

   이와 비슷한 문제를 해결하기 위해
   Swagger API doc을 수집하고 이를 다시 Swagger ui로 보여주는 웹어플리케이션을 만들어 오픈소스로 공개하고 있습니다.
   https://github.com/stray-cat-developers/giant-otter
   혹시나 비슷한 고민을 하시는 분들은 사용을 해보시는 것도 좋을 듯 하네요
"
"https://news.hada.io/topic?id=14602","Show HN: 빌드 구성 없이 웹 확장 프로그램을 생성하는 CLI 도구 제작","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Show HN: 빌드 구성 없이 웹 확장 프로그램을 생성하는 CLI 도구 제작

Extension.js 소개

     * Extension.js는 설정이 필요 없는 플러그 앤 플레이 방식의 크로스 브라우저 확장 개발 도구
     * TypeScript, WebAssembly, React, 모던 JavaScript를 기본으로 지원하여 크로스 브라우저 확장을 만들 수 있음

새로운 확장 만들기

     * 아래 명령어로 새 확장을 쉽게 만들 수 있음
npx extension create my-extension
cd my-extension
npm run dev

     * 명령어 실행 후 새 브라우저 인스턴스가 열리면 바로 개발을 시작할 수 있음

Chrome Extension Samples 활용하기

     * Chrome Extension Samples 저장소의 샘플을 활용하여 빠르게 개발 시작 가능
         1. 터미널 열기
         2. 프로젝트를 만들 디렉토리로 이동
         3. 아래 명령어 실행
npx extension dev <sample-name>

          + <sample-name>은 Chrome Extension Samples에서 사용할 샘플 이름으로 대체
     * 예시: page-redder 샘플 요청
npx extension dev https://github.com/GoogleChrome/chrome-extensions-samples/… --browser=edge

Microsoft Edge에서 Chrome Extension Samples 사용하기

     * Extension.js는 Microsoft Edge를 포함한 다양한 브라우저 지원
     * Edge 호환 확장 시작 방법:
         1. 터미널 열기
         2. 원하는 프로젝트 디렉토리로 이동
         3. 아래 명령어 실행
npx extension dev <sample-name> --browser=edge

          + <sample-name>은 사용할 샘플 이름으로 대체
     * 예시: magic8ball 샘플을 Edge에서 실행
npx extension dev https://github.com/GoogleChrome/chrome-extensions-samples/… --browser=edge

Edge에서 Mozilla 부가 기능 실행하기

     * Firefox와 Edge 간 격차를 줄이기 위해 Edge에서 Mozilla 부가 기능 실행 가능
         1. 프로젝트 디렉토리로 이동
         2. 아래 명령어 사용
npx extension dev <addon-name> --browser=edge --polyfill=true

          + Mozilla 부가 기능을 가져와 Edge용으로 조정
     * 예시: MDN WebExtensions Examples의 Apply CSS 샘플을 Edge에서 실행
npx extension dev https://github.com/mdn/webextensions-examples/tree/main/apply-css --browser=edge --polyfill=true

기존 확장에 Extension.js 사용하기

     * 기존 확장이 패키지 관리자를 사용 중이라면 Extension.js 패키지 설치 후 스크립트 생성하여 실행 가능
         1. devDependency로 extension 설치
npm install extension --save-dev

         2. npm 스크립트와 Extension.js 명령어 연결
{
  ""scripts"": {
    ""build"": ""extension build"",
    ""dev"": ""extension dev"",
    ""start"": ""extension start""
  },
  ""devDependencies"": {
    ""extension"": ""latest""
  }
}

     * 개발 시 npm run dev, 프로덕션 모드 시각화는 npm run start, 프로덕션 모드 빌드는 npm run build 사용

개발용 특정 브라우저 사용

     * 데스크톱 브라우저 지원 현황

   Brave Chrome Edge Firefox Opera Safari Vivaldi
   ☑️    ✅      ✅    ⛔️      ☑️    ⛔️     ☑️

     * ☑️ = 작동 가능성 높으나 브라우저 실행기 미지원
     * 모바일 브라우저 지원 현황

   Firefox Android iOS Safari
   ⛔️              ⛔️

     * 특정 브라우저 대상 시 dev/start 명령에 --browser 플래그 전달
          + 예: npx extension dev path/to/extension --browser=edge
     * 힌트: --browser=""all"" 전달 시 사용 가능한 모든 브라우저 한번에 로드

GN⁺의 의견

     * Extension.js는 크로스 브라우저 확장 개발을 위한 강력한 도구로 보임. 특히 설정 없이 바로 사용할 수 있고, 여러 브라우저를 손쉽게 지원할 수 있어 개발 시간을 크게 단축시킬 수 있을 것 같음.
     * Chrome Extension Samples나 MDN WebExtensions Examples 등 기존 샘플을 활용할 수 있는 것도 큰 장점. 초보 개발자들도 쉽게 시작할 수 있을 듯.
     * 다만 Firefox나 Safari 등 일부 브라우저는 아직 완벽히 지원되지 않는 것으로 보여 주의가 필요해 보임. 특정 브라우저만 타겟으로 할 경우 해당 브라우저의 전용 개발 도구 사용을 고려해 봐야 할 듯.
     * 기존 Plasmo, WebExtensions API 등 유사 도구들과 비교했을 때의 장단점이 궁금함. 특히 Manifest V3 등 최신 스펙 대응 여부를 확인해 볼 필요가 있어 보임.

        Hacker News 의견

     * Chrome 확장 프로그램 개발을 위한 유용한 프레임워크인 Extension.js 소개됨
          + 현재 Firefox 지원은 완벽하지 않은 상태
     * 다른 개발자들도 Chrome 확장 프로그램 개발 시 어려움을 겪은 경험 공유
          + 특히 스타일 적용이 까다로웠음
          + Extension.js가 이러한 어려움을 해소해 줄 것으로 기대됨
     * Extension.js의 README 문서도 잘 작성되어 있어 호평받음
     * 구글 플레이의 복잡성 때문에 앱에 확장 프로그램 추가를 주저했던 개발자도 Extension.js 사용을 고려 중
     * 확장 프로그램과 탭 간 통신 기능도 Extension.js에 포함되면 좋겠다는 의견 제시됨
          + DOM에서 읽거나 확장 프로그램에서 활성 탭으로 메시지 전송이 불편했음
     * Plasmo와 같은 유사 프레임워크와의 비교에 대한 질문 제기됨
     * Chrome 확장 프로그램 개발 시 겪는 가짜 증후군(Imposter Syndrome)에 대한 언급
          + 새 프로젝트 생성이 어려움
          + Extension.js가 이를 해소해 줄 것으로 기대됨
     * Safari 지원은 safari-web-extension-converter CLI 도구를 사용하면 비교적 간단할 것이라는 의견 제시됨
     * 기존에 Chrome 확장 프로그램을 개발해 본 경험에 비추어 Extension.js의 장점에 대한 궁금증 표현됨
          + 단순히 파일 복사 이상의 기능이 무엇인지?
          + 크로스 브라우저 지원? 다국어 지원?
     * Chrome 확장 프로그램 개발 시 개발 도구의 부족함을 느꼈던 개발자의 Extension.js에 대한 기대감 표현됨
"
"https://news.hada.io/topic?id=14600","SSH를 통해서 커피를 판매하는 새로운 스타트업","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       SSH를 통해서 커피를 판매하는 새로운 스타트업

     * ssh terminal.shop 명령어로 terminal.shop에 SSH 접속해서 커피를 주문 가능
     * 접속하면 터미널 창에서 + 상품 추가, - 상품 제거, c 체크아웃 등의 기능을 제공
     * ""nil 블렌드 커피"" 12oz(340gram) 이 $25 임 ( 현재 품절 )

GN+의 의견

     * 터미널 명령어로 커피를 주문할 수 있다는 것이 인상적임. 개발자를 위한 커피 주문 서비스인 것 같음
     * 시스템 접속 과정이 SSH로 이루어지고, 공개키 정보까지 제공하는 것을 보면 보안에 신경쓰는 듯함
     * 개발자들은 터미널에 익숙하므로 이런 방식의 주문 시스템은 그들에게 매력적으로 느껴질 수 있을 것 같음

   감성있네요 ㅋㅋㅋ

   개발자 채용 플랫폼으로 사용해도 되겠네요 ㅋㅋ

   와 이 생각은 못했었는데 대박 ㅋㅋ

   천잰데요?

   ㅋㅋ.. 재밌네요 vim 으로 코딩하다가 마우스에 손대지 않고 커피주문까지..!

   국내에서는 PG 심사 통과가 어려울 것 같네요 ㅎㅎ

   들어가봤는데 이거 깔끔하긴 하네요. (혹시나) 긱뉴스 굿즈 쇼핑몰을 연다면 오픈해두고 싶어요 ㅎㅎ

   빨리 만들어주세요,,

        Hacker News 의견

     * SSH Agent Forwarding을 비활성화해야 원격 서버에서 개인키를 재사용해 GitHub.com이나 운영 서버에 새로운 연결을 설정할 가능성을 차단할 수 있음
     * 신용카드 결제시 PCI 준수 방법에 의문이 있음. SSH로는 안전한 결제가 어려움
     * EU 기반 회사는 2차 인증(3D Secure)을 처리해야 하는데 SSH로는 구현이 어려움
     * Amazon 창업 전에 Bookstacks라는 텔넷 인터페이스 서점이 있었고, Bezos가 이를 경계했음
     * 프로젝트 참여자가 답변함. 재고 소진으로 잠시 중단하고 오픈소스화 예정
     * 누구를 위한 서비스인지 의문이 있음
     * Cloudflare의 엣지 네트워크를 활용한 기술 구현 방식에 호기심이 있음
     * 로컬 재배, 빠른 배송 가능 여부 문의
     * 미니텔처럼 터미널 기반 인터넷이 주류였던 평행세계를 그리워함
     * HTTPS 수준의 보안을 제공하지 않아 Stripe 접근이 곧 차단될 수 있음을 시연으로 보여줌
     * 샘플 텍스트 UI 예시 제시
"
"https://news.hada.io/topic?id=14545","구글, 파이썬(Python) 팀 감원","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          구글, 파이썬(Python) 팀 감원

     * 함께 일하던 모든 동료와 심지어 관리자까지 해고되는 힘든 날
     * 회사에서는 ""역할 축소""라는 표현을 사용함
     * 해고된 직원을 대체할 다른 나라의 사람들을 온보딩해야 하는 상황
          + 새로운 직원들도 이 상황을 달가워하지 않음
     * 자본주의가 좋지 않고 미국에서 살고 싶지 않다는 생각이 듦
     * 당분간은 반려견 Akio와 더 많은 시간을 보낼 예정

동료들의 위로와 조언

     * 안타까운 상황에 대한 위로의 말들
     * 새로운 직원들과 노조나 노사협의회를 만들어 조직화하는 것에 대한 도움 제안
          + 뮌헨의 새로운 직원들은 노사협의회가 있음
          + 이에 대해 적절한 사람들에게 알림
     * 지금은 관계를 망치지 않으면서 해고된 팀을 위해 무엇을 할 수 있을지 고민 중
     * 대체 인력을 온보딩할 필요가 없다는 조언
          + 회사를 위해서가 아니라는 것을 알고 있음

        Hacker News 의견

     * Google의 미래는 AI 제품에 크게 의존하고 있음
          + 모든 AI는 Python으로 작성됨
          + 하지만 Google은 Python 팀을 해고함
     * 이는 최근 Google의 전형적인 행태임
          + 1년 전에도 GCP 상위 티어 지원 인력을 해고하고 저렴한 인력으로 대체함
          + MAAN_ 회사들도 리크루터의 절반이 인도에 기반을 두고 있음
          + 이전에 필자를 해고한 MAAN_ 회사는 내부에서 다른 자리를 찾아주려 하지 않았음
     * MAAN 기업들이 최고의 인재를 유지하려면 장기적 지속가능성에 더 초점을 맞춰야 함
          + 다수의 해고로 인해 불확실성이 커지고, 모호한 구호와 저렴한 혜택 축소로 사기가 저하됨
     * Google의 Python 팀 해고에 연루된 한 직원의 슬픈 경험담
          + 20년 경력 중 가장 좋았던 직장이었으나 다시는 그런 직장을 갖기 어려울 것 같다고 토로
          + 오랜 기간 인원이 부족했던 팀이었지만 Python 생태계를 위해 놀라운 성과를 냈음
     * ML 그룹 외에는 Google 내부에서 Python을 선호하지 않으며 코드베이스에도 거의 없음
          + 이런 맥락에서 이번 조치는 놀랍지 않음
          + Google이 IBM화되고 있어 IBM 스타일의 행보가 예상됨
     * Google은 사람 관점에서는 나빠지고 있지만, 주주 입장에서는 좋아지고 있음
     * Kythe(Grok) 팀도 같은 일을 겪음
     * Meta가 오픈소스 AI에 투자하는 이유 중 하나는 OpenAI 등 소규모 AI 기업의 경쟁력을 약화시키기 위함
          + Google의 Python 팀도 같은 목적으로 AI/ML 도구를 구축하고 오픈소스화했을 수 있음
     * Sundar Pichai CEO는 아직 급여 삭감을 하지 않음
     * Google은 비용을 재외부화할 수 있다고 느끼므로 그렇게 함
          + Brian Cantrill의 말처럼 Google을 의인화하지 말 것
     * 정보가 부족하지만 한 팀의 책임을 다른 팀으로 통합하고 원래 팀은 해고한 것으로 보임
"
"https://news.hada.io/topic?id=14535","BSD 사용자의 Alpine Linux 도전기","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       BSD 사용자의 Alpine Linux 도전기

     * Alpine Linux의 역사
          + Alpine Linux는 독립적이고 비상업적인 범용 Linux 배포판으로, 보안, 단순성, 자원 효율성을 중요시하는 파워 유저를 위해 설계됨
          + 모든 userland 바이너리는 PIE(Position Independent Executables)로 컴파일되고 stack smashing protection이 적용되어, zero-day 취약점 등의 전체 클래스의 익스플로잇을 사전에 방지함
          + 2005년에 Natanael Copa가 프로젝트의 시작을 논의했으며, BSD와 마찬가지로 임베디드 시스템, 라우터, 모바일 기기뿐만 아니라 범용 서버와 데스크톱에서도 사용되고 있음
          + 컴팩트한 크기와 제한된 의존성으로 인해 Linux 컨테이너의 베이스로도 인기가 있음
          + chroot(8)에서 쉽게 실행할 수 있는 툴체인도 제공되어, NetBSD chroots(8)과 FreeBSD jail을 광범위하게 사용하는 사람들에게 흥미로움
     * Alpine Linux의 설치
          + ARM, PPC64, x86, x86_64용 빌드를 포함한 여러 가지 버전으로 제공됨
          + 설치 과정은 매우 단순하며, 라이브 환경에서 root로 로그인하고 setup-alpine을 실행하면 됨
          + 키맵, 네트워킹, 시간대, root 인증 등 기본적인 질문을 받고, SSH 키를 처음부터 주입할 수도 있어 오케스트레이션 도구로 VM이나 서버 집합을 배포하거나 미디어가 제공되지 않는 호스팅 제공업체에 배포할 때 유용함
          + 선호하는 OpenSSH와 openntpd를 선택할 수 있는 몇 가지 SSH 서버와 ntp 클라이언트 중에서 선택할 수 있으며, Xen에서 동작하는 것도 정확히 식별함
          + LVM을 구성할 수도 있지만, 현재는 ext4를 사용하는 Alpine의 표준 sys 파티션을 고수함
     * 설치 후 탐색
          + Alpine을 처음 부팅하면 특별한 이유를 알 수 있음: dmesg(1)는 OpenRC를 실행 중이라고 알려줌
          + 이동성이 있고, 작고, 빠르고, 효율적이고, 투명하며, 안전함
          + rc 스크립트 작성에 익숙한 BSD 사용자에게 매우 친숙함
          + /etc/rc.conf와 crond(8)의 존재는 기쁨을 줌
          + Devuan, Gentoo, Alpine 등 Linux 배포판에서 이를 사용하는 것은 매우 반가운 일이며, Linux를 다시 재미있게 만들어줌
          + OpenRC와 함께 musl과 busybox가 번들로 제공되어 기본 시스템의 크기와 공격 표면을 더욱 줄여줌
          + llvm과 선호하는 대화형 셸 중 하나인 MirBSD Korn 셸도 사용 가능함
     * 패키지
          + Alpine의 기본 패키지 관리자는 apk이며, Linux에서 일반적인 것처럼 기본 시스템과 모든 패키지를 구분하지 않고 업데이트를 처리함
          + BSD에서와 같이 비권한 사본을 실행할 수 있는지 확인해보고 싶지만 아직 확인하지 않았으며, pkgsrc도 있어서 문제가 되지 않음
          + 구성은 /etc/apk/repositories에 있으며, 설치 프로그램에서 제공한 두 번째 URL의 주석을 해제하여 community 저장소를 활성화할 수 있음
          + Alpine에는 testing 저장소도 있으며, 자체 저장소를 추가할 수도 있음
          + 사용법은 쉽지만, 오래된 습관 때문에 여전히 apk add 대신 apt install을 잘못 입력하고 있음
          + 공식 웹 인터페이스가 있으며, Alpine 저장소는 pkgs.org에 있음
          + zfs 패키지가 가장 놀라웠으며, 커널 모듈을 설치하고 로드하는 데 단 두 개의 명령만 필요했음 (root on ZFS는 더 복잡할 것임)
     * 결론
          + 표면만 살짝 긁어봤지만, 테스트와 서버를 위한 주요 Linux 배포판으로 전환하는 것을 진지하게 고려할 만한 충분한 이유가 있음
          + htop(1)과 lsof(1)가 인식할 수 있는 프로세스의 작은 목록만 표시하고, OpenRC를 사용하며, 패키지 관리가 간단해 보이고, 구성이 매우 단순한 점이 마음에 듦
          + 현대적이고 기능적인 ""Occam의 Linux""가 어떤 모습일지 궁금했는데, 이것이 바로 그것임
          + busybox보다 더 필요한 것이 있다면 uutils가 실행되는지 확인해보고 싶지만, 서버의 경우 의심스러움

GN⁺의 의견

     * Alpine Linux는 컨테이너 기반 배포에 최적화되어 있어, Docker와 같은 컨테이너 플랫폼에서 널리 사용되고 있습니다. 컨테이너를 활용한 마이크로서비스 아키텍처 구현 시 고려해볼만한 배포판이라고 생각합니다.
     * 기본으로 musl libc를 사용하는 것이 장점이자 단점이 될 수 있습니다. musl은 glibc에 비해 경량화되고 보안에 강점이 있지만, 일부 애플리케이션과 호환성 문제가 있을 수 있습니다. 따라서 사용할 애플리케이션의 호환성을 미리 확인해볼 필요가 있습니다.
     * 기본 쉘로 ash를 사용하는 것도 특이한 점입니다. ash는 bash에 비해 기능이 제한적이지만 매우 가볍고 빠른 쉘로, 임베디드 시스템 등 자원이 제한된 환경에서 유용할 것 같습니다. 반면 일반 사용자에겐 다소 불편할 수도 있겠네요.
     * BSD 계열 OS를 주로 사용하시는 분들이라면 익숙한 환경을 제공하는 Alpine Linux가 매력적으로 느껴질 것 같습니다. 다만 아직 데스크탑 환경 지원이 미흡해 보여서, 서버나 임베디드 용도로 사용하기에 적합해 보입니다.
     * 전반적으로 Alpine Linux는 가볍고 보안에 최적화된 배포판으로서 나름의 존재감을 가지고 있는 것 같습니다. 다만 자체 생태계가 그리 크지 않아 문제 발생 시 커뮤니티 지원이 다소 부족할 수 있다는 점은 고려해야 할 것 같네요. 하지만 시간이 지나면서 Alpine Linux의 장점들로 인해 점점 더 많은 사용자들을 확보해 나갈 것으로 기대됩니다.

        Hacker News 의견

   요약:
     * Linux 바이너리는 PIE(Position Independent Executable)로 컴파일되어 보안성이 높음
     * GLIBC는 힙 구현이 가장 경화되어 있어 이중 해제 등의 힙 취약점에 대한 완화 기능이 더 많음
     * Alpine은 musl을 사용하므로 GLIBC에 비해 보안성이 떨어짐. 작고 이해하기 쉬운 시스템이 보안에 도움됨
     * Illumos(OpenSolaris)는 수십년간 리눅스를 사용한 후 모든 것이 더 단순해짐
     * Solaris 10에서 작동하던 대부분이 약간의 수정으로 현재까지 적용됨
     * zone은 docker 컨테이너보다 10배 우수하며, ZFS 지원 내장됨
     * SMF로 서비스 관리. XML로 구성하는 것이 유일한 단점
     * OmniOS와 SmartOS 서버 사용 경험 공유
     * BSD 사용자로서 bhyve에서 Alpine을 처음 실행해봄
     * busybox 기반으로 /bin, /sbin 유틸리티가 분리된 바이너리일 필요가 없어 사용자 공간이 작고 부팅이 빠름
     * tmux, zsh로 대부분의 유닉스 용도에 충분
     * 많은 apk 설치 필요했지만 전반적으로 최고의 Linux 경험이었음
     * ZFS 내장되고 bhyve용 virtio 바인딩 지원되면 좋겠음
     * Void Linux도 BSD 사용자에게 추천. NetBSD 개발자가 만들었고 glibc/musl 버전 있음. runit을 init 시스템으로 사용
     * xbps-src로 소스에서 패키지 빌드 가능
     * Alpine에 기본으로 man 페이지가 포함되지 않아 사용을 꺼림
     * 패키지 설치 시 문서를 자동으로 설치하는 옵션이 있는지 궁금함
     * Docker에서 Alpine 성능 관련 포스트들 있었음. Debian/Ubuntu 사용 권장
          + Alpine이 느린 이유: Python 속도 저하, Ubuntu 이미지 대비 50% 느림
          + Alpine 옹호 포스트: Debian과 성능 비교 벤치마크
     * 이 내용이 아직 유효한지 궁금해 함
     * OpenRC 등이 매력적인 이유 모르겠음. 감독 기반 옵션이 PID 파일 관리보다 낫다고 봄
     * 자동 재시작 안 되는 게 장점이라는 점은 인정
     * syslog에 크게 의존하는 것도 80년대 기술
     * 여러 도구의 이벤트 순서를 알기 위해 중앙 집중식 뷰 개선 필요성은 동의
     * Alpine의 장점: Nix 없이 /etc/apk/world 편집 후 apk fix로 선언적 패키지 관리 가능
     * Slackware는 BSD와 Linux의 절충안. Unix 스럽고 복잡하지 않음. Slackbuilds로 풍부한 포트 트리 제공
     * musl이 pthread_attr_setaffinity_np 지원 안 해서 PyTorch 등 일부 소프트웨어 실행 불가
"
"https://news.hada.io/topic?id=14571","페인트 얼룩의 93%가 유효한 Perl 프로그램으로 판명 (2019)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 페인트 얼룩의 93%가 유효한 Perl 프로그램으로 판명 (2019)

Paint Splatters와 Perl 프로그래밍 언어의 관계에 대한 연구 논문 소개

     * SIGBOVIK 2019 학회에 게재 승인되고 ""Unwitting Participation Ribbon""을 수상한 논문
     * 페인트를 벽에 튀기면 93%의 확률로 유효한 Perl 프로그램이 만들어짐
     * 광학 문자 인식(OCR) 소프트웨어를 사용하여 실증적 접근 방식을 사용
     * Paint Splatter로 만들어진 Perl 프로그램의 특성을 분석하고, 유효한 Perl 프로그램이 아닌 7가지 Paint Splatter 예시를 제시함

논문의 보충 자료 소개

     * 단일 페이지에 모든 Paint Splatter와 해당 유효한 Perl 소스 코드를 표시
     * 유효한 Perl 프로그램으로 파싱되지 않은 이미지는 빨간색으로 ""유효하지 않음""이 표시됨
     * 서로 다른 OCR 설정으로 여러 유효한 Perl 프로그램이 인식된 경우, 저자의 미적 감각에 따라 가장 ""흥미로운"" 것을 선택함
     * 논문의 주요 데이터 세트로 사용된 100개의 Paint Splatter 이미지가 포함된 tarball 제공

논문 제출 마감 후 발견된 흥미로운 Paint Splatter Perl 프로그램 예시

     * lerzfijglpFiji-j 문자열로 인식되어 Perl에서 숫자 0으로 평가되는 splatter
     * *?- 문자열로 인식되어 Perl에서 숫자 0으로 평가되는 이미지
     * ;i;c;;#\\\\?z{;?;;fn':.; 문자열로 인식되어 Perl에서 문자열 ""c""로 평가되는 이미지
     * `;E,'', 문자열로 인식되어 Perl에서 문자열 ""E""로 평가되는 이미지

GN⁺의 의견

     * 독특하고 재미있는 아이디어로 프로그래밍 언어의 특성을 탐구한 논문으로 보임. Perl의 문법적 유연성을 역설적으로 보여주는 좋은 사례가 될 듯함.
     * 하지만 이 논문의 연구 결과가 Perl 언어 설계상의 문제점을 시사하는 것은 아닌지 궁금해짐. 무작위 문자열도 93%나 파싱된다는 것이 언어의 모호성을 드러내는 것 아닐까?
     * 비슷한 실험을 다른 프로그래밍 언어에 적용해본다면 어떤 결과가 나올지 궁금함. 언어별 결과 비교를 통해 언어 설계 철학의 차이를 엿볼 수 있을 것 같음.
     * 프로그래밍 언어 문법을 이런 방식으로 시각화하는 것도 흥미로운 시도일 것 같음. 문법의 복잡도나 규칙성 등을 시각적으로 파악하는데 도움이 될 듯.

        Hacker News 의견

     * OCR 소프트웨어가 텍스트가 아닌 이미지에서도 여전히 텍스트 결과를 생성하는 것은 잘못된 것임. 10년 전에 오래된 책을 OCR로 스캔했을 때, 작은 그림, 얼룩, 먼지 등에서 생성된 쓰레기 텍스트를 처리하는 것이 얼마나 성가신 일이었는지 기억남. 이 분야에서는 그 이후로 큰 진전이 없어 보임.
     * Concatenative 언어는 모든 토큰 시퀀스가 유효한 프로그램이 되는 특성이 있음.
          + 단일 비트를 토큰으로 사용하는 언어의 경우 모든 비트 시퀀스가 유효한 프로그램임.
          + Chris Barker의 zot이 그런 언어 중 하나임.
          + zot에서 영감을 받아 Binary Lambda Calculus의 concatenative 버전을 정의했는데, 이 버전도 같은 특성을 공유함.
     * 재미있는 각주가 있음:
          + Perl 프로그램 ""Illegal division by zero at /tmp/quine.pl line 1.""을 적절한 위치에 저장하면 ""Illegal division by zero at /tmp/quine.pl line 1.""을 출력함. 이런 동작의 이유는 독자의 연습 문제로 남겨둠.
     * 관련 글:
          + ""93% of Paint Splatters Are Valid Perl Programs (2019)"" (2021년 7월, 163개 댓글)
          + ""93% of Paint Splatters Are Valid Perl Programs (2019)"" (2023년 12월, 1개 댓글)
     * 이 글은 특정 ""광학 문자 인식"" 프로그램으로 페인트 스플래터를 문자로 인식하는 것에 대해 다루고 있음. 이 프로그램은 거의 항상 어떤 문자 조합으로든 인식하는 경향이 있는 것 같음.
     * 이를 실현할 수 있는 여러 가지 방법 중에서, 이것은 절대적으로 환영받을 만하고 정신에 부합함. 하지만 색상과 빈 공간의 패치를 0과 1로 취하고 전체를 프로그램으로 보는 등 다른 가능한 방법에 대한 첫인상을 주기도 함. 이런 경우 대부분은 무의미한 노이즈일 것임.
     * 노이즈가 대부분인 극단과 의미가 대부분인 극단, 이 두 가지 극단이 있음. 여기서 게임 속의 게임은 페인트 스플래터에 가능한 한 최대의 의미를 부여하는 해석 방식을 찾는 것임. 이때 의미는 규칙이 의미를 보는 것을 선택하는 데 얼마나 적극적인지가 아니라 구조에서 진정으로 나와야 함.
     * ""라인 노이즈와 구별할 수 없음""이라는 오래된 농담을 변형한 영리한 버전임.
     * 생성형 AI를 사용하면 작동하는 소프트웨어로 평가되는 새롭고 혁신적인 페인트 스플래터를 더 빠르게 만들 수 있음. 생성형 AI는 새로운 창작자 계층이 텍스트에서 이미지로의 워크플로를 활용하고 활용할 수 있게 해주며, 모든 규모의 비즈니스에 가치를 제공함. 새로운 AI 모델은 다양한 고해상도 콘텐츠에 작동 소프트웨어와 기계 판독 가능 코드를 내장할 수 있어 시청자를 사로잡고 창작자에게 새롭고 흥미로운 청중 확대 방법을 제공함.
     * 4월 1일에 게시됨. 이는 무언가를 암시함.
     * Perl 프로그래머로서 작동하지 않는 7%는 버그라고 생각함.
"
"https://news.hada.io/topic?id=14595","Show GN: AI영어 회화 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Show GN: AI영어 회화 앱

   영어를 모국어처럼 배웠지만 주변 많은 한국 분들이 영어 학습에 어려움을 겪는 것을 보고 개발하게 되었습니다

   어떤 모습인지 보이지 않는데 바로 가입을 요구하는 로그인창만 나와서..
   어떻게 사용하는지 볼 수 있도록 하는게 어떨까 싶네요

   좋은 피드백 감사합니다. 짧은 영상하나 올려놓겠습니다

   음성으로 듣고, 말하고, 텍스트로 보면서 회화 연습할 수 있습니다
"
"https://news.hada.io/topic?id=14613","인증서 문제로 인한 cdn.jsdelivr.net 접속 불능 사태","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  인증서 문제로 인한 cdn.jsdelivr.net 접속 불능 사태

   생각보다 크리티컬한 이슈인데, 별도 언급이 없는 것 같아 공유드립니다.
     * 전 세계적으로 가장 큰 오픈소스 프로젝트 CDN 서비스인 jsDelivr의 엣지 도메인 중 하나인 cdn.jsdelivr.net 접속 불가 사태가 2024-05-02 오전(KST) 부터 지속 중
     * SSL 인증서의 만료로 인한 오류(ERR_CERT_DATE_INVALID)로 보이나, 현재는 다른 오류 메세지(ERR_CERT_COMMON_NAME_INVALID)로 변경된 상태
     * 한국의 경우 jsDelivr 를 사용해 js 프론트엔드 라이브러리, 웹폰트 등을 서빙하는 사이트들이 많기 때문에 본인의 서비스나 프로젝트에 대한 점검 필요

   cdn.jsdelivr.net에서 제공하는 slick-slider의 경우에는 cdnjs.cloudflare.com에서도 제공하니까 참고하세요.

   디스코드에도 공지가 없더라구요.

   오후쯤 되니 뭐가 안된다 리포트 속출 ㅠㅠ

   한국시간 20시 08분경 제작자 Dmitriy Akulov(@jimaek)이 장애 포스트모텀 글을 게시하였습니다.

   https://www.jsdelivr.com/blog/jsdelivr-may-outage-postmortem/

   대략적인 내용을 번역 및 요약(Claude3 Sonnet LLM 이용)하면 아래와 같습니다.
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   2024년 5월 2일 밤, jsDelivr CDN 도메인 cdn.jsdelivr.net이 특정 지역의 클라이언트에게 만료된 SSL 인증서를 제공하여 약 5시간 이상 장애가 발생했습니다. 아프리카, 아시아, 유럽 및 라틴 아메리카 일부 국가 사용자들이 주로 영향을 받았습니다.

   장애 원인은 Cloudflare가 DigiCert 인증 기관에서 Google Trust Services로 변경하는 과정에서 도메인 유효성 검사 방법이 변경되어 jsDelivr의 특수한 설정으로 인해 자동 인증서 발급에 실패한 것이었습니다.

   jsDelivr 개발자는 이번 사태에 대해 전적으로 책임을 지며, 앞으로 CDN 제공업체의 중요한 변경 사항이 있을 때마다 jsDelivr에서 해당 CDN을 비활성화하고 수동 검증을 거칠 것이라고 합니다. 장기적으로는 DNS, 로드밸런싱, 장애 조치 시스템을 최적화하고 자체 Globalping 서비스를 통합할 계획입니다.

   어쩐지 이른 아침에 인증서 문제가 있었는데 검색해도 아무것도 안나오더군요
   이제서야...

   방금 정상화 됐습니다.

   보아하니 한국이 이슈가 가장 많고 그다음 아시아권 국가, 중동, 일부 유럽 국가에서 난리 났네요.
   흠... 저같은 경우 고객 사이트 중 프리텐다드만 이슈가 있는 상황이라 큰 문제는 아니지만, 과거에도 전례가 있는 바 앞으로는 로컬 위주로 쓰는 게 맞겠습니다.

   저도 급하게 만든 프로젝트에 장애가 발생해서 자체 CDN으로 옮겼네요..

   저 차제 cdn은 어떻게 구현하는건가요?

   저도 디스크캐시에 남아있는 소스를 복사해서 자체 CDN으로 옮겨서 해결 하였습니다.

   cdn.jsdelivr.net의 cdn 을 fastly 또는 gcore로 바꿔 해결하실 수 있습니다.
   찾아보니 2019년에도 해당 문제가 있었는데 당시에도 대응이 늦었던 것으로 보이네요.

   https://github.com/orioncactus/pretendard/…

   결국 크리티컬한 라이브러리는 무료 호스팅 보다는 셀프 호스팅 하는게 답인 것 같습니다. gcore, fastly도 언젠가는 마찬가치 문제가 발생 할 수 있어서요.

   헐 저도 이거 지금 머리싸매고있었는데
"
"https://news.hada.io/topic?id=14597","Show GN: 서버 업로드 없이 HEIC/HEIF를 JPG/PNG로 변환해주는 웹 앱","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Show GN: 서버 업로드 없이 HEIC/HEIF를 JPG/PNG로 변환해주는 웹 앱

   웹 브라우저에서 간단히 HEIC/HEIF 파일을 JPG/PNG로 변환하는 페이지입니다.

  장점

    서버 업로드 없음

   서버 업로드 없이 웹 브라우저 상에서 변환합니다. 설치 없음. 가입 없음. 유출 걱정 ㄴ

    빠름

   HEVC 가속을 사용해서 변환이 빠릅니다. 서버 업로드를 안 하니까 인터넷 속도 때문에 느려지지 않습니다.
   다른 웹 변환기와 비교하면 확연한 힘의 차이를 느끼실 수 있습니다 ㅎ

  단점

    호환성 문제

   OS, 브라우저에 따라서, HEIC을 생성한 기종에 따라서, 변환이 안 될 수도 있습니다.

   갤럭시에서 찍은 .heic은 Chrome에서 변환이 잘 됩니다.

   하지만 iOS에서 찍은 .heic을 Windows + Chrome에서 변환하면 변환이 안 됩니다.
   Windows에서 변환하려면 HEVC 확장(조건부 무료, 유료)을 설치하고 Edge에서 변환해야 합니다.

   Safari는 다 잘 되긴 할텐데, macOS, iOS에서 이런 변환기를 쓸 필요가... 있나요...?

   호환성 문제는 HEVC 가속을 사용한 부작용입니다. JS 디코더를 fallback으로 쓸 수도 있지만... 그러면 느리기도 하고, 특허사용료 문제도 있어서...

    ICC profile

   컬러 프로파일 지원이 부족하여 색 출력이 틀어질 수 있습니다.

    EXIF

   EXIF 메타데이터를 보존하지 않습니다.

  마무리

   호환성 문제를 완전히 해결할 수가 없어서... 원래는 도메인도 등록하고, 광고도 달고, ICC, EXIF도 전부 지원하게 해보려 했는데, 그냥 여기까지 마무리하고 공개합니다.

   그래도 여건만 되면 쓸만할 거에요...

   감사합니다

   좋은 정보 감사합니다

   감사합니다

   오전에 css가 안힙혀진다는 댓글을 봤던거같은데 사라진걸까요?
   cdn.jsdelivr.net 인증서 만료로 터졌다고 하네요.

   금방 해결이 안될 것 같아 다른 미러로 수정했습니다.

   제목을

   서버 업로드 없이 HEIC/HEIF를 JPG/PNG로 변환해주는 웹 앱

   으로 바꾸고 싶은데 수정이 안 되네요....

   그리고 이모지를 쓰고싶은데 이모지가 지워지네요... 의도된 사항인가요?

   제목 수정해두었습니다.

   이모지가 지워지는 것은 버그였어서 수정해두었습니다. 스팸 댓글 때문에 막아둔 코드에 문제가 있었네요.
   제보 감사합니다.

   반영 감사합니다 👍

   현재까지 알려진 사항을 페이지에 노출 시켜주면 좋을거 같습니다.

   반영했습니다.

   호환성 체크하고 문제 있으면 표시하는 방향으로 만들어보겠습니다.

   서버 업로드가 없으면 오히려 문제가 있는거 아닌가요...? 코덱 라이센스 문제는 어떻게 해결하셨는지 궁금합니다.

   아 그냥 브라우저에 탑재된 포트를 실행하는게 다군요! 좋은 유틸입니다 :+1:
"
"https://news.hada.io/topic?id=14559","구글이 더 저렴한 인건비를 위해 자체 파이썬 팀을 해고","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     구글이 더 저렴한 인건비를 위해 자체 파이썬 팀을 해고

     * 구글이 자사의 파이썬 개발팀을 전부 해고하고, 더 인건비가 저렴한 뮌휀 지역의 개발자들로 하여금 역할을 대신할 수 있도록 온보딩을 지원하도록 지시했다고 합니다.
     * 아래는 당사자의 직접적인 코멘트를 번역한 것입니다.
     * Thomas Wouters:
          + 당신이 직접 일하는 모든 사람들, 당신의 매니저를 포함하여 해고되었을 때 — 죄송합니다, '역할이 축소되었다'고 말해야겠네요, 그리고 당신은 그들의 후임자들을 교육시켜야 하는 상황입니다. 후임자들은 그와 똑같은 역할을 다른 나라에서 맡도록 지시받았지만, 그들 역시 이 상황에 대해 행복하지 않습니다. (거의 마치 자본주의가 실제로 좋지 않고 미국에 살고 싶어하지 않아야 한다는 것처럼요.) 앞으로 당분간 아키오를 데리고 좀 더 긴 산책을 할 것 같습니다.
            (출처: https://social.coop/@Yhg1s/112332127058328855)
     * 해커뉴스에서도 더 상세한 내용들을 볼 수 있습니다.
     * hi-v-rocknroll:
          + 이것은 최근의 전형적인 구글 사례입니다. 약 일년 전, 그들은 GCP 상위 지원 팀을 해고하고 더 저렴한 노동력으로 대체했습니다. PS: 어느 MAAN_인지는 말하지 않겠습니다만, 리크루터들의 절반은 이제 인도에 있습니다. 우연히도, 내가 최근에 해고된 그 MAAN_은 내부에서 다른 직무를 찾아주려는 시도보다는 해고를 선택했습니다. 뇌가 폭발할 것 같습니다. 아마도 MAANG들은 상위 인재를 유지하려는 의도가 있다면 장기적인 지속 가능성에 더 집중해야 할 것입니다. 왜냐하면 여러 차례의 해고로 인한 불확실성, 모호한 비즈니스 슬로건, 저렴한 혜택 축소로 인해 사기는 일관성 없이, 중간 정도로 불행하기 때문입니다.
            (출처: https://news.ycombinator.com/item?id=40171125)

   flutter 팀 해고와도 관련 있을까요

   미국에 베이스를 둔 글로벌 기업에서 벌어지고 있는 전형적인 일이라고 볼 수 있을것 같습니다.

   구글, 파이썬(Python) 팀 감원

   GN+ 에는 해당 마스토돈 글만 번역이 되어있네요. 해커뉴스 요약도 있으니 함께 보세요
"
"https://news.hada.io/topic?id=14566","GPT-4.5 또는 GPT-5가 LMSYS에서 테스트 중?","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    GPT-4.5 또는 GPT-5가 LMSYS에서 테스트 중?

배경 내용

     * LMSYS에서 최근 공개한 gpt2-chatbot 모델은 기존에 알려진 GPT-2 모델을 훨씬 뛰어넘는 성능을 보여주고 있음
     * 해당 모델에 대한 정보는 LMSYS 사이트나 다른 곳에서도 찾기 어려움
     * LMSYS의 벤치마크 API 결과에서도 이 모델만 유독 제외되어 있음

GPT2-Chatbot 모델의 주요 특징

     * 자신을 ""GPT-4 기반""이라고 주장하며 ""ChatGPT""라고 지칭함
     * 다른 조직에서 생성한 OpenAI 데이터셋으로 학습한 모델들과는 다른 특징을 보임
     * OpenAI의 tiktoken tokenizer를 사용하는 것으로 보임
     * OpenAI 고유의 프롬프트 인젝션 취약점이 발견됨
     * 다른 조직의 모델들과는 다른 출력 특성을 보임

GPT2-Chatbot에 대한 주관적 의견

     * 실제로는 GPT-4.5나 GPT-5일 가능성이 높아 보임. 출력 품질이 GPT-3.5에서 GPT-4로의 도약만큼 크게 향상됨
     * LMSYS가 자체 모델을 학습했거나 MoE와 유사한 방식을 사용했을 가능성도 있으나, OpenAI와의 연관성을 볼 때 가능성은 낮아 보임

GPT2-Chatbot 공개 목적에 대한 추론

     * OpenAI가 LMSYS를 통해 은밀히 최신 GPT 모델을 벤치마킹하기 위한 것으로 보임
     * 일반적인 벤치마크 테스트 결과를 얻고, 과도한 기대감으로 인한 부정적 평가를 피하며, 다른 경쟁사의 견제를 최소화하기 위함

또 다른 가능성에 대한 고찰

     * 실제로 GPT-2 아키텍처 기반일 가능성도 있음. 최근 연구에 따르면 GPT-2가 특정 영역에서 다른 모델보다 우수한 성능을 보였기 때문
     * GPT-4로 자칭하는 것은 GPT-4로 생성된 데이터셋을 활용했기 때문일 수 있음
     * LMSYS의 후원사 중 하나인 MBZUAI가 해당 연구에 관여했다는 점도 주목할 만함

GN⁺의 의견

     * gpt2-chatbot의 정체를 둘러싼 추측들이 흥미로움. OpenAI의 최신 모델일 가능성이 높다는 의견에 동의
     * 한편으로 GPT-2 아키텍처를 기반으로 했을 가능성도 배제할 순 없음. 최근 연구 결과들을 보면 GPT-2의 잠재력이 여전히 높아 보임
     * OpenAI가 LMSYS를 통해 은밀히 벤치마킹을 진행하고 있다는 추측도 설득력이 있음. 경쟁사의 견제를 피하면서도 객관적인 평가를 얻을 수 있는 전략.
     * 앞으로도 gpt2-chatbot의 실체를 밝히기 위한 다양한 실험과 연구가 이어질 것 같음. 대형 언어 모델 분야의 발전상을 가늠해 볼 수 있는 계기가 될 듯
     * 애초에 ""gpt2-chatbot""이라는 이름 자체가 GPT-2라는 인상을 주기 위한 것일 수도 있을 것. OpenAI가 의도적으로 붙인 이름일 가능성도 배제할 순 없을 것 같음
"
"https://news.hada.io/topic?id=14565","Mise - 다중언어(Polyglot) 버전 관리자","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Mise - 다중언어(Polyglot) 버전 관리자

     * 개발 도구/런타임을 설치 및 관리해주는 개발 환경 설정도구
     * asdf/nvm/pyenv/rbenv, direnv, make 등을 통합 대체
          + asdf 처럼 node,python,cmake,terraform 등의 ""개발 도구""를 관리
          + direnv 처럼 각 프로젝트 디렉토리별 ""환경 변수""를 관리
          + make 처럼 프로젝트를 빌드하고 테스트하는 ""태스크""를 관리
     * Rust로 개발되었으며 shims를 사용하지 않음
          + shims 지원은 하지만 PATH를 권장
          + 개발자는 shims/PATH 둘다 사용하지 않으며 mise x|exec 과 mise r|run 을 이용한다고(실행전에 모든 환경변수를 로딩)

   asdf 와의 비교 https://mise.jdx.dev/dev-tools/comparison-to-asdf.html
"
"https://news.hada.io/topic?id=14615","Y Combinator 없이 미국 진출하기 (feat. Techstars)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Y Combinator 없이 미국 진출하기 (feat. Techstars)

     * 창업 목표: 글로벌 B2B SaaS
     * 글로벌 진출을 위해 미국에 법인 설립
          + Stripe Atlas 활용
     * 데브옵스를 위한 AI 비서 서비스로 시작
          + Pre-seed 펀딩 확보
          + 한 달 만에 제품 출시
          + 런칭 이후 6개월간 한 명의 유료 고객도 확보하지 못함
     * YC 인터뷰 단계(약 3배수)까지 진행했으나 미국 내 고객을 확보하지 못해서 탈락
     * 뭐라도 변화를 만들기 위해 베이 지역으로 6주간 출장
          + 베이 지역에서 느끼는 AI 관련 성장 속도가 한국보다 몇 배는 빠름을 몸소 느낌
     * OpenAI Dev Day (a.k.a 피의 결혼식) 이후 피봇 결정
          + 다른 스타트업이 아니라 고객사의 기술팀과 경쟁하고 있다는 것을 깨달음
          + 각 회사가 스스로 쉽게 AI를 만드는 세상이 올 것이라고 판단
     * PlugBear 출시: 고객사가 Custom LLM App을 쉽게 구축하고 Slack, Teams 같은 익숙한 업무 도구에 연동할 수 있게 도와주는 서비스
          + 일주일 만에 개발 후 출시
          + 드디어 시장의 반응이 보이기 시작함
     * Techstars 지원 및 합격
          + Techstars
               o 국내에서는 잘 알려지지 않았으나, YC와 종종 비교되는 세계 최고 스타트업 액셀러레이터 중 하나
               o YC: 잘 될 비즈니스를 매우 잘 되게 만들어 줌
               o Techstars: 초보 창업자를 훌륭한 창업자로 만들어 줌
               o 창업팀은 그들의 기존 국내 경험과 상관 없이 미국 시장에서는 스스로 초초초보 창업자라고 판단
          + 고객이 확보되었기에 YC에 다시 지원하려고 했으나 지원 기간이 지남
          + YC 지원을 위해 6개월을 더 기다리기는 너무 긴 시간
          + 반면 본격적인 미국 진출을 위해 미국 내 투자 및 지원이 필요했음
          + 지난 미국 출장에서 만난 Techstars Mentor Jina 님의 도움을 받으며 Techstars에 지원
          + 2개월 간 지원 및 인터뷰 과정을 거쳐 베이 지역 Techstars'24에 합격 (합격률 1%)
     * 현재 상황
          + 출시 4개월 만에 50여 개 유료 고객사 확보
          + Techstars 참여 이후 한 달 만에 2배 이상 성장
          + 5/7 ProductHunt 런칭 준비 중
     * 덧. 5/22 Techstars 다음 배치 지원 마감

   Techstars로 대성공한 첫 한국 스타트업 탄생 응원합니다!

   (간략하게) 응원!
"
"https://news.hada.io/topic?id=14524","2018년부터 무료로 공유해온 PBR Textures와 3D 모델 제작자","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                2018년부터 무료로 공유해온 PBR Textures와 3D 모델 제작자

고품질의 텍스처와 3D 모델 제공 사이트 sharetextures 소개

     * sharetextures는 프로젝트에 사용할 수 있는 고품질의 3D 모델과 1000개 이상의 텍스처를 제공하는 사이트임
     * 현재 184개의 모델과 37개의 아틀라스(Atlas), 1502개의 텍스처를 제공하고 있으며, 매일 늘어나고 있음

완전 무료로 상업적 사용 가능

     * sharetextures의 모든 콘텐츠는 저작권이 없어 상업적 프로젝트를 포함한 어디에서나 사용 가능함
     * Patreon을 통해 후원을 받고 있으며, 현재 71명의 서포터가 있음
     * 최근 새로 가입한 Patron으로는 Ganicuus, Adar Shalev, Adham Taha, Kristian, mmd yy, Barış Manav 등이 있음

사이트를 만든 사람과 후원자 목록

     * sharetextures는 Patreon을 통해 후원 받고 있으며, SuRi, Umigenius, monica boulis, Cierwen Newell, Andrea Bianchi 등 다양한 사람들의 후원으로 운영되고 있음

GN⁺의 의견

     * 고품질의 3D 모델과 텍스처를 무료로 제공한다는 점에서 퀄리티 높은 프로젝트를 준비 중인 개발자나 디자이너에게 매우 유용한 사이트임
     * 완전 무료로 상업적 사용까지 가능하다는 점이 가장 큰 장점이지만, 반대로 지속가능성 측면에서는 우려가 될 수 있음
     * 비슷한 서비스로는 Poly Haven, ambientCG 등이 있는데, 각 사이트의 장단점을 잘 비교해 보고 프로젝트의 목적에 맞는 에셋을 가져오는 것이 좋겠음
     * 대부분 오픈소스 프로젝트가 그렇듯 커뮤니티의 기여로 운영되는 서비스인 만큼, 불건전한 콘텐츠나 저작권 이슈 등은 없는지 꼭 확인이 필요함

        Hacker News 의견

   요약:
     * 이 프로젝트는 모듈형 에셋/유틸리티 개발을 퍼블릭 도메인에 공개하는 것을 목표로 함. 전문화나 편의성에 대해서는 수익을 낼 수 있지만, 완전히 모듈화된 에셋은 무료로 제공해야 한다는 견해임.
     * 에셋 제작에 많은 노력이 들어갔더라도 유료화하기에는 부적절한 것들이 있음. 유료화하지 않고 공개하는 것이 더 의미 있다고 봄.
     * 에셋 제작자로서의 크레딧 표시에는 큰 관심이 없음. 제스처로는 좋지만 꼭 필요한 건 아님.
     * 이 프로젝트에 동참하고 싶어 함. 오랜 경력의 게임 개발자이며 Unreal 엔진 사용 경험이 있음. 프로젝트의 에셋 제작 프로세스와 규격을 준수할 의향이 있음.
     * 현재 다른 프로젝트로 바빠서 당장은 어렵지만, 향후 참여 가능 여부를 타진하고 싶어함.
     * 이런 활동 자체가 유용하고 이타적인 시도라고 평가함.
     * 다른 이용자는 무료 게임 개발 리소스 목록에 이 프로젝트 링크를 추가함.
     * PBR의 의미가 사람마다 다를 수 있다는 언급이 있음.
     * 90년대에는 이런 리소스가 있었다면 엄청난 도움이 되었을 것이라는 평이 있음.
     * 에셋이 퍼블릭 도메인이 아니라 CC0 라이선스임을 지적하는 의견도 있음.
     * Godot 3 엔진에서 이 에셋들을 활용해보려는 개발자도 있음.
     * 모델 목록이 감자, 의자, 양파, 램프, 중세 고문 도구, 바나나, 소파 등 잡다한 물건들로 구성되어 있다는 코멘트가 눈에 띔.
     * Babylon.js를 사용하는 오픈소스 프로젝트를 홍보하며 협력자를 구하는 글도 있음.
     * Atlas 기능이 무엇인지 궁금해하는 질문도 보임.
     * Firefox에서 웹사이트 레이아웃이 깨지는 문제가 있음. 검색 결과가 화면에 제대로 표시되지 않고, 에셋 이미지를 클릭해도 다운로드 되지 않는 등의 증상이 나타남.
     * 웹 디자인이 너무 현대적이라는 비판과 함께, 더 많은 썸네일을 한 페이지에 표시할 것을 제안함.
     * AmbientCG라는 유사 사이트를 추천하는 의견도 있음.
"
"https://news.hada.io/topic?id=14504","이제는 내가 바보라는 사실을 감추기 위해 허풍을 부릴 힘이 부족합니다.","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                이제는 내가 바보라는 사실을 감추기 위해 허풍을 부릴 힘이 부족합니다.

Edisto의 영감 및 젊은 화자 활용

     * Padgett Powell은 대학 교수의 임신한 아내와 아기의 모습에서 영감을 받아 Edisto를 집필함. 젊은 화자는 그 앞뒤가 맞지 않는 설정이 주는 자유로움과 매력이 있음.

인종 관계 묘사에 대해

     * Powell은 당시 인종 관계를 솔직하게 묘사하려 했으며, 실제 경험을 바탕으로 씀. 오늘날에는 그런 내용을 그대로 출판하기 어려울 것이라고 봄.

남부 문학 전통에 대한 견해

     * 남부 문학에 편입되는 것을 반기면서도 거리를 두는 애매한 입장을 취해왔음. 남부를 진지하게 믿는 것과 조롱하는 것 사이에서 줄타기를 해왔다고 표현함.
     * 남부 작가로 분류되는 것을 꺼리지는 않지만, 감상적인 남부 묘사는 좋아하지 않음. 진정한 남부 문학은 사람들이 얼마나 고통받는지를 깊이 인식하는 것이라고 봄.

The Interrogative Mood 집필 배경

     * 교수의 이메일에 질문으로만 된 장난스러운 답장을 보내며 영감을 받아 질문들로만 구성된 소설을 쓰게 됨.

문체에 대해

     * 라틴어 공부를 통해 자신만의 문체를 개발하게 되었음.

현대 독자의 반응에 대해

     * 최근 학생들 사이에서는 책의 파워보다 정치적 올바름에 더 신경쓰는 경향이 있다고 느낌. 자신의 책에서도 민감한 내용을 검열당한 경험이 있음.

문학의 미래에 대한 견해

     * 대중적 인기를 얻기 어려운 게 문학의 숙명이라고 봄. 미국에서 베스트셀러가 되려면 뭔가 잘못된 것이며, 이는 트럼프 현상과도 연결된다고 생각함.

GN⁺의 의견

     * Powell의 인터뷰를 통해 한 작가의 경험과 문학관을 솔직하게 들여다볼 수 있어 흥미로웠음.
     * 그가 40년 전 발표한 Edisto가 여전히 회자되는 것을 보면 세월을 뛰어넘는 작품성이 있음을 알 수 있음.
     * 남부 문학의 전통을 계승하면서도 새로운 시도를 했다는 점, 인종 문제를 직설적으로 다뤘다는 점 등이 주목할 만함.
     * 다만 오늘날 그의 묘사 방식 중 일부는 정치적으로 민감한 내용으로 받아들여질 수 있어, 재평가가 필요할 수도 있겠음.
     * 문학이 대중성을 잃어가는 것에 대한 우려는 공감이 가나, 결국 시대를 뛰어넘는 훌륭한 작품은 독자들에게 사랑받을 것이라고 봄. Powell의 작품이 그 좋은 예가 될 수 있을 것임.

        Hacker News 의견

     * 작가 Padgett Powell과의 훌륭한 인터뷰임. Powell의 솔직하고 유연한 답변과 인터뷰어의 질문에 담긴 NewsSpeak적 요소가 인상적임.
     * Powell은 Don Barthelme의 제자였으며, Barthelme의 주요 작품 경향에 대한 그의 분석이 돋보임.
     * Powell이 언급한 Flann O'Brian도 흥미로운 인물임.
     * Powell은 동료의 이메일에 위트있는 답장을 보냄. 학계에는 이런 위트와 직업 안정성을 겸비한 사람들이 필요함.
     * 특정 인종을 지칭할 때 대문자를 쓰고 다른 색깔은 소문자인 것이 이상함.
     * Powell은 인터뷰어의 질문에 동료 이메일과 같은 반감을 가짐. 그는 질문에 답하면서도 인터뷰어를 비판함.
          + 자신을 ""단순한 사람""이라 칭하며 인터뷰어가 과한 수사를 사용한다고 암시함.
          + ""다음 단어만 생각하며 써내려간다""며 인터뷰어에게 과한 생각은 하지 말라고 함.
          + 책을 읽는 잘못된 방법은 없다는 인터뷰어의 주장에 동의하지 않음. 책 쓰는 잘못된 방법은 있음을 지적.
     * Powell의 목소리를 들을 수 있는 유튜브 인터뷰 영상도 흥미로움.
     * Mupdeemut이라는 단어를 처음 봤지만 사용해보고 싶어짐. (주의: 부적절하게 들릴 수 있음)
     * Powell이 라틴어 3년 공부와 Aeneid 번역으로 영어 작문을 배웠다는 점이 인상적임.
     * 낯선 단어가 많아 읽는 재미가 있는 인터뷰임.
     * Powell과의 또 다른 훌륭한 인터뷰도 있음.
     * Verisimilitude라는 단어의 파생어인 Verisimilitudinously가 흥미로움.
"
"https://news.hada.io/topic?id=14553","크래프팅 인터프리터스(Crafting Interpreters): 15개월 만에 완성한 640페이지 분량의 저서","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     크래프팅 인터프리터스(Crafting Interpreters): 15개월 만에 완성한 640페이지 분량의 저서

15개월 만에 640페이지 책 완성

     * 2021년 7월 29일, 프로그래밍 언어에 관한 ""Crafting Interpreters"" 책을 완성함. 15개월 전에 완성했다고 했지만 이제는 진짜 완성됨. 인쇄본, e-book, PDF 버전 모두 완료되어 구매 가능해짐.
     * 640페이지에 가로 8인치, 세로 10인치로 예상보다 훨씬 큰 책이 됨.

새로운 빌드 시스템 개발

     * 한달 정도 휴식 후 다시 작업 시작. 독자들이 제보한 오타와 실수들 수정.
     * 특별한 이유 없이 책의 빌드 시스템을 Dart로 새로 작성함. 기존 Python으로 만든 것은 너무 느리고 유지보수하기 어려웠음.
     * 새 빌드 시스템은 원하는 대로 정확히 HTML과 syntax-highlight된 코드를 생성하고, 기존 Python 버전 대비 10배나 빨라짐.
     * Markdown 처리를 더 잘 제어할 수 있게 되었는데, 당시에는 그냥 재미로 한 작업이었음.

책 디자인

     * 큰 그래픽 디자인 프로젝트는 웹이나 게임 프로그래밍처럼 두 단계로 진행됨. 우선 ""프레임워크""나 ""엔진""을 설정하고, 그 구조에 콘텐츠를 넣음.
     * Adobe InDesign에서는 스타일과 마스터를 설정함. 마스터는 페이지의 여백과 그리드 라인을 정의하고, 스타일은 CSS처럼 특정 텍스트나 오브젝트에 글꼴, 스타일, 색상을 지정함.
     * 책 디자인은 문자 그대로 2차원 공간 작업임. 수평과 수직 방향 모두 쉽지 않은 작업이 됨.

너비와 높이 결정

     * 메인 텍스트 열은 가장 긴 코드 라인을 수용할 만큼 너비가 필요함. Aside는 특정 문장 옆에 배치되어야 해서 공간이 더 필요함.
     * 결국 8인치 폭의 페이지 메트릭을 사용하기로 함. 10인치 높이를 선택한 것은 POD (Publish on Demand) 업체에서 지원하는 사이즈 제약 때문.
     * 전체적으로 크긴 하지만 너무 큰 느낌은 아니길 바람. 다음에 책을 쓴다면 더 작은 책을 쓰겠음.

XML 처리

     * InDesign은 XML import를 지원함. 특정 태그에 자동으로 스타일을 적용할 수 있음.
     * 마크다운 프로세싱을 완벽히 제어할 수 있어서 InDesign에 최적화된 XML을 직접 생성할 수 있었음.

InDesign에서의 JavaScript

     * XML import만으로는 한계가 있음. Aside와 코드 위치 표시는 본문에서 빼내서 옆으로 배치해야 함.
     * InDesign은 JavaScript로 스크립팅이 가능함. 하지만 디버거나 스택 트레이스 같은 건 없고 alert() 뿐임.
     * 어찌어찌 Aside와 위치 태그를 뽑아내서 별도 텍스트 박스로 만드는 스크립트는 작성했으나, 정확한 위치 지정은 못했음. InDesign의 앵커 기능으로 어느정도 해결.

편집 작업

     * 전체 책을 다시 한번 읽으며 편집함. 같은 말장난을 많이 반복한 걸 알게됨. 5개월 걸림.
     * 전문 교정 편집자를 고용함. Word를 사용하는 편집 세계와 달리 나는 plain text와 Git을 고수함. 편집자가 잘 적응해줌.

조판 작업

     * 조판 작업 과정은 다음과 같음:
         1. 다음 장의 새 InDesign 파일 생성
         2. XML로 export
         3. InDesign으로 XML import
         4. JS 스크립트로 Aside와 위치 태그 추출
         5. Sidebar 요소들에 앵커 지정
         6. 페이지 끝 부분 공백 조정
     * 1~5 단계는 쉬웠으나 6단계가 가장 어려웠음.
     * 그림이 잘리거나 Aside가 다음 페이지로 넘어가선 안되고, 가능하면 코드도 페이지에 잘리지 않아야 함. 헤더 아래 내용 없이 페이지가 끝나는 것도 피해야 하고, widow/orphan 피하는 것도 중요함.
     * 630개나 되는 페이지에 이 규칙들을 모두 적용하는게 쉽지 않았음.

삽화

     * 삽화는 비교적 쉬웠음. 흑백으로 펜으로 그렸기에 인쇄에 적합함.
     * 하지만 페이지에 배치하는 건 또 다른 문제였음. 내 책은 삽화를 직접 참조하도록 글을 썼기에 삽화가 언급된 위치 근처에 삽화가 있어야 함. 그래서 630개의 페이지에 삽화와 코드, 본문이 잘 배치되도록 수작업으로 조정해야 했음.

앞/뒷부분 작업

     * 전문 색인 작성가도 있다는 걸 처음 알게됨. 나는 직접 2주에 걸쳐 색인을 만듦.
     * 앞부분에는 제목, 저작권, 헌사, 감사의 글을 넣고 InDesign이 자동으로 목차를 만들어 주도록 함. 여기까지 하니 드디어 책 내부가 완성됨.

표지 디자인

     * 책 표지는 중요함. 내 책에는 펜화 스타일의 삽화가 특징이라 그걸 활용하기로 함.
     * 등반 은유로 사용한 산 그림을 좀더 크고 디테일하게 그림. 직접 손글씨로 제목도 새로 씀.
     * 1950년대 스카우트 매뉴얼 같은 느낌의 색상을 사용함.

교정쇄 검토

     * POD로 주문한 교정쇄로 처음 책의 크기를 실감함. 오랜 시간의 작업량이 느껴짐.
     * 하지만 아직 끝난게 아님. 많은 부분 수작업으로 조판 작업을 했기에 실수가 있을 수 있어서 다시 한번 읽어보며 체크해야 함.
     * Git에 InDesign 파일을 올렸지만 바이너리라 변경사항 확인이 어려움.
     * 교정쇄와 변경사항 비교를 위해 Dart 스크립트로 PDF를 한 페이지씩 이미지로 만들고, Photoshop 액션으로 픽셀 차이 나는 부분에 빨간 테두리를 그리게 함.
     * 프로그래밍으로 정확히 의도한 변경만 되었음을 확인할 수 있어서 안심이 됨.

E-book 제작

     * 빌드 시스템을 활용해 EPUB에 필요한 XHTML과 메타데이터를 모두 생성함. 여러 리더기에서 테스트하며 CSS를 조정함.

GN⁺의 의견

     * 6년에 걸친 대장정 끝에 640페이지나 되는 분량의 책을 완성한 것은 대단한 성과임. 집필 과정에서 Dart로 빌드 시스템을 직접 개발하고, 조판을 위해 InDesign용 스크립트를 만드는 등 프로그래밍 기술을 총동원한 점이 흥미로움.
     * 특히 교정쇄 단계에서 변경 검증을 위해 PDF 비교용 스크립트를 만든 부분은 감탄을 자아냄. 이런 아이디어와 실행력이 있어야 개인이 책을 self-publishing할 수 있을 것 같음.
     * 다만 목표한 페이지 사이즈가 크다보니 조판 작업이 쉽지 않았던 점, 인쇄소 사정으로 사이즈 선택에 제약이 있었던 점은 아쉬움. 차기 작에는 좀더 출판 친화적인 사이즈를 택하는 것이 좋겠음.
     * 저자가 언급했듯 프로그래밍 언어 해설서의 경우 표지 디자인이 판매에 크게 영향을 주진 않겠지만, 이 책의 디자인 컨셉처럼 내용의 특징을 반영한 개성있는 표지는 오히려 눈에 띄는 장점이 될 수 있을 것임.
     * 무려 6년간 틈틈이 집필했다는 점에서 저자의 열정과 끈기에 경의를 표함. 이제 독자들이 얼마나 이 책을 찾을지, 어떤 피드백을 줄지 지켜볼 일만 남음. 분명 프로그래밍 언어를 학습하려는 많은 이들에게 도움이 될 책임은 분명해 보임.

        Hacker News 의견

     * Crafting Interpreters는 책 구매 링크와 무료 온라인 버전 링크를 모두 제공하는 웹페이지를 가지고 있음
     * 저자인 Nystrom이 물리적 사본 디자인에 기울인 세심한 주의와 손으로 그린 삽화, 훌륭한 글쓰기 덕분에 기술서적의 99%보다 나은 책으로, 구매할 가치가 충분함
     * 2017년부터 이 책을 통해 공부하기 시작했고, 책의 전반부를 마치면서 토크나이저/렉서/파서/인터프리터에 대한 이해가 명료해짐. 이는 Nystrom의 훌륭한 글쓰기와 주제에 대한 깊은 이해 덕분임
     * 저자가 실물 책으로 만들기로 결정했다는 사실을 몰랐는데, 비록 내게 가장 적합한 학습 방식은 아니지만 소장용으로, 그리고 저자를 후원하기 위해 구매하고 싶음
     * 지금까지 읽었던 기술서적 중 최고 수준으로, 읽으면서 많은 것을 배우고 정말 즐거웠음. 훌륭한 기술적 내용 외에도 글이 잘 쓰여졌고, 재치있으며, 삽화도 잘 그려져 있음
     * 각 챕터 말미에 진화하는 코드와 실행 가능한 프로그램을 갖추겠다는 비전이 인상적이었고, 저자가 그것을 해냈다는 점에서 찬사를 보냄. 트리-워킹 인터프리터는 건너뛰고 C 기반 바이트코드 인터프리터 부분을 통해 훨씬 더 많은 것을 배움
     * ironically 15개월 걸려 책을 다 읽었다는 댓글러가 있는데, 저자의 노고에 감사와 축하를 전함. 언어 영역에서 기술적 깊이가 있을 뿐 아니라 레이아웃과 그래픽의 작은 디테일도 독자를 몰입하게 만드는 책으로, 앞으로 오랫동안 의미있는 책이 될 것 같음
     * 이 책을 읽고 배운 내용을 바탕으로 직접 https://hexmos.com/compiler 페이지를 만들 정도로 책에 큰 애착을 느낌
     * 저자 Bob과의 인터뷰(https://corecursive.com/032-bob-nystrom-on-building-an-interpreter/)를 들어볼 만함
     * 저자가 그래픽 디자이너 출신 컴파일러 엔지니어라는 사실이 인상적임
     * Writing an Interpreter in Go 책을 읽은 후 다음 인터프리터 책으로 이 책을 읽을 예정인데, 200페이지 정도로 분량도 적당하고 마음에 듦
     * (2021년 댓글) 훌륭한 책이며 읽으면서 정말 즐거웠다고 함
"
"https://news.hada.io/topic?id=14562","[2024/04/22 ~ 04/28] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [2024/04/22 ~ 04/28] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)

     * DAIR.AI에서 매주 공개하는 ML 논문들에 대한 글을 자동 번역해보았습니다.
     * 이번 주에 제출된 논문들을 살펴보면 대부분이 차세대 언어 모델(Large Language Models, LLMs)과 그 응용 분야에 초점을 맞춘 것으로 보입니다. 구체적으로 ""Make Your LLM Fully Utilize the Context"", ""Graph Machine Learning in the Era of LLMs"", ""Self-Evolution of LLMs"" 그리고 ""Naturalized Execution Tuning (NExT)"" 등은 LLMs의 발전 및 최적화 방법, 그리고 새로운 응용 분야에 대한 연구 내용을 다루고 있습니다. 이는 최근 인공지능 분야에서 LLMs의 중요성과 응용 가능성이 커지고 있음을 반영합니다.
     * LLMs의 발전이 중요한 이유는 이 모델들이 자연어 처리(Natural Language Processing, NLP)뿐만 아니라 여러 멀티모달(Task) 작업을 수행할 때도 뛰어난 성능을 보이기 때문입니다. 예를 들어, ""Make Your LLM Fully Utilize the Context""라는 논문은 LLMs가 제공하는 컨텍스트를 최대한 활용하여 보다 정확한 정보를 추출하고 해석하는 방법에 대해 탐구합니다. 또한, ""Graph Machine Learning in the Era of LLMs""는 그래프 기반 데이터 학습이 어떻게 LLMs를 통해 향상될 수 있는지에 대한 연구로, 이는 복잡한 관계와 패턴을 이해하는 데 큰 도움이 됩니다.
     * 이러한 경향은 인공지능 분야에서 LLMs의 역할이 단순히 언어 이해와 생성에 그치지 않고, 더 광범위한 문제 해결과 응용 분야로 확장되고 있음을 시사합니다. 이는 연구자들이 인공지능의 다양한 측면을 탐색하고, 특히 인간의 언어를 더 잘 이해하고 사용할 수 있는 모델을 개발하기 위한 노력의 일환으로 볼 수 있습니다. 또한 이러한 연구 경향은 앞으로도 다양한 분야에서의 LLMs 활용이 증가할 것이라는 전망을 뒷받침합니다.

   [IMG] [2024/04/22 ~ 04/28] 이번 주의 주요 ML 논문 (Top ML Papers of the Week)|1028x618
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  Phi-3 기술 보고서: 휴대전화의 로컬에서 뛰어난 성능을 발휘하는 언어 모델 / Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone

    논문 소개

   3조 3천억 개의 토큰으로 훈련된 새로운 3.8B 매개변수 언어 모델인 phi-3-mini는 Mixtral 8x7B 및 GPT-3.5와 경쟁하는 것으로 보고되었으며, 기본 컨텍스트 길이가 4K이지만 128K로 확장된 버전(phi-mini-128K)도 포함하고, 3.8B 모델을 훈련하기 위해 고도로 필터링된 웹 데이터와 합성 데이터를 결합하고, 4.8T 토큰으로 훈련된 7B 및 14B 모델(phi-3-small 및 phi-3-medium) 결과도 보고하고 있습니다.

     A new 3.8B parameter language model called phi-3-mini trained on 3.3 trillion tokens and is reported to rival Mixtral 8x7B and GPT-3.5; has a default context length of 4K but also includes a version that is extended to 128K (phi-mini-128K); combines heavily filtered web data and synthetic data to train the 3.8B models; it also reports results on 7B and 14B models trained on 4.8T tokens (phi-3-small and phi-3-medium).

    논문 초록(Abstract)

   3조 3천억 개의 토큰으로 훈련된 38억 개의 파라미터 언어 모델인 phi-3-mini를 소개합니다. 학술 벤치마크와 내부 테스트에서 측정한 전체 성능은 휴대폰에 배포할 수 있을 만큼 작은 크기임에도 불구하고 Mixtral 8x7B 및 GPT-3.5와 같은 모델에 필적하는 수준(예: phi-3-mini는 MMLU에서 69%, MT-bench에서 8.38 달성)에 이르렀습니다. 이러한 혁신은 전적으로 훈련용 데이터 세트에 있으며, 이는 고도로 필터링된 웹 데이터와 합성 데이터로 구성된 phi-2에 사용된 데이터 세트의 확장 버전입니다. 이 모델은 또한 견고성, 안전성 및 채팅 형식에 맞게 더욱 조정되었습니다. 또한 4.8T 토큰에 대해 훈련된 7B 및 14B 모델, 즉 phi-3-small 및 phi-3-medium으로 불리는 초기 파라미터 확장 결과를 제공하며, 두 모델 모두 phi-3-mini보다 훨씬 더 뛰어난 성능(예: MMLU에서 각각 75% 및 78%, MT-bench에서 8.7 및
   8.9)을 보입니다.

     We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75% and 78% on MMLU, and 8.7 and 8.9 on MT-bench).

    논문 링크

   https://arxiv.org/abs/2404.14219

    더 읽어보기

   https://discuss.pytorch.kr/t/…

   https://x.com/omarsar0/status/1782780923806699716
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  OpenELM: 오픈 소스 학습 및 추론 프레임워크가 포함된 효율적인 언어 모델 제품군 / OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework

    논문 소개

   계층별 확장 전략을 사용하여 파라미터를 효율적으로 할당하고 효율성과 정확도를 향상시키는 새로운 개방형 언어 모델로, 270M, 450M, 1.1B, 3B 등 다양한 크기로 제공되며, 사전 학습 토큰이 2배 더 적게 필요하면서 OLMo 대비 정확도가 2.36% 향상됩니다.

     A new open language model that employs a layer-wise scaling strategy to efficiently allocate parameters and leading to better efficiency and accuracy; comes with different sizes such as 270M, 450M, 1.1B, and 3B; achieves a 2.36% improvement in accuracy compared to OLMo while requiring 2× fewer pre-training tokens.

    논문 초록(Abstract)

   대규모 언어 모델의 재현성과 투명성은 공개 연구를 발전시키고, 결과의 신뢰성을 보장하며, 데이터와 모델 편향성 및 잠재적 위험에 대한 조사를 가능하게 하는 데 매우 중요합니다. 이를 위해 최신 개방형 언어 모델인 OpenELM을 출시합니다. OpenELM은 계층별 확장 전략을 사용하여 트랜스포머 모델의 각 계층 내에서 파라미터를 효율적으로 할당함으로써 정확도를 향상시킵니다. 예를 들어, 매개변수 예산이 약 10억 개인 경우 OpenELM은 OLMo에 비해 정확도가 2.36% 향상되는 동시에 사전 학습 토큰이 2\배 더 적게 필요합니다. 모델 가중치와 추론 코드만 제공하고 비공개 데이터 세트에 대한 사전 학습만 제공하던 이전 사례와 달리, 이번 릴리스에는 학습 로그, 다중 체크포인트, 사전 학습 구성을 포함해 공개적으로 사용 가능한 데이터 세트에서 언어 모델을
   학습하고 평가하기 위한 전체 프레임워크가 포함되어 있습니다. 또한 Apple 기기에서 추론 및 미세 조정을 위해 모델을 MLX 라이브러리로 변환하는 코드도 릴리스합니다. 이 포괄적인 릴리스는 오픈 리서치 커뮤니티에 힘을 실어주고 강화하여 향후 오픈 리서치를 위한 기반을 마련하는 것을 목표로 합니다. 사전 훈련된 모델 가중치 및 훈련 레시피와 함께 소스 코드는 \url{https://github.com/apple/corenet}에서 확인할 수 있습니다. 또한, \모델 모델은 HuggingFace에서 찾을 수 있습니다: \url{https://huggingface.co/apple/OpenELM}.

     The reproducibility and transparency of large language models are crucial for advancing open research, ensuring the trustworthiness of results, and enabling investigations into data and model biases, as well as potential risks. To this end, we release OpenELM, a state-of-the-art open language model. OpenELM uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy. For example, with a parameter budget of approximately one billion parameters, OpenELM exhibits a 2.36% improvement in accuracy compared to OLMo while requiring $2\times$ fewer pre-training tokens. Diverging from prior practices that only provide model weights and inference code, and pre-train on private datasets, our release includes the complete framework for training and evaluation of the language model on publicly available datasets, including training logs, multiple checkpoints, and pre-training configurations. We also
     release code to convert models to MLX library for inference and fine-tuning on Apple devices. This comprehensive release aims to empower and strengthen the open research community, paving the way for future open research endeavors. Our source code along with pre-trained model weights and training recipes is available at \url{https://github.com/apple/corenet}. Additionally, \model models can be found on HuggingFace at: \url{https://huggingface.co/apple/OpenELM}.

    논문 링크

   https://arxiv.org/abs/2404.14619

    더 읽어보기

   https://discuss.pytorch.kr/t/apple-270m-3b-openelm/4204

   https://github.com/apple/corenet

   https://huggingface.co/apple/OpenELM

   https://x.com/rasbt/status/1783480053847736713
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  Snowflake Arctic

    논문 소개

   고유한 Dense-MoE 하이브리드 트랜스포머 아키텍처를 사용하는 오픈 소스 LLM(Apache 2.0 라이선스.)으로, 코딩(HumanEval+ 및 MBPP+), SQL(Spider), 명령어 추종(IFEval) 등의 엔터프라이즈 지표에서 Llama3 70B와 동등한 성능, Llama3 70B보다 17배 적은 컴퓨팅 예산을 사용한다고 주장하며 훈련 컴퓨팅은 약 2백만 달러 미만(3K GPU 주 미만)입니다.

     An open-source LLM (Apache 2.0 license.) that uses a unique Dense-MoE Hybrid transformer architecture; performs on par with Llama3 70B in enterprise metrics like coding (HumanEval+ & MBPP+), SQL (Spider) and instruction following (IFEval); claims to use 17x less compute budget than Llama 3 70B; the training compute is roughly under $2 million (less than 3K GPU weeks).

    논문 링크

   https://snowflake.com/blog/…

    더 읽어보기

   https://discuss.pytorch.kr/t/…

   https://x.com/omarsar0/status/1783176059694821632
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  컨텍스트를 최대한 활용하는 LLM 만들기 / Make Your LLM Fully Utilize the Context

    논문 소개

   LLM에서 흔히 발생하는 중도 포기 문제를 극복하기 위한 접근 방식을 제시합니다. Mistral-7B에 명시적인 '정보 집약적' 훈련 절차를 적용하여 LLM이 문맥을 충분히 활용할 수 있도록 합니다. 이 모델은 1) 합성된 긴 컨텍스트(4K-32K 토큰) 내에서 짧은 세그먼트(∼128개)에 대한 세분화된 정보 인식과 2) 두 개 이상의 짧은 세그먼트의 정보를 통합하고 추론해야 하는 합성 데이터 세트를 활용합니다. 결과 모델인 FILM-7B(중간 채우기)는 32K 컨텍스트 창에서 서로 다른 위치의 정보를 안정적으로 검색할 수 있음을 보여줍니다.

     Presents an approach to overcome the lost-in-the-middle challenge common in LLMs. It applies an explicit ""information-intensive"" training procedure on Mistral-7B to enable the LLM to fully utilize the context. It leverages a synthetic dataset where the answer requires fine-grained information awareness on a short segment (∼128 tokens) within a synthesized long context (4K−32K tokens), and 2) the integration and reasoning of information from two or more short segments. The resulting model, FILM-7B (Fill-in-the-Middle), shows that it can robustly retrieve information from different positions in its 32K context window.

    논문 초록(Abstract)

   현대의 많은 대규모 언어 모델(LLM)은 긴 입력을 처리할 수 있지만, 여전히 긴 문맥 내의 정보를 완전히 활용하는 데 어려움을 겪고 있으며, 이는 중간에서 길을 잃는 문제라고 알려져 있습니다. 우리는 이 문제가 긴 문맥 훈련 중 명시적인 감독이 불충분하여 긴 문맥의 모든 위치가 중요한 정보를 포함할 수 있다는 점을 강조하지 못하기 때문이라고 가설을 세웠습니다. 이러한 직관을 바탕으로 본 연구에서는 중간 손실 문제를 극복하기 위한 순수 데이터 기반 솔루션인 정보 집약적(IN2) 훈련을 제시합니다. 구체적으로 IN2 훈련은 합성된 긴 문맥의 질문-답변 데이터 세트를 활용하며, 여기서 답을 구하려면 (1) 합성된 긴 문맥(4K-32K 토큰) 내에서 짧은 세그먼트(~128개)에 대한 세분화된 정보 인식과 (2) 두 개 이상의 짧은 세그먼트에서 정보를 통합하고 추론하는
   것이 필요합니다. 이러한 정보 집약적인 훈련을 미스트랄-7B에 적용하여 FILM-7B(FILl-in-the-Middle)를 선보입니다. 긴 컨텍스트를 활용하는 FILM-7B의 능력을 철저히 평가하기 위해 다양한 컨텍스트 스타일(문서, 코드, 구조화된 데이터 컨텍스트)과 정보 검색 패턴(정방향, 역방향, 양방향 검색)을 포괄하는 세 가지 프로빙 작업을 설계했습니다. 프로빙 결과는 FILM-7B가 32K 컨텍스트 창에서 다양한 위치의 정보를 안정적으로 검색할 수 있음을 보여줍니다. 이러한 프로빙 작업 외에도, FILM-7B는 실제 긴 컨텍스트 작업에서 성능을 크게 향상시키면서(예: NarrativeQA에서 F1 점수 23.5->26.9), 짧은 컨텍스트 작업에서도 비슷한 성능을 유지합니다(예: MMLU에서 59.3->59.2 정확도). 깃허브 링크: https://github.com/microsoft/FILM.

     While many contemporary large language models (LLMs) can process lengthy input, they still struggle to fully utilize information within the long context, known as the lost-in-the-middle challenge. We hypothesize that it stems from insufficient explicit supervision during the long-context training, which fails to emphasize that any position in a long context can hold crucial information. Based on this intuition, our study presents information-intensive (IN2) training, a purely data-driven solution to overcome lost-in-the-middle. Specifically, IN2 training leverages a synthesized long-context question-answer dataset, where the answer requires (1) fine-grained information awareness on a short segment (~128 tokens) within a synthesized long context (4K-32K tokens), and (2) the integration and reasoning of information from two or more short segments. Through applying this information-intensive training on Mistral-7B, we present FILM-7B (FILl-in-the-Middle). To thoroughly assess
     the ability of FILM-7B for utilizing long contexts, we design three probing tasks that encompass various context styles (document, code, and structured-data context) and information retrieval patterns (forward, backward, and bi-directional retrieval). The probing results demonstrate that FILM-7B can robustly retrieve information from different positions in its 32K context window. Beyond these probing tasks, FILM-7B significantly improves the performance on real-world long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2 accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.

    논문 링크

   https://arxiv.org/abs/2404.16811

    더 읽어보기

   https://github.com/microsoft/FILM

   https://x.com/omarsar0/status/1783905514578980949
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  FineWeb

    논문 소개

   언어 모델 학습을 위한 15조 개의 토큰이 포함된 대규모 웹 데이터 세트, 2013년부터 2024년까지 CommonCrawl을 필터링 및 중복 제거하여 데이터의 품질을 개선하는 것이 목표입니다.

     A large-scale web dataset containing 15 trillion tokens for training language models; filters and deduplicates CommonCrawl between 2013 and 2024 and the goal is to improve the quality of the data.

    논문 링크

   https://huggingface.co/datasets/HuggingFaceFW/fineweb

    더 읽어보기

   https://x.com/gui_penedo/status/1781953413938557276
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  AI 기반 유전자 편집기 / AI-powered Gene Editors

    논문 소개

   대규모 생물학적 다양성에 대해 학습된 LLM으로 구동되는 AI 시스템으로 프로그래밍 가능한 유전자 편집기 설계를 통해 인간 게놈의 정밀 편집을 달성합니다.

     Achieves precision editing of the human genome with a programmable gene editor design with an AI system powered by an LLM trained on biological diversity at scale.

    논문 링크

   https://www.biorxiv.org/content/10.1101/2024.04.22.590591v1

    더 읽어보기

   https://x.com/thisismadani/status/1782510590839406904
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  자동 크롤러: 웹 크롤러 생성을 위한 웹 에이전트에 대한 진보적인 이해 / AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation

    논문 소개

   크롤러가 다양하고 변화하는 웹 환경을 보다 효율적으로 처리할 수 있도록 돕기 위해 LLM과 크롤러를 결합하고, 웹 크롤러 에이전트는 HTML의 계층 구조를 활용하여 점진적으로 이해하고, 하향식 및 단계적 작업을 사용하며, DOM 트리 구조를 활용하여 완전하고 실행 가능한 크롤러를 생성합니다.

     Combines LLMs with crawlers with the goal of helping crawlers handle diverse and changing web environments more efficiently; the web crawler agent leverages the hierarchical structure of HTML for progressive understanding; employs top-down and step-back operations, and leverages the DOM tree structure, to generate a complete and executable crawler.

    논문 초록(Abstract)

   웹 자동화는 일반적인 웹 작업을 자동화하고 운영 효율성을 높이며 수동 개입의 필요성을 줄임으로써 복잡한 웹 작업을 수행하는 중요한 기술입니다. 래퍼와 같은 기존 방식은 새로운 웹사이트에 직면했을 때 적응성과 확장성에 한계가 있습니다. 반면에 대규모 언어 모델(LLM)로 구동되는 제너레이티브 에이전트는 오픈 월드 시나리오에서 성능과 재사용성이 떨어집니다. 본 연구에서는 수직 정보 웹 페이지에 대한 크롤러 생성 작업과 다양하고 변화하는 웹 환경을 크롤러가 보다 효율적으로 처리할 수 있도록 LLM과 크롤러를 결합하는 패러다임을 소개합니다. HTML의 계층 구조를 활용하여 점진적으로 이해하는 2단계 프레임워크인 오토크롤러를 제안합니다. 오토크롤러는 하향식 및 단계적 작업을 통해 잘못된 동작을 학습하고 더 나은 동작 생성을 위해
   지속적으로 HTML을 정리할 수 있습니다. 여러 LLM으로 포괄적인 실험을 수행하여 프레임워크의 효과를 입증했습니다. 이 논문의 리소스는 \url{https://github.com/EZ-hwh/AutoCrawler}에서 확인할 수 있습니다

     Web automation is a significant technique that accomplishes complicated web tasks by automating common web actions, enhancing operational efficiency, and reducing the need for manual intervention. Traditional methods, such as wrappers, suffer from limited adaptability and scalability when faced with a new website. On the other hand, generative agents empowered by large language models (LLMs) exhibit poor performance and reusability in open-world scenarios. In this work, we introduce a crawler generation task for vertical information web pages and the paradigm of combining LLMs with crawlers, which helps crawlers handle diverse and changing web environments more efficiently. We propose AutoCrawler, a two-stage framework that leverages the hierarchical structure of HTML for progressive understanding. Through top-down and step-back operations, AutoCrawler can learn from erroneous actions and continuously prune HTML for better action generation. We conduct comprehensive
     experiments with multiple LLMs and demonstrate the effectiveness of our framework. Resources of this paper can be found at \url{https://github.com/EZ-hwh/AutoCrawler}

    논문 링크

   https://arxiv.org/abs/2404.12753

    더 읽어보기

   https://github.com/EZ-hwh/AutoCrawler

   https://x.com/omarsar0/status/1782462314983071757
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  대규모 언어 모델(LLM) 시대의 그래프 머신 러닝 / Graph Machine Learning in the Era of Large Language Models (LLMs)

    논문 소개

   그래프 ML의 최근 발전 사항, 그래프 기능을 향상시키는 방법, OOD 및 그래프 이질성과 같은 문제를 해결하는 방법 등 LLM 시대의 그래프 ML에 대한 최신 발전 사항을 포괄적으로 살펴봅니다.

     Provides a comprehensive overview of the latest advancements for Graph ML in the era of LLMs; covers the recent developments in Graph ML, how LLM can enhance graph features, and how it can address issues such as OOD and graph heterogeneity.

    논문 초록(Abstract)

   그래프는 소셜 네트워크, 지식 그래프, 분자 발견과 같은 다양한 영역에서 복잡한 관계를 표현하는 데 중요한 역할을 합니다. 딥러닝의 출현과 함께 그래프 신경망(GNN)은 그래프 구조의 표현과 처리를 용이하게 하는 그래프 머신러닝(Graph ML)의 초석으로 떠올랐습니다. 최근 LLM은 언어 작업에서 전례 없는 능력을 보여주며 컴퓨터 비전 및 추천 시스템과 같은 다양한 애플리케이션에 널리 채택되고 있습니다. 이러한 괄목할 만한 성공은 그래프 영역에 LLM을 적용하는 데에도 관심을 불러일으켰습니다. 그래프 ML의 일반화, 전이성, 소수점 학습 능력을 발전시키는 데 있어 LLM의 잠재력을 탐구하려는 노력이 점점 더 많아지고 있습니다. 한편 그래프, 특히 지식 그래프는 신뢰할 수 있는 사실적 지식이 풍부하기 때문에 이를 활용하여 LLM의 추론 능력을 향상시키고
   환각이나 설명력 부족과 같은 한계를 완화할 수 있습니다. 이러한 연구 방향의 빠른 진전을 고려할 때, 연구자 및 실무자에게 심도 있는 이해를 제공하기 위해 LLM 시대의 그래프 ML에 대한 최신 발전 사항을 정리한 체계적인 리뷰가 필요합니다. 따라서 이번 설문조사에서는 먼저 그래프 ML의 최근 발전 상황을 살펴봅니다. 그런 다음 그래프 특징의 품질을 향상시키고, 라벨링된 데이터에 대한 의존도를 완화하며, 그래프 이질성 및 분포 외 일반화(OOD) 같은 문제를 해결하기 위해 LLM을 어떻게 활용할 수 있는지 살펴봅니다. 그런 다음 그래프가 어떻게 LLM을 향상시킬 수 있는지 살펴보고, 그래프가 LLM 사전 학습과 추론을 향상시키는 기능을 강조합니다. 또한 다양한 응용 사례를 살펴보고 이 유망한 분야의 잠재적인 미래 방향에 대해 논의합니다.

     Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML's generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as
     hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.

    논문 링크

   https://arxiv.org/abs/2404.14928

    더 읽어보기

   https://x.com/omarsar0/status/1783171591020392886
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  대규모 언어 모델의 자기 진화에 관한 설문 조사 / A Survey on Self-Evolution of Large Language Models

    논문 소개

   LLM의 자기 진화 접근 방식에 대한 종합적인 설문조사를 제공합니다.

     Provides a comprehensive survey on self-evolution approaches in LLMs.

    논문 초록(Abstract)

   대규모 언어 모델(LLM)은 다양한 분야와 지능형 에이전트 애플리케이션에서 크게 발전해 왔습니다. 그러나 사람이나 외부 모델의 감독을 통해 학습하는 현재의 LLM은 비용이 많이 들고 작업의 복잡성과 다양성이 증가함에 따라 성능 한계에 직면할 수 있습니다. 이 문제를 해결하기 위해 모델 자체에서 생성된 경험을 자율적으로 획득, 개선, 학습할 수 있는 자가 진화 접근 방식이 빠르게 성장하고 있습니다. 인간의 경험적 학습 과정에서 영감을 얻은 이 새로운 훈련 패러다임은 초지능을 향해 LLM을 확장할 수 있는 잠재력을 제공합니다. 이 글에서는 LLM의 자기 진화 접근 방식에 대한 포괄적인 조사를 소개합니다. 먼저 자기 진화에 대한 개념적 프레임워크를 제안하고 진화 과정을 경험 획득, 경험 개선, 업데이트, 평가의 네 단계로 구성된 반복 주기로
   개괄적으로 설명합니다. 둘째, LLM과 LLM 기반 에이전트의 진화 목표를 분류한 다음, 문헌을 요약하고 각 모듈에 대한 분류법과 인사이트를 제공합니다. 마지막으로, 기존의 과제를 정확히 파악하고 자가 진화 프레임워크를 개선하기 위한 향후 방향을 제안하여 연구자들이 자가 진화하는 LLM의 개발을 빠르게 진행할 수 있는 중요한 인사이트를 제공합니다.

     Large language models (LLMs) have significantly advanced in various fields and intelligent agent applications. However, current LLMs that learn from human or external model supervision are costly and may face performance ceilings as task complexity and diversity increase. To address this issue, self-evolution approaches that enable LLM to autonomously acquire, refine, and learn from experiences generated by the model itself are rapidly growing. This new training paradigm inspired by the human experiential learning process offers the potential to scale LLMs towards superintelligence. In this work, we present a comprehensive survey of self-evolution approaches in LLMs. We first propose a conceptual framework for self-evolution and outline the evolving process as iterative cycles composed of four phases: experience acquisition, experience refinement, updating, and evaluation. Second, we categorize the evolution objectives of LLMs and LLM-based agents; then, we summarize the
     literature and provide taxonomy and insights for each module. Lastly, we pinpoint existing challenges and propose future directions to improve self-evolution frameworks, equipping researchers with critical insights to fast-track the development of self-evolving LLMs.

    논문 링크

   https://arxiv.org/abs/2404.14387

    더 읽어보기

   https://x.com/omarsar0/status/1782777977526231440
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  NExT: 대규모 언어 모델에 코드 실행에 대한 추론 교육하기 / NExT: Teaching Large Language Models to Reason about Code Execution

    논문 소개

   프로그램의 실행 추적을 검사하고 합성 사고 연쇄를 통해 런타임 동작을 추론할 수 있는 능력을 갖추도록 LLM을 훈련하고, MBPP와 Human에서 PaLM 2 모델의 수정률을 26.1%와 14.3% 향상시키고, 알 수 없는 시나리오에 대해서도 일반화할 수 있음을 보여줍니다.

     Trains an LLM to have the ability to inspect the execution traced of programs and reason about run-time behavior via synthetic chain-of-thought rationales; improves the fix rate of a PaLM 2 model on MBPP and Human by 26.1% and 14.3%; the model also shows that it can generalize to unknown scenarios.

    논문 초록(Abstract)

   인간 개발자의 기본 능력은 프로그램 실행을 이해하고 추론하는 능력입니다. 예를 들어 프로그래머는 자연어로 코드 실행을 정신적으로 시뮬레이션하여 코드를 디버깅하고 복구할 수 있습니다(일명 러버덕 디버깅). 그러나 코드의 대규모 언어 모델(LLM)은 일반적으로 프로그램의 표면 텍스트 형식에 대해 학습되기 때문에 런타임에 프로그램이 실행되는 방식에 대한 의미론적 이해가 부족할 수 있습니다. 이 문제를 해결하기 위해 저희는 LLM이 프로그램의 실행 추적(실행된 줄의 가변 상태)을 검사하고 생각의 연쇄(CoT) 논리를 통해 런타임 동작을 추론하도록 가르치는 방법인 NExT를 제안합니다. 특히, NExT는 자체 학습을 사용하여 실행 인식 추론의 합성 학습 집합을 부트스트랩하여 힘든 수동 주석 작업 없이 올바른 작업 솔루션(예: 고정 프로그램)으로
   이어집니다. MBPP와 HumanEval을 기반으로 한 프로그램 복구 작업에 대한 실험 결과, NExT는 자동화된 메트릭과 인간 평가자에 의해 검증된 것처럼 PaLM 2 모델의 수정률을 각각 26.1%와 14.3% 절대적으로 향상시키며 근거 품질을 크게 개선하는 것으로 나타났습니다. 또한 이 모델은 테스트 시점에 프로그램 트레이스가 없는 시나리오에도 일반화할 수 있습니다.

     A fundamental skill among human developers is the ability to understand and reason about program execution. As an example, a programmer can mentally simulate code execution in natural language to debug and repair code (aka. rubber duck debugging). However, large language models (LLMs) of code are typically trained on the surface textual form of programs, thus may lack a semantic understanding of how programs execute at run-time. To address this issue, we propose NExT, a method to teach LLMs to inspect the execution traces of programs (variable states of executed lines) and reason about their run-time behavior through chain-of-thought (CoT) rationales. Specifically, NExT uses self-training to bootstrap a synthetic training set of execution-aware rationales that lead to correct task solutions (e.g., fixed programs) without laborious manual annotation. Experiments on program repair tasks based on MBPP and HumanEval demonstrate that NExT improves the fix rate of a PaLM 2 model,
     by 26.1% and 14.3% absolute, respectively, with significantly improved rationale quality as verified by automated metrics and human raters. Our model can also generalize to scenarios where program traces are absent at test-time.

    논문 링크

   https://arxiv.org/abs/2404.14662

    더 읽어보기

   https://x.com/AnsongNi/status/1783311827390070941
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

  원문

   https://nlp.elvissaravia.com/p/top-ml-papers-of-the-week-b1c
     __________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

   이 글은 GPT 모델로 정리한 것으로, 잘못된 부분이 있을 수 있으니 글 아래쪽의 원문도 함께 참고해주세요! 읽으시면서 어색하거나 잘못된 내용을 발견하시면 덧글로 알려주시기를 부탁드립니다.

   ⚠️광고⚠️: 파이토치 한국 사용자 모임이 정리한 이 글이 유용하셨나요? 회원으로 가입하시면 주요 글들을 이메일로 보내드립니다! (기본은 Weekly지만 Daily로 변경도 가능합니다.)
"
"https://news.hada.io/topic?id=14580","Show HN: 개인정보 보호를 고려한 심플한 생리주기 추적 앱 개발","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Show HN: 개인정보 보호를 고려한 심플한 생리주기 추적 앱 개발

주요 기능

     * 생리 주기를 빠르고 쉽게 기록할 수 있는 주기 추적기
     * 현재 주기의 몇 번째 날인지, 다음 주기까지 얼마나 남았는지를 한눈에 확인 가능
     * 광고 없는 무료 생리 주기 추적기
     * 한 번의 클릭으로 다음 생리 주기 기록을 시작
     * 다양한 테마 중 하나를 선택하여 앱의 모양과 느낌을 원하는 대로 커스터마이징 가능
     * 통합 달력을 통해 과거 주기를 빠르고 쉽게 기록하고 볼 수 있으며, 미래 주기에 대한 예측도 표시됨
     * 평균 주기 길이나 최근 주기의 지속 시간 등의 통계 제공

배란일 예측 기능

     * 배란일도 추가로 표시할 수 있는 옵션 제공
     * 단, 입력된 주기를 기반으로 한 추정치일 뿐이므로 피임 목적으로 사용해서는 안 됨

데이터 보안

     * 데이터는 오직 사용자에게만 속함
     * 앱은 등록 없이 작동하며 데이터는 사용자의 휴대폰에만 저장됨

GN⁺의 의견

     * 단순하고 직관적인 UI로 사용이 쉬워 보임. 불필요한 기능이 없어 주기 관리에 집중할 수 있을 듯함.
     * 데이터를 사용자 기기에만 저장한다는 점이 개인정보 보호 측면에서 장점. 하지만 기기 분실시 데이터 복구가 어려울 수 있음.
     * 배란일 예측 기능이 있긴 하나, 정확도가 낮을 수 있어 피임 목적으로 사용하기엔 부적합함. 이 부분에 대해 앱 내에서 좀 더 강조할 필요가 있어 보임.
     * 주기 관련 증상이나 컨디션 등을 함께 기록할 수 있는 기능이 있으면 더 유용할 것 같음.
     * Clue, Flo 등 유사한 주기 추적 앱들이 많이 있는데, 이들과의 차별화 포인트가 명확하진 않아 보임. 장기적인 사용자 유지를 위해선 추가적인 기능 개발이 필요해 보임.

        Hacker News 의견

     * 프라이버시를 중시하는 앱 카탈로그가 있는지에 대한 질문이 있음
     * Drip, Bluemoon, Periodical, Log28 등 오픈소스 생리주기 앱 대안들이 소개됨
     * 안드로이드에서 클라우드 기반이 아닌 생리주기 앱을 찾기 어려웠다는 경험담이 공유됨
     * 생리주기 추적의 주요 사용 사례로 계획 수립과 임신 가능성 예측 향상이 제시됨
     * F-Droid에도 프라이버시 중심의 생리주기 앱 옵션들이 있음
     * 앱의 소스 코드 공개, 인앱 결제 제거, 애널리틱스 제거 등을 요구하는 의견들이 있음
     * 프라이버시 중심 앱의 수익화 모델에 대한 질문이 제기됨
     * 여성 개발자가 여성을 위한 앱을 만드는 것에 대한 격려와 오픈소스화 및 프라이버시 강조를 통한 홍보 전략 제안이 있음
     * 간단한 캘린더 앱에 인앱 결제가 필요한지에 대한 의문이 제기됨
     * Ovuview의 알림이 너무 공개적이라는 의견과 함께 가임기 예측 기능 계획에 대한 질문이 있음
"
